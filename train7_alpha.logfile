  0%|          | 0/1001 [00:00<?, ?it/s]  0%|          | 5/1001 [00:00<00:24, 40.93it/s]  1%|          | 10/1001 [00:00<00:24, 41.26it/s]  1%|▏         | 15/1001 [00:00<00:23, 41.29it/s]  2%|▏         | 20/1001 [00:00<00:23, 41.67it/s]  2%|▏         | 25/1001 [00:00<00:23, 41.57it/s]  3%|▎         | 30/1001 [00:00<00:23, 41.46it/s]  3%|▎         | 35/1001 [00:00<00:23, 41.33it/s]  4%|▍         | 40/1001 [00:00<00:23, 41.27it/s]  4%|▍         | 45/1001 [00:01<00:23, 41.33it/s]  5%|▍         | 50/1001 [00:01<00:22, 41.40it/s]  5%|▌         | 55/1001 [00:01<00:22, 41.65it/s]  6%|▌         | 60/1001 [00:01<00:22, 41.53it/s]  6%|▋         | 65/1001 [00:01<00:22, 41.21it/s]  7%|▋         | 70/1001 [00:01<00:22, 41.14it/s]  7%|▋         | 75/1001 [00:01<00:22, 41.23it/s]  8%|▊         | 80/1001 [00:01<00:22, 41.66it/s]  8%|▊         | 85/1001 [00:02<00:21, 41.66it/s]  9%|▉         | 90/1001 [00:02<00:21, 41.77it/s]  9%|▉         | 95/1001 [00:02<00:21, 42.03it/s] 10%|▉         | 100/1001 [00:02<00:21, 41.51it/s] 10%|█         | 105/1001 [00:02<00:21, 41.76it/s] 11%|█         | 110/1001 [00:02<00:21, 41.60it/s] 11%|█▏        | 115/1001 [00:02<00:21, 41.31it/s] 12%|█▏        | 120/1001 [00:02<00:21, 41.19it/s] 12%|█▏        | 125/1001 [00:03<00:21, 41.19it/s] 13%|█▎        | 130/1001 [00:03<00:21, 41.28it/s] 13%|█▎        | 135/1001 [00:03<00:20, 41.83it/s] 14%|█▍        | 140/1001 [00:03<00:20, 41.18it/s] 14%|█▍        | 145/1001 [00:03<00:20, 41.18it/s] 15%|█▍        | 150/1001 [00:03<00:20, 41.10it/s] 15%|█▌        | 155/1001 [00:03<00:20, 41.31it/s] 16%|█▌        | 160/1001 [00:03<00:20, 41.82it/s] 16%|█▋        | 165/1001 [00:03<00:20, 41.68it/s] 17%|█▋        | 170/1001 [00:04<00:20, 41.42it/s] 17%|█▋        | 175/1001 [00:04<00:19, 41.70it/s] 18%|█▊        | 180/1001 [00:04<00:19, 41.63it/s] 18%|█▊        | 185/1001 [00:04<00:19, 41.86it/s] 19%|█▉        | 190/1001 [00:04<00:19, 41.77it/s] 19%|█▉        | 195/1001 [00:04<00:19, 41.74it/s] 20%|█▉        | 200/1001 [00:04<00:19, 41.59it/s] 20%|██        | 205/1001 [00:04<00:19, 41.57it/s] 21%|██        | 210/1001 [00:05<00:19, 41.38it/s] 21%|██▏       | 215/1001 [00:05<00:18, 41.55it/s] 22%|██▏       | 220/1001 [00:05<00:18, 41.41it/s] 22%|██▏       | 225/1001 [00:05<00:18, 41.49it/s] 23%|██▎       | 230/1001 [00:05<00:18, 40.94it/s] 23%|██▎       | 235/1001 [00:05<00:18, 41.27it/s] 24%|██▍       | 240/1001 [00:05<00:18, 40.65it/s] 24%|██▍       | 245/1001 [00:05<00:18, 40.68it/s] 25%|██▍       | 250/1001 [00:06<00:18, 40.98it/s] 25%|██▌       | 255/1001 [00:06<00:18, 40.61it/s] 26%|██▌       | 260/1001 [00:06<00:18, 40.95it/s] 26%|██▋       | 265/1001 [00:06<00:17, 41.31it/s] 27%|██▋       | 270/1001 [00:06<00:17, 41.46it/s] 27%|██▋       | 275/1001 [00:06<00:17, 41.81it/s] 28%|██▊       | 280/1001 [00:06<00:17, 41.77it/s] 28%|██▊       | 285/1001 [00:06<00:17, 41.50it/s] 29%|██▉       | 290/1001 [00:07<00:17, 41.32it/s] 29%|██▉       | 295/1001 [00:07<00:17, 41.40it/s] 30%|██▉       | 300/1001 [00:07<00:17, 41.23it/s] 30%|███       | 305/1001 [00:07<00:16, 41.09it/s] 31%|███       | 310/1001 [00:07<00:16, 41.23it/s] 31%|███▏      | 315/1001 [00:07<00:16, 41.79it/s] 32%|███▏      | 320/1001 [00:07<00:16, 41.39it/s] 32%|███▏      | 325/1001 [00:07<00:16, 41.15it/s] 33%|███▎      | 330/1001 [00:07<00:16, 41.10it/s] 33%|███▎      | 335/1001 [00:08<00:16, 40.69it/s] 34%|███▍      | 340/1001 [00:08<00:16, 40.80it/s] 34%|███▍      | 345/1001 [00:08<00:16, 40.66it/s] 35%|███▍      | 350/1001 [00:08<00:15, 40.99it/s] 35%|███▌      | 355/1001 [00:08<00:15, 41.07it/s] 36%|███▌      | 360/1001 [00:08<00:15, 41.26it/s] 36%|███▋      | 365/1001 [00:08<00:15, 41.07it/s] 37%|███▋      | 370/1001 [00:08<00:15, 41.15it/s] 37%|███▋      | 375/1001 [00:09<00:15, 41.20it/s] 38%|███▊      | 380/1001 [00:09<00:15, 41.24it/s] 38%|███▊      | 385/1001 [00:09<00:14, 41.32it/s] 39%|███▉      | 390/1001 [00:09<00:14, 41.87it/s] 39%|███▉      | 395/1001 [00:09<00:14, 41.52it/s] 40%|███▉      | 400/1001 [00:09<00:14, 41.75it/s] 40%|████      | 405/1001 [00:09<00:14, 41.45it/s] 41%|████      | 410/1001 [00:09<00:14, 41.66it/s] 41%|████▏     | 415/1001 [00:10<00:14, 41.65it/s] 42%|████▏     | 420/1001 [00:10<00:13, 42.52it/s] 42%|████▏     | 425/1001 [00:10<00:13, 42.10it/s] 43%|████▎     | 430/1001 [00:10<00:13, 42.64it/s] 43%|████▎     | 435/1001 [00:10<00:13, 42.01it/s] 44%|████▍     | 440/1001 [00:10<00:13, 41.57it/s] 44%|████▍     | 445/1001 [00:10<00:13, 41.69it/s] 45%|████▍     | 450/1001 [00:10<00:13, 41.59it/s] 45%|████▌     | 455/1001 [00:10<00:13, 41.50it/s] 46%|████▌     | 460/1001 [00:11<00:13, 41.33it/s] 46%|████▋     | 465/1001 [00:11<00:12, 41.35it/s] 47%|████▋     | 470/1001 [00:11<00:12, 41.53it/s] 47%|████▋     | 475/1001 [00:11<00:12, 41.66it/s] 48%|████▊     | 480/1001 [00:11<00:12, 41.60it/s] 48%|████▊     | 485/1001 [00:11<00:12, 42.14it/s] 49%|████▉     | 490/1001 [00:11<00:12, 41.97it/s] 49%|████▉     | 495/1001 [00:11<00:12, 41.93it/s] 50%|████▉     | 500/1001 [00:12<00:11, 41.95it/s] 50%|█████     | 505/1001 [00:12<00:11, 41.96it/s] 51%|█████     | 510/1001 [00:12<00:11, 42.04it/s] 51%|█████▏    | 515/1001 [00:12<00:11, 42.30it/s] 52%|█████▏    | 520/1001 [00:12<00:11, 42.57it/s] 52%|█████▏    | 525/1001 [00:12<00:11, 42.62it/s] 53%|█████▎    | 530/1001 [00:12<00:11, 42.34it/s] 53%|█████▎    | 535/1001 [00:12<00:11, 42.34it/s] 54%|█████▍    | 540/1001 [00:12<00:10, 42.83it/s] 54%|█████▍    | 545/1001 [00:13<00:10, 42.84it/s] 55%|█████▍    | 550/1001 [00:13<00:10, 41.77it/s] 55%|█████▌    | 555/1001 [00:13<00:10, 41.80it/s] 56%|█████▌    | 560/1001 [00:13<00:10, 41.11it/s] 56%|█████▋    | 565/1001 [00:13<00:10, 41.23it/s] 57%|█████▋    | 570/1001 [00:13<00:10, 41.66it/s] 57%|█████▋    | 575/1001 [00:13<00:10, 41.84it/s] 58%|█████▊    | 580/1001 [00:13<00:09, 42.19it/s] 58%|█████▊    | 585/1001 [00:14<00:09, 42.76it/s] 59%|█████▉    | 590/1001 [00:14<00:09, 41.85it/s] 59%|█████▉    | 595/1001 [00:14<00:09, 41.67it/s] 60%|█████▉    | 600/1001 [00:14<00:09, 41.69it/s] 60%|██████    | 605/1001 [00:14<00:09, 41.78it/s] 61%|██████    | 610/1001 [00:14<00:09, 42.20it/s] 61%|██████▏   | 615/1001 [00:14<00:09, 41.82it/s] 62%|██████▏   | 620/1001 [00:14<00:09, 42.27it/s] 62%|██████▏   | 625/1001 [00:15<00:08, 41.88it/s] 63%|██████▎   | 630/1001 [00:15<00:08, 41.94it/s] 63%|██████▎   | 635/1001 [00:15<00:08, 41.75it/s] 64%|██████▍   | 640/1001 [00:15<00:08, 41.67it/s] 64%|██████▍   | 645/1001 [00:15<00:08, 40.87it/s] 65%|██████▍   | 650/1001 [00:15<00:08, 41.27it/s] 65%|██████▌   | 655/1001 [00:15<00:08, 41.09it/s] 66%|██████▌   | 660/1001 [00:15<00:08, 40.34it/s] 66%|██████▋   | 665/1001 [00:16<00:08, 40.81it/s] 67%|██████▋   | 670/1001 [00:16<00:08, 40.59it/s] 67%|██████▋   | 675/1001 [00:16<00:08, 40.65it/s] 68%|██████▊   | 680/1001 [00:16<00:07, 40.78it/s] 68%|██████▊   | 685/1001 [00:16<00:07, 41.00it/s] 69%|██████▉   | 690/1001 [00:16<00:07, 40.93it/s] 69%|██████▉   | 695/1001 [00:16<00:07, 41.19it/s] 70%|██████▉   | 700/1001 [00:16<00:07, 41.43it/s] 70%|███████   | 705/1001 [00:16<00:07, 41.82it/s] 71%|███████   | 710/1001 [00:17<00:06, 43.43it/s] 71%|███████▏  | 715/1001 [00:17<00:06, 43.19it/s] 72%|███████▏  | 720/1001 [00:17<00:06, 43.51it/s] 72%|███████▏  | 725/1001 [00:17<00:06, 43.24it/s] 73%|███████▎  | 730/1001 [00:17<00:06, 43.01it/s] 73%|███████▎  | 735/1001 [00:17<00:06, 42.48it/s] 74%|███████▍  | 740/1001 [00:17<00:06, 42.82it/s] 74%|███████▍  | 745/1001 [00:17<00:06, 42.27it/s] 75%|███████▍  | 750/1001 [00:18<00:05, 42.10it/s] 75%|███████▌  | 755/1001 [00:18<00:05, 42.28it/s] 76%|███████▌  | 760/1001 [00:18<00:05, 42.54it/s] 76%|███████▋  | 765/1001 [00:18<00:05, 42.86it/s] 77%|███████▋  | 770/1001 [00:18<00:05, 43.44it/s] 77%|███████▋  | 775/1001 [00:18<00:05, 43.07it/s] 78%|███████▊  | 780/1001 [00:18<00:05, 42.94it/s] 78%|███████▊  | 785/1001 [00:18<00:05, 42.34it/s] 79%|███████▉  | 790/1001 [00:18<00:04, 42.81it/s] 79%|███████▉  | 795/1001 [00:19<00:04, 42.25it/s] 80%|███████▉  | 800/1001 [00:19<00:04, 42.11it/s] 80%|████████  | 805/1001 [00:19<00:04, 42.93it/s] 81%|████████  | 810/1001 [00:19<00:04, 43.34it/s] 81%|████████▏ | 815/1001 [00:19<00:04, 43.27it/s] 82%|████████▏ | 820/1001 [00:19<00:04, 42.62it/s] 82%|████████▏ | 825/1001 [00:19<00:03, 44.10it/s] 83%|████████▎ | 830/1001 [00:19<00:03, 43.82it/s] 83%|████████▎ | 835/1001 [00:19<00:03, 45.38it/s] 84%|████████▍ | 840/1001 [00:20<00:03, 44.90it/s] 84%|████████▍ | 845/1001 [00:20<00:03, 45.22it/s] 85%|████████▍ | 850/1001 [00:20<00:03, 44.64it/s] 85%|████████▌ | 855/1001 [00:20<00:03, 44.36it/s] 86%|████████▌ | 860/1001 [00:20<00:03, 44.05it/s] 87%|████████▋ | 866/1001 [00:20<00:02, 46.27it/s] 87%|████████▋ | 871/1001 [00:20<00:02, 45.51it/s] 88%|████████▊ | 876/1001 [00:20<00:02, 45.96it/s] 88%|████████▊ | 881/1001 [00:20<00:02, 46.73it/s] 89%|████████▊ | 886/1001 [00:21<00:02, 45.81it/s] 89%|████████▉ | 891/1001 [00:21<00:02, 46.81it/s] 90%|████████▉ | 896/1001 [00:21<00:02, 46.89it/s] 90%|█████████ | 901/1001 [00:21<00:02, 46.01it/s] 91%|█████████ | 907/1001 [00:21<00:01, 47.58it/s] 91%|█████████ | 912/1001 [00:21<00:01, 46.39it/s] 92%|█████████▏| 917/1001 [00:21<00:01, 47.24it/s] 92%|█████████▏| 923/1001 [00:21<00:01, 48.95it/s] 93%|█████████▎| 928/1001 [00:21<00:01, 47.32it/s] 93%|█████████▎| 934/1001 [00:22<00:01, 48.89it/s] 94%|█████████▍| 939/1001 [00:22<00:01, 47.38it/s] 94%|█████████▍| 944/1001 [00:22<00:01, 47.41it/s] 95%|█████████▍| 950/1001 [00:22<00:01, 49.12it/s] 95%|█████████▌| 955/1001 [00:22<00:00, 48.58it/s] 96%|█████████▌| 960/1001 [00:22<00:00, 48.47it/s] 97%|█████████▋| 966/1001 [00:22<00:00, 49.22it/s] 97%|█████████▋| 972/1001 [00:22<00:00, 50.19it/s] 98%|█████████▊| 978/1001 [00:22<00:00, 50.98it/s] 98%|█████████▊| 984/1001 [00:23<00:00, 52.56it/s] 99%|█████████▉| 990/1001 [00:23<00:00, 53.69it/s]100%|█████████▉| 996/1001 [00:23<00:00, 54.33it/s]100%|██████████| 1001/1001 [00:23<00:00, 42.78it/s]
  0%|          | 0/90000 [00:00<?, ?it/s]  0%|          | 1/90000 [00:00<17:55:11,  1.40it/s]  0%|          | 23/90000 [00:00<39:54, 37.58it/s]    0%|          | 46/90000 [00:00<20:11, 74.23it/s]  0%|          | 69/90000 [00:01<14:01, 106.83it/s]  0%|          | 92/90000 [00:01<11:06, 134.94it/s]  0%|          | 116/90000 [00:01<09:22, 159.77it/s]  0%|          | 140/90000 [00:01<08:22, 178.94it/s]  0%|          | 162/90000 [00:01<07:55, 188.88it/s]  0%|          | 186/90000 [00:01<07:23, 202.72it/s]  0%|          | 209/90000 [00:01<07:08, 209.79it/s]  0%|          | 232/90000 [00:01<07:05, 210.78it/s]  0%|          | 256/90000 [00:01<06:53, 217.25it/s]  0%|          | 279/90000 [00:01<06:53, 217.16it/s]  0%|          | 302/90000 [00:02<06:47, 219.87it/s]  0%|          | 327/90000 [00:02<06:36, 226.19it/s]  0%|          | 351/90000 [00:02<06:35, 226.93it/s]  0%|          | 374/90000 [00:02<06:41, 223.18it/s]  0%|          | 398/90000 [00:02<06:33, 227.44it/s]  0%|          | 421/90000 [00:02<06:39, 224.47it/s]  0%|          | 445/90000 [00:02<06:31, 228.94it/s]  1%|          | 470/90000 [00:02<06:25, 232.37it/s]  1%|          | 494/90000 [00:02<06:33, 227.64it/s]  1%|          | 519/90000 [00:02<06:25, 231.96it/s]  1%|          | 543/90000 [00:03<06:35, 226.10it/s]  1%|          | 566/90000 [00:03<06:36, 225.76it/s]  1%|          | 591/90000 [00:03<06:27, 230.44it/s]  1%|          | 615/90000 [00:03<06:35, 225.89it/s]  1%|          | 638/90000 [00:03<06:33, 226.93it/s]  1%|          | 661/90000 [00:03<06:33, 226.86it/s]  1%|          | 684/90000 [00:03<06:34, 226.49it/s]  1%|          | 707/90000 [00:03<06:34, 226.60it/s]  1%|          | 730/90000 [00:03<06:34, 226.19it/s]  1%|          | 753/90000 [00:04<06:32, 227.23it/s]  1%|          | 776/90000 [00:04<06:36, 224.98it/s]  1%|          | 799/90000 [00:04<06:37, 224.39it/s]  1%|          | 825/90000 [00:04<06:21, 233.73it/s]  1%|          | 849/90000 [00:04<06:22, 233.19it/s]  1%|          | 873/90000 [00:04<06:25, 231.37it/s]  1%|          | 897/90000 [00:04<06:32, 226.97it/s]  1%|          | 920/90000 [00:04<06:33, 226.40it/s]  1%|          | 943/90000 [00:04<06:38, 223.76it/s]  1%|          | 966/90000 [00:04<06:39, 222.83it/s]  1%|          | 989/90000 [00:05<06:48, 217.74it/s]  1%|          | 1012/90000 [00:05<06:46, 218.74it/s]  1%|          | 1034/90000 [00:05<06:47, 218.06it/s]  1%|          | 1057/90000 [00:05<06:45, 219.17it/s]  1%|          | 1081/90000 [00:05<06:37, 223.81it/s]  1%|          | 1104/90000 [00:05<06:44, 219.69it/s]  1%|▏         | 1127/90000 [00:05<06:39, 222.36it/s]  1%|▏         | 1150/90000 [00:05<06:41, 221.27it/s]  1%|▏         | 1174/90000 [00:05<06:36, 224.18it/s]  1%|▏         | 1197/90000 [00:06<06:41, 221.04it/s]  1%|▏         | 1220/90000 [00:06<06:39, 222.31it/s]  1%|▏         | 1244/90000 [00:06<06:34, 225.15it/s]  1%|▏         | 1267/90000 [00:06<06:31, 226.42it/s]  1%|▏         | 1291/90000 [00:06<06:25, 230.15it/s]  1%|▏         | 1315/90000 [00:06<06:29, 227.53it/s]  1%|▏         | 1340/90000 [00:06<06:22, 231.94it/s]  2%|▏         | 1364/90000 [00:06<06:26, 229.10it/s]  2%|▏         | 1388/90000 [00:06<06:24, 230.71it/s]  2%|▏         | 1412/90000 [00:06<06:21, 232.06it/s]  2%|▏         | 1436/90000 [00:07<06:23, 231.17it/s]  2%|▏         | 1461/90000 [00:07<06:16, 235.31it/s]  2%|▏         | 1485/90000 [00:07<06:21, 231.99it/s]  2%|▏         | 1510/90000 [00:07<06:14, 236.39it/s]  2%|▏         | 1534/90000 [00:07<06:15, 235.52it/s]  2%|▏         | 1558/90000 [00:07<06:14, 236.02it/s]  2%|▏         | 1582/90000 [00:07<06:20, 232.22it/s]  2%|▏         | 1606/90000 [00:07<06:24, 230.06it/s]  2%|▏         | 1630/90000 [00:07<06:24, 229.87it/s]  2%|▏         | 1653/90000 [00:07<06:30, 226.40it/s]  2%|▏         | 1677/90000 [00:08<06:25, 228.96it/s]  2%|▏         | 1701/90000 [00:08<06:24, 229.48it/s]  2%|▏         | 1724/90000 [00:08<06:26, 228.18it/s]  2%|▏         | 1749/90000 [00:08<06:18, 232.88it/s]  2%|▏         | 1773/90000 [00:08<06:28, 227.22it/s]  2%|▏         | 1796/90000 [00:08<06:32, 224.69it/s]  2%|▏         | 1820/90000 [00:08<06:28, 227.21it/s]  2%|▏         | 1843/90000 [00:08<06:33, 224.30it/s]  2%|▏         | 1866/90000 [00:08<06:30, 225.41it/s]  2%|▏         | 1889/90000 [00:09<06:30, 225.54it/s]  2%|▏         | 1912/90000 [00:09<06:28, 226.73it/s]  2%|▏         | 1935/90000 [00:09<06:28, 226.61it/s]  2%|▏         | 1958/90000 [00:09<06:27, 227.44it/s]  2%|▏         | 1981/90000 [00:09<06:27, 226.97it/s]  2%|▏         | 2005/90000 [00:09<06:24, 228.77it/s]  2%|▏         | 2028/90000 [00:09<06:31, 224.95it/s]  2%|▏         | 2051/90000 [00:09<06:42, 218.63it/s]  2%|▏         | 2074/90000 [00:09<06:38, 220.70it/s]  2%|▏         | 2099/90000 [00:09<06:28, 226.02it/s]  2%|▏         | 2122/90000 [00:10<06:34, 222.69it/s]  2%|▏         | 2146/90000 [00:10<06:28, 225.99it/s]  2%|▏         | 2169/90000 [00:10<06:27, 226.60it/s]  2%|▏         | 2192/90000 [00:10<06:28, 225.90it/s]  2%|▏         | 2215/90000 [00:10<06:33, 223.04it/s]  2%|▏         | 2238/90000 [00:10<06:30, 224.82it/s]  3%|▎         | 2261/90000 [00:10<06:40, 219.25it/s]  3%|▎         | 2285/90000 [00:10<06:32, 223.32it/s]  3%|▎         | 2309/90000 [00:10<06:26, 226.61it/s]  3%|▎         | 2333/90000 [00:11<06:24, 227.74it/s]  3%|▎         | 2357/90000 [00:11<06:19, 230.78it/s]  3%|▎         | 2381/90000 [00:11<06:18, 231.19it/s]  3%|▎         | 2405/90000 [00:11<06:25, 227.48it/s]  3%|▎         | 2428/90000 [00:11<06:28, 225.26it/s]  3%|▎         | 2453/90000 [00:11<06:20, 229.97it/s]  3%|▎         | 2477/90000 [00:11<06:26, 226.30it/s]  3%|▎         | 2501/90000 [00:11<06:21, 229.42it/s]  3%|▎         | 2524/90000 [00:11<06:25, 226.79it/s]  3%|▎         | 2548/90000 [00:11<06:23, 228.10it/s]  3%|▎         | 2572/90000 [00:12<06:20, 229.61it/s]  3%|▎         | 2595/90000 [00:12<06:28, 224.89it/s]  3%|▎         | 2618/90000 [00:12<06:26, 226.31it/s]  3%|▎         | 2642/90000 [00:12<06:23, 227.93it/s]  3%|▎         | 2666/90000 [00:12<06:20, 229.23it/s]  3%|▎         | 2689/90000 [00:12<06:20, 229.29it/s]  3%|▎         | 2714/90000 [00:12<06:15, 232.76it/s]  3%|▎         | 2738/90000 [00:12<06:16, 231.68it/s]  3%|▎         | 2762/90000 [00:12<06:18, 230.42it/s]  3%|▎         | 2786/90000 [00:12<06:18, 230.19it/s]  3%|▎         | 2810/90000 [00:13<06:18, 230.52it/s]  3%|▎         | 2834/90000 [00:13<06:14, 232.95it/s]  3%|▎         | 2858/90000 [00:13<06:15, 231.94it/s]  3%|▎         | 2882/90000 [00:13<06:19, 229.66it/s]  3%|▎         | 2905/90000 [00:13<06:20, 228.84it/s]  3%|▎         | 2928/90000 [00:13<06:25, 226.00it/s]  3%|▎         | 2951/90000 [00:13<06:26, 225.31it/s]  3%|▎         | 2974/90000 [00:13<06:26, 225.32it/s]  3%|▎         | 2998/90000 [00:13<06:20, 228.62it/s]  3%|▎         | 3021/90000 [00:14<06:22, 227.43it/s]  3%|▎         | 3045/90000 [00:14<06:17, 230.10it/s]  3%|▎         | 3069/90000 [00:14<06:16, 231.13it/s]  3%|▎         | 3093/90000 [00:14<06:18, 229.42it/s]  3%|▎         | 3119/90000 [00:14<06:09, 235.22it/s]  3%|▎         | 3143/90000 [00:14<06:11, 233.99it/s]  4%|▎         | 3167/90000 [00:14<06:11, 233.51it/s]  4%|▎         | 3191/90000 [00:14<06:12, 232.80it/s]  4%|▎         | 3215/90000 [00:14<06:12, 233.13it/s]  4%|▎         | 3239/90000 [00:14<06:16, 230.55it/s]  4%|▎         | 3263/90000 [00:15<06:18, 229.26it/s]  4%|▎         | 3287/90000 [00:15<06:14, 231.74it/s]  4%|▎         | 3311/90000 [00:15<06:13, 231.89it/s]  4%|▎         | 3335/90000 [00:15<06:11, 233.35it/s]  4%|▎         | 3359/90000 [00:15<06:08, 235.04it/s]  4%|▍         | 3383/90000 [00:15<06:09, 234.20it/s]  4%|▍         | 3407/90000 [00:15<06:14, 231.10it/s]  4%|▍         | 3431/90000 [00:15<06:12, 232.38it/s]  4%|▍         | 3456/90000 [00:15<06:06, 235.87it/s]  4%|▍         | 3480/90000 [00:15<06:11, 233.16it/s]  4%|▍         | 3504/90000 [00:16<06:19, 227.91it/s]  4%|▍         | 3527/90000 [00:16<06:21, 226.95it/s]  4%|▍         | 3550/90000 [00:16<06:25, 224.03it/s]  4%|▍         | 3573/90000 [00:16<06:28, 222.37it/s]  4%|▍         | 3597/90000 [00:16<06:21, 226.37it/s]  4%|▍         | 3621/90000 [00:16<06:15, 230.19it/s]  4%|▍         | 3645/90000 [00:16<06:11, 232.14it/s]  4%|▍         | 3669/90000 [00:16<06:12, 231.86it/s]  4%|▍         | 3693/90000 [00:16<06:13, 231.04it/s]  4%|▍         | 3717/90000 [00:17<06:13, 231.31it/s]  4%|▍         | 3741/90000 [00:17<06:13, 230.84it/s]  4%|▍         | 3765/90000 [00:17<06:11, 232.06it/s]  4%|▍         | 3789/90000 [00:17<06:09, 233.19it/s]  4%|▍         | 3813/90000 [00:17<06:17, 228.39it/s]  4%|▍         | 3836/90000 [00:17<06:39, 215.69it/s]  4%|▍         | 3858/90000 [00:17<06:49, 210.48it/s]  4%|▍         | 3882/90000 [00:17<06:39, 215.79it/s]  4%|▍         | 3905/90000 [00:17<06:31, 219.79it/s]  4%|▍         | 3929/90000 [00:17<06:24, 223.78it/s]  4%|▍         | 3953/90000 [00:18<06:19, 226.47it/s]  4%|▍         | 3978/90000 [00:18<06:14, 229.88it/s]  4%|▍         | 4002/90000 [00:18<06:15, 229.26it/s]  4%|▍         | 4025/90000 [00:18<06:23, 224.11it/s]  4%|▍         | 4048/90000 [00:18<06:21, 225.34it/s]  5%|▍         | 4071/90000 [00:18<06:19, 226.34it/s]  5%|▍         | 4094/90000 [00:18<06:24, 223.36it/s]  5%|▍         | 4117/90000 [00:18<06:22, 224.69it/s]  5%|▍         | 4140/90000 [00:18<06:32, 219.00it/s]  5%|▍         | 4163/90000 [00:19<06:26, 222.16it/s]  5%|▍         | 4186/90000 [00:19<06:25, 222.45it/s]  5%|▍         | 4209/90000 [00:19<06:30, 219.52it/s]  5%|▍         | 4232/90000 [00:19<06:28, 220.81it/s]  5%|▍         | 4255/90000 [00:19<06:31, 219.16it/s]  5%|▍         | 4277/90000 [00:19<06:32, 218.14it/s]  5%|▍         | 4299/90000 [00:19<06:37, 215.77it/s]  5%|▍         | 4321/90000 [00:19<06:45, 211.44it/s]  5%|▍         | 4343/90000 [00:19<06:43, 212.42it/s]  5%|▍         | 4365/90000 [00:19<06:46, 210.46it/s]  5%|▍         | 4387/90000 [00:20<06:44, 211.63it/s]  5%|▍         | 4410/90000 [00:20<06:37, 215.31it/s]  5%|▍         | 4433/90000 [00:20<06:33, 217.60it/s]  5%|▍         | 4455/90000 [00:20<06:36, 216.00it/s]  5%|▍         | 4477/90000 [00:20<06:49, 208.88it/s]  5%|▌         | 4500/90000 [00:20<06:41, 212.96it/s]  5%|▌         | 4522/90000 [00:20<06:39, 213.85it/s]  5%|▌         | 4545/90000 [00:20<06:35, 216.25it/s]  5%|▌         | 4567/90000 [00:20<06:43, 211.66it/s]  5%|▌         | 4589/90000 [00:21<06:47, 209.65it/s]  5%|▌         | 4610/90000 [00:21<06:52, 206.98it/s]  5%|▌         | 4631/90000 [00:21<06:54, 205.84it/s]  5%|▌         | 4652/90000 [00:21<07:03, 201.68it/s]  5%|▌         | 4673/90000 [00:21<07:03, 201.49it/s]  5%|▌         | 4694/90000 [00:21<06:59, 203.49it/s]  5%|▌         | 4717/90000 [00:21<06:48, 208.87it/s]  5%|▌         | 4738/90000 [00:21<06:53, 206.07it/s]  5%|▌         | 4759/90000 [00:21<06:54, 205.50it/s]  5%|▌         | 4780/90000 [00:21<06:54, 205.44it/s]  5%|▌         | 4802/90000 [00:22<06:50, 207.59it/s]  5%|▌         | 4823/90000 [00:22<06:49, 207.80it/s]  5%|▌         | 4846/90000 [00:22<06:41, 211.87it/s]  5%|▌         | 4869/90000 [00:22<06:38, 213.80it/s]  5%|▌         | 4891/90000 [00:22<06:41, 212.05it/s]  5%|▌         | 4913/90000 [00:22<06:49, 207.72it/s]  5%|▌         | 4934/90000 [00:22<06:50, 207.30it/s]  6%|▌         | 4955/90000 [00:22<06:54, 205.28it/s]  6%|▌         | 4979/90000 [00:22<06:35, 214.80it/s]  6%|▌         | 5001/90000 [00:22<06:34, 215.26it/s]  6%|▌         | 5024/90000 [00:23<06:31, 217.32it/s]  6%|▌         | 5047/90000 [00:23<06:24, 220.88it/s]  6%|▌         | 5070/90000 [00:23<06:24, 220.80it/s]  6%|▌         | 5093/90000 [00:23<06:20, 223.15it/s]  6%|▌         | 5116/90000 [00:23<06:20, 222.82it/s]  6%|▌         | 5139/90000 [00:23<06:25, 220.15it/s]  6%|▌         | 5162/90000 [00:23<06:28, 218.27it/s]  6%|▌         | 5185/90000 [00:23<06:27, 219.05it/s]  6%|▌         | 5207/90000 [00:23<06:34, 215.04it/s]  6%|▌         | 5229/90000 [00:24<06:40, 211.67it/s]  6%|▌         | 5251/90000 [00:24<06:47, 207.78it/s]  6%|▌         | 5272/90000 [00:24<06:47, 208.14it/s]  6%|▌         | 5295/90000 [00:24<06:37, 212.85it/s]  6%|▌         | 5317/90000 [00:24<06:35, 214.12it/s]  6%|▌         | 5341/90000 [00:24<06:25, 219.70it/s]  6%|▌         | 5363/90000 [00:24<06:26, 219.23it/s]  6%|▌         | 5386/90000 [00:24<06:22, 220.96it/s]  6%|▌         | 5409/90000 [00:24<06:21, 221.98it/s]  6%|▌         | 5432/90000 [00:24<06:22, 220.87it/s]  6%|▌         | 5455/90000 [00:25<06:32, 215.55it/s]  6%|▌         | 5478/90000 [00:25<06:25, 218.98it/s]  6%|▌         | 5500/90000 [00:25<06:27, 218.21it/s]  6%|▌         | 5523/90000 [00:25<06:24, 219.65it/s]  6%|▌         | 5545/90000 [00:25<06:26, 218.70it/s]  6%|▌         | 5568/90000 [00:25<06:23, 220.43it/s]  6%|▌         | 5592/90000 [00:25<06:16, 223.97it/s]  6%|▌         | 5615/90000 [00:25<06:21, 221.17it/s]  6%|▋         | 5639/90000 [00:25<06:15, 224.64it/s]  6%|▋         | 5662/90000 [00:26<06:20, 221.70it/s]  6%|▋         | 5685/90000 [00:26<06:26, 218.04it/s]  6%|▋         | 5708/90000 [00:26<06:21, 221.06it/s]  6%|▋         | 5731/90000 [00:26<06:35, 213.13it/s]  6%|▋         | 5754/90000 [00:26<06:29, 216.50it/s]  6%|▋         | 5777/90000 [00:26<06:24, 218.86it/s]  6%|▋         | 5801/90000 [00:26<06:16, 223.79it/s]  6%|▋         | 5824/90000 [00:26<06:14, 224.75it/s]  6%|▋         | 5847/90000 [00:26<06:18, 222.09it/s]  7%|▋         | 5870/90000 [00:26<06:22, 219.76it/s]  7%|▋         | 5893/90000 [00:27<06:30, 215.25it/s]  7%|▋         | 5917/90000 [00:27<06:20, 220.81it/s]  7%|▋         | 5941/90000 [00:27<06:16, 223.50it/s]  7%|▋         | 5964/90000 [00:27<06:15, 223.81it/s]  7%|▋         | 5988/90000 [00:27<06:11, 225.84it/s]  7%|▋         | 6012/90000 [00:27<06:08, 228.15it/s]  7%|▋         | 6036/90000 [00:27<06:05, 229.79it/s]  7%|▋         | 6059/90000 [00:27<06:05, 229.49it/s]  7%|▋         | 6082/90000 [00:27<06:08, 227.93it/s]  7%|▋         | 6105/90000 [00:28<06:13, 224.61it/s]  7%|▋         | 6128/90000 [00:28<06:12, 225.14it/s]  7%|▋         | 6151/90000 [00:28<06:16, 222.76it/s]  7%|▋         | 6174/90000 [00:28<06:14, 223.88it/s]  7%|▋         | 6197/90000 [00:28<06:12, 224.87it/s]  7%|▋         | 6220/90000 [00:28<06:21, 219.70it/s]  7%|▋         | 6243/90000 [00:28<06:18, 221.01it/s]  7%|▋         | 6268/90000 [00:28<06:08, 227.34it/s]  7%|▋         | 6292/90000 [00:28<06:03, 230.24it/s]  7%|▋         | 6316/90000 [00:28<06:06, 228.03it/s]  7%|▋         | 6340/90000 [00:29<06:04, 229.38it/s]  7%|▋         | 6363/90000 [00:29<06:05, 229.04it/s]  7%|▋         | 6386/90000 [00:29<06:05, 228.54it/s]  7%|▋         | 6410/90000 [00:29<06:03, 229.69it/s]  7%|▋         | 6433/90000 [00:29<06:11, 225.07it/s]  7%|▋         | 6456/90000 [00:29<06:15, 222.74it/s]  7%|▋         | 6479/90000 [00:29<06:15, 222.48it/s]  7%|▋         | 6502/90000 [00:29<06:20, 219.23it/s]  7%|▋         | 6526/90000 [00:29<06:12, 223.95it/s]  7%|▋         | 6549/90000 [00:29<06:11, 224.33it/s]  7%|▋         | 6572/90000 [00:30<06:13, 223.46it/s]  7%|▋         | 6595/90000 [00:30<06:12, 224.02it/s]  7%|▋         | 6618/90000 [00:30<06:09, 225.43it/s]  7%|▋         | 6641/90000 [00:30<06:11, 224.25it/s]  7%|▋         | 6664/90000 [00:30<06:13, 223.09it/s]  7%|▋         | 6688/90000 [00:30<06:08, 225.95it/s]  7%|▋         | 6712/90000 [00:30<06:03, 229.15it/s]  7%|▋         | 6736/90000 [00:30<06:00, 231.09it/s]  8%|▊         | 6760/90000 [00:30<06:04, 228.52it/s]  8%|▊         | 6783/90000 [00:31<06:09, 225.10it/s]  8%|▊         | 6806/90000 [00:31<06:19, 219.15it/s]  8%|▊         | 6829/90000 [00:31<06:19, 219.06it/s]  8%|▊         | 6851/90000 [00:31<06:23, 216.89it/s]  8%|▊         | 6875/90000 [00:31<06:12, 223.32it/s]  8%|▊         | 6898/90000 [00:31<06:19, 219.16it/s]  8%|▊         | 6922/90000 [00:31<06:14, 222.11it/s]  8%|▊         | 6945/90000 [00:31<06:10, 224.07it/s]  8%|▊         | 6968/90000 [00:31<06:13, 222.18it/s]  8%|▊         | 6991/90000 [00:31<06:16, 220.57it/s]  8%|▊         | 7014/90000 [00:32<06:11, 223.17it/s]  8%|▊         | 7037/90000 [00:32<06:11, 223.23it/s]  8%|▊         | 7060/90000 [00:32<06:09, 224.55it/s]  8%|▊         | 7084/90000 [00:32<06:01, 229.08it/s]  8%|▊         | 7107/90000 [00:32<06:13, 221.97it/s]  8%|▊         | 7131/90000 [00:32<06:06, 226.13it/s]  8%|▊         | 7156/90000 [00:32<06:00, 229.75it/s]  8%|▊         | 7180/90000 [00:32<06:00, 229.92it/s]  8%|▊         | 7204/90000 [00:32<05:59, 230.27it/s]  8%|▊         | 7228/90000 [00:32<06:03, 227.56it/s]  8%|▊         | 7251/90000 [00:33<06:13, 221.48it/s]  8%|▊         | 7274/90000 [00:33<06:17, 219.16it/s]  8%|▊         | 7296/90000 [00:33<06:20, 217.09it/s]  8%|▊         | 7319/90000 [00:33<06:15, 220.16it/s]  8%|▊         | 7343/90000 [00:33<06:06, 225.36it/s]  8%|▊         | 7366/90000 [00:33<06:05, 226.28it/s]  8%|▊         | 7389/90000 [00:33<06:06, 225.23it/s]  8%|▊         | 7412/90000 [00:33<06:09, 223.33it/s]  8%|▊         | 7435/90000 [00:33<06:14, 220.18it/s]  8%|▊         | 7458/90000 [00:34<06:12, 221.63it/s]  8%|▊         | 7481/90000 [00:34<06:13, 221.17it/s]  8%|▊         | 7504/90000 [00:34<06:09, 223.51it/s]  8%|▊         | 7528/90000 [00:34<06:06, 224.95it/s]  8%|▊         | 7552/90000 [00:34<06:00, 228.94it/s]  8%|▊         | 7576/90000 [00:34<05:55, 232.10it/s]  8%|▊         | 7600/90000 [00:34<06:02, 227.10it/s]  8%|▊         | 7623/90000 [00:34<06:07, 224.30it/s]  8%|▊         | 7648/90000 [00:34<05:58, 229.82it/s]  9%|▊         | 7672/90000 [00:34<06:01, 227.97it/s]  9%|▊         | 7695/90000 [00:35<06:04, 225.92it/s]  9%|▊         | 7718/90000 [00:35<06:09, 222.90it/s]  9%|▊         | 7741/90000 [00:35<06:10, 222.18it/s]  9%|▊         | 7764/90000 [00:35<06:07, 223.64it/s]  9%|▊         | 7787/90000 [00:35<06:06, 224.22it/s]  9%|▊         | 7810/90000 [00:35<06:08, 222.88it/s]  9%|▊         | 7833/90000 [00:35<06:16, 218.35it/s]  9%|▊         | 7856/90000 [00:35<06:11, 220.84it/s]  9%|▉         | 7879/90000 [00:35<06:09, 222.29it/s]  9%|▉         | 7902/90000 [00:36<06:13, 219.86it/s]  9%|▉         | 7925/90000 [00:36<06:15, 218.56it/s]  9%|▉         | 7947/90000 [00:36<06:17, 217.51it/s]  9%|▉         | 7971/90000 [00:36<06:09, 221.76it/s]  9%|▉         | 7994/90000 [00:36<06:07, 223.26it/s]  9%|▉         | 8017/90000 [00:36<06:05, 224.49it/s]  9%|▉         | 8040/90000 [00:36<06:08, 222.61it/s]  9%|▉         | 8063/90000 [00:36<06:09, 222.04it/s]  9%|▉         | 8086/90000 [00:36<06:10, 220.88it/s]  9%|▉         | 8109/90000 [00:36<06:16, 217.76it/s]  9%|▉         | 8131/90000 [00:37<06:20, 215.32it/s]  9%|▉         | 8153/90000 [00:37<06:26, 212.03it/s]  9%|▉         | 8175/90000 [00:37<06:35, 207.01it/s]  9%|▉         | 8197/90000 [00:37<06:32, 208.35it/s]  9%|▉         | 8218/90000 [00:37<06:35, 207.00it/s]  9%|▉         | 8239/90000 [00:37<06:37, 205.89it/s]  9%|▉         | 8260/90000 [00:37<06:46, 201.05it/s]  9%|▉         | 8281/90000 [00:37<06:45, 201.62it/s]  9%|▉         | 8302/90000 [00:37<06:45, 201.38it/s]  9%|▉         | 8324/90000 [00:38<06:37, 205.64it/s]  9%|▉         | 8345/90000 [00:38<06:35, 206.52it/s]  9%|▉         | 8366/90000 [00:38<06:35, 206.23it/s]  9%|▉         | 8387/90000 [00:38<06:36, 205.76it/s]  9%|▉         | 8408/90000 [00:38<06:34, 206.94it/s]  9%|▉         | 8429/90000 [00:38<06:35, 206.35it/s]  9%|▉         | 8452/90000 [00:38<06:27, 210.58it/s]  9%|▉         | 8474/90000 [00:38<06:25, 211.56it/s]  9%|▉         | 8496/90000 [00:38<06:24, 212.17it/s]  9%|▉         | 8518/90000 [00:38<06:24, 211.85it/s]  9%|▉         | 8540/90000 [00:39<06:25, 211.35it/s] 10%|▉         | 8562/90000 [00:39<06:35, 206.14it/s] 10%|▉         | 8583/90000 [00:39<06:35, 205.95it/s] 10%|▉         | 8606/90000 [00:39<06:26, 210.64it/s] 10%|▉         | 8628/90000 [00:39<06:30, 208.56it/s] 10%|▉         | 8650/90000 [00:39<06:26, 210.72it/s] 10%|▉         | 8673/90000 [00:39<06:16, 216.07it/s] 10%|▉         | 8697/90000 [00:39<06:08, 220.70it/s] 10%|▉         | 8721/90000 [00:39<06:00, 225.61it/s] 10%|▉         | 8745/90000 [00:39<05:57, 227.26it/s] 10%|▉         | 8768/90000 [00:40<05:57, 227.09it/s] 10%|▉         | 8792/90000 [00:40<05:52, 230.48it/s] 10%|▉         | 8816/90000 [00:40<05:49, 232.57it/s] 10%|▉         | 8840/90000 [00:40<05:55, 228.29it/s] 10%|▉         | 8863/90000 [00:40<05:59, 225.90it/s] 10%|▉         | 8886/90000 [00:40<06:07, 220.69it/s] 10%|▉         | 8909/90000 [00:40<06:06, 221.41it/s] 10%|▉         | 8933/90000 [00:40<06:01, 224.29it/s] 10%|▉         | 8956/90000 [00:40<06:01, 224.40it/s] 10%|▉         | 8979/90000 [00:41<06:04, 222.03it/s] 10%|█         | 9002/90000 [00:41<06:05, 221.72it/s] 10%|█         | 9025/90000 [00:41<06:14, 216.18it/s] 10%|█         | 9048/90000 [00:41<06:08, 219.58it/s] 10%|█         | 9070/90000 [00:41<06:10, 218.24it/s] 10%|█         | 9093/90000 [00:41<06:08, 219.56it/s] 10%|█         | 9116/90000 [00:41<06:05, 221.07it/s] 10%|█         | 9139/90000 [00:41<06:06, 220.42it/s] 10%|█         | 9162/90000 [00:41<06:07, 219.68it/s] 10%|█         | 9185/90000 [00:41<06:05, 221.11it/s] 10%|█         | 9209/90000 [00:42<05:59, 224.63it/s] 10%|█         | 9232/90000 [00:42<06:02, 222.64it/s] 10%|█         | 9255/90000 [00:42<06:09, 218.30it/s] 10%|█         | 9279/90000 [00:42<06:02, 222.96it/s] 10%|█         | 9303/90000 [00:42<05:56, 226.64it/s] 10%|█         | 9326/90000 [00:42<06:04, 221.08it/s] 10%|█         | 9350/90000 [00:42<05:57, 225.59it/s] 10%|█         | 9374/90000 [00:42<05:52, 228.62it/s] 10%|█         | 9397/90000 [00:42<05:56, 226.17it/s] 10%|█         | 9420/90000 [00:43<05:59, 224.00it/s] 10%|█         | 9443/90000 [00:43<06:09, 217.94it/s] 11%|█         | 9465/90000 [00:43<06:11, 216.81it/s] 11%|█         | 9489/90000 [00:43<06:00, 223.46it/s] 11%|█         | 9512/90000 [00:43<06:03, 221.36it/s] 11%|█         | 9535/90000 [00:43<06:05, 220.10it/s] 11%|█         | 9558/90000 [00:43<06:10, 217.33it/s] 11%|█         | 9580/90000 [00:43<06:11, 216.73it/s] 11%|█         | 9603/90000 [00:43<06:07, 218.61it/s] 11%|█         | 9625/90000 [00:43<06:23, 209.58it/s] 11%|█         | 9648/90000 [00:44<06:17, 212.79it/s] 11%|█         | 9671/90000 [00:44<06:09, 217.36it/s] 11%|█         | 9693/90000 [00:44<06:08, 218.09it/s] 11%|█         | 9715/90000 [00:44<06:09, 217.23it/s] 11%|█         | 9737/90000 [00:44<06:08, 217.52it/s] 11%|█         | 9759/90000 [00:44<06:09, 216.94it/s] 11%|█         | 9781/90000 [00:44<06:12, 215.43it/s] 11%|█         | 9803/90000 [00:44<06:14, 214.23it/s] 11%|█         | 9825/90000 [00:44<06:14, 214.31it/s] 11%|█         | 9847/90000 [00:44<06:15, 213.28it/s] 11%|█         | 9869/90000 [00:45<06:12, 214.86it/s] 11%|█         | 9892/90000 [00:45<06:07, 217.79it/s] 11%|█         | 9914/90000 [00:45<06:07, 217.88it/s] 11%|█         | 9938/90000 [00:45<06:01, 221.51it/s] 11%|█         | 9961/90000 [00:45<06:02, 220.92it/s] 11%|█         | 9985/90000 [00:45<05:56, 224.41it/s] 11%|█         | 10008/90000 [00:45<06:06, 218.53it/s] 11%|█         | 10030/90000 [00:45<06:09, 216.49it/s] 11%|█         | 10054/90000 [00:45<06:00, 221.89it/s] 11%|█         | 10077/90000 [00:46<06:09, 216.43it/s] 11%|█         | 10099/90000 [00:46<06:11, 215.19it/s] 11%|█         | 10122/90000 [00:46<06:07, 217.52it/s] 11%|█▏        | 10145/90000 [00:46<06:04, 219.15it/s] 11%|█▏        | 10167/90000 [00:46<06:05, 218.37it/s] 11%|█▏        | 10189/90000 [00:46<06:16, 212.17it/s] 11%|█▏        | 10212/90000 [00:46<06:12, 214.43it/s] 11%|█▏        | 10234/90000 [00:46<06:12, 213.85it/s] 11%|█▏        | 10256/90000 [00:46<06:13, 213.25it/s] 11%|█▏        | 10278/90000 [00:46<06:18, 210.80it/s] 11%|█▏        | 10300/90000 [00:47<06:13, 213.14it/s] 11%|█▏        | 10322/90000 [00:47<06:18, 210.65it/s] 11%|█▏        | 10344/90000 [00:47<06:14, 212.68it/s] 12%|█▏        | 10366/90000 [00:47<06:13, 213.44it/s] 12%|█▏        | 10388/90000 [00:47<06:12, 213.90it/s] 12%|█▏        | 10411/90000 [00:47<06:04, 218.21it/s] 12%|█▏        | 10433/90000 [00:47<06:12, 213.69it/s] 12%|█▏        | 10456/90000 [00:47<06:07, 216.72it/s] 12%|█▏        | 10478/90000 [00:47<06:06, 217.22it/s] 12%|█▏        | 10501/90000 [00:48<06:01, 220.18it/s] 12%|█▏        | 10524/90000 [00:48<06:01, 220.08it/s] 12%|█▏        | 10547/90000 [00:48<06:00, 220.63it/s] 12%|█▏        | 10570/90000 [00:48<06:00, 220.37it/s] 12%|█▏        | 10593/90000 [00:48<06:00, 220.49it/s] 12%|█▏        | 10616/90000 [00:48<06:06, 216.83it/s] 12%|█▏        | 10638/90000 [00:48<06:09, 214.80it/s] 12%|█▏        | 10660/90000 [00:48<06:12, 212.91it/s] 12%|█▏        | 10682/90000 [00:48<06:11, 213.37it/s] 12%|█▏        | 10704/90000 [00:48<06:11, 213.56it/s] 12%|█▏        | 10726/90000 [00:49<06:17, 210.12it/s] 12%|█▏        | 10748/90000 [00:49<06:19, 208.60it/s] 12%|█▏        | 10769/90000 [00:49<06:22, 207.32it/s] 12%|█▏        | 10792/90000 [00:49<06:15, 211.04it/s] 12%|█▏        | 10814/90000 [00:49<06:15, 211.06it/s] 12%|█▏        | 10836/90000 [00:49<06:20, 208.14it/s] 12%|█▏        | 10857/90000 [00:49<06:20, 208.14it/s] 12%|█▏        | 10879/90000 [00:49<06:16, 210.11it/s] 12%|█▏        | 10901/90000 [00:49<06:12, 212.30it/s] 12%|█▏        | 10924/90000 [00:49<06:08, 214.66it/s] 12%|█▏        | 10947/90000 [00:50<06:01, 218.61it/s] 12%|█▏        | 10969/90000 [00:50<06:11, 212.73it/s] 12%|█▏        | 10991/90000 [00:50<06:11, 212.76it/s] 12%|█▏        | 11015/90000 [00:50<06:00, 218.97it/s] 12%|█▏        | 11037/90000 [00:50<06:02, 218.08it/s] 12%|█▏        | 11061/90000 [00:50<05:53, 223.12it/s] 12%|█▏        | 11084/90000 [00:50<05:55, 222.24it/s] 12%|█▏        | 11107/90000 [00:50<05:52, 223.66it/s] 12%|█▏        | 11130/90000 [00:50<05:56, 221.32it/s] 12%|█▏        | 11153/90000 [00:51<05:54, 222.48it/s] 12%|█▏        | 11176/90000 [00:51<05:51, 223.94it/s] 12%|█▏        | 11199/90000 [00:51<05:49, 225.66it/s] 12%|█▏        | 11222/90000 [00:51<05:52, 223.79it/s] 12%|█▏        | 11245/90000 [00:51<05:54, 222.19it/s] 13%|█▎        | 11269/90000 [00:51<05:47, 226.73it/s] 13%|█▎        | 11292/90000 [00:51<05:55, 221.46it/s] 13%|█▎        | 11315/90000 [00:51<05:54, 221.82it/s] 13%|█▎        | 11338/90000 [00:51<05:51, 223.56it/s] 13%|█▎        | 11361/90000 [00:51<05:50, 224.06it/s] 13%|█▎        | 11384/90000 [00:52<05:50, 224.60it/s] 13%|█▎        | 11407/90000 [00:52<05:51, 223.90it/s] 13%|█▎        | 11430/90000 [00:52<05:56, 220.60it/s] 13%|█▎        | 11453/90000 [00:52<05:57, 220.00it/s] 13%|█▎        | 11476/90000 [00:52<06:00, 217.75it/s] 13%|█▎        | 11499/90000 [00:52<05:58, 219.21it/s] 13%|█▎        | 11522/90000 [00:52<05:57, 219.78it/s] 13%|█▎        | 11545/90000 [00:52<05:54, 221.59it/s] 13%|█▎        | 11568/90000 [00:52<05:53, 221.68it/s] 13%|█▎        | 11591/90000 [00:52<05:54, 221.37it/s] 13%|█▎        | 11614/90000 [00:53<05:53, 221.62it/s] 13%|█▎        | 11637/90000 [00:53<05:57, 219.44it/s] 13%|█▎        | 11659/90000 [00:53<06:00, 217.20it/s] 13%|█▎        | 11683/90000 [00:53<05:54, 220.90it/s] 13%|█▎        | 11706/90000 [00:53<05:59, 217.75it/s] 13%|█▎        | 11729/90000 [00:53<05:57, 219.14it/s] 13%|█▎        | 11751/90000 [00:53<05:57, 218.97it/s] 13%|█▎        | 11773/90000 [00:53<06:00, 217.23it/s] 13%|█▎        | 11796/90000 [00:53<05:57, 218.55it/s] 13%|█▎        | 11819/90000 [00:54<05:55, 219.63it/s] 13%|█▎        | 11843/90000 [00:54<05:47, 224.88it/s] 13%|█▎        | 11866/90000 [00:54<05:54, 220.31it/s] 13%|█▎        | 11889/90000 [00:54<05:53, 220.88it/s] 13%|█▎        | 11912/90000 [00:54<05:53, 220.98it/s] 13%|█▎        | 11935/90000 [00:54<05:54, 220.27it/s] 13%|█▎        | 11958/90000 [00:54<05:54, 220.37it/s] 13%|█▎        | 11981/90000 [00:54<05:56, 218.66it/s] 13%|█▎        | 12003/90000 [00:54<05:57, 218.41it/s] 13%|█▎        | 12026/90000 [00:54<05:51, 221.68it/s] 13%|█▎        | 12050/90000 [00:55<05:44, 226.54it/s] 13%|█▎        | 12073/90000 [00:55<05:42, 227.26it/s] 13%|█▎        | 12096/90000 [00:55<05:46, 224.70it/s] 13%|█▎        | 12119/90000 [00:55<05:52, 220.84it/s] 13%|█▎        | 12142/90000 [00:55<05:49, 222.90it/s] 14%|█▎        | 12165/90000 [00:55<05:46, 224.42it/s] 14%|█▎        | 12188/90000 [00:55<05:51, 221.61it/s] 14%|█▎        | 12211/90000 [00:55<05:52, 220.60it/s] 14%|█▎        | 12234/90000 [00:55<05:59, 216.37it/s] 14%|█▎        | 12258/90000 [00:56<05:51, 220.89it/s] 14%|█▎        | 12281/90000 [00:56<05:52, 220.69it/s] 14%|█▎        | 12304/90000 [00:56<05:54, 219.11it/s] 14%|█▎        | 12328/90000 [00:56<05:48, 223.19it/s] 14%|█▎        | 12351/90000 [00:56<05:45, 224.69it/s] 14%|█▎        | 12374/90000 [00:56<05:45, 224.99it/s] 14%|█▍        | 12397/90000 [00:56<05:43, 225.71it/s] 14%|█▍        | 12421/90000 [00:56<05:41, 227.46it/s] 14%|█▍        | 12444/90000 [00:56<05:42, 226.20it/s] 14%|█▍        | 12467/90000 [00:56<05:45, 224.14it/s] 14%|█▍        | 12490/90000 [00:57<05:47, 222.87it/s] 14%|█▍        | 12514/90000 [00:57<05:41, 226.95it/s] 14%|█▍        | 12537/90000 [00:57<05:41, 226.76it/s] 14%|█▍        | 12561/90000 [00:57<05:38, 228.82it/s] 14%|█▍        | 12585/90000 [00:57<05:34, 231.20it/s] 14%|█▍        | 12609/90000 [00:57<05:34, 231.23it/s] 14%|█▍        | 12633/90000 [00:57<05:45, 223.94it/s] 14%|█▍        | 12656/90000 [00:57<05:44, 224.47it/s] 14%|█▍        | 12679/90000 [00:57<05:45, 223.89it/s] 14%|█▍        | 12702/90000 [00:57<05:43, 224.88it/s] 14%|█▍        | 12725/90000 [00:58<05:41, 225.95it/s] 14%|█▍        | 12748/90000 [00:58<05:41, 226.16it/s] 14%|█▍        | 12772/90000 [00:58<05:38, 228.40it/s] 14%|█▍        | 12798/90000 [00:58<05:26, 236.19it/s] 14%|█▍        | 12822/90000 [00:58<05:29, 234.28it/s] 14%|█▍        | 12846/90000 [00:58<05:33, 231.69it/s] 14%|█▍        | 12870/90000 [00:58<05:34, 230.68it/s] 14%|█▍        | 12894/90000 [00:58<05:36, 228.87it/s] 14%|█▍        | 12917/90000 [00:58<05:42, 225.04it/s] 14%|█▍        | 12942/90000 [00:59<05:34, 230.58it/s] 14%|█▍        | 12966/90000 [00:59<05:34, 230.28it/s] 14%|█▍        | 12990/90000 [00:59<05:32, 231.71it/s] 14%|█▍        | 13014/90000 [00:59<05:45, 223.14it/s] 14%|█▍        | 13037/90000 [00:59<05:46, 222.14it/s] 15%|█▍        | 13061/90000 [00:59<05:40, 226.07it/s] 15%|█▍        | 13084/90000 [00:59<05:40, 225.79it/s] 15%|█▍        | 13107/90000 [00:59<05:40, 225.97it/s] 15%|█▍        | 13130/90000 [00:59<05:39, 226.70it/s] 15%|█▍        | 13154/90000 [00:59<05:34, 229.61it/s] 15%|█▍        | 13177/90000 [01:00<05:38, 227.00it/s] 15%|█▍        | 13200/90000 [01:00<05:39, 226.50it/s] 15%|█▍        | 13223/90000 [01:00<05:38, 226.95it/s] 15%|█▍        | 13246/90000 [01:00<05:36, 227.79it/s] 15%|█▍        | 13269/90000 [01:00<05:47, 220.50it/s] 15%|█▍        | 13293/90000 [01:00<05:40, 225.05it/s] 15%|█▍        | 13316/90000 [01:00<05:38, 226.47it/s] 15%|█▍        | 13339/90000 [01:00<05:44, 222.64it/s] 15%|█▍        | 13362/90000 [01:00<05:41, 224.10it/s] 15%|█▍        | 13385/90000 [01:00<05:48, 219.69it/s] 15%|█▍        | 13409/90000 [01:01<05:39, 225.49it/s] 15%|█▍        | 13432/90000 [01:01<05:38, 225.90it/s] 15%|█▍        | 13455/90000 [01:01<05:43, 222.85it/s] 15%|█▍        | 13478/90000 [01:01<05:40, 224.56it/s] 15%|█▌        | 13501/90000 [01:01<05:38, 225.81it/s] 15%|█▌        | 13525/90000 [01:01<05:35, 227.97it/s] 15%|█▌        | 13548/90000 [01:01<05:37, 226.61it/s] 15%|█▌        | 13571/90000 [01:01<05:39, 225.23it/s] 15%|█▌        | 13594/90000 [01:01<05:49, 218.81it/s] 15%|█▌        | 13617/90000 [01:02<05:46, 220.19it/s] 15%|█▌        | 13640/90000 [01:02<05:46, 220.29it/s] 15%|█▌        | 13663/90000 [01:02<05:44, 221.69it/s] 15%|█▌        | 13687/90000 [01:02<05:37, 225.85it/s] 15%|█▌        | 13710/90000 [01:02<05:44, 221.47it/s] 15%|█▌        | 13733/90000 [01:02<05:43, 221.80it/s] 15%|█▌        | 13756/90000 [01:02<05:40, 223.87it/s] 15%|█▌        | 13779/90000 [01:02<05:37, 225.54it/s] 15%|█▌        | 13803/90000 [01:02<05:36, 226.55it/s] 15%|█▌        | 13827/90000 [01:02<05:35, 227.12it/s] 15%|█▌        | 13850/90000 [01:03<05:35, 227.23it/s] 15%|█▌        | 13874/90000 [01:03<05:32, 228.95it/s] 15%|█▌        | 13898/90000 [01:03<05:30, 230.35it/s] 15%|█▌        | 13922/90000 [01:03<05:31, 229.77it/s] 15%|█▌        | 13946/90000 [01:03<05:29, 230.59it/s] 16%|█▌        | 13970/90000 [01:03<05:31, 229.24it/s] 16%|█▌        | 13993/90000 [01:03<05:41, 222.62it/s] 16%|█▌        | 14018/90000 [01:03<05:33, 227.86it/s] 16%|█▌        | 14041/90000 [01:03<05:38, 224.35it/s] 16%|█▌        | 14064/90000 [01:04<05:39, 223.98it/s] 16%|█▌        | 14087/90000 [01:04<05:37, 224.61it/s] 16%|█▌        | 14110/90000 [01:04<05:41, 221.94it/s] 16%|█▌        | 14133/90000 [01:04<05:42, 221.59it/s] 16%|█▌        | 14157/90000 [01:04<05:36, 225.14it/s] 16%|█▌        | 14180/90000 [01:04<05:35, 225.80it/s] 16%|█▌        | 14203/90000 [01:04<05:35, 225.71it/s] 16%|█▌        | 14227/90000 [01:04<05:30, 229.36it/s] 16%|█▌        | 14251/90000 [01:04<05:26, 232.17it/s] 16%|█▌        | 14275/90000 [01:04<05:24, 233.09it/s] 16%|█▌        | 14299/90000 [01:05<05:24, 233.52it/s] 16%|█▌        | 14323/90000 [01:05<05:25, 232.17it/s] 16%|█▌        | 14347/90000 [01:05<05:28, 230.35it/s] 16%|█▌        | 14371/90000 [01:05<05:33, 227.05it/s] 16%|█▌        | 14395/90000 [01:05<05:27, 230.56it/s] 16%|█▌        | 14419/90000 [01:05<05:30, 228.76it/s] 16%|█▌        | 14442/90000 [01:05<05:36, 224.48it/s] 16%|█▌        | 14465/90000 [01:05<05:34, 225.72it/s] 16%|█▌        | 14488/90000 [01:05<05:35, 225.08it/s] 16%|█▌        | 14512/90000 [01:05<05:33, 226.53it/s] 16%|█▌        | 14535/90000 [01:06<05:35, 224.85it/s] 16%|█▌        | 14558/90000 [01:06<05:38, 223.14it/s] 16%|█▌        | 14581/90000 [01:06<05:35, 225.00it/s] 16%|█▌        | 14604/90000 [01:06<05:39, 222.18it/s] 16%|█▋        | 14627/90000 [01:06<05:36, 223.83it/s] 16%|█▋        | 14650/90000 [01:06<05:36, 223.67it/s] 16%|█▋        | 14673/90000 [01:06<05:35, 224.27it/s] 16%|█▋        | 14697/90000 [01:06<05:32, 226.78it/s] 16%|█▋        | 14720/90000 [01:06<05:39, 221.94it/s] 16%|█▋        | 14743/90000 [01:07<05:41, 220.56it/s] 16%|█▋        | 14766/90000 [01:07<05:39, 221.78it/s] 16%|█▋        | 14790/90000 [01:07<05:33, 225.78it/s] 16%|█▋        | 14813/90000 [01:07<05:38, 221.93it/s] 16%|█▋        | 14836/90000 [01:07<05:41, 220.12it/s] 17%|█▋        | 14859/90000 [01:07<05:39, 221.25it/s] 17%|█▋        | 14882/90000 [01:07<05:36, 223.05it/s] 17%|█▋        | 14905/90000 [01:07<05:38, 222.01it/s] 17%|█▋        | 14928/90000 [01:07<05:36, 223.36it/s] 17%|█▋        | 14951/90000 [01:07<05:38, 221.98it/s] 17%|█▋        | 14974/90000 [01:08<05:37, 222.23it/s] 17%|█▋        | 14997/90000 [01:08<05:36, 222.65it/s] 17%|█▋        | 15021/90000 [01:08<05:32, 225.49it/s] 17%|█▋        | 15044/90000 [01:08<05:37, 222.12it/s] 17%|█▋        | 15067/90000 [01:08<05:36, 222.60it/s] 17%|█▋        | 15090/90000 [01:08<05:34, 223.75it/s] 17%|█▋        | 15114/90000 [01:08<05:29, 227.23it/s] 17%|█▋        | 15138/90000 [01:08<05:26, 229.00it/s] 17%|█▋        | 15161/90000 [01:08<05:29, 227.30it/s] 17%|█▋        | 15184/90000 [01:08<05:32, 224.81it/s] 17%|█▋        | 15207/90000 [01:09<05:36, 222.35it/s] 17%|█▋        | 15230/90000 [01:09<05:34, 223.68it/s] 17%|█▋        | 15253/90000 [01:09<05:40, 219.22it/s] 17%|█▋        | 15276/90000 [01:09<05:37, 221.11it/s] 17%|█▋        | 15299/90000 [01:09<05:38, 220.68it/s] 17%|█▋        | 15322/90000 [01:09<05:34, 222.98it/s] 17%|█▋        | 15346/90000 [01:09<05:27, 227.71it/s] 17%|█▋        | 15369/90000 [01:09<05:27, 228.05it/s] 17%|█▋        | 15392/90000 [01:09<05:30, 226.03it/s] 17%|█▋        | 15415/90000 [01:10<05:31, 225.17it/s] 17%|█▋        | 15438/90000 [01:10<05:31, 225.01it/s] 17%|█▋        | 15461/90000 [01:10<05:35, 222.44it/s] 17%|█▋        | 15484/90000 [01:10<05:39, 219.57it/s] 17%|█▋        | 15507/90000 [01:10<05:38, 220.14it/s] 17%|█▋        | 15530/90000 [01:10<05:41, 217.84it/s] 17%|█▋        | 15553/90000 [01:10<05:40, 218.93it/s] 17%|█▋        | 15576/90000 [01:10<05:37, 220.51it/s] 17%|█▋        | 15599/90000 [01:10<05:41, 217.81it/s] 17%|█▋        | 15623/90000 [01:10<05:34, 222.23it/s] 17%|█▋        | 15646/90000 [01:11<05:32, 223.71it/s] 17%|█▋        | 15669/90000 [01:11<05:40, 218.42it/s] 17%|█▋        | 15693/90000 [01:11<05:34, 222.27it/s] 17%|█▋        | 15716/90000 [01:11<05:40, 217.95it/s] 17%|█▋        | 15739/90000 [01:11<05:37, 219.76it/s] 18%|█▊        | 15763/90000 [01:11<05:32, 223.22it/s] 18%|█▊        | 15786/90000 [01:11<05:37, 219.72it/s] 18%|█▊        | 15811/90000 [01:11<05:27, 226.35it/s] 18%|█▊        | 15834/90000 [01:11<05:32, 223.30it/s] 18%|█▊        | 15857/90000 [01:12<05:33, 222.02it/s] 18%|█▊        | 15880/90000 [01:12<05:30, 224.13it/s] 18%|█▊        | 15903/90000 [01:12<05:37, 219.45it/s] 18%|█▊        | 15925/90000 [01:12<05:43, 215.89it/s] 18%|█▊        | 15948/90000 [01:12<05:39, 217.99it/s] 18%|█▊        | 15970/90000 [01:12<05:49, 211.83it/s] 18%|█▊        | 15993/90000 [01:12<05:41, 216.96it/s] 18%|█▊        | 16015/90000 [01:12<05:39, 217.78it/s] 18%|█▊        | 16037/90000 [01:12<05:57, 206.81it/s] 18%|█▊        | 16062/90000 [01:12<05:41, 216.70it/s] 18%|█▊        | 16086/90000 [01:13<05:34, 220.72it/s] 18%|█▊        | 16109/90000 [01:13<05:35, 220.48it/s] 18%|█▊        | 16132/90000 [01:13<05:36, 219.34it/s] 18%|█▊        | 16156/90000 [01:13<05:30, 223.20it/s] 18%|█▊        | 16179/90000 [01:13<05:29, 223.83it/s] 18%|█▊        | 16202/90000 [01:13<05:27, 225.50it/s] 18%|█▊        | 16225/90000 [01:13<05:27, 224.93it/s] 18%|█▊        | 16248/90000 [01:13<05:31, 222.19it/s] 18%|█▊        | 16271/90000 [01:13<05:34, 220.10it/s] 18%|█▊        | 16295/90000 [01:14<05:29, 223.79it/s] 18%|█▊        | 16318/90000 [01:14<05:34, 220.34it/s] 18%|█▊        | 16343/90000 [01:14<05:24, 226.70it/s] 18%|█▊        | 16366/90000 [01:14<05:27, 224.66it/s] 18%|█▊        | 16389/90000 [01:14<05:26, 225.75it/s] 18%|█▊        | 16412/90000 [01:14<05:32, 221.57it/s] 18%|█▊        | 16435/90000 [01:14<05:29, 223.44it/s] 18%|█▊        | 16458/90000 [01:14<05:38, 217.16it/s] 18%|█▊        | 16480/90000 [01:14<05:39, 216.73it/s] 18%|█▊        | 16503/90000 [01:14<05:36, 218.39it/s] 18%|█▊        | 16526/90000 [01:15<05:32, 220.81it/s] 18%|█▊        | 16549/90000 [01:15<05:39, 216.08it/s] 18%|█▊        | 16572/90000 [01:15<05:36, 217.94it/s] 18%|█▊        | 16596/90000 [01:15<05:29, 222.73it/s] 18%|█▊        | 16619/90000 [01:15<05:28, 223.12it/s] 18%|█▊        | 16642/90000 [01:15<05:29, 222.84it/s] 19%|█▊        | 16666/90000 [01:15<05:23, 226.46it/s] 19%|█▊        | 16689/90000 [01:15<05:26, 224.25it/s] 19%|█▊        | 16712/90000 [01:15<05:28, 222.99it/s] 19%|█▊        | 16735/90000 [01:15<05:26, 224.47it/s] 19%|█▊        | 16758/90000 [01:16<05:35, 218.00it/s] 19%|█▊        | 16780/90000 [01:16<05:36, 217.39it/s] 19%|█▊        | 16802/90000 [01:16<05:41, 214.25it/s] 19%|█▊        | 16825/90000 [01:16<05:36, 217.57it/s] 19%|█▊        | 16847/90000 [01:16<05:44, 212.51it/s] 19%|█▊        | 16869/90000 [01:16<05:41, 214.20it/s] 19%|█▉        | 16891/90000 [01:16<05:42, 213.15it/s] 19%|█▉        | 16913/90000 [01:16<05:43, 213.06it/s] 19%|█▉        | 16938/90000 [01:16<05:29, 221.44it/s] 19%|█▉        | 16961/90000 [01:17<05:31, 220.00it/s] 19%|█▉        | 16985/90000 [01:17<05:26, 223.64it/s] 19%|█▉        | 17008/90000 [01:17<05:23, 225.34it/s] 19%|█▉        | 17031/90000 [01:17<05:28, 221.84it/s] 19%|█▉        | 17054/90000 [01:17<05:29, 221.52it/s] 19%|█▉        | 17077/90000 [01:17<05:31, 220.25it/s] 19%|█▉        | 17100/90000 [01:17<05:36, 216.61it/s] 19%|█▉        | 17123/90000 [01:17<05:30, 220.31it/s] 19%|█▉        | 17146/90000 [01:17<05:31, 219.53it/s] 19%|█▉        | 17169/90000 [01:17<05:31, 220.03it/s] 19%|█▉        | 17192/90000 [01:18<05:30, 220.61it/s] 19%|█▉        | 17215/90000 [01:18<05:42, 212.60it/s] 19%|█▉        | 17237/90000 [01:18<05:40, 213.50it/s] 19%|█▉        | 17259/90000 [01:18<05:39, 214.30it/s] 19%|█▉        | 17281/90000 [01:18<05:38, 214.59it/s] 19%|█▉        | 17303/90000 [01:18<05:42, 212.16it/s] 19%|█▉        | 17325/90000 [01:18<05:40, 213.21it/s] 19%|█▉        | 17347/90000 [01:18<05:38, 214.72it/s] 19%|█▉        | 17369/90000 [01:18<05:36, 216.15it/s] 19%|█▉        | 17393/90000 [01:19<05:28, 221.27it/s] 19%|█▉        | 17416/90000 [01:19<05:24, 223.60it/s] 19%|█▉        | 17439/90000 [01:19<05:25, 222.64it/s] 19%|█▉        | 17462/90000 [01:19<05:33, 217.46it/s] 19%|█▉        | 17484/90000 [01:19<05:36, 215.59it/s] 19%|█▉        | 17506/90000 [01:19<05:41, 212.13it/s] 19%|█▉        | 17530/90000 [01:19<05:32, 217.84it/s] 20%|█▉        | 17554/90000 [01:19<05:26, 221.82it/s] 20%|█▉        | 17577/90000 [01:19<05:31, 218.71it/s] 20%|█▉        | 17599/90000 [01:19<05:30, 218.97it/s] 20%|█▉        | 17622/90000 [01:20<05:28, 220.18it/s] 20%|█▉        | 17646/90000 [01:20<05:23, 223.66it/s] 20%|█▉        | 17669/90000 [01:20<05:26, 221.54it/s] 20%|█▉        | 17692/90000 [01:20<05:26, 221.74it/s] 20%|█▉        | 17715/90000 [01:20<05:22, 223.83it/s] 20%|█▉        | 17738/90000 [01:20<05:22, 224.38it/s] 20%|█▉        | 17761/90000 [01:20<05:28, 220.12it/s] 20%|█▉        | 17784/90000 [01:20<05:27, 220.30it/s] 20%|█▉        | 17807/90000 [01:20<05:26, 220.94it/s] 20%|█▉        | 17830/90000 [01:21<05:32, 217.38it/s] 20%|█▉        | 17853/90000 [01:21<05:29, 219.28it/s] 20%|█▉        | 17877/90000 [01:21<05:21, 224.44it/s] 20%|█▉        | 17900/90000 [01:21<05:23, 222.64it/s] 20%|█▉        | 17924/90000 [01:21<05:19, 225.31it/s] 20%|█▉        | 17948/90000 [01:21<05:16, 227.39it/s] 20%|█▉        | 17971/90000 [01:21<05:19, 225.20it/s] 20%|█▉        | 17996/90000 [01:21<05:13, 230.01it/s] 20%|██        | 18020/90000 [01:21<05:14, 228.62it/s] 20%|██        | 18043/90000 [01:21<05:21, 223.71it/s] 20%|██        | 18066/90000 [01:22<05:22, 222.99it/s] 20%|██        | 18090/90000 [01:22<05:19, 225.33it/s] 20%|██        | 18114/90000 [01:22<05:16, 227.37it/s] 20%|██        | 18138/90000 [01:22<05:12, 229.76it/s] 20%|██        | 18162/90000 [01:22<05:10, 231.73it/s] 20%|██        | 18186/90000 [01:22<05:09, 232.14it/s] 20%|██        | 18210/90000 [01:22<05:17, 226.00it/s] 20%|██        | 18233/90000 [01:22<05:21, 223.29it/s] 20%|██        | 18257/90000 [01:22<05:17, 225.74it/s] 20%|██        | 18280/90000 [01:22<05:20, 223.74it/s] 20%|██        | 18303/90000 [01:23<05:18, 225.03it/s] 20%|██        | 18327/90000 [01:23<05:13, 228.74it/s] 20%|██        | 18351/90000 [01:23<05:13, 228.72it/s] 20%|██        | 18374/90000 [01:23<05:14, 227.62it/s] 20%|██        | 18397/90000 [01:23<05:18, 225.00it/s] 20%|██        | 18420/90000 [01:23<05:17, 225.19it/s] 20%|██        | 18443/90000 [01:23<05:16, 226.25it/s] 21%|██        | 18466/90000 [01:23<05:16, 226.00it/s] 21%|██        | 18489/90000 [01:23<05:29, 217.09it/s] 21%|██        | 18512/90000 [01:24<05:24, 219.97it/s] 21%|██        | 18535/90000 [01:24<05:25, 219.65it/s] 21%|██        | 18558/90000 [01:24<05:22, 221.24it/s] 21%|██        | 18581/90000 [01:24<05:22, 221.67it/s] 21%|██        | 18605/90000 [01:24<05:18, 224.30it/s] 21%|██        | 18629/90000 [01:24<05:16, 225.30it/s] 21%|██        | 18652/90000 [01:24<05:17, 224.96it/s] 21%|██        | 18675/90000 [01:24<05:16, 225.49it/s] 21%|██        | 18698/90000 [01:24<05:15, 226.05it/s] 21%|██        | 18721/90000 [01:24<05:14, 226.61it/s] 21%|██        | 18745/90000 [01:25<05:10, 229.40it/s] 21%|██        | 18769/90000 [01:25<05:08, 230.66it/s] 21%|██        | 18793/90000 [01:25<05:13, 226.94it/s] 21%|██        | 18816/90000 [01:25<05:19, 222.69it/s] 21%|██        | 18839/90000 [01:25<05:19, 222.58it/s] 21%|██        | 18862/90000 [01:25<05:18, 223.22it/s] 21%|██        | 18885/90000 [01:25<05:18, 223.23it/s] 21%|██        | 18908/90000 [01:25<05:19, 222.79it/s] 21%|██        | 18933/90000 [01:25<05:11, 228.22it/s] 21%|██        | 18957/90000 [01:25<05:08, 230.40it/s] 21%|██        | 18981/90000 [01:26<05:07, 231.30it/s] 21%|██        | 19005/90000 [01:26<05:09, 229.52it/s] 21%|██        | 19028/90000 [01:26<05:14, 225.35it/s] 21%|██        | 19052/90000 [01:26<05:10, 228.21it/s] 21%|██        | 19076/90000 [01:26<05:07, 230.78it/s] 21%|██        | 19100/90000 [01:26<05:14, 225.24it/s] 21%|██        | 19124/90000 [01:26<05:12, 226.90it/s] 21%|██▏       | 19148/90000 [01:26<05:07, 230.12it/s] 21%|██▏       | 19172/90000 [01:26<05:06, 230.79it/s] 21%|██▏       | 19196/90000 [01:27<05:08, 229.24it/s] 21%|██▏       | 19220/90000 [01:27<05:06, 231.16it/s] 21%|██▏       | 19244/90000 [01:27<05:06, 230.82it/s] 21%|██▏       | 19268/90000 [01:27<05:14, 225.26it/s] 21%|██▏       | 19291/90000 [01:27<05:15, 223.92it/s] 21%|██▏       | 19314/90000 [01:27<05:15, 224.27it/s] 21%|██▏       | 19337/90000 [01:27<05:14, 224.92it/s] 22%|██▏       | 19362/90000 [01:27<05:06, 230.61it/s] 22%|██▏       | 19386/90000 [01:27<05:16, 223.07it/s] 22%|██▏       | 19409/90000 [01:27<05:17, 222.12it/s] 22%|██▏       | 19433/90000 [01:28<05:15, 223.75it/s] 22%|██▏       | 19456/90000 [01:28<05:15, 223.28it/s] 22%|██▏       | 19479/90000 [01:28<05:15, 223.62it/s] 22%|██▏       | 19502/90000 [01:28<05:14, 224.18it/s] 22%|██▏       | 19527/90000 [01:28<05:07, 228.91it/s] 22%|██▏       | 19552/90000 [01:28<05:02, 233.15it/s] 22%|██▏       | 19576/90000 [01:28<05:08, 227.91it/s] 22%|██▏       | 19600/90000 [01:28<05:05, 230.80it/s] 22%|██▏       | 19624/90000 [01:28<05:05, 230.44it/s] 22%|██▏       | 19648/90000 [01:29<05:10, 226.53it/s] 22%|██▏       | 19671/90000 [01:29<05:09, 227.13it/s] 22%|██▏       | 19694/90000 [01:29<05:10, 226.43it/s] 22%|██▏       | 19717/90000 [01:29<05:12, 225.19it/s] 22%|██▏       | 19740/90000 [01:29<05:11, 225.65it/s] 22%|██▏       | 19763/90000 [01:29<05:12, 224.85it/s] 22%|██▏       | 19786/90000 [01:29<05:12, 224.42it/s] 22%|██▏       | 19809/90000 [01:29<05:12, 224.44it/s] 22%|██▏       | 19833/90000 [01:29<05:06, 228.65it/s] 22%|██▏       | 19856/90000 [01:29<05:09, 226.82it/s] 22%|██▏       | 19879/90000 [01:30<05:12, 224.53it/s] 22%|██▏       | 19902/90000 [01:30<05:16, 221.16it/s] 22%|██▏       | 19925/90000 [01:30<05:13, 223.23it/s] 22%|██▏       | 19948/90000 [01:30<05:16, 221.65it/s] 22%|██▏       | 19972/90000 [01:30<05:11, 224.63it/s] 22%|██▏       | 19996/90000 [01:30<05:06, 228.41it/s] 22%|██▏       | 20020/90000 [01:30<05:04, 229.74it/s] 22%|██▏       | 20043/90000 [01:30<05:08, 226.78it/s] 22%|██▏       | 20067/90000 [01:30<05:04, 229.38it/s] 22%|██▏       | 20090/90000 [01:30<05:05, 228.80it/s] 22%|██▏       | 20114/90000 [01:31<05:01, 232.04it/s] 22%|██▏       | 20138/90000 [01:31<05:06, 227.89it/s] 22%|██▏       | 20161/90000 [01:31<05:05, 228.36it/s] 22%|██▏       | 20185/90000 [01:31<05:01, 231.44it/s] 22%|██▏       | 20209/90000 [01:31<05:05, 228.68it/s] 22%|██▏       | 20232/90000 [01:31<05:05, 228.54it/s] 23%|██▎       | 20255/90000 [01:31<05:05, 228.62it/s] 23%|██▎       | 20279/90000 [01:31<05:03, 229.52it/s] 23%|██▎       | 20303/90000 [01:31<05:00, 231.89it/s] 23%|██▎       | 20327/90000 [01:32<05:04, 228.59it/s] 23%|██▎       | 20350/90000 [01:32<05:05, 228.10it/s] 23%|██▎       | 20373/90000 [01:32<05:12, 222.86it/s] 23%|██▎       | 20396/90000 [01:32<05:15, 220.75it/s] 23%|██▎       | 20419/90000 [01:32<05:14, 221.17it/s] 23%|██▎       | 20442/90000 [01:32<05:15, 220.46it/s] 23%|██▎       | 20466/90000 [01:32<05:11, 223.43it/s] 23%|██▎       | 20490/90000 [01:32<05:08, 225.17it/s] 23%|██▎       | 20513/90000 [01:32<05:07, 226.09it/s] 23%|██▎       | 20536/90000 [01:32<05:06, 226.81it/s] 23%|██▎       | 20559/90000 [01:33<05:07, 225.96it/s] 23%|██▎       | 20582/90000 [01:33<05:08, 225.37it/s] 23%|██▎       | 20605/90000 [01:33<05:10, 223.43it/s] 23%|██▎       | 20628/90000 [01:33<05:08, 224.85it/s] 23%|██▎       | 20653/90000 [01:33<05:00, 230.95it/s] 23%|██▎       | 20677/90000 [01:33<05:07, 225.70it/s] 23%|██▎       | 20700/90000 [01:33<05:08, 224.57it/s] 23%|██▎       | 20724/90000 [01:33<05:03, 227.92it/s] 23%|██▎       | 20747/90000 [01:33<05:05, 226.96it/s] 23%|██▎       | 20772/90000 [01:33<04:57, 232.51it/s] 23%|██▎       | 20796/90000 [01:34<05:00, 230.34it/s] 23%|██▎       | 20820/90000 [01:34<04:58, 231.92it/s] 23%|██▎       | 20844/90000 [01:34<04:57, 232.33it/s] 23%|██▎       | 20868/90000 [01:34<05:00, 230.31it/s] 23%|██▎       | 20892/90000 [01:34<05:08, 223.92it/s] 23%|██▎       | 20915/90000 [01:34<05:10, 222.37it/s] 23%|██▎       | 20938/90000 [01:34<05:11, 221.68it/s] 23%|██▎       | 20961/90000 [01:34<05:12, 221.23it/s] 23%|██▎       | 20986/90000 [01:34<05:04, 226.90it/s] 23%|██▎       | 21009/90000 [01:35<05:05, 225.78it/s] 23%|██▎       | 21033/90000 [01:35<05:01, 228.67it/s] 23%|██▎       | 21057/90000 [01:35<05:00, 229.18it/s] 23%|██▎       | 21082/90000 [01:35<04:57, 231.42it/s] 23%|██▎       | 21106/90000 [01:35<04:56, 232.53it/s] 23%|██▎       | 21130/90000 [01:35<05:02, 227.69it/s] 24%|██▎       | 21153/90000 [01:35<05:05, 225.14it/s] 24%|██▎       | 21176/90000 [01:35<05:09, 222.18it/s] 24%|██▎       | 21199/90000 [01:35<05:10, 221.44it/s] 24%|██▎       | 21222/90000 [01:35<05:13, 219.13it/s] 24%|██▎       | 21244/90000 [01:36<05:14, 218.65it/s] 24%|██▎       | 21267/90000 [01:36<05:10, 221.45it/s] 24%|██▎       | 21290/90000 [01:36<05:12, 220.20it/s] 24%|██▎       | 21313/90000 [01:36<05:10, 221.53it/s] 24%|██▎       | 21337/90000 [01:36<05:03, 226.23it/s] 24%|██▎       | 21360/90000 [01:36<05:10, 220.99it/s] 24%|██▍       | 21385/90000 [01:36<05:02, 227.06it/s] 24%|██▍       | 21408/90000 [01:36<05:02, 226.56it/s] 24%|██▍       | 21431/90000 [01:36<05:02, 226.88it/s] 24%|██▍       | 21455/90000 [01:37<05:00, 227.96it/s] 24%|██▍       | 21478/90000 [01:37<05:00, 227.74it/s] 24%|██▍       | 21501/90000 [01:37<05:06, 223.54it/s] 24%|██▍       | 21524/90000 [01:37<05:04, 224.73it/s] 24%|██▍       | 21547/90000 [01:37<05:12, 219.31it/s] 24%|██▍       | 21571/90000 [01:37<05:04, 224.65it/s] 24%|██▍       | 21594/90000 [01:37<05:08, 221.98it/s] 24%|██▍       | 21618/90000 [01:37<05:03, 225.17it/s] 24%|██▍       | 21641/90000 [01:37<05:01, 226.45it/s] 24%|██▍       | 21664/90000 [01:37<05:01, 226.94it/s] 24%|██▍       | 21687/90000 [01:38<05:00, 227.58it/s] 24%|██▍       | 21710/90000 [01:38<05:02, 225.98it/s] 24%|██▍       | 21733/90000 [01:38<05:05, 223.29it/s] 24%|██▍       | 21757/90000 [01:38<05:01, 226.11it/s] 24%|██▍       | 21781/90000 [01:38<04:59, 227.62it/s] 24%|██▍       | 21805/90000 [01:38<04:55, 230.87it/s] 24%|██▍       | 21829/90000 [01:38<04:58, 228.33it/s] 24%|██▍       | 21852/90000 [01:38<04:59, 227.25it/s] 24%|██▍       | 21875/90000 [01:38<04:59, 227.22it/s] 24%|██▍       | 21898/90000 [01:38<04:59, 227.37it/s] 24%|██▍       | 21922/90000 [01:39<04:58, 228.12it/s] 24%|██▍       | 21946/90000 [01:39<04:56, 229.47it/s] 24%|██▍       | 21970/90000 [01:39<04:54, 230.92it/s] 24%|██▍       | 21994/90000 [01:39<04:54, 230.73it/s] 24%|██▍       | 22019/90000 [01:39<04:51, 233.05it/s] 24%|██▍       | 22043/90000 [01:39<04:50, 233.71it/s] 25%|██▍       | 22067/90000 [01:39<04:51, 233.03it/s] 25%|██▍       | 22091/90000 [01:39<04:54, 230.80it/s] 25%|██▍       | 22115/90000 [01:39<05:01, 224.95it/s] 25%|██▍       | 22138/90000 [01:40<05:00, 225.81it/s] 25%|██▍       | 22161/90000 [01:40<05:06, 221.03it/s] 25%|██▍       | 22186/90000 [01:40<04:58, 227.26it/s] 25%|██▍       | 22209/90000 [01:40<05:04, 222.35it/s] 25%|██▍       | 22232/90000 [01:40<05:02, 224.22it/s] 25%|██▍       | 22255/90000 [01:40<05:04, 222.42it/s] 25%|██▍       | 22279/90000 [01:40<05:01, 224.79it/s] 25%|██▍       | 22302/90000 [01:40<05:00, 224.95it/s] 25%|██▍       | 22325/90000 [01:40<04:59, 225.65it/s] 25%|██▍       | 22348/90000 [01:40<05:02, 223.97it/s] 25%|██▍       | 22372/90000 [01:41<04:59, 225.44it/s] 25%|██▍       | 22395/90000 [01:41<04:58, 226.30it/s] 25%|██▍       | 22419/90000 [01:41<04:54, 229.67it/s] 25%|██▍       | 22443/90000 [01:41<04:51, 231.80it/s] 25%|██▍       | 22467/90000 [01:41<04:54, 229.00it/s] 25%|██▍       | 22491/90000 [01:41<04:52, 230.87it/s] 25%|██▌       | 22515/90000 [01:41<04:53, 229.99it/s] 25%|██▌       | 22539/90000 [01:41<04:51, 231.70it/s] 25%|██▌       | 22563/90000 [01:41<04:52, 230.83it/s] 25%|██▌       | 22587/90000 [01:42<04:52, 230.86it/s] 25%|██▌       | 22611/90000 [01:42<04:51, 231.46it/s] 25%|██▌       | 22635/90000 [01:42<04:55, 227.73it/s] 25%|██▌       | 22659/90000 [01:42<04:51, 230.71it/s] 25%|██▌       | 22683/90000 [01:42<04:55, 228.19it/s] 25%|██▌       | 22706/90000 [01:42<04:58, 225.27it/s] 25%|██▌       | 22730/90000 [01:42<04:55, 228.02it/s] 25%|██▌       | 22753/90000 [01:42<04:57, 225.91it/s] 25%|██▌       | 22776/90000 [01:42<04:59, 224.53it/s] 25%|██▌       | 22800/90000 [01:42<04:55, 227.57it/s] 25%|██▌       | 22824/90000 [01:43<04:53, 229.19it/s] 25%|██▌       | 22847/90000 [01:43<04:54, 227.90it/s] 25%|██▌       | 22871/90000 [01:43<04:50, 231.02it/s] 25%|██▌       | 22895/90000 [01:43<04:50, 230.98it/s] 25%|██▌       | 22919/90000 [01:43<04:51, 229.94it/s] 25%|██▌       | 22943/90000 [01:43<04:55, 227.27it/s] 26%|██▌       | 22967/90000 [01:43<04:51, 229.57it/s] 26%|██▌       | 22990/90000 [01:43<04:56, 226.36it/s] 26%|██▌       | 23013/90000 [01:43<04:56, 225.63it/s] 26%|██▌       | 23036/90000 [01:43<04:57, 224.84it/s] 26%|██▌       | 23060/90000 [01:44<04:53, 227.77it/s] 26%|██▌       | 23083/90000 [01:44<04:53, 228.14it/s] 26%|██▌       | 23106/90000 [01:44<04:56, 225.70it/s] 26%|██▌       | 23129/90000 [01:44<04:56, 225.73it/s] 26%|██▌       | 23153/90000 [01:44<04:52, 228.35it/s] 26%|██▌       | 23177/90000 [01:44<04:50, 229.88it/s] 26%|██▌       | 23200/90000 [01:44<04:53, 227.92it/s] 26%|██▌       | 23224/90000 [01:44<04:50, 230.11it/s] 26%|██▌       | 23248/90000 [01:44<04:50, 229.44it/s] 26%|██▌       | 23271/90000 [01:45<04:50, 229.56it/s] 26%|██▌       | 23294/90000 [01:45<04:52, 228.38it/s] 26%|██▌       | 23318/90000 [01:45<04:49, 230.18it/s] 26%|██▌       | 23342/90000 [01:45<04:50, 229.76it/s] 26%|██▌       | 23365/90000 [01:45<04:54, 226.59it/s] 26%|██▌       | 23388/90000 [01:45<05:00, 221.40it/s] 26%|██▌       | 23412/90000 [01:45<04:56, 224.65it/s] 26%|██▌       | 23436/90000 [01:45<04:52, 227.40it/s] 26%|██▌       | 23459/90000 [01:45<04:52, 227.34it/s] 26%|██▌       | 23482/90000 [01:45<04:53, 226.90it/s] 26%|██▌       | 23507/90000 [01:46<04:48, 230.56it/s] 26%|██▌       | 23531/90000 [01:46<04:49, 229.83it/s] 26%|██▌       | 23554/90000 [01:46<04:53, 226.34it/s] 26%|██▌       | 23577/90000 [01:46<04:55, 224.55it/s] 26%|██▌       | 23600/90000 [01:46<04:56, 223.72it/s] 26%|██▌       | 23623/90000 [01:46<04:58, 222.54it/s] 26%|██▋       | 23647/90000 [01:46<04:54, 225.64it/s] 26%|██▋       | 23671/90000 [01:46<04:50, 228.13it/s] 26%|██▋       | 23694/90000 [01:46<04:51, 227.78it/s] 26%|██▋       | 23718/90000 [01:46<04:49, 228.64it/s] 26%|██▋       | 23741/90000 [01:47<04:52, 226.43it/s] 26%|██▋       | 23765/90000 [01:47<04:48, 229.21it/s] 26%|██▋       | 23789/90000 [01:47<04:45, 231.78it/s] 26%|██▋       | 23813/90000 [01:47<04:46, 231.06it/s] 26%|██▋       | 23837/90000 [01:47<04:44, 232.84it/s] 27%|██▋       | 23861/90000 [01:47<04:46, 230.97it/s] 27%|██▋       | 23885/90000 [01:47<04:45, 231.69it/s] 27%|██▋       | 23909/90000 [01:47<04:51, 226.77it/s] 27%|██▋       | 23932/90000 [01:47<04:55, 223.26it/s] 27%|██▋       | 23956/90000 [01:48<04:51, 226.53it/s] 27%|██▋       | 23979/90000 [01:48<04:53, 225.20it/s] 27%|██▋       | 24002/90000 [01:48<04:56, 222.69it/s] 27%|██▋       | 24025/90000 [01:48<04:54, 223.89it/s] 27%|██▋       | 24048/90000 [01:48<04:55, 222.90it/s] 27%|██▋       | 24071/90000 [01:48<04:58, 221.13it/s] 27%|██▋       | 24095/90000 [01:48<04:53, 224.45it/s] 27%|██▋       | 24118/90000 [01:48<04:53, 224.25it/s] 27%|██▋       | 24141/90000 [01:48<04:54, 223.82it/s] 27%|██▋       | 24165/90000 [01:48<04:51, 225.93it/s] 27%|██▋       | 24189/90000 [01:49<04:47, 228.57it/s] 27%|██▋       | 24214/90000 [01:49<04:42, 232.62it/s] 27%|██▋       | 24238/90000 [01:49<04:49, 227.11it/s] 27%|██▋       | 24263/90000 [01:49<04:42, 232.55it/s] 27%|██▋       | 24287/90000 [01:49<04:47, 228.86it/s] 27%|██▋       | 24311/90000 [01:49<04:44, 230.83it/s] 27%|██▋       | 24335/90000 [01:49<04:44, 230.45it/s] 27%|██▋       | 24359/90000 [01:49<04:42, 232.51it/s] 27%|██▋       | 24383/90000 [01:49<04:44, 230.86it/s] 27%|██▋       | 24407/90000 [01:49<04:41, 233.29it/s] 27%|██▋       | 24431/90000 [01:50<04:43, 231.12it/s] 27%|██▋       | 24455/90000 [01:50<04:45, 229.82it/s] 27%|██▋       | 24478/90000 [01:50<04:50, 225.94it/s] 27%|██▋       | 24503/90000 [01:50<04:44, 230.04it/s] 27%|██▋       | 24527/90000 [01:50<04:44, 230.28it/s] 27%|██▋       | 24551/90000 [01:50<04:44, 230.28it/s] 27%|██▋       | 24575/90000 [01:50<04:52, 223.30it/s] 27%|██▋       | 24598/90000 [01:50<04:53, 222.98it/s] 27%|██▋       | 24621/90000 [01:50<04:54, 222.27it/s] 27%|██▋       | 24644/90000 [01:51<04:52, 223.45it/s] 27%|██▋       | 24667/90000 [01:51<04:54, 221.56it/s] 27%|██▋       | 24690/90000 [01:51<04:54, 221.65it/s] 27%|██▋       | 24714/90000 [01:51<04:47, 226.90it/s] 27%|██▋       | 24737/90000 [01:51<04:47, 227.36it/s] 28%|██▊       | 24760/90000 [01:51<04:49, 225.30it/s] 28%|██▊       | 24783/90000 [01:51<04:49, 225.41it/s] 28%|██▊       | 24806/90000 [01:51<04:52, 222.73it/s] 28%|██▊       | 24829/90000 [01:51<04:50, 224.59it/s] 28%|██▊       | 24852/90000 [01:51<04:50, 223.93it/s] 28%|██▊       | 24875/90000 [01:52<04:51, 223.29it/s] 28%|██▊       | 24899/90000 [01:52<04:47, 226.18it/s] 28%|██▊       | 24922/90000 [01:52<04:46, 226.93it/s] 28%|██▊       | 24945/90000 [01:52<04:51, 223.10it/s] 28%|██▊       | 24969/90000 [01:52<04:49, 224.58it/s] 28%|██▊       | 24992/90000 [01:52<04:50, 223.99it/s] 28%|██▊       | 25015/90000 [01:52<04:53, 221.15it/s] 28%|██▊       | 25038/90000 [01:52<04:53, 221.40it/s] 28%|██▊       | 25063/90000 [01:52<04:45, 227.12it/s] 28%|██▊       | 25087/90000 [01:53<04:44, 228.41it/s] 28%|██▊       | 25112/90000 [01:53<04:38, 233.31it/s] 28%|██▊       | 25136/90000 [01:53<04:39, 232.22it/s] 28%|██▊       | 25160/90000 [01:53<04:42, 229.48it/s] 28%|██▊       | 25183/90000 [01:53<04:48, 224.60it/s] 28%|██▊       | 25208/90000 [01:53<04:41, 230.01it/s] 28%|██▊       | 25232/90000 [01:53<04:52, 221.44it/s] 28%|██▊       | 25255/90000 [01:53<04:53, 220.25it/s] 28%|██▊       | 25278/90000 [01:53<04:50, 222.63it/s] 28%|██▊       | 25301/90000 [01:53<04:55, 219.26it/s] 28%|██▊       | 25324/90000 [01:54<04:52, 221.05it/s] 28%|██▊       | 25347/90000 [01:54<04:54, 219.77it/s] 28%|██▊       | 25371/90000 [01:54<04:48, 224.07it/s] 28%|██▊       | 25394/90000 [01:54<04:47, 224.39it/s] 28%|██▊       | 25417/90000 [01:54<04:52, 220.50it/s] 28%|██▊       | 25441/90000 [01:54<04:46, 225.64it/s] 28%|██▊       | 25464/90000 [01:54<04:46, 225.13it/s] 28%|██▊       | 25488/90000 [01:54<04:41, 229.36it/s] 28%|██▊       | 25511/90000 [01:54<04:41, 228.72it/s] 28%|██▊       | 25535/90000 [01:55<04:39, 230.47it/s] 28%|██▊       | 25559/90000 [01:55<04:40, 229.72it/s] 28%|██▊       | 25583/90000 [01:55<04:40, 229.81it/s] 28%|██▊       | 25608/90000 [01:55<04:33, 235.02it/s] 28%|██▊       | 25632/90000 [01:55<04:33, 235.23it/s] 29%|██▊       | 25656/90000 [01:55<04:32, 236.38it/s] 29%|██▊       | 25680/90000 [01:55<04:36, 232.71it/s] 29%|██▊       | 25704/90000 [01:55<04:39, 230.03it/s] 29%|██▊       | 25728/90000 [01:55<04:39, 229.93it/s] 29%|██▊       | 25752/90000 [01:55<04:38, 230.74it/s] 29%|██▊       | 25776/90000 [01:56<04:40, 229.07it/s] 29%|██▊       | 25800/90000 [01:56<04:38, 230.40it/s] 29%|██▊       | 25824/90000 [01:56<04:37, 231.44it/s] 29%|██▊       | 25848/90000 [01:56<04:39, 229.92it/s] 29%|██▊       | 25871/90000 [01:56<04:40, 228.57it/s] 29%|██▉       | 25895/90000 [01:56<04:39, 229.50it/s] 29%|██▉       | 25919/90000 [01:56<04:38, 229.86it/s] 29%|██▉       | 25943/90000 [01:56<04:38, 230.13it/s] 29%|██▉       | 25967/90000 [01:56<04:36, 231.60it/s] 29%|██▉       | 25991/90000 [01:56<04:36, 231.28it/s] 29%|██▉       | 26015/90000 [01:57<04:36, 231.58it/s] 29%|██▉       | 26039/90000 [01:57<04:36, 231.25it/s] 29%|██▉       | 26063/90000 [01:57<04:40, 227.73it/s] 29%|██▉       | 26087/90000 [01:57<04:39, 228.86it/s] 29%|██▉       | 26110/90000 [01:57<04:41, 226.94it/s] 29%|██▉       | 26134/90000 [01:57<04:41, 227.12it/s] 29%|██▉       | 26157/90000 [01:57<04:42, 226.24it/s] 29%|██▉       | 26181/90000 [01:57<04:38, 229.14it/s] 29%|██▉       | 26205/90000 [01:57<04:37, 230.15it/s] 29%|██▉       | 26229/90000 [01:58<04:38, 229.38it/s] 29%|██▉       | 26252/90000 [01:58<04:40, 226.97it/s] 29%|██▉       | 26277/90000 [01:58<04:37, 230.00it/s] 29%|██▉       | 26301/90000 [01:58<04:36, 230.77it/s] 29%|██▉       | 26325/90000 [01:58<04:39, 227.77it/s] 29%|██▉       | 26348/90000 [01:58<04:40, 227.05it/s] 29%|██▉       | 26372/90000 [01:58<04:38, 228.74it/s] 29%|██▉       | 26395/90000 [01:58<04:37, 229.05it/s] 29%|██▉       | 26419/90000 [01:58<04:35, 230.40it/s] 29%|██▉       | 26443/90000 [01:58<04:43, 223.89it/s] 29%|██▉       | 26468/90000 [01:59<04:38, 227.96it/s] 29%|██▉       | 26492/90000 [01:59<04:36, 229.57it/s] 29%|██▉       | 26516/90000 [01:59<04:35, 230.53it/s] 29%|██▉       | 26540/90000 [01:59<04:39, 226.68it/s] 30%|██▉       | 26564/90000 [01:59<04:38, 227.66it/s] 30%|██▉       | 26587/90000 [01:59<04:41, 225.44it/s] 30%|██▉       | 26610/90000 [01:59<04:39, 226.49it/s] 30%|██▉       | 26633/90000 [01:59<04:41, 225.13it/s] 30%|██▉       | 26657/90000 [01:59<04:36, 229.16it/s] 30%|██▉       | 26681/90000 [02:00<04:33, 231.21it/s] 30%|██▉       | 26705/90000 [02:00<04:39, 226.44it/s] 30%|██▉       | 26729/90000 [02:00<04:36, 228.75it/s] 30%|██▉       | 26753/90000 [02:00<04:34, 230.56it/s] 30%|██▉       | 26777/90000 [02:00<04:34, 230.40it/s] 30%|██▉       | 26801/90000 [02:00<04:32, 232.27it/s] 30%|██▉       | 26825/90000 [02:00<04:32, 231.81it/s] 30%|██▉       | 26849/90000 [02:00<04:31, 232.34it/s] 30%|██▉       | 26874/90000 [02:00<04:28, 234.97it/s] 30%|██▉       | 26898/90000 [02:00<04:32, 231.50it/s] 30%|██▉       | 26922/90000 [02:01<04:34, 229.63it/s] 30%|██▉       | 26945/90000 [02:01<04:36, 228.07it/s] 30%|██▉       | 26968/90000 [02:01<04:36, 227.91it/s] 30%|██▉       | 26991/90000 [02:01<04:38, 226.00it/s] 30%|███       | 27014/90000 [02:01<04:43, 222.32it/s] 30%|███       | 27037/90000 [02:01<04:44, 221.29it/s] 30%|███       | 27061/90000 [02:01<04:39, 225.09it/s] 30%|███       | 27085/90000 [02:01<04:36, 227.66it/s] 30%|███       | 27108/90000 [02:01<04:37, 226.47it/s] 30%|███       | 27132/90000 [02:01<04:33, 229.58it/s] 30%|███       | 27157/90000 [02:02<04:30, 232.59it/s] 30%|███       | 27181/90000 [02:02<04:31, 230.96it/s] 30%|███       | 27205/90000 [02:02<04:30, 231.85it/s] 30%|███       | 27229/90000 [02:02<04:31, 231.50it/s] 30%|███       | 27253/90000 [02:02<04:30, 231.93it/s] 30%|███       | 27278/90000 [02:02<04:27, 234.60it/s] 30%|███       | 27302/90000 [02:02<04:30, 231.82it/s] 30%|███       | 27326/90000 [02:02<04:29, 232.86it/s] 30%|███       | 27350/90000 [02:02<04:29, 232.89it/s] 30%|███       | 27374/90000 [02:03<04:30, 231.77it/s] 30%|███       | 27398/90000 [02:03<04:27, 233.94it/s] 30%|███       | 27422/90000 [02:03<04:32, 229.78it/s] 30%|███       | 27447/90000 [02:03<04:28, 233.35it/s] 31%|███       | 27471/90000 [02:03<04:32, 229.38it/s] 31%|███       | 27494/90000 [02:03<04:34, 227.73it/s] 31%|███       | 27518/90000 [02:03<04:32, 229.60it/s] 31%|███       | 27541/90000 [02:03<04:34, 227.37it/s] 31%|███       | 27565/90000 [02:03<04:33, 228.03it/s] 31%|███       | 27588/90000 [02:03<04:37, 225.01it/s] 31%|███       | 27611/90000 [02:04<04:40, 222.36it/s] 31%|███       | 27635/90000 [02:04<04:35, 225.99it/s] 31%|███       | 27658/90000 [02:04<04:38, 223.84it/s] 31%|███       | 27681/90000 [02:04<04:37, 224.76it/s] 31%|███       | 27704/90000 [02:04<04:37, 224.83it/s] 31%|███       | 27727/90000 [02:04<04:37, 224.46it/s] 31%|███       | 27750/90000 [02:04<04:36, 225.17it/s] 31%|███       | 27774/90000 [02:04<04:33, 227.50it/s] 31%|███       | 27797/90000 [02:04<04:33, 227.63it/s] 31%|███       | 27821/90000 [02:04<04:31, 228.91it/s] 31%|███       | 27844/90000 [02:05<04:36, 224.64it/s] 31%|███       | 27867/90000 [02:05<04:36, 224.77it/s] 31%|███       | 27890/90000 [02:05<04:35, 225.83it/s] 31%|███       | 27913/90000 [02:05<04:39, 221.79it/s] 31%|███       | 27937/90000 [02:05<04:35, 225.00it/s] 31%|███       | 27961/90000 [02:05<04:33, 227.25it/s] 31%|███       | 27985/90000 [02:05<04:30, 229.15it/s] 31%|███       | 28008/90000 [02:05<04:31, 227.98it/s] 31%|███       | 28032/90000 [02:05<04:29, 230.09it/s] 31%|███       | 28058/90000 [02:06<04:22, 236.37it/s] 31%|███       | 28082/90000 [02:06<04:23, 234.94it/s] 31%|███       | 28106/90000 [02:06<04:23, 234.52it/s] 31%|███▏      | 28130/90000 [02:06<04:25, 233.17it/s] 31%|███▏      | 28154/90000 [02:06<04:25, 232.88it/s] 31%|███▏      | 28178/90000 [02:06<04:32, 226.55it/s] 31%|███▏      | 28203/90000 [02:06<04:27, 231.29it/s] 31%|███▏      | 28227/90000 [02:06<04:28, 230.14it/s] 31%|███▏      | 28251/90000 [02:06<04:30, 228.24it/s] 31%|███▏      | 28274/90000 [02:06<04:30, 228.21it/s] 31%|███▏      | 28297/90000 [02:07<04:33, 225.53it/s] 31%|███▏      | 28320/90000 [02:07<04:35, 224.07it/s] 31%|███▏      | 28343/90000 [02:07<04:42, 218.53it/s] 32%|███▏      | 28365/90000 [02:07<04:42, 218.48it/s] 32%|███▏      | 28390/90000 [02:07<04:33, 225.31it/s] 32%|███▏      | 28414/90000 [02:07<04:30, 227.82it/s] 32%|███▏      | 28437/90000 [02:07<04:30, 227.62it/s] 32%|███▏      | 28460/90000 [02:07<04:31, 226.93it/s] 32%|███▏      | 28483/90000 [02:07<04:31, 226.35it/s] 32%|███▏      | 28506/90000 [02:07<04:31, 226.75it/s] 32%|███▏      | 28529/90000 [02:08<04:37, 221.55it/s] 32%|███▏      | 28552/90000 [02:08<04:44, 216.30it/s] 32%|███▏      | 28576/90000 [02:08<04:35, 223.03it/s] 32%|███▏      | 28599/90000 [02:08<04:38, 220.48it/s] 32%|███▏      | 28622/90000 [02:08<04:37, 220.85it/s] 32%|███▏      | 28645/90000 [02:08<04:34, 223.18it/s] 32%|███▏      | 28669/90000 [02:08<04:31, 226.25it/s] 32%|███▏      | 28692/90000 [02:08<04:32, 225.01it/s] 32%|███▏      | 28715/90000 [02:08<04:36, 222.01it/s] 32%|███▏      | 28739/90000 [02:09<04:31, 225.58it/s] 32%|███▏      | 28765/90000 [02:09<04:22, 233.20it/s] 32%|███▏      | 28789/90000 [02:09<04:21, 234.35it/s] 32%|███▏      | 28813/90000 [02:09<04:29, 227.24it/s] 32%|███▏      | 28836/90000 [02:09<04:30, 226.01it/s] 32%|███▏      | 28860/90000 [02:09<04:26, 229.68it/s] 32%|███▏      | 28884/90000 [02:09<04:25, 229.89it/s] 32%|███▏      | 28909/90000 [02:09<04:21, 233.74it/s] 32%|███▏      | 28933/90000 [02:09<04:22, 232.40it/s] 32%|███▏      | 28957/90000 [02:09<04:25, 229.93it/s] 32%|███▏      | 28981/90000 [02:10<04:23, 231.31it/s] 32%|███▏      | 29005/90000 [02:10<04:27, 228.37it/s] 32%|███▏      | 29028/90000 [02:10<04:29, 226.20it/s] 32%|███▏      | 29051/90000 [02:10<04:32, 223.31it/s] 32%|███▏      | 29074/90000 [02:10<04:39, 217.99it/s] 32%|███▏      | 29097/90000 [02:10<04:37, 219.33it/s] 32%|███▏      | 29120/90000 [02:10<04:34, 221.78it/s] 32%|███▏      | 29143/90000 [02:10<04:33, 222.28it/s] 32%|███▏      | 29167/90000 [02:10<04:28, 226.90it/s] 32%|███▏      | 29191/90000 [02:11<04:23, 230.61it/s] 32%|███▏      | 29215/90000 [02:11<04:23, 230.82it/s] 32%|███▏      | 29239/90000 [02:11<04:25, 228.98it/s] 33%|███▎      | 29263/90000 [02:11<04:23, 230.46it/s] 33%|███▎      | 29287/90000 [02:11<04:20, 232.63it/s] 33%|███▎      | 29311/90000 [02:11<04:25, 228.87it/s] 33%|███▎      | 29335/90000 [02:11<04:22, 230.82it/s] 33%|███▎      | 29360/90000 [02:11<04:19, 233.68it/s] 33%|███▎      | 29384/90000 [02:11<04:20, 232.63it/s] 33%|███▎      | 29408/90000 [02:11<04:22, 231.07it/s] 33%|███▎      | 29432/90000 [02:12<04:25, 227.73it/s] 33%|███▎      | 29455/90000 [02:12<04:27, 226.42it/s] 33%|███▎      | 29480/90000 [02:12<04:21, 231.03it/s] 33%|███▎      | 29504/90000 [02:12<04:22, 230.13it/s] 33%|███▎      | 29528/90000 [02:12<04:23, 229.44it/s] 33%|███▎      | 29552/90000 [02:12<04:22, 230.30it/s] 33%|███▎      | 29576/90000 [02:12<04:21, 230.73it/s] 33%|███▎      | 29600/90000 [02:12<04:20, 231.73it/s] 33%|███▎      | 29625/90000 [02:12<04:17, 234.26it/s] 33%|███▎      | 29649/90000 [02:13<04:18, 233.32it/s] 33%|███▎      | 29673/90000 [02:13<04:22, 229.72it/s] 33%|███▎      | 29696/90000 [02:13<04:28, 224.90it/s] 33%|███▎      | 29719/90000 [02:13<04:28, 224.32it/s] 33%|███▎      | 29744/90000 [02:13<04:22, 229.78it/s] 33%|███▎      | 29767/90000 [02:13<04:22, 229.72it/s] 33%|███▎      | 29790/90000 [02:13<04:22, 229.47it/s] 33%|███▎      | 29814/90000 [02:13<04:19, 232.13it/s] 33%|███▎      | 29838/90000 [02:13<04:20, 231.12it/s] 33%|███▎      | 29862/90000 [02:13<04:18, 232.61it/s] 33%|███▎      | 29886/90000 [02:14<04:21, 229.88it/s] 33%|███▎      | 29910/90000 [02:14<04:23, 227.88it/s] 33%|███▎      | 29933/90000 [02:14<04:25, 225.91it/s] 33%|███▎      | 29957/90000 [02:14<04:24, 227.10it/s] 33%|███▎      | 29981/90000 [02:14<04:22, 228.55it/s] 33%|███▎      | 30004/90000 [02:14<04:22, 228.46it/s] 33%|███▎      | 30028/90000 [02:14<04:19, 231.40it/s] 33%|███▎      | 30052/90000 [02:14<04:20, 230.04it/s] 33%|███▎      | 30076/90000 [02:14<04:24, 226.67it/s] 33%|███▎      | 30099/90000 [02:14<04:23, 227.34it/s] 33%|███▎      | 30122/90000 [02:15<04:26, 225.05it/s] 33%|███▎      | 30145/90000 [02:15<04:28, 223.23it/s] 34%|███▎      | 30169/90000 [02:15<04:22, 227.80it/s] 34%|███▎      | 30192/90000 [02:15<04:24, 226.49it/s] 34%|███▎      | 30215/90000 [02:15<04:29, 222.24it/s] 34%|███▎      | 30238/90000 [02:15<04:28, 222.78it/s] 34%|███▎      | 30261/90000 [02:15<04:29, 221.26it/s] 34%|███▎      | 30284/90000 [02:15<04:30, 220.37it/s] 34%|███▎      | 30307/90000 [02:15<04:30, 220.84it/s] 34%|███▎      | 30330/90000 [02:16<04:30, 220.40it/s] 34%|███▎      | 30353/90000 [02:16<04:28, 222.38it/s] 34%|███▍      | 30376/90000 [02:16<04:28, 222.42it/s] 34%|███▍      | 30399/90000 [02:16<04:29, 220.87it/s] 34%|███▍      | 30422/90000 [02:16<04:30, 220.11it/s] 34%|███▍      | 30445/90000 [02:16<04:30, 220.38it/s] 34%|███▍      | 30468/90000 [02:16<04:33, 217.67it/s] 34%|███▍      | 30493/90000 [02:16<04:24, 224.65it/s] 34%|███▍      | 30517/90000 [02:16<04:21, 227.05it/s] 34%|███▍      | 30541/90000 [02:16<04:22, 226.89it/s] 34%|███▍      | 30564/90000 [02:17<04:24, 224.33it/s] 34%|███▍      | 30588/90000 [02:17<04:20, 228.46it/s] 34%|███▍      | 30612/90000 [02:17<04:17, 231.05it/s] 34%|███▍      | 30636/90000 [02:17<04:18, 229.47it/s] 34%|███▍      | 30659/90000 [02:17<04:24, 224.37it/s] 34%|███▍      | 30682/90000 [02:17<04:24, 223.93it/s] 34%|███▍      | 30705/90000 [02:17<04:23, 225.41it/s] 34%|███▍      | 30728/90000 [02:17<04:22, 226.17it/s] 34%|███▍      | 30751/90000 [02:17<04:21, 226.19it/s] 34%|███▍      | 30774/90000 [02:17<04:22, 225.80it/s] 34%|███▍      | 30797/90000 [02:18<04:23, 224.82it/s] 34%|███▍      | 30820/90000 [02:18<04:22, 225.30it/s] 34%|███▍      | 30843/90000 [02:18<04:24, 223.58it/s] 34%|███▍      | 30866/90000 [02:18<04:25, 222.66it/s] 34%|███▍      | 30889/90000 [02:18<04:25, 223.05it/s] 34%|███▍      | 30912/90000 [02:18<04:29, 219.11it/s] 34%|███▍      | 30935/90000 [02:18<04:26, 222.05it/s] 34%|███▍      | 30959/90000 [02:18<04:21, 225.40it/s] 34%|███▍      | 30982/90000 [02:18<04:24, 222.79it/s] 34%|███▍      | 31007/90000 [02:19<04:16, 230.01it/s] 34%|███▍      | 31031/90000 [02:19<04:18, 227.74it/s] 35%|███▍      | 31054/90000 [02:19<04:24, 222.76it/s] 35%|███▍      | 31077/90000 [02:19<04:25, 221.69it/s] 35%|███▍      | 31100/90000 [02:19<04:26, 220.90it/s] 35%|███▍      | 31123/90000 [02:19<04:23, 223.49it/s] 35%|███▍      | 31146/90000 [02:19<04:21, 224.92it/s] 35%|███▍      | 31169/90000 [02:19<04:22, 224.32it/s] 35%|███▍      | 31192/90000 [02:19<04:22, 224.12it/s] 35%|███▍      | 31215/90000 [02:19<04:22, 224.09it/s] 35%|███▍      | 31238/90000 [02:20<04:22, 223.91it/s] 35%|███▍      | 31261/90000 [02:20<04:25, 220.88it/s] 35%|███▍      | 31284/90000 [02:20<04:23, 222.94it/s] 35%|███▍      | 31308/90000 [02:20<04:17, 227.66it/s] 35%|███▍      | 31331/90000 [02:20<04:25, 221.04it/s] 35%|███▍      | 31355/90000 [02:20<04:22, 223.52it/s] 35%|███▍      | 31378/90000 [02:20<04:23, 222.11it/s] 35%|███▍      | 31401/90000 [02:20<04:24, 221.17it/s] 35%|███▍      | 31424/90000 [02:20<04:21, 223.63it/s] 35%|███▍      | 31447/90000 [02:21<04:23, 222.49it/s] 35%|███▍      | 31470/90000 [02:21<04:25, 220.09it/s] 35%|███▍      | 31493/90000 [02:21<04:24, 221.38it/s] 35%|███▌      | 31516/90000 [02:21<04:21, 223.51it/s] 35%|███▌      | 31539/90000 [02:21<04:22, 222.81it/s] 35%|███▌      | 31562/90000 [02:21<04:21, 223.23it/s] 35%|███▌      | 31585/90000 [02:21<04:24, 220.98it/s] 35%|███▌      | 31610/90000 [02:21<04:17, 226.49it/s] 35%|███▌      | 31633/90000 [02:21<04:19, 224.94it/s] 35%|███▌      | 31656/90000 [02:21<04:20, 223.87it/s] 35%|███▌      | 31679/90000 [02:22<04:23, 220.92it/s] 35%|███▌      | 31702/90000 [02:22<04:28, 216.86it/s] 35%|███▌      | 31725/90000 [02:22<04:25, 219.20it/s] 35%|███▌      | 31749/90000 [02:22<04:20, 223.31it/s] 35%|███▌      | 31772/90000 [02:22<04:24, 219.84it/s] 35%|███▌      | 31796/90000 [02:22<04:19, 224.29it/s] 35%|███▌      | 31819/90000 [02:22<04:18, 225.48it/s] 35%|███▌      | 31842/90000 [02:22<04:20, 222.93it/s] 35%|███▌      | 31865/90000 [02:22<04:22, 221.28it/s] 35%|███▌      | 31888/90000 [02:23<04:26, 217.95it/s] 35%|███▌      | 31911/90000 [02:23<04:24, 219.99it/s] 35%|███▌      | 31934/90000 [02:23<04:22, 221.51it/s] 36%|███▌      | 31957/90000 [02:23<04:19, 223.38it/s] 36%|███▌      | 31981/90000 [02:23<04:17, 225.28it/s] 36%|███▌      | 32004/90000 [02:23<04:19, 223.10it/s] 36%|███▌      | 32027/90000 [02:23<04:22, 220.57it/s] 36%|███▌      | 32050/90000 [02:23<04:23, 219.75it/s] 36%|███▌      | 32072/90000 [02:23<04:23, 219.57it/s] 36%|███▌      | 32095/90000 [02:23<04:22, 220.70it/s] 36%|███▌      | 32118/90000 [02:24<04:23, 219.61it/s] 36%|███▌      | 32140/90000 [02:24<04:24, 218.59it/s] 36%|███▌      | 32164/90000 [02:24<04:17, 224.32it/s] 36%|███▌      | 32188/90000 [02:24<04:13, 228.12it/s] 36%|███▌      | 32211/90000 [02:24<04:15, 226.46it/s] 36%|███▌      | 32234/90000 [02:24<04:15, 226.17it/s] 36%|███▌      | 32257/90000 [02:24<04:16, 225.16it/s] 36%|███▌      | 32280/90000 [02:24<04:18, 223.02it/s] 36%|███▌      | 32303/90000 [02:24<04:18, 222.81it/s] 36%|███▌      | 32326/90000 [02:24<04:18, 223.16it/s] 36%|███▌      | 32349/90000 [02:25<04:22, 219.27it/s] 36%|███▌      | 32371/90000 [02:25<04:22, 219.22it/s] 36%|███▌      | 32393/90000 [02:25<04:26, 216.20it/s] 36%|███▌      | 32415/90000 [02:25<04:25, 216.85it/s] 36%|███▌      | 32438/90000 [02:25<04:21, 220.33it/s] 36%|███▌      | 32461/90000 [02:25<04:29, 213.68it/s] 36%|███▌      | 32485/90000 [02:25<04:21, 219.63it/s] 36%|███▌      | 32509/90000 [02:25<04:17, 223.44it/s] 36%|███▌      | 32532/90000 [02:25<04:26, 215.99it/s] 36%|███▌      | 32556/90000 [02:26<04:19, 221.45it/s] 36%|███▌      | 32579/90000 [02:26<04:24, 217.29it/s] 36%|███▌      | 32601/90000 [02:26<04:24, 217.18it/s] 36%|███▌      | 32624/90000 [02:26<04:21, 219.56it/s] 36%|███▋      | 32646/90000 [02:26<04:24, 217.16it/s] 36%|███▋      | 32668/90000 [02:26<04:26, 214.88it/s] 36%|███▋      | 32691/90000 [02:26<04:25, 215.83it/s] 36%|███▋      | 32713/90000 [02:26<04:29, 212.67it/s] 36%|███▋      | 32736/90000 [02:26<04:24, 216.30it/s] 36%|███▋      | 32758/90000 [02:26<04:28, 213.53it/s] 36%|███▋      | 32780/90000 [02:27<04:27, 213.63it/s] 36%|███▋      | 32802/90000 [02:27<04:29, 211.86it/s] 36%|███▋      | 32825/90000 [02:27<04:23, 216.64it/s] 36%|███▋      | 32848/90000 [02:27<04:19, 220.02it/s] 37%|███▋      | 32871/90000 [02:27<04:22, 217.70it/s] 37%|███▋      | 32895/90000 [02:27<04:15, 223.50it/s] 37%|███▋      | 32918/90000 [02:27<04:16, 222.38it/s] 37%|███▋      | 32942/90000 [02:27<04:12, 226.04it/s] 37%|███▋      | 32965/90000 [02:27<04:19, 220.21it/s] 37%|███▋      | 32989/90000 [02:28<04:15, 223.53it/s] 37%|███▋      | 33012/90000 [02:28<04:14, 223.87it/s] 37%|███▋      | 33035/90000 [02:28<04:13, 224.63it/s] 37%|███▋      | 33059/90000 [02:28<04:10, 227.00it/s] 37%|███▋      | 33082/90000 [02:28<04:17, 221.34it/s] 37%|███▋      | 33105/90000 [02:28<04:14, 223.68it/s] 37%|███▋      | 33128/90000 [02:28<04:12, 225.50it/s] 37%|███▋      | 33151/90000 [02:28<04:15, 222.67it/s] 37%|███▋      | 33174/90000 [02:28<04:14, 223.22it/s] 37%|███▋      | 33198/90000 [02:28<04:09, 227.58it/s] 37%|███▋      | 33221/90000 [02:29<04:11, 225.63it/s] 37%|███▋      | 33245/90000 [02:29<04:07, 229.20it/s] 37%|███▋      | 33268/90000 [02:29<04:09, 227.52it/s] 37%|███▋      | 33292/90000 [02:29<04:05, 231.06it/s] 37%|███▋      | 33316/90000 [02:29<04:03, 233.09it/s] 37%|███▋      | 33340/90000 [02:29<04:06, 229.46it/s] 37%|███▋      | 33365/90000 [02:29<04:02, 233.19it/s] 37%|███▋      | 33389/90000 [02:29<04:03, 232.49it/s] 37%|███▋      | 33414/90000 [02:29<03:59, 235.96it/s] 37%|███▋      | 33439/90000 [02:29<03:56, 238.98it/s] 37%|███▋      | 33463/90000 [02:30<04:00, 235.54it/s] 37%|███▋      | 33487/90000 [02:30<04:02, 233.06it/s] 37%|███▋      | 33511/90000 [02:30<04:04, 231.48it/s] 37%|███▋      | 33535/90000 [02:30<04:03, 231.77it/s] 37%|███▋      | 33559/90000 [02:30<04:05, 230.24it/s] 37%|███▋      | 33583/90000 [02:30<04:04, 230.98it/s] 37%|███▋      | 33607/90000 [02:30<04:05, 229.79it/s] 37%|███▋      | 33630/90000 [02:30<04:05, 229.50it/s] 37%|███▋      | 33654/90000 [02:30<04:03, 231.46it/s] 37%|███▋      | 33678/90000 [02:30<04:03, 231.35it/s] 37%|███▋      | 33702/90000 [02:31<04:01, 232.75it/s] 37%|███▋      | 33726/90000 [02:31<04:01, 233.15it/s] 38%|███▊      | 33750/90000 [02:31<04:05, 229.47it/s] 38%|███▊      | 33774/90000 [02:31<04:04, 230.43it/s] 38%|███▊      | 33798/90000 [02:31<04:04, 229.87it/s] 38%|███▊      | 33821/90000 [02:31<04:06, 227.82it/s] 38%|███▊      | 33845/90000 [02:31<04:04, 229.81it/s] 38%|███▊      | 33868/90000 [02:31<04:06, 228.00it/s] 38%|███▊      | 33891/90000 [02:31<04:08, 226.12it/s] 38%|███▊      | 33914/90000 [02:32<04:07, 226.30it/s] 38%|███▊      | 33937/90000 [02:32<04:07, 226.51it/s] 38%|███▊      | 33960/90000 [02:32<04:07, 226.43it/s] 38%|███▊      | 33984/90000 [02:32<04:05, 227.90it/s] 38%|███▊      | 34007/90000 [02:32<04:07, 226.43it/s] 38%|███▊      | 34032/90000 [02:32<04:02, 230.89it/s] 38%|███▊      | 34056/90000 [02:32<04:02, 230.81it/s] 38%|███▊      | 34080/90000 [02:32<03:59, 233.29it/s] 38%|███▊      | 34104/90000 [02:32<03:58, 233.94it/s] 38%|███▊      | 34128/90000 [02:32<03:58, 234.17it/s] 38%|███▊      | 34152/90000 [02:33<04:04, 228.68it/s] 38%|███▊      | 34176/90000 [02:33<04:02, 229.73it/s] 38%|███▊      | 34199/90000 [02:33<04:07, 225.91it/s] 38%|███▊      | 34222/90000 [02:33<04:06, 226.09it/s] 38%|███▊      | 34245/90000 [02:33<04:06, 226.37it/s] 38%|███▊      | 34268/90000 [02:33<04:07, 225.55it/s] 38%|███▊      | 34292/90000 [02:33<04:02, 229.50it/s] 38%|███▊      | 34315/90000 [02:33<04:03, 228.44it/s] 38%|███▊      | 34338/90000 [02:33<04:03, 228.84it/s] 38%|███▊      | 34361/90000 [02:33<04:03, 228.08it/s] 38%|███▊      | 34385/90000 [02:34<04:02, 229.35it/s] 38%|███▊      | 34408/90000 [02:34<04:03, 228.06it/s] 38%|███▊      | 34431/90000 [02:34<04:11, 221.10it/s] 38%|███▊      | 34454/90000 [02:34<04:09, 222.71it/s] 38%|███▊      | 34477/90000 [02:34<04:10, 221.78it/s] 38%|███▊      | 34500/90000 [02:34<04:10, 221.72it/s] 38%|███▊      | 34524/90000 [02:34<04:07, 223.83it/s] 38%|███▊      | 34547/90000 [02:34<04:12, 219.67it/s] 38%|███▊      | 34569/90000 [02:34<04:13, 219.06it/s] 38%|███▊      | 34593/90000 [02:35<04:07, 223.50it/s] 38%|███▊      | 34616/90000 [02:35<04:12, 219.28it/s] 38%|███▊      | 34639/90000 [02:35<04:09, 222.27it/s] 39%|███▊      | 34662/90000 [02:35<04:07, 223.43it/s] 39%|███▊      | 34685/90000 [02:35<04:07, 223.38it/s] 39%|███▊      | 34708/90000 [02:35<04:08, 222.29it/s] 39%|███▊      | 34731/90000 [02:35<04:08, 222.31it/s] 39%|███▊      | 34754/90000 [02:35<04:09, 221.30it/s] 39%|███▊      | 34777/90000 [02:35<04:11, 219.24it/s] 39%|███▊      | 34800/90000 [02:35<04:09, 221.54it/s] 39%|███▊      | 34823/90000 [02:36<04:07, 223.02it/s] 39%|███▊      | 34846/90000 [02:36<04:07, 223.04it/s] 39%|███▊      | 34870/90000 [02:36<04:02, 226.90it/s] 39%|███▉      | 34893/90000 [02:36<04:05, 224.77it/s] 39%|███▉      | 34917/90000 [02:36<04:03, 226.34it/s] 39%|███▉      | 34941/90000 [02:36<04:02, 227.40it/s] 39%|███▉      | 34964/90000 [02:36<04:02, 226.84it/s] 39%|███▉      | 34988/90000 [02:36<04:00, 228.39it/s] 39%|███▉      | 35011/90000 [02:36<04:00, 228.18it/s] 39%|███▉      | 35035/90000 [02:36<03:58, 230.54it/s] 39%|███▉      | 35059/90000 [02:37<04:00, 228.69it/s] 39%|███▉      | 35082/90000 [02:37<04:03, 225.99it/s] 39%|███▉      | 35105/90000 [02:37<04:03, 225.88it/s] 39%|███▉      | 35128/90000 [02:37<04:06, 222.96it/s] 39%|███▉      | 35151/90000 [02:37<04:04, 224.65it/s] 39%|███▉      | 35174/90000 [02:37<04:05, 223.32it/s] 39%|███▉      | 35197/90000 [02:37<04:06, 222.63it/s] 39%|███▉      | 35220/90000 [02:37<04:08, 220.52it/s] 39%|███▉      | 35243/90000 [02:37<04:09, 219.43it/s] 39%|███▉      | 35265/90000 [02:38<04:10, 218.36it/s] 39%|███▉      | 35288/90000 [02:38<04:09, 219.21it/s] 39%|███▉      | 35310/90000 [02:38<04:09, 219.19it/s] 39%|███▉      | 35333/90000 [02:38<04:06, 221.90it/s] 39%|███▉      | 35356/90000 [02:38<04:04, 223.57it/s] 39%|███▉      | 35380/90000 [02:38<03:59, 227.72it/s] 39%|███▉      | 35404/90000 [02:38<03:57, 229.80it/s] 39%|███▉      | 35427/90000 [02:38<03:57, 229.68it/s] 39%|███▉      | 35451/90000 [02:38<03:57, 230.13it/s] 39%|███▉      | 35475/90000 [02:38<04:04, 222.92it/s] 39%|███▉      | 35500/90000 [02:39<03:58, 228.97it/s] 39%|███▉      | 35526/90000 [02:39<03:50, 236.47it/s] 40%|███▉      | 35550/90000 [02:39<03:52, 233.94it/s] 40%|███▉      | 35574/90000 [02:39<03:55, 231.38it/s] 40%|███▉      | 35598/90000 [02:39<03:59, 227.14it/s] 40%|███▉      | 35621/90000 [02:39<04:00, 226.14it/s] 40%|███▉      | 35644/90000 [02:39<04:00, 226.12it/s] 40%|███▉      | 35669/90000 [02:39<03:55, 230.52it/s] 40%|███▉      | 35693/90000 [02:39<03:59, 227.03it/s] 40%|███▉      | 35716/90000 [02:40<03:59, 227.12it/s] 40%|███▉      | 35739/90000 [02:40<04:02, 223.76it/s] 40%|███▉      | 35763/90000 [02:40<03:59, 226.63it/s] 40%|███▉      | 35787/90000 [02:40<03:58, 227.65it/s] 40%|███▉      | 35811/90000 [02:40<03:56, 229.49it/s] 40%|███▉      | 35835/90000 [02:40<03:55, 230.31it/s] 40%|███▉      | 35859/90000 [02:40<03:54, 230.75it/s] 40%|███▉      | 35883/90000 [02:40<03:57, 228.22it/s] 40%|███▉      | 35906/90000 [02:40<03:56, 228.67it/s] 40%|███▉      | 35930/90000 [02:40<03:54, 230.77it/s] 40%|███▉      | 35954/90000 [02:41<03:58, 226.97it/s] 40%|███▉      | 35977/90000 [02:41<03:57, 227.50it/s] 40%|████      | 36000/90000 [02:41<03:58, 226.14it/s] 40%|████      | 36023/90000 [02:41<04:03, 222.07it/s] 40%|████      | 36046/90000 [02:41<04:03, 221.45it/s] 40%|████      | 36069/90000 [02:41<04:02, 222.53it/s] 40%|████      | 36092/90000 [02:41<04:01, 222.79it/s] 40%|████      | 36115/90000 [02:41<04:01, 222.96it/s] 40%|████      | 36138/90000 [02:41<04:02, 221.70it/s] 40%|████      | 36161/90000 [02:41<04:00, 223.76it/s] 40%|████      | 36185/90000 [02:42<03:57, 227.04it/s] 40%|████      | 36208/90000 [02:42<03:59, 224.28it/s] 40%|████      | 36231/90000 [02:42<04:00, 223.98it/s] 40%|████      | 36254/90000 [02:42<04:05, 218.59it/s] 40%|████      | 36276/90000 [02:42<04:07, 216.65it/s] 40%|████      | 36299/90000 [02:42<04:05, 218.51it/s] 40%|████      | 36322/90000 [02:42<04:04, 219.87it/s] 40%|████      | 36345/90000 [02:42<04:02, 221.39it/s] 40%|████      | 36368/90000 [02:42<04:00, 222.95it/s] 40%|████      | 36391/90000 [02:43<04:07, 216.50it/s] 40%|████      | 36416/90000 [02:43<03:59, 223.59it/s] 40%|████      | 36439/90000 [02:43<04:06, 217.53it/s] 41%|████      | 36461/90000 [02:43<04:11, 213.23it/s] 41%|████      | 36483/90000 [02:43<04:12, 212.08it/s] 41%|████      | 36505/90000 [02:43<04:09, 214.15it/s] 41%|████      | 36527/90000 [02:43<04:08, 215.45it/s] 41%|████      | 36549/90000 [02:43<04:07, 216.07it/s] 41%|████      | 36572/90000 [02:43<04:05, 217.73it/s] 41%|████      | 36594/90000 [02:43<04:05, 217.36it/s] 41%|████      | 36618/90000 [02:44<03:59, 222.71it/s] 41%|████      | 36641/90000 [02:44<03:59, 222.82it/s] 41%|████      | 36664/90000 [02:44<03:59, 222.47it/s] 41%|████      | 36687/90000 [02:44<04:02, 219.45it/s] 41%|████      | 36709/90000 [02:44<04:03, 219.10it/s] 41%|████      | 36731/90000 [02:44<04:02, 219.25it/s] 41%|████      | 36754/90000 [02:44<04:02, 219.72it/s] 41%|████      | 36776/90000 [02:44<04:07, 215.31it/s] 41%|████      | 36798/90000 [02:44<04:10, 212.14it/s] 41%|████      | 36820/90000 [02:45<04:09, 212.87it/s] 41%|████      | 36842/90000 [02:45<04:08, 214.20it/s] 41%|████      | 36864/90000 [02:45<04:09, 212.74it/s] 41%|████      | 36886/90000 [02:45<04:13, 209.72it/s] 41%|████      | 36907/90000 [02:45<04:14, 208.77it/s] 41%|████      | 36929/90000 [02:45<04:11, 211.04it/s] 41%|████      | 36951/90000 [02:45<04:10, 211.53it/s] 41%|████      | 36973/90000 [02:45<04:12, 209.68it/s] 41%|████      | 36996/90000 [02:45<04:09, 212.35it/s] 41%|████      | 37018/90000 [02:45<04:10, 211.83it/s] 41%|████      | 37041/90000 [02:46<04:05, 215.67it/s] 41%|████      | 37064/90000 [02:46<04:01, 218.94it/s] 41%|████      | 37087/90000 [02:46<03:59, 220.75it/s] 41%|████      | 37110/90000 [02:46<04:04, 216.07it/s] 41%|████▏     | 37133/90000 [02:46<04:00, 220.06it/s] 41%|████▏     | 37156/90000 [02:46<04:03, 216.90it/s] 41%|████▏     | 37180/90000 [02:46<03:58, 221.19it/s] 41%|████▏     | 37203/90000 [02:46<03:57, 222.11it/s] 41%|████▏     | 37226/90000 [02:46<03:58, 221.22it/s] 41%|████▏     | 37249/90000 [02:46<03:55, 223.58it/s] 41%|████▏     | 37272/90000 [02:47<03:59, 220.29it/s] 41%|████▏     | 37298/90000 [02:47<03:49, 229.26it/s] 41%|████▏     | 37321/90000 [02:47<03:50, 228.73it/s] 41%|████▏     | 37345/90000 [02:47<03:48, 230.85it/s] 42%|████▏     | 37369/90000 [02:47<03:49, 229.71it/s] 42%|████▏     | 37392/90000 [02:47<03:54, 224.62it/s] 42%|████▏     | 37415/90000 [02:47<03:55, 223.70it/s] 42%|████▏     | 37438/90000 [02:47<03:55, 223.35it/s] 42%|████▏     | 37461/90000 [02:47<03:53, 224.55it/s] 42%|████▏     | 37485/90000 [02:48<03:50, 227.66it/s] 42%|████▏     | 37508/90000 [02:48<03:50, 227.82it/s] 42%|████▏     | 37531/90000 [02:48<03:50, 227.50it/s] 42%|████▏     | 37554/90000 [02:48<03:51, 226.96it/s] 42%|████▏     | 37577/90000 [02:48<03:53, 224.93it/s] 42%|████▏     | 37601/90000 [02:48<03:51, 226.81it/s] 42%|████▏     | 37624/90000 [02:48<03:52, 225.44it/s] 42%|████▏     | 37647/90000 [02:48<03:54, 222.81it/s] 42%|████▏     | 37670/90000 [02:48<03:54, 222.97it/s] 42%|████▏     | 37694/90000 [02:48<03:53, 224.41it/s] 42%|████▏     | 37717/90000 [02:49<03:53, 224.04it/s] 42%|████▏     | 37740/90000 [02:49<03:53, 224.27it/s] 42%|████▏     | 37764/90000 [02:49<03:49, 227.30it/s] 42%|████▏     | 37787/90000 [02:49<03:54, 222.81it/s] 42%|████▏     | 37810/90000 [02:49<03:55, 221.52it/s] 42%|████▏     | 37834/90000 [02:49<03:52, 224.72it/s] 42%|████▏     | 37857/90000 [02:49<03:53, 222.87it/s] 42%|████▏     | 37881/90000 [02:49<03:49, 227.20it/s] 42%|████▏     | 37906/90000 [02:49<03:45, 231.15it/s] 42%|████▏     | 37930/90000 [02:50<03:50, 225.89it/s] 42%|████▏     | 37954/90000 [02:50<03:47, 228.98it/s] 42%|████▏     | 37977/90000 [02:50<03:50, 226.03it/s] 42%|████▏     | 38000/90000 [02:50<03:52, 223.92it/s] 42%|████▏     | 38023/90000 [02:50<03:55, 220.33it/s] 42%|████▏     | 38046/90000 [02:50<03:54, 221.40it/s] 42%|████▏     | 38069/90000 [02:50<03:53, 222.27it/s] 42%|████▏     | 38092/90000 [02:50<03:58, 217.90it/s] 42%|████▏     | 38114/90000 [02:50<04:00, 216.01it/s] 42%|████▏     | 38137/90000 [02:50<03:57, 218.56it/s] 42%|████▏     | 38160/90000 [02:51<03:54, 220.67it/s] 42%|████▏     | 38183/90000 [02:51<03:56, 218.81it/s] 42%|████▏     | 38205/90000 [02:51<03:59, 216.60it/s] 42%|████▏     | 38228/90000 [02:51<03:56, 218.82it/s] 42%|████▎     | 38250/90000 [02:51<03:58, 216.66it/s] 43%|████▎     | 38272/90000 [02:51<03:58, 217.02it/s] 43%|████▎     | 38294/90000 [02:51<04:04, 211.11it/s] 43%|████▎     | 38316/90000 [02:51<04:02, 213.52it/s] 43%|████▎     | 38338/90000 [02:51<04:01, 214.26it/s] 43%|████▎     | 38361/90000 [02:51<03:57, 217.81it/s] 43%|████▎     | 38383/90000 [02:52<03:57, 217.55it/s] 43%|████▎     | 38405/90000 [02:52<03:57, 217.04it/s] 43%|████▎     | 38427/90000 [02:52<04:03, 212.13it/s] 43%|████▎     | 38449/90000 [02:52<04:02, 212.54it/s] 43%|████▎     | 38471/90000 [02:52<04:00, 214.39it/s] 43%|████▎     | 38493/90000 [02:52<04:00, 213.86it/s] 43%|████▎     | 38516/90000 [02:52<03:58, 215.89it/s] 43%|████▎     | 38538/90000 [02:52<03:57, 216.97it/s] 43%|████▎     | 38560/90000 [02:52<04:01, 212.90it/s] 43%|████▎     | 38582/90000 [02:53<04:00, 213.84it/s] 43%|████▎     | 38605/90000 [02:53<03:55, 217.97it/s] 43%|████▎     | 38627/90000 [02:53<03:55, 217.91it/s] 43%|████▎     | 38649/90000 [02:53<03:55, 217.90it/s] 43%|████▎     | 38673/90000 [02:53<03:52, 221.14it/s] 43%|████▎     | 38696/90000 [02:53<03:52, 220.36it/s] 43%|████▎     | 38719/90000 [02:53<03:50, 222.29it/s] 43%|████▎     | 38743/90000 [02:53<03:48, 224.49it/s] 43%|████▎     | 38766/90000 [02:53<03:47, 225.00it/s] 43%|████▎     | 38791/90000 [02:53<03:41, 230.92it/s] 43%|████▎     | 38815/90000 [02:54<03:47, 225.17it/s] 43%|████▎     | 38838/90000 [02:54<03:46, 225.78it/s] 43%|████▎     | 38861/90000 [02:54<03:48, 223.81it/s] 43%|████▎     | 38884/90000 [02:54<03:51, 220.63it/s] 43%|████▎     | 38908/90000 [02:54<03:48, 223.69it/s] 43%|████▎     | 38931/90000 [02:54<03:48, 223.59it/s] 43%|████▎     | 38954/90000 [02:54<03:48, 223.77it/s] 43%|████▎     | 38977/90000 [02:54<03:46, 225.51it/s] 43%|████▎     | 39000/90000 [02:54<03:47, 224.55it/s] 43%|████▎     | 39023/90000 [02:54<03:48, 222.89it/s] 43%|████▎     | 39046/90000 [02:55<03:48, 222.71it/s] 43%|████▎     | 39069/90000 [02:55<03:48, 222.72it/s] 43%|████▎     | 39093/90000 [02:55<03:43, 227.56it/s] 43%|████▎     | 39117/90000 [02:55<03:41, 229.35it/s] 43%|████▎     | 39142/90000 [02:55<03:38, 233.03it/s] 44%|████▎     | 39166/90000 [02:55<03:39, 231.55it/s] 44%|████▎     | 39191/90000 [02:55<03:35, 235.24it/s] 44%|████▎     | 39215/90000 [02:55<03:37, 233.44it/s] 44%|████▎     | 39239/90000 [02:55<03:41, 228.93it/s] 44%|████▎     | 39262/90000 [02:56<03:42, 228.48it/s] 44%|████▎     | 39285/90000 [02:56<03:47, 222.79it/s] 44%|████▎     | 39309/90000 [02:56<03:43, 227.27it/s] 44%|████▎     | 39332/90000 [02:56<03:43, 226.68it/s] 44%|████▎     | 39355/90000 [02:56<03:45, 224.55it/s] 44%|████▍     | 39378/90000 [02:56<03:44, 225.13it/s] 44%|████▍     | 39401/90000 [02:56<03:46, 223.00it/s] 44%|████▍     | 39424/90000 [02:56<03:47, 222.77it/s] 44%|████▍     | 39448/90000 [02:56<03:44, 225.09it/s] 44%|████▍     | 39471/90000 [02:56<03:45, 224.49it/s] 44%|████▍     | 39494/90000 [02:57<03:45, 223.72it/s] 44%|████▍     | 39517/90000 [02:57<03:48, 221.21it/s] 44%|████▍     | 39540/90000 [02:57<03:50, 218.65it/s] 44%|████▍     | 39564/90000 [02:57<03:47, 222.08it/s] 44%|████▍     | 39587/90000 [02:57<03:46, 222.69it/s] 44%|████▍     | 39611/90000 [02:57<03:43, 225.68it/s] 44%|████▍     | 39635/90000 [02:57<03:39, 229.70it/s] 44%|████▍     | 39658/90000 [02:57<03:47, 221.66it/s] 44%|████▍     | 39681/90000 [02:57<03:46, 222.43it/s] 44%|████▍     | 39705/90000 [02:58<03:43, 224.56it/s] 44%|████▍     | 39728/90000 [02:58<03:43, 224.67it/s] 44%|████▍     | 39751/90000 [02:58<03:42, 225.62it/s] 44%|████▍     | 39774/90000 [02:58<03:42, 225.54it/s] 44%|████▍     | 39797/90000 [02:58<03:43, 224.46it/s] 44%|████▍     | 39820/90000 [02:58<03:46, 221.32it/s] 44%|████▍     | 39843/90000 [02:58<03:49, 218.08it/s] 44%|████▍     | 39866/90000 [02:58<03:46, 221.25it/s] 44%|████▍     | 39890/90000 [02:58<03:42, 225.17it/s] 44%|████▍     | 39914/90000 [02:58<03:39, 228.01it/s] 44%|████▍     | 39937/90000 [02:59<03:40, 227.05it/s] 44%|████▍     | 39960/90000 [02:59<03:42, 224.97it/s] 44%|████▍     | 39984/90000 [02:59<03:39, 227.83it/s] 44%|████▍     | 40008/90000 [02:59<03:39, 228.11it/s] 44%|████▍     | 40031/90000 [02:59<03:44, 222.21it/s] 45%|████▍     | 40054/90000 [02:59<03:44, 221.99it/s] 45%|████▍     | 40077/90000 [02:59<03:42, 224.03it/s] 45%|████▍     | 40101/90000 [02:59<03:39, 226.83it/s] 45%|████▍     | 40124/90000 [02:59<03:41, 225.12it/s] 45%|████▍     | 40148/90000 [02:59<03:38, 228.49it/s] 45%|████▍     | 40171/90000 [03:00<03:38, 228.12it/s] 45%|████▍     | 40195/90000 [03:00<03:36, 230.53it/s] 45%|████▍     | 40219/90000 [03:00<03:42, 223.51it/s] 45%|████▍     | 40242/90000 [03:00<03:42, 224.00it/s] 45%|████▍     | 40265/90000 [03:00<03:41, 224.19it/s] 45%|████▍     | 40289/90000 [03:00<03:39, 225.98it/s] 45%|████▍     | 40312/90000 [03:00<03:41, 224.73it/s] 45%|████▍     | 40335/90000 [03:00<03:42, 223.36it/s] 45%|████▍     | 40359/90000 [03:00<03:39, 225.75it/s] 45%|████▍     | 40383/90000 [03:01<03:37, 228.01it/s] 45%|████▍     | 40406/90000 [03:01<03:40, 225.22it/s] 45%|████▍     | 40430/90000 [03:01<03:37, 228.32it/s] 45%|████▍     | 40453/90000 [03:01<03:41, 223.26it/s] 45%|████▍     | 40476/90000 [03:01<03:40, 224.82it/s] 45%|████▌     | 40500/90000 [03:01<03:38, 226.11it/s] 45%|████▌     | 40523/90000 [03:01<03:42, 222.85it/s] 45%|████▌     | 40547/90000 [03:01<03:37, 226.86it/s] 45%|████▌     | 40570/90000 [03:01<03:41, 223.51it/s] 45%|████▌     | 40593/90000 [03:01<03:43, 220.59it/s] 45%|████▌     | 40617/90000 [03:02<03:40, 224.12it/s] 45%|████▌     | 40640/90000 [03:02<03:40, 223.35it/s] 45%|████▌     | 40664/90000 [03:02<03:36, 228.13it/s] 45%|████▌     | 40687/90000 [03:02<03:35, 228.62it/s] 45%|████▌     | 40710/90000 [03:02<03:40, 223.31it/s] 45%|████▌     | 40735/90000 [03:02<03:34, 229.32it/s] 45%|████▌     | 40759/90000 [03:02<03:34, 229.23it/s] 45%|████▌     | 40782/90000 [03:02<03:35, 228.22it/s] 45%|████▌     | 40805/90000 [03:02<03:35, 228.29it/s] 45%|████▌     | 40829/90000 [03:02<03:33, 230.26it/s] 45%|████▌     | 40853/90000 [03:03<03:31, 232.66it/s] 45%|████▌     | 40878/90000 [03:03<03:26, 237.60it/s] 45%|████▌     | 40903/90000 [03:03<03:25, 239.14it/s] 45%|████▌     | 40927/90000 [03:03<03:26, 237.88it/s] 46%|████▌     | 40951/90000 [03:03<03:30, 233.54it/s] 46%|████▌     | 40975/90000 [03:03<03:30, 233.36it/s] 46%|████▌     | 40999/90000 [03:03<03:31, 232.11it/s] 46%|████▌     | 41023/90000 [03:03<03:32, 230.74it/s] 46%|████▌     | 41047/90000 [03:03<03:34, 228.00it/s] 46%|████▌     | 41070/90000 [03:04<03:36, 225.78it/s] 46%|████▌     | 41093/90000 [03:04<03:43, 219.28it/s] 46%|████▌     | 41115/90000 [03:04<03:44, 217.40it/s] 46%|████▌     | 41138/90000 [03:04<03:42, 219.61it/s] 46%|████▌     | 41161/90000 [03:04<03:40, 221.31it/s] 46%|████▌     | 41184/90000 [03:04<03:47, 214.27it/s] 46%|████▌     | 41206/90000 [03:04<03:52, 210.27it/s] 46%|████▌     | 41228/90000 [03:04<03:49, 212.37it/s] 46%|████▌     | 41252/90000 [03:04<03:44, 217.10it/s] 46%|████▌     | 41274/90000 [03:04<03:47, 214.33it/s] 46%|████▌     | 41298/90000 [03:05<03:42, 219.09it/s] 46%|████▌     | 41322/90000 [03:05<03:38, 222.56it/s] 46%|████▌     | 41345/90000 [03:05<03:37, 223.95it/s] 46%|████▌     | 41368/90000 [03:05<03:37, 223.82it/s] 46%|████▌     | 41391/90000 [03:05<03:40, 220.37it/s] 46%|████▌     | 41414/90000 [03:05<03:37, 223.05it/s] 46%|████▌     | 41437/90000 [03:05<03:38, 222.27it/s] 46%|████▌     | 41460/90000 [03:05<03:38, 221.82it/s] 46%|████▌     | 41484/90000 [03:05<03:35, 225.34it/s] 46%|████▌     | 41507/90000 [03:06<03:36, 224.26it/s] 46%|████▌     | 41530/90000 [03:06<03:36, 224.14it/s] 46%|████▌     | 41553/90000 [03:06<03:41, 218.88it/s] 46%|████▌     | 41576/90000 [03:06<03:40, 219.79it/s] 46%|████▌     | 41600/90000 [03:06<03:34, 225.43it/s] 46%|████▌     | 41623/90000 [03:06<03:38, 221.19it/s] 46%|████▋     | 41646/90000 [03:06<03:46, 213.74it/s] 46%|████▋     | 41668/90000 [03:06<03:46, 213.45it/s] 46%|████▋     | 41691/90000 [03:06<03:43, 216.16it/s] 46%|████▋     | 41714/90000 [03:06<03:40, 219.29it/s] 46%|████▋     | 41736/90000 [03:07<03:45, 214.21it/s] 46%|████▋     | 41760/90000 [03:07<03:38, 220.61it/s] 46%|████▋     | 41784/90000 [03:07<03:34, 224.54it/s] 46%|████▋     | 41809/90000 [03:07<03:30, 228.93it/s] 46%|████▋     | 41833/90000 [03:07<03:28, 231.06it/s] 47%|████▋     | 41857/90000 [03:07<03:30, 228.76it/s] 47%|████▋     | 41881/90000 [03:07<03:29, 230.00it/s] 47%|████▋     | 41905/90000 [03:07<03:31, 227.59it/s] 47%|████▋     | 41929/90000 [03:07<03:29, 229.92it/s] 47%|████▋     | 41954/90000 [03:08<03:25, 233.67it/s] 47%|████▋     | 41978/90000 [03:08<03:26, 232.65it/s] 47%|████▋     | 42002/90000 [03:08<03:29, 229.14it/s] 47%|████▋     | 42025/90000 [03:08<03:32, 225.84it/s] 47%|████▋     | 42049/90000 [03:08<03:29, 229.12it/s] 47%|████▋     | 42072/90000 [03:08<03:31, 226.26it/s] 47%|████▋     | 42096/90000 [03:08<03:28, 229.39it/s] 47%|████▋     | 42120/90000 [03:08<03:26, 232.17it/s] 47%|████▋     | 42144/90000 [03:08<03:27, 230.96it/s] 47%|████▋     | 42169/90000 [03:08<03:24, 233.69it/s] 47%|████▋     | 42193/90000 [03:09<03:25, 233.19it/s] 47%|████▋     | 42217/90000 [03:09<03:28, 229.31it/s] 47%|████▋     | 42241/90000 [03:09<03:26, 231.33it/s] 47%|████▋     | 42265/90000 [03:09<03:29, 228.25it/s] 47%|████▋     | 42289/90000 [03:09<03:27, 230.30it/s] 47%|████▋     | 42313/90000 [03:09<03:27, 230.32it/s] 47%|████▋     | 42337/90000 [03:09<03:27, 229.63it/s] 47%|████▋     | 42362/90000 [03:09<03:24, 233.13it/s] 47%|████▋     | 42386/90000 [03:09<03:23, 234.05it/s] 47%|████▋     | 42410/90000 [03:09<03:28, 228.70it/s] 47%|████▋     | 42434/90000 [03:10<03:26, 230.69it/s] 47%|████▋     | 42458/90000 [03:10<03:26, 230.23it/s] 47%|████▋     | 42482/90000 [03:10<03:27, 228.52it/s] 47%|████▋     | 42505/90000 [03:10<03:28, 228.13it/s] 47%|████▋     | 42529/90000 [03:10<03:27, 228.73it/s] 47%|████▋     | 42552/90000 [03:10<03:29, 226.23it/s] 47%|████▋     | 42577/90000 [03:10<03:26, 229.82it/s] 47%|████▋     | 42600/90000 [03:10<03:30, 225.62it/s] 47%|████▋     | 42624/90000 [03:10<03:28, 226.73it/s] 47%|████▋     | 42647/90000 [03:11<03:29, 226.04it/s] 47%|████▋     | 42670/90000 [03:11<03:30, 224.55it/s] 47%|████▋     | 42693/90000 [03:11<03:30, 224.48it/s] 47%|████▋     | 42717/90000 [03:11<03:27, 228.02it/s] 47%|████▋     | 42740/90000 [03:11<03:30, 224.92it/s] 48%|████▊     | 42764/90000 [03:11<03:27, 227.93it/s] 48%|████▊     | 42788/90000 [03:11<03:24, 230.89it/s] 48%|████▊     | 42812/90000 [03:11<03:24, 230.42it/s] 48%|████▊     | 42836/90000 [03:11<03:29, 225.04it/s] 48%|████▊     | 42859/90000 [03:11<03:30, 224.13it/s] 48%|████▊     | 42883/90000 [03:12<03:27, 226.82it/s] 48%|████▊     | 42906/90000 [03:12<03:28, 225.74it/s] 48%|████▊     | 42930/90000 [03:12<03:26, 227.60it/s] 48%|████▊     | 42954/90000 [03:12<03:24, 230.13it/s] 48%|████▊     | 42978/90000 [03:12<03:25, 229.17it/s] 48%|████▊     | 43001/90000 [03:12<03:25, 228.90it/s] 48%|████▊     | 43024/90000 [03:12<03:26, 227.55it/s] 48%|████▊     | 43047/90000 [03:12<03:26, 227.15it/s] 48%|████▊     | 43071/90000 [03:12<03:24, 229.98it/s] 48%|████▊     | 43095/90000 [03:12<03:24, 229.19it/s] 48%|████▊     | 43118/90000 [03:13<03:31, 221.64it/s] 48%|████▊     | 43142/90000 [03:13<03:28, 224.62it/s] 48%|████▊     | 43165/90000 [03:13<03:28, 224.57it/s] 48%|████▊     | 43188/90000 [03:13<03:32, 220.49it/s] 48%|████▊     | 43211/90000 [03:13<03:30, 222.17it/s] 48%|████▊     | 43234/90000 [03:13<03:30, 221.66it/s] 48%|████▊     | 43258/90000 [03:13<03:26, 226.03it/s] 48%|████▊     | 43281/90000 [03:13<03:28, 224.50it/s] 48%|████▊     | 43305/90000 [03:13<03:25, 227.40it/s] 48%|████▊     | 43328/90000 [03:14<03:24, 227.68it/s] 48%|████▊     | 43352/90000 [03:14<03:22, 230.29it/s] 48%|████▊     | 43377/90000 [03:14<03:19, 233.97it/s] 48%|████▊     | 43402/90000 [03:14<03:17, 235.69it/s] 48%|████▊     | 43426/90000 [03:14<03:20, 232.08it/s] 48%|████▊     | 43450/90000 [03:14<03:21, 230.48it/s] 48%|████▊     | 43474/90000 [03:14<03:22, 229.38it/s] 48%|████▊     | 43497/90000 [03:14<03:22, 229.19it/s] 48%|████▊     | 43520/90000 [03:14<03:23, 228.49it/s] 48%|████▊     | 43543/90000 [03:14<03:26, 224.69it/s] 48%|████▊     | 43566/90000 [03:15<03:26, 224.95it/s] 48%|████▊     | 43591/90000 [03:15<03:20, 231.48it/s] 48%|████▊     | 43615/90000 [03:15<03:21, 230.26it/s] 48%|████▊     | 43639/90000 [03:15<03:23, 227.51it/s] 49%|████▊     | 43662/90000 [03:15<03:25, 224.94it/s] 49%|████▊     | 43685/90000 [03:15<03:24, 225.95it/s] 49%|████▊     | 43711/90000 [03:15<03:18, 233.55it/s] 49%|████▊     | 43736/90000 [03:15<03:15, 236.61it/s] 49%|████▊     | 43760/90000 [03:15<03:17, 234.21it/s] 49%|████▊     | 43784/90000 [03:16<03:18, 233.05it/s] 49%|████▊     | 43808/90000 [03:16<03:20, 230.19it/s] 49%|████▊     | 43832/90000 [03:16<03:19, 231.45it/s] 49%|████▊     | 43856/90000 [03:16<03:19, 231.65it/s] 49%|████▉     | 43880/90000 [03:16<03:19, 231.53it/s] 49%|████▉     | 43904/90000 [03:16<03:20, 229.43it/s] 49%|████▉     | 43928/90000 [03:16<03:20, 230.12it/s] 49%|████▉     | 43952/90000 [03:16<03:19, 231.23it/s] 49%|████▉     | 43976/90000 [03:16<03:19, 230.59it/s] 49%|████▉     | 44000/90000 [03:16<03:21, 228.47it/s] 49%|████▉     | 44023/90000 [03:17<03:22, 227.03it/s] 49%|████▉     | 44046/90000 [03:17<03:25, 223.50it/s] 49%|████▉     | 44069/90000 [03:17<03:24, 224.68it/s] 49%|████▉     | 44092/90000 [03:17<03:27, 220.97it/s] 49%|████▉     | 44115/90000 [03:17<03:27, 220.71it/s] 49%|████▉     | 44138/90000 [03:17<03:29, 218.71it/s] 49%|████▉     | 44162/90000 [03:17<03:25, 223.36it/s] 49%|████▉     | 44185/90000 [03:17<03:26, 221.99it/s] 49%|████▉     | 44208/90000 [03:17<03:28, 219.23it/s] 49%|████▉     | 44231/90000 [03:18<03:26, 221.96it/s] 49%|████▉     | 44254/90000 [03:18<03:26, 221.24it/s] 49%|████▉     | 44278/90000 [03:18<03:23, 224.69it/s] 49%|████▉     | 44303/90000 [03:18<03:18, 229.89it/s] 49%|████▉     | 44327/90000 [03:18<03:23, 224.38it/s] 49%|████▉     | 44352/90000 [03:18<03:19, 229.30it/s] 49%|████▉     | 44376/90000 [03:18<03:17, 230.64it/s] 49%|████▉     | 44400/90000 [03:18<03:20, 227.30it/s] 49%|████▉     | 44424/90000 [03:18<03:17, 230.19it/s] 49%|████▉     | 44448/90000 [03:18<03:18, 228.92it/s] 49%|████▉     | 44471/90000 [03:19<03:19, 228.60it/s] 49%|████▉     | 44496/90000 [03:19<03:14, 233.45it/s] 49%|████▉     | 44520/90000 [03:19<03:17, 229.85it/s] 49%|████▉     | 44544/90000 [03:19<03:19, 227.42it/s] 50%|████▉     | 44568/90000 [03:19<03:17, 229.98it/s] 50%|████▉     | 44592/90000 [03:19<03:18, 228.88it/s] 50%|████▉     | 44616/90000 [03:19<03:17, 229.44it/s] 50%|████▉     | 44639/90000 [03:19<03:18, 228.41it/s] 50%|████▉     | 44662/90000 [03:19<03:18, 228.44it/s] 50%|████▉     | 44686/90000 [03:19<03:16, 230.60it/s] 50%|████▉     | 44710/90000 [03:20<03:21, 224.55it/s] 50%|████▉     | 44735/90000 [03:20<03:17, 229.36it/s] 50%|████▉     | 44758/90000 [03:20<03:17, 228.94it/s] 50%|████▉     | 44782/90000 [03:20<03:16, 230.41it/s] 50%|████▉     | 44806/90000 [03:20<03:14, 232.10it/s] 50%|████▉     | 44830/90000 [03:20<03:15, 231.45it/s] 50%|████▉     | 44854/90000 [03:20<03:16, 229.30it/s] 50%|████▉     | 44879/90000 [03:20<03:12, 234.19it/s] 50%|████▉     | 44903/90000 [03:20<03:13, 233.30it/s] 50%|████▉     | 44927/90000 [03:21<03:18, 227.03it/s] 50%|████▉     | 44952/90000 [03:21<03:13, 232.99it/s] 50%|████▉     | 44976/90000 [03:21<03:13, 232.74it/s] 50%|█████     | 45001/90000 [03:21<03:10, 236.64it/s] 50%|█████     | 45025/90000 [03:21<03:10, 235.57it/s] 50%|█████     | 45049/90000 [03:21<03:13, 231.73it/s] 50%|█████     | 45073/90000 [03:21<03:14, 231.35it/s] 50%|█████     | 45097/90000 [03:21<03:13, 232.16it/s] 50%|█████     | 45121/90000 [03:21<03:15, 230.04it/s] 50%|█████     | 45145/90000 [03:21<03:13, 231.62it/s] 50%|█████     | 45169/90000 [03:22<03:13, 232.14it/s] 50%|█████     | 45193/90000 [03:22<03:16, 228.39it/s] 50%|█████     | 45217/90000 [03:22<03:15, 229.55it/s] 50%|█████     | 45241/90000 [03:22<03:15, 228.52it/s] 50%|█████     | 45264/90000 [03:22<03:16, 228.09it/s] 50%|█████     | 45288/90000 [03:22<03:15, 228.77it/s] 50%|█████     | 45311/90000 [03:22<03:15, 229.00it/s] 50%|█████     | 45334/90000 [03:22<03:15, 228.60it/s] 50%|█████     | 45358/90000 [03:22<03:14, 229.95it/s] 50%|█████     | 45382/90000 [03:22<03:11, 232.52it/s] 50%|█████     | 45406/90000 [03:23<03:11, 232.54it/s] 50%|█████     | 45430/90000 [03:23<03:11, 233.29it/s] 51%|█████     | 45454/90000 [03:23<03:13, 230.19it/s] 51%|█████     | 45478/90000 [03:23<03:11, 232.55it/s] 51%|█████     | 45502/90000 [03:23<03:13, 229.59it/s] 51%|█████     | 45527/90000 [03:23<03:09, 234.49it/s] 51%|█████     | 45551/90000 [03:23<03:13, 229.33it/s] 51%|█████     | 45574/90000 [03:23<03:14, 228.87it/s] 51%|█████     | 45598/90000 [03:23<03:11, 231.48it/s] 51%|█████     | 45622/90000 [03:24<03:12, 230.34it/s] 51%|█████     | 45646/90000 [03:24<03:11, 231.74it/s] 51%|█████     | 45671/90000 [03:24<03:08, 235.05it/s] 51%|█████     | 45695/90000 [03:24<03:10, 232.90it/s] 51%|█████     | 45719/90000 [03:24<03:10, 231.93it/s] 51%|█████     | 45743/90000 [03:24<03:19, 222.30it/s] 51%|█████     | 45767/90000 [03:24<03:15, 225.76it/s] 51%|█████     | 45791/90000 [03:24<03:14, 227.50it/s] 51%|█████     | 45814/90000 [03:24<03:14, 227.24it/s] 51%|█████     | 45838/90000 [03:24<03:13, 228.67it/s] 51%|█████     | 45861/90000 [03:25<03:13, 228.40it/s] 51%|█████     | 45884/90000 [03:25<03:13, 228.21it/s] 51%|█████     | 45908/90000 [03:25<03:10, 231.10it/s] 51%|█████     | 45932/90000 [03:25<03:11, 230.19it/s] 51%|█████     | 45956/90000 [03:25<03:14, 226.71it/s] 51%|█████     | 45981/90000 [03:25<03:10, 231.27it/s] 51%|█████     | 46005/90000 [03:25<03:15, 224.87it/s] 51%|█████     | 46029/90000 [03:25<03:14, 226.50it/s] 51%|█████     | 46054/90000 [03:25<03:13, 227.39it/s] 51%|█████     | 46079/90000 [03:26<03:09, 231.88it/s] 51%|█████     | 46103/90000 [03:26<03:12, 227.98it/s] 51%|█████▏    | 46127/90000 [03:26<03:09, 231.01it/s] 51%|█████▏    | 46152/90000 [03:26<03:07, 233.63it/s] 51%|█████▏    | 46176/90000 [03:26<03:10, 230.16it/s] 51%|█████▏    | 46200/90000 [03:26<03:12, 228.09it/s] 51%|█████▏    | 46225/90000 [03:26<03:08, 231.87it/s] 51%|█████▏    | 46249/90000 [03:26<03:08, 232.55it/s] 51%|█████▏    | 46273/90000 [03:26<03:08, 231.74it/s] 51%|█████▏    | 46297/90000 [03:26<03:08, 231.66it/s] 51%|█████▏    | 46321/90000 [03:27<03:09, 230.90it/s] 51%|█████▏    | 46345/90000 [03:27<03:08, 231.61it/s] 52%|█████▏    | 46369/90000 [03:27<03:10, 229.01it/s] 52%|█████▏    | 46392/90000 [03:27<03:29, 207.70it/s] 52%|█████▏    | 46415/90000 [03:27<03:24, 212.84it/s] 52%|█████▏    | 46438/90000 [03:27<03:20, 217.19it/s] 52%|█████▏    | 46463/90000 [03:27<03:14, 224.10it/s] 52%|█████▏    | 46486/90000 [03:27<03:12, 225.70it/s] 52%|█████▏    | 46510/90000 [03:27<03:09, 229.52it/s] 52%|█████▏    | 46534/90000 [03:28<03:11, 227.47it/s] 52%|█████▏    | 46557/90000 [03:28<03:22, 214.33it/s] 52%|█████▏    | 46580/90000 [03:28<03:20, 216.82it/s] 52%|█████▏    | 46604/90000 [03:28<03:16, 221.20it/s] 52%|█████▏    | 46627/90000 [03:28<03:16, 221.06it/s] 52%|█████▏    | 46650/90000 [03:28<03:14, 222.54it/s] 52%|█████▏    | 46675/90000 [03:28<03:09, 228.27it/s] 52%|█████▏    | 46698/90000 [03:28<03:09, 228.53it/s] 52%|█████▏    | 46722/90000 [03:28<03:07, 230.83it/s] 52%|█████▏    | 46746/90000 [03:28<03:09, 227.81it/s] 52%|█████▏    | 46769/90000 [03:29<03:12, 224.50it/s] 52%|█████▏    | 46792/90000 [03:29<03:12, 224.14it/s] 52%|█████▏    | 46815/90000 [03:29<03:13, 223.47it/s] 52%|█████▏    | 46838/90000 [03:29<03:13, 223.52it/s] 52%|█████▏    | 46861/90000 [03:29<03:12, 224.04it/s] 52%|█████▏    | 46884/90000 [03:29<03:15, 220.38it/s] 52%|█████▏    | 46907/90000 [03:29<03:15, 220.30it/s] 52%|█████▏    | 46930/90000 [03:29<03:14, 220.93it/s] 52%|█████▏    | 46953/90000 [03:29<03:21, 213.64it/s] 52%|█████▏    | 46976/90000 [03:30<03:18, 216.60it/s] 52%|█████▏    | 47000/90000 [03:30<03:15, 220.24it/s] 52%|█████▏    | 47023/90000 [03:30<03:18, 216.45it/s] 52%|█████▏    | 47045/90000 [03:30<03:20, 214.08it/s] 52%|█████▏    | 47067/90000 [03:30<03:19, 215.28it/s] 52%|█████▏    | 47089/90000 [03:30<03:20, 214.02it/s] 52%|█████▏    | 47111/90000 [03:30<03:19, 214.80it/s] 52%|█████▏    | 47134/90000 [03:30<03:18, 216.10it/s] 52%|█████▏    | 47156/90000 [03:30<03:20, 214.21it/s] 52%|█████▏    | 47178/90000 [03:30<03:18, 215.20it/s] 52%|█████▏    | 47201/90000 [03:31<03:16, 218.32it/s] 52%|█████▏    | 47223/90000 [03:31<03:17, 216.33it/s] 52%|█████▏    | 47247/90000 [03:31<03:13, 221.21it/s] 53%|█████▎    | 47270/90000 [03:31<03:12, 221.66it/s] 53%|█████▎    | 47293/90000 [03:31<03:12, 221.83it/s] 53%|█████▎    | 47316/90000 [03:31<03:11, 222.89it/s] 53%|█████▎    | 47339/90000 [03:31<03:16, 217.35it/s] 53%|█████▎    | 47364/90000 [03:31<03:10, 223.27it/s] 53%|█████▎    | 47388/90000 [03:31<03:09, 225.08it/s] 53%|█████▎    | 47411/90000 [03:32<03:12, 221.21it/s] 53%|█████▎    | 47434/90000 [03:32<03:14, 219.02it/s] 53%|█████▎    | 47456/90000 [03:32<03:17, 215.01it/s] 53%|█████▎    | 47478/90000 [03:32<03:17, 215.54it/s] 53%|█████▎    | 47500/90000 [03:32<03:20, 211.91it/s] 53%|█████▎    | 47523/90000 [03:32<03:16, 215.99it/s] 53%|█████▎    | 47546/90000 [03:32<03:13, 219.07it/s] 53%|█████▎    | 47570/90000 [03:32<03:10, 222.17it/s] 53%|█████▎    | 47593/90000 [03:32<03:14, 218.31it/s] 53%|█████▎    | 47615/90000 [03:32<03:14, 218.29it/s] 53%|█████▎    | 47638/90000 [03:33<03:11, 220.75it/s] 53%|█████▎    | 47662/90000 [03:33<03:09, 223.73it/s] 53%|█████▎    | 47685/90000 [03:33<03:13, 218.87it/s] 53%|█████▎    | 47707/90000 [03:33<03:14, 217.67it/s] 53%|█████▎    | 47730/90000 [03:33<03:13, 218.88it/s] 53%|█████▎    | 47753/90000 [03:33<03:13, 218.86it/s] 53%|█████▎    | 47775/90000 [03:33<03:12, 219.13it/s] 53%|█████▎    | 47797/90000 [03:33<03:12, 219.33it/s] 53%|█████▎    | 47820/90000 [03:33<03:12, 219.52it/s] 53%|█████▎    | 47843/90000 [03:34<03:10, 221.71it/s] 53%|█████▎    | 47866/90000 [03:34<03:12, 219.07it/s] 53%|█████▎    | 47888/90000 [03:34<03:12, 218.42it/s] 53%|█████▎    | 47911/90000 [03:34<03:12, 218.88it/s] 53%|█████▎    | 47934/90000 [03:34<03:10, 220.28it/s] 53%|█████▎    | 47957/90000 [03:34<03:10, 220.40it/s] 53%|█████▎    | 47980/90000 [03:34<03:11, 219.64it/s] 53%|█████▎    | 48004/90000 [03:34<03:08, 223.14it/s] 53%|█████▎    | 48027/90000 [03:34<03:09, 221.91it/s] 53%|█████▎    | 48050/90000 [03:34<03:12, 218.40it/s] 53%|█████▎    | 48073/90000 [03:35<03:10, 220.00it/s] 53%|█████▎    | 48096/90000 [03:35<03:12, 217.45it/s] 53%|█████▎    | 48119/90000 [03:35<03:11, 219.14it/s] 53%|█████▎    | 48143/90000 [03:35<03:08, 222.63it/s] 54%|█████▎    | 48166/90000 [03:35<03:06, 224.44it/s] 54%|█████▎    | 48189/90000 [03:35<03:07, 222.80it/s] 54%|█████▎    | 48213/90000 [03:35<03:04, 226.20it/s] 54%|█████▎    | 48236/90000 [03:35<03:09, 220.27it/s] 54%|█████▎    | 48260/90000 [03:35<03:05, 224.44it/s] 54%|█████▎    | 48283/90000 [03:35<03:05, 224.59it/s] 54%|█████▎    | 48306/90000 [03:36<03:06, 223.23it/s] 54%|█████▎    | 48329/90000 [03:36<03:07, 222.50it/s] 54%|█████▎    | 48352/90000 [03:36<03:10, 218.29it/s] 54%|█████▍    | 48375/90000 [03:36<03:09, 219.37it/s] 54%|█████▍    | 48397/90000 [03:36<03:13, 215.39it/s] 54%|█████▍    | 48420/90000 [03:36<03:11, 216.68it/s] 54%|█████▍    | 48442/90000 [03:36<03:14, 213.85it/s] 54%|█████▍    | 48465/90000 [03:36<03:10, 218.38it/s] 54%|█████▍    | 48488/90000 [03:36<03:09, 219.55it/s] 54%|█████▍    | 48511/90000 [03:37<03:07, 221.22it/s] 54%|█████▍    | 48534/90000 [03:37<03:07, 221.57it/s] 54%|█████▍    | 48558/90000 [03:37<03:03, 225.35it/s] 54%|█████▍    | 48583/90000 [03:37<02:59, 230.18it/s] 54%|█████▍    | 48607/90000 [03:37<03:01, 227.68it/s] 54%|█████▍    | 48630/90000 [03:37<03:04, 223.86it/s] 54%|█████▍    | 48653/90000 [03:37<03:04, 224.37it/s] 54%|█████▍    | 48678/90000 [03:37<02:59, 229.86it/s] 54%|█████▍    | 48701/90000 [03:37<03:05, 223.04it/s] 54%|█████▍    | 48724/90000 [03:37<03:05, 222.43it/s] 54%|█████▍    | 48747/90000 [03:38<03:04, 223.30it/s] 54%|█████▍    | 48770/90000 [03:38<03:04, 224.02it/s] 54%|█████▍    | 48794/90000 [03:38<03:01, 227.05it/s] 54%|█████▍    | 48817/90000 [03:38<03:01, 226.96it/s] 54%|█████▍    | 48840/90000 [03:38<03:03, 223.72it/s] 54%|█████▍    | 48863/90000 [03:38<03:04, 223.00it/s] 54%|█████▍    | 48886/90000 [03:38<03:04, 222.87it/s] 54%|█████▍    | 48910/90000 [03:38<03:01, 225.94it/s] 54%|█████▍    | 48934/90000 [03:38<02:59, 229.13it/s] 54%|█████▍    | 48957/90000 [03:39<03:04, 222.08it/s] 54%|█████▍    | 48980/90000 [03:39<03:08, 218.05it/s] 54%|█████▍    | 49002/90000 [03:39<03:08, 217.33it/s] 54%|█████▍    | 49024/90000 [03:39<03:08, 217.62it/s] 54%|█████▍    | 49047/90000 [03:39<03:07, 218.67it/s] 55%|█████▍    | 49070/90000 [03:39<03:05, 220.67it/s] 55%|█████▍    | 49093/90000 [03:39<03:05, 220.82it/s] 55%|█████▍    | 49116/90000 [03:39<03:07, 218.02it/s] 55%|█████▍    | 49140/90000 [03:39<03:02, 223.59it/s] 55%|█████▍    | 49164/90000 [03:39<03:00, 226.65it/s] 55%|█████▍    | 49187/90000 [03:40<03:02, 223.52it/s] 55%|█████▍    | 49210/90000 [03:40<03:05, 219.80it/s] 55%|█████▍    | 49234/90000 [03:40<03:01, 224.58it/s] 55%|█████▍    | 49257/90000 [03:40<03:05, 219.34it/s] 55%|█████▍    | 49280/90000 [03:40<03:03, 222.12it/s] 55%|█████▍    | 49303/90000 [03:40<03:01, 224.04it/s] 55%|█████▍    | 49326/90000 [03:40<03:01, 223.86it/s] 55%|█████▍    | 49349/90000 [03:40<03:05, 219.27it/s] 55%|█████▍    | 49372/90000 [03:40<03:03, 221.69it/s] 55%|█████▍    | 49395/90000 [03:41<03:02, 222.18it/s] 55%|█████▍    | 49418/90000 [03:41<03:07, 216.30it/s] 55%|█████▍    | 49441/90000 [03:41<03:05, 218.58it/s] 55%|█████▍    | 49463/90000 [03:41<03:06, 217.49it/s] 55%|█████▍    | 49487/90000 [03:41<03:02, 222.56it/s] 55%|█████▌    | 49510/90000 [03:41<03:06, 217.57it/s] 55%|█████▌    | 49533/90000 [03:41<03:03, 220.36it/s] 55%|█████▌    | 49557/90000 [03:41<03:00, 224.03it/s] 55%|█████▌    | 49580/90000 [03:41<03:00, 224.51it/s] 55%|█████▌    | 49603/90000 [03:41<03:00, 223.45it/s] 55%|█████▌    | 49627/90000 [03:42<02:59, 225.43it/s] 55%|█████▌    | 49651/90000 [03:42<02:56, 229.04it/s] 55%|█████▌    | 49675/90000 [03:42<02:55, 229.90it/s] 55%|█████▌    | 49698/90000 [03:42<02:59, 225.05it/s] 55%|█████▌    | 49722/90000 [03:42<02:55, 229.20it/s] 55%|█████▌    | 49745/90000 [03:42<02:58, 225.66it/s] 55%|█████▌    | 49768/90000 [03:42<02:58, 225.86it/s] 55%|█████▌    | 49791/90000 [03:42<02:57, 226.36it/s] 55%|█████▌    | 49815/90000 [03:42<02:54, 229.79it/s] 55%|█████▌    | 49839/90000 [03:42<02:52, 232.22it/s] 55%|█████▌    | 49863/90000 [03:43<03:00, 222.16it/s] 55%|█████▌    | 49886/90000 [03:43<03:00, 222.27it/s] 55%|█████▌    | 49909/90000 [03:43<03:01, 221.22it/s] 55%|█████▌    | 49932/90000 [03:43<03:05, 215.75it/s] 56%|█████▌    | 49954/90000 [03:43<03:05, 216.27it/s] 56%|█████▌    | 49976/90000 [03:43<03:08, 212.79it/s] 56%|█████▌    | 49999/90000 [03:43<03:04, 216.95it/s] 56%|█████▌    | 50021/90000 [03:43<03:04, 216.51it/s] 56%|█████▌    | 50043/90000 [03:43<03:10, 209.61it/s] 56%|█████▌    | 50065/90000 [03:44<03:10, 209.26it/s] 56%|█████▌    | 50086/90000 [03:44<03:14, 205.46it/s] 56%|█████▌    | 50108/90000 [03:44<03:11, 208.26it/s] 56%|█████▌    | 50131/90000 [03:44<03:07, 213.04it/s] 56%|█████▌    | 50153/90000 [03:44<03:08, 210.85it/s] 56%|█████▌    | 50175/90000 [03:44<03:07, 212.06it/s] 56%|█████▌    | 50198/90000 [03:44<03:04, 216.31it/s] 56%|█████▌    | 50221/90000 [03:44<03:01, 219.77it/s] 56%|█████▌    | 50245/90000 [03:44<02:58, 222.69it/s] 56%|█████▌    | 50268/90000 [03:44<02:57, 224.29it/s] 56%|█████▌    | 50292/90000 [03:45<02:55, 226.87it/s] 56%|█████▌    | 50315/90000 [03:45<02:54, 227.33it/s] 56%|█████▌    | 50339/90000 [03:45<02:51, 230.61it/s] 56%|█████▌    | 50363/90000 [03:45<02:51, 230.72it/s] 56%|█████▌    | 50387/90000 [03:45<02:50, 232.28it/s] 56%|█████▌    | 50411/90000 [03:45<02:49, 232.93it/s] 56%|█████▌    | 50435/90000 [03:45<02:52, 229.28it/s] 56%|█████▌    | 50459/90000 [03:45<02:51, 230.74it/s] 56%|█████▌    | 50483/90000 [03:45<02:51, 230.48it/s] 56%|█████▌    | 50507/90000 [03:46<02:52, 229.42it/s] 56%|█████▌    | 50532/90000 [03:46<02:48, 234.31it/s] 56%|█████▌    | 50556/90000 [03:46<02:50, 230.74it/s] 56%|█████▌    | 50580/90000 [03:46<02:49, 231.94it/s] 56%|█████▌    | 50604/90000 [03:46<02:49, 232.73it/s] 56%|█████▋    | 50628/90000 [03:46<02:53, 227.19it/s] 56%|█████▋    | 50652/90000 [03:46<02:52, 228.20it/s] 56%|█████▋    | 50675/90000 [03:46<02:54, 225.00it/s] 56%|█████▋    | 50698/90000 [03:46<02:53, 226.13it/s] 56%|█████▋    | 50722/90000 [03:46<02:51, 228.49it/s] 56%|█████▋    | 50745/90000 [03:47<02:56, 222.14it/s] 56%|█████▋    | 50768/90000 [03:47<02:57, 221.27it/s] 56%|█████▋    | 50791/90000 [03:47<02:55, 223.21it/s] 56%|█████▋    | 50815/90000 [03:47<02:54, 225.15it/s] 56%|█████▋    | 50840/90000 [03:47<02:50, 230.25it/s] 57%|█████▋    | 50864/90000 [03:47<02:48, 231.85it/s] 57%|█████▋    | 50889/90000 [03:47<02:45, 235.79it/s] 57%|█████▋    | 50913/90000 [03:47<02:47, 233.30it/s] 57%|█████▋    | 50937/90000 [03:47<02:46, 235.18it/s] 57%|█████▋    | 50961/90000 [03:47<02:49, 230.98it/s] 57%|█████▋    | 50986/90000 [03:48<02:46, 234.15it/s] 57%|█████▋    | 51010/90000 [03:48<02:51, 227.92it/s] 57%|█████▋    | 51033/90000 [03:48<02:50, 228.38it/s] 57%|█████▋    | 51057/90000 [03:48<02:48, 231.02it/s] 57%|█████▋    | 51081/90000 [03:48<02:49, 229.68it/s] 57%|█████▋    | 51104/90000 [03:48<02:51, 226.19it/s] 57%|█████▋    | 51127/90000 [03:48<02:52, 225.56it/s] 57%|█████▋    | 51151/90000 [03:48<02:50, 227.75it/s] 57%|█████▋    | 51176/90000 [03:48<02:46, 233.32it/s] 57%|█████▋    | 51200/90000 [03:49<02:46, 232.77it/s] 57%|█████▋    | 51224/90000 [03:49<02:49, 228.30it/s] 57%|█████▋    | 51247/90000 [03:49<02:51, 226.26it/s] 57%|█████▋    | 51270/90000 [03:49<02:51, 226.43it/s] 57%|█████▋    | 51293/90000 [03:49<02:51, 225.50it/s] 57%|█████▋    | 51316/90000 [03:49<02:54, 222.24it/s] 57%|█████▋    | 51339/90000 [03:49<02:52, 224.20it/s] 57%|█████▋    | 51362/90000 [03:49<02:53, 222.83it/s] 57%|█████▋    | 51385/90000 [03:49<02:53, 223.06it/s] 57%|█████▋    | 51408/90000 [03:49<02:56, 218.89it/s] 57%|█████▋    | 51430/90000 [03:50<02:57, 217.01it/s] 57%|█████▋    | 51454/90000 [03:50<02:52, 222.94it/s] 57%|█████▋    | 51478/90000 [03:50<02:51, 224.58it/s] 57%|█████▋    | 51502/90000 [03:50<02:49, 227.16it/s] 57%|█████▋    | 51525/90000 [03:50<02:50, 226.01it/s] 57%|█████▋    | 51548/90000 [03:50<02:52, 222.55it/s] 57%|█████▋    | 51571/90000 [03:50<02:54, 220.80it/s] 57%|█████▋    | 51594/90000 [03:50<02:52, 222.66it/s] 57%|█████▋    | 51618/90000 [03:50<02:50, 224.80it/s] 57%|█████▋    | 51642/90000 [03:50<02:47, 229.10it/s] 57%|█████▋    | 51665/90000 [03:51<02:47, 228.93it/s] 57%|█████▋    | 51689/90000 [03:51<02:46, 229.84it/s] 57%|█████▋    | 51715/90000 [03:51<02:42, 235.71it/s] 57%|█████▋    | 51739/90000 [03:51<02:44, 231.98it/s] 58%|█████▊    | 51764/90000 [03:51<02:42, 235.53it/s] 58%|█████▊    | 51789/90000 [03:51<02:40, 237.37it/s] 58%|█████▊    | 51814/90000 [03:51<02:39, 238.69it/s] 58%|█████▊    | 51839/90000 [03:51<02:37, 241.96it/s] 58%|█████▊    | 51864/90000 [03:51<02:41, 236.02it/s] 58%|█████▊    | 51888/90000 [03:52<02:42, 234.58it/s] 58%|█████▊    | 51912/90000 [03:52<02:45, 230.57it/s] 58%|█████▊    | 51936/90000 [03:52<02:47, 226.89it/s] 58%|█████▊    | 51959/90000 [03:52<02:47, 227.09it/s] 58%|█████▊    | 51983/90000 [03:52<02:45, 230.16it/s] 58%|█████▊    | 52007/90000 [03:52<02:47, 226.64it/s] 58%|█████▊    | 52030/90000 [03:52<02:46, 227.57it/s] 58%|█████▊    | 52053/90000 [03:52<02:46, 227.83it/s] 58%|█████▊    | 52076/90000 [03:52<02:46, 227.62it/s] 58%|█████▊    | 52101/90000 [03:52<02:42, 232.55it/s] 58%|█████▊    | 52125/90000 [03:53<02:46, 227.36it/s] 58%|█████▊    | 52149/90000 [03:53<02:44, 229.56it/s] 58%|█████▊    | 52172/90000 [03:53<02:45, 228.24it/s] 58%|█████▊    | 52195/90000 [03:53<02:48, 223.86it/s] 58%|█████▊    | 52219/90000 [03:53<02:46, 227.31it/s] 58%|█████▊    | 52242/90000 [03:53<02:47, 225.47it/s] 58%|█████▊    | 52265/90000 [03:53<02:46, 226.06it/s] 58%|█████▊    | 52289/90000 [03:53<02:45, 227.95it/s] 58%|█████▊    | 52312/90000 [03:53<02:46, 226.91it/s] 58%|█████▊    | 52335/90000 [03:54<02:45, 227.07it/s] 58%|█████▊    | 52358/90000 [03:54<02:45, 226.85it/s] 58%|█████▊    | 52381/90000 [03:54<02:45, 227.29it/s] 58%|█████▊    | 52405/90000 [03:54<02:43, 229.49it/s] 58%|█████▊    | 52428/90000 [03:54<02:44, 228.16it/s] 58%|█████▊    | 52451/90000 [03:54<02:47, 224.30it/s] 58%|█████▊    | 52475/90000 [03:54<02:46, 225.01it/s] 58%|█████▊    | 52498/90000 [03:54<02:47, 224.46it/s] 58%|█████▊    | 52521/90000 [03:54<02:46, 225.49it/s] 58%|█████▊    | 52545/90000 [03:54<02:44, 228.15it/s] 58%|█████▊    | 52568/90000 [03:55<02:47, 223.85it/s] 58%|█████▊    | 52592/90000 [03:55<02:43, 228.13it/s] 58%|█████▊    | 52616/90000 [03:55<02:43, 228.63it/s] 58%|█████▊    | 52639/90000 [03:55<02:43, 229.01it/s] 59%|█████▊    | 52662/90000 [03:55<02:44, 227.30it/s] 59%|█████▊    | 52686/90000 [03:55<02:43, 228.88it/s] 59%|█████▊    | 52709/90000 [03:55<02:43, 227.79it/s] 59%|█████▊    | 52733/90000 [03:55<02:42, 229.86it/s] 59%|█████▊    | 52756/90000 [03:55<02:42, 229.72it/s] 59%|█████▊    | 52781/90000 [03:55<02:39, 233.57it/s] 59%|█████▊    | 52805/90000 [03:56<02:41, 230.87it/s] 59%|█████▊    | 52829/90000 [03:56<02:39, 233.18it/s] 59%|█████▊    | 52853/90000 [03:56<02:40, 232.12it/s] 59%|█████▉    | 52877/90000 [03:56<02:41, 230.18it/s] 59%|█████▉    | 52901/90000 [03:56<02:40, 231.53it/s] 59%|█████▉    | 52925/90000 [03:56<02:43, 226.61it/s] 59%|█████▉    | 52949/90000 [03:56<02:41, 228.95it/s] 59%|█████▉    | 52974/90000 [03:56<02:39, 231.89it/s] 59%|█████▉    | 52999/90000 [03:56<02:38, 233.51it/s] 59%|█████▉    | 53023/90000 [03:57<02:39, 231.27it/s] 59%|█████▉    | 53047/90000 [03:57<02:41, 228.69it/s] 59%|█████▉    | 53070/90000 [03:57<02:42, 227.74it/s] 59%|█████▉    | 53093/90000 [03:57<02:43, 225.34it/s] 59%|█████▉    | 53117/90000 [03:57<02:41, 227.93it/s] 59%|█████▉    | 53140/90000 [03:57<02:42, 226.39it/s] 59%|█████▉    | 53164/90000 [03:57<02:41, 228.29it/s] 59%|█████▉    | 53188/90000 [03:57<02:40, 230.07it/s] 59%|█████▉    | 53212/90000 [03:57<02:41, 227.88it/s] 59%|█████▉    | 53235/90000 [03:57<02:42, 225.69it/s] 59%|█████▉    | 53260/90000 [03:58<02:39, 230.69it/s] 59%|█████▉    | 53284/90000 [03:58<02:40, 229.14it/s] 59%|█████▉    | 53307/90000 [03:58<02:40, 228.52it/s] 59%|█████▉    | 53330/90000 [03:58<02:41, 227.13it/s] 59%|█████▉    | 53353/90000 [03:58<02:41, 227.50it/s] 59%|█████▉    | 53377/90000 [03:58<02:41, 226.93it/s] 59%|█████▉    | 53400/90000 [03:58<02:41, 227.18it/s] 59%|█████▉    | 53424/90000 [03:58<02:39, 229.03it/s] 59%|█████▉    | 53447/90000 [03:58<02:39, 228.51it/s] 59%|█████▉    | 53470/90000 [03:58<02:40, 228.02it/s] 59%|█████▉    | 53493/90000 [03:59<02:42, 224.30it/s] 59%|█████▉    | 53518/90000 [03:59<02:38, 230.01it/s] 59%|█████▉    | 53542/90000 [03:59<02:39, 229.06it/s] 60%|█████▉    | 53565/90000 [03:59<02:41, 225.46it/s] 60%|█████▉    | 53589/90000 [03:59<02:38, 229.25it/s] 60%|█████▉    | 53613/90000 [03:59<02:38, 229.66it/s] 60%|█████▉    | 53637/90000 [03:59<02:37, 230.16it/s] 60%|█████▉    | 53661/90000 [03:59<02:38, 229.33it/s] 60%|█████▉    | 53685/90000 [03:59<02:39, 227.80it/s] 60%|█████▉    | 53709/90000 [04:00<02:38, 229.20it/s] 60%|█████▉    | 53733/90000 [04:00<02:37, 230.55it/s] 60%|█████▉    | 53757/90000 [04:00<02:35, 232.62it/s] 60%|█████▉    | 53781/90000 [04:00<02:34, 234.03it/s] 60%|█████▉    | 53805/90000 [04:00<02:35, 233.14it/s] 60%|█████▉    | 53829/90000 [04:00<02:38, 228.66it/s] 60%|█████▉    | 53852/90000 [04:00<02:39, 227.26it/s] 60%|█████▉    | 53876/90000 [04:00<02:36, 230.60it/s] 60%|█████▉    | 53900/90000 [04:00<02:37, 229.12it/s] 60%|█████▉    | 53925/90000 [04:00<02:35, 232.46it/s] 60%|█████▉    | 53949/90000 [04:01<02:34, 232.94it/s] 60%|█████▉    | 53973/90000 [04:01<02:34, 232.53it/s] 60%|█████▉    | 53998/90000 [04:01<02:32, 236.32it/s] 60%|██████    | 54022/90000 [04:01<02:34, 232.62it/s] 60%|██████    | 54046/90000 [04:01<02:35, 230.69it/s] 60%|██████    | 54070/90000 [04:01<02:36, 229.93it/s] 60%|██████    | 54095/90000 [04:01<02:34, 232.94it/s] 60%|██████    | 54119/90000 [04:01<02:33, 233.58it/s] 60%|██████    | 54143/90000 [04:01<02:36, 229.51it/s] 60%|██████    | 54166/90000 [04:02<02:39, 225.13it/s] 60%|██████    | 54189/90000 [04:02<02:38, 225.33it/s] 60%|██████    | 54214/90000 [04:02<02:35, 230.32it/s] 60%|██████    | 54238/90000 [04:02<02:33, 232.58it/s] 60%|██████    | 54263/90000 [04:02<02:32, 235.09it/s] 60%|██████    | 54287/90000 [04:02<02:32, 234.30it/s] 60%|██████    | 54311/90000 [04:02<02:33, 232.13it/s] 60%|██████    | 54335/90000 [04:02<02:32, 233.24it/s] 60%|██████    | 54359/90000 [04:02<02:32, 233.84it/s] 60%|██████    | 54383/90000 [04:02<02:32, 234.10it/s] 60%|██████    | 54407/90000 [04:03<02:31, 234.65it/s] 60%|██████    | 54431/90000 [04:03<02:31, 234.32it/s] 61%|██████    | 54455/90000 [04:03<02:32, 232.92it/s] 61%|██████    | 54479/90000 [04:03<02:35, 228.53it/s] 61%|██████    | 54502/90000 [04:03<02:36, 226.11it/s] 61%|██████    | 54525/90000 [04:03<02:37, 225.07it/s] 61%|██████    | 54549/90000 [04:03<02:34, 229.25it/s] 61%|██████    | 54572/90000 [04:03<02:35, 227.70it/s] 61%|██████    | 54596/90000 [04:03<02:33, 230.53it/s] 61%|██████    | 54620/90000 [04:03<02:35, 227.08it/s] 61%|██████    | 54644/90000 [04:04<02:33, 230.07it/s] 61%|██████    | 54668/90000 [04:04<02:32, 232.02it/s] 61%|██████    | 54692/90000 [04:04<02:33, 229.40it/s] 61%|██████    | 54715/90000 [04:04<02:35, 227.39it/s] 61%|██████    | 54740/90000 [04:04<02:30, 233.81it/s] 61%|██████    | 54764/90000 [04:04<02:32, 231.08it/s] 61%|██████    | 54788/90000 [04:04<02:32, 231.47it/s] 61%|██████    | 54812/90000 [04:04<02:31, 232.74it/s] 61%|██████    | 54836/90000 [04:04<02:32, 230.05it/s] 61%|██████    | 54860/90000 [04:05<02:33, 228.21it/s] 61%|██████    | 54884/90000 [04:05<02:32, 229.66it/s] 61%|██████    | 54908/90000 [04:05<02:32, 230.64it/s] 61%|██████    | 54932/90000 [04:05<02:31, 231.00it/s] 61%|██████    | 54956/90000 [04:05<02:31, 230.77it/s] 61%|██████    | 54980/90000 [04:05<02:33, 228.22it/s] 61%|██████    | 55004/90000 [04:05<02:31, 230.56it/s] 61%|██████    | 55028/90000 [04:05<02:32, 228.65it/s] 61%|██████    | 55052/90000 [04:05<02:31, 230.37it/s] 61%|██████    | 55076/90000 [04:05<02:31, 230.79it/s] 61%|██████    | 55100/90000 [04:06<02:33, 227.99it/s] 61%|██████    | 55124/90000 [04:06<02:32, 229.18it/s] 61%|██████▏   | 55147/90000 [04:06<02:35, 224.80it/s] 61%|██████▏   | 55170/90000 [04:06<02:35, 224.59it/s] 61%|██████▏   | 55194/90000 [04:06<02:34, 225.64it/s] 61%|██████▏   | 55217/90000 [04:06<02:34, 225.19it/s] 61%|██████▏   | 55241/90000 [04:06<02:32, 227.30it/s] 61%|██████▏   | 55264/90000 [04:06<02:33, 225.63it/s] 61%|██████▏   | 55287/90000 [04:06<02:34, 225.17it/s] 61%|██████▏   | 55311/90000 [04:06<02:31, 228.79it/s] 61%|██████▏   | 55334/90000 [04:07<02:33, 225.36it/s] 62%|██████▏   | 55359/90000 [04:07<02:29, 232.03it/s] 62%|██████▏   | 55383/90000 [04:07<02:31, 228.18it/s] 62%|██████▏   | 55407/90000 [04:07<02:30, 229.33it/s] 62%|██████▏   | 55432/90000 [04:07<02:28, 233.00it/s] 62%|██████▏   | 55456/90000 [04:07<02:28, 232.72it/s] 62%|██████▏   | 55480/90000 [04:07<02:28, 231.86it/s] 62%|██████▏   | 55504/90000 [04:07<02:29, 230.28it/s] 62%|██████▏   | 55528/90000 [04:07<02:28, 232.02it/s] 62%|██████▏   | 55552/90000 [04:08<02:30, 229.47it/s] 62%|██████▏   | 55576/90000 [04:08<02:30, 229.33it/s] 62%|██████▏   | 55600/90000 [04:08<02:29, 230.43it/s] 62%|██████▏   | 55624/90000 [04:08<02:31, 227.02it/s] 62%|██████▏   | 55649/90000 [04:08<02:28, 231.35it/s] 62%|██████▏   | 55673/90000 [04:08<02:27, 232.43it/s] 62%|██████▏   | 55697/90000 [04:08<02:29, 230.06it/s] 62%|██████▏   | 55721/90000 [04:08<02:27, 231.72it/s] 62%|██████▏   | 55745/90000 [04:08<02:27, 231.87it/s] 62%|██████▏   | 55770/90000 [04:08<02:25, 234.65it/s] 62%|██████▏   | 55794/90000 [04:09<02:30, 226.84it/s] 62%|██████▏   | 55817/90000 [04:09<02:39, 213.70it/s] 62%|██████▏   | 55840/90000 [04:09<02:38, 215.72it/s] 62%|██████▏   | 55863/90000 [04:09<02:37, 217.10it/s] 62%|██████▏   | 55886/90000 [04:09<02:34, 220.33it/s] 62%|██████▏   | 55910/90000 [04:09<02:31, 225.26it/s] 62%|██████▏   | 55933/90000 [04:09<02:31, 225.20it/s] 62%|██████▏   | 55956/90000 [04:09<02:32, 223.91it/s] 62%|██████▏   | 55979/90000 [04:09<02:33, 221.61it/s] 62%|██████▏   | 56002/90000 [04:10<02:33, 221.89it/s] 62%|██████▏   | 56026/90000 [04:10<02:29, 226.86it/s] 62%|██████▏   | 56050/90000 [04:10<02:27, 230.16it/s] 62%|██████▏   | 56074/90000 [04:10<02:27, 229.55it/s] 62%|██████▏   | 56097/90000 [04:10<02:28, 227.71it/s] 62%|██████▏   | 56121/90000 [04:10<02:27, 229.65it/s] 62%|██████▏   | 56145/90000 [04:10<02:28, 228.74it/s] 62%|██████▏   | 56168/90000 [04:10<02:28, 228.49it/s] 62%|██████▏   | 56191/90000 [04:10<02:28, 227.55it/s] 62%|██████▏   | 56216/90000 [04:10<02:25, 232.18it/s] 62%|██████▏   | 56240/90000 [04:11<02:24, 233.90it/s] 63%|██████▎   | 56265/90000 [04:11<02:22, 236.88it/s] 63%|██████▎   | 56289/90000 [04:11<02:23, 234.80it/s] 63%|██████▎   | 56314/90000 [04:11<02:21, 238.04it/s] 63%|██████▎   | 56338/90000 [04:11<02:28, 226.33it/s] 63%|██████▎   | 56361/90000 [04:11<02:28, 226.94it/s] 63%|██████▎   | 56384/90000 [04:11<02:32, 220.08it/s] 63%|██████▎   | 56407/90000 [04:11<02:31, 221.09it/s] 63%|██████▎   | 56431/90000 [04:11<02:29, 224.82it/s] 63%|██████▎   | 56454/90000 [04:12<02:30, 223.37it/s] 63%|██████▎   | 56477/90000 [04:12<02:29, 224.81it/s] 63%|██████▎   | 56501/90000 [04:12<02:26, 228.54it/s] 63%|██████▎   | 56524/90000 [04:12<02:27, 226.44it/s] 63%|██████▎   | 56549/90000 [04:12<02:24, 230.99it/s] 63%|██████▎   | 56573/90000 [04:12<02:27, 226.97it/s] 63%|██████▎   | 56596/90000 [04:12<02:28, 225.02it/s] 63%|██████▎   | 56620/90000 [04:12<02:26, 227.85it/s] 63%|██████▎   | 56643/90000 [04:12<02:26, 227.54it/s] 63%|██████▎   | 56669/90000 [04:12<02:22, 234.49it/s] 63%|██████▎   | 56693/90000 [04:13<02:24, 230.48it/s] 63%|██████▎   | 56717/90000 [04:13<02:24, 229.80it/s] 63%|██████▎   | 56740/90000 [04:13<02:26, 227.57it/s] 63%|██████▎   | 56764/90000 [04:13<02:24, 230.56it/s] 63%|██████▎   | 56788/90000 [04:13<02:23, 230.66it/s] 63%|██████▎   | 56813/90000 [04:13<02:22, 232.51it/s] 63%|██████▎   | 56837/90000 [04:13<02:22, 232.61it/s] 63%|██████▎   | 56861/90000 [04:13<02:23, 230.95it/s] 63%|██████▎   | 56885/90000 [04:13<02:23, 231.52it/s] 63%|██████▎   | 56910/90000 [04:13<02:21, 234.46it/s] 63%|██████▎   | 56934/90000 [04:14<02:21, 233.74it/s] 63%|██████▎   | 56958/90000 [04:14<02:20, 234.77it/s] 63%|██████▎   | 56983/90000 [04:14<02:19, 236.05it/s] 63%|██████▎   | 57007/90000 [04:14<02:22, 231.35it/s] 63%|██████▎   | 57031/90000 [04:14<02:23, 229.53it/s] 63%|██████▎   | 57054/90000 [04:14<02:24, 227.58it/s] 63%|██████▎   | 57078/90000 [04:14<02:23, 229.34it/s] 63%|██████▎   | 57102/90000 [04:14<02:22, 231.15it/s] 63%|██████▎   | 57126/90000 [04:14<02:23, 228.86it/s] 64%|██████▎   | 57150/90000 [04:15<02:22, 229.88it/s] 64%|██████▎   | 57173/90000 [04:15<02:24, 226.48it/s] 64%|██████▎   | 57197/90000 [04:15<02:22, 230.22it/s] 64%|██████▎   | 57221/90000 [04:15<02:22, 229.65it/s] 64%|██████▎   | 57244/90000 [04:15<02:23, 227.67it/s] 64%|██████▎   | 57268/90000 [04:15<02:22, 230.18it/s] 64%|██████▎   | 57292/90000 [04:15<02:20, 232.83it/s] 64%|██████▎   | 57316/90000 [04:15<02:22, 229.96it/s] 64%|██████▎   | 57340/90000 [04:15<02:23, 227.96it/s] 64%|██████▎   | 57363/90000 [04:15<02:24, 226.54it/s] 64%|██████▍   | 57386/90000 [04:16<02:26, 222.89it/s] 64%|██████▍   | 57410/90000 [04:16<02:23, 227.55it/s] 64%|██████▍   | 57434/90000 [04:16<02:21, 229.49it/s] 64%|██████▍   | 57457/90000 [04:16<02:22, 227.80it/s] 64%|██████▍   | 57480/90000 [04:16<02:22, 227.68it/s] 64%|██████▍   | 57503/90000 [04:16<02:22, 228.19it/s] 64%|██████▍   | 57526/90000 [04:16<02:22, 227.87it/s] 64%|██████▍   | 57549/90000 [04:16<02:24, 225.03it/s] 64%|██████▍   | 57572/90000 [04:16<02:25, 223.46it/s] 64%|██████▍   | 57596/90000 [04:16<02:23, 226.08it/s] 64%|██████▍   | 57619/90000 [04:17<02:22, 227.03it/s] 64%|██████▍   | 57642/90000 [04:17<02:22, 227.10it/s] 64%|██████▍   | 57665/90000 [04:17<02:22, 226.58it/s] 64%|██████▍   | 57688/90000 [04:17<02:22, 226.82it/s] 64%|██████▍   | 57711/90000 [04:17<02:22, 226.58it/s] 64%|██████▍   | 57734/90000 [04:17<02:22, 227.06it/s] 64%|██████▍   | 57758/90000 [04:17<02:21, 228.31it/s] 64%|██████▍   | 57782/90000 [04:17<02:19, 230.23it/s] 64%|██████▍   | 57806/90000 [04:17<02:19, 230.81it/s] 64%|██████▍   | 57830/90000 [04:18<02:21, 226.98it/s] 64%|██████▍   | 57854/90000 [04:18<02:21, 227.91it/s] 64%|██████▍   | 57878/90000 [04:18<02:19, 230.87it/s] 64%|██████▍   | 57902/90000 [04:18<02:21, 226.84it/s] 64%|██████▍   | 57926/90000 [04:18<02:20, 228.73it/s] 64%|██████▍   | 57950/90000 [04:18<02:19, 229.77it/s] 64%|██████▍   | 57973/90000 [04:18<02:20, 227.23it/s] 64%|██████▍   | 57996/90000 [04:18<02:20, 227.12it/s] 64%|██████▍   | 58020/90000 [04:18<02:19, 229.69it/s] 64%|██████▍   | 58043/90000 [04:18<02:20, 227.29it/s] 65%|██████▍   | 58066/90000 [04:19<02:23, 223.28it/s] 65%|██████▍   | 58089/90000 [04:19<02:22, 224.72it/s] 65%|██████▍   | 58112/90000 [04:19<02:21, 225.33it/s] 65%|██████▍   | 58135/90000 [04:19<02:20, 226.44it/s] 65%|██████▍   | 58158/90000 [04:19<02:21, 225.37it/s] 65%|██████▍   | 58182/90000 [04:19<02:20, 227.14it/s] 65%|██████▍   | 58205/90000 [04:19<02:20, 226.26it/s] 65%|██████▍   | 58228/90000 [04:19<02:22, 222.87it/s] 65%|██████▍   | 58251/90000 [04:19<02:22, 223.47it/s] 65%|██████▍   | 58274/90000 [04:19<02:26, 217.16it/s] 65%|██████▍   | 58296/90000 [04:20<02:26, 216.75it/s] 65%|██████▍   | 58319/90000 [04:20<02:25, 218.20it/s] 65%|██████▍   | 58341/90000 [04:20<02:27, 215.08it/s] 65%|██████▍   | 58365/90000 [04:20<02:23, 219.82it/s] 65%|██████▍   | 58389/90000 [04:20<02:21, 223.12it/s] 65%|██████▍   | 58412/90000 [04:20<02:23, 219.73it/s] 65%|██████▍   | 58436/90000 [04:20<02:20, 224.36it/s] 65%|██████▍   | 58459/90000 [04:20<02:20, 225.18it/s] 65%|██████▍   | 58482/90000 [04:20<02:19, 225.56it/s] 65%|██████▌   | 58505/90000 [04:21<02:21, 222.05it/s] 65%|██████▌   | 58528/90000 [04:21<02:21, 222.66it/s] 65%|██████▌   | 58552/90000 [04:21<02:19, 225.76it/s] 65%|██████▌   | 58575/90000 [04:21<02:21, 222.31it/s] 65%|██████▌   | 58598/90000 [04:21<02:22, 220.98it/s] 65%|██████▌   | 58621/90000 [04:21<02:21, 222.46it/s] 65%|██████▌   | 58644/90000 [04:21<02:23, 218.64it/s] 65%|██████▌   | 58667/90000 [04:21<02:22, 219.82it/s] 65%|██████▌   | 58690/90000 [04:21<02:21, 221.62it/s] 65%|██████▌   | 58713/90000 [04:21<02:22, 219.91it/s] 65%|██████▌   | 58737/90000 [04:22<02:18, 225.12it/s] 65%|██████▌   | 58761/90000 [04:22<02:16, 228.27it/s] 65%|██████▌   | 58784/90000 [04:22<02:17, 226.53it/s] 65%|██████▌   | 58807/90000 [04:22<02:18, 225.12it/s] 65%|██████▌   | 58830/90000 [04:22<02:19, 223.69it/s] 65%|██████▌   | 58853/90000 [04:22<02:21, 220.20it/s] 65%|██████▌   | 58876/90000 [04:22<02:20, 220.91it/s] 65%|██████▌   | 58900/90000 [04:22<02:18, 225.31it/s] 65%|██████▌   | 58923/90000 [04:22<02:18, 223.82it/s] 65%|██████▌   | 58946/90000 [04:23<02:19, 222.58it/s] 66%|██████▌   | 58969/90000 [04:23<02:19, 222.95it/s] 66%|██████▌   | 58993/90000 [04:23<02:17, 226.30it/s] 66%|██████▌   | 59017/90000 [04:23<02:16, 227.44it/s] 66%|██████▌   | 59040/90000 [04:23<02:17, 225.07it/s] 66%|██████▌   | 59063/90000 [04:23<02:18, 224.07it/s] 66%|██████▌   | 59086/90000 [04:23<02:19, 221.32it/s] 66%|██████▌   | 59109/90000 [04:23<02:20, 219.13it/s] 66%|██████▌   | 59133/90000 [04:23<02:17, 223.99it/s] 66%|██████▌   | 59156/90000 [04:23<02:16, 225.31it/s] 66%|██████▌   | 59180/90000 [04:24<02:15, 227.86it/s] 66%|██████▌   | 59204/90000 [04:24<02:14, 229.70it/s] 66%|██████▌   | 59228/90000 [04:24<02:13, 230.64it/s] 66%|██████▌   | 59252/90000 [04:24<02:14, 229.35it/s] 66%|██████▌   | 59275/90000 [04:24<02:15, 227.10it/s] 66%|██████▌   | 59298/90000 [04:24<02:15, 227.09it/s] 66%|██████▌   | 59321/90000 [04:24<02:17, 222.86it/s] 66%|██████▌   | 59345/90000 [04:24<02:15, 225.71it/s] 66%|██████▌   | 59369/90000 [04:24<02:14, 227.49it/s] 66%|██████▌   | 59392/90000 [04:24<02:14, 227.74it/s] 66%|██████▌   | 59415/90000 [04:25<02:15, 225.90it/s] 66%|██████▌   | 59438/90000 [04:25<02:14, 226.79it/s] 66%|██████▌   | 59462/90000 [04:25<02:13, 228.78it/s] 66%|██████▌   | 59485/90000 [04:25<02:13, 228.28it/s] 66%|██████▌   | 59508/90000 [04:25<02:16, 223.22it/s] 66%|██████▌   | 59531/90000 [04:25<02:16, 223.27it/s] 66%|██████▌   | 59555/90000 [04:25<02:14, 226.85it/s] 66%|██████▌   | 59579/90000 [04:25<02:13, 228.15it/s] 66%|██████▌   | 59603/90000 [04:25<02:12, 229.90it/s] 66%|██████▋   | 59626/90000 [04:26<02:15, 223.75it/s] 66%|██████▋   | 59649/90000 [04:26<02:15, 224.59it/s] 66%|██████▋   | 59672/90000 [04:26<02:15, 223.64it/s] 66%|██████▋   | 59695/90000 [04:26<02:18, 218.93it/s] 66%|██████▋   | 59719/90000 [04:26<02:15, 223.18it/s] 66%|██████▋   | 59743/90000 [04:26<02:13, 226.55it/s] 66%|██████▋   | 59766/90000 [04:26<02:14, 224.87it/s] 66%|██████▋   | 59789/90000 [04:26<02:15, 222.44it/s] 66%|██████▋   | 59814/90000 [04:26<02:12, 227.45it/s] 66%|██████▋   | 59837/90000 [04:26<02:13, 226.24it/s] 67%|██████▋   | 59860/90000 [04:27<02:14, 224.65it/s] 67%|██████▋   | 59884/90000 [04:27<02:11, 228.18it/s] 67%|██████▋   | 59908/90000 [04:27<02:10, 231.47it/s] 67%|██████▋   | 59932/90000 [04:27<02:09, 233.01it/s] 67%|██████▋   | 59956/90000 [04:27<02:10, 230.56it/s] 67%|██████▋   | 59980/90000 [04:27<02:12, 227.24it/s] 67%|██████▋   | 60005/90000 [04:27<02:10, 229.90it/s] 67%|██████▋   | 60029/90000 [04:27<02:13, 224.82it/s] 67%|██████▋   | 60052/90000 [04:27<02:12, 225.35it/s] 67%|██████▋   | 60075/90000 [04:27<02:12, 225.22it/s] 67%|██████▋   | 60098/90000 [04:28<02:14, 222.22it/s] 67%|██████▋   | 60122/90000 [04:28<02:11, 226.82it/s] 67%|██████▋   | 60145/90000 [04:28<02:13, 223.53it/s] 67%|██████▋   | 60169/90000 [04:28<02:12, 225.45it/s] 67%|██████▋   | 60193/90000 [04:28<02:10, 228.17it/s] 67%|██████▋   | 60216/90000 [04:28<02:12, 225.17it/s] 67%|██████▋   | 60239/90000 [04:28<02:11, 225.94it/s] 67%|██████▋   | 60262/90000 [04:28<02:12, 223.91it/s] 67%|██████▋   | 60285/90000 [04:28<02:14, 221.51it/s] 67%|██████▋   | 60309/90000 [04:29<02:12, 223.86it/s] 67%|██████▋   | 60333/90000 [04:29<02:11, 225.68it/s] 67%|██████▋   | 60357/90000 [04:29<02:10, 227.08it/s] 67%|██████▋   | 60380/90000 [04:29<02:13, 222.32it/s] 67%|██████▋   | 60403/90000 [04:29<02:13, 222.00it/s] 67%|██████▋   | 60426/90000 [04:29<02:12, 223.91it/s] 67%|██████▋   | 60449/90000 [04:29<02:11, 225.43it/s] 67%|██████▋   | 60472/90000 [04:29<02:11, 225.23it/s] 67%|██████▋   | 60496/90000 [04:29<02:09, 227.22it/s] 67%|██████▋   | 60519/90000 [04:29<02:11, 224.73it/s] 67%|██████▋   | 60543/90000 [04:30<02:08, 228.50it/s] 67%|██████▋   | 60567/90000 [04:30<02:08, 229.57it/s] 67%|██████▋   | 60592/90000 [04:30<02:05, 234.50it/s] 67%|██████▋   | 60617/90000 [04:30<02:04, 236.66it/s] 67%|██████▋   | 60641/90000 [04:30<02:09, 227.13it/s] 67%|██████▋   | 60664/90000 [04:30<02:09, 226.22it/s] 67%|██████▋   | 60687/90000 [04:30<02:09, 226.91it/s] 67%|██████▋   | 60710/90000 [04:30<02:11, 223.11it/s] 67%|██████▋   | 60734/90000 [04:30<02:09, 225.81it/s] 68%|██████▊   | 60758/90000 [04:31<02:07, 228.99it/s] 68%|██████▊   | 60781/90000 [04:31<02:09, 225.55it/s] 68%|██████▊   | 60805/90000 [04:31<02:07, 229.70it/s] 68%|██████▊   | 60830/90000 [04:31<02:05, 233.11it/s] 68%|██████▊   | 60854/90000 [04:31<02:06, 230.35it/s] 68%|██████▊   | 60878/90000 [04:31<02:08, 226.37it/s] 68%|██████▊   | 60902/90000 [04:31<02:07, 228.48it/s] 68%|██████▊   | 60926/90000 [04:31<02:05, 230.76it/s] 68%|██████▊   | 60950/90000 [04:31<02:06, 229.71it/s] 68%|██████▊   | 60973/90000 [04:31<02:07, 227.60it/s] 68%|██████▊   | 60998/90000 [04:32<02:05, 231.88it/s] 68%|██████▊   | 61022/90000 [04:32<02:05, 231.15it/s] 68%|██████▊   | 61046/90000 [04:32<02:04, 231.77it/s] 68%|██████▊   | 61070/90000 [04:32<02:04, 232.53it/s] 68%|██████▊   | 61094/90000 [04:32<02:08, 225.75it/s] 68%|██████▊   | 61118/90000 [04:32<02:05, 229.67it/s] 68%|██████▊   | 61142/90000 [04:32<02:05, 230.08it/s] 68%|██████▊   | 61166/90000 [04:32<02:03, 232.77it/s] 68%|██████▊   | 61190/90000 [04:32<02:03, 233.41it/s] 68%|██████▊   | 61214/90000 [04:32<02:04, 231.46it/s] 68%|██████▊   | 61238/90000 [04:33<02:04, 231.12it/s] 68%|██████▊   | 61262/90000 [04:33<02:05, 228.80it/s] 68%|██████▊   | 61285/90000 [04:33<02:07, 225.32it/s] 68%|██████▊   | 61309/90000 [04:33<02:05, 229.09it/s] 68%|██████▊   | 61332/90000 [04:33<02:08, 222.60it/s] 68%|██████▊   | 61356/90000 [04:33<02:07, 225.41it/s] 68%|██████▊   | 61380/90000 [04:33<02:06, 226.45it/s] 68%|██████▊   | 61403/90000 [04:33<02:08, 222.40it/s] 68%|██████▊   | 61427/90000 [04:33<02:07, 224.14it/s] 68%|██████▊   | 61451/90000 [04:34<02:05, 227.95it/s] 68%|██████▊   | 61474/90000 [04:34<02:05, 226.42it/s] 68%|██████▊   | 61497/90000 [04:34<02:07, 223.77it/s] 68%|██████▊   | 61520/90000 [04:34<02:06, 224.69it/s] 68%|██████▊   | 61544/90000 [04:34<02:04, 228.52it/s] 68%|██████▊   | 61568/90000 [04:34<02:03, 231.04it/s] 68%|██████▊   | 61592/90000 [04:34<02:04, 227.37it/s] 68%|██████▊   | 61615/90000 [04:34<02:06, 224.62it/s] 68%|██████▊   | 61638/90000 [04:34<02:06, 223.92it/s] 69%|██████▊   | 61661/90000 [04:34<02:07, 222.35it/s] 69%|██████▊   | 61684/90000 [04:35<02:06, 224.22it/s] 69%|██████▊   | 61708/90000 [04:35<02:04, 228.00it/s] 69%|██████▊   | 61731/90000 [04:35<02:07, 221.92it/s] 69%|██████▊   | 61755/90000 [04:35<02:04, 226.50it/s] 69%|██████▊   | 61778/90000 [04:35<02:04, 226.90it/s] 69%|██████▊   | 61801/90000 [04:35<02:04, 226.86it/s] 69%|██████▊   | 61826/90000 [04:35<02:01, 231.43it/s] 69%|██████▊   | 61850/90000 [04:35<02:01, 230.92it/s] 69%|██████▊   | 61874/90000 [04:35<02:04, 226.46it/s] 69%|██████▉   | 61898/90000 [04:36<02:02, 229.53it/s] 69%|██████▉   | 61922/90000 [04:36<02:01, 230.34it/s] 69%|██████▉   | 61946/90000 [04:36<02:02, 229.93it/s] 69%|██████▉   | 61970/90000 [04:36<02:01, 231.27it/s] 69%|██████▉   | 61994/90000 [04:36<02:03, 227.32it/s] 69%|██████▉   | 62017/90000 [04:36<02:03, 226.25it/s] 69%|██████▉   | 62040/90000 [04:36<02:03, 227.23it/s] 69%|██████▉   | 62063/90000 [04:36<02:03, 226.11it/s] 69%|██████▉   | 62087/90000 [04:36<02:02, 228.27it/s] 69%|██████▉   | 62110/90000 [04:36<02:03, 226.16it/s] 69%|██████▉   | 62133/90000 [04:37<02:03, 224.75it/s] 69%|██████▉   | 62156/90000 [04:37<02:03, 225.03it/s] 69%|██████▉   | 62179/90000 [04:37<02:04, 222.97it/s] 69%|██████▉   | 62202/90000 [04:37<02:05, 222.06it/s] 69%|██████▉   | 62225/90000 [04:37<02:04, 223.87it/s] 69%|██████▉   | 62249/90000 [04:37<02:02, 226.01it/s] 69%|██████▉   | 62275/90000 [04:37<01:59, 232.39it/s] 69%|██████▉   | 62299/90000 [04:37<02:00, 230.70it/s] 69%|██████▉   | 62323/90000 [04:37<02:01, 227.78it/s] 69%|██████▉   | 62347/90000 [04:37<02:00, 230.00it/s] 69%|██████▉   | 62371/90000 [04:38<02:01, 227.08it/s] 69%|██████▉   | 62394/90000 [04:38<02:03, 223.57it/s] 69%|██████▉   | 62419/90000 [04:38<01:59, 231.13it/s] 69%|██████▉   | 62443/90000 [04:38<02:00, 229.56it/s] 69%|██████▉   | 62466/90000 [04:38<02:00, 228.31it/s] 69%|██████▉   | 62490/90000 [04:38<01:59, 230.07it/s] 69%|██████▉   | 62514/90000 [04:38<01:59, 229.60it/s] 69%|██████▉   | 62537/90000 [04:38<02:00, 227.73it/s] 70%|██████▉   | 62561/90000 [04:38<02:00, 227.61it/s] 70%|██████▉   | 62585/90000 [04:39<01:59, 228.61it/s] 70%|██████▉   | 62608/90000 [04:39<02:00, 227.63it/s] 70%|██████▉   | 62631/90000 [04:39<02:01, 225.90it/s] 70%|██████▉   | 62655/90000 [04:39<01:59, 229.13it/s] 70%|██████▉   | 62679/90000 [04:39<01:58, 231.53it/s] 70%|██████▉   | 62703/90000 [04:39<01:58, 229.77it/s] 70%|██████▉   | 62727/90000 [04:39<01:58, 230.39it/s] 70%|██████▉   | 62751/90000 [04:39<01:57, 231.96it/s] 70%|██████▉   | 62775/90000 [04:39<01:57, 232.41it/s] 70%|██████▉   | 62799/90000 [04:39<01:56, 233.45it/s] 70%|██████▉   | 62823/90000 [04:40<01:57, 231.11it/s] 70%|██████▉   | 62847/90000 [04:40<01:57, 231.30it/s] 70%|██████▉   | 62871/90000 [04:40<01:57, 230.24it/s] 70%|██████▉   | 62895/90000 [04:40<01:58, 228.53it/s] 70%|██████▉   | 62918/90000 [04:40<02:00, 224.63it/s] 70%|██████▉   | 62943/90000 [04:40<01:57, 229.54it/s] 70%|██████▉   | 62967/90000 [04:40<01:56, 231.31it/s] 70%|██████▉   | 62991/90000 [04:40<01:57, 229.31it/s] 70%|███████   | 63014/90000 [04:40<01:59, 226.35it/s] 70%|███████   | 63037/90000 [04:41<01:59, 225.49it/s] 70%|███████   | 63060/90000 [04:41<01:59, 225.79it/s] 70%|███████   | 63084/90000 [04:41<01:57, 228.41it/s] 70%|███████   | 63107/90000 [04:41<01:59, 225.96it/s] 70%|███████   | 63130/90000 [04:41<01:59, 224.00it/s] 70%|███████   | 63153/90000 [04:41<02:00, 222.79it/s] 70%|███████   | 63176/90000 [04:41<02:00, 222.86it/s] 70%|███████   | 63199/90000 [04:41<02:01, 220.27it/s] 70%|███████   | 63222/90000 [04:41<02:02, 218.86it/s] 70%|███████   | 63246/90000 [04:41<01:59, 223.06it/s] 70%|███████   | 63269/90000 [04:42<01:59, 224.37it/s] 70%|███████   | 63294/90000 [04:42<01:56, 228.92it/s] 70%|███████   | 63318/90000 [04:42<01:55, 230.07it/s] 70%|███████   | 63342/90000 [04:42<01:58, 225.70it/s] 70%|███████   | 63366/90000 [04:42<01:56, 228.32it/s] 70%|███████   | 63389/90000 [04:42<01:57, 226.44it/s] 70%|███████   | 63413/90000 [04:42<01:56, 227.89it/s] 70%|███████   | 63437/90000 [04:42<01:55, 229.12it/s] 71%|███████   | 63461/90000 [04:42<01:54, 232.28it/s] 71%|███████   | 63485/90000 [04:42<01:54, 232.44it/s] 71%|███████   | 63509/90000 [04:43<01:53, 234.20it/s] 71%|███████   | 63533/90000 [04:43<01:53, 233.56it/s] 71%|███████   | 63558/90000 [04:43<01:51, 236.49it/s] 71%|███████   | 63582/90000 [04:43<01:52, 234.23it/s] 71%|███████   | 63606/90000 [04:43<01:54, 230.72it/s] 71%|███████   | 63630/90000 [04:43<01:57, 224.51it/s] 71%|███████   | 63654/90000 [04:43<01:55, 227.73it/s] 71%|███████   | 63678/90000 [04:43<01:55, 228.68it/s] 71%|███████   | 63701/90000 [04:43<01:57, 223.07it/s] 71%|███████   | 63725/90000 [04:44<01:56, 226.44it/s] 71%|███████   | 63751/90000 [04:44<01:52, 233.54it/s] 71%|███████   | 63775/90000 [04:44<01:55, 226.10it/s] 71%|███████   | 63799/90000 [04:44<01:55, 227.55it/s] 71%|███████   | 63824/90000 [04:44<01:52, 232.49it/s] 71%|███████   | 63848/90000 [04:44<01:53, 229.81it/s] 71%|███████   | 63872/90000 [04:44<01:56, 225.07it/s] 71%|███████   | 63896/90000 [04:44<01:54, 228.89it/s] 71%|███████   | 63919/90000 [04:44<01:55, 225.73it/s] 71%|███████   | 63942/90000 [04:44<01:57, 222.18it/s] 71%|███████   | 63967/90000 [04:45<01:54, 227.77it/s] 71%|███████   | 63991/90000 [04:45<01:53, 228.49it/s] 71%|███████   | 64014/90000 [04:45<01:54, 227.83it/s] 71%|███████   | 64038/90000 [04:45<01:52, 230.72it/s] 71%|███████   | 64062/90000 [04:45<01:54, 225.71it/s] 71%|███████   | 64085/90000 [04:45<01:55, 224.43it/s] 71%|███████   | 64109/90000 [04:45<01:54, 225.41it/s] 71%|███████▏  | 64133/90000 [04:45<01:53, 227.65it/s] 71%|███████▏  | 64157/90000 [04:45<01:52, 229.93it/s] 71%|███████▏  | 64181/90000 [04:46<01:53, 227.99it/s] 71%|███████▏  | 64204/90000 [04:46<01:53, 227.74it/s] 71%|███████▏  | 64227/90000 [04:46<01:53, 227.78it/s] 71%|███████▏  | 64250/90000 [04:46<01:53, 227.58it/s] 71%|███████▏  | 64273/90000 [04:46<01:53, 226.86it/s] 71%|███████▏  | 64296/90000 [04:46<01:54, 223.88it/s] 71%|███████▏  | 64319/90000 [04:46<01:56, 220.71it/s] 71%|███████▏  | 64342/90000 [04:46<01:55, 222.47it/s] 72%|███████▏  | 64365/90000 [04:46<01:54, 222.96it/s] 72%|███████▏  | 64388/90000 [04:46<01:55, 221.90it/s] 72%|███████▏  | 64413/90000 [04:47<01:52, 227.99it/s] 72%|███████▏  | 64436/90000 [04:47<01:52, 228.14it/s] 72%|███████▏  | 64461/90000 [04:47<01:49, 233.00it/s] 72%|███████▏  | 64485/90000 [04:47<01:51, 227.85it/s] 72%|███████▏  | 64508/90000 [04:47<01:51, 228.19it/s] 72%|███████▏  | 64533/90000 [04:47<01:49, 231.64it/s] 72%|███████▏  | 64557/90000 [04:47<01:53, 223.50it/s] 72%|███████▏  | 64581/90000 [04:47<01:52, 226.22it/s] 72%|███████▏  | 64604/90000 [04:47<01:52, 225.79it/s] 72%|███████▏  | 64627/90000 [04:48<01:54, 220.92it/s] 72%|███████▏  | 64651/90000 [04:48<01:53, 223.25it/s] 72%|███████▏  | 64676/90000 [04:48<01:50, 228.50it/s] 72%|███████▏  | 64699/90000 [04:48<01:51, 226.13it/s] 72%|███████▏  | 64722/90000 [04:48<01:52, 225.25it/s] 72%|███████▏  | 64745/90000 [04:48<01:52, 224.77it/s] 72%|███████▏  | 64768/90000 [04:48<01:52, 225.11it/s] 72%|███████▏  | 64792/90000 [04:48<01:50, 227.50it/s] 72%|███████▏  | 64816/90000 [04:48<01:49, 229.20it/s] 72%|███████▏  | 64839/90000 [04:48<01:52, 224.31it/s] 72%|███████▏  | 64862/90000 [04:49<01:51, 225.21it/s] 72%|███████▏  | 64885/90000 [04:49<01:50, 226.60it/s] 72%|███████▏  | 64908/90000 [04:49<01:53, 220.90it/s] 72%|███████▏  | 64931/90000 [04:49<01:52, 223.02it/s] 72%|███████▏  | 64954/90000 [04:49<01:52, 222.22it/s] 72%|███████▏  | 64977/90000 [04:49<01:53, 220.94it/s] 72%|███████▏  | 65001/90000 [04:49<01:51, 224.57it/s] 72%|███████▏  | 65025/90000 [04:49<01:49, 227.50it/s] 72%|███████▏  | 65048/90000 [04:49<01:49, 227.77it/s] 72%|███████▏  | 65071/90000 [04:49<01:51, 223.46it/s] 72%|███████▏  | 65094/90000 [04:50<01:50, 224.61it/s] 72%|███████▏  | 65118/90000 [04:50<01:49, 227.19it/s] 72%|███████▏  | 65142/90000 [04:50<01:48, 229.95it/s] 72%|███████▏  | 65166/90000 [04:50<01:52, 221.45it/s] 72%|███████▏  | 65189/90000 [04:50<01:52, 220.58it/s] 72%|███████▏  | 65212/90000 [04:50<01:51, 223.18it/s] 72%|███████▏  | 65235/90000 [04:50<01:51, 222.58it/s] 73%|███████▎  | 65258/90000 [04:50<01:51, 222.74it/s] 73%|███████▎  | 65281/90000 [04:50<01:51, 221.48it/s] 73%|███████▎  | 65304/90000 [04:51<01:51, 221.37it/s] 73%|███████▎  | 65327/90000 [04:51<01:52, 220.22it/s] 73%|███████▎  | 65351/90000 [04:51<01:49, 224.74it/s] 73%|███████▎  | 65376/90000 [04:51<01:47, 229.68it/s] 73%|███████▎  | 65400/90000 [04:51<01:45, 232.43it/s] 73%|███████▎  | 65424/90000 [04:51<01:45, 232.07it/s] 73%|███████▎  | 65448/90000 [04:51<01:45, 231.88it/s] 73%|███████▎  | 65472/90000 [04:51<01:46, 230.41it/s] 73%|███████▎  | 65496/90000 [04:51<01:47, 227.55it/s] 73%|███████▎  | 65519/90000 [04:51<01:48, 225.61it/s] 73%|███████▎  | 65542/90000 [04:52<01:52, 217.74it/s] 73%|███████▎  | 65566/90000 [04:52<01:49, 223.62it/s] 73%|███████▎  | 65589/90000 [04:52<01:49, 223.52it/s] 73%|███████▎  | 65613/90000 [04:52<01:47, 227.36it/s] 73%|███████▎  | 65637/90000 [04:52<01:45, 230.21it/s] 73%|███████▎  | 65661/90000 [04:52<01:46, 228.57it/s] 73%|███████▎  | 65684/90000 [04:52<01:47, 227.16it/s] 73%|███████▎  | 65707/90000 [04:52<01:48, 223.63it/s] 73%|███████▎  | 65731/90000 [04:52<01:46, 226.86it/s] 73%|███████▎  | 65754/90000 [04:53<01:47, 226.06it/s] 73%|███████▎  | 65777/90000 [04:53<01:47, 224.73it/s] 73%|███████▎  | 65802/90000 [04:53<01:44, 231.04it/s] 73%|███████▎  | 65826/90000 [04:53<01:44, 231.67it/s] 73%|███████▎  | 65850/90000 [04:53<01:43, 232.30it/s] 73%|███████▎  | 65874/90000 [04:53<01:44, 230.61it/s] 73%|███████▎  | 65898/90000 [04:53<01:44, 229.65it/s] 73%|███████▎  | 65922/90000 [04:53<01:44, 230.72it/s] 73%|███████▎  | 65946/90000 [04:53<01:44, 231.19it/s] 73%|███████▎  | 65970/90000 [04:53<01:45, 228.56it/s] 73%|███████▎  | 65995/90000 [04:54<01:42, 233.70it/s] 73%|███████▎  | 66019/90000 [04:54<01:44, 229.87it/s] 73%|███████▎  | 66043/90000 [04:54<01:44, 228.84it/s] 73%|███████▎  | 66067/90000 [04:54<01:44, 229.10it/s] 73%|███████▎  | 66090/90000 [04:54<01:46, 225.41it/s] 73%|███████▎  | 66113/90000 [04:54<01:45, 225.71it/s] 73%|███████▎  | 66136/90000 [04:54<01:45, 226.13it/s] 74%|███████▎  | 66159/90000 [04:54<01:46, 223.05it/s] 74%|███████▎  | 66183/90000 [04:54<01:45, 224.83it/s] 74%|███████▎  | 66206/90000 [04:54<01:45, 225.34it/s] 74%|███████▎  | 66229/90000 [04:55<01:45, 226.13it/s] 74%|███████▎  | 66252/90000 [04:55<01:45, 224.57it/s] 74%|███████▎  | 66277/90000 [04:55<01:43, 230.00it/s] 74%|███████▎  | 66301/90000 [04:55<01:41, 232.91it/s] 74%|███████▎  | 66325/90000 [04:55<01:41, 232.24it/s] 74%|███████▎  | 66349/90000 [04:55<01:42, 231.81it/s] 74%|███████▎  | 66373/90000 [04:55<01:42, 231.28it/s] 74%|███████▍  | 66397/90000 [04:55<01:41, 233.07it/s] 74%|███████▍  | 66421/90000 [04:55<01:44, 226.10it/s] 74%|███████▍  | 66444/90000 [04:56<01:46, 221.90it/s] 74%|███████▍  | 66468/90000 [04:56<01:44, 226.09it/s] 74%|███████▍  | 66491/90000 [04:56<01:43, 226.20it/s] 74%|███████▍  | 66514/90000 [04:56<01:44, 225.27it/s] 74%|███████▍  | 66538/90000 [04:56<01:42, 228.93it/s] 74%|███████▍  | 66563/90000 [04:56<01:40, 233.73it/s] 74%|███████▍  | 66587/90000 [04:56<01:40, 231.90it/s] 74%|███████▍  | 66611/90000 [04:56<01:40, 232.70it/s] 74%|███████▍  | 66635/90000 [04:56<01:41, 229.37it/s] 74%|███████▍  | 66658/90000 [04:56<01:42, 228.24it/s] 74%|███████▍  | 66681/90000 [04:57<01:42, 228.56it/s] 74%|███████▍  | 66707/90000 [04:57<01:38, 235.58it/s] 74%|███████▍  | 66731/90000 [04:57<01:39, 232.94it/s] 74%|███████▍  | 66755/90000 [04:57<01:42, 225.97it/s] 74%|███████▍  | 66779/90000 [04:57<01:41, 228.30it/s] 74%|███████▍  | 66803/90000 [04:57<01:41, 229.08it/s] 74%|███████▍  | 66826/90000 [04:57<01:41, 227.30it/s] 74%|███████▍  | 66851/90000 [04:57<01:39, 232.19it/s] 74%|███████▍  | 66875/90000 [04:57<01:42, 226.12it/s] 74%|███████▍  | 66898/90000 [04:58<01:42, 224.55it/s] 74%|███████▍  | 66921/90000 [04:58<01:42, 224.87it/s] 74%|███████▍  | 66944/90000 [04:58<01:42, 224.52it/s] 74%|███████▍  | 66967/90000 [04:58<01:41, 226.06it/s] 74%|███████▍  | 66990/90000 [04:58<01:41, 226.80it/s] 74%|███████▍  | 67013/90000 [04:58<01:42, 224.74it/s] 74%|███████▍  | 67037/90000 [04:58<01:40, 227.63it/s] 75%|███████▍  | 67060/90000 [04:58<01:40, 227.70it/s] 75%|███████▍  | 67083/90000 [04:58<01:42, 224.14it/s] 75%|███████▍  | 67107/90000 [04:58<01:41, 226.13it/s] 75%|███████▍  | 67130/90000 [04:59<01:42, 223.43it/s] 75%|███████▍  | 67154/90000 [04:59<01:40, 227.54it/s] 75%|███████▍  | 67178/90000 [04:59<01:39, 229.40it/s] 75%|███████▍  | 67202/90000 [04:59<01:39, 229.46it/s] 75%|███████▍  | 67225/90000 [04:59<01:40, 227.49it/s] 75%|███████▍  | 67248/90000 [04:59<01:41, 224.75it/s] 75%|███████▍  | 67271/90000 [04:59<01:41, 222.89it/s] 75%|███████▍  | 67294/90000 [04:59<01:41, 223.03it/s] 75%|███████▍  | 67317/90000 [04:59<01:40, 225.02it/s] 75%|███████▍  | 67342/90000 [04:59<01:38, 229.85it/s] 75%|███████▍  | 67365/90000 [05:00<01:38, 228.69it/s] 75%|███████▍  | 67389/90000 [05:00<01:37, 230.80it/s] 75%|███████▍  | 67413/90000 [05:00<01:41, 223.20it/s] 75%|███████▍  | 67436/90000 [05:00<01:40, 223.58it/s] 75%|███████▍  | 67460/90000 [05:00<01:39, 227.00it/s] 75%|███████▍  | 67483/90000 [05:00<01:40, 223.66it/s] 75%|███████▌  | 67507/90000 [05:00<01:39, 227.08it/s] 75%|███████▌  | 67530/90000 [05:00<01:38, 227.10it/s] 75%|███████▌  | 67553/90000 [05:00<01:39, 225.92it/s] 75%|███████▌  | 67576/90000 [05:01<01:40, 222.86it/s] 75%|███████▌  | 67600/90000 [05:01<01:39, 225.22it/s] 75%|███████▌  | 67623/90000 [05:01<01:40, 222.51it/s] 75%|███████▌  | 67646/90000 [05:01<01:40, 223.28it/s] 75%|███████▌  | 67670/90000 [05:01<01:38, 226.62it/s] 75%|███████▌  | 67693/90000 [05:01<01:38, 225.53it/s] 75%|███████▌  | 67716/90000 [05:01<01:40, 220.96it/s] 75%|███████▌  | 67740/90000 [05:01<01:39, 224.48it/s] 75%|███████▌  | 67764/90000 [05:01<01:38, 226.67it/s] 75%|███████▌  | 67787/90000 [05:01<01:38, 225.20it/s] 75%|███████▌  | 67810/90000 [05:02<01:37, 226.53it/s] 75%|███████▌  | 67834/90000 [05:02<01:37, 228.14it/s] 75%|███████▌  | 67857/90000 [05:02<01:37, 227.74it/s] 75%|███████▌  | 67880/90000 [05:02<01:38, 223.45it/s] 75%|███████▌  | 67903/90000 [05:02<01:38, 225.31it/s] 75%|███████▌  | 67926/90000 [05:02<01:37, 226.65it/s] 75%|███████▌  | 67949/90000 [05:02<01:37, 226.50it/s] 76%|███████▌  | 67974/90000 [05:02<01:35, 231.53it/s] 76%|███████▌  | 67998/90000 [05:02<01:34, 232.04it/s] 76%|███████▌  | 68022/90000 [05:02<01:34, 231.50it/s] 76%|███████▌  | 68046/90000 [05:03<01:34, 231.59it/s] 76%|███████▌  | 68070/90000 [05:03<01:36, 226.59it/s] 76%|███████▌  | 68094/90000 [05:03<01:36, 227.70it/s] 76%|███████▌  | 68118/90000 [05:03<01:34, 230.46it/s] 76%|███████▌  | 68142/90000 [05:03<01:37, 224.67it/s] 76%|███████▌  | 68167/90000 [05:03<01:35, 228.79it/s] 76%|███████▌  | 68191/90000 [05:03<01:35, 229.32it/s] 76%|███████▌  | 68214/90000 [05:03<01:36, 224.88it/s] 76%|███████▌  | 68240/90000 [05:03<01:33, 233.27it/s] 76%|███████▌  | 68264/90000 [05:04<01:35, 227.74it/s] 76%|███████▌  | 68287/90000 [05:04<01:35, 227.42it/s] 76%|███████▌  | 68310/90000 [05:04<01:36, 225.00it/s] 76%|███████▌  | 68333/90000 [05:04<01:37, 222.54it/s] 76%|███████▌  | 68356/90000 [05:04<01:36, 224.17it/s] 76%|███████▌  | 68379/90000 [05:04<01:36, 223.19it/s] 76%|███████▌  | 68402/90000 [05:04<01:36, 223.68it/s] 76%|███████▌  | 68426/90000 [05:04<01:35, 226.09it/s] 76%|███████▌  | 68449/90000 [05:04<01:37, 220.19it/s] 76%|███████▌  | 68474/90000 [05:04<01:34, 226.59it/s] 76%|███████▌  | 68498/90000 [05:05<01:33, 230.11it/s] 76%|███████▌  | 68522/90000 [05:05<01:32, 231.65it/s] 76%|███████▌  | 68546/90000 [05:05<01:33, 230.04it/s] 76%|███████▌  | 68570/90000 [05:05<01:33, 229.24it/s] 76%|███████▌  | 68595/90000 [05:05<01:31, 232.88it/s] 76%|███████▌  | 68619/90000 [05:05<01:33, 229.77it/s] 76%|███████▋  | 68643/90000 [05:05<01:33, 229.57it/s] 76%|███████▋  | 68666/90000 [05:05<01:33, 228.70it/s] 76%|███████▋  | 68690/90000 [05:05<01:32, 230.60it/s] 76%|███████▋  | 68714/90000 [05:06<01:32, 229.33it/s] 76%|███████▋  | 68737/90000 [05:06<01:33, 226.71it/s] 76%|███████▋  | 68760/90000 [05:06<01:34, 225.51it/s] 76%|███████▋  | 68785/90000 [05:06<01:32, 229.34it/s] 76%|███████▋  | 68808/90000 [05:06<01:33, 226.96it/s] 76%|███████▋  | 68832/90000 [05:06<01:32, 228.28it/s] 77%|███████▋  | 68855/90000 [05:06<01:32, 227.38it/s] 77%|███████▋  | 68878/90000 [05:06<01:32, 227.76it/s] 77%|███████▋  | 68903/90000 [05:06<01:30, 232.54it/s] 77%|███████▋  | 68928/90000 [05:06<01:29, 235.84it/s] 77%|███████▋  | 68952/90000 [05:07<01:29, 235.38it/s] 77%|███████▋  | 68976/90000 [05:07<01:29, 234.75it/s] 77%|███████▋  | 69001/90000 [05:07<01:27, 238.85it/s] 77%|███████▋  | 69025/90000 [05:07<01:29, 234.70it/s] 77%|███████▋  | 69049/90000 [05:07<01:29, 234.56it/s] 77%|███████▋  | 69073/90000 [05:07<01:29, 234.76it/s] 77%|███████▋  | 69097/90000 [05:07<01:31, 227.68it/s] 77%|███████▋  | 69121/90000 [05:07<01:30, 230.55it/s] 77%|███████▋  | 69145/90000 [05:07<01:30, 230.66it/s] 77%|███████▋  | 69170/90000 [05:07<01:29, 233.90it/s] 77%|███████▋  | 69194/90000 [05:08<01:29, 233.19it/s] 77%|███████▋  | 69218/90000 [05:08<01:31, 226.35it/s] 77%|███████▋  | 69241/90000 [05:08<01:32, 223.62it/s] 77%|███████▋  | 69264/90000 [05:08<01:32, 224.68it/s] 77%|███████▋  | 69287/90000 [05:08<01:33, 220.60it/s] 77%|███████▋  | 69310/90000 [05:08<01:33, 222.36it/s] 77%|███████▋  | 69333/90000 [05:08<01:32, 223.13it/s] 77%|███████▋  | 69356/90000 [05:08<01:32, 223.28it/s] 77%|███████▋  | 69379/90000 [05:08<01:32, 224.04it/s] 77%|███████▋  | 69403/90000 [05:09<01:30, 228.41it/s] 77%|███████▋  | 69426/90000 [05:09<01:30, 226.39it/s] 77%|███████▋  | 69450/90000 [05:09<01:29, 229.54it/s] 77%|███████▋  | 69474/90000 [05:09<01:29, 229.64it/s] 77%|███████▋  | 69498/90000 [05:09<01:28, 231.60it/s] 77%|███████▋  | 69522/90000 [05:09<01:29, 229.17it/s] 77%|███████▋  | 69546/90000 [05:09<01:28, 230.49it/s] 77%|███████▋  | 69571/90000 [05:09<01:27, 233.85it/s] 77%|███████▋  | 69595/90000 [05:09<01:28, 231.47it/s] 77%|███████▋  | 69619/90000 [05:09<01:27, 232.04it/s] 77%|███████▋  | 69643/90000 [05:10<01:28, 229.31it/s] 77%|███████▋  | 69667/90000 [05:10<01:27, 232.18it/s] 77%|███████▋  | 69691/90000 [05:10<01:27, 230.87it/s] 77%|███████▋  | 69715/90000 [05:10<01:26, 233.48it/s] 77%|███████▋  | 69739/90000 [05:10<01:28, 227.71it/s] 78%|███████▊  | 69763/90000 [05:10<01:28, 229.25it/s] 78%|███████▊  | 69786/90000 [05:10<01:28, 228.77it/s] 78%|███████▊  | 69809/90000 [05:10<01:28, 228.97it/s] 78%|███████▊  | 69832/90000 [05:10<01:28, 227.20it/s] 78%|███████▊  | 69855/90000 [05:10<01:28, 226.73it/s] 78%|███████▊  | 69880/90000 [05:11<01:26, 232.42it/s] 78%|███████▊  | 69904/90000 [05:11<01:28, 228.26it/s] 78%|███████▊  | 69927/90000 [05:11<01:28, 226.19it/s] 78%|███████▊  | 69952/90000 [05:11<01:26, 231.23it/s] 78%|███████▊  | 69976/90000 [05:11<01:27, 227.70it/s] 78%|███████▊  | 69999/90000 [05:11<01:29, 223.60it/s] 78%|███████▊  | 70022/90000 [05:11<01:29, 224.21it/s] 78%|███████▊  | 70045/90000 [05:11<01:29, 223.98it/s] 78%|███████▊  | 70070/90000 [05:11<01:27, 226.66it/s] 78%|███████▊  | 70093/90000 [05:12<01:27, 226.92it/s] 78%|███████▊  | 70117/90000 [05:12<01:27, 228.18it/s] 78%|███████▊  | 70142/90000 [05:12<01:25, 233.46it/s] 78%|███████▊  | 70166/90000 [05:12<01:26, 229.45it/s] 78%|███████▊  | 70190/90000 [05:12<01:26, 229.78it/s] 78%|███████▊  | 70215/90000 [05:12<01:24, 234.14it/s] 78%|███████▊  | 70241/90000 [05:12<01:22, 239.25it/s] 78%|███████▊  | 70265/90000 [05:12<01:22, 238.90it/s] 78%|███████▊  | 70289/90000 [05:12<01:22, 238.43it/s] 78%|███████▊  | 70313/90000 [05:12<01:24, 234.31it/s] 78%|███████▊  | 70337/90000 [05:13<01:23, 235.48it/s] 78%|███████▊  | 70362/90000 [05:13<01:22, 237.00it/s] 78%|███████▊  | 70386/90000 [05:13<01:22, 237.28it/s] 78%|███████▊  | 70411/90000 [05:13<01:22, 237.50it/s] 78%|███████▊  | 70435/90000 [05:13<01:24, 232.54it/s] 78%|███████▊  | 70459/90000 [05:13<01:23, 233.33it/s] 78%|███████▊  | 70483/90000 [05:13<01:23, 233.44it/s] 78%|███████▊  | 70507/90000 [05:13<01:24, 230.04it/s] 78%|███████▊  | 70531/90000 [05:13<01:26, 223.94it/s] 78%|███████▊  | 70555/90000 [05:14<01:25, 228.06it/s] 78%|███████▊  | 70579/90000 [05:14<01:24, 229.16it/s] 78%|███████▊  | 70603/90000 [05:14<01:24, 229.89it/s] 78%|███████▊  | 70627/90000 [05:14<01:25, 227.20it/s] 79%|███████▊  | 70651/90000 [05:14<01:24, 228.32it/s] 79%|███████▊  | 70674/90000 [05:14<01:24, 228.56it/s] 79%|███████▊  | 70697/90000 [05:14<01:25, 227.03it/s] 79%|███████▊  | 70721/90000 [05:14<01:24, 228.74it/s] 79%|███████▊  | 70745/90000 [05:14<01:23, 229.40it/s] 79%|███████▊  | 70769/90000 [05:14<01:23, 230.69it/s] 79%|███████▊  | 70793/90000 [05:15<01:23, 229.11it/s] 79%|███████▊  | 70817/90000 [05:15<01:23, 230.63it/s] 79%|███████▊  | 70842/90000 [05:15<01:21, 236.27it/s] 79%|███████▊  | 70866/90000 [05:15<01:22, 233.00it/s] 79%|███████▉  | 70891/90000 [05:15<01:21, 235.13it/s] 79%|███████▉  | 70915/90000 [05:15<01:22, 232.37it/s] 79%|███████▉  | 70940/90000 [05:15<01:20, 236.37it/s] 79%|███████▉  | 70964/90000 [05:15<01:20, 237.28it/s] 79%|███████▉  | 70988/90000 [05:15<01:22, 230.68it/s] 79%|███████▉  | 71012/90000 [05:15<01:21, 231.93it/s] 79%|███████▉  | 71036/90000 [05:16<01:23, 228.15it/s] 79%|███████▉  | 71059/90000 [05:16<01:23, 226.37it/s] 79%|███████▉  | 71082/90000 [05:16<01:23, 225.87it/s] 79%|███████▉  | 71105/90000 [05:16<01:25, 222.05it/s] 79%|███████▉  | 71129/90000 [05:16<01:23, 226.73it/s] 79%|███████▉  | 71153/90000 [05:16<01:23, 226.85it/s] 79%|███████▉  | 71177/90000 [05:16<01:22, 228.53it/s] 79%|███████▉  | 71201/90000 [05:16<01:21, 230.85it/s] 79%|███████▉  | 71225/90000 [05:16<01:22, 226.96it/s] 79%|███████▉  | 71248/90000 [05:17<01:22, 227.18it/s] 79%|███████▉  | 71271/90000 [05:17<01:23, 224.63it/s] 79%|███████▉  | 71294/90000 [05:17<01:24, 221.90it/s] 79%|███████▉  | 71318/90000 [05:17<01:22, 225.79it/s] 79%|███████▉  | 71342/90000 [05:17<01:21, 228.12it/s] 79%|███████▉  | 71367/90000 [05:17<01:20, 231.70it/s] 79%|███████▉  | 71391/90000 [05:17<01:20, 231.88it/s] 79%|███████▉  | 71415/90000 [05:17<01:20, 232.18it/s] 79%|███████▉  | 71439/90000 [05:17<01:19, 232.93it/s] 79%|███████▉  | 71463/90000 [05:17<01:19, 234.02it/s] 79%|███████▉  | 71487/90000 [05:18<01:19, 232.02it/s] 79%|███████▉  | 71511/90000 [05:18<01:18, 234.05it/s] 79%|███████▉  | 71535/90000 [05:18<01:19, 232.95it/s] 80%|███████▉  | 71559/90000 [05:18<01:20, 229.69it/s] 80%|███████▉  | 71582/90000 [05:18<01:20, 227.81it/s] 80%|███████▉  | 71606/90000 [05:18<01:19, 230.00it/s] 80%|███████▉  | 71630/90000 [05:18<01:19, 230.09it/s] 80%|███████▉  | 71654/90000 [05:18<01:18, 232.43it/s] 80%|███████▉  | 71678/90000 [05:18<01:18, 232.35it/s] 80%|███████▉  | 71702/90000 [05:18<01:19, 230.05it/s] 80%|███████▉  | 71726/90000 [05:19<01:18, 232.40it/s] 80%|███████▉  | 71750/90000 [05:19<01:19, 230.58it/s] 80%|███████▉  | 71774/90000 [05:19<01:19, 228.75it/s] 80%|███████▉  | 71798/90000 [05:19<01:19, 230.18it/s] 80%|███████▉  | 71822/90000 [05:19<01:20, 226.31it/s] 80%|███████▉  | 71847/90000 [05:19<01:18, 230.80it/s] 80%|███████▉  | 71872/90000 [05:19<01:17, 233.28it/s] 80%|███████▉  | 71896/90000 [05:19<01:18, 231.73it/s] 80%|███████▉  | 71920/90000 [05:19<01:18, 230.11it/s] 80%|███████▉  | 71944/90000 [05:20<01:20, 225.11it/s] 80%|███████▉  | 71968/90000 [05:20<01:19, 226.88it/s] 80%|███████▉  | 71991/90000 [05:20<01:20, 224.63it/s] 80%|████████  | 72015/90000 [05:20<01:19, 227.47it/s] 80%|████████  | 72038/90000 [05:20<01:18, 227.79it/s] 80%|████████  | 72061/90000 [05:20<01:20, 223.72it/s] 80%|████████  | 72085/90000 [05:20<01:18, 228.38it/s] 80%|████████  | 72108/90000 [05:20<01:18, 228.48it/s] 80%|████████  | 72133/90000 [05:20<01:16, 232.36it/s] 80%|████████  | 72157/90000 [05:20<01:16, 233.84it/s] 80%|████████  | 72181/90000 [05:21<01:16, 234.17it/s] 80%|████████  | 72205/90000 [05:21<01:15, 234.82it/s] 80%|████████  | 72229/90000 [05:21<01:15, 234.57it/s] 80%|████████  | 72253/90000 [05:21<01:16, 232.92it/s] 80%|████████  | 72277/90000 [05:21<01:15, 233.46it/s] 80%|████████  | 72301/90000 [05:21<01:15, 234.32it/s] 80%|████████  | 72325/90000 [05:21<01:15, 235.20it/s] 80%|████████  | 72349/90000 [05:21<01:15, 233.24it/s] 80%|████████  | 72373/90000 [05:21<01:17, 227.61it/s] 80%|████████  | 72398/90000 [05:22<01:15, 232.20it/s] 80%|████████  | 72423/90000 [05:22<01:14, 235.79it/s] 80%|████████  | 72447/90000 [05:22<01:15, 232.39it/s] 81%|████████  | 72471/90000 [05:22<01:15, 231.76it/s] 81%|████████  | 72495/90000 [05:22<01:16, 230.08it/s] 81%|████████  | 72519/90000 [05:22<01:15, 231.51it/s] 81%|████████  | 72543/90000 [05:22<01:16, 228.29it/s] 81%|████████  | 72566/90000 [05:22<01:16, 227.52it/s] 81%|████████  | 72590/90000 [05:22<01:16, 228.65it/s] 81%|████████  | 72614/90000 [05:22<01:15, 229.95it/s] 81%|████████  | 72638/90000 [05:23<01:16, 227.82it/s] 81%|████████  | 72663/90000 [05:23<01:14, 232.23it/s] 81%|████████  | 72687/90000 [05:23<01:14, 232.90it/s] 81%|████████  | 72711/90000 [05:23<01:14, 231.78it/s] 81%|████████  | 72736/90000 [05:23<01:13, 235.92it/s] 81%|████████  | 72760/90000 [05:23<01:13, 234.61it/s] 81%|████████  | 72784/90000 [05:23<01:14, 232.57it/s] 81%|████████  | 72809/90000 [05:23<01:12, 236.57it/s] 81%|████████  | 72833/90000 [05:23<01:15, 228.54it/s] 81%|████████  | 72857/90000 [05:23<01:14, 230.32it/s] 81%|████████  | 72881/90000 [05:24<01:14, 231.04it/s] 81%|████████  | 72905/90000 [05:24<01:13, 233.51it/s] 81%|████████  | 72929/90000 [05:24<01:13, 231.01it/s] 81%|████████  | 72953/90000 [05:24<01:13, 230.45it/s] 81%|████████  | 72977/90000 [05:24<01:13, 231.94it/s] 81%|████████  | 73001/90000 [05:24<01:12, 233.02it/s] 81%|████████  | 73025/90000 [05:24<01:14, 227.25it/s] 81%|████████  | 73049/90000 [05:24<01:14, 228.57it/s] 81%|████████  | 73073/90000 [05:24<01:13, 229.93it/s] 81%|████████  | 73098/90000 [05:25<01:12, 233.81it/s] 81%|████████  | 73122/90000 [05:25<01:12, 233.05it/s] 81%|████████▏ | 73146/90000 [05:25<01:14, 224.86it/s] 81%|████████▏ | 73169/90000 [05:25<01:15, 223.47it/s] 81%|████████▏ | 73193/90000 [05:25<01:13, 228.10it/s] 81%|████████▏ | 73217/90000 [05:25<01:13, 229.89it/s] 81%|████████▏ | 73241/90000 [05:25<01:14, 223.60it/s] 81%|████████▏ | 73266/90000 [05:25<01:12, 229.41it/s] 81%|████████▏ | 73291/90000 [05:25<01:11, 234.06it/s] 81%|████████▏ | 73315/90000 [05:25<01:11, 232.56it/s] 81%|████████▏ | 73339/90000 [05:26<01:12, 229.98it/s] 82%|████████▏ | 73363/90000 [05:26<01:13, 226.02it/s] 82%|████████▏ | 73386/90000 [05:26<01:14, 223.83it/s] 82%|████████▏ | 73410/90000 [05:26<01:13, 227.13it/s] 82%|████████▏ | 73433/90000 [05:26<01:13, 225.42it/s] 82%|████████▏ | 73457/90000 [05:26<01:12, 228.95it/s] 82%|████████▏ | 73480/90000 [05:26<01:12, 227.02it/s] 82%|████████▏ | 73504/90000 [05:26<01:11, 229.48it/s] 82%|████████▏ | 73527/90000 [05:26<01:13, 223.36it/s] 82%|████████▏ | 73550/90000 [05:27<01:14, 219.44it/s] 82%|████████▏ | 73574/90000 [05:27<01:13, 222.94it/s] 82%|████████▏ | 73597/90000 [05:27<01:14, 219.17it/s] 82%|████████▏ | 73619/90000 [05:27<01:14, 218.79it/s] 82%|████████▏ | 73641/90000 [05:27<01:15, 217.61it/s] 82%|████████▏ | 73663/90000 [05:27<01:15, 216.39it/s] 82%|████████▏ | 73686/90000 [05:27<01:14, 218.38it/s] 82%|████████▏ | 73708/90000 [05:27<01:14, 217.75it/s] 82%|████████▏ | 73731/90000 [05:27<01:14, 218.73it/s] 82%|████████▏ | 73754/90000 [05:27<01:13, 221.28it/s] 82%|████████▏ | 73777/90000 [05:28<01:14, 219.00it/s] 82%|████████▏ | 73799/90000 [05:28<01:14, 218.33it/s] 82%|████████▏ | 73821/90000 [05:28<01:15, 215.07it/s] 82%|████████▏ | 73844/90000 [05:28<01:14, 217.79it/s] 82%|████████▏ | 73866/90000 [05:28<01:14, 217.16it/s] 82%|████████▏ | 73888/90000 [05:28<01:14, 217.50it/s] 82%|████████▏ | 73911/90000 [05:28<01:13, 220.16it/s] 82%|████████▏ | 73934/90000 [05:28<01:13, 219.65it/s] 82%|████████▏ | 73956/90000 [05:28<01:13, 217.48it/s] 82%|████████▏ | 73978/90000 [05:29<01:16, 210.76it/s] 82%|████████▏ | 74000/90000 [05:29<01:15, 213.17it/s] 82%|████████▏ | 74022/90000 [05:29<01:14, 214.45it/s] 82%|████████▏ | 74044/90000 [05:29<01:14, 215.49it/s] 82%|████████▏ | 74066/90000 [05:29<01:13, 216.32it/s] 82%|████████▏ | 74088/90000 [05:29<01:14, 214.32it/s] 82%|████████▏ | 74111/90000 [05:29<01:12, 218.32it/s] 82%|████████▏ | 74133/90000 [05:29<01:13, 216.68it/s] 82%|████████▏ | 74156/90000 [05:29<01:12, 217.63it/s] 82%|████████▏ | 74180/90000 [05:29<01:10, 223.02it/s] 82%|████████▏ | 74203/90000 [05:30<01:11, 219.86it/s] 82%|████████▏ | 74227/90000 [05:30<01:10, 224.05it/s] 82%|████████▎ | 74250/90000 [05:30<01:10, 222.68it/s] 83%|████████▎ | 74273/90000 [05:30<01:10, 222.24it/s] 83%|████████▎ | 74296/90000 [05:30<01:09, 224.44it/s] 83%|████████▎ | 74319/90000 [05:30<01:11, 217.81it/s] 83%|████████▎ | 74342/90000 [05:30<01:11, 218.44it/s] 83%|████████▎ | 74365/90000 [05:30<01:10, 221.44it/s] 83%|████████▎ | 74389/90000 [05:30<01:09, 224.14it/s] 83%|████████▎ | 74412/90000 [05:30<01:10, 221.28it/s] 83%|████████▎ | 74435/90000 [05:31<01:09, 223.38it/s] 83%|████████▎ | 74458/90000 [05:31<01:10, 220.70it/s] 83%|████████▎ | 74481/90000 [05:31<01:10, 218.84it/s] 83%|████████▎ | 74503/90000 [05:31<01:11, 216.01it/s] 83%|████████▎ | 74526/90000 [05:31<01:10, 218.66it/s] 83%|████████▎ | 74549/90000 [05:31<01:10, 219.51it/s] 83%|████████▎ | 74573/90000 [05:31<01:09, 221.65it/s] 83%|████████▎ | 74596/90000 [05:31<01:10, 219.30it/s] 83%|████████▎ | 74618/90000 [05:31<01:11, 216.64it/s] 83%|████████▎ | 74641/90000 [05:32<01:09, 219.45it/s] 83%|████████▎ | 74663/90000 [05:32<01:10, 217.80it/s] 83%|████████▎ | 74685/90000 [05:32<01:10, 216.70it/s] 83%|████████▎ | 74707/90000 [05:32<01:12, 211.51it/s] 83%|████████▎ | 74731/90000 [05:32<01:10, 216.86it/s] 83%|████████▎ | 74754/90000 [05:32<01:09, 220.00it/s] 83%|████████▎ | 74777/90000 [05:32<01:09, 219.92it/s] 83%|████████▎ | 74802/90000 [05:32<01:06, 228.33it/s] 83%|████████▎ | 74825/90000 [05:32<01:09, 219.71it/s] 83%|████████▎ | 74848/90000 [05:32<01:08, 221.08it/s] 83%|████████▎ | 74871/90000 [05:33<01:07, 223.24it/s] 83%|████████▎ | 74895/90000 [05:33<01:07, 225.31it/s] 83%|████████▎ | 74918/90000 [05:33<01:07, 224.99it/s] 83%|████████▎ | 74941/90000 [05:33<01:06, 225.45it/s] 83%|████████▎ | 74964/90000 [05:33<01:07, 222.57it/s] 83%|████████▎ | 74987/90000 [05:33<01:08, 219.27it/s] 83%|████████▎ | 75009/90000 [05:33<01:08, 217.89it/s] 83%|████████▎ | 75031/90000 [05:33<01:10, 212.02it/s] 83%|████████▎ | 75053/90000 [05:33<01:10, 210.63it/s] 83%|████████▎ | 75075/90000 [05:34<01:11, 210.12it/s] 83%|████████▎ | 75098/90000 [05:34<01:09, 213.13it/s] 83%|████████▎ | 75120/90000 [05:34<01:09, 214.76it/s] 83%|████████▎ | 75142/90000 [05:34<01:08, 216.19it/s] 84%|████████▎ | 75164/90000 [05:34<01:08, 217.06it/s] 84%|████████▎ | 75187/90000 [05:34<01:07, 218.32it/s] 84%|████████▎ | 75209/90000 [05:34<01:07, 217.66it/s] 84%|████████▎ | 75232/90000 [05:34<01:07, 219.63it/s] 84%|████████▎ | 75256/90000 [05:34<01:06, 223.05it/s] 84%|████████▎ | 75280/90000 [05:34<01:04, 226.94it/s] 84%|████████▎ | 75303/90000 [05:35<01:06, 222.09it/s] 84%|████████▎ | 75326/90000 [05:35<01:06, 221.65it/s] 84%|████████▎ | 75349/90000 [05:35<01:05, 224.02it/s] 84%|████████▎ | 75372/90000 [05:35<01:05, 222.13it/s] 84%|████████▍ | 75395/90000 [05:35<01:06, 219.67it/s] 84%|████████▍ | 75419/90000 [05:35<01:05, 223.26it/s] 84%|████████▍ | 75442/90000 [05:35<01:07, 217.16it/s] 84%|████████▍ | 75466/90000 [05:35<01:05, 221.29it/s] 84%|████████▍ | 75491/90000 [05:35<01:03, 228.33it/s] 84%|████████▍ | 75514/90000 [05:35<01:03, 228.54it/s] 84%|████████▍ | 75537/90000 [05:36<01:03, 228.16it/s] 84%|████████▍ | 75560/90000 [05:36<01:03, 227.08it/s] 84%|████████▍ | 75583/90000 [05:36<01:03, 227.34it/s] 84%|████████▍ | 75606/90000 [05:36<01:03, 227.23it/s] 84%|████████▍ | 75630/90000 [05:36<01:02, 228.77it/s] 84%|████████▍ | 75653/90000 [05:36<01:02, 227.82it/s] 84%|████████▍ | 75676/90000 [05:36<01:02, 228.12it/s] 84%|████████▍ | 75699/90000 [05:36<01:02, 227.50it/s] 84%|████████▍ | 75722/90000 [05:36<01:02, 228.17it/s] 84%|████████▍ | 75745/90000 [05:37<01:03, 223.68it/s] 84%|████████▍ | 75768/90000 [05:37<01:03, 225.21it/s] 84%|████████▍ | 75792/90000 [05:37<01:02, 228.25it/s] 84%|████████▍ | 75817/90000 [05:37<01:01, 231.43it/s] 84%|████████▍ | 75841/90000 [05:37<01:01, 229.37it/s] 84%|████████▍ | 75865/90000 [05:37<01:01, 230.80it/s] 84%|████████▍ | 75890/90000 [05:37<01:00, 235.01it/s] 84%|████████▍ | 75914/90000 [05:37<01:00, 232.05it/s] 84%|████████▍ | 75938/90000 [05:37<01:00, 230.96it/s] 84%|████████▍ | 75962/90000 [05:37<01:00, 231.98it/s] 84%|████████▍ | 75986/90000 [05:38<01:02, 224.51it/s] 84%|████████▍ | 76010/90000 [05:38<01:01, 227.97it/s] 84%|████████▍ | 76034/90000 [05:38<01:00, 229.93it/s] 85%|████████▍ | 76058/90000 [05:38<01:01, 227.51it/s] 85%|████████▍ | 76082/90000 [05:38<01:00, 229.14it/s] 85%|████████▍ | 76106/90000 [05:38<01:00, 228.93it/s] 85%|████████▍ | 76130/90000 [05:38<00:59, 231.17it/s] 85%|████████▍ | 76154/90000 [05:38<01:00, 229.16it/s] 85%|████████▍ | 76178/90000 [05:38<00:59, 231.80it/s] 85%|████████▍ | 76203/90000 [05:38<00:58, 234.93it/s] 85%|████████▍ | 76227/90000 [05:39<00:59, 233.20it/s] 85%|████████▍ | 76251/90000 [05:39<00:58, 233.44it/s] 85%|████████▍ | 76275/90000 [05:39<01:00, 228.49it/s] 85%|████████▍ | 76298/90000 [05:39<01:01, 222.75it/s] 85%|████████▍ | 76321/90000 [05:39<01:01, 221.73it/s] 85%|████████▍ | 76345/90000 [05:39<01:00, 225.87it/s] 85%|████████▍ | 76368/90000 [05:39<01:00, 226.86it/s] 85%|████████▍ | 76392/90000 [05:39<00:59, 228.09it/s] 85%|████████▍ | 76416/90000 [05:39<00:58, 230.91it/s] 85%|████████▍ | 76440/90000 [05:40<00:59, 229.37it/s] 85%|████████▍ | 76463/90000 [05:40<00:59, 228.34it/s] 85%|████████▍ | 76486/90000 [05:40<01:00, 225.05it/s] 85%|████████▌ | 76509/90000 [05:40<01:00, 223.62it/s] 85%|████████▌ | 76532/90000 [05:40<01:00, 223.66it/s] 85%|████████▌ | 76555/90000 [05:40<01:00, 221.29it/s] 85%|████████▌ | 76578/90000 [05:40<01:01, 219.92it/s] 85%|████████▌ | 76602/90000 [05:40<00:59, 225.08it/s] 85%|████████▌ | 76625/90000 [05:40<01:00, 219.33it/s] 85%|████████▌ | 76649/90000 [05:40<00:59, 223.86it/s] 85%|████████▌ | 76672/90000 [05:41<01:00, 221.33it/s] 85%|████████▌ | 76696/90000 [05:41<00:59, 225.20it/s] 85%|████████▌ | 76719/90000 [05:41<00:59, 222.08it/s] 85%|████████▌ | 76742/90000 [05:41<00:59, 221.36it/s] 85%|████████▌ | 76766/90000 [05:41<00:58, 224.54it/s] 85%|████████▌ | 76789/90000 [05:41<00:59, 220.76it/s] 85%|████████▌ | 76812/90000 [05:41<00:59, 220.18it/s] 85%|████████▌ | 76835/90000 [05:41<00:59, 219.83it/s] 85%|████████▌ | 76857/90000 [05:41<01:00, 217.09it/s] 85%|████████▌ | 76879/90000 [05:42<01:00, 216.51it/s] 85%|████████▌ | 76903/90000 [05:42<00:59, 220.70it/s] 85%|████████▌ | 76926/90000 [05:42<00:59, 219.99it/s] 86%|████████▌ | 76950/90000 [05:42<00:58, 224.82it/s] 86%|████████▌ | 76974/90000 [05:42<00:57, 227.76it/s] 86%|████████▌ | 76997/90000 [05:42<00:57, 226.68it/s] 86%|████████▌ | 77020/90000 [05:42<01:00, 215.67it/s] 86%|████████▌ | 77043/90000 [05:42<00:59, 217.22it/s] 86%|████████▌ | 77066/90000 [05:42<00:58, 219.25it/s] 86%|████████▌ | 77089/90000 [05:42<00:58, 221.36it/s] 86%|████████▌ | 77112/90000 [05:43<00:58, 219.34it/s] 86%|████████▌ | 77137/90000 [05:43<00:57, 224.57it/s] 86%|████████▌ | 77160/90000 [05:43<00:57, 221.42it/s] 86%|████████▌ | 77184/90000 [05:43<00:57, 223.93it/s] 86%|████████▌ | 77207/90000 [05:43<00:56, 224.97it/s] 86%|████████▌ | 77231/90000 [05:43<00:56, 227.71it/s] 86%|████████▌ | 77254/90000 [05:43<00:56, 224.14it/s] 86%|████████▌ | 77277/90000 [05:43<00:57, 223.11it/s] 86%|████████▌ | 77301/90000 [05:43<00:56, 225.45it/s] 86%|████████▌ | 77324/90000 [05:44<00:56, 224.51it/s] 86%|████████▌ | 77348/90000 [05:44<00:55, 227.31it/s] 86%|████████▌ | 77371/90000 [05:44<00:56, 225.43it/s] 86%|████████▌ | 77394/90000 [05:44<00:55, 226.31it/s] 86%|████████▌ | 77417/90000 [05:44<00:55, 226.08it/s] 86%|████████▌ | 77440/90000 [05:44<00:56, 221.52it/s] 86%|████████▌ | 77463/90000 [05:44<00:57, 219.56it/s] 86%|████████▌ | 77485/90000 [05:44<00:57, 217.29it/s] 86%|████████▌ | 77509/90000 [05:44<00:56, 221.22it/s] 86%|████████▌ | 77532/90000 [05:44<00:56, 221.79it/s] 86%|████████▌ | 77555/90000 [05:45<00:56, 221.13it/s] 86%|████████▌ | 77578/90000 [05:45<00:55, 221.86it/s] 86%|████████▌ | 77602/90000 [05:45<00:54, 225.54it/s] 86%|████████▋ | 77626/90000 [05:45<00:54, 227.98it/s] 86%|████████▋ | 77650/90000 [05:45<00:53, 229.24it/s] 86%|████████▋ | 77673/90000 [05:45<00:53, 228.88it/s] 86%|████████▋ | 77696/90000 [05:45<00:53, 228.51it/s] 86%|████████▋ | 77719/90000 [05:45<00:54, 224.33it/s] 86%|████████▋ | 77742/90000 [05:45<00:55, 221.75it/s] 86%|████████▋ | 77765/90000 [05:45<00:55, 220.94it/s] 86%|████████▋ | 77788/90000 [05:46<00:55, 220.56it/s] 86%|████████▋ | 77811/90000 [05:46<00:55, 220.05it/s] 86%|████████▋ | 77835/90000 [05:46<00:54, 223.41it/s] 87%|████████▋ | 77858/90000 [05:46<00:54, 223.48it/s] 87%|████████▋ | 77881/90000 [05:46<00:54, 222.59it/s] 87%|████████▋ | 77906/90000 [05:46<00:53, 227.40it/s] 87%|████████▋ | 77929/90000 [05:46<00:54, 221.91it/s] 87%|████████▋ | 77952/90000 [05:46<00:55, 217.48it/s] 87%|████████▋ | 77975/90000 [05:46<00:54, 219.94it/s] 87%|████████▋ | 77998/90000 [05:47<00:54, 219.39it/s] 87%|████████▋ | 78020/90000 [05:47<00:54, 219.39it/s] 87%|████████▋ | 78043/90000 [05:47<00:54, 220.13it/s] 87%|████████▋ | 78066/90000 [05:47<00:54, 217.79it/s] 87%|████████▋ | 78090/90000 [05:47<00:53, 221.63it/s] 87%|████████▋ | 78113/90000 [05:47<00:54, 218.42it/s] 87%|████████▋ | 78136/90000 [05:47<00:53, 220.76it/s] 87%|████████▋ | 78159/90000 [05:47<00:53, 223.35it/s] 87%|████████▋ | 78182/90000 [05:47<00:54, 217.44it/s] 87%|████████▋ | 78204/90000 [05:47<00:54, 218.03it/s] 87%|████████▋ | 78227/90000 [05:48<00:53, 221.42it/s] 87%|████████▋ | 78250/90000 [05:48<00:53, 218.06it/s] 87%|████████▋ | 78272/90000 [05:48<00:54, 216.82it/s] 87%|████████▋ | 78296/90000 [05:48<00:52, 223.41it/s] 87%|████████▋ | 78319/90000 [05:48<00:53, 218.94it/s] 87%|████████▋ | 78341/90000 [05:48<00:54, 215.86it/s] 87%|████████▋ | 78364/90000 [05:48<00:53, 217.18it/s] 87%|████████▋ | 78386/90000 [05:48<00:53, 215.41it/s] 87%|████████▋ | 78409/90000 [05:48<00:52, 218.90it/s] 87%|████████▋ | 78431/90000 [05:49<00:54, 213.95it/s] 87%|████████▋ | 78454/90000 [05:49<00:53, 217.62it/s] 87%|████████▋ | 78477/90000 [05:49<00:52, 220.32it/s] 87%|████████▋ | 78500/90000 [05:49<00:52, 220.30it/s] 87%|████████▋ | 78523/90000 [05:49<00:53, 215.29it/s] 87%|████████▋ | 78547/90000 [05:49<00:51, 220.33it/s] 87%|████████▋ | 78570/90000 [05:49<00:52, 218.60it/s] 87%|████████▋ | 78593/90000 [05:49<00:51, 221.48it/s] 87%|████████▋ | 78616/90000 [05:49<00:51, 221.79it/s] 87%|████████▋ | 78639/90000 [05:49<00:52, 218.34it/s] 87%|████████▋ | 78662/90000 [05:50<00:52, 217.93it/s] 87%|████████▋ | 78684/90000 [05:50<00:52, 215.60it/s] 87%|████████▋ | 78707/90000 [05:50<00:51, 217.90it/s] 87%|████████▋ | 78730/90000 [05:50<00:51, 218.89it/s] 88%|████████▊ | 78753/90000 [05:50<00:51, 220.08it/s] 88%|████████▊ | 78776/90000 [05:50<00:51, 219.70it/s] 88%|████████▊ | 78798/90000 [05:50<00:51, 218.27it/s] 88%|████████▊ | 78820/90000 [05:50<00:51, 216.30it/s] 88%|████████▊ | 78843/90000 [05:50<00:51, 218.04it/s] 88%|████████▊ | 78866/90000 [05:51<00:50, 219.41it/s] 88%|████████▊ | 78888/90000 [05:51<00:50, 218.91it/s] 88%|████████▊ | 78911/90000 [05:51<00:50, 219.45it/s] 88%|████████▊ | 78934/90000 [05:51<00:50, 220.53it/s] 88%|████████▊ | 78957/90000 [05:51<00:50, 219.81it/s] 88%|████████▊ | 78979/90000 [05:51<00:50, 218.83it/s] 88%|████████▊ | 79001/90000 [05:51<00:50, 218.38it/s] 88%|████████▊ | 79025/90000 [05:51<00:49, 221.39it/s] 88%|████████▊ | 79049/90000 [05:51<00:48, 225.26it/s] 88%|████████▊ | 79072/90000 [05:51<00:49, 222.08it/s] 88%|████████▊ | 79095/90000 [05:52<00:49, 222.54it/s] 88%|████████▊ | 79118/90000 [05:52<00:49, 221.11it/s] 88%|████████▊ | 79141/90000 [05:52<00:48, 222.64it/s] 88%|████████▊ | 79164/90000 [05:52<00:49, 218.35it/s] 88%|████████▊ | 79186/90000 [05:52<00:49, 218.30it/s] 88%|████████▊ | 79210/90000 [05:52<00:48, 222.95it/s] 88%|████████▊ | 79234/90000 [05:52<00:47, 227.57it/s] 88%|████████▊ | 79257/90000 [05:52<00:47, 225.99it/s] 88%|████████▊ | 79280/90000 [05:52<00:47, 225.80it/s] 88%|████████▊ | 79303/90000 [05:52<00:48, 220.17it/s] 88%|████████▊ | 79326/90000 [05:53<00:50, 210.98it/s] 88%|████████▊ | 79348/90000 [05:53<00:50, 211.58it/s] 88%|████████▊ | 79370/90000 [05:53<00:51, 206.50it/s] 88%|████████▊ | 79393/90000 [05:53<00:50, 211.34it/s] 88%|████████▊ | 79416/90000 [05:53<00:49, 213.21it/s] 88%|████████▊ | 79439/90000 [05:53<00:48, 217.39it/s] 88%|████████▊ | 79461/90000 [05:53<00:48, 217.46it/s] 88%|████████▊ | 79483/90000 [05:53<00:48, 216.38it/s] 88%|████████▊ | 79505/90000 [05:53<00:48, 215.58it/s] 88%|████████▊ | 79528/90000 [05:54<00:48, 217.73it/s] 88%|████████▊ | 79550/90000 [05:54<00:48, 213.39it/s] 88%|████████▊ | 79572/90000 [05:54<00:49, 211.10it/s] 88%|████████▊ | 79594/90000 [05:54<00:49, 210.01it/s] 88%|████████▊ | 79617/90000 [05:54<00:48, 213.39it/s] 88%|████████▊ | 79640/90000 [05:54<00:47, 217.82it/s] 89%|████████▊ | 79662/90000 [05:54<00:48, 214.64it/s] 89%|████████▊ | 79684/90000 [05:54<00:48, 212.25it/s] 89%|████████▊ | 79706/90000 [05:54<00:49, 208.88it/s] 89%|████████▊ | 79730/90000 [05:54<00:47, 216.83it/s] 89%|████████▊ | 79752/90000 [05:55<00:47, 214.60it/s] 89%|████████▊ | 79774/90000 [05:55<00:47, 214.23it/s] 89%|████████▊ | 79796/90000 [05:55<00:47, 215.88it/s] 89%|████████▊ | 79818/90000 [05:55<00:47, 216.57it/s] 89%|████████▊ | 79840/90000 [05:55<00:47, 215.56it/s] 89%|████████▊ | 79862/90000 [05:55<00:47, 214.99it/s] 89%|████████▉ | 79884/90000 [05:55<00:46, 216.22it/s] 89%|████████▉ | 79907/90000 [05:55<00:46, 218.96it/s] 89%|████████▉ | 79931/90000 [05:55<00:45, 221.76it/s] 89%|████████▉ | 79954/90000 [05:56<00:45, 221.31it/s] 89%|████████▉ | 79977/90000 [05:56<00:45, 219.72it/s] 89%|████████▉ | 79999/90000 [05:56<00:46, 216.19it/s] 89%|████████▉ | 80021/90000 [05:56<00:46, 213.02it/s] 89%|████████▉ | 80043/90000 [05:56<00:47, 211.43it/s] 89%|████████▉ | 80066/90000 [05:56<00:46, 214.43it/s] 89%|████████▉ | 80088/90000 [05:56<00:46, 211.72it/s] 89%|████████▉ | 80110/90000 [05:56<00:46, 212.62it/s] 89%|████████▉ | 80132/90000 [05:56<00:46, 213.77it/s] 89%|████████▉ | 80154/90000 [05:56<00:46, 209.94it/s] 89%|████████▉ | 80176/90000 [05:57<00:46, 211.93it/s] 89%|████████▉ | 80198/90000 [05:57<00:46, 211.90it/s] 89%|████████▉ | 80222/90000 [05:57<00:45, 217.26it/s] 89%|████████▉ | 80244/90000 [05:57<00:45, 216.43it/s] 89%|████████▉ | 80266/90000 [05:57<00:45, 214.08it/s] 89%|████████▉ | 80288/90000 [05:57<00:45, 213.06it/s] 89%|████████▉ | 80310/90000 [05:57<00:45, 210.70it/s] 89%|████████▉ | 80332/90000 [05:57<00:45, 211.95it/s] 89%|████████▉ | 80354/90000 [05:57<00:45, 211.89it/s] 89%|████████▉ | 80376/90000 [05:57<00:45, 212.54it/s] 89%|████████▉ | 80398/90000 [05:58<00:44, 214.61it/s] 89%|████████▉ | 80420/90000 [05:58<00:45, 212.23it/s] 89%|████████▉ | 80443/90000 [05:58<00:44, 216.35it/s] 89%|████████▉ | 80465/90000 [05:58<00:45, 210.42it/s] 89%|████████▉ | 80487/90000 [05:58<00:44, 212.16it/s] 89%|████████▉ | 80509/90000 [05:58<00:44, 214.12it/s] 89%|████████▉ | 80531/90000 [05:58<00:44, 211.22it/s] 90%|████████▉ | 80553/90000 [05:58<00:45, 205.59it/s] 90%|████████▉ | 80576/90000 [05:58<00:44, 212.26it/s] 90%|████████▉ | 80598/90000 [05:59<00:45, 205.25it/s] 90%|████████▉ | 80619/90000 [05:59<00:45, 205.57it/s] 90%|████████▉ | 80642/90000 [05:59<00:44, 211.39it/s] 90%|████████▉ | 80664/90000 [05:59<00:44, 212.01it/s] 90%|████████▉ | 80686/90000 [05:59<00:43, 212.13it/s] 90%|████████▉ | 80709/90000 [05:59<00:42, 216.11it/s] 90%|████████▉ | 80731/90000 [05:59<00:43, 214.08it/s] 90%|████████▉ | 80754/90000 [05:59<00:42, 216.87it/s] 90%|████████▉ | 80778/90000 [05:59<00:41, 223.53it/s] 90%|████████▉ | 80801/90000 [05:59<00:42, 216.08it/s] 90%|████████▉ | 80824/90000 [06:00<00:41, 220.05it/s] 90%|████████▉ | 80847/90000 [06:00<00:41, 219.25it/s] 90%|████████▉ | 80869/90000 [06:00<00:41, 218.09it/s] 90%|████████▉ | 80893/90000 [06:00<00:40, 224.14it/s] 90%|████████▉ | 80916/90000 [06:00<00:40, 225.59it/s] 90%|████████▉ | 80939/90000 [06:00<00:40, 224.55it/s] 90%|████████▉ | 80962/90000 [06:00<00:40, 225.71it/s] 90%|████████▉ | 80986/90000 [06:00<00:39, 228.29it/s] 90%|█████████ | 81009/90000 [06:00<00:39, 228.14it/s] 90%|█████████ | 81032/90000 [06:01<00:39, 225.99it/s] 90%|█████████ | 81055/90000 [06:01<00:39, 225.21it/s] 90%|█████████ | 81079/90000 [06:01<00:38, 228.76it/s] 90%|█████████ | 81102/90000 [06:01<00:38, 228.28it/s] 90%|█████████ | 81125/90000 [06:01<00:39, 224.73it/s] 90%|█████████ | 81148/90000 [06:01<00:39, 225.21it/s] 90%|█████████ | 81171/90000 [06:01<00:39, 226.31it/s] 90%|█████████ | 81194/90000 [06:01<00:39, 224.65it/s] 90%|█████████ | 81218/90000 [06:01<00:38, 225.71it/s] 90%|█████████ | 81241/90000 [06:01<00:39, 224.50it/s] 90%|█████████ | 81264/90000 [06:02<00:39, 221.57it/s] 90%|█████████ | 81287/90000 [06:02<00:39, 217.84it/s] 90%|█████████ | 81310/90000 [06:02<00:39, 219.63it/s] 90%|█████████ | 81332/90000 [06:02<00:39, 218.18it/s] 90%|█████████ | 81354/90000 [06:02<00:39, 218.50it/s] 90%|█████████ | 81377/90000 [06:02<00:39, 219.24it/s] 90%|█████████ | 81400/90000 [06:02<00:39, 220.23it/s] 90%|█████████ | 81424/90000 [06:02<00:38, 223.39it/s] 90%|█████████ | 81447/90000 [06:02<00:38, 220.83it/s] 91%|█████████ | 81470/90000 [06:02<00:38, 220.22it/s] 91%|█████████ | 81494/90000 [06:03<00:38, 223.00it/s] 91%|█████████ | 81517/90000 [06:03<00:38, 222.77it/s] 91%|█████████ | 81540/90000 [06:03<00:37, 223.46it/s] 91%|█████████ | 81563/90000 [06:03<00:37, 225.20it/s] 91%|█████████ | 81587/90000 [06:03<00:36, 229.08it/s] 91%|█████████ | 81610/90000 [06:03<00:37, 224.14it/s] 91%|█████████ | 81634/90000 [06:03<00:36, 227.85it/s] 91%|█████████ | 81657/90000 [06:03<00:36, 228.47it/s] 91%|█████████ | 81681/90000 [06:03<00:36, 229.73it/s] 91%|█████████ | 81704/90000 [06:04<00:36, 226.50it/s] 91%|█████████ | 81728/90000 [06:04<00:35, 230.09it/s] 91%|█████████ | 81752/90000 [06:04<00:36, 228.57it/s] 91%|█████████ | 81775/90000 [06:04<00:36, 226.22it/s] 91%|█████████ | 81798/90000 [06:04<00:37, 220.54it/s] 91%|█████████ | 81821/90000 [06:04<00:36, 222.68it/s] 91%|█████████ | 81844/90000 [06:04<00:36, 222.10it/s] 91%|█████████ | 81867/90000 [06:04<00:36, 220.67it/s] 91%|█████████ | 81890/90000 [06:04<00:36, 220.86it/s] 91%|█████████ | 81913/90000 [06:04<00:36, 218.72it/s] 91%|█████████ | 81935/90000 [06:05<00:37, 217.16it/s] 91%|█████████ | 81957/90000 [06:05<00:37, 215.10it/s] 91%|█████████ | 81981/90000 [06:05<00:36, 221.89it/s] 91%|█████████ | 82004/90000 [06:05<00:35, 222.51it/s] 91%|█████████ | 82028/90000 [06:05<00:35, 224.60it/s] 91%|█████████ | 82051/90000 [06:05<00:36, 220.62it/s] 91%|█████████ | 82074/90000 [06:05<00:36, 219.26it/s] 91%|█████████ | 82096/90000 [06:05<00:36, 218.71it/s] 91%|█████████ | 82118/90000 [06:05<00:36, 218.03it/s] 91%|█████████▏| 82140/90000 [06:05<00:36, 216.57it/s] 91%|█████████▏| 82164/90000 [06:06<00:35, 221.27it/s] 91%|█████████▏| 82187/90000 [06:06<00:35, 221.13it/s] 91%|█████████▏| 82210/90000 [06:06<00:35, 222.16it/s] 91%|█████████▏| 82233/90000 [06:06<00:35, 220.81it/s] 91%|█████████▏| 82256/90000 [06:06<00:34, 222.62it/s] 91%|█████████▏| 82279/90000 [06:06<00:34, 223.76it/s] 91%|█████████▏| 82302/90000 [06:06<00:34, 223.00it/s] 91%|█████████▏| 82325/90000 [06:06<00:34, 222.56it/s] 91%|█████████▏| 82348/90000 [06:06<00:34, 223.65it/s] 92%|█████████▏| 82371/90000 [06:07<00:34, 220.44it/s] 92%|█████████▏| 82394/90000 [06:07<00:35, 216.71it/s] 92%|█████████▏| 82416/90000 [06:07<00:34, 217.43it/s] 92%|█████████▏| 82438/90000 [06:07<00:35, 215.63it/s] 92%|█████████▏| 82461/90000 [06:07<00:34, 217.72it/s] 92%|█████████▏| 82483/90000 [06:07<00:34, 216.02it/s] 92%|█████████▏| 82505/90000 [06:07<00:34, 214.97it/s] 92%|█████████▏| 82527/90000 [06:07<00:34, 215.41it/s] 92%|█████████▏| 82550/90000 [06:07<00:34, 217.91it/s] 92%|█████████▏| 82572/90000 [06:07<00:34, 217.65it/s] 92%|█████████▏| 82595/90000 [06:08<00:33, 221.04it/s] 92%|█████████▏| 82618/90000 [06:08<00:33, 222.74it/s] 92%|█████████▏| 82641/90000 [06:08<00:33, 220.97it/s] 92%|█████████▏| 82664/90000 [06:08<00:33, 218.58it/s] 92%|█████████▏| 82687/90000 [06:08<00:32, 221.69it/s] 92%|█████████▏| 82712/90000 [06:08<00:32, 227.46it/s] 92%|█████████▏| 82735/90000 [06:08<00:32, 226.44it/s] 92%|█████████▏| 82758/90000 [06:08<00:32, 220.93it/s] 92%|█████████▏| 82781/90000 [06:08<00:32, 222.90it/s] 92%|█████████▏| 82804/90000 [06:08<00:32, 221.72it/s] 92%|█████████▏| 82827/90000 [06:09<00:32, 221.15it/s] 92%|█████████▏| 82850/90000 [06:09<00:32, 219.66it/s] 92%|█████████▏| 82873/90000 [06:09<00:32, 221.18it/s] 92%|█████████▏| 82896/90000 [06:09<00:32, 221.64it/s] 92%|█████████▏| 82919/90000 [06:09<00:32, 220.41it/s] 92%|█████████▏| 82943/90000 [06:09<00:31, 223.03it/s] 92%|█████████▏| 82966/90000 [06:09<00:31, 224.41it/s] 92%|█████████▏| 82990/90000 [06:09<00:30, 226.57it/s] 92%|█████████▏| 83014/90000 [06:09<00:30, 229.59it/s] 92%|█████████▏| 83037/90000 [06:10<00:31, 223.36it/s] 92%|█████████▏| 83060/90000 [06:10<00:30, 224.25it/s] 92%|█████████▏| 83083/90000 [06:10<00:31, 222.36it/s] 92%|█████████▏| 83106/90000 [06:10<00:30, 224.35it/s] 92%|█████████▏| 83129/90000 [06:10<00:30, 224.62it/s] 92%|█████████▏| 83152/90000 [06:10<00:30, 224.93it/s] 92%|█████████▏| 83175/90000 [06:10<00:30, 224.20it/s] 92%|█████████▏| 83199/90000 [06:10<00:29, 228.40it/s] 92%|█████████▏| 83222/90000 [06:10<00:30, 225.35it/s] 92%|█████████▏| 83246/90000 [06:10<00:29, 225.99it/s] 93%|█████████▎| 83269/90000 [06:11<00:29, 226.48it/s] 93%|█████████▎| 83292/90000 [06:11<00:30, 223.57it/s] 93%|█████████▎| 83316/90000 [06:11<00:29, 225.84it/s] 93%|█████████▎| 83339/90000 [06:11<00:29, 225.60it/s] 93%|█████████▎| 83362/90000 [06:11<00:29, 224.75it/s] 93%|█████████▎| 83385/90000 [06:11<00:29, 222.58it/s] 93%|█████████▎| 83408/90000 [06:11<00:29, 220.84it/s] 93%|█████████▎| 83431/90000 [06:11<00:29, 220.77it/s] 93%|█████████▎| 83455/90000 [06:11<00:29, 224.30it/s] 93%|█████████▎| 83478/90000 [06:12<00:29, 222.56it/s] 93%|█████████▎| 83501/90000 [06:12<00:29, 218.94it/s] 93%|█████████▎| 83523/90000 [06:12<00:29, 218.31it/s] 93%|█████████▎| 83546/90000 [06:12<00:29, 220.92it/s] 93%|█████████▎| 83570/90000 [06:12<00:28, 225.21it/s] 93%|█████████▎| 83593/90000 [06:12<00:28, 226.55it/s] 93%|█████████▎| 83616/90000 [06:12<00:28, 225.71it/s] 93%|█████████▎| 83639/90000 [06:12<00:28, 225.82it/s] 93%|█████████▎| 83662/90000 [06:12<00:28, 222.60it/s] 93%|█████████▎| 83685/90000 [06:12<00:28, 222.02it/s] 93%|█████████▎| 83709/90000 [06:13<00:27, 226.67it/s] 93%|█████████▎| 83732/90000 [06:13<00:27, 224.61it/s] 93%|█████████▎| 83756/90000 [06:13<00:27, 228.18it/s] 93%|█████████▎| 83779/90000 [06:13<00:27, 224.09it/s] 93%|█████████▎| 83803/90000 [06:13<00:27, 226.41it/s] 93%|█████████▎| 83826/90000 [06:13<00:27, 223.15it/s] 93%|█████████▎| 83849/90000 [06:13<00:27, 223.82it/s] 93%|█████████▎| 83872/90000 [06:13<00:27, 220.70it/s] 93%|█████████▎| 83895/90000 [06:13<00:27, 220.51it/s] 93%|█████████▎| 83918/90000 [06:13<00:27, 218.71it/s] 93%|█████████▎| 83942/90000 [06:14<00:27, 221.37it/s] 93%|█████████▎| 83965/90000 [06:14<00:27, 216.61it/s] 93%|█████████▎| 83987/90000 [06:14<00:27, 217.34it/s] 93%|█████████▎| 84011/90000 [06:14<00:26, 222.14it/s] 93%|█████████▎| 84034/90000 [06:14<00:27, 215.39it/s] 93%|█████████▎| 84056/90000 [06:14<00:27, 214.10it/s] 93%|█████████▎| 84078/90000 [06:14<00:27, 215.60it/s] 93%|█████████▎| 84102/90000 [06:14<00:26, 220.14it/s] 93%|█████████▎| 84126/90000 [06:14<00:26, 225.71it/s] 94%|█████████▎| 84150/90000 [06:15<00:25, 227.63it/s] 94%|█████████▎| 84173/90000 [06:15<00:25, 227.41it/s] 94%|█████████▎| 84196/90000 [06:15<00:25, 227.41it/s] 94%|█████████▎| 84219/90000 [06:15<00:25, 225.74it/s] 94%|█████████▎| 84243/90000 [06:15<00:25, 228.58it/s] 94%|█████████▎| 84266/90000 [06:15<00:25, 227.88it/s] 94%|█████████▎| 84289/90000 [06:15<00:25, 227.95it/s] 94%|█████████▎| 84312/90000 [06:15<00:25, 225.81it/s] 94%|█████████▎| 84335/90000 [06:15<00:25, 224.50it/s] 94%|█████████▎| 84359/90000 [06:15<00:24, 226.11it/s] 94%|█████████▍| 84382/90000 [06:16<00:24, 225.54it/s] 94%|█████████▍| 84405/90000 [06:16<00:25, 221.99it/s] 94%|█████████▍| 84428/90000 [06:16<00:25, 214.57it/s] 94%|█████████▍| 84451/90000 [06:16<00:25, 217.40it/s] 94%|█████████▍| 84473/90000 [06:16<00:25, 217.19it/s] 94%|█████████▍| 84496/90000 [06:16<00:24, 220.38it/s] 94%|█████████▍| 84519/90000 [06:16<00:24, 222.96it/s] 94%|█████████▍| 84543/90000 [06:16<00:23, 227.92it/s] 94%|█████████▍| 84566/90000 [06:16<00:23, 227.22it/s] 94%|█████████▍| 84589/90000 [06:16<00:23, 227.59it/s] 94%|█████████▍| 84612/90000 [06:17<00:24, 223.66it/s] 94%|█████████▍| 84635/90000 [06:17<00:23, 223.82it/s] 94%|█████████▍| 84659/90000 [06:17<00:23, 227.80it/s] 94%|█████████▍| 84683/90000 [06:17<00:23, 229.38it/s] 94%|█████████▍| 84706/90000 [06:17<00:23, 226.17it/s] 94%|█████████▍| 84729/90000 [06:17<00:23, 222.67it/s] 94%|█████████▍| 84753/90000 [06:17<00:23, 225.29it/s] 94%|█████████▍| 84777/90000 [06:17<00:22, 227.21it/s] 94%|█████████▍| 84800/90000 [06:17<00:22, 227.73it/s] 94%|█████████▍| 84824/90000 [06:18<00:22, 228.65it/s] 94%|█████████▍| 84847/90000 [06:18<00:22, 224.08it/s] 94%|█████████▍| 84870/90000 [06:18<00:23, 222.82it/s] 94%|█████████▍| 84893/90000 [06:18<00:22, 224.03it/s] 94%|█████████▍| 84916/90000 [06:18<00:23, 220.97it/s] 94%|█████████▍| 84939/90000 [06:18<00:22, 221.16it/s] 94%|█████████▍| 84962/90000 [06:18<00:22, 219.10it/s] 94%|█████████▍| 84984/90000 [06:18<00:22, 219.31it/s] 94%|█████████▍| 85009/90000 [06:18<00:22, 225.88it/s] 94%|█████████▍| 85032/90000 [06:18<00:22, 224.89it/s] 95%|█████████▍| 85055/90000 [06:19<00:22, 222.91it/s] 95%|█████████▍| 85079/90000 [06:19<00:21, 226.69it/s] 95%|█████████▍| 85102/90000 [06:19<00:21, 225.16it/s] 95%|█████████▍| 85125/90000 [06:19<00:21, 223.14it/s] 95%|█████████▍| 85149/90000 [06:19<00:21, 227.48it/s] 95%|█████████▍| 85173/90000 [06:19<00:21, 228.63it/s] 95%|█████████▍| 85196/90000 [06:19<00:21, 227.36it/s] 95%|█████████▍| 85219/90000 [06:19<00:21, 225.54it/s] 95%|█████████▍| 85242/90000 [06:19<00:21, 225.25it/s] 95%|█████████▍| 85265/90000 [06:19<00:20, 225.92it/s] 95%|█████████▍| 85288/90000 [06:20<00:21, 223.51it/s] 95%|█████████▍| 85311/90000 [06:20<00:21, 221.69it/s] 95%|█████████▍| 85335/90000 [06:20<00:20, 226.29it/s] 95%|█████████▍| 85358/90000 [06:20<00:20, 224.41it/s] 95%|█████████▍| 85381/90000 [06:20<00:20, 225.16it/s] 95%|█████████▍| 85404/90000 [06:20<00:20, 222.17it/s] 95%|█████████▍| 85427/90000 [06:20<00:20, 222.50it/s] 95%|█████████▍| 85450/90000 [06:20<00:20, 222.91it/s] 95%|█████████▍| 85473/90000 [06:20<00:20, 220.99it/s] 95%|█████████▍| 85497/90000 [06:21<00:20, 223.73it/s] 95%|█████████▌| 85520/90000 [06:21<00:20, 222.72it/s] 95%|█████████▌| 85543/90000 [06:21<00:20, 221.72it/s] 95%|█████████▌| 85566/90000 [06:21<00:20, 217.53it/s] 95%|█████████▌| 85588/90000 [06:21<00:20, 216.69it/s] 95%|█████████▌| 85610/90000 [06:21<00:20, 215.36it/s] 95%|█████████▌| 85634/90000 [06:21<00:19, 219.94it/s] 95%|█████████▌| 85657/90000 [06:21<00:19, 221.80it/s] 95%|█████████▌| 85680/90000 [06:21<00:19, 219.59it/s] 95%|█████████▌| 85703/90000 [06:21<00:19, 221.30it/s] 95%|█████████▌| 85726/90000 [06:22<00:19, 219.48it/s] 95%|█████████▌| 85749/90000 [06:22<00:19, 220.72it/s] 95%|█████████▌| 85772/90000 [06:22<00:19, 218.21it/s] 95%|█████████▌| 85794/90000 [06:22<00:19, 217.00it/s] 95%|█████████▌| 85818/90000 [06:22<00:18, 223.21it/s] 95%|█████████▌| 85841/90000 [06:22<00:18, 221.82it/s] 95%|█████████▌| 85864/90000 [06:22<00:18, 220.06it/s] 95%|█████████▌| 85887/90000 [06:22<00:18, 218.59it/s] 95%|█████████▌| 85910/90000 [06:22<00:18, 220.32it/s] 95%|█████████▌| 85934/90000 [06:23<00:18, 223.87it/s] 96%|█████████▌| 85958/90000 [06:23<00:17, 225.91it/s] 96%|█████████▌| 85983/90000 [06:23<00:17, 230.94it/s] 96%|█████████▌| 86007/90000 [06:23<00:17, 228.40it/s] 96%|█████████▌| 86031/90000 [06:23<00:17, 229.85it/s] 96%|█████████▌| 86055/90000 [06:23<00:17, 231.68it/s] 96%|█████████▌| 86079/90000 [06:23<00:17, 227.96it/s] 96%|█████████▌| 86102/90000 [06:23<00:17, 228.50it/s] 96%|█████████▌| 86126/90000 [06:23<00:16, 231.42it/s] 96%|█████████▌| 86150/90000 [06:23<00:16, 229.55it/s] 96%|█████████▌| 86174/90000 [06:24<00:16, 230.29it/s] 96%|█████████▌| 86198/90000 [06:24<00:16, 228.06it/s] 96%|█████████▌| 86221/90000 [06:24<00:16, 228.57it/s] 96%|█████████▌| 86245/90000 [06:24<00:16, 229.68it/s] 96%|█████████▌| 86268/90000 [06:24<00:16, 225.56it/s] 96%|█████████▌| 86292/90000 [06:24<00:16, 226.98it/s] 96%|█████████▌| 86316/90000 [06:24<00:16, 228.09it/s] 96%|█████████▌| 86339/90000 [06:24<00:16, 225.91it/s] 96%|█████████▌| 86363/90000 [06:24<00:16, 227.09it/s] 96%|█████████▌| 86386/90000 [06:24<00:15, 226.39it/s] 96%|█████████▌| 86409/90000 [06:25<00:15, 226.46it/s] 96%|█████████▌| 86432/90000 [06:25<00:15, 226.91it/s] 96%|█████████▌| 86455/90000 [06:25<00:15, 227.33it/s] 96%|█████████▌| 86480/90000 [06:25<00:15, 230.76it/s] 96%|█████████▌| 86504/90000 [06:25<00:15, 224.13it/s] 96%|█████████▌| 86527/90000 [06:25<00:15, 225.13it/s] 96%|█████████▌| 86550/90000 [06:25<00:15, 224.50it/s] 96%|█████████▌| 86575/90000 [06:25<00:14, 230.45it/s] 96%|█████████▌| 86599/90000 [06:25<00:14, 230.11it/s] 96%|█████████▌| 86623/90000 [06:26<00:14, 230.67it/s] 96%|█████████▋| 86647/90000 [06:26<00:14, 233.32it/s] 96%|█████████▋| 86671/90000 [06:26<00:14, 226.56it/s] 96%|█████████▋| 86694/90000 [06:26<00:14, 223.11it/s] 96%|█████████▋| 86718/90000 [06:26<00:14, 226.64it/s] 96%|█████████▋| 86741/90000 [06:26<00:14, 226.66it/s] 96%|█████████▋| 86765/90000 [06:26<00:14, 228.22it/s] 96%|█████████▋| 86790/90000 [06:26<00:13, 231.99it/s] 96%|█████████▋| 86814/90000 [06:26<00:13, 233.13it/s] 96%|█████████▋| 86838/90000 [06:26<00:13, 228.70it/s] 97%|█████████▋| 86862/90000 [06:27<00:13, 230.19it/s] 97%|█████████▋| 86886/90000 [06:27<00:13, 232.86it/s] 97%|█████████▋| 86910/90000 [06:27<00:13, 229.59it/s] 97%|█████████▋| 86934/90000 [06:27<00:13, 230.63it/s] 97%|█████████▋| 86958/90000 [06:27<00:13, 229.10it/s] 97%|█████████▋| 86981/90000 [06:27<00:13, 226.99it/s] 97%|█████████▋| 87004/90000 [06:27<00:13, 225.11it/s] 97%|█████████▋| 87027/90000 [06:27<00:13, 225.64it/s] 97%|█████████▋| 87050/90000 [06:27<00:13, 224.17it/s] 97%|█████████▋| 87073/90000 [06:28<00:13, 224.53it/s] 97%|█████████▋| 87096/90000 [06:28<00:13, 222.90it/s] 97%|█████████▋| 87120/90000 [06:28<00:12, 226.25it/s] 97%|█████████▋| 87143/90000 [06:28<00:12, 224.48it/s] 97%|█████████▋| 87166/90000 [06:28<00:12, 225.28it/s] 97%|█████████▋| 87190/90000 [06:28<00:12, 228.67it/s] 97%|█████████▋| 87215/90000 [06:28<00:11, 233.33it/s] 97%|█████████▋| 87239/90000 [06:28<00:11, 233.64it/s] 97%|█████████▋| 87263/90000 [06:28<00:11, 234.91it/s] 97%|█████████▋| 87287/90000 [06:28<00:11, 232.58it/s] 97%|█████████▋| 87311/90000 [06:29<00:11, 229.17it/s] 97%|█████████▋| 87334/90000 [06:29<00:11, 228.42it/s] 97%|█████████▋| 87358/90000 [06:29<00:11, 230.32it/s] 97%|█████████▋| 87382/90000 [06:29<00:11, 228.62it/s] 97%|█████████▋| 87405/90000 [06:29<00:11, 227.87it/s] 97%|█████████▋| 87430/90000 [06:29<00:11, 230.82it/s] 97%|█████████▋| 87454/90000 [06:29<00:11, 231.23it/s] 97%|█████████▋| 87478/90000 [06:29<00:10, 229.88it/s] 97%|█████████▋| 87501/90000 [06:29<00:10, 229.13it/s] 97%|█████████▋| 87524/90000 [06:29<00:10, 226.96it/s] 97%|█████████▋| 87547/90000 [06:30<00:10, 227.44it/s] 97%|█████████▋| 87570/90000 [06:30<00:10, 225.93it/s] 97%|█████████▋| 87594/90000 [06:30<00:10, 229.70it/s] 97%|█████████▋| 87617/90000 [06:30<00:10, 228.34it/s] 97%|█████████▋| 87640/90000 [06:30<00:10, 226.42it/s] 97%|█████████▋| 87663/90000 [06:30<00:10, 225.79it/s] 97%|█████████▋| 87686/90000 [06:30<00:10, 225.55it/s] 97%|█████████▋| 87711/90000 [06:30<00:09, 231.41it/s] 97%|█████████▋| 87735/90000 [06:30<00:09, 233.23it/s] 98%|█████████▊| 87759/90000 [06:31<00:09, 229.42it/s] 98%|█████████▊| 87782/90000 [06:31<00:09, 226.82it/s] 98%|█████████▊| 87806/90000 [06:31<00:09, 227.88it/s] 98%|█████████▊| 87829/90000 [06:31<00:09, 228.15it/s] 98%|█████████▊| 87852/90000 [06:31<00:09, 227.91it/s] 98%|█████████▊| 87876/90000 [06:31<00:09, 230.64it/s] 98%|█████████▊| 87900/90000 [06:31<00:09, 232.03it/s] 98%|█████████▊| 87925/90000 [06:31<00:08, 234.86it/s] 98%|█████████▊| 87949/90000 [06:31<00:08, 234.39it/s] 98%|█████████▊| 87973/90000 [06:31<00:08, 228.03it/s] 98%|█████████▊| 87997/90000 [06:32<00:08, 229.02it/s] 98%|█████████▊| 88020/90000 [06:32<00:08, 225.76it/s] 98%|█████████▊| 88045/90000 [06:32<00:08, 232.49it/s] 98%|█████████▊| 88069/90000 [06:32<00:08, 232.83it/s] 98%|█████████▊| 88093/90000 [06:32<00:08, 230.88it/s] 98%|█████████▊| 88117/90000 [06:32<00:08, 227.77it/s] 98%|█████████▊| 88142/90000 [06:32<00:07, 232.93it/s] 98%|█████████▊| 88166/90000 [06:32<00:08, 228.95it/s] 98%|█████████▊| 88189/90000 [06:32<00:07, 227.54it/s] 98%|█████████▊| 88212/90000 [06:32<00:07, 224.15it/s] 98%|█████████▊| 88236/90000 [06:33<00:07, 228.14it/s] 98%|█████████▊| 88261/90000 [06:33<00:07, 232.51it/s] 98%|█████████▊| 88286/90000 [06:33<00:07, 235.84it/s] 98%|█████████▊| 88310/90000 [06:33<00:07, 233.95it/s] 98%|█████████▊| 88334/90000 [06:33<00:07, 230.80it/s] 98%|█████████▊| 88358/90000 [06:33<00:07, 229.49it/s] 98%|█████████▊| 88382/90000 [06:33<00:06, 231.34it/s] 98%|█████████▊| 88406/90000 [06:33<00:06, 232.88it/s] 98%|█████████▊| 88430/90000 [06:33<00:06, 225.71it/s] 98%|█████████▊| 88453/90000 [06:34<00:06, 226.50it/s] 98%|█████████▊| 88476/90000 [06:34<00:06, 223.26it/s] 98%|█████████▊| 88500/90000 [06:34<00:06, 228.01it/s] 98%|█████████▊| 88524/90000 [06:34<00:06, 230.01it/s] 98%|█████████▊| 88548/90000 [06:34<00:06, 229.89it/s] 98%|█████████▊| 88572/90000 [06:34<00:06, 228.17it/s] 98%|█████████▊| 88595/90000 [06:34<00:06, 226.47it/s] 98%|█████████▊| 88619/90000 [06:34<00:06, 229.76it/s] 98%|█████████▊| 88643/90000 [06:34<00:05, 230.30it/s] 99%|█████████▊| 88667/90000 [06:34<00:05, 228.15it/s] 99%|█████████▊| 88690/90000 [06:35<00:05, 224.37it/s] 99%|█████████▊| 88713/90000 [06:35<00:05, 223.64it/s] 99%|█████████▊| 88736/90000 [06:35<00:05, 222.45it/s] 99%|█████████▊| 88761/90000 [06:35<00:05, 229.45it/s] 99%|█████████▊| 88785/90000 [06:35<00:05, 232.50it/s] 99%|█████████▊| 88809/90000 [06:35<00:05, 231.49it/s] 99%|█████████▊| 88834/90000 [06:35<00:04, 235.26it/s] 99%|█████████▊| 88858/90000 [06:35<00:04, 232.47it/s] 99%|█████████▉| 88882/90000 [06:35<00:04, 234.38it/s] 99%|█████████▉| 88907/90000 [06:35<00:04, 236.44it/s] 99%|█████████▉| 88931/90000 [06:36<00:04, 234.87it/s] 99%|█████████▉| 88955/90000 [06:36<00:04, 233.62it/s] 99%|█████████▉| 88979/90000 [06:36<00:04, 229.87it/s] 99%|█████████▉| 89003/90000 [06:36<00:04, 227.38it/s] 99%|█████████▉| 89027/90000 [06:36<00:04, 230.41it/s] 99%|█████████▉| 89051/90000 [06:36<00:04, 231.18it/s] 99%|█████████▉| 89077/90000 [06:36<00:03, 238.34it/s] 99%|█████████▉| 89101/90000 [06:36<00:03, 236.01it/s] 99%|█████████▉| 89125/90000 [06:36<00:03, 234.23it/s] 99%|█████████▉| 89149/90000 [06:37<00:03, 232.73it/s] 99%|█████████▉| 89173/90000 [06:37<00:03, 229.41it/s] 99%|█████████▉| 89196/90000 [06:37<00:03, 228.32it/s] 99%|█████████▉| 89219/90000 [06:37<00:03, 228.12it/s] 99%|█████████▉| 89243/90000 [06:37<00:03, 229.89it/s] 99%|█████████▉| 89266/90000 [06:37<00:03, 227.54it/s] 99%|█████████▉| 89290/90000 [06:37<00:03, 228.04it/s] 99%|█████████▉| 89314/90000 [06:37<00:02, 230.72it/s] 99%|█████████▉| 89338/90000 [06:37<00:02, 229.87it/s] 99%|█████████▉| 89362/90000 [06:37<00:02, 231.68it/s] 99%|█████████▉| 89386/90000 [06:38<00:02, 232.11it/s] 99%|█████████▉| 89410/90000 [06:38<00:02, 232.91it/s] 99%|█████████▉| 89434/90000 [06:38<00:02, 232.42it/s] 99%|█████████▉| 89458/90000 [06:38<00:02, 228.31it/s] 99%|█████████▉| 89483/90000 [06:38<00:02, 231.73it/s] 99%|█████████▉| 89507/90000 [06:38<00:02, 225.77it/s] 99%|█████████▉| 89532/90000 [06:38<00:02, 230.17it/s]100%|█████████▉| 89556/90000 [06:38<00:01, 230.59it/s]100%|█████████▉| 89580/90000 [06:38<00:01, 226.15it/s]100%|█████████▉| 89603/90000 [06:39<00:01, 225.97it/s]100%|█████████▉| 89627/90000 [06:39<00:01, 229.22it/s]100%|█████████▉| 89650/90000 [06:39<00:01, 227.87it/s]100%|█████████▉| 89674/90000 [06:39<00:01, 230.84it/s]100%|█████████▉| 89698/90000 [06:39<00:01, 227.52it/s]100%|█████████▉| 89722/90000 [06:39<00:01, 229.02it/s]100%|█████████▉| 89746/90000 [06:39<00:01, 229.06it/s]100%|█████████▉| 89770/90000 [06:39<00:00, 230.99it/s]100%|█████████▉| 89794/90000 [06:39<00:00, 230.03it/s]100%|█████████▉| 89818/90000 [06:39<00:00, 225.48it/s]100%|█████████▉| 89842/90000 [06:40<00:00, 229.14it/s]100%|█████████▉| 89865/90000 [06:40<00:00, 227.85it/s]100%|█████████▉| 89888/90000 [06:40<00:00, 223.55it/s]100%|█████████▉| 89912/90000 [06:40<00:00, 226.08it/s]100%|█████████▉| 89935/90000 [06:40<00:00, 222.27it/s]100%|█████████▉| 89958/90000 [06:40<00:00, 222.83it/s]100%|█████████▉| 89982/90000 [06:40<00:00, 227.70it/s]100%|██████████| 90000/90000 [06:40<00:00, 224.57it/s]Nestedspace(activation='elu', apply_unconditional_transform=False, base_transform_type='rq-coupling', basis_dir='data/GW170104_sample_prior_basis/', batch_norm=True, batch_size=2048, bw_dstar=None, cuda=True, data_dir='data/GW170104_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, dropout_probability=0.0, epochs=10000, flow_lr=None, hidden_dims=512, kl_annealing=True, lr=0.0002, lr_anneal_method='cosine', lr_annealing=True, mixed_alpha=0.15, mode='train', model_dir='models3/GW170104_sample_uniform_100basis_all_mixed_prior_a015/', model_source='new', model_type='nde', nbins=8, nflows=15, nsample=100000, nsamples_target_event=50000, num_transform_blocks=10, output_freq=10, sampling_from='mixed', save=True, save_aux_filename='waveforms_supplementary.hdf5', save_model_name='model.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, tail_bound=1.0, truncate_basis=100)
Waveform directory data/GW170104_sample_prior_basis/
Model directory models3/GW170104_sample_uniform_100basis_all_mixed_prior_a015/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Detectors: ['H1', 'L1']

Constructing model of type nde

Initial learning rate 0.0002
Using cosine LR annealing.

Model hyperparameters:
input_dim 	 15
num_flow_steps 	 15
context_dim 	 400
base_transform_kwargs
	 hidden_dim 	 512
	 num_transform_blocks 	 10
	 activation 	 elu
	 dropout_probability 	 0.0
	 batch_norm 	 True
	 num_bins 	 8
	 tail_bound 	 1.0
	 apply_unconditional_transform 	 False
	 base_transform_type 	 rq-coupling

Training for 10000 epochs
Starting timer
Learning rate: 0.0002

Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 27.2967	Cost: 24.49s
Train Epoch: 1 [20480/90000 (23%)]	Loss: 22.0061	Cost: 6.13s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 21.3752	Cost: 6.17s
Train Epoch: 1 [61440/90000 (68%)]	Loss: 21.3012	Cost: 6.03s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 21.1856	Cost: 5.89s
Train Epoch: 1 	Average Loss: 21.8227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2765

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999999506519785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 21.1275	Cost: 25.30s
Train Epoch: 2 [20480/90000 (23%)]	Loss: 21.0695	Cost: 6.15s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 21.0095	Cost: 6.30s
Train Epoch: 2 [61440/90000 (68%)]	Loss: 20.9760	Cost: 6.00s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 20.9204	Cost: 5.98s
Train Epoch: 2 	Average Loss: 21.0482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0891

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019999998026079186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 20.9070	Cost: 27.33s
Train Epoch: 3 [20480/90000 (23%)]	Loss: 20.8437	Cost: 6.11s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 20.8043	Cost: 6.21s
Train Epoch: 3 [61440/90000 (68%)]	Loss: 20.8745	Cost: 5.94s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 20.8329	Cost: 5.89s
Train Epoch: 3 	Average Loss: 20.8630
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9358

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019999995558678347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 20.8242	Cost: 23.90s
Train Epoch: 4 [20480/90000 (23%)]	Loss: 20.7635	Cost: 6.20s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 20.7690	Cost: 6.21s
Train Epoch: 4 [61440/90000 (68%)]	Loss: 20.7623	Cost: 5.98s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 20.7911	Cost: 5.88s
Train Epoch: 4 	Average Loss: 20.7559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8628

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.0001999999210431752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 20.6553	Cost: 22.10s
Train Epoch: 5 [20480/90000 (23%)]	Loss: 20.7953	Cost: 6.25s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 20.6679	Cost: 6.29s
Train Epoch: 5 [61440/90000 (68%)]	Loss: 20.6699	Cost: 6.08s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 20.6353	Cost: 5.89s
Train Epoch: 5 	Average Loss: 20.6535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7660

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.00019999987662997035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 20.5996	Cost: 26.92s
Train Epoch: 6 [20480/90000 (23%)]	Loss: 20.5546	Cost: 6.14s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 20.5300	Cost: 6.44s
Train Epoch: 6 [61440/90000 (68%)]	Loss: 20.5466	Cost: 6.05s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 20.3960	Cost: 6.20s
Train Epoch: 6 	Average Loss: 20.5280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6282

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019999982234717337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 20.4192	Cost: 24.82s
Train Epoch: 7 [20480/90000 (23%)]	Loss: 20.4316	Cost: 6.37s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 20.3834	Cost: 6.22s
Train Epoch: 7 [61440/90000 (68%)]	Loss: 20.3817	Cost: 6.08s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 20.2586	Cost: 5.90s
Train Epoch: 7 	Average Loss: 20.3735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4695

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.0001999997581947896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 20.2904	Cost: 23.17s
Train Epoch: 8 [20480/90000 (23%)]	Loss: 20.2393	Cost: 6.32s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 20.3028	Cost: 6.26s
Train Epoch: 8 [61440/90000 (68%)]	Loss: 20.2877	Cost: 6.21s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 20.2482	Cost: 6.18s
Train Epoch: 8 	Average Loss: 20.2813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4244

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.0001999996841728254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 20.1212	Cost: 22.55s
Train Epoch: 9 [20480/90000 (23%)]	Loss: 20.1821	Cost: 6.36s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 20.2239	Cost: 6.27s
Train Epoch: 9 [61440/90000 (68%)]	Loss: 20.0938	Cost: 6.07s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 19.9923	Cost: 5.97s
Train Epoch: 9 	Average Loss: 20.1689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2536

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019999960028128805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 19.9809	Cost: 23.28s
Train Epoch: 10 [20480/90000 (23%)]	Loss: 20.1180	Cost: 6.17s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 20.0638	Cost: 6.20s
Train Epoch: 10 [61440/90000 (68%)]	Loss: 20.1917	Cost: 6.36s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 20.0127	Cost: 6.17s
Train Epoch: 10 	Average Loss: 20.0607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2369

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 0.00019999950652018584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 20.0577	Cost: 23.92s
Train Epoch: 11 [20480/90000 (23%)]	Loss: 20.0445	Cost: 6.16s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 20.0424	Cost: 6.21s
Train Epoch: 11 [61440/90000 (68%)]	Loss: 19.9842	Cost: 6.09s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 19.8317	Cost: 5.91s
Train Epoch: 11 	Average Loss: 19.9920
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1736

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 0.00019999940288952797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 19.8373	Cost: 22.40s
Train Epoch: 12 [20480/90000 (23%)]	Loss: 19.9046	Cost: 7.17s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 19.8019	Cost: 6.14s
Train Epoch: 12 [61440/90000 (68%)]	Loss: 19.9180	Cost: 6.07s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 19.7862	Cost: 6.01s
Train Epoch: 12 	Average Loss: 19.8889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0860

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 0.00019999928938932473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 19.8983	Cost: 21.64s
Train Epoch: 13 [20480/90000 (23%)]	Loss: 19.7171	Cost: 6.33s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 19.8363	Cost: 6.23s
Train Epoch: 13 [61440/90000 (68%)]	Loss: 19.7353	Cost: 6.14s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 19.6298	Cost: 6.11s
Train Epoch: 13 	Average Loss: 19.7953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9777

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Learning rate: 0.0001999991660195873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 19.6645	Cost: 21.21s
Train Epoch: 14 [20480/90000 (23%)]	Loss: 19.7219	Cost: 6.38s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 19.6485	Cost: 6.25s
Train Epoch: 14 [61440/90000 (68%)]	Loss: 19.6871	Cost: 6.06s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 19.6198	Cost: 6.03s
Train Epoch: 14 	Average Loss: 19.6837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9107

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Learning rate: 0.0001999990327803279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 19.7058	Cost: 19.50s
Train Epoch: 15 [20480/90000 (23%)]	Loss: 19.6459	Cost: 6.32s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 19.5665	Cost: 6.23s
Train Epoch: 15 [61440/90000 (68%)]	Loss: 19.6288	Cost: 6.11s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 19.5688	Cost: 6.03s
Train Epoch: 15 	Average Loss: 19.6045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7384

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Learning rate: 0.00019999888967155963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 19.5458	Cost: 20.54s
Train Epoch: 16 [20480/90000 (23%)]	Loss: 19.4266	Cost: 6.22s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 19.5446	Cost: 6.15s
Train Epoch: 16 [61440/90000 (68%)]	Loss: 19.4513	Cost: 5.94s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 19.3782	Cost: 5.96s
Train Epoch: 16 	Average Loss: 19.5172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7582

Learning rate: 0.0001999987366932966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 19.4268	Cost: 19.69s
Train Epoch: 17 [20480/90000 (23%)]	Loss: 19.6112	Cost: 6.13s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 19.4047	Cost: 6.32s
Train Epoch: 17 [61440/90000 (68%)]	Loss: 19.3312	Cost: 6.22s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 19.4483	Cost: 6.00s
Train Epoch: 17 	Average Loss: 19.4467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6224

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Learning rate: 0.00019999857384555393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 19.2665	Cost: 19.71s
Train Epoch: 18 [20480/90000 (23%)]	Loss: 19.3074	Cost: 6.09s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 19.4332	Cost: 6.39s
Train Epoch: 18 [61440/90000 (68%)]	Loss: 19.3399	Cost: 6.15s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 19.5054	Cost: 5.98s
Train Epoch: 18 	Average Loss: 19.3495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5345

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Learning rate: 0.0001999984011283477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 19.3173	Cost: 18.54s
Train Epoch: 19 [20480/90000 (23%)]	Loss: 19.3643	Cost: 6.07s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 19.2398	Cost: 6.15s
Train Epoch: 19 [61440/90000 (68%)]	Loss: 19.2189	Cost: 6.06s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 19.1876	Cost: 6.13s
Train Epoch: 19 	Average Loss: 19.2854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4566

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Learning rate: 0.00019999821854169497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 19.2300	Cost: 18.88s
Train Epoch: 20 [20480/90000 (23%)]	Loss: 19.3655	Cost: 6.14s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 19.2559	Cost: 6.57s
Train Epoch: 20 [61440/90000 (68%)]	Loss: 19.2065	Cost: 6.13s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 19.0252	Cost: 7.10s
Train Epoch: 20 	Average Loss: 19.2095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3943

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Learning rate: 0.00019999802608561374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 19.0627	Cost: 19.37s
Train Epoch: 21 [20480/90000 (23%)]	Loss: 19.1816	Cost: 5.96s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 19.0713	Cost: 6.00s
Train Epoch: 21 [61440/90000 (68%)]	Loss: 19.1550	Cost: 5.96s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 19.1158	Cost: 6.89s
Train Epoch: 21 	Average Loss: 19.1491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3500

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Learning rate: 0.000199997823760123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 18.9976	Cost: 19.44s
Train Epoch: 22 [20480/90000 (23%)]	Loss: 19.0472	Cost: 6.03s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 19.1883	Cost: 6.31s
Train Epoch: 22 [61440/90000 (68%)]	Loss: 19.1477	Cost: 6.08s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 18.9410	Cost: 6.72s
Train Epoch: 22 	Average Loss: 19.0726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2994

Saving model as e22_model.pt & e22_waveforms_supplementary.hdf5
Learning rate: 0.00019999761156524272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 19.0669	Cost: 20.03s
Train Epoch: 23 [20480/90000 (23%)]	Loss: 18.9073	Cost: 6.00s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 19.0288	Cost: 6.06s
Train Epoch: 23 [61440/90000 (68%)]	Loss: 19.1447	Cost: 6.04s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 18.9180	Cost: 6.71s
Train Epoch: 23 	Average Loss: 19.0020
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3068

Learning rate: 0.00019999738950099387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 18.9996	Cost: 19.77s
Train Epoch: 24 [20480/90000 (23%)]	Loss: 18.9972	Cost: 6.00s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 18.9996	Cost: 6.03s
Train Epoch: 24 [61440/90000 (68%)]	Loss: 19.0388	Cost: 5.89s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 18.8794	Cost: 5.93s
Train Epoch: 24 	Average Loss: 18.9522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1847

Saving model as e24_model.pt & e24_waveforms_supplementary.hdf5
Learning rate: 0.00019999715756739833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 18.9649	Cost: 18.95s
Train Epoch: 25 [20480/90000 (23%)]	Loss: 18.9573	Cost: 6.06s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 18.8148	Cost: 6.16s
Train Epoch: 25 [61440/90000 (68%)]	Loss: 18.7604	Cost: 6.07s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 18.8200	Cost: 5.88s
Train Epoch: 25 	Average Loss: 18.8824
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1383

Saving model as e25_model.pt & e25_waveforms_supplementary.hdf5
Learning rate: 0.000199996915764479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 18.8680	Cost: 19.22s
Train Epoch: 26 [20480/90000 (23%)]	Loss: 19.0613	Cost: 6.03s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 18.8925	Cost: 6.01s
Train Epoch: 26 [61440/90000 (68%)]	Loss: 18.8267	Cost: 5.94s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 18.7064	Cost: 5.84s
Train Epoch: 26 	Average Loss: 18.8069
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1069

Saving model as e26_model.pt & e26_waveforms_supplementary.hdf5
Learning rate: 0.00019999666409225975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 18.8869	Cost: 19.62s
Train Epoch: 27 [20480/90000 (23%)]	Loss: 18.6244	Cost: 6.02s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 18.8710	Cost: 6.06s
Train Epoch: 27 [61440/90000 (68%)]	Loss: 18.7497	Cost: 5.94s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 18.7535	Cost: 5.82s
Train Epoch: 27 	Average Loss: 18.7758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0760

Saving model as e27_model.pt & e27_waveforms_supplementary.hdf5
Learning rate: 0.00019999640255076543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 18.6911	Cost: 19.80s
Train Epoch: 28 [20480/90000 (23%)]	Loss: 18.6911	Cost: 6.11s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 18.5920	Cost: 6.26s
Train Epoch: 28 [61440/90000 (68%)]	Loss: 18.7005	Cost: 5.86s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 18.8239	Cost: 5.88s
Train Epoch: 28 	Average Loss: 18.7324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0389

Saving model as e28_model.pt & e28_waveforms_supplementary.hdf5
Learning rate: 0.00019999613114002186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 18.6569	Cost: 19.59s
Train Epoch: 29 [20480/90000 (23%)]	Loss: 18.7422	Cost: 6.15s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 18.8333	Cost: 6.07s
Train Epoch: 29 [61440/90000 (68%)]	Loss: 18.7305	Cost: 6.01s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 18.6116	Cost: 5.84s
Train Epoch: 29 	Average Loss: 18.7113
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9834

Saving model as e29_model.pt & e29_waveforms_supplementary.hdf5
Learning rate: 0.0001999958498600558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 18.4411	Cost: 20.79s
Train Epoch: 30 [20480/90000 (23%)]	Loss: 18.5922	Cost: 6.03s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 18.6366	Cost: 6.06s
Train Epoch: 30 [61440/90000 (68%)]	Loss: 18.6891	Cost: 5.92s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 18.6466	Cost: 6.09s
Train Epoch: 30 	Average Loss: 18.6229
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9144

Saving model as e30_model.pt & e30_waveforms_supplementary.hdf5
Learning rate: 0.000199995558710895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 18.5657	Cost: 19.57s
Train Epoch: 31 [20480/90000 (23%)]	Loss: 18.5316	Cost: 6.14s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 18.6685	Cost: 6.09s
Train Epoch: 31 [61440/90000 (68%)]	Loss: 18.5139	Cost: 5.97s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 18.5527	Cost: 5.85s
Train Epoch: 31 	Average Loss: 18.5640
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8842

Saving model as e31_model.pt & e31_waveforms_supplementary.hdf5
Learning rate: 0.00019999525769256825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 18.5838	Cost: 20.61s
Train Epoch: 32 [20480/90000 (23%)]	Loss: 18.4176	Cost: 6.09s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 18.6037	Cost: 6.29s
Train Epoch: 32 [61440/90000 (68%)]	Loss: 18.3363	Cost: 5.90s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 18.4037	Cost: 5.91s
Train Epoch: 32 	Average Loss: 18.5212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7910

Saving model as e32_model.pt & e32_waveforms_supplementary.hdf5
Learning rate: 0.00019999494680510518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 18.6185	Cost: 20.32s
Train Epoch: 33 [20480/90000 (23%)]	Loss: 18.4443	Cost: 6.10s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 18.5300	Cost: 6.09s
Train Epoch: 33 [61440/90000 (68%)]	Loss: 18.5543	Cost: 5.96s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 18.4938	Cost: 5.84s
Train Epoch: 33 	Average Loss: 18.5357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7572

Saving model as e33_model.pt & e33_waveforms_supplementary.hdf5
Learning rate: 0.00019999462604853658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 18.5619	Cost: 19.52s
Train Epoch: 34 [20480/90000 (23%)]	Loss: 18.4241	Cost: 6.32s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 18.4231	Cost: 6.06s
Train Epoch: 34 [61440/90000 (68%)]	Loss: 18.3883	Cost: 5.91s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 18.4681	Cost: 5.87s
Train Epoch: 34 	Average Loss: 18.4461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6807

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Learning rate: 0.00019999429542289402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 18.4348	Cost: 20.39s
Train Epoch: 35 [20480/90000 (23%)]	Loss: 18.4903	Cost: 6.01s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 18.4123	Cost: 6.06s
Train Epoch: 35 [61440/90000 (68%)]	Loss: 18.5445	Cost: 5.85s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 18.2933	Cost: 5.84s
Train Epoch: 35 	Average Loss: 18.4090
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6569

Saving model as e35_model.pt & e35_waveforms_supplementary.hdf5
Learning rate: 0.00019999395492821016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 18.3398	Cost: 20.37s
Train Epoch: 36 [20480/90000 (23%)]	Loss: 18.2764	Cost: 6.05s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 18.3325	Cost: 6.07s
Train Epoch: 36 [61440/90000 (68%)]	Loss: 18.3816	Cost: 5.90s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 18.2334	Cost: 5.84s
Train Epoch: 36 	Average Loss: 18.3604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6541

Saving model as e36_model.pt & e36_waveforms_supplementary.hdf5
Learning rate: 0.0001999936045645186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 18.4709	Cost: 20.04s
Train Epoch: 37 [20480/90000 (23%)]	Loss: 18.3390	Cost: 6.00s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 18.2821	Cost: 6.02s
Train Epoch: 37 [61440/90000 (68%)]	Loss: 18.3330	Cost: 5.85s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 18.2767	Cost: 5.76s
Train Epoch: 37 	Average Loss: 18.3057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6334

Saving model as e37_model.pt & e37_waveforms_supplementary.hdf5
Learning rate: 0.00019999324433185394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 18.3534	Cost: 21.23s
Train Epoch: 38 [20480/90000 (23%)]	Loss: 18.3804	Cost: 5.98s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 18.2391	Cost: 6.28s
Train Epoch: 38 [61440/90000 (68%)]	Loss: 18.2532	Cost: 5.83s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 18.1835	Cost: 5.76s
Train Epoch: 38 	Average Loss: 18.2476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5822

Saving model as e38_model.pt & e38_waveforms_supplementary.hdf5
Learning rate: 0.0001999928742302517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 18.2182	Cost: 20.60s
Train Epoch: 39 [20480/90000 (23%)]	Loss: 18.1178	Cost: 6.00s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 18.2914	Cost: 6.13s
Train Epoch: 39 [61440/90000 (68%)]	Loss: 18.1411	Cost: 5.84s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 18.2105	Cost: 5.77s
Train Epoch: 39 	Average Loss: 18.2049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4976

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Learning rate: 0.00019999249425974844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 18.0612	Cost: 20.71s
Train Epoch: 40 [20480/90000 (23%)]	Loss: 18.2079	Cost: 6.01s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 18.1648	Cost: 6.02s
Train Epoch: 40 [61440/90000 (68%)]	Loss: 18.1853	Cost: 5.86s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 18.1330	Cost: 5.83s
Train Epoch: 40 	Average Loss: 18.1583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4619

Saving model as e40_model.pt & e40_waveforms_supplementary.hdf5
Learning rate: 0.00019999210442038165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 18.2373	Cost: 20.75s
Train Epoch: 41 [20480/90000 (23%)]	Loss: 18.2130	Cost: 6.03s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 18.2072	Cost: 6.39s
Train Epoch: 41 [61440/90000 (68%)]	Loss: 18.0687	Cost: 5.87s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 18.1946	Cost: 5.91s
Train Epoch: 41 	Average Loss: 18.1167
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3963

Saving model as e41_model.pt & e41_waveforms_supplementary.hdf5
Learning rate: 0.00019999170471218976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 18.0589	Cost: 21.34s
Train Epoch: 42 [20480/90000 (23%)]	Loss: 18.0699	Cost: 6.05s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 18.1048	Cost: 6.27s
Train Epoch: 42 [61440/90000 (68%)]	Loss: 18.1619	Cost: 5.84s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 18.1019	Cost: 5.79s
Train Epoch: 42 	Average Loss: 18.0648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3593

Saving model as e42_model.pt & e42_waveforms_supplementary.hdf5
Learning rate: 0.0001999912951352123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 18.1045	Cost: 20.51s
Train Epoch: 43 [20480/90000 (23%)]	Loss: 17.9601	Cost: 6.03s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 18.0939	Cost: 6.08s
Train Epoch: 43 [61440/90000 (68%)]	Loss: 18.0260	Cost: 5.87s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 18.0248	Cost: 5.77s
Train Epoch: 43 	Average Loss: 18.0132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3090

Saving model as e43_model.pt & e43_waveforms_supplementary.hdf5
Learning rate: 0.00019999087568948966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 18.0781	Cost: 21.13s
Train Epoch: 44 [20480/90000 (23%)]	Loss: 17.9820	Cost: 6.02s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 17.8046	Cost: 6.12s
Train Epoch: 44 [61440/90000 (68%)]	Loss: 17.9709	Cost: 5.87s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 17.8992	Cost: 5.77s
Train Epoch: 44 	Average Loss: 17.9669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2660

Saving model as e44_model.pt & e44_waveforms_supplementary.hdf5
Learning rate: 0.0001999904463750632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 17.9349	Cost: 21.17s
Train Epoch: 45 [20480/90000 (23%)]	Loss: 17.9948	Cost: 5.95s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 17.8372	Cost: 5.97s
Train Epoch: 45 [61440/90000 (68%)]	Loss: 17.6950	Cost: 5.84s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 17.8265	Cost: 5.82s
Train Epoch: 45 	Average Loss: 17.8878
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2075

Saving model as e45_model.pt & e45_waveforms_supplementary.hdf5
Learning rate: 0.00019999000719197536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 17.9680	Cost: 20.02s
Train Epoch: 46 [20480/90000 (23%)]	Loss: 17.8595	Cost: 5.98s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 17.9303	Cost: 6.25s
Train Epoch: 46 [61440/90000 (68%)]	Loss: 17.8111	Cost: 5.86s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 17.8184	Cost: 5.76s
Train Epoch: 46 	Average Loss: 17.8686
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1719

Saving model as e46_model.pt & e46_waveforms_supplementary.hdf5
Learning rate: 0.00019998955814026943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 17.9022	Cost: 19.74s
Train Epoch: 47 [20480/90000 (23%)]	Loss: 17.7985	Cost: 5.98s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 17.7672	Cost: 5.97s
Train Epoch: 47 [61440/90000 (68%)]	Loss: 17.8414	Cost: 5.85s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 17.7556	Cost: 5.75s
Train Epoch: 47 	Average Loss: 17.8315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1952

Learning rate: 0.00019998909921998973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 17.9526	Cost: 21.26s
Train Epoch: 48 [20480/90000 (23%)]	Loss: 17.7559	Cost: 6.18s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 17.7904	Cost: 6.78s
Train Epoch: 48 [61440/90000 (68%)]	Loss: 17.6707	Cost: 5.83s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 17.7249	Cost: 5.76s
Train Epoch: 48 	Average Loss: 17.7735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0874

Saving model as e48_model.pt & e48_waveforms_supplementary.hdf5
Learning rate: 0.0001999886304311816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 17.7410	Cost: 20.58s
Train Epoch: 49 [20480/90000 (23%)]	Loss: 17.7422	Cost: 6.15s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 17.8086	Cost: 6.53s
Train Epoch: 49 [61440/90000 (68%)]	Loss: 17.7002	Cost: 5.84s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 17.6815	Cost: 6.09s
Train Epoch: 49 	Average Loss: 17.7328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0438

Saving model as e49_model.pt & e49_waveforms_supplementary.hdf5
Learning rate: 0.00019998815177389132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 17.5701	Cost: 19.70s
Train Epoch: 50 [20480/90000 (23%)]	Loss: 17.7705	Cost: 6.13s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 17.6667	Cost: 6.04s
Train Epoch: 50 [61440/90000 (68%)]	Loss: 17.7296	Cost: 5.86s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 17.6820	Cost: 5.84s
Train Epoch: 50 	Average Loss: 17.7322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0567

Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 17.6226	Cost: 20.84s
Train Epoch: 51 [20480/90000 (23%)]	Loss: 17.6854	Cost: 5.96s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 17.7323	Cost: 5.99s
Train Epoch: 51 [61440/90000 (68%)]	Loss: 17.5781	Cost: 5.96s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 17.6451	Cost: 5.78s
Train Epoch: 51 	Average Loss: 17.6829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9786

Saving model as e51_model.pt & e51_waveforms_supplementary.hdf5
Learning rate: 0.00019998716485405404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 17.5809	Cost: 20.60s
Train Epoch: 52 [20480/90000 (23%)]	Loss: 17.5829	Cost: 6.01s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 17.6160	Cost: 6.01s
Train Epoch: 52 [61440/90000 (68%)]	Loss: 17.6520	Cost: 5.88s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 17.5210	Cost: 5.75s
Train Epoch: 52 	Average Loss: 17.6217
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8763

Saving model as e52_model.pt & e52_waveforms_supplementary.hdf5
Learning rate: 0.0001999866565916045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 17.5559	Cost: 19.95s
Train Epoch: 53 [20480/90000 (23%)]	Loss: 17.6528	Cost: 6.14s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 17.6708	Cost: 6.37s
Train Epoch: 53 [61440/90000 (68%)]	Loss: 17.5194	Cost: 5.85s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 17.5036	Cost: 5.76s
Train Epoch: 53 	Average Loss: 17.6052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9564

Learning rate: 0.0001999861384608676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 17.6512	Cost: 20.07s
Train Epoch: 54 [20480/90000 (23%)]	Loss: 17.5921	Cost: 6.04s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 17.4376	Cost: 6.59s
Train Epoch: 54 [61440/90000 (68%)]	Loss: 17.5177	Cost: 5.83s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 17.4918	Cost: 6.16s
Train Epoch: 54 	Average Loss: 17.5613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8566

Saving model as e54_model.pt & e54_waveforms_supplementary.hdf5
Learning rate: 0.00019998561046189446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 17.5731	Cost: 20.87s
Train Epoch: 55 [20480/90000 (23%)]	Loss: 17.5910	Cost: 5.91s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 17.5376	Cost: 6.45s
Train Epoch: 55 [61440/90000 (68%)]	Loss: 17.4523	Cost: 5.67s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 17.5026	Cost: 5.90s
Train Epoch: 55 	Average Loss: 17.5149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8299

Saving model as e55_model.pt & e55_waveforms_supplementary.hdf5
Learning rate: 0.00019998507259473718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 17.4433	Cost: 20.55s
Train Epoch: 56 [20480/90000 (23%)]	Loss: 17.4921	Cost: 5.95s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 17.5095	Cost: 6.36s
Train Epoch: 56 [61440/90000 (68%)]	Loss: 17.4084	Cost: 5.87s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 17.3759	Cost: 5.97s
Train Epoch: 56 	Average Loss: 17.4807
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7976

Saving model as e56_model.pt & e56_waveforms_supplementary.hdf5
Learning rate: 0.00019998452485944885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 17.5477	Cost: 21.23s
Train Epoch: 57 [20480/90000 (23%)]	Loss: 17.4878	Cost: 5.97s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 17.4115	Cost: 6.03s
Train Epoch: 57 [61440/90000 (68%)]	Loss: 17.4182	Cost: 5.89s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 17.3477	Cost: 5.89s
Train Epoch: 57 	Average Loss: 17.4270
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7487

Saving model as e57_model.pt & e57_waveforms_supplementary.hdf5
Learning rate: 0.00019998396725608354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 17.2927	Cost: 20.21s
Train Epoch: 58 [20480/90000 (23%)]	Loss: 17.3335	Cost: 5.99s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 17.3467	Cost: 6.03s
Train Epoch: 58 [61440/90000 (68%)]	Loss: 17.1545	Cost: 5.87s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 17.4198	Cost: 5.88s
Train Epoch: 58 	Average Loss: 17.4006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6495

Saving model as e58_model.pt & e58_waveforms_supplementary.hdf5
Learning rate: 0.00019998339978469627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 17.4422	Cost: 19.98s
Train Epoch: 59 [20480/90000 (23%)]	Loss: 17.3372	Cost: 6.09s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 17.3310	Cost: 6.03s
Train Epoch: 59 [61440/90000 (68%)]	Loss: 17.4780	Cost: 5.86s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 17.3007	Cost: 6.10s
Train Epoch: 59 	Average Loss: 17.3810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7149

Learning rate: 0.00019998282244534305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 17.3080	Cost: 20.03s
Train Epoch: 60 [20480/90000 (23%)]	Loss: 17.2721	Cost: 6.21s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 17.3430	Cost: 6.05s
Train Epoch: 60 [61440/90000 (68%)]	Loss: 17.3097	Cost: 5.93s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 17.3086	Cost: 5.79s
Train Epoch: 60 	Average Loss: 17.3159
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6523

Learning rate: 0.00019998223523808088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 17.2079	Cost: 19.36s
Train Epoch: 61 [20480/90000 (23%)]	Loss: 17.2285	Cost: 6.10s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 17.3982	Cost: 6.05s
Train Epoch: 61 [61440/90000 (68%)]	Loss: 17.2204	Cost: 5.88s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 17.3358	Cost: 5.76s
Train Epoch: 61 	Average Loss: 17.2975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6594

Learning rate: 0.0001999816381629677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 17.3326	Cost: 20.11s
Train Epoch: 62 [20480/90000 (23%)]	Loss: 17.1872	Cost: 6.07s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 17.3697	Cost: 7.25s
Train Epoch: 62 [61440/90000 (68%)]	Loss: 17.0667	Cost: 5.83s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 17.1687	Cost: 6.02s
Train Epoch: 62 	Average Loss: 17.2716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6444

Saving model as e62_model.pt & e62_waveforms_supplementary.hdf5
Learning rate: 0.00019998103122006246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 17.1989	Cost: 21.21s
Train Epoch: 63 [20480/90000 (23%)]	Loss: 17.3181	Cost: 6.03s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 17.4204	Cost: 6.09s
Train Epoch: 63 [61440/90000 (68%)]	Loss: 17.1188	Cost: 5.84s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 17.2231	Cost: 5.75s
Train Epoch: 63 	Average Loss: 17.2284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6332

Saving model as e63_model.pt & e63_waveforms_supplementary.hdf5
Learning rate: 0.00019998041440942506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 17.1500	Cost: 21.48s
Train Epoch: 64 [20480/90000 (23%)]	Loss: 17.3040	Cost: 5.94s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 17.2281	Cost: 6.34s
Train Epoch: 64 [61440/90000 (68%)]	Loss: 17.1256	Cost: 5.86s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 17.0919	Cost: 5.75s
Train Epoch: 64 	Average Loss: 17.2168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5245

Saving model as e64_model.pt & e64_waveforms_supplementary.hdf5
Learning rate: 0.00019997978773111632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 17.1244	Cost: 21.16s
Train Epoch: 65 [20480/90000 (23%)]	Loss: 17.1025	Cost: 5.95s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 17.2619	Cost: 6.54s
Train Epoch: 65 [61440/90000 (68%)]	Loss: 17.1751	Cost: 5.84s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 17.1665	Cost: 5.75s
Train Epoch: 65 	Average Loss: 17.1800
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4967

Saving model as e65_model.pt & e65_waveforms_supplementary.hdf5
Learning rate: 0.00019997915118519813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 17.2445	Cost: 21.21s
Train Epoch: 66 [20480/90000 (23%)]	Loss: 17.1682	Cost: 5.94s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 17.2291	Cost: 6.55s
Train Epoch: 66 [61440/90000 (68%)]	Loss: 17.1395	Cost: 5.86s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 17.0838	Cost: 5.90s
Train Epoch: 66 	Average Loss: 17.1544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4509

Saving model as e66_model.pt & e66_waveforms_supplementary.hdf5
Learning rate: 0.0001999785047717333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 17.1763	Cost: 20.37s
Train Epoch: 67 [20480/90000 (23%)]	Loss: 17.1470	Cost: 5.95s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 17.1699	Cost: 6.21s
Train Epoch: 67 [61440/90000 (68%)]	Loss: 17.2107	Cost: 5.91s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 17.1048	Cost: 5.94s
Train Epoch: 67 	Average Loss: 17.1311
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4202

Saving model as e67_model.pt & e67_waveforms_supplementary.hdf5
Learning rate: 0.00019997784849078566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 17.0561	Cost: 20.21s
Train Epoch: 68 [20480/90000 (23%)]	Loss: 17.1293	Cost: 6.05s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 17.1072	Cost: 6.05s
Train Epoch: 68 [61440/90000 (68%)]	Loss: 17.0708	Cost: 5.91s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 17.0421	Cost: 5.97s
Train Epoch: 68 	Average Loss: 17.1040
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3958

Saving model as e68_model.pt & e68_waveforms_supplementary.hdf5
Learning rate: 0.00019997718234242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 17.1776	Cost: 19.35s
Train Epoch: 69 [20480/90000 (23%)]	Loss: 17.0891	Cost: 6.04s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 17.1462	Cost: 6.11s
Train Epoch: 69 [61440/90000 (68%)]	Loss: 16.9671	Cost: 5.68s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 16.9041	Cost: 5.85s
Train Epoch: 69 	Average Loss: 17.0649
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3591

Saving model as e69_model.pt & e69_waveforms_supplementary.hdf5
Learning rate: 0.00019997650632670199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 17.0285	Cost: 19.73s
Train Epoch: 70 [20480/90000 (23%)]	Loss: 16.9961	Cost: 6.05s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 17.0369	Cost: 6.03s
Train Epoch: 70 [61440/90000 (68%)]	Loss: 17.0406	Cost: 5.89s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 17.1238	Cost: 5.85s
Train Epoch: 70 	Average Loss: 17.0464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3787

Learning rate: 0.0001999758204436984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 17.1025	Cost: 20.19s
Train Epoch: 71 [20480/90000 (23%)]	Loss: 17.2305	Cost: 6.00s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 17.2608	Cost: 6.15s
Train Epoch: 71 [61440/90000 (68%)]	Loss: 17.0632	Cost: 5.87s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 16.9581	Cost: 5.81s
Train Epoch: 71 	Average Loss: 17.0455
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3159

Saving model as e71_model.pt & e71_waveforms_supplementary.hdf5
Learning rate: 0.00019997512469347695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 17.0511	Cost: 20.61s
Train Epoch: 72 [20480/90000 (23%)]	Loss: 16.9893	Cost: 5.97s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 16.9414	Cost: 6.72s
Train Epoch: 72 [61440/90000 (68%)]	Loss: 16.8629	Cost: 5.83s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 16.8829	Cost: 5.81s
Train Epoch: 72 	Average Loss: 16.9954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3123

Saving model as e72_model.pt & e72_waveforms_supplementary.hdf5
Learning rate: 0.00019997441907610624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 17.0269	Cost: 19.88s
Train Epoch: 73 [20480/90000 (23%)]	Loss: 16.8870	Cost: 5.98s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 16.9500	Cost: 6.03s
Train Epoch: 73 [61440/90000 (68%)]	Loss: 16.9548	Cost: 5.85s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 16.9375	Cost: 6.08s
Train Epoch: 73 	Average Loss: 16.9538
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2635

Saving model as e73_model.pt & e73_waveforms_supplementary.hdf5
Learning rate: 0.00019997370359165596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 16.9257	Cost: 21.13s
Train Epoch: 74 [20480/90000 (23%)]	Loss: 17.0111	Cost: 6.00s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 16.8270	Cost: 6.47s
Train Epoch: 74 [61440/90000 (68%)]	Loss: 17.1221	Cost: 5.87s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 16.9256	Cost: 5.99s
Train Epoch: 74 	Average Loss: 16.9407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1883

Saving model as e74_model.pt & e74_waveforms_supplementary.hdf5
Learning rate: 0.0001999729782401967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 17.0425	Cost: 20.18s
Train Epoch: 75 [20480/90000 (23%)]	Loss: 17.0380	Cost: 6.03s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 16.9554	Cost: 6.18s
Train Epoch: 75 [61440/90000 (68%)]	Loss: 16.9718	Cost: 5.92s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 16.8303	Cost: 5.91s
Train Epoch: 75 	Average Loss: 16.9296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2446

Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 17.0707	Cost: 20.36s
Train Epoch: 76 [20480/90000 (23%)]	Loss: 16.8504	Cost: 6.09s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 16.8713	Cost: 6.06s
Train Epoch: 76 [61440/90000 (68%)]	Loss: 16.7494	Cost: 5.89s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 16.8875	Cost: 5.81s
Train Epoch: 76 	Average Loss: 16.8873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2334

Learning rate: 0.00019997149793653861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 16.8013	Cost: 21.46s
Train Epoch: 77 [20480/90000 (23%)]	Loss: 16.7416	Cost: 5.93s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 17.0088	Cost: 6.04s
Train Epoch: 77 [61440/90000 (68%)]	Loss: 16.8324	Cost: 5.84s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 16.7680	Cost: 5.75s
Train Epoch: 77 	Average Loss: 16.8969
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1945

Learning rate: 0.00019997074298448586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 16.9492	Cost: 20.79s
Train Epoch: 78 [20480/90000 (23%)]	Loss: 16.9195	Cost: 5.98s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 16.8399	Cost: 6.54s
Train Epoch: 78 [61440/90000 (68%)]	Loss: 16.8318	Cost: 5.84s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 16.8839	Cost: 5.77s
Train Epoch: 78 	Average Loss: 16.8758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1332

Saving model as e78_model.pt & e78_waveforms_supplementary.hdf5
Learning rate: 0.00019996997816571638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 16.9350	Cost: 20.34s
Train Epoch: 79 [20480/90000 (23%)]	Loss: 16.7909	Cost: 5.96s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 16.8913	Cost: 6.02s
Train Epoch: 79 [61440/90000 (68%)]	Loss: 16.7971	Cost: 5.83s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 16.6578	Cost: 5.86s
Train Epoch: 79 	Average Loss: 16.8331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1531

Learning rate: 0.00019996920348030559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 16.9729	Cost: 19.62s
Train Epoch: 80 [20480/90000 (23%)]	Loss: 16.8683	Cost: 6.05s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 16.7824	Cost: 6.25s
Train Epoch: 80 [61440/90000 (68%)]	Loss: 16.7239	Cost: 5.89s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 16.8655	Cost: 5.81s
Train Epoch: 80 	Average Loss: 16.8100
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1922

Learning rate: 0.00019996841892832998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 16.7220	Cost: 21.04s
Train Epoch: 81 [20480/90000 (23%)]	Loss: 16.9539	Cost: 6.04s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 16.6601	Cost: 6.06s
Train Epoch: 81 [61440/90000 (68%)]	Loss: 16.8575	Cost: 5.90s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 16.7975	Cost: 5.79s
Train Epoch: 81 	Average Loss: 16.8022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1943

Learning rate: 0.00019996762450986697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 16.8911	Cost: 19.29s
Train Epoch: 82 [20480/90000 (23%)]	Loss: 16.9078	Cost: 6.03s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 16.6882	Cost: 6.07s
Train Epoch: 82 [61440/90000 (68%)]	Loss: 16.7818	Cost: 5.84s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 16.8508	Cost: 6.13s
Train Epoch: 82 	Average Loss: 16.7830
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0944

Saving model as e82_model.pt & e82_waveforms_supplementary.hdf5
Learning rate: 0.00019996682022499498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 16.7754	Cost: 21.32s
Train Epoch: 83 [20480/90000 (23%)]	Loss: 16.6039	Cost: 6.02s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 16.8531	Cost: 6.33s
Train Epoch: 83 [61440/90000 (68%)]	Loss: 16.7875	Cost: 5.84s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 16.7820	Cost: 5.75s
Train Epoch: 83 	Average Loss: 16.7451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1034

Learning rate: 0.0001999660060737934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 16.7839	Cost: 19.61s
Train Epoch: 84 [20480/90000 (23%)]	Loss: 16.6000	Cost: 6.05s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 16.6718	Cost: 6.03s
Train Epoch: 84 [61440/90000 (68%)]	Loss: 16.7243	Cost: 5.87s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 16.5305	Cost: 5.76s
Train Epoch: 84 	Average Loss: 16.7622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1130

Learning rate: 0.00019996518205634255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 16.7497	Cost: 19.99s
Train Epoch: 85 [20480/90000 (23%)]	Loss: 16.6723	Cost: 6.03s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 16.7533	Cost: 6.62s
Train Epoch: 85 [61440/90000 (68%)]	Loss: 16.8020	Cost: 5.97s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 16.5466	Cost: 5.73s
Train Epoch: 85 	Average Loss: 16.7255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0736

Saving model as e85_model.pt & e85_waveforms_supplementary.hdf5
Learning rate: 0.0001999643481727238
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 16.8694	Cost: 21.40s
Train Epoch: 86 [20480/90000 (23%)]	Loss: 16.8346	Cost: 5.92s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 16.8021	Cost: 6.37s
Train Epoch: 86 [61440/90000 (68%)]	Loss: 16.7218	Cost: 5.86s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 16.5945	Cost: 5.76s
Train Epoch: 86 	Average Loss: 16.7076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0308

Saving model as e86_model.pt & e86_waveforms_supplementary.hdf5
Learning rate: 0.0001999635044230194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 16.8114	Cost: 20.47s
Train Epoch: 87 [20480/90000 (23%)]	Loss: 16.6394	Cost: 5.97s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 16.8270	Cost: 6.01s
Train Epoch: 87 [61440/90000 (68%)]	Loss: 16.6729	Cost: 5.89s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 16.5852	Cost: 5.78s
Train Epoch: 87 	Average Loss: 16.6983
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9858

Saving model as e87_model.pt & e87_waveforms_supplementary.hdf5
Learning rate: 0.00019996265080731267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 16.7433	Cost: 20.09s
Train Epoch: 88 [20480/90000 (23%)]	Loss: 16.4110	Cost: 6.01s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 16.6856	Cost: 5.97s
Train Epoch: 88 [61440/90000 (68%)]	Loss: 16.6673	Cost: 5.86s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 16.7265	Cost: 5.79s
Train Epoch: 88 	Average Loss: 16.6497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0279

Learning rate: 0.00019996178732568782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 16.6198	Cost: 21.73s
Train Epoch: 89 [20480/90000 (23%)]	Loss: 16.5598	Cost: 5.95s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 16.8092	Cost: 6.13s
Train Epoch: 89 [61440/90000 (68%)]	Loss: 16.5387	Cost: 5.85s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 16.5486	Cost: 5.79s
Train Epoch: 89 	Average Loss: 16.5968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0258

Learning rate: 0.00019996091397823007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 16.7379	Cost: 22.07s
Train Epoch: 90 [20480/90000 (23%)]	Loss: 16.6206	Cost: 5.94s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 16.6186	Cost: 6.04s
Train Epoch: 90 [61440/90000 (68%)]	Loss: 16.6399	Cost: 5.87s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 16.8221	Cost: 6.18s
Train Epoch: 90 	Average Loss: 16.6024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9764

Saving model as e90_model.pt & e90_waveforms_supplementary.hdf5
Learning rate: 0.00019996003076502562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 16.6426	Cost: 20.38s
Train Epoch: 91 [20480/90000 (23%)]	Loss: 16.5551	Cost: 6.02s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 16.5916	Cost: 6.35s
Train Epoch: 91 [61440/90000 (68%)]	Loss: 16.5910	Cost: 5.92s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 16.4186	Cost: 5.93s
Train Epoch: 91 	Average Loss: 16.5672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8754

Saving model as e91_model.pt & e91_waveforms_supplementary.hdf5
Learning rate: 0.0001999591376861617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 16.4915	Cost: 20.55s
Train Epoch: 92 [20480/90000 (23%)]	Loss: 16.4500	Cost: 6.02s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 16.4711	Cost: 6.12s
Train Epoch: 92 [61440/90000 (68%)]	Loss: 16.6716	Cost: 5.91s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 16.6538	Cost: 5.97s
Train Epoch: 92 	Average Loss: 16.5907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0275

Learning rate: 0.0001999582347417264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 16.6710	Cost: 20.78s
Train Epoch: 93 [20480/90000 (23%)]	Loss: 16.4615	Cost: 6.27s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 16.5217	Cost: 6.20s
Train Epoch: 93 [61440/90000 (68%)]	Loss: 16.4468	Cost: 5.90s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 16.5242	Cost: 6.00s
Train Epoch: 93 	Average Loss: 16.5389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9254

Learning rate: 0.00019995732193180883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 16.5810	Cost: 20.83s
Train Epoch: 94 [20480/90000 (23%)]	Loss: 16.4801	Cost: 6.06s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 16.6392	Cost: 6.33s
Train Epoch: 94 [61440/90000 (68%)]	Loss: 16.5310	Cost: 5.93s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 16.5590	Cost: 5.94s
Train Epoch: 94 	Average Loss: 16.5287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9124

Learning rate: 0.00019995639925649909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 16.6413	Cost: 20.99s
Train Epoch: 95 [20480/90000 (23%)]	Loss: 16.4056	Cost: 6.05s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 16.4464	Cost: 6.28s
Train Epoch: 95 [61440/90000 (68%)]	Loss: 16.5139	Cost: 5.93s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 16.3911	Cost: 5.90s
Train Epoch: 95 	Average Loss: 16.4964
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9199

Learning rate: 0.00019995546671588827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 16.5345	Cost: 19.52s
Train Epoch: 96 [20480/90000 (23%)]	Loss: 16.4361	Cost: 6.06s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 16.5327	Cost: 6.32s
Train Epoch: 96 [61440/90000 (68%)]	Loss: 16.4256	Cost: 5.91s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 16.5117	Cost: 5.77s
Train Epoch: 96 	Average Loss: 16.5082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8614

Saving model as e96_model.pt & e96_waveforms_supplementary.hdf5
Learning rate: 0.0001999545243100684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 16.3887	Cost: 20.20s
Train Epoch: 97 [20480/90000 (23%)]	Loss: 16.3696	Cost: 6.06s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 16.6450	Cost: 6.08s
Train Epoch: 97 [61440/90000 (68%)]	Loss: 16.4315	Cost: 5.90s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 16.4011	Cost: 5.83s
Train Epoch: 97 	Average Loss: 16.5000
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9122

Learning rate: 0.00019995357203913245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 16.6300	Cost: 20.12s
Train Epoch: 98 [20480/90000 (23%)]	Loss: 16.4544	Cost: 6.11s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 16.3669	Cost: 6.01s
Train Epoch: 98 [61440/90000 (68%)]	Loss: 16.4097	Cost: 5.91s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 16.5841	Cost: 5.87s
Train Epoch: 98 	Average Loss: 16.4504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9144

Learning rate: 0.00019995260990317447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 16.5723	Cost: 21.80s
Train Epoch: 99 [20480/90000 (23%)]	Loss: 16.3378	Cost: 5.99s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 16.5215	Cost: 6.55s
Train Epoch: 99 [61440/90000 (68%)]	Loss: 16.6179	Cost: 5.93s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 16.3745	Cost: 6.04s
Train Epoch: 99 	Average Loss: 16.4530
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8522

Saving model as e99_model.pt & e99_waveforms_supplementary.hdf5
Learning rate: 0.00019995163790228936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 16.4689	Cost: 20.49s
Train Epoch: 100 [20480/90000 (23%)]	Loss: 16.5224	Cost: 6.14s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 16.3971	Cost: 6.35s
Train Epoch: 100 [61440/90000 (68%)]	Loss: 16.4809	Cost: 5.91s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 16.4292	Cost: 6.16s
Train Epoch: 100 	Average Loss: 16.4323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8817

Learning rate: 0.0001999506560365731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 16.3271	Cost: 19.76s
Train Epoch: 101 [20480/90000 (23%)]	Loss: 16.3350	Cost: 6.11s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 16.4400	Cost: 6.08s
Train Epoch: 101 [61440/90000 (68%)]	Loss: 16.3889	Cost: 5.92s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 16.4309	Cost: 5.97s
Train Epoch: 101 	Average Loss: 16.4179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8054

Saving model as e101_model.pt & e101_waveforms_supplementary.hdf5
Learning rate: 0.00019994966430612258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 16.5712	Cost: 20.43s
Train Epoch: 102 [20480/90000 (23%)]	Loss: 16.3989	Cost: 6.06s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 16.3348	Cost: 6.03s
Train Epoch: 102 [61440/90000 (68%)]	Loss: 16.2969	Cost: 5.91s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 16.3178	Cost: 5.98s
Train Epoch: 102 	Average Loss: 16.3830
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8001

Saving model as e102_model.pt & e102_waveforms_supplementary.hdf5
Learning rate: 0.00019994866271103568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 16.4023	Cost: 19.89s
Train Epoch: 103 [20480/90000 (23%)]	Loss: 16.3076	Cost: 6.01s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 16.4744	Cost: 6.38s
Train Epoch: 103 [61440/90000 (68%)]	Loss: 16.3691	Cost: 5.91s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 16.1353	Cost: 6.07s
Train Epoch: 103 	Average Loss: 16.3961
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7583

Saving model as e103_model.pt & e103_waveforms_supplementary.hdf5
Learning rate: 0.0001999476512514112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 16.4085	Cost: 20.02s
Train Epoch: 104 [20480/90000 (23%)]	Loss: 16.1626	Cost: 5.99s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 16.4290	Cost: 6.78s
Train Epoch: 104 [61440/90000 (68%)]	Loss: 16.5534	Cost: 5.89s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 16.3983	Cost: 6.18s
Train Epoch: 104 	Average Loss: 16.4045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8205

Learning rate: 0.00019994662992734905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 16.3626	Cost: 22.04s
Train Epoch: 105 [20480/90000 (23%)]	Loss: 16.4166	Cost: 6.03s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 16.3950	Cost: 6.06s
Train Epoch: 105 [61440/90000 (68%)]	Loss: 16.5130	Cost: 5.89s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 16.3337	Cost: 5.89s
Train Epoch: 105 	Average Loss: 16.4022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7311

Saving model as e105_model.pt & e105_waveforms_supplementary.hdf5
Learning rate: 0.00019994559873894998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 16.3956	Cost: 20.88s
Train Epoch: 106 [20480/90000 (23%)]	Loss: 16.2868	Cost: 6.02s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 16.3499	Cost: 6.31s
Train Epoch: 106 [61440/90000 (68%)]	Loss: 16.1834	Cost: 5.93s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 16.3149	Cost: 6.07s
Train Epoch: 106 	Average Loss: 16.3324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7142

Saving model as e106_model.pt & e106_waveforms_supplementary.hdf5
Learning rate: 0.00019994455768631577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 16.3929	Cost: 20.48s
Train Epoch: 107 [20480/90000 (23%)]	Loss: 16.3402	Cost: 6.06s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 16.3266	Cost: 6.07s
Train Epoch: 107 [61440/90000 (68%)]	Loss: 16.2010	Cost: 5.91s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 16.1744	Cost: 5.84s
Train Epoch: 107 	Average Loss: 16.3063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6981

Saving model as e107_model.pt & e107_waveforms_supplementary.hdf5
Learning rate: 0.00019994350676954918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 16.5382	Cost: 20.65s
Train Epoch: 108 [20480/90000 (23%)]	Loss: 16.3209	Cost: 6.01s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 16.4930	Cost: 6.03s
Train Epoch: 108 [61440/90000 (68%)]	Loss: 16.3729	Cost: 5.86s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 16.3383	Cost: 5.93s
Train Epoch: 108 	Average Loss: 16.3309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8134

Learning rate: 0.00019994244598875392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 16.2956	Cost: 21.86s
Train Epoch: 109 [20480/90000 (23%)]	Loss: 16.1901	Cost: 6.04s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 16.2919	Cost: 5.90s
Train Epoch: 109 [61440/90000 (68%)]	Loss: 16.3114	Cost: 5.77s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 16.2792	Cost: 5.98s
Train Epoch: 109 	Average Loss: 16.3161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7241

Learning rate: 0.00019994137534403472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 16.5483	Cost: 21.42s
Train Epoch: 110 [20480/90000 (23%)]	Loss: 16.5622	Cost: 5.99s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 16.2328	Cost: 6.61s
Train Epoch: 110 [61440/90000 (68%)]	Loss: 16.3347	Cost: 5.81s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 16.2409	Cost: 5.92s
Train Epoch: 110 	Average Loss: 16.3049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6665

Saving model as e110_model.pt & e110_waveforms_supplementary.hdf5
Learning rate: 0.00019994029483549723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 16.3018	Cost: 21.03s
Train Epoch: 111 [20480/90000 (23%)]	Loss: 16.2143	Cost: 5.99s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 16.3180	Cost: 6.43s
Train Epoch: 111 [61440/90000 (68%)]	Loss: 16.2250	Cost: 5.86s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 16.2296	Cost: 6.61s
Train Epoch: 111 	Average Loss: 16.3126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6684

Learning rate: 0.00019993920446324803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 16.5410	Cost: 20.73s
Train Epoch: 112 [20480/90000 (23%)]	Loss: 16.3746	Cost: 5.95s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 16.2564	Cost: 6.12s
Train Epoch: 112 [61440/90000 (68%)]	Loss: 16.2146	Cost: 5.85s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 16.1503	Cost: 5.97s
Train Epoch: 112 	Average Loss: 16.2531
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6576

Saving model as e112_model.pt & e112_waveforms_supplementary.hdf5
Learning rate: 0.00019993810422739487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 16.0403	Cost: 20.75s
Train Epoch: 113 [20480/90000 (23%)]	Loss: 16.0155	Cost: 5.94s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 16.2086	Cost: 6.40s
Train Epoch: 113 [61440/90000 (68%)]	Loss: 16.2277	Cost: 5.82s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 16.1308	Cost: 5.79s
Train Epoch: 113 	Average Loss: 16.2532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6127

Saving model as e113_model.pt & e113_waveforms_supplementary.hdf5
Learning rate: 0.00019993699412804622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 16.4574	Cost: 20.34s
Train Epoch: 114 [20480/90000 (23%)]	Loss: 16.1564	Cost: 5.98s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 16.1038	Cost: 5.97s
Train Epoch: 114 [61440/90000 (68%)]	Loss: 16.2613	Cost: 5.87s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 16.3214	Cost: 5.87s
Train Epoch: 114 	Average Loss: 16.2173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6372

Learning rate: 0.00019993587416531166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 16.4369	Cost: 21.25s
Train Epoch: 115 [20480/90000 (23%)]	Loss: 16.1549	Cost: 5.95s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 16.2641	Cost: 5.98s
Train Epoch: 115 [61440/90000 (68%)]	Loss: 16.3716	Cost: 5.84s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 16.2828	Cost: 5.85s
Train Epoch: 115 	Average Loss: 16.2329
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6645

Learning rate: 0.00019993474433930176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 16.2947	Cost: 20.11s
Train Epoch: 116 [20480/90000 (23%)]	Loss: 16.0132	Cost: 5.99s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 16.1987	Cost: 5.97s
Train Epoch: 116 [61440/90000 (68%)]	Loss: 16.1469	Cost: 5.86s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 16.3821	Cost: 5.76s
Train Epoch: 116 	Average Loss: 16.2096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6355

Learning rate: 0.000199933604650128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 16.3033	Cost: 20.64s
Train Epoch: 117 [20480/90000 (23%)]	Loss: 16.2866	Cost: 6.00s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 16.2009	Cost: 6.03s
Train Epoch: 117 [61440/90000 (68%)]	Loss: 16.1712	Cost: 5.84s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 16.2356	Cost: 5.77s
Train Epoch: 117 	Average Loss: 16.2040
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5241

Saving model as e117_model.pt & e117_waveforms_supplementary.hdf5
Learning rate: 0.0001999324550979029
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 16.1803	Cost: 21.02s
Train Epoch: 118 [20480/90000 (23%)]	Loss: 16.0302	Cost: 5.96s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 16.2216	Cost: 5.99s
Train Epoch: 118 [61440/90000 (68%)]	Loss: 16.0566	Cost: 5.85s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 16.2950	Cost: 5.84s
Train Epoch: 118 	Average Loss: 16.1955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5312

Learning rate: 0.00019993129568273988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 16.4111	Cost: 21.08s
Train Epoch: 119 [20480/90000 (23%)]	Loss: 16.0916	Cost: 5.96s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 16.2615	Cost: 6.49s
Train Epoch: 119 [61440/90000 (68%)]	Loss: 16.2295	Cost: 5.86s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 16.1153	Cost: 5.98s
Train Epoch: 119 	Average Loss: 16.1819
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6074

Learning rate: 0.0001999301264047534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 16.2650	Cost: 19.61s
Train Epoch: 120 [20480/90000 (23%)]	Loss: 15.9669	Cost: 6.01s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 16.1998	Cost: 5.99s
Train Epoch: 120 [61440/90000 (68%)]	Loss: 16.1218	Cost: 5.83s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 16.1190	Cost: 5.75s
Train Epoch: 120 	Average Loss: 16.1674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5638

Learning rate: 0.00019992894726405882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 16.3028	Cost: 20.91s
Train Epoch: 121 [20480/90000 (23%)]	Loss: 16.0466	Cost: 6.11s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 16.3066	Cost: 6.10s
Train Epoch: 121 [61440/90000 (68%)]	Loss: 16.2605	Cost: 5.89s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 16.1845	Cost: 6.04s
Train Epoch: 121 	Average Loss: 16.1607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5318

Learning rate: 0.00019992775826077256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 16.1460	Cost: 20.39s
Train Epoch: 122 [20480/90000 (23%)]	Loss: 16.1548	Cost: 6.09s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 16.1785	Cost: 6.45s
Train Epoch: 122 [61440/90000 (68%)]	Loss: 16.1504	Cost: 5.87s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 16.2044	Cost: 5.78s
Train Epoch: 122 	Average Loss: 16.1401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5158

Saving model as e122_model.pt & e122_waveforms_supplementary.hdf5
Learning rate: 0.00019992655939501196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 16.2274	Cost: 20.92s
Train Epoch: 123 [20480/90000 (23%)]	Loss: 16.0049	Cost: 5.94s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 15.9916	Cost: 6.27s
Train Epoch: 123 [61440/90000 (68%)]	Loss: 16.1411	Cost: 5.84s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 16.1435	Cost: 5.74s
Train Epoch: 123 	Average Loss: 16.1114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5055

Saving model as e123_model.pt & e123_waveforms_supplementary.hdf5
Learning rate: 0.00019992535066689534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 16.2702	Cost: 20.49s
Train Epoch: 124 [20480/90000 (23%)]	Loss: 16.0792	Cost: 6.08s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 16.1625	Cost: 6.28s
Train Epoch: 124 [61440/90000 (68%)]	Loss: 16.1242	Cost: 5.91s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 16.1290	Cost: 5.97s
Train Epoch: 124 	Average Loss: 16.1313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5312

Learning rate: 0.00019992413207654198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 16.3133	Cost: 20.17s
Train Epoch: 125 [20480/90000 (23%)]	Loss: 16.3369	Cost: 6.10s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 16.2560	Cost: 6.16s
Train Epoch: 125 [61440/90000 (68%)]	Loss: 16.2665	Cost: 5.94s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 16.1125	Cost: 6.05s
Train Epoch: 125 	Average Loss: 16.1229
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4945

Saving model as e125_model.pt & e125_waveforms_supplementary.hdf5
Learning rate: 0.0001999229036240722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 16.0873	Cost: 20.31s
Train Epoch: 126 [20480/90000 (23%)]	Loss: 16.1373	Cost: 6.05s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 16.1464	Cost: 6.08s
Train Epoch: 126 [61440/90000 (68%)]	Loss: 16.0775	Cost: 5.93s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 16.0167	Cost: 6.09s
Train Epoch: 126 	Average Loss: 16.1097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5895

Learning rate: 0.0001999216653096072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 16.2854	Cost: 20.43s
Train Epoch: 127 [20480/90000 (23%)]	Loss: 16.0739	Cost: 6.05s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 16.1120	Cost: 6.08s
Train Epoch: 127 [61440/90000 (68%)]	Loss: 16.1030	Cost: 6.02s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 16.1089	Cost: 6.00s
Train Epoch: 127 	Average Loss: 16.1015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5408

Learning rate: 0.00019992041713326917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 16.0988	Cost: 19.91s
Train Epoch: 128 [20480/90000 (23%)]	Loss: 16.0526	Cost: 6.06s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 16.0887	Cost: 6.01s
Train Epoch: 128 [61440/90000 (68%)]	Loss: 16.0123	Cost: 6.10s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 15.9463	Cost: 5.99s
Train Epoch: 128 	Average Loss: 16.0532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4408

Saving model as e128_model.pt & e128_waveforms_supplementary.hdf5
Learning rate: 0.00019991915909518135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 16.0861	Cost: 20.00s
Train Epoch: 129 [20480/90000 (23%)]	Loss: 15.8052	Cost: 6.04s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 16.1582	Cost: 6.17s
Train Epoch: 129 [61440/90000 (68%)]	Loss: 16.0191	Cost: 6.10s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 16.0966	Cost: 7.02s
Train Epoch: 129 	Average Loss: 16.0415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4557

Learning rate: 0.0001999178911954679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 16.1914	Cost: 20.44s
Train Epoch: 130 [20480/90000 (23%)]	Loss: 16.0552	Cost: 6.10s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 15.9237	Cost: 6.21s
Train Epoch: 130 [61440/90000 (68%)]	Loss: 16.2059	Cost: 5.97s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 15.9945	Cost: 7.02s
Train Epoch: 130 	Average Loss: 16.0476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5156

Learning rate: 0.0001999166134342539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 16.1808	Cost: 19.29s
Train Epoch: 131 [20480/90000 (23%)]	Loss: 15.9379	Cost: 6.04s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 16.0148	Cost: 6.09s
Train Epoch: 131 [61440/90000 (68%)]	Loss: 15.9810	Cost: 5.98s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 15.9780	Cost: 6.26s
Train Epoch: 131 	Average Loss: 16.0614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5265

Learning rate: 0.00019991532581166554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 16.1825	Cost: 20.25s
Train Epoch: 132 [20480/90000 (23%)]	Loss: 15.9349	Cost: 6.10s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 16.0534	Cost: 6.14s
Train Epoch: 132 [61440/90000 (68%)]	Loss: 16.1296	Cost: 6.00s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 16.0798	Cost: 6.19s
Train Epoch: 132 	Average Loss: 15.9995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3815

Saving model as e132_model.pt & e132_waveforms_supplementary.hdf5
Learning rate: 0.00019991402832782987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 16.0394	Cost: 20.80s
Train Epoch: 133 [20480/90000 (23%)]	Loss: 15.9082	Cost: 6.22s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 15.8805	Cost: 6.20s
Train Epoch: 133 [61440/90000 (68%)]	Loss: 15.9650	Cost: 5.90s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 15.8923	Cost: 6.46s
Train Epoch: 133 	Average Loss: 16.0019
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3893

Learning rate: 0.00019991272098287494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 16.2350	Cost: 20.78s
Train Epoch: 134 [20480/90000 (23%)]	Loss: 16.0258	Cost: 6.02s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 15.9897	Cost: 6.28s
Train Epoch: 134 [61440/90000 (68%)]	Loss: 15.9647	Cost: 5.91s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 16.0355	Cost: 6.10s
Train Epoch: 134 	Average Loss: 15.9859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4206

Learning rate: 0.00019991140377692977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 15.8115	Cost: 20.63s
Train Epoch: 135 [20480/90000 (23%)]	Loss: 16.0854	Cost: 6.13s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 16.1152	Cost: 6.30s
Train Epoch: 135 [61440/90000 (68%)]	Loss: 15.8425	Cost: 6.22s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 16.2393	Cost: 5.92s
Train Epoch: 135 	Average Loss: 15.9797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4159

Learning rate: 0.0001999100767101244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 15.8884	Cost: 19.83s
Train Epoch: 136 [20480/90000 (23%)]	Loss: 15.9754	Cost: 6.18s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 16.0369	Cost: 6.05s
Train Epoch: 136 [61440/90000 (68%)]	Loss: 15.7549	Cost: 5.91s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 15.9869	Cost: 5.92s
Train Epoch: 136 	Average Loss: 15.9621
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3659

Saving model as e136_model.pt & e136_waveforms_supplementary.hdf5
Learning rate: 0.00019990873978258976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 16.1525	Cost: 20.59s
Train Epoch: 137 [20480/90000 (23%)]	Loss: 15.8333	Cost: 6.15s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 16.1546	Cost: 6.09s
Train Epoch: 137 [61440/90000 (68%)]	Loss: 16.0204	Cost: 5.91s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 15.9012	Cost: 6.60s
Train Epoch: 137 	Average Loss: 16.0014
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4400

Learning rate: 0.0001999073929944578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 16.1009	Cost: 20.44s
Train Epoch: 138 [20480/90000 (23%)]	Loss: 15.7986	Cost: 6.11s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 15.8957	Cost: 6.20s
Train Epoch: 138 [61440/90000 (68%)]	Loss: 15.9566	Cost: 5.94s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 15.8888	Cost: 6.30s
Train Epoch: 138 	Average Loss: 15.9625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2939

Saving model as e138_model.pt & e138_waveforms_supplementary.hdf5
Learning rate: 0.00019990603634586154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 15.9694	Cost: 20.96s
Train Epoch: 139 [20480/90000 (23%)]	Loss: 15.9658	Cost: 6.03s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 15.9938	Cost: 6.20s
Train Epoch: 139 [61440/90000 (68%)]	Loss: 15.7884	Cost: 6.00s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 15.8412	Cost: 5.87s
Train Epoch: 139 	Average Loss: 15.9328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3069

Learning rate: 0.00019990466983693474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 15.9820	Cost: 20.60s
Train Epoch: 140 [20480/90000 (23%)]	Loss: 15.7061	Cost: 6.11s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 16.0973	Cost: 6.28s
Train Epoch: 140 [61440/90000 (68%)]	Loss: 15.9728	Cost: 6.01s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 15.7737	Cost: 6.29s
Train Epoch: 140 	Average Loss: 15.9403
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3437

Learning rate: 0.00019990329346781236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 16.0730	Cost: 20.87s
Train Epoch: 141 [20480/90000 (23%)]	Loss: 15.9658	Cost: 6.05s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 15.9896	Cost: 6.46s
Train Epoch: 141 [61440/90000 (68%)]	Loss: 16.2900	Cost: 5.92s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 15.9724	Cost: 6.32s
Train Epoch: 141 	Average Loss: 15.9354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4933

Learning rate: 0.00019990190723863022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 15.8952	Cost: 19.74s
Train Epoch: 142 [20480/90000 (23%)]	Loss: 15.8870	Cost: 6.14s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 16.0052	Cost: 6.01s
Train Epoch: 142 [61440/90000 (68%)]	Loss: 15.9653	Cost: 5.91s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 15.9741	Cost: 5.99s
Train Epoch: 142 	Average Loss: 15.9319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3985

Learning rate: 0.00019990051114952508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 15.8082	Cost: 21.25s
Train Epoch: 143 [20480/90000 (23%)]	Loss: 15.9038	Cost: 6.16s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 16.0522	Cost: 6.24s
Train Epoch: 143 [61440/90000 (68%)]	Loss: 15.8168	Cost: 5.98s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 15.8635	Cost: 6.17s
Train Epoch: 143 	Average Loss: 15.9143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4036

Learning rate: 0.0001998991052006348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 16.0010	Cost: 20.76s
Train Epoch: 144 [20480/90000 (23%)]	Loss: 15.8803	Cost: 6.07s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 15.8612	Cost: 6.45s
Train Epoch: 144 [61440/90000 (68%)]	Loss: 15.8154	Cost: 6.01s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 16.0253	Cost: 5.98s
Train Epoch: 144 	Average Loss: 15.8892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2862

Saving model as e144_model.pt & e144_waveforms_supplementary.hdf5
Learning rate: 0.0001998976893920981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 16.0123	Cost: 20.22s
Train Epoch: 145 [20480/90000 (23%)]	Loss: 15.7386	Cost: 6.08s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 15.9988	Cost: 6.34s
Train Epoch: 145 [61440/90000 (68%)]	Loss: 15.9574	Cost: 5.92s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 15.7317	Cost: 5.96s
Train Epoch: 145 	Average Loss: 15.8901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3183

Learning rate: 0.00019989626372405477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 15.9122	Cost: 20.66s
Train Epoch: 146 [20480/90000 (23%)]	Loss: 15.9454	Cost: 6.09s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 15.7912	Cost: 6.75s
Train Epoch: 146 [61440/90000 (68%)]	Loss: 15.7668	Cost: 5.91s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 15.9857	Cost: 6.24s
Train Epoch: 146 	Average Loss: 15.8847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3982

Learning rate: 0.00019989482819664545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 15.9030	Cost: 20.00s
Train Epoch: 147 [20480/90000 (23%)]	Loss: 15.9465	Cost: 6.12s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 16.0108	Cost: 6.08s
Train Epoch: 147 [61440/90000 (68%)]	Loss: 15.7579	Cost: 5.94s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 15.7057	Cost: 5.88s
Train Epoch: 147 	Average Loss: 15.8850
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2438

Saving model as e147_model.pt & e147_waveforms_supplementary.hdf5
Learning rate: 0.00019989338281001189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 15.9244	Cost: 20.51s
Train Epoch: 148 [20480/90000 (23%)]	Loss: 15.6986	Cost: 6.01s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 15.6821	Cost: 6.40s
Train Epoch: 148 [61440/90000 (68%)]	Loss: 15.8499	Cost: 5.90s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 15.9569	Cost: 6.53s
Train Epoch: 148 	Average Loss: 15.8337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2579

Learning rate: 0.00019989192756429667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 16.0176	Cost: 20.25s
Train Epoch: 149 [20480/90000 (23%)]	Loss: 15.9300	Cost: 6.11s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 15.8071	Cost: 6.36s
Train Epoch: 149 [61440/90000 (68%)]	Loss: 15.9679	Cost: 5.90s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 15.7512	Cost: 6.16s
Train Epoch: 149 	Average Loss: 15.8414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2620

Learning rate: 0.00019989046245964345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 15.8335	Cost: 21.22s
Train Epoch: 150 [20480/90000 (23%)]	Loss: 15.9640	Cost: 6.07s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 15.8210	Cost: 6.03s
Train Epoch: 150 [61440/90000 (68%)]	Loss: 15.9237	Cost: 5.96s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 15.7066	Cost: 5.86s
Train Epoch: 150 	Average Loss: 15.8506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3340

Learning rate: 0.00019988898749619688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 15.9106	Cost: 21.40s
Train Epoch: 151 [20480/90000 (23%)]	Loss: 15.7699	Cost: 6.05s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 15.8740	Cost: 6.59s
Train Epoch: 151 [61440/90000 (68%)]	Loss: 15.7920	Cost: 6.01s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 15.9801	Cost: 6.12s
Train Epoch: 151 	Average Loss: 15.8329
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2395

Saving model as e151_model.pt & e151_waveforms_supplementary.hdf5
Learning rate: 0.00019988750267410245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 15.9456	Cost: 21.53s
Train Epoch: 152 [20480/90000 (23%)]	Loss: 15.8738	Cost: 6.03s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 15.7053	Cost: 6.58s
Train Epoch: 152 [61440/90000 (68%)]	Loss: 15.7295	Cost: 5.96s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 15.8333	Cost: 7.15s
Train Epoch: 152 	Average Loss: 15.8368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2409

Learning rate: 0.0001998860079935067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 15.9704	Cost: 20.49s
Train Epoch: 153 [20480/90000 (23%)]	Loss: 15.6003	Cost: 6.13s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 15.7255	Cost: 6.13s
Train Epoch: 153 [61440/90000 (68%)]	Loss: 15.7435	Cost: 5.91s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 15.9652	Cost: 6.30s
Train Epoch: 153 	Average Loss: 15.8131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2150

Saving model as e153_model.pt & e153_waveforms_supplementary.hdf5
Learning rate: 0.00019988450345455726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 15.8917	Cost: 20.01s
Train Epoch: 154 [20480/90000 (23%)]	Loss: 15.7300	Cost: 6.11s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 15.8634	Cost: 6.04s
Train Epoch: 154 [61440/90000 (68%)]	Loss: 15.9110	Cost: 5.98s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 15.7018	Cost: 5.99s
Train Epoch: 154 	Average Loss: 15.8183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2691

Learning rate: 0.00019988298905740252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 15.8819	Cost: 21.12s
Train Epoch: 155 [20480/90000 (23%)]	Loss: 15.8735	Cost: 6.41s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 15.8808	Cost: 6.20s
Train Epoch: 155 [61440/90000 (68%)]	Loss: 15.8487	Cost: 5.98s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 15.6573	Cost: 6.06s
Train Epoch: 155 	Average Loss: 15.7870
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2318

Learning rate: 0.000199881464802192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 15.6586	Cost: 19.51s
Train Epoch: 156 [20480/90000 (23%)]	Loss: 15.7239	Cost: 6.07s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 15.5290	Cost: 5.99s
Train Epoch: 156 [61440/90000 (68%)]	Loss: 15.7267	Cost: 5.94s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 15.7549	Cost: 5.98s
Train Epoch: 156 	Average Loss: 15.7669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2365

Learning rate: 0.0001998799306890761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 15.7515	Cost: 20.03s
Train Epoch: 157 [20480/90000 (23%)]	Loss: 15.6495	Cost: 6.19s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 15.7499	Cost: 6.14s
Train Epoch: 157 [61440/90000 (68%)]	Loss: 15.7945	Cost: 5.92s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 15.8009	Cost: 6.05s
Train Epoch: 157 	Average Loss: 15.7724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2268

Learning rate: 0.00019987838671820622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 15.7975	Cost: 19.34s
Train Epoch: 158 [20480/90000 (23%)]	Loss: 15.6732	Cost: 6.11s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 15.8108	Cost: 6.36s
Train Epoch: 158 [61440/90000 (68%)]	Loss: 15.7584	Cost: 5.95s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 15.7438	Cost: 6.00s
Train Epoch: 158 	Average Loss: 15.7830
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2193

Learning rate: 0.00019987683288973478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 16.0342	Cost: 21.37s
Train Epoch: 159 [20480/90000 (23%)]	Loss: 15.8467	Cost: 6.12s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 15.7892	Cost: 6.54s
Train Epoch: 159 [61440/90000 (68%)]	Loss: 15.6367	Cost: 5.96s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 15.6572	Cost: 6.58s
Train Epoch: 159 	Average Loss: 15.7594
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1699

Saving model as e159_model.pt & e159_waveforms_supplementary.hdf5
Learning rate: 0.00019987526920381513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 15.9291	Cost: 20.29s
Train Epoch: 160 [20480/90000 (23%)]	Loss: 15.7088	Cost: 6.04s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 15.7452	Cost: 6.23s
Train Epoch: 160 [61440/90000 (68%)]	Loss: 15.9834	Cost: 5.91s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 15.6805	Cost: 6.09s
Train Epoch: 160 	Average Loss: 15.7624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1192

Saving model as e160_model.pt & e160_waveforms_supplementary.hdf5
Learning rate: 0.00019987369566060162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 15.7688	Cost: 20.42s
Train Epoch: 161 [20480/90000 (23%)]	Loss: 15.6812	Cost: 6.02s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 15.7845	Cost: 6.14s
Train Epoch: 161 [61440/90000 (68%)]	Loss: 15.6212	Cost: 6.01s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 15.8003	Cost: 6.13s
Train Epoch: 161 	Average Loss: 15.7528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2027

Learning rate: 0.0001998721122602495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 15.7626	Cost: 20.60s
Train Epoch: 162 [20480/90000 (23%)]	Loss: 15.6168	Cost: 6.07s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 15.6171	Cost: 6.38s
Train Epoch: 162 [61440/90000 (68%)]	Loss: 15.7890	Cost: 5.93s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 15.7441	Cost: 6.10s
Train Epoch: 162 	Average Loss: 15.7677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1308

Learning rate: 0.00019987051900291508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 15.7512	Cost: 20.21s
Train Epoch: 163 [20480/90000 (23%)]	Loss: 15.6563	Cost: 6.08s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 15.8233	Cost: 6.16s
Train Epoch: 163 [61440/90000 (68%)]	Loss: 15.8059	Cost: 6.01s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 15.7036	Cost: 6.45s
Train Epoch: 163 	Average Loss: 15.7324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2389

Learning rate: 0.00019986891588875562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 15.9267	Cost: 20.19s
Train Epoch: 164 [20480/90000 (23%)]	Loss: 15.7922	Cost: 6.01s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 15.4849	Cost: 6.43s
Train Epoch: 164 [61440/90000 (68%)]	Loss: 15.8568	Cost: 5.95s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 15.5395	Cost: 6.22s
Train Epoch: 164 	Average Loss: 15.7156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1477

Learning rate: 0.0001998673029179293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 16.0179	Cost: 20.05s
Train Epoch: 165 [20480/90000 (23%)]	Loss: 15.7139	Cost: 6.05s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 15.6997	Cost: 6.00s
Train Epoch: 165 [61440/90000 (68%)]	Loss: 15.6891	Cost: 5.94s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 15.7019	Cost: 5.93s
Train Epoch: 165 	Average Loss: 15.7570
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1646

Learning rate: 0.00019986568009059536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 15.8825	Cost: 20.34s
Train Epoch: 166 [20480/90000 (23%)]	Loss: 15.6914	Cost: 6.06s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 15.6376	Cost: 6.26s
Train Epoch: 166 [61440/90000 (68%)]	Loss: 15.7512	Cost: 5.94s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 15.7997	Cost: 6.42s
Train Epoch: 166 	Average Loss: 15.7047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1780

Learning rate: 0.00019986404740691393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 15.9530	Cost: 20.09s
Train Epoch: 167 [20480/90000 (23%)]	Loss: 15.7488	Cost: 6.09s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 15.6770	Cost: 6.04s
Train Epoch: 167 [61440/90000 (68%)]	Loss: 15.5644	Cost: 5.92s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 15.7746	Cost: 6.04s
Train Epoch: 167 	Average Loss: 15.7165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1874

Learning rate: 0.00019986240486704617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 15.8349	Cost: 20.36s
Train Epoch: 168 [20480/90000 (23%)]	Loss: 15.5873	Cost: 6.06s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 15.5420	Cost: 6.03s
Train Epoch: 168 [61440/90000 (68%)]	Loss: 15.7025	Cost: 5.90s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 15.6392	Cost: 5.91s
Train Epoch: 168 	Average Loss: 15.6803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2103

Learning rate: 0.00019986075247115415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 15.6857	Cost: 20.60s
Train Epoch: 169 [20480/90000 (23%)]	Loss: 15.7586	Cost: 6.03s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 15.7703	Cost: 6.41s
Train Epoch: 169 [61440/90000 (68%)]	Loss: 15.7943	Cost: 5.94s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 15.5746	Cost: 5.95s
Train Epoch: 169 	Average Loss: 15.6846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1364

Learning rate: 0.00019985909021940103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 15.7181	Cost: 19.52s
Train Epoch: 170 [20480/90000 (23%)]	Loss: 15.6969	Cost: 6.02s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 15.6474	Cost: 6.09s
Train Epoch: 170 [61440/90000 (68%)]	Loss: 15.6295	Cost: 5.97s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 15.6619	Cost: 6.01s
Train Epoch: 170 	Average Loss: 15.6931
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0861

Saving model as e170_model.pt & e170_waveforms_supplementary.hdf5
Learning rate: 0.0001998574181119508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 15.8504	Cost: 20.46s
Train Epoch: 171 [20480/90000 (23%)]	Loss: 15.7652	Cost: 6.01s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 15.7615	Cost: 6.00s
Train Epoch: 171 [61440/90000 (68%)]	Loss: 15.6662	Cost: 6.02s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 15.6875	Cost: 6.27s
Train Epoch: 171 	Average Loss: 15.6668
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1790

Learning rate: 0.00019985573614896853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 15.5529	Cost: 20.54s
Train Epoch: 172 [20480/90000 (23%)]	Loss: 15.5156	Cost: 6.03s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 15.7422	Cost: 6.43s
Train Epoch: 172 [61440/90000 (68%)]	Loss: 15.6880	Cost: 5.97s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 15.6001	Cost: 6.01s
Train Epoch: 172 	Average Loss: 15.6885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1382

Learning rate: 0.00019985404433062024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 15.6135	Cost: 20.00s
Train Epoch: 173 [20480/90000 (23%)]	Loss: 15.6767	Cost: 6.01s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 15.8003	Cost: 6.19s
Train Epoch: 173 [61440/90000 (68%)]	Loss: 15.5933	Cost: 5.92s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 15.5533	Cost: 6.44s
Train Epoch: 173 	Average Loss: 15.6657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0821

Saving model as e173_model.pt & e173_waveforms_supplementary.hdf5
Learning rate: 0.00019985234265707287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 15.7034	Cost: 20.97s
Train Epoch: 174 [20480/90000 (23%)]	Loss: 15.5860	Cost: 5.93s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 15.6107	Cost: 6.30s
Train Epoch: 174 [61440/90000 (68%)]	Loss: 15.5374	Cost: 5.90s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 15.6623	Cost: 6.42s
Train Epoch: 174 	Average Loss: 15.6418
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1111

Learning rate: 0.00019985063112849436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 15.7964	Cost: 20.02s
Train Epoch: 175 [20480/90000 (23%)]	Loss: 15.6224	Cost: 6.00s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 15.8917	Cost: 6.50s
Train Epoch: 175 [61440/90000 (68%)]	Loss: 15.4712	Cost: 6.04s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 16.0049	Cost: 6.02s
Train Epoch: 175 	Average Loss: 15.6500
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0942

Learning rate: 0.00019984890974505368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 15.8028	Cost: 21.55s
Train Epoch: 176 [20480/90000 (23%)]	Loss: 15.5625	Cost: 5.99s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 15.6488	Cost: 6.25s
Train Epoch: 176 [61440/90000 (68%)]	Loss: 15.5860	Cost: 5.90s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 15.5669	Cost: 6.17s
Train Epoch: 176 	Average Loss: 15.6527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1223

Learning rate: 0.00019984717850692066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 15.6801	Cost: 20.92s
Train Epoch: 177 [20480/90000 (23%)]	Loss: 15.3683	Cost: 6.03s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 15.5302	Cost: 6.12s
Train Epoch: 177 [61440/90000 (68%)]	Loss: 15.8766	Cost: 5.89s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 15.5855	Cost: 5.91s
Train Epoch: 177 	Average Loss: 15.6474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0648

Saving model as e177_model.pt & e177_waveforms_supplementary.hdf5
Learning rate: 0.00019984543741426617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 15.8671	Cost: 20.36s
Train Epoch: 178 [20480/90000 (23%)]	Loss: 15.6751	Cost: 6.05s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 15.6599	Cost: 6.78s
Train Epoch: 178 [61440/90000 (68%)]	Loss: 15.4503	Cost: 5.94s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 15.6055	Cost: 6.23s
Train Epoch: 178 	Average Loss: 15.6565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0909

Learning rate: 0.0001998436864672621
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 15.6759	Cost: 20.29s
Train Epoch: 179 [20480/90000 (23%)]	Loss: 15.6156	Cost: 6.17s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 15.6077	Cost: 6.41s
Train Epoch: 179 [61440/90000 (68%)]	Loss: 15.4927	Cost: 6.02s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 15.5450	Cost: 6.59s
Train Epoch: 179 	Average Loss: 15.5974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1095

Learning rate: 0.00019984192566608125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 15.6897	Cost: 21.18s
Train Epoch: 180 [20480/90000 (23%)]	Loss: 15.6406	Cost: 6.18s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 15.5496	Cost: 6.32s
Train Epoch: 180 [61440/90000 (68%)]	Loss: 15.5276	Cost: 5.99s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 15.5113	Cost: 6.45s
Train Epoch: 180 	Average Loss: 15.6186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0507

Saving model as e180_model.pt & e180_waveforms_supplementary.hdf5
Learning rate: 0.00019984015501089739
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 15.7197	Cost: 20.76s
Train Epoch: 181 [20480/90000 (23%)]	Loss: 15.5952	Cost: 6.14s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 15.5944	Cost: 6.57s
Train Epoch: 181 [61440/90000 (68%)]	Loss: 15.5882	Cost: 6.02s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 15.7145	Cost: 6.35s
Train Epoch: 181 	Average Loss: 15.6304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0730

Learning rate: 0.00019983837450188524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 15.8720	Cost: 20.11s
Train Epoch: 182 [20480/90000 (23%)]	Loss: 15.3562	Cost: 6.05s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 15.6357	Cost: 6.12s
Train Epoch: 182 [61440/90000 (68%)]	Loss: 15.4993	Cost: 5.98s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 15.4622	Cost: 6.11s
Train Epoch: 182 	Average Loss: 15.6009
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0934

Learning rate: 0.0001998365841392206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 15.7019	Cost: 22.04s
Train Epoch: 183 [20480/90000 (23%)]	Loss: 15.4867	Cost: 6.04s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 15.5535	Cost: 6.84s
Train Epoch: 183 [61440/90000 (68%)]	Loss: 15.6460	Cost: 5.89s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 15.5703	Cost: 6.61s
Train Epoch: 183 	Average Loss: 15.5935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0195

Saving model as e183_model.pt & e183_waveforms_supplementary.hdf5
Learning rate: 0.00019983478392308012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 15.7300	Cost: 21.09s
Train Epoch: 184 [20480/90000 (23%)]	Loss: 15.5205	Cost: 6.26s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 15.5379	Cost: 6.38s
Train Epoch: 184 [61440/90000 (68%)]	Loss: 15.5861	Cost: 5.95s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 15.5189	Cost: 6.23s
Train Epoch: 184 	Average Loss: 15.5939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0628

Learning rate: 0.0001998329738536415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 15.7122	Cost: 21.32s
Train Epoch: 185 [20480/90000 (23%)]	Loss: 15.4866	Cost: 6.10s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 15.5561	Cost: 6.43s
Train Epoch: 185 [61440/90000 (68%)]	Loss: 15.4021	Cost: 6.04s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 15.6761	Cost: 6.29s
Train Epoch: 185 	Average Loss: 15.5760
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0886

Learning rate: 0.00019983115393108338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 15.6714	Cost: 20.85s
Train Epoch: 186 [20480/90000 (23%)]	Loss: 15.6112	Cost: 6.07s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 15.5495	Cost: 6.25s
Train Epoch: 186 [61440/90000 (68%)]	Loss: 15.3442	Cost: 5.94s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 15.4410	Cost: 6.27s
Train Epoch: 186 	Average Loss: 15.5344
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9486

Saving model as e186_model.pt & e186_waveforms_supplementary.hdf5
Learning rate: 0.0001998293241555854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 15.5290	Cost: 20.13s
Train Epoch: 187 [20480/90000 (23%)]	Loss: 15.6704	Cost: 6.14s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 15.5196	Cost: 6.46s
Train Epoch: 187 [61440/90000 (68%)]	Loss: 15.4791	Cost: 6.00s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 15.5706	Cost: 6.29s
Train Epoch: 187 	Average Loss: 15.5503
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0473

Learning rate: 0.0001998274845273281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 15.7388	Cost: 20.48s
Train Epoch: 188 [20480/90000 (23%)]	Loss: 15.4082	Cost: 6.39s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 15.6488	Cost: 6.26s
Train Epoch: 188 [61440/90000 (68%)]	Loss: 15.4363	Cost: 6.11s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 15.4235	Cost: 6.20s
Train Epoch: 188 	Average Loss: 15.5508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9683

Learning rate: 0.00019982563504649309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 15.8644	Cost: 21.79s
Train Epoch: 189 [20480/90000 (23%)]	Loss: 15.4869	Cost: 6.00s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 15.4651	Cost: 6.44s
Train Epoch: 189 [61440/90000 (68%)]	Loss: 15.5781	Cost: 5.95s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 15.3800	Cost: 6.24s
Train Epoch: 189 	Average Loss: 15.5378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9675

Learning rate: 0.00019982377571326284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 15.6400	Cost: 20.02s
Train Epoch: 190 [20480/90000 (23%)]	Loss: 15.4449	Cost: 6.12s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 15.4490	Cost: 6.13s
Train Epoch: 190 [61440/90000 (68%)]	Loss: 15.3992	Cost: 5.96s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 15.4524	Cost: 5.97s
Train Epoch: 190 	Average Loss: 15.5574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0277

Learning rate: 0.00019982190652782097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 15.7125	Cost: 21.47s
Train Epoch: 191 [20480/90000 (23%)]	Loss: 15.4708	Cost: 6.17s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 15.5122	Cost: 6.22s
Train Epoch: 191 [61440/90000 (68%)]	Loss: 15.4876	Cost: 6.18s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 15.5382	Cost: 6.20s
Train Epoch: 191 	Average Loss: 15.5366
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9153

Saving model as e191_model.pt & e191_waveforms_supplementary.hdf5
Learning rate: 0.0001998200274903519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 15.6554	Cost: 20.20s
Train Epoch: 192 [20480/90000 (23%)]	Loss: 15.5269	Cost: 6.13s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 15.4702	Cost: 6.35s
Train Epoch: 192 [61440/90000 (68%)]	Loss: 15.6978	Cost: 6.05s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 15.3761	Cost: 6.57s
Train Epoch: 192 	Average Loss: 15.5389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9901

Learning rate: 0.00019981813860104106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 15.6242	Cost: 20.49s
Train Epoch: 193 [20480/90000 (23%)]	Loss: 15.4431	Cost: 6.13s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 15.4926	Cost: 6.20s
Train Epoch: 193 [61440/90000 (68%)]	Loss: 15.5015	Cost: 5.97s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 15.6343	Cost: 6.22s
Train Epoch: 193 	Average Loss: 15.5256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0771

Learning rate: 0.0001998162398600749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 15.6788	Cost: 21.14s
Train Epoch: 194 [20480/90000 (23%)]	Loss: 15.5568	Cost: 6.13s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 15.6849	Cost: 6.28s
Train Epoch: 194 [61440/90000 (68%)]	Loss: 15.4997	Cost: 6.02s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 15.6633	Cost: 6.46s
Train Epoch: 194 	Average Loss: 15.5412
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0678

Learning rate: 0.00019981433126764085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 15.5099	Cost: 21.25s
Train Epoch: 195 [20480/90000 (23%)]	Loss: 15.5088	Cost: 6.24s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 15.3646	Cost: 6.13s
Train Epoch: 195 [61440/90000 (68%)]	Loss: 15.7114	Cost: 5.93s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 15.5780	Cost: 6.14s
Train Epoch: 195 	Average Loss: 15.5173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9847

Learning rate: 0.00019981241282392723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 15.7732	Cost: 22.31s
Train Epoch: 196 [20480/90000 (23%)]	Loss: 15.3413	Cost: 6.09s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 15.4339	Cost: 6.58s
Train Epoch: 196 [61440/90000 (68%)]	Loss: 15.4267	Cost: 6.01s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 15.4870	Cost: 5.95s
Train Epoch: 196 	Average Loss: 15.5001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9102

Saving model as e196_model.pt & e196_waveforms_supplementary.hdf5
Learning rate: 0.0001998104845291234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 15.5864	Cost: 19.79s
Train Epoch: 197 [20480/90000 (23%)]	Loss: 15.4922	Cost: 6.16s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 15.4860	Cost: 6.12s
Train Epoch: 197 [61440/90000 (68%)]	Loss: 15.5107	Cost: 5.97s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 15.5326	Cost: 6.81s
Train Epoch: 197 	Average Loss: 15.5038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9763

Learning rate: 0.00019980854638341968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 15.6150	Cost: 19.91s
Train Epoch: 198 [20480/90000 (23%)]	Loss: 15.5750	Cost: 6.42s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 15.1852	Cost: 6.50s
Train Epoch: 198 [61440/90000 (68%)]	Loss: 15.3565	Cost: 6.05s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 15.4840	Cost: 5.99s
Train Epoch: 198 	Average Loss: 15.5014
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0457

Learning rate: 0.00019980659838700736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 15.4040	Cost: 21.24s
Train Epoch: 199 [20480/90000 (23%)]	Loss: 15.4010	Cost: 6.09s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 15.2704	Cost: 6.98s
Train Epoch: 199 [61440/90000 (68%)]	Loss: 15.4112	Cost: 6.05s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 15.5106	Cost: 5.92s
Train Epoch: 199 	Average Loss: 15.4743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8770

Saving model as e199_model.pt & e199_waveforms_supplementary.hdf5
Learning rate: 0.0001998046405400787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 15.5429	Cost: 20.20s
Train Epoch: 200 [20480/90000 (23%)]	Loss: 15.2642	Cost: 6.26s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 15.4890	Cost: 6.29s
Train Epoch: 200 [61440/90000 (68%)]	Loss: 15.3344	Cost: 5.96s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 15.4547	Cost: 6.45s
Train Epoch: 200 	Average Loss: 15.4377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9788

Learning rate: 0.00019980267284282693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 15.6658	Cost: 20.90s
Train Epoch: 201 [20480/90000 (23%)]	Loss: 15.2122	Cost: 6.09s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 15.5054	Cost: 5.90s
Train Epoch: 201 [61440/90000 (68%)]	Loss: 15.3224	Cost: 5.83s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 15.4506	Cost: 6.21s
Train Epoch: 201 	Average Loss: 15.4632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9250

Learning rate: 0.00019980069529544622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 15.5393	Cost: 20.87s
Train Epoch: 202 [20480/90000 (23%)]	Loss: 15.3565	Cost: 6.19s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 15.4606	Cost: 6.04s
Train Epoch: 202 [61440/90000 (68%)]	Loss: 15.4552	Cost: 6.16s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 15.5118	Cost: 6.76s
Train Epoch: 202 	Average Loss: 15.4584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9594

Learning rate: 0.0001997987078981318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 15.6609	Cost: 20.07s
Train Epoch: 203 [20480/90000 (23%)]	Loss: 15.4990	Cost: 6.26s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 15.4261	Cost: 6.74s
Train Epoch: 203 [61440/90000 (68%)]	Loss: 15.2903	Cost: 6.03s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 15.5921	Cost: 6.45s
Train Epoch: 203 	Average Loss: 15.4827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0274

Learning rate: 0.00019979671065107978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 15.7710	Cost: 21.20s
Train Epoch: 204 [20480/90000 (23%)]	Loss: 15.3749	Cost: 6.09s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 15.3429	Cost: 6.49s
Train Epoch: 204 [61440/90000 (68%)]	Loss: 15.4185	Cost: 6.25s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 15.3815	Cost: 5.93s
Train Epoch: 204 	Average Loss: 15.4256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9409

Learning rate: 0.0001997947035544873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 15.6128	Cost: 21.60s
Train Epoch: 205 [20480/90000 (23%)]	Loss: 15.3276	Cost: 6.06s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 15.6310	Cost: 6.24s
Train Epoch: 205 [61440/90000 (68%)]	Loss: 15.4495	Cost: 5.99s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 15.4440	Cost: 6.13s
Train Epoch: 205 	Average Loss: 15.4122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9621

Learning rate: 0.00019979268660855247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 15.5696	Cost: 22.00s
Train Epoch: 206 [20480/90000 (23%)]	Loss: 15.4430	Cost: 6.09s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 15.3907	Cost: 6.42s
Train Epoch: 206 [61440/90000 (68%)]	Loss: 15.1961	Cost: 6.03s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 15.2552	Cost: 6.05s
Train Epoch: 206 	Average Loss: 15.4231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9552

Learning rate: 0.00019979065981347432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 15.3990	Cost: 21.85s
Train Epoch: 207 [20480/90000 (23%)]	Loss: 15.4528	Cost: 6.11s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 15.3831	Cost: 6.38s
Train Epoch: 207 [61440/90000 (68%)]	Loss: 15.2318	Cost: 6.16s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 15.4223	Cost: 6.44s
Train Epoch: 207 	Average Loss: 15.4389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9288

Learning rate: 0.0001997886231694529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 15.6147	Cost: 21.50s
Train Epoch: 208 [20480/90000 (23%)]	Loss: 15.4710	Cost: 6.18s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 15.3726	Cost: 6.61s
Train Epoch: 208 [61440/90000 (68%)]	Loss: 15.3440	Cost: 6.13s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 15.3494	Cost: 6.32s
Train Epoch: 208 	Average Loss: 15.4201
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8925

Learning rate: 0.0001997865766766892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 15.7225	Cost: 20.01s
Train Epoch: 209 [20480/90000 (23%)]	Loss: 15.2100	Cost: 6.08s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 15.4790	Cost: 5.96s
Train Epoch: 209 [61440/90000 (68%)]	Loss: 15.3460	Cost: 6.03s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 15.3341	Cost: 6.00s
Train Epoch: 209 	Average Loss: 15.4192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9468

Learning rate: 0.00019978452033538524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 15.3673	Cost: 20.09s
Train Epoch: 210 [20480/90000 (23%)]	Loss: 15.3267	Cost: 6.09s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 15.4135	Cost: 6.14s
Train Epoch: 210 [61440/90000 (68%)]	Loss: 15.4188	Cost: 5.98s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 15.3974	Cost: 6.76s
Train Epoch: 210 	Average Loss: 15.4250
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9671

Learning rate: 0.00019978245414574395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 15.5631	Cost: 20.40s
Train Epoch: 211 [20480/90000 (23%)]	Loss: 15.5211	Cost: 6.13s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 15.4891	Cost: 6.52s
Train Epoch: 211 [61440/90000 (68%)]	Loss: 15.1540	Cost: 6.01s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 15.5128	Cost: 6.50s
Train Epoch: 211 	Average Loss: 15.4150
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9369

Learning rate: 0.00019978037810796924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 15.6206	Cost: 21.32s
Train Epoch: 212 [20480/90000 (23%)]	Loss: 15.3871	Cost: 6.16s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 15.5547	Cost: 6.29s
Train Epoch: 212 [61440/90000 (68%)]	Loss: 15.1094	Cost: 5.99s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 15.2410	Cost: 6.45s
Train Epoch: 212 	Average Loss: 15.4047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8560

Saving model as e212_model.pt & e212_waveforms_supplementary.hdf5
Learning rate: 0.000199778292222266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 15.4584	Cost: 20.58s
Train Epoch: 213 [20480/90000 (23%)]	Loss: 15.3269	Cost: 6.17s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 15.3176	Cost: 7.10s
Train Epoch: 213 [61440/90000 (68%)]	Loss: 15.4070	Cost: 5.98s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 15.3286	Cost: 6.60s
Train Epoch: 213 	Average Loss: 15.4082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9558

Learning rate: 0.00019977619648884015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 15.4270	Cost: 21.60s
Train Epoch: 214 [20480/90000 (23%)]	Loss: 15.3093	Cost: 6.11s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 15.4188	Cost: 6.08s
Train Epoch: 214 [61440/90000 (68%)]	Loss: 15.4016	Cost: 6.19s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 15.4576	Cost: 5.87s
Train Epoch: 214 	Average Loss: 15.4015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8697

Learning rate: 0.0001997740909078985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 15.4265	Cost: 20.60s
Train Epoch: 215 [20480/90000 (23%)]	Loss: 15.3802	Cost: 6.39s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 15.3503	Cost: 6.16s
Train Epoch: 215 [61440/90000 (68%)]	Loss: 15.3272	Cost: 6.20s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 15.3573	Cost: 6.71s
Train Epoch: 215 	Average Loss: 15.4171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8769

Learning rate: 0.0001997719754796489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 15.5845	Cost: 20.94s
Train Epoch: 216 [20480/90000 (23%)]	Loss: 15.1799	Cost: 6.15s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 15.2077	Cost: 6.13s
Train Epoch: 216 [61440/90000 (68%)]	Loss: 15.4236	Cost: 6.04s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 15.3922	Cost: 7.08s
Train Epoch: 216 	Average Loss: 15.3987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9066

Learning rate: 0.00019976985020430003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 15.4157	Cost: 20.45s
Train Epoch: 217 [20480/90000 (23%)]	Loss: 15.3968	Cost: 6.21s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 15.1864	Cost: 6.39s
Train Epoch: 217 [61440/90000 (68%)]	Loss: 15.2049	Cost: 6.09s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 15.4399	Cost: 5.96s
Train Epoch: 217 	Average Loss: 15.3411
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8928

Learning rate: 0.00019976771508206176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 15.2653	Cost: 20.37s
Train Epoch: 218 [20480/90000 (23%)]	Loss: 15.2578	Cost: 6.23s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 15.4049	Cost: 6.14s
Train Epoch: 218 [61440/90000 (68%)]	Loss: 15.2935	Cost: 6.08s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 15.3976	Cost: 6.03s
Train Epoch: 218 	Average Loss: 15.3036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8919

Learning rate: 0.00019976557011314476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 15.6056	Cost: 21.06s
Train Epoch: 219 [20480/90000 (23%)]	Loss: 15.3571	Cost: 6.13s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 15.4262	Cost: 6.46s
Train Epoch: 219 [61440/90000 (68%)]	Loss: 15.3668	Cost: 5.97s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 15.2972	Cost: 6.13s
Train Epoch: 219 	Average Loss: 15.3704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8294

Saving model as e219_model.pt & e219_waveforms_supplementary.hdf5
Learning rate: 0.00019976341529776072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 15.6176	Cost: 21.37s
Train Epoch: 220 [20480/90000 (23%)]	Loss: 15.4125	Cost: 6.04s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 15.2979	Cost: 6.67s
Train Epoch: 220 [61440/90000 (68%)]	Loss: 15.0477	Cost: 5.95s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 15.4684	Cost: 5.95s
Train Epoch: 220 	Average Loss: 15.3605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9429

Learning rate: 0.00019976125063612233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 15.6628	Cost: 21.58s
Train Epoch: 221 [20480/90000 (23%)]	Loss: 15.3501	Cost: 6.14s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 15.3704	Cost: 6.63s
Train Epoch: 221 [61440/90000 (68%)]	Loss: 15.3143	Cost: 6.27s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 15.4136	Cost: 5.99s
Train Epoch: 221 	Average Loss: 15.3239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8822

Learning rate: 0.00019975907612844327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 15.2597	Cost: 21.40s
Train Epoch: 222 [20480/90000 (23%)]	Loss: 15.2640	Cost: 6.11s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 15.4715	Cost: 6.55s
Train Epoch: 222 [61440/90000 (68%)]	Loss: 15.3382	Cost: 6.22s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 15.1515	Cost: 5.83s
Train Epoch: 222 	Average Loss: 15.3099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8058

Saving model as e222_model.pt & e222_waveforms_supplementary.hdf5
Learning rate: 0.00019975689177493812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 15.5403	Cost: 21.10s
Train Epoch: 223 [20480/90000 (23%)]	Loss: 15.2770	Cost: 6.07s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 15.2898	Cost: 6.10s
Train Epoch: 223 [61440/90000 (68%)]	Loss: 15.4597	Cost: 5.96s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 15.3500	Cost: 6.25s
Train Epoch: 223 	Average Loss: 15.3672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8621

Learning rate: 0.00019975469757582245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 15.4386	Cost: 20.40s
Train Epoch: 224 [20480/90000 (23%)]	Loss: 15.3830	Cost: 6.13s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 15.3224	Cost: 6.40s
Train Epoch: 224 [61440/90000 (68%)]	Loss: 15.3881	Cost: 5.96s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 15.3841	Cost: 6.63s
Train Epoch: 224 	Average Loss: 15.3205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9346

Learning rate: 0.00019975249353131286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 15.4381	Cost: 20.23s
Train Epoch: 225 [20480/90000 (23%)]	Loss: 15.3035	Cost: 6.28s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 15.2746	Cost: 6.13s
Train Epoch: 225 [61440/90000 (68%)]	Loss: 15.1964	Cost: 6.11s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 15.4411	Cost: 6.01s
Train Epoch: 225 	Average Loss: 15.3140
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9101

Learning rate: 0.00019975027964162683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 15.5546	Cost: 20.67s
Train Epoch: 226 [20480/90000 (23%)]	Loss: 15.2926	Cost: 6.10s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 15.1691	Cost: 6.13s
Train Epoch: 226 [61440/90000 (68%)]	Loss: 15.3960	Cost: 6.13s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 15.2673	Cost: 5.90s
Train Epoch: 226 	Average Loss: 15.3280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9010

Learning rate: 0.0001997480559069829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 15.3900	Cost: 20.78s
Train Epoch: 227 [20480/90000 (23%)]	Loss: 15.2769	Cost: 6.17s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 15.3010	Cost: 6.21s
Train Epoch: 227 [61440/90000 (68%)]	Loss: 15.2015	Cost: 6.03s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 15.4938	Cost: 6.29s
Train Epoch: 227 	Average Loss: 15.3036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8254

Learning rate: 0.00019974582232760058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 15.3477	Cost: 20.78s
Train Epoch: 228 [20480/90000 (23%)]	Loss: 15.1030	Cost: 6.12s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 15.3447	Cost: 6.24s
Train Epoch: 228 [61440/90000 (68%)]	Loss: 15.1884	Cost: 6.03s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 15.3848	Cost: 6.00s
Train Epoch: 228 	Average Loss: 15.3024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9054

Learning rate: 0.0001997435789037002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 15.5631	Cost: 21.05s
Train Epoch: 229 [20480/90000 (23%)]	Loss: 15.4512	Cost: 6.17s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 15.1282	Cost: 6.56s
Train Epoch: 229 [61440/90000 (68%)]	Loss: 15.2018	Cost: 6.00s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 15.2074	Cost: 6.31s
Train Epoch: 229 	Average Loss: 15.3024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8772

Learning rate: 0.0001997413256355033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 15.2780	Cost: 21.03s
Train Epoch: 230 [20480/90000 (23%)]	Loss: 15.2215	Cost: 6.14s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 15.3487	Cost: 6.71s
Train Epoch: 230 [61440/90000 (68%)]	Loss: 15.2300	Cost: 6.18s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 15.2108	Cost: 6.25s
Train Epoch: 230 	Average Loss: 15.2843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8327

Learning rate: 0.0001997390625232322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 15.3812	Cost: 21.31s
Train Epoch: 231 [20480/90000 (23%)]	Loss: 15.2138	Cost: 6.23s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 15.2401	Cost: 6.22s
Train Epoch: 231 [61440/90000 (68%)]	Loss: 15.2378	Cost: 5.92s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 15.0847	Cost: 6.21s
Train Epoch: 231 	Average Loss: 15.2605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8330

Learning rate: 0.00019973678956711026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 15.4362	Cost: 20.79s
Train Epoch: 232 [20480/90000 (23%)]	Loss: 15.0958	Cost: 6.18s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 15.1977	Cost: 6.64s
Train Epoch: 232 [61440/90000 (68%)]	Loss: 15.2951	Cost: 5.94s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 15.1051	Cost: 6.86s
Train Epoch: 232 	Average Loss: 15.2771
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7620

Saving model as e232_model.pt & e232_waveforms_supplementary.hdf5
Learning rate: 0.00019973450676736185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 15.5803	Cost: 20.05s
Train Epoch: 233 [20480/90000 (23%)]	Loss: 15.2400	Cost: 6.21s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 15.3782	Cost: 6.23s
Train Epoch: 233 [61440/90000 (68%)]	Loss: 15.1386	Cost: 6.04s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 15.0750	Cost: 6.01s
Train Epoch: 233 	Average Loss: 15.2953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8958

Learning rate: 0.00019973221412421225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 15.6461	Cost: 20.76s
Train Epoch: 234 [20480/90000 (23%)]	Loss: 15.2298	Cost: 6.27s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 15.2632	Cost: 6.16s
Train Epoch: 234 [61440/90000 (68%)]	Loss: 15.2204	Cost: 5.96s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 15.2664	Cost: 6.08s
Train Epoch: 234 	Average Loss: 15.2908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8525

Learning rate: 0.0001997299116378877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 15.4750	Cost: 20.65s
Train Epoch: 235 [20480/90000 (23%)]	Loss: 15.3253	Cost: 6.14s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 15.1935	Cost: 6.38s
Train Epoch: 235 [61440/90000 (68%)]	Loss: 15.1491	Cost: 5.95s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 15.0985	Cost: 6.43s
Train Epoch: 235 	Average Loss: 15.2820
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7396

Saving model as e235_model.pt & e235_waveforms_supplementary.hdf5
Learning rate: 0.0001997275993086155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 15.3440	Cost: 20.78s
Train Epoch: 236 [20480/90000 (23%)]	Loss: 15.0982	Cost: 6.13s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 15.1720	Cost: 6.40s
Train Epoch: 236 [61440/90000 (68%)]	Loss: 15.5021	Cost: 5.95s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 15.1670	Cost: 6.63s
Train Epoch: 236 	Average Loss: 15.2745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8448

Learning rate: 0.0001997252771366239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 15.3762	Cost: 21.07s
Train Epoch: 237 [20480/90000 (23%)]	Loss: 15.1797	Cost: 6.14s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 15.1341	Cost: 6.32s
Train Epoch: 237 [61440/90000 (68%)]	Loss: 15.3473	Cost: 6.16s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 15.3439	Cost: 6.01s
Train Epoch: 237 	Average Loss: 15.2668
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8428

Learning rate: 0.000199722945122142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 15.4402	Cost: 21.16s
Train Epoch: 238 [20480/90000 (23%)]	Loss: 15.1629	Cost: 6.17s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 15.1131	Cost: 6.14s
Train Epoch: 238 [61440/90000 (68%)]	Loss: 15.1767	Cost: 6.01s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 15.0841	Cost: 6.35s
Train Epoch: 238 	Average Loss: 15.2378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7843

Learning rate: 0.0001997206032654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 15.4044	Cost: 21.02s
Train Epoch: 239 [20480/90000 (23%)]	Loss: 15.0119	Cost: 6.16s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 15.3740	Cost: 6.59s
Train Epoch: 239 [61440/90000 (68%)]	Loss: 15.1304	Cost: 5.91s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 15.2050	Cost: 7.05s
Train Epoch: 239 	Average Loss: 15.2141
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8131

Learning rate: 0.00019971825156662903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 15.4111	Cost: 21.20s
Train Epoch: 240 [20480/90000 (23%)]	Loss: 15.0329	Cost: 6.27s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 15.2776	Cost: 6.49s
Train Epoch: 240 [61440/90000 (68%)]	Loss: 15.1973	Cost: 6.08s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 15.3122	Cost: 6.32s
Train Epoch: 240 	Average Loss: 15.2712
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8233

Learning rate: 0.00019971589002606117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 15.4666	Cost: 19.95s
Train Epoch: 241 [20480/90000 (23%)]	Loss: 15.1109	Cost: 6.17s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 15.2498	Cost: 7.21s
Train Epoch: 241 [61440/90000 (68%)]	Loss: 15.0970	Cost: 6.01s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 15.3510	Cost: 5.93s
Train Epoch: 241 	Average Loss: 15.2595
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8846

Learning rate: 0.00019971351864392958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 15.5529	Cost: 21.08s
Train Epoch: 242 [20480/90000 (23%)]	Loss: 15.0148	Cost: 6.20s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 15.2962	Cost: 6.11s
Train Epoch: 242 [61440/90000 (68%)]	Loss: 15.0322	Cost: 5.96s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 15.0909	Cost: 6.68s
Train Epoch: 242 	Average Loss: 15.2290
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8870

Learning rate: 0.00019971113742046817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 15.3024	Cost: 20.80s
Train Epoch: 243 [20480/90000 (23%)]	Loss: 15.1609	Cost: 6.18s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 15.1594	Cost: 6.15s
Train Epoch: 243 [61440/90000 (68%)]	Loss: 15.0392	Cost: 5.94s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 15.1234	Cost: 5.90s
Train Epoch: 243 	Average Loss: 15.2085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7769

Learning rate: 0.00019970874635591207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 15.4516	Cost: 21.40s
Train Epoch: 244 [20480/90000 (23%)]	Loss: 15.1851	Cost: 6.14s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 15.2008	Cost: 6.04s
Train Epoch: 244 [61440/90000 (68%)]	Loss: 15.1139	Cost: 5.98s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 15.0562	Cost: 6.03s
Train Epoch: 244 	Average Loss: 15.2239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7948

Learning rate: 0.00019970634545049727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 15.3665	Cost: 20.02s
Train Epoch: 245 [20480/90000 (23%)]	Loss: 15.2075	Cost: 6.24s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 15.2666	Cost: 6.06s
Train Epoch: 245 [61440/90000 (68%)]	Loss: 15.0277	Cost: 5.96s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 15.3336	Cost: 5.89s
Train Epoch: 245 	Average Loss: 15.2282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8175

Learning rate: 0.0001997039347044607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 15.5150	Cost: 21.41s
Train Epoch: 246 [20480/90000 (23%)]	Loss: 15.4055	Cost: 6.19s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 15.1068	Cost: 6.13s
Train Epoch: 246 [61440/90000 (68%)]	Loss: 15.1689	Cost: 5.96s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 15.0471	Cost: 6.28s
Train Epoch: 246 	Average Loss: 15.2353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7777

Learning rate: 0.00019970151411804023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 15.3557	Cost: 21.55s
Train Epoch: 247 [20480/90000 (23%)]	Loss: 15.1853	Cost: 6.04s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 15.1039	Cost: 6.54s
Train Epoch: 247 [61440/90000 (68%)]	Loss: 15.2947	Cost: 6.03s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 15.1873	Cost: 6.69s
Train Epoch: 247 	Average Loss: 15.1752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7678

Learning rate: 0.00019969908369147485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 15.4406	Cost: 21.37s
Train Epoch: 248 [20480/90000 (23%)]	Loss: 15.1818	Cost: 6.15s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 15.1326	Cost: 6.23s
Train Epoch: 248 [61440/90000 (68%)]	Loss: 15.2449	Cost: 6.05s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 15.1797	Cost: 6.08s
Train Epoch: 248 	Average Loss: 15.2089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8034

Learning rate: 0.00019969664342500438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 15.6294	Cost: 20.56s
Train Epoch: 249 [20480/90000 (23%)]	Loss: 15.1384	Cost: 6.51s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 15.1313	Cost: 6.30s
Train Epoch: 249 [61440/90000 (68%)]	Loss: 15.1856	Cost: 5.94s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 15.0445	Cost: 6.28s
Train Epoch: 249 	Average Loss: 15.2118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7613

Learning rate: 0.00019969419331886966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 15.1966	Cost: 20.10s
Train Epoch: 250 [20480/90000 (23%)]	Loss: 15.0983	Cost: 6.14s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 15.0778	Cost: 6.31s
Train Epoch: 250 [61440/90000 (68%)]	Loss: 14.9914	Cost: 6.01s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 15.1800	Cost: 5.99s
Train Epoch: 250 	Average Loss: 15.1770
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7057

Saving model as e250_model.pt & e250_waveforms_supplementary.hdf5
Learning rate: 0.0001996917333733126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 15.3475	Cost: 20.09s
Train Epoch: 251 [20480/90000 (23%)]	Loss: 15.1101	Cost: 6.09s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 15.0502	Cost: 6.10s
Train Epoch: 251 [61440/90000 (68%)]	Loss: 15.3448	Cost: 6.12s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 15.1632	Cost: 6.12s
Train Epoch: 251 	Average Loss: 15.1950
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8200

Learning rate: 0.00019968926358857587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 15.3438	Cost: 21.40s
Train Epoch: 252 [20480/90000 (23%)]	Loss: 15.0674	Cost: 6.01s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 15.1653	Cost: 6.24s
Train Epoch: 252 [61440/90000 (68%)]	Loss: 15.1895	Cost: 5.93s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 15.4569	Cost: 5.95s
Train Epoch: 252 	Average Loss: 15.1842
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8024

Learning rate: 0.00019968678396490325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 15.3852	Cost: 21.40s
Train Epoch: 253 [20480/90000 (23%)]	Loss: 15.2479	Cost: 6.19s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 15.0621	Cost: 6.32s
Train Epoch: 253 [61440/90000 (68%)]	Loss: 15.0436	Cost: 5.99s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 15.1096	Cost: 5.93s
Train Epoch: 253 	Average Loss: 15.1621
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7368

Learning rate: 0.00019968429450253954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 15.4544	Cost: 21.66s
Train Epoch: 254 [20480/90000 (23%)]	Loss: 15.1116	Cost: 6.25s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 15.1456	Cost: 6.11s
Train Epoch: 254 [61440/90000 (68%)]	Loss: 15.0680	Cost: 6.10s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 15.1920	Cost: 6.13s
Train Epoch: 254 	Average Loss: 15.1582
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7977

Learning rate: 0.0001996817952017304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 15.4914	Cost: 20.60s
Train Epoch: 255 [20480/90000 (23%)]	Loss: 15.1873	Cost: 6.28s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 15.0120	Cost: 6.60s
Train Epoch: 255 [61440/90000 (68%)]	Loss: 15.0163	Cost: 5.95s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 15.2437	Cost: 5.89s
Train Epoch: 255 	Average Loss: 15.1919
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7644

Learning rate: 0.00019967928606272244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 15.3365	Cost: 21.09s
Train Epoch: 256 [20480/90000 (23%)]	Loss: 15.1246	Cost: 6.04s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 14.8619	Cost: 6.82s
Train Epoch: 256 [61440/90000 (68%)]	Loss: 15.0023	Cost: 6.12s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 15.0929	Cost: 6.17s
Train Epoch: 256 	Average Loss: 15.1408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7820

Learning rate: 0.0001996767670857634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 15.4858	Cost: 20.31s
Train Epoch: 257 [20480/90000 (23%)]	Loss: 15.1365	Cost: 6.15s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 14.8273	Cost: 6.72s
Train Epoch: 257 [61440/90000 (68%)]	Loss: 15.2650	Cost: 6.11s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 15.1436	Cost: 6.03s
Train Epoch: 257 	Average Loss: 15.1369
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8639

Learning rate: 0.00019967423827110182
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 15.2670	Cost: 20.12s
Train Epoch: 258 [20480/90000 (23%)]	Loss: 15.1522	Cost: 6.18s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 14.9987	Cost: 6.18s
Train Epoch: 258 [61440/90000 (68%)]	Loss: 15.0954	Cost: 6.07s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 15.2197	Cost: 6.02s
Train Epoch: 258 	Average Loss: 15.1464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7803

Learning rate: 0.00019967169961898734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 15.3694	Cost: 21.09s
Train Epoch: 259 [20480/90000 (23%)]	Loss: 15.1307	Cost: 6.42s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 15.0546	Cost: 6.29s
Train Epoch: 259 [61440/90000 (68%)]	Loss: 15.2364	Cost: 6.31s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 15.1684	Cost: 5.92s
Train Epoch: 259 	Average Loss: 15.1403
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6798

Saving model as e259_model.pt & e259_waveforms_supplementary.hdf5
Learning rate: 0.00019966915112967047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 15.4774	Cost: 20.90s
Train Epoch: 260 [20480/90000 (23%)]	Loss: 14.9959	Cost: 6.42s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 15.1420	Cost: 6.18s
Train Epoch: 260 [61440/90000 (68%)]	Loss: 15.0640	Cost: 6.10s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 15.1173	Cost: 6.26s
Train Epoch: 260 	Average Loss: 15.1254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8325

Learning rate: 0.00019966659280340273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 15.4089	Cost: 21.17s
Train Epoch: 261 [20480/90000 (23%)]	Loss: 15.1366	Cost: 6.31s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 15.0813	Cost: 6.21s
Train Epoch: 261 [61440/90000 (68%)]	Loss: 14.9218	Cost: 6.04s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 14.9855	Cost: 6.20s
Train Epoch: 261 	Average Loss: 15.1045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7276

Learning rate: 0.00019966402464043667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 15.6056	Cost: 21.65s
Train Epoch: 262 [20480/90000 (23%)]	Loss: 14.8917	Cost: 6.17s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 15.1190	Cost: 6.57s
Train Epoch: 262 [61440/90000 (68%)]	Loss: 15.0056	Cost: 6.00s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 15.1229	Cost: 6.18s
Train Epoch: 262 	Average Loss: 15.1328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7636

Learning rate: 0.00019966144664102572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 15.3949	Cost: 20.80s
Train Epoch: 263 [20480/90000 (23%)]	Loss: 15.1261	Cost: 6.24s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 15.0037	Cost: 6.29s
Train Epoch: 263 [61440/90000 (68%)]	Loss: 15.0614	Cost: 5.97s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 15.1892	Cost: 6.11s
Train Epoch: 263 	Average Loss: 15.1278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7296

Learning rate: 0.00019965885880542434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 15.3042	Cost: 21.35s
Train Epoch: 264 [20480/90000 (23%)]	Loss: 15.1610	Cost: 6.04s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 15.0968	Cost: 6.91s
Train Epoch: 264 [61440/90000 (68%)]	Loss: 14.9033	Cost: 5.97s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 15.1348	Cost: 6.61s
Train Epoch: 264 	Average Loss: 15.1300
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7479

Learning rate: 0.00019965626113388794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 15.3572	Cost: 20.35s
Train Epoch: 265 [20480/90000 (23%)]	Loss: 14.9749	Cost: 6.20s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 15.1374	Cost: 6.42s
Train Epoch: 265 [61440/90000 (68%)]	Loss: 15.0511	Cost: 5.99s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 14.9932	Cost: 6.87s
Train Epoch: 265 	Average Loss: 15.0856
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7492

Learning rate: 0.00019965365362667288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 15.2134	Cost: 20.80s
Train Epoch: 266 [20480/90000 (23%)]	Loss: 14.8299	Cost: 6.16s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 15.2950	Cost: 6.38s
Train Epoch: 266 [61440/90000 (68%)]	Loss: 15.0711	Cost: 6.10s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 15.0186	Cost: 5.92s
Train Epoch: 266 	Average Loss: 15.1179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7994

Learning rate: 0.0001996510362840365
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 15.3949	Cost: 21.17s
Train Epoch: 267 [20480/90000 (23%)]	Loss: 14.9837	Cost: 6.14s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 15.0943	Cost: 6.29s
Train Epoch: 267 [61440/90000 (68%)]	Loss: 15.1445	Cost: 5.96s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 15.0647	Cost: 6.11s
Train Epoch: 267 	Average Loss: 15.1072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7456

Learning rate: 0.00019964840910623716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 15.3048	Cost: 20.66s
Train Epoch: 268 [20480/90000 (23%)]	Loss: 14.9079	Cost: 6.06s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 15.0650	Cost: 6.11s
Train Epoch: 268 [61440/90000 (68%)]	Loss: 15.0728	Cost: 6.20s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 14.9964	Cost: 6.11s
Train Epoch: 268 	Average Loss: 15.0923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7069

Learning rate: 0.00019964577209353413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 15.3552	Cost: 20.32s
Train Epoch: 269 [20480/90000 (23%)]	Loss: 15.1063	Cost: 6.17s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 15.0569	Cost: 6.38s
Train Epoch: 269 [61440/90000 (68%)]	Loss: 15.1899	Cost: 6.05s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 14.8106	Cost: 6.27s
Train Epoch: 269 	Average Loss: 15.0945
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6968

Learning rate: 0.00019964312524618766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 15.4659	Cost: 20.66s
Train Epoch: 270 [20480/90000 (23%)]	Loss: 15.0318	Cost: 6.23s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 15.0281	Cost: 6.26s
Train Epoch: 270 [61440/90000 (68%)]	Loss: 15.0325	Cost: 5.95s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 14.9831	Cost: 5.96s
Train Epoch: 270 	Average Loss: 15.0519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6602

Saving model as e270_model.pt & e270_waveforms_supplementary.hdf5
Learning rate: 0.000199640468564459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 15.1727	Cost: 20.92s
Train Epoch: 271 [20480/90000 (23%)]	Loss: 15.0654	Cost: 6.20s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 15.1230	Cost: 6.27s
Train Epoch: 271 [61440/90000 (68%)]	Loss: 14.9287	Cost: 6.00s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 14.9873	Cost: 6.35s
Train Epoch: 271 	Average Loss: 15.0745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7774

Learning rate: 0.00019963780204861037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 15.3281	Cost: 21.41s
Train Epoch: 272 [20480/90000 (23%)]	Loss: 15.1609	Cost: 6.15s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 14.9904	Cost: 6.05s
Train Epoch: 272 [61440/90000 (68%)]	Loss: 15.0542	Cost: 6.13s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 14.9457	Cost: 6.12s
Train Epoch: 272 	Average Loss: 15.0876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6964

Learning rate: 0.0001996351256989049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 15.4515	Cost: 20.21s
Train Epoch: 273 [20480/90000 (23%)]	Loss: 15.0860	Cost: 6.18s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 15.1201	Cost: 6.14s
Train Epoch: 273 [61440/90000 (68%)]	Loss: 14.9307	Cost: 6.04s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 15.0963	Cost: 6.08s
Train Epoch: 273 	Average Loss: 15.0793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6745

Learning rate: 0.0001996324395156068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 15.2499	Cost: 20.57s
Train Epoch: 274 [20480/90000 (23%)]	Loss: 15.1273	Cost: 6.17s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 15.1561	Cost: 6.13s
Train Epoch: 274 [61440/90000 (68%)]	Loss: 15.0067	Cost: 6.40s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 14.9765	Cost: 5.95s
Train Epoch: 274 	Average Loss: 15.0863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7616

Learning rate: 0.00019962974349898107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 15.4518	Cost: 21.18s
Train Epoch: 275 [20480/90000 (23%)]	Loss: 14.9507	Cost: 6.31s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 15.1181	Cost: 6.44s
Train Epoch: 275 [61440/90000 (68%)]	Loss: 15.0914	Cost: 6.03s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 15.1762	Cost: 6.04s
Train Epoch: 275 	Average Loss: 15.0622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6139

Saving model as e275_model.pt & e275_waveforms_supplementary.hdf5
Learning rate: 0.0001996270376492939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 15.2643	Cost: 20.07s
Train Epoch: 276 [20480/90000 (23%)]	Loss: 15.0426	Cost: 6.15s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 14.8465	Cost: 6.23s
Train Epoch: 276 [61440/90000 (68%)]	Loss: 14.9021	Cost: 6.28s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 14.9010	Cost: 5.92s
Train Epoch: 276 	Average Loss: 15.0628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6812

Learning rate: 0.00019962432196681234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 15.2946	Cost: 20.78s
Train Epoch: 277 [20480/90000 (23%)]	Loss: 14.9814	Cost: 6.27s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 15.0362	Cost: 6.21s
Train Epoch: 277 [61440/90000 (68%)]	Loss: 14.8750	Cost: 6.03s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 14.9411	Cost: 6.08s
Train Epoch: 277 	Average Loss: 15.0220
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7740

Learning rate: 0.00019962159645180437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 15.2896	Cost: 21.19s
Train Epoch: 278 [20480/90000 (23%)]	Loss: 15.1261	Cost: 6.33s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 14.9694	Cost: 6.30s
Train Epoch: 278 [61440/90000 (68%)]	Loss: 15.0082	Cost: 6.05s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 14.9929	Cost: 5.99s
Train Epoch: 278 	Average Loss: 15.1106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6180

Learning rate: 0.00019961886110453903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 15.2400	Cost: 19.64s
Train Epoch: 279 [20480/90000 (23%)]	Loss: 15.0015	Cost: 6.27s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 15.1452	Cost: 6.12s
Train Epoch: 279 [61440/90000 (68%)]	Loss: 14.8493	Cost: 5.98s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 14.8733	Cost: 5.99s
Train Epoch: 279 	Average Loss: 15.0089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6253

Learning rate: 0.00019961611592528625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 15.2375	Cost: 22.30s
Train Epoch: 280 [20480/90000 (23%)]	Loss: 14.8939	Cost: 6.11s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 14.9025	Cost: 6.49s
Train Epoch: 280 [61440/90000 (68%)]	Loss: 14.9649	Cost: 5.92s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 14.9630	Cost: 6.09s
Train Epoch: 280 	Average Loss: 15.0362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7828

Learning rate: 0.000199613360914317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 15.4102	Cost: 20.13s
Train Epoch: 281 [20480/90000 (23%)]	Loss: 14.7228	Cost: 6.06s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 14.8972	Cost: 6.44s
Train Epoch: 281 [61440/90000 (68%)]	Loss: 15.0023	Cost: 5.98s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 14.9972	Cost: 5.95s
Train Epoch: 281 	Average Loss: 15.0221
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6935

Learning rate: 0.00019961059607190318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 15.3264	Cost: 21.19s
Train Epoch: 282 [20480/90000 (23%)]	Loss: 14.8706	Cost: 6.14s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 15.1362	Cost: 6.61s
Train Epoch: 282 [61440/90000 (68%)]	Loss: 14.9203	Cost: 5.93s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 15.0522	Cost: 6.64s
Train Epoch: 282 	Average Loss: 15.0425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7138

Learning rate: 0.00019960782139831766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 15.5006	Cost: 20.56s
Train Epoch: 283 [20480/90000 (23%)]	Loss: 15.2567	Cost: 6.16s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 15.1777	Cost: 6.36s
Train Epoch: 283 [61440/90000 (68%)]	Loss: 14.8959	Cost: 6.03s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 14.9674	Cost: 5.98s
Train Epoch: 283 	Average Loss: 15.0290
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6436

Learning rate: 0.00019960503689383428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 15.2004	Cost: 22.38s
Train Epoch: 284 [20480/90000 (23%)]	Loss: 15.0398	Cost: 6.00s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 15.0387	Cost: 7.05s
Train Epoch: 284 [61440/90000 (68%)]	Loss: 15.0592	Cost: 5.89s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 14.8945	Cost: 5.93s
Train Epoch: 284 	Average Loss: 15.0250
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5897

Saving model as e284_model.pt & e284_waveforms_supplementary.hdf5
Learning rate: 0.0001996022425587279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 15.3592	Cost: 21.77s
Train Epoch: 285 [20480/90000 (23%)]	Loss: 15.0802	Cost: 6.00s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 14.8151	Cost: 6.65s
Train Epoch: 285 [61440/90000 (68%)]	Loss: 14.8234	Cost: 5.89s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 14.8053	Cost: 6.22s
Train Epoch: 285 	Average Loss: 15.0076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7195

Learning rate: 0.0001995994383932743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 15.3249	Cost: 21.84s
Train Epoch: 286 [20480/90000 (23%)]	Loss: 15.0052	Cost: 6.24s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 14.9822	Cost: 5.93s
Train Epoch: 286 [61440/90000 (68%)]	Loss: 15.0753	Cost: 5.69s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 14.9929	Cost: 5.81s
Train Epoch: 286 	Average Loss: 15.0295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6529

Learning rate: 0.0001995966243977502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 15.1398	Cost: 21.24s
Train Epoch: 287 [20480/90000 (23%)]	Loss: 15.0214	Cost: 6.03s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 14.8025	Cost: 6.69s
Train Epoch: 287 [61440/90000 (68%)]	Loss: 14.9396	Cost: 5.94s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 14.9861	Cost: 5.88s
Train Epoch: 287 	Average Loss: 14.9911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7015

Learning rate: 0.0001995938005724334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 15.3353	Cost: 20.18s
Train Epoch: 288 [20480/90000 (23%)]	Loss: 14.9785	Cost: 6.06s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 14.9364	Cost: 6.70s
Train Epoch: 288 [61440/90000 (68%)]	Loss: 15.2549	Cost: 6.00s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 15.1882	Cost: 6.13s
Train Epoch: 288 	Average Loss: 15.0013
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6676

Learning rate: 0.00019959096691760252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 15.3263	Cost: 21.95s
Train Epoch: 289 [20480/90000 (23%)]	Loss: 14.9041	Cost: 5.98s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 14.8047	Cost: 6.48s
Train Epoch: 289 [61440/90000 (68%)]	Loss: 14.9739	Cost: 5.91s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 15.1568	Cost: 5.82s
Train Epoch: 289 	Average Loss: 15.0113
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6588

Learning rate: 0.00019958812343353726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 15.3150	Cost: 21.95s
Train Epoch: 290 [20480/90000 (23%)]	Loss: 14.9581	Cost: 5.94s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 15.0345	Cost: 7.08s
Train Epoch: 290 [61440/90000 (68%)]	Loss: 15.0223	Cost: 5.91s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 14.8373	Cost: 6.47s
Train Epoch: 290 	Average Loss: 15.0146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6892

Learning rate: 0.0001995852701205183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 15.0580	Cost: 21.56s
Train Epoch: 291 [20480/90000 (23%)]	Loss: 14.8072	Cost: 6.06s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 15.1048	Cost: 6.33s
Train Epoch: 291 [61440/90000 (68%)]	Loss: 14.9692	Cost: 5.93s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 14.8600	Cost: 5.95s
Train Epoch: 291 	Average Loss: 14.9638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7143

Learning rate: 0.0001995824069788272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 15.2329	Cost: 20.83s
Train Epoch: 292 [20480/90000 (23%)]	Loss: 14.8029	Cost: 6.12s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 14.9168	Cost: 6.34s
Train Epoch: 292 [61440/90000 (68%)]	Loss: 14.8375	Cost: 5.94s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 14.9623	Cost: 5.84s
Train Epoch: 292 	Average Loss: 14.9517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6372

Learning rate: 0.00019957953400874656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 15.2686	Cost: 20.84s
Train Epoch: 293 [20480/90000 (23%)]	Loss: 14.9704	Cost: 6.08s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 14.8603	Cost: 6.03s
Train Epoch: 293 [61440/90000 (68%)]	Loss: 14.8835	Cost: 5.93s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 15.0527	Cost: 5.84s
Train Epoch: 293 	Average Loss: 14.9571
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6668

Learning rate: 0.00019957665121055995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 15.4072	Cost: 19.95s
Train Epoch: 294 [20480/90000 (23%)]	Loss: 14.9494	Cost: 6.04s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 14.8299	Cost: 6.74s
Train Epoch: 294 [61440/90000 (68%)]	Loss: 14.8310	Cost: 5.91s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 14.9684	Cost: 6.15s
Train Epoch: 294 	Average Loss: 14.9885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5927

Learning rate: 0.00019957375858455185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 15.2550	Cost: 21.90s
Train Epoch: 295 [20480/90000 (23%)]	Loss: 14.6276	Cost: 6.01s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 14.7803	Cost: 6.55s
Train Epoch: 295 [61440/90000 (68%)]	Loss: 14.8163	Cost: 5.90s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 15.0410	Cost: 5.94s
Train Epoch: 295 	Average Loss: 14.9551
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7368

Learning rate: 0.00019957085613100776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 15.3422	Cost: 20.35s
Train Epoch: 296 [20480/90000 (23%)]	Loss: 14.7087	Cost: 6.12s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 14.8816	Cost: 6.41s
Train Epoch: 296 [61440/90000 (68%)]	Loss: 14.9844	Cost: 5.95s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 15.0260	Cost: 6.01s
Train Epoch: 296 	Average Loss: 14.9312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6432

Learning rate: 0.00019956794385021415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 15.1641	Cost: 21.33s
Train Epoch: 297 [20480/90000 (23%)]	Loss: 14.6457	Cost: 5.99s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 14.7525	Cost: 6.25s
Train Epoch: 297 [61440/90000 (68%)]	Loss: 14.8963	Cost: 5.88s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 14.8201	Cost: 6.12s
Train Epoch: 297 	Average Loss: 14.9576
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6340

Learning rate: 0.00019956502174245846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 15.2712	Cost: 19.95s
Train Epoch: 298 [20480/90000 (23%)]	Loss: 14.9171	Cost: 6.20s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 15.0509	Cost: 6.22s
Train Epoch: 298 [61440/90000 (68%)]	Loss: 14.9235	Cost: 5.93s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 14.7173	Cost: 5.77s
Train Epoch: 298 	Average Loss: 14.9196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7011

Learning rate: 0.0001995620898080291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 15.4449	Cost: 20.38s
Train Epoch: 299 [20480/90000 (23%)]	Loss: 14.7733	Cost: 6.05s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 14.8999	Cost: 6.02s
Train Epoch: 299 [61440/90000 (68%)]	Loss: 14.7254	Cost: 6.02s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 14.9232	Cost: 5.77s
Train Epoch: 299 	Average Loss: 14.9160
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7078

Learning rate: 0.00019955914804721542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 15.4339	Cost: 22.58s
Train Epoch: 300 [20480/90000 (23%)]	Loss: 14.9467	Cost: 5.94s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 15.1132	Cost: 6.48s
Train Epoch: 300 [61440/90000 (68%)]	Loss: 14.8548	Cost: 5.88s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 15.0217	Cost: 5.80s
Train Epoch: 300 	Average Loss: 14.9274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7127

Learning rate: 0.00019955619646030775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 15.3169	Cost: 19.57s
Train Epoch: 301 [20480/90000 (23%)]	Loss: 14.9724	Cost: 6.25s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 14.8840	Cost: 7.70s
Train Epoch: 301 [61440/90000 (68%)]	Loss: 15.0320	Cost: 5.92s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 15.0545	Cost: 6.24s
Train Epoch: 301 	Average Loss: 14.9577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6792

Learning rate: 0.0001995532350475974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 15.3267	Cost: 20.87s
Train Epoch: 302 [20480/90000 (23%)]	Loss: 14.8714	Cost: 6.07s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 14.8817	Cost: 6.86s
Train Epoch: 302 [61440/90000 (68%)]	Loss: 14.8415	Cost: 5.93s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 14.8436	Cost: 5.95s
Train Epoch: 302 	Average Loss: 14.8905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6177

Learning rate: 0.00019955026380937669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 15.2238	Cost: 20.69s
Train Epoch: 303 [20480/90000 (23%)]	Loss: 14.9050	Cost: 6.02s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 14.8209	Cost: 6.32s
Train Epoch: 303 [61440/90000 (68%)]	Loss: 14.8745	Cost: 5.89s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 14.8892	Cost: 5.81s
Train Epoch: 303 	Average Loss: 14.9131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6709

Learning rate: 0.00019954728274593884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 15.0358	Cost: 20.60s
Train Epoch: 304 [20480/90000 (23%)]	Loss: 14.8430	Cost: 6.09s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 14.8870	Cost: 6.75s
Train Epoch: 304 [61440/90000 (68%)]	Loss: 14.8446	Cost: 5.91s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 14.8530	Cost: 6.03s
Train Epoch: 304 	Average Loss: 14.9049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6371

Learning rate: 0.00019954429185757805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 15.2899	Cost: 20.70s
Train Epoch: 305 [20480/90000 (23%)]	Loss: 14.8209	Cost: 6.13s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 14.9760	Cost: 7.20s
Train Epoch: 305 [61440/90000 (68%)]	Loss: 14.7689	Cost: 5.88s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 14.8689	Cost: 6.06s
Train Epoch: 305 	Average Loss: 14.9473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6437

Learning rate: 0.00019954129114458955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 15.3015	Cost: 20.34s
Train Epoch: 306 [20480/90000 (23%)]	Loss: 14.7872	Cost: 6.05s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 14.9075	Cost: 6.27s
Train Epoch: 306 [61440/90000 (68%)]	Loss: 14.7593	Cost: 5.95s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 14.9449	Cost: 6.35s
Train Epoch: 306 	Average Loss: 14.9073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6925

Learning rate: 0.00019953828060726943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 15.5090	Cost: 20.19s
Train Epoch: 307 [20480/90000 (23%)]	Loss: 14.8543	Cost: 6.16s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 14.9541	Cost: 7.49s
Train Epoch: 307 [61440/90000 (68%)]	Loss: 14.9039	Cost: 5.91s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 14.8139	Cost: 6.16s
Train Epoch: 307 	Average Loss: 14.9653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7568

Learning rate: 0.00019953526024591494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 15.1928	Cost: 20.54s
Train Epoch: 308 [20480/90000 (23%)]	Loss: 15.0453	Cost: 6.19s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 14.7805	Cost: 7.21s
Train Epoch: 308 [61440/90000 (68%)]	Loss: 14.7680	Cost: 5.99s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 14.6586	Cost: 6.10s
Train Epoch: 308 	Average Loss: 14.9130
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6614

Learning rate: 0.00019953223006082406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 15.2789	Cost: 20.58s
Train Epoch: 309 [20480/90000 (23%)]	Loss: 15.0168	Cost: 6.14s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 14.7808	Cost: 7.53s
Train Epoch: 309 [61440/90000 (68%)]	Loss: 14.8864	Cost: 5.90s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 14.7904	Cost: 6.57s
Train Epoch: 309 	Average Loss: 14.8861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7239

Learning rate: 0.00019952919005229592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 15.1656	Cost: 21.91s
Train Epoch: 310 [20480/90000 (23%)]	Loss: 14.8063	Cost: 5.98s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 15.0124	Cost: 6.33s
Train Epoch: 310 [61440/90000 (68%)]	Loss: 14.8611	Cost: 6.15s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 14.9827	Cost: 5.84s
Train Epoch: 310 	Average Loss: 14.8604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6833

Learning rate: 0.00019952614022063054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 15.1039	Cost: 19.78s
Train Epoch: 311 [20480/90000 (23%)]	Loss: 14.9589	Cost: 6.24s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 14.8210	Cost: 6.39s
Train Epoch: 311 [61440/90000 (68%)]	Loss: 14.8298	Cost: 6.02s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 14.7744	Cost: 5.80s
Train Epoch: 311 	Average Loss: 14.8529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6892

Learning rate: 0.00019952308056612892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 15.5263	Cost: 20.65s
Train Epoch: 312 [20480/90000 (23%)]	Loss: 14.8957	Cost: 6.14s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 14.7051	Cost: 6.26s
Train Epoch: 312 [61440/90000 (68%)]	Loss: 14.7884	Cost: 5.97s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 14.8273	Cost: 5.86s
Train Epoch: 312 	Average Loss: 14.8763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6081

Learning rate: 0.00019952001108909304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 15.3972	Cost: 20.69s
Train Epoch: 313 [20480/90000 (23%)]	Loss: 14.8460	Cost: 6.03s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 14.9380	Cost: 6.37s
Train Epoch: 313 [61440/90000 (68%)]	Loss: 14.9110	Cost: 5.92s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 14.7900	Cost: 6.00s
Train Epoch: 313 	Average Loss: 14.8938
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6900

Learning rate: 0.00019951693178982586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 15.2539	Cost: 20.20s
Train Epoch: 314 [20480/90000 (23%)]	Loss: 14.6537	Cost: 6.27s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 14.9902	Cost: 6.20s
Train Epoch: 314 [61440/90000 (68%)]	Loss: 14.7864	Cost: 5.91s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 14.7427	Cost: 5.84s
Train Epoch: 314 	Average Loss: 14.8660
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6333

Learning rate: 0.00019951384266863126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 15.4318	Cost: 21.40s
Train Epoch: 315 [20480/90000 (23%)]	Loss: 14.8103	Cost: 6.02s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 14.7158	Cost: 6.65s
Train Epoch: 315 [61440/90000 (68%)]	Loss: 14.7343	Cost: 5.90s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 14.8985	Cost: 6.62s
Train Epoch: 315 	Average Loss: 14.8555
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7117

Learning rate: 0.00019951074372581416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 15.1458	Cost: 20.48s
Train Epoch: 316 [20480/90000 (23%)]	Loss: 14.9401	Cost: 6.16s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 14.9432	Cost: 6.75s
Train Epoch: 316 [61440/90000 (68%)]	Loss: 14.9012	Cost: 6.03s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 14.8705	Cost: 7.27s
Train Epoch: 316 	Average Loss: 14.8525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5520

Saving model as e316_model.pt & e316_waveforms_supplementary.hdf5
Learning rate: 0.00019950763496168037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 15.2575	Cost: 21.21s
Train Epoch: 317 [20480/90000 (23%)]	Loss: 14.8398	Cost: 6.13s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 15.0256	Cost: 6.38s
Train Epoch: 317 [61440/90000 (68%)]	Loss: 14.8543	Cost: 5.95s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 14.8725	Cost: 5.81s
Train Epoch: 317 	Average Loss: 14.8543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7008

Learning rate: 0.00019950451637653678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 15.1000	Cost: 20.39s
Train Epoch: 318 [20480/90000 (23%)]	Loss: 14.6692	Cost: 6.23s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 14.9441	Cost: 7.29s
Train Epoch: 318 [61440/90000 (68%)]	Loss: 14.7106	Cost: 5.95s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 14.8227	Cost: 6.56s
Train Epoch: 318 	Average Loss: 14.8268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6216

Learning rate: 0.00019950138797069118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 15.1405	Cost: 20.45s
Train Epoch: 319 [20480/90000 (23%)]	Loss: 14.6528	Cost: 6.10s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 14.6460	Cost: 6.20s
Train Epoch: 319 [61440/90000 (68%)]	Loss: 14.7171	Cost: 5.91s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 14.7072	Cost: 5.81s
Train Epoch: 319 	Average Loss: 14.8541
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6280

Learning rate: 0.00019949824974445222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 15.2092	Cost: 20.07s
Train Epoch: 320 [20480/90000 (23%)]	Loss: 14.8772	Cost: 6.02s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 14.7331	Cost: 6.51s
Train Epoch: 320 [61440/90000 (68%)]	Loss: 14.8048	Cost: 5.98s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 14.8631	Cost: 6.28s
Train Epoch: 320 	Average Loss: 14.8561
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6088

Learning rate: 0.00019949510169812976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 15.0385	Cost: 20.04s
Train Epoch: 321 [20480/90000 (23%)]	Loss: 14.8434	Cost: 6.05s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 14.7128	Cost: 6.34s
Train Epoch: 321 [61440/90000 (68%)]	Loss: 14.7141	Cost: 6.02s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 14.7091	Cost: 5.83s
Train Epoch: 321 	Average Loss: 14.8477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5758

Learning rate: 0.00019949194383203438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 15.1080	Cost: 21.07s
Train Epoch: 322 [20480/90000 (23%)]	Loss: 14.8028	Cost: 6.05s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 14.8970	Cost: 6.61s
Train Epoch: 322 [61440/90000 (68%)]	Loss: 14.6927	Cost: 5.92s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 14.7296	Cost: 6.09s
Train Epoch: 322 	Average Loss: 14.8426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5623

Learning rate: 0.00019948877614647787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 15.0102	Cost: 20.63s
Train Epoch: 323 [20480/90000 (23%)]	Loss: 14.9474	Cost: 6.00s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 14.7901	Cost: 6.03s
Train Epoch: 323 [61440/90000 (68%)]	Loss: 14.8346	Cost: 5.92s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 14.7110	Cost: 5.79s
Train Epoch: 323 	Average Loss: 14.8181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6023

Learning rate: 0.0001994855986417728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 15.3846	Cost: 19.91s
Train Epoch: 324 [20480/90000 (23%)]	Loss: 14.8041	Cost: 6.02s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 14.7748	Cost: 6.08s
Train Epoch: 324 [61440/90000 (68%)]	Loss: 14.6442	Cost: 5.93s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 14.7406	Cost: 5.77s
Train Epoch: 324 	Average Loss: 14.7841
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6629

Learning rate: 0.0001994824113182328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 15.2437	Cost: 20.35s
Train Epoch: 325 [20480/90000 (23%)]	Loss: 14.9622	Cost: 6.03s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 14.8358	Cost: 6.90s
Train Epoch: 325 [61440/90000 (68%)]	Loss: 14.7287	Cost: 5.78s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 14.7087	Cost: 6.23s
Train Epoch: 325 	Average Loss: 14.8023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6508

Learning rate: 0.00019947921417617242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 15.2891	Cost: 20.32s
Train Epoch: 326 [20480/90000 (23%)]	Loss: 14.7797	Cost: 6.18s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 14.9060	Cost: 6.90s
Train Epoch: 326 [61440/90000 (68%)]	Loss: 14.7640	Cost: 6.01s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 14.7811	Cost: 6.22s
Train Epoch: 326 	Average Loss: 14.8420
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6058

Learning rate: 0.0001994760072159072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 15.1939	Cost: 21.45s
Train Epoch: 327 [20480/90000 (23%)]	Loss: 14.7570	Cost: 6.17s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 14.8305	Cost: 7.06s
Train Epoch: 327 [61440/90000 (68%)]	Loss: 14.6317	Cost: 5.99s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 14.8122	Cost: 5.95s
Train Epoch: 327 	Average Loss: 14.8029
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6766

Learning rate: 0.00019947279043775368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 15.5176	Cost: 19.97s
Train Epoch: 328 [20480/90000 (23%)]	Loss: 14.8511	Cost: 6.11s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 14.7584	Cost: 6.45s
Train Epoch: 328 [61440/90000 (68%)]	Loss: 14.8016	Cost: 6.03s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 14.8503	Cost: 6.68s
Train Epoch: 328 	Average Loss: 14.8231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6761

Learning rate: 0.00019946956384202932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 15.2889	Cost: 20.60s
Train Epoch: 329 [20480/90000 (23%)]	Loss: 14.5930	Cost: 6.13s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 14.6379	Cost: 6.12s
Train Epoch: 329 [61440/90000 (68%)]	Loss: 14.6368	Cost: 5.91s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 14.3978	Cost: 6.10s
Train Epoch: 329 	Average Loss: 14.7519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6618

Learning rate: 0.00019946632742905265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 15.1785	Cost: 19.99s
Train Epoch: 330 [20480/90000 (23%)]	Loss: 14.6207	Cost: 6.11s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 14.7461	Cost: 6.35s
Train Epoch: 330 [61440/90000 (68%)]	Loss: 14.7174	Cost: 5.95s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 14.7550	Cost: 6.02s
Train Epoch: 330 	Average Loss: 14.8006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6181

Learning rate: 0.000199463081199143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 15.1621	Cost: 22.33s
Train Epoch: 331 [20480/90000 (23%)]	Loss: 14.8287	Cost: 6.19s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 14.5926	Cost: 6.14s
Train Epoch: 331 [61440/90000 (68%)]	Loss: 14.6871	Cost: 6.12s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 14.6956	Cost: 5.89s
Train Epoch: 331 	Average Loss: 14.7684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6731

Learning rate: 0.0001994598251526208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 15.1432	Cost: 22.58s
Train Epoch: 332 [20480/90000 (23%)]	Loss: 14.6589	Cost: 5.98s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 14.5672	Cost: 7.02s
Train Epoch: 332 [61440/90000 (68%)]	Loss: 14.8310	Cost: 5.91s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 14.7189	Cost: 6.17s
Train Epoch: 332 	Average Loss: 14.7658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6719

Learning rate: 0.00019945655928980737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 15.1289	Cost: 21.38s
Train Epoch: 333 [20480/90000 (23%)]	Loss: 14.4124	Cost: 6.07s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 14.7341	Cost: 6.62s
Train Epoch: 333 [61440/90000 (68%)]	Loss: 14.8982	Cost: 5.93s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 14.6013	Cost: 6.17s
Train Epoch: 333 	Average Loss: 14.7460
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7119

Learning rate: 0.0001994532836110251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 15.2229	Cost: 21.77s
Train Epoch: 334 [20480/90000 (23%)]	Loss: 14.4763	Cost: 6.21s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 14.6112	Cost: 6.31s
Train Epoch: 334 [61440/90000 (68%)]	Loss: 14.7583	Cost: 5.99s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 14.6962	Cost: 5.99s
Train Epoch: 334 	Average Loss: 14.7402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6272

Learning rate: 0.00019944999811659725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 15.0700	Cost: 22.22s
Train Epoch: 335 [20480/90000 (23%)]	Loss: 14.5483	Cost: 6.10s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 14.6941	Cost: 6.51s
Train Epoch: 335 [61440/90000 (68%)]	Loss: 14.7741	Cost: 5.92s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 14.6307	Cost: 6.39s
Train Epoch: 335 	Average Loss: 14.7897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6120

Learning rate: 0.00019944670280684805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 15.3854	Cost: 20.59s
Train Epoch: 336 [20480/90000 (23%)]	Loss: 14.5965	Cost: 6.10s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 14.8432	Cost: 6.77s
Train Epoch: 336 [61440/90000 (68%)]	Loss: 14.6619	Cost: 5.91s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 14.7721	Cost: 5.98s
Train Epoch: 336 	Average Loss: 14.7723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6436

Learning rate: 0.00019944339768210285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 15.0014	Cost: 20.74s
Train Epoch: 337 [20480/90000 (23%)]	Loss: 14.8479	Cost: 6.21s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 14.7195	Cost: 6.97s
Train Epoch: 337 [61440/90000 (68%)]	Loss: 14.8917	Cost: 5.89s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 14.7171	Cost: 5.93s
Train Epoch: 337 	Average Loss: 14.7278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6620

Learning rate: 0.0001994400827426877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 15.1586	Cost: 21.88s
Train Epoch: 338 [20480/90000 (23%)]	Loss: 14.6746	Cost: 6.07s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 14.7142	Cost: 7.62s
Train Epoch: 338 [61440/90000 (68%)]	Loss: 14.7739	Cost: 5.88s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 14.7785	Cost: 6.26s
Train Epoch: 338 	Average Loss: 14.7440
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6152

Learning rate: 0.0001994367579889299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 15.3800	Cost: 21.78s
Train Epoch: 339 [20480/90000 (23%)]	Loss: 14.6757	Cost: 5.94s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 14.6721	Cost: 6.63s
Train Epoch: 339 [61440/90000 (68%)]	Loss: 14.6686	Cost: 5.93s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 14.8133	Cost: 5.86s
Train Epoch: 339 	Average Loss: 14.7392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6164

Learning rate: 0.0001994334234211575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 15.2342	Cost: 21.64s
Train Epoch: 340 [20480/90000 (23%)]	Loss: 14.5501	Cost: 6.12s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 14.7030	Cost: 6.37s
Train Epoch: 340 [61440/90000 (68%)]	Loss: 14.7221	Cost: 5.92s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 14.6943	Cost: 6.16s
Train Epoch: 340 	Average Loss: 14.7305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6642

Learning rate: 0.00019943007903969968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 15.0346	Cost: 21.76s
Train Epoch: 341 [20480/90000 (23%)]	Loss: 14.4469	Cost: 6.04s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 14.6889	Cost: 7.25s
Train Epoch: 341 [61440/90000 (68%)]	Loss: 14.8444	Cost: 5.88s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 14.6385	Cost: 6.16s
Train Epoch: 341 	Average Loss: 14.7315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6616

Learning rate: 0.00019942672484488645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 15.1805	Cost: 22.07s
Train Epoch: 342 [20480/90000 (23%)]	Loss: 14.5192	Cost: 6.03s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 14.7271	Cost: 7.14s
Train Epoch: 342 [61440/90000 (68%)]	Loss: 14.8758	Cost: 5.87s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 14.7384	Cost: 5.94s
Train Epoch: 342 	Average Loss: 14.7382
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6151

Learning rate: 0.0001994233608370489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 15.2615	Cost: 20.74s
Train Epoch: 343 [20480/90000 (23%)]	Loss: 14.6367	Cost: 6.05s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 14.6515	Cost: 6.47s
Train Epoch: 343 [61440/90000 (68%)]	Loss: 14.5874	Cost: 5.89s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 14.4980	Cost: 5.96s
Train Epoch: 343 	Average Loss: 14.7312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6363

Learning rate: 0.00019941998701651908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 15.3494	Cost: 21.09s
Train Epoch: 344 [20480/90000 (23%)]	Loss: 14.5084	Cost: 6.06s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 14.8149	Cost: 6.67s
Train Epoch: 344 [61440/90000 (68%)]	Loss: 14.5316	Cost: 5.87s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 14.6719	Cost: 6.12s
Train Epoch: 344 	Average Loss: 14.7281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6317

Learning rate: 0.00019941660338362987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 15.3452	Cost: 20.81s
Train Epoch: 345 [20480/90000 (23%)]	Loss: 14.7926	Cost: 6.00s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 14.6050	Cost: 6.75s
Train Epoch: 345 [61440/90000 (68%)]	Loss: 14.5108	Cost: 5.87s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 14.6330	Cost: 6.52s
Train Epoch: 345 	Average Loss: 14.7172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6514

Learning rate: 0.0001994132099387153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 15.1800	Cost: 21.42s
Train Epoch: 346 [20480/90000 (23%)]	Loss: 14.5926	Cost: 6.07s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 14.6139	Cost: 6.43s
Train Epoch: 346 [61440/90000 (68%)]	Loss: 14.7730	Cost: 5.89s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 14.6909	Cost: 6.38s
Train Epoch: 346 	Average Loss: 14.7039
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6331

Learning rate: 0.00019940980668211027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 15.0129	Cost: 19.88s
Train Epoch: 347 [20480/90000 (23%)]	Loss: 14.7024	Cost: 6.03s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 14.6359	Cost: 6.05s
Train Epoch: 347 [61440/90000 (68%)]	Loss: 14.6340	Cost: 5.94s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 14.5942	Cost: 5.78s
Train Epoch: 347 	Average Loss: 14.7277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6862

Learning rate: 0.00019940639361415064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 14.9255	Cost: 21.69s
Train Epoch: 348 [20480/90000 (23%)]	Loss: 14.6500	Cost: 6.07s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 14.5270	Cost: 7.27s
Train Epoch: 348 [61440/90000 (68%)]	Loss: 14.5626	Cost: 5.85s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 14.6784	Cost: 6.72s
Train Epoch: 348 	Average Loss: 14.6965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6390

Learning rate: 0.00019940297073517331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 15.3074	Cost: 20.70s
Train Epoch: 349 [20480/90000 (23%)]	Loss: 14.6335	Cost: 6.04s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 14.6571	Cost: 6.79s
Train Epoch: 349 [61440/90000 (68%)]	Loss: 14.6196	Cost: 5.94s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 14.5546	Cost: 5.82s
Train Epoch: 349 	Average Loss: 14.6859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6396

Learning rate: 0.00019939953804551608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 15.2706	Cost: 20.64s
Train Epoch: 350 [20480/90000 (23%)]	Loss: 14.7904	Cost: 5.98s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 14.6836	Cost: 6.00s
Train Epoch: 350 [61440/90000 (68%)]	Loss: 14.7184	Cost: 5.87s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 14.5125	Cost: 6.38s
Train Epoch: 350 	Average Loss: 14.6792
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6763

Learning rate: 0.00019939609554551777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 15.2310	Cost: 21.23s
Train Epoch: 351 [20480/90000 (23%)]	Loss: 14.4405	Cost: 5.84s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 14.7476	Cost: 6.96s
Train Epoch: 351 [61440/90000 (68%)]	Loss: 14.5300	Cost: 5.88s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 14.7343	Cost: 5.84s
Train Epoch: 351 	Average Loss: 14.6978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6810

Learning rate: 0.0001993926432355181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 15.1898	Cost: 20.69s
Train Epoch: 352 [20480/90000 (23%)]	Loss: 14.3878	Cost: 6.12s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 14.5286	Cost: 6.17s
Train Epoch: 352 [61440/90000 (68%)]	Loss: 14.6418	Cost: 6.07s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 14.6178	Cost: 5.95s
Train Epoch: 352 	Average Loss: 14.6621
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6551

Learning rate: 0.00019938918111585784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 15.3266	Cost: 21.55s
Train Epoch: 353 [20480/90000 (23%)]	Loss: 14.4320	Cost: 5.99s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 14.5115	Cost: 6.61s
Train Epoch: 353 [61440/90000 (68%)]	Loss: 14.5280	Cost: 5.93s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 14.6127	Cost: 6.53s
Train Epoch: 353 	Average Loss: 14.6786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5631

Learning rate: 0.00019938570918687863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 15.0453	Cost: 20.53s
Train Epoch: 354 [20480/90000 (23%)]	Loss: 14.5230	Cost: 5.99s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 14.6680	Cost: 6.02s
Train Epoch: 354 [61440/90000 (68%)]	Loss: 14.5825	Cost: 5.85s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 14.5809	Cost: 5.82s
Train Epoch: 354 	Average Loss: 14.6418
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7064

Learning rate: 0.0001993822274489232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 15.3253	Cost: 23.19s
Train Epoch: 355 [20480/90000 (23%)]	Loss: 14.6412	Cost: 5.95s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 14.6204	Cost: 6.36s
Train Epoch: 355 [61440/90000 (68%)]	Loss: 14.7151	Cost: 5.68s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 14.3851	Cost: 6.01s
Train Epoch: 355 	Average Loss: 14.6728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6674

Learning rate: 0.00019937873590233516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 15.2318	Cost: 22.04s
Train Epoch: 356 [20480/90000 (23%)]	Loss: 14.6951	Cost: 5.98s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 14.4249	Cost: 6.34s
Train Epoch: 356 [61440/90000 (68%)]	Loss: 14.4578	Cost: 5.88s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 14.5704	Cost: 5.85s
Train Epoch: 356 	Average Loss: 14.6460
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6232

Learning rate: 0.0001993752345474591
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 15.1771	Cost: 21.62s
Train Epoch: 357 [20480/90000 (23%)]	Loss: 14.4589	Cost: 5.98s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 14.5020	Cost: 6.23s
Train Epoch: 357 [61440/90000 (68%)]	Loss: 14.5197	Cost: 5.90s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 14.5285	Cost: 6.94s
Train Epoch: 357 	Average Loss: 14.6494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5674

Learning rate: 0.0001993717233846406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 15.2621	Cost: 20.07s
Train Epoch: 358 [20480/90000 (23%)]	Loss: 14.6922	Cost: 6.00s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 14.6840	Cost: 6.80s
Train Epoch: 358 [61440/90000 (68%)]	Loss: 14.5222	Cost: 5.88s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 14.5926	Cost: 6.02s
Train Epoch: 358 	Average Loss: 14.6654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6663

Learning rate: 0.0001993682024142262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 15.4260	Cost: 22.40s
Train Epoch: 359 [20480/90000 (23%)]	Loss: 14.5436	Cost: 5.92s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 14.7096	Cost: 6.14s
Train Epoch: 359 [61440/90000 (68%)]	Loss: 14.7522	Cost: 5.87s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 14.6313	Cost: 5.81s
Train Epoch: 359 	Average Loss: 14.6522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5698

Learning rate: 0.00019936467163656337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 15.3830	Cost: 20.96s
Train Epoch: 360 [20480/90000 (23%)]	Loss: 14.6238	Cost: 6.14s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 14.4826	Cost: 6.21s
Train Epoch: 360 [61440/90000 (68%)]	Loss: 14.4690	Cost: 5.87s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 14.5326	Cost: 5.89s
Train Epoch: 360 	Average Loss: 14.6405
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7095

Learning rate: 0.00019936113105200064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 15.2408	Cost: 19.89s
Train Epoch: 361 [20480/90000 (23%)]	Loss: 14.4648	Cost: 6.03s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 14.4509	Cost: 6.59s
Train Epoch: 361 [61440/90000 (68%)]	Loss: 14.4316	Cost: 5.84s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 14.4936	Cost: 5.75s
Train Epoch: 361 	Average Loss: 14.6083
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6330

Learning rate: 0.00019935758066088742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 15.2017	Cost: 21.21s
Train Epoch: 362 [20480/90000 (23%)]	Loss: 14.5670	Cost: 5.98s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 14.4994	Cost: 6.49s
Train Epoch: 362 [61440/90000 (68%)]	Loss: 14.5019	Cost: 5.86s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 14.5557	Cost: 6.02s
Train Epoch: 362 	Average Loss: 14.6181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7154

Learning rate: 0.00019935402046357414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 15.5250	Cost: 21.21s
Train Epoch: 363 [20480/90000 (23%)]	Loss: 14.6606	Cost: 6.18s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 14.4986	Cost: 6.25s
Train Epoch: 363 [61440/90000 (68%)]	Loss: 14.5699	Cost: 5.99s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 14.5458	Cost: 6.12s
Train Epoch: 363 	Average Loss: 14.6135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6648

Learning rate: 0.00019935045046041218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 15.2960	Cost: 21.12s
Train Epoch: 364 [20480/90000 (23%)]	Loss: 14.5802	Cost: 6.07s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 14.6088	Cost: 7.20s
Train Epoch: 364 [61440/90000 (68%)]	Loss: 14.2708	Cost: 5.87s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 14.5920	Cost: 5.80s
Train Epoch: 364 	Average Loss: 14.5968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6638

Learning rate: 0.00019934687065175386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 15.0402	Cost: 21.02s
Train Epoch: 365 [20480/90000 (23%)]	Loss: 14.4416	Cost: 5.96s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 14.4383	Cost: 7.25s
Train Epoch: 365 [61440/90000 (68%)]	Loss: 14.6316	Cost: 5.83s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 14.7711	Cost: 5.78s
Train Epoch: 365 	Average Loss: 14.5884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5611

Learning rate: 0.00019934328103795248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 15.0257	Cost: 20.23s
Train Epoch: 366 [20480/90000 (23%)]	Loss: 14.4636	Cost: 6.06s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 14.4450	Cost: 6.32s
Train Epoch: 366 [61440/90000 (68%)]	Loss: 14.3345	Cost: 5.93s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 14.6378	Cost: 6.06s
Train Epoch: 366 	Average Loss: 14.6065
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7593

Learning rate: 0.00019933968161936236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 15.3864	Cost: 19.74s
Train Epoch: 367 [20480/90000 (23%)]	Loss: 14.7536	Cost: 6.16s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 14.6044	Cost: 6.09s
Train Epoch: 367 [61440/90000 (68%)]	Loss: 14.3779	Cost: 5.92s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 14.6927	Cost: 5.79s
Train Epoch: 367 	Average Loss: 14.6155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6702

Learning rate: 0.00019933607239633875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 15.4279	Cost: 20.10s
Train Epoch: 368 [20480/90000 (23%)]	Loss: 14.4261	Cost: 6.05s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 14.6013	Cost: 6.75s
Train Epoch: 368 [61440/90000 (68%)]	Loss: 14.4792	Cost: 5.85s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 14.5172	Cost: 6.02s
Train Epoch: 368 	Average Loss: 14.5929
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6547

Learning rate: 0.00019933245336923783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 15.2961	Cost: 19.71s
Train Epoch: 369 [20480/90000 (23%)]	Loss: 14.5100	Cost: 6.14s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 14.6833	Cost: 6.06s
Train Epoch: 369 [61440/90000 (68%)]	Loss: 14.4592	Cost: 5.88s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 14.5420	Cost: 5.76s
Train Epoch: 369 	Average Loss: 14.5891
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8069

Learning rate: 0.0001993288245384168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 15.4240	Cost: 19.89s
Train Epoch: 370 [20480/90000 (23%)]	Loss: 14.5734	Cost: 6.09s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 14.3088	Cost: 7.37s
Train Epoch: 370 [61440/90000 (68%)]	Loss: 14.4525	Cost: 5.85s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 14.4259	Cost: 6.32s
Train Epoch: 370 	Average Loss: 14.5861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6045

Learning rate: 0.00019932518590423377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 15.0846	Cost: 19.37s
Train Epoch: 371 [20480/90000 (23%)]	Loss: 14.4277	Cost: 6.10s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 14.4595	Cost: 6.22s
Train Epoch: 371 [61440/90000 (68%)]	Loss: 14.3816	Cost: 5.88s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 14.4895	Cost: 5.82s
Train Epoch: 371 	Average Loss: 14.5658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6844

Learning rate: 0.00019932153746704794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 15.2762	Cost: 19.42s
Train Epoch: 372 [20480/90000 (23%)]	Loss: 14.4456	Cost: 6.12s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 14.5590	Cost: 7.23s
Train Epoch: 372 [61440/90000 (68%)]	Loss: 14.5418	Cost: 5.90s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 14.5763	Cost: 6.03s
Train Epoch: 372 	Average Loss: 14.5438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6908

Learning rate: 0.00019931787922721937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 15.1591	Cost: 20.07s
Train Epoch: 373 [20480/90000 (23%)]	Loss: 14.4227	Cost: 6.05s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 14.4693	Cost: 6.59s
Train Epoch: 373 [61440/90000 (68%)]	Loss: 14.4559	Cost: 5.85s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 14.5284	Cost: 5.75s
Train Epoch: 373 	Average Loss: 14.5602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7142

Learning rate: 0.00019931421118510906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 15.3064	Cost: 19.87s
Train Epoch: 374 [20480/90000 (23%)]	Loss: 14.3193	Cost: 6.04s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 14.5089	Cost: 6.41s
Train Epoch: 374 [61440/90000 (68%)]	Loss: 14.7132	Cost: 5.88s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 14.4881	Cost: 5.96s
Train Epoch: 374 	Average Loss: 14.5394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6994

Learning rate: 0.0001993105333410791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 15.1426	Cost: 20.80s
Train Epoch: 375 [20480/90000 (23%)]	Loss: 14.3906	Cost: 6.03s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 14.4016	Cost: 6.36s
Train Epoch: 375 [61440/90000 (68%)]	Loss: 14.5361	Cost: 6.11s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 14.4413	Cost: 5.81s
Train Epoch: 375 	Average Loss: 14.5310
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6342

Learning rate: 0.00019930684569549248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 15.3051	Cost: 20.37s
Train Epoch: 376 [20480/90000 (23%)]	Loss: 14.2511	Cost: 6.05s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 14.5810	Cost: 6.00s
Train Epoch: 376 [61440/90000 (68%)]	Loss: 14.4911	Cost: 5.88s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 14.6584	Cost: 5.79s
Train Epoch: 376 	Average Loss: 14.5635
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6243

Learning rate: 0.0001993031482487131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 15.0207	Cost: 19.97s
Train Epoch: 377 [20480/90000 (23%)]	Loss: 14.4368	Cost: 6.06s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 14.5038	Cost: 6.79s
Train Epoch: 377 [61440/90000 (68%)]	Loss: 14.3776	Cost: 6.01s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 14.2205	Cost: 6.05s
Train Epoch: 377 	Average Loss: 14.5400
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6299

Learning rate: 0.0001992994410011059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 15.4106	Cost: 20.94s
Train Epoch: 378 [20480/90000 (23%)]	Loss: 14.5154	Cost: 6.11s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 14.5386	Cost: 6.29s
Train Epoch: 378 [61440/90000 (68%)]	Loss: 14.5617	Cost: 5.76s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 14.5693	Cost: 6.06s
Train Epoch: 378 	Average Loss: 14.5428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7102

Learning rate: 0.00019929572395303678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 15.0384	Cost: 20.83s
Train Epoch: 379 [20480/90000 (23%)]	Loss: 14.4721	Cost: 5.98s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 14.4246	Cost: 6.75s
Train Epoch: 379 [61440/90000 (68%)]	Loss: 14.6999	Cost: 5.87s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 14.6545	Cost: 6.30s
Train Epoch: 379 	Average Loss: 14.5370
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6730

Learning rate: 0.0001992919971048726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 14.9476	Cost: 20.11s
Train Epoch: 380 [20480/90000 (23%)]	Loss: 14.5132	Cost: 6.00s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 14.3022	Cost: 6.02s
Train Epoch: 380 [61440/90000 (68%)]	Loss: 14.3756	Cost: 5.89s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 14.5023	Cost: 5.75s
Train Epoch: 380 	Average Loss: 14.5287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6653

Learning rate: 0.0001992882604569812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 15.2280	Cost: 20.40s
Train Epoch: 381 [20480/90000 (23%)]	Loss: 14.3673	Cost: 6.03s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 14.4430	Cost: 7.19s
Train Epoch: 381 [61440/90000 (68%)]	Loss: 14.5670	Cost: 5.84s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 14.2294	Cost: 5.95s
Train Epoch: 381 	Average Loss: 14.5219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6478

Learning rate: 0.00019928451400973133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 15.3541	Cost: 19.66s
Train Epoch: 382 [20480/90000 (23%)]	Loss: 14.4306	Cost: 6.18s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 14.4577	Cost: 6.29s
Train Epoch: 382 [61440/90000 (68%)]	Loss: 14.4459	Cost: 5.84s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 14.1826	Cost: 5.83s
Train Epoch: 382 	Average Loss: 14.4860
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7226

Learning rate: 0.0001992807577634928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 15.2598	Cost: 19.45s
Train Epoch: 383 [20480/90000 (23%)]	Loss: 14.4925	Cost: 6.08s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 14.1909	Cost: 7.14s
Train Epoch: 383 [61440/90000 (68%)]	Loss: 14.6816	Cost: 5.93s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 14.5056	Cost: 5.74s
Train Epoch: 383 	Average Loss: 14.5107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6501

Learning rate: 0.00019927699171863632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 15.1178	Cost: 20.07s
Train Epoch: 384 [20480/90000 (23%)]	Loss: 14.5854	Cost: 6.01s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 14.5182	Cost: 6.00s
Train Epoch: 384 [61440/90000 (68%)]	Loss: 14.4637	Cost: 5.87s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 14.3834	Cost: 5.73s
Train Epoch: 384 	Average Loss: 14.5147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6789

Learning rate: 0.00019927321587553357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 15.3023	Cost: 19.92s
Train Epoch: 385 [20480/90000 (23%)]	Loss: 14.5002	Cost: 6.05s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 14.4785	Cost: 6.06s
Train Epoch: 385 [61440/90000 (68%)]	Loss: 14.5065	Cost: 5.88s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 14.5380	Cost: 5.76s
Train Epoch: 385 	Average Loss: 14.5184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6874

Learning rate: 0.00019926943023455717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 15.3716	Cost: 19.86s
Train Epoch: 386 [20480/90000 (23%)]	Loss: 14.3874	Cost: 5.92s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 14.4699	Cost: 6.30s
Train Epoch: 386 [61440/90000 (68%)]	Loss: 14.2433	Cost: 5.69s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 14.5914	Cost: 5.66s
Train Epoch: 386 	Average Loss: 14.4981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7208

Learning rate: 0.00019926563479608086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 15.2451	Cost: 19.56s
Train Epoch: 387 [20480/90000 (23%)]	Loss: 14.2087	Cost: 6.08s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 14.4201	Cost: 6.10s
Train Epoch: 387 [61440/90000 (68%)]	Loss: 14.4449	Cost: 5.96s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 14.4771	Cost: 6.09s
Train Epoch: 387 	Average Loss: 14.4982
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5910

Learning rate: 0.00019926182956047912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 15.1725	Cost: 19.51s
Train Epoch: 388 [20480/90000 (23%)]	Loss: 14.3332	Cost: 6.09s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 14.4574	Cost: 7.20s
Train Epoch: 388 [61440/90000 (68%)]	Loss: 14.1412	Cost: 6.01s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 14.4325	Cost: 5.78s
Train Epoch: 388 	Average Loss: 14.5005
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6816

Learning rate: 0.00019925801452812757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 15.3350	Cost: 19.49s
Train Epoch: 389 [20480/90000 (23%)]	Loss: 14.3890	Cost: 6.09s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 14.6865	Cost: 6.03s
Train Epoch: 389 [61440/90000 (68%)]	Loss: 14.4811	Cost: 5.90s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 14.4338	Cost: 5.77s
Train Epoch: 389 	Average Loss: 14.4626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6699

Learning rate: 0.00019925418969940278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 15.3119	Cost: 19.50s
Train Epoch: 390 [20480/90000 (23%)]	Loss: 14.2945	Cost: 6.05s
Train Epoch: 390 [40960/90000 (45%)]	Loss: 14.3853	Cost: 7.45s
Train Epoch: 390 [61440/90000 (68%)]	Loss: 14.6298	Cost: 5.80s
Train Epoch: 390 [81920/90000 (91%)]	Loss: 14.3939	Cost: 6.03s
Train Epoch: 390 	Average Loss: 14.4482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6702

Learning rate: 0.00019925035507468219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 15.2532	Cost: 19.71s
Train Epoch: 391 [20480/90000 (23%)]	Loss: 14.5032	Cost: 6.02s
Train Epoch: 391 [40960/90000 (45%)]	Loss: 14.4068	Cost: 6.29s
Train Epoch: 391 [61440/90000 (68%)]	Loss: 14.3956	Cost: 5.88s
Train Epoch: 391 [81920/90000 (91%)]	Loss: 14.3769	Cost: 5.75s
Train Epoch: 391 	Average Loss: 14.4544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6916

Learning rate: 0.00019924651065434423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 15.3826	Cost: 19.68s
Train Epoch: 392 [20480/90000 (23%)]	Loss: 14.3839	Cost: 6.01s
Train Epoch: 392 [40960/90000 (45%)]	Loss: 14.4675	Cost: 6.84s
Train Epoch: 392 [61440/90000 (68%)]	Loss: 14.2083	Cost: 5.79s
Train Epoch: 392 [81920/90000 (91%)]	Loss: 14.1912	Cost: 5.79s
Train Epoch: 392 	Average Loss: 14.4481
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6033

Learning rate: 0.0001992426564387684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 15.3200	Cost: 18.84s
Train Epoch: 393 [20480/90000 (23%)]	Loss: 14.3544	Cost: 6.16s
Train Epoch: 393 [40960/90000 (45%)]	Loss: 14.2714	Cost: 6.43s
Train Epoch: 393 [61440/90000 (68%)]	Loss: 14.2957	Cost: 5.88s
Train Epoch: 393 [81920/90000 (91%)]	Loss: 14.4286	Cost: 5.89s
Train Epoch: 393 	Average Loss: 14.4703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7247

Learning rate: 0.00019923879242833502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 15.3347	Cost: 20.53s
Train Epoch: 394 [20480/90000 (23%)]	Loss: 14.5058	Cost: 6.00s
Train Epoch: 394 [40960/90000 (45%)]	Loss: 14.4065	Cost: 6.56s
Train Epoch: 394 [61440/90000 (68%)]	Loss: 14.3415	Cost: 5.96s
Train Epoch: 394 [81920/90000 (91%)]	Loss: 14.4461	Cost: 5.92s
Train Epoch: 394 	Average Loss: 14.4633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6712

Learning rate: 0.00019923491862342552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 15.2352	Cost: 20.73s
Train Epoch: 395 [20480/90000 (23%)]	Loss: 14.4403	Cost: 6.09s
Train Epoch: 395 [40960/90000 (45%)]	Loss: 14.3720	Cost: 6.01s
Train Epoch: 395 [61440/90000 (68%)]	Loss: 14.5407	Cost: 5.88s
Train Epoch: 395 [81920/90000 (91%)]	Loss: 14.2569	Cost: 5.81s
Train Epoch: 395 	Average Loss: 14.4218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7560

Learning rate: 0.0001992310350244222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 15.1244	Cost: 21.29s
Train Epoch: 396 [20480/90000 (23%)]	Loss: 14.4049	Cost: 6.09s
Train Epoch: 396 [40960/90000 (45%)]	Loss: 14.3444	Cost: 6.07s
Train Epoch: 396 [61440/90000 (68%)]	Loss: 14.3263	Cost: 5.92s
Train Epoch: 396 [81920/90000 (91%)]	Loss: 14.4622	Cost: 5.97s
Train Epoch: 396 	Average Loss: 14.4255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6994

Learning rate: 0.0001992271416317084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 15.1252	Cost: 21.61s
Train Epoch: 397 [20480/90000 (23%)]	Loss: 14.3211	Cost: 6.06s
Train Epoch: 397 [40960/90000 (45%)]	Loss: 14.3555	Cost: 6.58s
Train Epoch: 397 [61440/90000 (68%)]	Loss: 14.3264	Cost: 5.91s
Train Epoch: 397 [81920/90000 (91%)]	Loss: 14.3194	Cost: 5.86s
Train Epoch: 397 	Average Loss: 14.4409
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6518

Learning rate: 0.0001992232384456683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 15.3905	Cost: 20.74s
Train Epoch: 398 [20480/90000 (23%)]	Loss: 14.3571	Cost: 6.02s
Train Epoch: 398 [40960/90000 (45%)]	Loss: 14.4269	Cost: 6.69s
Train Epoch: 398 [61440/90000 (68%)]	Loss: 14.3545	Cost: 5.96s
Train Epoch: 398 [81920/90000 (91%)]	Loss: 14.4514	Cost: 5.79s
Train Epoch: 398 	Average Loss: 14.4284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6480

Learning rate: 0.00019921932546668718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 15.2979	Cost: 20.54s
Train Epoch: 399 [20480/90000 (23%)]	Loss: 14.4681	Cost: 5.98s
Train Epoch: 399 [40960/90000 (45%)]	Loss: 14.2319	Cost: 6.17s
Train Epoch: 399 [61440/90000 (68%)]	Loss: 14.2540	Cost: 5.82s
Train Epoch: 399 [81920/90000 (91%)]	Loss: 14.2687	Cost: 5.89s
Train Epoch: 399 	Average Loss: 14.4051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7204

Learning rate: 0.00019921540269515121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 15.3368	Cost: 20.03s
Train Epoch: 400 [20480/90000 (23%)]	Loss: 14.2355	Cost: 5.99s
Train Epoch: 400 [40960/90000 (45%)]	Loss: 14.0905	Cost: 6.37s
Train Epoch: 400 [61440/90000 (68%)]	Loss: 14.3637	Cost: 5.86s
Train Epoch: 400 [81920/90000 (91%)]	Loss: 14.3130	Cost: 5.85s
Train Epoch: 400 	Average Loss: 14.4104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7222

Learning rate: 0.0001992114701314476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 401 [0/90000 (0%)]	Loss: 15.1219	Cost: 20.78s
Train Epoch: 401 [20480/90000 (23%)]	Loss: 14.1309	Cost: 6.00s
Train Epoch: 401 [40960/90000 (45%)]	Loss: 14.1934	Cost: 6.68s
Train Epoch: 401 [61440/90000 (68%)]	Loss: 14.3590	Cost: 6.04s
Train Epoch: 401 [81920/90000 (91%)]	Loss: 14.4888	Cost: 5.92s
Train Epoch: 401 	Average Loss: 14.3873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6441

Learning rate: 0.00019920752777596444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 402 [0/90000 (0%)]	Loss: 15.3597	Cost: 20.95s
Train Epoch: 402 [20480/90000 (23%)]	Loss: 14.2803	Cost: 5.98s
Train Epoch: 402 [40960/90000 (45%)]	Loss: 14.3619	Cost: 6.97s
Train Epoch: 402 [61440/90000 (68%)]	Loss: 14.1085	Cost: 5.87s
Train Epoch: 402 [81920/90000 (91%)]	Loss: 14.1665	Cost: 5.86s
Train Epoch: 402 	Average Loss: 14.3721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6950

Learning rate: 0.00019920357562909082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 403 [0/90000 (0%)]	Loss: 15.3199	Cost: 20.45s
Train Epoch: 403 [20480/90000 (23%)]	Loss: 14.0545	Cost: 6.08s
Train Epoch: 403 [40960/90000 (45%)]	Loss: 14.2680	Cost: 6.30s
Train Epoch: 403 [61440/90000 (68%)]	Loss: 14.1923	Cost: 5.96s
Train Epoch: 403 [81920/90000 (91%)]	Loss: 14.0679	Cost: 5.86s
Train Epoch: 403 	Average Loss: 14.3839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6692

Learning rate: 0.00019919961369121682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 404 [0/90000 (0%)]	Loss: 15.3859	Cost: 20.97s
Train Epoch: 404 [20480/90000 (23%)]	Loss: 14.3693	Cost: 5.96s
Train Epoch: 404 [40960/90000 (45%)]	Loss: 14.3670	Cost: 6.10s
Train Epoch: 404 [61440/90000 (68%)]	Loss: 14.3959	Cost: 5.89s
Train Epoch: 404 [81920/90000 (91%)]	Loss: 14.4712	Cost: 5.84s
Train Epoch: 404 	Average Loss: 14.4176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7327

Learning rate: 0.00019919564196273348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 405 [0/90000 (0%)]	Loss: 15.3020	Cost: 20.65s
Train Epoch: 405 [20480/90000 (23%)]	Loss: 14.2117	Cost: 6.09s
Train Epoch: 405 [40960/90000 (45%)]	Loss: 14.1308	Cost: 6.10s
Train Epoch: 405 [61440/90000 (68%)]	Loss: 14.3518	Cost: 5.90s
Train Epoch: 405 [81920/90000 (91%)]	Loss: 14.2844	Cost: 5.80s
Train Epoch: 405 	Average Loss: 14.4110
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6995

Learning rate: 0.00019919166044403278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 406 [0/90000 (0%)]	Loss: 15.3050	Cost: 21.01s
Train Epoch: 406 [20480/90000 (23%)]	Loss: 14.1103	Cost: 6.02s
Train Epoch: 406 [40960/90000 (45%)]	Loss: 14.1490	Cost: 6.04s
Train Epoch: 406 [61440/90000 (68%)]	Loss: 14.3300	Cost: 5.89s
Train Epoch: 406 [81920/90000 (91%)]	Loss: 14.4187	Cost: 5.87s
Train Epoch: 406 	Average Loss: 14.3926
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6079

Learning rate: 0.00019918766913550764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 407 [0/90000 (0%)]	Loss: 15.2740	Cost: 20.17s
Train Epoch: 407 [20480/90000 (23%)]	Loss: 14.3222	Cost: 6.07s
Train Epoch: 407 [40960/90000 (45%)]	Loss: 14.3125	Cost: 6.13s
Train Epoch: 407 [61440/90000 (68%)]	Loss: 14.3289	Cost: 5.94s
Train Epoch: 407 [81920/90000 (91%)]	Loss: 14.2695	Cost: 5.96s
Train Epoch: 407 	Average Loss: 14.3467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7700

Learning rate: 0.00019918366803755205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 408 [0/90000 (0%)]	Loss: 15.4823	Cost: 20.60s
Train Epoch: 408 [20480/90000 (23%)]	Loss: 14.2744	Cost: 6.04s
Train Epoch: 408 [40960/90000 (45%)]	Loss: 14.1537	Cost: 6.19s
Train Epoch: 408 [61440/90000 (68%)]	Loss: 14.3630	Cost: 5.96s
Train Epoch: 408 [81920/90000 (91%)]	Loss: 14.3464	Cost: 5.90s
Train Epoch: 408 	Average Loss: 14.3883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6413

Learning rate: 0.00019917965715056087
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 409 [0/90000 (0%)]	Loss: 15.2956	Cost: 20.12s
Train Epoch: 409 [20480/90000 (23%)]	Loss: 14.1909	Cost: 6.04s
Train Epoch: 409 [40960/90000 (45%)]	Loss: 14.2179	Cost: 6.18s
Train Epoch: 409 [61440/90000 (68%)]	Loss: 14.3708	Cost: 5.95s
Train Epoch: 409 [81920/90000 (91%)]	Loss: 14.1824	Cost: 5.96s
Train Epoch: 409 	Average Loss: 14.3516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6755

Learning rate: 0.00019917563647492995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 410 [0/90000 (0%)]	Loss: 15.4239	Cost: 20.11s
Train Epoch: 410 [20480/90000 (23%)]	Loss: 14.1931	Cost: 6.02s
Train Epoch: 410 [40960/90000 (45%)]	Loss: 14.1950	Cost: 7.21s
Train Epoch: 410 [61440/90000 (68%)]	Loss: 14.3155	Cost: 5.88s
Train Epoch: 410 [81920/90000 (91%)]	Loss: 14.2715	Cost: 6.48s
Train Epoch: 410 	Average Loss: 14.3545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6606

Learning rate: 0.00019917160601105614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 411 [0/90000 (0%)]	Loss: 15.1483	Cost: 20.58s
Train Epoch: 411 [20480/90000 (23%)]	Loss: 14.2046	Cost: 6.10s
Train Epoch: 411 [40960/90000 (45%)]	Loss: 14.3310	Cost: 6.41s
Train Epoch: 411 [61440/90000 (68%)]	Loss: 14.4739	Cost: 5.91s
Train Epoch: 411 [81920/90000 (91%)]	Loss: 14.4896	Cost: 6.60s
Train Epoch: 411 	Average Loss: 14.3785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6663

Learning rate: 0.0001991675657593372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 412 [0/90000 (0%)]	Loss: 15.3192	Cost: 20.30s
Train Epoch: 412 [20480/90000 (23%)]	Loss: 14.1971	Cost: 6.02s
Train Epoch: 412 [40960/90000 (45%)]	Loss: 14.2665	Cost: 7.01s
Train Epoch: 412 [61440/90000 (68%)]	Loss: 14.2373	Cost: 6.01s
Train Epoch: 412 [81920/90000 (91%)]	Loss: 14.3117	Cost: 5.79s
Train Epoch: 412 	Average Loss: 14.3437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6729

Learning rate: 0.00019916351572017192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 413 [0/90000 (0%)]	Loss: 15.3046	Cost: 20.84s
Train Epoch: 413 [20480/90000 (23%)]	Loss: 14.3566	Cost: 6.07s
Train Epoch: 413 [40960/90000 (45%)]	Loss: 14.3015	Cost: 6.92s
Train Epoch: 413 [61440/90000 (68%)]	Loss: 14.2682	Cost: 6.03s
Train Epoch: 413 [81920/90000 (91%)]	Loss: 14.2116	Cost: 5.89s
Train Epoch: 413 	Average Loss: 14.3256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7510

Learning rate: 0.00019915945589396003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 414 [0/90000 (0%)]	Loss: 15.4393	Cost: 20.81s
Train Epoch: 414 [20480/90000 (23%)]	Loss: 14.2111	Cost: 6.35s
Train Epoch: 414 [40960/90000 (45%)]	Loss: 14.0239	Cost: 6.18s
Train Epoch: 414 [61440/90000 (68%)]	Loss: 14.2024	Cost: 5.91s
Train Epoch: 414 [81920/90000 (91%)]	Loss: 14.3712	Cost: 5.78s
Train Epoch: 414 	Average Loss: 14.3424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7470

Learning rate: 0.00019915538628110217
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 415 [0/90000 (0%)]	Loss: 15.1605	Cost: 20.44s
Train Epoch: 415 [20480/90000 (23%)]	Loss: 14.2032	Cost: 6.05s
Train Epoch: 415 [40960/90000 (45%)]	Loss: 14.1751	Cost: 6.10s
Train Epoch: 415 [61440/90000 (68%)]	Loss: 14.2095	Cost: 6.00s
Train Epoch: 415 [81920/90000 (91%)]	Loss: 14.2847	Cost: 5.80s
Train Epoch: 415 	Average Loss: 14.3087
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7028

Learning rate: 0.00019915130688200001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 416 [0/90000 (0%)]	Loss: 15.2892	Cost: 20.61s
Train Epoch: 416 [20480/90000 (23%)]	Loss: 14.0920	Cost: 6.27s
Train Epoch: 416 [40960/90000 (45%)]	Loss: 14.3884	Cost: 6.06s
Train Epoch: 416 [61440/90000 (68%)]	Loss: 14.3227	Cost: 5.90s
Train Epoch: 416 [81920/90000 (91%)]	Loss: 14.3256	Cost: 5.81s
Train Epoch: 416 	Average Loss: 14.3282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5590

Learning rate: 0.0001991472176970562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 417 [0/90000 (0%)]	Loss: 15.3967	Cost: 19.74s
Train Epoch: 417 [20480/90000 (23%)]	Loss: 14.1969	Cost: 6.06s
Train Epoch: 417 [40960/90000 (45%)]	Loss: 14.2159	Cost: 6.21s
Train Epoch: 417 [61440/90000 (68%)]	Loss: 14.3632	Cost: 5.89s
Train Epoch: 417 [81920/90000 (91%)]	Loss: 14.2723	Cost: 5.81s
Train Epoch: 417 	Average Loss: 14.3287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7340

Learning rate: 0.00019914311872667434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 418 [0/90000 (0%)]	Loss: 15.1010	Cost: 19.84s
Train Epoch: 418 [20480/90000 (23%)]	Loss: 13.9937	Cost: 6.12s
Train Epoch: 418 [40960/90000 (45%)]	Loss: 14.1440	Cost: 6.04s
Train Epoch: 418 [61440/90000 (68%)]	Loss: 14.1816	Cost: 5.90s
Train Epoch: 418 [81920/90000 (91%)]	Loss: 14.1293	Cost: 5.78s
Train Epoch: 418 	Average Loss: 14.2889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7969

Learning rate: 0.0001991390099712589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 419 [0/90000 (0%)]	Loss: 15.1685	Cost: 20.45s
Train Epoch: 419 [20480/90000 (23%)]	Loss: 14.1523	Cost: 6.22s
Train Epoch: 419 [40960/90000 (45%)]	Loss: 14.3403	Cost: 6.07s
Train Epoch: 419 [61440/90000 (68%)]	Loss: 14.2069	Cost: 5.89s
Train Epoch: 419 [81920/90000 (91%)]	Loss: 14.2036	Cost: 6.14s
Train Epoch: 419 	Average Loss: 14.2950
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7813

Learning rate: 0.00019913489143121547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 420 [0/90000 (0%)]	Loss: 15.1570	Cost: 20.57s
Train Epoch: 420 [20480/90000 (23%)]	Loss: 14.2188	Cost: 6.04s
Train Epoch: 420 [40960/90000 (45%)]	Loss: 14.0141	Cost: 6.03s
Train Epoch: 420 [61440/90000 (68%)]	Loss: 14.1974	Cost: 5.93s
Train Epoch: 420 [81920/90000 (91%)]	Loss: 14.2204	Cost: 5.80s
Train Epoch: 420 	Average Loss: 14.2964
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7574

Learning rate: 0.0001991307631069505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 421 [0/90000 (0%)]	Loss: 15.1730	Cost: 19.81s
Train Epoch: 421 [20480/90000 (23%)]	Loss: 14.1052	Cost: 6.22s
Train Epoch: 421 [40960/90000 (45%)]	Loss: 14.2066	Cost: 6.84s
Train Epoch: 421 [61440/90000 (68%)]	Loss: 14.1398	Cost: 5.88s
Train Epoch: 421 [81920/90000 (91%)]	Loss: 14.2475	Cost: 5.82s
Train Epoch: 421 	Average Loss: 14.2917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7140

Learning rate: 0.0001991266249988715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 422 [0/90000 (0%)]	Loss: 15.2827	Cost: 21.17s
Train Epoch: 422 [20480/90000 (23%)]	Loss: 14.0879	Cost: 6.08s
Train Epoch: 422 [40960/90000 (45%)]	Loss: 14.2219	Cost: 6.42s
Train Epoch: 422 [61440/90000 (68%)]	Loss: 14.2696	Cost: 5.93s
Train Epoch: 422 [81920/90000 (91%)]	Loss: 14.1946	Cost: 5.93s
Train Epoch: 422 	Average Loss: 14.3136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6965

Learning rate: 0.00019912247710738676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 423 [0/90000 (0%)]	Loss: 15.3928	Cost: 20.16s
Train Epoch: 423 [20480/90000 (23%)]	Loss: 14.1867	Cost: 6.11s
Train Epoch: 423 [40960/90000 (45%)]	Loss: 14.2441	Cost: 6.73s
Train Epoch: 423 [61440/90000 (68%)]	Loss: 14.2708	Cost: 6.06s
Train Epoch: 423 [81920/90000 (91%)]	Loss: 14.2387	Cost: 5.82s
Train Epoch: 423 	Average Loss: 14.2819
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7250

Learning rate: 0.0001991183194329058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 424 [0/90000 (0%)]	Loss: 15.3963	Cost: 20.85s
Train Epoch: 424 [20480/90000 (23%)]	Loss: 14.2311	Cost: 6.17s
Train Epoch: 424 [40960/90000 (45%)]	Loss: 14.1093	Cost: 6.20s
Train Epoch: 424 [61440/90000 (68%)]	Loss: 13.9348	Cost: 5.94s
Train Epoch: 424 [81920/90000 (91%)]	Loss: 14.2734	Cost: 5.90s
Train Epoch: 424 	Average Loss: 14.2945
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6518

Learning rate: 0.00019911415197583891
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 425 [0/90000 (0%)]	Loss: 15.2808	Cost: 19.70s
Train Epoch: 425 [20480/90000 (23%)]	Loss: 14.1643	Cost: 6.11s
Train Epoch: 425 [40960/90000 (45%)]	Loss: 14.1644	Cost: 6.38s
Train Epoch: 425 [61440/90000 (68%)]	Loss: 14.2125	Cost: 5.85s
Train Epoch: 425 [81920/90000 (91%)]	Loss: 14.1232	Cost: 6.34s
Train Epoch: 425 	Average Loss: 14.2541
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6111

Learning rate: 0.00019910997473659734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 426 [0/90000 (0%)]	Loss: 15.3200	Cost: 21.11s
Train Epoch: 426 [20480/90000 (23%)]	Loss: 14.2232	Cost: 6.22s
Train Epoch: 426 [40960/90000 (45%)]	Loss: 14.4527	Cost: 7.17s
Train Epoch: 426 [61440/90000 (68%)]	Loss: 14.1317	Cost: 5.94s
Train Epoch: 426 [81920/90000 (91%)]	Loss: 14.4242	Cost: 6.08s
Train Epoch: 426 	Average Loss: 14.2801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7314

Learning rate: 0.00019910578771559345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 427 [0/90000 (0%)]	Loss: 15.4679	Cost: 20.75s
Train Epoch: 427 [20480/90000 (23%)]	Loss: 14.1140	Cost: 6.05s
Train Epoch: 427 [40960/90000 (45%)]	Loss: 14.1533	Cost: 6.57s
Train Epoch: 427 [61440/90000 (68%)]	Loss: 14.0695	Cost: 5.90s
Train Epoch: 427 [81920/90000 (91%)]	Loss: 14.2178	Cost: 6.07s
Train Epoch: 427 	Average Loss: 14.2729
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7672

Learning rate: 0.00019910159091324043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 428 [0/90000 (0%)]	Loss: 15.2988	Cost: 20.08s
Train Epoch: 428 [20480/90000 (23%)]	Loss: 14.2957	Cost: 6.22s
Train Epoch: 428 [40960/90000 (45%)]	Loss: 14.1305	Cost: 6.29s
Train Epoch: 428 [61440/90000 (68%)]	Loss: 14.0727	Cost: 5.97s
Train Epoch: 428 [81920/90000 (91%)]	Loss: 13.8643	Cost: 6.70s
Train Epoch: 428 	Average Loss: 14.2502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6611

Learning rate: 0.00019909738432995254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 429 [0/90000 (0%)]	Loss: 15.2663	Cost: 20.24s
Train Epoch: 429 [20480/90000 (23%)]	Loss: 14.1304	Cost: 6.20s
Train Epoch: 429 [40960/90000 (45%)]	Loss: 14.1639	Cost: 6.24s
Train Epoch: 429 [61440/90000 (68%)]	Loss: 13.9986	Cost: 5.99s
Train Epoch: 429 [81920/90000 (91%)]	Loss: 14.0016	Cost: 6.50s
Train Epoch: 429 	Average Loss: 14.2332
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7476

Learning rate: 0.00019909316796614494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 430 [0/90000 (0%)]	Loss: 15.3384	Cost: 19.78s
Train Epoch: 430 [20480/90000 (23%)]	Loss: 14.2505	Cost: 6.13s
Train Epoch: 430 [40960/90000 (45%)]	Loss: 14.1638	Cost: 6.74s
Train Epoch: 430 [61440/90000 (68%)]	Loss: 14.2361	Cost: 5.93s
Train Epoch: 430 [81920/90000 (91%)]	Loss: 14.1802	Cost: 6.34s
Train Epoch: 430 	Average Loss: 14.2323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7317

Learning rate: 0.00019908894182223372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 431 [0/90000 (0%)]	Loss: 15.3050	Cost: 21.40s
Train Epoch: 431 [20480/90000 (23%)]	Loss: 13.9806	Cost: 6.11s
Train Epoch: 431 [40960/90000 (45%)]	Loss: 14.0169	Cost: 6.48s
Train Epoch: 431 [61440/90000 (68%)]	Loss: 14.1670	Cost: 5.97s
Train Epoch: 431 [81920/90000 (91%)]	Loss: 13.9550	Cost: 6.33s
Train Epoch: 431 	Average Loss: 14.2739
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7251

Learning rate: 0.00019908470589863605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 432 [0/90000 (0%)]	Loss: 15.3107	Cost: 20.85s
Train Epoch: 432 [20480/90000 (23%)]	Loss: 14.0701	Cost: 6.13s
Train Epoch: 432 [40960/90000 (45%)]	Loss: 14.0896	Cost: 6.92s
Train Epoch: 432 [61440/90000 (68%)]	Loss: 14.0658	Cost: 6.05s
Train Epoch: 432 [81920/90000 (91%)]	Loss: 14.0053	Cost: 7.01s
Train Epoch: 432 	Average Loss: 14.1966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7362

Learning rate: 0.00019908046019576994
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 433 [0/90000 (0%)]	Loss: 15.5338	Cost: 20.20s
Train Epoch: 433 [20480/90000 (23%)]	Loss: 14.0771	Cost: 6.07s
Train Epoch: 433 [40960/90000 (45%)]	Loss: 14.0104	Cost: 6.15s
Train Epoch: 433 [61440/90000 (68%)]	Loss: 14.2495	Cost: 5.97s
Train Epoch: 433 [81920/90000 (91%)]	Loss: 14.1735	Cost: 5.92s
Train Epoch: 433 	Average Loss: 14.1974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8084

Learning rate: 0.00019907620471405445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 434 [0/90000 (0%)]	Loss: 15.2156	Cost: 22.04s
Train Epoch: 434 [20480/90000 (23%)]	Loss: 13.9703	Cost: 6.04s
Train Epoch: 434 [40960/90000 (45%)]	Loss: 14.0988	Cost: 6.78s
Train Epoch: 434 [61440/90000 (68%)]	Loss: 14.0356	Cost: 6.13s
Train Epoch: 434 [81920/90000 (91%)]	Loss: 14.1623	Cost: 6.67s
Train Epoch: 434 	Average Loss: 14.1882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7021

Learning rate: 0.0001990719394539096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 435 [0/90000 (0%)]	Loss: 15.3537	Cost: 21.07s
Train Epoch: 435 [20480/90000 (23%)]	Loss: 14.1753	Cost: 6.07s
Train Epoch: 435 [40960/90000 (45%)]	Loss: 14.0646	Cost: 6.50s
Train Epoch: 435 [61440/90000 (68%)]	Loss: 14.2551	Cost: 5.89s
Train Epoch: 435 [81920/90000 (91%)]	Loss: 14.0656	Cost: 6.32s
Train Epoch: 435 	Average Loss: 14.2095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7568

Learning rate: 0.0001990676644157563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 436 [0/90000 (0%)]	Loss: 15.1589	Cost: 21.32s
Train Epoch: 436 [20480/90000 (23%)]	Loss: 13.7839	Cost: 6.07s
Train Epoch: 436 [40960/90000 (45%)]	Loss: 14.2964	Cost: 6.22s
Train Epoch: 436 [61440/90000 (68%)]	Loss: 14.3694	Cost: 5.93s
Train Epoch: 436 [81920/90000 (91%)]	Loss: 14.1193	Cost: 6.26s
Train Epoch: 436 	Average Loss: 14.1707
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7838

Learning rate: 0.00019906337960001657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 437 [0/90000 (0%)]	Loss: 15.3801	Cost: 22.49s
Train Epoch: 437 [20480/90000 (23%)]	Loss: 14.0052	Cost: 5.94s
Train Epoch: 437 [40960/90000 (45%)]	Loss: 14.1179	Cost: 6.31s
Train Epoch: 437 [61440/90000 (68%)]	Loss: 14.0694	Cost: 5.87s
Train Epoch: 437 [81920/90000 (91%)]	Loss: 14.0093	Cost: 5.84s
Train Epoch: 437 	Average Loss: 14.1823
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7143

Learning rate: 0.0001990590850071132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 438 [0/90000 (0%)]	Loss: 15.0459	Cost: 20.11s
Train Epoch: 438 [20480/90000 (23%)]	Loss: 14.0485	Cost: 5.98s
Train Epoch: 438 [40960/90000 (45%)]	Loss: 13.9978	Cost: 6.00s
Train Epoch: 438 [61440/90000 (68%)]	Loss: 14.1635	Cost: 5.87s
Train Epoch: 438 [81920/90000 (91%)]	Loss: 13.9571	Cost: 5.80s
Train Epoch: 438 	Average Loss: 14.2052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7547

Learning rate: 0.0001990547806374701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 439 [0/90000 (0%)]	Loss: 15.3342	Cost: 21.29s
Train Epoch: 439 [20480/90000 (23%)]	Loss: 14.0755	Cost: 5.97s
Train Epoch: 439 [40960/90000 (45%)]	Loss: 14.0778	Cost: 6.62s
Train Epoch: 439 [61440/90000 (68%)]	Loss: 13.9649	Cost: 5.90s
Train Epoch: 439 [81920/90000 (91%)]	Loss: 14.0552	Cost: 6.14s
Train Epoch: 439 	Average Loss: 14.1637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7943

Learning rate: 0.00019905046649151213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 440 [0/90000 (0%)]	Loss: 15.1767	Cost: 21.04s
Train Epoch: 440 [20480/90000 (23%)]	Loss: 13.9281	Cost: 6.13s
Train Epoch: 440 [40960/90000 (45%)]	Loss: 14.2041	Cost: 6.11s
Train Epoch: 440 [61440/90000 (68%)]	Loss: 13.9285	Cost: 5.98s
Train Epoch: 440 [81920/90000 (91%)]	Loss: 13.9870	Cost: 5.89s
Train Epoch: 440 	Average Loss: 14.1498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7556

Learning rate: 0.00019904614256966498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 441 [0/90000 (0%)]	Loss: 15.3296	Cost: 21.29s
Train Epoch: 441 [20480/90000 (23%)]	Loss: 14.1693	Cost: 6.20s
Train Epoch: 441 [40960/90000 (45%)]	Loss: 13.9157	Cost: 6.37s
Train Epoch: 441 [61440/90000 (68%)]	Loss: 14.0645	Cost: 6.13s
Train Epoch: 441 [81920/90000 (91%)]	Loss: 14.1274	Cost: 5.87s
Train Epoch: 441 	Average Loss: 14.1674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7383

Learning rate: 0.00019904180887235552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 442 [0/90000 (0%)]	Loss: 15.4137	Cost: 20.83s
Train Epoch: 442 [20480/90000 (23%)]	Loss: 13.9639	Cost: 6.12s
Train Epoch: 442 [40960/90000 (45%)]	Loss: 14.0206	Cost: 6.28s
Train Epoch: 442 [61440/90000 (68%)]	Loss: 14.0180	Cost: 5.94s
Train Epoch: 442 [81920/90000 (91%)]	Loss: 13.8855	Cost: 5.87s
Train Epoch: 442 	Average Loss: 14.1616
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8482

Learning rate: 0.0001990374654000114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 443 [0/90000 (0%)]	Loss: 15.4437	Cost: 22.80s
Train Epoch: 443 [20480/90000 (23%)]	Loss: 14.0432	Cost: 6.04s
Train Epoch: 443 [40960/90000 (45%)]	Loss: 13.9781	Cost: 6.88s
Train Epoch: 443 [61440/90000 (68%)]	Loss: 13.9922	Cost: 5.92s
Train Epoch: 443 [81920/90000 (91%)]	Loss: 13.9551	Cost: 6.66s
Train Epoch: 443 	Average Loss: 14.1708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8220

Learning rate: 0.0001990331121530613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 444 [0/90000 (0%)]	Loss: 15.3160	Cost: 20.20s
Train Epoch: 444 [20480/90000 (23%)]	Loss: 14.0198	Cost: 6.16s
Train Epoch: 444 [40960/90000 (45%)]	Loss: 14.0534	Cost: 6.03s
Train Epoch: 444 [61440/90000 (68%)]	Loss: 13.7911	Cost: 5.96s
Train Epoch: 444 [81920/90000 (91%)]	Loss: 14.0558	Cost: 5.90s
Train Epoch: 444 	Average Loss: 14.1029
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7518

Learning rate: 0.0001990287491319349
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 445 [0/90000 (0%)]	Loss: 15.2057	Cost: 21.74s
Train Epoch: 445 [20480/90000 (23%)]	Loss: 13.8745	Cost: 6.07s
Train Epoch: 445 [40960/90000 (45%)]	Loss: 14.2319	Cost: 6.79s
Train Epoch: 445 [61440/90000 (68%)]	Loss: 14.1165	Cost: 6.14s
Train Epoch: 445 [81920/90000 (91%)]	Loss: 14.1461	Cost: 6.44s
Train Epoch: 445 	Average Loss: 14.1317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7196

Learning rate: 0.00019902437633706276
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 446 [0/90000 (0%)]	Loss: 15.5976	Cost: 20.50s
Train Epoch: 446 [20480/90000 (23%)]	Loss: 13.9078	Cost: 6.03s
Train Epoch: 446 [40960/90000 (45%)]	Loss: 14.0658	Cost: 6.43s
Train Epoch: 446 [61440/90000 (68%)]	Loss: 13.8629	Cost: 5.90s
Train Epoch: 446 [81920/90000 (91%)]	Loss: 13.9780	Cost: 5.86s
Train Epoch: 446 	Average Loss: 14.1403
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6956

Learning rate: 0.0001990199937688765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 447 [0/90000 (0%)]	Loss: 15.3834	Cost: 21.84s
Train Epoch: 447 [20480/90000 (23%)]	Loss: 13.9156	Cost: 6.06s
Train Epoch: 447 [40960/90000 (45%)]	Loss: 14.0752	Cost: 6.40s
Train Epoch: 447 [61440/90000 (68%)]	Loss: 14.0968	Cost: 5.90s
Train Epoch: 447 [81920/90000 (91%)]	Loss: 13.9810	Cost: 5.89s
Train Epoch: 447 	Average Loss: 14.1158
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8457

Learning rate: 0.00019901560142780868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 448 [0/90000 (0%)]	Loss: 15.2773	Cost: 20.88s
Train Epoch: 448 [20480/90000 (23%)]	Loss: 14.1351	Cost: 6.06s
Train Epoch: 448 [40960/90000 (45%)]	Loss: 14.1232	Cost: 6.33s
Train Epoch: 448 [61440/90000 (68%)]	Loss: 14.0503	Cost: 5.87s
Train Epoch: 448 [81920/90000 (91%)]	Loss: 13.8420	Cost: 5.86s
Train Epoch: 448 	Average Loss: 14.1157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8124

Learning rate: 0.0001990111993142928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 449 [0/90000 (0%)]	Loss: 15.3790	Cost: 21.35s
Train Epoch: 449 [20480/90000 (23%)]	Loss: 13.9449	Cost: 6.05s
Train Epoch: 449 [40960/90000 (45%)]	Loss: 14.0177	Cost: 6.08s
Train Epoch: 449 [61440/90000 (68%)]	Loss: 13.9821	Cost: 5.93s
Train Epoch: 449 [81920/90000 (91%)]	Loss: 13.9483	Cost: 6.16s
Train Epoch: 449 	Average Loss: 14.1356
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7701

Learning rate: 0.0001990067874287633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 450 [0/90000 (0%)]	Loss: 15.3592	Cost: 20.44s
Train Epoch: 450 [20480/90000 (23%)]	Loss: 13.7943	Cost: 6.03s
Train Epoch: 450 [40960/90000 (45%)]	Loss: 13.8462	Cost: 6.16s
Train Epoch: 450 [61440/90000 (68%)]	Loss: 14.0373	Cost: 5.86s
Train Epoch: 450 [81920/90000 (91%)]	Loss: 14.0108	Cost: 5.80s
Train Epoch: 450 	Average Loss: 14.0977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7390

Learning rate: 0.00019900236577165563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 451 [0/90000 (0%)]	Loss: 15.2381	Cost: 20.67s
Train Epoch: 451 [20480/90000 (23%)]	Loss: 13.7801	Cost: 6.12s
Train Epoch: 451 [40960/90000 (45%)]	Loss: 13.7528	Cost: 6.11s
Train Epoch: 451 [61440/90000 (68%)]	Loss: 14.0042	Cost: 5.68s
Train Epoch: 451 [81920/90000 (91%)]	Loss: 13.9497	Cost: 5.75s
Train Epoch: 451 	Average Loss: 14.0916
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8192

Learning rate: 0.00019899793434340619
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 452 [0/90000 (0%)]	Loss: 15.5172	Cost: 19.69s
Train Epoch: 452 [20480/90000 (23%)]	Loss: 13.9907	Cost: 6.08s
Train Epoch: 452 [40960/90000 (45%)]	Loss: 14.1702	Cost: 6.05s
Train Epoch: 452 [61440/90000 (68%)]	Loss: 13.9763	Cost: 5.93s
Train Epoch: 452 [81920/90000 (91%)]	Loss: 14.0153	Cost: 5.82s
Train Epoch: 452 	Average Loss: 14.0974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8263

Learning rate: 0.00019899349314445237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 453 [0/90000 (0%)]	Loss: 15.1579	Cost: 19.77s
Train Epoch: 453 [20480/90000 (23%)]	Loss: 13.8825	Cost: 6.10s
Train Epoch: 453 [40960/90000 (45%)]	Loss: 13.8560	Cost: 6.18s
Train Epoch: 453 [61440/90000 (68%)]	Loss: 13.9183	Cost: 5.97s
Train Epoch: 453 [81920/90000 (91%)]	Loss: 13.9420	Cost: 5.84s
Train Epoch: 453 	Average Loss: 14.1300
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8207

Learning rate: 0.00019898904217523244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 454 [0/90000 (0%)]	Loss: 15.4615	Cost: 22.17s
Train Epoch: 454 [20480/90000 (23%)]	Loss: 13.8095	Cost: 6.02s
Train Epoch: 454 [40960/90000 (45%)]	Loss: 14.0132	Cost: 6.46s
Train Epoch: 454 [61440/90000 (68%)]	Loss: 14.0477	Cost: 5.90s
Train Epoch: 454 [81920/90000 (91%)]	Loss: 13.9527	Cost: 5.85s
Train Epoch: 454 	Average Loss: 14.0758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8218

Learning rate: 0.00019898458143618574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 455 [0/90000 (0%)]	Loss: 15.4560	Cost: 20.76s
Train Epoch: 455 [20480/90000 (23%)]	Loss: 13.9601	Cost: 6.05s
Train Epoch: 455 [40960/90000 (45%)]	Loss: 13.9672	Cost: 6.13s
Train Epoch: 455 [61440/90000 (68%)]	Loss: 14.0150	Cost: 5.90s
Train Epoch: 455 [81920/90000 (91%)]	Loss: 13.8394	Cost: 5.91s
Train Epoch: 455 	Average Loss: 14.0728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7209

Learning rate: 0.0001989801109277525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 456 [0/90000 (0%)]	Loss: 15.4575	Cost: 21.95s
Train Epoch: 456 [20480/90000 (23%)]	Loss: 14.0223	Cost: 6.04s
Train Epoch: 456 [40960/90000 (45%)]	Loss: 13.7908	Cost: 6.46s
Train Epoch: 456 [61440/90000 (68%)]	Loss: 13.8088	Cost: 6.16s
Train Epoch: 456 [81920/90000 (91%)]	Loss: 13.9044	Cost: 6.20s
Train Epoch: 456 	Average Loss: 14.0763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7936

Learning rate: 0.000198975630650374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 457 [0/90000 (0%)]	Loss: 15.2496	Cost: 19.71s
Train Epoch: 457 [20480/90000 (23%)]	Loss: 14.1071	Cost: 6.13s
Train Epoch: 457 [40960/90000 (45%)]	Loss: 13.9956	Cost: 6.20s
Train Epoch: 457 [61440/90000 (68%)]	Loss: 13.8903	Cost: 5.91s
Train Epoch: 457 [81920/90000 (91%)]	Loss: 14.0220	Cost: 6.34s
Train Epoch: 457 	Average Loss: 14.0871
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7657

Learning rate: 0.0001989711406044923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 458 [0/90000 (0%)]	Loss: 15.2877	Cost: 21.01s
Train Epoch: 458 [20480/90000 (23%)]	Loss: 14.0340	Cost: 6.07s
Train Epoch: 458 [40960/90000 (45%)]	Loss: 13.8339	Cost: 6.56s
Train Epoch: 458 [61440/90000 (68%)]	Loss: 14.0158	Cost: 5.93s
Train Epoch: 458 [81920/90000 (91%)]	Loss: 13.9661	Cost: 6.61s
Train Epoch: 458 	Average Loss: 14.0284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7540

Learning rate: 0.0001989666407905507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 459 [0/90000 (0%)]	Loss: 15.3855	Cost: 20.81s
Train Epoch: 459 [20480/90000 (23%)]	Loss: 13.6433	Cost: 5.99s
Train Epoch: 459 [40960/90000 (45%)]	Loss: 14.1735	Cost: 6.20s
Train Epoch: 459 [61440/90000 (68%)]	Loss: 13.9081	Cost: 5.93s
Train Epoch: 459 [81920/90000 (91%)]	Loss: 13.9696	Cost: 5.91s
Train Epoch: 459 	Average Loss: 14.0229
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7178

Learning rate: 0.00019896213120899325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 460 [0/90000 (0%)]	Loss: 15.3554	Cost: 21.19s
Train Epoch: 460 [20480/90000 (23%)]	Loss: 14.0786	Cost: 6.05s
Train Epoch: 460 [40960/90000 (45%)]	Loss: 13.8779	Cost: 6.63s
Train Epoch: 460 [61440/90000 (68%)]	Loss: 13.9051	Cost: 6.00s
Train Epoch: 460 [81920/90000 (91%)]	Loss: 13.9936	Cost: 6.76s
Train Epoch: 460 	Average Loss: 14.0220
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7736

Learning rate: 0.00019895761186026497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 461 [0/90000 (0%)]	Loss: 15.4757	Cost: 19.82s
Train Epoch: 461 [20480/90000 (23%)]	Loss: 13.8129	Cost: 6.04s
Train Epoch: 461 [40960/90000 (45%)]	Loss: 13.9920	Cost: 6.20s
Train Epoch: 461 [61440/90000 (68%)]	Loss: 14.0296	Cost: 5.90s
Train Epoch: 461 [81920/90000 (91%)]	Loss: 13.8142	Cost: 6.39s
Train Epoch: 461 	Average Loss: 14.0373
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7560

Learning rate: 0.000198953082744812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 462 [0/90000 (0%)]	Loss: 15.3655	Cost: 20.90s
Train Epoch: 462 [20480/90000 (23%)]	Loss: 13.8020	Cost: 6.13s
Train Epoch: 462 [40960/90000 (45%)]	Loss: 13.9993	Cost: 6.31s
Train Epoch: 462 [61440/90000 (68%)]	Loss: 13.8842	Cost: 5.93s
Train Epoch: 462 [81920/90000 (91%)]	Loss: 13.9577	Cost: 6.28s
Train Epoch: 462 	Average Loss: 14.0301
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7185

Learning rate: 0.0001989485438630813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 463 [0/90000 (0%)]	Loss: 15.4735	Cost: 20.46s
Train Epoch: 463 [20480/90000 (23%)]	Loss: 13.9258	Cost: 6.11s
Train Epoch: 463 [40960/90000 (45%)]	Loss: 13.7877	Cost: 6.45s
Train Epoch: 463 [61440/90000 (68%)]	Loss: 13.9346	Cost: 5.89s
Train Epoch: 463 [81920/90000 (91%)]	Loss: 13.6354	Cost: 6.48s
Train Epoch: 463 	Average Loss: 14.0202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8034

Learning rate: 0.00019894399521552084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 464 [0/90000 (0%)]	Loss: 15.4250	Cost: 21.86s
Train Epoch: 464 [20480/90000 (23%)]	Loss: 13.7963	Cost: 6.09s
Train Epoch: 464 [40960/90000 (45%)]	Loss: 13.8253	Cost: 6.28s
Train Epoch: 464 [61440/90000 (68%)]	Loss: 13.9438	Cost: 5.99s
Train Epoch: 464 [81920/90000 (91%)]	Loss: 13.8012	Cost: 6.21s
Train Epoch: 464 	Average Loss: 14.0031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7526

Learning rate: 0.0001989394368025795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 465 [0/90000 (0%)]	Loss: 15.5655	Cost: 21.66s
Train Epoch: 465 [20480/90000 (23%)]	Loss: 13.6696	Cost: 6.08s
Train Epoch: 465 [40960/90000 (45%)]	Loss: 13.9380	Cost: 6.07s
Train Epoch: 465 [61440/90000 (68%)]	Loss: 13.7270	Cost: 5.94s
Train Epoch: 465 [81920/90000 (91%)]	Loss: 14.0608	Cost: 6.01s
Train Epoch: 465 	Average Loss: 13.9873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8082

Learning rate: 0.0001989348686247073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 466 [0/90000 (0%)]	Loss: 15.4294	Cost: 21.05s
Train Epoch: 466 [20480/90000 (23%)]	Loss: 13.7026	Cost: 6.00s
Train Epoch: 466 [40960/90000 (45%)]	Loss: 13.9324	Cost: 6.65s
Train Epoch: 466 [61440/90000 (68%)]	Loss: 13.9131	Cost: 5.94s
Train Epoch: 466 [81920/90000 (91%)]	Loss: 13.8180	Cost: 6.95s
Train Epoch: 466 	Average Loss: 14.0150
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8403

Learning rate: 0.000198930290682355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 467 [0/90000 (0%)]	Loss: 15.4093	Cost: 19.91s
Train Epoch: 467 [20480/90000 (23%)]	Loss: 13.7176	Cost: 6.10s
Train Epoch: 467 [40960/90000 (45%)]	Loss: 13.8809	Cost: 6.70s
Train Epoch: 467 [61440/90000 (68%)]	Loss: 13.9902	Cost: 6.13s
Train Epoch: 467 [81920/90000 (91%)]	Loss: 13.7026	Cost: 6.68s
Train Epoch: 467 	Average Loss: 14.0066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7096

Learning rate: 0.00019892570297597447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 468 [0/90000 (0%)]	Loss: 15.1892	Cost: 19.88s
Train Epoch: 468 [20480/90000 (23%)]	Loss: 13.8212	Cost: 6.08s
Train Epoch: 468 [40960/90000 (45%)]	Loss: 13.7705	Cost: 6.15s
Train Epoch: 468 [61440/90000 (68%)]	Loss: 13.9284	Cost: 6.10s
Train Epoch: 468 [81920/90000 (91%)]	Loss: 13.6499	Cost: 6.93s
Train Epoch: 468 	Average Loss: 13.9806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9274

Learning rate: 0.00019892110550601846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 469 [0/90000 (0%)]	Loss: 15.4463	Cost: 20.63s
Train Epoch: 469 [20480/90000 (23%)]	Loss: 13.6971	Cost: 6.12s
Train Epoch: 469 [40960/90000 (45%)]	Loss: 13.8827	Cost: 6.36s
Train Epoch: 469 [61440/90000 (68%)]	Loss: 13.7599	Cost: 6.01s
Train Epoch: 469 [81920/90000 (91%)]	Loss: 13.7612	Cost: 7.21s
Train Epoch: 469 	Average Loss: 13.9898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8711

Learning rate: 0.00019891649827294077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 470 [0/90000 (0%)]	Loss: 15.5138	Cost: 20.03s
Train Epoch: 470 [20480/90000 (23%)]	Loss: 13.9023	Cost: 6.03s
Train Epoch: 470 [40960/90000 (45%)]	Loss: 13.8462	Cost: 6.08s
Train Epoch: 470 [61440/90000 (68%)]	Loss: 13.6270	Cost: 6.00s
Train Epoch: 470 [81920/90000 (91%)]	Loss: 13.8769	Cost: 6.58s
Train Epoch: 470 	Average Loss: 13.9869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7885

Learning rate: 0.00019891188127719607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 471 [0/90000 (0%)]	Loss: 15.5219	Cost: 20.57s
Train Epoch: 471 [20480/90000 (23%)]	Loss: 13.8741	Cost: 6.11s
Train Epoch: 471 [40960/90000 (45%)]	Loss: 13.7687	Cost: 6.30s
Train Epoch: 471 [61440/90000 (68%)]	Loss: 13.6471	Cost: 5.97s
Train Epoch: 471 [81920/90000 (91%)]	Loss: 13.7778	Cost: 7.55s
Train Epoch: 471 	Average Loss: 13.9685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8761

Learning rate: 0.00019890725451924011
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 472 [0/90000 (0%)]	Loss: 15.3499	Cost: 19.84s
Train Epoch: 472 [20480/90000 (23%)]	Loss: 13.7337	Cost: 6.06s
Train Epoch: 472 [40960/90000 (45%)]	Loss: 14.0083	Cost: 6.09s
Train Epoch: 472 [61440/90000 (68%)]	Loss: 13.7016	Cost: 5.94s
Train Epoch: 472 [81920/90000 (91%)]	Loss: 13.6518	Cost: 6.45s
Train Epoch: 472 	Average Loss: 13.9308
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8330

Learning rate: 0.00019890261799952944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 473 [0/90000 (0%)]	Loss: 15.3729	Cost: 20.63s
Train Epoch: 473 [20480/90000 (23%)]	Loss: 13.8409	Cost: 6.06s
Train Epoch: 473 [40960/90000 (45%)]	Loss: 13.8529	Cost: 6.10s
Train Epoch: 473 [61440/90000 (68%)]	Loss: 13.7381	Cost: 5.96s
Train Epoch: 473 [81920/90000 (91%)]	Loss: 13.7704	Cost: 6.01s
Train Epoch: 473 	Average Loss: 13.9463
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7521

Learning rate: 0.00019889797171852172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 474 [0/90000 (0%)]	Loss: 15.3398	Cost: 20.56s
Train Epoch: 474 [20480/90000 (23%)]	Loss: 13.5883	Cost: 6.09s
Train Epoch: 474 [40960/90000 (45%)]	Loss: 13.9150	Cost: 6.23s
Train Epoch: 474 [61440/90000 (68%)]	Loss: 13.7576	Cost: 5.97s
Train Epoch: 474 [81920/90000 (91%)]	Loss: 13.7268	Cost: 6.44s
Train Epoch: 474 	Average Loss: 13.9104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8303

Learning rate: 0.0001988933156766755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 475 [0/90000 (0%)]	Loss: 15.4013	Cost: 22.20s
Train Epoch: 475 [20480/90000 (23%)]	Loss: 13.7064	Cost: 6.07s
Train Epoch: 475 [40960/90000 (45%)]	Loss: 13.9017	Cost: 6.08s
Train Epoch: 475 [61440/90000 (68%)]	Loss: 13.8834	Cost: 6.03s
Train Epoch: 475 [81920/90000 (91%)]	Loss: 13.8064	Cost: 6.76s
Train Epoch: 475 	Average Loss: 13.9148
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8101

Learning rate: 0.00019888864987445035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 476 [0/90000 (0%)]	Loss: 15.1671	Cost: 20.47s
Train Epoch: 476 [20480/90000 (23%)]	Loss: 13.6766	Cost: 6.07s
Train Epoch: 476 [40960/90000 (45%)]	Loss: 13.7420	Cost: 6.09s
Train Epoch: 476 [61440/90000 (68%)]	Loss: 13.7109	Cost: 5.95s
Train Epoch: 476 [81920/90000 (91%)]	Loss: 13.8516	Cost: 5.95s
Train Epoch: 476 	Average Loss: 13.8976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9043

Learning rate: 0.00019888397431230674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 477 [0/90000 (0%)]	Loss: 15.2719	Cost: 21.02s
Train Epoch: 477 [20480/90000 (23%)]	Loss: 13.7943	Cost: 6.14s
Train Epoch: 477 [40960/90000 (45%)]	Loss: 14.0009	Cost: 7.11s
Train Epoch: 477 [61440/90000 (68%)]	Loss: 13.8809	Cost: 5.94s
Train Epoch: 477 [81920/90000 (91%)]	Loss: 13.7686	Cost: 6.66s
Train Epoch: 477 	Average Loss: 13.9219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8506

Learning rate: 0.00019887928899070613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 478 [0/90000 (0%)]	Loss: 15.4869	Cost: 20.69s
Train Epoch: 478 [20480/90000 (23%)]	Loss: 13.6698	Cost: 6.02s
Train Epoch: 478 [40960/90000 (45%)]	Loss: 13.7634	Cost: 6.58s
Train Epoch: 478 [61440/90000 (68%)]	Loss: 13.6938	Cost: 6.06s
Train Epoch: 478 [81920/90000 (91%)]	Loss: 13.7570	Cost: 5.89s
Train Epoch: 478 	Average Loss: 13.8984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8985

Learning rate: 0.00019887459391011093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 479 [0/90000 (0%)]	Loss: 15.5425	Cost: 20.57s
Train Epoch: 479 [20480/90000 (23%)]	Loss: 13.5925	Cost: 6.06s
Train Epoch: 479 [40960/90000 (45%)]	Loss: 13.7437	Cost: 6.13s
Train Epoch: 479 [61440/90000 (68%)]	Loss: 13.5990	Cost: 5.98s
Train Epoch: 479 [81920/90000 (91%)]	Loss: 13.7062	Cost: 6.24s
Train Epoch: 479 	Average Loss: 13.9139
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9017

Learning rate: 0.0001988698890709845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 480 [0/90000 (0%)]	Loss: 15.4419	Cost: 20.77s
Train Epoch: 480 [20480/90000 (23%)]	Loss: 13.7823	Cost: 6.06s
Train Epoch: 480 [40960/90000 (45%)]	Loss: 13.9055	Cost: 6.14s
Train Epoch: 480 [61440/90000 (68%)]	Loss: 13.8962	Cost: 6.03s
Train Epoch: 480 [81920/90000 (91%)]	Loss: 13.7710	Cost: 6.10s
Train Epoch: 480 	Average Loss: 13.9643
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8801

Learning rate: 0.0001988651744737913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 481 [0/90000 (0%)]	Loss: 15.4487	Cost: 20.21s
Train Epoch: 481 [20480/90000 (23%)]	Loss: 13.6145	Cost: 6.10s
Train Epoch: 481 [40960/90000 (45%)]	Loss: 13.6876	Cost: 6.05s
Train Epoch: 481 [61440/90000 (68%)]	Loss: 13.9159	Cost: 6.15s
Train Epoch: 481 [81920/90000 (91%)]	Loss: 13.7814	Cost: 5.99s
Train Epoch: 481 	Average Loss: 13.9073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9278

Learning rate: 0.00019886045011899655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 482 [0/90000 (0%)]	Loss: 15.2367	Cost: 21.24s
Train Epoch: 482 [20480/90000 (23%)]	Loss: 13.7758	Cost: 6.10s
Train Epoch: 482 [40960/90000 (45%)]	Loss: 13.7978	Cost: 6.13s
Train Epoch: 482 [61440/90000 (68%)]	Loss: 13.7955	Cost: 6.02s
Train Epoch: 482 [81920/90000 (91%)]	Loss: 13.6547	Cost: 5.92s
Train Epoch: 482 	Average Loss: 13.8675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8856

Learning rate: 0.00019885571600706652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 483 [0/90000 (0%)]	Loss: 15.1984	Cost: 20.50s
Train Epoch: 483 [20480/90000 (23%)]	Loss: 13.5029	Cost: 6.03s
Train Epoch: 483 [40960/90000 (45%)]	Loss: 13.7583	Cost: 6.63s
Train Epoch: 483 [61440/90000 (68%)]	Loss: 13.9451	Cost: 5.93s
Train Epoch: 483 [81920/90000 (91%)]	Loss: 13.7264	Cost: 6.26s
Train Epoch: 483 	Average Loss: 13.8522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8207

Learning rate: 0.00019885097213846847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 484 [0/90000 (0%)]	Loss: 15.3759	Cost: 21.60s
Train Epoch: 484 [20480/90000 (23%)]	Loss: 13.6856	Cost: 6.04s
Train Epoch: 484 [40960/90000 (45%)]	Loss: 13.6779	Cost: 6.62s
Train Epoch: 484 [61440/90000 (68%)]	Loss: 13.7675	Cost: 5.96s
Train Epoch: 484 [81920/90000 (91%)]	Loss: 13.7283	Cost: 6.44s
Train Epoch: 484 	Average Loss: 13.8685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8385

Learning rate: 0.00019884621851367065
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 485 [0/90000 (0%)]	Loss: 15.3676	Cost: 20.76s
Train Epoch: 485 [20480/90000 (23%)]	Loss: 13.7424	Cost: 5.99s
Train Epoch: 485 [40960/90000 (45%)]	Loss: 13.7714	Cost: 6.55s
Train Epoch: 485 [61440/90000 (68%)]	Loss: 13.6295	Cost: 5.93s
Train Epoch: 485 [81920/90000 (91%)]	Loss: 13.8411	Cost: 6.11s
Train Epoch: 485 	Average Loss: 13.8980
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8700

Learning rate: 0.00019884145513314214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 486 [0/90000 (0%)]	Loss: 15.4627	Cost: 22.27s
Train Epoch: 486 [20480/90000 (23%)]	Loss: 13.8224	Cost: 6.03s
Train Epoch: 486 [40960/90000 (45%)]	Loss: 13.6307	Cost: 6.47s
Train Epoch: 486 [61440/90000 (68%)]	Loss: 13.7551	Cost: 5.91s
Train Epoch: 486 [81920/90000 (91%)]	Loss: 13.4791	Cost: 6.74s
Train Epoch: 486 	Average Loss: 13.8477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8495

Learning rate: 0.00019883668199735307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 487 [0/90000 (0%)]	Loss: 15.5135	Cost: 20.50s
Train Epoch: 487 [20480/90000 (23%)]	Loss: 13.6127	Cost: 6.15s
Train Epoch: 487 [40960/90000 (45%)]	Loss: 13.9058	Cost: 6.35s
Train Epoch: 487 [61440/90000 (68%)]	Loss: 13.6229	Cost: 5.91s
Train Epoch: 487 [81920/90000 (91%)]	Loss: 13.7159	Cost: 5.83s
Train Epoch: 487 	Average Loss: 13.8413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8620

Learning rate: 0.00019883189910677464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 488 [0/90000 (0%)]	Loss: 15.4662	Cost: 21.80s
Train Epoch: 488 [20480/90000 (23%)]	Loss: 13.7879	Cost: 6.07s
Train Epoch: 488 [40960/90000 (45%)]	Loss: 13.7157	Cost: 6.11s
Train Epoch: 488 [61440/90000 (68%)]	Loss: 13.7596	Cost: 5.90s
Train Epoch: 488 [81920/90000 (91%)]	Loss: 13.8224	Cost: 5.84s
Train Epoch: 488 	Average Loss: 13.8597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9154

Learning rate: 0.00019882710646187875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 489 [0/90000 (0%)]	Loss: 15.5367	Cost: 20.21s
Train Epoch: 489 [20480/90000 (23%)]	Loss: 13.6053	Cost: 6.01s
Train Epoch: 489 [40960/90000 (45%)]	Loss: 13.7140	Cost: 6.13s
Train Epoch: 489 [61440/90000 (68%)]	Loss: 13.7801	Cost: 6.03s
Train Epoch: 489 [81920/90000 (91%)]	Loss: 13.4867	Cost: 5.79s
Train Epoch: 489 	Average Loss: 13.8286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9691

Learning rate: 0.00019882230406313855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 490 [0/90000 (0%)]	Loss: 15.2646	Cost: 20.49s
Train Epoch: 490 [20480/90000 (23%)]	Loss: 13.6837	Cost: 5.98s
Train Epoch: 490 [40960/90000 (45%)]	Loss: 13.6337	Cost: 6.33s
Train Epoch: 490 [61440/90000 (68%)]	Loss: 13.6691	Cost: 5.87s
Train Epoch: 490 [81920/90000 (91%)]	Loss: 13.7438	Cost: 5.78s
Train Epoch: 490 	Average Loss: 13.8207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8540

Learning rate: 0.00019881749191102795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 491 [0/90000 (0%)]	Loss: 15.4179	Cost: 20.04s
Train Epoch: 491 [20480/90000 (23%)]	Loss: 13.6147	Cost: 6.15s
Train Epoch: 491 [40960/90000 (45%)]	Loss: 13.6340	Cost: 7.02s
Train Epoch: 491 [61440/90000 (68%)]	Loss: 13.6787	Cost: 5.85s
Train Epoch: 491 [81920/90000 (91%)]	Loss: 13.6509	Cost: 6.09s
Train Epoch: 491 	Average Loss: 13.8066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8857

Learning rate: 0.00019881267000602186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 492 [0/90000 (0%)]	Loss: 15.4800	Cost: 20.27s
Train Epoch: 492 [20480/90000 (23%)]	Loss: 13.5339	Cost: 6.17s
Train Epoch: 492 [40960/90000 (45%)]	Loss: 13.7332	Cost: 6.05s
Train Epoch: 492 [61440/90000 (68%)]	Loss: 13.4624	Cost: 5.92s
Train Epoch: 492 [81920/90000 (91%)]	Loss: 13.5469	Cost: 5.82s
Train Epoch: 492 	Average Loss: 13.7638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9333

Learning rate: 0.00019880783834859626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 493 [0/90000 (0%)]	Loss: 15.3960	Cost: 19.69s
Train Epoch: 493 [20480/90000 (23%)]	Loss: 13.6433	Cost: 6.15s
Train Epoch: 493 [40960/90000 (45%)]	Loss: 13.7042	Cost: 6.10s
Train Epoch: 493 [61440/90000 (68%)]	Loss: 13.4469	Cost: 5.95s
Train Epoch: 493 [81920/90000 (91%)]	Loss: 13.5368	Cost: 5.82s
Train Epoch: 493 	Average Loss: 13.7932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9175

Learning rate: 0.000198802996939228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 494 [0/90000 (0%)]	Loss: 15.2256	Cost: 20.36s
Train Epoch: 494 [20480/90000 (23%)]	Loss: 13.6334	Cost: 6.19s
Train Epoch: 494 [40960/90000 (45%)]	Loss: 13.5330	Cost: 6.13s
Train Epoch: 494 [61440/90000 (68%)]	Loss: 13.6268	Cost: 5.87s
Train Epoch: 494 [81920/90000 (91%)]	Loss: 13.6526	Cost: 5.79s
Train Epoch: 494 	Average Loss: 13.7982
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9221

Learning rate: 0.0001987981457783948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 495 [0/90000 (0%)]	Loss: 15.4452	Cost: 20.55s
Train Epoch: 495 [20480/90000 (23%)]	Loss: 13.6517	Cost: 5.99s
Train Epoch: 495 [40960/90000 (45%)]	Loss: 13.7555	Cost: 6.21s
Train Epoch: 495 [61440/90000 (68%)]	Loss: 13.8852	Cost: 5.88s
Train Epoch: 495 [81920/90000 (91%)]	Loss: 13.5686	Cost: 5.81s
Train Epoch: 495 	Average Loss: 13.7726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9140

Learning rate: 0.00019879328486657562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 496 [0/90000 (0%)]	Loss: 15.2813	Cost: 20.70s
Train Epoch: 496 [20480/90000 (23%)]	Loss: 13.5711	Cost: 6.07s
Train Epoch: 496 [40960/90000 (45%)]	Loss: 13.6117	Cost: 6.36s
Train Epoch: 496 [61440/90000 (68%)]	Loss: 13.6428	Cost: 5.93s
Train Epoch: 496 [81920/90000 (91%)]	Loss: 13.6713	Cost: 5.88s
Train Epoch: 496 	Average Loss: 13.7631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9218

Learning rate: 0.0001987884142042501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 497 [0/90000 (0%)]	Loss: 15.1807	Cost: 21.32s
Train Epoch: 497 [20480/90000 (23%)]	Loss: 13.5104	Cost: 6.00s
Train Epoch: 497 [40960/90000 (45%)]	Loss: 13.5592	Cost: 6.86s
Train Epoch: 497 [61440/90000 (68%)]	Loss: 13.5467	Cost: 5.94s
Train Epoch: 497 [81920/90000 (91%)]	Loss: 13.4845	Cost: 5.84s
Train Epoch: 497 	Average Loss: 13.7469
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9638

Learning rate: 0.00019878353379189899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 498 [0/90000 (0%)]	Loss: 15.5508	Cost: 22.40s
Train Epoch: 498 [20480/90000 (23%)]	Loss: 13.5751	Cost: 6.09s
Train Epoch: 498 [40960/90000 (45%)]	Loss: 13.4801	Cost: 6.51s
Train Epoch: 498 [61440/90000 (68%)]	Loss: 13.7840	Cost: 5.89s
Train Epoch: 498 [81920/90000 (91%)]	Loss: 13.7030	Cost: 6.06s
Train Epoch: 498 	Average Loss: 13.7571
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9490

Learning rate: 0.00019877864363000396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 499 [0/90000 (0%)]	Loss: 15.5970	Cost: 20.76s
Train Epoch: 499 [20480/90000 (23%)]	Loss: 13.6647	Cost: 6.26s
Train Epoch: 499 [40960/90000 (45%)]	Loss: 13.5826	Cost: 6.70s
Train Epoch: 499 [61440/90000 (68%)]	Loss: 13.5191	Cost: 5.87s
Train Epoch: 499 [81920/90000 (91%)]	Loss: 13.4285	Cost: 5.79s
Train Epoch: 499 	Average Loss: 13.7475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9897

Learning rate: 0.00019877374371904765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 500 [0/90000 (0%)]	Loss: 15.4571	Cost: 22.23s
Train Epoch: 500 [20480/90000 (23%)]	Loss: 13.6132	Cost: 5.95s
Train Epoch: 500 [40960/90000 (45%)]	Loss: 13.6571	Cost: 6.72s
Train Epoch: 500 [61440/90000 (68%)]	Loss: 13.5664	Cost: 6.04s
Train Epoch: 500 [81920/90000 (91%)]	Loss: 13.5325	Cost: 5.80s
Train Epoch: 500 	Average Loss: 13.7399
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0309

Learning rate: 0.00019876883405951367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 501 [0/90000 (0%)]	Loss: 15.4206	Cost: 20.01s
Train Epoch: 501 [20480/90000 (23%)]	Loss: 13.5195	Cost: 6.10s
Train Epoch: 501 [40960/90000 (45%)]	Loss: 13.7943	Cost: 6.43s
Train Epoch: 501 [61440/90000 (68%)]	Loss: 13.8362	Cost: 5.99s
Train Epoch: 501 [81920/90000 (91%)]	Loss: 13.4501	Cost: 5.96s
Train Epoch: 501 	Average Loss: 13.7371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0472

Learning rate: 0.00019876391465188656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 502 [0/90000 (0%)]	Loss: 15.5709	Cost: 19.44s
Train Epoch: 502 [20480/90000 (23%)]	Loss: 13.4223	Cost: 6.18s
Train Epoch: 502 [40960/90000 (45%)]	Loss: 13.6772	Cost: 6.25s
Train Epoch: 502 [61440/90000 (68%)]	Loss: 13.7213	Cost: 5.94s
Train Epoch: 502 [81920/90000 (91%)]	Loss: 13.5553	Cost: 5.89s
Train Epoch: 502 	Average Loss: 13.7605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8917

Learning rate: 0.00019875898549665186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 503 [0/90000 (0%)]	Loss: 15.6535	Cost: 20.30s
Train Epoch: 503 [20480/90000 (23%)]	Loss: 13.5381	Cost: 6.15s
Train Epoch: 503 [40960/90000 (45%)]	Loss: 13.6027	Cost: 6.70s
Train Epoch: 503 [61440/90000 (68%)]	Loss: 13.4272	Cost: 5.89s
Train Epoch: 503 [81920/90000 (91%)]	Loss: 13.5305	Cost: 6.27s
Train Epoch: 503 	Average Loss: 13.7343
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0418

Learning rate: 0.0001987540465942961
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 504 [0/90000 (0%)]	Loss: 15.5500	Cost: 20.97s
Train Epoch: 504 [20480/90000 (23%)]	Loss: 13.5399	Cost: 6.06s
Train Epoch: 504 [40960/90000 (45%)]	Loss: 13.6134	Cost: 6.14s
Train Epoch: 504 [61440/90000 (68%)]	Loss: 13.3177	Cost: 5.95s
Train Epoch: 504 [81920/90000 (91%)]	Loss: 13.5165	Cost: 5.77s
Train Epoch: 504 	Average Loss: 13.7064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0062

Learning rate: 0.00019874909794530664
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 505 [0/90000 (0%)]	Loss: 15.3221	Cost: 20.42s
Train Epoch: 505 [20480/90000 (23%)]	Loss: 13.4887	Cost: 6.04s
Train Epoch: 505 [40960/90000 (45%)]	Loss: 13.5488	Cost: 6.14s
Train Epoch: 505 [61440/90000 (68%)]	Loss: 13.4585	Cost: 5.98s
Train Epoch: 505 [81920/90000 (91%)]	Loss: 13.8186	Cost: 5.81s
Train Epoch: 505 	Average Loss: 13.7036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9718

Learning rate: 0.00019874413955017195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 506 [0/90000 (0%)]	Loss: 15.7114	Cost: 20.03s
Train Epoch: 506 [20480/90000 (23%)]	Loss: 13.4799	Cost: 6.22s
Train Epoch: 506 [40960/90000 (45%)]	Loss: 13.6039	Cost: 7.27s
Train Epoch: 506 [61440/90000 (68%)]	Loss: 13.4692	Cost: 5.93s
Train Epoch: 506 [81920/90000 (91%)]	Loss: 13.6254	Cost: 5.91s
Train Epoch: 506 	Average Loss: 13.6970
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9619

Learning rate: 0.00019873917140938142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 507 [0/90000 (0%)]	Loss: 15.6830	Cost: 19.83s
Train Epoch: 507 [20480/90000 (23%)]	Loss: 13.6034	Cost: 6.25s
Train Epoch: 507 [40960/90000 (45%)]	Loss: 13.3910	Cost: 6.73s
Train Epoch: 507 [61440/90000 (68%)]	Loss: 13.5838	Cost: 6.07s
Train Epoch: 507 [81920/90000 (91%)]	Loss: 13.5785	Cost: 5.80s
Train Epoch: 507 	Average Loss: 13.6978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9449

Learning rate: 0.00019873419352342536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 508 [0/90000 (0%)]	Loss: 15.4687	Cost: 20.54s
Train Epoch: 508 [20480/90000 (23%)]	Loss: 13.7176	Cost: 6.13s
Train Epoch: 508 [40960/90000 (45%)]	Loss: 13.5286	Cost: 6.46s
Train Epoch: 508 [61440/90000 (68%)]	Loss: 13.5406	Cost: 5.89s
Train Epoch: 508 [81920/90000 (91%)]	Loss: 13.6523	Cost: 5.87s
Train Epoch: 508 	Average Loss: 13.6820
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9371

Learning rate: 0.00019872920589279508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 509 [0/90000 (0%)]	Loss: 15.5010	Cost: 19.88s
Train Epoch: 509 [20480/90000 (23%)]	Loss: 13.6273	Cost: 6.23s
Train Epoch: 509 [40960/90000 (45%)]	Loss: 13.6503	Cost: 7.12s
Train Epoch: 509 [61440/90000 (68%)]	Loss: 13.5737	Cost: 5.67s
Train Epoch: 509 [81920/90000 (91%)]	Loss: 13.4863	Cost: 6.21s
Train Epoch: 509 	Average Loss: 13.6614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9921

Learning rate: 0.0001987242085179828
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 510 [0/90000 (0%)]	Loss: 15.5127	Cost: 21.03s
Train Epoch: 510 [20480/90000 (23%)]	Loss: 13.3834	Cost: 6.04s
Train Epoch: 510 [40960/90000 (45%)]	Loss: 13.4585	Cost: 6.08s
Train Epoch: 510 [61440/90000 (68%)]	Loss: 13.4670	Cost: 5.96s
Train Epoch: 510 [81920/90000 (91%)]	Loss: 13.4644	Cost: 5.78s
Train Epoch: 510 	Average Loss: 13.6584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0714

Learning rate: 0.00019871920139948181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 511 [0/90000 (0%)]	Loss: 15.4717	Cost: 20.23s
Train Epoch: 511 [20480/90000 (23%)]	Loss: 13.4489	Cost: 6.03s
Train Epoch: 511 [40960/90000 (45%)]	Loss: 13.3526	Cost: 6.14s
Train Epoch: 511 [61440/90000 (68%)]	Loss: 13.6925	Cost: 5.99s
Train Epoch: 511 [81920/90000 (91%)]	Loss: 13.5433	Cost: 5.81s
Train Epoch: 511 	Average Loss: 13.6858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0296

Learning rate: 0.00019871418453778627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 512 [0/90000 (0%)]	Loss: 15.6109	Cost: 20.70s
Train Epoch: 512 [20480/90000 (23%)]	Loss: 13.4160	Cost: 6.09s
Train Epoch: 512 [40960/90000 (45%)]	Loss: 13.5282	Cost: 6.97s
Train Epoch: 512 [61440/90000 (68%)]	Loss: 13.5336	Cost: 5.92s
Train Epoch: 512 [81920/90000 (91%)]	Loss: 13.6073	Cost: 6.15s
Train Epoch: 512 	Average Loss: 13.6594
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0386

Learning rate: 0.00019870915793339126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 513 [0/90000 (0%)]	Loss: 15.6042	Cost: 20.02s
Train Epoch: 513 [20480/90000 (23%)]	Loss: 13.4982	Cost: 6.15s
Train Epoch: 513 [40960/90000 (45%)]	Loss: 13.4632	Cost: 6.47s
Train Epoch: 513 [61440/90000 (68%)]	Loss: 13.5379	Cost: 5.92s
Train Epoch: 513 [81920/90000 (91%)]	Loss: 13.3489	Cost: 5.82s
Train Epoch: 513 	Average Loss: 13.6670
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1248

Learning rate: 0.00019870412158679292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 514 [0/90000 (0%)]	Loss: 15.6204	Cost: 20.72s
Train Epoch: 514 [20480/90000 (23%)]	Loss: 13.2343	Cost: 6.14s
Train Epoch: 514 [40960/90000 (45%)]	Loss: 13.5685	Cost: 7.20s
Train Epoch: 514 [61440/90000 (68%)]	Loss: 13.5296	Cost: 5.96s
Train Epoch: 514 [81920/90000 (91%)]	Loss: 13.3906	Cost: 6.65s
Train Epoch: 514 	Average Loss: 13.6467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9767

Learning rate: 0.00019869907549848836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 515 [0/90000 (0%)]	Loss: 15.4564	Cost: 19.87s
Train Epoch: 515 [20480/90000 (23%)]	Loss: 13.3238	Cost: 6.05s
Train Epoch: 515 [40960/90000 (45%)]	Loss: 13.4209	Cost: 6.97s
Train Epoch: 515 [61440/90000 (68%)]	Loss: 13.2531	Cost: 5.90s
Train Epoch: 515 [81920/90000 (91%)]	Loss: 13.5091	Cost: 6.37s
Train Epoch: 515 	Average Loss: 13.6004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9578

Learning rate: 0.0001986940196689756
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 516 [0/90000 (0%)]	Loss: 15.6301	Cost: 21.86s
Train Epoch: 516 [20480/90000 (23%)]	Loss: 13.6752	Cost: 6.08s
Train Epoch: 516 [40960/90000 (45%)]	Loss: 13.3714	Cost: 6.78s
Train Epoch: 516 [61440/90000 (68%)]	Loss: 13.4621	Cost: 5.89s
Train Epoch: 516 [81920/90000 (91%)]	Loss: 13.2745	Cost: 6.28s
Train Epoch: 516 	Average Loss: 13.5903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0101

Learning rate: 0.00019868895409875357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 517 [0/90000 (0%)]	Loss: 15.5250	Cost: 20.57s
Train Epoch: 517 [20480/90000 (23%)]	Loss: 13.3187	Cost: 6.10s
Train Epoch: 517 [40960/90000 (45%)]	Loss: 13.3435	Cost: 7.06s
Train Epoch: 517 [61440/90000 (68%)]	Loss: 13.4714	Cost: 5.88s
Train Epoch: 517 [81920/90000 (91%)]	Loss: 13.4983	Cost: 6.22s
Train Epoch: 517 	Average Loss: 13.5934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9918

Learning rate: 0.00019868387878832229
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 518 [0/90000 (0%)]	Loss: 15.3998	Cost: 19.96s
Train Epoch: 518 [20480/90000 (23%)]	Loss: 13.3800	Cost: 6.04s
Train Epoch: 518 [40960/90000 (45%)]	Loss: 13.4071	Cost: 6.18s
Train Epoch: 518 [61440/90000 (68%)]	Loss: 13.5292	Cost: 6.07s
Train Epoch: 518 [81920/90000 (91%)]	Loss: 13.5021	Cost: 6.22s
Train Epoch: 518 	Average Loss: 13.5885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0191

Learning rate: 0.00019867879373818264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 519 [0/90000 (0%)]	Loss: 15.1972	Cost: 19.92s
Train Epoch: 519 [20480/90000 (23%)]	Loss: 13.5202	Cost: 6.04s
Train Epoch: 519 [40960/90000 (45%)]	Loss: 13.5141	Cost: 6.04s
Train Epoch: 519 [61440/90000 (68%)]	Loss: 13.3690	Cost: 5.90s
Train Epoch: 519 [81920/90000 (91%)]	Loss: 13.4674	Cost: 5.76s
Train Epoch: 519 	Average Loss: 13.6179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1426

Learning rate: 0.00019867369894883648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 520 [0/90000 (0%)]	Loss: 15.6487	Cost: 21.71s
Train Epoch: 520 [20480/90000 (23%)]	Loss: 13.3973	Cost: 6.11s
Train Epoch: 520 [40960/90000 (45%)]	Loss: 13.4429	Cost: 6.58s
Train Epoch: 520 [61440/90000 (68%)]	Loss: 13.3840	Cost: 5.90s
Train Epoch: 520 [81920/90000 (91%)]	Loss: 13.3546	Cost: 6.45s
Train Epoch: 520 	Average Loss: 13.6021
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0614

Learning rate: 0.0001986685944207867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 521 [0/90000 (0%)]	Loss: 15.5828	Cost: 19.86s
Train Epoch: 521 [20480/90000 (23%)]	Loss: 13.2347	Cost: 6.03s
Train Epoch: 521 [40960/90000 (45%)]	Loss: 13.2725	Cost: 5.99s
Train Epoch: 521 [61440/90000 (68%)]	Loss: 13.4396	Cost: 5.88s
Train Epoch: 521 [81920/90000 (91%)]	Loss: 13.5078	Cost: 5.75s
Train Epoch: 521 	Average Loss: 13.5593
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0284

Learning rate: 0.00019866348015453705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 522 [0/90000 (0%)]	Loss: 15.7699	Cost: 20.85s
Train Epoch: 522 [20480/90000 (23%)]	Loss: 13.0979	Cost: 6.06s
Train Epoch: 522 [40960/90000 (45%)]	Loss: 13.5588	Cost: 6.75s
Train Epoch: 522 [61440/90000 (68%)]	Loss: 13.3881	Cost: 5.97s
Train Epoch: 522 [81920/90000 (91%)]	Loss: 13.2829	Cost: 6.48s
Train Epoch: 522 	Average Loss: 13.5635
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0384

Learning rate: 0.0001986583561505923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 523 [0/90000 (0%)]	Loss: 15.5164	Cost: 20.17s
Train Epoch: 523 [20480/90000 (23%)]	Loss: 13.3011	Cost: 6.12s
Train Epoch: 523 [40960/90000 (45%)]	Loss: 13.3730	Cost: 6.24s
Train Epoch: 523 [61440/90000 (68%)]	Loss: 13.2963	Cost: 5.89s
Train Epoch: 523 [81920/90000 (91%)]	Loss: 13.1711	Cost: 5.79s
Train Epoch: 523 	Average Loss: 13.5611
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1759

Learning rate: 0.0001986532224094582
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 524 [0/90000 (0%)]	Loss: 15.6054	Cost: 21.00s
Train Epoch: 524 [20480/90000 (23%)]	Loss: 13.1950	Cost: 6.00s
Train Epoch: 524 [40960/90000 (45%)]	Loss: 13.3613	Cost: 6.02s
Train Epoch: 524 [61440/90000 (68%)]	Loss: 13.2313	Cost: 5.95s
Train Epoch: 524 [81920/90000 (91%)]	Loss: 13.3663	Cost: 5.84s
Train Epoch: 524 	Average Loss: 13.5238
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0030

Learning rate: 0.00019864807893164133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 525 [0/90000 (0%)]	Loss: 15.5116	Cost: 20.58s
Train Epoch: 525 [20480/90000 (23%)]	Loss: 13.3113	Cost: 6.09s
Train Epoch: 525 [40960/90000 (45%)]	Loss: 13.2643	Cost: 6.11s
Train Epoch: 525 [61440/90000 (68%)]	Loss: 13.4244	Cost: 5.90s
Train Epoch: 525 [81920/90000 (91%)]	Loss: 13.4250	Cost: 6.12s
Train Epoch: 525 	Average Loss: 13.5574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1237

Learning rate: 0.00019864292571764947
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 526 [0/90000 (0%)]	Loss: 15.3444	Cost: 21.33s
Train Epoch: 526 [20480/90000 (23%)]	Loss: 13.1828	Cost: 6.10s
Train Epoch: 526 [40960/90000 (45%)]	Loss: 13.3970	Cost: 6.11s
Train Epoch: 526 [61440/90000 (68%)]	Loss: 13.0595	Cost: 5.93s
Train Epoch: 526 [81920/90000 (91%)]	Loss: 13.2087	Cost: 5.87s
Train Epoch: 526 	Average Loss: 13.5210
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1809

Learning rate: 0.00019863776276799112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 527 [0/90000 (0%)]	Loss: 15.4765	Cost: 21.73s
Train Epoch: 527 [20480/90000 (23%)]	Loss: 13.3374	Cost: 6.07s
Train Epoch: 527 [40960/90000 (45%)]	Loss: 13.2005	Cost: 6.86s
Train Epoch: 527 [61440/90000 (68%)]	Loss: 13.5229	Cost: 5.87s
Train Epoch: 527 [81920/90000 (91%)]	Loss: 13.3012	Cost: 6.39s
Train Epoch: 527 	Average Loss: 13.5150
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0482

Learning rate: 0.00019863259008317586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 528 [0/90000 (0%)]	Loss: 15.7512	Cost: 20.30s
Train Epoch: 528 [20480/90000 (23%)]	Loss: 13.1877	Cost: 6.03s
Train Epoch: 528 [40960/90000 (45%)]	Loss: 13.4744	Cost: 6.07s
Train Epoch: 528 [61440/90000 (68%)]	Loss: 13.4852	Cost: 5.90s
Train Epoch: 528 [81920/90000 (91%)]	Loss: 13.2263	Cost: 5.90s
Train Epoch: 528 	Average Loss: 13.5368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0671

Learning rate: 0.00019862740766371425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 529 [0/90000 (0%)]	Loss: 15.6002	Cost: 21.89s
Train Epoch: 529 [20480/90000 (23%)]	Loss: 13.3462	Cost: 6.01s
Train Epoch: 529 [40960/90000 (45%)]	Loss: 13.2069	Cost: 6.51s
Train Epoch: 529 [61440/90000 (68%)]	Loss: 13.3169	Cost: 6.02s
Train Epoch: 529 [81920/90000 (91%)]	Loss: 13.4025	Cost: 6.05s
Train Epoch: 529 	Average Loss: 13.5486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0857

Learning rate: 0.00019862221551011772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 530 [0/90000 (0%)]	Loss: 15.7076	Cost: 20.27s
Train Epoch: 530 [20480/90000 (23%)]	Loss: 13.1670	Cost: 6.13s
Train Epoch: 530 [40960/90000 (45%)]	Loss: 13.3145	Cost: 6.05s
Train Epoch: 530 [61440/90000 (68%)]	Loss: 13.0465	Cost: 5.89s
Train Epoch: 530 [81920/90000 (91%)]	Loss: 13.1726	Cost: 5.91s
Train Epoch: 530 	Average Loss: 13.4863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0994

Learning rate: 0.0001986170136228988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 531 [0/90000 (0%)]	Loss: 15.5407	Cost: 20.10s
Train Epoch: 531 [20480/90000 (23%)]	Loss: 13.2675	Cost: 6.07s
Train Epoch: 531 [40960/90000 (45%)]	Loss: 13.2238	Cost: 6.03s
Train Epoch: 531 [61440/90000 (68%)]	Loss: 13.2743	Cost: 5.96s
Train Epoch: 531 [81920/90000 (91%)]	Loss: 13.3544	Cost: 5.97s
Train Epoch: 531 	Average Loss: 13.4536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9862

Learning rate: 0.00019861180200257079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 532 [0/90000 (0%)]	Loss: 15.3579	Cost: 22.07s
Train Epoch: 532 [20480/90000 (23%)]	Loss: 13.2574	Cost: 5.92s
Train Epoch: 532 [40960/90000 (45%)]	Loss: 13.3808	Cost: 6.02s
Train Epoch: 532 [61440/90000 (68%)]	Loss: 13.3873	Cost: 5.93s
Train Epoch: 532 [81920/90000 (91%)]	Loss: 13.3089	Cost: 5.93s
Train Epoch: 532 	Average Loss: 13.4873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2116

Learning rate: 0.00019860658064964812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 533 [0/90000 (0%)]	Loss: 15.5425	Cost: 21.92s
Train Epoch: 533 [20480/90000 (23%)]	Loss: 13.2801	Cost: 5.98s
Train Epoch: 533 [40960/90000 (45%)]	Loss: 13.2985	Cost: 6.50s
Train Epoch: 533 [61440/90000 (68%)]	Loss: 13.2237	Cost: 5.87s
Train Epoch: 533 [81920/90000 (91%)]	Loss: 13.2904	Cost: 5.84s
Train Epoch: 533 	Average Loss: 13.4478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1362

Learning rate: 0.0001986013495646461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 534 [0/90000 (0%)]	Loss: 15.5016	Cost: 20.50s
Train Epoch: 534 [20480/90000 (23%)]	Loss: 13.2561	Cost: 5.99s
Train Epoch: 534 [40960/90000 (45%)]	Loss: 13.2397	Cost: 6.19s
Train Epoch: 534 [61440/90000 (68%)]	Loss: 13.3021	Cost: 5.89s
Train Epoch: 534 [81920/90000 (91%)]	Loss: 13.2962	Cost: 5.78s
Train Epoch: 534 	Average Loss: 13.4579
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2072

Learning rate: 0.00019859610874808106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 535 [0/90000 (0%)]	Loss: 15.8672	Cost: 20.41s
Train Epoch: 535 [20480/90000 (23%)]	Loss: 13.4539	Cost: 5.90s
Train Epoch: 535 [40960/90000 (45%)]	Loss: 13.1696	Cost: 5.81s
Train Epoch: 535 [61440/90000 (68%)]	Loss: 13.3769	Cost: 5.83s
Train Epoch: 535 [81920/90000 (91%)]	Loss: 13.2090	Cost: 5.86s
Train Epoch: 535 	Average Loss: 13.4648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0504

Learning rate: 0.0001985908582004702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 536 [0/90000 (0%)]	Loss: 15.4981	Cost: 21.41s
Train Epoch: 536 [20480/90000 (23%)]	Loss: 13.2797	Cost: 6.05s
Train Epoch: 536 [40960/90000 (45%)]	Loss: 13.3924	Cost: 6.42s
Train Epoch: 536 [61440/90000 (68%)]	Loss: 13.5679	Cost: 5.90s
Train Epoch: 536 [81920/90000 (91%)]	Loss: 13.1252	Cost: 6.03s
Train Epoch: 536 	Average Loss: 13.4611
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1779

Learning rate: 0.00019858559792233175
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 537 [0/90000 (0%)]	Loss: 15.7536	Cost: 19.47s
Train Epoch: 537 [20480/90000 (23%)]	Loss: 13.2346	Cost: 6.12s
Train Epoch: 537 [40960/90000 (45%)]	Loss: 13.1811	Cost: 6.07s
Train Epoch: 537 [61440/90000 (68%)]	Loss: 13.0759	Cost: 5.95s
Train Epoch: 537 [81920/90000 (91%)]	Loss: 13.1806	Cost: 5.85s
Train Epoch: 537 	Average Loss: 13.4656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1076

Learning rate: 0.00019858032791418486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 538 [0/90000 (0%)]	Loss: 15.5334	Cost: 22.06s
Train Epoch: 538 [20480/90000 (23%)]	Loss: 13.2348	Cost: 6.10s
Train Epoch: 538 [40960/90000 (45%)]	Loss: 13.0936	Cost: 6.44s
Train Epoch: 538 [61440/90000 (68%)]	Loss: 13.3560	Cost: 5.91s
Train Epoch: 538 [81920/90000 (91%)]	Loss: 13.1469	Cost: 6.27s
Train Epoch: 538 	Average Loss: 13.4125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2016

Learning rate: 0.00019857504817654965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 539 [0/90000 (0%)]	Loss: 15.3790	Cost: 22.05s
Train Epoch: 539 [20480/90000 (23%)]	Loss: 13.1141	Cost: 6.04s
Train Epoch: 539 [40960/90000 (45%)]	Loss: 13.4270	Cost: 6.79s
Train Epoch: 539 [61440/90000 (68%)]	Loss: 13.3541	Cost: 5.77s
Train Epoch: 539 [81920/90000 (91%)]	Loss: 13.1241	Cost: 6.38s
Train Epoch: 539 	Average Loss: 13.4285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0877

Learning rate: 0.00019856975870994725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 540 [0/90000 (0%)]	Loss: 15.6297	Cost: 20.50s
Train Epoch: 540 [20480/90000 (23%)]	Loss: 13.1504	Cost: 6.14s
Train Epoch: 540 [40960/90000 (45%)]	Loss: 13.1374	Cost: 6.44s
Train Epoch: 540 [61440/90000 (68%)]	Loss: 13.3029	Cost: 6.06s
Train Epoch: 540 [81920/90000 (91%)]	Loss: 13.2723	Cost: 5.96s
Train Epoch: 540 	Average Loss: 13.4199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0829

Learning rate: 0.0001985644595148997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 541 [0/90000 (0%)]	Loss: 15.8913	Cost: 19.54s
Train Epoch: 541 [20480/90000 (23%)]	Loss: 13.1904	Cost: 6.08s
Train Epoch: 541 [40960/90000 (45%)]	Loss: 13.1893	Cost: 6.33s
Train Epoch: 541 [61440/90000 (68%)]	Loss: 13.0792	Cost: 5.92s
Train Epoch: 541 [81920/90000 (91%)]	Loss: 13.3274	Cost: 6.14s
Train Epoch: 541 	Average Loss: 13.4248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1154

Learning rate: 0.00019855915059192997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 542 [0/90000 (0%)]	Loss: 15.7927	Cost: 21.16s
Train Epoch: 542 [20480/90000 (23%)]	Loss: 13.1912	Cost: 6.05s
Train Epoch: 542 [40960/90000 (45%)]	Loss: 13.3112	Cost: 6.49s
Train Epoch: 542 [61440/90000 (68%)]	Loss: 13.4018	Cost: 5.98s
Train Epoch: 542 [81920/90000 (91%)]	Loss: 13.0239	Cost: 6.21s
Train Epoch: 542 	Average Loss: 13.4038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1438

Learning rate: 0.00019855383194156202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 543 [0/90000 (0%)]	Loss: 15.5987	Cost: 19.81s
Train Epoch: 543 [20480/90000 (23%)]	Loss: 13.3499	Cost: 6.04s
Train Epoch: 543 [40960/90000 (45%)]	Loss: 12.9438	Cost: 6.42s
Train Epoch: 543 [61440/90000 (68%)]	Loss: 13.1210	Cost: 6.03s
Train Epoch: 543 [81920/90000 (91%)]	Loss: 13.2539	Cost: 5.90s
Train Epoch: 543 	Average Loss: 13.3658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1964

Learning rate: 0.00019854850356432085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 544 [0/90000 (0%)]	Loss: 15.7913	Cost: 21.52s
Train Epoch: 544 [20480/90000 (23%)]	Loss: 13.1776	Cost: 6.15s
Train Epoch: 544 [40960/90000 (45%)]	Loss: 13.0182	Cost: 6.50s
Train Epoch: 544 [61440/90000 (68%)]	Loss: 13.1435	Cost: 5.95s
Train Epoch: 544 [81920/90000 (91%)]	Loss: 13.2105	Cost: 6.28s
Train Epoch: 544 	Average Loss: 13.4079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1476

Learning rate: 0.00019854316546073235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 545 [0/90000 (0%)]	Loss: 15.7133	Cost: 21.90s
Train Epoch: 545 [20480/90000 (23%)]	Loss: 13.0852	Cost: 6.00s
Train Epoch: 545 [40960/90000 (45%)]	Loss: 13.1373	Cost: 6.08s
Train Epoch: 545 [61440/90000 (68%)]	Loss: 13.0638	Cost: 5.96s
Train Epoch: 545 [81920/90000 (91%)]	Loss: 13.2871	Cost: 5.85s
Train Epoch: 545 	Average Loss: 13.3682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1716

Learning rate: 0.0001985378176313233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 546 [0/90000 (0%)]	Loss: 15.8664	Cost: 21.88s
Train Epoch: 546 [20480/90000 (23%)]	Loss: 13.0406	Cost: 6.10s
Train Epoch: 546 [40960/90000 (45%)]	Loss: 13.2506	Cost: 6.35s
Train Epoch: 546 [61440/90000 (68%)]	Loss: 13.3468	Cost: 5.99s
Train Epoch: 546 [81920/90000 (91%)]	Loss: 13.3013	Cost: 6.44s
Train Epoch: 546 	Average Loss: 13.3811
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1197

Learning rate: 0.00019853246007662156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 547 [0/90000 (0%)]	Loss: 15.6264	Cost: 20.82s
Train Epoch: 547 [20480/90000 (23%)]	Loss: 13.1629	Cost: 6.00s
Train Epoch: 547 [40960/90000 (45%)]	Loss: 13.2340	Cost: 6.27s
Train Epoch: 547 [61440/90000 (68%)]	Loss: 13.3402	Cost: 5.87s
Train Epoch: 547 [81920/90000 (91%)]	Loss: 12.9718	Cost: 5.80s
Train Epoch: 547 	Average Loss: 13.3548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2282

Learning rate: 0.0001985270927971559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 548 [0/90000 (0%)]	Loss: 15.7274	Cost: 21.07s
Train Epoch: 548 [20480/90000 (23%)]	Loss: 13.2293	Cost: 6.08s
Train Epoch: 548 [40960/90000 (45%)]	Loss: 13.0514	Cost: 6.28s
Train Epoch: 548 [61440/90000 (68%)]	Loss: 13.1754	Cost: 5.98s
Train Epoch: 548 [81920/90000 (91%)]	Loss: 13.0837	Cost: 6.01s
Train Epoch: 548 	Average Loss: 13.3583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0921

Learning rate: 0.00019852171579345603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 549 [0/90000 (0%)]	Loss: 15.8915	Cost: 19.96s
Train Epoch: 549 [20480/90000 (23%)]	Loss: 13.0391	Cost: 6.07s
Train Epoch: 549 [40960/90000 (45%)]	Loss: 13.0322	Cost: 6.14s
Train Epoch: 549 [61440/90000 (68%)]	Loss: 13.1380	Cost: 5.90s
Train Epoch: 549 [81920/90000 (91%)]	Loss: 13.3039	Cost: 5.72s
Train Epoch: 549 	Average Loss: 13.3547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2267

Learning rate: 0.0001985163290660526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 550 [0/90000 (0%)]	Loss: 15.7663	Cost: 19.99s
Train Epoch: 550 [20480/90000 (23%)]	Loss: 13.1522	Cost: 6.02s
Train Epoch: 550 [40960/90000 (45%)]	Loss: 13.1859	Cost: 6.09s
Train Epoch: 550 [61440/90000 (68%)]	Loss: 13.2448	Cost: 5.91s
Train Epoch: 550 [81920/90000 (91%)]	Loss: 13.2346	Cost: 6.29s
Train Epoch: 550 	Average Loss: 13.3278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1936

Learning rate: 0.0001985109326154773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 551 [0/90000 (0%)]	Loss: 15.7223	Cost: 21.75s
Train Epoch: 551 [20480/90000 (23%)]	Loss: 13.0372	Cost: 5.99s
Train Epoch: 551 [40960/90000 (45%)]	Loss: 13.2462	Cost: 6.66s
Train Epoch: 551 [61440/90000 (68%)]	Loss: 13.3298	Cost: 6.02s
Train Epoch: 551 [81920/90000 (91%)]	Loss: 13.1769	Cost: 5.75s
Train Epoch: 551 	Average Loss: 13.3303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2834

Learning rate: 0.00019850552644226275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 552 [0/90000 (0%)]	Loss: 15.6738	Cost: 21.24s
Train Epoch: 552 [20480/90000 (23%)]	Loss: 13.1976	Cost: 6.00s
Train Epoch: 552 [40960/90000 (45%)]	Loss: 13.0471	Cost: 6.94s
Train Epoch: 552 [61440/90000 (68%)]	Loss: 13.1242	Cost: 5.92s
Train Epoch: 552 [81920/90000 (91%)]	Loss: 12.8467	Cost: 6.60s
Train Epoch: 552 	Average Loss: 13.3143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2663

Learning rate: 0.0001985001105469425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 553 [0/90000 (0%)]	Loss: 15.5936	Cost: 22.52s
Train Epoch: 553 [20480/90000 (23%)]	Loss: 12.9971	Cost: 5.94s
Train Epoch: 553 [40960/90000 (45%)]	Loss: 13.1519	Cost: 6.47s
Train Epoch: 553 [61440/90000 (68%)]	Loss: 13.1815	Cost: 5.90s
Train Epoch: 553 [81920/90000 (91%)]	Loss: 12.9598	Cost: 6.21s
Train Epoch: 553 	Average Loss: 13.3217
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1294

Learning rate: 0.00019849468493005109
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 554 [0/90000 (0%)]	Loss: 15.7314	Cost: 20.67s
Train Epoch: 554 [20480/90000 (23%)]	Loss: 13.1273	Cost: 5.97s
Train Epoch: 554 [40960/90000 (45%)]	Loss: 13.1956	Cost: 6.05s
Train Epoch: 554 [61440/90000 (68%)]	Loss: 12.9259	Cost: 5.91s
Train Epoch: 554 [81920/90000 (91%)]	Loss: 13.1791	Cost: 5.80s
Train Epoch: 554 	Average Loss: 13.3201
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2695

Learning rate: 0.000198489249592124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 555 [0/90000 (0%)]	Loss: 15.7587	Cost: 21.59s
Train Epoch: 555 [20480/90000 (23%)]	Loss: 12.9673	Cost: 6.01s
Train Epoch: 555 [40960/90000 (45%)]	Loss: 13.0895	Cost: 6.69s
Train Epoch: 555 [61440/90000 (68%)]	Loss: 12.9694	Cost: 5.85s
Train Epoch: 555 [81920/90000 (91%)]	Loss: 13.0452	Cost: 5.80s
Train Epoch: 555 	Average Loss: 13.2828
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1960

Learning rate: 0.00019848380453369767
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 556 [0/90000 (0%)]	Loss: 15.7730	Cost: 20.79s
Train Epoch: 556 [20480/90000 (23%)]	Loss: 12.8875	Cost: 6.12s
Train Epoch: 556 [40960/90000 (45%)]	Loss: 13.1255	Cost: 6.19s
Train Epoch: 556 [61440/90000 (68%)]	Loss: 13.2450	Cost: 5.90s
Train Epoch: 556 [81920/90000 (91%)]	Loss: 13.1223	Cost: 5.84s
Train Epoch: 556 	Average Loss: 13.2570
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2110

Learning rate: 0.00019847834975530955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 557 [0/90000 (0%)]	Loss: 15.9667	Cost: 20.49s
Train Epoch: 557 [20480/90000 (23%)]	Loss: 13.1572	Cost: 6.03s
Train Epoch: 557 [40960/90000 (45%)]	Loss: 13.1272	Cost: 6.46s
Train Epoch: 557 [61440/90000 (68%)]	Loss: 13.0567	Cost: 5.88s
Train Epoch: 557 [81920/90000 (91%)]	Loss: 12.9055	Cost: 5.98s
Train Epoch: 557 	Average Loss: 13.2939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2413

Learning rate: 0.00019847288525749797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 558 [0/90000 (0%)]	Loss: 15.8934	Cost: 20.13s
Train Epoch: 558 [20480/90000 (23%)]	Loss: 13.1664	Cost: 6.03s
Train Epoch: 558 [40960/90000 (45%)]	Loss: 13.0604	Cost: 6.36s
Train Epoch: 558 [61440/90000 (68%)]	Loss: 13.1311	Cost: 5.88s
Train Epoch: 558 [81920/90000 (91%)]	Loss: 13.0829	Cost: 5.94s
Train Epoch: 558 	Average Loss: 13.2980
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1213

Learning rate: 0.0001984674110408022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 559 [0/90000 (0%)]	Loss: 15.5839	Cost: 21.51s
Train Epoch: 559 [20480/90000 (23%)]	Loss: 12.8362	Cost: 6.05s
Train Epoch: 559 [40960/90000 (45%)]	Loss: 13.1984	Cost: 7.03s
Train Epoch: 559 [61440/90000 (68%)]	Loss: 13.1021	Cost: 5.88s
Train Epoch: 559 [81920/90000 (91%)]	Loss: 13.0103	Cost: 6.19s
Train Epoch: 559 	Average Loss: 13.2622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2625

Learning rate: 0.0001984619271057626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 560 [0/90000 (0%)]	Loss: 15.6615	Cost: 20.24s
Train Epoch: 560 [20480/90000 (23%)]	Loss: 13.0600	Cost: 6.11s
Train Epoch: 560 [40960/90000 (45%)]	Loss: 13.0102	Cost: 6.04s
Train Epoch: 560 [61440/90000 (68%)]	Loss: 13.0283	Cost: 5.94s
Train Epoch: 560 [81920/90000 (91%)]	Loss: 12.8522	Cost: 5.96s
Train Epoch: 560 	Average Loss: 13.2427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2113

Learning rate: 0.0001984564334529204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 561 [0/90000 (0%)]	Loss: 15.8521	Cost: 20.82s
Train Epoch: 561 [20480/90000 (23%)]	Loss: 13.1590	Cost: 6.10s
Train Epoch: 561 [40960/90000 (45%)]	Loss: 12.9533	Cost: 6.38s
Train Epoch: 561 [61440/90000 (68%)]	Loss: 13.0427	Cost: 5.84s
Train Epoch: 561 [81920/90000 (91%)]	Loss: 13.0260	Cost: 5.81s
Train Epoch: 561 	Average Loss: 13.2344
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1992

Learning rate: 0.0001984509300828178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 562 [0/90000 (0%)]	Loss: 15.8339	Cost: 20.54s
Train Epoch: 562 [20480/90000 (23%)]	Loss: 13.0249	Cost: 6.04s
Train Epoch: 562 [40960/90000 (45%)]	Loss: 12.8214	Cost: 6.81s
Train Epoch: 562 [61440/90000 (68%)]	Loss: 12.9654	Cost: 6.18s
Train Epoch: 562 [81920/90000 (91%)]	Loss: 13.1354	Cost: 6.58s
Train Epoch: 562 	Average Loss: 13.2312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1699

Learning rate: 0.00019844541699599793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 563 [0/90000 (0%)]	Loss: 15.7446	Cost: 21.62s
Train Epoch: 563 [20480/90000 (23%)]	Loss: 13.0796	Cost: 6.03s
Train Epoch: 563 [40960/90000 (45%)]	Loss: 13.0909	Cost: 6.33s
Train Epoch: 563 [61440/90000 (68%)]	Loss: 12.9781	Cost: 5.98s
Train Epoch: 563 [81920/90000 (91%)]	Loss: 13.2360	Cost: 6.37s
Train Epoch: 563 	Average Loss: 13.2182
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2794

Learning rate: 0.00019843989419300492
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 564 [0/90000 (0%)]	Loss: 15.5462	Cost: 19.86s
Train Epoch: 564 [20480/90000 (23%)]	Loss: 13.0548	Cost: 6.17s
Train Epoch: 564 [40960/90000 (45%)]	Loss: 13.2660	Cost: 6.04s
Train Epoch: 564 [61440/90000 (68%)]	Loss: 13.0988	Cost: 5.95s
Train Epoch: 564 [81920/90000 (91%)]	Loss: 13.0028	Cost: 5.82s
Train Epoch: 564 	Average Loss: 13.2434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3674

Learning rate: 0.00019843436167438387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 565 [0/90000 (0%)]	Loss: 15.5828	Cost: 21.16s
Train Epoch: 565 [20480/90000 (23%)]	Loss: 12.9426	Cost: 6.16s
Train Epoch: 565 [40960/90000 (45%)]	Loss: 12.8454	Cost: 6.82s
Train Epoch: 565 [61440/90000 (68%)]	Loss: 13.1494	Cost: 5.92s
Train Epoch: 565 [81920/90000 (91%)]	Loss: 12.7304	Cost: 6.77s
Train Epoch: 565 	Average Loss: 13.1625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3196

Learning rate: 0.00019842881944068082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 566 [0/90000 (0%)]	Loss: 15.9366	Cost: 21.76s
Train Epoch: 566 [20480/90000 (23%)]	Loss: 13.0266	Cost: 6.10s
Train Epoch: 566 [40960/90000 (45%)]	Loss: 13.0503	Cost: 6.38s
Train Epoch: 566 [61440/90000 (68%)]	Loss: 12.9427	Cost: 5.89s
Train Epoch: 566 [81920/90000 (91%)]	Loss: 13.0308	Cost: 6.12s
Train Epoch: 566 	Average Loss: 13.1924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2828

Learning rate: 0.00019842326749244275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 567 [0/90000 (0%)]	Loss: 15.6511	Cost: 21.15s
Train Epoch: 567 [20480/90000 (23%)]	Loss: 12.8513	Cost: 6.07s
Train Epoch: 567 [40960/90000 (45%)]	Loss: 12.7863	Cost: 7.35s
Train Epoch: 567 [61440/90000 (68%)]	Loss: 13.0473	Cost: 5.84s
Train Epoch: 567 [81920/90000 (91%)]	Loss: 13.1225	Cost: 6.56s
Train Epoch: 567 	Average Loss: 13.1940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3117

Learning rate: 0.00019841770583021762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 568 [0/90000 (0%)]	Loss: 15.7999	Cost: 21.78s
Train Epoch: 568 [20480/90000 (23%)]	Loss: 12.9864	Cost: 5.95s
Train Epoch: 568 [40960/90000 (45%)]	Loss: 12.6784	Cost: 6.13s
Train Epoch: 568 [61440/90000 (68%)]	Loss: 13.1197	Cost: 5.91s
Train Epoch: 568 [81920/90000 (91%)]	Loss: 12.8934	Cost: 5.94s
Train Epoch: 568 	Average Loss: 13.1534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2088

Learning rate: 0.00019841213445455434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 569 [0/90000 (0%)]	Loss: 15.8900	Cost: 20.11s
Train Epoch: 569 [20480/90000 (23%)]	Loss: 12.7976	Cost: 6.20s
Train Epoch: 569 [40960/90000 (45%)]	Loss: 12.9483	Cost: 6.04s
Train Epoch: 569 [61440/90000 (68%)]	Loss: 13.0795	Cost: 5.96s
Train Epoch: 569 [81920/90000 (91%)]	Loss: 12.9480	Cost: 5.93s
Train Epoch: 569 	Average Loss: 13.1464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2980

Learning rate: 0.00019840655336600282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 570 [0/90000 (0%)]	Loss: 16.0039	Cost: 20.04s
Train Epoch: 570 [20480/90000 (23%)]	Loss: 12.7698	Cost: 6.02s
Train Epoch: 570 [40960/90000 (45%)]	Loss: 12.9189	Cost: 6.60s
Train Epoch: 570 [61440/90000 (68%)]	Loss: 13.0017	Cost: 5.86s
Train Epoch: 570 [81920/90000 (91%)]	Loss: 13.0884	Cost: 5.83s
Train Epoch: 570 	Average Loss: 13.1659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2431

Learning rate: 0.00019840096256511382
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 571 [0/90000 (0%)]	Loss: 15.5910	Cost: 21.60s
Train Epoch: 571 [20480/90000 (23%)]	Loss: 12.9080	Cost: 6.01s
Train Epoch: 571 [40960/90000 (45%)]	Loss: 13.0751	Cost: 6.22s
Train Epoch: 571 [61440/90000 (68%)]	Loss: 12.8535	Cost: 5.91s
Train Epoch: 571 [81920/90000 (91%)]	Loss: 12.6828	Cost: 5.81s
Train Epoch: 571 	Average Loss: 13.1277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1726

Learning rate: 0.0001983953620524392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 572 [0/90000 (0%)]	Loss: 15.7223	Cost: 20.19s
Train Epoch: 572 [20480/90000 (23%)]	Loss: 12.8104	Cost: 6.09s
Train Epoch: 572 [40960/90000 (45%)]	Loss: 12.7597	Cost: 6.66s
Train Epoch: 572 [61440/90000 (68%)]	Loss: 12.8907	Cost: 5.92s
Train Epoch: 572 [81920/90000 (91%)]	Loss: 12.9010	Cost: 5.82s
Train Epoch: 572 	Average Loss: 13.1248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2733

Learning rate: 0.00019838975182853166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 573 [0/90000 (0%)]	Loss: 16.0436	Cost: 21.16s
Train Epoch: 573 [20480/90000 (23%)]	Loss: 12.9281	Cost: 6.07s
Train Epoch: 573 [40960/90000 (45%)]	Loss: 12.8716	Cost: 6.18s
Train Epoch: 573 [61440/90000 (68%)]	Loss: 12.9537	Cost: 6.06s
Train Epoch: 573 [81920/90000 (91%)]	Loss: 13.0207	Cost: 5.85s
Train Epoch: 573 	Average Loss: 13.1570
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2967

Learning rate: 0.0001983841318939449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 574 [0/90000 (0%)]	Loss: 15.8073	Cost: 21.62s
Train Epoch: 574 [20480/90000 (23%)]	Loss: 13.0163	Cost: 6.13s
Train Epoch: 574 [40960/90000 (45%)]	Loss: 12.8932	Cost: 6.80s
Train Epoch: 574 [61440/90000 (68%)]	Loss: 12.6481	Cost: 5.86s
Train Epoch: 574 [81920/90000 (91%)]	Loss: 12.7436	Cost: 6.09s
Train Epoch: 574 	Average Loss: 13.1368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3251

Learning rate: 0.00019837850224923363
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 575 [0/90000 (0%)]	Loss: 15.8639	Cost: 21.13s
Train Epoch: 575 [20480/90000 (23%)]	Loss: 12.7644	Cost: 6.02s
Train Epoch: 575 [40960/90000 (45%)]	Loss: 12.6920	Cost: 6.56s
Train Epoch: 575 [61440/90000 (68%)]	Loss: 13.0385	Cost: 5.92s
Train Epoch: 575 [81920/90000 (91%)]	Loss: 12.9500	Cost: 6.26s
Train Epoch: 575 	Average Loss: 13.1003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3205

Learning rate: 0.00019837286289495345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 576 [0/90000 (0%)]	Loss: 16.1845	Cost: 23.04s
Train Epoch: 576 [20480/90000 (23%)]	Loss: 12.9265	Cost: 5.95s
Train Epoch: 576 [40960/90000 (45%)]	Loss: 12.9033	Cost: 6.92s
Train Epoch: 576 [61440/90000 (68%)]	Loss: 13.1131	Cost: 5.90s
Train Epoch: 576 [81920/90000 (91%)]	Loss: 12.9486	Cost: 6.58s
Train Epoch: 576 	Average Loss: 13.1113
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2517

Learning rate: 0.00019836721383166095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 577 [0/90000 (0%)]	Loss: 16.0848	Cost: 20.82s
Train Epoch: 577 [20480/90000 (23%)]	Loss: 12.9602	Cost: 6.08s
Train Epoch: 577 [40960/90000 (45%)]	Loss: 12.9546	Cost: 6.11s
Train Epoch: 577 [61440/90000 (68%)]	Loss: 12.8711	Cost: 5.91s
Train Epoch: 577 [81920/90000 (91%)]	Loss: 12.8162	Cost: 5.82s
Train Epoch: 577 	Average Loss: 13.1245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2814

Learning rate: 0.00019836155505991362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 578 [0/90000 (0%)]	Loss: 15.8538	Cost: 21.09s
Train Epoch: 578 [20480/90000 (23%)]	Loss: 12.7745	Cost: 6.03s
Train Epoch: 578 [40960/90000 (45%)]	Loss: 12.7670	Cost: 6.24s
Train Epoch: 578 [61440/90000 (68%)]	Loss: 13.0382	Cost: 5.92s
Train Epoch: 578 [81920/90000 (91%)]	Loss: 12.8349	Cost: 6.44s
Train Epoch: 578 	Average Loss: 13.0980
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4277

Learning rate: 0.00019835588658027008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 579 [0/90000 (0%)]	Loss: 15.9741	Cost: 21.67s
Train Epoch: 579 [20480/90000 (23%)]	Loss: 12.9905	Cost: 6.01s
Train Epoch: 579 [40960/90000 (45%)]	Loss: 13.0950	Cost: 6.68s
Train Epoch: 579 [61440/90000 (68%)]	Loss: 13.0651	Cost: 5.85s
Train Epoch: 579 [81920/90000 (91%)]	Loss: 13.0368	Cost: 6.14s
Train Epoch: 579 	Average Loss: 13.1231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2719

Learning rate: 0.00019835020839328965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 580 [0/90000 (0%)]	Loss: 15.8294	Cost: 20.60s
Train Epoch: 580 [20480/90000 (23%)]	Loss: 12.9122	Cost: 6.10s
Train Epoch: 580 [40960/90000 (45%)]	Loss: 12.8775	Cost: 6.58s
Train Epoch: 580 [61440/90000 (68%)]	Loss: 12.9349	Cost: 5.88s
Train Epoch: 580 [81920/90000 (91%)]	Loss: 13.0973	Cost: 6.35s
Train Epoch: 580 	Average Loss: 13.1118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3334

Learning rate: 0.0001983445204995328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 581 [0/90000 (0%)]	Loss: 15.6648	Cost: 21.27s
Train Epoch: 581 [20480/90000 (23%)]	Loss: 12.8195	Cost: 5.98s
Train Epoch: 581 [40960/90000 (45%)]	Loss: 12.8771	Cost: 6.39s
Train Epoch: 581 [61440/90000 (68%)]	Loss: 13.0593	Cost: 5.90s
Train Epoch: 581 [81920/90000 (91%)]	Loss: 12.9005	Cost: 5.82s
Train Epoch: 581 	Average Loss: 13.0639
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3264

Learning rate: 0.00019833882289956094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 582 [0/90000 (0%)]	Loss: 15.9871	Cost: 22.24s
Train Epoch: 582 [20480/90000 (23%)]	Loss: 12.8055	Cost: 6.02s
Train Epoch: 582 [40960/90000 (45%)]	Loss: 12.7738	Cost: 6.57s
Train Epoch: 582 [61440/90000 (68%)]	Loss: 12.7616	Cost: 5.99s
Train Epoch: 582 [81920/90000 (91%)]	Loss: 13.1260	Cost: 6.50s
Train Epoch: 582 	Average Loss: 13.0449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3142

Learning rate: 0.00019833311559393636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 583 [0/90000 (0%)]	Loss: 15.7807	Cost: 21.43s
Train Epoch: 583 [20480/90000 (23%)]	Loss: 12.7048	Cost: 5.98s
Train Epoch: 583 [40960/90000 (45%)]	Loss: 12.8086	Cost: 6.09s
Train Epoch: 583 [61440/90000 (68%)]	Loss: 12.9100	Cost: 5.92s
Train Epoch: 583 [81920/90000 (91%)]	Loss: 12.8000	Cost: 5.81s
Train Epoch: 583 	Average Loss: 13.0407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3585

Learning rate: 0.00019832739858322235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 584 [0/90000 (0%)]	Loss: 15.9590	Cost: 21.03s
Train Epoch: 584 [20480/90000 (23%)]	Loss: 12.8905	Cost: 6.08s
Train Epoch: 584 [40960/90000 (45%)]	Loss: 12.8279	Cost: 6.58s
Train Epoch: 584 [61440/90000 (68%)]	Loss: 12.6067	Cost: 6.12s
Train Epoch: 584 [81920/90000 (91%)]	Loss: 12.8217	Cost: 6.04s
Train Epoch: 584 	Average Loss: 13.0532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4562

Learning rate: 0.00019832167186798315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 585 [0/90000 (0%)]	Loss: 15.8968	Cost: 19.73s
Train Epoch: 585 [20480/90000 (23%)]	Loss: 12.9898	Cost: 6.13s
Train Epoch: 585 [40960/90000 (45%)]	Loss: 12.7414	Cost: 6.07s
Train Epoch: 585 [61440/90000 (68%)]	Loss: 12.6132	Cost: 5.91s
Train Epoch: 585 [81920/90000 (91%)]	Loss: 12.7284	Cost: 5.89s
Train Epoch: 585 	Average Loss: 13.0272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3570

Learning rate: 0.000198315935448784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 586 [0/90000 (0%)]	Loss: 15.9152	Cost: 20.73s
Train Epoch: 586 [20480/90000 (23%)]	Loss: 12.5822	Cost: 6.07s
Train Epoch: 586 [40960/90000 (45%)]	Loss: 12.7853	Cost: 6.32s
Train Epoch: 586 [61440/90000 (68%)]	Loss: 12.8275	Cost: 5.90s
Train Epoch: 586 [81920/90000 (91%)]	Loss: 12.7134	Cost: 6.37s
Train Epoch: 586 	Average Loss: 13.0084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4073

Learning rate: 0.00019831018932619103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 587 [0/90000 (0%)]	Loss: 16.2848	Cost: 20.77s
Train Epoch: 587 [20480/90000 (23%)]	Loss: 12.7574	Cost: 6.07s
Train Epoch: 587 [40960/90000 (45%)]	Loss: 13.0462	Cost: 6.98s
Train Epoch: 587 [61440/90000 (68%)]	Loss: 12.7256	Cost: 5.87s
Train Epoch: 587 [81920/90000 (91%)]	Loss: 12.8029	Cost: 6.11s
Train Epoch: 587 	Average Loss: 13.0246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3673

Learning rate: 0.00019830443350077136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 588 [0/90000 (0%)]	Loss: 15.8141	Cost: 20.65s
Train Epoch: 588 [20480/90000 (23%)]	Loss: 12.7248	Cost: 6.15s
Train Epoch: 588 [40960/90000 (45%)]	Loss: 12.7893	Cost: 6.16s
Train Epoch: 588 [61440/90000 (68%)]	Loss: 12.7278	Cost: 5.89s
Train Epoch: 588 [81920/90000 (91%)]	Loss: 12.7296	Cost: 6.23s
Train Epoch: 588 	Average Loss: 12.9350
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4202

Learning rate: 0.0001982986679730931
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 589 [0/90000 (0%)]	Loss: 15.7175	Cost: 21.07s
Train Epoch: 589 [20480/90000 (23%)]	Loss: 12.7752	Cost: 6.16s
Train Epoch: 589 [40960/90000 (45%)]	Loss: 12.7340	Cost: 6.29s
Train Epoch: 589 [61440/90000 (68%)]	Loss: 12.6123	Cost: 5.92s
Train Epoch: 589 [81920/90000 (91%)]	Loss: 12.5589	Cost: 6.14s
Train Epoch: 589 	Average Loss: 12.9662
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3228

Learning rate: 0.00019829289274372522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 590 [0/90000 (0%)]	Loss: 15.9733	Cost: 20.98s
Train Epoch: 590 [20480/90000 (23%)]	Loss: 12.6888	Cost: 6.12s
Train Epoch: 590 [40960/90000 (45%)]	Loss: 12.5799	Cost: 6.45s
Train Epoch: 590 [61440/90000 (68%)]	Loss: 12.7046	Cost: 5.98s
Train Epoch: 590 [81920/90000 (91%)]	Loss: 12.6187	Cost: 6.28s
Train Epoch: 590 	Average Loss: 12.9596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5277

Learning rate: 0.00019828710781323776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 591 [0/90000 (0%)]	Loss: 16.0759	Cost: 20.18s
Train Epoch: 591 [20480/90000 (23%)]	Loss: 12.6056	Cost: 6.11s
Train Epoch: 591 [40960/90000 (45%)]	Loss: 12.6911	Cost: 6.82s
Train Epoch: 591 [61440/90000 (68%)]	Loss: 12.8806	Cost: 5.93s
Train Epoch: 591 [81920/90000 (91%)]	Loss: 12.8812	Cost: 5.84s
Train Epoch: 591 	Average Loss: 12.9662
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3694

Learning rate: 0.00019828131318220168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 592 [0/90000 (0%)]	Loss: 15.8365	Cost: 20.65s
Train Epoch: 592 [20480/90000 (23%)]	Loss: 12.7691	Cost: 6.00s
Train Epoch: 592 [40960/90000 (45%)]	Loss: 12.7493	Cost: 6.59s
Train Epoch: 592 [61440/90000 (68%)]	Loss: 12.5563	Cost: 5.87s
Train Epoch: 592 [81920/90000 (91%)]	Loss: 12.5047	Cost: 5.88s
Train Epoch: 592 	Average Loss: 12.9310
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4713

Learning rate: 0.00019827550885118884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 593 [0/90000 (0%)]	Loss: 16.1435	Cost: 20.92s
Train Epoch: 593 [20480/90000 (23%)]	Loss: 12.6663	Cost: 6.02s
Train Epoch: 593 [40960/90000 (45%)]	Loss: 12.6565	Cost: 6.38s
Train Epoch: 593 [61440/90000 (68%)]	Loss: 12.7568	Cost: 5.88s
Train Epoch: 593 [81920/90000 (91%)]	Loss: 12.6234	Cost: 5.78s
Train Epoch: 593 	Average Loss: 12.9665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3082

Learning rate: 0.00019826969482077218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 594 [0/90000 (0%)]	Loss: 15.7106	Cost: 19.59s
Train Epoch: 594 [20480/90000 (23%)]	Loss: 12.9046	Cost: 6.07s
Train Epoch: 594 [40960/90000 (45%)]	Loss: 12.9645	Cost: 6.62s
Train Epoch: 594 [61440/90000 (68%)]	Loss: 12.8077	Cost: 5.89s
Train Epoch: 594 [81920/90000 (91%)]	Loss: 12.8324	Cost: 5.79s
Train Epoch: 594 	Average Loss: 12.9727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3328

Learning rate: 0.00019826387109152545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 595 [0/90000 (0%)]	Loss: 15.8200	Cost: 19.33s
Train Epoch: 595 [20480/90000 (23%)]	Loss: 12.5931	Cost: 6.32s
Train Epoch: 595 [40960/90000 (45%)]	Loss: 12.8043	Cost: 6.74s
Train Epoch: 595 [61440/90000 (68%)]	Loss: 12.8189	Cost: 6.23s
Train Epoch: 595 [81920/90000 (91%)]	Loss: 12.8955	Cost: 6.12s
Train Epoch: 595 	Average Loss: 12.9220
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4229

Learning rate: 0.00019825803766402344
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 596 [0/90000 (0%)]	Loss: 15.8007	Cost: 20.50s
Train Epoch: 596 [20480/90000 (23%)]	Loss: 12.5408	Cost: 6.21s
Train Epoch: 596 [40960/90000 (45%)]	Loss: 12.6848	Cost: 6.97s
Train Epoch: 596 [61440/90000 (68%)]	Loss: 12.5298	Cost: 6.07s
Train Epoch: 596 [81920/90000 (91%)]	Loss: 12.6693	Cost: 6.03s
Train Epoch: 596 	Average Loss: 12.9106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4861

Learning rate: 0.00019825219453884193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 597 [0/90000 (0%)]	Loss: 15.9567	Cost: 20.37s
Train Epoch: 597 [20480/90000 (23%)]	Loss: 12.8520	Cost: 6.26s
Train Epoch: 597 [40960/90000 (45%)]	Loss: 12.7358	Cost: 6.87s
Train Epoch: 597 [61440/90000 (68%)]	Loss: 12.7202	Cost: 5.96s
Train Epoch: 597 [81920/90000 (91%)]	Loss: 12.8866	Cost: 6.50s
Train Epoch: 597 	Average Loss: 12.9183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4434

Learning rate: 0.00019824634171655754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 598 [0/90000 (0%)]	Loss: 15.9289	Cost: 20.03s
Train Epoch: 598 [20480/90000 (23%)]	Loss: 12.6467	Cost: 6.11s
Train Epoch: 598 [40960/90000 (45%)]	Loss: 12.7072	Cost: 6.70s
Train Epoch: 598 [61440/90000 (68%)]	Loss: 12.5676	Cost: 5.99s
Train Epoch: 598 [81920/90000 (91%)]	Loss: 12.5686	Cost: 6.23s
Train Epoch: 598 	Average Loss: 12.8906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4343

Learning rate: 0.000198240479197748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 599 [0/90000 (0%)]	Loss: 15.8801	Cost: 20.09s
Train Epoch: 599 [20480/90000 (23%)]	Loss: 12.6424	Cost: 6.15s
Train Epoch: 599 [40960/90000 (45%)]	Loss: 12.5188	Cost: 6.30s
Train Epoch: 599 [61440/90000 (68%)]	Loss: 12.6072	Cost: 5.97s
Train Epoch: 599 [81920/90000 (91%)]	Loss: 12.5995	Cost: 6.01s
Train Epoch: 599 	Average Loss: 12.8853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6192

Learning rate: 0.00019823460698299188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 600 [0/90000 (0%)]	Loss: 15.7878	Cost: 21.96s
Train Epoch: 600 [20480/90000 (23%)]	Loss: 12.4366	Cost: 6.22s
Train Epoch: 600 [40960/90000 (45%)]	Loss: 12.5493	Cost: 6.10s
Train Epoch: 600 [61440/90000 (68%)]	Loss: 12.5441	Cost: 6.06s
Train Epoch: 600 [81920/90000 (91%)]	Loss: 12.6424	Cost: 6.07s
Train Epoch: 600 	Average Loss: 12.8410
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4909

Learning rate: 0.00019822872507286872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 601 [0/90000 (0%)]	Loss: 16.0150	Cost: 20.35s
Train Epoch: 601 [20480/90000 (23%)]	Loss: 12.6039	Cost: 6.15s
Train Epoch: 601 [40960/90000 (45%)]	Loss: 12.5541	Cost: 6.34s
Train Epoch: 601 [61440/90000 (68%)]	Loss: 12.8246	Cost: 5.94s
Train Epoch: 601 [81920/90000 (91%)]	Loss: 12.6244	Cost: 5.97s
Train Epoch: 601 	Average Loss: 12.8830
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5650

Learning rate: 0.00019822283346795905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 602 [0/90000 (0%)]	Loss: 16.1841	Cost: 20.06s
Train Epoch: 602 [20480/90000 (23%)]	Loss: 12.7294	Cost: 6.16s
Train Epoch: 602 [40960/90000 (45%)]	Loss: 12.4859	Cost: 6.80s
Train Epoch: 602 [61440/90000 (68%)]	Loss: 12.7599	Cost: 6.02s
Train Epoch: 602 [81920/90000 (91%)]	Loss: 12.4649	Cost: 6.79s
Train Epoch: 602 	Average Loss: 12.8738
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4630

Learning rate: 0.0001982169321688444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 603 [0/90000 (0%)]	Loss: 16.2350	Cost: 20.04s
Train Epoch: 603 [20480/90000 (23%)]	Loss: 12.5810	Cost: 6.05s
Train Epoch: 603 [40960/90000 (45%)]	Loss: 12.4654	Cost: 6.41s
Train Epoch: 603 [61440/90000 (68%)]	Loss: 12.8201	Cost: 5.97s
Train Epoch: 603 [81920/90000 (91%)]	Loss: 12.5109	Cost: 6.88s
Train Epoch: 603 	Average Loss: 12.8742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4131

Learning rate: 0.00019821102117610715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 604 [0/90000 (0%)]	Loss: 15.8329	Cost: 20.72s
Train Epoch: 604 [20480/90000 (23%)]	Loss: 12.4979	Cost: 6.04s
Train Epoch: 604 [40960/90000 (45%)]	Loss: 12.6084	Cost: 6.16s
Train Epoch: 604 [61440/90000 (68%)]	Loss: 12.5277	Cost: 6.06s
Train Epoch: 604 [81920/90000 (91%)]	Loss: 12.7245	Cost: 6.97s
Train Epoch: 604 	Average Loss: 12.8091
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5316

Learning rate: 0.00019820510049033073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 605 [0/90000 (0%)]	Loss: 15.7725	Cost: 19.38s
Train Epoch: 605 [20480/90000 (23%)]	Loss: 12.5240	Cost: 6.19s
Train Epoch: 605 [40960/90000 (45%)]	Loss: 12.4327	Cost: 6.24s
Train Epoch: 605 [61440/90000 (68%)]	Loss: 12.3655	Cost: 6.10s
Train Epoch: 605 [81920/90000 (91%)]	Loss: 12.6055	Cost: 5.98s
Train Epoch: 605 	Average Loss: 12.8179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4899

Learning rate: 0.0001981991701120995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 606 [0/90000 (0%)]	Loss: 16.1443	Cost: 20.68s
Train Epoch: 606 [20480/90000 (23%)]	Loss: 12.3154	Cost: 6.24s
Train Epoch: 606 [40960/90000 (45%)]	Loss: 12.5190	Cost: 6.18s
Train Epoch: 606 [61440/90000 (68%)]	Loss: 12.5742	Cost: 6.10s
Train Epoch: 606 [81920/90000 (91%)]	Loss: 12.4918	Cost: 6.74s
Train Epoch: 606 	Average Loss: 12.8169
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5363

Learning rate: 0.00019819323004199868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 607 [0/90000 (0%)]	Loss: 16.0351	Cost: 20.29s
Train Epoch: 607 [20480/90000 (23%)]	Loss: 12.3382	Cost: 6.06s
Train Epoch: 607 [40960/90000 (45%)]	Loss: 12.4661	Cost: 6.60s
Train Epoch: 607 [61440/90000 (68%)]	Loss: 12.6383	Cost: 6.39s
Train Epoch: 607 [81920/90000 (91%)]	Loss: 12.7592	Cost: 6.14s
Train Epoch: 607 	Average Loss: 12.8028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5652

Learning rate: 0.0001981872802806146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 608 [0/90000 (0%)]	Loss: 15.8775	Cost: 20.28s
Train Epoch: 608 [20480/90000 (23%)]	Loss: 12.5273	Cost: 6.12s
Train Epoch: 608 [40960/90000 (45%)]	Loss: 12.5395	Cost: 6.25s
Train Epoch: 608 [61440/90000 (68%)]	Loss: 12.4696	Cost: 6.13s
Train Epoch: 608 [81920/90000 (91%)]	Loss: 12.6039	Cost: 6.83s
Train Epoch: 608 	Average Loss: 12.8097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4493

Learning rate: 0.0001981813208285345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 609 [0/90000 (0%)]	Loss: 16.1026	Cost: 19.97s
Train Epoch: 609 [20480/90000 (23%)]	Loss: 12.6969	Cost: 6.13s
Train Epoch: 609 [40960/90000 (45%)]	Loss: 12.4771	Cost: 6.05s
Train Epoch: 609 [61440/90000 (68%)]	Loss: 12.6419	Cost: 5.95s
Train Epoch: 609 [81920/90000 (91%)]	Loss: 12.6704	Cost: 6.50s
Train Epoch: 609 	Average Loss: 12.8083
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5733

Learning rate: 0.00019817535168634647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 610 [0/90000 (0%)]	Loss: 16.0285	Cost: 20.05s
Train Epoch: 610 [20480/90000 (23%)]	Loss: 12.4434	Cost: 6.31s
Train Epoch: 610 [40960/90000 (45%)]	Loss: 12.5747	Cost: 6.20s
Train Epoch: 610 [61440/90000 (68%)]	Loss: 12.5639	Cost: 6.05s
Train Epoch: 610 [81920/90000 (91%)]	Loss: 12.5591	Cost: 6.66s
Train Epoch: 610 	Average Loss: 12.8117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5558

Learning rate: 0.0001981693728546397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 611 [0/90000 (0%)]	Loss: 15.9470	Cost: 19.20s
Train Epoch: 611 [20480/90000 (23%)]	Loss: 12.5895	Cost: 6.13s
Train Epoch: 611 [40960/90000 (45%)]	Loss: 12.3496	Cost: 6.19s
Train Epoch: 611 [61440/90000 (68%)]	Loss: 12.5616	Cost: 6.05s
Train Epoch: 611 [81920/90000 (91%)]	Loss: 12.6972	Cost: 6.02s
Train Epoch: 611 	Average Loss: 12.8036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5010

Learning rate: 0.00019816338433400427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 612 [0/90000 (0%)]	Loss: 15.9838	Cost: 19.62s
Train Epoch: 612 [20480/90000 (23%)]	Loss: 12.4135	Cost: 6.11s
Train Epoch: 612 [40960/90000 (45%)]	Loss: 12.6078	Cost: 6.25s
Train Epoch: 612 [61440/90000 (68%)]	Loss: 12.5771	Cost: 6.01s
Train Epoch: 612 [81920/90000 (91%)]	Loss: 12.2618	Cost: 6.64s
Train Epoch: 612 	Average Loss: 12.7437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4945

Learning rate: 0.00019815738612503125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 613 [0/90000 (0%)]	Loss: 15.9749	Cost: 20.03s
Train Epoch: 613 [20480/90000 (23%)]	Loss: 12.1853	Cost: 6.16s
Train Epoch: 613 [40960/90000 (45%)]	Loss: 12.4190	Cost: 6.04s
Train Epoch: 613 [61440/90000 (68%)]	Loss: 12.7033	Cost: 5.95s
Train Epoch: 613 [81920/90000 (91%)]	Loss: 12.5458	Cost: 6.90s
Train Epoch: 613 	Average Loss: 12.7952
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6008

Learning rate: 0.00019815137822831258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 614 [0/90000 (0%)]	Loss: 15.8717	Cost: 20.31s
Train Epoch: 614 [20480/90000 (23%)]	Loss: 12.5243	Cost: 6.04s
Train Epoch: 614 [40960/90000 (45%)]	Loss: 12.6065	Cost: 6.41s
Train Epoch: 614 [61440/90000 (68%)]	Loss: 12.5519	Cost: 5.99s
Train Epoch: 614 [81920/90000 (91%)]	Loss: 12.6122	Cost: 6.57s
Train Epoch: 614 	Average Loss: 12.7756
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5738

Learning rate: 0.00019814536064444125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 615 [0/90000 (0%)]	Loss: 16.0974	Cost: 21.64s
Train Epoch: 615 [20480/90000 (23%)]	Loss: 12.3930	Cost: 5.97s
Train Epoch: 615 [40960/90000 (45%)]	Loss: 12.3804	Cost: 6.20s
Train Epoch: 615 [61440/90000 (68%)]	Loss: 12.6500	Cost: 6.13s
Train Epoch: 615 [81920/90000 (91%)]	Loss: 12.5067	Cost: 6.62s
Train Epoch: 615 	Average Loss: 12.7216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6184

Learning rate: 0.00019813933337401116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 616 [0/90000 (0%)]	Loss: 16.0502	Cost: 19.71s
Train Epoch: 616 [20480/90000 (23%)]	Loss: 12.5961	Cost: 6.19s
Train Epoch: 616 [40960/90000 (45%)]	Loss: 12.7096	Cost: 6.00s
Train Epoch: 616 [61440/90000 (68%)]	Loss: 12.5741	Cost: 5.89s
Train Epoch: 616 [81920/90000 (91%)]	Loss: 12.4476	Cost: 5.98s
Train Epoch: 616 	Average Loss: 12.7420
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5458

Learning rate: 0.0001981332964176172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 617 [0/90000 (0%)]	Loss: 16.1074	Cost: 20.56s
Train Epoch: 617 [20480/90000 (23%)]	Loss: 12.1943	Cost: 6.16s
Train Epoch: 617 [40960/90000 (45%)]	Loss: 12.3571	Cost: 6.94s
Train Epoch: 617 [61440/90000 (68%)]	Loss: 12.4759	Cost: 6.16s
Train Epoch: 617 [81920/90000 (91%)]	Loss: 12.5050	Cost: 6.17s
Train Epoch: 617 	Average Loss: 12.6871
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6344

Learning rate: 0.00019812724977585515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 618 [0/90000 (0%)]	Loss: 16.0146	Cost: 20.27s
Train Epoch: 618 [20480/90000 (23%)]	Loss: 12.5843	Cost: 6.02s
Train Epoch: 618 [40960/90000 (45%)]	Loss: 12.3076	Cost: 6.28s
Train Epoch: 618 [61440/90000 (68%)]	Loss: 12.4354	Cost: 5.96s
Train Epoch: 618 [81920/90000 (91%)]	Loss: 12.2982	Cost: 6.58s
Train Epoch: 618 	Average Loss: 12.7121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6629

Learning rate: 0.00019812119344932182
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 619 [0/90000 (0%)]	Loss: 15.8746	Cost: 20.97s
Train Epoch: 619 [20480/90000 (23%)]	Loss: 12.3494	Cost: 6.10s
Train Epoch: 619 [40960/90000 (45%)]	Loss: 12.3450	Cost: 6.16s
Train Epoch: 619 [61440/90000 (68%)]	Loss: 12.4844	Cost: 6.02s
Train Epoch: 619 [81920/90000 (91%)]	Loss: 12.4495	Cost: 7.02s
Train Epoch: 619 	Average Loss: 12.6992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5707

Learning rate: 0.00019811512743861495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 620 [0/90000 (0%)]	Loss: 15.9916	Cost: 19.66s
Train Epoch: 620 [20480/90000 (23%)]	Loss: 12.4148	Cost: 6.09s
Train Epoch: 620 [40960/90000 (45%)]	Loss: 12.4639	Cost: 6.22s
Train Epoch: 620 [61440/90000 (68%)]	Loss: 12.4709	Cost: 5.93s
Train Epoch: 620 [81920/90000 (91%)]	Loss: 12.5283	Cost: 6.08s
Train Epoch: 620 	Average Loss: 12.7287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7045

Learning rate: 0.00019810905174433323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 621 [0/90000 (0%)]	Loss: 16.1788	Cost: 21.59s
Train Epoch: 621 [20480/90000 (23%)]	Loss: 12.4057	Cost: 6.17s
Train Epoch: 621 [40960/90000 (45%)]	Loss: 12.2619	Cost: 6.20s
Train Epoch: 621 [61440/90000 (68%)]	Loss: 12.3283	Cost: 6.01s
Train Epoch: 621 [81920/90000 (91%)]	Loss: 12.6008	Cost: 7.11s
Train Epoch: 621 	Average Loss: 12.6877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5602

Learning rate: 0.0001981029663670763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 622 [0/90000 (0%)]	Loss: 16.1865	Cost: 20.05s
Train Epoch: 622 [20480/90000 (23%)]	Loss: 12.3324	Cost: 6.07s
Train Epoch: 622 [40960/90000 (45%)]	Loss: 12.5551	Cost: 6.06s
Train Epoch: 622 [61440/90000 (68%)]	Loss: 12.4880	Cost: 6.32s
Train Epoch: 622 [81920/90000 (91%)]	Loss: 12.4707	Cost: 7.61s
Train Epoch: 622 	Average Loss: 12.6708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6395

Learning rate: 0.00019809687130744477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 623 [0/90000 (0%)]	Loss: 16.1833	Cost: 20.78s
Train Epoch: 623 [20480/90000 (23%)]	Loss: 12.3140	Cost: 6.40s
Train Epoch: 623 [40960/90000 (45%)]	Loss: 12.2755	Cost: 6.07s
Train Epoch: 623 [61440/90000 (68%)]	Loss: 12.3578	Cost: 6.10s
Train Epoch: 623 [81920/90000 (91%)]	Loss: 12.3730	Cost: 7.15s
Train Epoch: 623 	Average Loss: 12.6384
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7099

Learning rate: 0.00019809076656604016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 624 [0/90000 (0%)]	Loss: 16.0654	Cost: 20.18s
Train Epoch: 624 [20480/90000 (23%)]	Loss: 12.3703	Cost: 6.21s
Train Epoch: 624 [40960/90000 (45%)]	Loss: 12.5714	Cost: 6.25s
Train Epoch: 624 [61440/90000 (68%)]	Loss: 12.3500	Cost: 6.08s
Train Epoch: 624 [81920/90000 (91%)]	Loss: 12.3293	Cost: 6.31s
Train Epoch: 624 	Average Loss: 12.6479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6063

Learning rate: 0.00019808465214346508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 625 [0/90000 (0%)]	Loss: 16.1228	Cost: 19.86s
Train Epoch: 625 [20480/90000 (23%)]	Loss: 12.1512	Cost: 6.18s
Train Epoch: 625 [40960/90000 (45%)]	Loss: 12.4421	Cost: 6.69s
Train Epoch: 625 [61440/90000 (68%)]	Loss: 12.4067	Cost: 6.29s
Train Epoch: 625 [81920/90000 (91%)]	Loss: 12.4173	Cost: 7.60s
Train Epoch: 625 	Average Loss: 12.6437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6681

Learning rate: 0.00019807852804032286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 626 [0/90000 (0%)]	Loss: 15.9335	Cost: 20.46s
Train Epoch: 626 [20480/90000 (23%)]	Loss: 12.1511	Cost: 6.05s
Train Epoch: 626 [40960/90000 (45%)]	Loss: 12.3266	Cost: 6.18s
Train Epoch: 626 [61440/90000 (68%)]	Loss: 12.1775	Cost: 6.11s
Train Epoch: 626 [81920/90000 (91%)]	Loss: 12.3514	Cost: 6.71s
Train Epoch: 626 	Average Loss: 12.6213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6284

Learning rate: 0.00019807239425721806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 627 [0/90000 (0%)]	Loss: 16.3237	Cost: 19.98s
Train Epoch: 627 [20480/90000 (23%)]	Loss: 12.3244	Cost: 6.06s
Train Epoch: 627 [40960/90000 (45%)]	Loss: 12.2046	Cost: 6.73s
Train Epoch: 627 [61440/90000 (68%)]	Loss: 12.3772	Cost: 6.13s
Train Epoch: 627 [81920/90000 (91%)]	Loss: 12.2330	Cost: 7.12s
Train Epoch: 627 	Average Loss: 12.6403
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6712

Learning rate: 0.00019806625079475595
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 628 [0/90000 (0%)]	Loss: 16.1026	Cost: 20.13s
Train Epoch: 628 [20480/90000 (23%)]	Loss: 12.2099	Cost: 6.36s
Train Epoch: 628 [40960/90000 (45%)]	Loss: 12.1373	Cost: 6.09s
Train Epoch: 628 [61440/90000 (68%)]	Loss: 12.3219	Cost: 5.99s
Train Epoch: 628 [81920/90000 (91%)]	Loss: 12.2208	Cost: 5.94s
Train Epoch: 628 	Average Loss: 12.6094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6514

Learning rate: 0.00019806009765354292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 629 [0/90000 (0%)]	Loss: 16.1518	Cost: 19.17s
Train Epoch: 629 [20480/90000 (23%)]	Loss: 12.3409	Cost: 6.10s
Train Epoch: 629 [40960/90000 (45%)]	Loss: 12.4301	Cost: 6.69s
Train Epoch: 629 [61440/90000 (68%)]	Loss: 12.2890	Cost: 6.06s
Train Epoch: 629 [81920/90000 (91%)]	Loss: 12.4145	Cost: 7.15s
Train Epoch: 629 	Average Loss: 12.5838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6526

Learning rate: 0.00019805393483418628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 630 [0/90000 (0%)]	Loss: 16.0839	Cost: 19.15s
Train Epoch: 630 [20480/90000 (23%)]	Loss: 12.2311	Cost: 6.26s
Train Epoch: 630 [40960/90000 (45%)]	Loss: 12.1623	Cost: 5.98s
Train Epoch: 630 [61440/90000 (68%)]	Loss: 12.2736	Cost: 6.29s
Train Epoch: 630 [81920/90000 (91%)]	Loss: 12.3102	Cost: 6.00s
Train Epoch: 630 	Average Loss: 12.6260
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6335

Learning rate: 0.00019804776233729425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 631 [0/90000 (0%)]	Loss: 16.2061	Cost: 20.16s
Train Epoch: 631 [20480/90000 (23%)]	Loss: 12.2267	Cost: 6.07s
Train Epoch: 631 [40960/90000 (45%)]	Loss: 12.1230	Cost: 6.42s
Train Epoch: 631 [61440/90000 (68%)]	Loss: 12.0973	Cost: 6.05s
Train Epoch: 631 [81920/90000 (91%)]	Loss: 12.3016	Cost: 7.36s
Train Epoch: 631 	Average Loss: 12.5843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7131

Learning rate: 0.00019804158016347603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 632 [0/90000 (0%)]	Loss: 16.2462	Cost: 20.05s
Train Epoch: 632 [20480/90000 (23%)]	Loss: 12.0823	Cost: 6.19s
Train Epoch: 632 [40960/90000 (45%)]	Loss: 12.0953	Cost: 6.21s
Train Epoch: 632 [61440/90000 (68%)]	Loss: 12.3530	Cost: 6.03s
Train Epoch: 632 [81920/90000 (91%)]	Loss: 12.3107	Cost: 6.20s
Train Epoch: 632 	Average Loss: 12.5485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7669

Learning rate: 0.0001980353883133418
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 633 [0/90000 (0%)]	Loss: 16.4604	Cost: 18.99s
Train Epoch: 633 [20480/90000 (23%)]	Loss: 12.2203	Cost: 6.15s
Train Epoch: 633 [40960/90000 (45%)]	Loss: 12.1249	Cost: 6.51s
Train Epoch: 633 [61440/90000 (68%)]	Loss: 12.1714	Cost: 6.14s
Train Epoch: 633 [81920/90000 (91%)]	Loss: 12.2177	Cost: 6.81s
Train Epoch: 633 	Average Loss: 12.5447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6887

Learning rate: 0.0001980291867875026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 634 [0/90000 (0%)]	Loss: 16.1389	Cost: 20.35s
Train Epoch: 634 [20480/90000 (23%)]	Loss: 12.1084	Cost: 6.19s
Train Epoch: 634 [40960/90000 (45%)]	Loss: 12.2427	Cost: 6.26s
Train Epoch: 634 [61440/90000 (68%)]	Loss: 12.2272	Cost: 6.06s
Train Epoch: 634 [81920/90000 (91%)]	Loss: 12.3932	Cost: 6.31s
Train Epoch: 634 	Average Loss: 12.5279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6685

Learning rate: 0.00019802297558657058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 635 [0/90000 (0%)]	Loss: 16.4542	Cost: 19.97s
Train Epoch: 635 [20480/90000 (23%)]	Loss: 12.1444	Cost: 6.14s
Train Epoch: 635 [40960/90000 (45%)]	Loss: 12.2780	Cost: 6.09s
Train Epoch: 635 [61440/90000 (68%)]	Loss: 12.2938	Cost: 6.06s
Train Epoch: 635 [81920/90000 (91%)]	Loss: 12.0507	Cost: 6.49s
Train Epoch: 635 	Average Loss: 12.5298
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7228

Learning rate: 0.00019801675471115872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 636 [0/90000 (0%)]	Loss: 16.3672	Cost: 19.87s
Train Epoch: 636 [20480/90000 (23%)]	Loss: 12.2295	Cost: 6.10s
Train Epoch: 636 [40960/90000 (45%)]	Loss: 12.3185	Cost: 6.19s
Train Epoch: 636 [61440/90000 (68%)]	Loss: 12.1221	Cost: 6.04s
Train Epoch: 636 [81920/90000 (91%)]	Loss: 12.3480	Cost: 6.58s
Train Epoch: 636 	Average Loss: 12.4730
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7821

Learning rate: 0.000198010524161881
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 637 [0/90000 (0%)]	Loss: 16.2609	Cost: 19.54s
Train Epoch: 637 [20480/90000 (23%)]	Loss: 12.1257	Cost: 6.11s
Train Epoch: 637 [40960/90000 (45%)]	Loss: 12.1945	Cost: 6.15s
Train Epoch: 637 [61440/90000 (68%)]	Loss: 12.3606	Cost: 6.12s
Train Epoch: 637 [81920/90000 (91%)]	Loss: 12.3658	Cost: 7.09s
Train Epoch: 637 	Average Loss: 12.5077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7482

Learning rate: 0.00019800428393935233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 638 [0/90000 (0%)]	Loss: 16.2741	Cost: 20.60s
Train Epoch: 638 [20480/90000 (23%)]	Loss: 12.1991	Cost: 6.11s
Train Epoch: 638 [40960/90000 (45%)]	Loss: 12.0310	Cost: 6.36s
Train Epoch: 638 [61440/90000 (68%)]	Loss: 12.1276	Cost: 6.17s
Train Epoch: 638 [81920/90000 (91%)]	Loss: 12.3466	Cost: 7.33s
Train Epoch: 638 	Average Loss: 12.4868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8088

Learning rate: 0.00019799803404418868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 639 [0/90000 (0%)]	Loss: 16.3705	Cost: 20.34s
Train Epoch: 639 [20480/90000 (23%)]	Loss: 12.1744	Cost: 6.20s
Train Epoch: 639 [40960/90000 (45%)]	Loss: 12.1527	Cost: 6.04s
Train Epoch: 639 [61440/90000 (68%)]	Loss: 12.1869	Cost: 6.33s
Train Epoch: 639 [81920/90000 (91%)]	Loss: 12.2476	Cost: 6.21s
Train Epoch: 639 	Average Loss: 12.4318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8588

Learning rate: 0.00019799177447700676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 640 [0/90000 (0%)]	Loss: 16.2377	Cost: 19.74s
Train Epoch: 640 [20480/90000 (23%)]	Loss: 12.0083	Cost: 6.16s
Train Epoch: 640 [40960/90000 (45%)]	Loss: 12.2058	Cost: 6.16s
Train Epoch: 640 [61440/90000 (68%)]	Loss: 12.4460	Cost: 6.12s
Train Epoch: 640 [81920/90000 (91%)]	Loss: 12.4933	Cost: 6.64s
Train Epoch: 640 	Average Loss: 12.4732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8285

Learning rate: 0.00019798550523842447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 641 [0/90000 (0%)]	Loss: 16.1811	Cost: 19.56s
Train Epoch: 641 [20480/90000 (23%)]	Loss: 12.2391	Cost: 6.17s
Train Epoch: 641 [40960/90000 (45%)]	Loss: 12.2631	Cost: 6.94s
Train Epoch: 641 [61440/90000 (68%)]	Loss: 12.1329	Cost: 5.99s
Train Epoch: 641 [81920/90000 (91%)]	Loss: 12.2950	Cost: 7.43s
Train Epoch: 641 	Average Loss: 12.4732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7025

Learning rate: 0.0001979792263290605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 642 [0/90000 (0%)]	Loss: 16.5544	Cost: 20.54s
Train Epoch: 642 [20480/90000 (23%)]	Loss: 12.1611	Cost: 6.27s
Train Epoch: 642 [40960/90000 (45%)]	Loss: 12.0656	Cost: 6.34s
Train Epoch: 642 [61440/90000 (68%)]	Loss: 11.8957	Cost: 6.02s
Train Epoch: 642 [81920/90000 (91%)]	Loss: 11.9693	Cost: 7.21s
Train Epoch: 642 	Average Loss: 12.4485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7423

Learning rate: 0.00019797293774953458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 643 [0/90000 (0%)]	Loss: 16.1800	Cost: 20.01s
Train Epoch: 643 [20480/90000 (23%)]	Loss: 12.1622	Cost: 6.06s
Train Epoch: 643 [40960/90000 (45%)]	Loss: 12.2363	Cost: 6.19s
Train Epoch: 643 [61440/90000 (68%)]	Loss: 12.2335	Cost: 6.07s
Train Epoch: 643 [81920/90000 (91%)]	Loss: 12.1356	Cost: 7.10s
Train Epoch: 643 	Average Loss: 12.4119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8125

Learning rate: 0.00019796663950046741
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 644 [0/90000 (0%)]	Loss: 16.0450	Cost: 20.15s
Train Epoch: 644 [20480/90000 (23%)]	Loss: 12.2456	Cost: 6.10s
Train Epoch: 644 [40960/90000 (45%)]	Loss: 12.2247	Cost: 6.05s
Train Epoch: 644 [61440/90000 (68%)]	Loss: 12.2039	Cost: 5.99s
Train Epoch: 644 [81920/90000 (91%)]	Loss: 12.3093	Cost: 6.46s
Train Epoch: 644 	Average Loss: 12.4544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7605

Learning rate: 0.0001979603315824805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 645 [0/90000 (0%)]	Loss: 16.3109	Cost: 19.95s
Train Epoch: 645 [20480/90000 (23%)]	Loss: 12.1237	Cost: 5.98s
Train Epoch: 645 [40960/90000 (45%)]	Loss: 12.2665	Cost: 5.87s
Train Epoch: 645 [61440/90000 (68%)]	Loss: 11.9815	Cost: 5.91s
Train Epoch: 645 [81920/90000 (91%)]	Loss: 12.2428	Cost: 6.01s
Train Epoch: 645 	Average Loss: 12.4266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8486

Learning rate: 0.0001979540139961965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 646 [0/90000 (0%)]	Loss: 16.4477	Cost: 20.15s
Train Epoch: 646 [20480/90000 (23%)]	Loss: 12.1045	Cost: 6.05s
Train Epoch: 646 [40960/90000 (45%)]	Loss: 12.0850	Cost: 6.64s
Train Epoch: 646 [61440/90000 (68%)]	Loss: 12.0035	Cost: 5.91s
Train Epoch: 646 [81920/90000 (91%)]	Loss: 12.2468	Cost: 6.53s
Train Epoch: 646 	Average Loss: 12.3961
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7966

Learning rate: 0.0001979476867422389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 647 [0/90000 (0%)]	Loss: 16.2902	Cost: 20.92s
Train Epoch: 647 [20480/90000 (23%)]	Loss: 11.9714	Cost: 6.11s
Train Epoch: 647 [40960/90000 (45%)]	Loss: 12.2616	Cost: 6.27s
Train Epoch: 647 [61440/90000 (68%)]	Loss: 12.0873	Cost: 5.94s
Train Epoch: 647 [81920/90000 (91%)]	Loss: 12.1581	Cost: 6.17s
Train Epoch: 647 	Average Loss: 12.4054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7249

Learning rate: 0.00019794134982123216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 648 [0/90000 (0%)]	Loss: 16.0838	Cost: 20.79s
Train Epoch: 648 [20480/90000 (23%)]	Loss: 12.0598	Cost: 6.09s
Train Epoch: 648 [40960/90000 (45%)]	Loss: 12.1861	Cost: 6.46s
Train Epoch: 648 [61440/90000 (68%)]	Loss: 12.1894	Cost: 5.92s
Train Epoch: 648 [81920/90000 (91%)]	Loss: 12.1763	Cost: 6.58s
Train Epoch: 648 	Average Loss: 12.3690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8612

Learning rate: 0.00019793500323380173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 649 [0/90000 (0%)]	Loss: 16.1996	Cost: 21.14s
Train Epoch: 649 [20480/90000 (23%)]	Loss: 12.2243	Cost: 6.08s
Train Epoch: 649 [40960/90000 (45%)]	Loss: 12.2529	Cost: 6.67s
Train Epoch: 649 [61440/90000 (68%)]	Loss: 12.2045	Cost: 6.02s
Train Epoch: 649 [81920/90000 (91%)]	Loss: 12.3634	Cost: 7.13s
Train Epoch: 649 	Average Loss: 12.4844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8313

Learning rate: 0.000197928646980574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 650 [0/90000 (0%)]	Loss: 16.2485	Cost: 20.54s
Train Epoch: 650 [20480/90000 (23%)]	Loss: 12.0330	Cost: 6.05s
Train Epoch: 650 [40960/90000 (45%)]	Loss: 11.9796	Cost: 6.28s
Train Epoch: 650 [61440/90000 (68%)]	Loss: 12.1519	Cost: 6.16s
Train Epoch: 650 [81920/90000 (91%)]	Loss: 12.0561	Cost: 6.87s
Train Epoch: 650 	Average Loss: 12.4192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8091

Learning rate: 0.00019792228106217628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 651 [0/90000 (0%)]	Loss: 15.9600	Cost: 20.70s
Train Epoch: 651 [20480/90000 (23%)]	Loss: 11.8755	Cost: 6.06s
Train Epoch: 651 [40960/90000 (45%)]	Loss: 12.0299	Cost: 6.55s
Train Epoch: 651 [61440/90000 (68%)]	Loss: 12.0339	Cost: 6.24s
Train Epoch: 651 [81920/90000 (91%)]	Loss: 12.2685	Cost: 7.77s
Train Epoch: 651 	Average Loss: 12.3845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7890

Learning rate: 0.00019791590547923692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 652 [0/90000 (0%)]	Loss: 16.2214	Cost: 20.70s
Train Epoch: 652 [20480/90000 (23%)]	Loss: 12.0151	Cost: 6.08s
Train Epoch: 652 [40960/90000 (45%)]	Loss: 11.9135	Cost: 6.43s
Train Epoch: 652 [61440/90000 (68%)]	Loss: 12.1182	Cost: 6.05s
Train Epoch: 652 [81920/90000 (91%)]	Loss: 12.1468	Cost: 7.13s
Train Epoch: 652 	Average Loss: 12.3437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9045

Learning rate: 0.00019790952023238508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 653 [0/90000 (0%)]	Loss: 16.2142	Cost: 21.63s
Train Epoch: 653 [20480/90000 (23%)]	Loss: 11.9217	Cost: 5.99s
Train Epoch: 653 [40960/90000 (45%)]	Loss: 11.9516	Cost: 6.47s
Train Epoch: 653 [61440/90000 (68%)]	Loss: 12.0128	Cost: 6.06s
Train Epoch: 653 [81920/90000 (91%)]	Loss: 12.0387	Cost: 7.35s
Train Epoch: 653 	Average Loss: 12.3007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8117

Learning rate: 0.000197903125322251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 654 [0/90000 (0%)]	Loss: 16.1328	Cost: 20.07s
Train Epoch: 654 [20480/90000 (23%)]	Loss: 11.9308	Cost: 6.11s
Train Epoch: 654 [40960/90000 (45%)]	Loss: 12.0983	Cost: 6.56s
Train Epoch: 654 [61440/90000 (68%)]	Loss: 12.0670	Cost: 6.15s
Train Epoch: 654 [81920/90000 (91%)]	Loss: 11.8766	Cost: 6.59s
Train Epoch: 654 	Average Loss: 12.3224
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8525

Learning rate: 0.00019789672074946586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 655 [0/90000 (0%)]	Loss: 16.2184	Cost: 20.47s
Train Epoch: 655 [20480/90000 (23%)]	Loss: 11.9169	Cost: 6.09s
Train Epoch: 655 [40960/90000 (45%)]	Loss: 12.0179	Cost: 6.71s
Train Epoch: 655 [61440/90000 (68%)]	Loss: 12.0431	Cost: 6.08s
Train Epoch: 655 [81920/90000 (91%)]	Loss: 12.1426	Cost: 7.58s
Train Epoch: 655 	Average Loss: 12.3123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8696

Learning rate: 0.00019789030651466173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 656 [0/90000 (0%)]	Loss: 16.4564	Cost: 20.06s
Train Epoch: 656 [20480/90000 (23%)]	Loss: 11.8464	Cost: 6.09s
Train Epoch: 656 [40960/90000 (45%)]	Loss: 11.8954	Cost: 6.23s
Train Epoch: 656 [61440/90000 (68%)]	Loss: 11.9359	Cost: 6.04s
Train Epoch: 656 [81920/90000 (91%)]	Loss: 11.9180	Cost: 5.93s
Train Epoch: 656 	Average Loss: 12.3314
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9831

Learning rate: 0.0001978838826184717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 657 [0/90000 (0%)]	Loss: 16.4229	Cost: 20.09s
Train Epoch: 657 [20480/90000 (23%)]	Loss: 11.8414	Cost: 6.10s
Train Epoch: 657 [40960/90000 (45%)]	Loss: 11.8829	Cost: 6.53s
Train Epoch: 657 [61440/90000 (68%)]	Loss: 12.0513	Cost: 6.02s
Train Epoch: 657 [81920/90000 (91%)]	Loss: 11.9996	Cost: 7.33s
Train Epoch: 657 	Average Loss: 12.2981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9501

Learning rate: 0.00019787744906152977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 658 [0/90000 (0%)]	Loss: 16.3548	Cost: 19.72s
Train Epoch: 658 [20480/90000 (23%)]	Loss: 12.1398	Cost: 6.04s
Train Epoch: 658 [40960/90000 (45%)]	Loss: 11.7828	Cost: 6.07s
Train Epoch: 658 [61440/90000 (68%)]	Loss: 11.9802	Cost: 6.03s
Train Epoch: 658 [81920/90000 (91%)]	Loss: 12.0114	Cost: 6.09s
Train Epoch: 658 	Average Loss: 12.3196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9088

Learning rate: 0.00019787100584447087
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 659 [0/90000 (0%)]	Loss: 16.4457	Cost: 20.54s
Train Epoch: 659 [20480/90000 (23%)]	Loss: 12.0303	Cost: 6.09s
Train Epoch: 659 [40960/90000 (45%)]	Loss: 11.9266	Cost: 6.08s
Train Epoch: 659 [61440/90000 (68%)]	Loss: 11.9090	Cost: 6.06s
Train Epoch: 659 [81920/90000 (91%)]	Loss: 11.8561	Cost: 6.77s
Train Epoch: 659 	Average Loss: 12.2822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9219

Learning rate: 0.00019786455296793095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 660 [0/90000 (0%)]	Loss: 16.3351	Cost: 19.86s
Train Epoch: 660 [20480/90000 (23%)]	Loss: 12.0620	Cost: 6.14s
Train Epoch: 660 [40960/90000 (45%)]	Loss: 11.8909	Cost: 6.21s
Train Epoch: 660 [61440/90000 (68%)]	Loss: 11.9008	Cost: 6.25s
Train Epoch: 660 [81920/90000 (91%)]	Loss: 12.1288	Cost: 6.72s
Train Epoch: 660 	Average Loss: 12.2555
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8080

Learning rate: 0.0001978580904325469
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 661 [0/90000 (0%)]	Loss: 16.3381	Cost: 20.45s
Train Epoch: 661 [20480/90000 (23%)]	Loss: 12.0609	Cost: 6.07s
Train Epoch: 661 [40960/90000 (45%)]	Loss: 11.8516	Cost: 6.44s
Train Epoch: 661 [61440/90000 (68%)]	Loss: 12.2515	Cost: 6.20s
Train Epoch: 661 [81920/90000 (91%)]	Loss: 11.9571	Cost: 6.87s
Train Epoch: 661 	Average Loss: 12.2758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9307

Learning rate: 0.00019785161823895653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 662 [0/90000 (0%)]	Loss: 16.1673	Cost: 21.38s
Train Epoch: 662 [20480/90000 (23%)]	Loss: 12.0405	Cost: 6.13s
Train Epoch: 662 [40960/90000 (45%)]	Loss: 11.7227	Cost: 6.08s
Train Epoch: 662 [61440/90000 (68%)]	Loss: 12.1092	Cost: 6.06s
Train Epoch: 662 [81920/90000 (91%)]	Loss: 12.0306	Cost: 7.22s
Train Epoch: 662 	Average Loss: 12.2645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9795

Learning rate: 0.00019784513638779864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 663 [0/90000 (0%)]	Loss: 16.3188	Cost: 19.66s
Train Epoch: 663 [20480/90000 (23%)]	Loss: 12.1156	Cost: 6.05s
Train Epoch: 663 [40960/90000 (45%)]	Loss: 11.8801	Cost: 6.21s
Train Epoch: 663 [61440/90000 (68%)]	Loss: 11.9425	Cost: 6.03s
Train Epoch: 663 [81920/90000 (91%)]	Loss: 12.0029	Cost: 6.22s
Train Epoch: 663 	Average Loss: 12.2483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9377

Learning rate: 0.0001978386448797129
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 664 [0/90000 (0%)]	Loss: 16.2040	Cost: 19.84s
Train Epoch: 664 [20480/90000 (23%)]	Loss: 11.9802	Cost: 6.09s
Train Epoch: 664 [40960/90000 (45%)]	Loss: 12.2556	Cost: 6.74s
Train Epoch: 664 [61440/90000 (68%)]	Loss: 12.0837	Cost: 6.11s
Train Epoch: 664 [81920/90000 (91%)]	Loss: 11.8256	Cost: 6.98s
Train Epoch: 664 	Average Loss: 12.2880
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8797

Learning rate: 0.00019783214371534008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 665 [0/90000 (0%)]	Loss: 16.2423	Cost: 20.75s
Train Epoch: 665 [20480/90000 (23%)]	Loss: 11.8370	Cost: 6.23s
Train Epoch: 665 [40960/90000 (45%)]	Loss: 11.7926	Cost: 6.24s
Train Epoch: 665 [61440/90000 (68%)]	Loss: 11.8130	Cost: 6.03s
Train Epoch: 665 [81920/90000 (91%)]	Loss: 11.7663	Cost: 6.65s
Train Epoch: 665 	Average Loss: 12.2064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8231

Learning rate: 0.00019782563289532173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 666 [0/90000 (0%)]	Loss: 16.4445	Cost: 19.99s
Train Epoch: 666 [20480/90000 (23%)]	Loss: 11.8944	Cost: 6.22s
Train Epoch: 666 [40960/90000 (45%)]	Loss: 11.7454	Cost: 6.16s
Train Epoch: 666 [61440/90000 (68%)]	Loss: 11.8436	Cost: 6.05s
Train Epoch: 666 [81920/90000 (91%)]	Loss: 11.9641	Cost: 7.62s
Train Epoch: 666 	Average Loss: 12.2131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0869

Learning rate: 0.0001978191124203005
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 667 [0/90000 (0%)]	Loss: 16.5094	Cost: 20.17s
Train Epoch: 667 [20480/90000 (23%)]	Loss: 11.7938	Cost: 6.10s
Train Epoch: 667 [40960/90000 (45%)]	Loss: 11.8232	Cost: 6.05s
Train Epoch: 667 [61440/90000 (68%)]	Loss: 11.8145	Cost: 6.08s
Train Epoch: 667 [81920/90000 (91%)]	Loss: 11.8296	Cost: 6.60s
Train Epoch: 667 	Average Loss: 12.2026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9412

Learning rate: 0.00019781258229091995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 668 [0/90000 (0%)]	Loss: 16.2177	Cost: 20.16s
Train Epoch: 668 [20480/90000 (23%)]	Loss: 11.8430	Cost: 6.08s
Train Epoch: 668 [40960/90000 (45%)]	Loss: 11.7943	Cost: 6.19s
Train Epoch: 668 [61440/90000 (68%)]	Loss: 11.7301	Cost: 5.98s
Train Epoch: 668 [81920/90000 (91%)]	Loss: 11.7342	Cost: 7.00s
Train Epoch: 668 	Average Loss: 12.1306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0181

Learning rate: 0.00019780604250782451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 669 [0/90000 (0%)]	Loss: 16.5206	Cost: 20.28s
Train Epoch: 669 [20480/90000 (23%)]	Loss: 11.9534	Cost: 6.05s
Train Epoch: 669 [40960/90000 (45%)]	Loss: 11.9126	Cost: 6.28s
Train Epoch: 669 [61440/90000 (68%)]	Loss: 12.0613	Cost: 6.01s
Train Epoch: 669 [81920/90000 (91%)]	Loss: 11.7100	Cost: 7.07s
Train Epoch: 669 	Average Loss: 12.2121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8599

Learning rate: 0.00019779949307165972
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 670 [0/90000 (0%)]	Loss: 16.3165	Cost: 20.58s
Train Epoch: 670 [20480/90000 (23%)]	Loss: 11.7117	Cost: 6.15s
Train Epoch: 670 [40960/90000 (45%)]	Loss: 11.8299	Cost: 6.63s
Train Epoch: 670 [61440/90000 (68%)]	Loss: 11.8089	Cost: 6.02s
Train Epoch: 670 [81920/90000 (91%)]	Loss: 11.8904	Cost: 6.72s
Train Epoch: 670 	Average Loss: 12.1777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9432

Learning rate: 0.00019779293398307192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 671 [0/90000 (0%)]	Loss: 16.3293	Cost: 19.69s
Train Epoch: 671 [20480/90000 (23%)]	Loss: 11.5796	Cost: 6.03s
Train Epoch: 671 [40960/90000 (45%)]	Loss: 11.7731	Cost: 6.71s
Train Epoch: 671 [61440/90000 (68%)]	Loss: 11.7721	Cost: 6.08s
Train Epoch: 671 [81920/90000 (91%)]	Loss: 11.7316	Cost: 6.74s
Train Epoch: 671 	Average Loss: 12.1517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0094

Learning rate: 0.00019778636524270848
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 672 [0/90000 (0%)]	Loss: 16.2073	Cost: 19.99s
Train Epoch: 672 [20480/90000 (23%)]	Loss: 11.6687	Cost: 6.10s
Train Epoch: 672 [40960/90000 (45%)]	Loss: 11.7510	Cost: 6.12s
Train Epoch: 672 [61440/90000 (68%)]	Loss: 11.7065	Cost: 6.24s
Train Epoch: 672 [81920/90000 (91%)]	Loss: 11.9599	Cost: 7.01s
Train Epoch: 672 	Average Loss: 12.1834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0484

Learning rate: 0.0001977797868512177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 673 [0/90000 (0%)]	Loss: 16.5904	Cost: 20.95s
Train Epoch: 673 [20480/90000 (23%)]	Loss: 11.6296	Cost: 6.12s
Train Epoch: 673 [40960/90000 (45%)]	Loss: 11.8513	Cost: 6.15s
Train Epoch: 673 [61440/90000 (68%)]	Loss: 11.6431	Cost: 6.23s
Train Epoch: 673 [81920/90000 (91%)]	Loss: 11.7294	Cost: 6.01s
Train Epoch: 673 	Average Loss: 12.1340
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9284

Learning rate: 0.00019777319880924887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 674 [0/90000 (0%)]	Loss: 16.4762	Cost: 20.96s
Train Epoch: 674 [20480/90000 (23%)]	Loss: 11.9307	Cost: 6.21s
Train Epoch: 674 [40960/90000 (45%)]	Loss: 11.8485	Cost: 6.32s
Train Epoch: 674 [61440/90000 (68%)]	Loss: 11.6818	Cost: 6.05s
Train Epoch: 674 [81920/90000 (91%)]	Loss: 11.7499	Cost: 6.95s
Train Epoch: 674 	Average Loss: 12.1082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9633

Learning rate: 0.0001977666011174522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 675 [0/90000 (0%)]	Loss: 16.5289	Cost: 19.28s
Train Epoch: 675 [20480/90000 (23%)]	Loss: 11.7341	Cost: 6.03s
Train Epoch: 675 [40960/90000 (45%)]	Loss: 11.6836	Cost: 6.24s
Train Epoch: 675 [61440/90000 (68%)]	Loss: 11.9349	Cost: 6.03s
Train Epoch: 675 [81920/90000 (91%)]	Loss: 11.6459	Cost: 6.76s
Train Epoch: 675 	Average Loss: 12.1143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0676

Learning rate: 0.00019775999377647882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 676 [0/90000 (0%)]	Loss: 16.3767	Cost: 20.64s
Train Epoch: 676 [20480/90000 (23%)]	Loss: 11.7282	Cost: 6.05s
Train Epoch: 676 [40960/90000 (45%)]	Loss: 11.5925	Cost: 6.70s
Train Epoch: 676 [61440/90000 (68%)]	Loss: 11.7817	Cost: 5.78s
Train Epoch: 676 [81920/90000 (91%)]	Loss: 11.8776	Cost: 7.69s
Train Epoch: 676 	Average Loss: 12.1092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0109

Learning rate: 0.00019775337678698088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 677 [0/90000 (0%)]	Loss: 16.3152	Cost: 20.26s
Train Epoch: 677 [20480/90000 (23%)]	Loss: 11.8182	Cost: 6.32s
Train Epoch: 677 [40960/90000 (45%)]	Loss: 11.8688	Cost: 6.45s
Train Epoch: 677 [61440/90000 (68%)]	Loss: 11.8753	Cost: 5.97s
Train Epoch: 677 [81920/90000 (91%)]	Loss: 11.8442	Cost: 6.62s
Train Epoch: 677 	Average Loss: 12.1286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1077

Learning rate: 0.00019774675014961146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 678 [0/90000 (0%)]	Loss: 16.5247	Cost: 18.49s
Train Epoch: 678 [20480/90000 (23%)]	Loss: 11.5641	Cost: 6.29s
Train Epoch: 678 [40960/90000 (45%)]	Loss: 11.7696	Cost: 6.37s
Train Epoch: 678 [61440/90000 (68%)]	Loss: 11.8010	Cost: 6.02s
Train Epoch: 678 [81920/90000 (91%)]	Loss: 11.9451	Cost: 5.92s
Train Epoch: 678 	Average Loss: 12.0808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8922

Learning rate: 0.00019774011386502452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 679 [0/90000 (0%)]	Loss: 16.5766	Cost: 19.53s
Train Epoch: 679 [20480/90000 (23%)]	Loss: 11.7116	Cost: 7.18s
Train Epoch: 679 [40960/90000 (45%)]	Loss: 11.6970	Cost: 6.91s
Train Epoch: 679 [61440/90000 (68%)]	Loss: 11.6484	Cost: 6.04s
Train Epoch: 679 [81920/90000 (91%)]	Loss: 11.9383	Cost: 6.40s
Train Epoch: 679 	Average Loss: 12.0795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9869

Learning rate: 0.0001977334679338751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 680 [0/90000 (0%)]	Loss: 16.6013	Cost: 20.83s
Train Epoch: 680 [20480/90000 (23%)]	Loss: 11.4436	Cost: 6.31s
Train Epoch: 680 [40960/90000 (45%)]	Loss: 11.7896	Cost: 6.47s
Train Epoch: 680 [61440/90000 (68%)]	Loss: 11.7846	Cost: 6.02s
Train Epoch: 680 [81920/90000 (91%)]	Loss: 11.7427	Cost: 6.48s
Train Epoch: 680 	Average Loss: 12.0691
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0069

Learning rate: 0.0001977268123568191
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 681 [0/90000 (0%)]	Loss: 16.3706	Cost: 21.83s
Train Epoch: 681 [20480/90000 (23%)]	Loss: 11.7377	Cost: 7.00s
Train Epoch: 681 [40960/90000 (45%)]	Loss: 11.8848	Cost: 6.65s
Train Epoch: 681 [61440/90000 (68%)]	Loss: 11.9190	Cost: 5.97s
Train Epoch: 681 [81920/90000 (91%)]	Loss: 11.7888	Cost: 6.83s
Train Epoch: 681 	Average Loss: 12.1237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0473

Learning rate: 0.00019772014713451342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 682 [0/90000 (0%)]	Loss: 16.4767	Cost: 22.38s
Train Epoch: 682 [20480/90000 (23%)]	Loss: 11.6103	Cost: 6.25s
Train Epoch: 682 [40960/90000 (45%)]	Loss: 11.6102	Cost: 6.09s
Train Epoch: 682 [61440/90000 (68%)]	Loss: 11.8190	Cost: 5.80s
Train Epoch: 682 [81920/90000 (91%)]	Loss: 11.6583	Cost: 6.17s
Train Epoch: 682 	Average Loss: 12.0347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0209

Learning rate: 0.00019771347226761588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 683 [0/90000 (0%)]	Loss: 16.5070	Cost: 24.01s
Train Epoch: 683 [20480/90000 (23%)]	Loss: 11.6573	Cost: 6.75s
Train Epoch: 683 [40960/90000 (45%)]	Loss: 11.8820	Cost: 6.72s
Train Epoch: 683 [61440/90000 (68%)]	Loss: 11.5570	Cost: 6.17s
Train Epoch: 683 [81920/90000 (91%)]	Loss: 12.0411	Cost: 6.88s
Train Epoch: 683 	Average Loss: 12.0441
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0082

Learning rate: 0.00019770678775678525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 684 [0/90000 (0%)]	Loss: 16.3928	Cost: 24.39s
Train Epoch: 684 [20480/90000 (23%)]	Loss: 11.8306	Cost: 7.31s
Train Epoch: 684 [40960/90000 (45%)]	Loss: 11.4737	Cost: 6.25s
Train Epoch: 684 [61440/90000 (68%)]	Loss: 11.6875	Cost: 6.02s
Train Epoch: 684 [81920/90000 (91%)]	Loss: 11.8271	Cost: 5.83s
Train Epoch: 684 	Average Loss: 12.0245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0545

Learning rate: 0.00019770009360268128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 685 [0/90000 (0%)]	Loss: 16.3214	Cost: 26.40s
Train Epoch: 685 [20480/90000 (23%)]	Loss: 11.7169	Cost: 6.09s
Train Epoch: 685 [40960/90000 (45%)]	Loss: 11.7184	Cost: 6.27s
Train Epoch: 685 [61440/90000 (68%)]	Loss: 11.4709	Cost: 6.08s
Train Epoch: 685 [81920/90000 (91%)]	Loss: 11.9295	Cost: 6.35s
Train Epoch: 685 	Average Loss: 11.9675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1069

Learning rate: 0.00019769338980596464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 686 [0/90000 (0%)]	Loss: 16.7279	Cost: 25.79s
Train Epoch: 686 [20480/90000 (23%)]	Loss: 11.5402	Cost: 5.83s
Train Epoch: 686 [40960/90000 (45%)]	Loss: 11.6702	Cost: 6.86s
Train Epoch: 686 [61440/90000 (68%)]	Loss: 11.7869	Cost: 6.01s
Train Epoch: 686 [81920/90000 (91%)]	Loss: 11.6302	Cost: 6.64s
Train Epoch: 686 	Average Loss: 12.0322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0555

Learning rate: 0.00019768667636729697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 687 [0/90000 (0%)]	Loss: 16.4515	Cost: 22.99s
Train Epoch: 687 [20480/90000 (23%)]	Loss: 11.6163	Cost: 6.24s
Train Epoch: 687 [40960/90000 (45%)]	Loss: 11.7567	Cost: 6.44s
Train Epoch: 687 [61440/90000 (68%)]	Loss: 11.7421	Cost: 6.06s
Train Epoch: 687 [81920/90000 (91%)]	Loss: 11.7428	Cost: 7.33s
Train Epoch: 687 	Average Loss: 11.9911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0754

Learning rate: 0.0001976799532873409
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 688 [0/90000 (0%)]	Loss: 16.3817	Cost: 20.68s
Train Epoch: 688 [20480/90000 (23%)]	Loss: 11.6779	Cost: 6.30s
Train Epoch: 688 [40960/90000 (45%)]	Loss: 11.6279	Cost: 6.27s
Train Epoch: 688 [61440/90000 (68%)]	Loss: 11.6105	Cost: 6.07s
Train Epoch: 688 [81920/90000 (91%)]	Loss: 11.7052	Cost: 5.86s
Train Epoch: 688 	Average Loss: 11.9982
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0919

Learning rate: 0.00019767322056675991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 689 [0/90000 (0%)]	Loss: 16.5598	Cost: 22.52s
Train Epoch: 689 [20480/90000 (23%)]	Loss: 11.3904	Cost: 6.40s
Train Epoch: 689 [40960/90000 (45%)]	Loss: 11.5575	Cost: 6.51s
Train Epoch: 689 [61440/90000 (68%)]	Loss: 11.5011	Cost: 6.21s
Train Epoch: 689 [81920/90000 (91%)]	Loss: 11.5377	Cost: 6.50s
Train Epoch: 689 	Average Loss: 11.9662
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0713

Learning rate: 0.00019766647820621853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 690 [0/90000 (0%)]	Loss: 16.4861	Cost: 20.11s
Train Epoch: 690 [20480/90000 (23%)]	Loss: 11.5156	Cost: 6.20s
Train Epoch: 690 [40960/90000 (45%)]	Loss: 11.6196	Cost: 6.91s
Train Epoch: 690 [61440/90000 (68%)]	Loss: 11.5159	Cost: 5.92s
Train Epoch: 690 [81920/90000 (91%)]	Loss: 11.4797	Cost: 6.33s
Train Epoch: 690 	Average Loss: 11.8998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1255

Learning rate: 0.0001976597262063822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 691 [0/90000 (0%)]	Loss: 16.5358	Cost: 20.59s
Train Epoch: 691 [20480/90000 (23%)]	Loss: 11.5282	Cost: 6.10s
Train Epoch: 691 [40960/90000 (45%)]	Loss: 11.6174	Cost: 6.40s
Train Epoch: 691 [61440/90000 (68%)]	Loss: 11.5563	Cost: 6.03s
Train Epoch: 691 [81920/90000 (91%)]	Loss: 11.3974	Cost: 5.88s
Train Epoch: 691 	Average Loss: 11.9002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2238

Learning rate: 0.00019765296456791733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 692 [0/90000 (0%)]	Loss: 16.6923	Cost: 19.98s
Train Epoch: 692 [20480/90000 (23%)]	Loss: 11.5632	Cost: 6.34s
Train Epoch: 692 [40960/90000 (45%)]	Loss: 11.5015	Cost: 7.23s
Train Epoch: 692 [61440/90000 (68%)]	Loss: 11.4904	Cost: 6.01s
Train Epoch: 692 [81920/90000 (91%)]	Loss: 11.6192	Cost: 6.47s
Train Epoch: 692 	Average Loss: 11.9257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1524

Learning rate: 0.00019764619329149126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 693 [0/90000 (0%)]	Loss: 16.6415	Cost: 20.11s
Train Epoch: 693 [20480/90000 (23%)]	Loss: 11.6455	Cost: 6.29s
Train Epoch: 693 [40960/90000 (45%)]	Loss: 11.3366	Cost: 6.98s
Train Epoch: 693 [61440/90000 (68%)]	Loss: 11.5942	Cost: 5.73s
Train Epoch: 693 [81920/90000 (91%)]	Loss: 11.5675	Cost: 6.58s
Train Epoch: 693 	Average Loss: 11.9778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1527

Learning rate: 0.00019763941237777225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 694 [0/90000 (0%)]	Loss: 16.7386	Cost: 19.64s
Train Epoch: 694 [20480/90000 (23%)]	Loss: 11.5185	Cost: 6.14s
Train Epoch: 694 [40960/90000 (45%)]	Loss: 11.6333	Cost: 6.42s
Train Epoch: 694 [61440/90000 (68%)]	Loss: 11.4753	Cost: 6.14s
Train Epoch: 694 [81920/90000 (91%)]	Loss: 11.7047	Cost: 5.96s
Train Epoch: 694 	Average Loss: 11.9470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1360

Learning rate: 0.0001976326218274296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 695 [0/90000 (0%)]	Loss: 16.4266	Cost: 20.54s
Train Epoch: 695 [20480/90000 (23%)]	Loss: 11.5183	Cost: 6.04s
Train Epoch: 695 [40960/90000 (45%)]	Loss: 11.6779	Cost: 6.87s
Train Epoch: 695 [61440/90000 (68%)]	Loss: 11.4900	Cost: 6.01s
Train Epoch: 695 [81920/90000 (91%)]	Loss: 11.7287	Cost: 6.34s
Train Epoch: 695 	Average Loss: 11.8781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1678

Learning rate: 0.00019762582164113346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 696 [0/90000 (0%)]	Loss: 16.5403	Cost: 20.67s
Train Epoch: 696 [20480/90000 (23%)]	Loss: 11.5114	Cost: 6.26s
Train Epoch: 696 [40960/90000 (45%)]	Loss: 11.7105	Cost: 6.44s
Train Epoch: 696 [61440/90000 (68%)]	Loss: 11.7056	Cost: 5.93s
Train Epoch: 696 [81920/90000 (91%)]	Loss: 11.8261	Cost: 6.26s
Train Epoch: 696 	Average Loss: 11.9419
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2358

Learning rate: 0.00019761901181955505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 697 [0/90000 (0%)]	Loss: 16.7866	Cost: 19.99s
Train Epoch: 697 [20480/90000 (23%)]	Loss: 11.5121	Cost: 6.19s
Train Epoch: 697 [40960/90000 (45%)]	Loss: 11.6674	Cost: 6.21s
Train Epoch: 697 [61440/90000 (68%)]	Loss: 11.6564	Cost: 5.91s
Train Epoch: 697 [81920/90000 (91%)]	Loss: 11.4903	Cost: 5.92s
Train Epoch: 697 	Average Loss: 11.9351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1491

Learning rate: 0.0001976121923633664
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 698 [0/90000 (0%)]	Loss: 16.6807	Cost: 21.38s
Train Epoch: 698 [20480/90000 (23%)]	Loss: 11.5411	Cost: 6.11s
Train Epoch: 698 [40960/90000 (45%)]	Loss: 11.5207	Cost: 6.36s
Train Epoch: 698 [61440/90000 (68%)]	Loss: 11.4972	Cost: 5.94s
Train Epoch: 698 [81920/90000 (91%)]	Loss: 11.6839	Cost: 6.01s
Train Epoch: 698 	Average Loss: 11.8964
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2346

Learning rate: 0.0001976053632732406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 699 [0/90000 (0%)]	Loss: 16.7057	Cost: 21.10s
Train Epoch: 699 [20480/90000 (23%)]	Loss: 11.5594	Cost: 6.15s
Train Epoch: 699 [40960/90000 (45%)]	Loss: 11.5410	Cost: 6.14s
Train Epoch: 699 [61440/90000 (68%)]	Loss: 11.5129	Cost: 5.89s
Train Epoch: 699 [81920/90000 (91%)]	Loss: 11.3233	Cost: 6.12s
Train Epoch: 699 	Average Loss: 11.8389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1869

Learning rate: 0.00019759852454985166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 700 [0/90000 (0%)]	Loss: 16.4535	Cost: 20.62s
Train Epoch: 700 [20480/90000 (23%)]	Loss: 11.5591	Cost: 6.14s
Train Epoch: 700 [40960/90000 (45%)]	Loss: 11.2658	Cost: 6.37s
Train Epoch: 700 [61440/90000 (68%)]	Loss: 11.2135	Cost: 5.96s
Train Epoch: 700 [81920/90000 (91%)]	Loss: 11.5465	Cost: 6.47s
Train Epoch: 700 	Average Loss: 11.8645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2601

Learning rate: 0.0001975916761938745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 701 [0/90000 (0%)]	Loss: 16.7501	Cost: 20.40s
Train Epoch: 701 [20480/90000 (23%)]	Loss: 11.5166	Cost: 6.14s
Train Epoch: 701 [40960/90000 (45%)]	Loss: 11.4459	Cost: 6.55s
Train Epoch: 701 [61440/90000 (68%)]	Loss: 11.6017	Cost: 5.96s
Train Epoch: 701 [81920/90000 (91%)]	Loss: 11.7004	Cost: 6.64s
Train Epoch: 701 	Average Loss: 11.9502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3074

Learning rate: 0.00019758481820598506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 702 [0/90000 (0%)]	Loss: 16.5051	Cost: 20.79s
Train Epoch: 702 [20480/90000 (23%)]	Loss: 11.4790	Cost: 6.34s
Train Epoch: 702 [40960/90000 (45%)]	Loss: 11.3985	Cost: 6.06s
Train Epoch: 702 [61440/90000 (68%)]	Loss: 11.4096	Cost: 6.05s
Train Epoch: 702 [81920/90000 (91%)]	Loss: 11.5792	Cost: 6.29s
Train Epoch: 702 	Average Loss: 11.9157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1775

Learning rate: 0.0001975779505868602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 703 [0/90000 (0%)]	Loss: 16.6836	Cost: 20.79s
Train Epoch: 703 [20480/90000 (23%)]	Loss: 11.4005	Cost: 6.22s
Train Epoch: 703 [40960/90000 (45%)]	Loss: 11.4594	Cost: 6.10s
Train Epoch: 703 [61440/90000 (68%)]	Loss: 11.4033	Cost: 6.01s
Train Epoch: 703 [81920/90000 (91%)]	Loss: 11.3077	Cost: 6.62s
Train Epoch: 703 	Average Loss: 11.8465
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1701

Learning rate: 0.0001975710733371777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 704 [0/90000 (0%)]	Loss: 16.6904	Cost: 21.17s
Train Epoch: 704 [20480/90000 (23%)]	Loss: 11.2268	Cost: 6.09s
Train Epoch: 704 [40960/90000 (45%)]	Loss: 11.1782	Cost: 6.51s
Train Epoch: 704 [61440/90000 (68%)]	Loss: 11.4243	Cost: 6.07s
Train Epoch: 704 [81920/90000 (91%)]	Loss: 11.4929	Cost: 6.92s
Train Epoch: 704 	Average Loss: 11.7976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1694

Learning rate: 0.00019756418645761634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 705 [0/90000 (0%)]	Loss: 16.6875	Cost: 20.90s
Train Epoch: 705 [20480/90000 (23%)]	Loss: 11.3183	Cost: 6.05s
Train Epoch: 705 [40960/90000 (45%)]	Loss: 11.4284	Cost: 6.49s
Train Epoch: 705 [61440/90000 (68%)]	Loss: 11.3454	Cost: 6.52s
Train Epoch: 705 [81920/90000 (91%)]	Loss: 11.4340	Cost: 6.47s
Train Epoch: 705 	Average Loss: 11.7925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2624

Learning rate: 0.0001975572899488558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 706 [0/90000 (0%)]	Loss: 16.6659	Cost: 21.01s
Train Epoch: 706 [20480/90000 (23%)]	Loss: 11.2284	Cost: 6.17s
Train Epoch: 706 [40960/90000 (45%)]	Loss: 11.2608	Cost: 6.33s
Train Epoch: 706 [61440/90000 (68%)]	Loss: 11.5311	Cost: 6.21s
Train Epoch: 706 [81920/90000 (91%)]	Loss: 11.5686	Cost: 7.29s
Train Epoch: 706 	Average Loss: 11.8189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1748

Learning rate: 0.0001975503838115768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 707 [0/90000 (0%)]	Loss: 16.5228	Cost: 20.74s
Train Epoch: 707 [20480/90000 (23%)]	Loss: 11.4951	Cost: 6.07s
Train Epoch: 707 [40960/90000 (45%)]	Loss: 11.3564	Cost: 6.16s
Train Epoch: 707 [61440/90000 (68%)]	Loss: 11.4689	Cost: 6.14s
Train Epoch: 707 [81920/90000 (91%)]	Loss: 11.6031	Cost: 6.71s
Train Epoch: 707 	Average Loss: 11.7862
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2266

Learning rate: 0.00019754346804646088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 708 [0/90000 (0%)]	Loss: 16.5975	Cost: 20.53s
Train Epoch: 708 [20480/90000 (23%)]	Loss: 11.4299	Cost: 6.18s
Train Epoch: 708 [40960/90000 (45%)]	Loss: 11.4627	Cost: 6.43s
Train Epoch: 708 [61440/90000 (68%)]	Loss: 11.3696	Cost: 6.00s
Train Epoch: 708 [81920/90000 (91%)]	Loss: 11.3445	Cost: 6.80s
Train Epoch: 708 	Average Loss: 11.7868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2612

Learning rate: 0.00019753654265419063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 709 [0/90000 (0%)]	Loss: 16.5607	Cost: 19.77s
Train Epoch: 709 [20480/90000 (23%)]	Loss: 11.5456	Cost: 6.13s
Train Epoch: 709 [40960/90000 (45%)]	Loss: 11.2365	Cost: 6.31s
Train Epoch: 709 [61440/90000 (68%)]	Loss: 11.1986	Cost: 6.11s
Train Epoch: 709 [81920/90000 (91%)]	Loss: 11.4376	Cost: 6.88s
Train Epoch: 709 	Average Loss: 11.7715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3033

Learning rate: 0.00019752960763544955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 710 [0/90000 (0%)]	Loss: 16.6397	Cost: 20.06s
Train Epoch: 710 [20480/90000 (23%)]	Loss: 11.3241	Cost: 6.11s
Train Epoch: 710 [40960/90000 (45%)]	Loss: 11.2285	Cost: 6.44s
Train Epoch: 710 [61440/90000 (68%)]	Loss: 11.2323	Cost: 6.02s
Train Epoch: 710 [81920/90000 (91%)]	Loss: 11.4697	Cost: 7.04s
Train Epoch: 710 	Average Loss: 11.7136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2851

Learning rate: 0.0001975226629909221
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 711 [0/90000 (0%)]	Loss: 16.7717	Cost: 19.42s
Train Epoch: 711 [20480/90000 (23%)]	Loss: 11.3273	Cost: 6.14s
Train Epoch: 711 [40960/90000 (45%)]	Loss: 11.3419	Cost: 6.28s
Train Epoch: 711 [61440/90000 (68%)]	Loss: 11.3023	Cost: 6.02s
Train Epoch: 711 [81920/90000 (91%)]	Loss: 11.5637	Cost: 6.42s
Train Epoch: 711 	Average Loss: 11.8012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2692

Learning rate: 0.00019751570872129367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 712 [0/90000 (0%)]	Loss: 16.6234	Cost: 19.35s
Train Epoch: 712 [20480/90000 (23%)]	Loss: 11.2986	Cost: 6.22s
Train Epoch: 712 [40960/90000 (45%)]	Loss: 11.2107	Cost: 6.44s
Train Epoch: 712 [61440/90000 (68%)]	Loss: 11.4371	Cost: 6.06s
Train Epoch: 712 [81920/90000 (91%)]	Loss: 11.2998	Cost: 5.99s
Train Epoch: 712 	Average Loss: 11.7280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2926

Learning rate: 0.00019750874482725065
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 713 [0/90000 (0%)]	Loss: 16.5913	Cost: 20.43s
Train Epoch: 713 [20480/90000 (23%)]	Loss: 11.3567	Cost: 6.04s
Train Epoch: 713 [40960/90000 (45%)]	Loss: 11.2666	Cost: 6.79s
Train Epoch: 713 [61440/90000 (68%)]	Loss: 11.4545	Cost: 6.17s
Train Epoch: 713 [81920/90000 (91%)]	Loss: 11.2097	Cost: 7.56s
Train Epoch: 713 	Average Loss: 11.6790
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3076

Learning rate: 0.00019750177130948036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 714 [0/90000 (0%)]	Loss: 16.6036	Cost: 19.97s
Train Epoch: 714 [20480/90000 (23%)]	Loss: 11.2218	Cost: 6.05s
Train Epoch: 714 [40960/90000 (45%)]	Loss: 11.1386	Cost: 6.25s
Train Epoch: 714 [61440/90000 (68%)]	Loss: 11.3663	Cost: 6.07s
Train Epoch: 714 [81920/90000 (91%)]	Loss: 11.4719	Cost: 7.13s
Train Epoch: 714 	Average Loss: 11.7086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3048

Learning rate: 0.00019749478816867102
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 715 [0/90000 (0%)]	Loss: 16.5078	Cost: 20.58s
Train Epoch: 715 [20480/90000 (23%)]	Loss: 11.1898	Cost: 6.20s
Train Epoch: 715 [40960/90000 (45%)]	Loss: 11.5852	Cost: 6.22s
Train Epoch: 715 [61440/90000 (68%)]	Loss: 11.1941	Cost: 6.12s
Train Epoch: 715 [81920/90000 (91%)]	Loss: 11.2190	Cost: 5.94s
Train Epoch: 715 	Average Loss: 11.6580
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3087

Learning rate: 0.0001974877954055119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 716 [0/90000 (0%)]	Loss: 16.6488	Cost: 19.28s
Train Epoch: 716 [20480/90000 (23%)]	Loss: 11.2207	Cost: 6.24s
Train Epoch: 716 [40960/90000 (45%)]	Loss: 11.0725	Cost: 6.13s
Train Epoch: 716 [61440/90000 (68%)]	Loss: 11.2066	Cost: 6.41s
Train Epoch: 716 [81920/90000 (91%)]	Loss: 11.2110	Cost: 6.15s
Train Epoch: 716 	Average Loss: 11.6378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2571

Learning rate: 0.00019748079302069307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 717 [0/90000 (0%)]	Loss: 16.8082	Cost: 20.50s
Train Epoch: 717 [20480/90000 (23%)]	Loss: 11.3025	Cost: 6.26s
Train Epoch: 717 [40960/90000 (45%)]	Loss: 11.0949	Cost: 6.07s
Train Epoch: 717 [61440/90000 (68%)]	Loss: 11.2844	Cost: 6.25s
Train Epoch: 717 [81920/90000 (91%)]	Loss: 11.3422	Cost: 7.24s
Train Epoch: 717 	Average Loss: 11.6019
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3148

Learning rate: 0.00019747378101490567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 718 [0/90000 (0%)]	Loss: 16.7720	Cost: 18.70s
Train Epoch: 718 [20480/90000 (23%)]	Loss: 11.2257	Cost: 6.16s
Train Epoch: 718 [40960/90000 (45%)]	Loss: 11.2850	Cost: 6.18s
Train Epoch: 718 [61440/90000 (68%)]	Loss: 11.2921	Cost: 6.21s
Train Epoch: 718 [81920/90000 (91%)]	Loss: 11.2849	Cost: 6.51s
Train Epoch: 718 	Average Loss: 11.6478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4011

Learning rate: 0.00019746675938884178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 719 [0/90000 (0%)]	Loss: 16.6260	Cost: 20.12s
Train Epoch: 719 [20480/90000 (23%)]	Loss: 11.1994	Cost: 6.16s
Train Epoch: 719 [40960/90000 (45%)]	Loss: 11.3669	Cost: 6.11s
Train Epoch: 719 [61440/90000 (68%)]	Loss: 11.1676	Cost: 6.16s
Train Epoch: 719 [81920/90000 (91%)]	Loss: 11.3817	Cost: 6.75s
Train Epoch: 719 	Average Loss: 11.7259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3986

Learning rate: 0.0001974597281431944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 720 [0/90000 (0%)]	Loss: 16.5766	Cost: 20.19s
Train Epoch: 720 [20480/90000 (23%)]	Loss: 11.2083	Cost: 6.09s
Train Epoch: 720 [40960/90000 (45%)]	Loss: 11.4481	Cost: 6.05s
Train Epoch: 720 [61440/90000 (68%)]	Loss: 11.2483	Cost: 6.13s
Train Epoch: 720 [81920/90000 (91%)]	Loss: 11.1657	Cost: 7.19s
Train Epoch: 720 	Average Loss: 11.6856
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2931

Learning rate: 0.0001974526872786575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 721 [0/90000 (0%)]	Loss: 16.4679	Cost: 20.43s
Train Epoch: 721 [20480/90000 (23%)]	Loss: 11.0833	Cost: 6.28s
Train Epoch: 721 [40960/90000 (45%)]	Loss: 11.1934	Cost: 6.29s
Train Epoch: 721 [61440/90000 (68%)]	Loss: 11.1988	Cost: 6.07s
Train Epoch: 721 [81920/90000 (91%)]	Loss: 11.5317	Cost: 6.92s
Train Epoch: 721 	Average Loss: 11.6260
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3836

Learning rate: 0.00019744563679592594
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 722 [0/90000 (0%)]	Loss: 16.6431	Cost: 20.15s
Train Epoch: 722 [20480/90000 (23%)]	Loss: 11.2340	Cost: 6.12s
Train Epoch: 722 [40960/90000 (45%)]	Loss: 11.2692	Cost: 6.34s
Train Epoch: 722 [61440/90000 (68%)]	Loss: 11.2115	Cost: 6.03s
Train Epoch: 722 [81920/90000 (91%)]	Loss: 11.2164	Cost: 6.05s
Train Epoch: 722 	Average Loss: 11.6322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3363

Learning rate: 0.0001974385766956956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 723 [0/90000 (0%)]	Loss: 16.7338	Cost: 19.15s
Train Epoch: 723 [20480/90000 (23%)]	Loss: 11.0745	Cost: 6.16s
Train Epoch: 723 [40960/90000 (45%)]	Loss: 11.3155	Cost: 6.34s
Train Epoch: 723 [61440/90000 (68%)]	Loss: 11.3709	Cost: 5.98s
Train Epoch: 723 [81920/90000 (91%)]	Loss: 11.1767	Cost: 7.50s
Train Epoch: 723 	Average Loss: 11.5957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3083

Learning rate: 0.0001974315069786633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 724 [0/90000 (0%)]	Loss: 16.6210	Cost: 20.02s
Train Epoch: 724 [20480/90000 (23%)]	Loss: 11.1700	Cost: 6.14s
Train Epoch: 724 [40960/90000 (45%)]	Loss: 11.3307	Cost: 6.46s
Train Epoch: 724 [61440/90000 (68%)]	Loss: 11.2207	Cost: 6.07s
Train Epoch: 724 [81920/90000 (91%)]	Loss: 11.2693	Cost: 6.89s
Train Epoch: 724 	Average Loss: 11.6333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3844

Learning rate: 0.00019742442764552676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 725 [0/90000 (0%)]	Loss: 16.7136	Cost: 19.52s
Train Epoch: 725 [20480/90000 (23%)]	Loss: 11.0082	Cost: 6.14s
Train Epoch: 725 [40960/90000 (45%)]	Loss: 11.4230	Cost: 6.16s
Train Epoch: 725 [61440/90000 (68%)]	Loss: 11.1455	Cost: 5.96s
Train Epoch: 725 [81920/90000 (91%)]	Loss: 11.1962	Cost: 6.51s
Train Epoch: 725 	Average Loss: 11.5972
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3290

Learning rate: 0.0001974173386969847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 726 [0/90000 (0%)]	Loss: 16.9520	Cost: 20.22s
Train Epoch: 726 [20480/90000 (23%)]	Loss: 10.9370	Cost: 6.12s
Train Epoch: 726 [40960/90000 (45%)]	Loss: 11.0790	Cost: 6.27s
Train Epoch: 726 [61440/90000 (68%)]	Loss: 11.0810	Cost: 6.05s
Train Epoch: 726 [81920/90000 (91%)]	Loss: 11.1818	Cost: 6.41s
Train Epoch: 726 	Average Loss: 11.5486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3544

Learning rate: 0.00019741024013373678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 727 [0/90000 (0%)]	Loss: 16.7439	Cost: 19.44s
Train Epoch: 727 [20480/90000 (23%)]	Loss: 11.1247	Cost: 6.16s
Train Epoch: 727 [40960/90000 (45%)]	Loss: 10.9979	Cost: 6.26s
Train Epoch: 727 [61440/90000 (68%)]	Loss: 11.0696	Cost: 6.25s
Train Epoch: 727 [81920/90000 (91%)]	Loss: 11.1555	Cost: 6.28s
Train Epoch: 727 	Average Loss: 11.5023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4106

Learning rate: 0.00019740313195648358
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 728 [0/90000 (0%)]	Loss: 16.7687	Cost: 20.58s
Train Epoch: 728 [20480/90000 (23%)]	Loss: 11.1100	Cost: 6.13s
Train Epoch: 728 [40960/90000 (45%)]	Loss: 10.9427	Cost: 6.28s
Train Epoch: 728 [61440/90000 (68%)]	Loss: 10.9670	Cost: 6.20s
Train Epoch: 728 [81920/90000 (91%)]	Loss: 11.1501	Cost: 6.13s
Train Epoch: 728 	Average Loss: 11.4928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4891

Learning rate: 0.00019739601416592667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 729 [0/90000 (0%)]	Loss: 16.8564	Cost: 19.10s
Train Epoch: 729 [20480/90000 (23%)]	Loss: 10.8573	Cost: 6.11s
Train Epoch: 729 [40960/90000 (45%)]	Loss: 11.0387	Cost: 6.33s
Train Epoch: 729 [61440/90000 (68%)]	Loss: 11.3591	Cost: 6.09s
Train Epoch: 729 [81920/90000 (91%)]	Loss: 11.3904	Cost: 7.45s
Train Epoch: 729 	Average Loss: 11.4970
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4653

Learning rate: 0.00019738888676276855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 730 [0/90000 (0%)]	Loss: 17.1265	Cost: 19.80s
Train Epoch: 730 [20480/90000 (23%)]	Loss: 11.1598	Cost: 6.05s
Train Epoch: 730 [40960/90000 (45%)]	Loss: 10.9961	Cost: 6.27s
Train Epoch: 730 [61440/90000 (68%)]	Loss: 11.0450	Cost: 5.98s
Train Epoch: 730 [81920/90000 (91%)]	Loss: 11.2460	Cost: 6.71s
Train Epoch: 730 	Average Loss: 11.5410
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4370

Learning rate: 0.00019738174974771262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 731 [0/90000 (0%)]	Loss: 16.7478	Cost: 18.65s
Train Epoch: 731 [20480/90000 (23%)]	Loss: 10.7967	Cost: 6.20s
Train Epoch: 731 [40960/90000 (45%)]	Loss: 11.0488	Cost: 6.15s
Train Epoch: 731 [61440/90000 (68%)]	Loss: 10.9736	Cost: 6.05s
Train Epoch: 731 [81920/90000 (91%)]	Loss: 11.1347	Cost: 6.25s
Train Epoch: 731 	Average Loss: 11.4619
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3409

Learning rate: 0.00019737460312146333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 732 [0/90000 (0%)]	Loss: 16.9570	Cost: 21.41s
Train Epoch: 732 [20480/90000 (23%)]	Loss: 11.0479	Cost: 6.06s
Train Epoch: 732 [40960/90000 (45%)]	Loss: 10.9769	Cost: 6.65s
Train Epoch: 732 [61440/90000 (68%)]	Loss: 11.0534	Cost: 5.98s
Train Epoch: 732 [81920/90000 (91%)]	Loss: 11.0713	Cost: 6.33s
Train Epoch: 732 	Average Loss: 11.5183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5466

Learning rate: 0.000197367446884726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 733 [0/90000 (0%)]	Loss: 17.0805	Cost: 20.36s
Train Epoch: 733 [20480/90000 (23%)]	Loss: 10.9563	Cost: 6.19s
Train Epoch: 733 [40960/90000 (45%)]	Loss: 11.0231	Cost: 6.36s
Train Epoch: 733 [61440/90000 (68%)]	Loss: 11.0611	Cost: 6.01s
Train Epoch: 733 [81920/90000 (91%)]	Loss: 11.2580	Cost: 6.17s
Train Epoch: 733 	Average Loss: 11.5033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4913

Learning rate: 0.00019736028103820694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 734 [0/90000 (0%)]	Loss: 16.7613	Cost: 21.23s
Train Epoch: 734 [20480/90000 (23%)]	Loss: 11.0455	Cost: 6.03s
Train Epoch: 734 [40960/90000 (45%)]	Loss: 11.1496	Cost: 6.71s
Train Epoch: 734 [61440/90000 (68%)]	Loss: 11.0590	Cost: 5.96s
Train Epoch: 734 [81920/90000 (91%)]	Loss: 11.1283	Cost: 7.20s
Train Epoch: 734 	Average Loss: 11.4920
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4148

Learning rate: 0.0001973531055826134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 735 [0/90000 (0%)]	Loss: 17.0882	Cost: 20.03s
Train Epoch: 735 [20480/90000 (23%)]	Loss: 10.6398	Cost: 6.00s
Train Epoch: 735 [40960/90000 (45%)]	Loss: 10.7714	Cost: 6.08s
Train Epoch: 735 [61440/90000 (68%)]	Loss: 11.0880	Cost: 6.06s
Train Epoch: 735 [81920/90000 (91%)]	Loss: 11.3056	Cost: 7.03s
Train Epoch: 735 	Average Loss: 11.3786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4672

Learning rate: 0.0001973459205186535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 736 [0/90000 (0%)]	Loss: 16.8540	Cost: 20.49s
Train Epoch: 736 [20480/90000 (23%)]	Loss: 10.8172	Cost: 6.10s
Train Epoch: 736 [40960/90000 (45%)]	Loss: 10.9333	Cost: 6.60s
Train Epoch: 736 [61440/90000 (68%)]	Loss: 10.9685	Cost: 6.04s
Train Epoch: 736 [81920/90000 (91%)]	Loss: 11.0180	Cost: 7.17s
Train Epoch: 736 	Average Loss: 11.3779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5122

Learning rate: 0.00019733872584703645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 737 [0/90000 (0%)]	Loss: 17.0809	Cost: 19.78s
Train Epoch: 737 [20480/90000 (23%)]	Loss: 10.8480	Cost: 6.11s
Train Epoch: 737 [40960/90000 (45%)]	Loss: 11.1584	Cost: 6.27s
Train Epoch: 737 [61440/90000 (68%)]	Loss: 11.0839	Cost: 6.19s
Train Epoch: 737 [81920/90000 (91%)]	Loss: 11.0494	Cost: 7.29s
Train Epoch: 737 	Average Loss: 11.4544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5646

Learning rate: 0.0001973315215684723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 738 [0/90000 (0%)]	Loss: 17.0115	Cost: 20.24s
Train Epoch: 738 [20480/90000 (23%)]	Loss: 10.9653	Cost: 6.05s
Train Epoch: 738 [40960/90000 (45%)]	Loss: 11.0294	Cost: 6.24s
Train Epoch: 738 [61440/90000 (68%)]	Loss: 10.9910	Cost: 6.20s
Train Epoch: 738 [81920/90000 (91%)]	Loss: 10.9576	Cost: 6.85s
Train Epoch: 738 	Average Loss: 11.4394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5260

Learning rate: 0.00019732430768367213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 739 [0/90000 (0%)]	Loss: 17.1402	Cost: 20.62s
Train Epoch: 739 [20480/90000 (23%)]	Loss: 10.6855	Cost: 6.10s
Train Epoch: 739 [40960/90000 (45%)]	Loss: 10.8834	Cost: 6.46s
Train Epoch: 739 [61440/90000 (68%)]	Loss: 11.0517	Cost: 6.02s
Train Epoch: 739 [81920/90000 (91%)]	Loss: 10.9988	Cost: 6.62s
Train Epoch: 739 	Average Loss: 11.3951
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5349

Learning rate: 0.00019731708419334784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 740 [0/90000 (0%)]	Loss: 17.1710	Cost: 20.13s
Train Epoch: 740 [20480/90000 (23%)]	Loss: 11.0017	Cost: 6.14s
Train Epoch: 740 [40960/90000 (45%)]	Loss: 11.0086	Cost: 6.26s
Train Epoch: 740 [61440/90000 (68%)]	Loss: 10.8644	Cost: 6.01s
Train Epoch: 740 [81920/90000 (91%)]	Loss: 11.2265	Cost: 6.74s
Train Epoch: 740 	Average Loss: 11.4537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6212

Learning rate: 0.00019730985109821242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 741 [0/90000 (0%)]	Loss: 16.6678	Cost: 19.81s
Train Epoch: 741 [20480/90000 (23%)]	Loss: 10.9004	Cost: 6.07s
Train Epoch: 741 [40960/90000 (45%)]	Loss: 10.9081	Cost: 6.50s
Train Epoch: 741 [61440/90000 (68%)]	Loss: 11.0044	Cost: 6.00s
Train Epoch: 741 [81920/90000 (91%)]	Loss: 11.1879	Cost: 6.88s
Train Epoch: 741 	Average Loss: 11.4285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5320

Learning rate: 0.0001973026083989797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 742 [0/90000 (0%)]	Loss: 16.9510	Cost: 19.86s
Train Epoch: 742 [20480/90000 (23%)]	Loss: 10.8085	Cost: 6.11s
Train Epoch: 742 [40960/90000 (45%)]	Loss: 10.8818	Cost: 6.13s
Train Epoch: 742 [61440/90000 (68%)]	Loss: 11.0022	Cost: 6.10s
Train Epoch: 742 [81920/90000 (91%)]	Loss: 11.1461	Cost: 6.00s
Train Epoch: 742 	Average Loss: 11.3691
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4852

Learning rate: 0.00019729535609636458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 743 [0/90000 (0%)]	Loss: 17.0717	Cost: 20.28s
Train Epoch: 743 [20480/90000 (23%)]	Loss: 10.6847	Cost: 6.13s
Train Epoch: 743 [40960/90000 (45%)]	Loss: 10.9618	Cost: 6.16s
Train Epoch: 743 [61440/90000 (68%)]	Loss: 10.8682	Cost: 6.03s
Train Epoch: 743 [81920/90000 (91%)]	Loss: 10.9389	Cost: 5.99s
Train Epoch: 743 	Average Loss: 11.4199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6085

Learning rate: 0.00019728809419108275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 744 [0/90000 (0%)]	Loss: 16.9043	Cost: 20.08s
Train Epoch: 744 [20480/90000 (23%)]	Loss: 10.8847	Cost: 6.18s
Train Epoch: 744 [40960/90000 (45%)]	Loss: 10.9650	Cost: 6.26s
Train Epoch: 744 [61440/90000 (68%)]	Loss: 10.8140	Cost: 6.13s
Train Epoch: 744 [81920/90000 (91%)]	Loss: 10.9215	Cost: 6.71s
Train Epoch: 744 	Average Loss: 11.3756
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5241

Learning rate: 0.00019728082268385098
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 745 [0/90000 (0%)]	Loss: 16.8320	Cost: 20.25s
Train Epoch: 745 [20480/90000 (23%)]	Loss: 10.9031	Cost: 6.15s
Train Epoch: 745 [40960/90000 (45%)]	Loss: 10.9343	Cost: 6.58s
Train Epoch: 745 [61440/90000 (68%)]	Loss: 10.9180	Cost: 6.06s
Train Epoch: 745 [81920/90000 (91%)]	Loss: 10.9817	Cost: 7.23s
Train Epoch: 745 	Average Loss: 11.3220
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6127

Learning rate: 0.00019727354157538695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 746 [0/90000 (0%)]	Loss: 16.7950	Cost: 19.13s
Train Epoch: 746 [20480/90000 (23%)]	Loss: 10.8697	Cost: 6.19s
Train Epoch: 746 [40960/90000 (45%)]	Loss: 10.8154	Cost: 6.27s
Train Epoch: 746 [61440/90000 (68%)]	Loss: 10.9009	Cost: 6.04s
Train Epoch: 746 [81920/90000 (91%)]	Loss: 11.0195	Cost: 6.08s
Train Epoch: 746 	Average Loss: 11.3030
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6585

Learning rate: 0.00019726625086640925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 747 [0/90000 (0%)]	Loss: 16.9649	Cost: 20.43s
Train Epoch: 747 [20480/90000 (23%)]	Loss: 10.5520	Cost: 5.95s
Train Epoch: 747 [40960/90000 (45%)]	Loss: 10.8696	Cost: 5.97s
Train Epoch: 747 [61440/90000 (68%)]	Loss: 10.8528	Cost: 6.14s
Train Epoch: 747 [81920/90000 (91%)]	Loss: 11.1062	Cost: 7.96s
Train Epoch: 747 	Average Loss: 11.2988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6101

Learning rate: 0.00019725895055763745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 748 [0/90000 (0%)]	Loss: 16.9591	Cost: 19.71s
Train Epoch: 748 [20480/90000 (23%)]	Loss: 10.7941	Cost: 6.12s
Train Epoch: 748 [40960/90000 (45%)]	Loss: 10.8160	Cost: 6.27s
Train Epoch: 748 [61440/90000 (68%)]	Loss: 10.8223	Cost: 6.01s
Train Epoch: 748 [81920/90000 (91%)]	Loss: 11.0909	Cost: 6.48s
Train Epoch: 748 	Average Loss: 11.3376
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5882

Learning rate: 0.00019725164064979207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 749 [0/90000 (0%)]	Loss: 17.1259	Cost: 19.38s
Train Epoch: 749 [20480/90000 (23%)]	Loss: 10.6944	Cost: 6.28s
Train Epoch: 749 [40960/90000 (45%)]	Loss: 10.8833	Cost: 6.68s
Train Epoch: 749 [61440/90000 (68%)]	Loss: 10.7987	Cost: 6.22s
Train Epoch: 749 [81920/90000 (91%)]	Loss: 10.9178	Cost: 6.75s
Train Epoch: 749 	Average Loss: 11.3078
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5981

Learning rate: 0.00019724432114359458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 750 [0/90000 (0%)]	Loss: 16.9159	Cost: 19.87s
Train Epoch: 750 [20480/90000 (23%)]	Loss: 10.6191	Cost: 6.36s
Train Epoch: 750 [40960/90000 (45%)]	Loss: 10.9357	Cost: 6.24s
Train Epoch: 750 [61440/90000 (68%)]	Loss: 10.9508	Cost: 6.03s
Train Epoch: 750 [81920/90000 (91%)]	Loss: 11.0206	Cost: 6.01s
Train Epoch: 750 	Average Loss: 11.3021
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6361

Learning rate: 0.00019723699203976736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 751 [0/90000 (0%)]	Loss: 17.0806	Cost: 19.36s
Train Epoch: 751 [20480/90000 (23%)]	Loss: 10.8171	Cost: 5.99s
Train Epoch: 751 [40960/90000 (45%)]	Loss: 10.9111	Cost: 6.61s
Train Epoch: 751 [61440/90000 (68%)]	Loss: 10.8090	Cost: 6.16s
Train Epoch: 751 [81920/90000 (91%)]	Loss: 11.0030	Cost: 7.21s
Train Epoch: 751 	Average Loss: 11.3306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5648

Learning rate: 0.0001972296533390338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 752 [0/90000 (0%)]	Loss: 16.9099	Cost: 20.25s
Train Epoch: 752 [20480/90000 (23%)]	Loss: 10.8283	Cost: 6.17s
Train Epoch: 752 [40960/90000 (45%)]	Loss: 10.8389	Cost: 6.41s
Train Epoch: 752 [61440/90000 (68%)]	Loss: 10.6115	Cost: 6.03s
Train Epoch: 752 [81920/90000 (91%)]	Loss: 10.8985	Cost: 6.20s
Train Epoch: 752 	Average Loss: 11.1962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6175

Learning rate: 0.00019722230504211813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 753 [0/90000 (0%)]	Loss: 16.6825	Cost: 19.74s
Train Epoch: 753 [20480/90000 (23%)]	Loss: 10.9756	Cost: 6.17s
Train Epoch: 753 [40960/90000 (45%)]	Loss: 10.6802	Cost: 6.33s
Train Epoch: 753 [61440/90000 (68%)]	Loss: 10.8143	Cost: 6.05s
Train Epoch: 753 [81920/90000 (91%)]	Loss: 10.9216	Cost: 6.72s
Train Epoch: 753 	Average Loss: 11.2520
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6431

Learning rate: 0.00019721494714974565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 754 [0/90000 (0%)]	Loss: 16.7610	Cost: 20.47s
Train Epoch: 754 [20480/90000 (23%)]	Loss: 10.7820	Cost: 6.10s
Train Epoch: 754 [40960/90000 (45%)]	Loss: 10.5762	Cost: 6.41s
Train Epoch: 754 [61440/90000 (68%)]	Loss: 10.7526	Cost: 5.99s
Train Epoch: 754 [81920/90000 (91%)]	Loss: 11.0336	Cost: 6.31s
Train Epoch: 754 	Average Loss: 11.2131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5858

Learning rate: 0.00019720757966264256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 755 [0/90000 (0%)]	Loss: 16.9358	Cost: 20.31s
Train Epoch: 755 [20480/90000 (23%)]	Loss: 10.7700	Cost: 6.03s
Train Epoch: 755 [40960/90000 (45%)]	Loss: 10.8938	Cost: 6.51s
Train Epoch: 755 [61440/90000 (68%)]	Loss: 10.8410	Cost: 5.97s
Train Epoch: 755 [81920/90000 (91%)]	Loss: 10.9017	Cost: 7.08s
Train Epoch: 755 	Average Loss: 11.2942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5912

Learning rate: 0.00019720020258153596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 756 [0/90000 (0%)]	Loss: 16.7785	Cost: 20.06s
Train Epoch: 756 [20480/90000 (23%)]	Loss: 10.5142	Cost: 6.26s
Train Epoch: 756 [40960/90000 (45%)]	Loss: 10.6688	Cost: 7.04s
Train Epoch: 756 [61440/90000 (68%)]	Loss: 10.7426	Cost: 6.06s
Train Epoch: 756 [81920/90000 (91%)]	Loss: 10.9472	Cost: 6.29s
Train Epoch: 756 	Average Loss: 11.2064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6889

Learning rate: 0.000197192815907154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 757 [0/90000 (0%)]	Loss: 17.1842	Cost: 20.64s
Train Epoch: 757 [20480/90000 (23%)]	Loss: 10.5902	Cost: 6.22s
Train Epoch: 757 [40960/90000 (45%)]	Loss: 10.8145	Cost: 7.09s
Train Epoch: 757 [61440/90000 (68%)]	Loss: 10.6539	Cost: 6.00s
Train Epoch: 757 [81920/90000 (91%)]	Loss: 10.8620	Cost: 6.46s
Train Epoch: 757 	Average Loss: 11.2342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6212

Learning rate: 0.00019718541964022568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 758 [0/90000 (0%)]	Loss: 17.0073	Cost: 19.49s
Train Epoch: 758 [20480/90000 (23%)]	Loss: 10.6992	Cost: 6.52s
Train Epoch: 758 [40960/90000 (45%)]	Loss: 10.7533	Cost: 6.98s
Train Epoch: 758 [61440/90000 (68%)]	Loss: 10.7373	Cost: 5.97s
Train Epoch: 758 [81920/90000 (91%)]	Loss: 10.8672	Cost: 6.37s
Train Epoch: 758 	Average Loss: 11.2369
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6280

Learning rate: 0.00019717801378148098
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 759 [0/90000 (0%)]	Loss: 17.0450	Cost: 20.06s
Train Epoch: 759 [20480/90000 (23%)]	Loss: 10.7187	Cost: 6.32s
Train Epoch: 759 [40960/90000 (45%)]	Loss: 10.6385	Cost: 6.55s
Train Epoch: 759 [61440/90000 (68%)]	Loss: 10.6700	Cost: 6.00s
Train Epoch: 759 [81920/90000 (91%)]	Loss: 10.8384	Cost: 6.61s
Train Epoch: 759 	Average Loss: 11.2369
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6492

Learning rate: 0.0001971705983316508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 760 [0/90000 (0%)]	Loss: 16.9626	Cost: 20.23s
Train Epoch: 760 [20480/90000 (23%)]	Loss: 10.5619	Cost: 6.74s
Train Epoch: 760 [40960/90000 (45%)]	Loss: 10.6817	Cost: 6.72s
Train Epoch: 760 [61440/90000 (68%)]	Loss: 10.5490	Cost: 6.17s
Train Epoch: 760 [81920/90000 (91%)]	Loss: 10.7058	Cost: 6.73s
Train Epoch: 760 	Average Loss: 11.2179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6775

Learning rate: 0.0001971631732914671
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 761 [0/90000 (0%)]	Loss: 16.9684	Cost: 20.89s
Train Epoch: 761 [20480/90000 (23%)]	Loss: 10.6871	Cost: 6.60s
Train Epoch: 761 [40960/90000 (45%)]	Loss: 10.9650	Cost: 6.36s
Train Epoch: 761 [61440/90000 (68%)]	Loss: 10.6622	Cost: 6.08s
Train Epoch: 761 [81920/90000 (91%)]	Loss: 10.9196	Cost: 6.28s
Train Epoch: 761 	Average Loss: 11.3017
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7117

Learning rate: 0.00019715573866166262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 762 [0/90000 (0%)]	Loss: 17.1154	Cost: 19.24s
Train Epoch: 762 [20480/90000 (23%)]	Loss: 10.7459	Cost: 6.82s
Train Epoch: 762 [40960/90000 (45%)]	Loss: 10.7447	Cost: 6.49s
Train Epoch: 762 [61440/90000 (68%)]	Loss: 10.7177	Cost: 6.06s
Train Epoch: 762 [81920/90000 (91%)]	Loss: 10.9037	Cost: 7.00s
Train Epoch: 762 	Average Loss: 11.2689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5843

Learning rate: 0.0001971482944429712
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 763 [0/90000 (0%)]	Loss: 17.1236	Cost: 20.00s
Train Epoch: 763 [20480/90000 (23%)]	Loss: 10.7336	Cost: 7.19s
Train Epoch: 763 [40960/90000 (45%)]	Loss: 10.6505	Cost: 6.94s
Train Epoch: 763 [61440/90000 (68%)]	Loss: 10.6939	Cost: 5.98s
Train Epoch: 763 [81920/90000 (91%)]	Loss: 10.7987	Cost: 5.92s
Train Epoch: 763 	Average Loss: 11.1477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6985

Learning rate: 0.00019714084063612747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 764 [0/90000 (0%)]	Loss: 16.8987	Cost: 19.12s
Train Epoch: 764 [20480/90000 (23%)]	Loss: 10.7188	Cost: 6.73s
Train Epoch: 764 [40960/90000 (45%)]	Loss: 10.5610	Cost: 6.48s
Train Epoch: 764 [61440/90000 (68%)]	Loss: 10.8926	Cost: 6.08s
Train Epoch: 764 [81920/90000 (91%)]	Loss: 10.6425	Cost: 6.54s
Train Epoch: 764 	Average Loss: 11.1142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7604

Learning rate: 0.00019713337724186716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 765 [0/90000 (0%)]	Loss: 17.0352	Cost: 20.26s
Train Epoch: 765 [20480/90000 (23%)]	Loss: 10.6096	Cost: 6.79s
Train Epoch: 765 [40960/90000 (45%)]	Loss: 10.8630	Cost: 6.74s
Train Epoch: 765 [61440/90000 (68%)]	Loss: 10.4629	Cost: 5.96s
Train Epoch: 765 [81920/90000 (91%)]	Loss: 10.8350	Cost: 6.36s
Train Epoch: 765 	Average Loss: 11.1554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7783

Learning rate: 0.00019712590426092686
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 766 [0/90000 (0%)]	Loss: 17.0726	Cost: 20.62s
Train Epoch: 766 [20480/90000 (23%)]	Loss: 10.7055	Cost: 6.84s
Train Epoch: 766 [40960/90000 (45%)]	Loss: 10.4946	Cost: 6.10s
Train Epoch: 766 [61440/90000 (68%)]	Loss: 10.6676	Cost: 5.81s
Train Epoch: 766 [81920/90000 (91%)]	Loss: 10.9042	Cost: 7.03s
Train Epoch: 766 	Average Loss: 11.1959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7558

Learning rate: 0.0001971184216940441
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 767 [0/90000 (0%)]	Loss: 17.0668	Cost: 23.40s
Train Epoch: 767 [20480/90000 (23%)]	Loss: 10.5817	Cost: 6.10s
Train Epoch: 767 [40960/90000 (45%)]	Loss: 10.6291	Cost: 6.13s
Train Epoch: 767 [61440/90000 (68%)]	Loss: 10.4224	Cost: 6.03s
Train Epoch: 767 [81920/90000 (91%)]	Loss: 10.7028	Cost: 5.90s
Train Epoch: 767 	Average Loss: 11.0686
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7434

Learning rate: 0.0001971109295419574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 768 [0/90000 (0%)]	Loss: 16.9860	Cost: 22.14s
Train Epoch: 768 [20480/90000 (23%)]	Loss: 10.4385	Cost: 6.75s
Train Epoch: 768 [40960/90000 (45%)]	Loss: 10.7241	Cost: 6.37s
Train Epoch: 768 [61440/90000 (68%)]	Loss: 10.5589	Cost: 6.02s
Train Epoch: 768 [81920/90000 (91%)]	Loss: 10.8027	Cost: 7.14s
Train Epoch: 768 	Average Loss: 11.0489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7274

Learning rate: 0.0001971034278054062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 769 [0/90000 (0%)]	Loss: 17.0558	Cost: 26.63s
Train Epoch: 769 [20480/90000 (23%)]	Loss: 10.5896	Cost: 6.05s
Train Epoch: 769 [40960/90000 (45%)]	Loss: 10.6719	Cost: 6.16s
Train Epoch: 769 [61440/90000 (68%)]	Loss: 10.3645	Cost: 5.88s
Train Epoch: 769 [81920/90000 (91%)]	Loss: 10.7406	Cost: 5.74s
Train Epoch: 769 	Average Loss: 11.0797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8338

Learning rate: 0.00019709591648513092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 770 [0/90000 (0%)]	Loss: 17.0007	Cost: 26.71s
Train Epoch: 770 [20480/90000 (23%)]	Loss: 10.4343	Cost: 6.23s
Train Epoch: 770 [40960/90000 (45%)]	Loss: 10.7770	Cost: 6.23s
Train Epoch: 770 [61440/90000 (68%)]	Loss: 10.4870	Cost: 6.03s
Train Epoch: 770 [81920/90000 (91%)]	Loss: 10.8767	Cost: 6.71s
Train Epoch: 770 	Average Loss: 11.0891
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8089

Learning rate: 0.00019708839558187284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 771 [0/90000 (0%)]	Loss: 17.1522	Cost: 22.79s
Train Epoch: 771 [20480/90000 (23%)]	Loss: 10.7253	Cost: 6.04s
Train Epoch: 771 [40960/90000 (45%)]	Loss: 10.3859	Cost: 6.66s
Train Epoch: 771 [61440/90000 (68%)]	Loss: 10.4349	Cost: 6.11s
Train Epoch: 771 [81920/90000 (91%)]	Loss: 10.8052	Cost: 6.30s
Train Epoch: 771 	Average Loss: 11.1461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7402

Learning rate: 0.0001970808650963743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 772 [0/90000 (0%)]	Loss: 17.0986	Cost: 21.93s
Train Epoch: 772 [20480/90000 (23%)]	Loss: 10.6572	Cost: 6.24s
Train Epoch: 772 [40960/90000 (45%)]	Loss: 10.6865	Cost: 6.20s
Train Epoch: 772 [61440/90000 (68%)]	Loss: 10.5038	Cost: 6.11s
Train Epoch: 772 [81920/90000 (91%)]	Loss: 10.7560	Cost: 6.50s
Train Epoch: 772 	Average Loss: 11.1166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7573

Learning rate: 0.00019707332502937847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 773 [0/90000 (0%)]	Loss: 16.9975	Cost: 20.76s
Train Epoch: 773 [20480/90000 (23%)]	Loss: 10.4233	Cost: 6.19s
Train Epoch: 773 [40960/90000 (45%)]	Loss: 10.6207	Cost: 6.27s
Train Epoch: 773 [61440/90000 (68%)]	Loss: 10.3716	Cost: 6.06s
Train Epoch: 773 [81920/90000 (91%)]	Loss: 10.6028	Cost: 6.64s
Train Epoch: 773 	Average Loss: 11.0185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8066

Learning rate: 0.00019706577538162957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 774 [0/90000 (0%)]	Loss: 17.0473	Cost: 21.21s
Train Epoch: 774 [20480/90000 (23%)]	Loss: 10.3907	Cost: 6.24s
Train Epoch: 774 [40960/90000 (45%)]	Loss: 10.3250	Cost: 6.64s
Train Epoch: 774 [61440/90000 (68%)]	Loss: 10.3434	Cost: 6.10s
Train Epoch: 774 [81920/90000 (91%)]	Loss: 10.4770	Cost: 6.50s
Train Epoch: 774 	Average Loss: 10.9971
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8246

Learning rate: 0.00019705821615387272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 775 [0/90000 (0%)]	Loss: 17.2288	Cost: 20.26s
Train Epoch: 775 [20480/90000 (23%)]	Loss: 10.5488	Cost: 6.20s
Train Epoch: 775 [40960/90000 (45%)]	Loss: 10.6746	Cost: 6.47s
Train Epoch: 775 [61440/90000 (68%)]	Loss: 10.6067	Cost: 5.95s
Train Epoch: 775 [81920/90000 (91%)]	Loss: 10.7587	Cost: 6.57s
Train Epoch: 775 	Average Loss: 11.0384
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8629

Learning rate: 0.000197050647346854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 776 [0/90000 (0%)]	Loss: 16.9515	Cost: 20.97s
Train Epoch: 776 [20480/90000 (23%)]	Loss: 10.3569	Cost: 6.12s
Train Epoch: 776 [40960/90000 (45%)]	Loss: 10.3802	Cost: 6.23s
Train Epoch: 776 [61440/90000 (68%)]	Loss: 10.7209	Cost: 5.95s
Train Epoch: 776 [81920/90000 (91%)]	Loss: 10.7954	Cost: 6.97s
Train Epoch: 776 	Average Loss: 11.0293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7643

Learning rate: 0.0001970430689613204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 777 [0/90000 (0%)]	Loss: 17.0490	Cost: 20.28s
Train Epoch: 777 [20480/90000 (23%)]	Loss: 10.6376	Cost: 6.14s
Train Epoch: 777 [40960/90000 (45%)]	Loss: 10.5530	Cost: 6.02s
Train Epoch: 777 [61440/90000 (68%)]	Loss: 10.5835	Cost: 5.95s
Train Epoch: 777 [81920/90000 (91%)]	Loss: 10.8705	Cost: 6.38s
Train Epoch: 777 	Average Loss: 11.1119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7955

Learning rate: 0.00019703548099801984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 778 [0/90000 (0%)]	Loss: 17.1679	Cost: 20.77s
Train Epoch: 778 [20480/90000 (23%)]	Loss: 10.3921	Cost: 6.06s
Train Epoch: 778 [40960/90000 (45%)]	Loss: 10.4950	Cost: 6.06s
Train Epoch: 778 [61440/90000 (68%)]	Loss: 10.4808	Cost: 6.05s
Train Epoch: 778 [81920/90000 (91%)]	Loss: 10.6629	Cost: 5.95s
Train Epoch: 778 	Average Loss: 11.0187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7475

Learning rate: 0.00019702788345770126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 779 [0/90000 (0%)]	Loss: 17.2613	Cost: 20.21s
Train Epoch: 779 [20480/90000 (23%)]	Loss: 10.4856	Cost: 6.23s
Train Epoch: 779 [40960/90000 (45%)]	Loss: 10.5185	Cost: 6.23s
Train Epoch: 779 [61440/90000 (68%)]	Loss: 10.5897	Cost: 6.01s
Train Epoch: 779 [81920/90000 (91%)]	Loss: 10.6384	Cost: 6.00s
Train Epoch: 779 	Average Loss: 10.9607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8182

Learning rate: 0.0001970202763411145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 780 [0/90000 (0%)]	Loss: 17.0234	Cost: 19.90s
Train Epoch: 780 [20480/90000 (23%)]	Loss: 10.4471	Cost: 6.01s
Train Epoch: 780 [40960/90000 (45%)]	Loss: 10.3367	Cost: 6.12s
Train Epoch: 780 [61440/90000 (68%)]	Loss: 10.5071	Cost: 6.12s
Train Epoch: 780 [81920/90000 (91%)]	Loss: 10.5146	Cost: 6.72s
Train Epoch: 780 	Average Loss: 10.9601
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8085

Learning rate: 0.00019701265964901035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 781 [0/90000 (0%)]	Loss: 17.3231	Cost: 19.98s
Train Epoch: 781 [20480/90000 (23%)]	Loss: 10.2736	Cost: 5.99s
Train Epoch: 781 [40960/90000 (45%)]	Loss: 10.3110	Cost: 6.07s
Train Epoch: 781 [61440/90000 (68%)]	Loss: 10.1763	Cost: 6.23s
Train Epoch: 781 [81920/90000 (91%)]	Loss: 10.5415	Cost: 6.68s
Train Epoch: 781 	Average Loss: 10.8534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7905

Learning rate: 0.00019700503338214057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 782 [0/90000 (0%)]	Loss: 17.4828	Cost: 19.15s
Train Epoch: 782 [20480/90000 (23%)]	Loss: 10.3201	Cost: 6.14s
Train Epoch: 782 [40960/90000 (45%)]	Loss: 10.4802	Cost: 6.01s
Train Epoch: 782 [61440/90000 (68%)]	Loss: 10.4762	Cost: 6.06s
Train Epoch: 782 [81920/90000 (91%)]	Loss: 10.5262	Cost: 5.98s
Train Epoch: 782 	Average Loss: 10.9287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7406

Learning rate: 0.0001969973975412578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 783 [0/90000 (0%)]	Loss: 17.2562	Cost: 19.99s
Train Epoch: 783 [20480/90000 (23%)]	Loss: 10.3565	Cost: 6.19s
Train Epoch: 783 [40960/90000 (45%)]	Loss: 10.3200	Cost: 6.39s
Train Epoch: 783 [61440/90000 (68%)]	Loss: 10.3742	Cost: 6.15s
Train Epoch: 783 [81920/90000 (91%)]	Loss: 10.5412	Cost: 7.74s
Train Epoch: 783 	Average Loss: 10.9295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8540

Learning rate: 0.00019698975212711572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 784 [0/90000 (0%)]	Loss: 17.3781	Cost: 20.52s
Train Epoch: 784 [20480/90000 (23%)]	Loss: 10.3486	Cost: 6.09s
Train Epoch: 784 [40960/90000 (45%)]	Loss: 10.3988	Cost: 6.24s
Train Epoch: 784 [61440/90000 (68%)]	Loss: 10.1886	Cost: 6.07s
Train Epoch: 784 [81920/90000 (91%)]	Loss: 10.5014	Cost: 6.56s
Train Epoch: 784 	Average Loss: 10.9104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9950

Learning rate: 0.00019698209714046885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 785 [0/90000 (0%)]	Loss: 17.4437	Cost: 20.95s
Train Epoch: 785 [20480/90000 (23%)]	Loss: 10.2395	Cost: 6.22s
Train Epoch: 785 [40960/90000 (45%)]	Loss: 10.3689	Cost: 6.59s
Train Epoch: 785 [61440/90000 (68%)]	Loss: 10.3308	Cost: 6.15s
Train Epoch: 785 [81920/90000 (91%)]	Loss: 10.5277	Cost: 7.58s
Train Epoch: 785 	Average Loss: 10.8476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9388

Learning rate: 0.00019697443258207274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 786 [0/90000 (0%)]	Loss: 17.4429	Cost: 19.93s
Train Epoch: 786 [20480/90000 (23%)]	Loss: 10.1929	Cost: 6.10s
Train Epoch: 786 [40960/90000 (45%)]	Loss: 10.5105	Cost: 6.40s
Train Epoch: 786 [61440/90000 (68%)]	Loss: 10.4813	Cost: 6.06s
Train Epoch: 786 [81920/90000 (91%)]	Loss: 10.3753	Cost: 6.72s
Train Epoch: 786 	Average Loss: 10.8788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8815

Learning rate: 0.00019696675845268385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 787 [0/90000 (0%)]	Loss: 16.9061	Cost: 20.09s
Train Epoch: 787 [20480/90000 (23%)]	Loss: 10.3627	Cost: 6.07s
Train Epoch: 787 [40960/90000 (45%)]	Loss: 10.3447	Cost: 6.80s
Train Epoch: 787 [61440/90000 (68%)]	Loss: 10.1824	Cost: 6.12s
Train Epoch: 787 [81920/90000 (91%)]	Loss: 10.3984	Cost: 7.49s
Train Epoch: 787 	Average Loss: 10.9199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9193

Learning rate: 0.00019695907475305956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 788 [0/90000 (0%)]	Loss: 17.2212	Cost: 20.01s
Train Epoch: 788 [20480/90000 (23%)]	Loss: 10.3794	Cost: 6.13s
Train Epoch: 788 [40960/90000 (45%)]	Loss: 10.3148	Cost: 6.15s
Train Epoch: 788 [61440/90000 (68%)]	Loss: 10.8372	Cost: 6.07s
Train Epoch: 788 [81920/90000 (91%)]	Loss: 10.7741	Cost: 6.93s
Train Epoch: 788 	Average Loss: 11.0500
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7504

Learning rate: 0.00019695138148395828
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 789 [0/90000 (0%)]	Loss: 17.2540	Cost: 18.93s
Train Epoch: 789 [20480/90000 (23%)]	Loss: 10.4199	Cost: 6.17s
Train Epoch: 789 [40960/90000 (45%)]	Loss: 10.4401	Cost: 6.32s
Train Epoch: 789 [61440/90000 (68%)]	Loss: 10.4996	Cost: 6.18s
Train Epoch: 789 [81920/90000 (91%)]	Loss: 10.5368	Cost: 6.01s
Train Epoch: 789 	Average Loss: 11.0053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7867

Learning rate: 0.00019694367864613922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 790 [0/90000 (0%)]	Loss: 16.9183	Cost: 19.86s
Train Epoch: 790 [20480/90000 (23%)]	Loss: 10.3690	Cost: 6.00s
Train Epoch: 790 [40960/90000 (45%)]	Loss: 10.2928	Cost: 6.78s
Train Epoch: 790 [61440/90000 (68%)]	Loss: 10.1653	Cost: 6.15s
Train Epoch: 790 [81920/90000 (91%)]	Loss: 10.4021	Cost: 7.70s
Train Epoch: 790 	Average Loss: 10.8305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9080

Learning rate: 0.00019693596624036267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 791 [0/90000 (0%)]	Loss: 17.2004	Cost: 20.46s
Train Epoch: 791 [20480/90000 (23%)]	Loss: 10.3640	Cost: 6.11s
Train Epoch: 791 [40960/90000 (45%)]	Loss: 10.5137	Cost: 6.30s
Train Epoch: 791 [61440/90000 (68%)]	Loss: 10.4310	Cost: 6.04s
Train Epoch: 791 [81920/90000 (91%)]	Loss: 10.5421	Cost: 6.60s
Train Epoch: 791 	Average Loss: 10.9304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9277

Learning rate: 0.00019692824426738987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 792 [0/90000 (0%)]	Loss: 17.4573	Cost: 20.89s
Train Epoch: 792 [20480/90000 (23%)]	Loss: 10.6550	Cost: 6.15s
Train Epoch: 792 [40960/90000 (45%)]	Loss: 10.5034	Cost: 6.20s
Train Epoch: 792 [61440/90000 (68%)]	Loss: 10.6234	Cost: 6.03s
Train Epoch: 792 [81920/90000 (91%)]	Loss: 10.4422	Cost: 6.76s
Train Epoch: 792 	Average Loss: 10.9754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9137

Learning rate: 0.0001969205127279828
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 793 [0/90000 (0%)]	Loss: 17.4931	Cost: 20.01s
Train Epoch: 793 [20480/90000 (23%)]	Loss: 10.2296	Cost: 6.11s
Train Epoch: 793 [40960/90000 (45%)]	Loss: 10.3487	Cost: 6.45s
Train Epoch: 793 [61440/90000 (68%)]	Loss: 10.2868	Cost: 6.02s
Train Epoch: 793 [81920/90000 (91%)]	Loss: 10.1598	Cost: 6.08s
Train Epoch: 793 	Average Loss: 10.8117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9168

Learning rate: 0.00019691277162290467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 794 [0/90000 (0%)]	Loss: 17.2128	Cost: 19.93s
Train Epoch: 794 [20480/90000 (23%)]	Loss: 10.1098	Cost: 6.20s
Train Epoch: 794 [40960/90000 (45%)]	Loss: 10.2581	Cost: 6.44s
Train Epoch: 794 [61440/90000 (68%)]	Loss: 10.2335	Cost: 6.07s
Train Epoch: 794 [81920/90000 (91%)]	Loss: 10.3837	Cost: 6.70s
Train Epoch: 794 	Average Loss: 10.7688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0192

Learning rate: 0.00019690502095291943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 795 [0/90000 (0%)]	Loss: 17.1613	Cost: 19.14s
Train Epoch: 795 [20480/90000 (23%)]	Loss: 10.4173	Cost: 6.25s
Train Epoch: 795 [40960/90000 (45%)]	Loss: 10.2796	Cost: 6.46s
Train Epoch: 795 [61440/90000 (68%)]	Loss: 10.3139	Cost: 6.15s
Train Epoch: 795 [81920/90000 (91%)]	Loss: 10.2726	Cost: 7.10s
Train Epoch: 795 	Average Loss: 10.7783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0189

Learning rate: 0.00019689726071879206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 796 [0/90000 (0%)]	Loss: 17.2805	Cost: 19.66s
Train Epoch: 796 [20480/90000 (23%)]	Loss: 10.3612	Cost: 6.18s
Train Epoch: 796 [40960/90000 (45%)]	Loss: 10.2140	Cost: 6.49s
Train Epoch: 796 [61440/90000 (68%)]	Loss: 10.2593	Cost: 6.03s
Train Epoch: 796 [81920/90000 (91%)]	Loss: 10.3952	Cost: 6.42s
Train Epoch: 796 	Average Loss: 10.8531
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9087

Learning rate: 0.00019688949092128843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 797 [0/90000 (0%)]	Loss: 17.2604	Cost: 19.43s
Train Epoch: 797 [20480/90000 (23%)]	Loss: 10.4652	Cost: 6.19s
Train Epoch: 797 [40960/90000 (45%)]	Loss: 10.1805	Cost: 6.47s
Train Epoch: 797 [61440/90000 (68%)]	Loss: 10.1582	Cost: 6.02s
Train Epoch: 797 [81920/90000 (91%)]	Loss: 10.1802	Cost: 6.24s
Train Epoch: 797 	Average Loss: 10.7672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8934

Learning rate: 0.00019688171156117545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 798 [0/90000 (0%)]	Loss: 17.0307	Cost: 19.94s
Train Epoch: 798 [20480/90000 (23%)]	Loss: 10.0962	Cost: 6.14s
Train Epoch: 798 [40960/90000 (45%)]	Loss: 10.2268	Cost: 6.77s
Train Epoch: 798 [61440/90000 (68%)]	Loss: 10.5748	Cost: 6.11s
Train Epoch: 798 [81920/90000 (91%)]	Loss: 10.7507	Cost: 6.89s
Train Epoch: 798 	Average Loss: 10.8007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9222

Learning rate: 0.00019687392263922088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 799 [0/90000 (0%)]	Loss: 17.2587	Cost: 19.53s
Train Epoch: 799 [20480/90000 (23%)]	Loss: 10.5146	Cost: 6.20s
Train Epoch: 799 [40960/90000 (45%)]	Loss: 10.2832	Cost: 6.28s
Train Epoch: 799 [61440/90000 (68%)]	Loss: 10.3262	Cost: 6.01s
Train Epoch: 799 [81920/90000 (91%)]	Loss: 10.2409	Cost: 5.86s
Train Epoch: 799 	Average Loss: 10.8460
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0502

Learning rate: 0.00019686612415619346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 800 [0/90000 (0%)]	Loss: 17.0281	Cost: 20.55s
Train Epoch: 800 [20480/90000 (23%)]	Loss: 10.2358	Cost: 6.16s
Train Epoch: 800 [40960/90000 (45%)]	Loss: 10.4600	Cost: 6.53s
Train Epoch: 800 [61440/90000 (68%)]	Loss: 10.2208	Cost: 6.00s
Train Epoch: 800 [81920/90000 (91%)]	Loss: 10.7684	Cost: 7.08s
Train Epoch: 800 	Average Loss: 10.8458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9732

Learning rate: 0.00019685831611286286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 801 [0/90000 (0%)]	Loss: 17.2866	Cost: 20.43s
Train Epoch: 801 [20480/90000 (23%)]	Loss: 10.7003	Cost: 6.08s
Train Epoch: 801 [40960/90000 (45%)]	Loss: 10.5620	Cost: 6.23s
Train Epoch: 801 [61440/90000 (68%)]	Loss: 10.4428	Cost: 5.97s
Train Epoch: 801 [81920/90000 (91%)]	Loss: 10.5163	Cost: 6.77s
Train Epoch: 801 	Average Loss: 10.9468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0064

Learning rate: 0.0001968504985099997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 802 [0/90000 (0%)]	Loss: 17.3030	Cost: 19.96s
Train Epoch: 802 [20480/90000 (23%)]	Loss: 10.3050	Cost: 6.20s
Train Epoch: 802 [40960/90000 (45%)]	Loss: 10.2263	Cost: 6.50s
Train Epoch: 802 [61440/90000 (68%)]	Loss: 10.1666	Cost: 6.08s
Train Epoch: 802 [81920/90000 (91%)]	Loss: 10.4015	Cost: 7.03s
Train Epoch: 802 	Average Loss: 10.7613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9968

Learning rate: 0.00019684267134837557
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 803 [0/90000 (0%)]	Loss: 17.3182	Cost: 19.20s
Train Epoch: 803 [20480/90000 (23%)]	Loss: 10.2019	Cost: 6.12s
Train Epoch: 803 [40960/90000 (45%)]	Loss: 10.3368	Cost: 6.16s
Train Epoch: 803 [61440/90000 (68%)]	Loss: 10.1455	Cost: 6.04s
Train Epoch: 803 [81920/90000 (91%)]	Loss: 10.2902	Cost: 6.38s
Train Epoch: 803 	Average Loss: 10.7868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8968

Learning rate: 0.00019683483462876295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 804 [0/90000 (0%)]	Loss: 17.5267	Cost: 19.53s
Train Epoch: 804 [20480/90000 (23%)]	Loss: 9.9698	Cost: 6.11s
Train Epoch: 804 [40960/90000 (45%)]	Loss: 10.3928	Cost: 6.17s
Train Epoch: 804 [61440/90000 (68%)]	Loss: 10.0803	Cost: 6.06s
Train Epoch: 804 [81920/90000 (91%)]	Loss: 10.2710	Cost: 6.69s
Train Epoch: 804 	Average Loss: 10.7244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9406

Learning rate: 0.0001968269883519353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 805 [0/90000 (0%)]	Loss: 17.4105	Cost: 20.57s
Train Epoch: 805 [20480/90000 (23%)]	Loss: 10.0876	Cost: 6.13s
Train Epoch: 805 [40960/90000 (45%)]	Loss: 10.0275	Cost: 6.18s
Train Epoch: 805 [61440/90000 (68%)]	Loss: 9.9111	Cost: 6.07s
Train Epoch: 805 [81920/90000 (91%)]	Loss: 10.2181	Cost: 6.35s
Train Epoch: 805 	Average Loss: 10.6399
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9551

Learning rate: 0.00019681913251866706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 806 [0/90000 (0%)]	Loss: 17.3185	Cost: 20.16s
Train Epoch: 806 [20480/90000 (23%)]	Loss: 9.9784	Cost: 6.03s
Train Epoch: 806 [40960/90000 (45%)]	Loss: 10.0948	Cost: 6.39s
Train Epoch: 806 [61440/90000 (68%)]	Loss: 10.1579	Cost: 6.26s
Train Epoch: 806 [81920/90000 (91%)]	Loss: 10.2420	Cost: 6.40s
Train Epoch: 806 	Average Loss: 10.6330
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9877

Learning rate: 0.00019681126712973353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 807 [0/90000 (0%)]	Loss: 17.3108	Cost: 20.02s
Train Epoch: 807 [20480/90000 (23%)]	Loss: 10.1082	Cost: 6.13s
Train Epoch: 807 [40960/90000 (45%)]	Loss: 10.3071	Cost: 6.34s
Train Epoch: 807 [61440/90000 (68%)]	Loss: 9.8716	Cost: 5.94s
Train Epoch: 807 [81920/90000 (91%)]	Loss: 9.9963	Cost: 6.09s
Train Epoch: 807 	Average Loss: 10.6210
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0595

Learning rate: 0.00019680339218591098
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 808 [0/90000 (0%)]	Loss: 17.1347	Cost: 19.71s
Train Epoch: 808 [20480/90000 (23%)]	Loss: 9.9889	Cost: 6.13s
Train Epoch: 808 [40960/90000 (45%)]	Loss: 10.0496	Cost: 6.53s
Train Epoch: 808 [61440/90000 (68%)]	Loss: 10.2058	Cost: 6.01s
Train Epoch: 808 [81920/90000 (91%)]	Loss: 10.3183	Cost: 7.18s
Train Epoch: 808 	Average Loss: 10.5827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1197

Learning rate: 0.00019679550768797666
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 809 [0/90000 (0%)]	Loss: 17.3778	Cost: 19.13s
Train Epoch: 809 [20480/90000 (23%)]	Loss: 10.1863	Cost: 6.16s
Train Epoch: 809 [40960/90000 (45%)]	Loss: 10.2670	Cost: 6.58s
Train Epoch: 809 [61440/90000 (68%)]	Loss: 10.2743	Cost: 6.13s
Train Epoch: 809 [81920/90000 (91%)]	Loss: 10.6557	Cost: 7.25s
Train Epoch: 809 	Average Loss: 10.7404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0191

Learning rate: 0.00019678761363670875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 810 [0/90000 (0%)]	Loss: 17.5540	Cost: 19.21s
Train Epoch: 810 [20480/90000 (23%)]	Loss: 10.3697	Cost: 6.35s
Train Epoch: 810 [40960/90000 (45%)]	Loss: 10.3636	Cost: 6.93s
Train Epoch: 810 [61440/90000 (68%)]	Loss: 10.2748	Cost: 6.07s
Train Epoch: 810 [81920/90000 (91%)]	Loss: 10.4618	Cost: 7.33s
Train Epoch: 810 	Average Loss: 10.8359
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0407

Learning rate: 0.0001967797100328863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 811 [0/90000 (0%)]	Loss: 17.3625	Cost: 19.41s
Train Epoch: 811 [20480/90000 (23%)]	Loss: 10.3571	Cost: 6.48s
Train Epoch: 811 [40960/90000 (45%)]	Loss: 10.3821	Cost: 7.40s
Train Epoch: 811 [61440/90000 (68%)]	Loss: 10.1392	Cost: 6.08s
Train Epoch: 811 [81920/90000 (91%)]	Loss: 10.3125	Cost: 7.08s
Train Epoch: 811 	Average Loss: 10.7532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0426

Learning rate: 0.00019677179687728943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 812 [0/90000 (0%)]	Loss: 17.0668	Cost: 20.82s
Train Epoch: 812 [20480/90000 (23%)]	Loss: 10.2914	Cost: 6.53s
Train Epoch: 812 [40960/90000 (45%)]	Loss: 10.2564	Cost: 6.49s
Train Epoch: 812 [61440/90000 (68%)]	Loss: 10.0689	Cost: 5.96s
Train Epoch: 812 [81920/90000 (91%)]	Loss: 10.2381	Cost: 6.32s
Train Epoch: 812 	Average Loss: 10.7245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0811

Learning rate: 0.00019676387417069913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 813 [0/90000 (0%)]	Loss: 17.2598	Cost: 22.40s
Train Epoch: 813 [20480/90000 (23%)]	Loss: 10.0335	Cost: 6.31s
Train Epoch: 813 [40960/90000 (45%)]	Loss: 10.1598	Cost: 6.94s
Train Epoch: 813 [61440/90000 (68%)]	Loss: 10.1582	Cost: 6.09s
Train Epoch: 813 [81920/90000 (91%)]	Loss: 10.2412	Cost: 7.32s
Train Epoch: 813 	Average Loss: 10.6376
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0221

Learning rate: 0.0001967559419138973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 814 [0/90000 (0%)]	Loss: 17.3090	Cost: 24.35s
Train Epoch: 814 [20480/90000 (23%)]	Loss: 10.0031	Cost: 6.08s
Train Epoch: 814 [40960/90000 (45%)]	Loss: 10.3262	Cost: 6.77s
Train Epoch: 814 [61440/90000 (68%)]	Loss: 10.5671	Cost: 5.98s
Train Epoch: 814 [81920/90000 (91%)]	Loss: 10.8089	Cost: 6.39s
Train Epoch: 814 	Average Loss: 10.9156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9981

Learning rate: 0.00019674800010766687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 815 [0/90000 (0%)]	Loss: 17.4956	Cost: 26.59s
Train Epoch: 815 [20480/90000 (23%)]	Loss: 10.2758	Cost: 6.14s
Train Epoch: 815 [40960/90000 (45%)]	Loss: 10.6774	Cost: 6.86s
Train Epoch: 815 [61440/90000 (68%)]	Loss: 10.3710	Cost: 6.07s
Train Epoch: 815 [81920/90000 (91%)]	Loss: 10.6816	Cost: 7.11s
Train Epoch: 815 	Average Loss: 11.0436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0026

Learning rate: 0.00019674004875279162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 816 [0/90000 (0%)]	Loss: 17.4677	Cost: 23.32s
Train Epoch: 816 [20480/90000 (23%)]	Loss: 10.4629	Cost: 6.21s
Train Epoch: 816 [40960/90000 (45%)]	Loss: 10.5970	Cost: 6.25s
Train Epoch: 816 [61440/90000 (68%)]	Loss: 10.5197	Cost: 5.99s
Train Epoch: 816 [81920/90000 (91%)]	Loss: 10.5029	Cost: 5.92s
Train Epoch: 816 	Average Loss: 11.0396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9074

Learning rate: 0.00019673208785005636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 817 [0/90000 (0%)]	Loss: 17.2674	Cost: 23.51s
Train Epoch: 817 [20480/90000 (23%)]	Loss: 10.2387	Cost: 6.27s
Train Epoch: 817 [40960/90000 (45%)]	Loss: 10.3799	Cost: 6.36s
Train Epoch: 817 [61440/90000 (68%)]	Loss: 10.1753	Cost: 6.06s
Train Epoch: 817 [81920/90000 (91%)]	Loss: 10.3524	Cost: 6.62s
Train Epoch: 817 	Average Loss: 10.8324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9356

Learning rate: 0.00019672411740024673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 818 [0/90000 (0%)]	Loss: 17.3593	Cost: 20.70s
Train Epoch: 818 [20480/90000 (23%)]	Loss: 10.1572	Cost: 6.18s
Train Epoch: 818 [40960/90000 (45%)]	Loss: 10.0684	Cost: 5.96s
Train Epoch: 818 [61440/90000 (68%)]	Loss: 10.0050	Cost: 6.19s
Train Epoch: 818 [81920/90000 (91%)]	Loss: 10.3392	Cost: 6.57s
Train Epoch: 818 	Average Loss: 10.7638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9812

Learning rate: 0.0001967161374041495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 819 [0/90000 (0%)]	Loss: 17.2951	Cost: 21.73s
Train Epoch: 819 [20480/90000 (23%)]	Loss: 10.1091	Cost: 6.15s
Train Epoch: 819 [40960/90000 (45%)]	Loss: 10.0310	Cost: 6.58s
Train Epoch: 819 [61440/90000 (68%)]	Loss: 9.9464	Cost: 5.85s
Train Epoch: 819 [81920/90000 (91%)]	Loss: 10.1691	Cost: 7.03s
Train Epoch: 819 	Average Loss: 10.6300
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1337

Learning rate: 0.00019670814786255217
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 820 [0/90000 (0%)]	Loss: 17.3910	Cost: 20.79s
Train Epoch: 820 [20480/90000 (23%)]	Loss: 9.9668	Cost: 6.19s
Train Epoch: 820 [40960/90000 (45%)]	Loss: 9.8347	Cost: 6.17s
Train Epoch: 820 [61440/90000 (68%)]	Loss: 10.0309	Cost: 6.02s
Train Epoch: 820 [81920/90000 (91%)]	Loss: 9.9666	Cost: 6.14s
Train Epoch: 820 	Average Loss: 10.5315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0441

Learning rate: 0.0001967001487762433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 821 [0/90000 (0%)]	Loss: 17.5145	Cost: 20.46s
Train Epoch: 821 [20480/90000 (23%)]	Loss: 10.1027	Cost: 6.37s
Train Epoch: 821 [40960/90000 (45%)]	Loss: 10.0003	Cost: 7.44s
Train Epoch: 821 [61440/90000 (68%)]	Loss: 10.0611	Cost: 6.08s
Train Epoch: 821 [81920/90000 (91%)]	Loss: 10.1205	Cost: 7.21s
Train Epoch: 821 	Average Loss: 10.5260
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1510

Learning rate: 0.00019669214014601236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 822 [0/90000 (0%)]	Loss: 17.5509	Cost: 20.20s
Train Epoch: 822 [20480/90000 (23%)]	Loss: 10.0519	Cost: 6.18s
Train Epoch: 822 [40960/90000 (45%)]	Loss: 10.0032	Cost: 6.12s
Train Epoch: 822 [61440/90000 (68%)]	Loss: 9.8079	Cost: 6.04s
Train Epoch: 822 [81920/90000 (91%)]	Loss: 10.1539	Cost: 5.91s
Train Epoch: 822 	Average Loss: 10.5783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0809

Learning rate: 0.00019668412197264976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 823 [0/90000 (0%)]	Loss: 17.2509	Cost: 20.26s
Train Epoch: 823 [20480/90000 (23%)]	Loss: 10.0187	Cost: 6.15s
Train Epoch: 823 [40960/90000 (45%)]	Loss: 9.9241	Cost: 6.63s
Train Epoch: 823 [61440/90000 (68%)]	Loss: 9.6700	Cost: 6.01s
Train Epoch: 823 [81920/90000 (91%)]	Loss: 10.1400	Cost: 6.98s
Train Epoch: 823 	Average Loss: 10.5644
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1262

Learning rate: 0.0001966760942569469
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 824 [0/90000 (0%)]	Loss: 17.3134	Cost: 20.15s
Train Epoch: 824 [20480/90000 (23%)]	Loss: 9.9058	Cost: 6.13s
Train Epoch: 824 [40960/90000 (45%)]	Loss: 9.8281	Cost: 6.36s
Train Epoch: 824 [61440/90000 (68%)]	Loss: 9.9676	Cost: 5.93s
Train Epoch: 824 [81920/90000 (91%)]	Loss: 9.8550	Cost: 6.69s
Train Epoch: 824 	Average Loss: 10.4679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0556

Learning rate: 0.00019666805699969608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 825 [0/90000 (0%)]	Loss: 17.5845	Cost: 20.20s
Train Epoch: 825 [20480/90000 (23%)]	Loss: 9.6679	Cost: 6.02s
Train Epoch: 825 [40960/90000 (45%)]	Loss: 9.9638	Cost: 6.13s
Train Epoch: 825 [61440/90000 (68%)]	Loss: 9.8149	Cost: 6.06s
Train Epoch: 825 [81920/90000 (91%)]	Loss: 10.2800	Cost: 6.28s
Train Epoch: 825 	Average Loss: 10.5311
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1200

Learning rate: 0.00019666001020169052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 826 [0/90000 (0%)]	Loss: 17.5475	Cost: 20.25s
Train Epoch: 826 [20480/90000 (23%)]	Loss: 9.9642	Cost: 6.25s
Train Epoch: 826 [40960/90000 (45%)]	Loss: 10.0059	Cost: 6.12s
Train Epoch: 826 [61440/90000 (68%)]	Loss: 9.8782	Cost: 5.98s
Train Epoch: 826 [81920/90000 (91%)]	Loss: 10.0334	Cost: 6.09s
Train Epoch: 826 	Average Loss: 10.6054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1840

Learning rate: 0.00019665195386372441
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 827 [0/90000 (0%)]	Loss: 17.5054	Cost: 21.50s
Train Epoch: 827 [20480/90000 (23%)]	Loss: 10.0694	Cost: 6.03s
Train Epoch: 827 [40960/90000 (45%)]	Loss: 10.2174	Cost: 6.24s
Train Epoch: 827 [61440/90000 (68%)]	Loss: 9.9062	Cost: 6.06s
Train Epoch: 827 [81920/90000 (91%)]	Loss: 10.0827	Cost: 6.30s
Train Epoch: 827 	Average Loss: 10.5596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2014

Learning rate: 0.00019664388798659287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 828 [0/90000 (0%)]	Loss: 17.4365	Cost: 20.00s
Train Epoch: 828 [20480/90000 (23%)]	Loss: 9.9314	Cost: 6.08s
Train Epoch: 828 [40960/90000 (45%)]	Loss: 9.8935	Cost: 6.38s
Train Epoch: 828 [61440/90000 (68%)]	Loss: 9.9551	Cost: 6.20s
Train Epoch: 828 [81920/90000 (91%)]	Loss: 9.9746	Cost: 6.35s
Train Epoch: 828 	Average Loss: 10.4963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1984

Learning rate: 0.00019663581257109203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 829 [0/90000 (0%)]	Loss: 17.5023	Cost: 19.82s
Train Epoch: 829 [20480/90000 (23%)]	Loss: 9.7079	Cost: 6.14s
Train Epoch: 829 [40960/90000 (45%)]	Loss: 9.7851	Cost: 6.20s
Train Epoch: 829 [61440/90000 (68%)]	Loss: 9.6786	Cost: 6.07s
Train Epoch: 829 [81920/90000 (91%)]	Loss: 10.0414	Cost: 6.68s
Train Epoch: 829 	Average Loss: 10.4179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0416

Learning rate: 0.00019662772761801884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 830 [0/90000 (0%)]	Loss: 17.5569	Cost: 19.36s
Train Epoch: 830 [20480/90000 (23%)]	Loss: 9.8678	Cost: 6.26s
Train Epoch: 830 [40960/90000 (45%)]	Loss: 9.9053	Cost: 6.15s
Train Epoch: 830 [61440/90000 (68%)]	Loss: 9.7476	Cost: 6.08s
Train Epoch: 830 [81920/90000 (91%)]	Loss: 9.9362	Cost: 6.78s
Train Epoch: 830 	Average Loss: 10.3630
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2052

Learning rate: 0.00019661963312817126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 831 [0/90000 (0%)]	Loss: 17.4408	Cost: 20.11s
Train Epoch: 831 [20480/90000 (23%)]	Loss: 9.7274	Cost: 6.17s
Train Epoch: 831 [40960/90000 (45%)]	Loss: 9.8136	Cost: 6.22s
Train Epoch: 831 [61440/90000 (68%)]	Loss: 9.6479	Cost: 6.05s
Train Epoch: 831 [81920/90000 (91%)]	Loss: 9.9176	Cost: 5.97s
Train Epoch: 831 	Average Loss: 10.3480
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1769

Learning rate: 0.00019661152910234822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 832 [0/90000 (0%)]	Loss: 17.4662	Cost: 20.46s
Train Epoch: 832 [20480/90000 (23%)]	Loss: 9.5372	Cost: 6.08s
Train Epoch: 832 [40960/90000 (45%)]	Loss: 9.5763	Cost: 6.93s
Train Epoch: 832 [61440/90000 (68%)]	Loss: 9.7382	Cost: 6.10s
Train Epoch: 832 [81920/90000 (91%)]	Loss: 9.8856	Cost: 7.01s
Train Epoch: 832 	Average Loss: 10.3341
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3150

Learning rate: 0.0001966034155413495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 833 [0/90000 (0%)]	Loss: 17.6089	Cost: 19.81s
Train Epoch: 833 [20480/90000 (23%)]	Loss: 9.6263	Cost: 6.02s
Train Epoch: 833 [40960/90000 (45%)]	Loss: 9.8405	Cost: 6.17s
Train Epoch: 833 [61440/90000 (68%)]	Loss: 9.6149	Cost: 5.93s
Train Epoch: 833 [81920/90000 (91%)]	Loss: 9.8266	Cost: 6.01s
Train Epoch: 833 	Average Loss: 10.3208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2505

Learning rate: 0.00019659529244597592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 834 [0/90000 (0%)]	Loss: 17.5042	Cost: 19.86s
Train Epoch: 834 [20480/90000 (23%)]	Loss: 9.5620	Cost: 6.19s
Train Epoch: 834 [40960/90000 (45%)]	Loss: 9.7246	Cost: 6.21s
Train Epoch: 834 [61440/90000 (68%)]	Loss: 9.7251	Cost: 6.08s
Train Epoch: 834 [81920/90000 (91%)]	Loss: 9.6526	Cost: 6.61s
Train Epoch: 834 	Average Loss: 10.3137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2238

Learning rate: 0.00019658715981702915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 835 [0/90000 (0%)]	Loss: 17.4288	Cost: 20.63s
Train Epoch: 835 [20480/90000 (23%)]	Loss: 9.5284	Cost: 6.03s
Train Epoch: 835 [40960/90000 (45%)]	Loss: 9.8275	Cost: 6.47s
Train Epoch: 835 [61440/90000 (68%)]	Loss: 9.5664	Cost: 5.97s
Train Epoch: 835 [81920/90000 (91%)]	Loss: 9.7565	Cost: 6.80s
Train Epoch: 835 	Average Loss: 10.2737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2779

Learning rate: 0.00019657901765531195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 836 [0/90000 (0%)]	Loss: 17.3474	Cost: 20.61s
Train Epoch: 836 [20480/90000 (23%)]	Loss: 9.6954	Cost: 6.03s
Train Epoch: 836 [40960/90000 (45%)]	Loss: 10.0423	Cost: 6.72s
Train Epoch: 836 [61440/90000 (68%)]	Loss: 9.7912	Cost: 6.07s
Train Epoch: 836 [81920/90000 (91%)]	Loss: 10.0784	Cost: 6.09s
Train Epoch: 836 	Average Loss: 10.4421
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3309

Learning rate: 0.0001965708659616278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 837 [0/90000 (0%)]	Loss: 17.6768	Cost: 19.60s
Train Epoch: 837 [20480/90000 (23%)]	Loss: 9.9100	Cost: 6.12s
Train Epoch: 837 [40960/90000 (45%)]	Loss: 9.8709	Cost: 6.28s
Train Epoch: 837 [61440/90000 (68%)]	Loss: 9.8411	Cost: 6.11s
Train Epoch: 837 [81920/90000 (91%)]	Loss: 10.0382	Cost: 5.96s
Train Epoch: 837 	Average Loss: 10.4539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3785

Learning rate: 0.00019656270473678128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 838 [0/90000 (0%)]	Loss: 17.3886	Cost: 20.00s
Train Epoch: 838 [20480/90000 (23%)]	Loss: 9.9738	Cost: 6.10s
Train Epoch: 838 [40960/90000 (45%)]	Loss: 10.0271	Cost: 6.63s
Train Epoch: 838 [61440/90000 (68%)]	Loss: 9.8750	Cost: 6.13s
Train Epoch: 838 [81920/90000 (91%)]	Loss: 10.1410	Cost: 7.52s
Train Epoch: 838 	Average Loss: 10.4872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2186

Learning rate: 0.0001965545339815779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 839 [0/90000 (0%)]	Loss: 17.8069	Cost: 21.04s
Train Epoch: 839 [20480/90000 (23%)]	Loss: 10.0381	Cost: 6.07s
Train Epoch: 839 [40960/90000 (45%)]	Loss: 9.9558	Cost: 6.68s
Train Epoch: 839 [61440/90000 (68%)]	Loss: 9.6092	Cost: 6.32s
Train Epoch: 839 [81920/90000 (91%)]	Loss: 9.6547	Cost: 6.35s
Train Epoch: 839 	Average Loss: 10.4442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2841

Learning rate: 0.00019654635369682408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 840 [0/90000 (0%)]	Loss: 17.5964	Cost: 18.40s
Train Epoch: 840 [20480/90000 (23%)]	Loss: 9.6931	Cost: 6.10s
Train Epoch: 840 [40960/90000 (45%)]	Loss: 9.6282	Cost: 6.13s
Train Epoch: 840 [61440/90000 (68%)]	Loss: 9.7935	Cost: 6.06s
Train Epoch: 840 [81920/90000 (91%)]	Loss: 9.7657	Cost: 5.92s
Train Epoch: 840 	Average Loss: 10.3094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4777

Learning rate: 0.00019653816388332714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 841 [0/90000 (0%)]	Loss: 17.6066	Cost: 21.10s
Train Epoch: 841 [20480/90000 (23%)]	Loss: 9.7009	Cost: 6.10s
Train Epoch: 841 [40960/90000 (45%)]	Loss: 9.8237	Cost: 6.62s
Train Epoch: 841 [61440/90000 (68%)]	Loss: 9.6459	Cost: 6.17s
Train Epoch: 841 [81920/90000 (91%)]	Loss: 9.7595	Cost: 7.47s
Train Epoch: 841 	Average Loss: 10.3493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4281

Learning rate: 0.00019652996454189544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 842 [0/90000 (0%)]	Loss: 17.8180	Cost: 20.06s
Train Epoch: 842 [20480/90000 (23%)]	Loss: 9.5362	Cost: 6.10s
Train Epoch: 842 [40960/90000 (45%)]	Loss: 9.7435	Cost: 6.27s
Train Epoch: 842 [61440/90000 (68%)]	Loss: 9.4727	Cost: 6.05s
Train Epoch: 842 [81920/90000 (91%)]	Loss: 9.7647	Cost: 6.29s
Train Epoch: 842 	Average Loss: 10.3110
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3725

Learning rate: 0.00019652175567333815
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 843 [0/90000 (0%)]	Loss: 17.6000	Cost: 19.78s
Train Epoch: 843 [20480/90000 (23%)]	Loss: 9.7371	Cost: 6.09s
Train Epoch: 843 [40960/90000 (45%)]	Loss: 9.6181	Cost: 6.51s
Train Epoch: 843 [61440/90000 (68%)]	Loss: 9.6286	Cost: 6.31s
Train Epoch: 843 [81920/90000 (91%)]	Loss: 9.7950	Cost: 7.92s
Train Epoch: 843 	Average Loss: 10.2979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2670

Learning rate: 0.00019651353727846553
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 844 [0/90000 (0%)]	Loss: 17.5579	Cost: 19.02s
Train Epoch: 844 [20480/90000 (23%)]	Loss: 9.5243	Cost: 6.17s
Train Epoch: 844 [40960/90000 (45%)]	Loss: 9.6821	Cost: 6.25s
Train Epoch: 844 [61440/90000 (68%)]	Loss: 9.6442	Cost: 6.03s
Train Epoch: 844 [81920/90000 (91%)]	Loss: 9.7783	Cost: 6.74s
Train Epoch: 844 	Average Loss: 10.2501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3112

Learning rate: 0.00019650530935808866
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 845 [0/90000 (0%)]	Loss: 17.4870	Cost: 20.45s
Train Epoch: 845 [20480/90000 (23%)]	Loss: 9.4727	Cost: 6.19s
Train Epoch: 845 [40960/90000 (45%)]	Loss: 9.6337	Cost: 6.82s
Train Epoch: 845 [61440/90000 (68%)]	Loss: 9.5407	Cost: 6.01s
Train Epoch: 845 [81920/90000 (91%)]	Loss: 9.7757	Cost: 7.10s
Train Epoch: 845 	Average Loss: 10.1738
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3037

Learning rate: 0.00019649707191301958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 846 [0/90000 (0%)]	Loss: 17.3600	Cost: 19.28s
Train Epoch: 846 [20480/90000 (23%)]	Loss: 9.6595	Cost: 6.10s
Train Epoch: 846 [40960/90000 (45%)]	Loss: 9.6518	Cost: 6.31s
Train Epoch: 846 [61440/90000 (68%)]	Loss: 9.8209	Cost: 5.80s
Train Epoch: 846 [81920/90000 (91%)]	Loss: 9.8996	Cost: 6.67s
Train Epoch: 846 	Average Loss: 10.2483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3626

Learning rate: 0.00019648882494407134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 847 [0/90000 (0%)]	Loss: 17.5128	Cost: 19.87s
Train Epoch: 847 [20480/90000 (23%)]	Loss: 9.5791	Cost: 6.14s
Train Epoch: 847 [40960/90000 (45%)]	Loss: 9.5408	Cost: 6.79s
Train Epoch: 847 [61440/90000 (68%)]	Loss: 9.5946	Cost: 6.02s
Train Epoch: 847 [81920/90000 (91%)]	Loss: 9.5702	Cost: 6.86s
Train Epoch: 847 	Average Loss: 10.2045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1904

Learning rate: 0.0001964805684520579
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 848 [0/90000 (0%)]	Loss: 17.7152	Cost: 19.95s
Train Epoch: 848 [20480/90000 (23%)]	Loss: 9.7738	Cost: 6.05s
Train Epoch: 848 [40960/90000 (45%)]	Loss: 9.7213	Cost: 6.64s
Train Epoch: 848 [61440/90000 (68%)]	Loss: 9.3795	Cost: 6.04s
Train Epoch: 848 [81920/90000 (91%)]	Loss: 9.8749	Cost: 5.92s
Train Epoch: 848 	Average Loss: 10.2253
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5211

Learning rate: 0.00019647230243779407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 849 [0/90000 (0%)]	Loss: 17.7033	Cost: 20.09s
Train Epoch: 849 [20480/90000 (23%)]	Loss: 9.7211	Cost: 6.18s
Train Epoch: 849 [40960/90000 (45%)]	Loss: 9.6943	Cost: 6.46s
Train Epoch: 849 [61440/90000 (68%)]	Loss: 9.7301	Cost: 6.06s
Train Epoch: 849 [81920/90000 (91%)]	Loss: 9.6954	Cost: 7.02s
Train Epoch: 849 	Average Loss: 10.3100
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3771

Learning rate: 0.00019646402690209574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 850 [0/90000 (0%)]	Loss: 17.5198	Cost: 20.19s
Train Epoch: 850 [20480/90000 (23%)]	Loss: 9.5145	Cost: 6.17s
Train Epoch: 850 [40960/90000 (45%)]	Loss: 9.4116	Cost: 7.74s
Train Epoch: 850 [61440/90000 (68%)]	Loss: 9.3444	Cost: 6.15s
Train Epoch: 850 [81920/90000 (91%)]	Loss: 9.4768	Cost: 6.59s
Train Epoch: 850 	Average Loss: 10.1242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3016

Learning rate: 0.0001964557418457796
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 851 [0/90000 (0%)]	Loss: 17.5934	Cost: 20.19s
Train Epoch: 851 [20480/90000 (23%)]	Loss: 9.3912	Cost: 6.10s
Train Epoch: 851 [40960/90000 (45%)]	Loss: 9.7604	Cost: 6.34s
Train Epoch: 851 [61440/90000 (68%)]	Loss: 9.5129	Cost: 5.98s
Train Epoch: 851 [81920/90000 (91%)]	Loss: 9.7229	Cost: 6.29s
Train Epoch: 851 	Average Loss: 10.1574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3859

Learning rate: 0.0001964474472696634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 852 [0/90000 (0%)]	Loss: 17.8447	Cost: 19.81s
Train Epoch: 852 [20480/90000 (23%)]	Loss: 9.3829	Cost: 6.31s
Train Epoch: 852 [40960/90000 (45%)]	Loss: 9.5328	Cost: 6.29s
Train Epoch: 852 [61440/90000 (68%)]	Loss: 9.2704	Cost: 6.04s
Train Epoch: 852 [81920/90000 (91%)]	Loss: 9.8334	Cost: 6.32s
Train Epoch: 852 	Average Loss: 10.1659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4289

Learning rate: 0.00019643914317456578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 853 [0/90000 (0%)]	Loss: 17.6851	Cost: 19.49s
Train Epoch: 853 [20480/90000 (23%)]	Loss: 9.8235	Cost: 6.22s
Train Epoch: 853 [40960/90000 (45%)]	Loss: 9.7381	Cost: 6.91s
Train Epoch: 853 [61440/90000 (68%)]	Loss: 9.5623	Cost: 6.05s
Train Epoch: 853 [81920/90000 (91%)]	Loss: 9.5049	Cost: 6.54s
Train Epoch: 853 	Average Loss: 10.2836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3002

Learning rate: 0.00019643082956130633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 854 [0/90000 (0%)]	Loss: 17.5537	Cost: 20.25s
Train Epoch: 854 [20480/90000 (23%)]	Loss: 9.4894	Cost: 6.38s
Train Epoch: 854 [40960/90000 (45%)]	Loss: 9.4778	Cost: 6.68s
Train Epoch: 854 [61440/90000 (68%)]	Loss: 9.4886	Cost: 6.01s
Train Epoch: 854 [81920/90000 (91%)]	Loss: 9.7188	Cost: 6.63s
Train Epoch: 854 	Average Loss: 10.1637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3627

Learning rate: 0.00019642250643070558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 855 [0/90000 (0%)]	Loss: 17.7111	Cost: 19.11s
Train Epoch: 855 [20480/90000 (23%)]	Loss: 9.4000	Cost: 6.97s
Train Epoch: 855 [40960/90000 (45%)]	Loss: 9.4027	Cost: 6.27s
Train Epoch: 855 [61440/90000 (68%)]	Loss: 9.1378	Cost: 6.01s
Train Epoch: 855 [81920/90000 (91%)]	Loss: 9.4340	Cost: 6.21s
Train Epoch: 855 	Average Loss: 10.0756
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4336

Learning rate: 0.00019641417378358494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 856 [0/90000 (0%)]	Loss: 17.5121	Cost: 19.43s
Train Epoch: 856 [20480/90000 (23%)]	Loss: 9.2724	Cost: 6.23s
Train Epoch: 856 [40960/90000 (45%)]	Loss: 9.2969	Cost: 7.01s
Train Epoch: 856 [61440/90000 (68%)]	Loss: 9.3861	Cost: 6.10s
Train Epoch: 856 [81920/90000 (91%)]	Loss: 9.4036	Cost: 7.19s
Train Epoch: 856 	Average Loss: 10.0486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4449

Learning rate: 0.00019640583162076685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 857 [0/90000 (0%)]	Loss: 17.5726	Cost: 18.68s
Train Epoch: 857 [20480/90000 (23%)]	Loss: 9.4313	Cost: 6.19s
Train Epoch: 857 [40960/90000 (45%)]	Loss: 9.7509	Cost: 6.41s
Train Epoch: 857 [61440/90000 (68%)]	Loss: 9.4871	Cost: 5.97s
Train Epoch: 857 [81920/90000 (91%)]	Loss: 9.7204	Cost: 6.60s
Train Epoch: 857 	Average Loss: 10.1413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4874

Learning rate: 0.00019639747994307463
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 858 [0/90000 (0%)]	Loss: 17.5831	Cost: 20.96s
Train Epoch: 858 [20480/90000 (23%)]	Loss: 9.5750	Cost: 6.14s
Train Epoch: 858 [40960/90000 (45%)]	Loss: 9.3224	Cost: 6.80s
Train Epoch: 858 [61440/90000 (68%)]	Loss: 9.5225	Cost: 6.02s
Train Epoch: 858 [81920/90000 (91%)]	Loss: 9.4565	Cost: 7.16s
Train Epoch: 858 	Average Loss: 10.1012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4151

Learning rate: 0.0001963891187513326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 859 [0/90000 (0%)]	Loss: 17.6253	Cost: 19.75s
Train Epoch: 859 [20480/90000 (23%)]	Loss: 9.4332	Cost: 7.61s
Train Epoch: 859 [40960/90000 (45%)]	Loss: 9.6007	Cost: 6.39s
Train Epoch: 859 [61440/90000 (68%)]	Loss: 9.4714	Cost: 5.76s
Train Epoch: 859 [81920/90000 (91%)]	Loss: 9.5691	Cost: 6.32s
Train Epoch: 859 	Average Loss: 10.1109
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4997

Learning rate: 0.0001963807480463659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 860 [0/90000 (0%)]	Loss: 17.4232	Cost: 19.36s
Train Epoch: 860 [20480/90000 (23%)]	Loss: 9.3277	Cost: 6.69s
Train Epoch: 860 [40960/90000 (45%)]	Loss: 9.4955	Cost: 7.20s
Train Epoch: 860 [61440/90000 (68%)]	Loss: 9.4602	Cost: 6.06s
Train Epoch: 860 [81920/90000 (91%)]	Loss: 9.4971	Cost: 7.46s
Train Epoch: 860 	Average Loss: 10.0336
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4067

Learning rate: 0.00019637236782900076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 861 [0/90000 (0%)]	Loss: 17.6475	Cost: 20.08s
Train Epoch: 861 [20480/90000 (23%)]	Loss: 9.3454	Cost: 6.98s
Train Epoch: 861 [40960/90000 (45%)]	Loss: 9.3192	Cost: 6.78s
Train Epoch: 861 [61440/90000 (68%)]	Loss: 9.2542	Cost: 6.13s
Train Epoch: 861 [81920/90000 (91%)]	Loss: 9.3065	Cost: 6.19s
Train Epoch: 861 	Average Loss: 9.9703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5853

Learning rate: 0.0001963639781000642
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 862 [0/90000 (0%)]	Loss: 17.7773	Cost: 21.33s
Train Epoch: 862 [20480/90000 (23%)]	Loss: 9.4491	Cost: 6.38s
Train Epoch: 862 [40960/90000 (45%)]	Loss: 9.4711	Cost: 6.94s
Train Epoch: 862 [61440/90000 (68%)]	Loss: 9.2552	Cost: 5.96s
Train Epoch: 862 [81920/90000 (91%)]	Loss: 9.3629	Cost: 7.11s
Train Epoch: 862 	Average Loss: 10.0227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4591

Learning rate: 0.00019635557886038432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 863 [0/90000 (0%)]	Loss: 17.5389	Cost: 21.60s
Train Epoch: 863 [20480/90000 (23%)]	Loss: 9.3598	Cost: 7.22s
Train Epoch: 863 [40960/90000 (45%)]	Loss: 9.2305	Cost: 6.15s
Train Epoch: 863 [61440/90000 (68%)]	Loss: 9.1146	Cost: 5.90s
Train Epoch: 863 [81920/90000 (91%)]	Loss: 9.3346	Cost: 6.73s
Train Epoch: 863 	Average Loss: 9.9339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5311

Learning rate: 0.00019634717011079007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 864 [0/90000 (0%)]	Loss: 17.6915	Cost: 23.67s
Train Epoch: 864 [20480/90000 (23%)]	Loss: 9.5582	Cost: 6.44s
Train Epoch: 864 [40960/90000 (45%)]	Loss: 9.4762	Cost: 6.40s
Train Epoch: 864 [61440/90000 (68%)]	Loss: 9.6246	Cost: 6.02s
Train Epoch: 864 [81920/90000 (91%)]	Loss: 9.7709	Cost: 6.28s
Train Epoch: 864 	Average Loss: 10.0522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5530

Learning rate: 0.00019633875185211136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 865 [0/90000 (0%)]	Loss: 17.7465	Cost: 23.48s
Train Epoch: 865 [20480/90000 (23%)]	Loss: 9.3926	Cost: 6.05s
Train Epoch: 865 [40960/90000 (45%)]	Loss: 9.5499	Cost: 6.59s
Train Epoch: 865 [61440/90000 (68%)]	Loss: 9.4298	Cost: 5.95s
Train Epoch: 865 [81920/90000 (91%)]	Loss: 9.5027	Cost: 6.18s
Train Epoch: 865 	Average Loss: 10.0874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4912

Learning rate: 0.00019633032408517903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 866 [0/90000 (0%)]	Loss: 17.9802	Cost: 25.13s
Train Epoch: 866 [20480/90000 (23%)]	Loss: 9.7106	Cost: 6.16s
Train Epoch: 866 [40960/90000 (45%)]	Loss: 9.8616	Cost: 6.11s
Train Epoch: 866 [61440/90000 (68%)]	Loss: 9.6715	Cost: 5.98s
Train Epoch: 866 [81920/90000 (91%)]	Loss: 9.5933	Cost: 6.36s
Train Epoch: 866 	Average Loss: 10.2916
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4794

Learning rate: 0.00019632188681082487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 867 [0/90000 (0%)]	Loss: 17.6795	Cost: 25.86s
Train Epoch: 867 [20480/90000 (23%)]	Loss: 9.5266	Cost: 6.11s
Train Epoch: 867 [40960/90000 (45%)]	Loss: 9.3688	Cost: 6.13s
Train Epoch: 867 [61440/90000 (68%)]	Loss: 9.5946	Cost: 6.20s
Train Epoch: 867 [81920/90000 (91%)]	Loss: 9.5961	Cost: 5.83s
Train Epoch: 867 	Average Loss: 10.1258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4452

Learning rate: 0.00019631344002988158
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 868 [0/90000 (0%)]	Loss: 17.7434	Cost: 23.59s
Train Epoch: 868 [20480/90000 (23%)]	Loss: 9.4729	Cost: 6.18s
Train Epoch: 868 [40960/90000 (45%)]	Loss: 9.6876	Cost: 6.34s
Train Epoch: 868 [61440/90000 (68%)]	Loss: 9.5296	Cost: 6.14s
Train Epoch: 868 [81920/90000 (91%)]	Loss: 9.6089	Cost: 5.88s
Train Epoch: 868 	Average Loss: 10.1108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5278

Learning rate: 0.00019630498374318287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 869 [0/90000 (0%)]	Loss: 17.7012	Cost: 22.68s
Train Epoch: 869 [20480/90000 (23%)]	Loss: 9.4212	Cost: 6.21s
Train Epoch: 869 [40960/90000 (45%)]	Loss: 9.4584	Cost: 6.31s
Train Epoch: 869 [61440/90000 (68%)]	Loss: 9.2993	Cost: 5.96s
Train Epoch: 869 [81920/90000 (91%)]	Loss: 9.3598	Cost: 5.95s
Train Epoch: 869 	Average Loss: 10.0774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6312

Learning rate: 0.00019629651795156333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 870 [0/90000 (0%)]	Loss: 17.5666	Cost: 24.22s
Train Epoch: 870 [20480/90000 (23%)]	Loss: 9.2149	Cost: 6.19s
Train Epoch: 870 [40960/90000 (45%)]	Loss: 9.2575	Cost: 6.25s
Train Epoch: 870 [61440/90000 (68%)]	Loss: 9.3026	Cost: 6.10s
Train Epoch: 870 [81920/90000 (91%)]	Loss: 9.2981	Cost: 6.23s
Train Epoch: 870 	Average Loss: 9.9759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4613

Learning rate: 0.00019628804265585853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 871 [0/90000 (0%)]	Loss: 17.6411	Cost: 22.94s
Train Epoch: 871 [20480/90000 (23%)]	Loss: 9.2909	Cost: 6.21s
Train Epoch: 871 [40960/90000 (45%)]	Loss: 9.1948	Cost: 6.10s
Train Epoch: 871 [61440/90000 (68%)]	Loss: 9.1198	Cost: 5.96s
Train Epoch: 871 [81920/90000 (91%)]	Loss: 9.3508	Cost: 5.92s
Train Epoch: 871 	Average Loss: 9.8355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6697

Learning rate: 0.00019627955785690487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 872 [0/90000 (0%)]	Loss: 17.8559	Cost: 24.98s
Train Epoch: 872 [20480/90000 (23%)]	Loss: 9.2116	Cost: 6.20s
Train Epoch: 872 [40960/90000 (45%)]	Loss: 9.3150	Cost: 6.24s
Train Epoch: 872 [61440/90000 (68%)]	Loss: 9.1166	Cost: 5.96s
Train Epoch: 872 [81920/90000 (91%)]	Loss: 9.4859	Cost: 5.91s
Train Epoch: 872 	Average Loss: 9.9074
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6572

Learning rate: 0.00019627106355553982
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 873 [0/90000 (0%)]	Loss: 17.8288	Cost: 23.51s
Train Epoch: 873 [20480/90000 (23%)]	Loss: 9.5357	Cost: 6.25s
Train Epoch: 873 [40960/90000 (45%)]	Loss: 9.2056	Cost: 6.33s
Train Epoch: 873 [61440/90000 (68%)]	Loss: 9.4014	Cost: 5.99s
Train Epoch: 873 [81920/90000 (91%)]	Loss: 9.5083	Cost: 5.90s
Train Epoch: 873 	Average Loss: 10.0005
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6127

Learning rate: 0.00019626255975260172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 874 [0/90000 (0%)]	Loss: 17.8945	Cost: 23.20s
Train Epoch: 874 [20480/90000 (23%)]	Loss: 9.2220	Cost: 6.32s
Train Epoch: 874 [40960/90000 (45%)]	Loss: 9.3265	Cost: 6.56s
Train Epoch: 874 [61440/90000 (68%)]	Loss: 9.4269	Cost: 6.02s
Train Epoch: 874 [81920/90000 (91%)]	Loss: 9.2705	Cost: 6.52s
Train Epoch: 874 	Average Loss: 9.9543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6461

Learning rate: 0.00019625404644892983
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 875 [0/90000 (0%)]	Loss: 17.9285	Cost: 21.98s
Train Epoch: 875 [20480/90000 (23%)]	Loss: 9.6528	Cost: 5.90s
Train Epoch: 875 [40960/90000 (45%)]	Loss: 9.5799	Cost: 6.81s
Train Epoch: 875 [61440/90000 (68%)]	Loss: 9.4399	Cost: 6.02s
Train Epoch: 875 [81920/90000 (91%)]	Loss: 9.3082	Cost: 6.79s
Train Epoch: 875 	Average Loss: 10.0190
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5277

Learning rate: 0.00019624552364536446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 876 [0/90000 (0%)]	Loss: 17.6280	Cost: 20.39s
Train Epoch: 876 [20480/90000 (23%)]	Loss: 9.1538	Cost: 6.08s
Train Epoch: 876 [40960/90000 (45%)]	Loss: 9.1904	Cost: 6.16s
Train Epoch: 876 [61440/90000 (68%)]	Loss: 9.0337	Cost: 6.02s
Train Epoch: 876 [81920/90000 (91%)]	Loss: 9.7038	Cost: 5.87s
Train Epoch: 876 	Average Loss: 9.9791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5034

Learning rate: 0.00019623699134274674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 877 [0/90000 (0%)]	Loss: 17.6994	Cost: 21.43s
Train Epoch: 877 [20480/90000 (23%)]	Loss: 9.5808	Cost: 6.10s
Train Epoch: 877 [40960/90000 (45%)]	Loss: 9.5285	Cost: 6.37s
Train Epoch: 877 [61440/90000 (68%)]	Loss: 9.4901	Cost: 5.99s
Train Epoch: 877 [81920/90000 (91%)]	Loss: 9.4958	Cost: 5.88s
Train Epoch: 877 	Average Loss: 10.0908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5726

Learning rate: 0.00019622844954191875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 878 [0/90000 (0%)]	Loss: 17.6688	Cost: 20.17s
Train Epoch: 878 [20480/90000 (23%)]	Loss: 9.1700	Cost: 6.18s
Train Epoch: 878 [40960/90000 (45%)]	Loss: 9.2876	Cost: 6.23s
Train Epoch: 878 [61440/90000 (68%)]	Loss: 9.2134	Cost: 5.94s
Train Epoch: 878 [81920/90000 (91%)]	Loss: 9.3245	Cost: 5.87s
Train Epoch: 878 	Average Loss: 9.9129
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6411

Learning rate: 0.00019621989824372354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 879 [0/90000 (0%)]	Loss: 17.9705	Cost: 21.31s
Train Epoch: 879 [20480/90000 (23%)]	Loss: 9.3476	Cost: 6.23s
Train Epoch: 879 [40960/90000 (45%)]	Loss: 9.2467	Cost: 6.73s
Train Epoch: 879 [61440/90000 (68%)]	Loss: 9.0466	Cost: 6.15s
Train Epoch: 879 [81920/90000 (91%)]	Loss: 9.3169	Cost: 6.60s
Train Epoch: 879 	Average Loss: 9.8543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5927

Learning rate: 0.0001962113374490051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 880 [0/90000 (0%)]	Loss: 17.8051	Cost: 21.30s
Train Epoch: 880 [20480/90000 (23%)]	Loss: 9.2877	Cost: 6.07s
Train Epoch: 880 [40960/90000 (45%)]	Loss: 9.2271	Cost: 6.73s
Train Epoch: 880 [61440/90000 (68%)]	Loss: 9.3425	Cost: 6.05s
Train Epoch: 880 [81920/90000 (91%)]	Loss: 9.2889	Cost: 6.82s
Train Epoch: 880 	Average Loss: 9.8539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6355

Learning rate: 0.00019620276715860832
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 881 [0/90000 (0%)]	Loss: 17.6053	Cost: 21.61s
Train Epoch: 881 [20480/90000 (23%)]	Loss: 9.1152	Cost: 6.07s
Train Epoch: 881 [40960/90000 (45%)]	Loss: 8.9766	Cost: 6.62s
Train Epoch: 881 [61440/90000 (68%)]	Loss: 9.3647	Cost: 6.03s
Train Epoch: 881 [81920/90000 (91%)]	Loss: 9.3041	Cost: 6.57s
Train Epoch: 881 	Average Loss: 9.7713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6560

Learning rate: 0.0001961941873733791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 882 [0/90000 (0%)]	Loss: 17.6595	Cost: 21.61s
Train Epoch: 882 [20480/90000 (23%)]	Loss: 9.2453	Cost: 6.04s
Train Epoch: 882 [40960/90000 (45%)]	Loss: 9.1719	Cost: 6.70s
Train Epoch: 882 [61440/90000 (68%)]	Loss: 9.0461	Cost: 5.95s
Train Epoch: 882 [81920/90000 (91%)]	Loss: 9.3285	Cost: 6.50s
Train Epoch: 882 	Average Loss: 9.7610
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5870

Learning rate: 0.0001961855980941642
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 883 [0/90000 (0%)]	Loss: 17.8487	Cost: 20.96s
Train Epoch: 883 [20480/90000 (23%)]	Loss: 9.1893	Cost: 6.05s
Train Epoch: 883 [40960/90000 (45%)]	Loss: 8.9658	Cost: 6.06s
Train Epoch: 883 [61440/90000 (68%)]	Loss: 9.1738	Cost: 5.94s
Train Epoch: 883 [81920/90000 (91%)]	Loss: 9.1105	Cost: 6.56s
Train Epoch: 883 	Average Loss: 9.8390
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6774

Learning rate: 0.0001961769993218114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 884 [0/90000 (0%)]	Loss: 17.9062	Cost: 20.26s
Train Epoch: 884 [20480/90000 (23%)]	Loss: 9.0189	Cost: 6.14s
Train Epoch: 884 [40960/90000 (45%)]	Loss: 9.1999	Cost: 6.24s
Train Epoch: 884 [61440/90000 (68%)]	Loss: 9.0017	Cost: 5.96s
Train Epoch: 884 [81920/90000 (91%)]	Loss: 9.0387	Cost: 6.86s
Train Epoch: 884 	Average Loss: 9.8240
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5988

Learning rate: 0.00019616839105716927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 885 [0/90000 (0%)]	Loss: 18.0214	Cost: 21.03s
Train Epoch: 885 [20480/90000 (23%)]	Loss: 8.9961	Cost: 6.05s
Train Epoch: 885 [40960/90000 (45%)]	Loss: 9.2106	Cost: 6.58s
Train Epoch: 885 [61440/90000 (68%)]	Loss: 9.1505	Cost: 6.00s
Train Epoch: 885 [81920/90000 (91%)]	Loss: 9.3341	Cost: 6.83s
Train Epoch: 885 	Average Loss: 9.7581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7235

Learning rate: 0.00019615977330108747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 886 [0/90000 (0%)]	Loss: 17.8344	Cost: 19.91s
Train Epoch: 886 [20480/90000 (23%)]	Loss: 9.2081	Cost: 6.12s
Train Epoch: 886 [40960/90000 (45%)]	Loss: 9.2786	Cost: 6.20s
Train Epoch: 886 [61440/90000 (68%)]	Loss: 9.1453	Cost: 6.20s
Train Epoch: 886 [81920/90000 (91%)]	Loss: 9.4822	Cost: 6.53s
Train Epoch: 886 	Average Loss: 9.8690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6132

Learning rate: 0.00019615114605441654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 887 [0/90000 (0%)]	Loss: 17.8685	Cost: 20.87s
Train Epoch: 887 [20480/90000 (23%)]	Loss: 9.2973	Cost: 6.24s
Train Epoch: 887 [40960/90000 (45%)]	Loss: 9.7724	Cost: 6.11s
Train Epoch: 887 [61440/90000 (68%)]	Loss: 9.3746	Cost: 6.08s
Train Epoch: 887 [81920/90000 (91%)]	Loss: 9.4695	Cost: 6.57s
Train Epoch: 887 	Average Loss: 10.0738
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6154

Learning rate: 0.00019614250931800791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 888 [0/90000 (0%)]	Loss: 17.6372	Cost: 20.19s
Train Epoch: 888 [20480/90000 (23%)]	Loss: 9.1745	Cost: 6.13s
Train Epoch: 888 [40960/90000 (45%)]	Loss: 9.2693	Cost: 6.18s
Train Epoch: 888 [61440/90000 (68%)]	Loss: 9.2138	Cost: 6.03s
Train Epoch: 888 [81920/90000 (91%)]	Loss: 9.0686	Cost: 6.67s
Train Epoch: 888 	Average Loss: 9.8639
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6040

Learning rate: 0.00019613386309271408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 889 [0/90000 (0%)]	Loss: 17.7757	Cost: 20.37s
Train Epoch: 889 [20480/90000 (23%)]	Loss: 8.8452	Cost: 6.05s
Train Epoch: 889 [40960/90000 (45%)]	Loss: 9.1259	Cost: 6.91s
Train Epoch: 889 [61440/90000 (68%)]	Loss: 9.0507	Cost: 6.12s
Train Epoch: 889 [81920/90000 (91%)]	Loss: 9.0224	Cost: 6.63s
Train Epoch: 889 	Average Loss: 9.6933
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6766

Learning rate: 0.0001961252073793883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 890 [0/90000 (0%)]	Loss: 17.9182	Cost: 20.16s
Train Epoch: 890 [20480/90000 (23%)]	Loss: 9.0137	Cost: 6.11s
Train Epoch: 890 [40960/90000 (45%)]	Loss: 9.2733	Cost: 6.09s
Train Epoch: 890 [61440/90000 (68%)]	Loss: 9.0010	Cost: 6.16s
Train Epoch: 890 [81920/90000 (91%)]	Loss: 9.2925	Cost: 5.95s
Train Epoch: 890 	Average Loss: 9.7910
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6828

Learning rate: 0.00019611654217888494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 891 [0/90000 (0%)]	Loss: 17.9970	Cost: 20.36s
Train Epoch: 891 [20480/90000 (23%)]	Loss: 9.0662	Cost: 6.16s
Train Epoch: 891 [40960/90000 (45%)]	Loss: 9.0196	Cost: 6.57s
Train Epoch: 891 [61440/90000 (68%)]	Loss: 9.0523	Cost: 6.08s
Train Epoch: 891 [81920/90000 (91%)]	Loss: 9.0300	Cost: 7.44s
Train Epoch: 891 	Average Loss: 9.7342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7500

Learning rate: 0.00019610786749205917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 892 [0/90000 (0%)]	Loss: 17.9417	Cost: 19.44s
Train Epoch: 892 [20480/90000 (23%)]	Loss: 8.9613	Cost: 6.15s
Train Epoch: 892 [40960/90000 (45%)]	Loss: 8.9163	Cost: 6.22s
Train Epoch: 892 [61440/90000 (68%)]	Loss: 8.9924	Cost: 6.21s
Train Epoch: 892 [81920/90000 (91%)]	Loss: 9.1377	Cost: 6.94s
Train Epoch: 892 	Average Loss: 9.6800
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7169

Learning rate: 0.00019609918331976714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 893 [0/90000 (0%)]	Loss: 18.0459	Cost: 20.38s
Train Epoch: 893 [20480/90000 (23%)]	Loss: 9.0021	Cost: 6.08s
Train Epoch: 893 [40960/90000 (45%)]	Loss: 9.1386	Cost: 6.78s
Train Epoch: 893 [61440/90000 (68%)]	Loss: 8.8613	Cost: 6.03s
Train Epoch: 893 [81920/90000 (91%)]	Loss: 9.2253	Cost: 6.81s
Train Epoch: 893 	Average Loss: 9.7161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6838

Learning rate: 0.00019609048966286597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 894 [0/90000 (0%)]	Loss: 17.5047	Cost: 20.12s
Train Epoch: 894 [20480/90000 (23%)]	Loss: 8.9970	Cost: 6.15s
Train Epoch: 894 [40960/90000 (45%)]	Loss: 9.1810	Cost: 6.47s
Train Epoch: 894 [61440/90000 (68%)]	Loss: 9.0902	Cost: 6.09s
Train Epoch: 894 [81920/90000 (91%)]	Loss: 9.3210	Cost: 6.43s
Train Epoch: 894 	Average Loss: 9.7958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6880

Learning rate: 0.0001960817865222137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 895 [0/90000 (0%)]	Loss: 17.9255	Cost: 19.02s
Train Epoch: 895 [20480/90000 (23%)]	Loss: 9.2667	Cost: 6.28s
Train Epoch: 895 [40960/90000 (45%)]	Loss: 9.3253	Cost: 6.43s
Train Epoch: 895 [61440/90000 (68%)]	Loss: 9.0517	Cost: 6.01s
Train Epoch: 895 [81920/90000 (91%)]	Loss: 9.1873	Cost: 6.52s
Train Epoch: 895 	Average Loss: 9.7246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7997

Learning rate: 0.00019607307389866925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 896 [0/90000 (0%)]	Loss: 18.0980	Cost: 20.65s
Train Epoch: 896 [20480/90000 (23%)]	Loss: 8.9212	Cost: 6.32s
Train Epoch: 896 [40960/90000 (45%)]	Loss: 8.8973	Cost: 6.43s
Train Epoch: 896 [61440/90000 (68%)]	Loss: 9.0602	Cost: 5.97s
Train Epoch: 896 [81920/90000 (91%)]	Loss: 8.9086	Cost: 6.60s
Train Epoch: 896 	Average Loss: 9.6402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6728

Learning rate: 0.00019606435179309254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 897 [0/90000 (0%)]	Loss: 18.2357	Cost: 20.15s
Train Epoch: 897 [20480/90000 (23%)]	Loss: 9.0330	Cost: 6.83s
Train Epoch: 897 [40960/90000 (45%)]	Loss: 9.2649	Cost: 6.12s
Train Epoch: 897 [61440/90000 (68%)]	Loss: 9.6041	Cost: 6.03s
Train Epoch: 897 [81920/90000 (91%)]	Loss: 9.6487	Cost: 6.26s
Train Epoch: 897 	Average Loss: 9.8901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6824

Learning rate: 0.00019605562020634444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 898 [0/90000 (0%)]	Loss: 18.0867	Cost: 20.80s
Train Epoch: 898 [20480/90000 (23%)]	Loss: 9.1787	Cost: 6.18s
Train Epoch: 898 [40960/90000 (45%)]	Loss: 9.1757	Cost: 6.93s
Train Epoch: 898 [61440/90000 (68%)]	Loss: 8.9228	Cost: 6.01s
Train Epoch: 898 [81920/90000 (91%)]	Loss: 9.1711	Cost: 6.98s
Train Epoch: 898 	Average Loss: 9.7999
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7277

Learning rate: 0.0001960468791392867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 899 [0/90000 (0%)]	Loss: 17.7765	Cost: 20.79s
Train Epoch: 899 [20480/90000 (23%)]	Loss: 9.0836	Cost: 6.57s
Train Epoch: 899 [40960/90000 (45%)]	Loss: 9.0778	Cost: 6.27s
Train Epoch: 899 [61440/90000 (68%)]	Loss: 9.2523	Cost: 6.07s
Train Epoch: 899 [81920/90000 (91%)]	Loss: 9.6224	Cost: 5.97s
Train Epoch: 899 	Average Loss: 9.7870
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6906

Learning rate: 0.000196038128592782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 900 [0/90000 (0%)]	Loss: 17.7672	Cost: 20.96s
Train Epoch: 900 [20480/90000 (23%)]	Loss: 9.4272	Cost: 6.30s
Train Epoch: 900 [40960/90000 (45%)]	Loss: 9.4149	Cost: 6.46s
Train Epoch: 900 [61440/90000 (68%)]	Loss: 9.2341	Cost: 5.99s
Train Epoch: 900 [81920/90000 (91%)]	Loss: 9.2568	Cost: 6.17s
Train Epoch: 900 	Average Loss: 9.8857
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7224

Learning rate: 0.00019602936856769404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 901 [0/90000 (0%)]	Loss: 18.0293	Cost: 21.56s
Train Epoch: 901 [20480/90000 (23%)]	Loss: 9.2714	Cost: 6.28s
Train Epoch: 901 [40960/90000 (45%)]	Loss: 9.0670	Cost: 6.35s
Train Epoch: 901 [61440/90000 (68%)]	Loss: 9.0607	Cost: 6.12s
Train Epoch: 901 [81920/90000 (91%)]	Loss: 9.4292	Cost: 5.97s
Train Epoch: 901 	Average Loss: 9.7848
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7277

Learning rate: 0.0001960205990648874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 902 [0/90000 (0%)]	Loss: 18.2614	Cost: 21.37s
Train Epoch: 902 [20480/90000 (23%)]	Loss: 8.6996	Cost: 6.73s
Train Epoch: 902 [40960/90000 (45%)]	Loss: 8.9307	Cost: 6.20s
Train Epoch: 902 [61440/90000 (68%)]	Loss: 9.0804	Cost: 5.97s
Train Epoch: 902 [81920/90000 (91%)]	Loss: 9.2158	Cost: 5.92s
Train Epoch: 902 	Average Loss: 9.6935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7749

Learning rate: 0.0001960118200852275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 903 [0/90000 (0%)]	Loss: 17.8259	Cost: 23.91s
Train Epoch: 903 [20480/90000 (23%)]	Loss: 9.2540	Cost: 6.10s
Train Epoch: 903 [40960/90000 (45%)]	Loss: 9.1044	Cost: 6.14s
Train Epoch: 903 [61440/90000 (68%)]	Loss: 9.2705	Cost: 6.04s
Train Epoch: 903 [81920/90000 (91%)]	Loss: 9.0929	Cost: 6.15s
Train Epoch: 903 	Average Loss: 9.8191
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7633

Learning rate: 0.00019600303162958089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 904 [0/90000 (0%)]	Loss: 18.1248	Cost: 23.02s
Train Epoch: 904 [20480/90000 (23%)]	Loss: 9.0994	Cost: 5.96s
Train Epoch: 904 [40960/90000 (45%)]	Loss: 9.2256	Cost: 6.69s
Train Epoch: 904 [61440/90000 (68%)]	Loss: 8.8569	Cost: 6.00s
Train Epoch: 904 [81920/90000 (91%)]	Loss: 9.0677	Cost: 5.93s
Train Epoch: 904 	Average Loss: 9.6880
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6994

Learning rate: 0.00019599423369881492
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 905 [0/90000 (0%)]	Loss: 17.8763	Cost: 25.86s
Train Epoch: 905 [20480/90000 (23%)]	Loss: 8.8810	Cost: 6.13s
Train Epoch: 905 [40960/90000 (45%)]	Loss: 9.0968	Cost: 6.24s
Train Epoch: 905 [61440/90000 (68%)]	Loss: 9.1370	Cost: 5.96s
Train Epoch: 905 [81920/90000 (91%)]	Loss: 9.0993	Cost: 5.84s
Train Epoch: 905 	Average Loss: 9.6081
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8248

Learning rate: 0.0001959854262937979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 906 [0/90000 (0%)]	Loss: 18.0676	Cost: 25.39s
Train Epoch: 906 [20480/90000 (23%)]	Loss: 8.8544	Cost: 6.06s
Train Epoch: 906 [40960/90000 (45%)]	Loss: 8.7235	Cost: 6.30s
Train Epoch: 906 [61440/90000 (68%)]	Loss: 8.7149	Cost: 5.90s
Train Epoch: 906 [81920/90000 (91%)]	Loss: 8.9702	Cost: 5.71s
Train Epoch: 906 	Average Loss: 9.5741
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7923

Learning rate: 0.0001959766094153991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 907 [0/90000 (0%)]	Loss: 18.0953	Cost: 24.55s
Train Epoch: 907 [20480/90000 (23%)]	Loss: 8.5189	Cost: 6.41s
Train Epoch: 907 [40960/90000 (45%)]	Loss: 8.5426	Cost: 6.37s
Train Epoch: 907 [61440/90000 (68%)]	Loss: 8.9387	Cost: 5.97s
Train Epoch: 907 [81920/90000 (91%)]	Loss: 9.1140	Cost: 5.93s
Train Epoch: 907 	Average Loss: 9.5283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8493

Learning rate: 0.00019596778306448873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 908 [0/90000 (0%)]	Loss: 17.9857	Cost: 27.20s
Train Epoch: 908 [20480/90000 (23%)]	Loss: 8.7697	Cost: 6.08s
Train Epoch: 908 [40960/90000 (45%)]	Loss: 8.9261	Cost: 6.08s
Train Epoch: 908 [61440/90000 (68%)]	Loss: 8.8665	Cost: 5.95s
Train Epoch: 908 [81920/90000 (91%)]	Loss: 8.9761	Cost: 6.81s
Train Epoch: 908 	Average Loss: 9.6086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8171

Learning rate: 0.0001959589472419379
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 909 [0/90000 (0%)]	Loss: 17.8646	Cost: 25.70s
Train Epoch: 909 [20480/90000 (23%)]	Loss: 8.8813	Cost: 6.05s
Train Epoch: 909 [40960/90000 (45%)]	Loss: 8.9024	Cost: 6.15s
Train Epoch: 909 [61440/90000 (68%)]	Loss: 8.8380	Cost: 5.93s
Train Epoch: 909 [81920/90000 (91%)]	Loss: 9.0453	Cost: 5.98s
Train Epoch: 909 	Average Loss: 9.6133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7361

Learning rate: 0.00019595010194861865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 910 [0/90000 (0%)]	Loss: 18.0446	Cost: 23.43s
Train Epoch: 910 [20480/90000 (23%)]	Loss: 8.8550	Cost: 6.14s
Train Epoch: 910 [40960/90000 (45%)]	Loss: 8.7655	Cost: 6.20s
Train Epoch: 910 [61440/90000 (68%)]	Loss: 8.8879	Cost: 6.11s
Train Epoch: 910 [81920/90000 (91%)]	Loss: 9.0377	Cost: 6.07s
Train Epoch: 910 	Average Loss: 9.5146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7981

Learning rate: 0.00019594124718540402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 911 [0/90000 (0%)]	Loss: 17.8860	Cost: 22.03s
Train Epoch: 911 [20480/90000 (23%)]	Loss: 8.7094	Cost: 6.23s
Train Epoch: 911 [40960/90000 (45%)]	Loss: 8.8678	Cost: 6.13s
Train Epoch: 911 [61440/90000 (68%)]	Loss: 8.7881	Cost: 5.97s
Train Epoch: 911 [81920/90000 (91%)]	Loss: 8.9381	Cost: 5.90s
Train Epoch: 911 	Average Loss: 9.5195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8687

Learning rate: 0.00019593238295316788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 912 [0/90000 (0%)]	Loss: 18.3247	Cost: 22.64s
Train Epoch: 912 [20480/90000 (23%)]	Loss: 9.0183	Cost: 6.19s
Train Epoch: 912 [40960/90000 (45%)]	Loss: 8.9122	Cost: 6.10s
Train Epoch: 912 [61440/90000 (68%)]	Loss: 8.7215	Cost: 5.98s
Train Epoch: 912 [81920/90000 (91%)]	Loss: 9.0429	Cost: 6.28s
Train Epoch: 912 	Average Loss: 9.5757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8603

Learning rate: 0.00019592350925278515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 913 [0/90000 (0%)]	Loss: 17.8675	Cost: 22.46s
Train Epoch: 913 [20480/90000 (23%)]	Loss: 8.9966	Cost: 6.22s
Train Epoch: 913 [40960/90000 (45%)]	Loss: 8.8205	Cost: 6.18s
Train Epoch: 913 [61440/90000 (68%)]	Loss: 8.9700	Cost: 5.99s
Train Epoch: 913 [81920/90000 (91%)]	Loss: 9.1127	Cost: 5.94s
Train Epoch: 913 	Average Loss: 9.5606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6752

Learning rate: 0.0001959146260851316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 914 [0/90000 (0%)]	Loss: 18.2367	Cost: 22.77s
Train Epoch: 914 [20480/90000 (23%)]	Loss: 8.7015	Cost: 6.10s
Train Epoch: 914 [40960/90000 (45%)]	Loss: 8.6587	Cost: 6.11s
Train Epoch: 914 [61440/90000 (68%)]	Loss: 8.9668	Cost: 6.11s
Train Epoch: 914 [81920/90000 (91%)]	Loss: 9.2629	Cost: 5.86s
Train Epoch: 914 	Average Loss: 9.6069
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8172

Learning rate: 0.00019590573345108395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 915 [0/90000 (0%)]	Loss: 18.2206	Cost: 21.25s
Train Epoch: 915 [20480/90000 (23%)]	Loss: 9.0869	Cost: 6.01s
Train Epoch: 915 [40960/90000 (45%)]	Loss: 9.0633	Cost: 6.10s
Train Epoch: 915 [61440/90000 (68%)]	Loss: 8.9127	Cost: 5.96s
Train Epoch: 915 [81920/90000 (91%)]	Loss: 9.1989	Cost: 6.00s
Train Epoch: 915 	Average Loss: 9.7264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8687

Learning rate: 0.00019589683135151992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 916 [0/90000 (0%)]	Loss: 17.9912	Cost: 20.48s
Train Epoch: 916 [20480/90000 (23%)]	Loss: 8.8886	Cost: 6.05s
Train Epoch: 916 [40960/90000 (45%)]	Loss: 9.1228	Cost: 6.22s
Train Epoch: 916 [61440/90000 (68%)]	Loss: 9.0107	Cost: 6.04s
Train Epoch: 916 [81920/90000 (91%)]	Loss: 8.9809	Cost: 6.12s
Train Epoch: 916 	Average Loss: 9.6980
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8351

Learning rate: 0.00019588791978731806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 917 [0/90000 (0%)]	Loss: 17.9450	Cost: 20.93s
Train Epoch: 917 [20480/90000 (23%)]	Loss: 8.9886	Cost: 6.08s
Train Epoch: 917 [40960/90000 (45%)]	Loss: 8.8913	Cost: 6.23s
Train Epoch: 917 [61440/90000 (68%)]	Loss: 8.7550	Cost: 5.99s
Train Epoch: 917 [81920/90000 (91%)]	Loss: 8.7979	Cost: 6.01s
Train Epoch: 917 	Average Loss: 9.5561
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8646

Learning rate: 0.00019587899875935793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 918 [0/90000 (0%)]	Loss: 18.0519	Cost: 20.73s
Train Epoch: 918 [20480/90000 (23%)]	Loss: 8.6236	Cost: 6.13s
Train Epoch: 918 [40960/90000 (45%)]	Loss: 8.9362	Cost: 6.45s
Train Epoch: 918 [61440/90000 (68%)]	Loss: 8.5713	Cost: 6.01s
Train Epoch: 918 [81920/90000 (91%)]	Loss: 9.1345	Cost: 6.22s
Train Epoch: 918 	Average Loss: 9.4488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8196

Learning rate: 0.00019587006826851997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 919 [0/90000 (0%)]	Loss: 18.2435	Cost: 20.50s
Train Epoch: 919 [20480/90000 (23%)]	Loss: 9.0629	Cost: 6.23s
Train Epoch: 919 [40960/90000 (45%)]	Loss: 8.7672	Cost: 7.71s
Train Epoch: 919 [61440/90000 (68%)]	Loss: 8.7157	Cost: 5.91s
Train Epoch: 919 [81920/90000 (91%)]	Loss: 8.9229	Cost: 6.58s
Train Epoch: 919 	Average Loss: 9.4949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9812

Learning rate: 0.00019586112831568563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 920 [0/90000 (0%)]	Loss: 18.0536	Cost: 21.29s
Train Epoch: 920 [20480/90000 (23%)]	Loss: 8.9087	Cost: 6.18s
Train Epoch: 920 [40960/90000 (45%)]	Loss: 8.9338	Cost: 6.67s
Train Epoch: 920 [61440/90000 (68%)]	Loss: 8.9850	Cost: 5.98s
Train Epoch: 920 [81920/90000 (91%)]	Loss: 8.9048	Cost: 6.65s
Train Epoch: 920 	Average Loss: 9.5358
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9233

Learning rate: 0.00019585217890173725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 921 [0/90000 (0%)]	Loss: 18.3248	Cost: 20.01s
Train Epoch: 921 [20480/90000 (23%)]	Loss: 8.6266	Cost: 6.33s
Train Epoch: 921 [40960/90000 (45%)]	Loss: 8.8491	Cost: 6.87s
Train Epoch: 921 [61440/90000 (68%)]	Loss: 8.7542	Cost: 6.15s
Train Epoch: 921 [81920/90000 (91%)]	Loss: 8.9378	Cost: 6.17s
Train Epoch: 921 	Average Loss: 9.4301
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8694

Learning rate: 0.0001958432200275581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 922 [0/90000 (0%)]	Loss: 18.0484	Cost: 20.32s
Train Epoch: 922 [20480/90000 (23%)]	Loss: 8.8683	Cost: 6.01s
Train Epoch: 922 [40960/90000 (45%)]	Loss: 8.9672	Cost: 6.91s
Train Epoch: 922 [61440/90000 (68%)]	Loss: 8.8629	Cost: 6.01s
Train Epoch: 922 [81920/90000 (91%)]	Loss: 9.0877	Cost: 6.59s
Train Epoch: 922 	Average Loss: 9.5712
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8866

Learning rate: 0.00019583425169403235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 923 [0/90000 (0%)]	Loss: 18.2190	Cost: 20.30s
Train Epoch: 923 [20480/90000 (23%)]	Loss: 9.0455	Cost: 6.47s
Train Epoch: 923 [40960/90000 (45%)]	Loss: 8.9612	Cost: 6.18s
Train Epoch: 923 [61440/90000 (68%)]	Loss: 8.8294	Cost: 5.99s
Train Epoch: 923 [81920/90000 (91%)]	Loss: 8.9954	Cost: 6.22s
Train Epoch: 923 	Average Loss: 9.6250
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9427

Learning rate: 0.00019582527390204514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 924 [0/90000 (0%)]	Loss: 18.1283	Cost: 20.62s
Train Epoch: 924 [20480/90000 (23%)]	Loss: 8.8465	Cost: 6.36s
Train Epoch: 924 [40960/90000 (45%)]	Loss: 8.9850	Cost: 6.16s
Train Epoch: 924 [61440/90000 (68%)]	Loss: 8.8108	Cost: 6.03s
Train Epoch: 924 [81920/90000 (91%)]	Loss: 8.9752	Cost: 5.94s
Train Epoch: 924 	Average Loss: 9.5620
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8801

Learning rate: 0.00019581628665248256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 925 [0/90000 (0%)]	Loss: 18.0045	Cost: 20.71s
Train Epoch: 925 [20480/90000 (23%)]	Loss: 8.7203	Cost: 6.21s
Train Epoch: 925 [40960/90000 (45%)]	Loss: 8.9276	Cost: 6.18s
Train Epoch: 925 [61440/90000 (68%)]	Loss: 8.7911	Cost: 5.97s
Train Epoch: 925 [81920/90000 (91%)]	Loss: 9.0749	Cost: 5.97s
Train Epoch: 925 	Average Loss: 9.5853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8710

Learning rate: 0.00019580728994623165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 926 [0/90000 (0%)]	Loss: 18.1413	Cost: 21.10s
Train Epoch: 926 [20480/90000 (23%)]	Loss: 8.9851	Cost: 6.19s
Train Epoch: 926 [40960/90000 (45%)]	Loss: 8.7765	Cost: 6.19s
Train Epoch: 926 [61440/90000 (68%)]	Loss: 8.5847	Cost: 5.93s
Train Epoch: 926 [81920/90000 (91%)]	Loss: 8.6953	Cost: 6.36s
Train Epoch: 926 	Average Loss: 9.4434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9463

Learning rate: 0.00019579828378418028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 927 [0/90000 (0%)]	Loss: 18.2071	Cost: 20.93s
Train Epoch: 927 [20480/90000 (23%)]	Loss: 8.4511	Cost: 6.03s
Train Epoch: 927 [40960/90000 (45%)]	Loss: 8.8167	Cost: 6.25s
Train Epoch: 927 [61440/90000 (68%)]	Loss: 8.6925	Cost: 5.97s
Train Epoch: 927 [81920/90000 (91%)]	Loss: 8.9070	Cost: 6.24s
Train Epoch: 927 	Average Loss: 9.3452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9516

Learning rate: 0.00019578926816721736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 928 [0/90000 (0%)]	Loss: 18.0461	Cost: 20.90s
Train Epoch: 928 [20480/90000 (23%)]	Loss: 8.4989	Cost: 6.09s
Train Epoch: 928 [40960/90000 (45%)]	Loss: 8.7114	Cost: 6.45s
Train Epoch: 928 [61440/90000 (68%)]	Loss: 8.4772	Cost: 6.13s
Train Epoch: 928 [81920/90000 (91%)]	Loss: 8.5803	Cost: 6.06s
Train Epoch: 928 	Average Loss: 9.3068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9849

Learning rate: 0.00019578024309623268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 929 [0/90000 (0%)]	Loss: 18.2891	Cost: 20.82s
Train Epoch: 929 [20480/90000 (23%)]	Loss: 8.4530	Cost: 6.21s
Train Epoch: 929 [40960/90000 (45%)]	Loss: 8.7992	Cost: 6.51s
Train Epoch: 929 [61440/90000 (68%)]	Loss: 8.3478	Cost: 5.99s
Train Epoch: 929 [81920/90000 (91%)]	Loss: 8.7306	Cost: 6.53s
Train Epoch: 929 	Average Loss: 9.3030
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8711

Learning rate: 0.00019577120857211698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 930 [0/90000 (0%)]	Loss: 18.1674	Cost: 21.32s
Train Epoch: 930 [20480/90000 (23%)]	Loss: 8.3992	Cost: 6.15s
Train Epoch: 930 [40960/90000 (45%)]	Loss: 8.5613	Cost: 6.09s
Train Epoch: 930 [61440/90000 (68%)]	Loss: 8.8227	Cost: 5.96s
Train Epoch: 930 [81920/90000 (91%)]	Loss: 8.8763	Cost: 6.72s
Train Epoch: 930 	Average Loss: 9.3488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9437

Learning rate: 0.00019576216459576195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 931 [0/90000 (0%)]	Loss: 18.1936	Cost: 20.65s
Train Epoch: 931 [20480/90000 (23%)]	Loss: 8.5165	Cost: 6.17s
Train Epoch: 931 [40960/90000 (45%)]	Loss: 8.3336	Cost: 7.01s
Train Epoch: 931 [61440/90000 (68%)]	Loss: 8.3780	Cost: 6.02s
Train Epoch: 931 [81920/90000 (91%)]	Loss: 8.4638	Cost: 7.21s
Train Epoch: 931 	Average Loss: 9.2440
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9289

Learning rate: 0.0001957531111680602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 932 [0/90000 (0%)]	Loss: 18.3720	Cost: 20.00s
Train Epoch: 932 [20480/90000 (23%)]	Loss: 8.6989	Cost: 6.06s
Train Epoch: 932 [40960/90000 (45%)]	Loss: 8.8974	Cost: 6.50s
Train Epoch: 932 [61440/90000 (68%)]	Loss: 8.7035	Cost: 6.23s
Train Epoch: 932 [81920/90000 (91%)]	Loss: 9.1675	Cost: 6.57s
Train Epoch: 932 	Average Loss: 9.5397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8611

Learning rate: 0.00019574404828990522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 933 [0/90000 (0%)]	Loss: 18.0011	Cost: 19.60s
Train Epoch: 933 [20480/90000 (23%)]	Loss: 9.1079	Cost: 5.97s
Train Epoch: 933 [40960/90000 (45%)]	Loss: 9.1893	Cost: 6.18s
Train Epoch: 933 [61440/90000 (68%)]	Loss: 8.7439	Cost: 6.07s
Train Epoch: 933 [81920/90000 (91%)]	Loss: 9.0661	Cost: 6.70s
Train Epoch: 933 	Average Loss: 9.6761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8241

Learning rate: 0.00019573497596219155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 934 [0/90000 (0%)]	Loss: 17.9954	Cost: 20.38s
Train Epoch: 934 [20480/90000 (23%)]	Loss: 8.8224	Cost: 6.03s
Train Epoch: 934 [40960/90000 (45%)]	Loss: 8.8024	Cost: 6.15s
Train Epoch: 934 [61440/90000 (68%)]	Loss: 8.8033	Cost: 6.06s
Train Epoch: 934 [81920/90000 (91%)]	Loss: 8.9832	Cost: 7.10s
Train Epoch: 934 	Average Loss: 9.4777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8906

Learning rate: 0.00019572589418581453
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 935 [0/90000 (0%)]	Loss: 18.1029	Cost: 20.47s
Train Epoch: 935 [20480/90000 (23%)]	Loss: 8.6344	Cost: 6.08s
Train Epoch: 935 [40960/90000 (45%)]	Loss: 8.6441	Cost: 6.89s
Train Epoch: 935 [61440/90000 (68%)]	Loss: 8.4053	Cost: 6.00s
Train Epoch: 935 [81920/90000 (91%)]	Loss: 8.7411	Cost: 7.46s
Train Epoch: 935 	Average Loss: 9.3346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9333

Learning rate: 0.00019571680296167054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 936 [0/90000 (0%)]	Loss: 18.1376	Cost: 20.71s
Train Epoch: 936 [20480/90000 (23%)]	Loss: 8.3690	Cost: 6.14s
Train Epoch: 936 [40960/90000 (45%)]	Loss: 8.4995	Cost: 6.04s
Train Epoch: 936 [61440/90000 (68%)]	Loss: 8.4039	Cost: 5.98s
Train Epoch: 936 [81920/90000 (91%)]	Loss: 8.6722	Cost: 6.40s
Train Epoch: 936 	Average Loss: 9.2208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9426

Learning rate: 0.00019570770229065682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 937 [0/90000 (0%)]	Loss: 18.0218	Cost: 21.82s
Train Epoch: 937 [20480/90000 (23%)]	Loss: 8.4770	Cost: 6.03s
Train Epoch: 937 [40960/90000 (45%)]	Loss: 8.4270	Cost: 6.29s
Train Epoch: 937 [61440/90000 (68%)]	Loss: 8.4753	Cost: 6.00s
Train Epoch: 937 [81920/90000 (91%)]	Loss: 8.6455	Cost: 7.25s
Train Epoch: 937 	Average Loss: 9.1554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9450

Learning rate: 0.0001956985921736716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 938 [0/90000 (0%)]	Loss: 18.3911	Cost: 20.01s
Train Epoch: 938 [20480/90000 (23%)]	Loss: 8.4899	Cost: 6.09s
Train Epoch: 938 [40960/90000 (45%)]	Loss: 8.6761	Cost: 6.02s
Train Epoch: 938 [61440/90000 (68%)]	Loss: 8.2889	Cost: 6.18s
Train Epoch: 938 [81920/90000 (91%)]	Loss: 8.6863	Cost: 6.21s
Train Epoch: 938 	Average Loss: 9.1868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0281

Learning rate: 0.00019568947261161396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 939 [0/90000 (0%)]	Loss: 18.1495	Cost: 20.55s
Train Epoch: 939 [20480/90000 (23%)]	Loss: 8.3536	Cost: 6.10s
Train Epoch: 939 [40960/90000 (45%)]	Loss: 8.6557	Cost: 6.39s
Train Epoch: 939 [61440/90000 (68%)]	Loss: 8.7707	Cost: 6.02s
Train Epoch: 939 [81920/90000 (91%)]	Loss: 9.2643	Cost: 6.36s
Train Epoch: 939 	Average Loss: 9.4810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0607

Learning rate: 0.00019568034360538402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 940 [0/90000 (0%)]	Loss: 18.1590	Cost: 21.39s
Train Epoch: 940 [20480/90000 (23%)]	Loss: 9.0382	Cost: 6.07s
Train Epoch: 940 [40960/90000 (45%)]	Loss: 9.1092	Cost: 6.47s
Train Epoch: 940 [61440/90000 (68%)]	Loss: 8.8126	Cost: 5.92s
Train Epoch: 940 [81920/90000 (91%)]	Loss: 8.7417	Cost: 6.35s
Train Epoch: 940 	Average Loss: 9.6402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8986

Learning rate: 0.00019567120515588275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 941 [0/90000 (0%)]	Loss: 18.0578	Cost: 21.62s
Train Epoch: 941 [20480/90000 (23%)]	Loss: 8.6479	Cost: 6.07s
Train Epoch: 941 [40960/90000 (45%)]	Loss: 8.5706	Cost: 6.61s
Train Epoch: 941 [61440/90000 (68%)]	Loss: 8.3097	Cost: 6.02s
Train Epoch: 941 [81920/90000 (91%)]	Loss: 8.7175	Cost: 5.96s
Train Epoch: 941 	Average Loss: 9.2920
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9899

Learning rate: 0.0001956620572640121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 942 [0/90000 (0%)]	Loss: 18.0011	Cost: 20.84s
Train Epoch: 942 [20480/90000 (23%)]	Loss: 8.3128	Cost: 6.18s
Train Epoch: 942 [40960/90000 (45%)]	Loss: 8.2942	Cost: 6.08s
Train Epoch: 942 [61440/90000 (68%)]	Loss: 8.3067	Cost: 6.05s
Train Epoch: 942 [81920/90000 (91%)]	Loss: 9.1123	Cost: 5.94s
Train Epoch: 942 	Average Loss: 9.2483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9970

Learning rate: 0.0001956528999306749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 943 [0/90000 (0%)]	Loss: 18.3193	Cost: 20.91s
Train Epoch: 943 [20480/90000 (23%)]	Loss: 9.3336	Cost: 6.00s
Train Epoch: 943 [40960/90000 (45%)]	Loss: 9.5251	Cost: 6.33s
Train Epoch: 943 [61440/90000 (68%)]	Loss: 9.1707	Cost: 6.07s
Train Epoch: 943 [81920/90000 (91%)]	Loss: 8.8689	Cost: 6.12s
Train Epoch: 943 	Average Loss: 9.8359
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9892

Learning rate: 0.00019564373315677494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 944 [0/90000 (0%)]	Loss: 18.1851	Cost: 21.17s
Train Epoch: 944 [20480/90000 (23%)]	Loss: 8.8823	Cost: 6.01s
Train Epoch: 944 [40960/90000 (45%)]	Loss: 8.5068	Cost: 7.05s
Train Epoch: 944 [61440/90000 (68%)]	Loss: 8.3503	Cost: 6.04s
Train Epoch: 944 [81920/90000 (91%)]	Loss: 8.4452	Cost: 6.41s
Train Epoch: 944 	Average Loss: 9.4036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9587

Learning rate: 0.00019563455694321697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 945 [0/90000 (0%)]	Loss: 18.1447	Cost: 20.87s
Train Epoch: 945 [20480/90000 (23%)]	Loss: 8.5805	Cost: 6.10s
Train Epoch: 945 [40960/90000 (45%)]	Loss: 8.5823	Cost: 6.77s
Train Epoch: 945 [61440/90000 (68%)]	Loss: 8.5455	Cost: 5.95s
Train Epoch: 945 [81920/90000 (91%)]	Loss: 8.5610	Cost: 6.58s
Train Epoch: 945 	Average Loss: 9.2815
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0349

Learning rate: 0.00019562537129090663
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 946 [0/90000 (0%)]	Loss: 18.3015	Cost: 21.39s
Train Epoch: 946 [20480/90000 (23%)]	Loss: 8.5946	Cost: 6.11s
Train Epoch: 946 [40960/90000 (45%)]	Loss: 8.6697	Cost: 6.16s
Train Epoch: 946 [61440/90000 (68%)]	Loss: 8.4263	Cost: 6.03s
Train Epoch: 946 [81920/90000 (91%)]	Loss: 8.7315	Cost: 6.09s
Train Epoch: 946 	Average Loss: 9.2711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9367

Learning rate: 0.00019561617620075054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 947 [0/90000 (0%)]	Loss: 17.9833	Cost: 20.53s
Train Epoch: 947 [20480/90000 (23%)]	Loss: 8.5297	Cost: 6.01s
Train Epoch: 947 [40960/90000 (45%)]	Loss: 8.6262	Cost: 6.11s
Train Epoch: 947 [61440/90000 (68%)]	Loss: 8.3327	Cost: 5.94s
Train Epoch: 947 [81920/90000 (91%)]	Loss: 8.5003	Cost: 6.05s
Train Epoch: 947 	Average Loss: 9.2691
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9981

Learning rate: 0.00019560697167365617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 948 [0/90000 (0%)]	Loss: 18.0902	Cost: 21.35s
Train Epoch: 948 [20480/90000 (23%)]	Loss: 8.3644	Cost: 6.08s
Train Epoch: 948 [40960/90000 (45%)]	Loss: 8.4773	Cost: 6.06s
Train Epoch: 948 [61440/90000 (68%)]	Loss: 8.5072	Cost: 5.77s
Train Epoch: 948 [81920/90000 (91%)]	Loss: 8.4620	Cost: 6.46s
Train Epoch: 948 	Average Loss: 9.1885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1147

Learning rate: 0.00019559775771053198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 949 [0/90000 (0%)]	Loss: 18.1241	Cost: 20.99s
Train Epoch: 949 [20480/90000 (23%)]	Loss: 8.7435	Cost: 5.98s
Train Epoch: 949 [40960/90000 (45%)]	Loss: 8.5610	Cost: 6.37s
Train Epoch: 949 [61440/90000 (68%)]	Loss: 8.5164	Cost: 5.94s
Train Epoch: 949 [81920/90000 (91%)]	Loss: 8.5626	Cost: 6.47s
Train Epoch: 949 	Average Loss: 9.3011
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1271

Learning rate: 0.0001955885343122874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 950 [0/90000 (0%)]	Loss: 18.0547	Cost: 19.94s
Train Epoch: 950 [20480/90000 (23%)]	Loss: 8.5657	Cost: 6.18s
Train Epoch: 950 [40960/90000 (45%)]	Loss: 8.6509	Cost: 6.10s
Train Epoch: 950 [61440/90000 (68%)]	Loss: 8.4504	Cost: 5.98s
Train Epoch: 950 [81920/90000 (91%)]	Loss: 8.5453	Cost: 6.17s
Train Epoch: 950 	Average Loss: 9.2194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1119

Learning rate: 0.0001955793014798327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 951 [0/90000 (0%)]	Loss: 18.6154	Cost: 20.79s
Train Epoch: 951 [20480/90000 (23%)]	Loss: 8.5245	Cost: 6.17s
Train Epoch: 951 [40960/90000 (45%)]	Loss: 8.5815	Cost: 6.09s
Train Epoch: 951 [61440/90000 (68%)]	Loss: 8.5614	Cost: 5.93s
Train Epoch: 951 [81920/90000 (91%)]	Loss: 8.5673	Cost: 6.04s
Train Epoch: 951 	Average Loss: 9.2448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1514

Learning rate: 0.00019557005921407914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 952 [0/90000 (0%)]	Loss: 18.3845	Cost: 22.32s
Train Epoch: 952 [20480/90000 (23%)]	Loss: 8.1426	Cost: 5.99s
Train Epoch: 952 [40960/90000 (45%)]	Loss: 8.2090	Cost: 6.24s
Train Epoch: 952 [61440/90000 (68%)]	Loss: 8.5177	Cost: 6.04s
Train Epoch: 952 [81920/90000 (91%)]	Loss: 8.3141	Cost: 6.38s
Train Epoch: 952 	Average Loss: 9.1271
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0754

Learning rate: 0.0001955608075159389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 953 [0/90000 (0%)]	Loss: 18.2028	Cost: 20.50s
Train Epoch: 953 [20480/90000 (23%)]	Loss: 8.4202	Cost: 6.13s
Train Epoch: 953 [40960/90000 (45%)]	Loss: 8.4091	Cost: 6.04s
Train Epoch: 953 [61440/90000 (68%)]	Loss: 8.1733	Cost: 6.00s
Train Epoch: 953 [81920/90000 (91%)]	Loss: 8.4729	Cost: 5.99s
Train Epoch: 953 	Average Loss: 9.1039
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1018

Learning rate: 0.00019555154638632502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 954 [0/90000 (0%)]	Loss: 18.3976	Cost: 22.86s
Train Epoch: 954 [20480/90000 (23%)]	Loss: 8.4312	Cost: 6.08s
Train Epoch: 954 [40960/90000 (45%)]	Loss: 8.1955	Cost: 6.43s
Train Epoch: 954 [61440/90000 (68%)]	Loss: 8.6008	Cost: 6.11s
Train Epoch: 954 [81920/90000 (91%)]	Loss: 8.7446	Cost: 6.67s
Train Epoch: 954 	Average Loss: 9.1896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0814

Learning rate: 0.00019554227582615162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 955 [0/90000 (0%)]	Loss: 18.0790	Cost: 21.76s
Train Epoch: 955 [20480/90000 (23%)]	Loss: 8.5979	Cost: 6.00s
Train Epoch: 955 [40960/90000 (45%)]	Loss: 8.5526	Cost: 6.56s
Train Epoch: 955 [61440/90000 (68%)]	Loss: 8.2907	Cost: 5.95s
Train Epoch: 955 [81920/90000 (91%)]	Loss: 8.5989	Cost: 6.24s
Train Epoch: 955 	Average Loss: 9.1945
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1120

Learning rate: 0.00019553299583633364
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 956 [0/90000 (0%)]	Loss: 18.1176	Cost: 21.15s
Train Epoch: 956 [20480/90000 (23%)]	Loss: 8.2067	Cost: 6.08s
Train Epoch: 956 [40960/90000 (45%)]	Loss: 8.3780	Cost: 6.29s
Train Epoch: 956 [61440/90000 (68%)]	Loss: 8.1760	Cost: 5.92s
Train Epoch: 956 [81920/90000 (91%)]	Loss: 8.4290	Cost: 6.39s
Train Epoch: 956 	Average Loss: 8.9841
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1811

Learning rate: 0.00019552370641778697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 957 [0/90000 (0%)]	Loss: 18.2408	Cost: 20.79s
Train Epoch: 957 [20480/90000 (23%)]	Loss: 8.2057	Cost: 6.13s
Train Epoch: 957 [40960/90000 (45%)]	Loss: 8.1676	Cost: 6.07s
Train Epoch: 957 [61440/90000 (68%)]	Loss: 7.9530	Cost: 5.95s
Train Epoch: 957 [81920/90000 (91%)]	Loss: 8.3979	Cost: 5.84s
Train Epoch: 957 	Average Loss: 9.0015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1327

Learning rate: 0.00019551440757142847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 958 [0/90000 (0%)]	Loss: 18.3839	Cost: 21.21s
Train Epoch: 958 [20480/90000 (23%)]	Loss: 8.2921	Cost: 6.01s
Train Epoch: 958 [40960/90000 (45%)]	Loss: 8.6078	Cost: 6.26s
Train Epoch: 958 [61440/90000 (68%)]	Loss: 8.5775	Cost: 6.00s
Train Epoch: 958 [81920/90000 (91%)]	Loss: 8.4499	Cost: 6.84s
Train Epoch: 958 	Average Loss: 9.1892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1736

Learning rate: 0.00019550509929817583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 959 [0/90000 (0%)]	Loss: 18.3154	Cost: 20.85s
Train Epoch: 959 [20480/90000 (23%)]	Loss: 8.6869	Cost: 5.81s
Train Epoch: 959 [40960/90000 (45%)]	Loss: 9.0596	Cost: 6.54s
Train Epoch: 959 [61440/90000 (68%)]	Loss: 8.5432	Cost: 5.71s
Train Epoch: 959 [81920/90000 (91%)]	Loss: 8.8873	Cost: 6.34s
Train Epoch: 959 	Average Loss: 9.5501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9948

Learning rate: 0.00019549578159894782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 960 [0/90000 (0%)]	Loss: 18.1287	Cost: 20.59s
Train Epoch: 960 [20480/90000 (23%)]	Loss: 8.7365	Cost: 6.06s
Train Epoch: 960 [40960/90000 (45%)]	Loss: 8.6150	Cost: 6.05s
Train Epoch: 960 [61440/90000 (68%)]	Loss: 8.2656	Cost: 5.94s
Train Epoch: 960 [81920/90000 (91%)]	Loss: 8.6242	Cost: 5.86s
Train Epoch: 960 	Average Loss: 9.2516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0423

Learning rate: 0.00019548645447466402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 961 [0/90000 (0%)]	Loss: 18.2352	Cost: 20.76s
Train Epoch: 961 [20480/90000 (23%)]	Loss: 8.4042	Cost: 6.04s
Train Epoch: 961 [40960/90000 (45%)]	Loss: 8.6391	Cost: 6.13s
Train Epoch: 961 [61440/90000 (68%)]	Loss: 8.4025	Cost: 5.91s
Train Epoch: 961 [81920/90000 (91%)]	Loss: 8.5454	Cost: 5.94s
Train Epoch: 961 	Average Loss: 9.1946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1419

Learning rate: 0.00019547711792624497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 962 [0/90000 (0%)]	Loss: 18.1436	Cost: 21.16s
Train Epoch: 962 [20480/90000 (23%)]	Loss: 8.3466	Cost: 6.15s
Train Epoch: 962 [40960/90000 (45%)]	Loss: 8.3404	Cost: 6.20s
Train Epoch: 962 [61440/90000 (68%)]	Loss: 8.2784	Cost: 5.95s
Train Epoch: 962 [81920/90000 (91%)]	Loss: 8.4188	Cost: 6.22s
Train Epoch: 962 	Average Loss: 9.0810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2228

Learning rate: 0.00019546777195461216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 963 [0/90000 (0%)]	Loss: 17.9954	Cost: 21.24s
Train Epoch: 963 [20480/90000 (23%)]	Loss: 8.2851	Cost: 6.14s
Train Epoch: 963 [40960/90000 (45%)]	Loss: 8.1294	Cost: 6.21s
Train Epoch: 963 [61440/90000 (68%)]	Loss: 8.1128	Cost: 6.02s
Train Epoch: 963 [81920/90000 (91%)]	Loss: 8.3456	Cost: 6.05s
Train Epoch: 963 	Average Loss: 9.0323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0886

Learning rate: 0.00019545841656068801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 964 [0/90000 (0%)]	Loss: 18.2256	Cost: 20.10s
Train Epoch: 964 [20480/90000 (23%)]	Loss: 8.4809	Cost: 6.15s
Train Epoch: 964 [40960/90000 (45%)]	Loss: 8.6850	Cost: 6.28s
Train Epoch: 964 [61440/90000 (68%)]	Loss: 8.4152	Cost: 6.00s
Train Epoch: 964 [81920/90000 (91%)]	Loss: 8.4054	Cost: 6.45s
Train Epoch: 964 	Average Loss: 9.1854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2463

Learning rate: 0.00019544905174539588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 965 [0/90000 (0%)]	Loss: 18.1394	Cost: 21.03s
Train Epoch: 965 [20480/90000 (23%)]	Loss: 8.4286	Cost: 6.15s
Train Epoch: 965 [40960/90000 (45%)]	Loss: 8.4271	Cost: 6.36s
Train Epoch: 965 [61440/90000 (68%)]	Loss: 8.2152	Cost: 6.24s
Train Epoch: 965 [81920/90000 (91%)]	Loss: 8.3842	Cost: 6.92s
Train Epoch: 965 	Average Loss: 9.0527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2027

Learning rate: 0.00019543967750965997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 966 [0/90000 (0%)]	Loss: 18.5237	Cost: 20.73s
Train Epoch: 966 [20480/90000 (23%)]	Loss: 8.0114	Cost: 6.12s
Train Epoch: 966 [40960/90000 (45%)]	Loss: 8.4185	Cost: 6.29s
Train Epoch: 966 [61440/90000 (68%)]	Loss: 8.0975	Cost: 6.02s
Train Epoch: 966 [81920/90000 (91%)]	Loss: 8.2793	Cost: 7.05s
Train Epoch: 966 	Average Loss: 8.9917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2320

Learning rate: 0.00019543029385440556
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 967 [0/90000 (0%)]	Loss: 18.1768	Cost: 21.32s
Train Epoch: 967 [20480/90000 (23%)]	Loss: 8.0089	Cost: 6.03s
Train Epoch: 967 [40960/90000 (45%)]	Loss: 8.4333	Cost: 6.36s
Train Epoch: 967 [61440/90000 (68%)]	Loss: 8.6732	Cost: 6.09s
Train Epoch: 967 [81920/90000 (91%)]	Loss: 8.6100	Cost: 7.26s
Train Epoch: 967 	Average Loss: 9.1086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3028

Learning rate: 0.00019542090078055873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 968 [0/90000 (0%)]	Loss: 18.0733	Cost: 19.95s
Train Epoch: 968 [20480/90000 (23%)]	Loss: 8.5629	Cost: 6.09s
Train Epoch: 968 [40960/90000 (45%)]	Loss: 8.4129	Cost: 6.19s
Train Epoch: 968 [61440/90000 (68%)]	Loss: 8.4677	Cost: 5.98s
Train Epoch: 968 [81920/90000 (91%)]	Loss: 8.5249	Cost: 6.72s
Train Epoch: 968 	Average Loss: 9.2365
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0061

Learning rate: 0.00019541149828904657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 969 [0/90000 (0%)]	Loss: 18.0440	Cost: 20.54s
Train Epoch: 969 [20480/90000 (23%)]	Loss: 8.1815	Cost: 6.08s
Train Epoch: 969 [40960/90000 (45%)]	Loss: 8.2246	Cost: 6.40s
Train Epoch: 969 [61440/90000 (68%)]	Loss: 8.7490	Cost: 6.06s
Train Epoch: 969 [81920/90000 (91%)]	Loss: 8.7006	Cost: 7.01s
Train Epoch: 969 	Average Loss: 9.1248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0743

Learning rate: 0.00019540208638079703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 970 [0/90000 (0%)]	Loss: 18.2244	Cost: 19.50s
Train Epoch: 970 [20480/90000 (23%)]	Loss: 8.8152	Cost: 6.17s
Train Epoch: 970 [40960/90000 (45%)]	Loss: 8.5663	Cost: 6.35s
Train Epoch: 970 [61440/90000 (68%)]	Loss: 8.2412	Cost: 5.97s
Train Epoch: 970 [81920/90000 (91%)]	Loss: 8.4138	Cost: 6.94s
Train Epoch: 970 	Average Loss: 9.2003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1141

Learning rate: 0.00019539266505673905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 971 [0/90000 (0%)]	Loss: 18.3289	Cost: 20.93s
Train Epoch: 971 [20480/90000 (23%)]	Loss: 8.2075	Cost: 6.10s
Train Epoch: 971 [40960/90000 (45%)]	Loss: 8.0170	Cost: 6.95s
Train Epoch: 971 [61440/90000 (68%)]	Loss: 8.7629	Cost: 5.89s
Train Epoch: 971 [81920/90000 (91%)]	Loss: 9.0498	Cost: 7.37s
Train Epoch: 971 	Average Loss: 9.2560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1265

Learning rate: 0.0001953832343178025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 972 [0/90000 (0%)]	Loss: 18.2638	Cost: 20.09s
Train Epoch: 972 [20480/90000 (23%)]	Loss: 8.9144	Cost: 6.04s
Train Epoch: 972 [40960/90000 (45%)]	Loss: 9.0635	Cost: 6.51s
Train Epoch: 972 [61440/90000 (68%)]	Loss: 8.3376	Cost: 5.98s
Train Epoch: 972 [81920/90000 (91%)]	Loss: 8.5921	Cost: 6.55s
Train Epoch: 972 	Average Loss: 9.4000
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0979

Learning rate: 0.00019537379416491811
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 973 [0/90000 (0%)]	Loss: 18.1886	Cost: 20.60s
Train Epoch: 973 [20480/90000 (23%)]	Loss: 8.4172	Cost: 6.11s
Train Epoch: 973 [40960/90000 (45%)]	Loss: 8.5109	Cost: 6.07s
Train Epoch: 973 [61440/90000 (68%)]	Loss: 8.2194	Cost: 6.01s
Train Epoch: 973 [81920/90000 (91%)]	Loss: 8.4087	Cost: 6.04s
Train Epoch: 973 	Average Loss: 9.0656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1750

Learning rate: 0.00019536434459901765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 974 [0/90000 (0%)]	Loss: 18.4203	Cost: 21.72s
Train Epoch: 974 [20480/90000 (23%)]	Loss: 8.5171	Cost: 6.00s
Train Epoch: 974 [40960/90000 (45%)]	Loss: 8.3590	Cost: 6.28s
Train Epoch: 974 [61440/90000 (68%)]	Loss: 8.1373	Cost: 5.74s
Train Epoch: 974 [81920/90000 (91%)]	Loss: 8.2297	Cost: 6.59s
Train Epoch: 974 	Average Loss: 9.0133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2768

Learning rate: 0.0001953548856210337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 975 [0/90000 (0%)]	Loss: 18.2247	Cost: 20.40s
Train Epoch: 975 [20480/90000 (23%)]	Loss: 7.8037	Cost: 6.07s
Train Epoch: 975 [40960/90000 (45%)]	Loss: 8.1820	Cost: 6.20s
Train Epoch: 975 [61440/90000 (68%)]	Loss: 7.9629	Cost: 5.97s
Train Epoch: 975 [81920/90000 (91%)]	Loss: 8.0754	Cost: 6.09s
Train Epoch: 975 	Average Loss: 8.7889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2298

Learning rate: 0.00019534541723189978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 976 [0/90000 (0%)]	Loss: 18.3441	Cost: 21.14s
Train Epoch: 976 [20480/90000 (23%)]	Loss: 8.1446	Cost: 6.07s
Train Epoch: 976 [40960/90000 (45%)]	Loss: 8.1572	Cost: 6.04s
Train Epoch: 976 [61440/90000 (68%)]	Loss: 7.8173	Cost: 6.22s
Train Epoch: 976 [81920/90000 (91%)]	Loss: 8.1395	Cost: 6.00s
Train Epoch: 976 	Average Loss: 8.7459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3658

Learning rate: 0.00019533593943255054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 977 [0/90000 (0%)]	Loss: 18.4445	Cost: 20.40s
Train Epoch: 977 [20480/90000 (23%)]	Loss: 8.4671	Cost: 6.25s
Train Epoch: 977 [40960/90000 (45%)]	Loss: 8.5752	Cost: 6.09s
Train Epoch: 977 [61440/90000 (68%)]	Loss: 8.2604	Cost: 5.97s
Train Epoch: 977 [81920/90000 (91%)]	Loss: 8.6870	Cost: 6.51s
Train Epoch: 977 	Average Loss: 9.1701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0915

Learning rate: 0.00019532645222392127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 978 [0/90000 (0%)]	Loss: 18.4739	Cost: 20.77s
Train Epoch: 978 [20480/90000 (23%)]	Loss: 8.3268	Cost: 6.11s
Train Epoch: 978 [40960/90000 (45%)]	Loss: 8.4840	Cost: 6.13s
Train Epoch: 978 [61440/90000 (68%)]	Loss: 8.2789	Cost: 6.01s
Train Epoch: 978 [81920/90000 (91%)]	Loss: 8.4810	Cost: 7.19s
Train Epoch: 978 	Average Loss: 9.0979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2879

Learning rate: 0.00019531695560694832
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 979 [0/90000 (0%)]	Loss: 18.3194	Cost: 20.62s
Train Epoch: 979 [20480/90000 (23%)]	Loss: 8.3024	Cost: 6.05s
Train Epoch: 979 [40960/90000 (45%)]	Loss: 8.3759	Cost: 6.07s
Train Epoch: 979 [61440/90000 (68%)]	Loss: 8.0782	Cost: 6.13s
Train Epoch: 979 [81920/90000 (91%)]	Loss: 8.2171	Cost: 7.03s
Train Epoch: 979 	Average Loss: 9.0267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1780

Learning rate: 0.00019530744958256901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 980 [0/90000 (0%)]	Loss: 18.4782	Cost: 21.42s
Train Epoch: 980 [20480/90000 (23%)]	Loss: 8.0309	Cost: 6.10s
Train Epoch: 980 [40960/90000 (45%)]	Loss: 8.2782	Cost: 6.40s
Train Epoch: 980 [61440/90000 (68%)]	Loss: 8.2570	Cost: 6.04s
Train Epoch: 980 [81920/90000 (91%)]	Loss: 8.4127	Cost: 7.01s
Train Epoch: 980 	Average Loss: 8.9900
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1176

Learning rate: 0.00019529793415172156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 981 [0/90000 (0%)]	Loss: 18.3736	Cost: 19.89s
Train Epoch: 981 [20480/90000 (23%)]	Loss: 8.3841	Cost: 6.08s
Train Epoch: 981 [40960/90000 (45%)]	Loss: 8.0748	Cost: 6.08s
Train Epoch: 981 [61440/90000 (68%)]	Loss: 7.8161	Cost: 6.12s
Train Epoch: 981 [81920/90000 (91%)]	Loss: 8.0072	Cost: 7.36s
Train Epoch: 981 	Average Loss: 8.8313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2031

Learning rate: 0.00019528840931534505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 982 [0/90000 (0%)]	Loss: 18.6127	Cost: 21.44s
Train Epoch: 982 [20480/90000 (23%)]	Loss: 8.0305	Cost: 6.15s
Train Epoch: 982 [40960/90000 (45%)]	Loss: 8.2765	Cost: 6.17s
Train Epoch: 982 [61440/90000 (68%)]	Loss: 8.0905	Cost: 6.08s
Train Epoch: 982 [81920/90000 (91%)]	Loss: 8.2191	Cost: 6.78s
Train Epoch: 982 	Average Loss: 8.8584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2365

Learning rate: 0.0001952788750743796
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 983 [0/90000 (0%)]	Loss: 18.2938	Cost: 20.37s
Train Epoch: 983 [20480/90000 (23%)]	Loss: 7.7924	Cost: 6.11s
Train Epoch: 983 [40960/90000 (45%)]	Loss: 7.8509	Cost: 6.05s
Train Epoch: 983 [61440/90000 (68%)]	Loss: 7.7186	Cost: 6.22s
Train Epoch: 983 [81920/90000 (91%)]	Loss: 7.9792	Cost: 6.60s
Train Epoch: 983 	Average Loss: 8.6348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3664

Learning rate: 0.0001952693314297662
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 984 [0/90000 (0%)]	Loss: 18.3161	Cost: 20.51s
Train Epoch: 984 [20480/90000 (23%)]	Loss: 8.0159	Cost: 6.15s
Train Epoch: 984 [40960/90000 (45%)]	Loss: 8.0670	Cost: 6.54s
Train Epoch: 984 [61440/90000 (68%)]	Loss: 8.0072	Cost: 6.11s
Train Epoch: 984 [81920/90000 (91%)]	Loss: 8.1024	Cost: 6.95s
Train Epoch: 984 	Average Loss: 8.7821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2902

Learning rate: 0.00019525977838244672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 985 [0/90000 (0%)]	Loss: 18.2999	Cost: 20.26s
Train Epoch: 985 [20480/90000 (23%)]	Loss: 7.8994	Cost: 6.13s
Train Epoch: 985 [40960/90000 (45%)]	Loss: 7.9538	Cost: 6.12s
Train Epoch: 985 [61440/90000 (68%)]	Loss: 7.7030	Cost: 6.07s
Train Epoch: 985 [81920/90000 (91%)]	Loss: 7.9967	Cost: 6.00s
Train Epoch: 985 	Average Loss: 8.6171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3666

Learning rate: 0.00019525021593336405
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 986 [0/90000 (0%)]	Loss: 18.1451	Cost: 20.53s
Train Epoch: 986 [20480/90000 (23%)]	Loss: 7.9399	Cost: 6.21s
Train Epoch: 986 [40960/90000 (45%)]	Loss: 7.9446	Cost: 6.63s
Train Epoch: 986 [61440/90000 (68%)]	Loss: 7.8547	Cost: 6.01s
Train Epoch: 986 [81920/90000 (91%)]	Loss: 7.9369	Cost: 6.99s
Train Epoch: 986 	Average Loss: 8.6906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2339

Learning rate: 0.00019524064408346195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 987 [0/90000 (0%)]	Loss: 18.7402	Cost: 20.68s
Train Epoch: 987 [20480/90000 (23%)]	Loss: 7.8508	Cost: 6.10s
Train Epoch: 987 [40960/90000 (45%)]	Loss: 7.9094	Cost: 6.73s
Train Epoch: 987 [61440/90000 (68%)]	Loss: 8.0836	Cost: 6.27s
Train Epoch: 987 [81920/90000 (91%)]	Loss: 8.1857	Cost: 6.62s
Train Epoch: 987 	Average Loss: 8.6691
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2593

Learning rate: 0.00019523106283368514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 988 [0/90000 (0%)]	Loss: 18.7811	Cost: 19.50s
Train Epoch: 988 [20480/90000 (23%)]	Loss: 7.8841	Cost: 6.16s
Train Epoch: 988 [40960/90000 (45%)]	Loss: 7.8960	Cost: 6.22s
Train Epoch: 988 [61440/90000 (68%)]	Loss: 7.9385	Cost: 6.01s
Train Epoch: 988 [81920/90000 (91%)]	Loss: 7.8871	Cost: 7.03s
Train Epoch: 988 	Average Loss: 8.7212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3496

Learning rate: 0.00019522147218497925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 989 [0/90000 (0%)]	Loss: 18.3000	Cost: 20.22s
Train Epoch: 989 [20480/90000 (23%)]	Loss: 8.2614	Cost: 6.18s
Train Epoch: 989 [40960/90000 (45%)]	Loss: 8.5208	Cost: 6.58s
Train Epoch: 989 [61440/90000 (68%)]	Loss: 8.3930	Cost: 6.14s
Train Epoch: 989 [81920/90000 (91%)]	Loss: 8.4238	Cost: 7.29s
Train Epoch: 989 	Average Loss: 9.0737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2939

Learning rate: 0.0001952118721382908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 990 [0/90000 (0%)]	Loss: 18.4357	Cost: 20.35s
Train Epoch: 990 [20480/90000 (23%)]	Loss: 8.0729	Cost: 6.12s
Train Epoch: 990 [40960/90000 (45%)]	Loss: 7.9477	Cost: 6.81s
Train Epoch: 990 [61440/90000 (68%)]	Loss: 7.8818	Cost: 6.01s
Train Epoch: 990 [81920/90000 (91%)]	Loss: 8.0817	Cost: 6.96s
Train Epoch: 990 	Average Loss: 8.8699
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2545

Learning rate: 0.0001952022626945673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 991 [0/90000 (0%)]	Loss: 18.3904	Cost: 20.13s
Train Epoch: 991 [20480/90000 (23%)]	Loss: 8.0632	Cost: 6.08s
Train Epoch: 991 [40960/90000 (45%)]	Loss: 8.3444	Cost: 6.10s
Train Epoch: 991 [61440/90000 (68%)]	Loss: 8.1182	Cost: 6.11s
Train Epoch: 991 [81920/90000 (91%)]	Loss: 7.9734	Cost: 6.78s
Train Epoch: 991 	Average Loss: 8.8020
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4642

Learning rate: 0.00019519264385475717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 992 [0/90000 (0%)]	Loss: 18.6619	Cost: 19.84s
Train Epoch: 992 [20480/90000 (23%)]	Loss: 7.6955	Cost: 6.15s
Train Epoch: 992 [40960/90000 (45%)]	Loss: 7.9240	Cost: 6.19s
Train Epoch: 992 [61440/90000 (68%)]	Loss: 7.7328	Cost: 6.21s
Train Epoch: 992 [81920/90000 (91%)]	Loss: 7.9766	Cost: 6.71s
Train Epoch: 992 	Average Loss: 8.6710
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4197

Learning rate: 0.00019518301561980976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 993 [0/90000 (0%)]	Loss: 18.5986	Cost: 19.63s
Train Epoch: 993 [20480/90000 (23%)]	Loss: 7.9062	Cost: 6.18s
Train Epoch: 993 [40960/90000 (45%)]	Loss: 7.8035	Cost: 6.34s
Train Epoch: 993 [61440/90000 (68%)]	Loss: 7.9488	Cost: 6.06s
Train Epoch: 993 [81920/90000 (91%)]	Loss: 8.1909	Cost: 5.98s
Train Epoch: 993 	Average Loss: 8.7150
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4044

Learning rate: 0.00019517337799067536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 994 [0/90000 (0%)]	Loss: 18.5268	Cost: 19.95s
Train Epoch: 994 [20480/90000 (23%)]	Loss: 7.9911	Cost: 6.09s
Train Epoch: 994 [40960/90000 (45%)]	Loss: 8.2122	Cost: 6.23s
Train Epoch: 994 [61440/90000 (68%)]	Loss: 8.0304	Cost: 6.02s
Train Epoch: 994 [81920/90000 (91%)]	Loss: 8.0727	Cost: 7.19s
Train Epoch: 994 	Average Loss: 8.8499
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3089

Learning rate: 0.00019516373096830513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 995 [0/90000 (0%)]	Loss: 18.2986	Cost: 20.27s
Train Epoch: 995 [20480/90000 (23%)]	Loss: 8.0784	Cost: 6.14s
Train Epoch: 995 [40960/90000 (45%)]	Loss: 8.0786	Cost: 6.19s
Train Epoch: 995 [61440/90000 (68%)]	Loss: 7.6874	Cost: 6.08s
Train Epoch: 995 [81920/90000 (91%)]	Loss: 7.9680	Cost: 7.62s
Train Epoch: 995 	Average Loss: 8.6531
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3841

Learning rate: 0.00019515407455365116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 996 [0/90000 (0%)]	Loss: 18.3275	Cost: 19.82s
Train Epoch: 996 [20480/90000 (23%)]	Loss: 7.8443	Cost: 6.18s
Train Epoch: 996 [40960/90000 (45%)]	Loss: 7.8406	Cost: 6.13s
Train Epoch: 996 [61440/90000 (68%)]	Loss: 7.6291	Cost: 6.12s
Train Epoch: 996 [81920/90000 (91%)]	Loss: 7.9404	Cost: 6.64s
Train Epoch: 996 	Average Loss: 8.5539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5140

Learning rate: 0.00019514440874766656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 997 [0/90000 (0%)]	Loss: 18.3964	Cost: 20.15s
Train Epoch: 997 [20480/90000 (23%)]	Loss: 7.7681	Cost: 6.10s
Train Epoch: 997 [40960/90000 (45%)]	Loss: 7.7868	Cost: 6.34s
Train Epoch: 997 [61440/90000 (68%)]	Loss: 7.5724	Cost: 6.14s
Train Epoch: 997 [81920/90000 (91%)]	Loss: 8.2419	Cost: 6.90s
Train Epoch: 997 	Average Loss: 8.5051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4625

Learning rate: 0.00019513473355130528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 998 [0/90000 (0%)]	Loss: 18.1448	Cost: 21.12s
Train Epoch: 998 [20480/90000 (23%)]	Loss: 7.6513	Cost: 6.18s
Train Epoch: 998 [40960/90000 (45%)]	Loss: 7.7450	Cost: 6.39s
Train Epoch: 998 [61440/90000 (68%)]	Loss: 7.7035	Cost: 6.17s
Train Epoch: 998 [81920/90000 (91%)]	Loss: 7.9957	Cost: 6.36s
Train Epoch: 998 	Average Loss: 8.5610
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4403

Learning rate: 0.00019512504896552222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 999 [0/90000 (0%)]	Loss: 18.5908	Cost: 19.79s
Train Epoch: 999 [20480/90000 (23%)]	Loss: 8.0483	Cost: 6.07s
Train Epoch: 999 [40960/90000 (45%)]	Loss: 8.2527	Cost: 6.10s
Train Epoch: 999 [61440/90000 (68%)]	Loss: 8.0566	Cost: 6.13s
Train Epoch: 999 [81920/90000 (91%)]	Loss: 8.1725	Cost: 7.26s
Train Epoch: 999 	Average Loss: 8.8265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5152

Learning rate: 0.00019511535499127324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1000 [0/90000 (0%)]	Loss: 18.4883	Cost: 19.90s
Train Epoch: 1000 [20480/90000 (23%)]	Loss: 7.9050	Cost: 6.02s
Train Epoch: 1000 [40960/90000 (45%)]	Loss: 8.0707	Cost: 6.98s
Train Epoch: 1000 [61440/90000 (68%)]	Loss: 7.7344	Cost: 6.02s
Train Epoch: 1000 [81920/90000 (91%)]	Loss: 7.8589	Cost: 6.53s
Train Epoch: 1000 	Average Loss: 8.6539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4652

Learning rate: 0.00019510565162951505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1001 [0/90000 (0%)]	Loss: 18.6203	Cost: 20.37s
Train Epoch: 1001 [20480/90000 (23%)]	Loss: 7.8319	Cost: 6.09s
Train Epoch: 1001 [40960/90000 (45%)]	Loss: 8.0936	Cost: 6.35s
Train Epoch: 1001 [61440/90000 (68%)]	Loss: 7.5108	Cost: 6.01s
Train Epoch: 1001 [81920/90000 (91%)]	Loss: 8.1196	Cost: 7.20s
Train Epoch: 1001 	Average Loss: 8.6804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4063

Learning rate: 0.00019509593888120534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1002 [0/90000 (0%)]	Loss: 18.7625	Cost: 19.71s
Train Epoch: 1002 [20480/90000 (23%)]	Loss: 7.9982	Cost: 6.13s
Train Epoch: 1002 [40960/90000 (45%)]	Loss: 7.9217	Cost: 6.12s
Train Epoch: 1002 [61440/90000 (68%)]	Loss: 7.7692	Cost: 6.15s
Train Epoch: 1002 [81920/90000 (91%)]	Loss: 7.6793	Cost: 6.54s
Train Epoch: 1002 	Average Loss: 8.6587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4598

Learning rate: 0.00019508621674730277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1003 [0/90000 (0%)]	Loss: 18.3902	Cost: 20.13s
Train Epoch: 1003 [20480/90000 (23%)]	Loss: 7.8913	Cost: 6.33s
Train Epoch: 1003 [40960/90000 (45%)]	Loss: 7.8777	Cost: 6.12s
Train Epoch: 1003 [61440/90000 (68%)]	Loss: 7.9010	Cost: 6.11s
Train Epoch: 1003 [81920/90000 (91%)]	Loss: 7.9518	Cost: 6.78s
Train Epoch: 1003 	Average Loss: 8.6352
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4783

Learning rate: 0.00019507648522876684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1004 [0/90000 (0%)]	Loss: 18.4524	Cost: 19.72s
Train Epoch: 1004 [20480/90000 (23%)]	Loss: 8.0114	Cost: 6.13s
Train Epoch: 1004 [40960/90000 (45%)]	Loss: 7.8153	Cost: 6.16s
Train Epoch: 1004 [61440/90000 (68%)]	Loss: 7.5104	Cost: 6.05s
Train Epoch: 1004 [81920/90000 (91%)]	Loss: 7.7120	Cost: 6.95s
Train Epoch: 1004 	Average Loss: 8.5483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4428

Learning rate: 0.00019506674432655802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1005 [0/90000 (0%)]	Loss: 18.7706	Cost: 19.79s
Train Epoch: 1005 [20480/90000 (23%)]	Loss: 8.1389	Cost: 6.05s
Train Epoch: 1005 [40960/90000 (45%)]	Loss: 7.7801	Cost: 6.30s
Train Epoch: 1005 [61440/90000 (68%)]	Loss: 7.6963	Cost: 6.12s
Train Epoch: 1005 [81920/90000 (91%)]	Loss: 7.9015	Cost: 6.53s
Train Epoch: 1005 	Average Loss: 8.6174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5007

Learning rate: 0.0001950569940416377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1006 [0/90000 (0%)]	Loss: 18.6640	Cost: 19.44s
Train Epoch: 1006 [20480/90000 (23%)]	Loss: 7.7144	Cost: 6.11s
Train Epoch: 1006 [40960/90000 (45%)]	Loss: 7.8688	Cost: 6.31s
Train Epoch: 1006 [61440/90000 (68%)]	Loss: 7.6453	Cost: 6.05s
Train Epoch: 1006 [81920/90000 (91%)]	Loss: 7.5359	Cost: 7.03s
Train Epoch: 1006 	Average Loss: 8.5314
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4794

Learning rate: 0.00019504723437496817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1007 [0/90000 (0%)]	Loss: 18.8243	Cost: 20.34s
Train Epoch: 1007 [20480/90000 (23%)]	Loss: 7.8678	Cost: 6.14s
Train Epoch: 1007 [40960/90000 (45%)]	Loss: 7.7532	Cost: 6.40s
Train Epoch: 1007 [61440/90000 (68%)]	Loss: 7.5813	Cost: 6.05s
Train Epoch: 1007 [81920/90000 (91%)]	Loss: 7.7238	Cost: 6.91s
Train Epoch: 1007 	Average Loss: 8.4840
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4610

Learning rate: 0.0001950374653275127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1008 [0/90000 (0%)]	Loss: 18.8126	Cost: 19.80s
Train Epoch: 1008 [20480/90000 (23%)]	Loss: 7.9395	Cost: 6.19s
Train Epoch: 1008 [40960/90000 (45%)]	Loss: 7.7857	Cost: 6.51s
Train Epoch: 1008 [61440/90000 (68%)]	Loss: 7.8495	Cost: 6.07s
Train Epoch: 1008 [81920/90000 (91%)]	Loss: 7.8433	Cost: 6.37s
Train Epoch: 1008 	Average Loss: 8.6026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5237

Learning rate: 0.00019502768690023544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1009 [0/90000 (0%)]	Loss: 18.8645	Cost: 19.70s
Train Epoch: 1009 [20480/90000 (23%)]	Loss: 7.7646	Cost: 5.92s
Train Epoch: 1009 [40960/90000 (45%)]	Loss: 7.9468	Cost: 6.56s
Train Epoch: 1009 [61440/90000 (68%)]	Loss: 7.8474	Cost: 6.19s
Train Epoch: 1009 [81920/90000 (91%)]	Loss: 7.9777	Cost: 6.70s
Train Epoch: 1009 	Average Loss: 8.5987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4712

Learning rate: 0.0001950178990941015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1010 [0/90000 (0%)]	Loss: 18.3918	Cost: 19.50s
Train Epoch: 1010 [20480/90000 (23%)]	Loss: 7.4118	Cost: 6.13s
Train Epoch: 1010 [40960/90000 (45%)]	Loss: 7.5442	Cost: 6.82s
Train Epoch: 1010 [61440/90000 (68%)]	Loss: 7.6701	Cost: 5.97s
Train Epoch: 1010 [81920/90000 (91%)]	Loss: 7.5518	Cost: 5.89s
Train Epoch: 1010 	Average Loss: 8.4498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5386

Learning rate: 0.00019500810191007685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1011 [0/90000 (0%)]	Loss: 18.8773	Cost: 19.89s
Train Epoch: 1011 [20480/90000 (23%)]	Loss: 7.4228	Cost: 6.25s
Train Epoch: 1011 [40960/90000 (45%)]	Loss: 7.5371	Cost: 6.36s
Train Epoch: 1011 [61440/90000 (68%)]	Loss: 7.5341	Cost: 6.03s
Train Epoch: 1011 [81920/90000 (91%)]	Loss: 7.7745	Cost: 6.38s
Train Epoch: 1011 	Average Loss: 8.3414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5081

Learning rate: 0.0001949982953491285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1012 [0/90000 (0%)]	Loss: 18.7083	Cost: 19.88s
Train Epoch: 1012 [20480/90000 (23%)]	Loss: 7.8257	Cost: 6.21s
Train Epoch: 1012 [40960/90000 (45%)]	Loss: 7.6755	Cost: 6.63s
Train Epoch: 1012 [61440/90000 (68%)]	Loss: 7.6227	Cost: 6.09s
Train Epoch: 1012 [81920/90000 (91%)]	Loss: 7.6977	Cost: 6.74s
Train Epoch: 1012 	Average Loss: 8.4436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5715

Learning rate: 0.0001949884794122243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1013 [0/90000 (0%)]	Loss: 18.5312	Cost: 18.95s
Train Epoch: 1013 [20480/90000 (23%)]	Loss: 7.6029	Cost: 6.18s
Train Epoch: 1013 [40960/90000 (45%)]	Loss: 7.5353	Cost: 6.44s
Train Epoch: 1013 [61440/90000 (68%)]	Loss: 7.9368	Cost: 6.08s
Train Epoch: 1013 [81920/90000 (91%)]	Loss: 7.6606	Cost: 5.99s
Train Epoch: 1013 	Average Loss: 8.4248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4791

Learning rate: 0.000194978654100333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1014 [0/90000 (0%)]	Loss: 18.6320	Cost: 20.03s
Train Epoch: 1014 [20480/90000 (23%)]	Loss: 7.6803	Cost: 6.05s
Train Epoch: 1014 [40960/90000 (45%)]	Loss: 8.0008	Cost: 6.95s
Train Epoch: 1014 [61440/90000 (68%)]	Loss: 7.8864	Cost: 6.03s
Train Epoch: 1014 [81920/90000 (91%)]	Loss: 8.1079	Cost: 7.38s
Train Epoch: 1014 	Average Loss: 8.5788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5438

Learning rate: 0.00019496881941442437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1015 [0/90000 (0%)]	Loss: 18.6762	Cost: 19.10s
Train Epoch: 1015 [20480/90000 (23%)]	Loss: 7.6541	Cost: 6.11s
Train Epoch: 1015 [40960/90000 (45%)]	Loss: 7.6647	Cost: 6.33s
Train Epoch: 1015 [61440/90000 (68%)]	Loss: 7.5500	Cost: 6.01s
Train Epoch: 1015 [81920/90000 (91%)]	Loss: 7.6653	Cost: 5.88s
Train Epoch: 1015 	Average Loss: 8.3991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5835

Learning rate: 0.00019495897535546904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1016 [0/90000 (0%)]	Loss: 18.4294	Cost: 18.70s
Train Epoch: 1016 [20480/90000 (23%)]	Loss: 7.6345	Cost: 6.23s
Train Epoch: 1016 [40960/90000 (45%)]	Loss: 7.6657	Cost: 6.20s
Train Epoch: 1016 [61440/90000 (68%)]	Loss: 7.6165	Cost: 6.07s
Train Epoch: 1016 [81920/90000 (91%)]	Loss: 7.7406	Cost: 6.68s
Train Epoch: 1016 	Average Loss: 8.4331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4821

Learning rate: 0.00019494912192443854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1017 [0/90000 (0%)]	Loss: 18.4403	Cost: 19.69s
Train Epoch: 1017 [20480/90000 (23%)]	Loss: 7.6334	Cost: 6.09s
Train Epoch: 1017 [40960/90000 (45%)]	Loss: 7.6681	Cost: 6.63s
Train Epoch: 1017 [61440/90000 (68%)]	Loss: 7.4188	Cost: 6.00s
Train Epoch: 1017 [81920/90000 (91%)]	Loss: 7.8828	Cost: 6.81s
Train Epoch: 1017 	Average Loss: 8.3888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5846

Learning rate: 0.00019493925912230544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1018 [0/90000 (0%)]	Loss: 18.7036	Cost: 19.46s
Train Epoch: 1018 [20480/90000 (23%)]	Loss: 8.1428	Cost: 6.14s
Train Epoch: 1018 [40960/90000 (45%)]	Loss: 8.0942	Cost: 6.39s
Train Epoch: 1018 [61440/90000 (68%)]	Loss: 7.9301	Cost: 5.84s
Train Epoch: 1018 [81920/90000 (91%)]	Loss: 7.7338	Cost: 7.00s
Train Epoch: 1018 	Average Loss: 8.7131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4850

Learning rate: 0.00019492938695004312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1019 [0/90000 (0%)]	Loss: 18.4617	Cost: 20.20s
Train Epoch: 1019 [20480/90000 (23%)]	Loss: 7.6626	Cost: 6.09s
Train Epoch: 1019 [40960/90000 (45%)]	Loss: 7.6301	Cost: 6.21s
Train Epoch: 1019 [61440/90000 (68%)]	Loss: 7.4195	Cost: 6.11s
Train Epoch: 1019 [81920/90000 (91%)]	Loss: 7.7756	Cost: 6.72s
Train Epoch: 1019 	Average Loss: 8.4719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5066

Learning rate: 0.00019491950540862592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1020 [0/90000 (0%)]	Loss: 18.5735	Cost: 19.71s
Train Epoch: 1020 [20480/90000 (23%)]	Loss: 7.5966	Cost: 6.23s
Train Epoch: 1020 [40960/90000 (45%)]	Loss: 7.7103	Cost: 6.53s
Train Epoch: 1020 [61440/90000 (68%)]	Loss: 7.2625	Cost: 6.14s
Train Epoch: 1020 [81920/90000 (91%)]	Loss: 7.6576	Cost: 6.73s
Train Epoch: 1020 	Average Loss: 8.3421
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5055

Learning rate: 0.0001949096144990291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1021 [0/90000 (0%)]	Loss: 18.7957	Cost: 19.64s
Train Epoch: 1021 [20480/90000 (23%)]	Loss: 7.4487	Cost: 5.97s
Train Epoch: 1021 [40960/90000 (45%)]	Loss: 7.5484	Cost: 6.85s
Train Epoch: 1021 [61440/90000 (68%)]	Loss: 7.4937	Cost: 5.77s
Train Epoch: 1021 [81920/90000 (91%)]	Loss: 7.4134	Cost: 7.33s
Train Epoch: 1021 	Average Loss: 8.2654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6731

Learning rate: 0.0001948997142222289
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1022 [0/90000 (0%)]	Loss: 18.7840	Cost: 18.21s
Train Epoch: 1022 [20480/90000 (23%)]	Loss: 7.3018	Cost: 6.92s
Train Epoch: 1022 [40960/90000 (45%)]	Loss: 7.4313	Cost: 7.29s
Train Epoch: 1022 [61440/90000 (68%)]	Loss: 7.1893	Cost: 5.98s
Train Epoch: 1022 [81920/90000 (91%)]	Loss: 7.5154	Cost: 6.65s
Train Epoch: 1022 	Average Loss: 8.2097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6827

Learning rate: 0.00019488980457920237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1023 [0/90000 (0%)]	Loss: 18.4540	Cost: 20.85s
Train Epoch: 1023 [20480/90000 (23%)]	Loss: 7.5083	Cost: 6.83s
Train Epoch: 1023 [40960/90000 (45%)]	Loss: 7.6877	Cost: 6.62s
Train Epoch: 1023 [61440/90000 (68%)]	Loss: 7.5273	Cost: 5.83s
Train Epoch: 1023 [81920/90000 (91%)]	Loss: 7.3537	Cost: 6.62s
Train Epoch: 1023 	Average Loss: 8.2727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6066

Learning rate: 0.00019487988557092759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1024 [0/90000 (0%)]	Loss: 18.7679	Cost: 21.44s
Train Epoch: 1024 [20480/90000 (23%)]	Loss: 7.7419	Cost: 6.34s
Train Epoch: 1024 [40960/90000 (45%)]	Loss: 7.4587	Cost: 6.25s
Train Epoch: 1024 [61440/90000 (68%)]	Loss: 7.3688	Cost: 5.80s
Train Epoch: 1024 [81920/90000 (91%)]	Loss: 7.2572	Cost: 6.77s
Train Epoch: 1024 	Average Loss: 8.2438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6224

Learning rate: 0.00019486995719838354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1025 [0/90000 (0%)]	Loss: 19.0139	Cost: 25.23s
Train Epoch: 1025 [20480/90000 (23%)]	Loss: 7.3073	Cost: 6.10s
Train Epoch: 1025 [40960/90000 (45%)]	Loss: 7.6279	Cost: 7.02s
Train Epoch: 1025 [61440/90000 (68%)]	Loss: 7.4227	Cost: 5.98s
Train Epoch: 1025 [81920/90000 (91%)]	Loss: 7.5911	Cost: 6.10s
Train Epoch: 1025 	Average Loss: 8.2878
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6530

Learning rate: 0.00019486001946255008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1026 [0/90000 (0%)]	Loss: 19.0474	Cost: 28.99s
Train Epoch: 1026 [20480/90000 (23%)]	Loss: 7.4989	Cost: 6.03s
Train Epoch: 1026 [40960/90000 (45%)]	Loss: 7.4446	Cost: 6.29s
Train Epoch: 1026 [61440/90000 (68%)]	Loss: 7.3526	Cost: 5.98s
Train Epoch: 1026 [81920/90000 (91%)]	Loss: 7.6567	Cost: 6.48s
Train Epoch: 1026 	Average Loss: 8.2575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7304

Learning rate: 0.00019485007236440808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1027 [0/90000 (0%)]	Loss: 18.5668	Cost: 27.76s
Train Epoch: 1027 [20480/90000 (23%)]	Loss: 7.3926	Cost: 6.03s
Train Epoch: 1027 [40960/90000 (45%)]	Loss: 7.4064	Cost: 6.43s
Train Epoch: 1027 [61440/90000 (68%)]	Loss: 7.2565	Cost: 6.02s
Train Epoch: 1027 [81920/90000 (91%)]	Loss: 7.5606	Cost: 6.63s
Train Epoch: 1027 	Average Loss: 8.2640
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5692

Learning rate: 0.00019484011590493924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1028 [0/90000 (0%)]	Loss: 18.7502	Cost: 22.49s
Train Epoch: 1028 [20480/90000 (23%)]	Loss: 7.3315	Cost: 6.02s
Train Epoch: 1028 [40960/90000 (45%)]	Loss: 7.5342	Cost: 6.06s
Train Epoch: 1028 [61440/90000 (68%)]	Loss: 7.5449	Cost: 5.94s
Train Epoch: 1028 [81920/90000 (91%)]	Loss: 7.5570	Cost: 5.81s
Train Epoch: 1028 	Average Loss: 8.2475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6845

Learning rate: 0.0001948301500851262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1029 [0/90000 (0%)]	Loss: 18.7683	Cost: 23.90s
Train Epoch: 1029 [20480/90000 (23%)]	Loss: 8.1211	Cost: 6.30s
Train Epoch: 1029 [40960/90000 (45%)]	Loss: 8.2028	Cost: 6.42s
Train Epoch: 1029 [61440/90000 (68%)]	Loss: 8.1500	Cost: 6.10s
Train Epoch: 1029 [81920/90000 (91%)]	Loss: 8.1152	Cost: 6.16s
Train Epoch: 1029 	Average Loss: 8.7326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5712

Learning rate: 0.00019482017490595255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1030 [0/90000 (0%)]	Loss: 18.7555	Cost: 21.58s
Train Epoch: 1030 [20480/90000 (23%)]	Loss: 7.8913	Cost: 6.07s
Train Epoch: 1030 [40960/90000 (45%)]	Loss: 7.5724	Cost: 6.77s
Train Epoch: 1030 [61440/90000 (68%)]	Loss: 7.2915	Cost: 5.98s
Train Epoch: 1030 [81920/90000 (91%)]	Loss: 7.5591	Cost: 5.94s
Train Epoch: 1030 	Average Loss: 8.3813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4722

Learning rate: 0.00019481019036840283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1031 [0/90000 (0%)]	Loss: 18.7506	Cost: 20.75s
Train Epoch: 1031 [20480/90000 (23%)]	Loss: 7.4253	Cost: 6.21s
Train Epoch: 1031 [40960/90000 (45%)]	Loss: 7.3789	Cost: 7.18s
Train Epoch: 1031 [61440/90000 (68%)]	Loss: 7.2638	Cost: 6.27s
Train Epoch: 1031 [81920/90000 (91%)]	Loss: 7.4008	Cost: 6.70s
Train Epoch: 1031 	Average Loss: 8.2061
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5678

Learning rate: 0.0001948001964734625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1032 [0/90000 (0%)]	Loss: 18.8574	Cost: 20.06s
Train Epoch: 1032 [20480/90000 (23%)]	Loss: 7.6230	Cost: 6.24s
Train Epoch: 1032 [40960/90000 (45%)]	Loss: 7.5398	Cost: 6.61s
Train Epoch: 1032 [61440/90000 (68%)]	Loss: 7.3027	Cost: 6.09s
Train Epoch: 1032 [81920/90000 (91%)]	Loss: 7.5196	Cost: 6.06s
Train Epoch: 1032 	Average Loss: 8.2836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7242

Learning rate: 0.00019479019322211785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1033 [0/90000 (0%)]	Loss: 18.9151	Cost: 20.09s
Train Epoch: 1033 [20480/90000 (23%)]	Loss: 7.4935	Cost: 6.16s
Train Epoch: 1033 [40960/90000 (45%)]	Loss: 7.6073	Cost: 6.49s
Train Epoch: 1033 [61440/90000 (68%)]	Loss: 7.2998	Cost: 6.06s
Train Epoch: 1033 [81920/90000 (91%)]	Loss: 7.4642	Cost: 6.94s
Train Epoch: 1033 	Average Loss: 8.3172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6797

Learning rate: 0.00019478018061535622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1034 [0/90000 (0%)]	Loss: 18.9434	Cost: 20.68s
Train Epoch: 1034 [20480/90000 (23%)]	Loss: 7.6047	Cost: 6.13s
Train Epoch: 1034 [40960/90000 (45%)]	Loss: 7.4984	Cost: 6.26s
Train Epoch: 1034 [61440/90000 (68%)]	Loss: 7.4118	Cost: 6.03s
Train Epoch: 1034 [81920/90000 (91%)]	Loss: 7.1644	Cost: 5.91s
Train Epoch: 1034 	Average Loss: 8.3048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6743

Learning rate: 0.0001947701586541658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1035 [0/90000 (0%)]	Loss: 18.6979	Cost: 21.46s
Train Epoch: 1035 [20480/90000 (23%)]	Loss: 7.5318	Cost: 6.30s
Train Epoch: 1035 [40960/90000 (45%)]	Loss: 7.1175	Cost: 6.12s
Train Epoch: 1035 [61440/90000 (68%)]	Loss: 7.2456	Cost: 6.02s
Train Epoch: 1035 [81920/90000 (91%)]	Loss: 7.3288	Cost: 6.08s
Train Epoch: 1035 	Average Loss: 8.2448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7818

Learning rate: 0.00019476012733953566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1036 [0/90000 (0%)]	Loss: 18.6500	Cost: 20.46s
Train Epoch: 1036 [20480/90000 (23%)]	Loss: 7.6243	Cost: 6.20s
Train Epoch: 1036 [40960/90000 (45%)]	Loss: 7.4078	Cost: 6.15s
Train Epoch: 1036 [61440/90000 (68%)]	Loss: 7.2838	Cost: 5.98s
Train Epoch: 1036 [81920/90000 (91%)]	Loss: 7.5639	Cost: 6.52s
Train Epoch: 1036 	Average Loss: 8.2764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6727

Learning rate: 0.0001947500866724559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1037 [0/90000 (0%)]	Loss: 18.8204	Cost: 20.50s
Train Epoch: 1037 [20480/90000 (23%)]	Loss: 7.4946	Cost: 6.21s
Train Epoch: 1037 [40960/90000 (45%)]	Loss: 7.5959	Cost: 6.35s
Train Epoch: 1037 [61440/90000 (68%)]	Loss: 7.1220	Cost: 5.96s
Train Epoch: 1037 [81920/90000 (91%)]	Loss: 7.4247	Cost: 6.24s
Train Epoch: 1037 	Average Loss: 8.2588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7115

Learning rate: 0.00019474003665391753
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1038 [0/90000 (0%)]	Loss: 18.9350	Cost: 20.83s
Train Epoch: 1038 [20480/90000 (23%)]	Loss: 7.4091	Cost: 6.14s
Train Epoch: 1038 [40960/90000 (45%)]	Loss: 7.4083	Cost: 6.13s
Train Epoch: 1038 [61440/90000 (68%)]	Loss: 7.4625	Cost: 5.73s
Train Epoch: 1038 [81920/90000 (91%)]	Loss: 7.6415	Cost: 6.55s
Train Epoch: 1038 	Average Loss: 8.1515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6920

Learning rate: 0.0001947299772849124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1039 [0/90000 (0%)]	Loss: 18.8228	Cost: 20.47s
Train Epoch: 1039 [20480/90000 (23%)]	Loss: 7.2569	Cost: 6.14s
Train Epoch: 1039 [40960/90000 (45%)]	Loss: 7.1886	Cost: 6.03s
Train Epoch: 1039 [61440/90000 (68%)]	Loss: 7.0996	Cost: 5.97s
Train Epoch: 1039 [81920/90000 (91%)]	Loss: 7.4074	Cost: 6.40s
Train Epoch: 1039 	Average Loss: 8.1351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7133

Learning rate: 0.00019471990856643334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1040 [0/90000 (0%)]	Loss: 18.7652	Cost: 21.61s
Train Epoch: 1040 [20480/90000 (23%)]	Loss: 7.3147	Cost: 6.12s
Train Epoch: 1040 [40960/90000 (45%)]	Loss: 7.1488	Cost: 6.07s
Train Epoch: 1040 [61440/90000 (68%)]	Loss: 6.9539	Cost: 6.05s
Train Epoch: 1040 [81920/90000 (91%)]	Loss: 7.1593	Cost: 5.86s
Train Epoch: 1040 	Average Loss: 8.0726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8217

Learning rate: 0.0001947098304994741
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1041 [0/90000 (0%)]	Loss: 18.8006	Cost: 20.47s
Train Epoch: 1041 [20480/90000 (23%)]	Loss: 7.2419	Cost: 6.13s
Train Epoch: 1041 [40960/90000 (45%)]	Loss: 7.1236	Cost: 6.32s
Train Epoch: 1041 [61440/90000 (68%)]	Loss: 7.1457	Cost: 5.92s
Train Epoch: 1041 [81920/90000 (91%)]	Loss: 7.1210	Cost: 6.22s
Train Epoch: 1041 	Average Loss: 7.9841
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7446

Learning rate: 0.0001946997430850293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1042 [0/90000 (0%)]	Loss: 18.8468	Cost: 21.24s
Train Epoch: 1042 [20480/90000 (23%)]	Loss: 7.2012	Cost: 6.30s
Train Epoch: 1042 [40960/90000 (45%)]	Loss: 7.1857	Cost: 6.40s
Train Epoch: 1042 [61440/90000 (68%)]	Loss: 6.9960	Cost: 6.23s
Train Epoch: 1042 [81920/90000 (91%)]	Loss: 7.2928	Cost: 6.14s
Train Epoch: 1042 	Average Loss: 8.0171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7284

Learning rate: 0.0001946896463240946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1043 [0/90000 (0%)]	Loss: 18.7900	Cost: 19.81s
Train Epoch: 1043 [20480/90000 (23%)]	Loss: 7.3743	Cost: 6.04s
Train Epoch: 1043 [40960/90000 (45%)]	Loss: 7.1402	Cost: 6.02s
Train Epoch: 1043 [61440/90000 (68%)]	Loss: 7.2567	Cost: 6.03s
Train Epoch: 1043 [81920/90000 (91%)]	Loss: 7.4529	Cost: 5.98s
Train Epoch: 1043 	Average Loss: 8.1378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7086

Learning rate: 0.00019467954021766648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1044 [0/90000 (0%)]	Loss: 19.1352	Cost: 19.28s
Train Epoch: 1044 [20480/90000 (23%)]	Loss: 7.5742	Cost: 6.09s
Train Epoch: 1044 [40960/90000 (45%)]	Loss: 7.5094	Cost: 6.16s
Train Epoch: 1044 [61440/90000 (68%)]	Loss: 7.3623	Cost: 6.07s
Train Epoch: 1044 [81920/90000 (91%)]	Loss: 7.5780	Cost: 6.02s
Train Epoch: 1044 	Average Loss: 8.3166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8228

Learning rate: 0.00019466942476674236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1045 [0/90000 (0%)]	Loss: 18.9199	Cost: 19.83s
Train Epoch: 1045 [20480/90000 (23%)]	Loss: 7.3006	Cost: 6.12s
Train Epoch: 1045 [40960/90000 (45%)]	Loss: 7.2288	Cost: 6.03s
Train Epoch: 1045 [61440/90000 (68%)]	Loss: 7.0196	Cost: 5.93s
Train Epoch: 1045 [81920/90000 (91%)]	Loss: 7.2680	Cost: 5.96s
Train Epoch: 1045 	Average Loss: 8.0898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8136

Learning rate: 0.00019465929997232058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1046 [0/90000 (0%)]	Loss: 18.3764	Cost: 20.07s
Train Epoch: 1046 [20480/90000 (23%)]	Loss: 7.1665	Cost: 6.18s
Train Epoch: 1046 [40960/90000 (45%)]	Loss: 7.3222	Cost: 6.13s
Train Epoch: 1046 [61440/90000 (68%)]	Loss: 7.1321	Cost: 6.03s
Train Epoch: 1046 [81920/90000 (91%)]	Loss: 7.0426	Cost: 6.75s
Train Epoch: 1046 	Average Loss: 7.9679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7078

Learning rate: 0.00019464916583540045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1047 [0/90000 (0%)]	Loss: 19.1722	Cost: 19.86s
Train Epoch: 1047 [20480/90000 (23%)]	Loss: 7.2104	Cost: 6.19s
Train Epoch: 1047 [40960/90000 (45%)]	Loss: 7.3633	Cost: 6.10s
Train Epoch: 1047 [61440/90000 (68%)]	Loss: 7.0607	Cost: 6.04s
Train Epoch: 1047 [81920/90000 (91%)]	Loss: 7.0793	Cost: 6.00s
Train Epoch: 1047 	Average Loss: 8.0266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7054

Learning rate: 0.00019463902235698218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1048 [0/90000 (0%)]	Loss: 18.7120	Cost: 20.28s
Train Epoch: 1048 [20480/90000 (23%)]	Loss: 7.1916	Cost: 6.01s
Train Epoch: 1048 [40960/90000 (45%)]	Loss: 7.3085	Cost: 6.24s
Train Epoch: 1048 [61440/90000 (68%)]	Loss: 7.1105	Cost: 5.94s
Train Epoch: 1048 [81920/90000 (91%)]	Loss: 7.1368	Cost: 6.50s
Train Epoch: 1048 	Average Loss: 7.9551
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8687

Learning rate: 0.00019462886953806687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1049 [0/90000 (0%)]	Loss: 18.7328	Cost: 21.18s
Train Epoch: 1049 [20480/90000 (23%)]	Loss: 7.2238	Cost: 6.11s
Train Epoch: 1049 [40960/90000 (45%)]	Loss: 7.3309	Cost: 6.18s
Train Epoch: 1049 [61440/90000 (68%)]	Loss: 7.3645	Cost: 5.94s
Train Epoch: 1049 [81920/90000 (91%)]	Loss: 7.3169	Cost: 5.96s
Train Epoch: 1049 	Average Loss: 8.0531
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7190

Learning rate: 0.00019461870737965656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1050 [0/90000 (0%)]	Loss: 18.9980	Cost: 21.36s
Train Epoch: 1050 [20480/90000 (23%)]	Loss: 7.0455	Cost: 6.08s
Train Epoch: 1050 [40960/90000 (45%)]	Loss: 7.2144	Cost: 6.79s
Train Epoch: 1050 [61440/90000 (68%)]	Loss: 7.4336	Cost: 5.95s
Train Epoch: 1050 [81920/90000 (91%)]	Loss: 7.4620	Cost: 6.30s
Train Epoch: 1050 	Average Loss: 8.1099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8699

Learning rate: 0.00019460853588275422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1051 [0/90000 (0%)]	Loss: 19.0888	Cost: 21.62s
Train Epoch: 1051 [20480/90000 (23%)]	Loss: 7.5646	Cost: 6.09s
Train Epoch: 1051 [40960/90000 (45%)]	Loss: 7.3933	Cost: 6.12s
Train Epoch: 1051 [61440/90000 (68%)]	Loss: 7.2825	Cost: 5.97s
Train Epoch: 1051 [81920/90000 (91%)]	Loss: 7.4899	Cost: 6.26s
Train Epoch: 1051 	Average Loss: 8.2357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8104

Learning rate: 0.00019459835504836374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1052 [0/90000 (0%)]	Loss: 18.6301	Cost: 20.61s
Train Epoch: 1052 [20480/90000 (23%)]	Loss: 7.4369	Cost: 6.08s
Train Epoch: 1052 [40960/90000 (45%)]	Loss: 7.4078	Cost: 6.69s
Train Epoch: 1052 [61440/90000 (68%)]	Loss: 7.1450	Cost: 6.05s
Train Epoch: 1052 [81920/90000 (91%)]	Loss: 7.3377	Cost: 6.40s
Train Epoch: 1052 	Average Loss: 8.1816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7931

Learning rate: 0.0001945881648774899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1053 [0/90000 (0%)]	Loss: 18.6442	Cost: 21.01s
Train Epoch: 1053 [20480/90000 (23%)]	Loss: 7.1980	Cost: 6.00s
Train Epoch: 1053 [40960/90000 (45%)]	Loss: 6.9175	Cost: 6.27s
Train Epoch: 1053 [61440/90000 (68%)]	Loss: 7.0327	Cost: 6.09s
Train Epoch: 1053 [81920/90000 (91%)]	Loss: 7.2949	Cost: 5.96s
Train Epoch: 1053 	Average Loss: 7.9286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8303

Learning rate: 0.00019457796537113845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1054 [0/90000 (0%)]	Loss: 18.6768	Cost: 20.89s
Train Epoch: 1054 [20480/90000 (23%)]	Loss: 7.1360	Cost: 6.25s
Train Epoch: 1054 [40960/90000 (45%)]	Loss: 7.0512	Cost: 6.13s
Train Epoch: 1054 [61440/90000 (68%)]	Loss: 6.8823	Cost: 5.91s
Train Epoch: 1054 [81920/90000 (91%)]	Loss: 7.1218	Cost: 6.13s
Train Epoch: 1054 	Average Loss: 7.9193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8775

Learning rate: 0.00019456775653031605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1055 [0/90000 (0%)]	Loss: 18.9187	Cost: 21.01s
Train Epoch: 1055 [20480/90000 (23%)]	Loss: 7.1672	Cost: 6.13s
Train Epoch: 1055 [40960/90000 (45%)]	Loss: 7.1148	Cost: 6.17s
Train Epoch: 1055 [61440/90000 (68%)]	Loss: 7.0781	Cost: 6.02s
Train Epoch: 1055 [81920/90000 (91%)]	Loss: 7.2978	Cost: 6.47s
Train Epoch: 1055 	Average Loss: 7.9096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8287

Learning rate: 0.0001945575383560303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1056 [0/90000 (0%)]	Loss: 18.6946	Cost: 20.37s
Train Epoch: 1056 [20480/90000 (23%)]	Loss: 7.0390	Cost: 6.14s
Train Epoch: 1056 [40960/90000 (45%)]	Loss: 6.9533	Cost: 6.13s
Train Epoch: 1056 [61440/90000 (68%)]	Loss: 7.0049	Cost: 6.13s
Train Epoch: 1056 [81920/90000 (91%)]	Loss: 6.9497	Cost: 5.99s
Train Epoch: 1056 	Average Loss: 7.9172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8646

Learning rate: 0.00019454731084928963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1057 [0/90000 (0%)]	Loss: 19.0343	Cost: 20.65s
Train Epoch: 1057 [20480/90000 (23%)]	Loss: 6.9333	Cost: 6.25s
Train Epoch: 1057 [40960/90000 (45%)]	Loss: 6.8887	Cost: 6.01s
Train Epoch: 1057 [61440/90000 (68%)]	Loss: 6.9203	Cost: 6.05s
Train Epoch: 1057 [81920/90000 (91%)]	Loss: 7.0761	Cost: 6.12s
Train Epoch: 1057 	Average Loss: 7.8683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9665

Learning rate: 0.0001945370740111035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1058 [0/90000 (0%)]	Loss: 19.0592	Cost: 20.80s
Train Epoch: 1058 [20480/90000 (23%)]	Loss: 7.0018	Cost: 5.94s
Train Epoch: 1058 [40960/90000 (45%)]	Loss: 7.1015	Cost: 5.97s
Train Epoch: 1058 [61440/90000 (68%)]	Loss: 7.0408	Cost: 5.93s
Train Epoch: 1058 [81920/90000 (91%)]	Loss: 7.1579	Cost: 6.13s
Train Epoch: 1058 	Average Loss: 7.9415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9137

Learning rate: 0.00019452682784248221
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1059 [0/90000 (0%)]	Loss: 18.9048	Cost: 20.61s
Train Epoch: 1059 [20480/90000 (23%)]	Loss: 7.0077	Cost: 6.18s
Train Epoch: 1059 [40960/90000 (45%)]	Loss: 7.0049	Cost: 6.33s
Train Epoch: 1059 [61440/90000 (68%)]	Loss: 7.1659	Cost: 5.83s
Train Epoch: 1059 [81920/90000 (91%)]	Loss: 7.1635	Cost: 6.44s
Train Epoch: 1059 	Average Loss: 7.9045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8603

Learning rate: 0.00019451657234443705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1060 [0/90000 (0%)]	Loss: 18.7812	Cost: 20.64s
Train Epoch: 1060 [20480/90000 (23%)]	Loss: 6.9619	Cost: 5.90s
Train Epoch: 1060 [40960/90000 (45%)]	Loss: 7.1351	Cost: 6.07s
Train Epoch: 1060 [61440/90000 (68%)]	Loss: 6.9371	Cost: 5.75s
Train Epoch: 1060 [81920/90000 (91%)]	Loss: 7.2345	Cost: 6.56s
Train Epoch: 1060 	Average Loss: 7.9071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8878

Learning rate: 0.00019450630751798018
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1061 [0/90000 (0%)]	Loss: 18.9412	Cost: 19.89s
Train Epoch: 1061 [20480/90000 (23%)]	Loss: 7.1084	Cost: 6.02s
Train Epoch: 1061 [40960/90000 (45%)]	Loss: 7.1147	Cost: 5.98s
Train Epoch: 1061 [61440/90000 (68%)]	Loss: 7.0539	Cost: 5.82s
Train Epoch: 1061 [81920/90000 (91%)]	Loss: 7.0536	Cost: 6.56s
Train Epoch: 1061 	Average Loss: 7.8699
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9620

Learning rate: 0.0001944960333641247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1062 [0/90000 (0%)]	Loss: 19.1436	Cost: 21.35s
Train Epoch: 1062 [20480/90000 (23%)]	Loss: 7.1781	Cost: 5.96s
Train Epoch: 1062 [40960/90000 (45%)]	Loss: 7.3022	Cost: 6.27s
Train Epoch: 1062 [61440/90000 (68%)]	Loss: 7.2134	Cost: 5.80s
Train Epoch: 1062 [81920/90000 (91%)]	Loss: 7.2011	Cost: 6.47s
Train Epoch: 1062 	Average Loss: 8.0586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9850

Learning rate: 0.0001944857498838846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1063 [0/90000 (0%)]	Loss: 19.1096	Cost: 20.70s
Train Epoch: 1063 [20480/90000 (23%)]	Loss: 7.4173	Cost: 6.01s
Train Epoch: 1063 [40960/90000 (45%)]	Loss: 7.3071	Cost: 5.99s
Train Epoch: 1063 [61440/90000 (68%)]	Loss: 7.5215	Cost: 5.84s
Train Epoch: 1063 [81920/90000 (91%)]	Loss: 7.6467	Cost: 5.99s
Train Epoch: 1063 	Average Loss: 8.3303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8792

Learning rate: 0.00019447545707827488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1064 [0/90000 (0%)]	Loss: 18.9660	Cost: 20.80s
Train Epoch: 1064 [20480/90000 (23%)]	Loss: 7.3218	Cost: 6.04s
Train Epoch: 1064 [40960/90000 (45%)]	Loss: 7.1047	Cost: 6.31s
Train Epoch: 1064 [61440/90000 (68%)]	Loss: 6.9259	Cost: 6.16s
Train Epoch: 1064 [81920/90000 (91%)]	Loss: 7.2922	Cost: 6.02s
Train Epoch: 1064 	Average Loss: 8.0649
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8596

Learning rate: 0.00019446515494831135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1065 [0/90000 (0%)]	Loss: 19.0355	Cost: 21.45s
Train Epoch: 1065 [20480/90000 (23%)]	Loss: 7.3462	Cost: 6.01s
Train Epoch: 1065 [40960/90000 (45%)]	Loss: 7.2540	Cost: 5.97s
Train Epoch: 1065 [61440/90000 (68%)]	Loss: 7.0908	Cost: 5.81s
Train Epoch: 1065 [81920/90000 (91%)]	Loss: 7.1680	Cost: 6.20s
Train Epoch: 1065 	Average Loss: 8.0152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9055

Learning rate: 0.00019445484349501084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1066 [0/90000 (0%)]	Loss: 19.2645	Cost: 20.54s
Train Epoch: 1066 [20480/90000 (23%)]	Loss: 7.3306	Cost: 5.95s
Train Epoch: 1066 [40960/90000 (45%)]	Loss: 7.1079	Cost: 6.33s
Train Epoch: 1066 [61440/90000 (68%)]	Loss: 7.0888	Cost: 5.83s
Train Epoch: 1066 [81920/90000 (91%)]	Loss: 7.3131	Cost: 6.61s
Train Epoch: 1066 	Average Loss: 7.9984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9078

Learning rate: 0.00019444452271939096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1067 [0/90000 (0%)]	Loss: 19.1160	Cost: 21.20s
Train Epoch: 1067 [20480/90000 (23%)]	Loss: 7.2260	Cost: 5.90s
Train Epoch: 1067 [40960/90000 (45%)]	Loss: 7.0792	Cost: 6.54s
Train Epoch: 1067 [61440/90000 (68%)]	Loss: 6.9615	Cost: 5.79s
Train Epoch: 1067 [81920/90000 (91%)]	Loss: 6.8272	Cost: 7.50s
Train Epoch: 1067 	Average Loss: 7.9270
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0681

Learning rate: 0.0001944341926224704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1068 [0/90000 (0%)]	Loss: 18.9385	Cost: 20.21s
Train Epoch: 1068 [20480/90000 (23%)]	Loss: 6.9569	Cost: 5.96s
Train Epoch: 1068 [40960/90000 (45%)]	Loss: 6.9698	Cost: 5.99s
Train Epoch: 1068 [61440/90000 (68%)]	Loss: 7.0312	Cost: 5.81s
Train Epoch: 1068 [81920/90000 (91%)]	Loss: 7.0093	Cost: 6.09s
Train Epoch: 1068 	Average Loss: 7.8565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8280

Learning rate: 0.00019442385320526872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1069 [0/90000 (0%)]	Loss: 18.9836	Cost: 20.10s
Train Epoch: 1069 [20480/90000 (23%)]	Loss: 6.8611	Cost: 6.04s
Train Epoch: 1069 [40960/90000 (45%)]	Loss: 6.7800	Cost: 6.17s
Train Epoch: 1069 [61440/90000 (68%)]	Loss: 6.8382	Cost: 5.87s
Train Epoch: 1069 [81920/90000 (91%)]	Loss: 6.9938	Cost: 7.02s
Train Epoch: 1069 	Average Loss: 7.7836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9213

Learning rate: 0.00019441350446880632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1070 [0/90000 (0%)]	Loss: 18.9116	Cost: 20.29s
Train Epoch: 1070 [20480/90000 (23%)]	Loss: 7.0673	Cost: 5.97s
Train Epoch: 1070 [40960/90000 (45%)]	Loss: 7.3931	Cost: 6.36s
Train Epoch: 1070 [61440/90000 (68%)]	Loss: 7.0597	Cost: 5.80s
Train Epoch: 1070 [81920/90000 (91%)]	Loss: 7.1213	Cost: 6.66s
Train Epoch: 1070 	Average Loss: 7.9294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9597

Learning rate: 0.00019440314641410464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1071 [0/90000 (0%)]	Loss: 18.9394	Cost: 20.12s
Train Epoch: 1071 [20480/90000 (23%)]	Loss: 7.3147	Cost: 6.00s
Train Epoch: 1071 [40960/90000 (45%)]	Loss: 6.8613	Cost: 6.05s
Train Epoch: 1071 [61440/90000 (68%)]	Loss: 7.0782	Cost: 5.86s
Train Epoch: 1071 [81920/90000 (91%)]	Loss: 7.1188	Cost: 7.18s
Train Epoch: 1071 	Average Loss: 7.8494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0572

Learning rate: 0.0001943927790421859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1072 [0/90000 (0%)]	Loss: 18.9875	Cost: 20.81s
Train Epoch: 1072 [20480/90000 (23%)]	Loss: 7.3097	Cost: 6.03s
Train Epoch: 1072 [40960/90000 (45%)]	Loss: 7.6141	Cost: 6.22s
Train Epoch: 1072 [61440/90000 (68%)]	Loss: 7.4408	Cost: 5.82s
Train Epoch: 1072 [81920/90000 (91%)]	Loss: 7.6326	Cost: 6.32s
Train Epoch: 1072 	Average Loss: 8.2133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8719

Learning rate: 0.00019438240235407337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1073 [0/90000 (0%)]	Loss: 19.0152	Cost: 21.12s
Train Epoch: 1073 [20480/90000 (23%)]	Loss: 7.2322	Cost: 5.89s
Train Epoch: 1073 [40960/90000 (45%)]	Loss: 7.6536	Cost: 6.43s
Train Epoch: 1073 [61440/90000 (68%)]	Loss: 7.0831	Cost: 5.83s
Train Epoch: 1073 [81920/90000 (91%)]	Loss: 7.3913	Cost: 6.62s
Train Epoch: 1073 	Average Loss: 8.2292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9143

Learning rate: 0.0001943720163507912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1074 [0/90000 (0%)]	Loss: 18.8989	Cost: 21.31s
Train Epoch: 1074 [20480/90000 (23%)]	Loss: 7.3284	Cost: 5.99s
Train Epoch: 1074 [40960/90000 (45%)]	Loss: 8.3904	Cost: 6.36s
Train Epoch: 1074 [61440/90000 (68%)]	Loss: 7.9303	Cost: 6.16s
Train Epoch: 1074 [81920/90000 (91%)]	Loss: 8.1220	Cost: 6.51s
Train Epoch: 1074 	Average Loss: 8.5852
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7647

Learning rate: 0.0001943616210333644
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1075 [0/90000 (0%)]	Loss: 18.8726	Cost: 20.82s
Train Epoch: 1075 [20480/90000 (23%)]	Loss: 7.9069	Cost: 5.94s
Train Epoch: 1075 [40960/90000 (45%)]	Loss: 7.6741	Cost: 6.22s
Train Epoch: 1075 [61440/90000 (68%)]	Loss: 7.5840	Cost: 6.29s
Train Epoch: 1075 [81920/90000 (91%)]	Loss: 7.1766	Cost: 6.62s
Train Epoch: 1075 	Average Loss: 8.3333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8700

Learning rate: 0.000194351216402819
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1076 [0/90000 (0%)]	Loss: 18.7251	Cost: 21.29s
Train Epoch: 1076 [20480/90000 (23%)]	Loss: 7.1415	Cost: 5.86s
Train Epoch: 1076 [40960/90000 (45%)]	Loss: 6.8944	Cost: 6.06s
Train Epoch: 1076 [61440/90000 (68%)]	Loss: 7.1852	Cost: 5.96s
Train Epoch: 1076 [81920/90000 (91%)]	Loss: 7.0765	Cost: 7.65s
Train Epoch: 1076 	Average Loss: 7.9744
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9009

Learning rate: 0.00019434080246018187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1077 [0/90000 (0%)]	Loss: 19.0616	Cost: 19.70s
Train Epoch: 1077 [20480/90000 (23%)]	Loss: 7.5154	Cost: 5.87s
Train Epoch: 1077 [40960/90000 (45%)]	Loss: 7.3037	Cost: 6.39s
Train Epoch: 1077 [61440/90000 (68%)]	Loss: 7.1781	Cost: 6.22s
Train Epoch: 1077 [81920/90000 (91%)]	Loss: 7.2611	Cost: 6.83s
Train Epoch: 1077 	Average Loss: 8.1141
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8989

Learning rate: 0.00019433037920648082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1078 [0/90000 (0%)]	Loss: 18.8878	Cost: 19.91s
Train Epoch: 1078 [20480/90000 (23%)]	Loss: 7.0047	Cost: 6.02s
Train Epoch: 1078 [40960/90000 (45%)]	Loss: 7.1136	Cost: 6.03s
Train Epoch: 1078 [61440/90000 (68%)]	Loss: 6.6856	Cost: 6.14s
Train Epoch: 1078 [81920/90000 (91%)]	Loss: 6.9542	Cost: 6.13s
Train Epoch: 1078 	Average Loss: 7.8155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8754

Learning rate: 0.0001943199466427446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1079 [0/90000 (0%)]	Loss: 18.9458	Cost: 20.21s
Train Epoch: 1079 [20480/90000 (23%)]	Loss: 7.0748	Cost: 5.94s
Train Epoch: 1079 [40960/90000 (45%)]	Loss: 6.8894	Cost: 6.79s
Train Epoch: 1079 [61440/90000 (68%)]	Loss: 7.0177	Cost: 6.19s
Train Epoch: 1079 [81920/90000 (91%)]	Loss: 6.9830	Cost: 6.87s
Train Epoch: 1079 	Average Loss: 7.8003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9912

Learning rate: 0.0001943095047700028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1080 [0/90000 (0%)]	Loss: 18.9774	Cost: 20.44s
Train Epoch: 1080 [20480/90000 (23%)]	Loss: 6.7712	Cost: 6.01s
Train Epoch: 1080 [40960/90000 (45%)]	Loss: 6.9599	Cost: 6.01s
Train Epoch: 1080 [61440/90000 (68%)]	Loss: 6.8094	Cost: 6.09s
Train Epoch: 1080 [81920/90000 (91%)]	Loss: 7.1494	Cost: 6.62s
Train Epoch: 1080 	Average Loss: 7.7977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9273

Learning rate: 0.00019429905358928608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1081 [0/90000 (0%)]	Loss: 19.1117	Cost: 19.61s
Train Epoch: 1081 [20480/90000 (23%)]	Loss: 6.9333	Cost: 5.95s
Train Epoch: 1081 [40960/90000 (45%)]	Loss: 6.9846	Cost: 5.97s
Train Epoch: 1081 [61440/90000 (68%)]	Loss: 6.7938	Cost: 6.04s
Train Epoch: 1081 [81920/90000 (91%)]	Loss: 6.9388	Cost: 6.15s
Train Epoch: 1081 	Average Loss: 7.7512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0671

Learning rate: 0.0001942885931016259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1082 [0/90000 (0%)]	Loss: 19.4810	Cost: 21.19s
Train Epoch: 1082 [20480/90000 (23%)]	Loss: 6.9015	Cost: 5.99s
Train Epoch: 1082 [40960/90000 (45%)]	Loss: 7.4637	Cost: 6.32s
Train Epoch: 1082 [61440/90000 (68%)]	Loss: 7.1235	Cost: 6.18s
Train Epoch: 1082 [81920/90000 (91%)]	Loss: 7.4904	Cost: 7.45s
Train Epoch: 1082 	Average Loss: 8.0242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0584

Learning rate: 0.00019427812330805462
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1083 [0/90000 (0%)]	Loss: 18.7154	Cost: 20.59s
Train Epoch: 1083 [20480/90000 (23%)]	Loss: 7.2094	Cost: 5.85s
Train Epoch: 1083 [40960/90000 (45%)]	Loss: 7.3833	Cost: 6.23s
Train Epoch: 1083 [61440/90000 (68%)]	Loss: 6.8105	Cost: 6.21s
Train Epoch: 1083 [81920/90000 (91%)]	Loss: 7.1483	Cost: 7.78s
Train Epoch: 1083 	Average Loss: 8.0005
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8752

Learning rate: 0.00019426764420960564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1084 [0/90000 (0%)]	Loss: 18.9962	Cost: 21.69s
Train Epoch: 1084 [20480/90000 (23%)]	Loss: 7.1811	Cost: 5.95s
Train Epoch: 1084 [40960/90000 (45%)]	Loss: 7.1971	Cost: 6.53s
Train Epoch: 1084 [61440/90000 (68%)]	Loss: 7.1733	Cost: 6.38s
Train Epoch: 1084 [81920/90000 (91%)]	Loss: 7.3743	Cost: 7.76s
Train Epoch: 1084 	Average Loss: 8.0154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0252

Learning rate: 0.00019425715580731318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1085 [0/90000 (0%)]	Loss: 18.8578	Cost: 19.76s
Train Epoch: 1085 [20480/90000 (23%)]	Loss: 7.2038	Cost: 5.96s
Train Epoch: 1085 [40960/90000 (45%)]	Loss: 7.1771	Cost: 6.10s
Train Epoch: 1085 [61440/90000 (68%)]	Loss: 7.1059	Cost: 6.14s
Train Epoch: 1085 [81920/90000 (91%)]	Loss: 7.3632	Cost: 7.43s
Train Epoch: 1085 	Average Loss: 8.0146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9756

Learning rate: 0.00019424665810221242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1086 [0/90000 (0%)]	Loss: 18.8779	Cost: 20.47s
Train Epoch: 1086 [20480/90000 (23%)]	Loss: 7.1202	Cost: 6.23s
Train Epoch: 1086 [40960/90000 (45%)]	Loss: 7.1126	Cost: 6.03s
Train Epoch: 1086 [61440/90000 (68%)]	Loss: 6.8072	Cost: 6.14s
Train Epoch: 1086 [81920/90000 (91%)]	Loss: 6.8770	Cost: 6.54s
Train Epoch: 1086 	Average Loss: 7.8145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9264

Learning rate: 0.00019423615109533942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1087 [0/90000 (0%)]	Loss: 18.9486	Cost: 20.27s
Train Epoch: 1087 [20480/90000 (23%)]	Loss: 6.8626	Cost: 5.97s
Train Epoch: 1087 [40960/90000 (45%)]	Loss: 6.8750	Cost: 6.15s
Train Epoch: 1087 [61440/90000 (68%)]	Loss: 6.9395	Cost: 6.03s
Train Epoch: 1087 [81920/90000 (91%)]	Loss: 6.6485	Cost: 7.34s
Train Epoch: 1087 	Average Loss: 7.7096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1557

Learning rate: 0.00019422563478773116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1088 [0/90000 (0%)]	Loss: 19.1252	Cost: 19.97s
Train Epoch: 1088 [20480/90000 (23%)]	Loss: 6.8518	Cost: 5.95s
Train Epoch: 1088 [40960/90000 (45%)]	Loss: 6.9291	Cost: 6.53s
Train Epoch: 1088 [61440/90000 (68%)]	Loss: 6.7335	Cost: 6.06s
Train Epoch: 1088 [81920/90000 (91%)]	Loss: 7.0003	Cost: 8.14s
Train Epoch: 1088 	Average Loss: 7.7504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9928

Learning rate: 0.00019421510918042557
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1089 [0/90000 (0%)]	Loss: 19.0053	Cost: 20.94s
Train Epoch: 1089 [20480/90000 (23%)]	Loss: 6.8711	Cost: 5.96s
Train Epoch: 1089 [40960/90000 (45%)]	Loss: 7.0831	Cost: 6.20s
Train Epoch: 1089 [61440/90000 (68%)]	Loss: 6.8158	Cost: 6.01s
Train Epoch: 1089 [81920/90000 (91%)]	Loss: 6.9743	Cost: 7.45s
Train Epoch: 1089 	Average Loss: 7.8330
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9012

Learning rate: 0.0001942045742744615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1090 [0/90000 (0%)]	Loss: 19.1135	Cost: 20.87s
Train Epoch: 1090 [20480/90000 (23%)]	Loss: 6.7871	Cost: 5.87s
Train Epoch: 1090 [40960/90000 (45%)]	Loss: 6.9220	Cost: 7.44s
Train Epoch: 1090 [61440/90000 (68%)]	Loss: 6.8663	Cost: 6.14s
Train Epoch: 1090 [81920/90000 (91%)]	Loss: 7.0801	Cost: 8.18s
Train Epoch: 1090 	Average Loss: 7.7597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1078

Learning rate: 0.0001941940300708787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1091 [0/90000 (0%)]	Loss: 18.8575	Cost: 20.65s
Train Epoch: 1091 [20480/90000 (23%)]	Loss: 6.7646	Cost: 5.88s
Train Epoch: 1091 [40960/90000 (45%)]	Loss: 6.8466	Cost: 6.47s
Train Epoch: 1091 [61440/90000 (68%)]	Loss: 6.6220	Cost: 6.18s
Train Epoch: 1091 [81920/90000 (91%)]	Loss: 6.8682	Cost: 7.37s
Train Epoch: 1091 	Average Loss: 7.6642
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0562

Learning rate: 0.00019418347657071785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1092 [0/90000 (0%)]	Loss: 19.2170	Cost: 19.44s
Train Epoch: 1092 [20480/90000 (23%)]	Loss: 6.9944	Cost: 5.87s
Train Epoch: 1092 [40960/90000 (45%)]	Loss: 7.0977	Cost: 7.25s
Train Epoch: 1092 [61440/90000 (68%)]	Loss: 6.5941	Cost: 6.14s
Train Epoch: 1092 [81920/90000 (91%)]	Loss: 6.8522	Cost: 7.53s
Train Epoch: 1092 	Average Loss: 7.7639
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9977

Learning rate: 0.0001941729137750205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1093 [0/90000 (0%)]	Loss: 19.1945	Cost: 19.65s
Train Epoch: 1093 [20480/90000 (23%)]	Loss: 6.6400	Cost: 6.06s
Train Epoch: 1093 [40960/90000 (45%)]	Loss: 6.6248	Cost: 6.05s
Train Epoch: 1093 [61440/90000 (68%)]	Loss: 6.8577	Cost: 6.36s
Train Epoch: 1093 [81920/90000 (91%)]	Loss: 6.6876	Cost: 6.18s
Train Epoch: 1093 	Average Loss: 7.6071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0465

Learning rate: 0.0001941623416848292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1094 [0/90000 (0%)]	Loss: 19.2925	Cost: 20.61s
Train Epoch: 1094 [20480/90000 (23%)]	Loss: 6.6439	Cost: 5.97s
Train Epoch: 1094 [40960/90000 (45%)]	Loss: 6.7272	Cost: 6.15s
Train Epoch: 1094 [61440/90000 (68%)]	Loss: 6.6649	Cost: 6.28s
Train Epoch: 1094 [81920/90000 (91%)]	Loss: 6.7308	Cost: 7.28s
Train Epoch: 1094 	Average Loss: 7.5477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1796

Learning rate: 0.00019415176030118734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1095 [0/90000 (0%)]	Loss: 18.9554	Cost: 20.98s
Train Epoch: 1095 [20480/90000 (23%)]	Loss: 6.5713	Cost: 6.01s
Train Epoch: 1095 [40960/90000 (45%)]	Loss: 6.5542	Cost: 6.00s
Train Epoch: 1095 [61440/90000 (68%)]	Loss: 6.3680	Cost: 6.22s
Train Epoch: 1095 [81920/90000 (91%)]	Loss: 6.8111	Cost: 7.01s
Train Epoch: 1095 	Average Loss: 7.4940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9978

Learning rate: 0.00019414116962513932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1096 [0/90000 (0%)]	Loss: 19.1955	Cost: 19.83s
Train Epoch: 1096 [20480/90000 (23%)]	Loss: 6.7726	Cost: 5.98s
Train Epoch: 1096 [40960/90000 (45%)]	Loss: 6.8733	Cost: 6.40s
Train Epoch: 1096 [61440/90000 (68%)]	Loss: 6.6749	Cost: 6.00s
Train Epoch: 1096 [81920/90000 (91%)]	Loss: 6.9305	Cost: 6.83s
Train Epoch: 1096 	Average Loss: 7.5982
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0914

Learning rate: 0.00019413056965773032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1097 [0/90000 (0%)]	Loss: 18.8923	Cost: 20.47s
Train Epoch: 1097 [20480/90000 (23%)]	Loss: 6.7274	Cost: 5.96s
Train Epoch: 1097 [40960/90000 (45%)]	Loss: 6.4663	Cost: 6.05s
Train Epoch: 1097 [61440/90000 (68%)]	Loss: 6.3931	Cost: 6.22s
Train Epoch: 1097 [81920/90000 (91%)]	Loss: 6.6640	Cost: 7.43s
Train Epoch: 1097 	Average Loss: 7.4696
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2084

Learning rate: 0.00019411996040000657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1098 [0/90000 (0%)]	Loss: 19.0664	Cost: 20.64s
Train Epoch: 1098 [20480/90000 (23%)]	Loss: 6.4140	Cost: 5.94s
Train Epoch: 1098 [40960/90000 (45%)]	Loss: 6.4638	Cost: 6.49s
Train Epoch: 1098 [61440/90000 (68%)]	Loss: 6.6045	Cost: 5.89s
Train Epoch: 1098 [81920/90000 (91%)]	Loss: 6.7662	Cost: 7.15s
Train Epoch: 1098 	Average Loss: 7.4434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2286

Learning rate: 0.00019410934185301514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1099 [0/90000 (0%)]	Loss: 19.1201	Cost: 20.43s
Train Epoch: 1099 [20480/90000 (23%)]	Loss: 6.6878	Cost: 6.03s
Train Epoch: 1099 [40960/90000 (45%)]	Loss: 6.7101	Cost: 6.14s
Train Epoch: 1099 [61440/90000 (68%)]	Loss: 6.4824	Cost: 5.83s
Train Epoch: 1099 [81920/90000 (91%)]	Loss: 6.8550	Cost: 6.89s
Train Epoch: 1099 	Average Loss: 7.5136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1140

Learning rate: 0.00019409871401780405
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1100 [0/90000 (0%)]	Loss: 19.1426	Cost: 20.51s
Train Epoch: 1100 [20480/90000 (23%)]	Loss: 6.6116	Cost: 6.02s
Train Epoch: 1100 [40960/90000 (45%)]	Loss: 6.5732	Cost: 6.36s
Train Epoch: 1100 [61440/90000 (68%)]	Loss: 6.3276	Cost: 5.84s
Train Epoch: 1100 [81920/90000 (91%)]	Loss: 6.5384	Cost: 6.38s
Train Epoch: 1100 	Average Loss: 7.5000
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0765

Learning rate: 0.0001940880768954222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1101 [0/90000 (0%)]	Loss: 19.1744	Cost: 20.90s
Train Epoch: 1101 [20480/90000 (23%)]	Loss: 6.4116	Cost: 5.98s
Train Epoch: 1101 [40960/90000 (45%)]	Loss: 6.6633	Cost: 6.64s
Train Epoch: 1101 [61440/90000 (68%)]	Loss: 6.3275	Cost: 5.85s
Train Epoch: 1101 [81920/90000 (91%)]	Loss: 6.4940	Cost: 7.30s
Train Epoch: 1101 	Average Loss: 7.4002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1420

Learning rate: 0.00019407743048691943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1102 [0/90000 (0%)]	Loss: 19.3623	Cost: 20.04s
Train Epoch: 1102 [20480/90000 (23%)]	Loss: 6.6431	Cost: 5.95s
Train Epoch: 1102 [40960/90000 (45%)]	Loss: 6.7155	Cost: 6.30s
Train Epoch: 1102 [61440/90000 (68%)]	Loss: 6.7568	Cost: 5.82s
Train Epoch: 1102 [81920/90000 (91%)]	Loss: 6.9414	Cost: 6.25s
Train Epoch: 1102 	Average Loss: 7.4921
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0659

Learning rate: 0.00019406677479334654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1103 [0/90000 (0%)]	Loss: 19.3095	Cost: 20.79s
Train Epoch: 1103 [20480/90000 (23%)]	Loss: 6.8300	Cost: 6.07s
Train Epoch: 1103 [40960/90000 (45%)]	Loss: 6.7009	Cost: 6.66s
Train Epoch: 1103 [61440/90000 (68%)]	Loss: 6.3832	Cost: 5.89s
Train Epoch: 1103 [81920/90000 (91%)]	Loss: 6.5668	Cost: 6.71s
Train Epoch: 1103 	Average Loss: 7.4750
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1258

Learning rate: 0.0001940561098157552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1104 [0/90000 (0%)]	Loss: 19.0412	Cost: 20.98s
Train Epoch: 1104 [20480/90000 (23%)]	Loss: 6.5421	Cost: 6.07s
Train Epoch: 1104 [40960/90000 (45%)]	Loss: 6.3998	Cost: 6.11s
Train Epoch: 1104 [61440/90000 (68%)]	Loss: 6.4264	Cost: 5.90s
Train Epoch: 1104 [81920/90000 (91%)]	Loss: 6.6449	Cost: 5.89s
Train Epoch: 1104 	Average Loss: 7.4264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2303

Learning rate: 0.00019404543555519795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1105 [0/90000 (0%)]	Loss: 18.9694	Cost: 20.21s
Train Epoch: 1105 [20480/90000 (23%)]	Loss: 6.6107	Cost: 6.15s
Train Epoch: 1105 [40960/90000 (45%)]	Loss: 6.2966	Cost: 6.02s
Train Epoch: 1105 [61440/90000 (68%)]	Loss: 6.2579	Cost: 5.90s
Train Epoch: 1105 [81920/90000 (91%)]	Loss: 6.4922	Cost: 5.87s
Train Epoch: 1105 	Average Loss: 7.3534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2103

Learning rate: 0.00019403475201272834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1106 [0/90000 (0%)]	Loss: 19.5031	Cost: 21.58s
Train Epoch: 1106 [20480/90000 (23%)]	Loss: 6.4241	Cost: 6.01s
Train Epoch: 1106 [40960/90000 (45%)]	Loss: 6.8301	Cost: 6.10s
Train Epoch: 1106 [61440/90000 (68%)]	Loss: 6.7627	Cost: 5.94s
Train Epoch: 1106 [81920/90000 (91%)]	Loss: 7.0723	Cost: 5.87s
Train Epoch: 1106 	Average Loss: 7.6311
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1060

Learning rate: 0.00019402405918940077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1107 [0/90000 (0%)]	Loss: 19.4425	Cost: 20.46s
Train Epoch: 1107 [20480/90000 (23%)]	Loss: 6.9480	Cost: 6.06s
Train Epoch: 1107 [40960/90000 (45%)]	Loss: 6.7927	Cost: 6.09s
Train Epoch: 1107 [61440/90000 (68%)]	Loss: 6.4835	Cost: 5.95s
Train Epoch: 1107 [81920/90000 (91%)]	Loss: 6.8050	Cost: 5.93s
Train Epoch: 1107 	Average Loss: 7.6353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1896

Learning rate: 0.00019401335708627064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1108 [0/90000 (0%)]	Loss: 19.3405	Cost: 22.61s
Train Epoch: 1108 [20480/90000 (23%)]	Loss: 6.6738	Cost: 6.08s
Train Epoch: 1108 [40960/90000 (45%)]	Loss: 6.6122	Cost: 6.23s
Train Epoch: 1108 [61440/90000 (68%)]	Loss: 6.4211	Cost: 6.11s
Train Epoch: 1108 [81920/90000 (91%)]	Loss: 6.7441	Cost: 5.94s
Train Epoch: 1108 	Average Loss: 7.4647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2163

Learning rate: 0.00019400264570439412
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1109 [0/90000 (0%)]	Loss: 19.3352	Cost: 20.99s
Train Epoch: 1109 [20480/90000 (23%)]	Loss: 6.3614	Cost: 6.12s
Train Epoch: 1109 [40960/90000 (45%)]	Loss: 6.5519	Cost: 6.52s
Train Epoch: 1109 [61440/90000 (68%)]	Loss: 6.4195	Cost: 5.81s
Train Epoch: 1109 [81920/90000 (91%)]	Loss: 6.5743	Cost: 6.06s
Train Epoch: 1109 	Average Loss: 7.3999
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2602

Learning rate: 0.0001939919250448284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1110 [0/90000 (0%)]	Loss: 19.0193	Cost: 20.62s
Train Epoch: 1110 [20480/90000 (23%)]	Loss: 6.4119	Cost: 6.11s
Train Epoch: 1110 [40960/90000 (45%)]	Loss: 6.6237	Cost: 6.62s
Train Epoch: 1110 [61440/90000 (68%)]	Loss: 6.2644	Cost: 6.00s
Train Epoch: 1110 [81920/90000 (91%)]	Loss: 6.8355	Cost: 6.25s
Train Epoch: 1110 	Average Loss: 7.3806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3425

Learning rate: 0.00019398119510863161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1111 [0/90000 (0%)]	Loss: 19.3302	Cost: 21.03s
Train Epoch: 1111 [20480/90000 (23%)]	Loss: 6.7757	Cost: 6.04s
Train Epoch: 1111 [40960/90000 (45%)]	Loss: 6.7643	Cost: 6.57s
Train Epoch: 1111 [61440/90000 (68%)]	Loss: 6.8308	Cost: 5.89s
Train Epoch: 1111 [81920/90000 (91%)]	Loss: 6.6135	Cost: 6.27s
Train Epoch: 1111 	Average Loss: 7.5686
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0692

Learning rate: 0.00019397045589686273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1112 [0/90000 (0%)]	Loss: 19.2213	Cost: 20.36s
Train Epoch: 1112 [20480/90000 (23%)]	Loss: 6.9116	Cost: 6.06s
Train Epoch: 1112 [40960/90000 (45%)]	Loss: 6.7780	Cost: 6.11s
Train Epoch: 1112 [61440/90000 (68%)]	Loss: 6.6065	Cost: 6.00s
Train Epoch: 1112 [81920/90000 (91%)]	Loss: 6.5221	Cost: 6.06s
Train Epoch: 1112 	Average Loss: 7.5766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2193

Learning rate: 0.00019395970741058167
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1113 [0/90000 (0%)]	Loss: 19.6837	Cost: 21.20s
Train Epoch: 1113 [20480/90000 (23%)]	Loss: 6.6702	Cost: 6.11s
Train Epoch: 1113 [40960/90000 (45%)]	Loss: 6.6488	Cost: 6.34s
Train Epoch: 1113 [61440/90000 (68%)]	Loss: 6.6135	Cost: 5.93s
Train Epoch: 1113 [81920/90000 (91%)]	Loss: 7.1591	Cost: 5.89s
Train Epoch: 1113 	Average Loss: 7.6520
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2968

Learning rate: 0.00019394894965084927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1114 [0/90000 (0%)]	Loss: 18.9660	Cost: 21.82s
Train Epoch: 1114 [20480/90000 (23%)]	Loss: 7.0382	Cost: 6.09s
Train Epoch: 1114 [40960/90000 (45%)]	Loss: 7.0227	Cost: 6.55s
Train Epoch: 1114 [61440/90000 (68%)]	Loss: 6.7099	Cost: 5.92s
Train Epoch: 1114 [81920/90000 (91%)]	Loss: 6.9562	Cost: 6.29s
Train Epoch: 1114 	Average Loss: 7.7288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1424

Learning rate: 0.00019393818261872732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1115 [0/90000 (0%)]	Loss: 19.2546	Cost: 21.24s
Train Epoch: 1115 [20480/90000 (23%)]	Loss: 6.6158	Cost: 6.02s
Train Epoch: 1115 [40960/90000 (45%)]	Loss: 6.6059	Cost: 6.03s
Train Epoch: 1115 [61440/90000 (68%)]	Loss: 6.5149	Cost: 5.99s
Train Epoch: 1115 [81920/90000 (91%)]	Loss: 6.9106	Cost: 6.01s
Train Epoch: 1115 	Average Loss: 7.5154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2019

Learning rate: 0.0001939274063152784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1116 [0/90000 (0%)]	Loss: 19.1337	Cost: 20.63s
Train Epoch: 1116 [20480/90000 (23%)]	Loss: 6.6001	Cost: 6.05s
Train Epoch: 1116 [40960/90000 (45%)]	Loss: 6.5727	Cost: 6.21s
Train Epoch: 1116 [61440/90000 (68%)]	Loss: 7.1973	Cost: 5.94s
Train Epoch: 1116 [81920/90000 (91%)]	Loss: 7.2927	Cost: 6.02s
Train Epoch: 1116 	Average Loss: 7.7129
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1478

Learning rate: 0.00019391662074156612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1117 [0/90000 (0%)]	Loss: 19.2406	Cost: 21.63s
Train Epoch: 1117 [20480/90000 (23%)]	Loss: 6.8920	Cost: 5.98s
Train Epoch: 1117 [40960/90000 (45%)]	Loss: 6.9074	Cost: 6.70s
Train Epoch: 1117 [61440/90000 (68%)]	Loss: 6.8195	Cost: 5.93s
Train Epoch: 1117 [81920/90000 (91%)]	Loss: 6.7522	Cost: 7.04s
Train Epoch: 1117 	Average Loss: 7.7982
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2116

Learning rate: 0.00019390582589865496
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1118 [0/90000 (0%)]	Loss: 19.0707	Cost: 20.45s
Train Epoch: 1118 [20480/90000 (23%)]	Loss: 6.8710	Cost: 6.00s
Train Epoch: 1118 [40960/90000 (45%)]	Loss: 6.5698	Cost: 6.02s
Train Epoch: 1118 [61440/90000 (68%)]	Loss: 6.9269	Cost: 6.03s
Train Epoch: 1118 [81920/90000 (91%)]	Loss: 6.7763	Cost: 6.59s
Train Epoch: 1118 	Average Loss: 7.6077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1704

Learning rate: 0.0001938950217876104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1119 [0/90000 (0%)]	Loss: 19.0944	Cost: 20.99s
Train Epoch: 1119 [20480/90000 (23%)]	Loss: 6.5446	Cost: 6.06s
Train Epoch: 1119 [40960/90000 (45%)]	Loss: 6.6826	Cost: 6.58s
Train Epoch: 1119 [61440/90000 (68%)]	Loss: 6.4861	Cost: 6.17s
Train Epoch: 1119 [81920/90000 (91%)]	Loss: 6.4871	Cost: 6.57s
Train Epoch: 1119 	Average Loss: 7.5467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1773

Learning rate: 0.00019388420840949869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1120 [0/90000 (0%)]	Loss: 18.9733	Cost: 19.84s
Train Epoch: 1120 [20480/90000 (23%)]	Loss: 6.7119	Cost: 6.03s
Train Epoch: 1120 [40960/90000 (45%)]	Loss: 6.6438	Cost: 6.04s
Train Epoch: 1120 [61440/90000 (68%)]	Loss: 6.5883	Cost: 6.00s
Train Epoch: 1120 [81920/90000 (91%)]	Loss: 6.7469	Cost: 6.48s
Train Epoch: 1120 	Average Loss: 7.4924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1158

Learning rate: 0.00019387338576538711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1121 [0/90000 (0%)]	Loss: 19.0259	Cost: 19.93s
Train Epoch: 1121 [20480/90000 (23%)]	Loss: 6.7362	Cost: 6.08s
Train Epoch: 1121 [40960/90000 (45%)]	Loss: 6.7153	Cost: 6.20s
Train Epoch: 1121 [61440/90000 (68%)]	Loss: 6.4382	Cost: 5.94s
Train Epoch: 1121 [81920/90000 (91%)]	Loss: 6.6698	Cost: 6.37s
Train Epoch: 1121 	Average Loss: 7.4623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2055

Learning rate: 0.00019386255385634376
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1122 [0/90000 (0%)]	Loss: 19.3055	Cost: 20.23s
Train Epoch: 1122 [20480/90000 (23%)]	Loss: 6.4887	Cost: 6.07s
Train Epoch: 1122 [40960/90000 (45%)]	Loss: 6.3798	Cost: 6.37s
Train Epoch: 1122 [61440/90000 (68%)]	Loss: 6.2954	Cost: 5.91s
Train Epoch: 1122 [81920/90000 (91%)]	Loss: 6.3954	Cost: 6.24s
Train Epoch: 1122 	Average Loss: 7.3085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2359

Learning rate: 0.00019385171268343775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1123 [0/90000 (0%)]	Loss: 19.0712	Cost: 22.22s
Train Epoch: 1123 [20480/90000 (23%)]	Loss: 6.2705	Cost: 6.06s
Train Epoch: 1123 [40960/90000 (45%)]	Loss: 6.3570	Cost: 6.22s
Train Epoch: 1123 [61440/90000 (68%)]	Loss: 6.0664	Cost: 5.97s
Train Epoch: 1123 [81920/90000 (91%)]	Loss: 6.6319	Cost: 6.11s
Train Epoch: 1123 	Average Loss: 7.2441
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2367

Learning rate: 0.00019384086224773903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1124 [0/90000 (0%)]	Loss: 19.1527	Cost: 19.85s
Train Epoch: 1124 [20480/90000 (23%)]	Loss: 6.5576	Cost: 6.00s
Train Epoch: 1124 [40960/90000 (45%)]	Loss: 6.4159	Cost: 6.20s
Train Epoch: 1124 [61440/90000 (68%)]	Loss: 6.2888	Cost: 5.90s
Train Epoch: 1124 [81920/90000 (91%)]	Loss: 6.5185	Cost: 5.97s
Train Epoch: 1124 	Average Loss: 7.3005
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3829

Learning rate: 0.00019383000255031852
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1125 [0/90000 (0%)]	Loss: 19.4372	Cost: 21.87s
Train Epoch: 1125 [20480/90000 (23%)]	Loss: 6.5090	Cost: 6.09s
Train Epoch: 1125 [40960/90000 (45%)]	Loss: 6.4666	Cost: 6.83s
Train Epoch: 1125 [61440/90000 (68%)]	Loss: 6.2925	Cost: 5.98s
Train Epoch: 1125 [81920/90000 (91%)]	Loss: 6.8466	Cost: 6.77s
Train Epoch: 1125 	Average Loss: 7.3781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2397

Learning rate: 0.00019381913359224807
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1126 [0/90000 (0%)]	Loss: 19.4097	Cost: 20.99s
Train Epoch: 1126 [20480/90000 (23%)]	Loss: 6.3798	Cost: 6.03s
Train Epoch: 1126 [40960/90000 (45%)]	Loss: 6.5885	Cost: 6.37s
Train Epoch: 1126 [61440/90000 (68%)]	Loss: 6.5675	Cost: 5.91s
Train Epoch: 1126 [81920/90000 (91%)]	Loss: 6.7055	Cost: 6.19s
Train Epoch: 1126 	Average Loss: 7.4874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2849

Learning rate: 0.00019380825537460033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1127 [0/90000 (0%)]	Loss: 19.3150	Cost: 21.60s
Train Epoch: 1127 [20480/90000 (23%)]	Loss: 6.3645	Cost: 5.98s
Train Epoch: 1127 [40960/90000 (45%)]	Loss: 6.3273	Cost: 6.08s
Train Epoch: 1127 [61440/90000 (68%)]	Loss: 6.1749	Cost: 5.92s
Train Epoch: 1127 [81920/90000 (91%)]	Loss: 6.6153	Cost: 6.53s
Train Epoch: 1127 	Average Loss: 7.3607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2645

Learning rate: 0.00019379736789844898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1128 [0/90000 (0%)]	Loss: 19.5269	Cost: 21.68s
Train Epoch: 1128 [20480/90000 (23%)]	Loss: 6.6227	Cost: 6.00s
Train Epoch: 1128 [40960/90000 (45%)]	Loss: 6.8815	Cost: 6.42s
Train Epoch: 1128 [61440/90000 (68%)]	Loss: 6.3874	Cost: 5.92s
Train Epoch: 1128 [81920/90000 (91%)]	Loss: 6.5716	Cost: 6.14s
Train Epoch: 1128 	Average Loss: 7.4100
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3162

Learning rate: 0.00019378647116486856
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1129 [0/90000 (0%)]	Loss: 19.3810	Cost: 20.98s
Train Epoch: 1129 [20480/90000 (23%)]	Loss: 6.4896	Cost: 6.08s
Train Epoch: 1129 [40960/90000 (45%)]	Loss: 6.7875	Cost: 6.91s
Train Epoch: 1129 [61440/90000 (68%)]	Loss: 6.4824	Cost: 5.90s
Train Epoch: 1129 [81920/90000 (91%)]	Loss: 6.3848	Cost: 5.86s
Train Epoch: 1129 	Average Loss: 7.3762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3024

Learning rate: 0.0001937755651749345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1130 [0/90000 (0%)]	Loss: 19.2396	Cost: 19.64s
Train Epoch: 1130 [20480/90000 (23%)]	Loss: 6.1616	Cost: 5.99s
Train Epoch: 1130 [40960/90000 (45%)]	Loss: 6.3783	Cost: 6.21s
Train Epoch: 1130 [61440/90000 (68%)]	Loss: 6.2066	Cost: 6.02s
Train Epoch: 1130 [81920/90000 (91%)]	Loss: 6.3327	Cost: 5.79s
Train Epoch: 1130 	Average Loss: 7.2191
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3160

Learning rate: 0.0001937646499297232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1131 [0/90000 (0%)]	Loss: 19.4352	Cost: 21.21s
Train Epoch: 1131 [20480/90000 (23%)]	Loss: 6.1821	Cost: 6.09s
Train Epoch: 1131 [40960/90000 (45%)]	Loss: 6.2302	Cost: 6.34s
Train Epoch: 1131 [61440/90000 (68%)]	Loss: 6.3846	Cost: 5.97s
Train Epoch: 1131 [81920/90000 (91%)]	Loss: 6.4796	Cost: 6.99s
Train Epoch: 1131 	Average Loss: 7.2059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2921

Learning rate: 0.000193753725430312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1132 [0/90000 (0%)]	Loss: 19.6381	Cost: 20.62s
Train Epoch: 1132 [20480/90000 (23%)]	Loss: 6.3906	Cost: 6.04s
Train Epoch: 1132 [40960/90000 (45%)]	Loss: 6.2041	Cost: 6.11s
Train Epoch: 1132 [61440/90000 (68%)]	Loss: 6.1691	Cost: 5.95s
Train Epoch: 1132 [81920/90000 (91%)]	Loss: 6.2653	Cost: 6.39s
Train Epoch: 1132 	Average Loss: 7.2079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3545

Learning rate: 0.00019374279167777905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1133 [0/90000 (0%)]	Loss: 19.3033	Cost: 20.23s
Train Epoch: 1133 [20480/90000 (23%)]	Loss: 6.4412	Cost: 6.02s
Train Epoch: 1133 [40960/90000 (45%)]	Loss: 6.2997	Cost: 6.16s
Train Epoch: 1133 [61440/90000 (68%)]	Loss: 6.4113	Cost: 5.90s
Train Epoch: 1133 [81920/90000 (91%)]	Loss: 6.8922	Cost: 5.96s
Train Epoch: 1133 	Average Loss: 7.3943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4115

Learning rate: 0.00019373184867320348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1134 [0/90000 (0%)]	Loss: 19.4565	Cost: 21.37s
Train Epoch: 1134 [20480/90000 (23%)]	Loss: 6.3230	Cost: 6.05s
Train Epoch: 1134 [40960/90000 (45%)]	Loss: 6.3810	Cost: 6.30s
Train Epoch: 1134 [61440/90000 (68%)]	Loss: 6.3317	Cost: 5.91s
Train Epoch: 1134 [81920/90000 (91%)]	Loss: 6.4284	Cost: 5.95s
Train Epoch: 1134 	Average Loss: 7.4268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3163

Learning rate: 0.00019372089641766534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1135 [0/90000 (0%)]	Loss: 19.1725	Cost: 21.03s
Train Epoch: 1135 [20480/90000 (23%)]	Loss: 6.4686	Cost: 6.07s
Train Epoch: 1135 [40960/90000 (45%)]	Loss: 6.2505	Cost: 6.16s
Train Epoch: 1135 [61440/90000 (68%)]	Loss: 6.0167	Cost: 5.99s
Train Epoch: 1135 [81920/90000 (91%)]	Loss: 6.0962	Cost: 5.93s
Train Epoch: 1135 	Average Loss: 7.1850
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2650

Learning rate: 0.00019370993491224555
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1136 [0/90000 (0%)]	Loss: 19.5770	Cost: 20.36s
Train Epoch: 1136 [20480/90000 (23%)]	Loss: 6.2242	Cost: 6.11s
Train Epoch: 1136 [40960/90000 (45%)]	Loss: 6.1758	Cost: 6.15s
Train Epoch: 1136 [61440/90000 (68%)]	Loss: 6.0430	Cost: 5.95s
Train Epoch: 1136 [81920/90000 (91%)]	Loss: 6.6676	Cost: 6.06s
Train Epoch: 1136 	Average Loss: 7.1904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4008

Learning rate: 0.00019369896415802597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1137 [0/90000 (0%)]	Loss: 19.5364	Cost: 21.65s
Train Epoch: 1137 [20480/90000 (23%)]	Loss: 6.4781	Cost: 5.97s
Train Epoch: 1137 [40960/90000 (45%)]	Loss: 6.3584	Cost: 6.56s
Train Epoch: 1137 [61440/90000 (68%)]	Loss: 6.2307	Cost: 5.95s
Train Epoch: 1137 [81920/90000 (91%)]	Loss: 6.4160	Cost: 6.10s
Train Epoch: 1137 	Average Loss: 7.2912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3451

Learning rate: 0.0001936879841560894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1138 [0/90000 (0%)]	Loss: 19.5525	Cost: 20.86s
Train Epoch: 1138 [20480/90000 (23%)]	Loss: 6.2069	Cost: 6.12s
Train Epoch: 1138 [40960/90000 (45%)]	Loss: 6.2615	Cost: 6.12s
Train Epoch: 1138 [61440/90000 (68%)]	Loss: 6.0329	Cost: 5.92s
Train Epoch: 1138 [81920/90000 (91%)]	Loss: 6.1446	Cost: 6.05s
Train Epoch: 1138 	Average Loss: 7.1135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3427

Learning rate: 0.00019367699490751948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1139 [0/90000 (0%)]	Loss: 19.1542	Cost: 21.13s
Train Epoch: 1139 [20480/90000 (23%)]	Loss: 6.1708	Cost: 6.20s
Train Epoch: 1139 [40960/90000 (45%)]	Loss: 6.3525	Cost: 6.07s
Train Epoch: 1139 [61440/90000 (68%)]	Loss: 5.9763	Cost: 5.93s
Train Epoch: 1139 [81920/90000 (91%)]	Loss: 6.3838	Cost: 5.83s
Train Epoch: 1139 	Average Loss: 7.0674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3443

Learning rate: 0.0001936659964134008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1140 [0/90000 (0%)]	Loss: 19.2641	Cost: 20.77s
Train Epoch: 1140 [20480/90000 (23%)]	Loss: 6.1901	Cost: 6.03s
Train Epoch: 1140 [40960/90000 (45%)]	Loss: 6.0599	Cost: 6.02s
Train Epoch: 1140 [61440/90000 (68%)]	Loss: 5.9321	Cost: 5.93s
Train Epoch: 1140 [81920/90000 (91%)]	Loss: 6.2066	Cost: 6.16s
Train Epoch: 1140 	Average Loss: 7.0701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4523

Learning rate: 0.0001936549886748189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1141 [0/90000 (0%)]	Loss: 19.2784	Cost: 21.48s
Train Epoch: 1141 [20480/90000 (23%)]	Loss: 6.2173	Cost: 6.02s
Train Epoch: 1141 [40960/90000 (45%)]	Loss: 6.2362	Cost: 6.32s
Train Epoch: 1141 [61440/90000 (68%)]	Loss: 6.0700	Cost: 6.01s
Train Epoch: 1141 [81920/90000 (91%)]	Loss: 6.2225	Cost: 5.91s
Train Epoch: 1141 	Average Loss: 7.1423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4965

Learning rate: 0.00019364397169286022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1142 [0/90000 (0%)]	Loss: 19.0419	Cost: 21.99s
Train Epoch: 1142 [20480/90000 (23%)]	Loss: 6.1294	Cost: 6.04s
Train Epoch: 1142 [40960/90000 (45%)]	Loss: 6.0729	Cost: 6.79s
Train Epoch: 1142 [61440/90000 (68%)]	Loss: 6.0608	Cost: 5.91s
Train Epoch: 1142 [81920/90000 (91%)]	Loss: 6.2133	Cost: 6.91s
Train Epoch: 1142 	Average Loss: 7.0033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3851

Learning rate: 0.00019363294546861204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1143 [0/90000 (0%)]	Loss: 19.7712	Cost: 22.48s
Train Epoch: 1143 [20480/90000 (23%)]	Loss: 6.0117	Cost: 5.95s
Train Epoch: 1143 [40960/90000 (45%)]	Loss: 6.2341	Cost: 6.00s
Train Epoch: 1143 [61440/90000 (68%)]	Loss: 6.1291	Cost: 5.92s
Train Epoch: 1143 [81920/90000 (91%)]	Loss: 6.1683	Cost: 5.88s
Train Epoch: 1143 	Average Loss: 7.0183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4782

Learning rate: 0.00019362191000316264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1144 [0/90000 (0%)]	Loss: 19.3640	Cost: 21.04s
Train Epoch: 1144 [20480/90000 (23%)]	Loss: 6.0634	Cost: 5.86s
Train Epoch: 1144 [40960/90000 (45%)]	Loss: 6.1335	Cost: 7.14s
Train Epoch: 1144 [61440/90000 (68%)]	Loss: 5.7993	Cost: 5.69s
Train Epoch: 1144 [81920/90000 (91%)]	Loss: 6.0874	Cost: 6.37s
Train Epoch: 1144 	Average Loss: 6.9898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3956

Learning rate: 0.0001936108652976012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1145 [0/90000 (0%)]	Loss: 19.6106	Cost: 21.43s
Train Epoch: 1145 [20480/90000 (23%)]	Loss: 6.0552	Cost: 6.06s
Train Epoch: 1145 [40960/90000 (45%)]	Loss: 6.1319	Cost: 6.36s
Train Epoch: 1145 [61440/90000 (68%)]	Loss: 5.9346	Cost: 5.89s
Train Epoch: 1145 [81920/90000 (91%)]	Loss: 6.0796	Cost: 5.98s
Train Epoch: 1145 	Average Loss: 6.9708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4323

Learning rate: 0.0001935998113530177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1146 [0/90000 (0%)]	Loss: 19.3571	Cost: 20.59s
Train Epoch: 1146 [20480/90000 (23%)]	Loss: 5.9382	Cost: 6.08s
Train Epoch: 1146 [40960/90000 (45%)]	Loss: 6.0415	Cost: 6.05s
Train Epoch: 1146 [61440/90000 (68%)]	Loss: 6.1700	Cost: 5.97s
Train Epoch: 1146 [81920/90000 (91%)]	Loss: 6.3948	Cost: 6.10s
Train Epoch: 1146 	Average Loss: 7.0421
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4928

Learning rate: 0.0001935887481705032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1147 [0/90000 (0%)]	Loss: 19.9219	Cost: 20.69s
Train Epoch: 1147 [20480/90000 (23%)]	Loss: 6.3970	Cost: 6.00s
Train Epoch: 1147 [40960/90000 (45%)]	Loss: 6.2264	Cost: 6.33s
Train Epoch: 1147 [61440/90000 (68%)]	Loss: 6.2834	Cost: 5.89s
Train Epoch: 1147 [81920/90000 (91%)]	Loss: 6.3459	Cost: 5.80s
Train Epoch: 1147 	Average Loss: 7.1663
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3886

Learning rate: 0.00019357767575114954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1148 [0/90000 (0%)]	Loss: 19.5414	Cost: 20.01s
Train Epoch: 1148 [20480/90000 (23%)]	Loss: 6.1663	Cost: 6.14s
Train Epoch: 1148 [40960/90000 (45%)]	Loss: 6.3125	Cost: 6.14s
Train Epoch: 1148 [61440/90000 (68%)]	Loss: 6.3710	Cost: 5.96s
Train Epoch: 1148 [81920/90000 (91%)]	Loss: 6.7218	Cost: 5.86s
Train Epoch: 1148 	Average Loss: 7.1940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5469

Learning rate: 0.0001935665940960496
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1149 [0/90000 (0%)]	Loss: 19.2520	Cost: 21.35s
Train Epoch: 1149 [20480/90000 (23%)]	Loss: 6.5093	Cost: 6.03s
Train Epoch: 1149 [40960/90000 (45%)]	Loss: 6.3999	Cost: 6.22s
Train Epoch: 1149 [61440/90000 (68%)]	Loss: 6.0661	Cost: 6.21s
Train Epoch: 1149 [81920/90000 (91%)]	Loss: 6.5649	Cost: 5.87s
Train Epoch: 1149 	Average Loss: 7.2945
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4707

Learning rate: 0.000193555503206297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1150 [0/90000 (0%)]	Loss: 19.2447	Cost: 21.73s
Train Epoch: 1150 [20480/90000 (23%)]	Loss: 6.8817	Cost: 6.04s
Train Epoch: 1150 [40960/90000 (45%)]	Loss: 6.8007	Cost: 6.38s
Train Epoch: 1150 [61440/90000 (68%)]	Loss: 6.6482	Cost: 5.95s
Train Epoch: 1150 [81920/90000 (91%)]	Loss: 6.5827	Cost: 5.83s
Train Epoch: 1150 	Average Loss: 7.5064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3962

Learning rate: 0.00019354440308298645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1151 [0/90000 (0%)]	Loss: 19.1146	Cost: 22.04s
Train Epoch: 1151 [20480/90000 (23%)]	Loss: 6.3330	Cost: 6.06s
Train Epoch: 1151 [40960/90000 (45%)]	Loss: 6.4640	Cost: 6.04s
Train Epoch: 1151 [61440/90000 (68%)]	Loss: 6.7032	Cost: 5.90s
Train Epoch: 1151 [81920/90000 (91%)]	Loss: 6.6521	Cost: 5.90s
Train Epoch: 1151 	Average Loss: 7.3002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2755

Learning rate: 0.00019353329372721341
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1152 [0/90000 (0%)]	Loss: 19.3497	Cost: 21.89s
Train Epoch: 1152 [20480/90000 (23%)]	Loss: 6.3318	Cost: 5.97s
Train Epoch: 1152 [40960/90000 (45%)]	Loss: 6.4139	Cost: 6.31s
Train Epoch: 1152 [61440/90000 (68%)]	Loss: 6.0834	Cost: 6.04s
Train Epoch: 1152 [81920/90000 (91%)]	Loss: 6.5033	Cost: 5.91s
Train Epoch: 1152 	Average Loss: 7.2457
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4332

Learning rate: 0.0001935221751400744
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1153 [0/90000 (0%)]	Loss: 19.4631	Cost: 20.61s
Train Epoch: 1153 [20480/90000 (23%)]	Loss: 6.0561	Cost: 6.05s
Train Epoch: 1153 [40960/90000 (45%)]	Loss: 6.3308	Cost: 6.21s
Train Epoch: 1153 [61440/90000 (68%)]	Loss: 6.1650	Cost: 6.15s
Train Epoch: 1153 [81920/90000 (91%)]	Loss: 6.1990	Cost: 5.91s
Train Epoch: 1153 	Average Loss: 7.1787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3428

Learning rate: 0.00019351104732266675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1154 [0/90000 (0%)]	Loss: 19.3407	Cost: 19.90s
Train Epoch: 1154 [20480/90000 (23%)]	Loss: 6.0907	Cost: 6.10s
Train Epoch: 1154 [40960/90000 (45%)]	Loss: 6.0010	Cost: 6.25s
Train Epoch: 1154 [61440/90000 (68%)]	Loss: 5.7795	Cost: 5.92s
Train Epoch: 1154 [81920/90000 (91%)]	Loss: 6.2217	Cost: 6.05s
Train Epoch: 1154 	Average Loss: 7.1052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4200

Learning rate: 0.00019349991027608872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1155 [0/90000 (0%)]	Loss: 19.1260	Cost: 21.97s
Train Epoch: 1155 [20480/90000 (23%)]	Loss: 6.0848	Cost: 6.10s
Train Epoch: 1155 [40960/90000 (45%)]	Loss: 6.0864	Cost: 6.70s
Train Epoch: 1155 [61440/90000 (68%)]	Loss: 5.8273	Cost: 5.96s
Train Epoch: 1155 [81920/90000 (91%)]	Loss: 6.3890	Cost: 6.94s
Train Epoch: 1155 	Average Loss: 7.0177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5553

Learning rate: 0.0001934887640014395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1156 [0/90000 (0%)]	Loss: 19.4502	Cost: 19.72s
Train Epoch: 1156 [20480/90000 (23%)]	Loss: 6.3372	Cost: 6.06s
Train Epoch: 1156 [40960/90000 (45%)]	Loss: 6.4271	Cost: 6.16s
Train Epoch: 1156 [61440/90000 (68%)]	Loss: 6.1234	Cost: 5.91s
Train Epoch: 1156 [81920/90000 (91%)]	Loss: 6.3112	Cost: 5.79s
Train Epoch: 1156 	Average Loss: 7.2650
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3944

Learning rate: 0.00019347760849981922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1157 [0/90000 (0%)]	Loss: 19.3310	Cost: 20.66s
Train Epoch: 1157 [20480/90000 (23%)]	Loss: 6.1964	Cost: 6.06s
Train Epoch: 1157 [40960/90000 (45%)]	Loss: 6.3784	Cost: 6.18s
Train Epoch: 1157 [61440/90000 (68%)]	Loss: 6.0919	Cost: 5.87s
Train Epoch: 1157 [81920/90000 (91%)]	Loss: 6.0492	Cost: 5.80s
Train Epoch: 1157 	Average Loss: 7.1156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4467

Learning rate: 0.00019346644377232883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1158 [0/90000 (0%)]	Loss: 19.6322	Cost: 21.54s
Train Epoch: 1158 [20480/90000 (23%)]	Loss: 6.0090	Cost: 6.01s
Train Epoch: 1158 [40960/90000 (45%)]	Loss: 5.9773	Cost: 6.11s
Train Epoch: 1158 [61440/90000 (68%)]	Loss: 5.8754	Cost: 5.90s
Train Epoch: 1158 [81920/90000 (91%)]	Loss: 6.0424	Cost: 5.99s
Train Epoch: 1158 	Average Loss: 6.9815
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5218

Learning rate: 0.0001934552698200703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1159 [0/90000 (0%)]	Loss: 19.4559	Cost: 20.36s
Train Epoch: 1159 [20480/90000 (23%)]	Loss: 6.1182	Cost: 6.02s
Train Epoch: 1159 [40960/90000 (45%)]	Loss: 6.0844	Cost: 6.15s
Train Epoch: 1159 [61440/90000 (68%)]	Loss: 6.0684	Cost: 5.88s
Train Epoch: 1159 [81920/90000 (91%)]	Loss: 6.0226	Cost: 6.05s
Train Epoch: 1159 	Average Loss: 7.0261
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5078

Learning rate: 0.0001934440866441464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1160 [0/90000 (0%)]	Loss: 19.3916	Cost: 22.00s
Train Epoch: 1160 [20480/90000 (23%)]	Loss: 6.1098	Cost: 6.10s
Train Epoch: 1160 [40960/90000 (45%)]	Loss: 6.0658	Cost: 6.10s
Train Epoch: 1160 [61440/90000 (68%)]	Loss: 6.1735	Cost: 5.89s
Train Epoch: 1160 [81920/90000 (91%)]	Loss: 6.3085	Cost: 6.13s
Train Epoch: 1160 	Average Loss: 7.0947
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5079

Learning rate: 0.0001934328942456609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1161 [0/90000 (0%)]	Loss: 19.2986	Cost: 20.80s
Train Epoch: 1161 [20480/90000 (23%)]	Loss: 6.0291	Cost: 6.02s
Train Epoch: 1161 [40960/90000 (45%)]	Loss: 5.9579	Cost: 6.37s
Train Epoch: 1161 [61440/90000 (68%)]	Loss: 6.0131	Cost: 5.92s
Train Epoch: 1161 [81920/90000 (91%)]	Loss: 6.0995	Cost: 6.38s
Train Epoch: 1161 	Average Loss: 7.0467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5536

Learning rate: 0.0001934216926257184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1162 [0/90000 (0%)]	Loss: 19.5729	Cost: 21.19s
Train Epoch: 1162 [20480/90000 (23%)]	Loss: 6.3665	Cost: 6.03s
Train Epoch: 1162 [40960/90000 (45%)]	Loss: 6.4027	Cost: 6.45s
Train Epoch: 1162 [61440/90000 (68%)]	Loss: 7.2717	Cost: 5.91s
Train Epoch: 1162 [81920/90000 (91%)]	Loss: 7.1093	Cost: 6.17s
Train Epoch: 1162 	Average Loss: 7.6335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5225

Learning rate: 0.0001934104817854245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1163 [0/90000 (0%)]	Loss: 19.2311	Cost: 21.55s
Train Epoch: 1163 [20480/90000 (23%)]	Loss: 6.7504	Cost: 6.07s
Train Epoch: 1163 [40960/90000 (45%)]	Loss: 6.6272	Cost: 6.21s
Train Epoch: 1163 [61440/90000 (68%)]	Loss: 6.2523	Cost: 6.20s
Train Epoch: 1163 [81920/90000 (91%)]	Loss: 6.4464	Cost: 6.23s
Train Epoch: 1163 	Average Loss: 7.5474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3890

Learning rate: 0.00019339926172588564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1164 [0/90000 (0%)]	Loss: 19.7287	Cost: 21.16s
Train Epoch: 1164 [20480/90000 (23%)]	Loss: 6.1139	Cost: 6.04s
Train Epoch: 1164 [40960/90000 (45%)]	Loss: 6.2590	Cost: 6.30s
Train Epoch: 1164 [61440/90000 (68%)]	Loss: 6.0546	Cost: 5.91s
Train Epoch: 1164 [81920/90000 (91%)]	Loss: 6.5489	Cost: 6.04s
Train Epoch: 1164 	Average Loss: 7.1546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4080

Learning rate: 0.00019338803244820925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1165 [0/90000 (0%)]	Loss: 19.4807	Cost: 20.07s
Train Epoch: 1165 [20480/90000 (23%)]	Loss: 6.2895	Cost: 6.10s
Train Epoch: 1165 [40960/90000 (45%)]	Loss: 6.3353	Cost: 6.14s
Train Epoch: 1165 [61440/90000 (68%)]	Loss: 5.9514	Cost: 6.03s
Train Epoch: 1165 [81920/90000 (91%)]	Loss: 6.2033	Cost: 6.00s
Train Epoch: 1165 	Average Loss: 7.2181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4779

Learning rate: 0.00019337679395350357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1166 [0/90000 (0%)]	Loss: 19.3371	Cost: 21.05s
Train Epoch: 1166 [20480/90000 (23%)]	Loss: 5.9753	Cost: 5.98s
Train Epoch: 1166 [40960/90000 (45%)]	Loss: 6.1495	Cost: 6.06s
Train Epoch: 1166 [61440/90000 (68%)]	Loss: 5.9682	Cost: 5.94s
Train Epoch: 1166 [81920/90000 (91%)]	Loss: 5.9161	Cost: 5.93s
Train Epoch: 1166 	Average Loss: 6.9404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4736

Learning rate: 0.00019336554624287778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1167 [0/90000 (0%)]	Loss: 19.8745	Cost: 21.18s
Train Epoch: 1167 [20480/90000 (23%)]	Loss: 5.9533	Cost: 6.15s
Train Epoch: 1167 [40960/90000 (45%)]	Loss: 5.6884	Cost: 6.42s
Train Epoch: 1167 [61440/90000 (68%)]	Loss: 5.7232	Cost: 5.89s
Train Epoch: 1167 [81920/90000 (91%)]	Loss: 5.9598	Cost: 6.09s
Train Epoch: 1167 	Average Loss: 6.8220
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5294

Learning rate: 0.00019335428931744204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1168 [0/90000 (0%)]	Loss: 19.3525	Cost: 20.54s
Train Epoch: 1168 [20480/90000 (23%)]	Loss: 6.2464	Cost: 6.03s
Train Epoch: 1168 [40960/90000 (45%)]	Loss: 6.1329	Cost: 6.14s
Train Epoch: 1168 [61440/90000 (68%)]	Loss: 6.0763	Cost: 5.92s
Train Epoch: 1168 [81920/90000 (91%)]	Loss: 6.0404	Cost: 6.19s
Train Epoch: 1168 	Average Loss: 6.9941
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5282

Learning rate: 0.0001933430231783073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1169 [0/90000 (0%)]	Loss: 19.5202	Cost: 20.23s
Train Epoch: 1169 [20480/90000 (23%)]	Loss: 6.0634	Cost: 6.03s
Train Epoch: 1169 [40960/90000 (45%)]	Loss: 6.2268	Cost: 6.33s
Train Epoch: 1169 [61440/90000 (68%)]	Loss: 5.9110	Cost: 5.90s
Train Epoch: 1169 [81920/90000 (91%)]	Loss: 6.6716	Cost: 6.01s
Train Epoch: 1169 	Average Loss: 7.1524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5423

Learning rate: 0.00019333174782658552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1170 [0/90000 (0%)]	Loss: 19.7714	Cost: 21.26s
Train Epoch: 1170 [20480/90000 (23%)]	Loss: 6.4731	Cost: 6.05s
Train Epoch: 1170 [40960/90000 (45%)]	Loss: 6.3591	Cost: 6.19s
Train Epoch: 1170 [61440/90000 (68%)]	Loss: 5.9084	Cost: 6.05s
Train Epoch: 1170 [81920/90000 (91%)]	Loss: 5.7860	Cost: 5.94s
Train Epoch: 1170 	Average Loss: 7.0895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5641

Learning rate: 0.0001933204632633895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1171 [0/90000 (0%)]	Loss: 19.5952	Cost: 20.32s
Train Epoch: 1171 [20480/90000 (23%)]	Loss: 6.1630	Cost: 6.10s
Train Epoch: 1171 [40960/90000 (45%)]	Loss: 5.8870	Cost: 6.26s
Train Epoch: 1171 [61440/90000 (68%)]	Loss: 5.6868	Cost: 5.93s
Train Epoch: 1171 [81920/90000 (91%)]	Loss: 6.0080	Cost: 5.96s
Train Epoch: 1171 	Average Loss: 6.8614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5875

Learning rate: 0.00019330916948983305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1172 [0/90000 (0%)]	Loss: 19.4647	Cost: 22.23s
Train Epoch: 1172 [20480/90000 (23%)]	Loss: 5.7894	Cost: 5.98s
Train Epoch: 1172 [40960/90000 (45%)]	Loss: 6.0214	Cost: 6.14s
Train Epoch: 1172 [61440/90000 (68%)]	Loss: 5.7709	Cost: 5.94s
Train Epoch: 1172 [81920/90000 (91%)]	Loss: 6.1179	Cost: 6.40s
Train Epoch: 1172 	Average Loss: 6.8963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5459

Learning rate: 0.00019329786650703075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1173 [0/90000 (0%)]	Loss: 19.4651	Cost: 20.97s
Train Epoch: 1173 [20480/90000 (23%)]	Loss: 5.8592	Cost: 5.99s
Train Epoch: 1173 [40960/90000 (45%)]	Loss: 5.5071	Cost: 6.57s
Train Epoch: 1173 [61440/90000 (68%)]	Loss: 5.7097	Cost: 5.98s
Train Epoch: 1173 [81920/90000 (91%)]	Loss: 5.7525	Cost: 5.90s
Train Epoch: 1173 	Average Loss: 6.7106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6238

Learning rate: 0.00019328655431609818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1174 [0/90000 (0%)]	Loss: 19.6083	Cost: 21.93s
Train Epoch: 1174 [20480/90000 (23%)]	Loss: 5.7487	Cost: 6.00s
Train Epoch: 1174 [40960/90000 (45%)]	Loss: 5.8045	Cost: 6.86s
Train Epoch: 1174 [61440/90000 (68%)]	Loss: 5.6427	Cost: 6.10s
Train Epoch: 1174 [81920/90000 (91%)]	Loss: 5.8414	Cost: 6.87s
Train Epoch: 1174 	Average Loss: 6.7442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6435

Learning rate: 0.00019327523291815183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1175 [0/90000 (0%)]	Loss: 19.6370	Cost: 21.01s
Train Epoch: 1175 [20480/90000 (23%)]	Loss: 5.6622	Cost: 6.10s
Train Epoch: 1175 [40960/90000 (45%)]	Loss: 5.7034	Cost: 6.16s
Train Epoch: 1175 [61440/90000 (68%)]	Loss: 5.5425	Cost: 6.06s
Train Epoch: 1175 [81920/90000 (91%)]	Loss: 6.0212	Cost: 5.93s
Train Epoch: 1175 	Average Loss: 6.7915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6122

Learning rate: 0.00019326390231430904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1176 [0/90000 (0%)]	Loss: 19.5695	Cost: 21.92s
Train Epoch: 1176 [20480/90000 (23%)]	Loss: 5.7288	Cost: 6.02s
Train Epoch: 1176 [40960/90000 (45%)]	Loss: 5.8224	Cost: 6.72s
Train Epoch: 1176 [61440/90000 (68%)]	Loss: 5.6781	Cost: 5.88s
Train Epoch: 1176 [81920/90000 (91%)]	Loss: 5.9883	Cost: 7.38s
Train Epoch: 1176 	Average Loss: 6.7621
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5209

Learning rate: 0.00019325256250568812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1177 [0/90000 (0%)]	Loss: 19.3945	Cost: 21.46s
Train Epoch: 1177 [20480/90000 (23%)]	Loss: 5.6866	Cost: 6.08s
Train Epoch: 1177 [40960/90000 (45%)]	Loss: 5.8984	Cost: 6.67s
Train Epoch: 1177 [61440/90000 (68%)]	Loss: 5.9533	Cost: 5.91s
Train Epoch: 1177 [81920/90000 (91%)]	Loss: 5.8106	Cost: 6.10s
Train Epoch: 1177 	Average Loss: 6.8193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6338

Learning rate: 0.00019324121349340828
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1178 [0/90000 (0%)]	Loss: 19.8003	Cost: 20.26s
Train Epoch: 1178 [20480/90000 (23%)]	Loss: 6.0814	Cost: 6.09s
Train Epoch: 1178 [40960/90000 (45%)]	Loss: 6.0214	Cost: 6.06s
Train Epoch: 1178 [61440/90000 (68%)]	Loss: 5.6864	Cost: 6.01s
Train Epoch: 1178 [81920/90000 (91%)]	Loss: 5.9380	Cost: 5.94s
Train Epoch: 1178 	Average Loss: 6.9046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5891

Learning rate: 0.0001932298552785896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1179 [0/90000 (0%)]	Loss: 19.5318	Cost: 20.71s
Train Epoch: 1179 [20480/90000 (23%)]	Loss: 6.0924	Cost: 6.05s
Train Epoch: 1179 [40960/90000 (45%)]	Loss: 5.8250	Cost: 6.01s
Train Epoch: 1179 [61440/90000 (68%)]	Loss: 5.8455	Cost: 5.89s
Train Epoch: 1179 [81920/90000 (91%)]	Loss: 6.1092	Cost: 5.92s
Train Epoch: 1179 	Average Loss: 6.9669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6906

Learning rate: 0.00019321848786235313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1180 [0/90000 (0%)]	Loss: 19.4202	Cost: 20.34s
Train Epoch: 1180 [20480/90000 (23%)]	Loss: 6.1099	Cost: 6.03s
Train Epoch: 1180 [40960/90000 (45%)]	Loss: 5.9744	Cost: 6.15s
Train Epoch: 1180 [61440/90000 (68%)]	Loss: 5.9497	Cost: 5.93s
Train Epoch: 1180 [81920/90000 (91%)]	Loss: 5.9087	Cost: 5.91s
Train Epoch: 1180 	Average Loss: 6.9449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5747

Learning rate: 0.0001932071112458207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1181 [0/90000 (0%)]	Loss: 19.4555	Cost: 21.48s
Train Epoch: 1181 [20480/90000 (23%)]	Loss: 5.9331	Cost: 5.96s
Train Epoch: 1181 [40960/90000 (45%)]	Loss: 5.9941	Cost: 6.65s
Train Epoch: 1181 [61440/90000 (68%)]	Loss: 5.9469	Cost: 5.94s
Train Epoch: 1181 [81920/90000 (91%)]	Loss: 6.1208	Cost: 5.92s
Train Epoch: 1181 	Average Loss: 6.8700
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7010

Learning rate: 0.00019319572543011524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1182 [0/90000 (0%)]	Loss: 19.6021	Cost: 20.59s
Train Epoch: 1182 [20480/90000 (23%)]	Loss: 5.8468	Cost: 5.98s
Train Epoch: 1182 [40960/90000 (45%)]	Loss: 5.6686	Cost: 6.77s
Train Epoch: 1182 [61440/90000 (68%)]	Loss: 5.5735	Cost: 6.00s
Train Epoch: 1182 [81920/90000 (91%)]	Loss: 5.7903	Cost: 6.24s
Train Epoch: 1182 	Average Loss: 6.7627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7180

Learning rate: 0.0001931843304163604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1183 [0/90000 (0%)]	Loss: 19.7127	Cost: 21.66s
Train Epoch: 1183 [20480/90000 (23%)]	Loss: 5.6314	Cost: 6.07s
Train Epoch: 1183 [40960/90000 (45%)]	Loss: 5.6173	Cost: 6.03s
Train Epoch: 1183 [61440/90000 (68%)]	Loss: 5.6084	Cost: 5.90s
Train Epoch: 1183 [81920/90000 (91%)]	Loss: 5.9722	Cost: 5.88s
Train Epoch: 1183 	Average Loss: 6.7301
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6325

Learning rate: 0.0001931729262056809
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1184 [0/90000 (0%)]	Loss: 19.6323	Cost: 20.93s
Train Epoch: 1184 [20480/90000 (23%)]	Loss: 5.6367	Cost: 6.07s
Train Epoch: 1184 [40960/90000 (45%)]	Loss: 5.8125	Cost: 6.28s
Train Epoch: 1184 [61440/90000 (68%)]	Loss: 5.7567	Cost: 5.95s
Train Epoch: 1184 [81920/90000 (91%)]	Loss: 5.8171	Cost: 6.02s
Train Epoch: 1184 	Average Loss: 6.7178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6582

Learning rate: 0.0001931615127992022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1185 [0/90000 (0%)]	Loss: 19.9137	Cost: 22.23s
Train Epoch: 1185 [20480/90000 (23%)]	Loss: 6.0118	Cost: 6.09s
Train Epoch: 1185 [40960/90000 (45%)]	Loss: 6.0572	Cost: 6.22s
Train Epoch: 1185 [61440/90000 (68%)]	Loss: 6.1086	Cost: 6.06s
Train Epoch: 1185 [81920/90000 (91%)]	Loss: 5.8512	Cost: 6.03s
Train Epoch: 1185 	Average Loss: 6.8476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7400

Learning rate: 0.00019315009019805086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1186 [0/90000 (0%)]	Loss: 19.4993	Cost: 21.40s
Train Epoch: 1186 [20480/90000 (23%)]	Loss: 5.9059	Cost: 5.96s
Train Epoch: 1186 [40960/90000 (45%)]	Loss: 5.8728	Cost: 6.33s
Train Epoch: 1186 [61440/90000 (68%)]	Loss: 5.7772	Cost: 5.89s
Train Epoch: 1186 [81920/90000 (91%)]	Loss: 6.1279	Cost: 5.93s
Train Epoch: 1186 	Average Loss: 6.7370
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7039

Learning rate: 0.00019313865840335417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1187 [0/90000 (0%)]	Loss: 19.7015	Cost: 21.29s
Train Epoch: 1187 [20480/90000 (23%)]	Loss: 5.9649	Cost: 6.02s
Train Epoch: 1187 [40960/90000 (45%)]	Loss: 5.9542	Cost: 6.50s
Train Epoch: 1187 [61440/90000 (68%)]	Loss: 5.8308	Cost: 5.95s
Train Epoch: 1187 [81920/90000 (91%)]	Loss: 5.8209	Cost: 6.82s
Train Epoch: 1187 	Average Loss: 6.8164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6227

Learning rate: 0.00019312721741624044
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1188 [0/90000 (0%)]	Loss: 20.0183	Cost: 20.30s
Train Epoch: 1188 [20480/90000 (23%)]	Loss: 5.8502	Cost: 6.03s
Train Epoch: 1188 [40960/90000 (45%)]	Loss: 5.7612	Cost: 6.10s
Train Epoch: 1188 [61440/90000 (68%)]	Loss: 5.6554	Cost: 5.93s
Train Epoch: 1188 [81920/90000 (91%)]	Loss: 5.9440	Cost: 6.00s
Train Epoch: 1188 	Average Loss: 6.7627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7282

Learning rate: 0.00019311576723783885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1189 [0/90000 (0%)]	Loss: 19.6910	Cost: 21.08s
Train Epoch: 1189 [20480/90000 (23%)]	Loss: 5.7332	Cost: 6.05s
Train Epoch: 1189 [40960/90000 (45%)]	Loss: 5.6923	Cost: 6.57s
Train Epoch: 1189 [61440/90000 (68%)]	Loss: 5.5866	Cost: 5.96s
Train Epoch: 1189 [81920/90000 (91%)]	Loss: 5.8261	Cost: 6.83s
Train Epoch: 1189 	Average Loss: 6.7281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8233

Learning rate: 0.00019310430786927943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1190 [0/90000 (0%)]	Loss: 19.7110	Cost: 20.32s
Train Epoch: 1190 [20480/90000 (23%)]	Loss: 5.8938	Cost: 6.05s
Train Epoch: 1190 [40960/90000 (45%)]	Loss: 5.7061	Cost: 6.07s
Train Epoch: 1190 [61440/90000 (68%)]	Loss: 5.8401	Cost: 5.89s
Train Epoch: 1190 [81920/90000 (91%)]	Loss: 5.8670	Cost: 5.96s
Train Epoch: 1190 	Average Loss: 6.8102
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7068

Learning rate: 0.0001930928393116932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1191 [0/90000 (0%)]	Loss: 19.4973	Cost: 21.38s
Train Epoch: 1191 [20480/90000 (23%)]	Loss: 5.8351	Cost: 6.08s
Train Epoch: 1191 [40960/90000 (45%)]	Loss: 6.4410	Cost: 6.45s
Train Epoch: 1191 [61440/90000 (68%)]	Loss: 6.2188	Cost: 5.89s
Train Epoch: 1191 [81920/90000 (91%)]	Loss: 6.1854	Cost: 6.05s
Train Epoch: 1191 	Average Loss: 7.0045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5702

Learning rate: 0.00019308136156621214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1192 [0/90000 (0%)]	Loss: 19.4027	Cost: 19.65s
Train Epoch: 1192 [20480/90000 (23%)]	Loss: 6.1246	Cost: 6.12s
Train Epoch: 1192 [40960/90000 (45%)]	Loss: 6.1402	Cost: 6.61s
Train Epoch: 1192 [61440/90000 (68%)]	Loss: 7.1109	Cost: 5.86s
Train Epoch: 1192 [81920/90000 (91%)]	Loss: 6.9624	Cost: 6.11s
Train Epoch: 1192 	Average Loss: 7.5384
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6662

Learning rate: 0.00019306987463396896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1193 [0/90000 (0%)]	Loss: 19.4710	Cost: 19.70s
Train Epoch: 1193 [20480/90000 (23%)]	Loss: 6.7281	Cost: 6.07s
Train Epoch: 1193 [40960/90000 (45%)]	Loss: 6.3062	Cost: 6.07s
Train Epoch: 1193 [61440/90000 (68%)]	Loss: 6.2593	Cost: 5.93s
Train Epoch: 1193 [81920/90000 (91%)]	Loss: 6.3290	Cost: 5.83s
Train Epoch: 1193 	Average Loss: 7.3506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5839

Learning rate: 0.00019305837851609745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1194 [0/90000 (0%)]	Loss: 19.3008	Cost: 21.03s
Train Epoch: 1194 [20480/90000 (23%)]	Loss: 5.9388	Cost: 6.13s
Train Epoch: 1194 [40960/90000 (45%)]	Loss: 5.9853	Cost: 6.32s
Train Epoch: 1194 [61440/90000 (68%)]	Loss: 5.9197	Cost: 5.92s
Train Epoch: 1194 [81920/90000 (91%)]	Loss: 5.7269	Cost: 5.94s
Train Epoch: 1194 	Average Loss: 6.9448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6756

Learning rate: 0.00019304687321373217
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1195 [0/90000 (0%)]	Loss: 19.6270	Cost: 21.26s
Train Epoch: 1195 [20480/90000 (23%)]	Loss: 5.9425	Cost: 5.99s
Train Epoch: 1195 [40960/90000 (45%)]	Loss: 5.7596	Cost: 6.47s
Train Epoch: 1195 [61440/90000 (68%)]	Loss: 5.8827	Cost: 6.04s
Train Epoch: 1195 [81920/90000 (91%)]	Loss: 6.0413	Cost: 6.36s
Train Epoch: 1195 	Average Loss: 6.8794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4830

Learning rate: 0.00019303535872800865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1196 [0/90000 (0%)]	Loss: 19.4395	Cost: 20.50s
Train Epoch: 1196 [20480/90000 (23%)]	Loss: 5.8240	Cost: 6.02s
Train Epoch: 1196 [40960/90000 (45%)]	Loss: 6.0312	Cost: 6.58s
Train Epoch: 1196 [61440/90000 (68%)]	Loss: 5.9338	Cost: 6.10s
Train Epoch: 1196 [81920/90000 (91%)]	Loss: 5.8763	Cost: 5.90s
Train Epoch: 1196 	Average Loss: 6.8647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5864

Learning rate: 0.00019302383506006335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1197 [0/90000 (0%)]	Loss: 19.3351	Cost: 20.93s
Train Epoch: 1197 [20480/90000 (23%)]	Loss: 5.7729	Cost: 5.97s
Train Epoch: 1197 [40960/90000 (45%)]	Loss: 5.8172	Cost: 6.10s
Train Epoch: 1197 [61440/90000 (68%)]	Loss: 5.8294	Cost: 5.95s
Train Epoch: 1197 [81920/90000 (91%)]	Loss: 5.7911	Cost: 6.84s
Train Epoch: 1197 	Average Loss: 6.8049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6296

Learning rate: 0.00019301230221103362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1198 [0/90000 (0%)]	Loss: 19.6831	Cost: 21.03s
Train Epoch: 1198 [20480/90000 (23%)]	Loss: 5.6661	Cost: 5.96s
Train Epoch: 1198 [40960/90000 (45%)]	Loss: 5.9797	Cost: 6.80s
Train Epoch: 1198 [61440/90000 (68%)]	Loss: 5.7050	Cost: 5.85s
Train Epoch: 1198 [81920/90000 (91%)]	Loss: 6.7712	Cost: 6.10s
Train Epoch: 1198 	Average Loss: 6.9218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7924

Learning rate: 0.0001930007601820577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1199 [0/90000 (0%)]	Loss: 19.8939	Cost: 21.06s
Train Epoch: 1199 [20480/90000 (23%)]	Loss: 5.9299	Cost: 5.99s
Train Epoch: 1199 [40960/90000 (45%)]	Loss: 5.9493	Cost: 6.48s
Train Epoch: 1199 [61440/90000 (68%)]	Loss: 5.9250	Cost: 5.93s
Train Epoch: 1199 [81920/90000 (91%)]	Loss: 5.9583	Cost: 6.36s
Train Epoch: 1199 	Average Loss: 6.9985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7220

Learning rate: 0.00019298920897427473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1200 [0/90000 (0%)]	Loss: 19.7347	Cost: 21.57s
Train Epoch: 1200 [20480/90000 (23%)]	Loss: 5.8100	Cost: 6.05s
Train Epoch: 1200 [40960/90000 (45%)]	Loss: 5.6847	Cost: 6.23s
Train Epoch: 1200 [61440/90000 (68%)]	Loss: 5.7410	Cost: 5.93s
Train Epoch: 1200 [81920/90000 (91%)]	Loss: 5.7747	Cost: 6.34s
Train Epoch: 1200 	Average Loss: 6.7093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6143

Learning rate: 0.00019297764858882476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1201 [0/90000 (0%)]	Loss: 19.5272	Cost: 20.42s
Train Epoch: 1201 [20480/90000 (23%)]	Loss: 6.0208	Cost: 5.98s
Train Epoch: 1201 [40960/90000 (45%)]	Loss: 5.6652	Cost: 6.42s
Train Epoch: 1201 [61440/90000 (68%)]	Loss: 5.7604	Cost: 5.99s
Train Epoch: 1201 [81920/90000 (91%)]	Loss: 5.7655	Cost: 6.69s
Train Epoch: 1201 	Average Loss: 6.7646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7710

Learning rate: 0.0001929660790268488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1202 [0/90000 (0%)]	Loss: 20.0643	Cost: 21.57s
Train Epoch: 1202 [20480/90000 (23%)]	Loss: 5.7711	Cost: 5.98s
Train Epoch: 1202 [40960/90000 (45%)]	Loss: 5.4686	Cost: 6.24s
Train Epoch: 1202 [61440/90000 (68%)]	Loss: 5.5148	Cost: 5.98s
Train Epoch: 1202 [81920/90000 (91%)]	Loss: 5.7158	Cost: 6.77s
Train Epoch: 1202 	Average Loss: 6.5973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6830

Learning rate: 0.00019295450028948867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1203 [0/90000 (0%)]	Loss: 19.8054	Cost: 20.67s
Train Epoch: 1203 [20480/90000 (23%)]	Loss: 5.7659	Cost: 6.07s
Train Epoch: 1203 [40960/90000 (45%)]	Loss: 5.5999	Cost: 6.53s
Train Epoch: 1203 [61440/90000 (68%)]	Loss: 5.4019	Cost: 6.06s
Train Epoch: 1203 [81920/90000 (91%)]	Loss: 5.5118	Cost: 6.76s
Train Epoch: 1203 	Average Loss: 6.5903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6206

Learning rate: 0.00019294291237788717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1204 [0/90000 (0%)]	Loss: 19.6137	Cost: 21.24s
Train Epoch: 1204 [20480/90000 (23%)]	Loss: 5.3698	Cost: 6.14s
Train Epoch: 1204 [40960/90000 (45%)]	Loss: 5.2922	Cost: 6.38s
Train Epoch: 1204 [61440/90000 (68%)]	Loss: 5.2413	Cost: 5.78s
Train Epoch: 1204 [81920/90000 (91%)]	Loss: 5.5790	Cost: 6.81s
Train Epoch: 1204 	Average Loss: 6.4763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8137

Learning rate: 0.00019293131529318796
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1205 [0/90000 (0%)]	Loss: 19.3141	Cost: 20.01s
Train Epoch: 1205 [20480/90000 (23%)]	Loss: 5.2984	Cost: 6.06s
Train Epoch: 1205 [40960/90000 (45%)]	Loss: 5.2747	Cost: 6.08s
Train Epoch: 1205 [61440/90000 (68%)]	Loss: 5.2922	Cost: 6.03s
Train Epoch: 1205 [81920/90000 (91%)]	Loss: 5.3155	Cost: 6.82s
Train Epoch: 1205 	Average Loss: 6.3728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7851

Learning rate: 0.00019291970903653568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1206 [0/90000 (0%)]	Loss: 19.7486	Cost: 21.30s
Train Epoch: 1206 [20480/90000 (23%)]	Loss: 5.4594	Cost: 5.97s
Train Epoch: 1206 [40960/90000 (45%)]	Loss: 5.4723	Cost: 6.35s
Train Epoch: 1206 [61440/90000 (68%)]	Loss: 5.4669	Cost: 6.01s
Train Epoch: 1206 [81920/90000 (91%)]	Loss: 5.6651	Cost: 7.84s
Train Epoch: 1206 	Average Loss: 6.4784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8551

Learning rate: 0.00019290809360907572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1207 [0/90000 (0%)]	Loss: 19.7799	Cost: 20.66s
Train Epoch: 1207 [20480/90000 (23%)]	Loss: 5.3848	Cost: 6.19s
Train Epoch: 1207 [40960/90000 (45%)]	Loss: 5.4627	Cost: 6.08s
Train Epoch: 1207 [61440/90000 (68%)]	Loss: 5.3209	Cost: 6.13s
Train Epoch: 1207 [81920/90000 (91%)]	Loss: 5.5060	Cost: 6.42s
Train Epoch: 1207 	Average Loss: 6.4293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9892

Learning rate: 0.0001928964690119546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1208 [0/90000 (0%)]	Loss: 19.7949	Cost: 20.94s
Train Epoch: 1208 [20480/90000 (23%)]	Loss: 5.4473	Cost: 6.04s
Train Epoch: 1208 [40960/90000 (45%)]	Loss: 5.1275	Cost: 6.92s
Train Epoch: 1208 [61440/90000 (68%)]	Loss: 5.2729	Cost: 6.06s
Train Epoch: 1208 [81920/90000 (91%)]	Loss: 5.4830	Cost: 8.00s
Train Epoch: 1208 	Average Loss: 6.3972
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8606

Learning rate: 0.00019288483524631953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1209 [0/90000 (0%)]	Loss: 19.5962	Cost: 19.29s
Train Epoch: 1209 [20480/90000 (23%)]	Loss: 5.3761	Cost: 6.06s
Train Epoch: 1209 [40960/90000 (45%)]	Loss: 5.6551	Cost: 6.43s
Train Epoch: 1209 [61440/90000 (68%)]	Loss: 5.5497	Cost: 6.06s
Train Epoch: 1209 [81920/90000 (91%)]	Loss: 5.6007	Cost: 8.08s
Train Epoch: 1209 	Average Loss: 6.5155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9004

Learning rate: 0.00019287319231331873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1210 [0/90000 (0%)]	Loss: 19.6347	Cost: 19.71s
Train Epoch: 1210 [20480/90000 (23%)]	Loss: 5.4624	Cost: 6.11s
Train Epoch: 1210 [40960/90000 (45%)]	Loss: 5.2386	Cost: 6.16s
Train Epoch: 1210 [61440/90000 (68%)]	Loss: 5.3884	Cost: 6.08s
Train Epoch: 1210 [81920/90000 (91%)]	Loss: 5.5287	Cost: 6.69s
Train Epoch: 1210 	Average Loss: 6.4404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8396

Learning rate: 0.00019286154021410135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1211 [0/90000 (0%)]	Loss: 19.7429	Cost: 20.27s
Train Epoch: 1211 [20480/90000 (23%)]	Loss: 5.3469	Cost: 6.16s
Train Epoch: 1211 [40960/90000 (45%)]	Loss: 5.4566	Cost: 6.20s
Train Epoch: 1211 [61440/90000 (68%)]	Loss: 5.5609	Cost: 5.91s
Train Epoch: 1211 [81920/90000 (91%)]	Loss: 5.5961	Cost: 6.92s
Train Epoch: 1211 	Average Loss: 6.4543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9403

Learning rate: 0.0001928498789498174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1212 [0/90000 (0%)]	Loss: 19.8535	Cost: 20.07s
Train Epoch: 1212 [20480/90000 (23%)]	Loss: 5.2464	Cost: 6.08s
Train Epoch: 1212 [40960/90000 (45%)]	Loss: 5.3174	Cost: 6.03s
Train Epoch: 1212 [61440/90000 (68%)]	Loss: 5.0903	Cost: 5.97s
Train Epoch: 1212 [81920/90000 (91%)]	Loss: 5.3574	Cost: 6.04s
Train Epoch: 1212 	Average Loss: 6.3534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8532

Learning rate: 0.00019283820852161778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1213 [0/90000 (0%)]	Loss: 19.8578	Cost: 20.57s
Train Epoch: 1213 [20480/90000 (23%)]	Loss: 5.3644	Cost: 6.00s
Train Epoch: 1213 [40960/90000 (45%)]	Loss: 5.4652	Cost: 6.17s
Train Epoch: 1213 [61440/90000 (68%)]	Loss: 5.2550	Cost: 5.91s
Train Epoch: 1213 [81920/90000 (91%)]	Loss: 5.6749	Cost: 6.11s
Train Epoch: 1213 	Average Loss: 6.4619
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7652

Learning rate: 0.00019282652893065432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1214 [0/90000 (0%)]	Loss: 20.0431	Cost: 21.13s
Train Epoch: 1214 [20480/90000 (23%)]	Loss: 5.6646	Cost: 6.02s
Train Epoch: 1214 [40960/90000 (45%)]	Loss: 5.5455	Cost: 6.29s
Train Epoch: 1214 [61440/90000 (68%)]	Loss: 5.4310	Cost: 5.91s
Train Epoch: 1214 [81920/90000 (91%)]	Loss: 5.4549	Cost: 7.12s
Train Epoch: 1214 	Average Loss: 6.5826
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8226

Learning rate: 0.00019281484017807975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1215 [0/90000 (0%)]	Loss: 19.8410	Cost: 20.56s
Train Epoch: 1215 [20480/90000 (23%)]	Loss: 5.4326	Cost: 6.03s
Train Epoch: 1215 [40960/90000 (45%)]	Loss: 5.5912	Cost: 6.44s
Train Epoch: 1215 [61440/90000 (68%)]	Loss: 5.8110	Cost: 5.90s
Train Epoch: 1215 [81920/90000 (91%)]	Loss: 5.8088	Cost: 5.88s
Train Epoch: 1215 	Average Loss: 6.5974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7251

Learning rate: 0.00019280314226504771
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1216 [0/90000 (0%)]	Loss: 19.6755	Cost: 22.10s
Train Epoch: 1216 [20480/90000 (23%)]	Loss: 5.4376	Cost: 6.06s
Train Epoch: 1216 [40960/90000 (45%)]	Loss: 5.3087	Cost: 6.07s
Train Epoch: 1216 [61440/90000 (68%)]	Loss: 5.2449	Cost: 5.89s
Train Epoch: 1216 [81920/90000 (91%)]	Loss: 5.3430	Cost: 6.16s
Train Epoch: 1216 	Average Loss: 6.4707
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7901

Learning rate: 0.00019279143519271272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1217 [0/90000 (0%)]	Loss: 19.6718	Cost: 21.36s
Train Epoch: 1217 [20480/90000 (23%)]	Loss: 5.2641	Cost: 6.11s
Train Epoch: 1217 [40960/90000 (45%)]	Loss: 5.4456	Cost: 6.41s
Train Epoch: 1217 [61440/90000 (68%)]	Loss: 5.2940	Cost: 5.90s
Train Epoch: 1217 [81920/90000 (91%)]	Loss: 5.5494	Cost: 6.03s
Train Epoch: 1217 	Average Loss: 6.3696
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8754

Learning rate: 0.00019277971896223024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1218 [0/90000 (0%)]	Loss: 20.0701	Cost: 20.43s
Train Epoch: 1218 [20480/90000 (23%)]	Loss: 5.4114	Cost: 6.01s
Train Epoch: 1218 [40960/90000 (45%)]	Loss: 5.3929	Cost: 6.09s
Train Epoch: 1218 [61440/90000 (68%)]	Loss: 5.2610	Cost: 6.04s
Train Epoch: 1218 [81920/90000 (91%)]	Loss: 5.4329	Cost: 5.92s
Train Epoch: 1218 	Average Loss: 6.4074
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9176

Learning rate: 0.00019276799357475661
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1219 [0/90000 (0%)]	Loss: 19.6545	Cost: 21.92s
Train Epoch: 1219 [20480/90000 (23%)]	Loss: 5.2130	Cost: 6.03s
Train Epoch: 1219 [40960/90000 (45%)]	Loss: 5.3356	Cost: 6.64s
Train Epoch: 1219 [61440/90000 (68%)]	Loss: 5.4691	Cost: 5.86s
Train Epoch: 1219 [81920/90000 (91%)]	Loss: 5.4991	Cost: 5.83s
Train Epoch: 1219 	Average Loss: 6.4108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9099

Learning rate: 0.00019275625903144908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1220 [0/90000 (0%)]	Loss: 19.7006	Cost: 21.29s
Train Epoch: 1220 [20480/90000 (23%)]	Loss: 5.4257	Cost: 5.79s
Train Epoch: 1220 [40960/90000 (45%)]	Loss: 5.7561	Cost: 6.68s
Train Epoch: 1220 [61440/90000 (68%)]	Loss: 5.6450	Cost: 5.90s
Train Epoch: 1220 [81920/90000 (91%)]	Loss: 5.8893	Cost: 6.16s
Train Epoch: 1220 	Average Loss: 6.6199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8755

Learning rate: 0.0001927445153334658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1221 [0/90000 (0%)]	Loss: 19.3234	Cost: 21.46s
Train Epoch: 1221 [20480/90000 (23%)]	Loss: 5.6222	Cost: 6.00s
Train Epoch: 1221 [40960/90000 (45%)]	Loss: 5.5073	Cost: 7.32s
Train Epoch: 1221 [61440/90000 (68%)]	Loss: 5.7022	Cost: 5.86s
Train Epoch: 1221 [81920/90000 (91%)]	Loss: 5.9915	Cost: 6.37s
Train Epoch: 1221 	Average Loss: 6.6198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8751

Learning rate: 0.00019273276248196581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1222 [0/90000 (0%)]	Loss: 19.8462	Cost: 20.63s
Train Epoch: 1222 [20480/90000 (23%)]	Loss: 5.5321	Cost: 6.08s
Train Epoch: 1222 [40960/90000 (45%)]	Loss: 5.4915	Cost: 6.40s
Train Epoch: 1222 [61440/90000 (68%)]	Loss: 5.5629	Cost: 5.71s
Train Epoch: 1222 [81920/90000 (91%)]	Loss: 5.6773	Cost: 5.71s
Train Epoch: 1222 	Average Loss: 6.6023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7790

Learning rate: 0.0001927210004781091
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1223 [0/90000 (0%)]	Loss: 19.7086	Cost: 20.69s
Train Epoch: 1223 [20480/90000 (23%)]	Loss: 5.6364	Cost: 6.07s
Train Epoch: 1223 [40960/90000 (45%)]	Loss: 5.4757	Cost: 6.06s
Train Epoch: 1223 [61440/90000 (68%)]	Loss: 5.5202	Cost: 5.97s
Train Epoch: 1223 [81920/90000 (91%)]	Loss: 5.6497	Cost: 5.88s
Train Epoch: 1223 	Average Loss: 6.5032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8637

Learning rate: 0.0001927092293230565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1224 [0/90000 (0%)]	Loss: 19.7525	Cost: 20.38s
Train Epoch: 1224 [20480/90000 (23%)]	Loss: 5.2668	Cost: 6.14s
Train Epoch: 1224 [40960/90000 (45%)]	Loss: 5.5936	Cost: 6.29s
Train Epoch: 1224 [61440/90000 (68%)]	Loss: 4.9455	Cost: 5.84s
Train Epoch: 1224 [81920/90000 (91%)]	Loss: 5.3653	Cost: 5.71s
Train Epoch: 1224 	Average Loss: 6.3138
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7808

Learning rate: 0.00019269744901796983
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1225 [0/90000 (0%)]	Loss: 19.8298	Cost: 19.81s
Train Epoch: 1225 [20480/90000 (23%)]	Loss: 5.3671	Cost: 6.06s
Train Epoch: 1225 [40960/90000 (45%)]	Loss: 5.3259	Cost: 6.04s
Train Epoch: 1225 [61440/90000 (68%)]	Loss: 5.0848	Cost: 5.92s
Train Epoch: 1225 [81920/90000 (91%)]	Loss: 5.2735	Cost: 5.84s
Train Epoch: 1225 	Average Loss: 6.2073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8433

Learning rate: 0.0001926856595640117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1226 [0/90000 (0%)]	Loss: 19.6191	Cost: 20.43s
Train Epoch: 1226 [20480/90000 (23%)]	Loss: 5.7879	Cost: 6.06s
Train Epoch: 1226 [40960/90000 (45%)]	Loss: 5.8931	Cost: 6.29s
Train Epoch: 1226 [61440/90000 (68%)]	Loss: 5.5667	Cost: 5.88s
Train Epoch: 1226 [81920/90000 (91%)]	Loss: 5.6784	Cost: 5.99s
Train Epoch: 1226 	Average Loss: 6.6366
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9078

Learning rate: 0.00019267386096234575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1227 [0/90000 (0%)]	Loss: 19.8143	Cost: 21.36s
Train Epoch: 1227 [20480/90000 (23%)]	Loss: 5.4190	Cost: 6.15s
Train Epoch: 1227 [40960/90000 (45%)]	Loss: 5.5509	Cost: 6.64s
Train Epoch: 1227 [61440/90000 (68%)]	Loss: 5.2698	Cost: 5.90s
Train Epoch: 1227 [81920/90000 (91%)]	Loss: 5.3736	Cost: 6.59s
Train Epoch: 1227 	Average Loss: 6.3927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8477

Learning rate: 0.0001926620532141364
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1228 [0/90000 (0%)]	Loss: 19.8633	Cost: 22.14s
Train Epoch: 1228 [20480/90000 (23%)]	Loss: 5.4908	Cost: 6.00s
Train Epoch: 1228 [40960/90000 (45%)]	Loss: 5.4585	Cost: 6.59s
Train Epoch: 1228 [61440/90000 (68%)]	Loss: 5.2236	Cost: 5.92s
Train Epoch: 1228 [81920/90000 (91%)]	Loss: 5.3015	Cost: 5.91s
Train Epoch: 1228 	Average Loss: 6.3055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9784

Learning rate: 0.00019265023632054903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1229 [0/90000 (0%)]	Loss: 19.4361	Cost: 20.40s
Train Epoch: 1229 [20480/90000 (23%)]	Loss: 5.5022	Cost: 6.04s
Train Epoch: 1229 [40960/90000 (45%)]	Loss: 5.3147	Cost: 6.12s
Train Epoch: 1229 [61440/90000 (68%)]	Loss: 5.2728	Cost: 6.20s
Train Epoch: 1229 [81920/90000 (91%)]	Loss: 5.1975	Cost: 5.96s
Train Epoch: 1229 	Average Loss: 6.3334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9180

Learning rate: 0.00019263841028274996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1230 [0/90000 (0%)]	Loss: 19.6427	Cost: 20.54s
Train Epoch: 1230 [20480/90000 (23%)]	Loss: 5.3141	Cost: 6.13s
Train Epoch: 1230 [40960/90000 (45%)]	Loss: 5.2786	Cost: 6.41s
Train Epoch: 1230 [61440/90000 (68%)]	Loss: 5.0570	Cost: 5.89s
Train Epoch: 1230 [81920/90000 (91%)]	Loss: 5.3873	Cost: 6.21s
Train Epoch: 1230 	Average Loss: 6.2080
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9273

Learning rate: 0.0001926265751019063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1231 [0/90000 (0%)]	Loss: 19.9420	Cost: 21.58s
Train Epoch: 1231 [20480/90000 (23%)]	Loss: 5.1407	Cost: 6.06s
Train Epoch: 1231 [40960/90000 (45%)]	Loss: 5.0398	Cost: 6.21s
Train Epoch: 1231 [61440/90000 (68%)]	Loss: 4.9644	Cost: 5.95s
Train Epoch: 1231 [81920/90000 (91%)]	Loss: 5.2463	Cost: 6.53s
Train Epoch: 1231 	Average Loss: 6.2045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9733

Learning rate: 0.00019261473077918618
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1232 [0/90000 (0%)]	Loss: 19.8850	Cost: 20.98s
Train Epoch: 1232 [20480/90000 (23%)]	Loss: 5.2616	Cost: 6.03s
Train Epoch: 1232 [40960/90000 (45%)]	Loss: 5.1418	Cost: 6.22s
Train Epoch: 1232 [61440/90000 (68%)]	Loss: 5.3747	Cost: 5.91s
Train Epoch: 1232 [81920/90000 (91%)]	Loss: 5.5651	Cost: 5.82s
Train Epoch: 1232 	Average Loss: 6.2404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9383

Learning rate: 0.00019260287731575864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1233 [0/90000 (0%)]	Loss: 19.7334	Cost: 20.96s
Train Epoch: 1233 [20480/90000 (23%)]	Loss: 5.1677	Cost: 6.09s
Train Epoch: 1233 [40960/90000 (45%)]	Loss: 5.2301	Cost: 6.52s
Train Epoch: 1233 [61440/90000 (68%)]	Loss: 5.0481	Cost: 5.91s
Train Epoch: 1233 [81920/90000 (91%)]	Loss: 5.2279	Cost: 5.94s
Train Epoch: 1233 	Average Loss: 6.1986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0454

Learning rate: 0.0001925910147127935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1234 [0/90000 (0%)]	Loss: 19.8898	Cost: 20.09s
Train Epoch: 1234 [20480/90000 (23%)]	Loss: 4.9786	Cost: 6.05s
Train Epoch: 1234 [40960/90000 (45%)]	Loss: 4.9659	Cost: 6.03s
Train Epoch: 1234 [61440/90000 (68%)]	Loss: 4.8367	Cost: 5.90s
Train Epoch: 1234 [81920/90000 (91%)]	Loss: 5.1550	Cost: 5.82s
Train Epoch: 1234 	Average Loss: 6.1410
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0166

Learning rate: 0.00019257914297146156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1235 [0/90000 (0%)]	Loss: 19.8036	Cost: 20.22s
Train Epoch: 1235 [20480/90000 (23%)]	Loss: 5.1408	Cost: 6.15s
Train Epoch: 1235 [40960/90000 (45%)]	Loss: 5.3605	Cost: 6.00s
Train Epoch: 1235 [61440/90000 (68%)]	Loss: 5.1528	Cost: 5.88s
Train Epoch: 1235 [81920/90000 (91%)]	Loss: 5.2120	Cost: 5.82s
Train Epoch: 1235 	Average Loss: 6.2683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0044

Learning rate: 0.00019256726209293456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1236 [0/90000 (0%)]	Loss: 19.8717	Cost: 20.56s
Train Epoch: 1236 [20480/90000 (23%)]	Loss: 5.0778	Cost: 6.12s
Train Epoch: 1236 [40960/90000 (45%)]	Loss: 5.0130	Cost: 6.02s
Train Epoch: 1236 [61440/90000 (68%)]	Loss: 4.6896	Cost: 5.88s
Train Epoch: 1236 [81920/90000 (91%)]	Loss: 5.1149	Cost: 5.81s
Train Epoch: 1236 	Average Loss: 6.1402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9568

Learning rate: 0.00019255537207838502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1237 [0/90000 (0%)]	Loss: 19.9192	Cost: 20.61s
Train Epoch: 1237 [20480/90000 (23%)]	Loss: 5.0827	Cost: 6.05s
Train Epoch: 1237 [40960/90000 (45%)]	Loss: 5.4908	Cost: 6.27s
Train Epoch: 1237 [61440/90000 (68%)]	Loss: 5.4360	Cost: 5.91s
Train Epoch: 1237 [81920/90000 (91%)]	Loss: 5.2598	Cost: 5.89s
Train Epoch: 1237 	Average Loss: 6.3434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9127

Learning rate: 0.0001925434729289865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1238 [0/90000 (0%)]	Loss: 20.0575	Cost: 22.59s
Train Epoch: 1238 [20480/90000 (23%)]	Loss: 5.2971	Cost: 6.07s
Train Epoch: 1238 [40960/90000 (45%)]	Loss: 5.4366	Cost: 6.33s
Train Epoch: 1238 [61440/90000 (68%)]	Loss: 5.4491	Cost: 5.93s
Train Epoch: 1238 [81920/90000 (91%)]	Loss: 5.8244	Cost: 5.94s
Train Epoch: 1238 	Average Loss: 6.5823
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0256

Learning rate: 0.00019253156464591338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1239 [0/90000 (0%)]	Loss: 20.0139	Cost: 21.72s
Train Epoch: 1239 [20480/90000 (23%)]	Loss: 5.3778	Cost: 6.10s
Train Epoch: 1239 [40960/90000 (45%)]	Loss: 5.6296	Cost: 6.18s
Train Epoch: 1239 [61440/90000 (68%)]	Loss: 5.1241	Cost: 5.88s
Train Epoch: 1239 [81920/90000 (91%)]	Loss: 5.1655	Cost: 6.07s
Train Epoch: 1239 	Average Loss: 6.4216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9292

Learning rate: 0.00019251964723034095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1240 [0/90000 (0%)]	Loss: 19.9845	Cost: 21.36s
Train Epoch: 1240 [20480/90000 (23%)]	Loss: 5.2523	Cost: 6.10s
Train Epoch: 1240 [40960/90000 (45%)]	Loss: 5.1531	Cost: 6.81s
Train Epoch: 1240 [61440/90000 (68%)]	Loss: 4.8899	Cost: 6.12s
Train Epoch: 1240 [81920/90000 (91%)]	Loss: 5.3796	Cost: 5.99s
Train Epoch: 1240 	Average Loss: 6.2057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9516

Learning rate: 0.00019250772068344542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1241 [0/90000 (0%)]	Loss: 20.0020	Cost: 20.77s
Train Epoch: 1241 [20480/90000 (23%)]	Loss: 5.0576	Cost: 6.01s
Train Epoch: 1241 [40960/90000 (45%)]	Loss: 5.0445	Cost: 6.68s
Train Epoch: 1241 [61440/90000 (68%)]	Loss: 4.8520	Cost: 5.89s
Train Epoch: 1241 [81920/90000 (91%)]	Loss: 5.1131	Cost: 5.99s
Train Epoch: 1241 	Average Loss: 6.1376
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9480

Learning rate: 0.0001924957850064039
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1242 [0/90000 (0%)]	Loss: 19.7653	Cost: 20.13s
Train Epoch: 1242 [20480/90000 (23%)]	Loss: 4.9511	Cost: 6.16s
Train Epoch: 1242 [40960/90000 (45%)]	Loss: 5.1870	Cost: 6.07s
Train Epoch: 1242 [61440/90000 (68%)]	Loss: 4.9634	Cost: 5.92s
Train Epoch: 1242 [81920/90000 (91%)]	Loss: 5.2333	Cost: 5.85s
Train Epoch: 1242 	Average Loss: 6.2329
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9455

Learning rate: 0.0001924838402003944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1243 [0/90000 (0%)]	Loss: 20.0821	Cost: 21.12s
Train Epoch: 1243 [20480/90000 (23%)]	Loss: 5.1274	Cost: 5.97s
Train Epoch: 1243 [40960/90000 (45%)]	Loss: 5.3891	Cost: 6.29s
Train Epoch: 1243 [61440/90000 (68%)]	Loss: 5.1358	Cost: 5.95s
Train Epoch: 1243 [81920/90000 (91%)]	Loss: 5.4436	Cost: 5.95s
Train Epoch: 1243 	Average Loss: 6.2880
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0844

Learning rate: 0.0001924718862665958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1244 [0/90000 (0%)]	Loss: 19.5131	Cost: 21.17s
Train Epoch: 1244 [20480/90000 (23%)]	Loss: 5.4727	Cost: 6.10s
Train Epoch: 1244 [40960/90000 (45%)]	Loss: 5.5550	Cost: 6.18s
Train Epoch: 1244 [61440/90000 (68%)]	Loss: 5.3007	Cost: 5.98s
Train Epoch: 1244 [81920/90000 (91%)]	Loss: 5.4414	Cost: 6.17s
Train Epoch: 1244 	Average Loss: 6.3796
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9268

Learning rate: 0.0001924599232061879
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1245 [0/90000 (0%)]	Loss: 20.2496	Cost: 20.74s
Train Epoch: 1245 [20480/90000 (23%)]	Loss: 5.2978	Cost: 6.02s
Train Epoch: 1245 [40960/90000 (45%)]	Loss: 5.3200	Cost: 6.19s
Train Epoch: 1245 [61440/90000 (68%)]	Loss: 5.1680	Cost: 5.93s
Train Epoch: 1245 [81920/90000 (91%)]	Loss: 5.3320	Cost: 6.01s
Train Epoch: 1245 	Average Loss: 6.2777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9177

Learning rate: 0.00019244795102035147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1246 [0/90000 (0%)]	Loss: 19.6929	Cost: 20.82s
Train Epoch: 1246 [20480/90000 (23%)]	Loss: 5.1984	Cost: 6.24s
Train Epoch: 1246 [40960/90000 (45%)]	Loss: 5.0368	Cost: 6.43s
Train Epoch: 1246 [61440/90000 (68%)]	Loss: 4.9614	Cost: 5.95s
Train Epoch: 1246 [81920/90000 (91%)]	Loss: 5.0252	Cost: 6.28s
Train Epoch: 1246 	Average Loss: 6.1451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9767

Learning rate: 0.00019243596971026803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1247 [0/90000 (0%)]	Loss: 20.0947	Cost: 20.18s
Train Epoch: 1247 [20480/90000 (23%)]	Loss: 5.1145	Cost: 6.14s
Train Epoch: 1247 [40960/90000 (45%)]	Loss: 5.1774	Cost: 6.29s
Train Epoch: 1247 [61440/90000 (68%)]	Loss: 5.0580	Cost: 6.00s
Train Epoch: 1247 [81920/90000 (91%)]	Loss: 5.2832	Cost: 6.27s
Train Epoch: 1247 	Average Loss: 6.1169
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0239

Learning rate: 0.00019242397927712014
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1248 [0/90000 (0%)]	Loss: 20.0874	Cost: 20.26s
Train Epoch: 1248 [20480/90000 (23%)]	Loss: 4.9074	Cost: 6.21s
Train Epoch: 1248 [40960/90000 (45%)]	Loss: 4.9517	Cost: 6.04s
Train Epoch: 1248 [61440/90000 (68%)]	Loss: 5.1305	Cost: 5.95s
Train Epoch: 1248 [81920/90000 (91%)]	Loss: 5.0678	Cost: 5.96s
Train Epoch: 1248 	Average Loss: 6.0855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9755

Learning rate: 0.00019241197972209119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1249 [0/90000 (0%)]	Loss: 19.7933	Cost: 21.25s
Train Epoch: 1249 [20480/90000 (23%)]	Loss: 5.0750	Cost: 6.02s
Train Epoch: 1249 [40960/90000 (45%)]	Loss: 4.9836	Cost: 6.33s
Train Epoch: 1249 [61440/90000 (68%)]	Loss: 5.1678	Cost: 5.95s
Train Epoch: 1249 [81920/90000 (91%)]	Loss: 5.2969	Cost: 6.41s
Train Epoch: 1249 	Average Loss: 6.1065
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1533

Learning rate: 0.0001923999710463655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1250 [0/90000 (0%)]	Loss: 20.1899	Cost: 19.98s
Train Epoch: 1250 [20480/90000 (23%)]	Loss: 4.9682	Cost: 6.31s
Train Epoch: 1250 [40960/90000 (45%)]	Loss: 5.0715	Cost: 6.18s
Train Epoch: 1250 [61440/90000 (68%)]	Loss: 4.9407	Cost: 5.99s
Train Epoch: 1250 [81920/90000 (91%)]	Loss: 5.1983	Cost: 6.20s
Train Epoch: 1250 	Average Loss: 6.0667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0497

Learning rate: 0.0001923879532511283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1251 [0/90000 (0%)]	Loss: 19.8634	Cost: 21.88s
Train Epoch: 1251 [20480/90000 (23%)]	Loss: 5.0960	Cost: 5.99s
Train Epoch: 1251 [40960/90000 (45%)]	Loss: 4.7302	Cost: 6.07s
Train Epoch: 1251 [61440/90000 (68%)]	Loss: 4.6139	Cost: 6.14s
Train Epoch: 1251 [81920/90000 (91%)]	Loss: 4.9175	Cost: 6.01s
Train Epoch: 1251 	Average Loss: 5.9656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1514

Learning rate: 0.00019237592633756566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1252 [0/90000 (0%)]	Loss: 20.0522	Cost: 19.78s
Train Epoch: 1252 [20480/90000 (23%)]	Loss: 5.1783	Cost: 6.10s
Train Epoch: 1252 [40960/90000 (45%)]	Loss: 5.2338	Cost: 6.10s
Train Epoch: 1252 [61440/90000 (68%)]	Loss: 5.1229	Cost: 5.96s
Train Epoch: 1252 [81920/90000 (91%)]	Loss: 5.3381	Cost: 6.02s
Train Epoch: 1252 	Average Loss: 6.1874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0370

Learning rate: 0.00019236389030686458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1253 [0/90000 (0%)]	Loss: 19.7940	Cost: 20.45s
Train Epoch: 1253 [20480/90000 (23%)]	Loss: 5.1729	Cost: 6.14s
Train Epoch: 1253 [40960/90000 (45%)]	Loss: 5.0538	Cost: 6.46s
Train Epoch: 1253 [61440/90000 (68%)]	Loss: 4.8299	Cost: 5.99s
Train Epoch: 1253 [81920/90000 (91%)]	Loss: 5.0565	Cost: 6.15s
Train Epoch: 1253 	Average Loss: 6.0888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1714

Learning rate: 0.000192351845160213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1254 [0/90000 (0%)]	Loss: 20.1966	Cost: 21.05s
Train Epoch: 1254 [20480/90000 (23%)]	Loss: 4.9696	Cost: 6.16s
Train Epoch: 1254 [40960/90000 (45%)]	Loss: 5.0654	Cost: 6.07s
Train Epoch: 1254 [61440/90000 (68%)]	Loss: 4.8382	Cost: 5.99s
Train Epoch: 1254 [81920/90000 (91%)]	Loss: 5.2285	Cost: 6.04s
Train Epoch: 1254 	Average Loss: 6.1141
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1099

Learning rate: 0.00019233979089879974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1255 [0/90000 (0%)]	Loss: 19.8249	Cost: 21.04s
Train Epoch: 1255 [20480/90000 (23%)]	Loss: 5.0920	Cost: 6.12s
Train Epoch: 1255 [40960/90000 (45%)]	Loss: 5.2042	Cost: 6.58s
Train Epoch: 1255 [61440/90000 (68%)]	Loss: 4.9476	Cost: 6.03s
Train Epoch: 1255 [81920/90000 (91%)]	Loss: 5.0406	Cost: 6.29s
Train Epoch: 1255 	Average Loss: 6.1517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0131

Learning rate: 0.00019232772752381447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1256 [0/90000 (0%)]	Loss: 19.6447	Cost: 20.02s
Train Epoch: 1256 [20480/90000 (23%)]	Loss: 4.7248	Cost: 6.08s
Train Epoch: 1256 [40960/90000 (45%)]	Loss: 5.0039	Cost: 6.06s
Train Epoch: 1256 [61440/90000 (68%)]	Loss: 4.6866	Cost: 5.93s
Train Epoch: 1256 [81920/90000 (91%)]	Loss: 5.0712	Cost: 6.15s
Train Epoch: 1256 	Average Loss: 5.9299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0868

Learning rate: 0.00019231565503644783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1257 [0/90000 (0%)]	Loss: 19.9582	Cost: 21.00s
Train Epoch: 1257 [20480/90000 (23%)]	Loss: 4.8419	Cost: 6.10s
Train Epoch: 1257 [40960/90000 (45%)]	Loss: 4.9949	Cost: 6.62s
Train Epoch: 1257 [61440/90000 (68%)]	Loss: 4.6159	Cost: 5.98s
Train Epoch: 1257 [81920/90000 (91%)]	Loss: 5.1826	Cost: 6.58s
Train Epoch: 1257 	Average Loss: 6.0105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1154

Learning rate: 0.0001923035734378913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1258 [0/90000 (0%)]	Loss: 19.9509	Cost: 20.17s
Train Epoch: 1258 [20480/90000 (23%)]	Loss: 4.7635	Cost: 6.24s
Train Epoch: 1258 [40960/90000 (45%)]	Loss: 4.9975	Cost: 6.14s
Train Epoch: 1258 [61440/90000 (68%)]	Loss: 4.8355	Cost: 5.95s
Train Epoch: 1258 [81920/90000 (91%)]	Loss: 5.2474	Cost: 6.39s
Train Epoch: 1258 	Average Loss: 6.0466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0356

Learning rate: 0.00019229148272933733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1259 [0/90000 (0%)]	Loss: 20.1033	Cost: 21.03s
Train Epoch: 1259 [20480/90000 (23%)]	Loss: 4.8534	Cost: 6.13s
Train Epoch: 1259 [40960/90000 (45%)]	Loss: 5.0465	Cost: 6.53s
Train Epoch: 1259 [61440/90000 (68%)]	Loss: 4.9422	Cost: 5.98s
Train Epoch: 1259 [81920/90000 (91%)]	Loss: 5.2028	Cost: 6.42s
Train Epoch: 1259 	Average Loss: 5.9895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1123

Learning rate: 0.00019227938291197918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1260 [0/90000 (0%)]	Loss: 19.9267	Cost: 20.66s
Train Epoch: 1260 [20480/90000 (23%)]	Loss: 4.9257	Cost: 6.13s
Train Epoch: 1260 [40960/90000 (45%)]	Loss: 4.8462	Cost: 6.24s
Train Epoch: 1260 [61440/90000 (68%)]	Loss: 4.7972	Cost: 5.97s
Train Epoch: 1260 [81920/90000 (91%)]	Loss: 5.1877	Cost: 6.08s
Train Epoch: 1260 	Average Loss: 6.0095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0092

Learning rate: 0.00019226727398701107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1261 [0/90000 (0%)]	Loss: 20.1688	Cost: 20.14s
Train Epoch: 1261 [20480/90000 (23%)]	Loss: 5.2020	Cost: 6.16s
Train Epoch: 1261 [40960/90000 (45%)]	Loss: 5.4642	Cost: 6.35s
Train Epoch: 1261 [61440/90000 (68%)]	Loss: 5.0006	Cost: 5.91s
Train Epoch: 1261 [81920/90000 (91%)]	Loss: 5.6109	Cost: 6.79s
Train Epoch: 1261 	Average Loss: 6.2962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1807

Learning rate: 0.00019225515595562809
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1262 [0/90000 (0%)]	Loss: 19.9685	Cost: 20.20s
Train Epoch: 1262 [20480/90000 (23%)]	Loss: 5.4170	Cost: 6.15s
Train Epoch: 1262 [40960/90000 (45%)]	Loss: 5.4821	Cost: 6.20s
Train Epoch: 1262 [61440/90000 (68%)]	Loss: 5.1507	Cost: 6.08s
Train Epoch: 1262 [81920/90000 (91%)]	Loss: 5.2865	Cost: 6.09s
Train Epoch: 1262 	Average Loss: 6.3275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9656

Learning rate: 0.00019224302881902622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1263 [0/90000 (0%)]	Loss: 20.1998	Cost: 19.96s
Train Epoch: 1263 [20480/90000 (23%)]	Loss: 4.8918	Cost: 5.99s
Train Epoch: 1263 [40960/90000 (45%)]	Loss: 5.2775	Cost: 6.23s
Train Epoch: 1263 [61440/90000 (68%)]	Loss: 4.9404	Cost: 6.00s
Train Epoch: 1263 [81920/90000 (91%)]	Loss: 5.2544	Cost: 6.47s
Train Epoch: 1263 	Average Loss: 6.1330
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1237

Learning rate: 0.00019223089257840243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1264 [0/90000 (0%)]	Loss: 20.2397	Cost: 19.36s
Train Epoch: 1264 [20480/90000 (23%)]	Loss: 5.0269	Cost: 6.20s
Train Epoch: 1264 [40960/90000 (45%)]	Loss: 5.2396	Cost: 6.32s
Train Epoch: 1264 [61440/90000 (68%)]	Loss: 5.2080	Cost: 5.95s
Train Epoch: 1264 [81920/90000 (91%)]	Loss: 5.0249	Cost: 6.53s
Train Epoch: 1264 	Average Loss: 6.1804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1196

Learning rate: 0.0001922187472349545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1265 [0/90000 (0%)]	Loss: 20.1531	Cost: 20.60s
Train Epoch: 1265 [20480/90000 (23%)]	Loss: 5.0285	Cost: 6.02s
Train Epoch: 1265 [40960/90000 (45%)]	Loss: 5.0368	Cost: 6.09s
Train Epoch: 1265 [61440/90000 (68%)]	Loss: 4.9167	Cost: 5.92s
Train Epoch: 1265 [81920/90000 (91%)]	Loss: 5.1321	Cost: 6.02s
Train Epoch: 1265 	Average Loss: 6.0599
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2038

Learning rate: 0.0001922065927898811
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1266 [0/90000 (0%)]	Loss: 19.8434	Cost: 19.69s
Train Epoch: 1266 [20480/90000 (23%)]	Loss: 5.4210	Cost: 6.03s
Train Epoch: 1266 [40960/90000 (45%)]	Loss: 5.4680	Cost: 6.26s
Train Epoch: 1266 [61440/90000 (68%)]	Loss: 5.7642	Cost: 5.87s
Train Epoch: 1266 [81920/90000 (91%)]	Loss: 5.6559	Cost: 6.45s
Train Epoch: 1266 	Average Loss: 6.4934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0621

Learning rate: 0.0001921944292443818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1267 [0/90000 (0%)]	Loss: 20.1462	Cost: 19.99s
Train Epoch: 1267 [20480/90000 (23%)]	Loss: 5.2936	Cost: 6.09s
Train Epoch: 1267 [40960/90000 (45%)]	Loss: 5.8462	Cost: 6.04s
Train Epoch: 1267 [61440/90000 (68%)]	Loss: 8.8541	Cost: 5.96s
Train Epoch: 1267 [81920/90000 (91%)]	Loss: 8.4930	Cost: 6.03s
Train Epoch: 1267 	Average Loss: 7.9939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0804

Learning rate: 0.00019218225659965716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1268 [0/90000 (0%)]	Loss: 20.1990	Cost: 21.03s
Train Epoch: 1268 [20480/90000 (23%)]	Loss: 7.5267	Cost: 6.02s
Train Epoch: 1268 [40960/90000 (45%)]	Loss: 7.0295	Cost: 6.33s
Train Epoch: 1268 [61440/90000 (68%)]	Loss: 6.5260	Cost: 5.89s
Train Epoch: 1268 [81920/90000 (91%)]	Loss: 6.5247	Cost: 6.15s
Train Epoch: 1268 	Average Loss: 7.9966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7273

Learning rate: 0.00019217007485690854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1269 [0/90000 (0%)]	Loss: 19.4432	Cost: 20.62s
Train Epoch: 1269 [20480/90000 (23%)]	Loss: 5.9581	Cost: 6.09s
Train Epoch: 1269 [40960/90000 (45%)]	Loss: 6.2014	Cost: 6.08s
Train Epoch: 1269 [61440/90000 (68%)]	Loss: 5.5743	Cost: 5.91s
Train Epoch: 1269 [81920/90000 (91%)]	Loss: 6.1107	Cost: 5.99s
Train Epoch: 1269 	Average Loss: 6.8965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8591

Learning rate: 0.00019215788401733824
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1270 [0/90000 (0%)]	Loss: 19.9823	Cost: 20.49s
Train Epoch: 1270 [20480/90000 (23%)]	Loss: 5.4125	Cost: 6.04s
Train Epoch: 1270 [40960/90000 (45%)]	Loss: 5.2595	Cost: 6.11s
Train Epoch: 1270 [61440/90000 (68%)]	Loss: 5.0252	Cost: 5.94s
Train Epoch: 1270 [81920/90000 (91%)]	Loss: 5.3749	Cost: 5.92s
Train Epoch: 1270 	Average Loss: 6.4037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8843

Learning rate: 0.00019214568408214942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1271 [0/90000 (0%)]	Loss: 19.6368	Cost: 21.53s
Train Epoch: 1271 [20480/90000 (23%)]	Loss: 5.2140	Cost: 6.05s
Train Epoch: 1271 [40960/90000 (45%)]	Loss: 5.2316	Cost: 6.14s
Train Epoch: 1271 [61440/90000 (68%)]	Loss: 5.0259	Cost: 5.94s
Train Epoch: 1271 [81920/90000 (91%)]	Loss: 5.1089	Cost: 6.19s
Train Epoch: 1271 	Average Loss: 6.1752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9821

Learning rate: 0.00019213347505254617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1272 [0/90000 (0%)]	Loss: 20.0442	Cost: 20.29s
Train Epoch: 1272 [20480/90000 (23%)]	Loss: 5.3848	Cost: 6.08s
Train Epoch: 1272 [40960/90000 (45%)]	Loss: 5.1337	Cost: 6.00s
Train Epoch: 1272 [61440/90000 (68%)]	Loss: 4.8623	Cost: 5.94s
Train Epoch: 1272 [81920/90000 (91%)]	Loss: 5.1427	Cost: 5.98s
Train Epoch: 1272 	Average Loss: 6.1782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9778

Learning rate: 0.0001921212569297335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1273 [0/90000 (0%)]	Loss: 19.9614	Cost: 19.71s
Train Epoch: 1273 [20480/90000 (23%)]	Loss: 5.0083	Cost: 6.03s
Train Epoch: 1273 [40960/90000 (45%)]	Loss: 5.1805	Cost: 6.68s
Train Epoch: 1273 [61440/90000 (68%)]	Loss: 4.9121	Cost: 6.04s
Train Epoch: 1273 [81920/90000 (91%)]	Loss: 5.2888	Cost: 6.00s
Train Epoch: 1273 	Average Loss: 6.1568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9981

Learning rate: 0.00019210902971491728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1274 [0/90000 (0%)]	Loss: 20.0581	Cost: 20.39s
Train Epoch: 1274 [20480/90000 (23%)]	Loss: 5.0862	Cost: 6.01s
Train Epoch: 1274 [40960/90000 (45%)]	Loss: 4.9281	Cost: 6.21s
Train Epoch: 1274 [61440/90000 (68%)]	Loss: 4.8190	Cost: 5.96s
Train Epoch: 1274 [81920/90000 (91%)]	Loss: 4.9797	Cost: 6.00s
Train Epoch: 1274 	Average Loss: 6.0025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0844

Learning rate: 0.0001920967934093043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1275 [0/90000 (0%)]	Loss: 19.6202	Cost: 20.30s
Train Epoch: 1275 [20480/90000 (23%)]	Loss: 4.6969	Cost: 6.20s
Train Epoch: 1275 [40960/90000 (45%)]	Loss: 4.8164	Cost: 6.29s
Train Epoch: 1275 [61440/90000 (68%)]	Loss: 4.7763	Cost: 6.02s
Train Epoch: 1275 [81920/90000 (91%)]	Loss: 5.0429	Cost: 6.24s
Train Epoch: 1275 	Average Loss: 5.8918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1157

Learning rate: 0.00019208454801410222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1276 [0/90000 (0%)]	Loss: 19.8915	Cost: 20.23s
Train Epoch: 1276 [20480/90000 (23%)]	Loss: 4.6948	Cost: 6.08s
Train Epoch: 1276 [40960/90000 (45%)]	Loss: 4.8016	Cost: 6.06s
Train Epoch: 1276 [61440/90000 (68%)]	Loss: 4.7934	Cost: 5.92s
Train Epoch: 1276 [81920/90000 (91%)]	Loss: 5.4047	Cost: 5.64s
Train Epoch: 1276 	Average Loss: 5.9383
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1215

Learning rate: 0.00019207229353051958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1277 [0/90000 (0%)]	Loss: 20.1809	Cost: 20.45s
Train Epoch: 1277 [20480/90000 (23%)]	Loss: 5.0765	Cost: 6.11s
Train Epoch: 1277 [40960/90000 (45%)]	Loss: 5.1590	Cost: 6.05s
Train Epoch: 1277 [61440/90000 (68%)]	Loss: 4.8882	Cost: 6.12s
Train Epoch: 1277 [81920/90000 (91%)]	Loss: 5.2264	Cost: 5.90s
Train Epoch: 1277 	Average Loss: 6.1130
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0535

Learning rate: 0.00019206002995976587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1278 [0/90000 (0%)]	Loss: 19.7567	Cost: 20.93s
Train Epoch: 1278 [20480/90000 (23%)]	Loss: 4.9459	Cost: 6.11s
Train Epoch: 1278 [40960/90000 (45%)]	Loss: 4.7935	Cost: 6.12s
Train Epoch: 1278 [61440/90000 (68%)]	Loss: 4.5940	Cost: 5.98s
Train Epoch: 1278 [81920/90000 (91%)]	Loss: 4.8755	Cost: 5.91s
Train Epoch: 1278 	Average Loss: 5.8649
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1283

Learning rate: 0.00019204775730305153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1279 [0/90000 (0%)]	Loss: 19.9909	Cost: 20.41s
Train Epoch: 1279 [20480/90000 (23%)]	Loss: 4.8816	Cost: 6.13s
Train Epoch: 1279 [40960/90000 (45%)]	Loss: 4.9362	Cost: 6.16s
Train Epoch: 1279 [61440/90000 (68%)]	Loss: 5.0554	Cost: 5.99s
Train Epoch: 1279 [81920/90000 (91%)]	Loss: 4.9831	Cost: 5.91s
Train Epoch: 1279 	Average Loss: 5.9424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1331

Learning rate: 0.00019203547556158768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1280 [0/90000 (0%)]	Loss: 20.1568	Cost: 20.17s
Train Epoch: 1280 [20480/90000 (23%)]	Loss: 5.2219	Cost: 6.14s
Train Epoch: 1280 [40960/90000 (45%)]	Loss: 4.9341	Cost: 6.07s
Train Epoch: 1280 [61440/90000 (68%)]	Loss: 4.7222	Cost: 5.98s
Train Epoch: 1280 [81920/90000 (91%)]	Loss: 4.8609	Cost: 5.80s
Train Epoch: 1280 	Average Loss: 5.9708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1473

Learning rate: 0.0001920231847365866
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1281 [0/90000 (0%)]	Loss: 20.0888	Cost: 21.05s
Train Epoch: 1281 [20480/90000 (23%)]	Loss: 4.6370	Cost: 6.06s
Train Epoch: 1281 [40960/90000 (45%)]	Loss: 4.5736	Cost: 6.11s
Train Epoch: 1281 [61440/90000 (68%)]	Loss: 4.6014	Cost: 5.93s
Train Epoch: 1281 [81920/90000 (91%)]	Loss: 4.5620	Cost: 5.91s
Train Epoch: 1281 	Average Loss: 5.7766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1384

Learning rate: 0.00019201088482926132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1282 [0/90000 (0%)]	Loss: 19.9680	Cost: 20.44s
Train Epoch: 1282 [20480/90000 (23%)]	Loss: 4.6140	Cost: 6.08s
Train Epoch: 1282 [40960/90000 (45%)]	Loss: 4.5483	Cost: 6.34s
Train Epoch: 1282 [61440/90000 (68%)]	Loss: 4.4913	Cost: 6.00s
Train Epoch: 1282 [81920/90000 (91%)]	Loss: 4.4308	Cost: 6.17s
Train Epoch: 1282 	Average Loss: 5.6610
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1715

Learning rate: 0.00019199857584082573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1283 [0/90000 (0%)]	Loss: 19.8787	Cost: 20.61s
Train Epoch: 1283 [20480/90000 (23%)]	Loss: 4.7032	Cost: 6.12s
Train Epoch: 1283 [40960/90000 (45%)]	Loss: 4.5562	Cost: 6.05s
Train Epoch: 1283 [61440/90000 (68%)]	Loss: 4.5535	Cost: 5.96s
Train Epoch: 1283 [81920/90000 (91%)]	Loss: 4.9413	Cost: 5.87s
Train Epoch: 1283 	Average Loss: 5.7924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1998

Learning rate: 0.00019198625777249478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1284 [0/90000 (0%)]	Loss: 20.0327	Cost: 20.80s
Train Epoch: 1284 [20480/90000 (23%)]	Loss: 4.6570	Cost: 6.06s
Train Epoch: 1284 [40960/90000 (45%)]	Loss: 4.8045	Cost: 6.12s
Train Epoch: 1284 [61440/90000 (68%)]	Loss: 4.7012	Cost: 6.20s
Train Epoch: 1284 [81920/90000 (91%)]	Loss: 4.8908	Cost: 5.84s
Train Epoch: 1284 	Average Loss: 5.9107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2416

Learning rate: 0.00019197393062548413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1285 [0/90000 (0%)]	Loss: 19.9536	Cost: 20.19s
Train Epoch: 1285 [20480/90000 (23%)]	Loss: 4.5309	Cost: 6.14s
Train Epoch: 1285 [40960/90000 (45%)]	Loss: 4.6861	Cost: 6.19s
Train Epoch: 1285 [61440/90000 (68%)]	Loss: 4.6552	Cost: 5.93s
Train Epoch: 1285 [81920/90000 (91%)]	Loss: 5.1340	Cost: 5.91s
Train Epoch: 1285 	Average Loss: 5.8021
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3346

Learning rate: 0.00019196159440101047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1286 [0/90000 (0%)]	Loss: 19.9329	Cost: 21.26s
Train Epoch: 1286 [20480/90000 (23%)]	Loss: 4.7450	Cost: 6.14s
Train Epoch: 1286 [40960/90000 (45%)]	Loss: 4.9290	Cost: 6.10s
Train Epoch: 1286 [61440/90000 (68%)]	Loss: 4.6267	Cost: 5.93s
Train Epoch: 1286 [81920/90000 (91%)]	Loss: 5.0450	Cost: 6.13s
Train Epoch: 1286 	Average Loss: 5.9790
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1220

Learning rate: 0.0001919492491002913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1287 [0/90000 (0%)]	Loss: 20.0428	Cost: 20.69s
Train Epoch: 1287 [20480/90000 (23%)]	Loss: 4.9153	Cost: 6.17s
Train Epoch: 1287 [40960/90000 (45%)]	Loss: 4.9090	Cost: 6.37s
Train Epoch: 1287 [61440/90000 (68%)]	Loss: 4.7451	Cost: 5.91s
Train Epoch: 1287 [81920/90000 (91%)]	Loss: 4.8287	Cost: 6.04s
Train Epoch: 1287 	Average Loss: 5.9482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2097

Learning rate: 0.00019193689472454505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1288 [0/90000 (0%)]	Loss: 19.9904	Cost: 20.21s
Train Epoch: 1288 [20480/90000 (23%)]	Loss: 4.5846	Cost: 6.05s
Train Epoch: 1288 [40960/90000 (45%)]	Loss: 4.6273	Cost: 6.08s
Train Epoch: 1288 [61440/90000 (68%)]	Loss: 4.6026	Cost: 6.03s
Train Epoch: 1288 [81920/90000 (91%)]	Loss: 4.7146	Cost: 6.39s
Train Epoch: 1288 	Average Loss: 5.7533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2013

Learning rate: 0.0001919245312749911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1289 [0/90000 (0%)]	Loss: 20.0861	Cost: 21.28s
Train Epoch: 1289 [20480/90000 (23%)]	Loss: 4.5440	Cost: 6.02s
Train Epoch: 1289 [40960/90000 (45%)]	Loss: 4.7216	Cost: 6.48s
Train Epoch: 1289 [61440/90000 (68%)]	Loss: 4.4323	Cost: 5.95s
Train Epoch: 1289 [81920/90000 (91%)]	Loss: 4.5931	Cost: 6.14s
Train Epoch: 1289 	Average Loss: 5.6887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3032

Learning rate: 0.00019191215875284963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1290 [0/90000 (0%)]	Loss: 20.0882	Cost: 21.11s
Train Epoch: 1290 [20480/90000 (23%)]	Loss: 4.5296	Cost: 6.23s
Train Epoch: 1290 [40960/90000 (45%)]	Loss: 4.6298	Cost: 6.19s
Train Epoch: 1290 [61440/90000 (68%)]	Loss: 4.6362	Cost: 6.10s
Train Epoch: 1290 [81920/90000 (91%)]	Loss: 5.0501	Cost: 6.04s
Train Epoch: 1290 	Average Loss: 5.7117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2044

Learning rate: 0.00019189977715934172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1291 [0/90000 (0%)]	Loss: 19.9843	Cost: 20.55s
Train Epoch: 1291 [20480/90000 (23%)]	Loss: 4.7862	Cost: 6.00s
Train Epoch: 1291 [40960/90000 (45%)]	Loss: 4.5493	Cost: 6.09s
Train Epoch: 1291 [61440/90000 (68%)]	Loss: 4.4952	Cost: 5.95s
Train Epoch: 1291 [81920/90000 (91%)]	Loss: 4.8474	Cost: 7.01s
Train Epoch: 1291 	Average Loss: 5.7729
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2076

Learning rate: 0.0001918873864956895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1292 [0/90000 (0%)]	Loss: 20.2647	Cost: 20.32s
Train Epoch: 1292 [20480/90000 (23%)]	Loss: 4.8152	Cost: 6.03s
Train Epoch: 1292 [40960/90000 (45%)]	Loss: 4.9941	Cost: 6.47s
Train Epoch: 1292 [61440/90000 (68%)]	Loss: 4.8751	Cost: 6.22s
Train Epoch: 1292 [81920/90000 (91%)]	Loss: 5.0475	Cost: 6.96s
Train Epoch: 1292 	Average Loss: 5.9685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2054

Learning rate: 0.00019187498676311577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1293 [0/90000 (0%)]	Loss: 20.1751	Cost: 20.26s
Train Epoch: 1293 [20480/90000 (23%)]	Loss: 4.7728	Cost: 5.93s
Train Epoch: 1293 [40960/90000 (45%)]	Loss: 5.0808	Cost: 6.49s
Train Epoch: 1293 [61440/90000 (68%)]	Loss: 4.7033	Cost: 6.12s
Train Epoch: 1293 [81920/90000 (91%)]	Loss: 4.8539	Cost: 7.40s
Train Epoch: 1293 	Average Loss: 5.8941
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2870

Learning rate: 0.0001918625779628444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1294 [0/90000 (0%)]	Loss: 20.0987	Cost: 19.16s
Train Epoch: 1294 [20480/90000 (23%)]	Loss: 4.9937	Cost: 6.03s
Train Epoch: 1294 [40960/90000 (45%)]	Loss: 5.0844	Cost: 6.11s
Train Epoch: 1294 [61440/90000 (68%)]	Loss: 4.9460	Cost: 6.07s
Train Epoch: 1294 [81920/90000 (91%)]	Loss: 4.9245	Cost: 6.58s
Train Epoch: 1294 	Average Loss: 5.9036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1909

Learning rate: 0.00019185016009610006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1295 [0/90000 (0%)]	Loss: 20.2627	Cost: 20.05s
Train Epoch: 1295 [20480/90000 (23%)]	Loss: 4.7028	Cost: 6.10s
Train Epoch: 1295 [40960/90000 (45%)]	Loss: 4.5684	Cost: 6.13s
Train Epoch: 1295 [61440/90000 (68%)]	Loss: 4.4531	Cost: 6.36s
Train Epoch: 1295 [81920/90000 (91%)]	Loss: 4.6249	Cost: 6.51s
Train Epoch: 1295 	Average Loss: 5.7087
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2458

Learning rate: 0.00019183773316410835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1296 [0/90000 (0%)]	Loss: 19.9552	Cost: 20.67s
Train Epoch: 1296 [20480/90000 (23%)]	Loss: 4.5723	Cost: 5.97s
Train Epoch: 1296 [40960/90000 (45%)]	Loss: 4.6550	Cost: 6.42s
Train Epoch: 1296 [61440/90000 (68%)]	Loss: 4.4689	Cost: 6.21s
Train Epoch: 1296 [81920/90000 (91%)]	Loss: 4.4916	Cost: 7.46s
Train Epoch: 1296 	Average Loss: 5.7162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2887

Learning rate: 0.00019182529716809578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1297 [0/90000 (0%)]	Loss: 20.2961	Cost: 19.62s
Train Epoch: 1297 [20480/90000 (23%)]	Loss: 4.6345	Cost: 6.16s
Train Epoch: 1297 [40960/90000 (45%)]	Loss: 4.8999	Cost: 6.27s
Train Epoch: 1297 [61440/90000 (68%)]	Loss: 4.4550	Cost: 5.95s
Train Epoch: 1297 [81920/90000 (91%)]	Loss: 5.2206	Cost: 5.96s
Train Epoch: 1297 	Average Loss: 5.8827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2536

Learning rate: 0.0001918128521092897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1298 [0/90000 (0%)]	Loss: 20.1268	Cost: 20.00s
Train Epoch: 1298 [20480/90000 (23%)]	Loss: 5.5062	Cost: 6.09s
Train Epoch: 1298 [40960/90000 (45%)]	Loss: 5.1832	Cost: 6.18s
Train Epoch: 1298 [61440/90000 (68%)]	Loss: 5.1023	Cost: 6.06s
Train Epoch: 1298 [81920/90000 (91%)]	Loss: 5.2208	Cost: 6.13s
Train Epoch: 1298 	Average Loss: 6.2819
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1754

Learning rate: 0.0001918003979889184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1299 [0/90000 (0%)]	Loss: 20.1894	Cost: 19.34s
Train Epoch: 1299 [20480/90000 (23%)]	Loss: 5.0760	Cost: 6.06s
Train Epoch: 1299 [40960/90000 (45%)]	Loss: 4.9911	Cost: 6.27s
Train Epoch: 1299 [61440/90000 (68%)]	Loss: 4.7599	Cost: 6.11s
Train Epoch: 1299 [81920/90000 (91%)]	Loss: 4.7573	Cost: 7.63s
Train Epoch: 1299 	Average Loss: 5.9878
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2804

Learning rate: 0.00019178793480821105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1300 [0/90000 (0%)]	Loss: 19.7181	Cost: 19.82s
Train Epoch: 1300 [20480/90000 (23%)]	Loss: 5.0450	Cost: 6.06s
Train Epoch: 1300 [40960/90000 (45%)]	Loss: 4.5284	Cost: 6.30s
Train Epoch: 1300 [61440/90000 (68%)]	Loss: 4.2770	Cost: 6.05s
Train Epoch: 1300 [81920/90000 (91%)]	Loss: 4.6375	Cost: 6.84s
Train Epoch: 1300 	Average Loss: 5.6950
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3074

Learning rate: 0.00019177546256839772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1301 [0/90000 (0%)]	Loss: 20.0972	Cost: 19.86s
Train Epoch: 1301 [20480/90000 (23%)]	Loss: 4.6341	Cost: 6.02s
Train Epoch: 1301 [40960/90000 (45%)]	Loss: 4.6511	Cost: 6.20s
Train Epoch: 1301 [61440/90000 (68%)]	Loss: 4.6496	Cost: 6.07s
Train Epoch: 1301 [81920/90000 (91%)]	Loss: 4.8575	Cost: 7.17s
Train Epoch: 1301 	Average Loss: 5.7024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2027

Learning rate: 0.00019176298127070938
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1302 [0/90000 (0%)]	Loss: 20.1801	Cost: 19.54s
Train Epoch: 1302 [20480/90000 (23%)]	Loss: 4.5020	Cost: 6.12s
Train Epoch: 1302 [40960/90000 (45%)]	Loss: 4.5502	Cost: 6.09s
Train Epoch: 1302 [61440/90000 (68%)]	Loss: 4.6427	Cost: 5.97s
Train Epoch: 1302 [81920/90000 (91%)]	Loss: 4.7113	Cost: 5.91s
Train Epoch: 1302 	Average Loss: 5.7283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3586

Learning rate: 0.00019175049091637786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1303 [0/90000 (0%)]	Loss: 20.3773	Cost: 19.35s
Train Epoch: 1303 [20480/90000 (23%)]	Loss: 4.4278	Cost: 6.05s
Train Epoch: 1303 [40960/90000 (45%)]	Loss: 4.6525	Cost: 6.11s
Train Epoch: 1303 [61440/90000 (68%)]	Loss: 4.7523	Cost: 5.99s
Train Epoch: 1303 [81920/90000 (91%)]	Loss: 4.9178	Cost: 6.74s
Train Epoch: 1303 	Average Loss: 5.8369
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3196

Learning rate: 0.00019173799150663595
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1304 [0/90000 (0%)]	Loss: 20.2655	Cost: 19.76s
Train Epoch: 1304 [20480/90000 (23%)]	Loss: 4.8158	Cost: 6.05s
Train Epoch: 1304 [40960/90000 (45%)]	Loss: 4.4777	Cost: 6.36s
Train Epoch: 1304 [61440/90000 (68%)]	Loss: 4.5137	Cost: 6.06s
Train Epoch: 1304 [81920/90000 (91%)]	Loss: 4.8961	Cost: 7.25s
Train Epoch: 1304 	Average Loss: 5.8213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2179

Learning rate: 0.00019172548304271725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1305 [0/90000 (0%)]	Loss: 19.9606	Cost: 19.90s
Train Epoch: 1305 [20480/90000 (23%)]	Loss: 5.1417	Cost: 6.01s
Train Epoch: 1305 [40960/90000 (45%)]	Loss: 4.9317	Cost: 6.09s
Train Epoch: 1305 [61440/90000 (68%)]	Loss: 4.9171	Cost: 5.94s
Train Epoch: 1305 [81920/90000 (91%)]	Loss: 5.1104	Cost: 5.91s
Train Epoch: 1305 	Average Loss: 6.1070
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1785

Learning rate: 0.00019171296552585629
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1306 [0/90000 (0%)]	Loss: 20.4093	Cost: 20.51s
Train Epoch: 1306 [20480/90000 (23%)]	Loss: 5.1072	Cost: 6.02s
Train Epoch: 1306 [40960/90000 (45%)]	Loss: 4.5968	Cost: 6.01s
Train Epoch: 1306 [61440/90000 (68%)]	Loss: 4.7626	Cost: 6.08s
Train Epoch: 1306 [81920/90000 (91%)]	Loss: 4.8625	Cost: 6.08s
Train Epoch: 1306 	Average Loss: 5.9288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2661

Learning rate: 0.00019170043895728857
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1307 [0/90000 (0%)]	Loss: 20.3079	Cost: 20.59s
Train Epoch: 1307 [20480/90000 (23%)]	Loss: 4.6987	Cost: 6.05s
Train Epoch: 1307 [40960/90000 (45%)]	Loss: 4.7253	Cost: 6.62s
Train Epoch: 1307 [61440/90000 (68%)]	Loss: 4.6599	Cost: 5.93s
Train Epoch: 1307 [81920/90000 (91%)]	Loss: 4.7903	Cost: 5.99s
Train Epoch: 1307 	Average Loss: 5.8632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1320

Learning rate: 0.00019168790333825032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1308 [0/90000 (0%)]	Loss: 19.9700	Cost: 21.39s
Train Epoch: 1308 [20480/90000 (23%)]	Loss: 4.3937	Cost: 6.09s
Train Epoch: 1308 [40960/90000 (45%)]	Loss: 4.5369	Cost: 6.05s
Train Epoch: 1308 [61440/90000 (68%)]	Loss: 4.7005	Cost: 5.93s
Train Epoch: 1308 [81920/90000 (91%)]	Loss: 4.4374	Cost: 6.69s
Train Epoch: 1308 	Average Loss: 5.6370
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4362

Learning rate: 0.00019167535866997882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1309 [0/90000 (0%)]	Loss: 20.3423	Cost: 20.94s
Train Epoch: 1309 [20480/90000 (23%)]	Loss: 4.3221	Cost: 6.11s
Train Epoch: 1309 [40960/90000 (45%)]	Loss: 4.6047	Cost: 6.10s
Train Epoch: 1309 [61440/90000 (68%)]	Loss: 4.3691	Cost: 6.02s
Train Epoch: 1309 [81920/90000 (91%)]	Loss: 4.6495	Cost: 5.95s
Train Epoch: 1309 	Average Loss: 5.5482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3788

Learning rate: 0.0001916628049537122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1310 [0/90000 (0%)]	Loss: 20.2491	Cost: 20.36s
Train Epoch: 1310 [20480/90000 (23%)]	Loss: 7.8662	Cost: 6.10s
Train Epoch: 1310 [40960/90000 (45%)]	Loss: 8.7729	Cost: 6.17s
Train Epoch: 1310 [61440/90000 (68%)]	Loss: 8.2144	Cost: 5.93s
Train Epoch: 1310 [81920/90000 (91%)]	Loss: 7.6614	Cost: 6.41s
Train Epoch: 1310 	Average Loss: 8.5552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1532

Learning rate: 0.00019165024219068937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1311 [0/90000 (0%)]	Loss: 20.2668	Cost: 20.46s
Train Epoch: 1311 [20480/90000 (23%)]	Loss: 6.8010	Cost: 6.07s
Train Epoch: 1311 [40960/90000 (45%)]	Loss: 6.6063	Cost: 6.61s
Train Epoch: 1311 [61440/90000 (68%)]	Loss: 6.1768	Cost: 6.02s
Train Epoch: 1311 [81920/90000 (91%)]	Loss: 5.9008	Cost: 6.34s
Train Epoch: 1311 	Average Loss: 7.5671
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0364

Learning rate: 0.0001916376703821503
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1312 [0/90000 (0%)]	Loss: 19.6438	Cost: 20.73s
Train Epoch: 1312 [20480/90000 (23%)]	Loss: 5.9500	Cost: 6.07s
Train Epoch: 1312 [40960/90000 (45%)]	Loss: 5.6160	Cost: 6.52s
Train Epoch: 1312 [61440/90000 (68%)]	Loss: 5.4280	Cost: 6.10s
Train Epoch: 1312 [81920/90000 (91%)]	Loss: 5.6709	Cost: 7.15s
Train Epoch: 1312 	Average Loss: 6.7149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0381

Learning rate: 0.00019162508952933575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1313 [0/90000 (0%)]	Loss: 20.1788	Cost: 19.41s
Train Epoch: 1313 [20480/90000 (23%)]	Loss: 5.1318	Cost: 6.19s
Train Epoch: 1313 [40960/90000 (45%)]	Loss: 5.0990	Cost: 6.05s
Train Epoch: 1313 [61440/90000 (68%)]	Loss: 5.0213	Cost: 6.05s
Train Epoch: 1313 [81920/90000 (91%)]	Loss: 4.9492	Cost: 6.66s
Train Epoch: 1313 	Average Loss: 6.1184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1907

Learning rate: 0.0001916124996334874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1314 [0/90000 (0%)]	Loss: 20.2215	Cost: 19.86s
Train Epoch: 1314 [20480/90000 (23%)]	Loss: 4.9777	Cost: 6.05s
Train Epoch: 1314 [40960/90000 (45%)]	Loss: 5.1000	Cost: 6.18s
Train Epoch: 1314 [61440/90000 (68%)]	Loss: 4.9204	Cost: 6.01s
Train Epoch: 1314 [81920/90000 (91%)]	Loss: 4.9995	Cost: 6.07s
Train Epoch: 1314 	Average Loss: 6.0484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0613

Learning rate: 0.00019159990069584783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1315 [0/90000 (0%)]	Loss: 19.9340	Cost: 20.28s
Train Epoch: 1315 [20480/90000 (23%)]	Loss: 4.7897	Cost: 6.11s
Train Epoch: 1315 [40960/90000 (45%)]	Loss: 5.1288	Cost: 6.44s
Train Epoch: 1315 [61440/90000 (68%)]	Loss: 4.6856	Cost: 5.99s
Train Epoch: 1315 [81920/90000 (91%)]	Loss: 4.8871	Cost: 5.99s
Train Epoch: 1315 	Average Loss: 5.9222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2679

Learning rate: 0.0001915872927176605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1316 [0/90000 (0%)]	Loss: 19.9690	Cost: 20.80s
Train Epoch: 1316 [20480/90000 (23%)]	Loss: 4.7555	Cost: 6.09s
Train Epoch: 1316 [40960/90000 (45%)]	Loss: 4.6022	Cost: 6.65s
Train Epoch: 1316 [61440/90000 (68%)]	Loss: 4.7098	Cost: 5.96s
Train Epoch: 1316 [81920/90000 (91%)]	Loss: 4.6790	Cost: 6.30s
Train Epoch: 1316 	Average Loss: 5.7740
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2675

Learning rate: 0.0001915746757001698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1317 [0/90000 (0%)]	Loss: 19.9886	Cost: 20.03s
Train Epoch: 1317 [20480/90000 (23%)]	Loss: 5.1199	Cost: 6.44s
Train Epoch: 1317 [40960/90000 (45%)]	Loss: 4.7953	Cost: 6.51s
Train Epoch: 1317 [61440/90000 (68%)]	Loss: 4.7092	Cost: 6.23s
Train Epoch: 1317 [81920/90000 (91%)]	Loss: 4.6606	Cost: 5.84s
Train Epoch: 1317 	Average Loss: 5.8874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2240

Learning rate: 0.00019156204964462093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1318 [0/90000 (0%)]	Loss: 20.1246	Cost: 20.65s
Train Epoch: 1318 [20480/90000 (23%)]	Loss: 4.6119	Cost: 6.01s
Train Epoch: 1318 [40960/90000 (45%)]	Loss: 4.6078	Cost: 6.27s
Train Epoch: 1318 [61440/90000 (68%)]	Loss: 4.3376	Cost: 6.01s
Train Epoch: 1318 [81920/90000 (91%)]	Loss: 4.3706	Cost: 6.68s
Train Epoch: 1318 	Average Loss: 5.6070
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2417

Learning rate: 0.00019154941455226007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1319 [0/90000 (0%)]	Loss: 20.2454	Cost: 18.61s
Train Epoch: 1319 [20480/90000 (23%)]	Loss: 4.5774	Cost: 5.95s
Train Epoch: 1319 [40960/90000 (45%)]	Loss: 4.5916	Cost: 6.21s
Train Epoch: 1319 [61440/90000 (68%)]	Loss: 4.3273	Cost: 6.01s
Train Epoch: 1319 [81920/90000 (91%)]	Loss: 4.5778	Cost: 6.81s
Train Epoch: 1319 	Average Loss: 5.5402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4449

Learning rate: 0.00019153677042433424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1320 [0/90000 (0%)]	Loss: 20.1580	Cost: 19.84s
Train Epoch: 1320 [20480/90000 (23%)]	Loss: 4.6573	Cost: 6.10s
Train Epoch: 1320 [40960/90000 (45%)]	Loss: 4.4582	Cost: 6.28s
Train Epoch: 1320 [61440/90000 (68%)]	Loss: 4.3882	Cost: 5.91s
Train Epoch: 1320 [81920/90000 (91%)]	Loss: 4.5877	Cost: 6.19s
Train Epoch: 1320 	Average Loss: 5.6145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1990

Learning rate: 0.00019152411726209133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1321 [0/90000 (0%)]	Loss: 20.2906	Cost: 19.65s
Train Epoch: 1321 [20480/90000 (23%)]	Loss: 4.6618	Cost: 6.11s
Train Epoch: 1321 [40960/90000 (45%)]	Loss: 4.7011	Cost: 6.12s
Train Epoch: 1321 [61440/90000 (68%)]	Loss: 4.7151	Cost: 5.96s
Train Epoch: 1321 [81920/90000 (91%)]	Loss: 4.7670	Cost: 5.91s
Train Epoch: 1321 	Average Loss: 5.8668
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3673

Learning rate: 0.00019151145506678021
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1322 [0/90000 (0%)]	Loss: 19.9486	Cost: 19.90s
Train Epoch: 1322 [20480/90000 (23%)]	Loss: 4.7353	Cost: 6.05s
Train Epoch: 1322 [40960/90000 (45%)]	Loss: 4.6259	Cost: 6.26s
Train Epoch: 1322 [61440/90000 (68%)]	Loss: 4.3231	Cost: 5.90s
Train Epoch: 1322 [81920/90000 (91%)]	Loss: 4.4246	Cost: 6.08s
Train Epoch: 1322 	Average Loss: 5.7162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2793

Learning rate: 0.00019149878383965054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1323 [0/90000 (0%)]	Loss: 20.2723	Cost: 19.66s
Train Epoch: 1323 [20480/90000 (23%)]	Loss: 4.6257	Cost: 6.18s
Train Epoch: 1323 [40960/90000 (45%)]	Loss: 4.7073	Cost: 6.67s
Train Epoch: 1323 [61440/90000 (68%)]	Loss: 4.4149	Cost: 5.90s
Train Epoch: 1323 [81920/90000 (91%)]	Loss: 4.6405	Cost: 6.22s
Train Epoch: 1323 	Average Loss: 5.6876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2903

Learning rate: 0.00019148610358195298
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1324 [0/90000 (0%)]	Loss: 20.1590	Cost: 21.02s
Train Epoch: 1324 [20480/90000 (23%)]	Loss: 4.6377	Cost: 6.11s
Train Epoch: 1324 [40960/90000 (45%)]	Loss: 4.7910	Cost: 6.48s
Train Epoch: 1324 [61440/90000 (68%)]	Loss: 4.5282	Cost: 5.91s
Train Epoch: 1324 [81920/90000 (91%)]	Loss: 4.4580	Cost: 6.23s
Train Epoch: 1324 	Average Loss: 5.7111
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2802

Learning rate: 0.00019147341429493896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1325 [0/90000 (0%)]	Loss: 19.9838	Cost: 20.23s
Train Epoch: 1325 [20480/90000 (23%)]	Loss: 4.5048	Cost: 6.02s
Train Epoch: 1325 [40960/90000 (45%)]	Loss: 4.2360	Cost: 6.30s
Train Epoch: 1325 [61440/90000 (68%)]	Loss: 4.4380	Cost: 5.91s
Train Epoch: 1325 [81920/90000 (91%)]	Loss: 4.7157	Cost: 6.02s
Train Epoch: 1325 	Average Loss: 5.5424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2942

Learning rate: 0.00019146071597986092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1326 [0/90000 (0%)]	Loss: 20.2238	Cost: 21.11s
Train Epoch: 1326 [20480/90000 (23%)]	Loss: 4.5105	Cost: 6.09s
Train Epoch: 1326 [40960/90000 (45%)]	Loss: 4.2825	Cost: 6.45s
Train Epoch: 1326 [61440/90000 (68%)]	Loss: 4.3703	Cost: 5.99s
Train Epoch: 1326 [81920/90000 (91%)]	Loss: 4.3974	Cost: 5.88s
Train Epoch: 1326 	Average Loss: 5.4684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3213

Learning rate: 0.00019144800863797208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1327 [0/90000 (0%)]	Loss: 20.0399	Cost: 21.42s
Train Epoch: 1327 [20480/90000 (23%)]	Loss: 4.5865	Cost: 6.13s
Train Epoch: 1327 [40960/90000 (45%)]	Loss: 4.4485	Cost: 6.08s
Train Epoch: 1327 [61440/90000 (68%)]	Loss: 4.5528	Cost: 6.03s
Train Epoch: 1327 [81920/90000 (91%)]	Loss: 4.6232	Cost: 5.85s
Train Epoch: 1327 	Average Loss: 5.6449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3573

Learning rate: 0.00019143529227052663
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1328 [0/90000 (0%)]	Loss: 20.3675	Cost: 21.08s
Train Epoch: 1328 [20480/90000 (23%)]	Loss: 4.4566	Cost: 6.12s
Train Epoch: 1328 [40960/90000 (45%)]	Loss: 4.4569	Cost: 6.14s
Train Epoch: 1328 [61440/90000 (68%)]	Loss: 4.4618	Cost: 6.16s
Train Epoch: 1328 [81920/90000 (91%)]	Loss: 4.4800	Cost: 5.84s
Train Epoch: 1328 	Average Loss: 5.5585
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3503

Learning rate: 0.00019142256687877963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1329 [0/90000 (0%)]	Loss: 20.0677	Cost: 21.28s
Train Epoch: 1329 [20480/90000 (23%)]	Loss: 4.4350	Cost: 6.18s
Train Epoch: 1329 [40960/90000 (45%)]	Loss: 4.4857	Cost: 6.22s
Train Epoch: 1329 [61440/90000 (68%)]	Loss: 4.5036	Cost: 5.93s
Train Epoch: 1329 [81920/90000 (91%)]	Loss: 4.4872	Cost: 6.20s
Train Epoch: 1329 	Average Loss: 5.4907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3838

Learning rate: 0.00019140983246398704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1330 [0/90000 (0%)]	Loss: 20.2680	Cost: 20.58s
Train Epoch: 1330 [20480/90000 (23%)]	Loss: 4.2233	Cost: 6.08s
Train Epoch: 1330 [40960/90000 (45%)]	Loss: 4.1056	Cost: 6.10s
Train Epoch: 1330 [61440/90000 (68%)]	Loss: 4.1240	Cost: 6.13s
Train Epoch: 1330 [81920/90000 (91%)]	Loss: 4.3885	Cost: 5.93s
Train Epoch: 1330 	Average Loss: 5.4132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4563

Learning rate: 0.00019139708902740564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1331 [0/90000 (0%)]	Loss: 20.1741	Cost: 20.39s
Train Epoch: 1331 [20480/90000 (23%)]	Loss: 4.2945	Cost: 6.02s
Train Epoch: 1331 [40960/90000 (45%)]	Loss: 4.1094	Cost: 6.11s
Train Epoch: 1331 [61440/90000 (68%)]	Loss: 4.1094	Cost: 6.00s
Train Epoch: 1331 [81920/90000 (91%)]	Loss: 4.3194	Cost: 6.02s
Train Epoch: 1331 	Average Loss: 5.3024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4275

Learning rate: 0.00019138433657029324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1332 [0/90000 (0%)]	Loss: 20.0038	Cost: 19.67s
Train Epoch: 1332 [20480/90000 (23%)]	Loss: 4.2795	Cost: 6.19s
Train Epoch: 1332 [40960/90000 (45%)]	Loss: 4.0418	Cost: 6.23s
Train Epoch: 1332 [61440/90000 (68%)]	Loss: 4.1874	Cost: 5.95s
Train Epoch: 1332 [81920/90000 (91%)]	Loss: 4.2478	Cost: 6.17s
Train Epoch: 1332 	Average Loss: 5.2316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6064

Learning rate: 0.0001913715750939084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1333 [0/90000 (0%)]	Loss: 20.3151	Cost: 20.40s
Train Epoch: 1333 [20480/90000 (23%)]	Loss: 4.1489	Cost: 6.07s
Train Epoch: 1333 [40960/90000 (45%)]	Loss: 4.3320	Cost: 6.20s
Train Epoch: 1333 [61440/90000 (68%)]	Loss: 4.2728	Cost: 6.10s
Train Epoch: 1333 [81920/90000 (91%)]	Loss: 4.3337	Cost: 6.05s
Train Epoch: 1333 	Average Loss: 5.4047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4759

Learning rate: 0.00019135880459951061
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1334 [0/90000 (0%)]	Loss: 20.4699	Cost: 20.15s
Train Epoch: 1334 [20480/90000 (23%)]	Loss: 4.0523	Cost: 6.19s
Train Epoch: 1334 [40960/90000 (45%)]	Loss: 4.0708	Cost: 6.12s
Train Epoch: 1334 [61440/90000 (68%)]	Loss: 3.9117	Cost: 5.97s
Train Epoch: 1334 [81920/90000 (91%)]	Loss: 4.4002	Cost: 6.07s
Train Epoch: 1334 	Average Loss: 5.3280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5050

Learning rate: 0.00019134602508836032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1335 [0/90000 (0%)]	Loss: 20.6945	Cost: 20.23s
Train Epoch: 1335 [20480/90000 (23%)]	Loss: 4.4116	Cost: 6.15s
Train Epoch: 1335 [40960/90000 (45%)]	Loss: 4.4264	Cost: 6.34s
Train Epoch: 1335 [61440/90000 (68%)]	Loss: 4.4094	Cost: 6.16s
Train Epoch: 1335 [81920/90000 (91%)]	Loss: 4.5720	Cost: 7.47s
Train Epoch: 1335 	Average Loss: 5.4569
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4800

Learning rate: 0.00019133323656171877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1336 [0/90000 (0%)]	Loss: 20.2234	Cost: 19.83s
Train Epoch: 1336 [20480/90000 (23%)]	Loss: 4.5913	Cost: 6.04s
Train Epoch: 1336 [40960/90000 (45%)]	Loss: 4.6086	Cost: 6.09s
Train Epoch: 1336 [61440/90000 (68%)]	Loss: 4.2702	Cost: 6.07s
Train Epoch: 1336 [81920/90000 (91%)]	Loss: 4.3856	Cost: 6.26s
Train Epoch: 1336 	Average Loss: 5.5559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4629

Learning rate: 0.0001913204390208482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1337 [0/90000 (0%)]	Loss: 20.4780	Cost: 19.71s
Train Epoch: 1337 [20480/90000 (23%)]	Loss: 4.1823	Cost: 6.09s
Train Epoch: 1337 [40960/90000 (45%)]	Loss: 4.1088	Cost: 6.08s
Train Epoch: 1337 [61440/90000 (68%)]	Loss: 4.1971	Cost: 6.19s
Train Epoch: 1337 [81920/90000 (91%)]	Loss: 4.2178	Cost: 6.04s
Train Epoch: 1337 	Average Loss: 5.3218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4878

Learning rate: 0.0001913076324670116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1338 [0/90000 (0%)]	Loss: 20.4389	Cost: 19.25s
Train Epoch: 1338 [20480/90000 (23%)]	Loss: 4.0297	Cost: 5.94s
Train Epoch: 1338 [40960/90000 (45%)]	Loss: 4.3455	Cost: 6.09s
Train Epoch: 1338 [61440/90000 (68%)]	Loss: 4.1345	Cost: 6.17s
Train Epoch: 1338 [81920/90000 (91%)]	Loss: 4.1591	Cost: 7.10s
Train Epoch: 1338 	Average Loss: 5.3337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4690

Learning rate: 0.00019129481690147293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1339 [0/90000 (0%)]	Loss: 20.1091	Cost: 20.25s
Train Epoch: 1339 [20480/90000 (23%)]	Loss: 4.2474	Cost: 6.23s
Train Epoch: 1339 [40960/90000 (45%)]	Loss: 3.9607	Cost: 6.46s
Train Epoch: 1339 [61440/90000 (68%)]	Loss: 3.8609	Cost: 6.02s
Train Epoch: 1339 [81920/90000 (91%)]	Loss: 4.1923	Cost: 6.30s
Train Epoch: 1339 	Average Loss: 5.2428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5085

Learning rate: 0.0001912819923254971
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1340 [0/90000 (0%)]	Loss: 20.0838	Cost: 19.44s
Train Epoch: 1340 [20480/90000 (23%)]	Loss: 4.0317	Cost: 6.26s
Train Epoch: 1340 [40960/90000 (45%)]	Loss: 3.9558	Cost: 6.15s
Train Epoch: 1340 [61440/90000 (68%)]	Loss: 3.9657	Cost: 6.12s
Train Epoch: 1340 [81920/90000 (91%)]	Loss: 4.2570	Cost: 5.98s
Train Epoch: 1340 	Average Loss: 5.2398
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4724

Learning rate: 0.00019126915874034982
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1341 [0/90000 (0%)]	Loss: 20.5030	Cost: 20.33s
Train Epoch: 1341 [20480/90000 (23%)]	Loss: 4.4146	Cost: 6.18s
Train Epoch: 1341 [40960/90000 (45%)]	Loss: 4.2531	Cost: 6.67s
Train Epoch: 1341 [61440/90000 (68%)]	Loss: 3.9872	Cost: 5.99s
Train Epoch: 1341 [81920/90000 (91%)]	Loss: 4.1101	Cost: 6.67s
Train Epoch: 1341 	Average Loss: 5.2925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5169

Learning rate: 0.00019125631614729769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1342 [0/90000 (0%)]	Loss: 20.4556	Cost: 18.53s
Train Epoch: 1342 [20480/90000 (23%)]	Loss: 4.1342	Cost: 6.23s
Train Epoch: 1342 [40960/90000 (45%)]	Loss: 4.1425	Cost: 6.19s
Train Epoch: 1342 [61440/90000 (68%)]	Loss: 4.3524	Cost: 6.27s
Train Epoch: 1342 [81920/90000 (91%)]	Loss: 4.6692	Cost: 6.60s
Train Epoch: 1342 	Average Loss: 5.3377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4627

Learning rate: 0.00019124346454760824
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1343 [0/90000 (0%)]	Loss: 20.3315	Cost: 18.67s
Train Epoch: 1343 [20480/90000 (23%)]	Loss: 4.2160	Cost: 6.21s
Train Epoch: 1343 [40960/90000 (45%)]	Loss: 4.0615	Cost: 6.04s
Train Epoch: 1343 [61440/90000 (68%)]	Loss: 3.8312	Cost: 6.07s
Train Epoch: 1343 [81920/90000 (91%)]	Loss: 4.1292	Cost: 5.96s
Train Epoch: 1343 	Average Loss: 5.2325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5649

Learning rate: 0.00019123060394254988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1344 [0/90000 (0%)]	Loss: 20.5883	Cost: 20.00s
Train Epoch: 1344 [20480/90000 (23%)]	Loss: 3.9301	Cost: 6.07s
Train Epoch: 1344 [40960/90000 (45%)]	Loss: 3.7885	Cost: 6.15s
Train Epoch: 1344 [61440/90000 (68%)]	Loss: 3.9580	Cost: 6.19s
Train Epoch: 1344 [81920/90000 (91%)]	Loss: 3.9103	Cost: 7.11s
Train Epoch: 1344 	Average Loss: 5.0978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6435

Learning rate: 0.00019121773433339187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1345 [0/90000 (0%)]	Loss: 20.5532	Cost: 19.83s
Train Epoch: 1345 [20480/90000 (23%)]	Loss: 3.8303	Cost: 6.20s
Train Epoch: 1345 [40960/90000 (45%)]	Loss: 3.8822	Cost: 6.34s
Train Epoch: 1345 [61440/90000 (68%)]	Loss: 3.8244	Cost: 6.01s
Train Epoch: 1345 [81920/90000 (91%)]	Loss: 4.1147	Cost: 5.94s
Train Epoch: 1345 	Average Loss: 5.0875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6222

Learning rate: 0.00019120485572140446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1346 [0/90000 (0%)]	Loss: 20.4524	Cost: 20.26s
Train Epoch: 1346 [20480/90000 (23%)]	Loss: 3.7028	Cost: 6.18s
Train Epoch: 1346 [40960/90000 (45%)]	Loss: 3.8639	Cost: 6.08s
Train Epoch: 1346 [61440/90000 (68%)]	Loss: 3.7910	Cost: 6.09s
Train Epoch: 1346 [81920/90000 (91%)]	Loss: 4.0449	Cost: 6.32s
Train Epoch: 1346 	Average Loss: 5.0914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5991

Learning rate: 0.00019119196810785867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1347 [0/90000 (0%)]	Loss: 20.6735	Cost: 19.44s
Train Epoch: 1347 [20480/90000 (23%)]	Loss: 4.0932	Cost: 6.17s
Train Epoch: 1347 [40960/90000 (45%)]	Loss: 4.2974	Cost: 6.50s
Train Epoch: 1347 [61440/90000 (68%)]	Loss: 3.7225	Cost: 6.04s
Train Epoch: 1347 [81920/90000 (91%)]	Loss: 4.0851	Cost: 6.60s
Train Epoch: 1347 	Average Loss: 5.2227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5971

Learning rate: 0.0001911790714940264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1348 [0/90000 (0%)]	Loss: 20.5850	Cost: 19.78s
Train Epoch: 1348 [20480/90000 (23%)]	Loss: 3.9318	Cost: 6.27s
Train Epoch: 1348 [40960/90000 (45%)]	Loss: 3.9798	Cost: 6.08s
Train Epoch: 1348 [61440/90000 (68%)]	Loss: 3.9615	Cost: 5.96s
Train Epoch: 1348 [81920/90000 (91%)]	Loss: 4.1445	Cost: 6.30s
Train Epoch: 1348 	Average Loss: 5.1863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6041

Learning rate: 0.0001911661658811806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1349 [0/90000 (0%)]	Loss: 20.1728	Cost: 20.41s
Train Epoch: 1349 [20480/90000 (23%)]	Loss: 4.3735	Cost: 5.95s
Train Epoch: 1349 [40960/90000 (45%)]	Loss: 4.1087	Cost: 5.94s
Train Epoch: 1349 [61440/90000 (68%)]	Loss: 4.1365	Cost: 6.26s
Train Epoch: 1349 [81920/90000 (91%)]	Loss: 4.0813	Cost: 6.99s
Train Epoch: 1349 	Average Loss: 5.2775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5638

Learning rate: 0.00019115325127059494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1350 [0/90000 (0%)]	Loss: 20.6200	Cost: 19.59s
Train Epoch: 1350 [20480/90000 (23%)]	Loss: 4.0514	Cost: 6.12s
Train Epoch: 1350 [40960/90000 (45%)]	Loss: 3.8353	Cost: 6.15s
Train Epoch: 1350 [61440/90000 (68%)]	Loss: 3.9551	Cost: 6.24s
Train Epoch: 1350 [81920/90000 (91%)]	Loss: 4.1199	Cost: 5.96s
Train Epoch: 1350 	Average Loss: 5.1771
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6316

Learning rate: 0.00019114032766354405
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1351 [0/90000 (0%)]	Loss: 20.1660	Cost: 20.15s
Train Epoch: 1351 [20480/90000 (23%)]	Loss: 3.7235	Cost: 6.07s
Train Epoch: 1351 [40960/90000 (45%)]	Loss: 3.6007	Cost: 6.18s
Train Epoch: 1351 [61440/90000 (68%)]	Loss: 3.7435	Cost: 6.13s
Train Epoch: 1351 [81920/90000 (91%)]	Loss: 3.8991	Cost: 6.33s
Train Epoch: 1351 	Average Loss: 5.0103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6479

Learning rate: 0.00019112739506130344
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1352 [0/90000 (0%)]	Loss: 20.3345	Cost: 19.89s
Train Epoch: 1352 [20480/90000 (23%)]	Loss: 4.4528	Cost: 5.92s
Train Epoch: 1352 [40960/90000 (45%)]	Loss: 4.2376	Cost: 6.39s
Train Epoch: 1352 [61440/90000 (68%)]	Loss: 3.9423	Cost: 6.07s
Train Epoch: 1352 [81920/90000 (91%)]	Loss: 4.1407	Cost: 6.60s
Train Epoch: 1352 	Average Loss: 5.2468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6769

Learning rate: 0.0001911144534651495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1353 [0/90000 (0%)]	Loss: 20.1362	Cost: 19.90s
Train Epoch: 1353 [20480/90000 (23%)]	Loss: 4.1439	Cost: 6.20s
Train Epoch: 1353 [40960/90000 (45%)]	Loss: 3.9575	Cost: 5.96s
Train Epoch: 1353 [61440/90000 (68%)]	Loss: 3.8066	Cost: 6.01s
Train Epoch: 1353 [81920/90000 (91%)]	Loss: 4.0493	Cost: 6.29s
Train Epoch: 1353 	Average Loss: 5.1856
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5897

Learning rate: 0.00019110150287635953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1354 [0/90000 (0%)]	Loss: 20.7677	Cost: 18.78s
Train Epoch: 1354 [20480/90000 (23%)]	Loss: 3.9864	Cost: 6.19s
Train Epoch: 1354 [40960/90000 (45%)]	Loss: 4.1341	Cost: 6.03s
Train Epoch: 1354 [61440/90000 (68%)]	Loss: 4.0348	Cost: 6.30s
Train Epoch: 1354 [81920/90000 (91%)]	Loss: 4.4074	Cost: 5.93s
Train Epoch: 1354 	Average Loss: 5.2570
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6097

Learning rate: 0.00019108854329621171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1355 [0/90000 (0%)]	Loss: 20.3743	Cost: 19.50s
Train Epoch: 1355 [20480/90000 (23%)]	Loss: 4.0717	Cost: 6.00s
Train Epoch: 1355 [40960/90000 (45%)]	Loss: 4.0354	Cost: 6.18s
Train Epoch: 1355 [61440/90000 (68%)]	Loss: 3.7602	Cost: 6.09s
Train Epoch: 1355 [81920/90000 (91%)]	Loss: 4.2088	Cost: 7.51s
Train Epoch: 1355 	Average Loss: 5.2119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5416

Learning rate: 0.0001910755747259851
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1356 [0/90000 (0%)]	Loss: 20.3620	Cost: 19.94s
Train Epoch: 1356 [20480/90000 (23%)]	Loss: 4.1255	Cost: 6.14s
Train Epoch: 1356 [40960/90000 (45%)]	Loss: 4.0670	Cost: 6.06s
Train Epoch: 1356 [61440/90000 (68%)]	Loss: 4.0037	Cost: 6.25s
Train Epoch: 1356 [81920/90000 (91%)]	Loss: 4.3379	Cost: 6.95s
Train Epoch: 1356 	Average Loss: 5.2446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6450

Learning rate: 0.0001910625971669596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1357 [0/90000 (0%)]	Loss: 20.4583	Cost: 20.03s
Train Epoch: 1357 [20480/90000 (23%)]	Loss: 4.0492	Cost: 6.05s
Train Epoch: 1357 [40960/90000 (45%)]	Loss: 3.9907	Cost: 6.15s
Train Epoch: 1357 [61440/90000 (68%)]	Loss: 4.2613	Cost: 6.06s
Train Epoch: 1357 [81920/90000 (91%)]	Loss: 4.3266	Cost: 6.72s
Train Epoch: 1357 	Average Loss: 5.2367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6316

Learning rate: 0.00019104961062041612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1358 [0/90000 (0%)]	Loss: 20.4841	Cost: 19.31s
Train Epoch: 1358 [20480/90000 (23%)]	Loss: 4.1176	Cost: 6.11s
Train Epoch: 1358 [40960/90000 (45%)]	Loss: 4.0121	Cost: 6.12s
Train Epoch: 1358 [61440/90000 (68%)]	Loss: 3.8511	Cost: 6.22s
Train Epoch: 1358 [81920/90000 (91%)]	Loss: 4.1753	Cost: 5.99s
Train Epoch: 1358 	Average Loss: 5.2460
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5898

Learning rate: 0.0001910366150876363
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1359 [0/90000 (0%)]	Loss: 20.3716	Cost: 19.67s
Train Epoch: 1359 [20480/90000 (23%)]	Loss: 3.7436	Cost: 6.06s
Train Epoch: 1359 [40960/90000 (45%)]	Loss: 4.0411	Cost: 6.09s
Train Epoch: 1359 [61440/90000 (68%)]	Loss: 4.0194	Cost: 6.14s
Train Epoch: 1359 [81920/90000 (91%)]	Loss: 4.2947	Cost: 7.61s
Train Epoch: 1359 	Average Loss: 5.1877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7209

Learning rate: 0.0001910236105699028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1360 [0/90000 (0%)]	Loss: 20.5899	Cost: 19.24s
Train Epoch: 1360 [20480/90000 (23%)]	Loss: 4.3573	Cost: 6.12s
Train Epoch: 1360 [40960/90000 (45%)]	Loss: 4.4781	Cost: 6.12s
Train Epoch: 1360 [61440/90000 (68%)]	Loss: 4.1296	Cost: 6.10s
Train Epoch: 1360 [81920/90000 (91%)]	Loss: 4.0844	Cost: 5.96s
Train Epoch: 1360 	Average Loss: 5.4045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6302

Learning rate: 0.00019101059706849906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1361 [0/90000 (0%)]	Loss: 20.2218	Cost: 20.38s
Train Epoch: 1361 [20480/90000 (23%)]	Loss: 3.9310	Cost: 6.21s
Train Epoch: 1361 [40960/90000 (45%)]	Loss: 3.8716	Cost: 6.07s
Train Epoch: 1361 [61440/90000 (68%)]	Loss: 3.6430	Cost: 6.26s
Train Epoch: 1361 [81920/90000 (91%)]	Loss: 4.1271	Cost: 6.79s
Train Epoch: 1361 	Average Loss: 5.0442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6470

Learning rate: 0.00019099757458470952
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1362 [0/90000 (0%)]	Loss: 20.6722	Cost: 19.20s
Train Epoch: 1362 [20480/90000 (23%)]	Loss: 3.8788	Cost: 6.12s
Train Epoch: 1362 [40960/90000 (45%)]	Loss: 3.8293	Cost: 6.12s
Train Epoch: 1362 [61440/90000 (68%)]	Loss: 3.8341	Cost: 5.81s
Train Epoch: 1362 [81920/90000 (91%)]	Loss: 4.2347	Cost: 5.70s
Train Epoch: 1362 	Average Loss: 5.0775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7594

Learning rate: 0.00019098454311981946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1363 [0/90000 (0%)]	Loss: 20.6823	Cost: 19.82s
Train Epoch: 1363 [20480/90000 (23%)]	Loss: 4.2705	Cost: 6.12s
Train Epoch: 1363 [40960/90000 (45%)]	Loss: 4.3797	Cost: 6.20s
Train Epoch: 1363 [61440/90000 (68%)]	Loss: 4.2159	Cost: 5.99s
Train Epoch: 1363 [81920/90000 (91%)]	Loss: 4.1983	Cost: 7.11s
Train Epoch: 1363 	Average Loss: 5.3241
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6054

Learning rate: 0.000190971502675115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1364 [0/90000 (0%)]	Loss: 20.5251	Cost: 20.02s
Train Epoch: 1364 [20480/90000 (23%)]	Loss: 4.1809	Cost: 6.08s
Train Epoch: 1364 [40960/90000 (45%)]	Loss: 4.0501	Cost: 6.25s
Train Epoch: 1364 [61440/90000 (68%)]	Loss: 3.9555	Cost: 6.14s
Train Epoch: 1364 [81920/90000 (91%)]	Loss: 4.0339	Cost: 6.93s
Train Epoch: 1364 	Average Loss: 5.2079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6084

Learning rate: 0.00019095845325188318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1365 [0/90000 (0%)]	Loss: 20.3068	Cost: 20.62s
Train Epoch: 1365 [20480/90000 (23%)]	Loss: 4.2951	Cost: 6.27s
Train Epoch: 1365 [40960/90000 (45%)]	Loss: 4.3047	Cost: 6.17s
Train Epoch: 1365 [61440/90000 (68%)]	Loss: 4.1451	Cost: 6.12s
Train Epoch: 1365 [81920/90000 (91%)]	Loss: 4.2856	Cost: 6.48s
Train Epoch: 1365 	Average Loss: 5.3449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6897

Learning rate: 0.0001909453948514119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1366 [0/90000 (0%)]	Loss: 20.5567	Cost: 18.40s
Train Epoch: 1366 [20480/90000 (23%)]	Loss: 4.2142	Cost: 6.09s
Train Epoch: 1366 [40960/90000 (45%)]	Loss: 4.1295	Cost: 6.53s
Train Epoch: 1366 [61440/90000 (68%)]	Loss: 4.0975	Cost: 6.00s
Train Epoch: 1366 [81920/90000 (91%)]	Loss: 3.9434	Cost: 7.14s
Train Epoch: 1366 	Average Loss: 5.2345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6757

Learning rate: 0.00019093232747499004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1367 [0/90000 (0%)]	Loss: 20.6070	Cost: 19.51s
Train Epoch: 1367 [20480/90000 (23%)]	Loss: 4.1287	Cost: 6.19s
Train Epoch: 1367 [40960/90000 (45%)]	Loss: 4.1374	Cost: 6.26s
Train Epoch: 1367 [61440/90000 (68%)]	Loss: 4.2856	Cost: 6.03s
Train Epoch: 1367 [81920/90000 (91%)]	Loss: 4.3144	Cost: 6.03s
Train Epoch: 1367 	Average Loss: 5.2953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6714

Learning rate: 0.00019091925112390724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1368 [0/90000 (0%)]	Loss: 20.1115	Cost: 19.39s
Train Epoch: 1368 [20480/90000 (23%)]	Loss: 3.9656	Cost: 6.34s
Train Epoch: 1368 [40960/90000 (45%)]	Loss: 3.9756	Cost: 6.05s
Train Epoch: 1368 [61440/90000 (68%)]	Loss: 3.9795	Cost: 6.14s
Train Epoch: 1368 [81920/90000 (91%)]	Loss: 4.0779	Cost: 6.17s
Train Epoch: 1368 	Average Loss: 5.1129
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6201

Learning rate: 0.0001909061657994541
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1369 [0/90000 (0%)]	Loss: 20.5266	Cost: 19.83s
Train Epoch: 1369 [20480/90000 (23%)]	Loss: 4.0553	Cost: 6.09s
Train Epoch: 1369 [40960/90000 (45%)]	Loss: 4.0382	Cost: 6.17s
Train Epoch: 1369 [61440/90000 (68%)]	Loss: 3.8367	Cost: 6.06s
Train Epoch: 1369 [81920/90000 (91%)]	Loss: 3.6162	Cost: 6.55s
Train Epoch: 1369 	Average Loss: 5.0536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6811

Learning rate: 0.0001908930715029221
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1370 [0/90000 (0%)]	Loss: 20.5428	Cost: 20.29s
Train Epoch: 1370 [20480/90000 (23%)]	Loss: 3.8680	Cost: 6.12s
Train Epoch: 1370 [40960/90000 (45%)]	Loss: 3.7077	Cost: 6.10s
Train Epoch: 1370 [61440/90000 (68%)]	Loss: 3.5960	Cost: 6.10s
Train Epoch: 1370 [81920/90000 (91%)]	Loss: 3.7572	Cost: 6.84s
Train Epoch: 1370 	Average Loss: 4.9726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5884

Learning rate: 0.0001908799682356036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1371 [0/90000 (0%)]	Loss: 20.4539	Cost: 20.43s
Train Epoch: 1371 [20480/90000 (23%)]	Loss: 3.8778	Cost: 6.01s
Train Epoch: 1371 [40960/90000 (45%)]	Loss: 3.6869	Cost: 6.23s
Train Epoch: 1371 [61440/90000 (68%)]	Loss: 3.6538	Cost: 6.07s
Train Epoch: 1371 [81920/90000 (91%)]	Loss: 3.6534	Cost: 6.74s
Train Epoch: 1371 	Average Loss: 4.9128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8240

Learning rate: 0.0001908668559987918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1372 [0/90000 (0%)]	Loss: 20.5395	Cost: 18.96s
Train Epoch: 1372 [20480/90000 (23%)]	Loss: 3.7783	Cost: 6.03s
Train Epoch: 1372 [40960/90000 (45%)]	Loss: 3.7731	Cost: 6.13s
Train Epoch: 1372 [61440/90000 (68%)]	Loss: 3.6727	Cost: 6.31s
Train Epoch: 1372 [81920/90000 (91%)]	Loss: 3.5472	Cost: 6.16s
Train Epoch: 1372 	Average Loss: 4.9021
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7538

Learning rate: 0.00019085373479378083
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1373 [0/90000 (0%)]	Loss: 20.6569	Cost: 19.90s
Train Epoch: 1373 [20480/90000 (23%)]	Loss: 3.8034	Cost: 6.20s
Train Epoch: 1373 [40960/90000 (45%)]	Loss: 3.7712	Cost: 6.02s
Train Epoch: 1373 [61440/90000 (68%)]	Loss: 3.7972	Cost: 6.13s
Train Epoch: 1373 [81920/90000 (91%)]	Loss: 4.1015	Cost: 7.20s
Train Epoch: 1373 	Average Loss: 4.9604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7273

Learning rate: 0.00019084060462186577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1374 [0/90000 (0%)]	Loss: 20.9270	Cost: 19.78s
Train Epoch: 1374 [20480/90000 (23%)]	Loss: 3.9452	Cost: 6.13s
Train Epoch: 1374 [40960/90000 (45%)]	Loss: 3.8430	Cost: 6.29s
Train Epoch: 1374 [61440/90000 (68%)]	Loss: 3.7853	Cost: 5.97s
Train Epoch: 1374 [81920/90000 (91%)]	Loss: 3.8767	Cost: 6.63s
Train Epoch: 1374 	Average Loss: 5.0293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7315

Learning rate: 0.00019082746548434244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1375 [0/90000 (0%)]	Loss: 20.3258	Cost: 19.50s
Train Epoch: 1375 [20480/90000 (23%)]	Loss: 3.7787	Cost: 6.06s
Train Epoch: 1375 [40960/90000 (45%)]	Loss: 3.5991	Cost: 6.38s
Train Epoch: 1375 [61440/90000 (68%)]	Loss: 3.5196	Cost: 6.02s
Train Epoch: 1375 [81920/90000 (91%)]	Loss: 3.7982	Cost: 6.13s
Train Epoch: 1375 	Average Loss: 4.9017
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7709

Learning rate: 0.0001908143173825077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1376 [0/90000 (0%)]	Loss: 20.7248	Cost: 19.59s
Train Epoch: 1376 [20480/90000 (23%)]	Loss: 3.7978	Cost: 6.18s
Train Epoch: 1376 [40960/90000 (45%)]	Loss: 3.7990	Cost: 6.16s
Train Epoch: 1376 [61440/90000 (68%)]	Loss: 3.6339	Cost: 6.00s
Train Epoch: 1376 [81920/90000 (91%)]	Loss: 3.8053	Cost: 6.83s
Train Epoch: 1376 	Average Loss: 4.9804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7935

Learning rate: 0.00019080116031765912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1377 [0/90000 (0%)]	Loss: 20.2403	Cost: 19.47s
Train Epoch: 1377 [20480/90000 (23%)]	Loss: 3.8308	Cost: 6.12s
Train Epoch: 1377 [40960/90000 (45%)]	Loss: 3.8362	Cost: 6.18s
Train Epoch: 1377 [61440/90000 (68%)]	Loss: 3.7862	Cost: 6.08s
Train Epoch: 1377 [81920/90000 (91%)]	Loss: 3.9092	Cost: 5.95s
Train Epoch: 1377 	Average Loss: 5.0056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7869

Learning rate: 0.00019078799429109533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1378 [0/90000 (0%)]	Loss: 20.4158	Cost: 20.14s
Train Epoch: 1378 [20480/90000 (23%)]	Loss: 3.5807	Cost: 6.15s
Train Epoch: 1378 [40960/90000 (45%)]	Loss: 3.6819	Cost: 6.08s
Train Epoch: 1378 [61440/90000 (68%)]	Loss: 3.8951	Cost: 6.06s
Train Epoch: 1378 [81920/90000 (91%)]	Loss: 3.6648	Cost: 6.23s
Train Epoch: 1378 	Average Loss: 4.9490
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8018

Learning rate: 0.0001907748193041157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1379 [0/90000 (0%)]	Loss: 20.5284	Cost: 20.61s
Train Epoch: 1379 [20480/90000 (23%)]	Loss: 3.7575	Cost: 6.06s
Train Epoch: 1379 [40960/90000 (45%)]	Loss: 3.8803	Cost: 6.28s
Train Epoch: 1379 [61440/90000 (68%)]	Loss: 3.7395	Cost: 6.00s
Train Epoch: 1379 [81920/90000 (91%)]	Loss: 3.7247	Cost: 6.50s
Train Epoch: 1379 	Average Loss: 4.9619
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7489

Learning rate: 0.00019076163535802063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1380 [0/90000 (0%)]	Loss: 20.6400	Cost: 19.98s
Train Epoch: 1380 [20480/90000 (23%)]	Loss: 3.9066	Cost: 6.10s
Train Epoch: 1380 [40960/90000 (45%)]	Loss: 3.9428	Cost: 6.12s
Train Epoch: 1380 [61440/90000 (68%)]	Loss: 3.9474	Cost: 6.07s
Train Epoch: 1380 [81920/90000 (91%)]	Loss: 4.0403	Cost: 6.83s
Train Epoch: 1380 	Average Loss: 5.0926
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7416

Learning rate: 0.00019074844245411124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1381 [0/90000 (0%)]	Loss: 20.6548	Cost: 19.47s
Train Epoch: 1381 [20480/90000 (23%)]	Loss: 3.7970	Cost: 6.06s
Train Epoch: 1381 [40960/90000 (45%)]	Loss: 4.0625	Cost: 6.10s
Train Epoch: 1381 [61440/90000 (68%)]	Loss: 3.8276	Cost: 6.04s
Train Epoch: 1381 [81920/90000 (91%)]	Loss: 3.9797	Cost: 5.98s
Train Epoch: 1381 	Average Loss: 5.1103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7332

Learning rate: 0.00019073524059368967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1382 [0/90000 (0%)]	Loss: 20.4675	Cost: 20.32s
Train Epoch: 1382 [20480/90000 (23%)]	Loss: 3.9368	Cost: 6.05s
Train Epoch: 1382 [40960/90000 (45%)]	Loss: 3.8158	Cost: 6.43s
Train Epoch: 1382 [61440/90000 (68%)]	Loss: 3.5837	Cost: 6.00s
Train Epoch: 1382 [81920/90000 (91%)]	Loss: 3.8873	Cost: 7.27s
Train Epoch: 1382 	Average Loss: 4.9867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7630

Learning rate: 0.00019072202977805887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1383 [0/90000 (0%)]	Loss: 20.3888	Cost: 19.76s
Train Epoch: 1383 [20480/90000 (23%)]	Loss: 3.7785	Cost: 6.04s
Train Epoch: 1383 [40960/90000 (45%)]	Loss: 3.8180	Cost: 6.26s
Train Epoch: 1383 [61440/90000 (68%)]	Loss: 3.6630	Cost: 6.36s
Train Epoch: 1383 [81920/90000 (91%)]	Loss: 4.0167	Cost: 6.53s
Train Epoch: 1383 	Average Loss: 5.0441
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7072

Learning rate: 0.0001907088100085227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1384 [0/90000 (0%)]	Loss: 20.5097	Cost: 19.67s
Train Epoch: 1384 [20480/90000 (23%)]	Loss: 4.0376	Cost: 6.06s
Train Epoch: 1384 [40960/90000 (45%)]	Loss: 3.8758	Cost: 6.25s
Train Epoch: 1384 [61440/90000 (68%)]	Loss: 3.8113	Cost: 6.09s
Train Epoch: 1384 [81920/90000 (91%)]	Loss: 3.8404	Cost: 7.07s
Train Epoch: 1384 	Average Loss: 5.0388
