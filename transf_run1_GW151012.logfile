Nestedspace(activation='elu', apply_unconditional_transform=False, base_transform_type='rq-coupling', basis_dir='data/GW151012_sample_prior_basis/', batch_norm=True, batch_size=4096, bw_dstar=None, cuda=True, data_dir='data/GW151012_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, dropout_probability=0.0, epochs=10000, flow_lr=None, hidden_dims=512, kl_annealing=True, lr=0.0002, lr_anneal_method='cosine', lr_annealing=True, mixed_alpha=1.0, mode='train', model_dir='models/GW151012_sample_uniform_100basis_all_mixed_prior_transfered/', model_source='new', model_type='nde', nbins=8, nflows=15, nsample=100000, nsamples_target_event=50000, num_transform_blocks=10, output_freq=10, sampling_from='mixed', save=True, save_aux_filename='waveforms_supplementary.hdf5', save_model_name='model.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, tail_bound=1.0, transfer_epochs=400, truncate_basis=100)
Waveform directory data/GW151012_sample_prior_basis/
Model directory models/GW151012_sample_uniform_100basis_all_mixed_prior_transfered/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Detectors: ['H1', 'L1']

Constructing model of type nde

Initial learning rate 0.0002
Using cosine LR annealing.

Model hyperparameters:
input_dim 	 15
num_flow_steps 	 15
context_dim 	 400
base_transform_kwargs
	 hidden_dim 	 512
	 num_transform_blocks 	 10
	 activation 	 elu
	 dropout_probability 	 0.0
	 batch_norm 	 True
	 num_bins 	 8
	 tail_bound 	 1.0
	 apply_unconditional_transform 	 False
	 base_transform_type 	 rq-coupling

Training for 10000 epochs
Starting timer
Now, transfer learning from alpha=1.0!
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 27.5147	Cost: 37.00s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 21.5890	Cost: 9.47s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 20.2474	Cost: 17.20s
Train Epoch: 1 	Average Loss: 21.7170
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4847

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999999506519785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 20.2303	Cost: 38.16s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 19.2570	Cost: 9.46s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 18.8924	Cost: 19.65s
Train Epoch: 2 	Average Loss: 19.3739
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8070

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019999998026079186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 18.8076	Cost: 38.65s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 18.3861	Cost: 9.66s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 17.8257	Cost: 18.27s
Train Epoch: 3 	Average Loss: 18.3131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8653

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019999995558678347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 17.7889	Cost: 35.61s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 17.3393	Cost: 9.70s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 16.8151	Cost: 17.33s
Train Epoch: 4 	Average Loss: 17.2585
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9249

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.0001999999210431752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 16.7300	Cost: 35.00s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 16.2502	Cost: 10.06s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 15.9493	Cost: 18.03s
Train Epoch: 5 	Average Loss: 16.3038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0721

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.00019999987662997035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 15.9499	Cost: 38.88s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 15.6136	Cost: 9.69s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 15.3209	Cost: 17.54s
Train Epoch: 6 	Average Loss: 15.6445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4647

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019999982234717337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 15.2729	Cost: 38.54s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 15.1954	Cost: 10.11s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 14.8170	Cost: 19.85s
Train Epoch: 7 	Average Loss: 15.1208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0977

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.0001999997581947896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 14.8778	Cost: 37.12s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 14.7193	Cost: 9.80s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 14.4349	Cost: 22.62s
Train Epoch: 8 	Average Loss: 14.6610
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7375

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.0001999996841728254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 14.4689	Cost: 34.93s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 14.2485	Cost: 9.60s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 14.0925	Cost: 23.72s
Train Epoch: 9 	Average Loss: 14.2992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3754

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019999960028128805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 14.1649	Cost: 36.72s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 14.0893	Cost: 9.55s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 13.8299	Cost: 21.86s
Train Epoch: 10 	Average Loss: 14.0357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0463

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 0.00019999950652018584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 13.8848	Cost: 37.10s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 13.8250	Cost: 9.61s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 13.5508	Cost: 17.86s
Train Epoch: 11 	Average Loss: 13.7407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6757

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 0.00019999940288952797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 13.5677	Cost: 38.45s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 13.5931	Cost: 9.44s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 13.4060	Cost: 20.04s
Train Epoch: 12 	Average Loss: 13.4987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4696

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 0.00019999928938932473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 13.3666	Cost: 35.57s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 13.3258	Cost: 9.43s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 13.2621	Cost: 17.94s
Train Epoch: 13 	Average Loss: 13.2984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3568

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Learning rate: 0.0001999991660195873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 13.1993	Cost: 35.42s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 13.1570	Cost: 9.44s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 13.1052	Cost: 18.36s
Train Epoch: 14 	Average Loss: 13.1611
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1016

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Learning rate: 0.0001999990327803279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 13.1777	Cost: 38.52s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 13.0480	Cost: 9.73s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 12.8963	Cost: 17.77s
Train Epoch: 15 	Average Loss: 12.9581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9040

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Learning rate: 0.00019999888967155963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 12.9674	Cost: 37.78s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 12.8295	Cost: 9.61s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 12.6946	Cost: 20.42s
Train Epoch: 16 	Average Loss: 12.8192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8163

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Learning rate: 0.0001999987366932966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 12.8289	Cost: 38.23s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 12.7695	Cost: 9.64s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 12.5924	Cost: 20.32s
Train Epoch: 17 	Average Loss: 12.6979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6029

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Learning rate: 0.00019999857384555393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 12.7491	Cost: 35.07s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 12.5621	Cost: 9.63s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 12.4576	Cost: 21.26s
Train Epoch: 18 	Average Loss: 12.5788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5904

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Learning rate: 0.0001999984011283477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 12.5019	Cost: 35.21s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 12.4818	Cost: 9.95s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 12.3179	Cost: 22.60s
Train Epoch: 19 	Average Loss: 12.4401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4177

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Learning rate: 0.00019999821854169497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 12.5312	Cost: 35.15s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 12.3373	Cost: 9.59s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 12.1858	Cost: 23.72s
Train Epoch: 20 	Average Loss: 12.3301
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3062

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Learning rate: 0.00019999802608561374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 12.2359	Cost: 37.33s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 12.1624	Cost: 9.52s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 12.2215	Cost: 21.65s
Train Epoch: 21 	Average Loss: 12.2316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2822

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Learning rate: 0.000199997823760123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 12.1841	Cost: 37.14s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 12.2553	Cost: 9.47s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 11.9563	Cost: 18.91s
Train Epoch: 22 	Average Loss: 12.1054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0832

Saving model as e22_model.pt & e22_waveforms_supplementary.hdf5
Learning rate: 0.00019999761156524272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 12.0289	Cost: 38.95s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 12.0540	Cost: 9.59s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 11.8904	Cost: 17.67s
Train Epoch: 23 	Average Loss: 12.0146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8903

Saving model as e23_model.pt & e23_waveforms_supplementary.hdf5
Learning rate: 0.00019999738950099387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 11.9671	Cost: 38.51s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 12.0397	Cost: 9.67s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 11.8098	Cost: 19.75s
Train Epoch: 24 	Average Loss: 11.9493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0413

Learning rate: 0.00019999715756739833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 11.8861	Cost: 40.20s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 11.7763	Cost: 9.43s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 11.5696	Cost: 19.85s
Train Epoch: 25 	Average Loss: 11.8086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8724

Saving model as e25_model.pt & e25_waveforms_supplementary.hdf5
Learning rate: 0.000199996915764479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 11.7413	Cost: 38.07s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 11.8483	Cost: 9.45s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 11.6649	Cost: 20.69s
Train Epoch: 26 	Average Loss: 11.7503
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7115

Saving model as e26_model.pt & e26_waveforms_supplementary.hdf5
Learning rate: 0.00019999666409225975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 11.7579	Cost: 37.34s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 11.6952	Cost: 9.47s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 11.5979	Cost: 19.64s
Train Epoch: 27 	Average Loss: 11.6522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5567

Saving model as e27_model.pt & e27_waveforms_supplementary.hdf5
Learning rate: 0.00019999640255076543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 11.5818	Cost: 37.77s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 11.4293	Cost: 9.40s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 11.3152	Cost: 20.68s
Train Epoch: 28 	Average Loss: 11.4648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4164

Saving model as e28_model.pt & e28_waveforms_supplementary.hdf5
Learning rate: 0.00019999613114002186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 11.4244	Cost: 36.68s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 11.2683	Cost: 10.13s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 11.2530	Cost: 21.52s
Train Epoch: 29 	Average Loss: 11.3332
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3693

Saving model as e29_model.pt & e29_waveforms_supplementary.hdf5
Learning rate: 0.0001999958498600558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 11.3105	Cost: 36.97s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 11.3764	Cost: 9.55s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 11.1509	Cost: 24.03s
Train Epoch: 30 	Average Loss: 11.2724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1797

Saving model as e30_model.pt & e30_waveforms_supplementary.hdf5
Learning rate: 0.000199995558710895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 11.2240	Cost: 36.19s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 11.1834	Cost: 9.53s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 11.0387	Cost: 21.86s
Train Epoch: 31 	Average Loss: 11.1863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2844

Learning rate: 0.00019999525769256825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 11.1344	Cost: 36.81s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 11.1414	Cost: 9.45s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 11.0069	Cost: 20.24s
Train Epoch: 32 	Average Loss: 11.0960
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9984

Saving model as e32_model.pt & e32_waveforms_supplementary.hdf5
Learning rate: 0.00019999494680510518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 11.0520	Cost: 37.24s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 11.0481	Cost: 9.44s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 10.9842	Cost: 18.98s
Train Epoch: 33 	Average Loss: 11.0300
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9769

Saving model as e33_model.pt & e33_waveforms_supplementary.hdf5
Learning rate: 0.00019999462604853658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 11.0412	Cost: 38.97s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 10.9367	Cost: 9.48s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 11.0041	Cost: 20.06s
Train Epoch: 34 	Average Loss: 10.9198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9496

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Learning rate: 0.00019999429542289402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 10.9199	Cost: 39.98s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 10.8323	Cost: 9.65s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 10.8234	Cost: 18.52s
Train Epoch: 35 	Average Loss: 10.8745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8153

Saving model as e35_model.pt & e35_waveforms_supplementary.hdf5
Learning rate: 0.00019999395492821016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 10.9135	Cost: 37.58s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 10.8012	Cost: 10.17s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 10.7056	Cost: 17.94s
Train Epoch: 36 	Average Loss: 10.8224
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7080

Saving model as e36_model.pt & e36_waveforms_supplementary.hdf5
Learning rate: 0.0001999936045645186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 10.7521	Cost: 37.76s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 10.5869	Cost: 9.69s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 10.7209	Cost: 19.41s
Train Epoch: 37 	Average Loss: 10.6810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6338

Saving model as e37_model.pt & e37_waveforms_supplementary.hdf5
Learning rate: 0.00019999324433185394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 10.6930	Cost: 37.30s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 10.6665	Cost: 10.13s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 10.5004	Cost: 20.33s
Train Epoch: 38 	Average Loss: 10.6701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6424

Learning rate: 0.0001999928742302517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 10.5588	Cost: 37.51s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 10.6578	Cost: 9.76s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 10.3762	Cost: 22.54s
Train Epoch: 39 	Average Loss: 10.5451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5524

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Learning rate: 0.00019999249425974844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 10.4114	Cost: 36.32s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 10.4076	Cost: 9.55s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 10.3716	Cost: 24.18s
Train Epoch: 40 	Average Loss: 10.4454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3993

Saving model as e40_model.pt & e40_waveforms_supplementary.hdf5
Learning rate: 0.00019999210442038165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 10.6077	Cost: 36.82s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 10.4650	Cost: 9.47s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 10.2992	Cost: 21.64s
Train Epoch: 41 	Average Loss: 10.4064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5399

Learning rate: 0.00019999170471218976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 10.3688	Cost: 36.92s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 10.4268	Cost: 9.44s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 10.2549	Cost: 18.53s
Train Epoch: 42 	Average Loss: 10.2940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2972

Saving model as e42_model.pt & e42_waveforms_supplementary.hdf5
Learning rate: 0.0001999912951352123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 10.3076	Cost: 37.24s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 10.1526	Cost: 9.47s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 10.1081	Cost: 18.41s
Train Epoch: 43 	Average Loss: 10.2427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0786

Saving model as e43_model.pt & e43_waveforms_supplementary.hdf5
Learning rate: 0.00019999087568948966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 10.1507	Cost: 38.43s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 10.2029	Cost: 9.64s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 10.1530	Cost: 19.29s
Train Epoch: 44 	Average Loss: 10.1831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2024

Learning rate: 0.0001999904463750632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 10.1865	Cost: 34.93s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 10.1348	Cost: 9.72s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 10.0750	Cost: 17.80s
Train Epoch: 45 	Average Loss: 10.1515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0642

Saving model as e45_model.pt & e45_waveforms_supplementary.hdf5
Learning rate: 0.00019999000719197536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 9.9829	Cost: 38.95s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 10.2593	Cost: 9.81s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 9.9728	Cost: 20.07s
Train Epoch: 46 	Average Loss: 10.0617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0447

Saving model as e46_model.pt & e46_waveforms_supplementary.hdf5
Learning rate: 0.00019998955814026943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 9.9749	Cost: 38.56s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 9.9382	Cost: 9.72s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 9.9203	Cost: 19.06s
Train Epoch: 47 	Average Loss: 9.9708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9294

Saving model as e47_model.pt & e47_waveforms_supplementary.hdf5
Learning rate: 0.00019998909921998973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 10.0888	Cost: 38.07s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 9.9417	Cost: 9.70s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 9.7817	Cost: 20.84s
Train Epoch: 48 	Average Loss: 9.9407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9540

Learning rate: 0.0001999886304311816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 9.9543	Cost: 37.19s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 9.9277	Cost: 9.63s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 9.7760	Cost: 23.69s
Train Epoch: 49 	Average Loss: 9.8817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8978

Saving model as e49_model.pt & e49_waveforms_supplementary.hdf5
Learning rate: 0.00019998815177389132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 9.7547	Cost: 36.59s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 9.8732	Cost: 9.56s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 9.6475	Cost: 23.49s
Train Epoch: 50 	Average Loss: 9.7702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7027

Saving model as e50_model.pt & e50_waveforms_supplementary.hdf5
Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 9.6521	Cost: 37.35s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 9.6584	Cost: 9.50s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 9.7934	Cost: 21.04s
Train Epoch: 51 	Average Loss: 9.6928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6788

Saving model as e51_model.pt & e51_waveforms_supplementary.hdf5
Learning rate: 0.00019998716485405404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 9.6888	Cost: 37.48s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 9.7000	Cost: 9.44s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 9.5660	Cost: 18.96s
Train Epoch: 52 	Average Loss: 9.7162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7927

Learning rate: 0.0001999866565916045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 9.7141	Cost: 36.51s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 9.7045	Cost: 9.53s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 9.5763	Cost: 20.20s
Train Epoch: 53 	Average Loss: 9.6475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7715

Learning rate: 0.0001999861384608676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 9.8818	Cost: 37.37s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 9.5708	Cost: 9.60s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 9.4656	Cost: 18.03s
Train Epoch: 54 	Average Loss: 9.6034
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6011

Saving model as e54_model.pt & e54_waveforms_supplementary.hdf5
Learning rate: 0.00019998561046189446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 9.5864	Cost: 36.10s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 9.6409	Cost: 9.66s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 9.4768	Cost: 18.17s
Train Epoch: 55 	Average Loss: 9.5886
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4908

Saving model as e55_model.pt & e55_waveforms_supplementary.hdf5
Learning rate: 0.00019998507259473718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 9.5663	Cost: 39.15s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 9.4593	Cost: 10.15s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 9.2938	Cost: 19.93s
Train Epoch: 56 	Average Loss: 9.5007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4526

Saving model as e56_model.pt & e56_waveforms_supplementary.hdf5
Learning rate: 0.00019998452485944885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 9.5155	Cost: 38.15s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 9.3738	Cost: 9.73s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 9.4515	Cost: 19.16s
Train Epoch: 57 	Average Loss: 9.3891
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3783

Saving model as e57_model.pt & e57_waveforms_supplementary.hdf5
Learning rate: 0.00019998396725608354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 9.4123	Cost: 35.40s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 9.3141	Cost: 9.66s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 9.2215	Cost: 19.95s
Train Epoch: 58 	Average Loss: 9.4093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5462

Learning rate: 0.00019998339978469627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 9.6073	Cost: 34.53s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 9.3161	Cost: 9.65s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 9.1679	Cost: 20.42s
Train Epoch: 59 	Average Loss: 9.3516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3257

Saving model as e59_model.pt & e59_waveforms_supplementary.hdf5
Learning rate: 0.00019998282244534305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 9.3979	Cost: 37.08s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 9.3480	Cost: 9.77s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 9.2394	Cost: 23.14s
Train Epoch: 60 	Average Loss: 9.3159
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2732

Saving model as e60_model.pt & e60_waveforms_supplementary.hdf5
Learning rate: 0.00019998223523808088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 9.4353	Cost: 36.81s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 9.2403	Cost: 9.56s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 9.0906	Cost: 23.23s
Train Epoch: 61 	Average Loss: 9.2732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3131

Learning rate: 0.0001999816381629677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 9.2612	Cost: 36.85s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 9.1759	Cost: 9.51s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 9.0975	Cost: 21.39s
Train Epoch: 62 	Average Loss: 9.2165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3770

Learning rate: 0.00019998103122006246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 9.4125	Cost: 36.46s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 9.1699	Cost: 9.45s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 9.1627	Cost: 18.57s
Train Epoch: 63 	Average Loss: 9.1989
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1458

Saving model as e63_model.pt & e63_waveforms_supplementary.hdf5
Learning rate: 0.00019998041440942506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 9.2063	Cost: 37.39s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 9.2117	Cost: 9.43s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 9.0656	Cost: 17.98s
Train Epoch: 64 	Average Loss: 9.1468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0895

Saving model as e64_model.pt & e64_waveforms_supplementary.hdf5
Learning rate: 0.00019997978773111632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 9.0769	Cost: 39.28s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 9.1146	Cost: 9.64s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 8.9394	Cost: 19.68s
Train Epoch: 65 	Average Loss: 9.0729
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0083

Saving model as e65_model.pt & e65_waveforms_supplementary.hdf5
Learning rate: 0.00019997915118519813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 8.9557	Cost: 36.05s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 9.0285	Cost: 9.62s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 9.0025	Cost: 18.57s
Train Epoch: 66 	Average Loss: 9.0622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1599

Learning rate: 0.0001999785047717333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 9.1521	Cost: 37.95s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 9.0608	Cost: 9.63s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 8.9691	Cost: 21.59s
Train Epoch: 67 	Average Loss: 9.0334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0596

Learning rate: 0.00019997784849078566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 9.0140	Cost: 37.69s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 8.8953	Cost: 9.52s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 8.8492	Cost: 19.87s
Train Epoch: 68 	Average Loss: 8.9319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0343

Learning rate: 0.00019997718234242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 9.1239	Cost: 37.99s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 8.8960	Cost: 9.76s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 8.7567	Cost: 18.85s
Train Epoch: 69 	Average Loss: 8.9350
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9878

Saving model as e69_model.pt & e69_waveforms_supplementary.hdf5
Learning rate: 0.00019997650632670199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 9.0231	Cost: 37.44s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 8.8297	Cost: 9.52s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 8.7533	Cost: 22.40s
Train Epoch: 70 	Average Loss: 8.8848
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9596

Saving model as e70_model.pt & e70_waveforms_supplementary.hdf5
Learning rate: 0.0001999758204436984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 8.9691	Cost: 36.14s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 8.9583	Cost: 9.85s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 8.7995	Cost: 22.70s
Train Epoch: 71 	Average Loss: 8.8837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8605

Saving model as e71_model.pt & e71_waveforms_supplementary.hdf5
Learning rate: 0.00019997512469347695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 8.7966	Cost: 36.18s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 8.7846	Cost: 9.58s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 8.8622	Cost: 22.51s
Train Epoch: 72 	Average Loss: 8.8322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8187

Saving model as e72_model.pt & e72_waveforms_supplementary.hdf5
Learning rate: 0.00019997441907610624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 8.8259	Cost: 37.28s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 8.7701	Cost: 9.47s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 8.6966	Cost: 20.58s
Train Epoch: 73 	Average Loss: 8.7905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8615

Learning rate: 0.00019997370359165596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 8.8482	Cost: 36.64s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 8.6791	Cost: 9.46s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 8.7318	Cost: 18.39s
Train Epoch: 74 	Average Loss: 8.7941
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7796

Saving model as e74_model.pt & e74_waveforms_supplementary.hdf5
Learning rate: 0.0001999729782401967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 8.7966	Cost: 37.76s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 8.7616	Cost: 9.49s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 8.6074	Cost: 18.17s
Train Epoch: 75 	Average Loss: 8.7164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7927

Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 8.6943	Cost: 39.22s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 8.7439	Cost: 9.48s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 8.5466	Cost: 19.95s
Train Epoch: 76 	Average Loss: 8.6389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5926

Saving model as e76_model.pt & e76_waveforms_supplementary.hdf5
Learning rate: 0.00019997149793653861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 8.6373	Cost: 36.84s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 8.6458	Cost: 9.52s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 8.5359	Cost: 20.15s
Train Epoch: 77 	Average Loss: 8.6717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6761

Learning rate: 0.00019997074298448586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 8.7956	Cost: 36.27s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 8.6201	Cost: 9.65s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 8.5437	Cost: 19.41s
Train Epoch: 78 	Average Loss: 8.5842
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6375

Learning rate: 0.00019996997816571638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 8.6353	Cost: 39.12s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 8.5220	Cost: 9.87s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 8.4248	Cost: 21.01s
Train Epoch: 79 	Average Loss: 8.5746
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7510

Learning rate: 0.00019996920348030559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 8.8425	Cost: 37.78s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 8.6020	Cost: 9.60s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 8.3740	Cost: 19.79s
Train Epoch: 80 	Average Loss: 8.5812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5142

Saving model as e80_model.pt & e80_waveforms_supplementary.hdf5
Learning rate: 0.00019996841892832998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 8.4806	Cost: 38.79s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 8.4481	Cost: 10.18s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 8.4742	Cost: 19.20s
Train Epoch: 81 	Average Loss: 8.4861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5524

Learning rate: 0.00019996762450986697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 8.5698	Cost: 37.35s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 8.4149	Cost: 10.21s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 8.2762	Cost: 20.81s
Train Epoch: 82 	Average Loss: 8.4721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3709

Saving model as e82_model.pt & e82_waveforms_supplementary.hdf5
Learning rate: 0.00019996682022499498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 8.3884	Cost: 36.22s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 8.4242	Cost: 10.01s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 8.2971	Cost: 22.68s
Train Epoch: 83 	Average Loss: 8.4371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4210

Learning rate: 0.0001999660060737934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 8.4484	Cost: 36.74s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 8.4479	Cost: 9.54s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 8.2340	Cost: 23.68s
Train Epoch: 84 	Average Loss: 8.3811
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3106

Saving model as e84_model.pt & e84_waveforms_supplementary.hdf5
Learning rate: 0.00019996518205634255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 8.4094	Cost: 36.70s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 8.3202	Cost: 9.67s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 8.2449	Cost: 20.96s
Train Epoch: 85 	Average Loss: 8.3504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4280

Learning rate: 0.0001999643481727238
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 8.4361	Cost: 36.66s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 8.4174	Cost: 9.46s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 8.1572	Cost: 18.82s
Train Epoch: 86 	Average Loss: 8.3403
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3136

Learning rate: 0.0001999635044230194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 8.2651	Cost: 37.73s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 8.2332	Cost: 9.43s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 8.1184	Cost: 18.59s
Train Epoch: 87 	Average Loss: 8.2630
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3924

Learning rate: 0.00019996265080731267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 8.3855	Cost: 37.74s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 8.2399	Cost: 9.48s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 8.2442	Cost: 19.92s
Train Epoch: 88 	Average Loss: 8.2887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4259

Learning rate: 0.00019996178732568782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 8.2855	Cost: 39.36s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 8.2861	Cost: 9.66s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 8.1611	Cost: 19.89s
Train Epoch: 89 	Average Loss: 8.2594
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3065

Saving model as e89_model.pt & e89_waveforms_supplementary.hdf5
Learning rate: 0.00019996091397823007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 8.3773	Cost: 35.23s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 8.2297	Cost: 9.55s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 8.1105	Cost: 18.24s
Train Epoch: 90 	Average Loss: 8.2743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2930

Saving model as e90_model.pt & e90_waveforms_supplementary.hdf5
Learning rate: 0.00019996003076502562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 8.2132	Cost: 39.11s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 8.2743	Cost: 9.45s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 8.1803	Cost: 20.92s
Train Epoch: 91 	Average Loss: 8.1878
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2515

Saving model as e91_model.pt & e91_waveforms_supplementary.hdf5
Learning rate: 0.0001999591376861617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 8.2384	Cost: 38.67s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 8.1688	Cost: 9.88s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 8.0613	Cost: 19.87s
Train Epoch: 92 	Average Loss: 8.1532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1598

Saving model as e92_model.pt & e92_waveforms_supplementary.hdf5
Learning rate: 0.0001999582347417264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 8.2110	Cost: 36.36s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 8.2045	Cost: 9.45s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 8.2493	Cost: 22.13s
Train Epoch: 93 	Average Loss: 8.1951
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2034

Learning rate: 0.00019995732193180883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 8.1109	Cost: 35.55s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 8.1581	Cost: 9.59s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 8.0892	Cost: 23.46s
Train Epoch: 94 	Average Loss: 8.1507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2451

Learning rate: 0.00019995639925649909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 8.2248	Cost: 37.04s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 8.0857	Cost: 9.79s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 8.0884	Cost: 23.02s
Train Epoch: 95 	Average Loss: 8.1026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1470

Saving model as e95_model.pt & e95_waveforms_supplementary.hdf5
Learning rate: 0.00019995546671588827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 8.0049	Cost: 37.56s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 8.1481	Cost: 9.46s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 8.1156	Cost: 19.43s
Train Epoch: 96 	Average Loss: 8.1268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0392

Saving model as e96_model.pt & e96_waveforms_supplementary.hdf5
Learning rate: 0.0001999545243100684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 8.0576	Cost: 36.87s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 8.0143	Cost: 9.50s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 7.9880	Cost: 17.99s
Train Epoch: 97 	Average Loss: 8.0734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0833

Learning rate: 0.00019995357203913245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 8.0928	Cost: 36.51s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 8.1967	Cost: 9.50s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 7.9262	Cost: 17.68s
Train Epoch: 98 	Average Loss: 8.0364
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0250

Saving model as e98_model.pt & e98_waveforms_supplementary.hdf5
Learning rate: 0.00019995260990317447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 8.0527	Cost: 36.56s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 7.9922	Cost: 9.67s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 7.8898	Cost: 18.12s
Train Epoch: 99 	Average Loss: 7.9956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0380

Learning rate: 0.00019995163790228936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 7.9949	Cost: 36.64s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 8.0875	Cost: 9.79s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 7.9425	Cost: 17.51s
Train Epoch: 100 	Average Loss: 8.0642
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1394

Learning rate: 0.0001999506560365731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 8.0163	Cost: 39.82s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 7.9850	Cost: 9.79s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 7.9081	Cost: 17.31s
Train Epoch: 101 	Average Loss: 7.9944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0357

Learning rate: 0.00019994966430612258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 7.9678	Cost: 37.90s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 7.9745	Cost: 9.76s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 7.9517	Cost: 19.98s
Train Epoch: 102 	Average Loss: 7.9574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0126

Saving model as e102_model.pt & e102_waveforms_supplementary.hdf5
Learning rate: 0.00019994866271103568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 8.0756	Cost: 37.76s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 7.9079	Cost: 9.63s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 7.8948	Cost: 19.05s
Train Epoch: 103 	Average Loss: 7.8987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0416

Learning rate: 0.0001999476512514112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 7.8952	Cost: 35.22s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 7.9301	Cost: 9.79s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 7.8880	Cost: 19.48s
Train Epoch: 104 	Average Loss: 7.9019
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9849

Saving model as e104_model.pt & e104_waveforms_supplementary.hdf5
Learning rate: 0.00019994662992734905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 8.0447	Cost: 37.11s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 7.8608	Cost: 9.81s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 7.8009	Cost: 22.24s
Train Epoch: 105 	Average Loss: 7.8771
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9002

Saving model as e105_model.pt & e105_waveforms_supplementary.hdf5
Learning rate: 0.00019994559873894998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 8.0067	Cost: 36.20s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 7.8383	Cost: 9.61s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 7.8628	Cost: 24.09s
Train Epoch: 106 	Average Loss: 7.8301
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8440

Saving model as e106_model.pt & e106_waveforms_supplementary.hdf5
Learning rate: 0.00019994455768631577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 7.8366	Cost: 37.35s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 7.7779	Cost: 9.71s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 7.8295	Cost: 23.05s
Train Epoch: 107 	Average Loss: 7.8472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9605

Learning rate: 0.00019994350676954918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 7.8924	Cost: 36.49s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 7.7931	Cost: 9.63s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 7.6587	Cost: 21.14s
Train Epoch: 108 	Average Loss: 7.8042
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8287

Saving model as e108_model.pt & e108_waveforms_supplementary.hdf5
Learning rate: 0.00019994244598875392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 7.9082	Cost: 38.08s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 7.7540	Cost: 9.47s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 7.6933	Cost: 18.07s
Train Epoch: 109 	Average Loss: 7.7926
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7914

Saving model as e109_model.pt & e109_waveforms_supplementary.hdf5
Learning rate: 0.00019994137534403472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 7.8963	Cost: 38.83s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 7.7919	Cost: 9.56s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 7.7901	Cost: 20.87s
Train Epoch: 110 	Average Loss: 7.7479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8005

Learning rate: 0.00019994029483549723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 7.7489	Cost: 36.33s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 7.7809	Cost: 9.60s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 7.7591	Cost: 17.79s
Train Epoch: 111 	Average Loss: 7.7860
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7377

Saving model as e111_model.pt & e111_waveforms_supplementary.hdf5
Learning rate: 0.00019993920446324803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 7.8582	Cost: 38.04s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 7.8106	Cost: 9.92s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 7.6417	Cost: 17.54s
Train Epoch: 112 	Average Loss: 7.7598
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8469

Learning rate: 0.00019993810422739487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 7.8515	Cost: 35.71s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 7.8300	Cost: 10.21s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 7.6470	Cost: 17.15s
Train Epoch: 113 	Average Loss: 7.7319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8327

Learning rate: 0.00019993699412804622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 7.8138	Cost: 38.27s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 7.7061	Cost: 9.86s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 7.7908	Cost: 18.83s
Train Epoch: 114 	Average Loss: 7.7613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8052

Learning rate: 0.00019993587416531166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 7.8573	Cost: 38.84s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 7.7224	Cost: 9.97s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 7.5243	Cost: 20.34s
Train Epoch: 115 	Average Loss: 7.6946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7058

Saving model as e115_model.pt & e115_waveforms_supplementary.hdf5
Learning rate: 0.00019993474433930176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 7.8126	Cost: 36.75s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 7.6702	Cost: 9.69s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 7.6170	Cost: 22.27s
Train Epoch: 116 	Average Loss: 7.6480
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7019

Saving model as e116_model.pt & e116_waveforms_supplementary.hdf5
Learning rate: 0.000199933604650128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 7.7377	Cost: 35.15s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 7.6315	Cost: 9.70s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 7.5003	Cost: 23.35s
Train Epoch: 117 	Average Loss: 7.6388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6636

Saving model as e117_model.pt & e117_waveforms_supplementary.hdf5
Learning rate: 0.0001999324550979029
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 7.6814	Cost: 37.07s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 7.6635	Cost: 9.55s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 7.7642	Cost: 22.61s
Train Epoch: 118 	Average Loss: 7.6874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9378

Learning rate: 0.00019993129568273988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 7.9707	Cost: 36.98s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 7.7145	Cost: 9.48s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 7.6126	Cost: 20.56s
Train Epoch: 119 	Average Loss: 7.7053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7040

Learning rate: 0.0001999301264047534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 7.7047	Cost: 37.83s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 7.5842	Cost: 9.47s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 7.7287	Cost: 19.46s
Train Epoch: 120 	Average Loss: 7.6355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5803

Saving model as e120_model.pt & e120_waveforms_supplementary.hdf5
Learning rate: 0.00019992894726405882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 7.6224	Cost: 39.69s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 7.5610	Cost: 9.45s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 7.7336	Cost: 18.99s
Train Epoch: 121 	Average Loss: 7.5811
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7851

Learning rate: 0.00019992775826077256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 7.8408	Cost: 37.16s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 7.6947	Cost: 9.51s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 7.5186	Cost: 18.16s
Train Epoch: 122 	Average Loss: 7.6718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6964

Learning rate: 0.00019992655939501196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 7.5967	Cost: 36.06s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 7.6052	Cost: 9.66s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 7.5140	Cost: 18.23s
Train Epoch: 123 	Average Loss: 7.5462
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6703

Learning rate: 0.00019992535066689534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 7.5829	Cost: 40.42s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 7.5014	Cost: 9.77s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 7.4874	Cost: 18.83s
Train Epoch: 124 	Average Loss: 7.5634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5730

Saving model as e124_model.pt & e124_waveforms_supplementary.hdf5
Learning rate: 0.00019992413207654198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 7.5886	Cost: 34.61s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 7.5935	Cost: 9.66s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 7.7196	Cost: 17.93s
Train Epoch: 125 	Average Loss: 7.6001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6161

Learning rate: 0.0001999229036240722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 7.6921	Cost: 37.21s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 7.6814	Cost: 9.84s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 7.5567	Cost: 19.22s
Train Epoch: 126 	Average Loss: 7.5801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5608

Saving model as e126_model.pt & e126_waveforms_supplementary.hdf5
Learning rate: 0.0001999216653096072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 7.5053	Cost: 38.80s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 7.4785	Cost: 9.55s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 7.4598	Cost: 20.52s
Train Epoch: 127 	Average Loss: 7.4874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5468

Saving model as e127_model.pt & e127_waveforms_supplementary.hdf5
Learning rate: 0.00019992041713326917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 7.6100	Cost: 36.87s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 7.4776	Cost: 10.08s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 7.4029	Cost: 22.64s
Train Epoch: 128 	Average Loss: 7.4956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5380

Saving model as e128_model.pt & e128_waveforms_supplementary.hdf5
Learning rate: 0.00019991915909518135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 7.4767	Cost: 35.95s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 7.4137	Cost: 9.55s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 7.4201	Cost: 23.61s
Train Epoch: 129 	Average Loss: 7.4738
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5463

Learning rate: 0.0001999178911954679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 7.5390	Cost: 37.53s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 7.5550	Cost: 9.50s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 7.3970	Cost: 22.52s
Train Epoch: 130 	Average Loss: 7.4668
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6834

Learning rate: 0.0001999166134342539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 7.7419	Cost: 36.95s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 7.6340	Cost: 9.46s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 7.3532	Cost: 18.28s
Train Epoch: 131 	Average Loss: 7.5141
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5600

Learning rate: 0.00019991532581166554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 7.6170	Cost: 37.85s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 7.5045	Cost: 9.46s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 7.3947	Cost: 18.29s
Train Epoch: 132 	Average Loss: 7.4462
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4651

Saving model as e132_model.pt & e132_waveforms_supplementary.hdf5
Learning rate: 0.00019991402832782987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 7.5269	Cost: 37.05s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 7.3799	Cost: 9.54s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 7.3059	Cost: 18.58s
Train Epoch: 133 	Average Loss: 7.4248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4756

Learning rate: 0.00019991272098287494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 7.4334	Cost: 36.90s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 7.4398	Cost: 9.94s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 7.3657	Cost: 18.06s
Train Epoch: 134 	Average Loss: 7.4670
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4911

Learning rate: 0.00019991140377692977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 7.5402	Cost: 40.27s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 7.3586	Cost: 9.74s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 7.2944	Cost: 18.66s
Train Epoch: 135 	Average Loss: 7.3977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4998

Learning rate: 0.0001999100767101244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 7.4810	Cost: 35.23s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 7.4333	Cost: 10.23s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 7.4360	Cost: 18.22s
Train Epoch: 136 	Average Loss: 7.3818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4452

Saving model as e136_model.pt & e136_waveforms_supplementary.hdf5
Learning rate: 0.00019990873978258976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 7.4332	Cost: 38.33s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 7.3664	Cost: 9.68s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 7.3613	Cost: 20.29s
Train Epoch: 137 	Average Loss: 7.3770
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4250

Saving model as e137_model.pt & e137_waveforms_supplementary.hdf5
Learning rate: 0.0001999073929944578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 7.5033	Cost: 38.53s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 7.3204	Cost: 9.58s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 7.2747	Cost: 20.98s
Train Epoch: 138 	Average Loss: 7.3377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4348

Learning rate: 0.00019990603634586154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 7.4008	Cost: 37.55s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 7.3542	Cost: 9.94s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 7.2169	Cost: 22.28s
Train Epoch: 139 	Average Loss: 7.3270
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4417

Learning rate: 0.00019990466983693474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 7.4091	Cost: 36.33s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 7.3022	Cost: 9.62s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 7.2191	Cost: 23.97s
Train Epoch: 140 	Average Loss: 7.3193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4798

Learning rate: 0.00019990329346781236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 7.4520	Cost: 35.68s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 7.3068	Cost: 9.55s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 7.1510	Cost: 23.15s
Train Epoch: 141 	Average Loss: 7.2834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4392

Learning rate: 0.00019990190723863022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 7.5012	Cost: 36.42s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 7.2863	Cost: 9.51s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 7.1509	Cost: 21.96s
Train Epoch: 142 	Average Loss: 7.3000
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4120

Saving model as e142_model.pt & e142_waveforms_supplementary.hdf5
Learning rate: 0.00019990051114952508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 7.4764	Cost: 38.00s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 7.2565	Cost: 9.44s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 7.1927	Cost: 18.29s
Train Epoch: 143 	Average Loss: 7.3030
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5856

Learning rate: 0.0001998991052006348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 7.5575	Cost: 38.86s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 7.3151	Cost: 9.54s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 7.1546	Cost: 17.84s
Train Epoch: 144 	Average Loss: 7.3362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4695

Learning rate: 0.0001998976893920981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 7.5218	Cost: 37.30s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 7.4033	Cost: 9.66s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 7.2569	Cost: 19.55s
Train Epoch: 145 	Average Loss: 7.3413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4164

Learning rate: 0.00019989626372405477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 7.4234	Cost: 35.90s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 7.2007	Cost: 9.65s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 7.0978	Cost: 19.08s
Train Epoch: 146 	Average Loss: 7.2631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5325

Learning rate: 0.00019989482819664545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 7.4746	Cost: 38.67s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 7.2795	Cost: 10.27s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 7.1785	Cost: 19.95s
Train Epoch: 147 	Average Loss: 7.2040
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3174

Saving model as e147_model.pt & e147_waveforms_supplementary.hdf5
Learning rate: 0.00019989338281001189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 7.3426	Cost: 38.23s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 7.2404	Cost: 9.64s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 7.0812	Cost: 20.83s
Train Epoch: 148 	Average Loss: 7.2291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3153

Saving model as e148_model.pt & e148_waveforms_supplementary.hdf5
Learning rate: 0.00019989192756429667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 7.2593	Cost: 38.37s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 7.2203	Cost: 9.67s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 7.2111	Cost: 19.83s
Train Epoch: 149 	Average Loss: 7.2574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3466

Learning rate: 0.00019989046245964345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 7.3220	Cost: 36.60s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 7.2003	Cost: 9.77s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 7.1150	Cost: 21.03s
Train Epoch: 150 	Average Loss: 7.1776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2823

Saving model as e150_model.pt & e150_waveforms_supplementary.hdf5
Learning rate: 0.00019988898749619688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 7.2601	Cost: 36.72s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 7.0722	Cost: 9.82s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 7.0585	Cost: 23.18s
Train Epoch: 151 	Average Loss: 7.1724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3025

Learning rate: 0.00019988750267410245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 7.3362	Cost: 35.10s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 7.0995	Cost: 9.57s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 7.0809	Cost: 23.77s
Train Epoch: 152 	Average Loss: 7.1596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5187

Learning rate: 0.0001998860079935067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 7.3313	Cost: 36.70s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 7.1775	Cost: 9.55s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 7.0509	Cost: 23.16s
Train Epoch: 153 	Average Loss: 7.1589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2165

Saving model as e153_model.pt & e153_waveforms_supplementary.hdf5
Learning rate: 0.00019988450345455726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 7.2460	Cost: 37.36s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 7.2511	Cost: 9.47s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 7.1194	Cost: 20.09s
Train Epoch: 154 	Average Loss: 7.2059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3330

Learning rate: 0.00019988298905740252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 7.3549	Cost: 36.62s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 7.2192	Cost: 9.45s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 7.0096	Cost: 18.68s
Train Epoch: 155 	Average Loss: 7.1509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2646

Learning rate: 0.000199881464802192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 7.2900	Cost: 37.64s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 7.1849	Cost: 9.49s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 7.0986	Cost: 18.32s
Train Epoch: 156 	Average Loss: 7.1666
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2532

Learning rate: 0.0001998799306890761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 7.2885	Cost: 37.53s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 7.0815	Cost: 9.46s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 6.9103	Cost: 18.02s
Train Epoch: 157 	Average Loss: 7.0965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2154

Saving model as e157_model.pt & e157_waveforms_supplementary.hdf5
Learning rate: 0.00019987838671820622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 7.3874	Cost: 36.30s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 7.0658	Cost: 9.65s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 7.1308	Cost: 18.48s
Train Epoch: 158 	Average Loss: 7.1142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2585

Learning rate: 0.00019987683288973478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 7.2148	Cost: 36.38s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 7.1212	Cost: 9.64s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 7.0467	Cost: 17.72s
Train Epoch: 159 	Average Loss: 7.0772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2387

Learning rate: 0.00019987526920381513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 7.2380	Cost: 38.93s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 7.0966	Cost: 9.46s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 7.0847	Cost: 21.21s
Train Epoch: 160 	Average Loss: 7.0765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1594

Saving model as e160_model.pt & e160_waveforms_supplementary.hdf5
Learning rate: 0.00019987369566060162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 7.1763	Cost: 35.85s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 7.1135	Cost: 9.56s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 6.9803	Cost: 17.62s
Train Epoch: 161 	Average Loss: 7.0840
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2189

Learning rate: 0.0001998721122602495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 7.2219	Cost: 38.50s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 7.0693	Cost: 9.90s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 6.9812	Cost: 18.57s
Train Epoch: 162 	Average Loss: 7.0705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2064

Learning rate: 0.00019987051900291508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 7.2666	Cost: 35.37s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 7.0881	Cost: 9.51s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 6.9729	Cost: 19.34s
Train Epoch: 163 	Average Loss: 7.0549
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1993

Learning rate: 0.00019986891588875562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 7.0820	Cost: 35.07s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 7.0777	Cost: 10.16s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 6.8911	Cost: 19.91s
Train Epoch: 164 	Average Loss: 7.0257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2309

Learning rate: 0.0001998673029179293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 7.1604	Cost: 37.96s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 7.0330	Cost: 9.96s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 6.9990	Cost: 21.66s
Train Epoch: 165 	Average Loss: 7.0354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2298

Learning rate: 0.00019986568009059536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 7.2231	Cost: 37.29s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 7.0746	Cost: 9.75s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 6.8386	Cost: 22.97s
Train Epoch: 166 	Average Loss: 7.0119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1444

Saving model as e166_model.pt & e166_waveforms_supplementary.hdf5
Learning rate: 0.00019986404740691393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 7.2049	Cost: 36.34s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 6.9575	Cost: 9.59s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 6.9492	Cost: 23.56s
Train Epoch: 167 	Average Loss: 7.0064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1807

Learning rate: 0.00019986240486704617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 7.1392	Cost: 36.50s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 6.9659	Cost: 9.55s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 6.8389	Cost: 22.82s
Train Epoch: 168 	Average Loss: 6.9784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1432

Saving model as e168_model.pt & e168_waveforms_supplementary.hdf5
Learning rate: 0.00019986075247115415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 7.1434	Cost: 37.25s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 7.0076	Cost: 9.46s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 6.8464	Cost: 19.08s
Train Epoch: 169 	Average Loss: 6.9864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1068

Saving model as e169_model.pt & e169_waveforms_supplementary.hdf5
Learning rate: 0.00019985909021940103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 7.1175	Cost: 39.37s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 6.9504	Cost: 9.75s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 6.8527	Cost: 17.91s
Train Epoch: 170 	Average Loss: 6.9578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1007

Saving model as e170_model.pt & e170_waveforms_supplementary.hdf5
Learning rate: 0.0001998574181119508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 7.0579	Cost: 39.87s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 6.8994	Cost: 9.48s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 6.8691	Cost: 20.30s
Train Epoch: 171 	Average Loss: 6.9232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0621

Saving model as e171_model.pt & e171_waveforms_supplementary.hdf5
Learning rate: 0.00019985573614896853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 7.0759	Cost: 35.86s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 6.9137	Cost: 9.98s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 6.8264	Cost: 17.31s
Train Epoch: 172 	Average Loss: 6.9211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0480

Saving model as e172_model.pt & e172_waveforms_supplementary.hdf5
Learning rate: 0.00019985404433062024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 6.9754	Cost: 36.11s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 6.8879	Cost: 9.85s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 6.8499	Cost: 18.30s
Train Epoch: 173 	Average Loss: 6.8953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0538

Learning rate: 0.00019985234265707287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 7.0345	Cost: 38.71s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 6.8230	Cost: 9.79s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 6.8291	Cost: 20.73s
Train Epoch: 174 	Average Loss: 6.8984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0578

Learning rate: 0.00019985063112849436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 7.0513	Cost: 34.92s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 6.8174	Cost: 9.71s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 6.7899	Cost: 18.34s
Train Epoch: 175 	Average Loss: 6.8975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0050

Saving model as e175_model.pt & e175_waveforms_supplementary.hdf5
Learning rate: 0.00019984890974505368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 7.0897	Cost: 35.09s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 6.8801	Cost: 9.61s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 6.7806	Cost: 21.02s
Train Epoch: 176 	Average Loss: 6.8810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0838

Learning rate: 0.00019984717850692066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 7.0750	Cost: 35.06s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 6.9080	Cost: 9.59s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 6.8392	Cost: 22.42s
Train Epoch: 177 	Average Loss: 6.8980
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9735

Saving model as e177_model.pt & e177_waveforms_supplementary.hdf5
Learning rate: 0.00019984543741426617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 7.0879	Cost: 35.03s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 6.8180	Cost: 9.92s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 6.7138	Cost: 21.72s
Train Epoch: 178 	Average Loss: 6.8387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1083

Learning rate: 0.0001998436864672621
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 7.0263	Cost: 37.02s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 6.9722	Cost: 9.78s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 6.7645	Cost: 23.65s
Train Epoch: 179 	Average Loss: 6.8417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0233

Learning rate: 0.00019984192566608125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 6.9982	Cost: 36.11s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 6.6767	Cost: 9.53s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 6.6800	Cost: 24.35s
Train Epoch: 180 	Average Loss: 6.8256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9576

Saving model as e180_model.pt & e180_waveforms_supplementary.hdf5
Learning rate: 0.00019984015501089739
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 7.1179	Cost: 37.41s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 6.8515	Cost: 9.49s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 6.7743	Cost: 21.55s
Train Epoch: 181 	Average Loss: 6.8226
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0752

Learning rate: 0.00019983837450188524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 7.0531	Cost: 36.96s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 6.7881	Cost: 9.45s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 6.7094	Cost: 18.35s
Train Epoch: 182 	Average Loss: 6.7839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9855

Learning rate: 0.0001998365841392206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 7.0330	Cost: 38.57s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 6.8089	Cost: 9.56s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 6.7078	Cost: 19.33s
Train Epoch: 183 	Average Loss: 6.7911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9990

Learning rate: 0.00019983478392308012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 7.0671	Cost: 39.19s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 6.8467	Cost: 9.46s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 6.7162	Cost: 20.11s
Train Epoch: 184 	Average Loss: 6.7812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9374

Saving model as e184_model.pt & e184_waveforms_supplementary.hdf5
Learning rate: 0.0001998329738536415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 7.0313	Cost: 37.00s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 6.8274	Cost: 9.67s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 6.7333	Cost: 20.27s
Train Epoch: 185 	Average Loss: 6.8254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9726

Learning rate: 0.00019983115393108338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 7.0323	Cost: 36.72s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 6.7172	Cost: 9.63s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 6.6231	Cost: 20.98s
Train Epoch: 186 	Average Loss: 6.7637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8996

Saving model as e186_model.pt & e186_waveforms_supplementary.hdf5
Learning rate: 0.0001998293241555854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 6.9345	Cost: 39.11s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 6.6825	Cost: 9.57s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 6.7205	Cost: 20.40s
Train Epoch: 187 	Average Loss: 6.7481
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9680

Learning rate: 0.0001998274845273281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 7.0004	Cost: 35.09s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 6.8141	Cost: 10.07s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 6.6537	Cost: 16.96s
Train Epoch: 188 	Average Loss: 6.8248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0714

Learning rate: 0.00019982563504649309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 7.1241	Cost: 38.58s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 6.7232	Cost: 9.65s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 6.6857	Cost: 21.16s
Train Epoch: 189 	Average Loss: 6.7753
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9552

Learning rate: 0.00019982377571326284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 6.8626	Cost: 38.14s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 6.6700	Cost: 10.26s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 6.5316	Cost: 20.81s
Train Epoch: 190 	Average Loss: 6.6589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8941

Saving model as e190_model.pt & e190_waveforms_supplementary.hdf5
Learning rate: 0.00019982190652782097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 7.0079	Cost: 37.34s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 6.7185	Cost: 9.81s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 6.5238	Cost: 23.11s
Train Epoch: 191 	Average Loss: 6.6888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0096

Learning rate: 0.0001998200274903519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 7.0480	Cost: 36.44s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 6.6824	Cost: 9.60s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 6.5488	Cost: 24.28s
Train Epoch: 192 	Average Loss: 6.6867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9160

Learning rate: 0.00019981813860104106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 6.9131	Cost: 37.37s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 6.5074	Cost: 9.54s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 6.5757	Cost: 22.75s
Train Epoch: 193 	Average Loss: 6.6606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9406

Learning rate: 0.0001998162398600749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 6.8514	Cost: 36.93s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 6.6653	Cost: 9.46s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 6.6999	Cost: 20.94s
Train Epoch: 194 	Average Loss: 6.6773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9552

Learning rate: 0.00019981433126764085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 6.9003	Cost: 36.68s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 6.5758	Cost: 9.44s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 6.6074	Cost: 18.75s
Train Epoch: 195 	Average Loss: 6.6300
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8834

Saving model as e195_model.pt & e195_waveforms_supplementary.hdf5
Learning rate: 0.00019981241282392723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 6.9182	Cost: 37.27s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 6.6731	Cost: 9.52s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 6.4611	Cost: 18.25s
Train Epoch: 196 	Average Loss: 6.6237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9436

Learning rate: 0.0001998104845291234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 6.8832	Cost: 36.33s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 6.5064	Cost: 9.57s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 6.4428	Cost: 19.93s
Train Epoch: 197 	Average Loss: 6.5922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8653

Saving model as e197_model.pt & e197_waveforms_supplementary.hdf5
Learning rate: 0.00019980854638341968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 6.8533	Cost: 40.58s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 6.4501	Cost: 9.59s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 6.3950	Cost: 17.92s
Train Epoch: 198 	Average Loss: 6.5861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8536

Saving model as e198_model.pt & e198_waveforms_supplementary.hdf5
Learning rate: 0.00019980659838700736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 6.8695	Cost: 39.21s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 6.5929	Cost: 9.62s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 6.5118	Cost: 20.48s
Train Epoch: 199 	Average Loss: 6.5881
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8412

Saving model as e199_model.pt & e199_waveforms_supplementary.hdf5
Learning rate: 0.0001998046405400787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 6.7243	Cost: 35.14s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 6.5297	Cost: 9.71s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 6.4120	Cost: 17.89s
Train Epoch: 200 	Average Loss: 6.5685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8260

Saving model as e200_model.pt & e200_waveforms_supplementary.hdf5
Learning rate: 0.00019980267284282693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 6.8098	Cost: 34.98s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 6.5519	Cost: 10.11s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 6.4130	Cost: 19.98s
Train Epoch: 201 	Average Loss: 6.5461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7710

Saving model as e201_model.pt & e201_waveforms_supplementary.hdf5
Learning rate: 0.00019980069529544622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 6.6381	Cost: 37.51s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 6.5492	Cost: 9.72s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 6.5084	Cost: 22.91s
Train Epoch: 202 	Average Loss: 6.5452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9147

Learning rate: 0.0001997987078981318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 6.7032	Cost: 34.79s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 6.5015	Cost: 9.63s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 6.5041	Cost: 24.14s
Train Epoch: 203 	Average Loss: 6.5985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7867

Learning rate: 0.00019979671065107978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 6.8009	Cost: 35.69s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 6.4434	Cost: 9.53s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 6.3896	Cost: 23.43s
Train Epoch: 204 	Average Loss: 6.5160
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8013

Learning rate: 0.0001997947035544873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 6.7052	Cost: 37.25s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 6.4797	Cost: 9.50s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 6.3482	Cost: 21.33s
Train Epoch: 205 	Average Loss: 6.5185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7825

Learning rate: 0.00019979268660855247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 6.8923	Cost: 37.21s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 6.4596	Cost: 9.45s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 6.3996	Cost: 18.66s
Train Epoch: 206 	Average Loss: 6.4921
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7939

Learning rate: 0.00019979065981347432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 6.7652	Cost: 37.87s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 6.5204	Cost: 9.51s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 6.3845	Cost: 18.24s
Train Epoch: 207 	Average Loss: 6.4880
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7514

Saving model as e207_model.pt & e207_waveforms_supplementary.hdf5
Learning rate: 0.0001997886231694529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 6.9374	Cost: 36.54s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 6.6151	Cost: 9.57s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 6.3597	Cost: 17.98s
Train Epoch: 208 	Average Loss: 6.5498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7427

Saving model as e208_model.pt & e208_waveforms_supplementary.hdf5
Learning rate: 0.0001997865766766892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 6.6940	Cost: 40.27s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 6.4566	Cost: 9.84s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 6.3195	Cost: 19.08s
Train Epoch: 209 	Average Loss: 6.4472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7036

Saving model as e209_model.pt & e209_waveforms_supplementary.hdf5
Learning rate: 0.00019978452033538524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 6.7642	Cost: 36.27s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 6.4338	Cost: 10.29s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 6.3906	Cost: 17.38s
Train Epoch: 210 	Average Loss: 6.4613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7225

Learning rate: 0.00019978245414574395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 6.6464	Cost: 37.88s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 6.3972	Cost: 9.95s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 6.2740	Cost: 22.90s
Train Epoch: 211 	Average Loss: 6.4139
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6913

Saving model as e211_model.pt & e211_waveforms_supplementary.hdf5
Learning rate: 0.00019978037810796924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 6.6796	Cost: 36.37s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 6.3732	Cost: 9.67s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 6.3295	Cost: 19.20s
Train Epoch: 212 	Average Loss: 6.4256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7435

Learning rate: 0.000199778292222266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 6.7290	Cost: 39.13s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 6.4588	Cost: 9.50s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 6.2678	Cost: 22.30s
Train Epoch: 213 	Average Loss: 6.4401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7859

Learning rate: 0.00019977619648884015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 6.8317	Cost: 37.88s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 6.3582	Cost: 9.53s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 6.3148	Cost: 24.03s
Train Epoch: 214 	Average Loss: 6.4137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6921

Learning rate: 0.0001997740909078985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 6.6918	Cost: 37.31s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 6.3891	Cost: 9.57s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 6.1739	Cost: 23.59s
Train Epoch: 215 	Average Loss: 6.3355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6003

Saving model as e215_model.pt & e215_waveforms_supplementary.hdf5
Learning rate: 0.0001997719754796489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 6.6593	Cost: 37.96s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 6.3672	Cost: 10.08s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 6.2249	Cost: 20.08s
Train Epoch: 216 	Average Loss: 6.3487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6404

Learning rate: 0.00019976985020430003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 6.6245	Cost: 46.50s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 6.4567	Cost: 16.11s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 6.2163	Cost: 15.19s
Train Epoch: 217 	Average Loss: 6.3135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6487

Learning rate: 0.00019976771508206176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 6.6960	Cost: 54.37s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 6.2684	Cost: 10.02s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 6.1237	Cost: 20.16s
Train Epoch: 218 	Average Loss: 6.3237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6217

Learning rate: 0.00019976557011314476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 6.6653	Cost: 38.63s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 6.2301	Cost: 9.74s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 6.1964	Cost: 31.95s
Train Epoch: 219 	Average Loss: 6.3099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5359

Saving model as e219_model.pt & e219_waveforms_supplementary.hdf5
Learning rate: 0.00019976341529776072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 6.7847	Cost: 43.31s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 6.2567	Cost: 16.87s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 6.2291	Cost: 21.77s
Train Epoch: 220 	Average Loss: 6.3050
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6481

Learning rate: 0.00019976125063612233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 6.7148	Cost: 45.54s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 6.2172	Cost: 14.63s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 6.1004	Cost: 22.43s
Train Epoch: 221 	Average Loss: 6.2911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6629

Learning rate: 0.00019975907612844327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 6.7181	Cost: 45.16s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 6.2492	Cost: 16.48s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 6.1934	Cost: 19.07s
Train Epoch: 222 	Average Loss: 6.3004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5934

Learning rate: 0.00019975689177493812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 6.7189	Cost: 57.04s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 6.2290	Cost: 15.49s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 6.1832	Cost: 16.98s
Train Epoch: 223 	Average Loss: 6.2849
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6265

Learning rate: 0.00019975469757582245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 6.7211	Cost: 41.98s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 6.3649	Cost: 9.57s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 6.1195	Cost: 24.22s
Train Epoch: 224 	Average Loss: 6.2698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5439

Learning rate: 0.00019975249353131286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 6.5488	Cost: 38.85s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 6.5054	Cost: 11.77s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 6.1229	Cost: 21.18s
Train Epoch: 225 	Average Loss: 6.2823
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6253

Learning rate: 0.00019975027964162683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 6.6276	Cost: 38.97s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 6.2675	Cost: 11.16s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 6.0696	Cost: 31.02s
Train Epoch: 226 	Average Loss: 6.2271
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5031

Saving model as e226_model.pt & e226_waveforms_supplementary.hdf5
Learning rate: 0.0001997480559069829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 6.5209	Cost: 54.24s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 6.1359	Cost: 16.57s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 6.0570	Cost: 19.71s
Train Epoch: 227 	Average Loss: 6.2161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5456

Learning rate: 0.00019974582232760058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 6.4802	Cost: 47.14s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 6.0952	Cost: 16.55s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 6.2164	Cost: 16.43s
Train Epoch: 228 	Average Loss: 6.1270
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5175

Learning rate: 0.0001997435789037002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 6.6007	Cost: 44.12s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 6.1252	Cost: 14.63s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 6.0433	Cost: 14.78s
Train Epoch: 229 	Average Loss: 6.1988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5344

Learning rate: 0.0001997413256355033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 6.5814	Cost: 42.83s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 6.2600	Cost: 12.15s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 6.0709	Cost: 20.51s
Train Epoch: 230 	Average Loss: 6.1519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5093

Learning rate: 0.0001997390625232322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 6.5048	Cost: 41.96s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 6.1015	Cost: 16.16s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 6.0539	Cost: 18.13s
Train Epoch: 231 	Average Loss: 6.1227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5431

Learning rate: 0.00019973678956711026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 6.5217	Cost: 42.23s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 6.0174	Cost: 9.75s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 5.9346	Cost: 24.36s
Train Epoch: 232 	Average Loss: 6.1099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5312

Learning rate: 0.00019973450676736185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 6.6771	Cost: 42.57s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 6.0557	Cost: 9.74s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 6.0349	Cost: 30.78s
Train Epoch: 233 	Average Loss: 6.1053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5204

Learning rate: 0.00019973221412421225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 6.4224	Cost: 42.27s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 6.0860	Cost: 14.97s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 5.9273	Cost: 25.83s
Train Epoch: 234 	Average Loss: 6.0752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4033

Saving model as e234_model.pt & e234_waveforms_supplementary.hdf5
Learning rate: 0.0001997299116378877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 6.5208	Cost: 44.37s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 6.0722	Cost: 16.49s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 6.0172	Cost: 17.16s
Train Epoch: 235 	Average Loss: 6.0639
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4259

Learning rate: 0.0001997275993086155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 6.5130	Cost: 43.61s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 5.9237	Cost: 12.65s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 5.8958	Cost: 21.87s
Train Epoch: 236 	Average Loss: 6.0402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4043

Learning rate: 0.0001997252771366239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 6.4074	Cost: 42.39s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 6.0332	Cost: 17.27s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 5.8449	Cost: 15.79s
Train Epoch: 237 	Average Loss: 6.0362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4907

Learning rate: 0.000199722945122142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 6.3861	Cost: 44.04s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 5.9981	Cost: 9.68s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 5.8490	Cost: 25.20s
Train Epoch: 238 	Average Loss: 6.0411
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4421

Learning rate: 0.0001997206032654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 6.5127	Cost: 42.21s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 6.1227	Cost: 12.56s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 5.8842	Cost: 14.87s
Train Epoch: 239 	Average Loss: 6.0426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4758

Learning rate: 0.00019971825156662903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 6.3827	Cost: 38.70s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 6.0142	Cost: 9.75s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 5.8321	Cost: 31.59s
Train Epoch: 240 	Average Loss: 5.9955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5151

Learning rate: 0.00019971589002606117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 6.4531	Cost: 43.22s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 5.9982	Cost: 17.23s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 5.8142	Cost: 22.98s
Train Epoch: 241 	Average Loss: 5.9576
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4981

Learning rate: 0.00019971351864392958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 6.4412	Cost: 50.19s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 5.9345	Cost: 16.48s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 5.9349	Cost: 14.21s
Train Epoch: 242 	Average Loss: 5.9651
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4389

Learning rate: 0.00019971113742046817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 6.5183	Cost: 56.62s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 5.8576	Cost: 16.46s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 5.8133	Cost: 14.60s
Train Epoch: 243 	Average Loss: 5.9842
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4465

Learning rate: 0.00019970874635591207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 6.3964	Cost: 44.15s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 5.9406	Cost: 11.47s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 5.7248	Cost: 22.47s
Train Epoch: 244 	Average Loss: 5.9304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3091

Saving model as e244_model.pt & e244_waveforms_supplementary.hdf5
Learning rate: 0.00019970634545049727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 6.3593	Cost: 38.84s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 5.8159	Cost: 11.91s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 5.9506	Cost: 18.36s
Train Epoch: 245 	Average Loss: 5.9260
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4145

Learning rate: 0.0001997039347044607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 6.4280	Cost: 37.50s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 5.8431	Cost: 10.00s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 5.7503	Cost: 25.75s
Train Epoch: 246 	Average Loss: 5.8980
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4346

Learning rate: 0.00019970151411804023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 6.3774	Cost: 38.99s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 5.9117	Cost: 10.27s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 5.6914	Cost: 31.81s
Train Epoch: 247 	Average Loss: 5.9263
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3472

Learning rate: 0.00019969908369147485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 6.3334	Cost: 50.50s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 5.9620	Cost: 16.62s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 5.6604	Cost: 19.82s
Train Epoch: 248 	Average Loss: 5.8844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2992

Saving model as e248_model.pt & e248_waveforms_supplementary.hdf5
Learning rate: 0.00019969664342500438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 6.3908	Cost: 45.27s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 5.8417	Cost: 12.91s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 5.6981	Cost: 17.73s
Train Epoch: 249 	Average Loss: 5.8675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4429

Learning rate: 0.00019969419331886966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 6.4915	Cost: 42.52s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 5.7689	Cost: 13.49s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 5.6697	Cost: 17.80s
Train Epoch: 250 	Average Loss: 5.8427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2540

Saving model as e250_model.pt & e250_waveforms_supplementary.hdf5
Learning rate: 0.0001996917333733126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 6.2116	Cost: 40.12s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 5.7727	Cost: 9.63s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 5.7220	Cost: 24.58s
Train Epoch: 251 	Average Loss: 5.8056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3103

Learning rate: 0.00019968926358857587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 6.4292	Cost: 43.28s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 5.8069	Cost: 9.97s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 5.6269	Cost: 28.52s
Train Epoch: 252 	Average Loss: 5.8171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3230

Learning rate: 0.00019968678396490325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 6.2706	Cost: 46.17s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 5.6792	Cost: 17.15s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 5.6864	Cost: 21.49s
Train Epoch: 253 	Average Loss: 5.7916
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2845

Learning rate: 0.00019968429450253954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 6.2394	Cost: 44.47s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 5.7965	Cost: 16.51s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 5.5970	Cost: 16.61s
Train Epoch: 254 	Average Loss: 5.7940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2322

Saving model as e254_model.pt & e254_waveforms_supplementary.hdf5
Learning rate: 0.0001996817952017304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 6.2840	Cost: 44.24s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 5.7879	Cost: 12.38s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 5.5829	Cost: 21.21s
Train Epoch: 255 	Average Loss: 5.7524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2976

Learning rate: 0.00019967928606272244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 6.2222	Cost: 42.50s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 5.7736	Cost: 16.71s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 5.5286	Cost: 17.52s
Train Epoch: 256 	Average Loss: 5.7218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1988

Saving model as e256_model.pt & e256_waveforms_supplementary.hdf5
Learning rate: 0.0001996767670857634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 6.3274	Cost: 41.03s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 5.7224	Cost: 9.82s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 5.5263	Cost: 26.40s
Train Epoch: 257 	Average Loss: 5.6906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2080

Learning rate: 0.00019967423827110182
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 6.2190	Cost: 42.21s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 5.5668	Cost: 9.69s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 5.5590	Cost: 31.31s
Train Epoch: 258 	Average Loss: 5.6761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2298

Learning rate: 0.00019967169961898734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 6.3439	Cost: 42.94s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 5.6454	Cost: 17.24s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 5.4679	Cost: 22.37s
Train Epoch: 259 	Average Loss: 5.7008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2272

Learning rate: 0.00019966915112967047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 6.1687	Cost: 46.76s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 5.7928	Cost: 16.76s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 5.5462	Cost: 18.94s
Train Epoch: 260 	Average Loss: 5.7137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2158

Learning rate: 0.00019966659280340273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 6.3272	Cost: 44.76s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 5.5567	Cost: 13.44s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 5.4944	Cost: 18.58s
Train Epoch: 261 	Average Loss: 5.6697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2131

Learning rate: 0.00019966402464043667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 6.1129	Cost: 44.48s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 5.4899	Cost: 13.29s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 5.3595	Cost: 19.49s
Train Epoch: 262 	Average Loss: 5.6304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1046

Saving model as e262_model.pt & e262_waveforms_supplementary.hdf5
Learning rate: 0.00019966144664102572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 6.0297	Cost: 42.54s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 5.5863	Cost: 12.78s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 5.3466	Cost: 15.53s
Train Epoch: 263 	Average Loss: 5.6007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2348

Learning rate: 0.00019965885880542434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 6.1168	Cost: 38.84s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 5.5980	Cost: 9.73s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 5.5291	Cost: 31.77s
Train Epoch: 264 	Average Loss: 5.6625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1991

Learning rate: 0.00019965626113388794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 6.2441	Cost: 43.77s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 5.5251	Cost: 17.10s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 5.3727	Cost: 22.51s
Train Epoch: 265 	Average Loss: 5.5862
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1247

Learning rate: 0.00019965365362667288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 6.0963	Cost: 46.41s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 5.4830	Cost: 16.72s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 5.3468	Cost: 19.61s
Train Epoch: 266 	Average Loss: 5.5174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1311

Learning rate: 0.0001996510362840365
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 6.1234	Cost: 49.79s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 5.5436	Cost: 15.98s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 5.3297	Cost: 17.28s
Train Epoch: 267 	Average Loss: 5.5110
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2316

Learning rate: 0.00019964840910623716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 6.2441	Cost: 44.95s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 5.5200	Cost: 15.39s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 5.3962	Cost: 18.15s
Train Epoch: 268 	Average Loss: 5.5293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1453

Learning rate: 0.00019964577209353413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 6.0874	Cost: 42.90s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 5.4982	Cost: 9.53s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 5.4071	Cost: 24.10s
Train Epoch: 269 	Average Loss: 5.5580
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1590

Learning rate: 0.00019964312524618766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 6.0223	Cost: 37.35s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 5.4686	Cost: 12.89s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 5.2890	Cost: 20.52s
Train Epoch: 270 	Average Loss: 5.4728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9975

Saving model as e270_model.pt & e270_waveforms_supplementary.hdf5
Learning rate: 0.000199640468564459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 5.9976	Cost: 43.46s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 5.3508	Cost: 9.73s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 5.1498	Cost: 32.94s
Train Epoch: 271 	Average Loss: 5.4200
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9579

Saving model as e271_model.pt & e271_waveforms_supplementary.hdf5
Learning rate: 0.00019963780204861037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 6.0720	Cost: 45.99s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 5.6381	Cost: 15.04s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 5.3273	Cost: 17.50s
Train Epoch: 272 	Average Loss: 5.4798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0709

Learning rate: 0.0001996351256989049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 5.9364	Cost: 45.19s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 5.4475	Cost: 16.23s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 5.2738	Cost: 16.68s
Train Epoch: 273 	Average Loss: 5.4465
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9711

Learning rate: 0.0001996324395156068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 5.9128	Cost: 44.50s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 5.3736	Cost: 16.25s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 5.3157	Cost: 17.45s
Train Epoch: 274 	Average Loss: 5.4012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0068

Learning rate: 0.00019962974349898107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 5.9572	Cost: 43.12s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 5.3814	Cost: 15.17s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 5.1579	Cost: 19.41s
Train Epoch: 275 	Average Loss: 5.3946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0312

Learning rate: 0.0001996270376492939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 6.0368	Cost: 42.81s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 5.3874	Cost: 9.75s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 5.1375	Cost: 24.39s
Train Epoch: 276 	Average Loss: 5.3489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9736

Learning rate: 0.00019962432196681234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 5.9748	Cost: 41.97s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 5.2038	Cost: 9.82s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 5.1945	Cost: 30.63s
Train Epoch: 277 	Average Loss: 5.3385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9359

Saving model as e277_model.pt & e277_waveforms_supplementary.hdf5
Learning rate: 0.00019962159645180437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 5.9074	Cost: 44.68s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 5.2362	Cost: 16.72s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 5.1747	Cost: 20.20s
Train Epoch: 278 	Average Loss: 5.3184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8846

Saving model as e278_model.pt & e278_waveforms_supplementary.hdf5
Learning rate: 0.00019961886110453903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 5.9267	Cost: 44.79s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 5.2576	Cost: 16.67s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 5.1631	Cost: 17.66s
Train Epoch: 279 	Average Loss: 5.3249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1338

Learning rate: 0.00019961611592528625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 5.9505	Cost: 42.39s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 5.2375	Cost: 13.92s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 5.1138	Cost: 20.44s
Train Epoch: 280 	Average Loss: 5.3036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9293

Learning rate: 0.000199613360914317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 5.8375	Cost: 43.22s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 5.2128	Cost: 16.15s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 5.0778	Cost: 17.44s
Train Epoch: 281 	Average Loss: 5.2875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9938

Learning rate: 0.00019961059607190318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 5.8994	Cost: 42.16s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 5.3428	Cost: 9.67s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 5.1587	Cost: 23.88s
Train Epoch: 282 	Average Loss: 5.3158
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0613

Learning rate: 0.00019960782139831766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 5.8958	Cost: 39.59s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 5.1897	Cost: 13.10s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 5.0689	Cost: 16.36s
Train Epoch: 283 	Average Loss: 5.2636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9368

Learning rate: 0.00019960503689383428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 5.9740	Cost: 36.39s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 5.1601	Cost: 12.76s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 5.2168	Cost: 14.24s
Train Epoch: 284 	Average Loss: 5.2290
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9601

Learning rate: 0.0001996022425587279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 5.9372	Cost: 37.91s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 5.1015	Cost: 10.77s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 5.0132	Cost: 29.56s
Train Epoch: 285 	Average Loss: 5.1856
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8920

Learning rate: 0.0001995994383932743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 5.8250	Cost: 41.88s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 5.1359	Cost: 12.33s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 5.0832	Cost: 27.09s
Train Epoch: 286 	Average Loss: 5.1841
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8980

Learning rate: 0.0001995966243977502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 5.8442	Cost: 46.33s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 5.0958	Cost: 13.45s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 5.1188	Cost: 20.69s
Train Epoch: 287 	Average Loss: 5.1962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8763

Saving model as e287_model.pt & e287_waveforms_supplementary.hdf5
Learning rate: 0.0001995938005724334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 5.7938	Cost: 45.79s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 5.1180	Cost: 14.98s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 5.0241	Cost: 14.11s
Train Epoch: 288 	Average Loss: 5.1491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8676

Saving model as e288_model.pt & e288_waveforms_supplementary.hdf5
Learning rate: 0.00019959096691760252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 5.8439	Cost: 42.11s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 5.0526	Cost: 13.20s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 4.9679	Cost: 17.12s
Train Epoch: 289 	Average Loss: 5.1371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7950

Saving model as e289_model.pt & e289_waveforms_supplementary.hdf5
Learning rate: 0.00019958812343353726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 5.7323	Cost: 42.93s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 5.0765	Cost: 12.20s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 4.9152	Cost: 22.48s
Train Epoch: 290 	Average Loss: 5.0899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8028

Learning rate: 0.0001995852701205183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 5.8121	Cost: 40.94s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 5.1279	Cost: 12.81s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 4.8650	Cost: 20.11s
Train Epoch: 291 	Average Loss: 5.1044
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8166

Learning rate: 0.0001995824069788272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 5.7153	Cost: 41.32s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 4.9802	Cost: 10.41s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 4.8554	Cost: 29.40s
Train Epoch: 292 	Average Loss: 5.0477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8234

Learning rate: 0.00019957953400874656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 5.8034	Cost: 40.40s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 5.0539	Cost: 15.99s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 4.8278	Cost: 21.98s
Train Epoch: 293 	Average Loss: 5.0450
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8554

Learning rate: 0.00019957665121055995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 5.8936	Cost: 47.18s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 5.0137	Cost: 17.03s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 4.7460	Cost: 17.25s
Train Epoch: 294 	Average Loss: 5.0078
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7826

Saving model as e294_model.pt & e294_waveforms_supplementary.hdf5
Learning rate: 0.00019957375858455185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 5.7571	Cost: 46.38s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 4.9279	Cost: 12.36s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 4.7382	Cost: 21.00s
Train Epoch: 295 	Average Loss: 4.9788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7043

Saving model as e295_model.pt & e295_waveforms_supplementary.hdf5
Learning rate: 0.00019957085613100776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 5.7281	Cost: 42.99s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 5.0805	Cost: 16.18s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 4.7386	Cost: 17.31s
Train Epoch: 296 	Average Loss: 4.9770
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7447

Learning rate: 0.00019956794385021415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 5.8466	Cost: 43.52s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 4.8787	Cost: 9.68s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 4.7469	Cost: 22.03s
Train Epoch: 297 	Average Loss: 4.9765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7307

Learning rate: 0.00019956502174245846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 5.7238	Cost: 40.01s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 4.9014	Cost: 9.85s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 4.6684	Cost: 30.02s
Train Epoch: 298 	Average Loss: 4.9459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8175

Learning rate: 0.0001995620898080291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 5.9030	Cost: 43.30s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 4.8721	Cost: 17.09s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 4.6586	Cost: 20.41s
Train Epoch: 299 	Average Loss: 4.9342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6901

Saving model as e299_model.pt & e299_waveforms_supplementary.hdf5
Learning rate: 0.00019955914804721542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 5.6723	Cost: 44.17s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 4.8182	Cost: 16.82s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 4.8008	Cost: 17.48s
Train Epoch: 300 	Average Loss: 4.8949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7586

Learning rate: 0.00019955619646030775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 5.8017	Cost: 44.07s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 4.8639	Cost: 13.59s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 4.6387	Cost: 18.75s
Train Epoch: 301 	Average Loss: 4.9010
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6370

Saving model as e301_model.pt & e301_waveforms_supplementary.hdf5
Learning rate: 0.0001995532350475974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 5.5954	Cost: 43.27s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 4.7491	Cost: 11.75s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 4.6686	Cost: 22.81s
Train Epoch: 302 	Average Loss: 4.8449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6689

Learning rate: 0.00019955026380937669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 5.6803	Cost: 47.21s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 4.8318	Cost: 12.79s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 4.6576	Cost: 17.22s
Train Epoch: 303 	Average Loss: 4.8690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7686

Learning rate: 0.00019954728274593884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 5.6225	Cost: 38.71s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 4.7995	Cost: 12.85s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 4.6022	Cost: 17.55s
Train Epoch: 304 	Average Loss: 4.8559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6298

Saving model as e304_model.pt & e304_waveforms_supplementary.hdf5
Learning rate: 0.00019954429185757805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 5.6169	Cost: 37.18s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 4.8210	Cost: 10.25s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 4.5903	Cost: 33.09s
Train Epoch: 305 	Average Loss: 4.8351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6593

Learning rate: 0.00019954129114458955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 5.6537	Cost: 43.22s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 4.7784	Cost: 13.51s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 4.5873	Cost: 28.62s
Train Epoch: 306 	Average Loss: 4.8352
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5832

Saving model as e306_model.pt & e306_waveforms_supplementary.hdf5
Learning rate: 0.00019953828060726943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 5.5928	Cost: 55.36s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 4.6133	Cost: 12.82s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 4.4720	Cost: 16.39s
Train Epoch: 307 	Average Loss: 4.7341
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5190

Saving model as e307_model.pt & e307_waveforms_supplementary.hdf5
Learning rate: 0.00019953526024591494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 5.4884	Cost: 45.92s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 4.6418	Cost: 16.43s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 4.4423	Cost: 15.56s
Train Epoch: 308 	Average Loss: 4.6797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5605

Learning rate: 0.00019953223006082406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 5.6334	Cost: 44.35s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 4.6174	Cost: 12.11s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 4.5778	Cost: 21.83s
Train Epoch: 309 	Average Loss: 4.7385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5203

Learning rate: 0.00019952919005229592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 5.5564	Cost: 38.98s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 4.6709	Cost: 12.80s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 4.6498	Cost: 21.04s
Train Epoch: 310 	Average Loss: 4.7205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5614

Learning rate: 0.00019952614022063054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 5.5980	Cost: 37.95s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 4.6144	Cost: 9.82s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 4.5091	Cost: 32.02s
Train Epoch: 311 	Average Loss: 4.6942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6768

Learning rate: 0.00019952308056612892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 5.5777	Cost: 42.39s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 4.5566	Cost: 14.82s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 4.4124	Cost: 22.95s
Train Epoch: 312 	Average Loss: 4.6306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5041

Saving model as e312_model.pt & e312_waveforms_supplementary.hdf5
Learning rate: 0.00019952001108909304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 5.7133	Cost: 45.69s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 4.5449	Cost: 16.91s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 4.4045	Cost: 17.47s
Train Epoch: 313 	Average Loss: 4.6630
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4812

Saving model as e313_model.pt & e313_waveforms_supplementary.hdf5
Learning rate: 0.00019951693178982586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 5.4387	Cost: 43.74s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 4.6472	Cost: 12.33s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 4.3998	Cost: 18.70s
Train Epoch: 314 	Average Loss: 4.6323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6018

Learning rate: 0.00019951384266863126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 5.6118	Cost: 42.61s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 4.5664	Cost: 16.54s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 4.2670	Cost: 16.64s
Train Epoch: 315 	Average Loss: 4.6106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5439

Learning rate: 0.00019951074372581416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 5.4735	Cost: 41.52s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 4.5148	Cost: 11.38s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 4.4314	Cost: 25.10s
Train Epoch: 316 	Average Loss: 4.6002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4494

Saving model as e316_model.pt & e316_waveforms_supplementary.hdf5
Learning rate: 0.00019950763496168037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 5.4736	Cost: 44.71s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 4.5467	Cost: 12.68s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 4.3304	Cost: 17.98s
Train Epoch: 317 	Average Loss: 4.5616
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4906

Learning rate: 0.00019950451637653678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 5.5337	Cost: 39.85s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 4.4752	Cost: 9.95s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 4.2859	Cost: 31.34s
Train Epoch: 318 	Average Loss: 4.5493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4066

Saving model as e318_model.pt & e318_waveforms_supplementary.hdf5
Learning rate: 0.00019950138797069118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 5.3438	Cost: 42.68s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 4.4824	Cost: 15.24s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 4.3813	Cost: 21.94s
Train Epoch: 319 	Average Loss: 4.5274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4783

Learning rate: 0.00019949824974445222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 5.3718	Cost: 45.03s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 4.4480	Cost: 16.77s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 4.2472	Cost: 17.80s
Train Epoch: 320 	Average Loss: 4.5096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3721

Saving model as e320_model.pt & e320_waveforms_supplementary.hdf5
Learning rate: 0.00019949510169812976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 5.4539	Cost: 44.89s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 4.3855	Cost: 16.70s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 4.2466	Cost: 15.00s
Train Epoch: 321 	Average Loss: 4.4609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4463

Learning rate: 0.00019949194383203438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 5.4115	Cost: 42.96s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 4.6642	Cost: 9.60s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 4.2315	Cost: 24.17s
Train Epoch: 322 	Average Loss: 4.4913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3950

Learning rate: 0.00019948877614647787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 5.2204	Cost: 41.53s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 4.3247	Cost: 9.81s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 4.1949	Cost: 30.85s
Train Epoch: 323 	Average Loss: 4.3889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3294

Saving model as e323_model.pt & e323_waveforms_supplementary.hdf5
Learning rate: 0.0001994855986417728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 5.2724	Cost: 43.84s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 4.4760	Cost: 17.15s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 4.2422	Cost: 19.86s
Train Epoch: 324 	Average Loss: 4.4161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3831

Learning rate: 0.0001994824113182328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 5.3610	Cost: 44.53s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 4.2811	Cost: 16.60s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 4.1369	Cost: 19.05s
Train Epoch: 325 	Average Loss: 4.3733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3560

Learning rate: 0.00019947921417617242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 5.4359	Cost: 45.22s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 4.4662	Cost: 12.57s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 4.0708	Cost: 20.89s
Train Epoch: 326 	Average Loss: 4.3587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4056

Learning rate: 0.0001994760072159072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 5.5586	Cost: 42.29s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 4.2956	Cost: 16.26s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 4.1431	Cost: 17.15s
Train Epoch: 327 	Average Loss: 4.3747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3063

Saving model as e327_model.pt & e327_waveforms_supplementary.hdf5
Learning rate: 0.00019947279043775368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 5.2759	Cost: 47.35s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 4.3761	Cost: 9.69s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 4.2026	Cost: 21.70s
Train Epoch: 328 	Average Loss: 4.3654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4589

Learning rate: 0.00019946956384202932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 5.2623	Cost: 41.74s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 4.2922	Cost: 12.69s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 4.0244	Cost: 18.03s
Train Epoch: 329 	Average Loss: 4.3274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2961

Saving model as e329_model.pt & e329_waveforms_supplementary.hdf5
Learning rate: 0.00019946632742905265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 5.3179	Cost: 39.57s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 4.2389	Cost: 9.76s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 4.0899	Cost: 29.76s
Train Epoch: 330 	Average Loss: 4.2894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2300

Saving model as e330_model.pt & e330_waveforms_supplementary.hdf5
Learning rate: 0.000199463081199143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 5.2875	Cost: 45.50s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 4.2859	Cost: 15.41s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 4.1212	Cost: 22.16s
Train Epoch: 331 	Average Loss: 4.2981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2370

Learning rate: 0.0001994598251526208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 5.1456	Cost: 45.27s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 4.2944	Cost: 17.13s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 3.9886	Cost: 13.40s
Train Epoch: 332 	Average Loss: 4.2216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2445

Learning rate: 0.00019945655928980737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 5.0699	Cost: 51.59s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 4.3444	Cost: 13.06s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 4.1591	Cost: 18.59s
Train Epoch: 333 	Average Loss: 4.2643
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2271

Saving model as e333_model.pt & e333_waveforms_supplementary.hdf5
Learning rate: 0.0001994532836110251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 5.3005	Cost: 40.06s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 4.1889	Cost: 12.79s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 4.0402	Cost: 16.29s
Train Epoch: 334 	Average Loss: 4.2324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1767

Saving model as e334_model.pt & e334_waveforms_supplementary.hdf5
Learning rate: 0.00019944999811659725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 5.2181	Cost: 40.84s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 4.0551	Cost: 11.23s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 3.9726	Cost: 19.19s
Train Epoch: 335 	Average Loss: 4.2013
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1805

Learning rate: 0.00019944670280684805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 5.2538	Cost: 35.70s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 4.1146	Cost: 9.61s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 3.9208	Cost: 25.96s
Train Epoch: 336 	Average Loss: 4.1652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1685

Saving model as e336_model.pt & e336_waveforms_supplementary.hdf5
Learning rate: 0.00019944339768210285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 4.9265	Cost: 39.36s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 4.0227	Cost: 11.29s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 3.9564	Cost: 30.01s
Train Epoch: 337 	Average Loss: 4.1276
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1023

Saving model as e337_model.pt & e337_waveforms_supplementary.hdf5
Learning rate: 0.0001994400827426877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 5.2421	Cost: 45.85s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 3.9842	Cost: 15.47s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 3.9152	Cost: 21.65s
Train Epoch: 338 	Average Loss: 4.1333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2212

Learning rate: 0.0001994367579889299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 5.1025	Cost: 53.11s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 4.0014	Cost: 16.70s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 3.8729	Cost: 14.81s
Train Epoch: 339 	Average Loss: 4.0927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1568

Learning rate: 0.0001994334234211575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 5.0863	Cost: 44.65s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 4.0143	Cost: 14.17s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 3.8042	Cost: 17.09s
Train Epoch: 340 	Average Loss: 4.0613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0463

Saving model as e340_model.pt & e340_waveforms_supplementary.hdf5
Learning rate: 0.00019943007903969968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 5.0281	Cost: 41.27s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 4.0564	Cost: 9.54s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 3.8941	Cost: 23.29s
Train Epoch: 341 	Average Loss: 4.0823
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1324

Learning rate: 0.00019942672484488645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 5.2075	Cost: 40.23s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 3.9807	Cost: 12.68s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 3.8136	Cost: 19.51s
Train Epoch: 342 	Average Loss: 4.0575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0622

Learning rate: 0.0001994233608370489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 5.2137	Cost: 40.93s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 4.0180	Cost: 10.10s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 3.6791	Cost: 31.05s
Train Epoch: 343 	Average Loss: 4.0205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0914

Learning rate: 0.00019941998701651908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 4.9759	Cost: 43.28s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 3.9275	Cost: 13.32s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 3.7367	Cost: 24.79s
Train Epoch: 344 	Average Loss: 4.0142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1961

Learning rate: 0.00019941660338362987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 5.1563	Cost: 45.99s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 3.8973	Cost: 16.74s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 3.7290	Cost: 16.40s
Train Epoch: 345 	Average Loss: 3.9710
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9977

Saving model as e345_model.pt & e345_waveforms_supplementary.hdf5
Learning rate: 0.0001994132099387153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 4.9093	Cost: 44.81s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 3.8462	Cost: 11.77s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 3.6066	Cost: 19.05s
Train Epoch: 346 	Average Loss: 3.9264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0700

Learning rate: 0.00019940980668211027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 5.0297	Cost: 42.64s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 3.8585	Cost: 16.07s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 3.6839	Cost: 12.93s
Train Epoch: 347 	Average Loss: 3.9125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9572

Saving model as e347_model.pt & e347_waveforms_supplementary.hdf5
Learning rate: 0.00019940639361415064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 4.8638	Cost: 39.44s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 3.8966	Cost: 9.55s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 3.6112	Cost: 23.07s
Train Epoch: 348 	Average Loss: 3.8833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9180

Saving model as e348_model.pt & e348_waveforms_supplementary.hdf5
Learning rate: 0.00019940297073517331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 4.9465	Cost: 38.12s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 3.7775	Cost: 10.04s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 3.6617	Cost: 31.14s
Train Epoch: 349 	Average Loss: 3.8802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9780

Learning rate: 0.00019939953804551608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 5.0325	Cost: 42.90s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 3.8168	Cost: 17.56s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 3.6101	Cost: 20.87s
Train Epoch: 350 	Average Loss: 3.8872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9977

Learning rate: 0.00019939609554551777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 4.8956	Cost: 46.94s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 3.7289	Cost: 17.06s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 3.6192	Cost: 16.97s
Train Epoch: 351 	Average Loss: 3.8602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9456

Learning rate: 0.0001993926432355181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 4.8792	Cost: 44.52s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 3.7834	Cost: 14.81s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 3.5646	Cost: 18.37s
Train Epoch: 352 	Average Loss: 3.8280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0138

Learning rate: 0.00019938918111585784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 4.9914	Cost: 41.92s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 3.7746	Cost: 16.38s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 3.5816	Cost: 17.91s
Train Epoch: 353 	Average Loss: 3.8071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8669

Saving model as e353_model.pt & e353_waveforms_supplementary.hdf5
Learning rate: 0.00019938570918687863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 5.0210	Cost: 40.63s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 3.7008	Cost: 9.68s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 3.5082	Cost: 26.57s
Train Epoch: 354 	Average Loss: 3.7721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8959

Learning rate: 0.0001993822274489232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 4.8128	Cost: 41.47s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 3.7713	Cost: 12.67s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 3.5424	Cost: 18.09s
Train Epoch: 355 	Average Loss: 3.7695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9387

Learning rate: 0.00019937873590233516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 4.8976	Cost: 43.30s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 3.6830	Cost: 10.01s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 3.6400	Cost: 30.79s
Train Epoch: 356 	Average Loss: 3.7528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9837

Learning rate: 0.0001993752345474591
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 4.9795	Cost: 41.77s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 3.6438	Cost: 17.02s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 3.3498	Cost: 19.63s
Train Epoch: 357 	Average Loss: 3.7079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8889

Learning rate: 0.0001993717233846406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 4.8529	Cost: 46.04s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 3.6459	Cost: 16.55s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 3.3537	Cost: 18.33s
Train Epoch: 358 	Average Loss: 3.6649
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9207

Learning rate: 0.0001993682024142262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 4.8399	Cost: 45.10s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 3.7507	Cost: 13.94s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 3.5385	Cost: 17.54s
Train Epoch: 359 	Average Loss: 3.7119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9251

Learning rate: 0.00019936467163656337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 4.9505	Cost: 45.58s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 3.6748	Cost: 15.83s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 3.4294	Cost: 19.00s
Train Epoch: 360 	Average Loss: 3.7102
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8271

Saving model as e360_model.pt & e360_waveforms_supplementary.hdf5
Learning rate: 0.00019936113105200064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 4.8098	Cost: 41.49s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 3.5962	Cost: 9.75s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 3.3463	Cost: 21.21s
Train Epoch: 361 	Average Loss: 3.5925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8367

Learning rate: 0.00019935758066088742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 4.8787	Cost: 42.31s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 3.5082	Cost: 10.01s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 3.3393	Cost: 28.99s
Train Epoch: 362 	Average Loss: 3.5986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9411

Learning rate: 0.00019935402046357414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 4.8973	Cost: 45.60s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 3.5815	Cost: 16.97s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 3.2999	Cost: 21.17s
Train Epoch: 363 	Average Loss: 3.6192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8287

Learning rate: 0.00019935045046041218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 4.7091	Cost: 44.46s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 3.5020	Cost: 16.46s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 3.2099	Cost: 17.81s
Train Epoch: 364 	Average Loss: 3.5169
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7670

Saving model as e364_model.pt & e364_waveforms_supplementary.hdf5
Learning rate: 0.00019934687065175386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 4.6773	Cost: 43.99s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 3.4592	Cost: 16.80s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 3.3355	Cost: 16.87s
Train Epoch: 365 	Average Loss: 3.5875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8558

Learning rate: 0.00019934328103795248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 4.7975	Cost: 43.59s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 3.4572	Cost: 16.16s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 3.2288	Cost: 16.58s
Train Epoch: 366 	Average Loss: 3.5732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6727

Saving model as e366_model.pt & e366_waveforms_supplementary.hdf5
Learning rate: 0.00019933968161936236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 4.7216	Cost: 41.53s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 3.6418	Cost: 9.70s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 3.2254	Cost: 22.79s
Train Epoch: 367 	Average Loss: 3.5662
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7945

Learning rate: 0.00019933607239633875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 4.7338	Cost: 42.33s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 3.4144	Cost: 11.06s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 3.1891	Cost: 27.23s
Train Epoch: 368 	Average Loss: 3.5048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7284

Learning rate: 0.00019933245336923783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 4.6606	Cost: 39.27s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 3.4714	Cost: 9.59s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 3.2100	Cost: 35.54s
Train Epoch: 369 	Average Loss: 3.4969
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6757

Learning rate: 0.0001993288245384168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 4.5764	Cost: 44.16s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 3.3451	Cost: 16.16s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 3.2906	Cost: 20.83s
Train Epoch: 370 	Average Loss: 3.4588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6558

Saving model as e370_model.pt & e370_waveforms_supplementary.hdf5
Learning rate: 0.00019932518590423377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 4.5201	Cost: 44.31s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 3.3216	Cost: 14.61s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 3.2373	Cost: 16.28s
Train Epoch: 371 	Average Loss: 3.4298
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6519

Saving model as e371_model.pt & e371_waveforms_supplementary.hdf5
Learning rate: 0.00019932153746704794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 4.7038	Cost: 56.69s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 3.3135	Cost: 13.55s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 2.9993	Cost: 16.45s
Train Epoch: 372 	Average Loss: 3.3781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5370

Saving model as e372_model.pt & e372_waveforms_supplementary.hdf5
Learning rate: 0.00019931787922721937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 4.6299	Cost: 40.73s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 3.2774	Cost: 9.58s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 3.1140	Cost: 22.22s
Train Epoch: 373 	Average Loss: 3.3682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5830

Learning rate: 0.00019931421118510906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 4.5863	Cost: 40.00s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 3.2668	Cost: 10.12s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 3.0499	Cost: 30.34s
Train Epoch: 374 	Average Loss: 3.3493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6589

Learning rate: 0.0001993105333410791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 4.4196	Cost: 44.13s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 3.3502	Cost: 17.53s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 3.0862	Cost: 23.15s
Train Epoch: 375 	Average Loss: 3.3724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6311

Learning rate: 0.00019930684569549248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 4.5525	Cost: 52.41s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 3.2722	Cost: 15.75s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 3.1133	Cost: 14.72s
Train Epoch: 376 	Average Loss: 3.3245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5711

Learning rate: 0.0001993031482487131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 4.4481	Cost: 52.14s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 3.2114	Cost: 14.62s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 3.0826	Cost: 14.94s
Train Epoch: 377 	Average Loss: 3.2881
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6026

Learning rate: 0.0001992994410011059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 4.3431	Cost: 46.03s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 3.2125	Cost: 15.14s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 3.0108	Cost: 15.52s
Train Epoch: 378 	Average Loss: 3.2561
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5633

Learning rate: 0.00019929572395303678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 4.5645	Cost: 43.44s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 3.2663	Cost: 9.64s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 2.9419	Cost: 24.81s
Train Epoch: 379 	Average Loss: 3.2532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4968

Saving model as e379_model.pt & e379_waveforms_supplementary.hdf5
Learning rate: 0.0001992919971048726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 4.5208	Cost: 39.20s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 3.1836	Cost: 9.94s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 2.9576	Cost: 24.08s
Train Epoch: 380 	Average Loss: 3.2563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4439

Saving model as e380_model.pt & e380_waveforms_supplementary.hdf5
Learning rate: 0.0001992882604569812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 4.4205	Cost: 37.49s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 3.1043	Cost: 11.32s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 3.0306	Cost: 28.18s
Train Epoch: 381 	Average Loss: 3.2351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4506

Learning rate: 0.00019928451400973133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 4.5113	Cost: 48.64s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 3.1359	Cost: 16.66s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 2.9513	Cost: 22.64s
Train Epoch: 382 	Average Loss: 3.2086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5872

Learning rate: 0.0001992807577634928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 4.5204	Cost: 53.13s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 3.1194	Cost: 16.39s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 2.8473	Cost: 16.42s
Train Epoch: 383 	Average Loss: 3.1949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5397

Learning rate: 0.00019927699171863632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 4.4519	Cost: 47.99s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 3.0077	Cost: 14.84s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 2.9022	Cost: 14.62s
Train Epoch: 384 	Average Loss: 3.1660
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4391

Saving model as e384_model.pt & e384_waveforms_supplementary.hdf5
Learning rate: 0.00019927321587553357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 4.5048	Cost: 43.82s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 3.0018	Cost: 16.85s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 2.8837	Cost: 12.58s
Train Epoch: 385 	Average Loss: 3.1442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5096

Learning rate: 0.00019926943023455717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 4.3925	Cost: 42.20s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 2.9877	Cost: 14.43s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 2.8081	Cost: 19.47s
Train Epoch: 386 	Average Loss: 3.0679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3051

Saving model as e386_model.pt & e386_waveforms_supplementary.hdf5
Learning rate: 0.00019926563479608086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 4.4938	Cost: 39.88s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 3.0865	Cost: 9.82s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 2.7941	Cost: 25.93s
Train Epoch: 387 	Average Loss: 3.0711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4599

Learning rate: 0.00019926182956047912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 4.3041	Cost: 42.85s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 2.9938	Cost: 9.61s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 2.7262	Cost: 30.13s
Train Epoch: 388 	Average Loss: 3.0424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4153

Learning rate: 0.00019925801452812757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 4.3383	Cost: 43.99s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 2.9943	Cost: 14.64s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 2.6576	Cost: 27.77s
Train Epoch: 389 	Average Loss: 3.0127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4360

Learning rate: 0.00019925418969940278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 4.3841	Cost: 43.77s
Train Epoch: 390 [40960/90000 (45%)]	Loss: 2.9076	Cost: 16.09s
Train Epoch: 390 [81920/90000 (91%)]	Loss: 2.7763	Cost: 17.29s
Train Epoch: 390 	Average Loss: 3.0063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4005

Learning rate: 0.00019925035507468219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 4.3001	Cost: 45.45s
Train Epoch: 391 [40960/90000 (45%)]	Loss: 2.9462	Cost: 16.82s
Train Epoch: 391 [81920/90000 (91%)]	Loss: 2.7824	Cost: 15.57s
Train Epoch: 391 	Average Loss: 2.9745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3116

Learning rate: 0.00019924651065434423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 4.2516	Cost: 42.96s
Train Epoch: 392 [40960/90000 (45%)]	Loss: 2.9651	Cost: 13.39s
Train Epoch: 392 [81920/90000 (91%)]	Loss: 2.6803	Cost: 21.03s
Train Epoch: 392 	Average Loss: 2.9802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3022

Saving model as e392_model.pt & e392_waveforms_supplementary.hdf5
Learning rate: 0.0001992426564387684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 4.4021	Cost: 43.26s
Train Epoch: 393 [40960/90000 (45%)]	Loss: 2.9880	Cost: 9.72s
Train Epoch: 393 [81920/90000 (91%)]	Loss: 2.6425	Cost: 27.00s
Train Epoch: 393 	Average Loss: 2.9341
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3361

Learning rate: 0.00019923879242833502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 4.1818	Cost: 42.99s
Train Epoch: 394 [40960/90000 (45%)]	Loss: 2.8671	Cost: 9.64s
Train Epoch: 394 [81920/90000 (91%)]	Loss: 2.6068	Cost: 30.65s
Train Epoch: 394 	Average Loss: 2.9012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3065

Learning rate: 0.00019923491862342552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 4.1143	Cost: 42.73s
Train Epoch: 395 [40960/90000 (45%)]	Loss: 2.8281	Cost: 15.48s
Train Epoch: 395 [81920/90000 (91%)]	Loss: 2.5527	Cost: 24.94s
Train Epoch: 395 	Average Loss: 2.8946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3110

Learning rate: 0.0001992310350244222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 4.1653	Cost: 44.55s
Train Epoch: 396 [40960/90000 (45%)]	Loss: 2.8817	Cost: 16.49s
Train Epoch: 396 [81920/90000 (91%)]	Loss: 2.6141	Cost: 17.26s
Train Epoch: 396 	Average Loss: 2.9702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3017

Saving model as e396_model.pt & e396_waveforms_supplementary.hdf5
Learning rate: 0.0001992271416317084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 4.3546	Cost: 42.78s
Train Epoch: 397 [40960/90000 (45%)]	Loss: 2.8627	Cost: 13.64s
Train Epoch: 397 [81920/90000 (91%)]	Loss: 2.8116	Cost: 20.92s
Train Epoch: 397 	Average Loss: 3.0032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3502

Learning rate: 0.0001992232384456683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 4.3862	Cost: 42.28s
Train Epoch: 398 [40960/90000 (45%)]	Loss: 2.8230	Cost: 15.47s
Train Epoch: 398 [81920/90000 (91%)]	Loss: 2.6573	Cost: 19.32s
Train Epoch: 398 	Average Loss: 2.9171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2930

Saving model as e398_model.pt & e398_waveforms_supplementary.hdf5
Learning rate: 0.00019921932546668718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 4.2032	Cost: 45.72s
Train Epoch: 399 [40960/90000 (45%)]	Loss: 2.8106	Cost: 12.54s
Train Epoch: 399 [81920/90000 (91%)]	Loss: 2.4595	Cost: 18.15s
Train Epoch: 399 	Average Loss: 2.8725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2159

Saving model as e399_model.pt & e399_waveforms_supplementary.hdf5
Learning rate: 0.00019921540269515121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 4.1084	Cost: 40.53s
Train Epoch: 400 [40960/90000 (45%)]	Loss: 2.7701	Cost: 9.96s
Train Epoch: 400 [81920/90000 (91%)]	Loss: 2.4730	Cost: 32.37s
Train Epoch: 400 	Average Loss: 2.7718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1031

Saving model as e400_model.pt & e400_waveforms_supplementary.hdf5
Stopping timer.
Training time (including validation): 51297.82214593887 seconds
Saving model
Transfer learning by starting with alpha=0.8!
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 50.2654	Cost: 46.45s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 23.6729	Cost: 10.87s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 18.9074	Cost: 26.25s
Train Epoch: 1 	Average Loss: 26.2569
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6440

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999691576447898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 18.2197	Cost: 51.98s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 15.5991	Cost: 14.26s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 14.1116	Cost: 15.81s
Train Epoch: 2 	Average Loss: 15.7214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1559

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 13.8609	Cost: 47.73s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 12.3778	Cost: 9.80s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 11.6639	Cost: 20.96s
Train Epoch: 3 	Average Loss: 12.6098
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5532

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 11.3836	Cost: 38.95s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 11.0434	Cost: 9.60s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 10.5491	Cost: 24.75s
Train Epoch: 4 	Average Loss: 10.9221
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6683

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.00019995065603657316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 10.8966	Cost: 38.22s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 10.0607	Cost: 9.91s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 9.9188	Cost: 25.93s
Train Epoch: 5 	Average Loss: 10.1925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8329

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.0001999229036240723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 9.8497	Cost: 39.76s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 9.3321	Cost: 15.05s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 9.4875	Cost: 18.88s
Train Epoch: 6 	Average Loss: 9.4568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1598

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019988898749619702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 9.2075	Cost: 40.05s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 9.1374	Cost: 14.10s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 8.6965	Cost: 15.29s
Train Epoch: 7 	Average Loss: 9.0489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7953

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.00019984890974505381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 9.3531	Cost: 40.26s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 8.4972	Cost: 9.57s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 8.3131	Cost: 18.60s
Train Epoch: 8 	Average Loss: 8.6335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2904

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.00019980267284282717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 8.6675	Cost: 36.88s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 8.1504	Cost: 11.11s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 8.2041	Cost: 30.77s
Train Epoch: 9 	Average Loss: 8.2973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1374

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019975027964162705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 8.2573	Cost: 47.86s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 7.9791	Cost: 16.54s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 8.0672	Cost: 20.25s
Train Epoch: 10 	Average Loss: 8.0561
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0469

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 0.00019969173337331284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 8.5483	Cost: 46.12s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 7.8581	Cost: 16.78s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 7.8832	Cost: 13.03s
Train Epoch: 11 	Average Loss: 7.9674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9671

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 0.00019962703764929416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 8.1401	Cost: 46.99s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 7.6777	Cost: 9.85s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 7.6115	Cost: 21.73s
Train Epoch: 12 	Average Loss: 7.6606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5230

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 0.00019955619646030802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 7.7248	Cost: 37.48s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 7.5120	Cost: 9.81s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 7.3789	Cost: 27.34s
Train Epoch: 13 	Average Loss: 7.4698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5773

Learning rate: 0.00019947921417617267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 7.8415	Cost: 38.81s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 7.2287	Cost: 13.73s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 7.2277	Cost: 23.53s
Train Epoch: 14 	Average Loss: 7.3839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4191

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Learning rate: 0.000199396095545518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 7.7852	Cost: 38.13s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 7.3170	Cost: 17.24s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 7.4315	Cost: 16.68s
Train Epoch: 15 	Average Loss: 7.2978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3397

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Learning rate: 0.00019930684569549264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 7.5136	Cost: 41.28s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 6.8175	Cost: 13.39s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 6.9336	Cost: 15.40s
Train Epoch: 16 	Average Loss: 7.1912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3668

Learning rate: 0.0001992114701314478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 7.4780	Cost: 42.44s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 6.8462	Cost: 16.14s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 6.9359	Cost: 14.89s
Train Epoch: 17 	Average Loss: 6.9998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1166

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Learning rate: 0.00019910997473659747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 7.1845	Cost: 37.31s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 6.7904	Cost: 9.76s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 6.8525	Cost: 25.39s
Train Epoch: 18 	Average Loss: 6.8951
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0791

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Learning rate: 0.00019900236577165574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 6.9403	Cost: 45.73s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 6.8276	Cost: 9.91s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 6.7783	Cost: 28.11s
Train Epoch: 19 	Average Loss: 6.8073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8943

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Learning rate: 0.00019888864987445046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 7.4741	Cost: 44.28s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 6.4478	Cost: 14.44s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 6.5606	Cost: 18.14s
Train Epoch: 20 	Average Loss: 6.7179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8572

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Learning rate: 0.00019876883405951377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 7.0714	Cost: 48.72s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 6.6233	Cost: 15.08s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 6.3726	Cost: 12.94s
Train Epoch: 21 	Average Loss: 6.6253
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7199

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Learning rate: 0.00019864292571764955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 6.9994	Cost: 41.52s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 6.4046	Cost: 13.62s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 6.4059	Cost: 18.52s
Train Epoch: 22 	Average Loss: 6.4773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7208

Learning rate: 0.0001985109326154774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 7.1117	Cost: 39.41s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 6.2742	Cost: 12.76s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 6.5187	Cost: 14.27s
Train Epoch: 23 	Average Loss: 6.4289
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7631

Learning rate: 0.00019837286289495361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 6.8287	Cost: 34.55s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 6.2733	Cost: 9.94s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 6.2422	Cost: 28.91s
Train Epoch: 24 	Average Loss: 6.3819
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5009

Saving model as e24_model.pt & e24_waveforms_supplementary.hdf5
Learning rate: 0.0001982287250728689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 6.8578	Cost: 35.15s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 6.2229	Cost: 15.15s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 6.3969	Cost: 26.54s
Train Epoch: 25 	Average Loss: 6.2562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6794

Learning rate: 0.00019807852804032305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 6.8951	Cost: 45.93s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 6.1225	Cost: 16.71s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 6.3719	Cost: 16.62s
Train Epoch: 26 	Average Loss: 6.2693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5220

Learning rate: 0.00019792228106217658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 6.6858	Cost: 50.83s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 6.0459	Cost: 12.23s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 6.1927	Cost: 21.33s
Train Epoch: 27 	Average Loss: 6.1813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3720

Saving model as e27_model.pt & e27_waveforms_supplementary.hdf5
Learning rate: 0.0001977599937764791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 6.8393	Cost: 40.87s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 6.0513	Cost: 11.12s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 5.9290	Cost: 21.07s
Train Epoch: 28 	Average Loss: 6.0562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2380

Saving model as e28_model.pt & e28_waveforms_supplementary.hdf5
Learning rate: 0.00019759167619387474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 6.7168	Cost: 37.14s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 6.0875	Cost: 10.00s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 6.1126	Cost: 23.15s
Train Epoch: 29 	Average Loss: 5.9767
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3191

Learning rate: 0.00019741733869698495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 6.6741	Cost: 42.39s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 5.8175	Cost: 16.93s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 5.7248	Cost: 17.34s
Train Epoch: 30 	Average Loss: 5.9618
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3665

Learning rate: 0.00019723699203976766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 6.5860	Cost: 38.79s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 5.8372	Cost: 13.83s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 5.8526	Cost: 18.18s
Train Epoch: 31 	Average Loss: 5.9432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2256

Saving model as e31_model.pt & e31_waveforms_supplementary.hdf5
Learning rate: 0.00019705064734685425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 6.6038	Cost: 39.85s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 5.7350	Cost: 15.70s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 5.8579	Cost: 14.00s
Train Epoch: 32 	Average Loss: 5.8481
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2526

Learning rate: 0.00019685831611286313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 6.5902	Cost: 42.39s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 5.6056	Cost: 16.46s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 5.9142	Cost: 13.64s
Train Epoch: 33 	Average Loss: 5.8293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2076

Saving model as e33_model.pt & e33_waveforms_supplementary.hdf5
Learning rate: 0.00019666001020169073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 6.2467	Cost: 38.47s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 5.5299	Cost: 9.85s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 5.8378	Cost: 24.18s
Train Epoch: 34 	Average Loss: 5.8377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1332

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Learning rate: 0.0001964557418457798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 6.3346	Cost: 41.97s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 5.5917	Cost: 11.39s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 5.6070	Cost: 25.24s
Train Epoch: 35 	Average Loss: 5.6639
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1151

Saving model as e35_model.pt & e35_waveforms_supplementary.hdf5
Learning rate: 0.0001962455236453647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 6.3694	Cost: 45.67s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 5.3023	Cost: 9.95s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 5.6936	Cost: 25.46s
Train Epoch: 36 	Average Loss: 5.6611
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0858

Saving model as e36_model.pt & e36_waveforms_supplementary.hdf5
Learning rate: 0.00019602936856769428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 6.3902	Cost: 43.61s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 5.4314	Cost: 15.32s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 5.4809	Cost: 17.98s
Train Epoch: 37 	Average Loss: 5.5970
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1090

Learning rate: 0.0001958072899462319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 6.1018	Cost: 40.11s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 5.3807	Cost: 16.54s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 5.5094	Cost: 18.28s
Train Epoch: 38 	Average Loss: 5.5244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9466

Saving model as e38_model.pt & e38_waveforms_supplementary.hdf5
Learning rate: 0.00019557930147983297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 6.1936	Cost: 38.47s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 5.5453	Cost: 16.77s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 5.4012	Cost: 17.34s
Train Epoch: 39 	Average Loss: 5.5264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9010

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Learning rate: 0.00019534541723190008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 6.3458	Cost: 43.90s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 5.3042	Cost: 13.58s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 5.3206	Cost: 13.53s
Train Epoch: 40 	Average Loss: 5.4568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9753

Learning rate: 0.00019510565162951532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 6.0852	Cost: 35.51s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 5.4166	Cost: 12.99s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 5.8847	Cost: 20.39s
Train Epoch: 41 	Average Loss: 5.4305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1221

Learning rate: 0.0001948600194625504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 6.1002	Cost: 38.29s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 5.6202	Cost: 10.75s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 5.3539	Cost: 30.98s
Train Epoch: 42 	Average Loss: 5.4119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9840

Learning rate: 0.00019460853588275446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 6.0983	Cost: 47.59s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 5.4316	Cost: 15.32s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 5.2700	Cost: 20.59s
Train Epoch: 43 	Average Loss: 5.4249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8645

Saving model as e43_model.pt & e43_waveforms_supplementary.hdf5
Learning rate: 0.0001943512164028193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 5.9819	Cost: 48.48s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 5.3067	Cost: 15.67s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 5.2338	Cost: 15.48s
Train Epoch: 44 	Average Loss: 5.3118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7861

Saving model as e44_model.pt & e44_waveforms_supplementary.hdf5
Learning rate: 0.00019408807689542249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 5.9865	Cost: 46.77s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 5.0610	Cost: 9.91s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 5.0063	Cost: 19.99s
Train Epoch: 45 	Average Loss: 5.2150
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7434

Saving model as e45_model.pt & e45_waveforms_supplementary.hdf5
Learning rate: 0.00019381913359224837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 5.7879	Cost: 39.50s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 4.9861	Cost: 9.84s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 5.1582	Cost: 25.08s
Train Epoch: 46 	Average Loss: 5.1887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8011

Learning rate: 0.0001935444030829867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 5.8059	Cost: 39.00s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 4.8600	Cost: 9.76s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 4.9838	Cost: 25.03s
Train Epoch: 47 	Average Loss: 5.1566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7678

Learning rate: 0.00019326390231430937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 5.7945	Cost: 45.22s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 4.9531	Cost: 15.64s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 5.0206	Cost: 18.22s
Train Epoch: 48 	Average Loss: 5.1350
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7273

Saving model as e48_model.pt & e48_waveforms_supplementary.hdf5
Learning rate: 0.00019297764858882508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 5.6548	Cost: 38.70s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 5.0058	Cost: 16.65s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 5.1424	Cost: 16.59s
Train Epoch: 49 	Average Loss: 5.0693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8442

Learning rate: 0.000192685659564012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 6.0351	Cost: 39.86s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 4.8998	Cost: 12.47s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 4.8432	Cost: 15.92s
Train Epoch: 50 	Average Loss: 5.0892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7488

Learning rate: 0.00019238795325112859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 5.9469	Cost: 39.97s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 4.7635	Cost: 12.62s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 4.9198	Cost: 16.14s
Train Epoch: 51 	Average Loss: 5.0022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5791

Saving model as e51_model.pt & e51_waveforms_supplementary.hdf5
Learning rate: 0.00019208454801410258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 6.0602	Cost: 36.54s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 4.8986	Cost: 11.67s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 4.9183	Cost: 25.11s
Train Epoch: 52 	Average Loss: 4.9151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5404

Saving model as e52_model.pt & e52_waveforms_supplementary.hdf5
Learning rate: 0.00019177546256839804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 5.7912	Cost: 41.27s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 4.6752	Cost: 9.90s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 4.9113	Cost: 23.36s
Train Epoch: 53 	Average Loss: 4.8673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6621

Learning rate: 0.0001914607159798613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 5.8763	Cost: 42.52s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 4.7786	Cost: 16.84s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 4.9282	Cost: 19.58s
Train Epoch: 54 	Average Loss: 4.8482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5664

Learning rate: 0.00019114032766354445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 5.6745	Cost: 47.02s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 4.5673	Cost: 15.74s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 4.9932	Cost: 16.88s
Train Epoch: 55 	Average Loss: 4.8272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5587

Learning rate: 0.00019081431738250806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 5.7006	Cost: 51.27s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 4.5304	Cost: 13.61s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 4.7704	Cost: 16.08s
Train Epoch: 56 	Average Loss: 4.7936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6739

Learning rate: 0.00019048270524660188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 5.6990	Cost: 50.19s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 4.4806	Cost: 11.83s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 4.9541	Cost: 19.28s
Train Epoch: 57 	Average Loss: 4.8295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6489

Learning rate: 0.0001901455117112245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 5.6873	Cost: 36.94s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 4.7749	Cost: 9.72s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 4.6144	Cost: 22.30s
Train Epoch: 58 	Average Loss: 4.8041
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5194

Saving model as e58_model.pt & e58_waveforms_supplementary.hdf5
Learning rate: 0.0001898027575760615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 5.8027	Cost: 38.46s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 4.6600	Cost: 9.82s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 4.6249	Cost: 27.48s
Train Epoch: 59 	Average Loss: 4.7510
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4251

Saving model as e59_model.pt & e59_waveforms_supplementary.hdf5
Learning rate: 0.00018945446398380245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 5.6303	Cost: 37.32s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 4.2908	Cost: 17.50s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 4.5928	Cost: 22.91s
Train Epoch: 60 	Average Loss: 4.6467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3758

Saving model as e60_model.pt & e60_waveforms_supplementary.hdf5
Learning rate: 0.00018910065241883672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 5.6000	Cost: 37.38s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 4.4888	Cost: 16.79s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 4.5124	Cost: 21.41s
Train Epoch: 61 	Average Loss: 4.6212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4680

Learning rate: 0.00018874134470592827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 5.4480	Cost: 43.84s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 4.4755	Cost: 10.11s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 4.6902	Cost: 30.19s
Train Epoch: 62 	Average Loss: 4.5683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4408

Learning rate: 0.0001883765630088693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 5.6436	Cost: 46.24s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 4.4470	Cost: 9.98s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 4.4740	Cost: 27.10s
Train Epoch: 63 	Average Loss: 4.6090
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4344

Learning rate: 0.00018800632982911313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 5.4679	Cost: 45.19s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 4.2782	Cost: 13.91s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 4.4434	Cost: 21.25s
Train Epoch: 64 	Average Loss: 4.4652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3173

Saving model as e64_model.pt & e64_waveforms_supplementary.hdf5
Learning rate: 0.00018763066800438628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 5.2919	Cost: 39.53s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 4.4696	Cost: 14.00s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 4.3827	Cost: 20.92s
Train Epoch: 65 	Average Loss: 4.5116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2670

Saving model as e65_model.pt & e65_waveforms_supplementary.hdf5
Learning rate: 0.00018724960070727966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 5.7279	Cost: 37.20s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 4.2826	Cost: 13.35s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 4.5001	Cost: 13.52s
Train Epoch: 66 	Average Loss: 4.4202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2039

Saving model as e66_model.pt & e66_waveforms_supplementary.hdf5
Learning rate: 0.00018686315144381908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 5.5798	Cost: 37.52s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 4.2907	Cost: 10.62s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 4.4442	Cost: 16.16s
Train Epoch: 67 	Average Loss: 4.3967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2932

Learning rate: 0.00018647134405201546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 5.5720	Cost: 36.24s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 4.2115	Cost: 13.15s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 4.4962	Cost: 19.37s
Train Epoch: 68 	Average Loss: 4.4122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3800

Learning rate: 0.00018607420270039433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 5.4673	Cost: 38.94s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 4.3410	Cost: 11.34s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 4.1820	Cost: 27.62s
Train Epoch: 69 	Average Loss: 4.4328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2817

Learning rate: 0.00018567175188650495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 5.1912	Cost: 47.14s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 4.3012	Cost: 16.88s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 4.4630	Cost: 19.63s
Train Epoch: 70 	Average Loss: 4.4391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2790

Learning rate: 0.0001852640164354092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 5.4775	Cost: 45.65s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 4.1823	Cost: 12.59s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 4.2374	Cost: 21.23s
Train Epoch: 71 	Average Loss: 4.3125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1719

Saving model as e71_model.pt & e71_waveforms_supplementary.hdf5
Learning rate: 0.00018485102149815036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 5.1764	Cost: 53.36s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 4.1032	Cost: 15.37s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 4.2376	Cost: 11.59s
Train Epoch: 72 	Average Loss: 4.2432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2187

Learning rate: 0.0001844327925502015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 5.5040	Cost: 48.83s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 4.0890	Cost: 16.87s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 4.1866	Cost: 14.94s
Train Epoch: 73 	Average Loss: 4.2327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2313

Learning rate: 0.00018400935538989417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 5.2153	Cost: 48.05s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 4.0268	Cost: 9.78s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 4.1088	Cost: 19.99s
Train Epoch: 74 	Average Loss: 4.2130
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1486

Saving model as e74_model.pt & e74_waveforms_supplementary.hdf5
Learning rate: 0.00018358073613682703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 5.3171	Cost: 37.78s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 3.7311	Cost: 10.68s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 4.0615	Cost: 21.33s
Train Epoch: 75 	Average Loss: 4.1547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1466

Saving model as e75_model.pt & e75_waveforms_supplementary.hdf5
Learning rate: 0.00018314696123025452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 5.4520	Cost: 34.64s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 3.8168	Cost: 10.09s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 4.3156	Cost: 23.97s
Train Epoch: 76 	Average Loss: 4.1826
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1210

Saving model as e76_model.pt & e76_waveforms_supplementary.hdf5
Learning rate: 0.00018270805742745614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 5.3641	Cost: 36.30s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 3.8251	Cost: 15.41s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 4.0419	Cost: 21.36s
Train Epoch: 77 	Average Loss: 4.1218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0933

Saving model as e77_model.pt & e77_waveforms_supplementary.hdf5
Learning rate: 0.00018226405180208597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 5.2081	Cost: 42.94s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 3.7998	Cost: 16.18s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 4.1879	Cost: 16.50s
Train Epoch: 78 	Average Loss: 4.0873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2406

Learning rate: 0.00018181497174250233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 5.3984	Cost: 42.15s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 3.8916	Cost: 15.71s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 3.8711	Cost: 14.92s
Train Epoch: 79 	Average Loss: 4.1244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9919

Saving model as e79_model.pt & e79_waveforms_supplementary.hdf5
Learning rate: 0.00018136084495007872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 5.1367	Cost: 41.63s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 3.6800	Cost: 17.02s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 4.2199	Cost: 15.39s
Train Epoch: 80 	Average Loss: 4.0552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0209

Learning rate: 0.00018090169943749476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 5.3410	Cost: 38.88s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 3.7983	Cost: 9.92s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 4.0388	Cost: 24.50s
Train Epoch: 81 	Average Loss: 4.0211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0103

Learning rate: 0.00018043756352700846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 5.0677	Cost: 40.25s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 3.6999	Cost: 12.91s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 4.0610	Cost: 21.13s
Train Epoch: 82 	Average Loss: 3.9430
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0507

Learning rate: 0.00017996846584870908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 5.1514	Cost: 41.52s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 3.5847	Cost: 9.95s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 3.8737	Cost: 26.97s
Train Epoch: 83 	Average Loss: 3.8998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9384

Saving model as e83_model.pt & e83_waveforms_supplementary.hdf5
Learning rate: 0.000179494435338751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 5.4007	Cost: 44.97s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 3.7600	Cost: 14.71s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 3.7847	Cost: 18.88s
Train Epoch: 84 	Average Loss: 3.9037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8964

Saving model as e84_model.pt & e84_waveforms_supplementary.hdf5
Learning rate: 0.00017901550123756904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 5.4156	Cost: 42.14s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 3.5552	Cost: 16.67s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 3.8011	Cost: 15.28s
Train Epoch: 85 	Average Loss: 3.8544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8591

Saving model as e85_model.pt & e85_waveforms_supplementary.hdf5
Learning rate: 0.00017853169308807448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 5.2391	Cost: 46.67s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 3.4982	Cost: 10.83s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 3.8543	Cost: 22.08s
Train Epoch: 86 	Average Loss: 3.8466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9420

Learning rate: 0.00017804304073383296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 5.2933	Cost: 36.29s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 3.7653	Cost: 11.16s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 3.7319	Cost: 19.22s
Train Epoch: 87 	Average Loss: 3.8631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9141

Learning rate: 0.00017754957431722346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 4.8938	Cost: 36.97s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 3.5888	Cost: 9.94s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 3.5605	Cost: 27.55s
Train Epoch: 88 	Average Loss: 3.7485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9796

Learning rate: 0.00017705132427757892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 4.7620	Cost: 34.65s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 3.4944	Cost: 15.33s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 3.6833	Cost: 19.85s
Train Epoch: 89 	Average Loss: 3.7219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7923

Saving model as e89_model.pt & e89_waveforms_supplementary.hdf5
Learning rate: 0.00017654832134930882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 4.9723	Cost: 35.88s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 3.4759	Cost: 13.32s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 3.7913	Cost: 25.27s
Train Epoch: 90 	Average Loss: 3.6538
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8719

Learning rate: 0.0001760405965600031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 5.1209	Cost: 40.70s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 3.2628	Cost: 17.00s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 3.5725	Cost: 20.72s
Train Epoch: 91 	Average Loss: 3.6706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8301

Learning rate: 0.00017552818122851838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 4.8847	Cost: 40.64s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 3.5889	Cost: 9.77s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 3.6046	Cost: 23.84s
Train Epoch: 92 	Average Loss: 3.6245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7138

Saving model as e92_model.pt & e92_waveforms_supplementary.hdf5
Learning rate: 0.00017501110696304596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 5.0341	Cost: 42.54s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 3.3595	Cost: 9.87s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 3.7487	Cost: 25.28s
Train Epoch: 93 	Average Loss: 3.6332
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7754

Learning rate: 0.0001744894056591622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 5.0401	Cost: 42.31s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 3.2860	Cost: 16.82s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 3.4660	Cost: 18.07s
Train Epoch: 94 	Average Loss: 3.5545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7848

Learning rate: 0.00017396310949786096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 4.8497	Cost: 37.61s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 3.3801	Cost: 15.60s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 3.6240	Cost: 17.89s
Train Epoch: 95 	Average Loss: 3.5222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6151

Saving model as e95_model.pt & e95_waveforms_supplementary.hdf5
Learning rate: 0.00017343225094356858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 5.0003	Cost: 41.60s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 3.3333	Cost: 16.48s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 3.5485	Cost: 9.75s
Train Epoch: 96 	Average Loss: 3.5606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7177

Learning rate: 0.00017289686274214118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 4.9319	Cost: 41.52s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 3.2540	Cost: 9.58s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 3.5063	Cost: 19.37s
Train Epoch: 97 	Average Loss: 3.5112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7238

Learning rate: 0.00017235697791884494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 4.9161	Cost: 38.34s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 3.3432	Cost: 10.53s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 3.3818	Cost: 28.55s
Train Epoch: 98 	Average Loss: 3.5301
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7893

Learning rate: 0.0001718126297763189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 4.7764	Cost: 39.81s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 3.3005	Cost: 11.53s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 3.1945	Cost: 25.70s
Train Epoch: 99 	Average Loss: 3.5021
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7949

Learning rate: 0.00017126385189252056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 4.9084	Cost: 60.42s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 2.9645	Cost: 14.30s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 3.4777	Cost: 14.60s
Train Epoch: 100 	Average Loss: 3.4225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7123

Learning rate: 0.00017071067811865479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 4.5808	Cost: 54.60s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 3.2521	Cost: 13.51s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 3.2029	Cost: 16.75s
Train Epoch: 101 	Average Loss: 3.4112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7263

Learning rate: 0.00017015314257708562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 4.6998	Cost: 38.33s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 2.9627	Cost: 9.61s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 3.3464	Cost: 21.07s
Train Epoch: 102 	Average Loss: 3.3270
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6434

Learning rate: 0.00016959127965923145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 4.7422	Cost: 36.99s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 3.1718	Cost: 10.04s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 3.2075	Cost: 22.65s
Train Epoch: 103 	Average Loss: 3.3565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6587

Learning rate: 0.00016902512402344375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 4.5888	Cost: 37.77s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 3.0520	Cost: 11.85s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 3.1137	Cost: 24.41s
Train Epoch: 104 	Average Loss: 3.2935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6318

Learning rate: 0.0001684547105928689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 4.7164	Cost: 38.94s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 2.9648	Cost: 14.90s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 3.2209	Cost: 22.26s
Train Epoch: 105 	Average Loss: 3.3139
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6384

Learning rate: 0.00016788007455329423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 4.5395	Cost: 38.69s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 3.1015	Cost: 16.91s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 3.1291	Cost: 15.98s
Train Epoch: 106 	Average Loss: 3.2894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5815

Saving model as e106_model.pt & e106_waveforms_supplementary.hdf5
Learning rate: 0.00016730125135097737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 4.6943	Cost: 38.81s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 2.9477	Cost: 13.42s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 3.1584	Cost: 22.82s
Train Epoch: 107 	Average Loss: 3.2143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6150

Learning rate: 0.00016671827669046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 4.5399	Cost: 40.00s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 2.8027	Cost: 9.99s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 3.0438	Cost: 26.62s
Train Epoch: 108 	Average Loss: 3.1801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6024

Learning rate: 0.0001661311865323652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 4.6667	Cost: 46.27s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 3.0098	Cost: 9.86s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 3.0536	Cost: 28.11s
Train Epoch: 109 	Average Loss: 3.1738
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4465

Saving model as e109_model.pt & e109_waveforms_supplementary.hdf5
Learning rate: 0.00016554001709117943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 4.7470	Cost: 40.87s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 3.0274	Cost: 13.41s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 2.9732	Cost: 22.87s
Train Epoch: 110 	Average Loss: 3.1475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6637

Learning rate: 0.00016494480483301838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 4.8401	Cost: 41.70s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 2.9182	Cost: 14.88s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 2.9697	Cost: 19.00s
Train Epoch: 111 	Average Loss: 3.1136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4619

Learning rate: 0.0001643455864733779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 4.5367	Cost: 37.97s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 2.8649	Cost: 13.18s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 3.1184	Cost: 14.08s
Train Epoch: 112 	Average Loss: 3.0958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5098

Learning rate: 0.000163742398974869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 4.7707	Cost: 36.26s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 2.9121	Cost: 13.15s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 3.1237	Cost: 14.23s
Train Epoch: 113 	Average Loss: 3.1773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5430

Learning rate: 0.00016313527954493778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 4.6351	Cost: 37.95s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 2.7583	Cost: 11.97s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 2.8361	Cost: 15.17s
Train Epoch: 114 	Average Loss: 3.0291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3605

Saving model as e114_model.pt & e114_waveforms_supplementary.hdf5
Learning rate: 0.00016252426563357055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 4.6475	Cost: 35.17s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 2.6586	Cost: 13.03s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 2.8368	Cost: 22.13s
Train Epoch: 115 	Average Loss: 2.9852
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5693

Learning rate: 0.0001619093949309834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 4.3995	Cost: 39.06s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 2.8471	Cost: 11.01s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 2.8865	Cost: 27.28s
Train Epoch: 116 	Average Loss: 2.9611
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4662

Learning rate: 0.00016129070536529766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 4.4667	Cost: 40.57s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 2.8318	Cost: 10.55s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 2.7434	Cost: 28.50s
Train Epoch: 117 	Average Loss: 2.9843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5470

Learning rate: 0.00016066823510019996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 4.4381	Cost: 46.92s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 2.7474	Cost: 13.19s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 2.9711	Cost: 22.03s
Train Epoch: 118 	Average Loss: 3.0343
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3963

Learning rate: 0.0001600420225325884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 4.3146	Cost: 49.66s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 2.6837	Cost: 16.94s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 3.0222	Cost: 15.71s
Train Epoch: 119 	Average Loss: 2.9532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3620

Learning rate: 0.00015941210629020385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 4.3930	Cost: 60.01s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 2.5637	Cost: 9.71s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 2.8429	Cost: 19.83s
Train Epoch: 120 	Average Loss: 2.9090
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3430

Saving model as e120_model.pt & e120_waveforms_supplementary.hdf5
Learning rate: 0.00015877852522924735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 4.4964	Cost: 36.91s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 2.6850	Cost: 9.72s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 2.7400	Cost: 26.70s
Train Epoch: 121 	Average Loss: 2.9162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4451

Learning rate: 0.00015814131843198305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 4.2224	Cost: 38.19s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 2.4789	Cost: 10.16s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 2.6590	Cost: 26.32s
Train Epoch: 122 	Average Loss: 2.7932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4549

Learning rate: 0.00015750052520432787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 4.2054	Cost: 37.32s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 2.5088	Cost: 14.17s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 2.5414	Cost: 18.97s
Train Epoch: 123 	Average Loss: 2.7839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2069

Saving model as e123_model.pt & e123_waveforms_supplementary.hdf5
Learning rate: 0.0001568561850734264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 4.2839	Cost: 38.80s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 2.6444	Cost: 16.48s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 2.6417	Cost: 16.78s
Train Epoch: 124 	Average Loss: 2.7370
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3783

Learning rate: 0.00015620833778521307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 4.3254	Cost: 41.08s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 2.4854	Cost: 15.66s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 2.7202	Cost: 14.30s
Train Epoch: 125 	Average Loss: 2.7538
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1391

Saving model as e125_model.pt & e125_waveforms_supplementary.hdf5
Learning rate: 0.00015555702330196023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 4.1127	Cost: 41.05s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 2.2764	Cost: 13.33s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 2.6500	Cost: 16.73s
Train Epoch: 126 	Average Loss: 2.7126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1224

Saving model as e126_model.pt & e126_waveforms_supplementary.hdf5
Learning rate: 0.00015490228179981317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 4.3225	Cost: 36.39s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 2.4684	Cost: 10.74s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 2.5448	Cost: 23.13s
Train Epoch: 127 	Average Loss: 2.6781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2062

Learning rate: 0.00015424415366631188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 4.4244	Cost: 41.44s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 2.4941	Cost: 10.29s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 2.8178	Cost: 27.22s
Train Epoch: 128 	Average Loss: 2.7717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2540

Learning rate: 0.00015358267949789966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 4.6913	Cost: 46.16s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 2.6259	Cost: 14.14s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 2.6857	Cost: 22.09s
Train Epoch: 129 	Average Loss: 2.7937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3399

Learning rate: 0.00015291790009741904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 4.4909	Cost: 43.16s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 2.4304	Cost: 14.85s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 2.7165	Cost: 19.43s
Train Epoch: 130 	Average Loss: 2.7467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2125

Learning rate: 0.00015224985647159487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 4.2608	Cost: 44.13s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 2.4299	Cost: 13.90s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 2.7641	Cost: 13.37s
Train Epoch: 131 	Average Loss: 2.6586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2590

Learning rate: 0.00015157858982850473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 4.4709	Cost: 45.89s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 2.3814	Cost: 16.44s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 2.2851	Cost: 13.33s
Train Epoch: 132 	Average Loss: 2.5867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3005

Learning rate: 0.0001509041415750371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 4.0608	Cost: 43.88s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 2.2605	Cost: 11.01s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 2.3778	Cost: 19.11s
Train Epoch: 133 	Average Loss: 2.4987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1164

Saving model as e133_model.pt & e133_waveforms_supplementary.hdf5
Learning rate: 0.00015022655331433721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 4.0199	Cost: 38.46s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 2.1596	Cost: 9.87s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 2.3610	Cost: 21.85s
Train Epoch: 134 	Average Loss: 2.4483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1542

Learning rate: 0.00014954586684324072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 4.1812	Cost: 37.20s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 2.1489	Cost: 9.80s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 2.3455	Cost: 28.11s
Train Epoch: 135 	Average Loss: 2.4180
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0570

Saving model as e135_model.pt & e135_waveforms_supplementary.hdf5
Learning rate: 0.00014886212414969547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 4.1596	Cost: 42.04s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 2.0700	Cost: 13.93s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 2.3067	Cost: 23.49s
Train Epoch: 136 	Average Loss: 2.3872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1023

Learning rate: 0.0001481753674101715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 4.2699	Cost: 40.32s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 2.3824	Cost: 13.50s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 2.4520	Cost: 25.09s
Train Epoch: 137 	Average Loss: 2.5012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2285

Learning rate: 0.00014748563898705943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 4.2918	Cost: 39.51s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 2.1366	Cost: 9.93s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 2.2678	Cost: 26.09s
Train Epoch: 138 	Average Loss: 2.4417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0718

Learning rate: 0.00014679298142605734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 4.2523	Cost: 41.48s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 2.0867	Cost: 11.62s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 2.3180	Cost: 20.28s
Train Epoch: 139 	Average Loss: 2.3890
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1943

Learning rate: 0.00014609743745354624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 3.9555	Cost: 38.19s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 2.1777	Cost: 9.91s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 2.2865	Cost: 26.27s
Train Epoch: 140 	Average Loss: 2.4080
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8973

Saving model as e140_model.pt & e140_waveforms_supplementary.hdf5
Learning rate: 0.00014539904997395466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 4.1051	Cost: 45.15s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 1.8822	Cost: 16.88s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 2.2118	Cost: 19.37s
Train Epoch: 141 	Average Loss: 2.3769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0615

Learning rate: 0.0001446978620671121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 3.9713	Cost: 39.66s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 2.1763	Cost: 14.32s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 2.3164	Cost: 19.74s
Train Epoch: 142 	Average Loss: 2.3528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1296

Learning rate: 0.0001439939169855915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 4.0955	Cost: 39.25s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 2.0345	Cost: 16.74s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 2.1250	Cost: 15.89s
Train Epoch: 143 	Average Loss: 2.3451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0312

Learning rate: 0.0001432872581520414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 4.1280	Cost: 37.40s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 2.0215	Cost: 14.05s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 2.1617	Cost: 13.20s
Train Epoch: 144 	Average Loss: 2.3104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0183

Learning rate: 0.00014257792915650728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 4.1149	Cost: 42.45s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 2.0912	Cost: 9.95s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 2.3752	Cost: 18.52s
Train Epoch: 145 	Average Loss: 2.2817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0350

Learning rate: 0.0001418659737537428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 4.0865	Cost: 36.78s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 1.9521	Cost: 11.05s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 2.5476	Cost: 31.64s
Train Epoch: 146 	Average Loss: 2.2976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4916

Learning rate: 0.00014115143586051088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 4.2962	Cost: 38.84s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 2.4298	Cost: 15.15s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 2.3401	Cost: 22.92s
Train Epoch: 147 	Average Loss: 2.7048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2376

Learning rate: 0.0001404343595528745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 4.3168	Cost: 54.61s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 2.4364	Cost: 16.52s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 2.4032	Cost: 18.18s
Train Epoch: 148 	Average Loss: 2.4884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9904

Learning rate: 0.00013971478906347806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 3.9490	Cost: 46.67s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 1.9976	Cost: 14.51s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 2.0429	Cost: 14.77s
Train Epoch: 149 	Average Loss: 2.2061
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8232

Saving model as e149_model.pt & e149_waveforms_supplementary.hdf5
Learning rate: 0.00013899276877881884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 3.6583	Cost: 45.58s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 1.9750	Cost: 9.82s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 2.2843	Cost: 22.49s
Train Epoch: 150 	Average Loss: 2.0991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9732

Learning rate: 0.000138268343236509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 4.0253	Cost: 42.84s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 1.7949	Cost: 9.80s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 2.1951	Cost: 26.41s
Train Epoch: 151 	Average Loss: 2.1307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8278

Learning rate: 0.00013754155712252834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 3.8709	Cost: 37.85s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 1.7630	Cost: 9.88s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 1.9890	Cost: 26.84s
Train Epoch: 152 	Average Loss: 2.0546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9002

Learning rate: 0.00013681245526846785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 3.8822	Cost: 42.38s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 1.8046	Cost: 13.60s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 1.9984	Cost: 19.69s
Train Epoch: 153 	Average Loss: 2.0429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8392

Learning rate: 0.00013608108264876422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 3.8960	Cost: 34.90s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 1.8136	Cost: 9.93s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 2.1023	Cost: 16.80s
Train Epoch: 154 	Average Loss: 2.0312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7640

Saving model as e154_model.pt & e154_waveforms_supplementary.hdf5
Learning rate: 0.00013534748437792575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 4.2245	Cost: 34.52s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 1.8034	Cost: 9.48s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 2.0757	Cost: 19.13s
Train Epoch: 155 	Average Loss: 2.0481
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9176

Learning rate: 0.00013461170570774932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 3.9255	Cost: 33.99s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 1.7423	Cost: 9.46s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 1.9506	Cost: 20.62s
Train Epoch: 156 	Average Loss: 2.0122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7050

Saving model as e156_model.pt & e156_waveforms_supplementary.hdf5
Learning rate: 0.0001338737920245292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 3.8558	Cost: 34.54s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 1.7949	Cost: 9.45s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 1.7065	Cost: 21.27s
Train Epoch: 157 	Average Loss: 1.9124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6857

Saving model as e157_model.pt & e157_waveforms_supplementary.hdf5
Learning rate: 0.00013313378884625713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 3.8969	Cost: 34.62s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 1.3752	Cost: 9.52s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 1.6562	Cost: 22.51s
Train Epoch: 158 	Average Loss: 1.8948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7812

Learning rate: 0.00013239174181981498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 3.6614	Cost: 33.58s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 1.6527	Cost: 9.49s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 1.7944	Cost: 23.10s
Train Epoch: 159 	Average Loss: 1.8201
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7291

Learning rate: 0.00013164769671815865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 3.6243	Cost: 37.31s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 1.6425	Cost: 10.01s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 1.7607	Cost: 25.66s
Train Epoch: 160 	Average Loss: 1.7839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7025

Learning rate: 0.0001309016994374948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 3.6218	Cost: 45.66s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 1.6134	Cost: 16.79s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 1.7297	Cost: 17.04s
Train Epoch: 161 	Average Loss: 1.7691
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5255

Saving model as e161_model.pt & e161_waveforms_supplementary.hdf5
Learning rate: 0.00013015379599444962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 3.4817	Cost: 52.91s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 1.6566	Cost: 14.88s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 1.6025	Cost: 14.45s
Train Epoch: 162 	Average Loss: 1.7615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6450

Learning rate: 0.00012940403252323043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 3.6450	Cost: 36.86s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 1.6186	Cost: 12.20s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 1.5212	Cost: 18.13s
Train Epoch: 163 	Average Loss: 1.7680
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7623

Learning rate: 0.00012865245527277986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 3.7633	Cost: 35.38s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 1.4078	Cost: 9.97s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 1.5336	Cost: 26.17s
Train Epoch: 164 	Average Loss: 1.7463
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8188

Learning rate: 0.00012789911060392294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 3.7719	Cost: 38.14s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 1.5126	Cost: 16.43s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 1.6209	Cost: 16.95s
Train Epoch: 165 	Average Loss: 1.7424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4946

Saving model as e165_model.pt & e165_waveforms_supplementary.hdf5
Learning rate: 0.00012714404498650745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 3.6498	Cost: 42.18s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 1.4263	Cost: 17.04s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 1.7158	Cost: 16.06s
Train Epoch: 166 	Average Loss: 1.7087
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5432

Learning rate: 0.00012638730499653727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 3.4580	Cost: 37.56s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 1.1487	Cost: 9.86s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 1.3180	Cost: 24.05s
Train Epoch: 167 	Average Loss: 1.6104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7005

Learning rate: 0.00012562893731329965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 3.6935	Cost: 43.51s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 1.2774	Cost: 10.08s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 1.6408	Cost: 28.47s
Train Epoch: 168 	Average Loss: 1.7157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6809

Learning rate: 0.00012486898871648546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 3.5038	Cost: 51.10s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 1.3096	Cost: 16.18s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 1.4867	Cost: 16.65s
Train Epoch: 169 	Average Loss: 1.6273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6852

Learning rate: 0.00012410750608330388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 3.6840	Cost: 46.16s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 1.3849	Cost: 14.76s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 1.5380	Cost: 17.15s
Train Epoch: 170 	Average Loss: 1.7033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5691

Learning rate: 0.00012334453638559054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 3.7827	Cost: 43.49s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 1.3077	Cost: 9.76s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 1.5191	Cost: 22.16s
Train Epoch: 171 	Average Loss: 1.6312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5871

Learning rate: 0.00012258012668691037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 3.6615	Cost: 37.68s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 1.3357	Cost: 9.83s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 1.3061	Cost: 27.42s
Train Epoch: 172 	Average Loss: 1.5451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6272

Learning rate: 0.00012181432413965427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 3.5839	Cost: 37.81s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 1.1118	Cost: 14.20s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 1.1043	Cost: 20.45s
Train Epoch: 173 	Average Loss: 1.4762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3315

Saving model as e173_model.pt & e173_waveforms_supplementary.hdf5
Learning rate: 0.0001210471759821306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 3.4791	Cost: 40.87s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 1.0989	Cost: 16.38s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 1.0519	Cost: 18.76s
Train Epoch: 174 	Average Loss: 1.3995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6400

Learning rate: 0.00012027872953565127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 3.5805	Cost: 36.62s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 1.1363	Cost: 9.66s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 1.2993	Cost: 25.57s
Train Epoch: 175 	Average Loss: 1.4607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5692

Learning rate: 0.00011950903220161285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 3.6165	Cost: 39.70s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 1.1049	Cost: 9.85s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 1.1828	Cost: 26.70s
Train Epoch: 176 	Average Loss: 1.4134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4576

Learning rate: 0.00011873813145857249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 3.4839	Cost: 51.21s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 1.3554	Cost: 15.58s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 1.1771	Cost: 17.19s
Train Epoch: 177 	Average Loss: 1.3796
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6018

Learning rate: 0.00011796607485931927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 3.6331	Cost: 53.56s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 1.0327	Cost: 14.18s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 1.3072	Cost: 14.33s
Train Epoch: 178 	Average Loss: 1.3537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3995

Learning rate: 0.00011719291002794096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 3.5611	Cost: 36.97s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 1.0401	Cost: 12.59s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 1.3957	Cost: 17.50s
Train Epoch: 179 	Average Loss: 1.3801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4282

Learning rate: 0.0001164186846568863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 3.5524	Cost: 36.89s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 1.4401	Cost: 10.47s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 1.2076	Cost: 26.15s
Train Epoch: 180 	Average Loss: 1.4361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4236

Learning rate: 0.0001156434465040231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 3.1372	Cost: 41.20s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 1.0988	Cost: 14.91s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 1.3299	Cost: 20.57s
Train Epoch: 181 	Average Loss: 1.2912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3607

Learning rate: 0.00011486724338969234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 3.2246	Cost: 42.42s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 0.9638	Cost: 14.26s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 1.1899	Cost: 21.55s
Train Epoch: 182 	Average Loss: 1.3296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6005

Learning rate: 0.0001140901231937583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 3.1730	Cost: 43.79s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 1.0760	Cost: 10.45s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 1.1874	Cost: 28.43s
Train Epoch: 183 	Average Loss: 1.3008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3666

Learning rate: 0.00011331213385265528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 3.1928	Cost: 47.77s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 0.8350	Cost: 16.80s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 1.1811	Cost: 18.08s
Train Epoch: 184 	Average Loss: 1.2007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4057

Learning rate: 0.00011253332335643047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 3.4900	Cost: 39.62s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 0.9231	Cost: 16.64s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 0.9675	Cost: 14.08s
Train Epoch: 185 	Average Loss: 1.2749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3973

Learning rate: 0.0001117537397457838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 3.3750	Cost: 42.74s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 0.6801	Cost: 14.98s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 0.9775	Cost: 12.86s
Train Epoch: 186 	Average Loss: 1.1068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3373

Learning rate: 0.00011097343110910456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 3.3614	Cost: 43.27s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 0.7445	Cost: 9.63s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 1.0165	Cost: 19.57s
Train Epoch: 187 	Average Loss: 1.1176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1593

Saving model as e187_model.pt & e187_waveforms_supplementary.hdf5
Learning rate: 0.00011019244557950502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 3.3677	Cost: 34.42s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 0.8583	Cost: 9.88s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 0.9199	Cost: 26.71s
Train Epoch: 188 	Average Loss: 1.1142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1877

Learning rate: 0.00010941083133185145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 3.1709	Cost: 39.20s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 1.0747	Cost: 16.70s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 1.1563	Cost: 18.94s
Train Epoch: 189 	Average Loss: 1.2992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3363

Learning rate: 0.00010862863657979236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 3.3228	Cost: 39.99s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 0.7947	Cost: 16.79s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 1.0151	Cost: 13.60s
Train Epoch: 190 	Average Loss: 1.2393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3995

Learning rate: 0.00010784590957278452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 3.2911	Cost: 41.96s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 0.7570	Cost: 9.77s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 1.2274	Cost: 18.35s
Train Epoch: 191 	Average Loss: 1.1286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4283

Learning rate: 0.00010706269859311669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 3.4777	Cost: 34.45s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 0.9573	Cost: 9.85s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 0.9949	Cost: 31.54s
Train Epoch: 192 	Average Loss: 1.0797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3374

Learning rate: 0.00010627905195293137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 3.2174	Cost: 37.73s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 0.9541	Cost: 17.23s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 0.8091	Cost: 24.09s
Train Epoch: 193 	Average Loss: 1.0275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0453

Saving model as e193_model.pt & e193_waveforms_supplementary.hdf5
Learning rate: 0.00010549501799124461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 3.1661	Cost: 46.13s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 0.7678	Cost: 11.00s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 0.8816	Cost: 26.00s
Train Epoch: 194 	Average Loss: 1.0650
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3375

Learning rate: 0.00010471064507096429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 3.9107	Cost: 40.66s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 0.6600	Cost: 9.76s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 0.7514	Cost: 27.96s
Train Epoch: 195 	Average Loss: 1.0382
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1781

Learning rate: 0.00010392598157590689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 3.0765	Cost: 42.73s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 0.6503	Cost: 17.33s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 0.9263	Cost: 17.24s
Train Epoch: 196 	Average Loss: 0.9831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3647

Learning rate: 0.00010314107590781285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 3.4665	Cost: 40.92s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 0.8423	Cost: 15.05s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 0.9166	Cost: 13.54s
Train Epoch: 197 	Average Loss: 1.1032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2773

Learning rate: 0.00010235597648336105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 3.4120	Cost: 38.39s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 0.6946	Cost: 9.92s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 0.7983	Cost: 19.24s
Train Epoch: 198 	Average Loss: 1.0161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3648

Learning rate: 0.0001015707317311821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 3.1580	Cost: 35.62s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 0.6013	Cost: 9.92s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 0.4894	Cost: 31.09s
Train Epoch: 199 	Average Loss: 0.9935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1457

Learning rate: 0.00010078539008887115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 3.0032	Cost: 38.82s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 0.4957	Cost: 16.99s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 0.7848	Cost: 22.59s
Train Epoch: 200 	Average Loss: 0.8550
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0447

Saving model as e200_model.pt & e200_waveforms_supplementary.hdf5
Learning rate: 0.00010000000000000002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 3.1827	Cost: 37.98s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 0.3719	Cost: 13.91s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 0.4339	Cost: 18.07s
Train Epoch: 201 	Average Loss: 0.7606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0816

Learning rate: 9.92146099111289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 3.3018	Cost: 43.99s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 0.9952	Cost: 12.78s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 1.1752	Cost: 18.86s
Train Epoch: 202 	Average Loss: 1.1729
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2639

Learning rate: 9.842926826881797e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 3.5882	Cost: 42.08s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 1.0359	Cost: 10.10s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 0.9664	Cost: 26.10s
Train Epoch: 203 	Average Loss: 1.1115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1541

Learning rate: 9.7644023516639e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 3.1146	Cost: 45.83s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 0.8399	Cost: 16.53s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 1.0098	Cost: 16.87s
Train Epoch: 204 	Average Loss: 1.0987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2166

Learning rate: 9.68589240921872e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 3.2773	Cost: 45.05s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 0.6539	Cost: 15.19s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 0.9160	Cost: 11.89s
Train Epoch: 205 	Average Loss: 1.0473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4256

Learning rate: 9.607401842409317e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 3.2270	Cost: 38.98s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 0.6856	Cost: 12.55s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 0.6011	Cost: 16.76s
Train Epoch: 206 	Average Loss: 0.9166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2582

Learning rate: 9.528935492903578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 2.9800	Cost: 38.20s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 0.5498	Cost: 12.45s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 0.6635	Cost: 16.95s
Train Epoch: 207 	Average Loss: 0.7765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0884

Learning rate: 9.450498200875547e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 3.1349	Cost: 36.56s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 0.3750	Cost: 9.87s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 0.5728	Cost: 27.48s
Train Epoch: 208 	Average Loss: 0.7266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0529

Learning rate: 9.372094804706868e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 2.9685	Cost: 38.20s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 0.2949	Cost: 16.61s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 0.3926	Cost: 16.69s
Train Epoch: 209 	Average Loss: 0.6182
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9883

Saving model as e209_model.pt & e209_waveforms_supplementary.hdf5
Learning rate: 9.293730140688336e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 3.2027	Cost: 37.82s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 0.4029	Cost: 15.85s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 0.4567	Cost: 11.81s
Train Epoch: 210 	Average Loss: 0.6118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9087

Saving model as e210_model.pt & e210_waveforms_supplementary.hdf5
Learning rate: 9.215409042721555e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 2.8993	Cost: 36.06s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 0.0856	Cost: 9.69s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 0.2887	Cost: 20.53s
Train Epoch: 211 	Average Loss: 0.5774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9431

Learning rate: 9.13713634202077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 2.9190	Cost: 38.78s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 0.5695	Cost: 10.63s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 0.4935	Cost: 27.01s
Train Epoch: 212 	Average Loss: 0.5318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0532

Learning rate: 9.058916866814858e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 2.9352	Cost: 49.24s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 0.2074	Cost: 17.34s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 0.3757	Cost: 19.00s
Train Epoch: 213 	Average Loss: 0.5236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9606

Learning rate: 8.9807554420495e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 3.1186	Cost: 54.26s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 0.1074	Cost: 15.09s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 0.4328	Cost: 13.82s
Train Epoch: 214 	Average Loss: 0.5708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9556

Learning rate: 8.902656889089548e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 2.9169	Cost: 37.93s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 0.1867	Cost: 11.69s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 0.5050	Cost: 18.39s
Train Epoch: 215 	Average Loss: 0.5652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9916

Learning rate: 8.824626025421624e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 3.0588	Cost: 37.52s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 0.1823	Cost: 9.73s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 0.2909	Cost: 27.32s
Train Epoch: 216 	Average Loss: 0.4893
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9980

Learning rate: 8.746667664356959e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 2.9665	Cost: 41.11s
Train Epoch: 217 [40960/90000 (45%)]	Loss: -0.0259	Cost: 16.10s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 0.2251	Cost: 20.83s
Train Epoch: 217 	Average Loss: 0.4911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9190

Learning rate: 8.668786614734478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 2.9461	Cost: 42.82s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 0.0674	Cost: 9.77s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 0.4127	Cost: 26.01s
Train Epoch: 218 	Average Loss: 0.4081
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9881

Learning rate: 8.590987680624175e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 2.8429	Cost: 46.03s
Train Epoch: 219 [40960/90000 (45%)]	Loss: -0.0983	Cost: 12.02s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 0.1444	Cost: 20.88s
Train Epoch: 219 	Average Loss: 0.3424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7360

Saving model as e219_model.pt & e219_waveforms_supplementary.hdf5
Learning rate: 8.51327566103077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 2.6535	Cost: 43.21s
Train Epoch: 220 [40960/90000 (45%)]	Loss: -0.0124	Cost: 14.50s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 0.2087	Cost: 21.10s
Train Epoch: 220 	Average Loss: 0.3015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8399

Learning rate: 8.435655349597692e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 2.9241	Cost: 45.85s
Train Epoch: 221 [40960/90000 (45%)]	Loss: -0.0930	Cost: 14.83s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 0.1587	Cost: 18.36s
Train Epoch: 221 	Average Loss: 0.3393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8791

Learning rate: 8.35813153431137e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 3.0605	Cost: 43.79s
Train Epoch: 222 [40960/90000 (45%)]	Loss: -0.1937	Cost: 15.15s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 0.0986	Cost: 15.11s
Train Epoch: 222 	Average Loss: 0.3355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8649

Learning rate: 8.280708997205904e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 3.0228	Cost: 42.19s
Train Epoch: 223 [40960/90000 (45%)]	Loss: -0.1132	Cost: 9.63s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 0.2716	Cost: 20.09s
Train Epoch: 223 	Average Loss: 0.3944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9236

Learning rate: 8.203392514068074e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 2.8213	Cost: 34.69s
Train Epoch: 224 [40960/90000 (45%)]	Loss: -0.1892	Cost: 9.83s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 0.0853	Cost: 27.76s
Train Epoch: 224 	Average Loss: 0.2451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8236

Learning rate: 8.126186854142755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 2.4267	Cost: 36.82s
Train Epoch: 225 [40960/90000 (45%)]	Loss: -0.2922	Cost: 16.51s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 0.1290	Cost: 19.19s
Train Epoch: 225 	Average Loss: 0.2140
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7547

Learning rate: 8.049096779838719e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 2.7137	Cost: 39.74s
Train Epoch: 226 [40960/90000 (45%)]	Loss: -0.2262	Cost: 16.90s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 0.0544	Cost: 16.90s
Train Epoch: 226 	Average Loss: 0.2060
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8339

Learning rate: 7.972127046434877e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 2.8613	Cost: 43.67s
Train Epoch: 227 [40960/90000 (45%)]	Loss: -0.0086	Cost: 10.73s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 0.1260	Cost: 21.13s
Train Epoch: 227 	Average Loss: 0.1858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8542

Learning rate: 7.895282401786947e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 2.6176	Cost: 42.09s
Train Epoch: 228 [40960/90000 (45%)]	Loss: -0.2605	Cost: 9.83s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 0.0431	Cost: 27.71s
Train Epoch: 228 	Average Loss: 0.1449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7103

Saving model as e228_model.pt & e228_waveforms_supplementary.hdf5
Learning rate: 7.818567586034578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 2.8790	Cost: 50.42s
Train Epoch: 229 [40960/90000 (45%)]	Loss: -0.4413	Cost: 16.76s
Train Epoch: 229 [81920/90000 (91%)]	Loss: -0.1144	Cost: 17.39s
Train Epoch: 229 	Average Loss: 0.1361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7526

Learning rate: 7.741987331308968e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 2.9910	Cost: 46.11s
Train Epoch: 230 [40960/90000 (45%)]	Loss: -0.3685	Cost: 13.83s
Train Epoch: 230 [81920/90000 (91%)]	Loss: -0.0453	Cost: 14.47s
Train Epoch: 230 	Average Loss: 0.1251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7930

Learning rate: 7.665546361440945e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 2.6288	Cost: 45.46s
Train Epoch: 231 [40960/90000 (45%)]	Loss: -0.2715	Cost: 9.54s
Train Epoch: 231 [81920/90000 (91%)]	Loss: -0.1135	Cost: 21.40s
Train Epoch: 231 	Average Loss: 0.1074
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7051

Saving model as e231_model.pt & e231_waveforms_supplementary.hdf5
Learning rate: 7.589249391669613e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 2.8919	Cost: 34.40s
Train Epoch: 232 [40960/90000 (45%)]	Loss: -0.2417	Cost: 10.30s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 0.0452	Cost: 26.55s
Train Epoch: 232 	Average Loss: 0.1350
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7376

Learning rate: 7.513101128351452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 2.6632	Cost: 38.97s
Train Epoch: 233 [40960/90000 (45%)]	Loss: -0.1766	Cost: 17.11s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 0.0516	Cost: 18.64s
Train Epoch: 233 	Average Loss: 0.1124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7079

Learning rate: 7.437106268670034e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 2.4228	Cost: 39.60s
Train Epoch: 234 [40960/90000 (45%)]	Loss: -0.2893	Cost: 16.46s
Train Epoch: 234 [81920/90000 (91%)]	Loss: -0.3059	Cost: 16.87s
Train Epoch: 234 	Average Loss: 0.0331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6499

Saving model as e234_model.pt & e234_waveforms_supplementary.hdf5
Learning rate: 7.361269500346273e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 2.5965	Cost: 41.00s
Train Epoch: 235 [40960/90000 (45%)]	Loss: -0.3619	Cost: 10.31s
Train Epoch: 235 [81920/90000 (91%)]	Loss: -0.2150	Cost: 20.51s
Train Epoch: 235 	Average Loss: 0.0155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7076

Learning rate: 7.28559550134926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 2.6987	Cost: 37.34s
Train Epoch: 236 [40960/90000 (45%)]	Loss: -0.3812	Cost: 10.02s
Train Epoch: 236 [81920/90000 (91%)]	Loss: -0.0139	Cost: 24.04s
Train Epoch: 236 	Average Loss: 0.0533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7095

Learning rate: 7.210088939607711e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 2.8244	Cost: 45.44s
Train Epoch: 237 [40960/90000 (45%)]	Loss: -0.1925	Cost: 12.95s
Train Epoch: 237 [81920/90000 (91%)]	Loss: -0.1829	Cost: 24.27s
Train Epoch: 237 	Average Loss: 0.0977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6223

Saving model as e237_model.pt & e237_waveforms_supplementary.hdf5
Learning rate: 7.13475447272202e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 2.6700	Cost: 56.57s
Train Epoch: 238 [40960/90000 (45%)]	Loss: -0.4837	Cost: 15.07s
Train Epoch: 238 [81920/90000 (91%)]	Loss: -0.2438	Cost: 12.37s
Train Epoch: 238 	Average Loss: -0.0086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6510

Learning rate: 7.059596747676965e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 2.5876	Cost: 38.54s
Train Epoch: 239 [40960/90000 (45%)]	Loss: -0.3031	Cost: 11.35s
Train Epoch: 239 [81920/90000 (91%)]	Loss: -0.1753	Cost: 16.74s
Train Epoch: 239 	Average Loss: 0.0196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7458

Learning rate: 6.984620400555048e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 2.6083	Cost: 35.07s
Train Epoch: 240 [40960/90000 (45%)]	Loss: -0.3808	Cost: 9.79s
Train Epoch: 240 [81920/90000 (91%)]	Loss: -0.2351	Cost: 26.93s
Train Epoch: 240 	Average Loss: 0.0374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5763

Saving model as e240_model.pt & e240_waveforms_supplementary.hdf5
Learning rate: 6.909830056250531e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 2.5628	Cost: 37.46s
Train Epoch: 241 [40960/90000 (45%)]	Loss: -0.4452	Cost: 13.58s
Train Epoch: 241 [81920/90000 (91%)]	Loss: -0.2211	Cost: 22.40s
Train Epoch: 241 	Average Loss: -0.0786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7105

Learning rate: 6.835230328184141e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 2.5361	Cost: 37.87s
Train Epoch: 242 [40960/90000 (45%)]	Loss: -0.5674	Cost: 16.59s
Train Epoch: 242 [81920/90000 (91%)]	Loss: -0.4789	Cost: 16.69s
Train Epoch: 242 	Average Loss: -0.1196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6605

Learning rate: 6.760825818018508e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 2.2620	Cost: 43.41s
Train Epoch: 243 [40960/90000 (45%)]	Loss: -0.4183	Cost: 9.69s
Train Epoch: 243 [81920/90000 (91%)]	Loss: -0.2846	Cost: 20.08s
Train Epoch: 243 	Average Loss: -0.1689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5158

Saving model as e243_model.pt & e243_waveforms_supplementary.hdf5
Learning rate: 6.686621115374292e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 2.3003	Cost: 37.96s
Train Epoch: 244 [40960/90000 (45%)]	Loss: -0.5572	Cost: 11.16s
Train Epoch: 244 [81920/90000 (91%)]	Loss: -0.3806	Cost: 27.52s
Train Epoch: 244 	Average Loss: -0.1252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6575

Learning rate: 6.61262079754709e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 2.5770	Cost: 54.65s
Train Epoch: 245 [40960/90000 (45%)]	Loss: -0.6439	Cost: 16.55s
Train Epoch: 245 [81920/90000 (91%)]	Loss: -0.1890	Cost: 17.59s
Train Epoch: 245 	Average Loss: -0.2053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6388

Learning rate: 6.538829429225073e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 2.5386	Cost: 46.84s
Train Epoch: 246 [40960/90000 (45%)]	Loss: -0.6091	Cost: 9.84s
Train Epoch: 246 [81920/90000 (91%)]	Loss: -0.1939	Cost: 20.73s
Train Epoch: 246 	Average Loss: -0.1458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6652

Learning rate: 6.465251562207432e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 2.5900	Cost: 37.55s
Train Epoch: 247 [40960/90000 (45%)]	Loss: -0.4301	Cost: 10.00s
Train Epoch: 247 [81920/90000 (91%)]	Loss: -0.4479	Cost: 27.10s
Train Epoch: 247 	Average Loss: -0.1507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4700

Saving model as e247_model.pt & e247_waveforms_supplementary.hdf5
Learning rate: 6.391891735123586e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 2.5240	Cost: 39.81s
Train Epoch: 248 [40960/90000 (45%)]	Loss: -0.4465	Cost: 16.41s
Train Epoch: 248 [81920/90000 (91%)]	Loss: -0.5145	Cost: 18.84s
Train Epoch: 248 	Average Loss: -0.2012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4872

Learning rate: 6.318754473153225e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 2.3765	Cost: 38.79s
Train Epoch: 249 [40960/90000 (45%)]	Loss: -0.4971	Cost: 16.75s
Train Epoch: 249 [81920/90000 (91%)]	Loss: -0.3136	Cost: 16.59s
Train Epoch: 249 	Average Loss: -0.2331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5601

Learning rate: 6.245844287747173e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 2.2598	Cost: 41.67s
Train Epoch: 250 [40960/90000 (45%)]	Loss: -0.6369	Cost: 15.93s
Train Epoch: 250 [81920/90000 (91%)]	Loss: -0.5041	Cost: 12.39s
Train Epoch: 250 	Average Loss: -0.3700
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4611

Saving model as e250_model.pt & e250_waveforms_supplementary.hdf5
Learning rate: 6.173165676349108e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 2.1532	Cost: 36.05s
Train Epoch: 251 [40960/90000 (45%)]	Loss: -0.8957	Cost: 11.62s
Train Epoch: 251 [81920/90000 (91%)]	Loss: -0.5770	Cost: 23.75s
Train Epoch: 251 	Average Loss: -0.3572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4703

Learning rate: 6.10072312211812e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 2.2897	Cost: 38.19s
Train Epoch: 252 [40960/90000 (45%)]	Loss: -0.7240	Cost: 11.22s
Train Epoch: 252 [81920/90000 (91%)]	Loss: -0.5870	Cost: 27.65s
Train Epoch: 252 	Average Loss: -0.3604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4077

Saving model as e252_model.pt & e252_waveforms_supplementary.hdf5
Learning rate: 6.0285210936521955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 2.4800	Cost: 43.82s
Train Epoch: 253 [40960/90000 (45%)]	Loss: -0.8693	Cost: 16.76s
Train Epoch: 253 [81920/90000 (91%)]	Loss: -0.6517	Cost: 19.67s
Train Epoch: 253 	Average Loss: -0.3928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4280

Learning rate: 5.956564044712553e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 2.5392	Cost: 44.34s
Train Epoch: 254 [40960/90000 (45%)]	Loss: -0.8452	Cost: 16.25s
Train Epoch: 254 [81920/90000 (91%)]	Loss: -0.4696	Cost: 19.44s
Train Epoch: 254 	Average Loss: -0.3783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3908

Saving model as e254_model.pt & e254_waveforms_supplementary.hdf5
Learning rate: 5.8848564139489155e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 2.2321	Cost: 52.29s
Train Epoch: 255 [40960/90000 (45%)]	Loss: -0.7559	Cost: 12.37s
Train Epoch: 255 [81920/90000 (91%)]	Loss: -0.6991	Cost: 18.07s
Train Epoch: 255 	Average Loss: -0.4259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4978

Learning rate: 5.813402624625721e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 2.1010	Cost: 37.25s
Train Epoch: 256 [40960/90000 (45%)]	Loss: -0.6957	Cost: 9.94s
Train Epoch: 256 [81920/90000 (91%)]	Loss: -0.4256	Cost: 26.35s
Train Epoch: 256 	Average Loss: -0.4515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4750

Learning rate: 5.742207084349277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 2.2507	Cost: 37.99s
Train Epoch: 257 [40960/90000 (45%)]	Loss: -0.9201	Cost: 16.66s
Train Epoch: 257 [81920/90000 (91%)]	Loss: -0.6883	Cost: 17.49s
Train Epoch: 257 	Average Loss: -0.4910
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4157

Learning rate: 5.6712741847958634e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 2.5553	Cost: 36.36s
Train Epoch: 258 [40960/90000 (45%)]	Loss: -0.7264	Cost: 16.82s
Train Epoch: 258 [81920/90000 (91%)]	Loss: -0.6317	Cost: 16.55s
Train Epoch: 258 	Average Loss: -0.4681
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3726

Saving model as e258_model.pt & e258_waveforms_supplementary.hdf5
Learning rate: 5.600608301440851e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 2.4283	Cost: 36.34s
Train Epoch: 259 [40960/90000 (45%)]	Loss: -0.9617	Cost: 14.70s
Train Epoch: 259 [81920/90000 (91%)]	Loss: -0.7299	Cost: 12.18s
Train Epoch: 259 	Average Loss: -0.5179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3627

Saving model as e259_model.pt & e259_waveforms_supplementary.hdf5
Learning rate: 5.5302137932887924e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 2.4753	Cost: 34.91s
Train Epoch: 260 [40960/90000 (45%)]	Loss: -0.8117	Cost: 9.61s
Train Epoch: 260 [81920/90000 (91%)]	Loss: -0.7280	Cost: 17.87s
Train Epoch: 260 	Average Loss: -0.5267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3983

Learning rate: 5.460095002604535e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 2.0840	Cost: 35.11s
Train Epoch: 261 [40960/90000 (45%)]	Loss: -1.0927	Cost: 9.88s
Train Epoch: 261 [81920/90000 (91%)]	Loss: -0.8000	Cost: 29.67s
Train Epoch: 261 	Average Loss: -0.6236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5116

Learning rate: 5.390256254645381e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 2.4234	Cost: 36.63s
Train Epoch: 262 [40960/90000 (45%)]	Loss: -0.8586	Cost: 17.73s
Train Epoch: 262 [81920/90000 (91%)]	Loss: -0.6770	Cost: 24.28s
Train Epoch: 262 	Average Loss: -0.4950
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4261

Learning rate: 5.3207018573942705e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 2.0985	Cost: 40.76s
Train Epoch: 263 [40960/90000 (45%)]	Loss: -0.9567	Cost: 16.59s
Train Epoch: 263 [81920/90000 (91%)]	Loss: -0.8484	Cost: 15.81s
Train Epoch: 263 	Average Loss: -0.6079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2506

Saving model as e263_model.pt & e263_waveforms_supplementary.hdf5
Learning rate: 5.251436101294054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 2.5125	Cost: 38.07s
Train Epoch: 264 [40960/90000 (45%)]	Loss: -0.9189	Cost: 9.74s
Train Epoch: 264 [81920/90000 (91%)]	Loss: -0.7698	Cost: 23.73s
Train Epoch: 264 	Average Loss: -0.5852
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3885

Learning rate: 5.1824632589828485e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 2.2163	Cost: 41.39s
Train Epoch: 265 [40960/90000 (45%)]	Loss: -1.1159	Cost: 10.09s
Train Epoch: 265 [81920/90000 (91%)]	Loss: -0.7210	Cost: 26.85s
Train Epoch: 265 	Average Loss: -0.6329
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2582

Learning rate: 5.1137875850304516e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 2.2707	Cost: 39.03s
Train Epoch: 266 [40960/90000 (45%)]	Loss: -0.7916	Cost: 15.90s
Train Epoch: 266 [81920/90000 (91%)]	Loss: -0.7012	Cost: 19.29s
Train Epoch: 266 	Average Loss: -0.5887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2973

Learning rate: 5.045413315675926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 2.1313	Cost: 40.34s
Train Epoch: 267 [40960/90000 (45%)]	Loss: -1.1235	Cost: 15.55s
Train Epoch: 267 [81920/90000 (91%)]	Loss: -0.7543	Cost: 18.19s
Train Epoch: 267 	Average Loss: -0.6475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4151

Learning rate: 4.977344668566277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 2.2893	Cost: 43.02s
Train Epoch: 268 [40960/90000 (45%)]	Loss: -1.0225	Cost: 12.51s
Train Epoch: 268 [81920/90000 (91%)]	Loss: -0.7574	Cost: 16.09s
Train Epoch: 268 	Average Loss: -0.5888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2382

Saving model as e268_model.pt & e268_waveforms_supplementary.hdf5
Learning rate: 4.909585842496289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 2.0112	Cost: 37.16s
Train Epoch: 269 [40960/90000 (45%)]	Loss: -1.1590	Cost: 11.96s
Train Epoch: 269 [81920/90000 (91%)]	Loss: -0.7976	Cost: 26.84s
Train Epoch: 269 	Average Loss: -0.6725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2463

Learning rate: 4.842141017149528e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 2.1707	Cost: 46.92s
Train Epoch: 270 [40960/90000 (45%)]	Loss: -1.1785	Cost: 16.73s
Train Epoch: 270 [81920/90000 (91%)]	Loss: -0.9011	Cost: 20.85s
Train Epoch: 270 	Average Loss: -0.6768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3293

Learning rate: 4.775014352840514e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 1.8623	Cost: 51.15s
Train Epoch: 271 [40960/90000 (45%)]	Loss: -1.2099	Cost: 14.80s
Train Epoch: 271 [81920/90000 (91%)]	Loss: -0.8155	Cost: 14.33s
Train Epoch: 271 	Average Loss: -0.7448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2315

Saving model as e271_model.pt & e271_waveforms_supplementary.hdf5
Learning rate: 4.708209990258097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 2.1124	Cost: 45.30s
Train Epoch: 272 [40960/90000 (45%)]	Loss: -1.3126	Cost: 9.84s
Train Epoch: 272 [81920/90000 (91%)]	Loss: -0.9171	Cost: 21.28s
Train Epoch: 272 	Average Loss: -0.8037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2387

Learning rate: 4.641732050210033e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 2.2367	Cost: 38.56s
Train Epoch: 273 [40960/90000 (45%)]	Loss: -1.5247	Cost: 9.95s
Train Epoch: 273 [81920/90000 (91%)]	Loss: -1.1380	Cost: 22.59s
Train Epoch: 273 	Average Loss: -0.8289
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1429

Saving model as e273_model.pt & e273_waveforms_supplementary.hdf5
Learning rate: 4.575584633368813e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 2.0816	Cost: 38.52s
Train Epoch: 274 [40960/90000 (45%)]	Loss: -1.4102	Cost: 10.27s
Train Epoch: 274 [81920/90000 (91%)]	Loss: -0.9698	Cost: 27.29s
Train Epoch: 274 	Average Loss: -0.8606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1198

Saving model as e274_model.pt & e274_waveforms_supplementary.hdf5
Learning rate: 4.509771820018683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 2.0700	Cost: 39.46s
Train Epoch: 275 [40960/90000 (45%)]	Loss: -1.2115	Cost: 16.32s
Train Epoch: 275 [81920/90000 (91%)]	Loss: -1.0131	Cost: 13.69s
Train Epoch: 275 	Average Loss: -0.8302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0535

Saving model as e275_model.pt & e275_waveforms_supplementary.hdf5
Learning rate: 4.4442976698039786e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 2.0658	Cost: 40.46s
Train Epoch: 276 [40960/90000 (45%)]	Loss: -1.2022	Cost: 9.95s
Train Epoch: 276 [81920/90000 (91%)]	Loss: -0.8941	Cost: 19.74s
Train Epoch: 276 	Average Loss: -0.8490
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2681

Learning rate: 4.379166221478695e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 1.8547	Cost: 34.39s
Train Epoch: 277 [40960/90000 (45%)]	Loss: -1.3374	Cost: 9.77s
Train Epoch: 277 [81920/90000 (91%)]	Loss: -0.8907	Cost: 28.11s
Train Epoch: 277 	Average Loss: -0.9181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1811

Learning rate: 4.3143814926573614e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 2.0935	Cost: 37.31s
Train Epoch: 278 [40960/90000 (45%)]	Loss: -1.3524	Cost: 15.90s
Train Epoch: 278 [81920/90000 (91%)]	Loss: -1.0637	Cost: 21.50s
Train Epoch: 278 	Average Loss: -0.8994
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0677

Learning rate: 4.249947479567216e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 1.9969	Cost: 42.54s
Train Epoch: 279 [40960/90000 (45%)]	Loss: -1.4051	Cost: 9.84s
Train Epoch: 279 [81920/90000 (91%)]	Loss: -1.1985	Cost: 25.80s
Train Epoch: 279 	Average Loss: -0.9454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1827

Learning rate: 4.1858681568016955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 2.1854	Cost: 43.20s
Train Epoch: 280 [40960/90000 (45%)]	Loss: -1.5154	Cost: 9.84s
Train Epoch: 280 [81920/90000 (91%)]	Loss: -0.9213	Cost: 27.17s
Train Epoch: 280 	Average Loss: -0.9057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1018

Learning rate: 4.122147477075271e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 1.9318	Cost: 44.83s
Train Epoch: 281 [40960/90000 (45%)]	Loss: -1.2323	Cost: 16.79s
Train Epoch: 281 [81920/90000 (91%)]	Loss: -1.0419	Cost: 17.10s
Train Epoch: 281 	Average Loss: -0.8152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0908

Learning rate: 4.058789370979617e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 2.2046	Cost: 42.33s
Train Epoch: 282 [40960/90000 (45%)]	Loss: -1.3757	Cost: 16.14s
Train Epoch: 282 [81920/90000 (91%)]	Loss: -1.0807	Cost: 16.33s
Train Epoch: 282 	Average Loss: -0.8741
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9390

Saving model as e282_model.pt & e282_waveforms_supplementary.hdf5
Learning rate: 3.995797746741162e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 1.9359	Cost: 42.04s
Train Epoch: 283 [40960/90000 (45%)]	Loss: -1.0104	Cost: 9.63s
Train Epoch: 283 [81920/90000 (91%)]	Loss: -0.9734	Cost: 20.32s
Train Epoch: 283 	Average Loss: -0.7890
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2164

Learning rate: 3.933176489980003e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 2.3477	Cost: 35.13s
Train Epoch: 284 [40960/90000 (45%)]	Loss: -1.2017	Cost: 9.94s
Train Epoch: 284 [81920/90000 (91%)]	Loss: -1.1696	Cost: 27.45s
Train Epoch: 284 	Average Loss: -0.8322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0567

Learning rate: 3.8709294634702356e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 2.1400	Cost: 36.89s
Train Epoch: 285 [40960/90000 (45%)]	Loss: -1.4728	Cost: 15.74s
Train Epoch: 285 [81920/90000 (91%)]	Loss: -1.2541	Cost: 22.79s
Train Epoch: 285 	Average Loss: -0.9690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1065

Learning rate: 3.809060506901661e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 1.8247	Cost: 37.52s
Train Epoch: 286 [40960/90000 (45%)]	Loss: -1.4635	Cost: 16.83s
Train Epoch: 286 [81920/90000 (91%)]	Loss: -1.1101	Cost: 20.27s
Train Epoch: 286 	Average Loss: -1.0212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1711

Learning rate: 3.747573436642949e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 2.0961	Cost: 39.95s
Train Epoch: 287 [40960/90000 (45%)]	Loss: -1.2716	Cost: 11.07s
Train Epoch: 287 [81920/90000 (91%)]	Loss: -1.2760	Cost: 28.59s
Train Epoch: 287 	Average Loss: -0.9792
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8942

Saving model as e287_model.pt & e287_waveforms_supplementary.hdf5
Learning rate: 3.686472045506224e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 2.1655	Cost: 41.33s
Train Epoch: 288 [40960/90000 (45%)]	Loss: -1.3919	Cost: 9.93s
Train Epoch: 288 [81920/90000 (91%)]	Loss: -1.2742	Cost: 26.47s
Train Epoch: 288 	Average Loss: -1.0076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0207

Learning rate: 3.625760102513104e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 1.9382	Cost: 44.14s
Train Epoch: 289 [40960/90000 (45%)]	Loss: -1.4423	Cost: 16.39s
Train Epoch: 289 [81920/90000 (91%)]	Loss: -1.3114	Cost: 16.93s
Train Epoch: 289 	Average Loss: -1.0706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1667

Learning rate: 3.5654413526622126e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 1.8327	Cost: 49.43s
Train Epoch: 290 [40960/90000 (45%)]	Loss: -1.5437	Cost: 16.02s
Train Epoch: 290 [81920/90000 (91%)]	Loss: -1.0741	Cost: 16.56s
Train Epoch: 290 	Average Loss: -1.0993
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9932

Learning rate: 3.505519516698166e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 1.7342	Cost: 41.11s
Train Epoch: 291 [40960/90000 (45%)]	Loss: -1.5762	Cost: 9.81s
Train Epoch: 291 [81920/90000 (91%)]	Loss: -1.2131	Cost: 20.11s
Train Epoch: 291 	Average Loss: -1.1571
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1597

Learning rate: 3.445998290882063e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 1.9700	Cost: 34.65s
Train Epoch: 292 [40960/90000 (45%)]	Loss: -1.4731	Cost: 9.77s
Train Epoch: 292 [81920/90000 (91%)]	Loss: -1.4881	Cost: 27.75s
Train Epoch: 292 	Average Loss: -1.1557
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9772

Learning rate: 3.386881346763484e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 1.9569	Cost: 37.39s
Train Epoch: 293 [40960/90000 (45%)]	Loss: -1.6337	Cost: 17.10s
Train Epoch: 293 [81920/90000 (91%)]	Loss: -1.4170	Cost: 23.83s
Train Epoch: 293 	Average Loss: -1.2003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8851

Saving model as e293_model.pt & e293_waveforms_supplementary.hdf5
Learning rate: 3.328172330954006e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 1.7498	Cost: 41.97s
Train Epoch: 294 [40960/90000 (45%)]	Loss: -1.7053	Cost: 14.95s
Train Epoch: 294 [81920/90000 (91%)]	Loss: -1.3324	Cost: 18.09s
Train Epoch: 294 	Average Loss: -1.2261
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9678

Learning rate: 3.269874864902267e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 2.0118	Cost: 42.87s
Train Epoch: 295 [40960/90000 (45%)]	Loss: -1.5632	Cost: 12.84s
Train Epoch: 295 [81920/90000 (91%)]	Loss: -1.4663	Cost: 16.96s
Train Epoch: 295 	Average Loss: -1.2049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8475

Saving model as e295_model.pt & e295_waveforms_supplementary.hdf5
Learning rate: 3.2119925446705836e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 1.6482	Cost: 41.09s
Train Epoch: 296 [40960/90000 (45%)]	Loss: -1.7005	Cost: 9.91s
Train Epoch: 296 [81920/90000 (91%)]	Loss: -1.4980	Cost: 25.42s
Train Epoch: 296 	Average Loss: -1.2717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8755

Learning rate: 3.1545289407131144e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 1.7341	Cost: 39.85s
Train Epoch: 297 [40960/90000 (45%)]	Loss: -1.6910	Cost: 16.59s
Train Epoch: 297 [81920/90000 (91%)]	Loss: -1.5125	Cost: 18.12s
Train Epoch: 297 	Average Loss: -1.2874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8735

Learning rate: 3.09748759765563e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 1.8695	Cost: 41.18s
Train Epoch: 298 [40960/90000 (45%)]	Loss: -1.7512	Cost: 16.71s
Train Epoch: 298 [81920/90000 (91%)]	Loss: -1.5193	Cost: 12.95s
Train Epoch: 298 	Average Loss: -1.2760
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8960

Learning rate: 3.0408720340768585e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 1.7577	Cost: 38.76s
Train Epoch: 299 [40960/90000 (45%)]	Loss: -1.8607	Cost: 10.51s
Train Epoch: 299 [81920/90000 (91%)]	Loss: -1.4124	Cost: 19.02s
Train Epoch: 299 	Average Loss: -1.3057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7926

Saving model as e299_model.pt & e299_waveforms_supplementary.hdf5
Learning rate: 2.9846857422914446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 1.7139	Cost: 35.05s
Train Epoch: 300 [40960/90000 (45%)]	Loss: -1.9087	Cost: 10.86s
Train Epoch: 300 [81920/90000 (91%)]	Loss: -1.5541	Cost: 30.97s
Train Epoch: 300 	Average Loss: -1.2924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8699

Learning rate: 2.9289321881345268e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 1.9874	Cost: 40.77s
Train Epoch: 301 [40960/90000 (45%)]	Loss: -1.8113	Cost: 17.14s
Train Epoch: 301 [81920/90000 (91%)]	Loss: -1.4838	Cost: 20.38s
Train Epoch: 301 	Average Loss: -1.2990
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8805

Learning rate: 2.8736148107479478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 1.5499	Cost: 58.00s
Train Epoch: 302 [40960/90000 (45%)]	Loss: -1.7106	Cost: 14.37s
Train Epoch: 302 [81920/90000 (91%)]	Loss: -1.6539	Cost: 18.20s
Train Epoch: 302 	Average Loss: -1.3319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8111

Learning rate: 2.8187370223681142e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 1.9580	Cost: 38.23s
Train Epoch: 303 [40960/90000 (45%)]	Loss: -1.8924	Cost: 9.78s
Train Epoch: 303 [81920/90000 (91%)]	Loss: -1.5267	Cost: 25.47s
Train Epoch: 303 	Average Loss: -1.3148
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8385

Learning rate: 2.764302208115509e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 1.7174	Cost: 37.52s
Train Epoch: 304 [40960/90000 (45%)]	Loss: -1.5851	Cost: 9.93s
Train Epoch: 304 [81920/90000 (91%)]	Loss: -1.6517	Cost: 26.30s
Train Epoch: 304 	Average Loss: -1.3589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9454

Learning rate: 2.710313725785888e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 1.4762	Cost: 38.98s
Train Epoch: 305 [40960/90000 (45%)]	Loss: -1.6958	Cost: 16.73s
Train Epoch: 305 [81920/90000 (91%)]	Loss: -1.4727	Cost: 16.75s
Train Epoch: 305 	Average Loss: -1.3302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9155

Learning rate: 2.6567749056431446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 1.9883	Cost: 40.43s
Train Epoch: 306 [40960/90000 (45%)]	Loss: -1.8314	Cost: 12.11s
Train Epoch: 306 [81920/90000 (91%)]	Loss: -1.6381	Cost: 16.52s
Train Epoch: 306 	Average Loss: -1.3913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7188

Saving model as e306_model.pt & e306_waveforms_supplementary.hdf5
Learning rate: 2.6036890502139035e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 1.6703	Cost: 35.65s
Train Epoch: 307 [40960/90000 (45%)]	Loss: -1.8109	Cost: 13.00s
Train Epoch: 307 [81920/90000 (91%)]	Loss: -1.6181	Cost: 21.71s
Train Epoch: 307 	Average Loss: -1.4232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8824

Learning rate: 2.55105943408378e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 1.8432	Cost: 37.70s
Train Epoch: 308 [40960/90000 (45%)]	Loss: -1.8356	Cost: 11.37s
Train Epoch: 308 [81920/90000 (91%)]	Loss: -1.7611	Cost: 32.42s
Train Epoch: 308 	Average Loss: -1.4353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7509

Learning rate: 2.4988893036954053e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 1.9801	Cost: 52.41s
Train Epoch: 309 [40960/90000 (45%)]	Loss: -1.9488	Cost: 16.81s
Train Epoch: 309 [81920/90000 (91%)]	Loss: -1.4444	Cost: 18.06s
Train Epoch: 309 	Average Loss: -1.4631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8834

Learning rate: 2.4471818771481658e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 1.4043	Cost: 54.03s
Train Epoch: 310 [40960/90000 (45%)]	Loss: -1.7883	Cost: 15.79s
Train Epoch: 310 [81920/90000 (91%)]	Loss: -1.7334	Cost: 14.71s
Train Epoch: 310 	Average Loss: -1.4585
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8980

Learning rate: 2.3959403439996917e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 1.6551	Cost: 39.59s
Train Epoch: 311 [40960/90000 (45%)]	Loss: -1.9958	Cost: 9.67s
Train Epoch: 311 [81920/90000 (91%)]	Loss: -1.7280	Cost: 23.09s
Train Epoch: 311 	Average Loss: -1.5384
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8186

Learning rate: 2.345167865069121e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 1.6198	Cost: 33.75s
Train Epoch: 312 [40960/90000 (45%)]	Loss: -1.8365	Cost: 10.03s
Train Epoch: 312 [81920/90000 (91%)]	Loss: -1.8194	Cost: 27.32s
Train Epoch: 312 	Average Loss: -1.4943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7480

Learning rate: 2.2948675722421096e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 1.5862	Cost: 38.24s
Train Epoch: 313 [40960/90000 (45%)]	Loss: -1.9870	Cost: 14.59s
Train Epoch: 313 [81920/90000 (91%)]	Loss: -1.7987	Cost: 17.10s
Train Epoch: 313 	Average Loss: -1.5362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7953

Learning rate: 2.2450425682776575e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 1.7835	Cost: 42.16s
Train Epoch: 314 [40960/90000 (45%)]	Loss: -1.9030	Cost: 16.91s
Train Epoch: 314 [81920/90000 (91%)]	Loss: -1.6757	Cost: 13.20s
Train Epoch: 314 	Average Loss: -1.5154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6525

Saving model as e314_model.pt & e314_waveforms_supplementary.hdf5
Learning rate: 2.1956959266167054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 1.4271	Cost: 39.06s
Train Epoch: 315 [40960/90000 (45%)]	Loss: -1.9872	Cost: 9.73s
Train Epoch: 315 [81920/90000 (91%)]	Loss: -1.8306	Cost: 22.66s
Train Epoch: 315 	Average Loss: -1.5484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7436

Learning rate: 2.1468306911925506e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 1.6823	Cost: 37.37s
Train Epoch: 316 [40960/90000 (45%)]	Loss: -1.9790	Cost: 10.44s
Train Epoch: 316 [81920/90000 (91%)]	Loss: -1.6731	Cost: 26.53s
Train Epoch: 316 	Average Loss: -1.5903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6776

Learning rate: 2.098449876243097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 1.6587	Cost: 53.80s
Train Epoch: 317 [40960/90000 (45%)]	Loss: -2.1198	Cost: 16.71s
Train Epoch: 317 [81920/90000 (91%)]	Loss: -1.9837	Cost: 18.41s
Train Epoch: 317 	Average Loss: -1.6117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6791

Learning rate: 2.050556466124901e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 1.2158	Cost: 51.87s
Train Epoch: 318 [40960/90000 (45%)]	Loss: -2.0032	Cost: 13.99s
Train Epoch: 318 [81920/90000 (91%)]	Loss: -1.8296	Cost: 17.74s
Train Epoch: 318 	Average Loss: -1.6505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8681

Learning rate: 2.0031534151290953e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 1.3078	Cost: 48.83s
Train Epoch: 319 [40960/90000 (45%)]	Loss: -2.0495	Cost: 9.54s
Train Epoch: 319 [81920/90000 (91%)]	Loss: -1.9109	Cost: 20.76s
Train Epoch: 319 	Average Loss: -1.6623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7143

Learning rate: 1.9562436472991562e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 1.5906	Cost: 34.02s
Train Epoch: 320 [40960/90000 (45%)]	Loss: -2.0515	Cost: 9.67s
Train Epoch: 320 [81920/90000 (91%)]	Loss: -1.7603	Cost: 25.85s
Train Epoch: 320 	Average Loss: -1.6558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6673

Learning rate: 1.9098300562505276e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 1.3489	Cost: 39.79s
Train Epoch: 321 [40960/90000 (45%)]	Loss: -2.0995	Cost: 10.67s
Train Epoch: 321 [81920/90000 (91%)]	Loss: -1.8251	Cost: 24.81s
Train Epoch: 321 	Average Loss: -1.7096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7007

Learning rate: 1.863915504992132e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 1.2246	Cost: 42.76s
Train Epoch: 322 [40960/90000 (45%)]	Loss: -2.1891	Cost: 16.45s
Train Epoch: 322 [81920/90000 (91%)]	Loss: -1.8230	Cost: 16.58s
Train Epoch: 322 	Average Loss: -1.7050
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6754

Learning rate: 1.8185028257497683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 1.5688	Cost: 43.26s
Train Epoch: 323 [40960/90000 (45%)]	Loss: -2.0981	Cost: 9.66s
Train Epoch: 323 [81920/90000 (91%)]	Loss: -1.8314	Cost: 19.13s
Train Epoch: 323 	Average Loss: -1.6986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4879

Saving model as e323_model.pt & e323_waveforms_supplementary.hdf5
Learning rate: 1.7735948197914044e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 1.5989	Cost: 34.34s
Train Epoch: 324 [40960/90000 (45%)]	Loss: -2.0862	Cost: 10.62s
Train Epoch: 324 [81920/90000 (91%)]	Loss: -1.8885	Cost: 28.05s
Train Epoch: 324 	Average Loss: -1.7020
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6339

Learning rate: 1.729194257254384e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 1.3280	Cost: 40.16s
Train Epoch: 325 [40960/90000 (45%)]	Loss: -2.1394	Cost: 16.79s
Train Epoch: 325 [81920/90000 (91%)]	Loss: -1.9083	Cost: 20.45s
Train Epoch: 325 	Average Loss: -1.7346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6374

Learning rate: 1.685303876974551e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 1.3652	Cost: 52.37s
Train Epoch: 326 [40960/90000 (45%)]	Loss: -2.1718	Cost: 12.92s
Train Epoch: 326 [81920/90000 (91%)]	Loss: -1.9017	Cost: 21.26s
Train Epoch: 326 	Average Loss: -1.7449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7158

Learning rate: 1.6419263863173007e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 1.6338	Cost: 38.76s
Train Epoch: 327 [40960/90000 (45%)]	Loss: -2.1754	Cost: 11.71s
Train Epoch: 327 [81920/90000 (91%)]	Loss: -1.9100	Cost: 17.62s
Train Epoch: 327 	Average Loss: -1.6948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6263

Learning rate: 1.599064461010582e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 1.5151	Cost: 39.98s
Train Epoch: 328 [40960/90000 (45%)]	Loss: -2.2031	Cost: 9.99s
Train Epoch: 328 [81920/90000 (91%)]	Loss: -1.9181	Cost: 27.13s
Train Epoch: 328 	Average Loss: -1.7309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6584

Learning rate: 1.5567207449798525e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 1.3197	Cost: 39.00s
Train Epoch: 329 [40960/90000 (45%)]	Loss: -2.2846	Cost: 16.84s
Train Epoch: 329 [81920/90000 (91%)]	Loss: -1.8244	Cost: 17.86s
Train Epoch: 329 	Average Loss: -1.7489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6009

Learning rate: 1.5148978501849652e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 1.6249	Cost: 44.30s
Train Epoch: 330 [40960/90000 (45%)]	Loss: -2.2065	Cost: 10.12s
Train Epoch: 330 [81920/90000 (91%)]	Loss: -2.0621	Cost: 19.33s
Train Epoch: 330 	Average Loss: -1.8128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5235

Learning rate: 1.4735983564590815e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 1.7453	Cost: 35.18s
Train Epoch: 331 [40960/90000 (45%)]	Loss: -2.4800	Cost: 10.51s
Train Epoch: 331 [81920/90000 (91%)]	Loss: -1.9625	Cost: 33.02s
Train Epoch: 331 	Average Loss: -1.7983
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5565

Learning rate: 1.4328248113495055e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 1.2475	Cost: 44.96s
Train Epoch: 332 [40960/90000 (45%)]	Loss: -2.2199	Cost: 16.97s
Train Epoch: 332 [81920/90000 (91%)]	Loss: -2.1298	Cost: 20.77s
Train Epoch: 332 	Average Loss: -1.8438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5902

Learning rate: 1.3925797299605635e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 1.1629	Cost: 51.31s
Train Epoch: 333 [40960/90000 (45%)]	Loss: -2.2834	Cost: 15.42s
Train Epoch: 333 [81920/90000 (91%)]	Loss: -2.0749	Cost: 15.85s
Train Epoch: 333 	Average Loss: -1.8147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4909

Learning rate: 1.3528655947984512e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 1.6662	Cost: 41.49s
Train Epoch: 334 [40960/90000 (45%)]	Loss: -2.2452	Cost: 10.18s
Train Epoch: 334 [81920/90000 (91%)]	Loss: -2.0336	Cost: 19.74s
Train Epoch: 334 	Average Loss: -1.7618
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5105

Learning rate: 1.3136848556180878e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 1.5662	Cost: 41.13s
Train Epoch: 335 [40960/90000 (45%)]	Loss: -2.2882	Cost: 10.02s
Train Epoch: 335 [81920/90000 (91%)]	Loss: -2.0286	Cost: 27.04s
Train Epoch: 335 	Average Loss: -1.8076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5873

Learning rate: 1.2750399292720314e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 1.2712	Cost: 40.47s
Train Epoch: 336 [40960/90000 (45%)]	Loss: -2.3283	Cost: 16.63s
Train Epoch: 336 [81920/90000 (91%)]	Loss: -1.8428	Cost: 17.89s
Train Epoch: 336 	Average Loss: -1.8453
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5384

Learning rate: 1.2369331995613651e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 1.3311	Cost: 40.80s
Train Epoch: 337 [40960/90000 (45%)]	Loss: -2.2216	Cost: 15.62s
Train Epoch: 337 [81920/90000 (91%)]	Loss: -1.8876	Cost: 13.92s
Train Epoch: 337 	Average Loss: -1.7781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6213

Learning rate: 1.1993670170886837e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 1.4538	Cost: 35.20s
Train Epoch: 338 [40960/90000 (45%)]	Loss: -2.5235	Cost: 9.82s
Train Epoch: 338 [81920/90000 (91%)]	Loss: -2.0372	Cost: 18.47s
Train Epoch: 338 	Average Loss: -1.8584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3530

Saving model as e338_model.pt & e338_waveforms_supplementary.hdf5
Learning rate: 1.1623436991130663e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 1.5682	Cost: 35.47s
Train Epoch: 339 [40960/90000 (45%)]	Loss: -2.4653	Cost: 10.89s
Train Epoch: 339 [81920/90000 (91%)]	Loss: -2.0768	Cost: 30.16s
Train Epoch: 339 	Average Loss: -1.8910
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5503

Learning rate: 1.1258655294071704e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 1.2466	Cost: 38.05s
Train Epoch: 340 [40960/90000 (45%)]	Loss: -2.4235	Cost: 17.42s
Train Epoch: 340 [81920/90000 (91%)]	Loss: -2.2043	Cost: 26.25s
Train Epoch: 340 	Average Loss: -1.9249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6801

Learning rate: 1.089934758116323e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 1.2595	Cost: 47.16s
Train Epoch: 341 [40960/90000 (45%)]	Loss: -2.3012	Cost: 11.28s
Train Epoch: 341 [81920/90000 (91%)]	Loss: -2.0291	Cost: 24.97s
Train Epoch: 341 	Average Loss: -1.9110
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4516

Learning rate: 1.054553601619753e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 1.3449	Cost: 39.51s
Train Epoch: 342 [40960/90000 (45%)]	Loss: -2.3411	Cost: 10.02s
Train Epoch: 342 [81920/90000 (91%)]	Loss: -2.1359	Cost: 25.11s
Train Epoch: 342 	Average Loss: -1.9314
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4741

Learning rate: 1.0197242423938455e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 1.5990	Cost: 37.35s
Train Epoch: 343 [40960/90000 (45%)]	Loss: -2.4800	Cost: 13.82s
Train Epoch: 343 [81920/90000 (91%)]	Loss: -2.1894	Cost: 21.16s
Train Epoch: 343 	Average Loss: -1.9414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4615

Learning rate: 9.854488288775428e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 1.5725	Cost: 42.25s
Train Epoch: 344 [40960/90000 (45%)]	Loss: -2.5957	Cost: 16.34s
Train Epoch: 344 [81920/90000 (91%)]	Loss: -2.2077	Cost: 16.32s
Train Epoch: 344 	Average Loss: -1.9581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4503

Learning rate: 9.517294753398073e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 1.6375	Cost: 43.73s
Train Epoch: 345 [40960/90000 (45%)]	Loss: -2.2914	Cost: 12.84s
Train Epoch: 345 [81920/90000 (91%)]	Loss: -2.2026	Cost: 14.86s
Train Epoch: 345 	Average Loss: -1.9560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4367

Learning rate: 9.185682617491872e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 1.6503	Cost: 35.72s
Train Epoch: 346 [40960/90000 (45%)]	Loss: -2.3627	Cost: 12.80s
Train Epoch: 346 [81920/90000 (91%)]	Loss: -2.2101	Cost: 19.43s
Train Epoch: 346 	Average Loss: -1.9052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3890

Learning rate: 8.859672336455501e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 1.5670	Cost: 36.20s
Train Epoch: 347 [40960/90000 (45%)]	Loss: -2.4771	Cost: 11.56s
Train Epoch: 347 [81920/90000 (91%)]	Loss: -2.1108	Cost: 27.32s
Train Epoch: 347 	Average Loss: -1.9803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3869

Learning rate: 8.539284020138645e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 1.4327	Cost: 42.31s
Train Epoch: 348 [40960/90000 (45%)]	Loss: -2.3752	Cost: 17.03s
Train Epoch: 348 [81920/90000 (91%)]	Loss: -2.2629	Cost: 18.77s
Train Epoch: 348 	Average Loss: -1.9881
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5133

Learning rate: 8.224537431601915e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 1.1289	Cost: 52.93s
Train Epoch: 349 [40960/90000 (45%)]	Loss: -2.4078	Cost: 16.15s
Train Epoch: 349 [81920/90000 (91%)]	Loss: -2.2314	Cost: 16.47s
Train Epoch: 349 	Average Loss: -1.9971
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4344

Learning rate: 7.915451985897387e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 1.4379	Cost: 54.56s
Train Epoch: 350 [40960/90000 (45%)]	Loss: -2.3226	Cost: 9.65s
Train Epoch: 350 [81920/90000 (91%)]	Loss: -2.3725	Cost: 21.67s
Train Epoch: 350 	Average Loss: -2.0071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4746

Learning rate: 7.612046748871354e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 1.1051	Cost: 41.14s
Train Epoch: 351 [40960/90000 (45%)]	Loss: -2.4649	Cost: 9.84s
Train Epoch: 351 [81920/90000 (91%)]	Loss: -2.5058	Cost: 26.57s
Train Epoch: 351 	Average Loss: -2.0390
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4527

Learning rate: 7.314340435987926e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 1.0907	Cost: 43.66s
Train Epoch: 352 [40960/90000 (45%)]	Loss: -2.2288	Cost: 16.21s
Train Epoch: 352 [81920/90000 (91%)]	Loss: -2.4451	Cost: 19.38s
Train Epoch: 352 	Average Loss: -1.9746
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5507

Learning rate: 7.022351411174871e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 1.1971	Cost: 37.53s
Train Epoch: 353 [40960/90000 (45%)]	Loss: -2.4643	Cost: 15.24s
Train Epoch: 353 [81920/90000 (91%)]	Loss: -2.2366	Cost: 11.64s
Train Epoch: 353 	Average Loss: -2.0001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4315

Learning rate: 6.736097685690606e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 1.3181	Cost: 41.70s
Train Epoch: 354 [40960/90000 (45%)]	Loss: -2.5516	Cost: 9.81s
Train Epoch: 354 [81920/90000 (91%)]	Loss: -2.3662	Cost: 19.82s
Train Epoch: 354 	Average Loss: -2.0617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3477

Saving model as e354_model.pt & e354_waveforms_supplementary.hdf5
Learning rate: 6.455596917013267e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 1.0577	Cost: 34.74s
Train Epoch: 355 [40960/90000 (45%)]	Loss: -2.5442	Cost: 9.89s
Train Epoch: 355 [81920/90000 (91%)]	Loss: -2.2872	Cost: 28.27s
Train Epoch: 355 	Average Loss: -2.0790
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3401

Saving model as e355_model.pt & e355_waveforms_supplementary.hdf5
Learning rate: 6.1808664077516005e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 1.4088	Cost: 40.61s
Train Epoch: 356 [40960/90000 (45%)]	Loss: -2.6024	Cost: 16.53s
Train Epoch: 356 [81920/90000 (91%)]	Loss: -2.2965	Cost: 21.51s
Train Epoch: 356 	Average Loss: -2.0157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4753

Learning rate: 5.91192310457746e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 1.1842	Cost: 37.80s
Train Epoch: 357 [40960/90000 (45%)]	Loss: -2.4849	Cost: 15.41s
Train Epoch: 357 [81920/90000 (91%)]	Loss: -2.2608	Cost: 17.41s
Train Epoch: 357 	Average Loss: -2.0279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3286

Saving model as e357_model.pt & e357_waveforms_supplementary.hdf5
Learning rate: 5.648783597180656e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 0.9329	Cost: 41.64s
Train Epoch: 358 [40960/90000 (45%)]	Loss: -2.5424	Cost: 9.86s
Train Epoch: 358 [81920/90000 (91%)]	Loss: -2.2765	Cost: 26.33s
Train Epoch: 358 	Average Loss: -2.0715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4676

Learning rate: 5.3914641172454745e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 1.3512	Cost: 43.78s
Train Epoch: 359 [40960/90000 (45%)]	Loss: -2.4632	Cost: 10.00s
Train Epoch: 359 [81920/90000 (91%)]	Loss: -2.2492	Cost: 25.21s
Train Epoch: 359 	Average Loss: -2.0613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3504

Learning rate: 5.139980537449555e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 1.4003	Cost: 43.37s
Train Epoch: 360 [40960/90000 (45%)]	Loss: -2.6722	Cost: 13.99s
Train Epoch: 360 [81920/90000 (91%)]	Loss: -2.2977	Cost: 20.80s
Train Epoch: 360 	Average Loss: -2.1030
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3808

Learning rate: 4.894348370484651e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 1.3192	Cost: 45.12s
Train Epoch: 361 [40960/90000 (45%)]	Loss: -2.5633	Cost: 15.75s
Train Epoch: 361 [81920/90000 (91%)]	Loss: -2.4131	Cost: 12.73s
Train Epoch: 361 	Average Loss: -2.1049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3350

Learning rate: 4.6545827680998834e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 0.9778	Cost: 39.04s
Train Epoch: 362 [40960/90000 (45%)]	Loss: -2.3978	Cost: 9.65s
Train Epoch: 362 [81920/90000 (91%)]	Loss: -2.4898	Cost: 20.08s
Train Epoch: 362 	Average Loss: -2.1116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3472

Learning rate: 4.420698520166991e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 1.1693	Cost: 34.94s
Train Epoch: 363 [40960/90000 (45%)]	Loss: -2.6250	Cost: 9.75s
Train Epoch: 363 [81920/90000 (91%)]	Loss: -2.4756	Cost: 28.11s
Train Epoch: 363 	Average Loss: -2.1164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4451

Learning rate: 4.1927100537680815e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 1.2024	Cost: 39.04s
Train Epoch: 364 [40960/90000 (45%)]	Loss: -2.6188	Cost: 12.85s
Train Epoch: 364 [81920/90000 (91%)]	Loss: -2.3899	Cost: 17.91s
Train Epoch: 364 	Average Loss: -2.1271
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2457

Saving model as e364_model.pt & e364_waveforms_supplementary.hdf5
Learning rate: 3.970631432305708e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 1.2728	Cost: 43.10s
Train Epoch: 365 [40960/90000 (45%)]	Loss: -2.5828	Cost: 11.78s
Train Epoch: 365 [81920/90000 (91%)]	Loss: -2.4702	Cost: 17.97s
Train Epoch: 365 	Average Loss: -2.1427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4841

Learning rate: 3.7544763546352753e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 1.5591	Cost: 38.90s
Train Epoch: 366 [40960/90000 (45%)]	Loss: -2.5811	Cost: 10.38s
Train Epoch: 366 [81920/90000 (91%)]	Loss: -2.2852	Cost: 27.53s
Train Epoch: 366 	Average Loss: -2.0959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2615

Learning rate: 3.5442581542202067e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 1.0326	Cost: 42.21s
Train Epoch: 367 [40960/90000 (45%)]	Loss: -2.6687	Cost: 12.05s
Train Epoch: 367 [81920/90000 (91%)]	Loss: -2.2686	Cost: 26.06s
Train Epoch: 367 	Average Loss: -2.1677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2609

Learning rate: 3.339989798309276e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 1.2307	Cost: 53.79s
Train Epoch: 368 [40960/90000 (45%)]	Loss: -2.7553	Cost: 16.65s
Train Epoch: 368 [81920/90000 (91%)]	Loss: -2.3586	Cost: 16.89s
Train Epoch: 368 	Average Loss: -2.1482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3473

Learning rate: 3.1416838871369064e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 1.3924	Cost: 48.09s
Train Epoch: 369 [40960/90000 (45%)]	Loss: -2.6845	Cost: 15.30s
Train Epoch: 369 [81920/90000 (91%)]	Loss: -2.3857	Cost: 15.61s
Train Epoch: 369 	Average Loss: -2.0840
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3367

Learning rate: 2.9493526531457563e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 1.1450	Cost: 52.31s
Train Epoch: 370 [40960/90000 (45%)]	Loss: -2.6544	Cost: 10.04s
Train Epoch: 370 [81920/90000 (91%)]	Loss: -2.5543	Cost: 20.24s
Train Epoch: 370 	Average Loss: -2.1757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3850

Learning rate: 2.7630079602323468e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 1.1027	Cost: 39.75s
Train Epoch: 371 [40960/90000 (45%)]	Loss: -2.7058	Cost: 9.87s
Train Epoch: 371 [81920/90000 (91%)]	Loss: -2.4846	Cost: 27.47s
Train Epoch: 371 	Average Loss: -2.1718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3427

Learning rate: 2.582661303015068e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 1.0098	Cost: 43.43s
Train Epoch: 372 [40960/90000 (45%)]	Loss: -2.5929	Cost: 16.06s
Train Epoch: 372 [81920/90000 (91%)]	Loss: -2.3006	Cost: 19.20s
Train Epoch: 372 	Average Loss: -2.1470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4211

Learning rate: 2.40832380612527e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 1.4034	Cost: 39.66s
Train Epoch: 373 [40960/90000 (45%)]	Loss: -2.6588	Cost: 11.79s
Train Epoch: 373 [81920/90000 (91%)]	Loss: -2.2548	Cost: 18.07s
Train Epoch: 373 	Average Loss: -2.1611
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3396

Learning rate: 2.2400062235209426e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 1.0158	Cost: 35.08s
Train Epoch: 374 [40960/90000 (45%)]	Loss: -2.5576	Cost: 12.98s
Train Epoch: 374 [81920/90000 (91%)]	Loss: -2.3377	Cost: 19.15s
Train Epoch: 374 	Average Loss: -2.1705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5057

Learning rate: 2.0777189378234156e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 1.2152	Cost: 37.84s
Train Epoch: 375 [40960/90000 (45%)]	Loss: -2.5711	Cost: 11.51s
Train Epoch: 375 [81920/90000 (91%)]	Loss: -2.2835	Cost: 33.50s
Train Epoch: 375 	Average Loss: -2.1669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2698

Learning rate: 1.9214719596769582e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 1.1057	Cost: 61.43s
Train Epoch: 376 [40960/90000 (45%)]	Loss: -2.4960	Cost: 13.60s
Train Epoch: 376 [81920/90000 (91%)]	Loss: -2.4157	Cost: 13.96s
Train Epoch: 376 	Average Loss: -2.1704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2799

Learning rate: 1.771274927131129e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 0.8586	Cost: 37.86s
Train Epoch: 377 [40960/90000 (45%)]	Loss: -2.5542	Cost: 12.23s
Train Epoch: 377 [81920/90000 (91%)]	Loss: -2.5541	Cost: 17.62s
Train Epoch: 377 	Average Loss: -2.1879
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3031

Learning rate: 1.6271371050464177e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 1.4447	Cost: 33.10s
Train Epoch: 378 [40960/90000 (45%)]	Loss: -2.5758	Cost: 9.89s
Train Epoch: 378 [81920/90000 (91%)]	Loss: -2.4116	Cost: 28.00s
Train Epoch: 378 	Average Loss: -2.1724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3805

Learning rate: 1.4890673845226142e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 1.1999	Cost: 37.17s
Train Epoch: 379 [40960/90000 (45%)]	Loss: -2.7003	Cost: 16.83s
Train Epoch: 379 [81920/90000 (91%)]	Loss: -2.6101	Cost: 18.67s
Train Epoch: 379 	Average Loss: -2.2178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4518

Learning rate: 1.3570742823504575e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 1.0441	Cost: 37.99s
Train Epoch: 380 [40960/90000 (45%)]	Loss: -2.6906	Cost: 16.86s
Train Epoch: 380 [81920/90000 (91%)]	Loss: -2.5745	Cost: 16.50s
Train Epoch: 380 	Average Loss: -2.1773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4427

Learning rate: 1.2311659404862349e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 0.9520	Cost: 41.87s
Train Epoch: 381 [40960/90000 (45%)]	Loss: -2.5309	Cost: 14.08s
Train Epoch: 381 [81920/90000 (91%)]	Loss: -2.4056	Cost: 17.08s
Train Epoch: 381 	Average Loss: -2.1801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3102

Learning rate: 1.1113501255495491e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 1.0684	Cost: 41.41s
Train Epoch: 382 [40960/90000 (45%)]	Loss: -2.5299	Cost: 11.29s
Train Epoch: 382 [81920/90000 (91%)]	Loss: -2.3730	Cost: 25.14s
Train Epoch: 382 	Average Loss: -2.1791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4310

Learning rate: 9.97634228344247e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 1.1342	Cost: 43.22s
Train Epoch: 383 [40960/90000 (45%)]	Loss: -2.6265	Cost: 12.13s
Train Epoch: 383 [81920/90000 (91%)]	Loss: -2.2410	Cost: 24.71s
Train Epoch: 383 	Average Loss: -2.1716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3819

Learning rate: 8.90025263402528e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 1.3211	Cost: 50.40s
Train Epoch: 384 [40960/90000 (45%)]	Loss: -2.6902	Cost: 17.01s
Train Epoch: 384 [81920/90000 (91%)]	Loss: -2.4820	Cost: 17.21s
Train Epoch: 384 	Average Loss: -2.1976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3807

Learning rate: 7.88529868552224e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 1.2651	Cost: 44.38s
Train Epoch: 385 [40960/90000 (45%)]	Loss: -2.6364	Cost: 16.27s
Train Epoch: 385 [81920/90000 (91%)]	Loss: -2.4444	Cost: 14.13s
Train Epoch: 385 	Average Loss: -2.1762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4841

Learning rate: 6.931543045073711e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 1.3280	Cost: 38.79s
Train Epoch: 386 [40960/90000 (45%)]	Loss: -2.6687	Cost: 9.55s
Train Epoch: 386 [81920/90000 (91%)]	Loss: -2.4174	Cost: 21.01s
Train Epoch: 386 	Average Loss: -2.1706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4300

Learning rate: 6.039044544820409e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 1.2568	Cost: 36.29s
Train Epoch: 387 [40960/90000 (45%)]	Loss: -2.6851	Cost: 9.88s
Train Epoch: 387 [81920/90000 (91%)]	Loss: -2.4479	Cost: 27.53s
Train Epoch: 387 	Average Loss: -2.1692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2743

Learning rate: 5.207858238273524e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 1.4042	Cost: 40.77s
Train Epoch: 388 [40960/90000 (45%)]	Loss: -2.6967	Cost: 16.14s
Train Epoch: 388 [81920/90000 (91%)]	Loss: -2.4477	Cost: 16.58s
Train Epoch: 388 	Average Loss: -2.1896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3864

Learning rate: 4.4380353969200063e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 1.4798	Cost: 42.04s
Train Epoch: 389 [40960/90000 (45%)]	Loss: -2.4879	Cost: 13.26s
Train Epoch: 389 [81920/90000 (91%)]	Loss: -2.4518	Cost: 15.57s
Train Epoch: 389 	Average Loss: -2.1797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3287

Learning rate: 3.7296235070587456e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 1.4258	Cost: 40.72s
Train Epoch: 390 [40960/90000 (45%)]	Loss: -2.7688	Cost: 9.61s
Train Epoch: 390 [81920/90000 (91%)]	Loss: -2.5241	Cost: 23.93s
Train Epoch: 390 	Average Loss: -2.1838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4755

Learning rate: 3.082666266872038e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 0.8439	Cost: 34.52s
Train Epoch: 391 [40960/90000 (45%)]	Loss: -2.8972	Cost: 9.88s
Train Epoch: 391 [81920/90000 (91%)]	Loss: -2.4435	Cost: 25.90s
Train Epoch: 391 	Average Loss: -2.2405
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2102

Saving model as e391_model.pt & e391_waveforms_supplementary.hdf5
Learning rate: 2.497203583729958e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 1.2078	Cost: 36.55s
Train Epoch: 392 [40960/90000 (45%)]	Loss: -2.6752	Cost: 16.58s
Train Epoch: 392 [81920/90000 (91%)]	Loss: -2.4437	Cost: 16.30s
Train Epoch: 392 	Average Loss: -2.2052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4407

Learning rate: 1.973271571728442e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 1.0397	Cost: 36.29s
Train Epoch: 393 [40960/90000 (45%)]	Loss: -2.6488	Cost: 16.15s
Train Epoch: 393 [81920/90000 (91%)]	Loss: -2.4210	Cost: 16.16s
Train Epoch: 393 	Average Loss: -2.2097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2107

Learning rate: 1.5109025494620685e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 0.9882	Cost: 40.19s
Train Epoch: 394 [40960/90000 (45%)]	Loss: -2.8746	Cost: 16.71s
Train Epoch: 394 [81920/90000 (91%)]	Loss: -2.4460	Cost: 16.30s
Train Epoch: 394 	Average Loss: -2.2269
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3003

Learning rate: 1.1101250380300971e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 1.6942	Cost: 38.34s
Train Epoch: 395 [40960/90000 (45%)]	Loss: -2.6982	Cost: 16.04s
Train Epoch: 395 [81920/90000 (91%)]	Loss: -2.4233	Cost: 15.75s
Train Epoch: 395 	Average Loss: -2.1897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3715

Learning rate: 7.709637592770994e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 1.3477	Cost: 44.26s
Train Epoch: 396 [40960/90000 (45%)]	Loss: -2.6114	Cost: 13.40s
Train Epoch: 396 [81920/90000 (91%)]	Loss: -2.3026	Cost: 17.05s
Train Epoch: 396 	Average Loss: -2.1902
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3412

Learning rate: 4.934396342684002e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 1.4234	Cost: 38.14s
Train Epoch: 397 [40960/90000 (45%)]	Loss: -2.7856	Cost: 12.57s
Train Epoch: 397 [81920/90000 (91%)]	Loss: -2.5066	Cost: 14.03s
Train Epoch: 397 	Average Loss: -2.1698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4392

Learning rate: 2.7756978199944282e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 0.9831	Cost: 33.23s
Train Epoch: 398 [40960/90000 (45%)]	Loss: -2.7469	Cost: 9.97s
Train Epoch: 398 [81920/90000 (91%)]	Loss: -2.6184	Cost: 27.54s
Train Epoch: 398 	Average Loss: -2.2213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4008

Learning rate: 1.2336751833941234e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 1.2960	Cost: 39.39s
Train Epoch: 399 [40960/90000 (45%)]	Loss: -2.6457	Cost: 16.01s
Train Epoch: 399 [81920/90000 (91%)]	Loss: -2.3983	Cost: 21.14s
Train Epoch: 399 	Average Loss: -2.1829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4027

Learning rate: 3.084235521033653e-09
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 1.1634	Cost: 41.05s
Train Epoch: 400 [40960/90000 (45%)]	Loss: -2.7787	Cost: 12.62s
Train Epoch: 400 [81920/90000 (91%)]	Loss: -2.4042	Cost: 20.51s
Train Epoch: 400 	Average Loss: -2.2114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4358

Stopping timer.
Training time (including validation): 107313.79731559753 seconds
Saving model
Transfer learning by starting with alpha=0.6!
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 29.7717	Cost: 35.66s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 15.1280	Cost: 11.85s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 12.7424	Cost: 28.17s
Train Epoch: 1 	Average Loss: 16.2160
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0290

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999691576447898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 12.6884	Cost: 39.63s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 11.7696	Cost: 15.49s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 10.7924	Cost: 22.13s
Train Epoch: 2 	Average Loss: 11.6951
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0308

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 10.8397	Cost: 42.80s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 10.2474	Cost: 15.90s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 9.9635	Cost: 12.80s
Train Epoch: 3 	Average Loss: 10.3106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1235

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 9.9595	Cost: 46.64s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 9.5321	Cost: 9.83s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 9.2814	Cost: 23.10s
Train Epoch: 4 	Average Loss: 9.4918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5363

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.00019995065603657316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 9.4797	Cost: 40.62s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 8.9476	Cost: 9.88s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 8.6317	Cost: 24.82s
Train Epoch: 5 	Average Loss: 8.9600
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2412

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.0001999229036240723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 9.0429	Cost: 44.58s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 8.6003	Cost: 16.53s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 8.2108	Cost: 16.06s
Train Epoch: 6 	Average Loss: 8.5778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9587

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019988898749619702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 8.2806	Cost: 43.40s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 8.3285	Cost: 10.53s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 8.0406	Cost: 21.04s
Train Epoch: 7 	Average Loss: 8.1698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7277

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.00019984890974505381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 8.4122	Cost: 37.78s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 8.0139	Cost: 9.91s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 7.7254	Cost: 25.85s
Train Epoch: 8 	Average Loss: 7.9036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5662

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.00019980267284282717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 8.1380	Cost: 38.77s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 7.7828	Cost: 15.36s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 7.5546	Cost: 21.62s
Train Epoch: 9 	Average Loss: 7.6489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4313

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019975027964162705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 8.0049	Cost: 42.72s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 7.3661	Cost: 9.80s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 7.3859	Cost: 29.44s
Train Epoch: 10 	Average Loss: 7.4502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4355

Learning rate: 0.00019969173337331284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 7.6782	Cost: 46.14s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 7.2784	Cost: 10.04s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 7.1491	Cost: 25.57s
Train Epoch: 11 	Average Loss: 7.3166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2458

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 0.00019962703764929416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 7.9917	Cost: 44.75s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 7.4471	Cost: 16.47s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 7.2731	Cost: 16.13s
Train Epoch: 12 	Average Loss: 7.3016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3899

Learning rate: 0.00019955619646030802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 7.9145	Cost: 51.48s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 7.0813	Cost: 14.63s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 7.2500	Cost: 15.76s
Train Epoch: 13 	Average Loss: 7.2364
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2839

Learning rate: 0.00019947921417617267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 7.8921	Cost: 43.71s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 7.0879	Cost: 12.77s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 7.4191	Cost: 15.95s
Train Epoch: 14 	Average Loss: 7.2527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5420

Learning rate: 0.000199396095545518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 7.9439	Cost: 37.50s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 7.2729	Cost: 12.59s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 7.1258	Cost: 16.51s
Train Epoch: 15 	Average Loss: 7.1961
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2694

Learning rate: 0.00019930684569549264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 7.6113	Cost: 34.51s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 6.9820	Cost: 9.97s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 6.7720	Cost: 26.55s
Train Epoch: 16 	Average Loss: 6.9874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2014

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Learning rate: 0.0001992114701314478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 7.6014	Cost: 37.50s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 7.1295	Cost: 16.69s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 6.7685	Cost: 16.79s
Train Epoch: 17 	Average Loss: 6.9876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0659

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Learning rate: 0.00019910997473659747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 7.7887	Cost: 38.56s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 7.0330	Cost: 16.62s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 6.8699	Cost: 16.87s
Train Epoch: 18 	Average Loss: 6.8397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1814

Learning rate: 0.00019900236577165574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 7.5305	Cost: 37.51s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 6.7559	Cost: 16.71s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 6.7026	Cost: 10.22s
Train Epoch: 19 	Average Loss: 6.8324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0385

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Learning rate: 0.00019888864987445046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 7.3880	Cost: 37.90s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 7.0846	Cost: 9.76s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 7.0247	Cost: 19.20s
Train Epoch: 20 	Average Loss: 6.8792
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2940

Learning rate: 0.00019876883405951377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 7.5264	Cost: 34.40s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 6.8052	Cost: 10.53s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 6.4169	Cost: 30.32s
Train Epoch: 21 	Average Loss: 6.7978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9522

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Learning rate: 0.00019864292571764955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 7.4578	Cost: 36.99s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 6.5512	Cost: 17.54s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 6.6797	Cost: 24.95s
Train Epoch: 22 	Average Loss: 6.6607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8532

Saving model as e22_model.pt & e22_waveforms_supplementary.hdf5
Learning rate: 0.0001985109326154774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 7.8502	Cost: 36.46s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 6.6431	Cost: 16.99s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 6.6065	Cost: 15.33s
Train Epoch: 23 	Average Loss: 6.6099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9745

Learning rate: 0.00019837286289495361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 7.1992	Cost: 39.21s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 6.6405	Cost: 9.97s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 6.4153	Cost: 27.54s
Train Epoch: 24 	Average Loss: 6.5555
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8898

Learning rate: 0.0001982287250728689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 7.6340	Cost: 41.34s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 6.6042	Cost: 9.83s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 6.5090	Cost: 27.62s
Train Epoch: 25 	Average Loss: 6.5636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0039

Learning rate: 0.00019807852804032305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 7.2873	Cost: 45.69s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 6.6472	Cost: 16.05s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 6.4430	Cost: 19.81s
Train Epoch: 26 	Average Loss: 6.5058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0647

Learning rate: 0.00019792228106217658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 7.1557	Cost: 50.12s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 6.4636	Cost: 16.34s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 6.1630	Cost: 13.03s
Train Epoch: 27 	Average Loss: 6.4061
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0401

Learning rate: 0.0001977599937764791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 7.5448	Cost: 44.87s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 6.2744	Cost: 11.03s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 6.3716	Cost: 18.40s
Train Epoch: 28 	Average Loss: 6.3893
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8738

Learning rate: 0.00019759167619387474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 7.3665	Cost: 38.09s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 6.3718	Cost: 11.32s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 6.2227	Cost: 19.73s
Train Epoch: 29 	Average Loss: 6.3386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9198

Learning rate: 0.00019741733869698495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 7.1766	Cost: 40.41s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 6.2878	Cost: 9.88s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 6.6643	Cost: 23.30s
Train Epoch: 30 	Average Loss: 6.4018
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9875

Learning rate: 0.00019723699203976766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 7.6600	Cost: 44.39s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 6.7306	Cost: 16.78s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 6.2359	Cost: 16.86s
Train Epoch: 31 	Average Loss: 6.4824
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0108

Learning rate: 0.00019705064734685425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 7.4905	Cost: 44.28s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 6.3536	Cost: 14.68s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 6.5068	Cost: 15.22s
Train Epoch: 32 	Average Loss: 6.3829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9642

Learning rate: 0.00019685831611286313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 7.5132	Cost: 40.67s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 6.3942	Cost: 9.54s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 6.2481	Cost: 22.04s
Train Epoch: 33 	Average Loss: 6.3285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0491

Learning rate: 0.00019666001020169073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 7.2072	Cost: 34.41s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 6.2808	Cost: 10.69s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 6.1523	Cost: 18.48s
Train Epoch: 34 	Average Loss: 6.3246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8410

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Learning rate: 0.0001964557418457798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 7.2379	Cost: 36.22s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 6.1906	Cost: 14.04s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 6.0636	Cost: 18.57s
Train Epoch: 35 	Average Loss: 6.1531
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8456

Learning rate: 0.0001962455236453647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 7.3829	Cost: 37.72s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 6.5059	Cost: 16.92s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 6.2517	Cost: 16.70s
Train Epoch: 36 	Average Loss: 6.2711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9876

Learning rate: 0.00019602936856769428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 7.2493	Cost: 37.91s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 6.0490	Cost: 14.50s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 6.3655	Cost: 13.90s
Train Epoch: 37 	Average Loss: 6.2281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0360

Learning rate: 0.0001958072899462319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 7.1602	Cost: 39.19s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 6.1070	Cost: 9.63s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 5.9317	Cost: 26.01s
Train Epoch: 38 	Average Loss: 6.1129
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9148

Learning rate: 0.00019557930147983297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 7.2608	Cost: 32.63s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 6.0757	Cost: 11.63s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 5.7615	Cost: 30.21s
Train Epoch: 39 	Average Loss: 6.0609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7970

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Learning rate: 0.00019534541723190008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 7.0803	Cost: 37.99s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 5.9590	Cost: 17.57s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 5.7563	Cost: 17.54s
Train Epoch: 40 	Average Loss: 6.0194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8540

Learning rate: 0.00019510565162951532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 7.1628	Cost: 48.74s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 5.7570	Cost: 15.13s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 5.6558	Cost: 14.77s
Train Epoch: 41 	Average Loss: 5.9598
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9002

Learning rate: 0.0001948600194625504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 7.1208	Cost: 48.45s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 6.0135	Cost: 9.85s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 5.9177	Cost: 23.72s
Train Epoch: 42 	Average Loss: 5.9614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8267

Learning rate: 0.00019460853588275446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 7.0402	Cost: 36.68s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 5.9515	Cost: 9.68s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 5.8771	Cost: 25.00s
Train Epoch: 43 	Average Loss: 5.9080
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7837

Saving model as e43_model.pt & e43_waveforms_supplementary.hdf5
Learning rate: 0.0001943512164028193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 7.2224	Cost: 40.80s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 6.3290	Cost: 14.27s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 6.1385	Cost: 20.04s
Train Epoch: 44 	Average Loss: 6.1419
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8971

Learning rate: 0.00019408807689542249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 7.3882	Cost: 40.85s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 5.8768	Cost: 16.79s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 5.7690	Cost: 16.65s
Train Epoch: 45 	Average Loss: 6.0637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6683

Saving model as e45_model.pt & e45_waveforms_supplementary.hdf5
Learning rate: 0.00019381913359224837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 6.8320	Cost: 35.89s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 5.7991	Cost: 14.56s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 5.6048	Cost: 12.52s
Train Epoch: 46 	Average Loss: 5.8408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5143

Saving model as e46_model.pt & e46_waveforms_supplementary.hdf5
Learning rate: 0.0001935444030829867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 6.9621	Cost: 38.96s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 5.8161	Cost: 9.65s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 5.6594	Cost: 17.70s
Train Epoch: 47 	Average Loss: 5.8346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6554

Learning rate: 0.00019326390231430937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 7.0824	Cost: 34.89s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 5.5957	Cost: 9.79s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 5.6699	Cost: 26.89s
Train Epoch: 48 	Average Loss: 5.8273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7046

Learning rate: 0.00019297764858882508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 7.0743	Cost: 37.36s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 5.8519	Cost: 17.74s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 5.8293	Cost: 21.52s
Train Epoch: 49 	Average Loss: 5.9568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7103

Learning rate: 0.000192685659564012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 7.1646	Cost: 40.30s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 5.5527	Cost: 15.35s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 5.5121	Cost: 22.95s
Train Epoch: 50 	Average Loss: 5.8275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6776

Learning rate: 0.00019238795325112859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 6.6813	Cost: 40.15s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 5.5312	Cost: 12.33s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 5.5831	Cost: 22.37s
Train Epoch: 51 	Average Loss: 5.7690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5851

Learning rate: 0.00019208454801410258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 6.9761	Cost: 38.73s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 5.6948	Cost: 10.13s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 5.6183	Cost: 26.23s
Train Epoch: 52 	Average Loss: 5.6960
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6055

Learning rate: 0.00019177546256839804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 7.1320	Cost: 44.32s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 5.5388	Cost: 16.76s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 5.3162	Cost: 16.78s
Train Epoch: 53 	Average Loss: 5.6803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7817

Learning rate: 0.0001914607159798613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 6.7485	Cost: 46.24s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 5.4930	Cost: 13.92s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 5.4031	Cost: 12.74s
Train Epoch: 54 	Average Loss: 5.5677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7114

Learning rate: 0.00019114032766354445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 6.7852	Cost: 48.41s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 5.4639	Cost: 9.82s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 5.4708	Cost: 18.89s
Train Epoch: 55 	Average Loss: 5.5627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7540

Learning rate: 0.00019081431738250806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 7.0120	Cost: 36.18s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 5.4859	Cost: 9.57s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 5.3914	Cost: 22.95s
Train Epoch: 56 	Average Loss: 5.5067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6937

Learning rate: 0.00019048270524660188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 6.8517	Cost: 38.78s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 5.4836	Cost: 9.98s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 5.3411	Cost: 25.19s
Train Epoch: 57 	Average Loss: 5.5952
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6480

Learning rate: 0.0001901455117112245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 6.8861	Cost: 42.59s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 5.4244	Cost: 16.61s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 5.6457	Cost: 17.57s
Train Epoch: 58 	Average Loss: 5.6579
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9693

Learning rate: 0.0001898027575760615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 7.2091	Cost: 42.05s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 5.6061	Cost: 10.67s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 5.6107	Cost: 17.51s
Train Epoch: 59 	Average Loss: 5.8325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7235

Learning rate: 0.00018945446398380245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 6.9615	Cost: 34.25s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 5.7046	Cost: 10.91s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 5.7474	Cost: 28.15s
Train Epoch: 60 	Average Loss: 5.8529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8497

Learning rate: 0.00018910065241883672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 6.9665	Cost: 37.25s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 5.4802	Cost: 17.20s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 5.5238	Cost: 23.86s
Train Epoch: 61 	Average Loss: 5.6589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6800

Learning rate: 0.00018874134470592827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 6.9949	Cost: 40.90s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 5.5813	Cost: 13.62s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 5.4742	Cost: 23.74s
Train Epoch: 62 	Average Loss: 5.5600
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4551

Saving model as e62_model.pt & e62_waveforms_supplementary.hdf5
Learning rate: 0.0001883765630088693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 6.8935	Cost: 42.47s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 5.2530	Cost: 9.69s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 5.1739	Cost: 23.50s
Train Epoch: 63 	Average Loss: 5.4411
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6703

Learning rate: 0.00018800632982911313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 6.9451	Cost: 42.87s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 5.3244	Cost: 10.01s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 5.1484	Cost: 24.76s
Train Epoch: 64 	Average Loss: 5.3471
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5510

Learning rate: 0.00018763066800438628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 6.7193	Cost: 49.07s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 5.3502	Cost: 16.37s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 5.3715	Cost: 16.01s
Train Epoch: 65 	Average Loss: 5.4627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6461

Learning rate: 0.00018724960070727966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 7.0043	Cost: 48.06s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 5.1930	Cost: 10.66s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 5.0373	Cost: 20.48s
Train Epoch: 66 	Average Loss: 5.3593
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7054

Learning rate: 0.00018686315144381908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 6.9743	Cost: 36.81s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 5.3616	Cost: 12.63s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 4.9408	Cost: 16.13s
Train Epoch: 67 	Average Loss: 5.3930
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5836

Learning rate: 0.00018647134405201546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 7.0970	Cost: 37.48s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 5.1098	Cost: 9.74s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 5.5896	Cost: 25.69s
Train Epoch: 68 	Average Loss: 5.4853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6652

Learning rate: 0.00018607420270039433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 7.1596	Cost: 40.01s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 6.1401	Cost: 16.10s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 5.6174	Cost: 20.84s
Train Epoch: 69 	Average Loss: 5.8236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6744

Learning rate: 0.00018567175188650495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 6.9959	Cost: 41.94s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 5.5249	Cost: 12.77s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 5.3246	Cost: 19.18s
Train Epoch: 70 	Average Loss: 5.5334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6130

Learning rate: 0.0001852640164354092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 6.9021	Cost: 39.35s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 5.4024	Cost: 13.09s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 5.2400	Cost: 22.68s
Train Epoch: 71 	Average Loss: 5.4788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5734

Learning rate: 0.00018485102149815036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 7.0432	Cost: 44.60s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 5.2172	Cost: 10.11s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 5.0834	Cost: 24.57s
Train Epoch: 72 	Average Loss: 5.3452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5301

Learning rate: 0.0001844327925502015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 6.7145	Cost: 45.76s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 5.0117	Cost: 16.66s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 4.9322	Cost: 17.80s
Train Epoch: 73 	Average Loss: 5.1955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5445

Learning rate: 0.00018400935538989417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 6.5578	Cost: 46.49s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 4.9070	Cost: 16.43s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 5.1202	Cost: 14.54s
Train Epoch: 74 	Average Loss: 5.0956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5370

Learning rate: 0.00018358073613682703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 6.9923	Cost: 40.78s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 4.9687	Cost: 9.67s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 5.0607	Cost: 17.53s
Train Epoch: 75 	Average Loss: 5.1816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5634

Learning rate: 0.00018314696123025452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 7.0414	Cost: 44.06s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 5.0165	Cost: 9.61s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 4.9659	Cost: 18.65s
Train Epoch: 76 	Average Loss: 5.1802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5221

Learning rate: 0.00018270805742745614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 6.7889	Cost: 42.31s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 5.2228	Cost: 9.56s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 4.8491	Cost: 17.83s
Train Epoch: 77 	Average Loss: 5.1536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5341

Learning rate: 0.00018226405180208597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 6.7042	Cost: 39.50s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 4.8459	Cost: 9.58s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 4.9380	Cost: 19.58s
Train Epoch: 78 	Average Loss: 5.0861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5055

Learning rate: 0.00018181497174250233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 6.7529	Cost: 44.88s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 5.0148	Cost: 9.63s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 4.8727	Cost: 19.52s
Train Epoch: 79 	Average Loss: 5.0271
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4146

Saving model as e79_model.pt & e79_waveforms_supplementary.hdf5
Learning rate: 0.00018136084495007872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 6.5562	Cost: 41.85s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 5.0409	Cost: 9.52s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 4.9717	Cost: 21.53s
Train Epoch: 80 	Average Loss: 5.0527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5763

Learning rate: 0.00018090169943749476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 6.7652	Cost: 39.40s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 5.0719	Cost: 9.97s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 4.9160	Cost: 24.04s
Train Epoch: 81 	Average Loss: 5.1275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5144

Learning rate: 0.00018043756352700846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 6.6816	Cost: 42.93s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 4.9471	Cost: 16.57s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 4.6925	Cost: 17.33s
Train Epoch: 82 	Average Loss: 5.0040
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4984

Learning rate: 0.00017996846584870908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 6.6570	Cost: 42.36s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 5.1327	Cost: 15.45s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 4.8914	Cost: 18.80s
Train Epoch: 83 	Average Loss: 5.0654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6061

Learning rate: 0.000179494435338751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 6.7079	Cost: 37.95s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 4.8683	Cost: 16.66s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 4.8553	Cost: 15.22s
Train Epoch: 84 	Average Loss: 5.0022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3673

Saving model as e84_model.pt & e84_waveforms_supplementary.hdf5
Learning rate: 0.00017901550123756904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 6.6260	Cost: 41.04s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 4.8910	Cost: 9.68s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 4.6260	Cost: 17.35s
Train Epoch: 85 	Average Loss: 5.0137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4844

Learning rate: 0.00017853169308807448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 6.6376	Cost: 36.93s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 4.6345	Cost: 12.78s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 4.6978	Cost: 17.27s
Train Epoch: 86 	Average Loss: 4.9557
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4603

Learning rate: 0.00017804304073383296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 6.5603	Cost: 32.82s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 4.6895	Cost: 10.42s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 4.6037	Cost: 30.25s
Train Epoch: 87 	Average Loss: 4.8508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3043

Saving model as e87_model.pt & e87_waveforms_supplementary.hdf5
Learning rate: 0.00017754957431722346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 6.8694	Cost: 40.19s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 4.4727	Cost: 14.91s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 4.5477	Cost: 21.80s
Train Epoch: 88 	Average Loss: 4.8386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4002

Learning rate: 0.00017705132427757892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 6.9751	Cost: 38.37s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 4.6908	Cost: 16.34s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 4.5477	Cost: 16.66s
Train Epoch: 89 	Average Loss: 4.8681
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4308

Learning rate: 0.00017654832134930882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 6.5384	Cost: 37.37s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 4.6776	Cost: 10.09s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 4.5145	Cost: 28.58s
Train Epoch: 90 	Average Loss: 4.7735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4280

Learning rate: 0.0001760405965600031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 6.5966	Cost: 45.95s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 4.8693	Cost: 10.05s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 4.7082	Cost: 24.90s
Train Epoch: 91 	Average Loss: 4.8622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4416

Learning rate: 0.00017552818122851838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 6.3806	Cost: 45.67s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 5.2937	Cost: 16.64s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 5.0003	Cost: 16.57s
Train Epoch: 92 	Average Loss: 5.1384
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5393

Learning rate: 0.00017501110696304596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 6.7932	Cost: 45.59s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 5.0796	Cost: 16.03s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 4.8937	Cost: 11.53s
Train Epoch: 93 	Average Loss: 5.1143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5315

Learning rate: 0.0001744894056591622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 6.8302	Cost: 47.74s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 4.6843	Cost: 10.94s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 4.7106	Cost: 17.98s
Train Epoch: 94 	Average Loss: 4.9274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5524

Learning rate: 0.00017396310949786096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 6.5485	Cost: 41.48s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 4.5800	Cost: 12.71s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 4.7696	Cost: 17.00s
Train Epoch: 95 	Average Loss: 4.8748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5544

Learning rate: 0.00017343225094356858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 6.7723	Cost: 35.89s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 5.0250	Cost: 10.01s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 5.2146	Cost: 25.85s
Train Epoch: 96 	Average Loss: 5.1490
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7312

Learning rate: 0.00017289686274214118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 7.0382	Cost: 37.46s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 4.9630	Cost: 17.08s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 4.8701	Cost: 16.78s
Train Epoch: 97 	Average Loss: 5.0568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4718

Learning rate: 0.00017235697791884494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 6.7630	Cost: 41.44s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 5.0032	Cost: 16.46s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 4.5750	Cost: 16.60s
Train Epoch: 98 	Average Loss: 4.9020
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5268

Learning rate: 0.0001718126297763189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 6.7750	Cost: 44.15s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 4.7008	Cost: 16.51s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 4.5500	Cost: 9.98s
Train Epoch: 99 	Average Loss: 4.7989
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3572

Learning rate: 0.00017126385189252056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 6.9201	Cost: 39.16s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 4.5703	Cost: 9.71s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 4.3650	Cost: 18.33s
Train Epoch: 100 	Average Loss: 4.6537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2946

Saving model as e100_model.pt & e100_waveforms_supplementary.hdf5
Learning rate: 0.00017071067811865479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 6.4741	Cost: 34.40s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 4.5136	Cost: 11.42s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 4.6520	Cost: 32.09s
Train Epoch: 101 	Average Loss: 4.7241
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3825

Learning rate: 0.00017015314257708562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 6.5921	Cost: 38.58s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 4.7200	Cost: 17.15s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 4.5292	Cost: 22.70s
Train Epoch: 102 	Average Loss: 4.7911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4111

Learning rate: 0.00016959127965923145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 6.3814	Cost: 40.09s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 4.5400	Cost: 16.74s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 4.6656	Cost: 16.68s
Train Epoch: 103 	Average Loss: 4.7420
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2985

Learning rate: 0.00016902512402344375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 6.6615	Cost: 42.21s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 4.3416	Cost: 16.94s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 4.4826	Cost: 14.31s
Train Epoch: 104 	Average Loss: 4.6877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3106

Learning rate: 0.0001684547105928689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 6.7574	Cost: 37.74s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 4.5278	Cost: 10.02s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 4.3911	Cost: 25.23s
Train Epoch: 105 	Average Loss: 4.5990
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1668

Saving model as e105_model.pt & e105_waveforms_supplementary.hdf5
Learning rate: 0.00016788007455329423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 6.7603	Cost: 42.70s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 4.4567	Cost: 9.72s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 4.3193	Cost: 26.53s
Train Epoch: 106 	Average Loss: 4.6494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4107

Learning rate: 0.00016730125135097737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 6.2630	Cost: 42.74s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 4.3893	Cost: 15.68s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 4.3680	Cost: 17.39s
Train Epoch: 107 	Average Loss: 4.5557
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3752

Learning rate: 0.00016671827669046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 6.5787	Cost: 44.03s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 4.2128	Cost: 16.30s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 3.9627	Cost: 16.33s
Train Epoch: 108 	Average Loss: 4.4370
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3061

Learning rate: 0.0001661311865323652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 6.1884	Cost: 40.83s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 4.1194	Cost: 9.67s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 4.1550	Cost: 19.32s
Train Epoch: 109 	Average Loss: 4.3835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2960

Learning rate: 0.00016554001709117943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 6.6086	Cost: 34.38s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 4.3001	Cost: 10.06s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 4.0962	Cost: 27.10s
Train Epoch: 110 	Average Loss: 4.4817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2290

Learning rate: 0.00016494480483301838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 6.5462	Cost: 36.96s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 4.3094	Cost: 17.67s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 4.1081	Cost: 23.89s
Train Epoch: 111 	Average Loss: 4.4074
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1167

Saving model as e111_model.pt & e111_waveforms_supplementary.hdf5
Learning rate: 0.0001643455864733779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 6.3627	Cost: 36.11s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 4.0979	Cost: 14.13s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 3.9800	Cost: 17.75s
Train Epoch: 112 	Average Loss: 4.3919
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2086

Learning rate: 0.000163742398974869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 6.1399	Cost: 40.87s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 4.5334	Cost: 13.49s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 4.6161	Cost: 22.69s
Train Epoch: 113 	Average Loss: 4.5226
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4767

Learning rate: 0.00016313527954493778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 6.9497	Cost: 41.46s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 4.5278	Cost: 12.83s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 4.1811	Cost: 16.67s
Train Epoch: 114 	Average Loss: 4.5749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3943

Learning rate: 0.00016252426563357055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 6.5435	Cost: 40.73s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 4.3877	Cost: 10.12s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 4.1613	Cost: 24.45s
Train Epoch: 115 	Average Loss: 4.4516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1867

Learning rate: 0.0001619093949309834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 6.1830	Cost: 45.31s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 4.0885	Cost: 16.26s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 4.0733	Cost: 16.77s
Train Epoch: 116 	Average Loss: 4.3034
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1885

Learning rate: 0.00016129070536529766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 6.2606	Cost: 51.33s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 4.1221	Cost: 13.42s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 4.1893	Cost: 15.01s
Train Epoch: 117 	Average Loss: 4.2742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0944

Saving model as e117_model.pt & e117_waveforms_supplementary.hdf5
Learning rate: 0.00016066823510019996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 6.2538	Cost: 37.65s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 3.9999	Cost: 12.52s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 4.1334	Cost: 15.44s
Train Epoch: 118 	Average Loss: 4.2440
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1470

Learning rate: 0.0001600420225325884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 6.4068	Cost: 35.54s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 4.2449	Cost: 9.61s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 4.0312	Cost: 26.33s
Train Epoch: 119 	Average Loss: 4.3107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1226

Learning rate: 0.00015941210629020385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 6.4162	Cost: 37.35s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 4.1990	Cost: 16.97s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 4.0956	Cost: 16.65s
Train Epoch: 120 	Average Loss: 4.3777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2675

Learning rate: 0.00015877852522924735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 6.5565	Cost: 38.35s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 4.2248	Cost: 16.77s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 4.2300	Cost: 13.76s
Train Epoch: 121 	Average Loss: 4.3893
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1734

Learning rate: 0.00015814131843198305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 6.2794	Cost: 41.19s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 4.0865	Cost: 9.61s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 4.0513	Cost: 18.50s
Train Epoch: 122 	Average Loss: 4.2539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0977

Learning rate: 0.00015750052520432787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 6.5491	Cost: 34.00s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 4.0421	Cost: 10.84s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 4.0523	Cost: 29.81s
Train Epoch: 123 	Average Loss: 4.3753
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2088

Learning rate: 0.0001568561850734264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 6.4095	Cost: 38.43s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 3.9716	Cost: 17.13s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 3.8809	Cost: 23.56s
Train Epoch: 124 	Average Loss: 4.2497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1935

Learning rate: 0.00015620833778521307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 6.1906	Cost: 52.25s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 3.9931	Cost: 12.11s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 4.0081	Cost: 21.17s
Train Epoch: 125 	Average Loss: 4.1843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1188

Learning rate: 0.00015555702330196023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 6.4543	Cost: 47.56s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 3.9967	Cost: 9.80s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 3.8050	Cost: 22.46s
Train Epoch: 126 	Average Loss: 4.0593
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2638

Learning rate: 0.00015490228179981317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 6.3691	Cost: 37.62s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 3.6688	Cost: 10.12s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 3.6074	Cost: 25.87s
Train Epoch: 127 	Average Loss: 4.0263
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2778

Learning rate: 0.00015424415366631188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 6.0167	Cost: 39.63s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 3.8310	Cost: 14.19s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 3.7719	Cost: 20.72s
Train Epoch: 128 	Average Loss: 3.9602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9300

Saving model as e128_model.pt & e128_waveforms_supplementary.hdf5
Learning rate: 0.00015358267949789966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 6.1681	Cost: 38.79s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 3.7112	Cost: 15.90s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 3.7931	Cost: 17.97s
Train Epoch: 129 	Average Loss: 3.9319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1610

Learning rate: 0.00015291790009741904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 6.1181	Cost: 38.28s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 3.6932	Cost: 13.22s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 3.6064	Cost: 13.98s
Train Epoch: 130 	Average Loss: 3.8954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1359

Learning rate: 0.00015224985647159487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 6.2459	Cost: 41.74s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 3.9242	Cost: 10.11s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 3.6630	Cost: 19.82s
Train Epoch: 131 	Average Loss: 4.0485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0594

Learning rate: 0.00015157858982850473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 5.9553	Cost: 35.04s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 3.7349	Cost: 10.59s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 3.6442	Cost: 29.01s
Train Epoch: 132 	Average Loss: 3.9177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0903

Learning rate: 0.0001509041415750371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 6.3121	Cost: 37.56s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 3.6896	Cost: 17.70s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 3.7814	Cost: 24.53s
Train Epoch: 133 	Average Loss: 3.9791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0174

Learning rate: 0.00015022655331433721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 6.2329	Cost: 36.28s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 3.7437	Cost: 15.54s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 3.6749	Cost: 16.45s
Train Epoch: 134 	Average Loss: 3.9427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0730

Learning rate: 0.00014954586684324072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 6.2273	Cost: 36.19s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 3.5786	Cost: 9.95s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 3.7366	Cost: 22.23s
Train Epoch: 135 	Average Loss: 3.9299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1035

Learning rate: 0.00014886212414969547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 6.1501	Cost: 39.68s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 3.7631	Cost: 13.10s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 3.6953	Cost: 22.81s
Train Epoch: 136 	Average Loss: 3.9292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9624

Learning rate: 0.0001481753674101715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 6.2321	Cost: 44.09s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 3.5794	Cost: 10.00s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 3.7826	Cost: 25.70s
Train Epoch: 137 	Average Loss: 3.8976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9755

Learning rate: 0.00014748563898705943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 6.0382	Cost: 55.54s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 3.7879	Cost: 16.93s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 3.6225	Cost: 12.90s
Train Epoch: 138 	Average Loss: 3.8988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9863

Learning rate: 0.00014679298142605734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 5.9316	Cost: 42.95s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 3.5319	Cost: 10.60s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 3.6661	Cost: 19.61s
Train Epoch: 139 	Average Loss: 3.7954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9632

Learning rate: 0.00014609743745354624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 6.1253	Cost: 35.12s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 3.7079	Cost: 12.59s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 3.6056	Cost: 17.78s
Train Epoch: 140 	Average Loss: 3.8154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1589

Learning rate: 0.00014539904997395466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 6.1230	Cost: 34.64s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 3.5229	Cost: 10.01s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 3.5103	Cost: 26.66s
Train Epoch: 141 	Average Loss: 3.7440
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9532

Learning rate: 0.0001446978620671121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 6.1830	Cost: 38.47s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 3.5716	Cost: 16.80s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 3.4767	Cost: 17.01s
Train Epoch: 142 	Average Loss: 3.6940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9572

Learning rate: 0.0001439939169855915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 5.9984	Cost: 37.65s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 3.2778	Cost: 16.64s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 3.2330	Cost: 16.86s
Train Epoch: 143 	Average Loss: 3.5946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8920

Saving model as e143_model.pt & e143_waveforms_supplementary.hdf5
Learning rate: 0.0001432872581520414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 5.9200	Cost: 39.72s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 3.3757	Cost: 16.62s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 3.5605	Cost: 10.15s
Train Epoch: 144 	Average Loss: 3.6436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0766

Learning rate: 0.00014257792915650728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 6.2411	Cost: 39.39s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 3.5312	Cost: 9.79s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 3.3554	Cost: 20.55s
Train Epoch: 145 	Average Loss: 3.7125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9289

Learning rate: 0.0001418659737537428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 6.4465	Cost: 35.39s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 3.6591	Cost: 10.73s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 3.5271	Cost: 30.28s
Train Epoch: 146 	Average Loss: 3.6785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9299

Learning rate: 0.00014115143586051088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 5.9239	Cost: 40.45s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 3.3708	Cost: 16.80s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 3.4783	Cost: 21.99s
Train Epoch: 147 	Average Loss: 3.6260
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0881

Learning rate: 0.0001404343595528745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 6.0551	Cost: 55.83s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 3.5787	Cost: 15.33s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 3.3089	Cost: 16.53s
Train Epoch: 148 	Average Loss: 3.7201
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0272

Learning rate: 0.00013971478906347806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 6.0502	Cost: 51.24s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 3.5720	Cost: 9.85s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 3.3846	Cost: 21.78s
Train Epoch: 149 	Average Loss: 3.6389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0780

Learning rate: 0.00013899276877881884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 6.0686	Cost: 37.90s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 3.3796	Cost: 9.85s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 3.4416	Cost: 26.60s
Train Epoch: 150 	Average Loss: 3.6001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8745

Saving model as e150_model.pt & e150_waveforms_supplementary.hdf5
Learning rate: 0.000138268343236509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 6.0290	Cost: 39.90s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 3.5375	Cost: 11.17s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 3.5266	Cost: 23.30s
Train Epoch: 151 	Average Loss: 3.6648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0246

Learning rate: 0.00013754155712252834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 5.9945	Cost: 40.42s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 3.3811	Cost: 14.13s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 3.2691	Cost: 19.47s
Train Epoch: 152 	Average Loss: 3.6345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0970

Learning rate: 0.00013681245526846785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 6.1393	Cost: 43.69s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 3.3502	Cost: 15.42s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 3.4224	Cost: 13.10s
Train Epoch: 153 	Average Loss: 3.5958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1110

Learning rate: 0.00013608108264876422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 6.0652	Cost: 38.22s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 3.3903	Cost: 12.22s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 3.0649	Cost: 16.30s
Train Epoch: 154 	Average Loss: 3.5725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8390

Saving model as e154_model.pt & e154_waveforms_supplementary.hdf5
Learning rate: 0.00013534748437792575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 6.1251	Cost: 34.99s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 3.5268	Cost: 11.30s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 3.5088	Cost: 28.90s
Train Epoch: 155 	Average Loss: 3.6720
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1006

Learning rate: 0.00013461170570774932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 6.0828	Cost: 39.63s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 3.3772	Cost: 16.78s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 3.4303	Cost: 24.08s
Train Epoch: 156 	Average Loss: 3.7178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2128

Learning rate: 0.0001338737920245292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 6.4017	Cost: 39.02s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 3.6505	Cost: 15.40s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 3.3376	Cost: 18.56s
Train Epoch: 157 	Average Loss: 3.7091
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9727

Learning rate: 0.00013313378884625713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 5.9476	Cost: 38.68s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 3.4622	Cost: 9.88s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 3.0390	Cost: 27.99s
Train Epoch: 158 	Average Loss: 3.5203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0310

Learning rate: 0.00013239174181981498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 6.1710	Cost: 45.42s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 3.0846	Cost: 9.98s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 3.1753	Cost: 26.13s
Train Epoch: 159 	Average Loss: 3.4388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9163

Learning rate: 0.00013164769671815865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 5.7888	Cost: 54.00s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 3.0509	Cost: 15.53s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 3.0254	Cost: 14.49s
Train Epoch: 160 	Average Loss: 3.3234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9859

Learning rate: 0.0001309016994374948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 5.8053	Cost: 40.34s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 3.0771	Cost: 9.65s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 2.9263	Cost: 22.47s
Train Epoch: 161 	Average Loss: 3.3367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0134

Learning rate: 0.00013015379599444962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 5.7476	Cost: 36.50s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 3.1298	Cost: 9.83s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 3.1977	Cost: 26.88s
Train Epoch: 162 	Average Loss: 3.5208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7251

Saving model as e162_model.pt & e162_waveforms_supplementary.hdf5
Learning rate: 0.00012940403252323043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 6.0369	Cost: 37.80s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 3.0770	Cost: 16.64s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 3.1193	Cost: 19.80s
Train Epoch: 163 	Average Loss: 3.3839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8251

Learning rate: 0.00012865245527277986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 5.7131	Cost: 42.38s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 3.0216	Cost: 12.15s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 2.8441	Cost: 19.10s
Train Epoch: 164 	Average Loss: 3.3009
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9011

Learning rate: 0.00012789911060392294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 5.8689	Cost: 41.54s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 2.9887	Cost: 12.90s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 2.8054	Cost: 20.50s
Train Epoch: 165 	Average Loss: 3.2777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8520

Learning rate: 0.00012714404498650745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 5.8542	Cost: 42.11s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 3.2207	Cost: 10.01s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 3.1381	Cost: 26.12s
Train Epoch: 166 	Average Loss: 3.3850
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8660

Learning rate: 0.00012638730499653727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 6.1490	Cost: 49.71s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 3.0332	Cost: 16.61s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 3.0830	Cost: 16.86s
Train Epoch: 167 	Average Loss: 3.3429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0310

Learning rate: 0.00012562893731329965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 5.6739	Cost: 45.82s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 2.9391	Cost: 16.01s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 2.9616	Cost: 10.83s
Train Epoch: 168 	Average Loss: 3.1659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8203

Learning rate: 0.00012486898871648546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 5.7876	Cost: 45.28s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 3.0145	Cost: 9.79s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 2.7212	Cost: 23.37s
Train Epoch: 169 	Average Loss: 3.1439
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7285

Learning rate: 0.00012410750608330388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 6.0071	Cost: 39.92s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 2.9344	Cost: 9.91s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 2.8289	Cost: 27.00s
Train Epoch: 170 	Average Loss: 3.1243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8111

Learning rate: 0.00012334453638559054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 5.5395	Cost: 42.05s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 2.9302	Cost: 16.16s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 2.8734	Cost: 16.91s
Train Epoch: 171 	Average Loss: 3.0915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8255

Learning rate: 0.00012258012668691037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 6.0813	Cost: 41.94s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 2.6830	Cost: 16.03s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 2.6304	Cost: 12.23s
Train Epoch: 172 	Average Loss: 3.0898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8198

Learning rate: 0.00012181432413965427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 5.8459	Cost: 40.37s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 2.7919	Cost: 9.69s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 2.6306	Cost: 21.68s
Train Epoch: 173 	Average Loss: 3.0238
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8636

Learning rate: 0.0001210471759821306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 5.5873	Cost: 36.79s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 2.9866	Cost: 10.04s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 2.8447	Cost: 26.84s
Train Epoch: 174 	Average Loss: 3.0646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7804

Learning rate: 0.00012027872953565127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 5.7411	Cost: 40.92s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 2.5953	Cost: 16.14s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 2.6798	Cost: 20.93s
Train Epoch: 175 	Average Loss: 2.9846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9271

Learning rate: 0.00011950903220161285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 5.9787	Cost: 41.63s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 2.9793	Cost: 11.63s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 2.5922	Cost: 26.58s
Train Epoch: 176 	Average Loss: 3.0434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7951

Learning rate: 0.00011873813145857249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 5.8560	Cost: 42.02s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 2.8101	Cost: 11.61s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 2.6416	Cost: 21.93s
Train Epoch: 177 	Average Loss: 2.9688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7958

Learning rate: 0.00011796607485931927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 5.8588	Cost: 46.14s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 2.6765	Cost: 12.46s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 2.7006	Cost: 23.27s
Train Epoch: 178 	Average Loss: 3.0554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7973

Learning rate: 0.00011719291002794096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 5.8628	Cost: 55.19s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 2.7351	Cost: 16.73s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 2.7810	Cost: 12.19s
Train Epoch: 179 	Average Loss: 3.0774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9090

Learning rate: 0.0001164186846568863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 5.8551	Cost: 42.99s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 2.9299	Cost: 12.10s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 2.6257	Cost: 17.26s
Train Epoch: 180 	Average Loss: 3.0883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6396

Saving model as e180_model.pt & e180_waveforms_supplementary.hdf5
Learning rate: 0.0001156434465040231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 5.9703	Cost: 38.02s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 2.9123	Cost: 12.62s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 2.7386	Cost: 17.26s
Train Epoch: 181 	Average Loss: 2.9625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7418

Learning rate: 0.00011486724338969234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 6.1192	Cost: 33.45s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 2.7488	Cost: 9.79s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 2.8007	Cost: 26.25s
Train Epoch: 182 	Average Loss: 2.9655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7281

Learning rate: 0.0001140901231937583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 6.0185	Cost: 37.72s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 2.7823	Cost: 13.72s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 2.8339	Cost: 22.08s
Train Epoch: 183 	Average Loss: 3.1591
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8932

Learning rate: 0.00011331213385265528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 6.4553	Cost: 40.80s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 2.6358	Cost: 14.70s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 2.6784	Cost: 15.91s
Train Epoch: 184 	Average Loss: 3.0078
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6241

Saving model as e184_model.pt & e184_waveforms_supplementary.hdf5
Learning rate: 0.00011253332335643047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 5.6970	Cost: 43.01s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 2.5188	Cost: 13.90s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 2.3799	Cost: 13.94s
Train Epoch: 185 	Average Loss: 2.8016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5723

Saving model as e185_model.pt & e185_waveforms_supplementary.hdf5
Learning rate: 0.0001117537397457838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 5.2621	Cost: 36.42s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 2.6962	Cost: 11.96s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 2.1896	Cost: 13.55s
Train Epoch: 186 	Average Loss: 2.6930
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6123

Learning rate: 0.00011097343110910456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 5.6281	Cost: 35.18s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 2.4025	Cost: 12.78s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 2.3682	Cost: 19.46s
Train Epoch: 187 	Average Loss: 2.6882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6174

Learning rate: 0.00011019244557950502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 5.5288	Cost: 32.38s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 2.2639	Cost: 11.03s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 2.4090	Cost: 30.40s
Train Epoch: 188 	Average Loss: 2.6211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7652

Learning rate: 0.00010941083133185145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 5.3148	Cost: 37.77s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 2.4735	Cost: 17.15s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 2.5507	Cost: 22.66s
Train Epoch: 189 	Average Loss: 2.6550
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5191

Saving model as e189_model.pt & e189_waveforms_supplementary.hdf5
Learning rate: 0.00010862863657979236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 5.2342	Cost: 44.15s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 2.3644	Cost: 9.75s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 2.1814	Cost: 25.57s
Train Epoch: 190 	Average Loss: 2.5735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6078

Learning rate: 0.00010784590957278452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 5.3415	Cost: 41.56s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 2.3009	Cost: 10.11s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 2.3600	Cost: 25.87s
Train Epoch: 191 	Average Loss: 2.5595
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6688

Learning rate: 0.00010706269859311669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 5.7506	Cost: 44.04s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 2.4094	Cost: 16.51s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 2.3553	Cost: 16.68s
Train Epoch: 192 	Average Loss: 2.7185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7267

Learning rate: 0.00010627905195293137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 6.0662	Cost: 43.09s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 2.5460	Cost: 16.55s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 2.5616	Cost: 15.12s
Train Epoch: 193 	Average Loss: 2.7227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6148

Learning rate: 0.00010549501799124461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 5.7205	Cost: 42.93s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 2.3809	Cost: 11.14s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 2.3858	Cost: 18.64s
Train Epoch: 194 	Average Loss: 2.6553
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6644

Learning rate: 0.00010471064507096429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 5.5209	Cost: 36.45s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 2.4154	Cost: 12.63s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 2.4234	Cost: 13.44s
Train Epoch: 195 	Average Loss: 2.5976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7205

Learning rate: 0.00010392598157590689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 5.6115	Cost: 34.01s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 2.5555	Cost: 9.97s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 2.3461	Cost: 26.61s
Train Epoch: 196 	Average Loss: 2.6192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4744

Saving model as e196_model.pt & e196_waveforms_supplementary.hdf5
Learning rate: 0.00010314107590781285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 5.4626	Cost: 37.79s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 2.1783	Cost: 16.87s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 2.1597	Cost: 17.81s
Train Epoch: 197 	Average Loss: 2.5352
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5390

Learning rate: 0.00010235597648336105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 5.3545	Cost: 38.48s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 2.1986	Cost: 16.81s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 2.3339	Cost: 17.10s
Train Epoch: 198 	Average Loss: 2.5404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3899

Saving model as e198_model.pt & e198_waveforms_supplementary.hdf5
Learning rate: 0.0001015707317311821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 5.8216	Cost: 43.42s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 2.3089	Cost: 12.18s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 2.1025	Cost: 19.78s
Train Epoch: 199 	Average Loss: 2.4983
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6772

Learning rate: 0.00010078539008887115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 5.7660	Cost: 39.59s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 2.3422	Cost: 9.91s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 2.1813	Cost: 24.67s
Train Epoch: 200 	Average Loss: 2.4723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5668

Learning rate: 0.00010000000000000002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 5.3007	Cost: 37.43s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 2.2919	Cost: 13.40s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 2.2733	Cost: 26.78s
Train Epoch: 201 	Average Loss: 2.5294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6765

Learning rate: 9.92146099111289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 5.7087	Cost: 41.30s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 2.2951	Cost: 13.63s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 2.2867	Cost: 20.63s
Train Epoch: 202 	Average Loss: 2.5484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7032

Learning rate: 9.842926826881797e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 5.2748	Cost: 50.90s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 2.2562	Cost: 16.16s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 2.1945	Cost: 13.09s
Train Epoch: 203 	Average Loss: 2.5264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9022

Learning rate: 9.7644023516639e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 5.5560	Cost: 46.51s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 2.1353	Cost: 16.24s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 2.0476	Cost: 13.59s
Train Epoch: 204 	Average Loss: 2.4033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4499

Learning rate: 9.68589240921872e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 5.2919	Cost: 43.56s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 2.0980	Cost: 10.59s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 1.9782	Cost: 19.79s
Train Epoch: 205 	Average Loss: 2.3306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6243

Learning rate: 9.607401842409317e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 5.5182	Cost: 38.45s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 2.0330	Cost: 10.08s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 2.1622	Cost: 26.00s
Train Epoch: 206 	Average Loss: 2.2890
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4413

Learning rate: 9.528935492903578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 5.5587	Cost: 37.66s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 2.1465	Cost: 14.93s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 2.2582	Cost: 18.39s
Train Epoch: 207 	Average Loss: 2.3826
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4011

Learning rate: 9.450498200875547e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 5.3036	Cost: 41.18s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 1.8910	Cost: 16.64s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 2.1232	Cost: 16.85s
Train Epoch: 208 	Average Loss: 2.3485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6749

Learning rate: 9.372094804706868e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 5.6044	Cost: 40.48s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 2.4053	Cost: 16.60s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 1.9616	Cost: 16.17s
Train Epoch: 209 	Average Loss: 2.3037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5192

Learning rate: 9.293730140688336e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 5.1808	Cost: 40.70s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 1.9539	Cost: 11.47s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 1.9528	Cost: 18.14s
Train Epoch: 210 	Average Loss: 2.1611
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4858

Learning rate: 9.215409042721555e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 5.4204	Cost: 35.33s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 2.0481	Cost: 13.02s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 2.0599	Cost: 19.51s
Train Epoch: 211 	Average Loss: 2.2594
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6245

Learning rate: 9.13713634202077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 5.5430	Cost: 33.37s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 2.1509	Cost: 11.11s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 1.9380	Cost: 26.59s
Train Epoch: 212 	Average Loss: 2.2881
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6140

Learning rate: 9.058916866814858e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 5.3949	Cost: 38.07s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 1.8282	Cost: 17.19s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 2.0653	Cost: 22.40s
Train Epoch: 213 	Average Loss: 2.2004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6384

Learning rate: 8.9807554420495e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 5.3798	Cost: 44.38s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 1.8281	Cost: 13.69s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 1.9066	Cost: 23.69s
Train Epoch: 214 	Average Loss: 2.2125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3844

Saving model as e214_model.pt & e214_waveforms_supplementary.hdf5
Learning rate: 8.902656889089548e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 5.3278	Cost: 43.57s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 1.7467	Cost: 9.82s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 1.6100	Cost: 23.00s
Train Epoch: 215 	Average Loss: 2.1242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3951

Learning rate: 8.824626025421624e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 5.1862	Cost: 41.80s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 1.6142	Cost: 9.95s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 1.5698	Cost: 24.49s
Train Epoch: 216 	Average Loss: 2.0492
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3907

Learning rate: 8.746667664356959e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 5.4202	Cost: 43.61s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 1.8950	Cost: 16.33s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 1.9402	Cost: 16.50s
Train Epoch: 217 	Average Loss: 2.2012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5479

Learning rate: 8.668786614734478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 5.0902	Cost: 43.41s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 2.0336	Cost: 14.57s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 1.8757	Cost: 13.85s
Train Epoch: 218 	Average Loss: 2.2085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4846

Learning rate: 8.590987680624175e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 5.5019	Cost: 40.99s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 1.7939	Cost: 10.09s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 1.6293	Cost: 19.82s
Train Epoch: 219 	Average Loss: 2.0990
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4419

Learning rate: 8.51327566103077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 5.1901	Cost: 34.90s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 1.6178	Cost: 12.60s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 1.5839	Cost: 17.99s
Train Epoch: 220 	Average Loss: 2.0488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4336

Learning rate: 8.435655349597692e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 5.6726	Cost: 32.86s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 1.8191	Cost: 9.99s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 1.4114	Cost: 26.57s
Train Epoch: 221 	Average Loss: 2.0140
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2315

Saving model as e221_model.pt & e221_waveforms_supplementary.hdf5
Learning rate: 8.35813153431137e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 5.0806	Cost: 37.98s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 1.8202	Cost: 16.76s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 1.7617	Cost: 16.55s
Train Epoch: 222 	Average Loss: 1.9946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5681

Learning rate: 8.280708997205904e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 5.5135	Cost: 43.44s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 1.6822	Cost: 15.54s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 1.5784	Cost: 11.57s
Train Epoch: 223 	Average Loss: 2.0447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5403

Learning rate: 8.203392514068074e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 5.2400	Cost: 37.22s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 1.8883	Cost: 9.67s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 1.9113	Cost: 19.57s
Train Epoch: 224 	Average Loss: 2.1152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5243

Learning rate: 8.126186854142755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 5.5445	Cost: 33.96s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 2.0175	Cost: 9.67s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 1.6825	Cost: 27.62s
Train Epoch: 225 	Average Loss: 2.2008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6484

Learning rate: 8.049096779838719e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 5.1523	Cost: 37.80s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 1.8114	Cost: 17.64s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 1.8377	Cost: 21.15s
Train Epoch: 226 	Average Loss: 1.9894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3972

Learning rate: 7.972127046434877e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 5.2556	Cost: 39.68s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 1.6462	Cost: 14.13s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 1.4530	Cost: 22.10s
Train Epoch: 227 	Average Loss: 1.9183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3613

Learning rate: 7.895282401786947e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 5.6317	Cost: 36.96s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 1.6059	Cost: 10.00s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 1.4397	Cost: 27.67s
Train Epoch: 228 	Average Loss: 1.9109
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3249

Learning rate: 7.818567586034578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 5.3291	Cost: 36.52s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 1.5031	Cost: 10.74s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 1.4840	Cost: 25.18s
Train Epoch: 229 	Average Loss: 1.8578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3918

Learning rate: 7.741987331308968e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 5.0423	Cost: 47.17s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 1.5411	Cost: 16.61s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 1.5578	Cost: 18.59s
Train Epoch: 230 	Average Loss: 1.8798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2680

Learning rate: 7.665546361440945e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 5.3822	Cost: 53.41s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 1.2675	Cost: 9.61s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 1.6269	Cost: 20.91s
Train Epoch: 231 	Average Loss: 1.7872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4080

Learning rate: 7.589249391669613e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 5.0906	Cost: 38.70s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 1.4752	Cost: 9.86s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 1.5036	Cost: 26.48s
Train Epoch: 232 	Average Loss: 1.7942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3667

Learning rate: 7.513101128351452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 5.3303	Cost: 42.35s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 1.3821	Cost: 16.84s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 1.1993	Cost: 16.83s
Train Epoch: 233 	Average Loss: 1.7147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1303

Saving model as e233_model.pt & e233_waveforms_supplementary.hdf5
Learning rate: 7.437106268670034e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 5.2201	Cost: 39.73s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 1.2632	Cost: 16.53s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 1.4811	Cost: 16.59s
Train Epoch: 234 	Average Loss: 1.6951
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1080

Saving model as e234_model.pt & e234_waveforms_supplementary.hdf5
Learning rate: 7.361269500346273e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 5.0224	Cost: 41.18s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 1.5540	Cost: 9.58s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 1.2712	Cost: 17.80s
Train Epoch: 235 	Average Loss: 1.6314
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1894

Learning rate: 7.28559550134926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 5.1972	Cost: 33.55s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 1.2423	Cost: 10.61s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 1.2660	Cost: 27.51s
Train Epoch: 236 	Average Loss: 1.5565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2905

Learning rate: 7.210088939607711e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 5.2422	Cost: 41.82s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 1.1029	Cost: 14.83s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 1.4480	Cost: 22.70s
Train Epoch: 237 	Average Loss: 1.6235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4286

Learning rate: 7.13475447272202e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 5.3082	Cost: 42.67s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 1.2868	Cost: 10.24s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 1.1570	Cost: 23.27s
Train Epoch: 238 	Average Loss: 1.6171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2552

Learning rate: 7.059596747676965e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 5.4821	Cost: 43.18s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 1.2423	Cost: 12.76s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 1.4447	Cost: 19.64s
Train Epoch: 239 	Average Loss: 1.5817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3143

Learning rate: 6.984620400555048e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 5.1997	Cost: 40.40s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 1.1730	Cost: 10.07s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 1.1413	Cost: 25.96s
Train Epoch: 240 	Average Loss: 1.6163
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2798

Learning rate: 6.909830056250531e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 4.7989	Cost: 45.54s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 1.1803	Cost: 16.66s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 1.2577	Cost: 16.45s
Train Epoch: 241 	Average Loss: 1.5475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1752

Learning rate: 6.835230328184141e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 4.9208	Cost: 43.83s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 1.3150	Cost: 14.40s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 1.3588	Cost: 14.40s
Train Epoch: 242 	Average Loss: 1.5867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3610

Learning rate: 6.760825818018508e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 5.1941	Cost: 42.95s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 1.1472	Cost: 11.77s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 1.2672	Cost: 18.22s
Train Epoch: 243 	Average Loss: 1.5163
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1424

Learning rate: 6.686621115374292e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 5.0024	Cost: 34.82s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 1.2154	Cost: 9.94s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 1.0246	Cost: 26.44s
Train Epoch: 244 	Average Loss: 1.4138
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1842

Learning rate: 6.61262079754709e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 4.8786	Cost: 38.15s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 1.0155	Cost: 17.00s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 1.1958	Cost: 17.32s
Train Epoch: 245 	Average Loss: 1.4560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3277

Learning rate: 6.538829429225073e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 5.2819	Cost: 39.09s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 0.9375	Cost: 16.41s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 0.8815	Cost: 16.60s
Train Epoch: 246 	Average Loss: 1.4103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0169

Saving model as e246_model.pt & e246_waveforms_supplementary.hdf5
Learning rate: 6.465251562207432e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 5.3250	Cost: 37.39s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 1.1067	Cost: 15.26s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 1.0267	Cost: 10.63s
Train Epoch: 247 	Average Loss: 1.3554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1556

Learning rate: 6.391891735123586e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 4.7884	Cost: 37.80s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 1.0308	Cost: 9.80s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 1.2187	Cost: 19.21s
Train Epoch: 248 	Average Loss: 1.3666
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1998

Learning rate: 6.318754473153225e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 4.9112	Cost: 34.43s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 0.9478	Cost: 10.31s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 0.9704	Cost: 23.27s
Train Epoch: 249 	Average Loss: 1.2850
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3365

Learning rate: 6.245844287747173e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 5.0686	Cost: 37.17s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 0.9621	Cost: 14.72s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 1.0768	Cost: 20.04s
Train Epoch: 250 	Average Loss: 1.4497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3655

Learning rate: 6.173165676349108e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 5.2992	Cost: 37.59s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 1.0236	Cost: 16.84s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 1.0787	Cost: 17.01s
Train Epoch: 251 	Average Loss: 1.4872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1471

Learning rate: 6.10072312211812e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 5.3471	Cost: 41.39s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 1.1996	Cost: 13.26s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 1.0682	Cost: 18.82s
Train Epoch: 252 	Average Loss: 1.3597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2842

Learning rate: 6.0285210936521955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 5.0463	Cost: 40.59s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 1.0777	Cost: 12.69s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 1.0262	Cost: 22.51s
Train Epoch: 253 	Average Loss: 1.3103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2212

Learning rate: 5.956564044712553e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 5.0700	Cost: 36.53s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 0.8629	Cost: 9.76s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 0.7235	Cost: 24.47s
Train Epoch: 254 	Average Loss: 1.2923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2157

Learning rate: 5.8848564139489155e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 4.9388	Cost: 48.68s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 0.8977	Cost: 16.90s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 0.8072	Cost: 16.86s
Train Epoch: 255 	Average Loss: 1.2945
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1625

Learning rate: 5.813402624625721e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 4.9406	Cost: 59.58s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 0.9368	Cost: 15.63s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 0.6741	Cost: 14.52s
Train Epoch: 256 	Average Loss: 1.2094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1849

Learning rate: 5.742207084349277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 5.1700	Cost: 49.08s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 0.7963	Cost: 12.64s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 0.7364	Cost: 14.91s
Train Epoch: 257 	Average Loss: 1.2191
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3214

Learning rate: 5.6712741847958634e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 4.6413	Cost: 35.03s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 0.8384	Cost: 10.04s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 0.7983	Cost: 26.03s
Train Epoch: 258 	Average Loss: 1.1315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1997

Learning rate: 5.600608301440851e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 4.6855	Cost: 37.09s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 0.8497	Cost: 10.11s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 0.6801	Cost: 24.13s
Train Epoch: 259 	Average Loss: 1.1452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3470

Learning rate: 5.5302137932887924e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 4.9092	Cost: 39.80s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 0.8325	Cost: 15.99s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 0.8843	Cost: 19.05s
Train Epoch: 260 	Average Loss: 1.1524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0006

Saving model as e260_model.pt & e260_waveforms_supplementary.hdf5
Learning rate: 5.460095002604535e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 4.8460	Cost: 40.63s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 0.7988	Cost: 9.67s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 0.5838	Cost: 19.87s
Train Epoch: 261 	Average Loss: 1.1382
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3000

Learning rate: 5.390256254645381e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 4.6101	Cost: 35.51s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 0.8209	Cost: 9.86s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 0.8020	Cost: 27.33s
Train Epoch: 262 	Average Loss: 1.0818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9225

Saving model as e262_model.pt & e262_waveforms_supplementary.hdf5
Learning rate: 5.3207018573942705e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 4.9525	Cost: 38.56s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 0.8583	Cost: 16.81s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 0.6606	Cost: 20.16s
Train Epoch: 263 	Average Loss: 1.1337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1423

Learning rate: 5.251436101294054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 4.9882	Cost: 41.01s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 0.8295	Cost: 9.85s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 0.6131	Cost: 27.56s
Train Epoch: 264 	Average Loss: 1.1108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0166

Learning rate: 5.1824632589828485e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 4.8719	Cost: 42.82s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 0.8241	Cost: 10.16s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 0.5992	Cost: 27.25s
Train Epoch: 265 	Average Loss: 1.0655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0529

Learning rate: 5.1137875850304516e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 4.7191	Cost: 49.95s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 0.8413	Cost: 16.64s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 0.6002	Cost: 16.61s
Train Epoch: 266 	Average Loss: 1.1401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0173

Learning rate: 5.045413315675926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 4.9068	Cost: 43.10s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 0.5680	Cost: 15.46s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 0.6863	Cost: 15.15s
Train Epoch: 267 	Average Loss: 1.0537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9244

Learning rate: 4.977344668566277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 4.7310	Cost: 42.38s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 0.6184	Cost: 9.57s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 0.5946	Cost: 22.49s
Train Epoch: 268 	Average Loss: 0.9921
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9191

Saving model as e268_model.pt & e268_waveforms_supplementary.hdf5
Learning rate: 4.909585842496289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 4.8200	Cost: 35.15s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 0.5598	Cost: 9.87s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 0.6044	Cost: 26.66s
Train Epoch: 269 	Average Loss: 0.9692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9871

Learning rate: 4.842141017149528e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 4.9572	Cost: 41.82s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 0.5761	Cost: 16.56s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 0.6865	Cost: 17.62s
Train Epoch: 270 	Average Loss: 1.0038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9812

Learning rate: 4.775014352840514e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 4.8781	Cost: 41.61s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 0.6241	Cost: 16.88s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 0.6977	Cost: 14.19s
Train Epoch: 271 	Average Loss: 0.9284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9636

Learning rate: 4.708209990258097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 4.8660	Cost: 38.32s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 0.6944	Cost: 9.63s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 0.6655	Cost: 23.60s
Train Epoch: 272 	Average Loss: 0.9793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0393

Learning rate: 4.641732050210033e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 4.7974	Cost: 39.46s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 0.7585	Cost: 10.68s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 0.6551	Cost: 28.74s
Train Epoch: 273 	Average Loss: 0.9782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1181

Learning rate: 4.575584633368813e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 4.7987	Cost: 41.63s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 0.5679	Cost: 17.66s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 0.6389	Cost: 17.53s
Train Epoch: 274 	Average Loss: 0.9978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0309

Learning rate: 4.509771820018683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 4.8816	Cost: 48.89s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 0.6367	Cost: 16.77s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 0.4986	Cost: 17.48s
Train Epoch: 275 	Average Loss: 0.9387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9811

Learning rate: 4.4442976698039786e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 4.6779	Cost: 54.31s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 0.5932	Cost: 12.41s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 0.4937	Cost: 18.81s
Train Epoch: 276 	Average Loss: 0.8618
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8761

Saving model as e276_model.pt & e276_waveforms_supplementary.hdf5
Learning rate: 4.379166221478695e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 4.4202	Cost: 35.26s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 0.1259	Cost: 9.91s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 0.3775	Cost: 25.36s
Train Epoch: 277 	Average Loss: 0.8061
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9968

Learning rate: 4.3143814926573614e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 4.6408	Cost: 37.77s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 0.5513	Cost: 11.05s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 0.5797	Cost: 23.51s
Train Epoch: 278 	Average Loss: 0.7964
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8472

Saving model as e278_model.pt & e278_waveforms_supplementary.hdf5
Learning rate: 4.249947479567216e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 5.2136	Cost: 40.07s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 0.4411	Cost: 16.59s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 0.3117	Cost: 16.65s
Train Epoch: 279 	Average Loss: 0.7674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8972

Learning rate: 4.1858681568016955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 4.6097	Cost: 39.56s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 0.3942	Cost: 15.38s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 0.5005	Cost: 12.77s
Train Epoch: 280 	Average Loss: 0.7305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8816

Learning rate: 4.122147477075271e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 4.6596	Cost: 39.76s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 0.3293	Cost: 9.72s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 0.3885	Cost: 20.32s
Train Epoch: 281 	Average Loss: 0.7130
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9361

Learning rate: 4.058789370979617e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 4.4393	Cost: 32.47s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 0.2142	Cost: 9.93s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 0.3350	Cost: 30.69s
Train Epoch: 282 	Average Loss: 0.6425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0103

Learning rate: 3.995797746741162e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 4.7153	Cost: 37.77s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 0.4864	Cost: 17.26s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 0.1775	Cost: 23.95s
Train Epoch: 283 	Average Loss: 0.7190
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9167

Learning rate: 3.933176489980003e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 4.5448	Cost: 36.92s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 0.2935	Cost: 15.00s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 0.2237	Cost: 17.95s
Train Epoch: 284 	Average Loss: 0.6085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7713

Saving model as e284_model.pt & e284_waveforms_supplementary.hdf5
Learning rate: 3.8709294634702356e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 4.3984	Cost: 35.56s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 0.3003	Cost: 11.54s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 0.2821	Cost: 21.74s
Train Epoch: 285 	Average Loss: 0.6239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9099

Learning rate: 3.809060506901661e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 4.9585	Cost: 42.75s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 0.0817	Cost: 10.08s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 0.1780	Cost: 26.22s
Train Epoch: 286 	Average Loss: 0.5964
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9495

Learning rate: 3.747573436642949e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 4.1523	Cost: 39.86s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 0.1867	Cost: 9.78s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 0.0378	Cost: 26.17s
Train Epoch: 287 	Average Loss: 0.5495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8675

Learning rate: 3.686472045506224e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 4.7608	Cost: 61.59s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 0.1718	Cost: 10.60s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 0.1264	Cost: 19.80s
Train Epoch: 288 	Average Loss: 0.5519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9072

Learning rate: 3.625760102513104e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 4.5140	Cost: 36.07s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 0.1269	Cost: 9.83s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 0.0685	Cost: 24.02s
Train Epoch: 289 	Average Loss: 0.5668
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9569

Learning rate: 3.5654413526622126e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 4.4904	Cost: 37.75s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 0.3131	Cost: 10.67s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 0.0454	Cost: 24.44s
Train Epoch: 290 	Average Loss: 0.5097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8273

Learning rate: 3.505519516698166e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 4.3755	Cost: 40.34s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 0.1254	Cost: 15.49s
Train Epoch: 291 [81920/90000 (91%)]	Loss: -0.0803	Cost: 17.36s
Train Epoch: 291 	Average Loss: 0.4565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8996

Learning rate: 3.445998290882063e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 4.4837	Cost: 39.68s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 0.1428	Cost: 13.44s
Train Epoch: 292 [81920/90000 (91%)]	Loss: -0.0850	Cost: 14.32s
Train Epoch: 292 	Average Loss: 0.4764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8898

Learning rate: 3.386881346763484e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 4.4271	Cost: 42.21s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 0.0417	Cost: 9.79s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 0.0027	Cost: 19.36s
Train Epoch: 293 	Average Loss: 0.4443
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8110

Learning rate: 3.328172330954006e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 4.6222	Cost: 37.20s
Train Epoch: 294 [40960/90000 (45%)]	Loss: -0.1761	Cost: 9.70s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 0.0281	Cost: 28.85s
Train Epoch: 294 	Average Loss: 0.3926
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7495

Saving model as e294_model.pt & e294_waveforms_supplementary.hdf5
Learning rate: 3.269874864902267e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 4.4082	Cost: 36.60s
Train Epoch: 295 [40960/90000 (45%)]	Loss: -0.1364	Cost: 17.19s
Train Epoch: 295 [81920/90000 (91%)]	Loss: -0.1121	Cost: 19.33s
Train Epoch: 295 	Average Loss: 0.3918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7552

Learning rate: 3.2119925446705836e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 4.5183	Cost: 36.35s
Train Epoch: 296 [40960/90000 (45%)]	Loss: -0.2140	Cost: 16.89s
Train Epoch: 296 [81920/90000 (91%)]	Loss: -0.1533	Cost: 15.66s
Train Epoch: 296 	Average Loss: 0.3949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9815

Learning rate: 3.1545289407131144e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 4.5785	Cost: 35.85s
Train Epoch: 297 [40960/90000 (45%)]	Loss: -0.0850	Cost: 10.10s
Train Epoch: 297 [81920/90000 (91%)]	Loss: -0.1621	Cost: 24.04s
Train Epoch: 297 	Average Loss: 0.3501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7796

Learning rate: 3.09748759765563e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 4.6237	Cost: 45.09s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 0.0699	Cost: 10.01s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 0.0824	Cost: 26.88s
Train Epoch: 298 	Average Loss: 0.4351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9379

Learning rate: 3.0408720340768585e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 4.2085	Cost: 48.66s
Train Epoch: 299 [40960/90000 (45%)]	Loss: -0.0715	Cost: 16.72s
Train Epoch: 299 [81920/90000 (91%)]	Loss: -0.0857	Cost: 16.53s
Train Epoch: 299 	Average Loss: 0.3723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7434

Saving model as e299_model.pt & e299_waveforms_supplementary.hdf5
Learning rate: 2.9846857422914446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 5.0583	Cost: 41.83s
Train Epoch: 300 [40960/90000 (45%)]	Loss: -0.0611	Cost: 16.51s
Train Epoch: 300 [81920/90000 (91%)]	Loss: -0.2217	Cost: 16.45s
Train Epoch: 300 	Average Loss: 0.3581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7139

Saving model as e300_model.pt & e300_waveforms_supplementary.hdf5
Learning rate: 2.9289321881345268e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 4.4106	Cost: 45.54s
Train Epoch: 301 [40960/90000 (45%)]	Loss: -0.1944	Cost: 12.08s
Train Epoch: 301 [81920/90000 (91%)]	Loss: -0.2785	Cost: 18.67s
Train Epoch: 301 	Average Loss: 0.2881
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7227

Learning rate: 2.8736148107479478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 4.4707	Cost: 38.74s
Train Epoch: 302 [40960/90000 (45%)]	Loss: -0.1805	Cost: 12.14s
Train Epoch: 302 [81920/90000 (91%)]	Loss: -0.1202	Cost: 16.40s
Train Epoch: 302 	Average Loss: 0.2906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8720

Learning rate: 2.8187370223681142e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 4.4611	Cost: 35.71s
Train Epoch: 303 [40960/90000 (45%)]	Loss: -0.1752	Cost: 9.74s
Train Epoch: 303 [81920/90000 (91%)]	Loss: -0.0309	Cost: 22.75s
Train Epoch: 303 	Average Loss: 0.3201
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7396

Learning rate: 2.764302208115509e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 4.0991	Cost: 39.51s
Train Epoch: 304 [40960/90000 (45%)]	Loss: -0.1599	Cost: 16.01s
Train Epoch: 304 [81920/90000 (91%)]	Loss: -0.2994	Cost: 19.64s
Train Epoch: 304 	Average Loss: 0.2372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4773

Saving model as e304_model.pt & e304_waveforms_supplementary.hdf5
Learning rate: 2.710313725785888e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 4.6232	Cost: 42.45s
Train Epoch: 305 [40960/90000 (45%)]	Loss: -0.3575	Cost: 13.30s
Train Epoch: 305 [81920/90000 (91%)]	Loss: -0.1730	Cost: 24.56s
Train Epoch: 305 	Average Loss: 0.2015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6987

Learning rate: 2.6567749056431446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 4.7277	Cost: 41.58s
Train Epoch: 306 [40960/90000 (45%)]	Loss: -0.0253	Cost: 12.82s
Train Epoch: 306 [81920/90000 (91%)]	Loss: -0.1290	Cost: 20.33s
Train Epoch: 306 	Average Loss: 0.2812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6690

Learning rate: 2.6036890502139035e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 4.4332	Cost: 41.56s
Train Epoch: 307 [40960/90000 (45%)]	Loss: -0.3062	Cost: 10.11s
Train Epoch: 307 [81920/90000 (91%)]	Loss: -0.1191	Cost: 26.02s
Train Epoch: 307 	Average Loss: 0.1519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6863

Learning rate: 2.55105943408378e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 4.3967	Cost: 43.69s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 0.0216	Cost: 17.02s
Train Epoch: 308 [81920/90000 (91%)]	Loss: -0.1578	Cost: 17.59s
Train Epoch: 308 	Average Loss: 0.2724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7581

Learning rate: 2.4988893036954053e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 4.2995	Cost: 45.54s
Train Epoch: 309 [40960/90000 (45%)]	Loss: -0.2099	Cost: 16.59s
Train Epoch: 309 [81920/90000 (91%)]	Loss: -0.2836	Cost: 16.78s
Train Epoch: 309 	Average Loss: 0.1116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5832

Learning rate: 2.4471818771481658e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 4.5095	Cost: 44.50s
Train Epoch: 310 [40960/90000 (45%)]	Loss: -0.4720	Cost: 16.48s
Train Epoch: 310 [81920/90000 (91%)]	Loss: -0.4373	Cost: 12.28s
Train Epoch: 310 	Average Loss: 0.0821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8159

Learning rate: 2.3959403439996917e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 4.1644	Cost: 44.88s
Train Epoch: 311 [40960/90000 (45%)]	Loss: -0.1868	Cost: 9.70s
Train Epoch: 311 [81920/90000 (91%)]	Loss: -0.0560	Cost: 19.16s
Train Epoch: 311 	Average Loss: 0.2752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6784

Learning rate: 2.345167865069121e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 4.3803	Cost: 34.40s
Train Epoch: 312 [40960/90000 (45%)]	Loss: -0.2758	Cost: 9.83s
Train Epoch: 312 [81920/90000 (91%)]	Loss: -0.3624	Cost: 25.88s
Train Epoch: 312 	Average Loss: 0.1056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6182

Learning rate: 2.2948675722421096e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 4.0249	Cost: 36.60s
Train Epoch: 313 [40960/90000 (45%)]	Loss: -0.2363	Cost: 13.04s
Train Epoch: 313 [81920/90000 (91%)]	Loss: -0.0624	Cost: 22.01s
Train Epoch: 313 	Average Loss: 0.1056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6858

Learning rate: 2.2450425682776575e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 4.1707	Cost: 39.66s
Train Epoch: 314 [40960/90000 (45%)]	Loss: -0.4180	Cost: 16.45s
Train Epoch: 314 [81920/90000 (91%)]	Loss: -0.4889	Cost: 18.38s
Train Epoch: 314 	Average Loss: -0.0030
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6520

Learning rate: 2.1956959266167054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 4.3144	Cost: 44.01s
Train Epoch: 315 [40960/90000 (45%)]	Loss: -0.5276	Cost: 9.57s
Train Epoch: 315 [81920/90000 (91%)]	Loss: -0.3237	Cost: 19.56s
Train Epoch: 315 	Average Loss: 0.0178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6599

Learning rate: 2.1468306911925506e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 4.1395	Cost: 33.36s
Train Epoch: 316 [40960/90000 (45%)]	Loss: -0.4450	Cost: 10.85s
Train Epoch: 316 [81920/90000 (91%)]	Loss: -0.4825	Cost: 27.78s
Train Epoch: 316 	Average Loss: -0.0466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7553

Learning rate: 2.098449876243097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 4.2014	Cost: 35.37s
Train Epoch: 317 [40960/90000 (45%)]	Loss: -0.5450	Cost: 16.01s
Train Epoch: 317 [81920/90000 (91%)]	Loss: -0.3192	Cost: 24.79s
Train Epoch: 317 	Average Loss: -0.0114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5042

Learning rate: 2.050556466124901e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 4.1013	Cost: 39.46s
Train Epoch: 318 [40960/90000 (45%)]	Loss: -0.4010	Cost: 16.83s
Train Epoch: 318 [81920/90000 (91%)]	Loss: -0.3995	Cost: 18.08s
Train Epoch: 318 	Average Loss: 0.0170
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6199

Learning rate: 2.0031534151290953e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 4.0868	Cost: 40.36s
Train Epoch: 319 [40960/90000 (45%)]	Loss: -0.4441	Cost: 9.93s
Train Epoch: 319 [81920/90000 (91%)]	Loss: -0.5440	Cost: 24.66s
Train Epoch: 319 	Average Loss: -0.0377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6123

Learning rate: 1.9562436472991562e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 4.0161	Cost: 44.80s
Train Epoch: 320 [40960/90000 (45%)]	Loss: -0.3924	Cost: 9.87s
Train Epoch: 320 [81920/90000 (91%)]	Loss: -0.5590	Cost: 27.61s
Train Epoch: 320 	Average Loss: -0.0471
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4804

Learning rate: 1.9098300562505276e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 4.1976	Cost: 45.73s
Train Epoch: 321 [40960/90000 (45%)]	Loss: -0.6795	Cost: 16.66s
Train Epoch: 321 [81920/90000 (91%)]	Loss: -0.4964	Cost: 16.87s
Train Epoch: 321 	Average Loss: -0.0756
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4973

Learning rate: 1.863915504992132e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 3.8645	Cost: 45.85s
Train Epoch: 322 [40960/90000 (45%)]	Loss: -0.6482	Cost: 15.15s
Train Epoch: 322 [81920/90000 (91%)]	Loss: -0.5470	Cost: 11.75s
Train Epoch: 322 	Average Loss: -0.1397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6962

Learning rate: 1.8185028257497683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 4.4619	Cost: 40.27s
Train Epoch: 323 [40960/90000 (45%)]	Loss: -0.5441	Cost: 13.05s
Train Epoch: 323 [81920/90000 (91%)]	Loss: -0.4442	Cost: 18.09s
Train Epoch: 323 	Average Loss: -0.0683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6911

Learning rate: 1.7735948197914044e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 4.1052	Cost: 35.82s
Train Epoch: 324 [40960/90000 (45%)]	Loss: -0.4679	Cost: 12.61s
Train Epoch: 324 [81920/90000 (91%)]	Loss: -0.6660	Cost: 16.88s
Train Epoch: 324 	Average Loss: -0.1392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5177

Learning rate: 1.729194257254384e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 4.1604	Cost: 36.21s
Train Epoch: 325 [40960/90000 (45%)]	Loss: -0.6811	Cost: 9.76s
Train Epoch: 325 [81920/90000 (91%)]	Loss: -0.5896	Cost: 25.94s
Train Epoch: 325 	Average Loss: -0.1484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6061

Learning rate: 1.685303876974551e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 4.2334	Cost: 37.13s
Train Epoch: 326 [40960/90000 (45%)]	Loss: -0.5506	Cost: 16.88s
Train Epoch: 326 [81920/90000 (91%)]	Loss: -0.5307	Cost: 16.80s
Train Epoch: 326 	Average Loss: -0.1502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6127

Learning rate: 1.6419263863173007e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 4.2465	Cost: 36.90s
Train Epoch: 327 [40960/90000 (45%)]	Loss: -0.4575	Cost: 14.91s
Train Epoch: 327 [81920/90000 (91%)]	Loss: -0.6862	Cost: 13.58s
Train Epoch: 327 	Average Loss: -0.1673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6190

Learning rate: 1.599064461010582e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 4.2911	Cost: 38.95s
Train Epoch: 328 [40960/90000 (45%)]	Loss: -0.4817	Cost: 9.61s
Train Epoch: 328 [81920/90000 (91%)]	Loss: -0.6776	Cost: 22.19s
Train Epoch: 328 	Average Loss: -0.1699
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5765

Learning rate: 1.5567207449798525e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 4.7524	Cost: 33.85s
Train Epoch: 329 [40960/90000 (45%)]	Loss: -0.7537	Cost: 11.28s
Train Epoch: 329 [81920/90000 (91%)]	Loss: -0.5673	Cost: 32.37s
Train Epoch: 329 	Average Loss: -0.1981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5772

Learning rate: 1.5148978501849652e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 4.4421	Cost: 38.30s
Train Epoch: 330 [40960/90000 (45%)]	Loss: -0.7231	Cost: 17.16s
Train Epoch: 330 [81920/90000 (91%)]	Loss: -0.6183	Cost: 21.23s
Train Epoch: 330 	Average Loss: -0.2142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5712

Learning rate: 1.4735983564590815e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 4.3675	Cost: 44.63s
Train Epoch: 331 [40960/90000 (45%)]	Loss: -0.8418	Cost: 14.19s
Train Epoch: 331 [81920/90000 (91%)]	Loss: -0.6076	Cost: 20.49s
Train Epoch: 331 	Average Loss: -0.2758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6120

Learning rate: 1.4328248113495055e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 4.4249	Cost: 42.13s
Train Epoch: 332 [40960/90000 (45%)]	Loss: -0.7412	Cost: 11.83s
Train Epoch: 332 [81920/90000 (91%)]	Loss: -0.7657	Cost: 17.72s
Train Epoch: 332 	Average Loss: -0.2429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5709

Learning rate: 1.3925797299605635e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 4.4379	Cost: 40.60s
Train Epoch: 333 [40960/90000 (45%)]	Loss: -0.5414	Cost: 10.04s
Train Epoch: 333 [81920/90000 (91%)]	Loss: -0.5959	Cost: 24.63s
Train Epoch: 333 	Average Loss: -0.2413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6244

Learning rate: 1.3528655947984512e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 3.8061	Cost: 43.33s
Train Epoch: 334 [40960/90000 (45%)]	Loss: -0.8327	Cost: 16.10s
Train Epoch: 334 [81920/90000 (91%)]	Loss: -0.7598	Cost: 17.97s
Train Epoch: 334 	Average Loss: -0.3430
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5527

Learning rate: 1.3136848556180878e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 4.1603	Cost: 43.70s
Train Epoch: 335 [40960/90000 (45%)]	Loss: -0.6514	Cost: 15.20s
Train Epoch: 335 [81920/90000 (91%)]	Loss: -0.6231	Cost: 13.03s
Train Epoch: 335 	Average Loss: -0.2756
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4290

Saving model as e335_model.pt & e335_waveforms_supplementary.hdf5
Learning rate: 1.2750399292720314e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 4.3912	Cost: 39.94s
Train Epoch: 336 [40960/90000 (45%)]	Loss: -0.8333	Cost: 10.86s
Train Epoch: 336 [81920/90000 (91%)]	Loss: -0.5936	Cost: 17.33s
Train Epoch: 336 	Average Loss: -0.3232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6128

Learning rate: 1.2369331995613651e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 4.2899	Cost: 37.31s
Train Epoch: 337 [40960/90000 (45%)]	Loss: -0.8530	Cost: 10.03s
Train Epoch: 337 [81920/90000 (91%)]	Loss: -0.7433	Cost: 21.76s
Train Epoch: 337 	Average Loss: -0.3187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4791

Learning rate: 1.1993670170886837e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 4.1342	Cost: 36.77s
Train Epoch: 338 [40960/90000 (45%)]	Loss: -0.8270	Cost: 10.02s
Train Epoch: 338 [81920/90000 (91%)]	Loss: -0.8093	Cost: 26.05s
Train Epoch: 338 	Average Loss: -0.3510
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4609

Learning rate: 1.1623436991130663e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 4.6115	Cost: 42.42s
Train Epoch: 339 [40960/90000 (45%)]	Loss: -0.8089	Cost: 16.02s
Train Epoch: 339 [81920/90000 (91%)]	Loss: -0.9454	Cost: 19.17s
Train Epoch: 339 	Average Loss: -0.3294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6190

Learning rate: 1.1258655294071704e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 3.8477	Cost: 43.41s
Train Epoch: 340 [40960/90000 (45%)]	Loss: -0.6082	Cost: 15.38s
Train Epoch: 340 [81920/90000 (91%)]	Loss: -0.8326	Cost: 13.01s
Train Epoch: 340 	Average Loss: -0.3615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3686

Saving model as e340_model.pt & e340_waveforms_supplementary.hdf5
Learning rate: 1.089934758116323e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 3.8605	Cost: 37.52s
Train Epoch: 341 [40960/90000 (45%)]	Loss: -0.8835	Cost: 12.66s
Train Epoch: 341 [81920/90000 (91%)]	Loss: -0.8287	Cost: 15.78s
Train Epoch: 341 	Average Loss: -0.4006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5656

Learning rate: 1.054553601619753e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 4.3102	Cost: 34.11s
Train Epoch: 342 [40960/90000 (45%)]	Loss: -0.4713	Cost: 10.12s
Train Epoch: 342 [81920/90000 (91%)]	Loss: -0.7265	Cost: 27.46s
Train Epoch: 342 	Average Loss: -0.2721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5251

Learning rate: 1.0197242423938455e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 4.2492	Cost: 37.31s
Train Epoch: 343 [40960/90000 (45%)]	Loss: -0.8150	Cost: 17.23s
Train Epoch: 343 [81920/90000 (91%)]	Loss: -0.7592	Cost: 21.29s
Train Epoch: 343 	Average Loss: -0.3628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5180

Learning rate: 9.854488288775428e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 4.3587	Cost: 38.54s
Train Epoch: 344 [40960/90000 (45%)]	Loss: -0.7795	Cost: 15.79s
Train Epoch: 344 [81920/90000 (91%)]	Loss: -0.8556	Cost: 15.92s
Train Epoch: 344 	Average Loss: -0.3658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7804

Learning rate: 9.517294753398073e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 3.9774	Cost: 35.99s
Train Epoch: 345 [40960/90000 (45%)]	Loss: -0.8960	Cost: 13.49s
Train Epoch: 345 [81920/90000 (91%)]	Loss: -0.8979	Cost: 16.81s
Train Epoch: 345 	Average Loss: -0.4238
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5609

Learning rate: 9.185682617491872e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 3.8116	Cost: 38.56s
Train Epoch: 346 [40960/90000 (45%)]	Loss: -0.9623	Cost: 13.17s
Train Epoch: 346 [81920/90000 (91%)]	Loss: -0.6641	Cost: 24.00s
Train Epoch: 346 	Average Loss: -0.4429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4895

Learning rate: 8.859672336455501e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 4.0284	Cost: 43.79s
Train Epoch: 347 [40960/90000 (45%)]	Loss: -0.8527	Cost: 9.94s
Train Epoch: 347 [81920/90000 (91%)]	Loss: -1.0256	Cost: 28.03s
Train Epoch: 347 	Average Loss: -0.4693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3024

Saving model as e347_model.pt & e347_waveforms_supplementary.hdf5
Learning rate: 8.539284020138645e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 3.7644	Cost: 54.60s
Train Epoch: 348 [40960/90000 (45%)]	Loss: -0.8308	Cost: 12.52s
Train Epoch: 348 [81920/90000 (91%)]	Loss: -0.7683	Cost: 15.58s
Train Epoch: 348 	Average Loss: -0.4436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4471

Learning rate: 8.224537431601915e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 4.3512	Cost: 36.53s
Train Epoch: 349 [40960/90000 (45%)]	Loss: -1.0089	Cost: 12.59s
Train Epoch: 349 [81920/90000 (91%)]	Loss: -0.7864	Cost: 16.73s
Train Epoch: 349 	Average Loss: -0.4408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5285

Learning rate: 7.915451985897387e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 3.7810	Cost: 33.24s
Train Epoch: 350 [40960/90000 (45%)]	Loss: -0.9406	Cost: 9.90s
Train Epoch: 350 [81920/90000 (91%)]	Loss: -0.9159	Cost: 26.96s
Train Epoch: 350 	Average Loss: -0.4367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4504

Learning rate: 7.612046748871354e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 4.2016	Cost: 38.67s
Train Epoch: 351 [40960/90000 (45%)]	Loss: -0.8629	Cost: 17.41s
Train Epoch: 351 [81920/90000 (91%)]	Loss: -0.9868	Cost: 16.80s
Train Epoch: 351 	Average Loss: -0.4011
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4885

Learning rate: 7.314340435987926e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 4.1913	Cost: 43.67s
Train Epoch: 352 [40960/90000 (45%)]	Loss: -0.8998	Cost: 14.98s
Train Epoch: 352 [81920/90000 (91%)]	Loss: -0.9560	Cost: 11.85s
Train Epoch: 352 	Average Loss: -0.4245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3812

Learning rate: 7.022351411174871e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 4.0735	Cost: 37.75s
Train Epoch: 353 [40960/90000 (45%)]	Loss: -0.8063	Cost: 9.65s
Train Epoch: 353 [81920/90000 (91%)]	Loss: -0.9468	Cost: 19.47s
Train Epoch: 353 	Average Loss: -0.5030
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5249

Learning rate: 6.736097685690606e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 4.4891	Cost: 34.83s
Train Epoch: 354 [40960/90000 (45%)]	Loss: -0.7330	Cost: 10.57s
Train Epoch: 354 [81920/90000 (91%)]	Loss: -0.9643	Cost: 28.15s
Train Epoch: 354 	Average Loss: -0.4913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4704

Learning rate: 6.455596917013267e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 3.9256	Cost: 36.60s
Train Epoch: 355 [40960/90000 (45%)]	Loss: -0.8968	Cost: 17.48s
Train Epoch: 355 [81920/90000 (91%)]	Loss: -1.0405	Cost: 20.35s
Train Epoch: 355 	Average Loss: -0.4984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4598

Learning rate: 6.1808664077516005e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 4.1845	Cost: 38.31s
Train Epoch: 356 [40960/90000 (45%)]	Loss: -0.8992	Cost: 17.03s
Train Epoch: 356 [81920/90000 (91%)]	Loss: -1.0010	Cost: 16.38s
Train Epoch: 356 	Average Loss: -0.4992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2841

Saving model as e356_model.pt & e356_waveforms_supplementary.hdf5
Learning rate: 5.91192310457746e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 4.4782	Cost: 40.74s
Train Epoch: 357 [40960/90000 (45%)]	Loss: -0.9063	Cost: 10.97s
Train Epoch: 357 [81920/90000 (91%)]	Loss: -0.9279	Cost: 23.74s
Train Epoch: 357 	Average Loss: -0.4872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2821

Saving model as e357_model.pt & e357_waveforms_supplementary.hdf5
Learning rate: 5.648783597180656e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 3.6748	Cost: 42.74s
Train Epoch: 358 [40960/90000 (45%)]	Loss: -0.8670	Cost: 11.86s
Train Epoch: 358 [81920/90000 (91%)]	Loss: -1.0340	Cost: 22.59s
Train Epoch: 358 	Average Loss: -0.6123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3792

Learning rate: 5.3914641172454745e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 3.9745	Cost: 44.45s
Train Epoch: 359 [40960/90000 (45%)]	Loss: -0.9949	Cost: 14.22s
Train Epoch: 359 [81920/90000 (91%)]	Loss: -0.9895	Cost: 22.49s
Train Epoch: 359 	Average Loss: -0.5630
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3669

Learning rate: 5.139980537449555e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 4.2594	Cost: 57.32s
Train Epoch: 360 [40960/90000 (45%)]	Loss: -0.9053	Cost: 16.68s
Train Epoch: 360 [81920/90000 (91%)]	Loss: -1.0127	Cost: 16.15s
Train Epoch: 360 	Average Loss: -0.5374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4557

Learning rate: 4.894348370484651e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 3.9294	Cost: 39.77s
Train Epoch: 361 [40960/90000 (45%)]	Loss: -1.1176	Cost: 14.28s
Train Epoch: 361 [81920/90000 (91%)]	Loss: -1.1772	Cost: 12.76s
Train Epoch: 361 	Average Loss: -0.5568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5750

Learning rate: 4.6545827680998834e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 4.0370	Cost: 54.13s
Train Epoch: 362 [40960/90000 (45%)]	Loss: -0.9599	Cost: 12.95s
Train Epoch: 362 [81920/90000 (91%)]	Loss: -0.9680	Cost: 18.13s
Train Epoch: 362 	Average Loss: -0.5657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5038

Learning rate: 4.420698520166991e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 3.9358	Cost: 36.41s
Train Epoch: 363 [40960/90000 (45%)]	Loss: -0.9781	Cost: 12.68s
Train Epoch: 363 [81920/90000 (91%)]	Loss: -0.9808	Cost: 16.69s
Train Epoch: 363 	Average Loss: -0.5649
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4921

Learning rate: 4.1927100537680815e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 4.3453	Cost: 34.80s
Train Epoch: 364 [40960/90000 (45%)]	Loss: -0.9408	Cost: 10.05s
Train Epoch: 364 [81920/90000 (91%)]	Loss: -0.7203	Cost: 25.64s
Train Epoch: 364 	Average Loss: -0.5251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4642

Learning rate: 3.970631432305708e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 3.9529	Cost: 36.32s
Train Epoch: 365 [40960/90000 (45%)]	Loss: -0.9552	Cost: 16.80s
Train Epoch: 365 [81920/90000 (91%)]	Loss: -1.1008	Cost: 17.39s
Train Epoch: 365 	Average Loss: -0.6136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3326

Learning rate: 3.7544763546352753e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 4.1196	Cost: 37.55s
Train Epoch: 366 [40960/90000 (45%)]	Loss: -1.0476	Cost: 15.36s
Train Epoch: 366 [81920/90000 (91%)]	Loss: -1.0977	Cost: 16.78s
Train Epoch: 366 	Average Loss: -0.5717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5673

Learning rate: 3.5442581542202067e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 4.1448	Cost: 37.79s
Train Epoch: 367 [40960/90000 (45%)]	Loss: -1.2234	Cost: 15.81s
Train Epoch: 367 [81920/90000 (91%)]	Loss: -1.1030	Cost: 12.48s
Train Epoch: 367 	Average Loss: -0.5763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4081

Learning rate: 3.339989798309276e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 3.8383	Cost: 40.99s
Train Epoch: 368 [40960/90000 (45%)]	Loss: -1.0495	Cost: 11.40s
Train Epoch: 368 [81920/90000 (91%)]	Loss: -1.2120	Cost: 16.85s
Train Epoch: 368 	Average Loss: -0.6511
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5070

Learning rate: 3.1416838871369064e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 4.0655	Cost: 34.99s
Train Epoch: 369 [40960/90000 (45%)]	Loss: -1.1610	Cost: 10.49s
Train Epoch: 369 [81920/90000 (91%)]	Loss: -1.2585	Cost: 29.78s
Train Epoch: 369 	Average Loss: -0.6259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4991

Learning rate: 2.9493526531457563e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 4.0547	Cost: 36.44s
Train Epoch: 370 [40960/90000 (45%)]	Loss: -1.1319	Cost: 17.18s
Train Epoch: 370 [81920/90000 (91%)]	Loss: -1.1606	Cost: 23.77s
Train Epoch: 370 	Average Loss: -0.6280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2695

Saving model as e370_model.pt & e370_waveforms_supplementary.hdf5
Learning rate: 2.7630079602323468e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 4.2570	Cost: 37.87s
Train Epoch: 371 [40960/90000 (45%)]	Loss: -1.0218	Cost: 15.28s
Train Epoch: 371 [81920/90000 (91%)]	Loss: -1.0269	Cost: 17.08s
Train Epoch: 371 	Average Loss: -0.6117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6521

Learning rate: 2.582661303015068e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 4.3629	Cost: 41.24s
Train Epoch: 372 [40960/90000 (45%)]	Loss: -1.4449	Cost: 13.18s
Train Epoch: 372 [81920/90000 (91%)]	Loss: -0.9469	Cost: 21.81s
Train Epoch: 372 	Average Loss: -0.5900
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3680

Learning rate: 2.40832380612527e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 4.1096	Cost: 40.66s
Train Epoch: 373 [40960/90000 (45%)]	Loss: -1.1899	Cost: 10.12s
Train Epoch: 373 [81920/90000 (91%)]	Loss: -1.2056	Cost: 24.31s
Train Epoch: 373 	Average Loss: -0.6432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3938

Learning rate: 2.2400062235209426e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 4.2528	Cost: 45.91s
Train Epoch: 374 [40960/90000 (45%)]	Loss: -1.0711	Cost: 16.83s
Train Epoch: 374 [81920/90000 (91%)]	Loss: -1.0806	Cost: 16.71s
Train Epoch: 374 	Average Loss: -0.6727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5346

Learning rate: 2.0777189378234156e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 3.6152	Cost: 40.99s
Train Epoch: 375 [40960/90000 (45%)]	Loss: -1.0707	Cost: 16.07s
Train Epoch: 375 [81920/90000 (91%)]	Loss: -0.9983	Cost: 16.49s
Train Epoch: 375 	Average Loss: -0.6599
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4864

Learning rate: 1.9214719596769582e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 4.0910	Cost: 43.93s
Train Epoch: 376 [40960/90000 (45%)]	Loss: -1.0477	Cost: 14.62s
Train Epoch: 376 [81920/90000 (91%)]	Loss: -1.3208	Cost: 15.62s
Train Epoch: 376 	Average Loss: -0.6681
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4614

Learning rate: 1.771274927131129e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 4.1075	Cost: 40.32s
Train Epoch: 377 [40960/90000 (45%)]	Loss: -1.1820	Cost: 10.19s
Train Epoch: 377 [81920/90000 (91%)]	Loss: -1.0112	Cost: 18.19s
Train Epoch: 377 	Average Loss: -0.6867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4291

Learning rate: 1.6271371050464177e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 3.9994	Cost: 35.34s
Train Epoch: 378 [40960/90000 (45%)]	Loss: -0.9810	Cost: 9.90s
Train Epoch: 378 [81920/90000 (91%)]	Loss: -1.1435	Cost: 27.78s
Train Epoch: 378 	Average Loss: -0.7060
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3540

Learning rate: 1.4890673845226142e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 4.0369	Cost: 36.29s
Train Epoch: 379 [40960/90000 (45%)]	Loss: -1.0435	Cost: 17.21s
Train Epoch: 379 [81920/90000 (91%)]	Loss: -1.2408	Cost: 19.08s
Train Epoch: 379 	Average Loss: -0.6838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5434

Learning rate: 1.3570742823504575e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 4.2987	Cost: 39.52s
Train Epoch: 380 [40960/90000 (45%)]	Loss: -1.0315	Cost: 16.68s
Train Epoch: 380 [81920/90000 (91%)]	Loss: -1.2882	Cost: 18.49s
Train Epoch: 380 	Average Loss: -0.6777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6440

Learning rate: 1.2311659404862349e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 3.9398	Cost: 39.03s
Train Epoch: 381 [40960/90000 (45%)]	Loss: -1.1447	Cost: 9.86s
Train Epoch: 381 [81920/90000 (91%)]	Loss: -1.0973	Cost: 29.05s
Train Epoch: 381 	Average Loss: -0.7142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2788

Learning rate: 1.1113501255495491e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 3.8850	Cost: 40.50s
Train Epoch: 382 [40960/90000 (45%)]	Loss: -1.1232	Cost: 10.15s
Train Epoch: 382 [81920/90000 (91%)]	Loss: -1.3543	Cost: 25.89s
Train Epoch: 382 	Average Loss: -0.7115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2640

Saving model as e382_model.pt & e382_waveforms_supplementary.hdf5
Learning rate: 9.97634228344247e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 3.8528	Cost: 42.78s
Train Epoch: 383 [40960/90000 (45%)]	Loss: -1.1656	Cost: 15.75s
Train Epoch: 383 [81920/90000 (91%)]	Loss: -1.0073	Cost: 18.79s
Train Epoch: 383 	Average Loss: -0.6815
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4940

Learning rate: 8.90025263402528e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 3.6686	Cost: 48.06s
Train Epoch: 384 [40960/90000 (45%)]	Loss: -1.1634	Cost: 16.65s
Train Epoch: 384 [81920/90000 (91%)]	Loss: -1.0988	Cost: 13.11s
Train Epoch: 384 	Average Loss: -0.6701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3691

Learning rate: 7.88529868552224e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 4.2444	Cost: 44.02s
Train Epoch: 385 [40960/90000 (45%)]	Loss: -1.3139	Cost: 11.84s
Train Epoch: 385 [81920/90000 (91%)]	Loss: -1.1715	Cost: 15.48s
Train Epoch: 385 	Average Loss: -0.7017
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3812

Learning rate: 6.931543045073711e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 4.1029	Cost: 37.26s
Train Epoch: 386 [40960/90000 (45%)]	Loss: -1.1623	Cost: 12.55s
Train Epoch: 386 [81920/90000 (91%)]	Loss: -1.3898	Cost: 16.14s
Train Epoch: 386 	Average Loss: -0.7181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4569

Learning rate: 6.039044544820409e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 4.1768	Cost: 36.06s
Train Epoch: 387 [40960/90000 (45%)]	Loss: -1.1803	Cost: 9.72s
Train Epoch: 387 [81920/90000 (91%)]	Loss: -1.3144	Cost: 27.02s
Train Epoch: 387 	Average Loss: -0.6888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5320

Learning rate: 5.207858238273524e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 4.1146	Cost: 36.12s
Train Epoch: 388 [40960/90000 (45%)]	Loss: -0.9011	Cost: 11.24s
Train Epoch: 388 [81920/90000 (91%)]	Loss: -1.2284	Cost: 24.21s
Train Epoch: 388 	Average Loss: -0.7287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5287

Learning rate: 4.4380353969200063e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 3.5906	Cost: 39.10s
Train Epoch: 389 [40960/90000 (45%)]	Loss: -1.3235	Cost: 15.77s
Train Epoch: 389 [81920/90000 (91%)]	Loss: -1.3000	Cost: 16.60s
Train Epoch: 389 	Average Loss: -0.7367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4246

Learning rate: 3.7296235070587456e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 3.6073	Cost: 37.49s
Train Epoch: 390 [40960/90000 (45%)]	Loss: -1.0738	Cost: 16.76s
Train Epoch: 390 [81920/90000 (91%)]	Loss: -1.2599	Cost: 12.28s
Train Epoch: 390 	Average Loss: -0.7151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2599

Saving model as e390_model.pt & e390_waveforms_supplementary.hdf5
Learning rate: 3.082666266872038e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 3.9796	Cost: 36.27s
Train Epoch: 391 [40960/90000 (45%)]	Loss: -1.0014	Cost: 13.53s
Train Epoch: 391 [81920/90000 (91%)]	Loss: -1.1932	Cost: 12.24s
Train Epoch: 391 	Average Loss: -0.6838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3038

Learning rate: 2.497203583729958e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 3.8067	Cost: 37.29s
Train Epoch: 392 [40960/90000 (45%)]	Loss: -1.1092	Cost: 12.82s
Train Epoch: 392 [81920/90000 (91%)]	Loss: -1.1793	Cost: 14.95s
Train Epoch: 392 	Average Loss: -0.7092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3316

Learning rate: 1.973271571728442e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 4.0222	Cost: 33.60s
Train Epoch: 393 [40960/90000 (45%)]	Loss: -1.0964	Cost: 11.13s
Train Epoch: 393 [81920/90000 (91%)]	Loss: -1.0845	Cost: 31.44s
Train Epoch: 393 	Average Loss: -0.6946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5076

Learning rate: 1.5109025494620685e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 4.1468	Cost: 38.46s
Train Epoch: 394 [40960/90000 (45%)]	Loss: -1.0941	Cost: 16.71s
Train Epoch: 394 [81920/90000 (91%)]	Loss: -1.1215	Cost: 23.20s
Train Epoch: 394 	Average Loss: -0.6244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3961

Learning rate: 1.1101250380300971e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 4.1167	Cost: 45.42s
Train Epoch: 395 [40960/90000 (45%)]	Loss: -1.1324	Cost: 9.80s
Train Epoch: 395 [81920/90000 (91%)]	Loss: -0.9709	Cost: 26.67s
Train Epoch: 395 	Average Loss: -0.6797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2263

Saving model as e395_model.pt & e395_waveforms_supplementary.hdf5
Learning rate: 7.709637592770994e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 3.6030	Cost: 38.00s
Train Epoch: 396 [40960/90000 (45%)]	Loss: -0.9982	Cost: 10.08s
Train Epoch: 396 [81920/90000 (91%)]	Loss: -1.2691	Cost: 26.04s
Train Epoch: 396 	Average Loss: -0.6992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5660

Learning rate: 4.934396342684002e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 3.8436	Cost: 44.05s
Train Epoch: 397 [40960/90000 (45%)]	Loss: -1.2515	Cost: 16.70s
Train Epoch: 397 [81920/90000 (91%)]	Loss: -1.1337	Cost: 16.42s
Train Epoch: 397 	Average Loss: -0.7184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4276

Learning rate: 2.7756978199944282e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 4.4915	Cost: 45.50s
Train Epoch: 398 [40960/90000 (45%)]	Loss: -1.2334	Cost: 16.46s
Train Epoch: 398 [81920/90000 (91%)]	Loss: -1.2380	Cost: 13.19s
Train Epoch: 398 	Average Loss: -0.6890
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4017

Learning rate: 1.2336751833941234e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 3.8301	Cost: 42.99s
Train Epoch: 399 [40960/90000 (45%)]	Loss: -1.0857	Cost: 9.66s
Train Epoch: 399 [81920/90000 (91%)]	Loss: -0.9824	Cost: 21.09s
Train Epoch: 399 	Average Loss: -0.6667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4567

Learning rate: 3.084235521033653e-09
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 4.2029	Cost: 38.61s
Train Epoch: 400 [40960/90000 (45%)]	Loss: -1.0463	Cost: 9.89s
Train Epoch: 400 [81920/90000 (91%)]	Loss: -1.1239	Cost: 27.69s
Train Epoch: 400 	Average Loss: -0.6891
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4849

Stopping timer.
Training time (including validation): 162567.8636250496 seconds
Saving model
Transfer learning by starting with alpha=0.4!
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 30.1217	Cost: 34.86s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 17.6720	Cost: 9.49s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 15.9432	Cost: 18.45s
Train Epoch: 1 	Average Loss: 18.6609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8225

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999691576447898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 15.6140	Cost: 35.32s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 14.8384	Cost: 9.78s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 14.3046	Cost: 16.77s
Train Epoch: 2 	Average Loss: 14.8436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4027

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 13.9636	Cost: 35.83s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 13.5968	Cost: 9.70s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 13.5307	Cost: 17.26s
Train Epoch: 3 	Average Loss: 13.6578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5648

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 13.4248	Cost: 35.96s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 13.0490	Cost: 9.94s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 12.9494	Cost: 16.15s
Train Epoch: 4 	Average Loss: 13.0410
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1614

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.00019995065603657316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 12.7357	Cost: 35.62s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 12.3469	Cost: 9.89s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 12.6342	Cost: 16.48s
Train Epoch: 5 	Average Loss: 12.4908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9542

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.0001999229036240723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 12.6082	Cost: 36.16s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 12.2816	Cost: 9.60s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 12.0385	Cost: 26.66s
Train Epoch: 6 	Average Loss: 12.2244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7744

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019988898749619702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 12.4422	Cost: 36.38s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 11.9201	Cost: 12.53s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 11.8813	Cost: 22.18s
Train Epoch: 7 	Average Loss: 11.9814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7539

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.00019984890974505381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 12.2837	Cost: 37.56s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 11.5414	Cost: 16.57s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 11.7314	Cost: 16.68s
Train Epoch: 8 	Average Loss: 11.7274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5005

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.00019980267284282717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 11.9784	Cost: 37.06s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 11.5526	Cost: 14.92s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 11.5537	Cost: 20.67s
Train Epoch: 9 	Average Loss: 11.5299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5468

Learning rate: 0.00019975027964162705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 11.8662	Cost: 36.10s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 11.1320	Cost: 14.34s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 11.3710	Cost: 22.13s
Train Epoch: 10 	Average Loss: 11.2904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3602

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 0.00019969173337331284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 11.7418	Cost: 40.57s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 11.1463	Cost: 16.41s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 11.0446	Cost: 16.99s
Train Epoch: 11 	Average Loss: 11.1896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4694

Learning rate: 0.00019962703764929416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 11.4552	Cost: 36.10s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 11.1705	Cost: 14.09s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 10.9910	Cost: 21.22s
Train Epoch: 12 	Average Loss: 11.0276
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4104

Learning rate: 0.00019955619646030802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 11.5860	Cost: 39.75s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 10.9719	Cost: 16.62s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 10.8860	Cost: 15.44s
Train Epoch: 13 	Average Loss: 10.9299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3353

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Learning rate: 0.00019947921417617267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 11.4121	Cost: 37.81s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 10.7497	Cost: 13.41s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 10.7368	Cost: 16.60s
Train Epoch: 14 	Average Loss: 10.7503
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3492

Learning rate: 0.000199396095545518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 11.4083	Cost: 39.78s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 10.6885	Cost: 14.48s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 10.7967	Cost: 16.98s
Train Epoch: 15 	Average Loss: 10.6703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4690

Learning rate: 0.00019930684569549264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 11.4083	Cost: 40.78s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 10.3832	Cost: 10.16s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 10.5412	Cost: 22.60s
Train Epoch: 16 	Average Loss: 10.6079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2011

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Learning rate: 0.0001992114701314478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 11.4335	Cost: 37.70s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 10.3707	Cost: 12.82s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 10.3022	Cost: 18.67s
Train Epoch: 17 	Average Loss: 10.5292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3937

Learning rate: 0.00019910997473659747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 11.2814	Cost: 39.01s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 10.3977	Cost: 9.73s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 10.5650	Cost: 27.27s
Train Epoch: 18 	Average Loss: 10.5190
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3545

Learning rate: 0.00019900236577165574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 11.1874	Cost: 42.35s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 10.1537	Cost: 13.13s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 10.3408	Cost: 18.36s
Train Epoch: 19 	Average Loss: 10.4460
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5082

Learning rate: 0.00019888864987445046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 11.2013	Cost: 44.80s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 10.3582	Cost: 16.03s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 10.5537	Cost: 16.10s
Train Epoch: 20 	Average Loss: 10.2942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3234

Learning rate: 0.00019876883405951377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 11.1336	Cost: 41.41s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 10.1155	Cost: 16.45s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 10.2708	Cost: 16.39s
Train Epoch: 21 	Average Loss: 10.2783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2575

Learning rate: 0.00019864292571764955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 11.4335	Cost: 39.42s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 10.0601	Cost: 16.63s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 10.1982	Cost: 16.61s
Train Epoch: 22 	Average Loss: 10.2347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0754

Saving model as e22_model.pt & e22_waveforms_supplementary.hdf5
Learning rate: 0.0001985109326154774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 11.3424	Cost: 37.05s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 10.1031	Cost: 14.33s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 10.2914	Cost: 16.44s
Train Epoch: 23 	Average Loss: 10.2385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3844

Learning rate: 0.00019837286289495361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 11.0129	Cost: 37.15s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 10.2315	Cost: 15.35s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 10.1544	Cost: 17.18s
Train Epoch: 24 	Average Loss: 10.1897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1546

Learning rate: 0.0001982287250728689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 11.0861	Cost: 37.33s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 9.8559	Cost: 15.93s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 10.2212	Cost: 16.56s
Train Epoch: 25 	Average Loss: 10.0988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3934

Learning rate: 0.00019807852804032305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 11.4299	Cost: 37.44s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 10.0032	Cost: 16.01s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 10.0466	Cost: 17.24s
Train Epoch: 26 	Average Loss: 10.1974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2787

Learning rate: 0.00019792228106217658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 11.0643	Cost: 36.07s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 10.0396	Cost: 15.98s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 9.8325	Cost: 18.44s
Train Epoch: 27 	Average Loss: 9.9691
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3156

Learning rate: 0.0001977599937764791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 11.1193	Cost: 37.79s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 9.7910	Cost: 15.23s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 9.7513	Cost: 21.17s
Train Epoch: 28 	Average Loss: 9.8769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3376

Learning rate: 0.00019759167619387474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 11.1027	Cost: 38.52s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 9.8779	Cost: 16.76s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 9.7470	Cost: 18.28s
Train Epoch: 29 	Average Loss: 9.8576
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3486

Learning rate: 0.00019741733869698495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 11.0606	Cost: 38.29s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 9.8536	Cost: 16.48s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 9.6979	Cost: 17.84s
Train Epoch: 30 	Average Loss: 9.8065
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2522

Learning rate: 0.00019723699203976766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 11.0862	Cost: 39.78s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 9.6228	Cost: 16.36s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 9.7848	Cost: 17.13s
Train Epoch: 31 	Average Loss: 9.7828
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1694

Learning rate: 0.00019705064734685425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 11.1119	Cost: 39.32s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 9.7233	Cost: 16.51s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 9.8932	Cost: 16.05s
Train Epoch: 32 	Average Loss: 9.7746
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1595

Learning rate: 0.00019685831611286313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 10.8145	Cost: 38.71s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 9.4496	Cost: 16.56s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 9.8079	Cost: 17.00s
Train Epoch: 33 	Average Loss: 9.7193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1878

Learning rate: 0.00019666001020169073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 11.3941	Cost: 36.16s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 9.7029	Cost: 16.66s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 9.5504	Cost: 17.98s
Train Epoch: 34 	Average Loss: 9.7285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1919

Learning rate: 0.0001964557418457798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 10.9978	Cost: 38.23s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 9.5990	Cost: 16.44s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 9.4562	Cost: 18.42s
Train Epoch: 35 	Average Loss: 9.6910
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2599

Learning rate: 0.0001962455236453647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 10.9337	Cost: 37.43s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 9.6980	Cost: 16.85s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 9.5160	Cost: 18.40s
Train Epoch: 36 	Average Loss: 9.6631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2883

Learning rate: 0.00019602936856769428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 11.0055	Cost: 37.31s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 9.3746	Cost: 16.77s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 9.5935	Cost: 19.62s
Train Epoch: 37 	Average Loss: 9.5644
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2509

Learning rate: 0.0001958072899462319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 10.8039	Cost: 36.98s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 9.3406	Cost: 16.50s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 9.4881	Cost: 19.02s
Train Epoch: 38 	Average Loss: 9.5836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2504

Learning rate: 0.00019557930147983297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 10.7619	Cost: 37.07s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 9.4673	Cost: 16.57s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 9.5097	Cost: 17.93s
Train Epoch: 39 	Average Loss: 9.6160
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2369

Learning rate: 0.00019534541723190008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 11.1209	Cost: 36.01s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 9.2241	Cost: 15.37s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 9.3790	Cost: 20.27s
Train Epoch: 40 	Average Loss: 9.4399
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1780

Learning rate: 0.00019510565162951532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 10.9711	Cost: 37.93s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 9.3779	Cost: 15.89s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 9.3629	Cost: 20.29s
Train Epoch: 41 	Average Loss: 9.4329
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2751

Learning rate: 0.0001948600194625504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 10.9587	Cost: 39.24s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 9.5391	Cost: 16.78s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 9.4567	Cost: 17.26s
Train Epoch: 42 	Average Loss: 9.5475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3227

Learning rate: 0.00019460853588275446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 10.9436	Cost: 38.87s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 9.2030	Cost: 16.09s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 9.6726	Cost: 15.43s
Train Epoch: 43 	Average Loss: 9.4375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0067

Saving model as e43_model.pt & e43_waveforms_supplementary.hdf5
Learning rate: 0.0001943512164028193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 11.3375	Cost: 41.69s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 9.2016	Cost: 14.44s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 9.3609	Cost: 16.17s
Train Epoch: 44 	Average Loss: 9.4646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1527

Learning rate: 0.00019408807689542249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 11.0844	Cost: 38.03s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 9.2689	Cost: 9.57s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 9.3097	Cost: 24.64s
Train Epoch: 45 	Average Loss: 9.4386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2619

Learning rate: 0.00019381913359224837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 10.7581	Cost: 36.66s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 9.0990	Cost: 10.12s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 9.2800	Cost: 20.81s
Train Epoch: 46 	Average Loss: 9.2956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1491

Learning rate: 0.0001935444030829867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 10.8454	Cost: 35.63s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 9.1708	Cost: 11.50s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 9.2287	Cost: 24.84s
Train Epoch: 47 	Average Loss: 9.2346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1800

Learning rate: 0.00019326390231430937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 10.6352	Cost: 36.80s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 8.7696	Cost: 13.78s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 9.1760	Cost: 19.95s
Train Epoch: 48 	Average Loss: 9.2031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1389

Learning rate: 0.00019297764858882508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 11.4026	Cost: 37.13s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 9.4538	Cost: 13.51s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 9.2820	Cost: 19.85s
Train Epoch: 49 	Average Loss: 9.3227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0822

Learning rate: 0.000192685659564012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 10.9857	Cost: 40.61s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 9.1604	Cost: 13.45s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 9.2401	Cost: 13.14s
Train Epoch: 50 	Average Loss: 9.2448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2746

Learning rate: 0.00019238795325112859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 10.9522	Cost: 40.21s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 9.3052	Cost: 15.95s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 9.3141	Cost: 10.60s
Train Epoch: 51 	Average Loss: 9.3460
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2024

Learning rate: 0.00019208454801410258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 10.9550	Cost: 35.98s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 9.1440	Cost: 15.30s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 9.0603	Cost: 11.26s
Train Epoch: 52 	Average Loss: 9.2703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1823

Learning rate: 0.00019177546256839804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 10.9853	Cost: 43.18s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 9.1092	Cost: 16.28s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 9.3186	Cost: 11.19s
Train Epoch: 53 	Average Loss: 9.2858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1564

Learning rate: 0.0001914607159798613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 10.9541	Cost: 38.48s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 9.2651	Cost: 9.56s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 9.0348	Cost: 21.79s
Train Epoch: 54 	Average Loss: 9.2979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1737

Learning rate: 0.00019114032766354445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 11.0957	Cost: 38.43s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 8.9690	Cost: 12.55s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 8.9233	Cost: 13.76s
Train Epoch: 55 	Average Loss: 9.0802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1736

Learning rate: 0.00019081431738250806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 10.7576	Cost: 39.68s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 8.7508	Cost: 9.67s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 9.1843	Cost: 26.84s
Train Epoch: 56 	Average Loss: 9.1573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1876

Learning rate: 0.00019048270524660188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 11.3334	Cost: 40.16s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 8.9779	Cost: 9.55s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 9.0655	Cost: 22.71s
Train Epoch: 57 	Average Loss: 9.2250
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1657

Learning rate: 0.0001901455117112245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 11.0254	Cost: 39.53s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 8.6678	Cost: 16.20s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 8.7919	Cost: 16.49s
Train Epoch: 58 	Average Loss: 9.0711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1889

Learning rate: 0.0001898027575760615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 10.9472	Cost: 37.18s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 8.6943	Cost: 16.29s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 8.8707	Cost: 16.51s
Train Epoch: 59 	Average Loss: 8.9666
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1722

Learning rate: 0.00018945446398380245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 11.0884	Cost: 39.32s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 8.6274	Cost: 16.60s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 8.7589	Cost: 16.40s
Train Epoch: 60 	Average Loss: 8.8863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1358

Learning rate: 0.00018910065241883672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 10.7777	Cost: 35.81s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 8.6750	Cost: 13.85s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 8.9927	Cost: 16.60s
Train Epoch: 61 	Average Loss: 8.8898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1149

Learning rate: 0.00018874134470592827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 10.7764	Cost: 36.89s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 8.5950	Cost: 13.84s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 8.7396	Cost: 16.38s
Train Epoch: 62 	Average Loss: 8.7810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2536

Learning rate: 0.0001883765630088693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 10.8091	Cost: 36.91s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 8.7164	Cost: 13.59s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 8.7011	Cost: 16.56s
Train Epoch: 63 	Average Loss: 8.8487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1652

Learning rate: 0.00018800632982911313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 10.7974	Cost: 35.62s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 8.7087	Cost: 13.84s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 8.7148	Cost: 19.35s
Train Epoch: 64 	Average Loss: 8.8346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1824

Learning rate: 0.00018763066800438628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 10.8503	Cost: 36.10s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 8.6062	Cost: 15.53s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 8.4670	Cost: 19.49s
Train Epoch: 65 	Average Loss: 8.7539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1738

Learning rate: 0.00018724960070727966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 10.6255	Cost: 39.29s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 8.4710	Cost: 16.60s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 8.6816	Cost: 15.90s
Train Epoch: 66 	Average Loss: 8.7756
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2232

Learning rate: 0.00018686315144381908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 10.6218	Cost: 36.83s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 8.4294	Cost: 16.19s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 8.8335	Cost: 14.37s
Train Epoch: 67 	Average Loss: 8.6766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1135

Learning rate: 0.00018647134405201546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 10.4622	Cost: 38.61s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 8.4721	Cost: 15.32s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 8.6163	Cost: 16.39s
Train Epoch: 68 	Average Loss: 8.7252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1624

Learning rate: 0.00018607420270039433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 10.9887	Cost: 39.59s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 8.4121	Cost: 15.69s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 8.5104	Cost: 16.31s
Train Epoch: 69 	Average Loss: 8.7287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1439

Learning rate: 0.00018567175188650495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 10.9625	Cost: 40.56s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 8.3245	Cost: 9.61s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 8.5660	Cost: 24.55s
Train Epoch: 70 	Average Loss: 8.6930
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0696

Learning rate: 0.0001852640164354092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 10.9767	Cost: 33.52s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 8.5226	Cost: 9.82s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 8.6998	Cost: 22.15s
Train Epoch: 71 	Average Loss: 8.7468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3574

Learning rate: 0.00018485102149815036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 10.6766	Cost: 35.16s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 8.5920	Cost: 9.84s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 8.8862	Cost: 24.80s
Train Epoch: 72 	Average Loss: 8.7214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2896

Learning rate: 0.0001844327925502015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 10.9993	Cost: 41.21s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 8.3462	Cost: 10.68s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 8.5153	Cost: 25.02s
Train Epoch: 73 	Average Loss: 8.6767
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2282

Learning rate: 0.00018400935538989417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 10.8596	Cost: 53.22s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 8.3725	Cost: 14.47s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 8.5147	Cost: 16.67s
Train Epoch: 74 	Average Loss: 8.6302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2396

Learning rate: 0.00018358073613682703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 10.7270	Cost: 41.71s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 8.3711	Cost: 13.57s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 8.3220	Cost: 16.66s
Train Epoch: 75 	Average Loss: 8.5782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2248

Learning rate: 0.00018314696123025452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 10.7863	Cost: 36.10s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 8.3384	Cost: 14.20s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 8.5200	Cost: 16.72s
Train Epoch: 76 	Average Loss: 8.6223
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1937

Learning rate: 0.00018270805742745614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 10.7081	Cost: 37.27s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 8.4500	Cost: 14.49s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 8.5578	Cost: 17.35s
Train Epoch: 77 	Average Loss: 8.7142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1395

Learning rate: 0.00018226405180208597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 10.6896	Cost: 36.77s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 8.6275	Cost: 16.65s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 8.4680	Cost: 16.50s
Train Epoch: 78 	Average Loss: 8.6428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1899

Learning rate: 0.00018181497174250233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 10.9045	Cost: 36.53s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 8.1864	Cost: 14.85s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 8.3246	Cost: 19.06s
Train Epoch: 79 	Average Loss: 8.5865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1886

Learning rate: 0.00018136084495007872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 10.5109	Cost: 36.74s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 8.5415	Cost: 15.63s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 8.3323	Cost: 19.56s
Train Epoch: 80 	Average Loss: 8.5689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1303

Learning rate: 0.00018090169943749476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 11.0088	Cost: 37.37s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 8.3590	Cost: 16.57s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 8.7591	Cost: 16.99s
Train Epoch: 81 	Average Loss: 8.5424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2773

Learning rate: 0.00018043756352700846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 10.9908	Cost: 38.07s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 8.1983	Cost: 16.34s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 8.2503	Cost: 14.44s
Train Epoch: 82 	Average Loss: 8.4728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1830

Learning rate: 0.00017996846584870908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 10.8988	Cost: 38.12s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 8.2304	Cost: 14.83s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 8.3303	Cost: 15.49s
Train Epoch: 83 	Average Loss: 8.4232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1967

Learning rate: 0.000179494435338751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 10.5741	Cost: 39.62s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 8.0584	Cost: 15.91s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 8.2280	Cost: 14.12s
Train Epoch: 84 	Average Loss: 8.3792
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1779

Learning rate: 0.00017901550123756904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 10.7137	Cost: 38.15s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 7.9017	Cost: 16.53s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 8.2271	Cost: 16.18s
Train Epoch: 85 	Average Loss: 8.3724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1739

Learning rate: 0.00017853169308807448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 11.0434	Cost: 38.49s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 8.1539	Cost: 16.27s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 8.5410	Cost: 15.29s
Train Epoch: 86 	Average Loss: 8.4929
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2600

Learning rate: 0.00017804304073383296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 11.0228	Cost: 37.15s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 8.2257	Cost: 16.73s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 8.4459	Cost: 16.59s
Train Epoch: 87 	Average Loss: 8.5640
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1514

Learning rate: 0.00017754957431722346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 10.5497	Cost: 37.90s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 8.2093	Cost: 16.51s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 8.3820	Cost: 16.97s
Train Epoch: 88 	Average Loss: 8.4698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1017

Learning rate: 0.00017705132427757892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 10.9455	Cost: 37.65s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 7.9660	Cost: 16.63s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 8.1067	Cost: 16.88s
Train Epoch: 89 	Average Loss: 8.3707
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1460

Learning rate: 0.00017654832134930882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 10.8615	Cost: 41.07s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 8.0752	Cost: 15.34s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 8.1096	Cost: 16.29s
Train Epoch: 90 	Average Loss: 8.3020
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1751

Learning rate: 0.0001760405965600031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 10.5778	Cost: 45.54s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 8.1268	Cost: 15.87s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 8.3041	Cost: 16.28s
Train Epoch: 91 	Average Loss: 8.2666
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2316

Learning rate: 0.00017552818122851838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 10.9676	Cost: 45.95s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 7.9870	Cost: 13.22s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 8.1754	Cost: 16.63s
Train Epoch: 92 	Average Loss: 8.2275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2026

Learning rate: 0.00017501110696304596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 11.2165	Cost: 41.45s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 7.8745	Cost: 14.57s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 8.0126	Cost: 16.33s
Train Epoch: 93 	Average Loss: 8.2037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1765

Learning rate: 0.0001744894056591622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 11.0345	Cost: 37.36s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 7.8530	Cost: 15.23s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 8.2111	Cost: 16.51s
Train Epoch: 94 	Average Loss: 8.1535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2280

Learning rate: 0.00017396310949786096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 10.5574	Cost: 39.17s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 8.0631	Cost: 16.61s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 8.0739	Cost: 16.76s
Train Epoch: 95 	Average Loss: 8.2927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2128

Learning rate: 0.00017343225094356858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 10.7327	Cost: 40.65s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 8.0083	Cost: 17.01s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 8.0658	Cost: 9.81s
Train Epoch: 96 	Average Loss: 8.2155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2004

Learning rate: 0.00017289686274214118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 10.6701	Cost: 40.16s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 7.8526	Cost: 11.11s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 8.1993	Cost: 16.18s
Train Epoch: 97 	Average Loss: 8.2287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1942

Learning rate: 0.00017235697791884494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 10.8090	Cost: 36.50s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 7.8300	Cost: 12.48s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 7.9345	Cost: 16.04s
Train Epoch: 98 	Average Loss: 8.2308
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1071

Learning rate: 0.0001718126297763189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 10.9962	Cost: 34.08s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 7.9292	Cost: 10.62s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 7.9766	Cost: 22.91s
Train Epoch: 99 	Average Loss: 8.2125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2280

Learning rate: 0.00017126385189252056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 10.6025	Cost: 34.45s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 7.7475	Cost: 9.81s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 7.9820	Cost: 27.70s
Train Epoch: 100 	Average Loss: 8.1132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3271

Learning rate: 0.00017071067811865479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 10.8321	Cost: 36.37s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 7.7165	Cost: 12.64s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 7.9768	Cost: 20.85s
Train Epoch: 101 	Average Loss: 8.0853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0158

Learning rate: 0.00017015314257708562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 10.5293	Cost: 39.05s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 7.7370	Cost: 16.45s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 7.7335	Cost: 17.87s
Train Epoch: 102 	Average Loss: 8.0000
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1941

Learning rate: 0.00016959127965923145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 10.9923	Cost: 40.23s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 7.6537	Cost: 14.13s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 7.6217	Cost: 20.12s
Train Epoch: 103 	Average Loss: 8.0424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0910

Learning rate: 0.00016902512402344375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 10.6417	Cost: 45.41s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 7.8528	Cost: 16.44s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 7.7124	Cost: 16.54s
Train Epoch: 104 	Average Loss: 7.9413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1300

Learning rate: 0.0001684547105928689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 10.7753	Cost: 42.67s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 7.5418	Cost: 13.70s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 7.6923	Cost: 16.83s
Train Epoch: 105 	Average Loss: 7.9868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2595

Learning rate: 0.00016788007455329423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 10.9856	Cost: 53.59s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 8.0916	Cost: 16.30s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 8.1132	Cost: 14.86s
Train Epoch: 106 	Average Loss: 8.2813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2632

Learning rate: 0.00016730125135097737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 10.8365	Cost: 52.73s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 7.7362	Cost: 14.83s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 7.7331	Cost: 13.36s
Train Epoch: 107 	Average Loss: 8.0548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2460

Learning rate: 0.00016671827669046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 10.7856	Cost: 45.65s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 7.7546	Cost: 15.85s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 7.8111	Cost: 13.59s
Train Epoch: 108 	Average Loss: 8.0312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2627

Learning rate: 0.0001661311865323652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 10.4614	Cost: 43.48s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 7.6686	Cost: 16.59s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 7.6166	Cost: 16.68s
Train Epoch: 109 	Average Loss: 7.9349
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2768

Learning rate: 0.00016554001709117943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 10.7317	Cost: 40.70s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 7.5659	Cost: 15.55s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 7.7643	Cost: 16.43s
Train Epoch: 110 	Average Loss: 7.8945
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2928

Learning rate: 0.00016494480483301838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 10.7021	Cost: 39.60s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 7.7451	Cost: 13.19s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 7.7151	Cost: 16.25s
Train Epoch: 111 	Average Loss: 7.8604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0395

Learning rate: 0.0001643455864733779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 10.4785	Cost: 36.86s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 7.6498	Cost: 14.39s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 7.4387	Cost: 16.68s
Train Epoch: 112 	Average Loss: 7.8700
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2145

Learning rate: 0.000163742398974869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 10.6537	Cost: 36.87s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 7.7575	Cost: 13.70s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 7.5850	Cost: 16.46s
Train Epoch: 113 	Average Loss: 7.7803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1182

Learning rate: 0.00016313527954493778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 10.9565	Cost: 36.81s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 7.5039	Cost: 13.09s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 7.6007	Cost: 20.46s
Train Epoch: 114 	Average Loss: 7.7160
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0609

Learning rate: 0.00016252426563357055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 10.6534	Cost: 36.34s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 8.0164	Cost: 15.36s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 7.7899	Cost: 19.49s
Train Epoch: 115 	Average Loss: 7.9507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2094

Learning rate: 0.0001619093949309834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 10.8106	Cost: 36.57s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 7.6539	Cost: 16.68s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 7.6691	Cost: 17.76s
Train Epoch: 116 	Average Loss: 7.8362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2023

Learning rate: 0.00016129070536529766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 10.9818	Cost: 37.89s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 7.4732	Cost: 16.50s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 7.5186	Cost: 16.68s
Train Epoch: 117 	Average Loss: 7.7936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1761

Learning rate: 0.00016066823510019996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 10.9073	Cost: 41.65s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 7.5471	Cost: 15.98s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 7.5966	Cost: 16.33s
Train Epoch: 118 	Average Loss: 7.8301
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1207

Learning rate: 0.0001600420225325884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 10.5253	Cost: 54.73s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 7.5389	Cost: 14.19s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 7.4058	Cost: 13.98s
Train Epoch: 119 	Average Loss: 7.7016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2691

Learning rate: 0.00015941210629020385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 10.9370	Cost: 39.83s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 7.4235	Cost: 16.37s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 7.2667	Cost: 16.17s
Train Epoch: 120 	Average Loss: 7.5605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0672

Learning rate: 0.00015877852522924735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 10.6998	Cost: 49.13s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 7.2714	Cost: 16.42s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 7.2240	Cost: 16.26s
Train Epoch: 121 	Average Loss: 7.5411
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1246

Learning rate: 0.00015814131843198305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 10.7948	Cost: 40.59s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 7.3808	Cost: 16.84s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 7.3940	Cost: 16.46s
Train Epoch: 122 	Average Loss: 7.5552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4152

Learning rate: 0.00015750052520432787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 10.6759	Cost: 37.63s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 7.1115	Cost: 16.84s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 7.4710	Cost: 14.98s
Train Epoch: 123 	Average Loss: 7.5189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1141

Learning rate: 0.0001568561850734264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 10.8250	Cost: 40.90s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 7.7805	Cost: 14.90s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 7.7429	Cost: 12.39s
Train Epoch: 124 	Average Loss: 8.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1692

Learning rate: 0.00015620833778521307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 10.8494	Cost: 37.76s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 7.2077	Cost: 9.54s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 7.3691	Cost: 19.89s
Train Epoch: 125 	Average Loss: 7.7040
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1755

Learning rate: 0.00015555702330196023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 10.9583	Cost: 36.35s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 7.3894	Cost: 9.52s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 7.2713	Cost: 22.95s
Train Epoch: 126 	Average Loss: 7.6271
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3258

Learning rate: 0.00015490228179981317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 10.5816	Cost: 36.40s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 7.2176	Cost: 9.83s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 7.4380	Cost: 24.07s
Train Epoch: 127 	Average Loss: 7.5500
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4169

Learning rate: 0.00015424415366631188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 10.5772	Cost: 35.68s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 6.9957	Cost: 13.85s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 7.1648	Cost: 21.32s
Train Epoch: 128 	Average Loss: 7.4288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2388

Learning rate: 0.00015358267949789966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 10.4908	Cost: 37.87s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 7.1614	Cost: 16.70s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 7.1326	Cost: 18.88s
Train Epoch: 129 	Average Loss: 7.4146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2301

Learning rate: 0.00015291790009741904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 10.4749	Cost: 38.29s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 7.1104	Cost: 16.63s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 7.1063	Cost: 16.51s
Train Epoch: 130 	Average Loss: 7.3539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2267

Learning rate: 0.00015224985647159487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 10.6181	Cost: 40.14s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 6.9945	Cost: 16.42s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 7.1408	Cost: 16.54s
Train Epoch: 131 	Average Loss: 7.4393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3845

Learning rate: 0.00015157858982850473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 10.4603	Cost: 48.29s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 7.0967	Cost: 14.58s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 7.1205	Cost: 14.65s
Train Epoch: 132 	Average Loss: 7.4190
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1864

Learning rate: 0.0001509041415750371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 10.7330	Cost: 48.74s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 7.1236	Cost: 13.44s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 7.0720	Cost: 13.20s
Train Epoch: 133 	Average Loss: 7.4343
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2221

Learning rate: 0.00015022655331433721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 10.3730	Cost: 43.50s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 7.2505	Cost: 16.30s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 7.0224	Cost: 16.32s
Train Epoch: 134 	Average Loss: 7.3785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3429

Learning rate: 0.00014954586684324072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 10.8652	Cost: 43.91s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 7.1689	Cost: 16.35s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 6.9731	Cost: 16.32s
Train Epoch: 135 	Average Loss: 7.3806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2854

Learning rate: 0.00014886212414969547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 10.5259	Cost: 44.69s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 6.9098	Cost: 14.78s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 6.9723	Cost: 17.02s
Train Epoch: 136 	Average Loss: 7.3238
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1733

Learning rate: 0.0001481753674101715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 10.5146	Cost: 40.55s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 6.9078	Cost: 13.71s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 7.1118	Cost: 16.65s
Train Epoch: 137 	Average Loss: 7.3191
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2852

Learning rate: 0.00014748563898705943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 10.6338	Cost: 38.80s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 7.0344	Cost: 16.45s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 6.9988	Cost: 16.58s
Train Epoch: 138 	Average Loss: 7.4016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2905

Learning rate: 0.00014679298142605734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 10.6318	Cost: 39.67s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 7.0328	Cost: 16.22s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 6.8653	Cost: 16.63s
Train Epoch: 139 	Average Loss: 7.3264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2566

Learning rate: 0.00014609743745354624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 10.4668	Cost: 37.98s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 6.7707	Cost: 16.43s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 6.9015	Cost: 12.86s
Train Epoch: 140 	Average Loss: 7.2560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2787

Learning rate: 0.00014539904997395466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 10.7747	Cost: 36.33s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 6.7624	Cost: 16.20s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 6.8614	Cost: 10.36s
Train Epoch: 141 	Average Loss: 7.1918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1795

Learning rate: 0.0001446978620671121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 10.3230	Cost: 41.88s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 6.8053	Cost: 9.46s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 6.8015	Cost: 17.21s
Train Epoch: 142 	Average Loss: 7.1124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3576

Learning rate: 0.0001439939169855915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 10.4694	Cost: 35.07s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 6.6814	Cost: 11.93s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 6.8586	Cost: 17.10s
Train Epoch: 143 	Average Loss: 7.0801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2861

Learning rate: 0.0001432872581520414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 11.0405	Cost: 35.02s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 6.7256	Cost: 9.68s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 6.7324	Cost: 26.74s
Train Epoch: 144 	Average Loss: 7.0959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3175

Learning rate: 0.00014257792915650728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 10.6496	Cost: 35.99s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 6.6778	Cost: 9.89s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 6.6699	Cost: 23.58s
Train Epoch: 145 	Average Loss: 7.0733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3541

Learning rate: 0.0001418659737537428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 10.4863	Cost: 35.95s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 6.7502	Cost: 16.27s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 6.8241	Cost: 17.55s
Train Epoch: 146 	Average Loss: 7.2042
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3679

Learning rate: 0.00014115143586051088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 10.5516	Cost: 37.42s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 6.8957	Cost: 17.14s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 6.8309	Cost: 18.03s
Train Epoch: 147 	Average Loss: 7.1612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3510

Learning rate: 0.0001404343595528745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 10.7106	Cost: 38.01s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 6.6574	Cost: 13.02s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 6.7544	Cost: 21.87s
Train Epoch: 148 	Average Loss: 7.1097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2385

Learning rate: 0.00013971478906347806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 10.4095	Cost: 43.30s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 6.8161	Cost: 16.47s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 6.8108	Cost: 16.91s
Train Epoch: 149 	Average Loss: 7.0364
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1658

Learning rate: 0.00013899276877881884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 10.7104	Cost: 52.90s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 6.6652	Cost: 16.61s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 6.7368	Cost: 14.04s
Train Epoch: 150 	Average Loss: 7.0672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2129

Learning rate: 0.000138268343236509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 10.7232	Cost: 42.70s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 6.6847	Cost: 16.59s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 6.8908	Cost: 16.24s
Train Epoch: 151 	Average Loss: 7.0490
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1422

Learning rate: 0.00013754155712252834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 10.7553	Cost: 49.96s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 6.5506	Cost: 16.18s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 6.7462	Cost: 16.59s
Train Epoch: 152 	Average Loss: 7.0529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3082

Learning rate: 0.00013681245526846785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 10.7576	Cost: 45.65s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 6.7267	Cost: 13.90s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 6.7148	Cost: 16.33s
Train Epoch: 153 	Average Loss: 7.0705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2458

Learning rate: 0.00013608108264876422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 10.7705	Cost: 37.98s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 6.5248	Cost: 13.42s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 6.7292	Cost: 16.56s
Train Epoch: 154 	Average Loss: 6.9817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3347

Learning rate: 0.00013534748437792575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 10.2243	Cost: 37.40s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 6.7479	Cost: 13.55s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 6.7569	Cost: 16.85s
Train Epoch: 155 	Average Loss: 6.9218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3155

Learning rate: 0.00013461170570774932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 10.6417	Cost: 36.61s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 6.5530	Cost: 14.53s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 6.5906	Cost: 16.54s
Train Epoch: 156 	Average Loss: 6.8490
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2285

Learning rate: 0.0001338737920245292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 10.1748	Cost: 36.37s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 6.4987	Cost: 14.60s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 6.6997	Cost: 18.49s
Train Epoch: 157 	Average Loss: 6.7874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2518

Learning rate: 0.00013313378884625713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 10.4924	Cost: 36.96s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 6.2733	Cost: 13.84s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 6.5714	Cost: 21.30s
Train Epoch: 158 	Average Loss: 6.7777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2611

Learning rate: 0.00013239174181981498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 10.6213	Cost: 39.41s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 6.4016	Cost: 16.14s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 6.6311	Cost: 18.31s
Train Epoch: 159 	Average Loss: 6.7483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2355

Learning rate: 0.00013164769671815865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 10.6094	Cost: 45.12s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 6.5777	Cost: 16.25s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 6.5069	Cost: 16.50s
Train Epoch: 160 	Average Loss: 6.7560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1688

Learning rate: 0.0001309016994374948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 10.4784	Cost: 43.04s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 6.5079	Cost: 16.49s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 6.5182	Cost: 16.34s
Train Epoch: 161 	Average Loss: 6.7025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2869

Learning rate: 0.00013015379599444962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 10.5906	Cost: 48.99s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 6.2330	Cost: 16.37s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 6.4367	Cost: 16.04s
Train Epoch: 162 	Average Loss: 6.7297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2717

Learning rate: 0.00012940403252323043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 10.6997	Cost: 45.51s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 6.3612	Cost: 16.52s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 6.5658	Cost: 15.35s
Train Epoch: 163 	Average Loss: 6.6949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3004

Learning rate: 0.00012865245527277986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 10.4742	Cost: 47.22s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 6.3368	Cost: 15.89s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 6.4672	Cost: 10.92s
Train Epoch: 164 	Average Loss: 6.7402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2803

Learning rate: 0.00012789911060392294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 10.6189	Cost: 39.81s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 6.4011	Cost: 14.70s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 6.5527	Cost: 14.17s
Train Epoch: 165 	Average Loss: 6.8136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5026

Learning rate: 0.00012714404498650745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 10.3994	Cost: 44.07s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 6.3474	Cost: 16.56s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 6.6589	Cost: 16.47s
Train Epoch: 166 	Average Loss: 6.8229
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3432

Learning rate: 0.00012638730499653727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 10.2938	Cost: 39.70s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 6.3040	Cost: 16.46s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 6.4016	Cost: 16.46s
Train Epoch: 167 	Average Loss: 6.6875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3420

Learning rate: 0.00012562893731329965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 10.7178	Cost: 43.15s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 6.3708	Cost: 16.96s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 6.3180	Cost: 16.65s
Train Epoch: 168 	Average Loss: 6.6780
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3277

Learning rate: 0.00012486898871648546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 10.5500	Cost: 37.80s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 6.0387	Cost: 15.72s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 6.2440	Cost: 13.79s
Train Epoch: 169 	Average Loss: 6.6259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2492

Learning rate: 0.00012410750608330388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 10.6488	Cost: 37.77s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 6.0241	Cost: 12.63s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 6.2946	Cost: 14.15s
Train Epoch: 170 	Average Loss: 6.5692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2002

Learning rate: 0.00012334453638559054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 10.6404	Cost: 35.48s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 6.0902	Cost: 16.74s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 6.2084	Cost: 10.34s
Train Epoch: 171 	Average Loss: 6.5554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3178

Learning rate: 0.00012258012668691037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 10.6755	Cost: 41.16s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 6.5341	Cost: 9.48s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 6.5027	Cost: 17.62s
Train Epoch: 172 	Average Loss: 6.8444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2685

Learning rate: 0.00012181432413965427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 10.6939	Cost: 35.95s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 6.1618	Cost: 12.88s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 6.3965	Cost: 16.10s
Train Epoch: 173 	Average Loss: 6.6372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3179

Learning rate: 0.0001210471759821306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 10.6119	Cost: 33.64s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 6.3887	Cost: 10.62s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 6.2288	Cost: 24.65s
Train Epoch: 174 	Average Loss: 6.5349
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3327

Learning rate: 0.00012027872953565127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 10.3098	Cost: 35.77s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 6.2395	Cost: 9.94s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 6.4229	Cost: 22.09s
Train Epoch: 175 	Average Loss: 6.4876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3411

Learning rate: 0.00011950903220161285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 10.2896	Cost: 37.02s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 6.1901	Cost: 15.04s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 6.0960	Cost: 20.02s
Train Epoch: 176 	Average Loss: 6.4683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2847

Learning rate: 0.00011873813145857249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 10.5873	Cost: 36.60s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 5.9483	Cost: 16.39s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 6.2225	Cost: 17.09s
Train Epoch: 177 	Average Loss: 6.4544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2621

Learning rate: 0.00011796607485931927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 10.5557	Cost: 37.48s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 5.9568	Cost: 14.43s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 6.1886	Cost: 20.55s
Train Epoch: 178 	Average Loss: 6.4113
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2392

Learning rate: 0.00011719291002794096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 10.5014	Cost: 38.92s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 6.0797	Cost: 16.19s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 6.0007	Cost: 16.67s
Train Epoch: 179 	Average Loss: 6.4244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1583

Learning rate: 0.0001164186846568863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 10.5632	Cost: 40.26s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 5.6803	Cost: 16.47s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 5.8875	Cost: 15.89s
Train Epoch: 180 	Average Loss: 6.2554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1595

Learning rate: 0.0001156434465040231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 10.3308	Cost: 40.18s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 5.9800	Cost: 16.25s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 6.1430	Cost: 16.41s
Train Epoch: 181 	Average Loss: 6.2807
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3150

Learning rate: 0.00011486724338969234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 10.7931	Cost: 42.68s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 5.8665	Cost: 16.38s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 5.8932	Cost: 16.22s
Train Epoch: 182 	Average Loss: 6.2649
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4102

Learning rate: 0.0001140901231937583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 10.3514	Cost: 52.94s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 6.1616	Cost: 15.54s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 6.0544	Cost: 13.15s
Train Epoch: 183 	Average Loss: 6.4486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3606

Learning rate: 0.00011331213385265528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 10.6028	Cost: 49.25s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 5.8322	Cost: 15.96s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 6.0466	Cost: 10.84s
Train Epoch: 184 	Average Loss: 6.2625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3527

Learning rate: 0.00011253332335643047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 10.4993	Cost: 38.46s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 5.6820	Cost: 16.47s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 5.6937	Cost: 16.33s
Train Epoch: 185 	Average Loss: 6.1790
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1493

Learning rate: 0.0001117537397457838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 10.4715	Cost: 48.75s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 5.8406	Cost: 16.86s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 5.8976	Cost: 13.60s
Train Epoch: 186 	Average Loss: 6.1661
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4165

Learning rate: 0.00011097343110910456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 10.3410	Cost: 43.75s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 5.6305	Cost: 16.04s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 5.7732	Cost: 14.24s
Train Epoch: 187 	Average Loss: 6.1424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2945

Learning rate: 0.00011019244557950502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 10.2154	Cost: 51.85s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 5.7740	Cost: 14.16s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 5.8880	Cost: 12.86s
Train Epoch: 188 	Average Loss: 6.1586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3200

Learning rate: 0.00010941083133185145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 10.4933	Cost: 40.97s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 5.6868	Cost: 14.53s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 5.8406	Cost: 13.93s
Train Epoch: 189 	Average Loss: 6.1184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3113

Learning rate: 0.00010862863657979236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 10.5421	Cost: 40.44s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 5.6604	Cost: 16.38s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 5.7537	Cost: 14.30s
Train Epoch: 190 	Average Loss: 6.0976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1507

Learning rate: 0.00010784590957278452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 10.1417	Cost: 40.51s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 5.6986	Cost: 15.91s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 5.7107	Cost: 13.78s
Train Epoch: 191 	Average Loss: 6.0764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3943

Learning rate: 0.00010706269859311669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 10.3374	Cost: 41.87s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 5.7260	Cost: 14.96s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 5.7929	Cost: 13.27s
Train Epoch: 192 	Average Loss: 6.0340
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3833

Learning rate: 0.00010627905195293137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 10.6613	Cost: 44.09s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 5.5591	Cost: 16.01s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 5.7852	Cost: 13.43s
Train Epoch: 193 	Average Loss: 6.0378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4886

Learning rate: 0.00010549501799124461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 10.2515	Cost: 48.77s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 5.5182	Cost: 16.26s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 5.6548	Cost: 13.47s
Train Epoch: 194 	Average Loss: 6.0680
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3230

Learning rate: 0.00010471064507096429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 10.3148	Cost: 39.43s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 5.7053	Cost: 14.75s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 5.6811	Cost: 16.35s
Train Epoch: 195 	Average Loss: 6.0367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2648

Learning rate: 0.00010392598157590689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 10.6175	Cost: 42.96s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 5.5815	Cost: 16.18s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 5.6033	Cost: 16.24s
Train Epoch: 196 	Average Loss: 6.0491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4309

Learning rate: 0.00010314107590781285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 10.4720	Cost: 38.99s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 5.5583	Cost: 16.48s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 5.5309	Cost: 16.41s
Train Epoch: 197 	Average Loss: 6.0469
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3539

Learning rate: 0.00010235597648336105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 10.4301	Cost: 37.94s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 5.4981	Cost: 14.32s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 5.5650	Cost: 16.33s
Train Epoch: 198 	Average Loss: 6.0139
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3825

Learning rate: 0.0001015707317311821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 10.4224	Cost: 40.22s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 5.4544	Cost: 16.30s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 5.7243	Cost: 16.48s
Train Epoch: 199 	Average Loss: 6.0396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4321

Learning rate: 0.00010078539008887115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 10.5741	Cost: 39.71s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 5.4720	Cost: 13.14s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 5.5967	Cost: 13.37s
Train Epoch: 200 	Average Loss: 5.9615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4803

Learning rate: 0.00010000000000000002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 10.4465	Cost: 37.90s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 5.5039	Cost: 13.42s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 5.5563	Cost: 13.51s
Train Epoch: 201 	Average Loss: 5.9350
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3975

Learning rate: 9.92146099111289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 10.4950	Cost: 40.79s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 5.4825	Cost: 9.50s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 5.6435	Cost: 19.79s
Train Epoch: 202 	Average Loss: 5.8466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3886

Learning rate: 9.842926826881797e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 10.4590	Cost: 34.65s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 5.3976	Cost: 12.94s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 5.4334	Cost: 17.78s
Train Epoch: 203 	Average Loss: 5.8507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4092

Learning rate: 9.7644023516639e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 10.2190	Cost: 33.95s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 5.2518	Cost: 10.74s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 5.3034	Cost: 27.48s
Train Epoch: 204 	Average Loss: 5.7603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4557

Learning rate: 9.68589240921872e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 10.3434	Cost: 37.57s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 5.2077	Cost: 11.56s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 5.1896	Cost: 28.06s
Train Epoch: 205 	Average Loss: 5.7144
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2487

Learning rate: 9.607401842409317e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 10.6236	Cost: 40.27s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 5.5261	Cost: 16.10s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 5.6164	Cost: 18.74s
Train Epoch: 206 	Average Loss: 5.7758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3055

Learning rate: 9.528935492903578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 10.3581	Cost: 43.00s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 5.3119	Cost: 16.41s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 5.5036	Cost: 16.60s
Train Epoch: 207 	Average Loss: 5.8042
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3390

Learning rate: 9.450498200875547e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 10.4265	Cost: 50.36s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 5.0733	Cost: 15.74s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 5.5161	Cost: 14.17s
Train Epoch: 208 	Average Loss: 5.6740
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2966

Learning rate: 9.372094804706868e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 10.3915	Cost: 46.96s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 5.3864	Cost: 16.30s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 5.2768	Cost: 13.45s
Train Epoch: 209 	Average Loss: 5.6274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3280

Learning rate: 9.293730140688336e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 10.3330	Cost: 47.80s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 5.4408	Cost: 16.35s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 5.2883	Cost: 12.80s
Train Epoch: 210 	Average Loss: 5.6912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4833

Learning rate: 9.215409042721555e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 10.8575	Cost: 48.89s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 5.2828	Cost: 13.62s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 5.3875	Cost: 13.53s
Train Epoch: 211 	Average Loss: 5.7308
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4086

Learning rate: 9.13713634202077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 10.4823	Cost: 50.52s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 5.3750	Cost: 14.60s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 5.3740	Cost: 12.15s
Train Epoch: 212 	Average Loss: 5.7823
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4025

Learning rate: 9.058916866814858e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 10.3299	Cost: 43.82s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 5.1269	Cost: 12.74s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 5.1878	Cost: 14.03s
Train Epoch: 213 	Average Loss: 5.7011
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3220

Learning rate: 8.9807554420495e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 10.3780	Cost: 43.31s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 4.7983	Cost: 16.73s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 5.0479	Cost: 14.90s
Train Epoch: 214 	Average Loss: 5.5999
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3792

Learning rate: 8.902656889089548e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 10.3383	Cost: 40.68s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 5.2629	Cost: 16.72s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 5.2522	Cost: 16.44s
Train Epoch: 215 	Average Loss: 5.6291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3345

Learning rate: 8.824626025421624e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 10.3449	Cost: 44.69s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 5.0976	Cost: 16.30s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 5.2821	Cost: 16.39s
Train Epoch: 216 	Average Loss: 5.5910
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3364

Learning rate: 8.746667664356959e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 10.3300	Cost: 40.18s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 5.1795	Cost: 16.85s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 5.1421	Cost: 14.15s
Train Epoch: 217 	Average Loss: 5.5586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5037

Learning rate: 8.668786614734478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 10.4098	Cost: 35.36s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 4.9572	Cost: 13.72s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 4.9394	Cost: 13.06s
Train Epoch: 218 	Average Loss: 5.4360
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2384

Learning rate: 8.590987680624175e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 10.3687	Cost: 42.00s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 4.8901	Cost: 9.59s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 5.1223	Cost: 18.85s
Train Epoch: 219 	Average Loss: 5.4244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3832

Learning rate: 8.51327566103077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 10.7147	Cost: 35.47s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 4.8956	Cost: 12.67s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 4.9192	Cost: 17.25s
Train Epoch: 220 	Average Loss: 5.4237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3475

Learning rate: 8.435655349597692e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 9.9245	Cost: 33.50s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 4.9009	Cost: 10.14s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 5.0061	Cost: 30.49s
Train Epoch: 221 	Average Loss: 5.3205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2962

Learning rate: 8.35813153431137e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 10.4278	Cost: 35.92s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 4.8568	Cost: 9.65s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 5.0389	Cost: 31.50s
Train Epoch: 222 	Average Loss: 5.3600
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4512

Learning rate: 8.280708997205904e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 10.2836	Cost: 38.79s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 4.8037	Cost: 16.38s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 4.9415	Cost: 16.62s
Train Epoch: 223 	Average Loss: 5.3236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4068

Learning rate: 8.203392514068074e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 10.4814	Cost: 39.08s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 4.8569	Cost: 13.25s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 4.8990	Cost: 18.39s
Train Epoch: 224 	Average Loss: 5.3391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4546

Learning rate: 8.126186854142755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 10.2500	Cost: 53.32s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 5.0123	Cost: 16.33s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 5.0330	Cost: 14.87s
Train Epoch: 225 	Average Loss: 5.3475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5545

Learning rate: 8.049096779838719e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 10.7123	Cost: 46.23s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 4.9234	Cost: 15.77s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 5.1876	Cost: 16.00s
Train Epoch: 226 	Average Loss: 5.4216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4038

Learning rate: 7.972127046434877e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 10.2571	Cost: 45.23s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 4.9032	Cost: 15.36s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 5.1134	Cost: 16.39s
Train Epoch: 227 	Average Loss: 5.3367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4973

Learning rate: 7.895282401786947e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 10.2273	Cost: 38.49s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 4.7255	Cost: 13.76s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 4.7610	Cost: 16.49s
Train Epoch: 228 	Average Loss: 5.2582
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5179

Learning rate: 7.818567586034578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 10.3417	Cost: 37.46s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 4.6346	Cost: 15.62s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 4.6421	Cost: 16.66s
Train Epoch: 229 	Average Loss: 5.1896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3530

Learning rate: 7.741987331308968e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 10.0861	Cost: 37.79s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 4.8651	Cost: 16.48s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 4.7103	Cost: 16.31s
Train Epoch: 230 	Average Loss: 5.2057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4228

Learning rate: 7.665546361440945e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 10.5376	Cost: 38.56s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 4.5145	Cost: 16.45s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 4.7863	Cost: 16.35s
Train Epoch: 231 	Average Loss: 5.1677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4910

Learning rate: 7.589249391669613e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 10.5865	Cost: 39.21s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 4.6385	Cost: 16.49s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 4.5973	Cost: 16.15s
Train Epoch: 232 	Average Loss: 5.2311
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3471

Learning rate: 7.513101128351452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 10.3007	Cost: 38.29s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 4.5101	Cost: 16.10s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 4.6830	Cost: 16.58s
Train Epoch: 233 	Average Loss: 5.1168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3458

Learning rate: 7.437106268670034e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 10.4323	Cost: 39.00s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 4.3237	Cost: 16.23s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 4.7228	Cost: 17.79s
Train Epoch: 234 	Average Loss: 5.0873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4907

Learning rate: 7.361269500346273e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 10.7355	Cost: 37.10s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 4.5312	Cost: 16.46s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 4.5808	Cost: 17.76s
Train Epoch: 235 	Average Loss: 5.0717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3622

Learning rate: 7.28559550134926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 10.3200	Cost: 39.58s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 4.5020	Cost: 16.74s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 4.2896	Cost: 16.15s
Train Epoch: 236 	Average Loss: 4.9775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4115

Learning rate: 7.210088939607711e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 10.3362	Cost: 40.02s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 4.5131	Cost: 16.50s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 4.7654	Cost: 14.21s
Train Epoch: 237 	Average Loss: 4.9470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5275

Learning rate: 7.13475447272202e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 10.1947	Cost: 38.14s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 4.3937	Cost: 16.16s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 4.6098	Cost: 13.62s
Train Epoch: 238 	Average Loss: 4.9302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3682

Learning rate: 7.059596747676965e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 10.4186	Cost: 37.61s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 4.5086	Cost: 16.23s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 4.6143	Cost: 13.05s
Train Epoch: 239 	Average Loss: 5.0297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4071

Learning rate: 6.984620400555048e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 10.4002	Cost: 37.14s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 4.5210	Cost: 16.22s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 4.4759	Cost: 16.59s
Train Epoch: 240 	Average Loss: 4.9913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2488

Learning rate: 6.909830056250531e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 10.0653	Cost: 37.29s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 4.2663	Cost: 14.89s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 4.5592	Cost: 20.69s
Train Epoch: 241 	Average Loss: 4.8765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5645

Learning rate: 6.835230328184141e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 10.4073	Cost: 38.41s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 4.4037	Cost: 16.38s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 4.5424	Cost: 15.77s
Train Epoch: 242 	Average Loss: 4.8780
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3852

Learning rate: 6.760825818018508e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 10.4854	Cost: 39.45s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 4.4206	Cost: 16.22s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 4.4792	Cost: 13.77s
Train Epoch: 243 	Average Loss: 4.9196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3629

Learning rate: 6.686621115374292e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 10.3120	Cost: 36.85s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 4.5526	Cost: 15.79s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 4.3003	Cost: 16.16s
Train Epoch: 244 	Average Loss: 4.8978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5669

Learning rate: 6.61262079754709e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 10.2603	Cost: 39.67s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 4.1479	Cost: 10.83s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 4.5597	Cost: 20.50s
Train Epoch: 245 	Average Loss: 4.8596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5034

Learning rate: 6.538829429225073e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 10.0674	Cost: 36.85s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 4.5700	Cost: 12.97s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 4.3452	Cost: 19.40s
Train Epoch: 246 	Average Loss: 4.9152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5726

Learning rate: 6.465251562207432e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 10.2605	Cost: 35.12s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 4.5741	Cost: 9.90s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 4.4394	Cost: 25.38s
Train Epoch: 247 	Average Loss: 4.9093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4260

Learning rate: 6.391891735123586e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 10.1805	Cost: 39.56s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 4.4061	Cost: 11.35s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 4.6767	Cost: 25.57s
Train Epoch: 248 	Average Loss: 4.8762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4786

Learning rate: 6.318754473153225e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 10.3108	Cost: 42.70s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 4.4776	Cost: 10.43s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 4.6846	Cost: 20.71s
Train Epoch: 249 	Average Loss: 4.8655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4627

Learning rate: 6.245844287747173e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 10.4111	Cost: 52.59s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 4.4161	Cost: 13.92s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 4.6695	Cost: 16.45s
Train Epoch: 250 	Average Loss: 4.8867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4053

Learning rate: 6.173165676349108e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 10.6383	Cost: 41.82s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 4.1753	Cost: 16.44s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 4.2379	Cost: 16.55s
Train Epoch: 251 	Average Loss: 4.8207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5509

Learning rate: 6.10072312211812e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 10.0588	Cost: 39.57s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 4.2325	Cost: 16.73s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 4.2714	Cost: 16.43s
Train Epoch: 252 	Average Loss: 4.7340
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3614

Learning rate: 6.0285210936521955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 10.6705	Cost: 37.21s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 4.1332	Cost: 13.67s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 4.0623	Cost: 18.65s
Train Epoch: 253 	Average Loss: 4.7164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4284

Learning rate: 5.956564044712553e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 9.9578	Cost: 36.10s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 4.0318	Cost: 15.21s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 4.1544	Cost: 19.52s
Train Epoch: 254 	Average Loss: 4.5939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4150

Learning rate: 5.8848564139489155e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 10.6056	Cost: 36.62s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 4.1547	Cost: 16.32s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 4.2276	Cost: 16.32s
Train Epoch: 255 	Average Loss: 4.6489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4756

Learning rate: 5.813402624625721e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 9.8749	Cost: 38.43s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 4.0685	Cost: 14.63s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 4.0334	Cost: 16.55s
Train Epoch: 256 	Average Loss: 4.5505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3390

Learning rate: 5.742207084349277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 10.2781	Cost: 35.96s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 3.8007	Cost: 13.31s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 4.1779	Cost: 17.90s
Train Epoch: 257 	Average Loss: 4.5781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4275

Learning rate: 5.6712741847958634e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 9.8486	Cost: 37.60s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 4.1156	Cost: 16.70s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 4.1538	Cost: 16.93s
Train Epoch: 258 	Average Loss: 4.6206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5461

Learning rate: 5.600608301440851e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 10.3668	Cost: 37.55s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 4.1161	Cost: 13.71s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 4.2370	Cost: 20.99s
Train Epoch: 259 	Average Loss: 4.6492
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6044

Learning rate: 5.5302137932887924e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 10.1708	Cost: 39.46s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 4.0052	Cost: 16.40s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 4.1645	Cost: 16.53s
Train Epoch: 260 	Average Loss: 4.5820
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5589

Learning rate: 5.460095002604535e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 10.4399	Cost: 40.29s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 3.8162	Cost: 16.60s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 4.1534	Cost: 16.16s
Train Epoch: 261 	Average Loss: 4.5207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2438

Learning rate: 5.390256254645381e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 10.6896	Cost: 38.19s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 3.6149	Cost: 16.35s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 4.0022	Cost: 16.47s
Train Epoch: 262 	Average Loss: 4.4822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5567

Learning rate: 5.3207018573942705e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 10.7187	Cost: 42.39s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 3.7069	Cost: 16.54s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 3.9154	Cost: 16.66s
Train Epoch: 263 	Average Loss: 4.4259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4835

Learning rate: 5.251436101294054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 10.1490	Cost: 51.76s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 3.6607	Cost: 16.48s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 4.0742	Cost: 15.42s
Train Epoch: 264 	Average Loss: 4.4167
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3258

Learning rate: 5.1824632589828485e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 10.1050	Cost: 41.49s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 3.7708	Cost: 15.48s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 3.9129	Cost: 16.64s
Train Epoch: 265 	Average Loss: 4.3399
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5515

Learning rate: 5.1137875850304516e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 10.4669	Cost: 37.92s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 3.8267	Cost: 13.49s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 3.6988	Cost: 16.62s
Train Epoch: 266 	Average Loss: 4.3370
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4021

Learning rate: 5.045413315675926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 9.8165	Cost: 37.92s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 3.8303	Cost: 13.77s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 3.9386	Cost: 16.38s
Train Epoch: 267 	Average Loss: 4.2717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4171

Learning rate: 4.977344668566277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 10.1302	Cost: 37.80s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 3.6646	Cost: 15.40s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 3.8449	Cost: 16.62s
Train Epoch: 268 	Average Loss: 4.2774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5196

Learning rate: 4.909585842496289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 10.2188	Cost: 38.65s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 3.7435	Cost: 16.48s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 3.7502	Cost: 16.48s
Train Epoch: 269 	Average Loss: 4.2207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6520

Learning rate: 4.842141017149528e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 10.0001	Cost: 38.26s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 3.6466	Cost: 16.44s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 3.7621	Cost: 17.06s
Train Epoch: 270 	Average Loss: 4.2797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5522

Learning rate: 4.775014352840514e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 10.2959	Cost: 39.82s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 3.4595	Cost: 15.86s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 3.8966	Cost: 12.61s
Train Epoch: 271 	Average Loss: 4.2301
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4099

Learning rate: 4.708209990258097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 10.2744	Cost: 36.12s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 3.7149	Cost: 15.75s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 3.7241	Cost: 10.99s
Train Epoch: 272 	Average Loss: 4.2067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5053

Learning rate: 4.641732050210033e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 10.3960	Cost: 39.72s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 3.3737	Cost: 15.57s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 3.6828	Cost: 10.55s
Train Epoch: 273 	Average Loss: 4.1529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4960

Learning rate: 4.575584633368813e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 10.3635	Cost: 39.22s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 3.7369	Cost: 9.52s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 3.6510	Cost: 16.96s
Train Epoch: 274 	Average Loss: 4.2194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7114

Learning rate: 4.509771820018683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 10.2485	Cost: 35.27s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 3.9455	Cost: 9.66s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 3.8607	Cost: 21.52s
Train Epoch: 275 	Average Loss: 4.4127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6462

Learning rate: 4.4442976698039786e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 10.2341	Cost: 34.97s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 3.6685	Cost: 9.77s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 3.9766	Cost: 25.93s
Train Epoch: 276 	Average Loss: 4.2877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5083

Learning rate: 4.379166221478695e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 10.0292	Cost: 37.59s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 3.6210	Cost: 13.79s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 3.8475	Cost: 20.09s
Train Epoch: 277 	Average Loss: 4.1899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4288

Learning rate: 4.3143814926573614e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 10.1941	Cost: 36.49s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 3.6865	Cost: 16.66s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 3.8495	Cost: 17.07s
Train Epoch: 278 	Average Loss: 4.1864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3250

Learning rate: 4.249947479567216e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 10.2028	Cost: 39.20s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 3.6834	Cost: 11.54s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 3.5082	Cost: 24.69s
Train Epoch: 279 	Average Loss: 4.0461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6959

Learning rate: 4.1858681568016955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 10.4071	Cost: 41.77s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 3.4190	Cost: 15.82s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 3.6926	Cost: 14.33s
Train Epoch: 280 	Average Loss: 4.0626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5459

Learning rate: 4.122147477075271e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 10.3176	Cost: 40.76s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 3.3880	Cost: 12.65s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 3.5587	Cost: 17.67s
Train Epoch: 281 	Average Loss: 4.0823
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5532

Learning rate: 4.058789370979617e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 10.3479	Cost: 37.45s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 3.5137	Cost: 16.24s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 3.5334	Cost: 14.40s
Train Epoch: 282 	Average Loss: 4.0331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5743

Learning rate: 3.995797746741162e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 10.0372	Cost: 38.76s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 3.3786	Cost: 9.70s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 3.5907	Cost: 23.94s
Train Epoch: 283 	Average Loss: 3.9876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5280

Learning rate: 3.933176489980003e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 10.0143	Cost: 38.12s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 3.3251	Cost: 12.72s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 3.5435	Cost: 18.51s
Train Epoch: 284 	Average Loss: 3.9203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6687

Learning rate: 3.8709294634702356e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 10.3060	Cost: 39.23s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 3.3695	Cost: 9.86s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 3.3346	Cost: 26.77s
Train Epoch: 285 	Average Loss: 3.9508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5816

Learning rate: 3.809060506901661e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 10.0695	Cost: 41.12s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 3.2561	Cost: 13.44s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 3.4649	Cost: 20.63s
Train Epoch: 286 	Average Loss: 3.9458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4284

Learning rate: 3.747573436642949e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 9.8689	Cost: 39.08s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 3.2919	Cost: 16.13s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 3.3574	Cost: 16.52s
Train Epoch: 287 	Average Loss: 3.9078
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5789

Learning rate: 3.686472045506224e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 10.3728	Cost: 38.65s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 3.1201	Cost: 16.46s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 3.3690	Cost: 16.52s
Train Epoch: 288 	Average Loss: 3.9253
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5749

Learning rate: 3.625760102513104e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 9.5854	Cost: 37.40s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 3.3051	Cost: 14.55s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 3.3395	Cost: 16.96s
Train Epoch: 289 	Average Loss: 3.8634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5383

Learning rate: 3.5654413526622126e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 10.1321	Cost: 37.27s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 3.3389	Cost: 15.70s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 3.3545	Cost: 17.01s
Train Epoch: 290 	Average Loss: 3.8523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6008

Learning rate: 3.505519516698166e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 9.9843	Cost: 36.84s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 3.2129	Cost: 16.28s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 3.2856	Cost: 17.19s
Train Epoch: 291 	Average Loss: 3.8467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4575

Learning rate: 3.445998290882063e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 10.1829	Cost: 36.20s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 3.0769	Cost: 16.72s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 3.2003	Cost: 18.11s
Train Epoch: 292 	Average Loss: 3.8281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4302

Learning rate: 3.386881346763484e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 9.6762	Cost: 38.52s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 3.0950	Cost: 16.12s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 3.1037	Cost: 13.62s
Train Epoch: 293 	Average Loss: 3.7452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5450

Learning rate: 3.328172330954006e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 9.8851	Cost: 39.29s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 3.1679	Cost: 16.23s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 3.2696	Cost: 14.70s
Train Epoch: 294 	Average Loss: 3.7758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4835

Learning rate: 3.269874864902267e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 9.8464	Cost: 37.31s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 3.1213	Cost: 16.59s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 3.0521	Cost: 16.57s
Train Epoch: 295 	Average Loss: 3.7649
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7421

Learning rate: 3.2119925446705836e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 9.9526	Cost: 37.13s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 3.1384	Cost: 16.33s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 3.2083	Cost: 17.60s
Train Epoch: 296 	Average Loss: 3.7370
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5102

Learning rate: 3.1545289407131144e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 9.9698	Cost: 37.13s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 3.1050	Cost: 16.52s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 3.2860	Cost: 17.10s
Train Epoch: 297 	Average Loss: 3.7100
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7856

Learning rate: 3.09748759765563e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 10.1565	Cost: 39.67s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 3.1478	Cost: 16.46s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 3.0959	Cost: 15.29s
Train Epoch: 298 	Average Loss: 3.7151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4509

Learning rate: 3.0408720340768585e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 10.0372	Cost: 39.25s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 2.9642	Cost: 13.26s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 3.0785	Cost: 15.99s
Train Epoch: 299 	Average Loss: 3.6548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5342

Learning rate: 2.9846857422914446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 10.2007	Cost: 39.67s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 3.1144	Cost: 15.02s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 2.9568	Cost: 15.84s
Train Epoch: 300 	Average Loss: 3.6399
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5883

Learning rate: 2.9289321881345268e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 10.1805	Cost: 39.10s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 3.0155	Cost: 9.66s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 3.0935	Cost: 22.90s
Train Epoch: 301 	Average Loss: 3.6684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5007

Learning rate: 2.8736148107479478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 9.9809	Cost: 36.67s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 2.9748	Cost: 9.85s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 3.0029	Cost: 24.55s
Train Epoch: 302 	Average Loss: 3.5891
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4725

Learning rate: 2.8187370223681142e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 9.9402	Cost: 40.22s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 2.9042	Cost: 11.97s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 2.9834	Cost: 21.13s
Train Epoch: 303 	Average Loss: 3.5738
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5002

Learning rate: 2.764302208115509e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 9.7813	Cost: 42.11s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 2.9314	Cost: 16.58s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 3.0998	Cost: 16.48s
Train Epoch: 304 	Average Loss: 3.5508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5201

Learning rate: 2.710313725785888e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 9.9946	Cost: 36.78s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 2.7582	Cost: 16.21s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 2.8629	Cost: 16.56s
Train Epoch: 305 	Average Loss: 3.5334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7236

Learning rate: 2.6567749056431446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 10.0070	Cost: 38.16s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 3.0353	Cost: 13.21s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 3.0955	Cost: 16.42s
Train Epoch: 306 	Average Loss: 3.5704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6176

Learning rate: 2.6036890502139035e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 9.9037	Cost: 36.59s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 2.7118	Cost: 14.77s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 3.2076	Cost: 16.32s
Train Epoch: 307 	Average Loss: 3.5206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5396

Learning rate: 2.55105943408378e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 10.0822	Cost: 36.90s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 2.8540	Cost: 16.09s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 2.9926	Cost: 16.53s
Train Epoch: 308 	Average Loss: 3.5285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5293

Learning rate: 2.4988893036954053e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 10.2084	Cost: 37.16s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 3.1138	Cost: 16.51s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 2.7936	Cost: 16.41s
Train Epoch: 309 	Average Loss: 3.4708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6788

Learning rate: 2.4471818771481658e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 10.2594	Cost: 36.01s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 2.8183	Cost: 14.15s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 2.7731	Cost: 20.75s
Train Epoch: 310 	Average Loss: 3.4577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6026

Learning rate: 2.3959403439996917e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 10.3030	Cost: 39.40s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 2.8362	Cost: 16.63s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 2.8172	Cost: 16.42s
Train Epoch: 311 	Average Loss: 3.4844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6273

Learning rate: 2.345167865069121e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 10.0851	Cost: 39.37s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 2.6846	Cost: 16.90s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 2.8224	Cost: 16.31s
Train Epoch: 312 	Average Loss: 3.3688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5779

Learning rate: 2.2948675722421096e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 10.3657	Cost: 42.42s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 2.6840	Cost: 16.72s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 2.6709	Cost: 16.59s
Train Epoch: 313 	Average Loss: 3.3509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6046

Learning rate: 2.2450425682776575e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 10.1777	Cost: 55.92s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 2.8002	Cost: 16.56s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 2.8120	Cost: 12.92s
Train Epoch: 314 	Average Loss: 3.3563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7225

Learning rate: 2.1956959266167054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 10.0533	Cost: 42.60s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 2.8664	Cost: 14.48s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 2.8019	Cost: 13.54s
Train Epoch: 315 	Average Loss: 3.2979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5447

Learning rate: 2.1468306911925506e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 9.6995	Cost: 44.47s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 2.5735	Cost: 14.61s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 2.5014	Cost: 16.01s
Train Epoch: 316 	Average Loss: 3.2905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6031

Learning rate: 2.098449876243097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 10.0381	Cost: 45.75s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 2.6487	Cost: 15.14s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 2.7334	Cost: 16.40s
Train Epoch: 317 	Average Loss: 3.2936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5539

Learning rate: 2.050556466124901e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 9.8911	Cost: 37.36s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 2.6998	Cost: 13.51s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 2.6844	Cost: 16.52s
Train Epoch: 318 	Average Loss: 3.2660
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5414

Learning rate: 2.0031534151290953e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 10.2375	Cost: 37.99s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 2.5515	Cost: 16.00s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 2.7198	Cost: 16.56s
Train Epoch: 319 	Average Loss: 3.2750
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5143

Learning rate: 1.9562436472991562e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 9.9976	Cost: 36.16s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 2.5841	Cost: 16.29s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 2.6041	Cost: 16.80s
Train Epoch: 320 	Average Loss: 3.2766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4861

Learning rate: 1.9098300562505276e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 10.0799	Cost: 39.44s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 2.4187	Cost: 16.64s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 2.5729	Cost: 15.97s
Train Epoch: 321 	Average Loss: 3.2077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5236

Learning rate: 1.863915504992132e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 10.0141	Cost: 38.63s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 2.6062	Cost: 15.88s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 2.7364	Cost: 11.07s
Train Epoch: 322 	Average Loss: 3.2291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3960

Learning rate: 1.8185028257497683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 9.9748	Cost: 40.94s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 2.4546	Cost: 9.50s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 2.9451	Cost: 17.80s
Train Epoch: 323 	Average Loss: 3.2137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5335

Learning rate: 1.7735948197914044e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 9.8657	Cost: 36.83s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 2.4343	Cost: 12.60s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 2.5680	Cost: 17.86s
Train Epoch: 324 	Average Loss: 3.1642
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6734

Learning rate: 1.729194257254384e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 9.7633	Cost: 35.29s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 2.6938	Cost: 10.30s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 2.4179	Cost: 25.54s
Train Epoch: 325 	Average Loss: 3.1597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5162

Learning rate: 1.685303876974551e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 9.8609	Cost: 35.47s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 2.5013	Cost: 9.62s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 2.6470	Cost: 23.77s
Train Epoch: 326 	Average Loss: 3.1642
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7768

Learning rate: 1.6419263863173007e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 9.6225	Cost: 36.74s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 2.5715	Cost: 16.46s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 2.7778	Cost: 16.66s
Train Epoch: 327 	Average Loss: 3.1212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5141

Learning rate: 1.599064461010582e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 9.6642	Cost: 38.23s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 2.3021	Cost: 14.90s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 2.7810	Cost: 18.35s
Train Epoch: 328 	Average Loss: 3.1699
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3887

Learning rate: 1.5567207449798525e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 10.3075	Cost: 38.49s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 2.4569	Cost: 12.90s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 2.4283	Cost: 19.44s
Train Epoch: 329 	Average Loss: 3.1585
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5126

Learning rate: 1.5148978501849652e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 10.0013	Cost: 52.20s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 2.5234	Cost: 16.39s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 2.5507	Cost: 16.25s
Train Epoch: 330 	Average Loss: 3.0951
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6299

Learning rate: 1.4735983564590815e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 9.9766	Cost: 47.99s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 2.3361	Cost: 16.52s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 2.3982	Cost: 15.93s
Train Epoch: 331 	Average Loss: 3.0368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5874

Learning rate: 1.4328248113495055e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 9.8480	Cost: 38.54s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 2.5060	Cost: 14.21s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 2.3354	Cost: 16.45s
Train Epoch: 332 	Average Loss: 3.0778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5309

Learning rate: 1.3925797299605635e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 9.9753	Cost: 55.38s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 2.3965	Cost: 15.66s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 2.4942	Cost: 13.45s
Train Epoch: 333 	Average Loss: 3.0912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4466

Learning rate: 1.3528655947984512e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 10.1516	Cost: 47.27s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 2.3389	Cost: 12.88s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 2.5418	Cost: 14.00s
Train Epoch: 334 	Average Loss: 3.0315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3574

Learning rate: 1.3136848556180878e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 9.9874	Cost: 50.25s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 2.2456	Cost: 12.68s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 2.6167	Cost: 14.64s
Train Epoch: 335 	Average Loss: 3.0447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7276

Learning rate: 1.2750399292720314e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 9.9206	Cost: 53.41s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 2.3051	Cost: 15.44s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 2.4214	Cost: 13.02s
Train Epoch: 336 	Average Loss: 3.0227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5867

Learning rate: 1.2369331995613651e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 10.0980	Cost: 44.25s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 2.4609	Cost: 14.49s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 2.4876	Cost: 14.68s
Train Epoch: 337 	Average Loss: 3.0139
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6691

Learning rate: 1.1993670170886837e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 9.6569	Cost: 42.63s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 2.4298	Cost: 16.74s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 2.6289	Cost: 14.53s
Train Epoch: 338 	Average Loss: 2.9657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4672

Learning rate: 1.1623436991130663e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 9.7555	Cost: 38.72s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 2.4834	Cost: 14.30s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 2.2109	Cost: 15.85s
Train Epoch: 339 	Average Loss: 3.0069
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5160

Learning rate: 1.1258655294071704e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 9.6046	Cost: 42.59s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 2.3682	Cost: 16.53s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 2.4063	Cost: 16.43s
Train Epoch: 340 	Average Loss: 2.9578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6384

Learning rate: 1.089934758116323e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 9.8458	Cost: 40.11s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 2.2986	Cost: 16.52s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 2.2290	Cost: 16.36s
Train Epoch: 341 	Average Loss: 2.9770
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5383

Learning rate: 1.054553601619753e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 10.1785	Cost: 36.84s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 2.3420	Cost: 14.14s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 2.4792	Cost: 16.51s
Train Epoch: 342 	Average Loss: 2.9397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5057

Learning rate: 1.0197242423938455e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 10.0436	Cost: 38.06s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 2.1825	Cost: 16.52s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 2.3524	Cost: 16.25s
Train Epoch: 343 	Average Loss: 2.9424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5262

Learning rate: 9.854488288775428e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 9.8094	Cost: 37.84s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 2.1426	Cost: 16.42s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 1.9983	Cost: 12.65s
Train Epoch: 344 	Average Loss: 2.8601
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4475

Learning rate: 9.517294753398073e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 9.9925	Cost: 36.37s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 2.1463	Cost: 13.83s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 2.1926	Cost: 13.43s
Train Epoch: 345 	Average Loss: 2.9138
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3262

Learning rate: 9.185682617491872e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 9.8887	Cost: 40.48s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 2.4053	Cost: 11.51s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 2.3726	Cost: 16.42s
Train Epoch: 346 	Average Loss: 2.8495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4791

Learning rate: 8.859672336455501e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 10.3794	Cost: 36.11s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 2.0868	Cost: 12.67s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 2.1803	Cost: 14.42s
Train Epoch: 347 	Average Loss: 2.8537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6295

Learning rate: 8.539284020138645e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 9.3536	Cost: 33.84s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 2.4272	Cost: 9.80s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 2.2235	Cost: 22.77s
Train Epoch: 348 	Average Loss: 2.8735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4357

Learning rate: 8.224537431601915e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 9.8481	Cost: 35.83s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 2.1588	Cost: 9.80s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 2.2977	Cost: 22.25s
Train Epoch: 349 	Average Loss: 2.8367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4783

Learning rate: 7.915451985897387e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 9.9006	Cost: 35.72s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 2.1231	Cost: 11.93s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 2.0940	Cost: 20.52s
Train Epoch: 350 	Average Loss: 2.8040
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6330

Learning rate: 7.612046748871354e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 9.9283	Cost: 37.62s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 1.9739	Cost: 16.30s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 2.1646	Cost: 16.79s
Train Epoch: 351 	Average Loss: 2.8651
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5617

Learning rate: 7.314340435987926e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 9.9634	Cost: 39.14s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 2.2534	Cost: 17.07s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 2.2033	Cost: 18.20s
Train Epoch: 352 	Average Loss: 2.7991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7091

Learning rate: 7.022351411174871e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 9.6472	Cost: 37.15s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 2.0867	Cost: 14.10s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 2.0626	Cost: 19.74s
Train Epoch: 353 	Average Loss: 2.8130
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5420

Learning rate: 6.736097685690606e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 10.2795	Cost: 38.72s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 2.2671	Cost: 16.42s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 2.1996	Cost: 16.46s
Train Epoch: 354 	Average Loss: 2.8416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5148

Learning rate: 6.455596917013267e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 10.0172	Cost: 41.40s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 2.1500	Cost: 15.28s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 2.0772	Cost: 16.41s
Train Epoch: 355 	Average Loss: 2.8144
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6181

Learning rate: 6.1808664077516005e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 9.9024	Cost: 52.15s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 2.0713	Cost: 13.87s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 2.0978	Cost: 16.41s
Train Epoch: 356 	Average Loss: 2.8148
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3340

Learning rate: 5.91192310457746e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 9.7226	Cost: 43.58s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 2.1911	Cost: 14.45s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 2.3494	Cost: 21.68s
Train Epoch: 357 	Average Loss: 2.7708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4459

Learning rate: 5.648783597180656e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 9.3736	Cost: 39.50s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 2.2648	Cost: 16.24s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 2.1102	Cost: 16.42s
Train Epoch: 358 	Average Loss: 2.7873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4966

Learning rate: 5.3914641172454745e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 9.9327	Cost: 41.10s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 2.1610	Cost: 16.04s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 2.1390	Cost: 16.25s
Train Epoch: 359 	Average Loss: 2.7956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6057

Learning rate: 5.139980537449555e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 10.6256	Cost: 36.70s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 2.1531	Cost: 16.71s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 2.0917	Cost: 14.10s
Train Epoch: 360 	Average Loss: 2.8196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7572

Learning rate: 4.894348370484651e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 10.0921	Cost: 39.60s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 1.8976	Cost: 15.36s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 2.0524	Cost: 13.40s
Train Epoch: 361 	Average Loss: 2.7494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6821

Learning rate: 4.6545827680998834e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 9.8044	Cost: 38.65s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 2.1347	Cost: 14.33s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 2.1710	Cost: 12.52s
Train Epoch: 362 	Average Loss: 2.7361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5260

Learning rate: 4.420698520166991e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 9.9788	Cost: 36.07s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 2.0000	Cost: 15.91s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 2.2426	Cost: 10.50s
Train Epoch: 363 	Average Loss: 2.7177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5621

Learning rate: 4.1927100537680815e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 9.6990	Cost: 41.33s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 2.0863	Cost: 9.59s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 2.2879	Cost: 16.81s
Train Epoch: 364 	Average Loss: 2.7102
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7597

Learning rate: 3.970631432305708e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 9.6769	Cost: 36.08s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 2.0071	Cost: 12.51s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 1.8926	Cost: 21.20s
Train Epoch: 365 	Average Loss: 2.7107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5547

Learning rate: 3.7544763546352753e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 9.8601	Cost: 33.91s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 2.1344	Cost: 11.39s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 2.1874	Cost: 25.76s
Train Epoch: 366 	Average Loss: 2.6862
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4003

Learning rate: 3.5442581542202067e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 10.1550	Cost: 33.93s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 2.1815	Cost: 10.43s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 2.0887	Cost: 23.81s
Train Epoch: 367 	Average Loss: 2.7245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5723

Learning rate: 3.339989798309276e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 9.8306	Cost: 36.32s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 1.8218	Cost: 16.45s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 1.9994	Cost: 18.03s
Train Epoch: 368 	Average Loss: 2.6554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6882

Learning rate: 3.1416838871369064e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 9.5280	Cost: 39.09s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 2.0695	Cost: 13.49s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 2.1376	Cost: 21.48s
Train Epoch: 369 	Average Loss: 2.7207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6725

Learning rate: 2.9493526531457563e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 10.2645	Cost: 41.26s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 2.0091	Cost: 16.31s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 2.0013	Cost: 16.67s
Train Epoch: 370 	Average Loss: 2.7159
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5623

Learning rate: 2.7630079602323468e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 10.5745	Cost: 43.97s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 2.0318	Cost: 16.53s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 1.9775	Cost: 16.58s
Train Epoch: 371 	Average Loss: 2.7056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6849

Learning rate: 2.582661303015068e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 9.6960	Cost: 52.78s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 1.9485	Cost: 14.35s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 2.1039	Cost: 14.10s
Train Epoch: 372 	Average Loss: 2.6636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5752

Learning rate: 2.40832380612527e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 9.7587	Cost: 51.82s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 1.9772	Cost: 15.78s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 1.9295	Cost: 14.10s
Train Epoch: 373 	Average Loss: 2.6322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5338

Learning rate: 2.2400062235209426e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 10.0870	Cost: 53.98s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 2.2159	Cost: 14.72s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 1.8917	Cost: 14.56s
Train Epoch: 374 	Average Loss: 2.6409
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5934

Learning rate: 2.0777189378234156e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 9.8218	Cost: 48.12s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 2.1046	Cost: 11.44s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 1.9954	Cost: 16.06s
Train Epoch: 375 	Average Loss: 2.6538
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6130

Learning rate: 1.9214719596769582e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 10.0690	Cost: 38.56s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 2.0427	Cost: 9.96s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 2.1731	Cost: 19.84s
Train Epoch: 376 	Average Loss: 2.6750
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5929

Learning rate: 1.771274927131129e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 9.8885	Cost: 37.80s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 1.9497	Cost: 9.62s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 2.1939	Cost: 28.88s
Train Epoch: 377 	Average Loss: 2.6519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8029

Learning rate: 1.6271371050464177e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 9.9187	Cost: 37.80s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 1.9404	Cost: 16.72s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 2.0725	Cost: 16.66s
Train Epoch: 378 	Average Loss: 2.6385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5720

Learning rate: 1.4890673845226142e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 9.7030	Cost: 37.50s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 2.0372	Cost: 16.69s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 1.9989	Cost: 19.02s
Train Epoch: 379 	Average Loss: 2.6609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5904

Learning rate: 1.3570742823504575e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 9.8333	Cost: 35.85s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 1.8129	Cost: 14.80s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 2.2052	Cost: 20.74s
Train Epoch: 380 	Average Loss: 2.6672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6485

Learning rate: 1.2311659404862349e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 9.8136	Cost: 40.44s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 1.9696	Cost: 16.38s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 2.0395	Cost: 16.49s
Train Epoch: 381 	Average Loss: 2.6233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5177

Learning rate: 1.1113501255495491e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 10.0326	Cost: 39.10s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 1.7523	Cost: 14.90s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 1.9203	Cost: 18.43s
Train Epoch: 382 	Average Loss: 2.6281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4585

Learning rate: 9.97634228344247e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 9.8244	Cost: 42.39s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 1.7720	Cost: 16.36s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 1.9174	Cost: 16.80s
Train Epoch: 383 	Average Loss: 2.5992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5207

Learning rate: 8.90025263402528e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 9.5778	Cost: 57.35s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 2.0605	Cost: 14.91s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 2.2776	Cost: 12.65s
Train Epoch: 384 	Average Loss: 2.6576
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6323

Learning rate: 7.88529868552224e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 9.6022	Cost: 39.90s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 2.1234	Cost: 16.38s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 1.9310	Cost: 16.60s
Train Epoch: 385 	Average Loss: 2.6487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7085

Learning rate: 6.931543045073711e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 10.1590	Cost: 42.38s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 1.9914	Cost: 15.39s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 2.0184	Cost: 16.49s
Train Epoch: 386 	Average Loss: 2.6771
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8874

Learning rate: 6.039044544820409e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 9.8793	Cost: 50.63s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 1.9260	Cost: 16.49s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 2.0257	Cost: 16.33s
Train Epoch: 387 	Average Loss: 2.6572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5873

Learning rate: 5.207858238273524e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 9.9612	Cost: 34.99s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 2.1255	Cost: 9.54s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 1.8865	Cost: 18.24s
Train Epoch: 388 	Average Loss: 2.6162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4753

Learning rate: 4.4380353969200063e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 9.7021	Cost: 34.27s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 1.9114	Cost: 10.31s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 1.9205	Cost: 17.55s
Train Epoch: 389 	Average Loss: 2.6331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5422

Learning rate: 3.7296235070587456e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 9.9920	Cost: 37.24s
Train Epoch: 390 [40960/90000 (45%)]	Loss: 1.9589	Cost: 10.07s
Train Epoch: 390 [81920/90000 (91%)]	Loss: 2.0750	Cost: 16.74s
Train Epoch: 390 	Average Loss: 2.6434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6807

Learning rate: 3.082666266872038e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 10.2102	Cost: 35.28s
Train Epoch: 391 [40960/90000 (45%)]	Loss: 1.8636	Cost: 9.79s
Train Epoch: 391 [81920/90000 (91%)]	Loss: 2.0202	Cost: 17.91s
Train Epoch: 391 	Average Loss: 2.6435
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5966

Learning rate: 2.497203583729958e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 10.6829	Cost: 37.07s
Train Epoch: 392 [40960/90000 (45%)]	Loss: 2.0409	Cost: 9.90s
Train Epoch: 392 [81920/90000 (91%)]	Loss: 1.8463	Cost: 17.38s
Train Epoch: 392 	Average Loss: 2.6785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5356

Learning rate: 1.973271571728442e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 9.8559	Cost: 36.14s
Train Epoch: 393 [40960/90000 (45%)]	Loss: 1.9098	Cost: 9.76s
Train Epoch: 393 [81920/90000 (91%)]	Loss: 1.9297	Cost: 18.11s
Train Epoch: 393 	Average Loss: 2.6420
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6349

Learning rate: 1.5109025494620685e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 10.7167	Cost: 33.69s
Train Epoch: 394 [40960/90000 (45%)]	Loss: 1.9710	Cost: 9.69s
Train Epoch: 394 [81920/90000 (91%)]	Loss: 2.0057	Cost: 22.19s
Train Epoch: 394 	Average Loss: 2.7034
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8152

Learning rate: 1.1101250380300971e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 10.1409	Cost: 35.42s
Train Epoch: 395 [40960/90000 (45%)]	Loss: 2.1280	Cost: 9.88s
Train Epoch: 395 [81920/90000 (91%)]	Loss: 2.0916	Cost: 28.10s
Train Epoch: 395 	Average Loss: 2.6388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4758

Learning rate: 7.709637592770994e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 9.9952	Cost: 38.08s
Train Epoch: 396 [40960/90000 (45%)]	Loss: 1.8844	Cost: 13.98s
Train Epoch: 396 [81920/90000 (91%)]	Loss: 1.9992	Cost: 20.60s
Train Epoch: 396 	Average Loss: 2.6141
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7264

Learning rate: 4.934396342684002e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 10.3277	Cost: 35.38s
Train Epoch: 397 [40960/90000 (45%)]	Loss: 1.9500	Cost: 17.11s
Train Epoch: 397 [81920/90000 (91%)]	Loss: 2.0401	Cost: 16.53s
Train Epoch: 397 	Average Loss: 2.6591
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4800

Learning rate: 2.7756978199944282e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 10.1166	Cost: 37.56s
Train Epoch: 398 [40960/90000 (45%)]	Loss: 1.8644	Cost: 16.37s
Train Epoch: 398 [81920/90000 (91%)]	Loss: 1.9607	Cost: 17.95s
Train Epoch: 398 	Average Loss: 2.6170
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5244

Learning rate: 1.2336751833941234e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 9.6612	Cost: 40.15s
Train Epoch: 399 [40960/90000 (45%)]	Loss: 2.0682	Cost: 13.47s
Train Epoch: 399 [81920/90000 (91%)]	Loss: 2.1448	Cost: 23.19s
Train Epoch: 399 	Average Loss: 2.6611
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6609

Learning rate: 3.084235521033653e-09
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 10.1418	Cost: 39.37s
Train Epoch: 400 [40960/90000 (45%)]	Loss: 1.9713	Cost: 14.99s
Train Epoch: 400 [81920/90000 (91%)]	Loss: 2.0169	Cost: 14.86s
Train Epoch: 400 	Average Loss: 2.6906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5723

Stopping timer.
Training time (including validation): 213974.70289969444 seconds
Saving model
Transfer learning by starting with alpha=0.2!
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 29.4190	Cost: 33.89s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 19.9836	Cost: 9.54s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 18.5106	Cost: 18.15s
Train Epoch: 1 	Average Loss: 20.8047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0499

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999691576447898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 18.4596	Cost: 37.62s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 17.4760	Cost: 12.89s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 16.9533	Cost: 12.64s
Train Epoch: 2 	Average Loss: 17.5683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5868

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 17.1097	Cost: 33.77s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 16.5891	Cost: 9.71s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 16.3447	Cost: 22.50s
Train Epoch: 3 	Average Loss: 16.6136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9845

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 16.4193	Cost: 35.33s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 16.1031	Cost: 9.71s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 15.8342	Cost: 21.30s
Train Epoch: 4 	Average Loss: 16.1123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7406

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.00019995065603657316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 16.3336	Cost: 36.90s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 15.7062	Cost: 16.74s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 15.5781	Cost: 16.50s
Train Epoch: 5 	Average Loss: 15.8139
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5338

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.0001999229036240723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 16.0328	Cost: 37.09s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 15.4657	Cost: 16.34s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 15.4413	Cost: 16.43s
Train Epoch: 6 	Average Loss: 15.5718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3788

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019988898749619702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 15.7239	Cost: 34.85s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 15.3958	Cost: 16.25s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 15.3510	Cost: 16.26s
Train Epoch: 7 	Average Loss: 15.3742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2530

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.00019984890974505381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 15.7878	Cost: 36.85s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 15.2089	Cost: 15.30s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 15.1362	Cost: 16.31s
Train Epoch: 8 	Average Loss: 15.2991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2431

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.00019980267284282717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 15.9013	Cost: 36.51s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 14.9790	Cost: 16.24s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 15.0349	Cost: 16.63s
Train Epoch: 9 	Average Loss: 15.1404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2395

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019975027964162705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 15.6007	Cost: 37.29s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 14.8629	Cost: 16.49s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 14.9154	Cost: 16.51s
Train Epoch: 10 	Average Loss: 15.0614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2535

Learning rate: 0.00019969173337331284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 15.7472	Cost: 35.90s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 14.6880	Cost: 16.16s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 14.8357	Cost: 17.78s
Train Epoch: 11 	Average Loss: 14.9870
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2499

Learning rate: 0.00019962703764929416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 15.5071	Cost: 39.17s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 14.7136	Cost: 16.68s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 14.6935	Cost: 16.33s
Train Epoch: 12 	Average Loss: 14.8596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1737

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 0.00019955619646030802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 15.6003	Cost: 50.68s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 14.5887	Cost: 13.43s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 14.5115	Cost: 13.29s
Train Epoch: 13 	Average Loss: 14.7572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3013

Learning rate: 0.00019947921417617267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 15.5357	Cost: 41.66s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 14.6827	Cost: 14.83s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 14.4135	Cost: 13.62s
Train Epoch: 14 	Average Loss: 14.6894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1259

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Learning rate: 0.000199396095545518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 15.4371	Cost: 39.92s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 14.3932	Cost: 14.51s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 14.4434	Cost: 12.91s
Train Epoch: 15 	Average Loss: 14.6078
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2691

Learning rate: 0.00019930684569549264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 15.5535	Cost: 36.95s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 14.3283	Cost: 13.93s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 14.3124	Cost: 15.63s
Train Epoch: 16 	Average Loss: 14.5303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2146

Learning rate: 0.0001992114701314478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 15.5378	Cost: 36.93s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 14.2426	Cost: 15.74s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 14.3085	Cost: 13.04s
Train Epoch: 17 	Average Loss: 14.4792
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1525

Learning rate: 0.00019910997473659747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 15.5453	Cost: 38.58s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 14.1900	Cost: 16.54s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 14.3214	Cost: 13.61s
Train Epoch: 18 	Average Loss: 14.4099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3166

Learning rate: 0.00019900236577165574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 15.5824	Cost: 36.21s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 14.2435	Cost: 14.25s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 14.3046	Cost: 13.58s
Train Epoch: 19 	Average Loss: 14.3700
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1695

Learning rate: 0.00019888864987445046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 15.6183	Cost: 35.59s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 14.1312	Cost: 13.34s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 14.0810	Cost: 13.62s
Train Epoch: 20 	Average Loss: 14.3284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2298

Learning rate: 0.00019876883405951377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 15.6794	Cost: 34.59s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 14.1445	Cost: 16.64s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 14.0080	Cost: 10.02s
Train Epoch: 21 	Average Loss: 14.2473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1795

Learning rate: 0.00019864292571764955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 15.4119	Cost: 38.03s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 14.0079	Cost: 13.44s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 13.8593	Cost: 10.86s
Train Epoch: 22 	Average Loss: 14.1772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3550

Learning rate: 0.0001985109326154774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 15.4424	Cost: 32.12s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 13.7232	Cost: 10.55s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 13.8758	Cost: 14.81s
Train Epoch: 23 	Average Loss: 14.1162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2870

Learning rate: 0.00019837286289495361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 15.5868	Cost: 35.02s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 13.8456	Cost: 9.52s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 13.7141	Cost: 21.54s
Train Epoch: 24 	Average Loss: 14.1351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3425

Learning rate: 0.0001982287250728689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 15.4546	Cost: 34.72s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 13.7465	Cost: 9.83s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 13.8125	Cost: 25.01s
Train Epoch: 25 	Average Loss: 14.0685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3387

Learning rate: 0.00019807852804032305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 15.5830	Cost: 34.11s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 13.8300	Cost: 11.34s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 13.6109	Cost: 20.36s
Train Epoch: 26 	Average Loss: 14.0409
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3328

Learning rate: 0.00019792228106217658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 15.4767	Cost: 36.44s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 13.8917	Cost: 16.39s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 13.6472	Cost: 16.50s
Train Epoch: 27 	Average Loss: 14.0020
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3465

Learning rate: 0.0001977599937764791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 15.5139	Cost: 35.59s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 13.7425	Cost: 16.43s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 13.6738	Cost: 16.60s
Train Epoch: 28 	Average Loss: 14.0114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3797

Learning rate: 0.00019759167619387474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 15.6805	Cost: 41.21s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 13.7774	Cost: 15.15s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 13.7872	Cost: 23.82s
Train Epoch: 29 	Average Loss: 13.9702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3965

Learning rate: 0.00019741733869698495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 15.5765	Cost: 36.05s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 13.6002	Cost: 13.23s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 13.6024	Cost: 17.54s
Train Epoch: 30 	Average Loss: 13.9281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4039

Learning rate: 0.00019723699203976766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 15.5071	Cost: 38.41s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 13.7382	Cost: 14.74s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 13.6295	Cost: 19.32s
Train Epoch: 31 	Average Loss: 13.9332
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3535

Learning rate: 0.00019705064734685425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 15.6738	Cost: 35.04s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 13.5509	Cost: 16.09s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 13.5281	Cost: 12.91s
Train Epoch: 32 	Average Loss: 13.8989
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3383

Learning rate: 0.00019685831611286313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 15.5847	Cost: 35.79s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 13.6052	Cost: 16.04s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 13.5276	Cost: 11.93s
Train Epoch: 33 	Average Loss: 13.8256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2786

Learning rate: 0.00019666001020169073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 15.5737	Cost: 35.83s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 13.4896	Cost: 15.27s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 13.5561	Cost: 11.26s
Train Epoch: 34 	Average Loss: 13.7536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4073

Learning rate: 0.0001964557418457798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 15.5121	Cost: 42.15s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 13.4973	Cost: 15.57s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 13.4332	Cost: 9.53s
Train Epoch: 35 	Average Loss: 13.6864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3586

Learning rate: 0.0001962455236453647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 15.6299	Cost: 39.86s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 13.3867	Cost: 9.46s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 13.5703	Cost: 17.26s
Train Epoch: 36 	Average Loss: 13.6393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3839

Learning rate: 0.00019602936856769428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 15.5726	Cost: 38.02s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 13.3657	Cost: 12.54s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 13.5676	Cost: 13.36s
Train Epoch: 37 	Average Loss: 13.6467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4382

Learning rate: 0.0001958072899462319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 15.5362	Cost: 32.92s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 13.3565	Cost: 10.21s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 13.4996	Cost: 21.86s
Train Epoch: 38 	Average Loss: 13.6331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4112

Learning rate: 0.00019557930147983297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 15.6683	Cost: 35.13s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 13.4239	Cost: 9.77s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 13.1957	Cost: 24.61s
Train Epoch: 39 	Average Loss: 13.5858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4628

Learning rate: 0.00019534541723190008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 15.5870	Cost: 34.87s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 13.3096	Cost: 13.14s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 13.0889	Cost: 20.53s
Train Epoch: 40 	Average Loss: 13.5185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4317

Learning rate: 0.00019510565162951532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 15.6413	Cost: 37.40s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 13.2413	Cost: 16.44s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 13.0954	Cost: 16.37s
Train Epoch: 41 	Average Loss: 13.5122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4111

Learning rate: 0.0001948600194625504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 15.5991	Cost: 36.92s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 13.1396	Cost: 16.43s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 13.1790	Cost: 19.12s
Train Epoch: 42 	Average Loss: 13.4685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4261

Learning rate: 0.00019460853588275446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 15.7129	Cost: 38.96s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 13.1465	Cost: 16.10s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 12.9500	Cost: 20.03s
Train Epoch: 43 	Average Loss: 13.4270
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4337

Learning rate: 0.0001943512164028193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 15.7349	Cost: 41.34s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 12.9388	Cost: 16.21s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 13.0567	Cost: 16.58s
Train Epoch: 44 	Average Loss: 13.3698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4827

Learning rate: 0.00019408807689542249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 15.7766	Cost: 43.27s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 12.9546	Cost: 14.57s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 13.0635	Cost: 15.99s
Train Epoch: 45 	Average Loss: 13.3286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4289

Learning rate: 0.00019381913359224837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 15.8753	Cost: 53.67s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 12.9455	Cost: 16.53s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 12.9831	Cost: 15.85s
Train Epoch: 46 	Average Loss: 13.3180
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4201

Learning rate: 0.0001935444030829867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 15.7117	Cost: 41.81s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 12.9356	Cost: 16.48s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 12.8662	Cost: 16.57s
Train Epoch: 47 	Average Loss: 13.2754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5018

Learning rate: 0.00019326390231430937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 15.7956	Cost: 38.29s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 13.0283	Cost: 13.86s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 12.9804	Cost: 16.18s
Train Epoch: 48 	Average Loss: 13.2468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5090

Learning rate: 0.00019297764858882508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 15.7292	Cost: 39.80s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 12.9899	Cost: 14.64s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 13.0474	Cost: 16.66s
Train Epoch: 49 	Average Loss: 13.2791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6654

Learning rate: 0.000192685659564012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 15.7480	Cost: 37.94s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 12.9797	Cost: 13.81s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 12.9769	Cost: 16.69s
Train Epoch: 50 	Average Loss: 13.3183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5837

Learning rate: 0.00019238795325112859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 15.8726	Cost: 39.14s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 13.1299	Cost: 14.48s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 12.8055	Cost: 16.45s
Train Epoch: 51 	Average Loss: 13.2598
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5598

Learning rate: 0.00019208454801410258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 15.7867	Cost: 36.77s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 12.9686	Cost: 13.85s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 12.7268	Cost: 16.60s
Train Epoch: 52 	Average Loss: 13.1949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5609

Learning rate: 0.00019177546256839804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 15.7716	Cost: 36.39s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 12.8361	Cost: 13.80s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 12.4359	Cost: 16.48s
Train Epoch: 53 	Average Loss: 13.1104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4574

Learning rate: 0.0001914607159798613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 15.7750	Cost: 35.70s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 12.8506	Cost: 16.45s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 12.7196	Cost: 16.40s
Train Epoch: 54 	Average Loss: 13.1116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6037

Learning rate: 0.00019114032766354445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 15.9631	Cost: 36.87s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 12.8419	Cost: 14.74s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 12.7783	Cost: 16.41s
Train Epoch: 55 	Average Loss: 13.0990
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6172

Learning rate: 0.00019081431738250806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 15.7458	Cost: 35.74s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 12.6771	Cost: 14.73s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 12.6480	Cost: 18.32s
Train Epoch: 56 	Average Loss: 13.0614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5057

Learning rate: 0.00019048270524660188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 15.7256	Cost: 36.05s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 12.8741	Cost: 14.98s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 12.8551	Cost: 18.87s
Train Epoch: 57 	Average Loss: 13.0812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5680

Learning rate: 0.0001901455117112245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 15.7282	Cost: 36.57s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 12.7839	Cost: 15.91s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 12.8007	Cost: 18.11s
Train Epoch: 58 	Average Loss: 13.0444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6871

Learning rate: 0.0001898027575760615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 15.8470	Cost: 37.79s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 12.7210	Cost: 13.47s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 12.6743	Cost: 20.16s
Train Epoch: 59 	Average Loss: 13.0484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5290

Learning rate: 0.00018945446398380245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 15.6834	Cost: 45.61s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 12.8552	Cost: 16.52s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 12.6684	Cost: 16.48s
Train Epoch: 60 	Average Loss: 13.0446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6550

Learning rate: 0.00018910065241883672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 15.6966	Cost: 43.05s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 12.7161	Cost: 16.68s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 12.6115	Cost: 16.48s
Train Epoch: 61 	Average Loss: 12.9508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6228

Learning rate: 0.00018874134470592827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 15.8326	Cost: 43.74s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 12.4266	Cost: 16.57s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 12.4514	Cost: 16.44s
Train Epoch: 62 	Average Loss: 12.8885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5709

Learning rate: 0.0001883765630088693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 15.9350	Cost: 42.63s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 12.5738	Cost: 16.21s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 12.6000	Cost: 16.42s
Train Epoch: 63 	Average Loss: 12.9041
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5700

Learning rate: 0.00018800632982911313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 15.7573	Cost: 37.57s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 12.3317	Cost: 16.46s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 12.4579	Cost: 16.42s
Train Epoch: 64 	Average Loss: 12.8233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6178

Learning rate: 0.00018763066800438628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 16.0458	Cost: 36.62s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 12.5307	Cost: 13.29s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 12.4395	Cost: 16.30s
Train Epoch: 65 	Average Loss: 12.7947
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6866

Learning rate: 0.00018724960070727966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 15.6694	Cost: 37.45s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 12.3311	Cost: 13.78s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 12.6341	Cost: 16.56s
Train Epoch: 66 	Average Loss: 12.8443
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5780

Learning rate: 0.00018686315144381908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 15.9379	Cost: 35.89s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 12.4471	Cost: 14.00s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 12.4201	Cost: 16.46s
Train Epoch: 67 	Average Loss: 12.8041
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8232

Learning rate: 0.00018647134405201546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 15.9672	Cost: 36.59s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 12.4370	Cost: 15.38s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 12.5249	Cost: 16.13s
Train Epoch: 68 	Average Loss: 12.8704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7359

Learning rate: 0.00018607420270039433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 15.8224	Cost: 35.55s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 12.5856	Cost: 15.99s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 12.3179	Cost: 16.28s
Train Epoch: 69 	Average Loss: 12.8973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6787

Learning rate: 0.00018567175188650495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 16.0397	Cost: 37.91s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 12.5359	Cost: 16.41s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 12.3514	Cost: 18.29s
Train Epoch: 70 	Average Loss: 12.9217
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7220

Learning rate: 0.0001852640164354092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 15.9401	Cost: 39.21s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 12.3849	Cost: 16.46s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 12.3785	Cost: 16.44s
Train Epoch: 71 	Average Loss: 12.8111
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6787

Learning rate: 0.00018485102149815036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 16.0308	Cost: 46.70s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 12.2707	Cost: 16.58s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 12.1633	Cost: 16.52s
Train Epoch: 72 	Average Loss: 12.7017
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7112

Learning rate: 0.0001844327925502015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 15.7523	Cost: 42.89s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 12.2335	Cost: 16.54s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 12.3543	Cost: 16.54s
Train Epoch: 73 	Average Loss: 12.6177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7912

Learning rate: 0.00018400935538989417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 15.7437	Cost: 51.45s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 12.2310	Cost: 16.74s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 12.0336	Cost: 15.04s
Train Epoch: 74 	Average Loss: 12.5735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7921

Learning rate: 0.00018358073613682703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 15.9102	Cost: 40.42s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 12.3478	Cost: 16.23s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 12.3426	Cost: 16.33s
Train Epoch: 75 	Average Loss: 12.7570
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6929

Learning rate: 0.00018314696123025452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 15.7551	Cost: 36.77s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 12.1776	Cost: 16.63s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 12.1203	Cost: 16.60s
Train Epoch: 76 	Average Loss: 12.6511
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7988

Learning rate: 0.00018270805742745614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 15.7110	Cost: 37.66s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 12.2564	Cost: 16.45s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 12.1722	Cost: 16.09s
Train Epoch: 77 	Average Loss: 12.5754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7707

Learning rate: 0.00018226405180208597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 15.8920	Cost: 36.72s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 12.1342	Cost: 16.29s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 12.0456	Cost: 12.25s
Train Epoch: 78 	Average Loss: 12.5498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8071

Learning rate: 0.00018181497174250233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 16.0867	Cost: 35.07s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 11.9162	Cost: 13.50s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 12.3180	Cost: 13.15s
Train Epoch: 79 	Average Loss: 12.5544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8254

Learning rate: 0.00018136084495007872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 16.0337	Cost: 35.07s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 12.0003	Cost: 16.68s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 12.1330	Cost: 10.03s
Train Epoch: 80 	Average Loss: 12.6007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8471

Learning rate: 0.00018090169943749476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 16.0467	Cost: 38.53s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 11.9663	Cost: 9.54s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 12.1442	Cost: 16.69s
Train Epoch: 81 	Average Loss: 12.5431
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9170

Learning rate: 0.00018043756352700846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 15.9188	Cost: 33.71s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 12.0689	Cost: 12.66s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 11.8716	Cost: 12.63s
Train Epoch: 82 	Average Loss: 12.5328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8426

Learning rate: 0.00017996846584870908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 16.0025	Cost: 33.33s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 12.2121	Cost: 10.92s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 12.0731	Cost: 17.44s
Train Epoch: 83 	Average Loss: 12.5469
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8158

Learning rate: 0.000179494435338751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 16.0389	Cost: 32.23s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 12.1114	Cost: 10.11s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 12.0107	Cost: 20.82s
Train Epoch: 84 	Average Loss: 12.4563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8583

Learning rate: 0.00017901550123756904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 15.9680	Cost: 34.00s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 12.0637	Cost: 9.62s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 11.9009	Cost: 22.70s
Train Epoch: 85 	Average Loss: 12.4304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7926

Learning rate: 0.00017853169308807448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 16.0157	Cost: 36.88s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 12.0185	Cost: 16.44s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 12.0025	Cost: 16.54s
Train Epoch: 86 	Average Loss: 12.3971
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8719

Learning rate: 0.00017804304073383296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 15.9285	Cost: 36.96s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 11.9545	Cost: 16.46s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 12.0868	Cost: 16.33s
Train Epoch: 87 	Average Loss: 12.4625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8805

Learning rate: 0.00017754957431722346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 15.8153	Cost: 35.63s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 11.8990	Cost: 16.86s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 12.0377	Cost: 16.65s
Train Epoch: 88 	Average Loss: 12.4203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9491

Learning rate: 0.00017705132427757892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 16.1384	Cost: 35.75s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 11.9130	Cost: 13.98s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 11.7080	Cost: 19.71s
Train Epoch: 89 	Average Loss: 12.3517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8721

Learning rate: 0.00017654832134930882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 16.1318	Cost: 38.20s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 11.9850	Cost: 16.15s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 11.8184	Cost: 16.47s
Train Epoch: 90 	Average Loss: 12.3224
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8868

Learning rate: 0.0001760405965600031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 16.0013	Cost: 42.58s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 11.9616	Cost: 14.43s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 11.8269	Cost: 16.46s
Train Epoch: 91 	Average Loss: 12.3173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9581

Learning rate: 0.00017552818122851838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 16.1255	Cost: 39.56s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 11.7590	Cost: 16.07s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 11.7769	Cost: 16.41s
Train Epoch: 92 	Average Loss: 12.2952
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9218

Learning rate: 0.00017501110696304596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 15.9996	Cost: 39.43s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 11.6423	Cost: 16.03s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 11.7297	Cost: 16.59s
Train Epoch: 93 	Average Loss: 12.1954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9222

Learning rate: 0.0001744894056591622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 16.0953	Cost: 49.01s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 11.6719	Cost: 16.04s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 11.5788	Cost: 16.51s
Train Epoch: 94 	Average Loss: 12.1325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8654

Learning rate: 0.00017396310949786096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 16.1137	Cost: 51.14s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 11.5072	Cost: 16.31s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 11.6406	Cost: 15.98s
Train Epoch: 95 	Average Loss: 12.0837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9676

Learning rate: 0.00017343225094356858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 16.0512	Cost: 39.88s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 11.6110	Cost: 16.34s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 11.5774	Cost: 12.73s
Train Epoch: 96 	Average Loss: 12.0843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0767

Learning rate: 0.00017289686274214118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 16.0824	Cost: 36.55s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 11.6192	Cost: 14.72s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 11.7442	Cost: 12.91s
Train Epoch: 97 	Average Loss: 12.1273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2389

Learning rate: 0.00017235697791884494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 16.2400	Cost: 46.10s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 11.5125	Cost: 14.96s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 11.5289	Cost: 12.92s
Train Epoch: 98 	Average Loss: 12.0744
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0844

Learning rate: 0.0001718126297763189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 15.9768	Cost: 47.49s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 11.5157	Cost: 14.04s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 11.6589	Cost: 12.74s
Train Epoch: 99 	Average Loss: 12.0732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1121

Learning rate: 0.00017126385189252056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 16.0802	Cost: 43.63s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 11.3808	Cost: 15.57s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 11.5294	Cost: 13.12s
Train Epoch: 100 	Average Loss: 11.9974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9897

Learning rate: 0.00017071067811865479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 16.0600	Cost: 53.12s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 11.4211	Cost: 16.30s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 11.4252	Cost: 15.33s
Train Epoch: 101 	Average Loss: 11.9571
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0013

Learning rate: 0.00017015314257708562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 16.0591	Cost: 54.60s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 11.4442	Cost: 14.64s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 11.3336	Cost: 12.19s
Train Epoch: 102 	Average Loss: 11.8941
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0692

Learning rate: 0.00016959127965923145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 16.1428	Cost: 38.34s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 11.2807	Cost: 16.69s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 11.5325	Cost: 13.80s
Train Epoch: 103 	Average Loss: 11.8942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1589

Learning rate: 0.00016902512402344375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 16.1718	Cost: 46.81s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 11.4356	Cost: 16.30s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 11.4982	Cost: 12.23s
Train Epoch: 104 	Average Loss: 11.9601
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0547

Learning rate: 0.0001684547105928689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 16.0798	Cost: 44.02s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 11.4174	Cost: 16.52s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 11.4974	Cost: 13.09s
Train Epoch: 105 	Average Loss: 11.9875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0898

Learning rate: 0.00016788007455329423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 16.1259	Cost: 38.69s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 11.3141	Cost: 15.84s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 11.4367	Cost: 16.26s
Train Epoch: 106 	Average Loss: 11.9027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0340

Learning rate: 0.00016730125135097737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 16.1364	Cost: 40.94s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 11.3258	Cost: 13.20s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 11.4748	Cost: 16.91s
Train Epoch: 107 	Average Loss: 11.8554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1452

Learning rate: 0.00016671827669046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 16.2504	Cost: 39.84s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 11.3909	Cost: 14.53s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 11.2484	Cost: 16.69s
Train Epoch: 108 	Average Loss: 11.8915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0814

Learning rate: 0.0001661311865323652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 16.1895	Cost: 41.58s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 11.1140	Cost: 16.04s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 11.1188	Cost: 16.58s
Train Epoch: 109 	Average Loss: 11.7719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0632

Learning rate: 0.00016554001709117943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 16.2714	Cost: 40.49s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 11.0995	Cost: 15.34s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 11.3092	Cost: 16.58s
Train Epoch: 110 	Average Loss: 11.7215
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1926

Learning rate: 0.00016494480483301838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 16.4109	Cost: 45.04s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 11.0198	Cost: 16.43s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 11.3486	Cost: 16.43s
Train Epoch: 111 	Average Loss: 11.6985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2433

Learning rate: 0.0001643455864733779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 16.3398	Cost: 39.51s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 10.9399	Cost: 16.49s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 11.0439	Cost: 16.41s
Train Epoch: 112 	Average Loss: 11.6296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1858

Learning rate: 0.000163742398974869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 16.2369	Cost: 39.46s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 11.0250	Cost: 16.59s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 10.9735	Cost: 16.61s
Train Epoch: 113 	Average Loss: 11.5900
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0944

Learning rate: 0.00016313527954493778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 16.1483	Cost: 37.93s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 10.9702	Cost: 15.91s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 10.8902	Cost: 16.36s
Train Epoch: 114 	Average Loss: 11.5556
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0970

Learning rate: 0.00016252426563357055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 16.3695	Cost: 35.79s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 10.9138	Cost: 13.76s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 11.0083	Cost: 16.10s
Train Epoch: 115 	Average Loss: 11.5677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1318

Learning rate: 0.0001619093949309834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 16.2472	Cost: 34.89s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 10.9538	Cost: 16.33s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 10.8348	Cost: 16.31s
Train Epoch: 116 	Average Loss: 11.5211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2070

Learning rate: 0.00016129070536529766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 16.2398	Cost: 37.74s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 10.8823	Cost: 15.77s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 11.0485	Cost: 16.48s
Train Epoch: 117 	Average Loss: 11.5342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3098

Learning rate: 0.00016066823510019996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 16.5917	Cost: 35.36s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 10.8788	Cost: 15.71s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 11.1016	Cost: 16.24s
Train Epoch: 118 	Average Loss: 11.5464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1579

Learning rate: 0.0001600420225325884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 16.2739	Cost: 36.47s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 10.8976	Cost: 11.91s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 10.7039	Cost: 18.95s
Train Epoch: 119 	Average Loss: 11.4684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2516

Learning rate: 0.00015941210629020385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 16.6064	Cost: 36.49s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 10.9622	Cost: 16.92s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 10.8572	Cost: 18.22s
Train Epoch: 120 	Average Loss: 11.4880
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2399

Learning rate: 0.00015877852522924735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 16.4755	Cost: 41.56s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 10.8551	Cost: 15.27s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 10.9376	Cost: 17.93s
Train Epoch: 121 	Average Loss: 11.4542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2229

Learning rate: 0.00015814131843198305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 16.2825	Cost: 42.27s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 10.7985	Cost: 14.75s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 10.8679	Cost: 16.51s
Train Epoch: 122 	Average Loss: 11.4387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3119

Learning rate: 0.00015750052520432787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 16.4575	Cost: 35.71s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 10.7406	Cost: 16.05s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 10.8698	Cost: 15.83s
Train Epoch: 123 	Average Loss: 11.4237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1625

Learning rate: 0.0001568561850734264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 16.4802	Cost: 34.78s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 10.7738	Cost: 16.21s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 10.8356	Cost: 16.40s
Train Epoch: 124 	Average Loss: 11.3838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1731

Learning rate: 0.00015620833778521307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 16.5688	Cost: 35.98s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 10.8246	Cost: 16.54s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 10.9408	Cost: 16.26s
Train Epoch: 125 	Average Loss: 11.4146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1766

Learning rate: 0.00015555702330196023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 16.3918	Cost: 34.97s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 10.6282	Cost: 16.30s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 10.7484	Cost: 16.01s
Train Epoch: 126 	Average Loss: 11.4527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3228

Learning rate: 0.00015490228179981317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 16.3958	Cost: 35.57s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 10.7624	Cost: 16.46s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 10.9779	Cost: 17.09s
Train Epoch: 127 	Average Loss: 11.4851
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3528

Learning rate: 0.00015424415366631188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 16.3484	Cost: 40.86s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 10.7895	Cost: 15.78s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 10.8693	Cost: 16.23s
Train Epoch: 128 	Average Loss: 11.3981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3262

Learning rate: 0.00015358267949789966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 16.3107	Cost: 42.02s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 10.7802	Cost: 15.34s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 10.6829	Cost: 16.57s
Train Epoch: 129 	Average Loss: 11.3541
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1924

Learning rate: 0.00015291790009741904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 16.4375	Cost: 42.94s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 10.5645	Cost: 15.22s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 10.5646	Cost: 16.53s
Train Epoch: 130 	Average Loss: 11.3198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4144

Learning rate: 0.00015224985647159487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 16.5181	Cost: 43.90s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 10.6011	Cost: 13.83s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 10.5686	Cost: 16.29s
Train Epoch: 131 	Average Loss: 11.3031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3294

Learning rate: 0.00015157858982850473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 16.5111	Cost: 43.25s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 10.4208	Cost: 16.62s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 10.6316	Cost: 16.07s
Train Epoch: 132 	Average Loss: 11.2511
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3966

Learning rate: 0.0001509041415750371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 16.3050	Cost: 41.08s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 10.5972	Cost: 16.53s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 10.7431	Cost: 16.49s
Train Epoch: 133 	Average Loss: 11.2711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2571

Learning rate: 0.00015022655331433721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 16.4780	Cost: 50.58s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 10.6291	Cost: 16.25s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 10.7032	Cost: 16.61s
Train Epoch: 134 	Average Loss: 11.2313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2962

Learning rate: 0.00014954586684324072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 16.4907	Cost: 38.26s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 10.5643	Cost: 16.30s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 10.5245	Cost: 14.85s
Train Epoch: 135 	Average Loss: 11.2186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3078

Learning rate: 0.00014886212414969547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 16.2683	Cost: 37.89s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 10.5254	Cost: 14.44s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 10.5658	Cost: 14.12s
Train Epoch: 136 	Average Loss: 11.1201
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3968

Learning rate: 0.0001481753674101715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 16.4382	Cost: 35.44s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 10.4791	Cost: 13.43s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 10.4648	Cost: 13.51s
Train Epoch: 137 	Average Loss: 11.1412
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3738

Learning rate: 0.00014748563898705943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 16.3337	Cost: 38.56s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 10.4602	Cost: 15.14s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 10.4927	Cost: 11.35s
Train Epoch: 138 	Average Loss: 11.2036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4738

Learning rate: 0.00014679298142605734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 16.4520	Cost: 41.79s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 10.4047	Cost: 9.45s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 10.5421	Cost: 17.23s
Train Epoch: 139 	Average Loss: 11.1092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4324

Learning rate: 0.00014609743745354624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 16.4743	Cost: 33.39s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 10.3299	Cost: 12.47s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 10.4158	Cost: 12.59s
Train Epoch: 140 	Average Loss: 11.0786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4943

Learning rate: 0.00014539904997395466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 16.4540	Cost: 32.79s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 10.4028	Cost: 10.00s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 10.6327	Cost: 18.56s
Train Epoch: 141 	Average Loss: 11.0902
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3721

Learning rate: 0.0001446978620671121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 16.5859	Cost: 34.16s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 10.7202	Cost: 9.70s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 10.6393	Cost: 28.32s
Train Epoch: 142 	Average Loss: 11.2568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3691

Learning rate: 0.0001439939169855915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 16.4241	Cost: 35.49s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 10.3806	Cost: 14.63s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 10.4080	Cost: 18.62s
Train Epoch: 143 	Average Loss: 11.0912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3796

Learning rate: 0.0001432872581520414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 16.2531	Cost: 38.72s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 10.0885	Cost: 15.14s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 10.3283	Cost: 19.12s
Train Epoch: 144 	Average Loss: 10.9458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4267

Learning rate: 0.00014257792915650728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 16.6044	Cost: 38.38s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 10.2193	Cost: 16.03s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 10.3666	Cost: 17.15s
Train Epoch: 145 	Average Loss: 10.9075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5136

Learning rate: 0.0001418659737537428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 16.4295	Cost: 46.55s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 9.9582	Cost: 15.31s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 10.2353	Cost: 16.54s
Train Epoch: 146 	Average Loss: 10.8476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4807

Learning rate: 0.00014115143586051088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 16.4650	Cost: 45.90s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 10.1773	Cost: 16.44s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 10.1444	Cost: 16.61s
Train Epoch: 147 	Average Loss: 10.8258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4700

Learning rate: 0.0001404343595528745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 16.3755	Cost: 37.53s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 10.1334	Cost: 16.30s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 10.1604	Cost: 16.31s
Train Epoch: 148 	Average Loss: 10.8053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5061

Learning rate: 0.00013971478906347806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 16.5685	Cost: 37.18s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 10.1414	Cost: 16.35s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 10.1132	Cost: 16.25s
Train Epoch: 149 	Average Loss: 10.8051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6294

Learning rate: 0.00013899276877881884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 16.5407	Cost: 37.02s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 9.9104	Cost: 16.63s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 10.0313	Cost: 16.38s
Train Epoch: 150 	Average Loss: 10.7684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4757

Learning rate: 0.000138268343236509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 16.5225	Cost: 37.38s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 10.2558	Cost: 16.46s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 10.2301	Cost: 16.65s
Train Epoch: 151 	Average Loss: 10.8818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6195

Learning rate: 0.00013754155712252834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 16.6959	Cost: 36.08s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 9.9603	Cost: 16.60s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 10.0959	Cost: 16.54s
Train Epoch: 152 	Average Loss: 10.7513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5633

Learning rate: 0.00013681245526846785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 16.7210	Cost: 38.98s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 9.9844	Cost: 13.24s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 10.0429	Cost: 23.41s
Train Epoch: 153 	Average Loss: 10.6916
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5127

Learning rate: 0.00013608108264876422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 16.5239	Cost: 41.47s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 9.9714	Cost: 12.42s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 9.8981	Cost: 16.30s
Train Epoch: 154 	Average Loss: 10.6479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5037

Learning rate: 0.00013534748437792575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 16.4578	Cost: 36.16s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 9.7278	Cost: 15.61s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 9.9216	Cost: 13.67s
Train Epoch: 155 	Average Loss: 10.5780
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5324

Learning rate: 0.00013461170570774932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 16.6678	Cost: 37.75s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 9.7836	Cost: 15.79s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 9.9737	Cost: 12.66s
Train Epoch: 156 	Average Loss: 10.5275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6576

Learning rate: 0.0001338737920245292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 16.5047	Cost: 35.08s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 9.8083	Cost: 16.73s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 9.8448	Cost: 14.90s
Train Epoch: 157 	Average Loss: 10.5361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4018

Learning rate: 0.00013313378884625713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 16.4106	Cost: 38.75s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 9.7103	Cost: 16.29s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 9.6619	Cost: 13.27s
Train Epoch: 158 	Average Loss: 10.4891
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7114

Learning rate: 0.00013239174181981498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 16.4689	Cost: 35.71s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 9.7004	Cost: 13.53s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 9.8097	Cost: 13.52s
Train Epoch: 159 	Average Loss: 10.4552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6744

Learning rate: 0.00013164769671815865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 16.6600	Cost: 36.03s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 9.8416	Cost: 17.02s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 9.7087	Cost: 16.62s
Train Epoch: 160 	Average Loss: 10.4575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6451

Learning rate: 0.0001309016994374948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 16.5653	Cost: 38.02s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 9.5793	Cost: 16.33s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 9.8215	Cost: 15.73s
Train Epoch: 161 	Average Loss: 10.3858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6367

Learning rate: 0.00013015379599444962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 16.6943	Cost: 35.01s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 9.6659	Cost: 16.79s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 9.7598	Cost: 12.41s
Train Epoch: 162 	Average Loss: 10.3896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6621

Learning rate: 0.00012940403252323043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 16.6335	Cost: 34.40s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 9.5787	Cost: 14.00s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 9.7175	Cost: 12.60s
Train Epoch: 163 	Average Loss: 10.3571
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7202

Learning rate: 0.00012865245527277986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 16.8928	Cost: 35.82s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 9.6678	Cost: 16.16s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 9.6226	Cost: 10.58s
Train Epoch: 164 	Average Loss: 10.3726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6853

Learning rate: 0.00012789911060392294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 16.2166	Cost: 37.96s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 9.5309	Cost: 11.15s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 9.6810	Cost: 17.39s
Train Epoch: 165 	Average Loss: 10.3196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6853

Learning rate: 0.00012714404498650745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 16.5366	Cost: 35.48s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 9.3199	Cost: 12.50s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 9.5386	Cost: 13.18s
Train Epoch: 166 	Average Loss: 10.2310
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7167

Learning rate: 0.00012638730499653727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 16.5483	Cost: 32.55s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 9.4502	Cost: 11.06s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 9.3543	Cost: 16.42s
Train Epoch: 167 	Average Loss: 10.1876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6628

Learning rate: 0.00012562893731329965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 16.7349	Cost: 34.18s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 9.4351	Cost: 9.95s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 9.4933	Cost: 24.69s
Train Epoch: 168 	Average Loss: 10.1869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8101

Learning rate: 0.00012486898871648546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 16.6085	Cost: 35.63s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 9.4823	Cost: 11.66s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 9.6947	Cost: 20.16s
Train Epoch: 169 	Average Loss: 10.2688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7470

Learning rate: 0.00012410750608330388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 16.8367	Cost: 36.32s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 9.6008	Cost: 16.56s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 9.6198	Cost: 16.52s
Train Epoch: 170 	Average Loss: 10.2425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7952

Learning rate: 0.00012334453638559054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 16.8814	Cost: 35.76s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 9.0869	Cost: 16.55s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 9.2665	Cost: 17.09s
Train Epoch: 171 	Average Loss: 10.0957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8467

Learning rate: 0.00012258012668691037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 16.5676	Cost: 38.13s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 9.2072	Cost: 16.78s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 9.3236	Cost: 17.17s
Train Epoch: 172 	Average Loss: 10.0243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7084

Learning rate: 0.00012181432413965427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 16.9702	Cost: 42.52s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 9.1654	Cost: 16.72s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 9.3663	Cost: 16.42s
Train Epoch: 173 	Average Loss: 10.0704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7635

Learning rate: 0.0001210471759821306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 16.9396	Cost: 52.72s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 9.0922	Cost: 16.52s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 9.4098	Cost: 16.56s
Train Epoch: 174 	Average Loss: 10.0136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8526

Learning rate: 0.00012027872953565127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 16.6167	Cost: 40.70s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 9.3393	Cost: 16.24s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 9.3782	Cost: 16.55s
Train Epoch: 175 	Average Loss: 10.1317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9547

Learning rate: 0.00011950903220161285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 16.8478	Cost: 37.67s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 9.2546	Cost: 16.44s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 9.2625	Cost: 16.58s
Train Epoch: 176 	Average Loss: 10.0579
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8189

Learning rate: 0.00011873813145857249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 16.6824	Cost: 36.15s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 9.1671	Cost: 16.44s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 9.2145	Cost: 16.58s
Train Epoch: 177 	Average Loss: 10.0034
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9276

Learning rate: 0.00011796607485931927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 16.8860	Cost: 37.24s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 9.1220	Cost: 16.38s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 9.0976	Cost: 16.32s
Train Epoch: 178 	Average Loss: 9.9260
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6870

Learning rate: 0.00011719291002794096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 16.5984	Cost: 35.23s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 9.0008	Cost: 16.27s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 9.1545	Cost: 16.51s
Train Epoch: 179 	Average Loss: 9.9043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9465

Learning rate: 0.0001164186846568863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 16.7918	Cost: 36.15s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 9.2648	Cost: 16.63s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 9.2584	Cost: 16.37s
Train Epoch: 180 	Average Loss: 9.9138
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0270

Learning rate: 0.0001156434465040231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 16.8132	Cost: 37.04s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 9.0963	Cost: 16.38s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 9.2537	Cost: 18.33s
Train Epoch: 181 	Average Loss: 9.9205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9058

Learning rate: 0.00011486724338969234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 16.7063	Cost: 41.00s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 9.0776	Cost: 14.30s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 9.0299	Cost: 17.92s
Train Epoch: 182 	Average Loss: 9.9060
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7463

Learning rate: 0.0001140901231937583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 16.8612	Cost: 42.42s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 9.0318	Cost: 13.98s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 8.9436	Cost: 16.18s
Train Epoch: 183 	Average Loss: 9.8052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9829

Learning rate: 0.00011331213385265528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 16.7685	Cost: 56.82s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 8.8854	Cost: 14.34s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 8.9410	Cost: 13.59s
Train Epoch: 184 	Average Loss: 9.6972
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0191

Learning rate: 0.00011253332335643047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 16.5817	Cost: 42.50s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 8.9527	Cost: 16.36s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 9.0532	Cost: 16.22s
Train Epoch: 185 	Average Loss: 9.7189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0414

Learning rate: 0.0001117537397457838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 16.8886	Cost: 39.02s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 8.8326	Cost: 13.92s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 8.9621	Cost: 16.50s
Train Epoch: 186 	Average Loss: 9.7000
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0652

Learning rate: 0.00011097343110910456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 16.7611	Cost: 40.52s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 8.8441	Cost: 14.16s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 8.7523	Cost: 16.60s
Train Epoch: 187 	Average Loss: 9.6789
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1158

Learning rate: 0.00011019244557950502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 16.9221	Cost: 41.06s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 8.6010	Cost: 14.70s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 9.0424	Cost: 16.54s
Train Epoch: 188 	Average Loss: 9.6513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0057

Learning rate: 0.00010941083133185145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 16.9124	Cost: 36.22s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 8.7278	Cost: 16.36s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 8.8098	Cost: 16.47s
Train Epoch: 189 	Average Loss: 9.6147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0664

Learning rate: 0.00010862863657979236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 17.0179	Cost: 35.19s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 8.8852	Cost: 13.99s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 8.8862	Cost: 16.39s
Train Epoch: 190 	Average Loss: 9.6439
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0195

Learning rate: 0.00010784590957278452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 17.0721	Cost: 35.38s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 8.7926	Cost: 14.04s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 8.8049	Cost: 16.51s
Train Epoch: 191 	Average Loss: 9.6562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9799

Learning rate: 0.00010706269859311669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 16.8915	Cost: 35.92s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 8.6265	Cost: 15.63s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 8.7087	Cost: 16.67s
Train Epoch: 192 	Average Loss: 9.5222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1632

Learning rate: 0.00010627905195293137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 16.9568	Cost: 40.83s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 8.6568	Cost: 15.76s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 8.7276	Cost: 17.19s
Train Epoch: 193 	Average Loss: 9.4815
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0640

Learning rate: 0.00010549501799124461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 16.7804	Cost: 35.29s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 8.4572	Cost: 15.41s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 8.7164	Cost: 18.43s
Train Epoch: 194 	Average Loss: 9.4304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2186

Learning rate: 0.00010471064507096429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 17.1511	Cost: 37.14s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 8.5558	Cost: 16.28s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 8.6107	Cost: 16.30s
Train Epoch: 195 	Average Loss: 9.4205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0762

Learning rate: 0.00010392598157590689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 16.6722	Cost: 40.29s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 8.4230	Cost: 16.59s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 8.3982	Cost: 16.39s
Train Epoch: 196 	Average Loss: 9.3686
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0832

Learning rate: 0.00010314107590781285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 16.5770	Cost: 49.04s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 8.5515	Cost: 16.51s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 8.5535	Cost: 16.60s
Train Epoch: 197 	Average Loss: 9.3661
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1369

Learning rate: 0.00010235597648336105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 16.9420	Cost: 44.14s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 8.4645	Cost: 14.62s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 8.5273	Cost: 16.42s
Train Epoch: 198 	Average Loss: 9.3309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1483

Learning rate: 0.0001015707317311821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 17.0868	Cost: 46.94s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 8.3514	Cost: 16.49s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 8.4418	Cost: 16.65s
Train Epoch: 199 	Average Loss: 9.2752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2584

Learning rate: 0.00010078539008887115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 16.8237	Cost: 36.79s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 8.4213	Cost: 16.27s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 8.3795	Cost: 15.99s
Train Epoch: 200 	Average Loss: 9.2350
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0701

Learning rate: 0.00010000000000000002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 16.8377	Cost: 36.78s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 8.2160	Cost: 13.83s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 8.4670	Cost: 16.38s
Train Epoch: 201 	Average Loss: 9.2202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2083

Learning rate: 9.92146099111289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 17.1154	Cost: 36.54s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 8.2594	Cost: 14.69s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 8.4338	Cost: 16.45s
Train Epoch: 202 	Average Loss: 9.2516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2510

Learning rate: 9.842926826881797e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 16.8932	Cost: 35.87s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 8.2370	Cost: 16.20s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 8.2298	Cost: 16.50s
Train Epoch: 203 	Average Loss: 9.1575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2479

Learning rate: 9.7644023516639e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 16.9151	Cost: 35.67s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 8.1958	Cost: 16.50s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 8.1852	Cost: 16.65s
Train Epoch: 204 	Average Loss: 9.1158
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3608

Learning rate: 9.68589240921872e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 16.9155	Cost: 35.17s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 8.1753	Cost: 16.31s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 8.2596	Cost: 17.65s
Train Epoch: 205 	Average Loss: 9.0835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3045

Learning rate: 9.607401842409317e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 16.8961	Cost: 38.51s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 8.2619	Cost: 16.48s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 8.2064	Cost: 16.41s
Train Epoch: 206 	Average Loss: 9.1248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3037

Learning rate: 9.528935492903578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 17.1545	Cost: 37.55s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 8.2338	Cost: 16.43s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 8.2799	Cost: 16.54s
Train Epoch: 207 	Average Loss: 9.1195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1968

Learning rate: 9.450498200875547e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 17.0266	Cost: 44.05s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 8.2965	Cost: 14.52s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 8.1904	Cost: 16.28s
Train Epoch: 208 	Average Loss: 9.1146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3016

Learning rate: 9.372094804706868e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 16.9364	Cost: 47.87s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 7.9504	Cost: 16.48s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 8.1770	Cost: 16.37s
Train Epoch: 209 	Average Loss: 9.0473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2091

Learning rate: 9.293730140688336e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 17.0546	Cost: 43.10s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 8.0486	Cost: 16.37s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 8.1247	Cost: 16.12s
Train Epoch: 210 	Average Loss: 9.0304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1716

Learning rate: 9.215409042721555e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 17.3364	Cost: 39.17s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 7.9952	Cost: 16.46s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 8.0729	Cost: 16.30s
Train Epoch: 211 	Average Loss: 9.0146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3383

Learning rate: 9.13713634202077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 16.9281	Cost: 38.25s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 8.0892	Cost: 16.33s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 8.1444	Cost: 16.25s
Train Epoch: 212 	Average Loss: 9.0127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5586

Learning rate: 9.058916866814858e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 16.8760	Cost: 35.04s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 7.9417	Cost: 16.16s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 8.2238	Cost: 16.59s
Train Epoch: 213 	Average Loss: 8.9844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5322

Learning rate: 8.9807554420495e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 17.2947	Cost: 34.55s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 8.1118	Cost: 16.26s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 8.1330	Cost: 16.21s
Train Epoch: 214 	Average Loss: 9.0389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4871

Learning rate: 8.902656889089548e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 17.0910	Cost: 35.91s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 8.1487	Cost: 14.01s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 8.2828	Cost: 16.54s
Train Epoch: 215 	Average Loss: 9.0564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3344

Learning rate: 8.824626025421624e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 16.9310	Cost: 36.57s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 7.9266	Cost: 16.45s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 8.0523	Cost: 16.62s
Train Epoch: 216 	Average Loss: 9.0301
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4554

Learning rate: 8.746667664356959e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 17.0108	Cost: 36.28s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 7.8367	Cost: 15.88s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 8.0280	Cost: 17.03s
Train Epoch: 217 	Average Loss: 8.9450
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4685

Learning rate: 8.668786614734478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 17.2141	Cost: 35.65s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 7.8429	Cost: 15.81s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 7.9854	Cost: 16.43s
Train Epoch: 218 	Average Loss: 8.8150
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3559

Learning rate: 8.590987680624175e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 17.0471	Cost: 36.92s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 7.6742	Cost: 17.05s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 7.8945	Cost: 17.49s
Train Epoch: 219 	Average Loss: 8.7320
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4491

Learning rate: 8.51327566103077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 17.2262	Cost: 39.69s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 7.7737	Cost: 13.86s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 7.8419	Cost: 20.46s
Train Epoch: 220 	Average Loss: 8.7269
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3474

Learning rate: 8.435655349597692e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 17.0517	Cost: 40.19s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 7.7798	Cost: 15.09s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 7.8996	Cost: 16.57s
Train Epoch: 221 	Average Loss: 8.7509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5049

Learning rate: 8.35813153431137e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 17.4719	Cost: 41.41s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 7.9791	Cost: 16.46s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 7.9638	Cost: 16.34s
Train Epoch: 222 	Average Loss: 8.8561
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4418

Learning rate: 8.280708997205904e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 17.0232	Cost: 52.18s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 7.7970	Cost: 16.26s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 7.8574	Cost: 14.81s
Train Epoch: 223 	Average Loss: 8.7136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4573

Learning rate: 8.203392514068074e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 17.2759	Cost: 52.85s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 7.5948	Cost: 16.58s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 7.5214	Cost: 15.63s
Train Epoch: 224 	Average Loss: 8.6580
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3969

Learning rate: 8.126186854142755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 16.9518	Cost: 37.68s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 7.5639	Cost: 16.59s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 7.7440	Cost: 16.53s
Train Epoch: 225 	Average Loss: 8.6375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5164

Learning rate: 8.049096779838719e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 17.2380	Cost: 38.61s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 7.7488	Cost: 16.51s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 7.8057	Cost: 15.70s
Train Epoch: 226 	Average Loss: 8.7328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5266

Learning rate: 7.972127046434877e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 17.1312	Cost: 39.55s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 7.7642	Cost: 16.29s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 7.6342	Cost: 14.70s
Train Epoch: 227 	Average Loss: 8.6020
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4677

Learning rate: 7.895282401786947e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 17.2065	Cost: 36.02s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 7.5858	Cost: 16.56s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 7.8480	Cost: 14.57s
Train Epoch: 228 	Average Loss: 8.5799
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6020

Learning rate: 7.818567586034578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 17.3367	Cost: 36.20s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 7.4425	Cost: 14.96s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 7.4928	Cost: 11.89s
Train Epoch: 229 	Average Loss: 8.5279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3814

Learning rate: 7.741987331308968e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 16.9816	Cost: 36.60s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 7.5101	Cost: 10.43s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 7.5830	Cost: 13.62s
Train Epoch: 230 	Average Loss: 8.4410
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5849

Learning rate: 7.665546361440945e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 17.0983	Cost: 36.60s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 7.1654	Cost: 12.75s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 7.5226	Cost: 13.10s
Train Epoch: 231 	Average Loss: 8.3830
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6196

Learning rate: 7.589249391669613e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 17.2080	Cost: 33.89s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 7.4870	Cost: 11.74s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 7.4037	Cost: 19.55s
Train Epoch: 232 	Average Loss: 8.3899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5295

Learning rate: 7.513101128351452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 17.4693	Cost: 33.08s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 7.4287	Cost: 10.26s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 7.4476	Cost: 29.09s
Train Epoch: 233 	Average Loss: 8.3894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5060

Learning rate: 7.437106268670034e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 17.2536	Cost: 35.21s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 7.3293	Cost: 14.72s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 7.1968	Cost: 22.42s
Train Epoch: 234 	Average Loss: 8.2889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5769

Learning rate: 7.361269500346273e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 17.4312	Cost: 38.89s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 7.2936	Cost: 14.18s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 7.3240	Cost: 19.47s
Train Epoch: 235 	Average Loss: 8.2973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7289

Learning rate: 7.28559550134926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 17.2758	Cost: 40.70s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 7.0263	Cost: 16.77s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 7.1819	Cost: 16.36s
Train Epoch: 236 	Average Loss: 8.2097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7912

Learning rate: 7.210088939607711e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 17.3941	Cost: 39.25s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 7.3437	Cost: 15.90s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 7.2349	Cost: 16.74s
Train Epoch: 237 	Average Loss: 8.2613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7710

Learning rate: 7.13475447272202e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 17.5278	Cost: 50.84s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 7.3342	Cost: 13.51s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 7.1345	Cost: 16.57s
Train Epoch: 238 	Average Loss: 8.2995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6038

Learning rate: 7.059596747676965e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 17.3636	Cost: 43.05s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 7.0170	Cost: 16.63s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 7.0773	Cost: 16.49s
Train Epoch: 239 	Average Loss: 8.1796
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6910

Learning rate: 6.984620400555048e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 17.5216	Cost: 41.68s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 7.2523	Cost: 16.70s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 7.1737	Cost: 16.45s
Train Epoch: 240 	Average Loss: 8.2331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5579

Learning rate: 6.909830056250531e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 17.4060	Cost: 36.10s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 7.1002	Cost: 16.56s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 7.3850	Cost: 16.32s
Train Epoch: 241 	Average Loss: 8.2132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7841

Learning rate: 6.835230328184141e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 17.3195	Cost: 34.75s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 7.0637	Cost: 15.31s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 7.1173	Cost: 16.24s
Train Epoch: 242 	Average Loss: 8.0995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7838

Learning rate: 6.760825818018508e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 17.5528	Cost: 38.54s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 6.8884	Cost: 16.10s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 7.1399	Cost: 16.35s
Train Epoch: 243 	Average Loss: 8.0701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6954

Learning rate: 6.686621115374292e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 17.3635	Cost: 36.98s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 6.9637	Cost: 16.29s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 7.0590	Cost: 16.59s
Train Epoch: 244 	Average Loss: 8.0305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8523

Learning rate: 6.61262079754709e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 17.3156	Cost: 37.51s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 6.9061	Cost: 16.22s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 7.0272	Cost: 16.54s
Train Epoch: 245 	Average Loss: 8.0462
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6992

Learning rate: 6.538829429225073e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 17.1648	Cost: 36.74s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 6.8660	Cost: 16.98s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 6.9198	Cost: 18.01s
Train Epoch: 246 	Average Loss: 7.9903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8778

Learning rate: 6.465251562207432e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 17.4917	Cost: 40.63s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 6.9383	Cost: 14.58s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 7.0544	Cost: 17.32s
Train Epoch: 247 	Average Loss: 7.9845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8923

Learning rate: 6.391891735123586e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 17.2397	Cost: 54.59s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 6.8561	Cost: 15.35s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 7.0248	Cost: 13.46s
Train Epoch: 248 	Average Loss: 8.0027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7353

Learning rate: 6.318754473153225e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 17.5804	Cost: 41.25s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 6.8434	Cost: 13.91s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 6.9903	Cost: 15.76s
Train Epoch: 249 	Average Loss: 8.0402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7408

Learning rate: 6.245844287747173e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 17.5976	Cost: 41.30s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 6.8747	Cost: 15.93s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 6.9430	Cost: 16.52s
Train Epoch: 250 	Average Loss: 7.9835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8034

Learning rate: 6.173165676349108e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 17.1834	Cost: 45.61s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 6.8864	Cost: 16.22s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 6.9303	Cost: 16.44s
Train Epoch: 251 	Average Loss: 7.9203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7478

Learning rate: 6.10072312211812e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 17.7454	Cost: 41.12s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 6.8897	Cost: 16.39s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 6.9136	Cost: 16.26s
Train Epoch: 252 	Average Loss: 7.9172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7848

Learning rate: 6.0285210936521955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 17.7377	Cost: 40.86s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 6.8703	Cost: 16.43s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 6.8312	Cost: 16.55s
Train Epoch: 253 	Average Loss: 7.9048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7714

Learning rate: 5.956564044712553e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 17.3173	Cost: 39.09s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 6.8233	Cost: 16.50s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 6.8768	Cost: 16.55s
Train Epoch: 254 	Average Loss: 7.8363
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8830

Learning rate: 5.8848564139489155e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 17.5551	Cost: 36.53s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 6.8303	Cost: 16.45s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 6.9773	Cost: 16.64s
Train Epoch: 255 	Average Loss: 7.8692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8403

Learning rate: 5.813402624625721e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 17.3794	Cost: 36.72s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 6.7041	Cost: 14.76s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 6.7743	Cost: 16.39s
Train Epoch: 256 	Average Loss: 7.7901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8004

Learning rate: 5.742207084349277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 17.4518	Cost: 35.55s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 6.6798	Cost: 15.17s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 6.8075	Cost: 16.40s
Train Epoch: 257 	Average Loss: 7.7684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9985

Learning rate: 5.6712741847958634e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 17.4183	Cost: 36.72s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 6.6604	Cost: 16.43s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 6.6445	Cost: 16.50s
Train Epoch: 258 	Average Loss: 7.7943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9730

Learning rate: 5.600608301440851e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 17.7994	Cost: 35.29s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 6.7265	Cost: 16.89s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 6.8456	Cost: 16.52s
Train Epoch: 259 	Average Loss: 7.8558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0034

Learning rate: 5.5302137932887924e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 17.5778	Cost: 36.33s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 6.7013	Cost: 15.41s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 6.6317	Cost: 18.30s
Train Epoch: 260 	Average Loss: 7.7851
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9004

Learning rate: 5.460095002604535e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 17.5967	Cost: 36.52s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 6.6410	Cost: 16.04s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 6.7656	Cost: 17.26s
Train Epoch: 261 	Average Loss: 7.7627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8913

Learning rate: 5.390256254645381e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 17.2853	Cost: 36.49s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 6.6034	Cost: 15.40s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 6.6235	Cost: 16.20s
Train Epoch: 262 	Average Loss: 7.6440
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9314

Learning rate: 5.3207018573942705e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 17.4880	Cost: 44.75s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 6.5100	Cost: 16.47s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 6.5585	Cost: 16.86s
Train Epoch: 263 	Average Loss: 7.6597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9541

Learning rate: 5.251436101294054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 17.7619	Cost: 45.62s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 6.4533	Cost: 16.24s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 6.4172	Cost: 16.41s
Train Epoch: 264 	Average Loss: 7.5603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9182

Learning rate: 5.1824632589828485e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 17.4208	Cost: 39.84s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 6.2283	Cost: 16.45s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 6.5759	Cost: 16.48s
Train Epoch: 265 	Average Loss: 7.5395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9569

Learning rate: 5.1137875850304516e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 17.5545	Cost: 38.14s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 6.3921	Cost: 16.52s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 6.5024	Cost: 16.50s
Train Epoch: 266 	Average Loss: 7.5497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9220

Learning rate: 5.045413315675926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 17.5896	Cost: 36.00s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 6.4370	Cost: 15.75s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 6.3621	Cost: 16.11s
Train Epoch: 267 	Average Loss: 7.5171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9368

Learning rate: 4.977344668566277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 17.5239	Cost: 35.62s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 6.3154	Cost: 15.52s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 6.5823	Cost: 16.70s
Train Epoch: 268 	Average Loss: 7.4400
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0488

Learning rate: 4.909585842496289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 17.5647	Cost: 35.30s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 6.3695	Cost: 16.50s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 6.3653	Cost: 16.54s
Train Epoch: 269 	Average Loss: 7.4189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0633

Learning rate: 4.842141017149528e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 17.3909	Cost: 36.41s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 6.3510	Cost: 16.46s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 6.3215	Cost: 16.68s
Train Epoch: 270 	Average Loss: 7.3734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9889

Learning rate: 4.775014352840514e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 17.5806	Cost: 38.15s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 6.2726	Cost: 16.67s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 6.2904	Cost: 16.30s
Train Epoch: 271 	Average Loss: 7.3678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1475

Learning rate: 4.708209990258097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 17.4932	Cost: 36.82s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 6.2607	Cost: 16.87s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 6.2929	Cost: 14.97s
Train Epoch: 272 	Average Loss: 7.3366
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1031

Learning rate: 4.641732050210033e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 17.5683	Cost: 36.40s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 6.3697	Cost: 17.04s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 6.2116	Cost: 14.42s
Train Epoch: 273 	Average Loss: 7.2905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0492

Learning rate: 4.575584633368813e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 17.4062	Cost: 33.95s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 6.0545	Cost: 15.28s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 6.2399	Cost: 11.42s
Train Epoch: 274 	Average Loss: 7.1709
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0404

Learning rate: 4.509771820018683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 17.7511	Cost: 40.75s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 5.9733	Cost: 12.23s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 6.0322	Cost: 14.84s
Train Epoch: 275 	Average Loss: 7.1801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0527

Learning rate: 4.4442976698039786e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 17.5613	Cost: 35.73s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 5.9036	Cost: 12.48s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 6.0685	Cost: 13.08s
Train Epoch: 276 	Average Loss: 7.1608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2243

Learning rate: 4.379166221478695e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 17.6254	Cost: 33.61s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 5.8963	Cost: 11.81s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 5.7540	Cost: 19.48s
Train Epoch: 277 	Average Loss: 7.1449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2074

Learning rate: 4.3143814926573614e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 17.6345	Cost: 32.09s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 5.9206	Cost: 9.91s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 5.9375	Cost: 21.78s
Train Epoch: 278 	Average Loss: 7.1161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1431

Learning rate: 4.249947479567216e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 17.5525	Cost: 33.17s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 5.8708	Cost: 9.90s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 5.9610	Cost: 26.33s
Train Epoch: 279 	Average Loss: 7.0677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3337

Learning rate: 4.1858681568016955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 17.7669	Cost: 34.79s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 6.0173	Cost: 14.05s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 5.9257	Cost: 17.23s
Train Epoch: 280 	Average Loss: 7.1013
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1663

Learning rate: 4.122147477075271e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 17.7064	Cost: 35.25s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 5.7789	Cost: 16.38s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 5.8884	Cost: 17.34s
Train Epoch: 281 	Average Loss: 7.0090
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0999

Learning rate: 4.058789370979617e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 17.7271	Cost: 37.94s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 5.8065	Cost: 15.98s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 5.8540	Cost: 18.65s
Train Epoch: 282 	Average Loss: 7.0286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2671

Learning rate: 3.995797746741162e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 17.6643	Cost: 39.50s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 5.8937	Cost: 16.91s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 5.9696	Cost: 17.22s
Train Epoch: 283 	Average Loss: 6.9991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3361

Learning rate: 3.933176489980003e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 17.5851	Cost: 51.14s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 5.6989	Cost: 16.43s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 5.8264	Cost: 16.51s
Train Epoch: 284 	Average Loss: 6.9345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2212

Learning rate: 3.8709294634702356e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 17.7920	Cost: 48.92s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 5.7089	Cost: 16.20s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 5.7668	Cost: 16.15s
Train Epoch: 285 	Average Loss: 6.9368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2498

Learning rate: 3.809060506901661e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 17.7434	Cost: 38.41s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 5.6402	Cost: 15.70s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 5.7269	Cost: 16.22s
Train Epoch: 286 	Average Loss: 6.9368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3220

Learning rate: 3.747573436642949e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 17.5548	Cost: 40.15s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 5.7969	Cost: 12.81s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 5.8681	Cost: 19.05s
Train Epoch: 287 	Average Loss: 6.8976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1122

Learning rate: 3.686472045506224e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 17.9347	Cost: 37.13s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 5.6712	Cost: 14.04s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 5.6751	Cost: 18.29s
Train Epoch: 288 	Average Loss: 6.8923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3926

Learning rate: 3.625760102513104e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 17.4381	Cost: 36.08s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 5.7713	Cost: 15.15s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 5.6315	Cost: 16.03s
Train Epoch: 289 	Average Loss: 6.8428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2901

Learning rate: 3.5654413526622126e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 17.9881	Cost: 35.46s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 5.5056	Cost: 13.27s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 5.6797	Cost: 18.53s
Train Epoch: 290 	Average Loss: 6.8605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2663

Learning rate: 3.505519516698166e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 17.7906	Cost: 36.16s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 5.5625	Cost: 13.85s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 5.5790	Cost: 16.88s
Train Epoch: 291 	Average Loss: 6.8234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3170

Learning rate: 3.445998290882063e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 17.8813	Cost: 38.10s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 5.6235	Cost: 11.48s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 5.6415	Cost: 19.69s
Train Epoch: 292 	Average Loss: 6.8752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3024

Learning rate: 3.386881346763484e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 18.0754	Cost: 37.72s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 5.5990	Cost: 16.16s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 5.5722	Cost: 16.49s
Train Epoch: 293 	Average Loss: 6.8485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3885

Learning rate: 3.328172330954006e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 17.5056	Cost: 35.20s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 5.5680	Cost: 16.42s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 5.4373	Cost: 16.46s
Train Epoch: 294 	Average Loss: 6.7916
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3614

Learning rate: 3.269874864902267e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 17.7963	Cost: 36.50s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 5.4667	Cost: 16.11s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 5.7438	Cost: 16.50s
Train Epoch: 295 	Average Loss: 6.7954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2861

Learning rate: 3.2119925446705836e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 17.5311	Cost: 38.75s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 5.5860	Cost: 16.22s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 5.6304	Cost: 16.75s
Train Epoch: 296 	Average Loss: 6.7452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3621

Learning rate: 3.1545289407131144e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 17.8431	Cost: 35.32s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 5.5205	Cost: 16.52s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 5.5495	Cost: 16.35s
Train Epoch: 297 	Average Loss: 6.6944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4104

Learning rate: 3.09748759765563e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 17.6953	Cost: 36.17s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 5.5122	Cost: 16.79s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 5.4652	Cost: 16.93s
Train Epoch: 298 	Average Loss: 6.6744
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5436

Learning rate: 3.0408720340768585e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 17.9316	Cost: 39.82s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 5.4325	Cost: 13.77s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 5.5430	Cost: 19.69s
Train Epoch: 299 	Average Loss: 6.6784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3610

Learning rate: 2.9846857422914446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 17.7622	Cost: 41.81s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 5.4841	Cost: 14.66s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 5.5757	Cost: 16.15s
Train Epoch: 300 	Average Loss: 6.5999
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3855

Learning rate: 2.9289321881345268e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 17.7372	Cost: 43.85s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 5.4861	Cost: 14.42s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 5.3747	Cost: 16.39s
Train Epoch: 301 	Average Loss: 6.5869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5181

Learning rate: 2.8736148107479478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 17.8592	Cost: 52.63s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 5.2607	Cost: 16.46s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 5.2980	Cost: 15.66s
Train Epoch: 302 	Average Loss: 6.5663
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4993

Learning rate: 2.8187370223681142e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 17.9614	Cost: 38.18s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 5.3184	Cost: 16.75s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 5.2853	Cost: 14.82s
Train Epoch: 303 	Average Loss: 6.5488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5095

Learning rate: 2.764302208115509e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 18.1291	Cost: 41.17s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 5.3376	Cost: 15.06s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 5.2344	Cost: 11.81s
Train Epoch: 304 	Average Loss: 6.5355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4676

Learning rate: 2.710313725785888e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 17.8761	Cost: 36.42s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 5.1741	Cost: 16.24s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 5.0859	Cost: 9.59s
Train Epoch: 305 	Average Loss: 6.4254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4918

Learning rate: 2.6567749056431446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 17.7867	Cost: 35.74s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 5.1436	Cost: 14.58s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 5.1457	Cost: 10.83s
Train Epoch: 306 	Average Loss: 6.4353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3982

Learning rate: 2.6036890502139035e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 17.6809	Cost: 39.13s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 5.1282	Cost: 12.69s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 5.1937	Cost: 13.18s
Train Epoch: 307 	Average Loss: 6.4414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5164

Learning rate: 2.55105943408378e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 17.7255	Cost: 38.88s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 5.1510	Cost: 9.50s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 5.1024	Cost: 17.18s
Train Epoch: 308 	Average Loss: 6.3867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5445

Learning rate: 2.4988893036954053e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 17.9555	Cost: 34.73s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 5.1746	Cost: 10.80s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 5.0694	Cost: 14.30s
Train Epoch: 309 	Average Loss: 6.3849
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4609

Learning rate: 2.4471818771481658e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 17.7488	Cost: 36.87s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 4.9119	Cost: 12.60s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 4.8955	Cost: 13.62s
Train Epoch: 310 	Average Loss: 6.3055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4753

Learning rate: 2.3959403439996917e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 17.7097	Cost: 32.86s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 5.1393	Cost: 12.52s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 4.9759	Cost: 12.49s
Train Epoch: 311 	Average Loss: 6.3192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5363

Learning rate: 2.345167865069121e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 17.9341	Cost: 34.85s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 5.0089	Cost: 9.54s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 5.1748	Cost: 21.35s
Train Epoch: 312 	Average Loss: 6.3014
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6418

Learning rate: 2.2948675722421096e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 17.7309	Cost: 34.56s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 5.0694	Cost: 9.98s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 4.9875	Cost: 22.49s
Train Epoch: 313 	Average Loss: 6.2550
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5684

Learning rate: 2.2450425682776575e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 17.6639	Cost: 37.25s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 5.0182	Cost: 15.22s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 5.0769	Cost: 16.09s
Train Epoch: 314 	Average Loss: 6.2469
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5287

Learning rate: 2.1956959266167054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 17.7347	Cost: 36.15s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 4.9561	Cost: 16.50s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 4.9287	Cost: 16.61s
Train Epoch: 315 	Average Loss: 6.2275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5329

Learning rate: 2.1468306911925506e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 17.6391	Cost: 37.13s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 4.8836	Cost: 16.77s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 4.9042	Cost: 17.18s
Train Epoch: 316 	Average Loss: 6.1976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8419

Learning rate: 2.098449876243097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 18.0115	Cost: 39.12s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 4.9527	Cost: 13.46s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 4.9938	Cost: 20.16s
Train Epoch: 317 	Average Loss: 6.1903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6993

Learning rate: 2.050556466124901e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 17.8578	Cost: 39.86s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 4.9298	Cost: 14.05s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 4.9569	Cost: 16.51s
Train Epoch: 318 	Average Loss: 6.1677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5949

Learning rate: 2.0031534151290953e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 18.0415	Cost: 44.21s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 4.8402	Cost: 16.53s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 4.9496	Cost: 16.53s
Train Epoch: 319 	Average Loss: 6.1366
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6667

Learning rate: 1.9562436472991562e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 17.9380	Cost: 40.97s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 4.8097	Cost: 16.52s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 4.7803	Cost: 16.72s
Train Epoch: 320 	Average Loss: 6.1084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5778

Learning rate: 1.9098300562505276e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 17.5072	Cost: 38.74s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 4.9202	Cost: 14.58s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 4.8333	Cost: 16.50s
Train Epoch: 321 	Average Loss: 6.0923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6647

Learning rate: 1.863915504992132e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 17.9956	Cost: 37.21s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 4.7076	Cost: 16.70s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 4.9697	Cost: 16.67s
Train Epoch: 322 	Average Loss: 6.1056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7244

Learning rate: 1.8185028257497683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 17.9336	Cost: 37.30s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 4.7284	Cost: 16.43s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 4.8730	Cost: 15.32s
Train Epoch: 323 	Average Loss: 6.1010
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8003

Learning rate: 1.7735948197914044e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 17.9148	Cost: 35.63s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 4.7462	Cost: 13.64s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 4.8834	Cost: 13.24s
Train Epoch: 324 	Average Loss: 6.0787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8120

Learning rate: 1.729194257254384e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 17.6893	Cost: 34.61s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 4.6525	Cost: 14.40s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 4.9532	Cost: 12.60s
Train Epoch: 325 	Average Loss: 6.0641
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7533

Learning rate: 1.685303876974551e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 17.6673	Cost: 39.25s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 4.6553	Cost: 13.02s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 4.7420	Cost: 13.06s
Train Epoch: 326 	Average Loss: 6.0025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6263

Learning rate: 1.6419263863173007e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 17.8963	Cost: 36.97s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 4.6705	Cost: 12.02s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 4.6993	Cost: 14.23s
Train Epoch: 327 	Average Loss: 5.9887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7870

Learning rate: 1.599064461010582e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 17.7605	Cost: 32.95s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 4.6083	Cost: 10.46s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 4.6767	Cost: 19.06s
Train Epoch: 328 	Average Loss: 6.0019
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5823

Learning rate: 1.5567207449798525e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 17.6434	Cost: 32.85s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 4.6015	Cost: 9.80s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 4.6562	Cost: 24.88s
Train Epoch: 329 	Average Loss: 5.8884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8250

Learning rate: 1.5148978501849652e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 17.7867	Cost: 34.13s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 4.6861	Cost: 10.25s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 4.6563	Cost: 22.20s
Train Epoch: 330 	Average Loss: 5.9202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7359

Learning rate: 1.4735983564590815e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 17.7147	Cost: 36.97s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 4.5794	Cost: 16.39s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 4.4800	Cost: 16.29s
Train Epoch: 331 	Average Loss: 5.8590
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7701

Learning rate: 1.4328248113495055e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 17.7251	Cost: 37.31s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 4.4993	Cost: 16.48s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 4.5693	Cost: 16.45s
Train Epoch: 332 	Average Loss: 5.8253
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7418

Learning rate: 1.3925797299605635e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 18.1752	Cost: 36.84s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 4.4538	Cost: 16.60s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 4.5469	Cost: 17.47s
Train Epoch: 333 	Average Loss: 5.8096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6939

Learning rate: 1.3528655947984512e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 18.0837	Cost: 39.94s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 4.5645	Cost: 16.51s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 4.5210	Cost: 17.28s
Train Epoch: 334 	Average Loss: 5.8149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7953

Learning rate: 1.3136848556180878e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 17.8933	Cost: 56.31s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 4.5851	Cost: 16.18s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 4.5400	Cost: 15.84s
Train Epoch: 335 	Average Loss: 5.8126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7410

Learning rate: 1.2750399292720314e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 18.2235	Cost: 42.10s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 4.4736	Cost: 16.64s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 4.5603	Cost: 16.62s
Train Epoch: 336 	Average Loss: 5.7937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9506

Learning rate: 1.2369331995613651e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 17.8848	Cost: 41.00s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 4.5085	Cost: 16.36s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 4.4634	Cost: 16.43s
Train Epoch: 337 	Average Loss: 5.7709
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7736

Learning rate: 1.1993670170886837e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 17.9071	Cost: 43.83s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 4.3653	Cost: 16.69s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 4.5929	Cost: 16.64s
Train Epoch: 338 	Average Loss: 5.7912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6741

Learning rate: 1.1623436991130663e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 17.9145	Cost: 35.69s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 4.4432	Cost: 14.10s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 4.5471	Cost: 16.53s
Train Epoch: 339 	Average Loss: 5.7613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6126

Learning rate: 1.1258655294071704e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 18.0971	Cost: 37.90s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 4.4230	Cost: 13.35s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 4.3965	Cost: 16.31s
Train Epoch: 340 	Average Loss: 5.7210
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7792

Learning rate: 1.089934758116323e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 17.8100	Cost: 35.79s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 4.5458	Cost: 15.22s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 4.3679	Cost: 17.13s
Train Epoch: 341 	Average Loss: 5.7228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7687

Learning rate: 1.054553601619753e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 17.9924	Cost: 34.69s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 4.3153	Cost: 14.31s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 4.2184	Cost: 16.39s
Train Epoch: 342 	Average Loss: 5.6870
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8649

Learning rate: 1.0197242423938455e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 17.8426	Cost: 35.62s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 4.2302	Cost: 13.97s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 4.4734	Cost: 17.36s
Train Epoch: 343 	Average Loss: 5.6834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7994

Learning rate: 9.854488288775428e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 17.9822	Cost: 36.94s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 4.3124	Cost: 15.67s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 4.3510	Cost: 17.24s
Train Epoch: 344 	Average Loss: 5.6519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6186

Learning rate: 9.517294753398073e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 17.8915	Cost: 38.29s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 4.2097	Cost: 14.08s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 4.3266	Cost: 21.09s
Train Epoch: 345 	Average Loss: 5.6733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9875

Learning rate: 9.185682617491872e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 17.6939	Cost: 38.94s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 4.2213	Cost: 16.43s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 4.2601	Cost: 16.73s
Train Epoch: 346 	Average Loss: 5.6773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7998

Learning rate: 8.859672336455501e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 17.8620	Cost: 38.43s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 4.2931	Cost: 15.01s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 4.4861	Cost: 16.45s
Train Epoch: 347 	Average Loss: 5.6374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8471

Learning rate: 8.539284020138645e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 17.8597	Cost: 38.31s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 4.3328	Cost: 11.34s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 4.3122	Cost: 19.70s
Train Epoch: 348 	Average Loss: 5.6245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9518

Learning rate: 8.224537431601915e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 17.8903	Cost: 37.51s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 4.2423	Cost: 11.23s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 4.2330	Cost: 20.97s
Train Epoch: 349 	Average Loss: 5.6132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8108

Learning rate: 7.915451985897387e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 17.7245	Cost: 51.43s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 4.2547	Cost: 16.45s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 4.2886	Cost: 16.53s
Train Epoch: 350 	Average Loss: 5.6129
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8012

Learning rate: 7.612046748871354e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 17.5571	Cost: 40.49s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 4.2636	Cost: 16.37s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 4.1831	Cost: 16.70s
Train Epoch: 351 	Average Loss: 5.5779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8617

Learning rate: 7.314340435987926e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 17.6387	Cost: 38.96s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 4.1863	Cost: 16.35s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 4.2408	Cost: 16.54s
Train Epoch: 352 	Average Loss: 5.5669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9667

Learning rate: 7.022351411174871e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 17.7779	Cost: 37.19s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 4.1302	Cost: 16.53s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 4.2578	Cost: 16.44s
Train Epoch: 353 	Average Loss: 5.5614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9220

Learning rate: 6.736097685690606e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 17.7245	Cost: 35.05s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 4.1882	Cost: 16.09s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 4.4169	Cost: 15.92s
Train Epoch: 354 	Average Loss: 5.5669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9124

Learning rate: 6.455596917013267e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 18.1925	Cost: 36.02s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 4.3750	Cost: 16.55s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 4.1574	Cost: 16.61s
Train Epoch: 355 	Average Loss: 5.5728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9258

Learning rate: 6.1808664077516005e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 18.0522	Cost: 36.56s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 4.2999	Cost: 14.46s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 4.2108	Cost: 17.35s
Train Epoch: 356 	Average Loss: 5.5653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0254

Learning rate: 5.91192310457746e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 17.9959	Cost: 35.72s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 4.1537	Cost: 14.10s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 4.2496	Cost: 19.84s
Train Epoch: 357 	Average Loss: 5.5542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7616

Learning rate: 5.648783597180656e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 17.8740	Cost: 37.79s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 4.1583	Cost: 15.70s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 4.1341	Cost: 17.66s
Train Epoch: 358 	Average Loss: 5.5495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8011

Learning rate: 5.3914641172454745e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 17.5765	Cost: 39.93s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 4.3474	Cost: 14.73s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 4.0133	Cost: 17.07s
Train Epoch: 359 	Average Loss: 5.5053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9573

Learning rate: 5.139980537449555e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 17.7432	Cost: 42.40s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 4.1344	Cost: 14.24s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 4.1862	Cost: 16.29s
Train Epoch: 360 	Average Loss: 5.5287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8087

Learning rate: 4.894348370484651e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 17.9252	Cost: 39.57s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 4.1869	Cost: 14.60s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 4.2193	Cost: 16.67s
Train Epoch: 361 	Average Loss: 5.5029
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0216

Learning rate: 4.6545827680998834e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 18.0467	Cost: 41.42s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 4.1450	Cost: 16.39s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 4.2449	Cost: 16.48s
Train Epoch: 362 	Average Loss: 5.5206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9391

Learning rate: 4.420698520166991e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 17.8832	Cost: 35.97s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 3.9117	Cost: 14.70s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 4.2367	Cost: 16.54s
Train Epoch: 363 	Average Loss: 5.4684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0548

Learning rate: 4.1927100537680815e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 18.1818	Cost: 34.81s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 3.9418	Cost: 13.19s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 4.0583	Cost: 21.02s
Train Epoch: 364 	Average Loss: 5.4655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9468

Learning rate: 3.970631432305708e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 18.0689	Cost: 38.12s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 4.1443	Cost: 16.45s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 4.0704	Cost: 17.53s
Train Epoch: 365 	Average Loss: 5.4941
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9512

Learning rate: 3.7544763546352753e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 18.0237	Cost: 36.28s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 4.1035	Cost: 16.22s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 4.1359	Cost: 16.57s
Train Epoch: 366 	Average Loss: 5.4867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9740

Learning rate: 3.5442581542202067e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 17.9523	Cost: 37.85s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 4.1450	Cost: 16.52s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 4.3161	Cost: 16.20s
Train Epoch: 367 	Average Loss: 5.4814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0481

Learning rate: 3.339989798309276e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 17.9095	Cost: 35.76s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 4.1675	Cost: 16.42s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 4.0589	Cost: 16.28s
Train Epoch: 368 	Average Loss: 5.4452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0116

Learning rate: 3.1416838871369064e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 17.8306	Cost: 34.87s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 4.0384	Cost: 15.37s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 4.1108	Cost: 18.58s
Train Epoch: 369 	Average Loss: 5.4205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9776

Learning rate: 2.9493526531457563e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 17.9448	Cost: 35.97s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 4.1229	Cost: 14.76s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 4.0916	Cost: 19.13s
Train Epoch: 370 	Average Loss: 5.4585
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8606

Learning rate: 2.7630079602323468e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 18.0728	Cost: 37.78s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 4.1423	Cost: 16.41s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 4.1682	Cost: 16.58s
Train Epoch: 371 	Average Loss: 5.4531
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9429

Learning rate: 2.582661303015068e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 17.9349	Cost: 43.83s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 3.9056	Cost: 15.33s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 4.1681	Cost: 16.44s
Train Epoch: 372 	Average Loss: 5.4499
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9919

Learning rate: 2.40832380612527e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 18.0407	Cost: 38.33s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 4.1012	Cost: 9.52s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 4.0022	Cost: 21.94s
Train Epoch: 373 	Average Loss: 5.4633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9171

Learning rate: 2.2400062235209426e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 17.8213	Cost: 39.11s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 4.2155	Cost: 14.10s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 3.8723	Cost: 19.69s
Train Epoch: 374 	Average Loss: 5.4365
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9195

Learning rate: 2.0777189378234156e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 17.6784	Cost: 38.28s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 4.0830	Cost: 14.77s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 4.0976	Cost: 18.50s
Train Epoch: 375 	Average Loss: 5.4616
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0024

Learning rate: 1.9214719596769582e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 17.9204	Cost: 49.21s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 4.0947	Cost: 16.48s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 3.9399	Cost: 17.38s
Train Epoch: 376 	Average Loss: 5.4441
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0551

Learning rate: 1.771274927131129e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 18.2732	Cost: 37.57s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 4.0384	Cost: 9.65s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 3.9948	Cost: 14.30s
Train Epoch: 377 	Average Loss: 5.4317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8557

Learning rate: 1.6271371050464177e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 18.2771	Cost: 33.78s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 3.7949	Cost: 9.64s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 4.0259	Cost: 14.68s
Train Epoch: 378 	Average Loss: 5.3884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9693

Learning rate: 1.4890673845226142e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 17.9071	Cost: 34.70s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 3.9989	Cost: 9.72s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 4.1569	Cost: 16.04s
Train Epoch: 379 	Average Loss: 5.4156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9394

Learning rate: 1.3570742823504575e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 18.0623	Cost: 34.60s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 4.0200	Cost: 9.77s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 4.0025	Cost: 14.41s
Train Epoch: 380 	Average Loss: 5.3711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0670

Learning rate: 1.2311659404862349e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 17.9708	Cost: 34.73s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 4.1912	Cost: 9.62s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 3.9930	Cost: 13.89s
Train Epoch: 381 	Average Loss: 5.4223
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9932

Learning rate: 1.1113501255495491e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 17.9726	Cost: 33.61s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 4.0594	Cost: 9.52s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 4.1319	Cost: 15.61s
Train Epoch: 382 	Average Loss: 5.4125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9369

Learning rate: 9.97634228344247e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 17.9779	Cost: 43.37s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 3.9994	Cost: 14.96s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 4.0755	Cost: 18.40s
Train Epoch: 383 	Average Loss: 5.3904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9526

Learning rate: 8.90025263402528e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 17.8440	Cost: 43.92s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 4.0470	Cost: 16.85s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 4.0850	Cost: 16.21s
Train Epoch: 384 	Average Loss: 5.3990
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9782

Learning rate: 7.88529868552224e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 18.0327	Cost: 38.80s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 3.9065	Cost: 16.08s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 4.1433	Cost: 16.35s
Train Epoch: 385 	Average Loss: 5.3810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0108

Learning rate: 6.931543045073711e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 17.8275	Cost: 40.70s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 4.0787	Cost: 16.39s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 4.0069	Cost: 13.56s
Train Epoch: 386 	Average Loss: 5.4001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9377

Learning rate: 6.039044544820409e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 18.2855	Cost: 40.31s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 4.0019	Cost: 15.27s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 4.0120	Cost: 11.70s
Train Epoch: 387 	Average Loss: 5.3975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0269

Learning rate: 5.207858238273524e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 17.7985	Cost: 38.98s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 3.9588	Cost: 12.98s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 4.0232	Cost: 13.77s
Train Epoch: 388 	Average Loss: 5.3719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9530

Learning rate: 4.4380353969200063e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 17.9091	Cost: 36.94s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 3.9944	Cost: 9.66s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 4.1331	Cost: 19.87s
Train Epoch: 389 	Average Loss: 5.3831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9583

Learning rate: 3.7296235070587456e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 17.9341	Cost: 35.52s
Train Epoch: 390 [40960/90000 (45%)]	Loss: 4.0363	Cost: 10.32s
Train Epoch: 390 [81920/90000 (91%)]	Loss: 4.0077	Cost: 26.45s
Train Epoch: 390 	Average Loss: 5.4147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0389

Learning rate: 3.082666266872038e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 17.5235	Cost: 40.98s
Train Epoch: 391 [40960/90000 (45%)]	Loss: 4.0917	Cost: 9.98s
Train Epoch: 391 [81920/90000 (91%)]	Loss: 3.8786	Cost: 26.87s
Train Epoch: 391 	Average Loss: 5.3819
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9417

Learning rate: 2.497203583729958e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 17.8781	Cost: 48.53s
Train Epoch: 392 [40960/90000 (45%)]	Loss: 4.1062	Cost: 14.94s
Train Epoch: 392 [81920/90000 (91%)]	Loss: 4.0074	Cost: 16.71s
Train Epoch: 392 	Average Loss: 5.3669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1781

Learning rate: 1.973271571728442e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 17.8971	Cost: 44.59s
Train Epoch: 393 [40960/90000 (45%)]	Loss: 3.9676	Cost: 16.89s
Train Epoch: 393 [81920/90000 (91%)]	Loss: 4.1730	Cost: 15.00s
Train Epoch: 393 	Average Loss: 5.3947
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0008

Learning rate: 1.5109025494620685e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 18.1311	Cost: 39.77s
Train Epoch: 394 [40960/90000 (45%)]	Loss: 3.8745	Cost: 15.46s
Train Epoch: 394 [81920/90000 (91%)]	Loss: 4.0549	Cost: 11.51s
Train Epoch: 394 	Average Loss: 5.4022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8717

Learning rate: 1.1101250380300971e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 17.9008	Cost: 36.44s
Train Epoch: 395 [40960/90000 (45%)]	Loss: 4.0055	Cost: 9.63s
Train Epoch: 395 [81920/90000 (91%)]	Loss: 4.0175	Cost: 19.94s
Train Epoch: 395 	Average Loss: 5.3952
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9964

Learning rate: 7.709637592770994e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 17.7524	Cost: 34.68s
Train Epoch: 396 [40960/90000 (45%)]	Loss: 4.0565	Cost: 10.52s
Train Epoch: 396 [81920/90000 (91%)]	Loss: 4.1498	Cost: 23.92s
Train Epoch: 396 	Average Loss: 5.3693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8800

Learning rate: 4.934396342684002e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 17.8641	Cost: 34.27s
Train Epoch: 397 [40960/90000 (45%)]	Loss: 4.0586	Cost: 12.09s
Train Epoch: 397 [81920/90000 (91%)]	Loss: 3.9495	Cost: 23.97s
Train Epoch: 397 	Average Loss: 5.3674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8629

Learning rate: 2.7756978199944282e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 17.6694	Cost: 57.97s
Train Epoch: 398 [40960/90000 (45%)]	Loss: 4.0368	Cost: 16.39s
Train Epoch: 398 [81920/90000 (91%)]	Loss: 3.9895	Cost: 16.27s
Train Epoch: 398 	Average Loss: 5.3872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8656

Learning rate: 1.2336751833941234e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 17.9984	Cost: 48.89s
Train Epoch: 399 [40960/90000 (45%)]	Loss: 4.1073	Cost: 16.11s
Train Epoch: 399 [81920/90000 (91%)]	Loss: 4.1234	Cost: 16.23s
Train Epoch: 399 	Average Loss: 5.3681
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0534

Learning rate: 3.084235521033653e-09
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 18.1157	Cost: 39.40s
Train Epoch: 400 [40960/90000 (45%)]	Loss: 4.0883	Cost: 16.65s
Train Epoch: 400 [81920/90000 (91%)]	Loss: 4.0486	Cost: 14.09s
Train Epoch: 400 	Average Loss: 5.3569
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0171

Stopping timer.
Training time (including validation): 265304.40532279015 seconds
Saving model
Transfer learning by starting with alpha=0.1!
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 25.1788	Cost: 51.07s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 20.6778	Cost: 17.23s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 19.5492	Cost: 16.82s
Train Epoch: 1 	Average Loss: 20.9574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2756

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999691576447898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 19.3728	Cost: 41.06s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 18.4932	Cost: 16.84s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 17.9926	Cost: 13.85s
Train Epoch: 2 	Average Loss: 18.5140
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6107

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 18.1919	Cost: 45.90s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 17.5379	Cost: 12.45s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 17.3671	Cost: 11.78s
Train Epoch: 3 	Average Loss: 17.6111
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9254

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 17.6652	Cost: 36.50s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 17.1787	Cost: 12.59s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 17.0164	Cost: 12.57s
Train Epoch: 4 	Average Loss: 17.1663
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5832

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.00019995065603657316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 17.5775	Cost: 35.07s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 16.8627	Cost: 10.13s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 16.7606	Cost: 26.84s
Train Epoch: 5 	Average Loss: 16.8700
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5056

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.0001999229036240723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 17.3283	Cost: 42.19s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 16.7360	Cost: 16.56s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 16.6135	Cost: 16.58s
Train Epoch: 6 	Average Loss: 16.7007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4300

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019988898749619702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 17.3449	Cost: 41.51s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 16.4740	Cost: 11.91s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 16.3770	Cost: 13.68s
Train Epoch: 7 	Average Loss: 16.5607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4283

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.00019984890974505381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 17.2090	Cost: 32.55s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 16.3919	Cost: 13.20s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 16.2283	Cost: 21.27s
Train Epoch: 8 	Average Loss: 16.4559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3632

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.00019980267284282717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 17.2051	Cost: 38.45s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 16.3074	Cost: 10.50s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 16.2304	Cost: 21.86s
Train Epoch: 9 	Average Loss: 16.3544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4025

Learning rate: 0.00019975027964162705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 17.2327	Cost: 50.74s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 16.1460	Cost: 16.98s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 16.0395	Cost: 12.75s
Train Epoch: 10 	Average Loss: 16.2738
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4207

Learning rate: 0.00019969173337331284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 17.1977	Cost: 46.12s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 16.0893	Cost: 12.07s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 16.1082	Cost: 19.29s
Train Epoch: 11 	Average Loss: 16.1682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4083

Learning rate: 0.00019962703764929416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 17.1311	Cost: 37.25s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 16.0049	Cost: 12.54s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 15.9902	Cost: 14.81s
Train Epoch: 12 	Average Loss: 16.0972
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4021

Learning rate: 0.00019955619646030802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 17.1538	Cost: 34.95s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 16.0349	Cost: 10.11s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 15.7919	Cost: 27.89s
Train Epoch: 13 	Average Loss: 16.0330
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.4813

Learning rate: 0.00019947921417617267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 17.3514	Cost: 39.52s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 15.8176	Cost: 16.44s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 15.7311	Cost: 16.59s
Train Epoch: 14 	Average Loss: 15.9840
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5978

Learning rate: 0.000199396095545518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 17.2770	Cost: 40.74s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 15.6937	Cost: 9.64s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 15.7362	Cost: 16.34s
Train Epoch: 15 	Average Loss: 15.9205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5408

Learning rate: 0.00019930684569549264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 17.2635	Cost: 34.44s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 15.6480	Cost: 13.02s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 15.7553	Cost: 20.41s
Train Epoch: 16 	Average Loss: 15.8601
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5530

Learning rate: 0.0001992114701314478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 17.4395	Cost: 34.44s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 15.7140	Cost: 12.06s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 15.6006	Cost: 25.29s
Train Epoch: 17 	Average Loss: 15.8253
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5812

Learning rate: 0.00019910997473659747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 17.3871	Cost: 40.41s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 15.6679	Cost: 17.08s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 15.5711	Cost: 17.22s
Train Epoch: 18 	Average Loss: 15.7711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6004

Learning rate: 0.00019900236577165574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 17.4568	Cost: 53.56s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 15.5494	Cost: 11.89s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 15.4734	Cost: 18.92s
Train Epoch: 19 	Average Loss: 15.7342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6856

Learning rate: 0.00019888864987445046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 17.4276	Cost: 36.66s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 15.5301	Cost: 12.55s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 15.4191	Cost: 15.85s
Train Epoch: 20 	Average Loss: 15.6826
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7406

Learning rate: 0.00019876883405951377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 17.4770	Cost: 33.25s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 15.4734	Cost: 9.93s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 15.5007	Cost: 26.86s
Train Epoch: 21 	Average Loss: 15.6582
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7160

Learning rate: 0.00019864292571764955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 17.5301	Cost: 38.94s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 15.4945	Cost: 16.77s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 15.2790	Cost: 17.88s
Train Epoch: 22 	Average Loss: 15.5882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7000

Learning rate: 0.0001985109326154774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 17.4204	Cost: 42.00s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 15.4234	Cost: 16.61s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 15.2370	Cost: 16.54s
Train Epoch: 23 	Average Loss: 15.5297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7881

Learning rate: 0.00019837286289495361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 17.5610	Cost: 40.54s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 15.3356	Cost: 13.16s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 15.1456	Cost: 12.44s
Train Epoch: 24 	Average Loss: 15.5041
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7839

Learning rate: 0.0001982287250728689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 17.6128	Cost: 34.30s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 15.1684	Cost: 12.84s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 15.2232	Cost: 17.27s
Train Epoch: 25 	Average Loss: 15.4661
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8040

Learning rate: 0.00019807852804032305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 17.4968	Cost: 41.92s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 15.1339	Cost: 10.08s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 15.0747	Cost: 23.28s
Train Epoch: 26 	Average Loss: 15.3977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7734

Learning rate: 0.00019792228106217658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 17.5895	Cost: 52.44s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 15.1511	Cost: 16.85s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 15.0753	Cost: 13.65s
Train Epoch: 27 	Average Loss: 15.3509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9145

Learning rate: 0.0001977599937764791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 17.7536	Cost: 43.23s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 15.1202	Cost: 14.02s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 14.9899	Cost: 12.76s
Train Epoch: 28 	Average Loss: 15.3220
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8912

Learning rate: 0.00019759167619387474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 17.7312	Cost: 35.25s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 15.1133	Cost: 12.19s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 15.0948	Cost: 16.88s
Train Epoch: 29 	Average Loss: 15.3454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8727

Learning rate: 0.00019741733869698495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 17.6322	Cost: 33.28s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 15.0966	Cost: 9.82s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 14.9269	Cost: 22.38s
Train Epoch: 30 	Average Loss: 15.2732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8556

Learning rate: 0.00019723699203976766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 17.5984	Cost: 39.38s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 14.9141	Cost: 16.88s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 14.9409	Cost: 17.15s
Train Epoch: 31 	Average Loss: 15.2294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9790

Learning rate: 0.00019705064734685425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 17.4911	Cost: 40.25s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 15.0121	Cost: 15.36s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 14.8600	Cost: 11.29s
Train Epoch: 32 	Average Loss: 15.1514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9930

Learning rate: 0.00019685831611286313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 17.5862	Cost: 37.10s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 14.8218	Cost: 9.67s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 14.9369	Cost: 18.55s
Train Epoch: 33 	Average Loss: 15.1249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9775

Learning rate: 0.00019666001020169073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 17.8737	Cost: 31.62s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 14.9034	Cost: 10.85s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 14.7168	Cost: 26.24s
Train Epoch: 34 	Average Loss: 15.0794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0735

Learning rate: 0.0001964557418457798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 17.7859	Cost: 36.98s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 14.7167	Cost: 16.90s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 14.8166	Cost: 20.65s
Train Epoch: 35 	Average Loss: 15.0806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0830

Learning rate: 0.0001962455236453647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 17.6303	Cost: 46.35s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 14.7509	Cost: 15.79s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 14.6768	Cost: 16.33s
Train Epoch: 36 	Average Loss: 15.0210
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0746

Learning rate: 0.00019602936856769428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 17.8510	Cost: 47.73s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 14.5716	Cost: 11.56s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 14.7109	Cost: 18.73s
Train Epoch: 37 	Average Loss: 14.9801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0641

Learning rate: 0.0001958072899462319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 17.9493	Cost: 35.86s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 14.6021	Cost: 9.89s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 14.6551	Cost: 27.10s
Train Epoch: 38 	Average Loss: 14.9662
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1190

Learning rate: 0.00019557930147983297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 17.7667	Cost: 40.04s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 14.6242	Cost: 16.80s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 14.7112	Cost: 16.65s
Train Epoch: 39 	Average Loss: 14.9626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1210

Learning rate: 0.00019534541723190008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 17.9063	Cost: 40.97s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 14.6005	Cost: 16.37s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 14.6046	Cost: 15.97s
Train Epoch: 40 	Average Loss: 14.9465
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0917

Learning rate: 0.00019510565162951532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 17.7954	Cost: 41.75s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 14.5816	Cost: 9.61s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 14.5357	Cost: 17.06s
Train Epoch: 41 	Average Loss: 14.8748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1706

Learning rate: 0.0001948600194625504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 17.9510	Cost: 32.33s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 14.4057	Cost: 9.88s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 14.2912	Cost: 28.65s
Train Epoch: 42 	Average Loss: 14.8168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1908

Learning rate: 0.00019460853588275446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 17.8897	Cost: 34.02s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 14.4180	Cost: 17.00s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 14.4148	Cost: 16.94s
Train Epoch: 43 	Average Loss: 14.7645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2989

Learning rate: 0.0001943512164028193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 17.9368	Cost: 37.55s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 14.4127	Cost: 16.52s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 14.4271	Cost: 19.71s
Train Epoch: 44 	Average Loss: 14.7224
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2250

Learning rate: 0.00019408807689542249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 17.8796	Cost: 41.05s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 14.4210	Cost: 12.14s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 14.2097	Cost: 22.82s
Train Epoch: 45 	Average Loss: 14.6546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2463

Learning rate: 0.00019381913359224837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 17.8590	Cost: 38.92s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 14.2323	Cost: 12.58s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 14.2702	Cost: 11.04s
Train Epoch: 46 	Average Loss: 14.6443
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2581

Learning rate: 0.0001935444030829867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 18.0463	Cost: 37.96s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 14.3413	Cost: 10.27s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 14.2776	Cost: 27.64s
Train Epoch: 47 	Average Loss: 14.6804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3438

Learning rate: 0.00019326390231430937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 17.9177	Cost: 39.46s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 14.2858	Cost: 16.09s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 14.2025	Cost: 18.73s
Train Epoch: 48 	Average Loss: 14.6178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3253

Learning rate: 0.00019297764858882508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 17.9718	Cost: 34.53s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 14.2769	Cost: 16.10s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 14.1790	Cost: 10.72s
Train Epoch: 49 	Average Loss: 14.6234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3345

Learning rate: 0.000192685659564012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 18.0008	Cost: 37.56s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 14.1868	Cost: 9.78s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 14.1684	Cost: 21.52s
Train Epoch: 50 	Average Loss: 14.5731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4044

Learning rate: 0.00019238795325112859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 18.1144	Cost: 32.98s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 14.2289	Cost: 9.93s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 14.1553	Cost: 24.69s
Train Epoch: 51 	Average Loss: 14.6030
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4137

Learning rate: 0.00019208454801410258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 18.1282	Cost: 39.01s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 14.2493	Cost: 16.77s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 14.1936	Cost: 18.97s
Train Epoch: 52 	Average Loss: 14.5466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3660

Learning rate: 0.00019177546256839804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 18.0191	Cost: 38.81s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 14.2713	Cost: 17.10s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 14.1322	Cost: 18.24s
Train Epoch: 53 	Average Loss: 14.5093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3548

Learning rate: 0.0001914607159798613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 18.0964	Cost: 40.21s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 14.1294	Cost: 9.86s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 13.8749	Cost: 24.46s
Train Epoch: 54 	Average Loss: 14.4316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4076

Learning rate: 0.00019114032766354445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 18.2153	Cost: 40.63s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 14.0897	Cost: 9.96s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 13.9006	Cost: 28.48s
Train Epoch: 55 	Average Loss: 14.3841
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5046

Learning rate: 0.00019081431738250806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 18.1866	Cost: 41.88s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 13.8730	Cost: 17.01s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 14.0370	Cost: 16.60s
Train Epoch: 56 	Average Loss: 14.3598
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5410

Learning rate: 0.00019048270524660188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 18.2226	Cost: 41.97s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 14.0226	Cost: 15.64s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 13.8638	Cost: 14.34s
Train Epoch: 57 	Average Loss: 14.3323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4998

Learning rate: 0.0001901455117112245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 18.2319	Cost: 37.02s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 13.8775	Cost: 11.24s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 13.8261	Cost: 16.09s
Train Epoch: 58 	Average Loss: 14.3029
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5273

Learning rate: 0.0001898027575760615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 18.1366	Cost: 32.67s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 13.8662	Cost: 9.93s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 13.9640	Cost: 26.34s
Train Epoch: 59 	Average Loss: 14.3098
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5071

Learning rate: 0.00018945446398380245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 18.1694	Cost: 40.42s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 13.8452	Cost: 16.80s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 13.8745	Cost: 18.81s
Train Epoch: 60 	Average Loss: 14.3057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5406

Learning rate: 0.00018910065241883672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 18.3135	Cost: 38.70s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 13.8014	Cost: 10.52s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 13.8532	Cost: 26.53s
Train Epoch: 61 	Average Loss: 14.2555
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5759

Learning rate: 0.00018874134470592827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 18.3502	Cost: 40.37s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 13.6454	Cost: 10.65s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 13.7140	Cost: 20.95s
Train Epoch: 62 	Average Loss: 14.1944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5806

Learning rate: 0.0001883765630088693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 18.2993	Cost: 40.70s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 13.8653	Cost: 13.17s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 13.8157	Cost: 22.73s
Train Epoch: 63 	Average Loss: 14.1799
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7093

Learning rate: 0.00018800632982911313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 18.2379	Cost: 46.43s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 13.6754	Cost: 16.28s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 13.6282	Cost: 16.16s
Train Epoch: 64 	Average Loss: 14.1845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5895

Learning rate: 0.00018763066800438628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 18.2542	Cost: 41.14s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 13.7607	Cost: 11.96s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 13.7139	Cost: 16.69s
Train Epoch: 65 	Average Loss: 14.2263
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6754

Learning rate: 0.00018724960070727966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 18.2695	Cost: 36.20s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 13.6804	Cost: 12.87s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 13.6690	Cost: 12.89s
Train Epoch: 66 	Average Loss: 14.2076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6314

Learning rate: 0.00018686315144381908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 18.2688	Cost: 34.99s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 13.6529	Cost: 10.19s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 13.7983	Cost: 25.48s
Train Epoch: 67 	Average Loss: 14.1076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6145

Learning rate: 0.00018647134405201546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 18.3899	Cost: 40.01s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 13.5526	Cost: 16.76s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 13.5315	Cost: 16.65s
Train Epoch: 68 	Average Loss: 14.0277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7064

Learning rate: 0.00018607420270039433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 18.2894	Cost: 40.43s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 13.5898	Cost: 12.69s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 13.4583	Cost: 17.78s
Train Epoch: 69 	Average Loss: 14.0056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6723

Learning rate: 0.00018567175188650495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 18.3604	Cost: 38.05s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 13.4856	Cost: 12.93s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 13.5110	Cost: 16.16s
Train Epoch: 70 	Average Loss: 13.9670
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6759

Learning rate: 0.0001852640164354092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 18.4854	Cost: 40.69s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 13.6167	Cost: 10.07s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 13.4572	Cost: 23.81s
Train Epoch: 71 	Average Loss: 14.0479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7260

Learning rate: 0.00018485102149815036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 18.4109	Cost: 46.28s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 13.5363	Cost: 16.66s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 13.5088	Cost: 16.57s
Train Epoch: 72 	Average Loss: 13.9958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6646

Learning rate: 0.0001844327925502015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 18.4842	Cost: 43.31s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 13.4122	Cost: 13.79s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 13.3825	Cost: 13.62s
Train Epoch: 73 	Average Loss: 13.8844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7110

Learning rate: 0.00018400935538989417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 18.5550	Cost: 37.47s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 13.2274	Cost: 9.62s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 13.2578	Cost: 18.38s
Train Epoch: 74 	Average Loss: 13.8220
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7618

Learning rate: 0.00018358073613682703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 18.5819	Cost: 33.96s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 13.3394	Cost: 9.86s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 13.2276	Cost: 27.26s
Train Epoch: 75 	Average Loss: 13.8718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8615

Learning rate: 0.00018314696123025452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 18.3300	Cost: 39.41s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 13.3349	Cost: 17.14s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 13.4116	Cost: 17.47s
Train Epoch: 76 	Average Loss: 13.8672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8226

Learning rate: 0.00018270805742745614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 18.4621	Cost: 34.15s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 13.4963	Cost: 17.02s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 13.2198	Cost: 17.20s
Train Epoch: 77 	Average Loss: 13.8281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8059

Learning rate: 0.00018226405180208597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 18.5176	Cost: 42.07s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 13.2276	Cost: 13.04s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 13.1636	Cost: 12.53s
Train Epoch: 78 	Average Loss: 13.8042
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8938

Learning rate: 0.00018181497174250233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 18.6595	Cost: 35.46s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 13.7105	Cost: 12.84s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 13.5334	Cost: 19.06s
Train Epoch: 79 	Average Loss: 14.1685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7093

Learning rate: 0.00018136084495007872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 18.5587	Cost: 41.26s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 13.4652	Cost: 10.01s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 13.4092	Cost: 27.71s
Train Epoch: 80 	Average Loss: 13.9647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7666

Learning rate: 0.00018090169943749476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 18.3679	Cost: 45.95s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 13.3313	Cost: 16.43s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 13.1732	Cost: 16.57s
Train Epoch: 81 	Average Loss: 13.7438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8034

Learning rate: 0.00018043756352700846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 18.6603	Cost: 43.47s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 13.1778	Cost: 11.94s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 13.0320	Cost: 18.39s
Train Epoch: 82 	Average Loss: 13.6374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8593

Learning rate: 0.00017996846584870908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 18.6273	Cost: 33.97s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 13.1017	Cost: 9.90s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 12.9883	Cost: 24.38s
Train Epoch: 83 	Average Loss: 13.5893
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0158

Learning rate: 0.000179494435338751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 18.6935	Cost: 38.38s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 13.0621	Cost: 17.45s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 13.0933	Cost: 18.03s
Train Epoch: 84 	Average Loss: 13.5946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0208

Learning rate: 0.00017901550123756904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 18.7496	Cost: 41.40s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 12.9001	Cost: 16.81s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 12.9791	Cost: 16.20s
Train Epoch: 85 	Average Loss: 13.5462
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9258

Learning rate: 0.00017853169308807448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 18.7048	Cost: 41.58s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 13.0547	Cost: 10.07s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 12.8953	Cost: 27.33s
Train Epoch: 86 	Average Loss: 13.5156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9648

Learning rate: 0.00017804304073383296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 18.6815	Cost: 38.25s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 12.8941	Cost: 10.03s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 12.9130	Cost: 26.93s
Train Epoch: 87 	Average Loss: 13.4900
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9729

Learning rate: 0.00017754957431722346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 18.4257	Cost: 45.52s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 12.8125	Cost: 16.98s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 12.8158	Cost: 16.62s
Train Epoch: 88 	Average Loss: 13.4480
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9500

Learning rate: 0.00017705132427757892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 18.5862	Cost: 42.87s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 12.8224	Cost: 16.49s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 12.9141	Cost: 16.50s
Train Epoch: 89 	Average Loss: 13.4573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0869

Learning rate: 0.00017654832134930882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 18.7050	Cost: 41.39s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 13.0045	Cost: 12.04s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 13.0035	Cost: 17.04s
Train Epoch: 90 	Average Loss: 13.4741
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0210

Learning rate: 0.0001760405965600031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 18.6485	Cost: 33.80s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 12.7323	Cost: 10.79s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 12.7929	Cost: 22.34s
Train Epoch: 91 	Average Loss: 13.4035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0174

Learning rate: 0.00017552818122851838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 18.8558	Cost: 38.33s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 12.7591	Cost: 17.14s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 12.7998	Cost: 19.58s
Train Epoch: 92 	Average Loss: 13.3412
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1078

Learning rate: 0.00017501110696304596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 18.7215	Cost: 42.94s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 12.7717	Cost: 15.01s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 12.7268	Cost: 17.87s
Train Epoch: 93 	Average Loss: 13.3060
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1207

Learning rate: 0.0001744894056591622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 18.7600	Cost: 38.59s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 12.7126	Cost: 9.96s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 12.7260	Cost: 24.52s
Train Epoch: 94 	Average Loss: 13.2306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1599

Learning rate: 0.00017396310949786096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 18.7581	Cost: 35.96s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 12.6870	Cost: 10.29s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 12.6191	Cost: 25.97s
Train Epoch: 95 	Average Loss: 13.2082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1745

Learning rate: 0.00017343225094356858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 18.7433	Cost: 48.24s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 12.6419	Cost: 17.01s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 12.7327	Cost: 17.05s
Train Epoch: 96 	Average Loss: 13.2091
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1881

Learning rate: 0.00017289686274214118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 18.8421	Cost: 43.33s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 12.6750	Cost: 16.73s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 12.6354	Cost: 11.61s
Train Epoch: 97 	Average Loss: 13.2167
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1880

Learning rate: 0.00017235697791884494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 18.9684	Cost: 48.90s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 12.4134	Cost: 10.77s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 12.3572	Cost: 16.22s
Train Epoch: 98 	Average Loss: 13.0917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3079

Learning rate: 0.0001718126297763189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 18.7563	Cost: 35.89s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 12.4079	Cost: 12.55s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 12.4015	Cost: 15.38s
Train Epoch: 99 	Average Loss: 13.0271
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2882

Learning rate: 0.00017126385189252056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 18.8354	Cost: 33.17s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 12.3593	Cost: 9.89s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 12.3368	Cost: 27.05s
Train Epoch: 100 	Average Loss: 12.9774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2809

Learning rate: 0.00017071067811865479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 18.7752	Cost: 38.21s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 12.2674	Cost: 17.46s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 12.3850	Cost: 17.19s
Train Epoch: 101 	Average Loss: 12.9187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3297

Learning rate: 0.00017015314257708562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 18.7599	Cost: 37.83s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 12.1251	Cost: 16.73s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 12.1876	Cost: 14.20s
Train Epoch: 102 	Average Loss: 12.8875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4281

Learning rate: 0.00016959127965923145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 18.9670	Cost: 40.02s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 12.1695	Cost: 9.62s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 12.1719	Cost: 16.28s
Train Epoch: 103 	Average Loss: 12.8795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4238

Learning rate: 0.00016902512402344375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 18.9385	Cost: 32.87s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 12.2349	Cost: 10.51s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 12.2083	Cost: 25.32s
Train Epoch: 104 	Average Loss: 12.8228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4551

Learning rate: 0.0001684547105928689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 18.8884	Cost: 36.63s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 12.2073	Cost: 17.01s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 12.1563	Cost: 21.48s
Train Epoch: 105 	Average Loss: 12.7939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4192

Learning rate: 0.00016788007455329423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 19.0352	Cost: 40.16s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 12.1204	Cost: 17.17s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 12.1598	Cost: 16.70s
Train Epoch: 106 	Average Loss: 12.7360
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4785

Learning rate: 0.00016730125135097737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 18.9744	Cost: 35.96s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 11.9366	Cost: 10.39s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 12.0099	Cost: 24.28s
Train Epoch: 107 	Average Loss: 12.6991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5032

Learning rate: 0.00016671827669046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 19.0683	Cost: 43.98s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 11.9356	Cost: 10.23s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 12.0270	Cost: 24.62s
Train Epoch: 108 	Average Loss: 12.6962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4705

Learning rate: 0.0001661311865323652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 19.1222	Cost: 43.50s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 12.1095	Cost: 17.06s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 12.0355	Cost: 16.91s
Train Epoch: 109 	Average Loss: 12.7253
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4977

Learning rate: 0.00016554001709117943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 18.9519	Cost: 46.07s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 11.9147	Cost: 17.16s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 11.9138	Cost: 14.01s
Train Epoch: 110 	Average Loss: 12.6326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4699

Learning rate: 0.00016494480483301838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 19.0300	Cost: 44.36s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 11.8901	Cost: 13.88s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 11.8426	Cost: 11.76s
Train Epoch: 111 	Average Loss: 12.5765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5303

Learning rate: 0.0001643455864733779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 18.8747	Cost: 38.57s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 11.8388	Cost: 9.58s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 11.7224	Cost: 18.59s
Train Epoch: 112 	Average Loss: 12.5453
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6152

Learning rate: 0.000163742398974869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 18.9569	Cost: 34.65s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 11.8492	Cost: 9.91s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 11.8445	Cost: 27.27s
Train Epoch: 113 	Average Loss: 12.4786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6697

Learning rate: 0.00016313527954493778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 19.0922	Cost: 40.63s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 11.8104	Cost: 16.22s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 11.6742	Cost: 18.25s
Train Epoch: 114 	Average Loss: 12.4430
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6636

Learning rate: 0.00016252426563357055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 19.1051	Cost: 41.67s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 11.6745	Cost: 16.41s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 11.6997	Cost: 16.55s
Train Epoch: 115 	Average Loss: 12.3918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7709

Learning rate: 0.0001619093949309834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 18.9216	Cost: 40.26s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 11.6802	Cost: 16.46s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 11.7062	Cost: 12.42s
Train Epoch: 116 	Average Loss: 12.3912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6123

Learning rate: 0.00016129070536529766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 19.2582	Cost: 39.10s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 11.8030	Cost: 9.55s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 11.6312	Cost: 15.52s
Train Epoch: 117 	Average Loss: 12.4627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5998

Learning rate: 0.00016066823510019996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 19.1266	Cost: 32.16s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 11.6158	Cost: 11.05s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 11.5164	Cost: 22.49s
Train Epoch: 118 	Average Loss: 12.4000
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6361

Learning rate: 0.0001600420225325884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 19.0818	Cost: 37.49s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 11.6135	Cost: 14.46s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 11.5146	Cost: 20.75s
Train Epoch: 119 	Average Loss: 12.3011
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7100

Learning rate: 0.00015941210629020385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 19.2590	Cost: 36.87s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 11.6284	Cost: 14.92s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 11.4366	Cost: 22.09s
Train Epoch: 120 	Average Loss: 12.2657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7067

Learning rate: 0.00015877852522924735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 19.2687	Cost: 41.07s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 11.4411	Cost: 10.02s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 11.4512	Cost: 27.50s
Train Epoch: 121 	Average Loss: 12.2846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7956

Learning rate: 0.00015814131843198305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 19.1490	Cost: 36.55s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 11.3980	Cost: 9.95s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 11.5576	Cost: 25.75s
Train Epoch: 122 	Average Loss: 12.2357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7110

Learning rate: 0.00015750052520432787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 19.1805	Cost: 44.64s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 11.4487	Cost: 14.26s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 11.4263	Cost: 20.43s
Train Epoch: 123 	Average Loss: 12.1416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8096

Learning rate: 0.0001568561850734264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 19.2066	Cost: 52.37s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 11.3951	Cost: 16.09s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 11.4765	Cost: 11.39s
Train Epoch: 124 	Average Loss: 12.1004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9015

Learning rate: 0.00015620833778521307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 19.2355	Cost: 41.25s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 11.4335	Cost: 10.38s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 11.3808	Cost: 15.34s
Train Epoch: 125 	Average Loss: 12.0974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8598

Learning rate: 0.00015555702330196023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 19.2913	Cost: 36.60s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 11.3748	Cost: 12.56s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 11.3741	Cost: 13.59s
Train Epoch: 126 	Average Loss: 12.1338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9054

Learning rate: 0.00015490228179981317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 19.3416	Cost: 32.13s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 11.3249	Cost: 9.68s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 11.1304	Cost: 26.78s
Train Epoch: 127 	Average Loss: 12.0935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9271

Learning rate: 0.00015424415366631188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 19.3159	Cost: 37.47s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 11.2735	Cost: 11.30s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 11.1832	Cost: 24.97s
Train Epoch: 128 	Average Loss: 12.0344
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8741

Learning rate: 0.00015358267949789966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 19.2079	Cost: 43.44s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 11.2303	Cost: 16.38s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 11.2068	Cost: 16.45s
Train Epoch: 129 	Average Loss: 12.0176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8963

Learning rate: 0.00015291790009741904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 19.4444	Cost: 40.39s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 11.1465	Cost: 12.12s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 11.2714	Cost: 12.74s
Train Epoch: 130 	Average Loss: 11.9795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9725

Learning rate: 0.00015224985647159487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 19.3588	Cost: 35.47s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 11.0505	Cost: 12.96s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 11.0337	Cost: 19.01s
Train Epoch: 131 	Average Loss: 12.0104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0060

Learning rate: 0.00015157858982850473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 19.4578	Cost: 40.68s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 11.1070	Cost: 9.80s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 11.1656	Cost: 24.26s
Train Epoch: 132 	Average Loss: 11.9220
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8348

Learning rate: 0.0001509041415750371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 19.3346	Cost: 55.55s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 11.1041	Cost: 17.00s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 11.0348	Cost: 14.50s
Train Epoch: 133 	Average Loss: 11.9006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9219

Learning rate: 0.00015022655331433721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 19.2696	Cost: 47.77s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 11.0087	Cost: 13.37s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 11.0013	Cost: 11.81s
Train Epoch: 134 	Average Loss: 11.8304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8946

Learning rate: 0.00014954586684324072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 19.5093	Cost: 41.61s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 11.0241	Cost: 10.77s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 11.0081	Cost: 18.17s
Train Epoch: 135 	Average Loss: 11.7687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0520

Learning rate: 0.00014886212414969547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 19.2946	Cost: 33.70s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 10.9644	Cost: 10.10s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 11.0413	Cost: 27.29s
Train Epoch: 136 	Average Loss: 11.7648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0361

Learning rate: 0.0001481753674101715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 19.4252	Cost: 36.72s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 10.8941	Cost: 14.87s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 10.9136	Cost: 19.58s
Train Epoch: 137 	Average Loss: 11.8083
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0675

Learning rate: 0.00014748563898705943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 19.2653	Cost: 36.24s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 10.9325	Cost: 16.61s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 10.8931	Cost: 16.66s
Train Epoch: 138 	Average Loss: 11.7736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1998

Learning rate: 0.00014679298142605734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 19.4337	Cost: 41.62s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 10.7601	Cost: 13.33s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 10.7162	Cost: 13.29s
Train Epoch: 139 	Average Loss: 11.6322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1206

Learning rate: 0.00014609743745354624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 19.4045	Cost: 38.49s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 10.7386	Cost: 9.59s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 10.7028	Cost: 15.93s
Train Epoch: 140 	Average Loss: 11.5770
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2530

Learning rate: 0.00014539904997395466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 19.4522	Cost: 32.44s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 10.7089	Cost: 9.79s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 10.5659	Cost: 24.40s
Train Epoch: 141 	Average Loss: 11.5466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1787

Learning rate: 0.0001446978620671121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 19.2479	Cost: 35.67s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 10.8281	Cost: 16.90s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 10.5491	Cost: 16.89s
Train Epoch: 142 	Average Loss: 11.5578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2895

Learning rate: 0.0001439939169855915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 19.3314	Cost: 40.87s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 10.6687	Cost: 16.77s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 10.5398	Cost: 15.41s
Train Epoch: 143 	Average Loss: 11.4882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2917

Learning rate: 0.0001432872581520414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 19.3065	Cost: 41.05s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 10.4974	Cost: 9.95s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 10.6783	Cost: 27.87s
Train Epoch: 144 	Average Loss: 11.4673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2095

Learning rate: 0.00014257792915650728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 19.3676	Cost: 39.14s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 10.5377	Cost: 10.27s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 10.8861	Cost: 27.19s
Train Epoch: 145 	Average Loss: 11.5347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2792

Learning rate: 0.0001418659737537428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 19.4099	Cost: 42.69s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 10.8253	Cost: 16.76s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 10.6924	Cost: 16.54s
Train Epoch: 146 	Average Loss: 11.6071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2408

Learning rate: 0.00014115143586051088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 19.3749	Cost: 42.83s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 10.6083	Cost: 16.69s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 10.5021	Cost: 14.44s
Train Epoch: 147 	Average Loss: 11.4833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2187

Learning rate: 0.0001404343595528745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 19.4862	Cost: 42.03s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 10.4690	Cost: 14.24s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 10.4219	Cost: 13.24s
Train Epoch: 148 	Average Loss: 11.3688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3242

Learning rate: 0.00013971478906347806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 19.4849	Cost: 35.10s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 10.4648	Cost: 11.14s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 10.4134	Cost: 17.73s
Train Epoch: 149 	Average Loss: 11.2979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2703

Learning rate: 0.00013899276877881884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 19.5313	Cost: 32.38s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 10.5483	Cost: 9.77s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 10.4455	Cost: 27.07s
Train Epoch: 150 	Average Loss: 11.3292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3773

Learning rate: 0.000138268343236509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 19.6212	Cost: 39.76s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 10.6360	Cost: 16.58s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 10.4838	Cost: 16.64s
Train Epoch: 151 	Average Loss: 11.5043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2562

Learning rate: 0.00013754155712252834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 19.4287	Cost: 41.15s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 10.4795	Cost: 12.24s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 10.5059	Cost: 14.63s
Train Epoch: 152 	Average Loss: 11.4014
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3871

Learning rate: 0.00013681245526846785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 19.3603	Cost: 35.20s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 10.4446	Cost: 13.03s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 10.3968	Cost: 20.21s
Train Epoch: 153 	Average Loss: 11.3344
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3891

Learning rate: 0.00013608108264876422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 19.5201	Cost: 42.59s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 10.4322	Cost: 10.52s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 10.4508	Cost: 25.59s
Train Epoch: 154 	Average Loss: 11.2598
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4800

Learning rate: 0.00013534748437792575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 19.4737	Cost: 43.30s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 10.2887	Cost: 16.73s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 10.3728	Cost: 14.94s
Train Epoch: 155 	Average Loss: 11.1942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4484

Learning rate: 0.00013461170570774932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 19.2967	Cost: 49.05s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 10.3231	Cost: 13.96s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 10.3726	Cost: 13.36s
Train Epoch: 156 	Average Loss: 11.1405
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5316

Learning rate: 0.0001338737920245292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 19.6169	Cost: 57.79s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 10.2183	Cost: 9.77s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 10.3953	Cost: 19.92s
Train Epoch: 157 	Average Loss: 11.1084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4880

Learning rate: 0.00013313378884625713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 19.5220	Cost: 33.04s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 10.3695	Cost: 10.01s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 10.5614	Cost: 25.80s
Train Epoch: 158 	Average Loss: 11.2356
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5334

Learning rate: 0.00013239174181981498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 19.4808	Cost: 36.27s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 10.3455	Cost: 12.14s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 10.4844	Cost: 23.11s
Train Epoch: 159 	Average Loss: 11.2766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5561

Learning rate: 0.00013164769671815865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 19.4503	Cost: 35.14s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 10.4511	Cost: 16.34s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 10.4814	Cost: 16.93s
Train Epoch: 160 	Average Loss: 11.2529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5547

Learning rate: 0.0001309016994374948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 19.6069	Cost: 33.46s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 10.4209	Cost: 16.20s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 10.3711	Cost: 10.52s
Train Epoch: 161 	Average Loss: 11.2165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5802

Learning rate: 0.00013015379599444962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 19.4866	Cost: 39.53s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 10.4979	Cost: 9.82s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 10.4847	Cost: 16.27s
Train Epoch: 162 	Average Loss: 11.2016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4786

Learning rate: 0.00012940403252323043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 19.4824	Cost: 32.56s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 10.4388	Cost: 9.79s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 10.3601	Cost: 25.68s
Train Epoch: 163 	Average Loss: 11.2672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6273

Learning rate: 0.00012865245527277986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 19.6117	Cost: 37.97s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 10.2753	Cost: 17.42s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 10.3578	Cost: 20.74s
Train Epoch: 164 	Average Loss: 11.1942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6336

Learning rate: 0.00012789911060392294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 19.5334	Cost: 44.93s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 10.7671	Cost: 9.80s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 12.5686	Cost: 23.45s
Train Epoch: 165 	Average Loss: 12.1315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4358

Learning rate: 0.00012714404498650745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 19.8301	Cost: 40.37s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 12.0189	Cost: 9.98s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 11.5867	Cost: 27.59s
Train Epoch: 166 	Average Loss: 12.7937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9997

Learning rate: 0.00012638730499653727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 19.5920	Cost: 42.08s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 11.0214	Cost: 16.51s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 10.6362	Cost: 16.52s
Train Epoch: 167 	Average Loss: 11.8003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0835

Learning rate: 0.00012562893731329965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 19.3933	Cost: 43.02s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 10.3091	Cost: 16.35s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 10.0848	Cost: 16.59s
Train Epoch: 168 	Average Loss: 11.1711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2755

Learning rate: 0.00012486898871648546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 19.5179	Cost: 39.52s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 10.1815	Cost: 13.42s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 9.9655	Cost: 12.94s
Train Epoch: 169 	Average Loss: 11.0085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3991

Learning rate: 0.00012410750608330388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 19.7902	Cost: 36.25s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 9.8752	Cost: 12.25s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 9.8309	Cost: 14.59s
Train Epoch: 170 	Average Loss: 10.8283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5116

Learning rate: 0.00012334453638559054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 19.4728	Cost: 31.36s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 9.7979	Cost: 9.94s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 9.7440	Cost: 26.10s
Train Epoch: 171 	Average Loss: 10.7548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6495

Learning rate: 0.00012258012668691037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 19.8981	Cost: 38.82s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 9.8146	Cost: 16.68s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 9.7568	Cost: 18.66s
Train Epoch: 172 	Average Loss: 10.7636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5989

Learning rate: 0.00012181432413965427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 19.7807	Cost: 42.36s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 9.8030	Cost: 16.11s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 9.8050	Cost: 17.72s
Train Epoch: 173 	Average Loss: 10.7240
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5972

Learning rate: 0.0001210471759821306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 19.8263	Cost: 40.72s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 9.7986	Cost: 11.91s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 9.6806	Cost: 18.72s
Train Epoch: 174 	Average Loss: 10.6794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6412

Learning rate: 0.00012027872953565127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 19.7251	Cost: 39.22s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 9.8185	Cost: 10.07s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 9.7216	Cost: 27.70s
Train Epoch: 175 	Average Loss: 10.6675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6782

Learning rate: 0.00011950903220161285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 19.8434	Cost: 42.62s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 9.7387	Cost: 16.69s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 9.7144	Cost: 18.13s
Train Epoch: 176 	Average Loss: 10.6491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6173

Learning rate: 0.00011873813145857249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 19.9054	Cost: 42.84s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 9.7503	Cost: 15.70s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 9.6113	Cost: 11.19s
Train Epoch: 177 	Average Loss: 10.6493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7476

Learning rate: 0.00011796607485931927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 19.8090	Cost: 37.37s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 9.6194	Cost: 12.83s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 9.4733	Cost: 12.99s
Train Epoch: 178 	Average Loss: 10.5061
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8214

Learning rate: 0.00011719291002794096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 19.6293	Cost: 32.05s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 9.6729	Cost: 10.82s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 9.4681	Cost: 23.11s
Train Epoch: 179 	Average Loss: 10.4765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8246

Learning rate: 0.0001164186846568863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 19.6368	Cost: 37.66s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 9.5130	Cost: 16.95s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 9.2934	Cost: 19.79s
Train Epoch: 180 	Average Loss: 10.4268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7583

Learning rate: 0.0001156434465040231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 19.8097	Cost: 46.67s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 9.3282	Cost: 16.64s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 9.5173	Cost: 13.16s
Train Epoch: 181 	Average Loss: 10.3559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8523

Learning rate: 0.00011486724338969234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 20.0273	Cost: 42.21s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 9.6660	Cost: 9.80s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 9.4447	Cost: 22.93s
Train Epoch: 182 	Average Loss: 10.5837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8685

Learning rate: 0.0001140901231937583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 19.7381	Cost: 36.20s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 9.4889	Cost: 10.03s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 9.1533	Cost: 26.81s
Train Epoch: 183 	Average Loss: 10.3826
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8709

Learning rate: 0.00011331213385265528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 19.7429	Cost: 33.85s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 9.1701	Cost: 16.28s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 9.2723	Cost: 17.90s
Train Epoch: 184 	Average Loss: 10.2779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9957

Learning rate: 0.00011253332335643047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 19.8232	Cost: 35.61s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 9.1791	Cost: 16.88s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 9.0359	Cost: 16.84s
Train Epoch: 185 	Average Loss: 10.2976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9480

Learning rate: 0.0001117537397457838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 19.8383	Cost: 33.90s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 9.1392	Cost: 16.56s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 8.9245	Cost: 16.75s
Train Epoch: 186 	Average Loss: 10.1821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8550

Learning rate: 0.00011097343110910456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 19.9016	Cost: 35.06s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 9.1682	Cost: 16.63s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 9.4544	Cost: 17.08s
Train Epoch: 187 	Average Loss: 10.2597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0106

Learning rate: 0.00011019244557950502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 19.9780	Cost: 36.02s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 9.3434	Cost: 17.06s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 9.4831	Cost: 16.90s
Train Epoch: 188 	Average Loss: 10.4569
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8954

Learning rate: 0.00010941083133185145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 20.1519	Cost: 35.73s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 10.0055	Cost: 16.98s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 9.7527	Cost: 16.82s
Train Epoch: 189 	Average Loss: 10.9429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6239

Learning rate: 0.00010862863657979236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 19.9756	Cost: 37.09s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 9.6884	Cost: 16.95s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 9.3402	Cost: 16.91s
Train Epoch: 190 	Average Loss: 10.5858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8544

Learning rate: 0.00010784590957278452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 19.7533	Cost: 38.03s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 9.3641	Cost: 16.98s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 9.1637	Cost: 16.99s
Train Epoch: 191 	Average Loss: 10.3336
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8721

Learning rate: 0.00010706269859311669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 19.9530	Cost: 37.65s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 9.0949	Cost: 16.68s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 9.1309	Cost: 16.56s
Train Epoch: 192 	Average Loss: 10.2235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9901

Learning rate: 0.00010627905195293137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 19.8893	Cost: 36.53s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 9.2614	Cost: 15.31s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 9.0599	Cost: 16.58s
Train Epoch: 193 	Average Loss: 10.2298
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8743

Learning rate: 0.00010549501799124461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 19.8529	Cost: 37.19s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 9.0319	Cost: 16.78s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 8.8286	Cost: 16.54s
Train Epoch: 194 	Average Loss: 10.0256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8984

Learning rate: 0.00010471064507096429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 19.8229	Cost: 35.78s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 8.8939	Cost: 15.68s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 8.7337	Cost: 18.23s
Train Epoch: 195 	Average Loss: 9.9053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9369

Learning rate: 0.00010392598157590689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 19.8194	Cost: 39.60s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 8.9640	Cost: 16.41s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 8.8955	Cost: 16.57s
Train Epoch: 196 	Average Loss: 9.9276
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9978

Learning rate: 0.00010314107590781285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 19.8892	Cost: 40.26s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 8.9270	Cost: 14.28s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 8.7431	Cost: 17.09s
Train Epoch: 197 	Average Loss: 9.8393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0698

Learning rate: 0.00010235597648336105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 19.8776	Cost: 51.70s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 8.9165	Cost: 16.55s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 9.0204	Cost: 16.70s
Train Epoch: 198 	Average Loss: 9.9113
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0485

Learning rate: 0.0001015707317311821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 20.0486	Cost: 38.96s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 8.7992	Cost: 16.62s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 8.5760	Cost: 16.50s
Train Epoch: 199 	Average Loss: 9.8407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0852

Learning rate: 0.00010078539008887115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 19.9112	Cost: 37.97s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 8.6182	Cost: 15.23s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 8.6334	Cost: 16.50s
Train Epoch: 200 	Average Loss: 9.7334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1716

Learning rate: 0.00010000000000000002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 19.7630	Cost: 36.16s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 8.5189	Cost: 16.63s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 8.6093	Cost: 16.38s
Train Epoch: 201 	Average Loss: 9.7130
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2136

Learning rate: 9.92146099111289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 19.7680	Cost: 35.29s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 8.7371	Cost: 17.03s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 8.8173	Cost: 16.62s
Train Epoch: 202 	Average Loss: 9.7673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0620

Learning rate: 9.842926826881797e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 19.9434	Cost: 35.40s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 8.7928	Cost: 16.65s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 8.6578	Cost: 16.41s
Train Epoch: 203 	Average Loss: 9.7223
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2177

Learning rate: 9.7644023516639e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 19.8007	Cost: 35.41s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 8.7122	Cost: 16.23s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 8.5710	Cost: 17.12s
Train Epoch: 204 	Average Loss: 9.6158
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1678

Learning rate: 9.68589240921872e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 19.7261	Cost: 38.69s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 8.7991	Cost: 16.84s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 9.0234	Cost: 14.51s
Train Epoch: 205 	Average Loss: 9.8936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1150

Learning rate: 9.607401842409317e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 19.9098	Cost: 37.31s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 8.8450	Cost: 16.96s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 8.8417	Cost: 14.84s
Train Epoch: 206 	Average Loss: 9.8679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0357

Learning rate: 9.528935492903578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 19.9263	Cost: 36.75s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 8.6336	Cost: 15.70s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 8.9570	Cost: 12.81s
Train Epoch: 207 	Average Loss: 9.6687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0328

Learning rate: 9.450498200875547e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 20.1628	Cost: 36.50s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 11.8003	Cost: 13.99s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 11.4283	Cost: 12.57s
Train Epoch: 208 	Average Loss: 12.0045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7941

Learning rate: 9.372094804706868e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 19.9207	Cost: 36.32s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 10.7009	Cost: 16.22s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 10.1017	Cost: 10.60s
Train Epoch: 209 	Average Loss: 11.5296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8070

Learning rate: 9.293730140688336e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 19.9057	Cost: 40.50s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 9.8207	Cost: 9.62s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 9.3906	Cost: 17.50s
Train Epoch: 210 	Average Loss: 10.7280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9501

Learning rate: 9.215409042721555e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 20.3960	Cost: 36.59s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 9.2480	Cost: 13.02s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 8.7716	Cost: 13.51s
Train Epoch: 211 	Average Loss: 10.1329
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1162

Learning rate: 9.13713634202077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 20.4873	Cost: 32.40s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 8.7350	Cost: 9.73s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 8.4742	Cost: 19.42s
Train Epoch: 212 	Average Loss: 9.7807
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1840

Learning rate: 9.058916866814858e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 20.3536	Cost: 33.98s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 8.6241	Cost: 9.91s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 8.3869	Cost: 24.99s
Train Epoch: 213 	Average Loss: 9.6363
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3210

Learning rate: 8.9807554420495e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 20.1027	Cost: 35.56s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 8.4704	Cost: 11.28s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 8.3062	Cost: 21.75s
Train Epoch: 214 	Average Loss: 9.5201
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1759

Learning rate: 8.902656889089548e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 20.1363	Cost: 36.38s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 8.4482	Cost: 16.55s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 8.5193	Cost: 16.68s
Train Epoch: 215 	Average Loss: 9.5467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2165

Learning rate: 8.824626025421624e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 20.1747	Cost: 36.75s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 8.6566	Cost: 16.39s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 8.4342	Cost: 16.77s
Train Epoch: 216 	Average Loss: 9.7106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5260

Learning rate: 8.746667664356959e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 20.0687	Cost: 36.21s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 8.3207	Cost: 16.85s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 8.6178	Cost: 17.22s
Train Epoch: 217 	Average Loss: 9.5123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2846

Learning rate: 8.668786614734478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 20.2553	Cost: 37.56s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 9.3198	Cost: 14.40s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 8.8516	Cost: 18.22s
Train Epoch: 218 	Average Loss: 10.1522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2890

Learning rate: 8.590987680624175e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 20.7550	Cost: 46.47s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 8.7680	Cost: 13.30s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 8.4829	Cost: 18.60s
Train Epoch: 219 	Average Loss: 9.8206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4151

Learning rate: 8.51327566103077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 20.5236	Cost: 45.00s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 8.2863	Cost: 14.03s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 8.1341	Cost: 16.59s
Train Epoch: 220 	Average Loss: 9.4969
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4333

Learning rate: 8.435655349597692e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 20.2587	Cost: 40.35s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 8.1851	Cost: 15.52s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 7.8932	Cost: 17.29s
Train Epoch: 221 	Average Loss: 9.2294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5077

Learning rate: 8.35813153431137e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 20.2953	Cost: 40.84s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 7.9301	Cost: 16.85s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 8.5670	Cost: 16.70s
Train Epoch: 222 	Average Loss: 9.2955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3918

Learning rate: 8.280708997205904e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 20.3908	Cost: 38.67s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 8.5939	Cost: 16.65s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 8.4083	Cost: 16.48s
Train Epoch: 223 	Average Loss: 9.6478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4475

Learning rate: 8.203392514068074e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 20.1409	Cost: 37.23s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 8.8289	Cost: 16.84s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 8.6878	Cost: 16.41s
Train Epoch: 224 	Average Loss: 9.7406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4287

Learning rate: 8.126186854142755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 20.7340	Cost: 36.03s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 8.2821	Cost: 14.50s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 8.2703	Cost: 16.29s
Train Epoch: 225 	Average Loss: 9.4767
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4403

Learning rate: 8.049096779838719e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 20.0178	Cost: 37.19s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 8.4195	Cost: 15.45s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 8.0001	Cost: 16.76s
Train Epoch: 226 	Average Loss: 9.3735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5241

Learning rate: 7.972127046434877e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 20.4326	Cost: 36.58s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 7.9671	Cost: 15.21s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 7.7379	Cost: 16.86s
Train Epoch: 227 	Average Loss: 9.1343
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5590

Learning rate: 7.895282401786947e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 20.4581	Cost: 35.74s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 7.9013	Cost: 14.19s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 7.7176	Cost: 16.94s
Train Epoch: 228 	Average Loss: 8.9855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6256

Learning rate: 7.818567586034578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 20.1635	Cost: 36.91s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 7.6666	Cost: 16.83s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 7.7420	Cost: 17.24s
Train Epoch: 229 	Average Loss: 8.9112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6229

Learning rate: 7.741987331308968e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 20.2266	Cost: 37.15s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 7.7519	Cost: 16.86s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 7.4643	Cost: 16.56s
Train Epoch: 230 	Average Loss: 8.8091
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6868

Learning rate: 7.665546361440945e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 20.4728	Cost: 35.93s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 7.6412	Cost: 15.44s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 7.6294	Cost: 17.48s
Train Epoch: 231 	Average Loss: 8.7798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7226

Learning rate: 7.589249391669613e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 20.2507	Cost: 38.70s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 7.9017	Cost: 16.40s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 7.6704	Cost: 16.31s
Train Epoch: 232 	Average Loss: 8.9394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6903

Learning rate: 7.513101128351452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 20.1403	Cost: 41.07s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 7.6271	Cost: 16.24s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 7.3967	Cost: 16.48s
Train Epoch: 233 	Average Loss: 8.7064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6203

Learning rate: 7.437106268670034e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 20.5103	Cost: 47.72s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 7.4987	Cost: 16.65s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 7.1911	Cost: 16.48s
Train Epoch: 234 	Average Loss: 8.5394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8250

Learning rate: 7.361269500346273e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 20.4022	Cost: 39.83s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 7.2991	Cost: 16.48s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 7.2009	Cost: 16.57s
Train Epoch: 235 	Average Loss: 8.5151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7213

Learning rate: 7.28559550134926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 20.3874	Cost: 36.80s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 7.3108	Cost: 16.91s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 7.0376	Cost: 16.65s
Train Epoch: 236 	Average Loss: 8.4781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7140

Learning rate: 7.210088939607711e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 20.3812	Cost: 38.69s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 7.1958	Cost: 16.49s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 6.9554	Cost: 16.33s
Train Epoch: 237 	Average Loss: 8.3557
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6871

Learning rate: 7.13475447272202e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 20.3652	Cost: 36.69s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 7.0919	Cost: 16.47s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 6.9378	Cost: 16.41s
Train Epoch: 238 	Average Loss: 8.2970
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8609

Learning rate: 7.059596747676965e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 20.3867	Cost: 34.25s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 7.7356	Cost: 16.38s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 7.3843	Cost: 16.51s
Train Epoch: 239 	Average Loss: 8.6522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8774

Learning rate: 6.984620400555048e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 20.2790	Cost: 36.78s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 7.4397	Cost: 15.78s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 7.0486	Cost: 17.16s
Train Epoch: 240 	Average Loss: 8.5763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7732

Learning rate: 6.909830056250531e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 20.3351	Cost: 37.07s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 7.1503	Cost: 15.07s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 6.8527	Cost: 17.80s
Train Epoch: 241 	Average Loss: 8.3426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9245

Learning rate: 6.835230328184141e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 20.3745	Cost: 36.39s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 7.0315	Cost: 16.46s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 7.2313	Cost: 16.43s
Train Epoch: 242 	Average Loss: 8.2585
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9891

Learning rate: 6.760825818018508e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 20.5140	Cost: 39.17s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 7.5082	Cost: 17.63s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 7.0907	Cost: 16.90s
Train Epoch: 243 	Average Loss: 8.5365
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9241

Learning rate: 6.686621115374292e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 20.4641	Cost: 42.28s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 7.1643	Cost: 16.69s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 6.9350	Cost: 16.43s
Train Epoch: 244 	Average Loss: 8.3267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8808

Learning rate: 6.61262079754709e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 20.2915	Cost: 52.54s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 6.9429	Cost: 16.07s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 6.7756	Cost: 15.08s
Train Epoch: 245 	Average Loss: 8.1471
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9410

Learning rate: 6.538829429225073e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 20.4554	Cost: 45.88s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 7.3174	Cost: 14.29s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 7.4980	Cost: 16.87s
Train Epoch: 246 	Average Loss: 8.5822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9192

Learning rate: 6.465251562207432e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 20.3386	Cost: 43.62s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 7.3821	Cost: 13.33s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 7.0703	Cost: 16.52s
Train Epoch: 247 	Average Loss: 8.5922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0562

Learning rate: 6.391891735123586e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 20.1996	Cost: 38.94s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 6.9923	Cost: 15.98s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 6.7272	Cost: 16.53s
Train Epoch: 248 	Average Loss: 8.2145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8022

Learning rate: 6.318754473153225e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 20.1944	Cost: 38.48s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 6.9485	Cost: 15.82s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 6.8388	Cost: 17.21s
Train Epoch: 249 	Average Loss: 8.1267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1080

Learning rate: 6.245844287747173e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 20.4394	Cost: 38.68s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 6.9474	Cost: 14.53s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 6.7963	Cost: 16.03s
Train Epoch: 250 	Average Loss: 8.1265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8951

Learning rate: 6.173165676349108e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 20.3744	Cost: 37.18s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 6.9922	Cost: 16.22s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 6.7437	Cost: 16.44s
Train Epoch: 251 	Average Loss: 8.0976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8877

Learning rate: 6.10072312211812e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 20.4590	Cost: 36.73s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 6.7579	Cost: 14.41s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 6.6987	Cost: 16.12s
Train Epoch: 252 	Average Loss: 7.9977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1603

Learning rate: 6.0285210936521955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 20.4673	Cost: 37.61s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 6.9084	Cost: 14.58s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 6.5948	Cost: 16.61s
Train Epoch: 253 	Average Loss: 8.0062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1139

Learning rate: 5.956564044712553e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 20.7271	Cost: 36.17s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 6.7365	Cost: 15.26s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 6.7816	Cost: 16.48s
Train Epoch: 254 	Average Loss: 8.0087
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0651

Learning rate: 5.8848564139489155e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 20.4254	Cost: 35.44s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 6.7117	Cost: 13.88s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 6.4740	Cost: 16.50s
Train Epoch: 255 	Average Loss: 7.9780
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0601

Learning rate: 5.813402624625721e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 20.5182	Cost: 35.75s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 6.7801	Cost: 16.56s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 6.4216	Cost: 16.71s
Train Epoch: 256 	Average Loss: 7.8351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0556

Learning rate: 5.742207084349277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 20.4191	Cost: 36.58s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 6.4851	Cost: 16.89s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 6.3426	Cost: 16.56s
Train Epoch: 257 	Average Loss: 7.7831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9984

Learning rate: 5.6712741847958634e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 20.5220	Cost: 35.46s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 6.3174	Cost: 17.03s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 6.2464	Cost: 17.26s
Train Epoch: 258 	Average Loss: 7.6850
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1287

Learning rate: 5.600608301440851e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 20.4855	Cost: 41.77s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 6.3278	Cost: 16.16s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 6.1929	Cost: 16.64s
Train Epoch: 259 	Average Loss: 7.6236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1125

Learning rate: 5.5302137932887924e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 20.3437	Cost: 43.63s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 6.4467	Cost: 16.79s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 6.1819	Cost: 16.45s
Train Epoch: 260 	Average Loss: 7.6689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0584

Learning rate: 5.460095002604535e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 20.3489	Cost: 42.62s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 6.2904	Cost: 16.58s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 6.1178	Cost: 16.63s
Train Epoch: 261 	Average Loss: 7.5801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1843

Learning rate: 5.390256254645381e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 20.4008	Cost: 41.20s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 6.2757	Cost: 16.55s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 6.1093	Cost: 16.44s
Train Epoch: 262 	Average Loss: 7.5261
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1357

Learning rate: 5.3207018573942705e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 20.6221	Cost: 38.91s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 6.2771	Cost: 16.46s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 6.1024	Cost: 15.96s
Train Epoch: 263 	Average Loss: 7.5628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0122

Learning rate: 5.251436101294054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 20.4646	Cost: 39.48s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 6.3142	Cost: 16.66s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 6.0783	Cost: 16.96s
Train Epoch: 264 	Average Loss: 7.5993
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2153

Learning rate: 5.1824632589828485e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 20.4203	Cost: 36.72s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 6.0326	Cost: 16.86s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 5.9672	Cost: 16.93s
Train Epoch: 265 	Average Loss: 7.4958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1095

Learning rate: 5.1137875850304516e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 20.4876	Cost: 36.61s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 6.0306	Cost: 16.89s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 5.8935	Cost: 16.87s
Train Epoch: 266 	Average Loss: 7.4264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1649

Learning rate: 5.045413315675926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 20.3901	Cost: 36.23s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 6.0730	Cost: 15.26s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 6.1577	Cost: 13.21s
Train Epoch: 267 	Average Loss: 7.4571
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1066

Learning rate: 4.977344668566277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 20.6309	Cost: 36.46s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 6.2170	Cost: 14.68s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 6.0982	Cost: 13.05s
Train Epoch: 268 	Average Loss: 7.4993
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2701

Learning rate: 4.909585842496289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 20.6670	Cost: 35.39s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 6.2913	Cost: 15.56s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 6.3271	Cost: 9.52s
Train Epoch: 269 	Average Loss: 7.5766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3732

Learning rate: 4.842141017149528e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 20.5321	Cost: 38.38s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 6.6091	Cost: 9.83s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 6.2229	Cost: 16.51s
Train Epoch: 270 	Average Loss: 7.8084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2485

Learning rate: 4.775014352840514e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 20.4720	Cost: 36.12s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 6.2776	Cost: 12.80s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 7.1257	Cost: 12.66s
Train Epoch: 271 	Average Loss: 7.7198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2612

Learning rate: 4.708209990258097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 20.7804	Cost: 32.64s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 7.1900	Cost: 9.99s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 6.6737	Cost: 19.52s
Train Epoch: 272 	Average Loss: 8.2973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2931

Learning rate: 4.641732050210033e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 20.5200	Cost: 32.93s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 6.5476	Cost: 10.02s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 6.2013	Cost: 23.60s
Train Epoch: 273 	Average Loss: 7.7089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2530

Learning rate: 4.575584633368813e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 20.6470	Cost: 35.77s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 6.3171	Cost: 13.49s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 6.1173	Cost: 16.33s
Train Epoch: 274 	Average Loss: 7.5626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3282

Learning rate: 4.509771820018683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 20.6837	Cost: 35.89s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 6.3533	Cost: 16.40s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 6.9033	Cost: 16.62s
Train Epoch: 275 	Average Loss: 7.6698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3068

Learning rate: 4.4442976698039786e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 20.5435	Cost: 37.09s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 6.9406	Cost: 16.93s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 6.4268	Cost: 16.63s
Train Epoch: 276 	Average Loss: 8.1871
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4820

Learning rate: 4.379166221478695e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 20.6747	Cost: 37.72s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 6.5716	Cost: 16.58s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 6.1876	Cost: 17.23s
Train Epoch: 277 	Average Loss: 7.7880
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5185

Learning rate: 4.3143814926573614e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 20.8873	Cost: 37.02s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 6.2897	Cost: 16.23s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 5.8085	Cost: 16.59s
Train Epoch: 278 	Average Loss: 7.5001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3481

Learning rate: 4.249947479567216e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 20.6574	Cost: 44.21s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 5.8923	Cost: 15.98s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 5.5766	Cost: 16.39s
Train Epoch: 279 	Average Loss: 7.2183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4357

Learning rate: 4.1858681568016955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 20.7971	Cost: 44.50s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 5.8424	Cost: 14.64s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 5.6793	Cost: 16.43s
Train Epoch: 280 	Average Loss: 7.1592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4461

Learning rate: 4.122147477075271e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 20.6056	Cost: 53.58s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 5.8931	Cost: 16.73s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 5.6846	Cost: 13.47s
Train Epoch: 281 	Average Loss: 7.1982
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6115

Learning rate: 4.058789370979617e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 20.7314	Cost: 41.40s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 5.6800	Cost: 16.52s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 5.5133	Cost: 16.05s
Train Epoch: 282 	Average Loss: 7.0393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3184

Learning rate: 3.995797746741162e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 20.4552	Cost: 41.26s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 5.5653	Cost: 16.39s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 5.5941	Cost: 16.56s
Train Epoch: 283 	Average Loss: 6.9050
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5042

Learning rate: 3.933176489980003e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 20.7973	Cost: 43.73s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 11.7454	Cost: 16.35s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 11.4039	Cost: 16.32s
Train Epoch: 284 	Average Loss: 11.5139
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3985

Learning rate: 3.8709294634702356e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 21.2164	Cost: 39.87s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 10.6212	Cost: 16.43s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 9.8356	Cost: 16.53s
Train Epoch: 285 	Average Loss: 11.5504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8314

Learning rate: 3.809060506901661e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 21.1163	Cost: 37.04s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 9.3981	Cost: 16.52s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 8.7551	Cost: 17.23s
Train Epoch: 286 	Average Loss: 10.3565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0288

Learning rate: 3.747573436642949e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 20.6965	Cost: 36.20s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 8.4569	Cost: 13.92s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 7.9302	Cost: 16.79s
Train Epoch: 287 	Average Loss: 9.5717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0464

Learning rate: 3.686472045506224e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 20.9225	Cost: 35.51s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 8.0476	Cost: 16.54s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 7.6375	Cost: 16.56s
Train Epoch: 288 	Average Loss: 9.0862
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1630

Learning rate: 3.625760102513104e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 20.6286	Cost: 35.97s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 7.5357	Cost: 13.98s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 7.2709	Cost: 16.85s
Train Epoch: 289 	Average Loss: 8.7375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3920

Learning rate: 3.5654413526622126e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 20.5180	Cost: 35.96s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 7.3258	Cost: 15.75s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 7.0030	Cost: 16.38s
Train Epoch: 290 	Average Loss: 8.4886
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4599

Learning rate: 3.505519516698166e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 20.7431	Cost: 36.61s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 7.1929	Cost: 14.50s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 6.6999	Cost: 16.75s
Train Epoch: 291 	Average Loss: 8.3056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2838

Learning rate: 3.445998290882063e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 20.5744	Cost: 35.47s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 6.8701	Cost: 16.64s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 6.7931	Cost: 16.65s
Train Epoch: 292 	Average Loss: 8.0966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1120

Learning rate: 3.386881346763484e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 20.5737	Cost: 35.48s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 6.8109	Cost: 17.44s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 6.5599	Cost: 16.65s
Train Epoch: 293 	Average Loss: 8.0155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2295

Learning rate: 3.328172330954006e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 20.7002	Cost: 38.06s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 6.6175	Cost: 16.89s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 6.2295	Cost: 16.92s
Train Epoch: 294 	Average Loss: 7.8459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3218

Learning rate: 3.269874864902267e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 20.5064	Cost: 44.35s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 6.4870	Cost: 16.71s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 6.1346	Cost: 16.51s
Train Epoch: 295 	Average Loss: 7.6836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5670

Learning rate: 3.2119925446705836e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 20.4656	Cost: 47.79s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 6.2228	Cost: 14.42s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 6.1070	Cost: 16.71s
Train Epoch: 296 	Average Loss: 7.5235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5401

Learning rate: 3.1545289407131144e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 20.5728	Cost: 47.06s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 6.3289	Cost: 16.15s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 6.2747	Cost: 16.46s
Train Epoch: 297 	Average Loss: 7.5916
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2788

Learning rate: 3.09748759765563e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 20.5837	Cost: 40.49s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 6.2447	Cost: 14.89s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 6.0182	Cost: 17.23s
Train Epoch: 298 	Average Loss: 7.6001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3369

Learning rate: 3.0408720340768585e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 20.6434	Cost: 36.99s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 6.2207	Cost: 14.95s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 5.8792	Cost: 16.84s
Train Epoch: 299 	Average Loss: 7.3828
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2562

Learning rate: 2.9846857422914446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 20.4323	Cost: 36.57s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 6.0083	Cost: 16.35s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 5.7542	Cost: 16.55s
Train Epoch: 300 	Average Loss: 7.2731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2356

Learning rate: 2.9289321881345268e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 20.7446	Cost: 35.58s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 5.8853	Cost: 14.14s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 5.5801	Cost: 16.83s
Train Epoch: 301 	Average Loss: 7.1927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4590

Learning rate: 2.8736148107479478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 20.5293	Cost: 39.37s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 5.7548	Cost: 16.38s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 5.4818	Cost: 16.48s
Train Epoch: 302 	Average Loss: 7.1115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3046

Learning rate: 2.8187370223681142e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 20.5096	Cost: 36.84s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 5.6454	Cost: 16.53s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 5.4945	Cost: 16.17s
Train Epoch: 303 	Average Loss: 7.0493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4013

Learning rate: 2.764302208115509e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 20.4961	Cost: 36.38s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 5.5487	Cost: 16.62s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 5.4152	Cost: 16.67s
Train Epoch: 304 	Average Loss: 6.9892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5322

Learning rate: 2.710313725785888e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 20.6618	Cost: 35.31s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 5.6311	Cost: 16.86s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 5.2752	Cost: 16.54s
Train Epoch: 305 	Average Loss: 6.9818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4252

Learning rate: 2.6567749056431446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 20.5640	Cost: 35.78s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 5.5190	Cost: 14.15s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 5.2845	Cost: 18.94s
Train Epoch: 306 	Average Loss: 6.8908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4857

Learning rate: 2.6036890502139035e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 20.5645	Cost: 36.94s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 5.6123	Cost: 15.70s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 5.2592	Cost: 17.88s
Train Epoch: 307 	Average Loss: 6.8561
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5132

Learning rate: 2.55105943408378e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 20.6744	Cost: 35.42s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 5.5469	Cost: 15.48s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 5.3070	Cost: 18.13s
Train Epoch: 308 	Average Loss: 6.8191
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4801

Learning rate: 2.4988893036954053e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 20.6554	Cost: 36.82s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 5.6108	Cost: 14.20s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 5.3794	Cost: 19.02s
Train Epoch: 309 	Average Loss: 6.9463
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5383

Learning rate: 2.4471818771481658e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 20.7333	Cost: 36.80s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 5.6262	Cost: 16.12s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 5.4597	Cost: 16.52s
Train Epoch: 310 	Average Loss: 6.9292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5044

Learning rate: 2.3959403439996917e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 20.6882	Cost: 39.33s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 5.4852	Cost: 13.59s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 5.2907	Cost: 18.67s
Train Epoch: 311 	Average Loss: 6.8426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6360

Learning rate: 2.345167865069121e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 20.7434	Cost: 39.82s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 5.3666	Cost: 16.73s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 5.0896	Cost: 16.56s
Train Epoch: 312 	Average Loss: 6.7451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6296

Learning rate: 2.2948675722421096e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 20.7380	Cost: 46.00s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 5.3757	Cost: 16.29s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 5.1481	Cost: 16.76s
Train Epoch: 313 	Average Loss: 6.6783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4861

Learning rate: 2.2450425682776575e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 20.6341	Cost: 37.07s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 5.4808	Cost: 16.52s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 5.1922	Cost: 16.19s
Train Epoch: 314 	Average Loss: 6.6464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5906

Learning rate: 2.1956959266167054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 20.6458	Cost: 40.37s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 5.2231	Cost: 16.17s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 5.0234	Cost: 16.41s
Train Epoch: 315 	Average Loss: 6.6053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5426

Learning rate: 2.1468306911925506e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 20.4327	Cost: 37.03s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 5.2665	Cost: 16.60s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 5.0143	Cost: 16.67s
Train Epoch: 316 	Average Loss: 6.5383
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3965

Learning rate: 2.098449876243097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 20.5710	Cost: 36.35s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 5.2751	Cost: 16.93s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 4.8871	Cost: 16.13s
Train Epoch: 317 	Average Loss: 6.5323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7202

Learning rate: 2.050556466124901e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 20.7016	Cost: 37.09s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 5.2139	Cost: 16.97s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 4.8974	Cost: 16.92s
Train Epoch: 318 	Average Loss: 6.4854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6841

Learning rate: 2.0031534151290953e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 20.6877	Cost: 36.83s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 5.1203	Cost: 16.54s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 4.8859	Cost: 16.63s
Train Epoch: 319 	Average Loss: 6.4826
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8906

Learning rate: 1.9562436472991562e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 20.5891	Cost: 37.89s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 5.1259	Cost: 16.86s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 4.9051	Cost: 16.45s
Train Epoch: 320 	Average Loss: 6.4234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6234

Learning rate: 1.9098300562505276e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 20.5259	Cost: 37.98s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 5.1807	Cost: 16.33s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 4.8697	Cost: 16.70s
Train Epoch: 321 	Average Loss: 6.4224
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7436

Learning rate: 1.863915504992132e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 20.6772	Cost: 36.19s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 4.9826	Cost: 16.39s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 4.7782	Cost: 16.48s
Train Epoch: 322 	Average Loss: 6.4064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7020

Learning rate: 1.8185028257497683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 20.8334	Cost: 35.19s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 5.0383	Cost: 16.11s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 4.6848	Cost: 16.69s
Train Epoch: 323 	Average Loss: 6.3796
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6240

Learning rate: 1.7735948197914044e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 20.8031	Cost: 38.33s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 4.9575	Cost: 15.36s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 4.7096	Cost: 19.01s
Train Epoch: 324 	Average Loss: 6.3667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6584

Learning rate: 1.729194257254384e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 20.9884	Cost: 38.52s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 5.1484	Cost: 13.74s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 4.9778	Cost: 20.10s
Train Epoch: 325 	Average Loss: 6.5142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7123

Learning rate: 1.685303876974551e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 20.8168	Cost: 37.94s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 5.1840	Cost: 14.41s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 4.7725	Cost: 17.60s
Train Epoch: 326 	Average Loss: 6.4302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7444

Learning rate: 1.6419263863173007e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 20.7689	Cost: 41.28s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 5.1416	Cost: 15.82s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 4.9342	Cost: 16.51s
Train Epoch: 327 	Average Loss: 6.4505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6105

Learning rate: 1.599064461010582e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 20.7222	Cost: 42.31s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 5.0815	Cost: 15.76s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 4.7372	Cost: 16.61s
Train Epoch: 328 	Average Loss: 6.4154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7363

Learning rate: 1.5567207449798525e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 20.8550	Cost: 33.02s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 4.8991	Cost: 9.76s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 4.6419	Cost: 14.11s
Train Epoch: 329 	Average Loss: 6.3350
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9615

Learning rate: 1.5148978501849652e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 20.9538	Cost: 34.30s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 4.9696	Cost: 10.00s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 4.6643	Cost: 14.41s
Train Epoch: 330 	Average Loss: 6.2831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7142

Learning rate: 1.4735983564590815e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 20.7237	Cost: 34.40s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 4.8667	Cost: 9.72s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 4.5971	Cost: 13.79s
Train Epoch: 331 	Average Loss: 6.2295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7261

Learning rate: 1.4328248113495055e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 20.7744	Cost: 33.48s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 4.8192	Cost: 9.80s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 4.6434	Cost: 13.59s
Train Epoch: 332 	Average Loss: 6.2373
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8036

Learning rate: 1.3925797299605635e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 20.7615	Cost: 33.97s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 4.7125	Cost: 9.57s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 4.6602	Cost: 15.10s
Train Epoch: 333 	Average Loss: 6.1953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7118

Learning rate: 1.3528655947984512e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 20.8049	Cost: 34.60s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 4.8120	Cost: 9.57s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 4.5737	Cost: 16.01s
Train Epoch: 334 	Average Loss: 6.1687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0008

Learning rate: 1.3136848556180878e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 20.9423	Cost: 45.35s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 4.7377	Cost: 12.06s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 4.5322	Cost: 21.38s
Train Epoch: 335 	Average Loss: 6.1599
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6869

Learning rate: 1.2750399292720314e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 20.7747	Cost: 43.24s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 4.7098	Cost: 16.62s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 4.4570	Cost: 16.16s
Train Epoch: 336 	Average Loss: 6.1032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6791

Learning rate: 1.2369331995613651e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 20.6501	Cost: 40.31s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 4.6836	Cost: 17.14s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 4.5157	Cost: 16.77s
Train Epoch: 337 	Average Loss: 6.0874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7347

Learning rate: 1.1993670170886837e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 20.8734	Cost: 44.05s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 4.6446	Cost: 16.98s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 4.5755	Cost: 16.83s
Train Epoch: 338 	Average Loss: 6.0809
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7489

Learning rate: 1.1623436991130663e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 21.0901	Cost: 43.53s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 4.6829	Cost: 16.87s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 4.4680	Cost: 13.62s
Train Epoch: 339 	Average Loss: 6.1049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8783

Learning rate: 1.1258655294071704e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 20.7821	Cost: 40.42s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 4.6011	Cost: 14.06s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 4.5026	Cost: 12.73s
Train Epoch: 340 	Average Loss: 6.0662
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7597

Learning rate: 1.089934758116323e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 20.7452	Cost: 42.66s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 4.6025	Cost: 15.69s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 4.3901	Cost: 10.98s
Train Epoch: 341 	Average Loss: 6.0522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7811

Learning rate: 1.054553601619753e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 20.7975	Cost: 37.24s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 4.5396	Cost: 9.60s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 4.4401	Cost: 20.41s
Train Epoch: 342 	Average Loss: 6.0140
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8910

Learning rate: 1.0197242423938455e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 20.7313	Cost: 35.27s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 4.6070	Cost: 11.11s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 4.3992	Cost: 22.11s
Train Epoch: 343 	Average Loss: 6.0242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8231

Learning rate: 9.854488288775428e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 20.7111	Cost: 36.81s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 4.5319	Cost: 9.90s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 4.3281	Cost: 26.81s
Train Epoch: 344 	Average Loss: 5.9770
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9651

Learning rate: 9.517294753398073e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 20.9069	Cost: 45.28s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 4.5592	Cost: 16.48s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 4.4199	Cost: 16.55s
Train Epoch: 345 	Average Loss: 5.9962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9082

Learning rate: 9.185682617491872e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 20.6617	Cost: 49.11s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 4.6348	Cost: 16.81s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 4.3290	Cost: 16.20s
Train Epoch: 346 	Average Loss: 5.9797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8797

Learning rate: 8.859672336455501e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 20.8763	Cost: 40.85s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 4.5184	Cost: 16.65s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 4.3973	Cost: 13.43s
Train Epoch: 347 	Average Loss: 5.9772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8434

Learning rate: 8.539284020138645e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 20.9800	Cost: 37.22s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 4.4537	Cost: 12.71s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 4.3001	Cost: 14.10s
Train Epoch: 348 	Average Loss: 5.9681
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8940

Learning rate: 8.224537431601915e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 20.8903	Cost: 37.08s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 4.4910	Cost: 16.03s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 4.2809	Cost: 12.65s
Train Epoch: 349 	Average Loss: 5.9505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9621

Learning rate: 7.915451985897387e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 20.8359	Cost: 36.15s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 4.5302	Cost: 9.57s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 4.3473	Cost: 19.86s
Train Epoch: 350 	Average Loss: 5.9313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8072

Learning rate: 7.612046748871354e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 20.8504	Cost: 32.29s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 4.4227	Cost: 10.84s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 4.1871	Cost: 24.85s
Train Epoch: 351 	Average Loss: 5.9093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8654

Learning rate: 7.314340435987926e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 20.8786	Cost: 39.61s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 4.5390	Cost: 15.39s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 4.2631	Cost: 20.04s
Train Epoch: 352 	Average Loss: 5.9196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8429

Learning rate: 7.022351411174871e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 20.9067	Cost: 52.58s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 4.5964	Cost: 16.87s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 4.3623	Cost: 16.36s
Train Epoch: 353 	Average Loss: 5.9233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9603

Learning rate: 6.736097685690606e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 20.9434	Cost: 42.01s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 4.5252	Cost: 16.58s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 4.2819	Cost: 15.48s
Train Epoch: 354 	Average Loss: 5.9168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8550

Learning rate: 6.455596917013267e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 20.7040	Cost: 40.45s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 4.3871	Cost: 15.71s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 4.1861	Cost: 11.08s
Train Epoch: 355 	Average Loss: 5.8613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9208

Learning rate: 6.1808664077516005e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 20.8490	Cost: 37.91s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 4.4413	Cost: 9.57s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 4.2531	Cost: 21.38s
Train Epoch: 356 	Average Loss: 5.8721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8750

Learning rate: 5.91192310457746e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 20.8728	Cost: 31.32s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 4.3968	Cost: 12.80s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 4.2338	Cost: 19.53s
Train Epoch: 357 	Average Loss: 5.8593
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8866

Learning rate: 5.648783597180656e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 20.8733	Cost: 33.18s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 4.4380	Cost: 11.71s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 4.1741	Cost: 29.12s
Train Epoch: 358 	Average Loss: 5.8499
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3942

Learning rate: 5.3914641172454745e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 20.9862	Cost: 47.82s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 4.3939	Cost: 16.78s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 4.1797	Cost: 16.37s
Train Epoch: 359 	Average Loss: 5.8467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9627

Learning rate: 5.139980537449555e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 21.0145	Cost: 48.20s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 4.3760	Cost: 16.01s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 4.2625	Cost: 16.68s
Train Epoch: 360 	Average Loss: 5.8750
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1059

Learning rate: 4.894348370484651e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 20.7802	Cost: 41.50s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 4.4516	Cost: 16.66s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 4.0935	Cost: 16.23s
Train Epoch: 361 	Average Loss: 5.8573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9186

Learning rate: 4.6545827680998834e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 20.9315	Cost: 40.69s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 4.3411	Cost: 15.48s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 4.1909	Cost: 13.25s
Train Epoch: 362 	Average Loss: 5.8251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9358

Learning rate: 4.420698520166991e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 20.9517	Cost: 38.42s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 4.4015	Cost: 12.70s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 4.1984	Cost: 16.67s
Train Epoch: 363 	Average Loss: 5.8137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1135

Learning rate: 4.1927100537680815e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 20.8497	Cost: 35.90s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 4.3683	Cost: 12.20s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 4.1309	Cost: 15.56s
Train Epoch: 364 	Average Loss: 5.8059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9509

Learning rate: 3.970631432305708e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 20.8323	Cost: 34.96s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 4.4199	Cost: 10.63s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 4.1249	Cost: 25.84s
Train Epoch: 365 	Average Loss: 5.8016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0277

Learning rate: 3.7544763546352753e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 20.9928	Cost: 44.98s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 4.3660	Cost: 9.79s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 4.0885	Cost: 27.87s
Train Epoch: 366 	Average Loss: 5.8263
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9547

Learning rate: 3.5442581542202067e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 20.8107	Cost: 55.45s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 4.3415	Cost: 15.36s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 4.1714	Cost: 16.85s
Train Epoch: 367 	Average Loss: 5.7631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8744

Learning rate: 3.339989798309276e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 20.7941	Cost: 40.19s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 4.3140	Cost: 16.78s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 4.1495	Cost: 16.75s
Train Epoch: 368 	Average Loss: 5.7803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8476

Learning rate: 3.1416838871369064e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 20.7938	Cost: 39.44s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 4.2248	Cost: 16.35s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 4.1494	Cost: 14.03s
Train Epoch: 369 	Average Loss: 5.7579
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9927

Learning rate: 2.9493526531457563e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 20.7234	Cost: 39.14s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 4.3350	Cost: 10.40s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 4.1056	Cost: 20.72s
Train Epoch: 370 	Average Loss: 5.7730
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1214

Learning rate: 2.7630079602323468e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 20.8761	Cost: 34.93s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 4.3101	Cost: 12.82s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 4.0212	Cost: 16.08s
Train Epoch: 371 	Average Loss: 5.7720
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9767

Learning rate: 2.582661303015068e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 20.8880	Cost: 37.95s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 4.3225	Cost: 9.95s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 4.1233	Cost: 28.01s
Train Epoch: 372 	Average Loss: 5.7801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9954

Learning rate: 2.40832380612527e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 20.9089	Cost: 50.83s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 4.3193	Cost: 16.49s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 4.0686	Cost: 16.53s
Train Epoch: 373 	Average Loss: 5.7554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8463

Learning rate: 2.2400062235209426e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 20.7511	Cost: 49.70s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 4.2625	Cost: 16.87s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 3.9953	Cost: 16.15s
Train Epoch: 374 	Average Loss: 5.7345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0251

Learning rate: 2.0777189378234156e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 21.0145	Cost: 40.19s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 4.3859	Cost: 14.40s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 3.9070	Cost: 15.42s
Train Epoch: 375 	Average Loss: 5.7434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9633

Learning rate: 1.9214719596769582e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 20.8229	Cost: 35.88s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 4.3500	Cost: 12.69s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 3.9991	Cost: 14.77s
Train Epoch: 376 	Average Loss: 5.7251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1590

Learning rate: 1.771274927131129e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 20.7426	Cost: 35.12s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 4.2824	Cost: 10.21s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 4.0602	Cost: 28.05s
Train Epoch: 377 	Average Loss: 5.7248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9033

Learning rate: 1.6271371050464177e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 20.9190	Cost: 53.66s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 4.3353	Cost: 16.61s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 4.1063	Cost: 16.93s
Train Epoch: 378 	Average Loss: 5.7486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0283

Learning rate: 1.4890673845226142e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 20.8366	Cost: 46.46s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 4.3001	Cost: 14.73s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 4.1067	Cost: 16.61s
Train Epoch: 379 	Average Loss: 5.7410
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0997

Learning rate: 1.3570742823504575e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 20.9942	Cost: 43.06s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 4.2200	Cost: 16.63s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 4.1275	Cost: 16.28s
Train Epoch: 380 	Average Loss: 5.7111
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0880

Learning rate: 1.2311659404862349e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 20.9348	Cost: 41.29s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 4.2892	Cost: 14.84s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 4.0803	Cost: 13.52s
Train Epoch: 381 	Average Loss: 5.7394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8681

Learning rate: 1.1113501255495491e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 21.0754	Cost: 38.01s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 4.3494	Cost: 9.58s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 4.0071	Cost: 20.11s
Train Epoch: 382 	Average Loss: 5.7245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0647

Learning rate: 9.97634228344247e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 20.9158	Cost: 34.21s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 4.2988	Cost: 13.20s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 4.0426	Cost: 18.65s
Train Epoch: 383 	Average Loss: 5.7346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0583

Learning rate: 8.90025263402528e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 20.7005	Cost: 33.87s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 4.2572	Cost: 10.74s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 4.0327	Cost: 28.62s
Train Epoch: 384 	Average Loss: 5.7211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9737

Learning rate: 7.88529868552224e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 21.0010	Cost: 53.21s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 4.2941	Cost: 15.19s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 4.0939	Cost: 17.06s
Train Epoch: 385 	Average Loss: 5.7109
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9216

Learning rate: 6.931543045073711e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 21.0840	Cost: 50.37s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 4.3742	Cost: 16.53s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 4.0892	Cost: 13.40s
Train Epoch: 386 	Average Loss: 5.7279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1709

Learning rate: 6.039044544820409e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 20.9874	Cost: 41.73s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 4.2399	Cost: 13.58s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 4.1352	Cost: 13.45s
Train Epoch: 387 	Average Loss: 5.7331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1218

Learning rate: 5.207858238273524e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 20.7589	Cost: 39.54s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 4.2934	Cost: 13.69s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 4.0976	Cost: 13.09s
Train Epoch: 388 	Average Loss: 5.7037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9771

Learning rate: 4.4380353969200063e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 20.9351	Cost: 42.76s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 4.2157	Cost: 15.00s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 3.9996	Cost: 13.12s
Train Epoch: 389 	Average Loss: 5.7120
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0253

Learning rate: 3.7296235070587456e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 20.9927	Cost: 40.69s
Train Epoch: 390 [40960/90000 (45%)]	Loss: 4.2746	Cost: 9.56s
Train Epoch: 390 [81920/90000 (91%)]	Loss: 4.0576	Cost: 17.15s
Train Epoch: 390 	Average Loss: 5.7103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0135

Learning rate: 3.082666266872038e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 20.8248	Cost: 35.86s
Train Epoch: 391 [40960/90000 (45%)]	Loss: 4.2835	Cost: 9.89s
Train Epoch: 391 [81920/90000 (91%)]	Loss: 4.1188	Cost: 29.17s
Train Epoch: 391 	Average Loss: 5.7029
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0929

Learning rate: 2.497203583729958e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 20.9062	Cost: 43.66s
Train Epoch: 392 [40960/90000 (45%)]	Loss: 4.2843	Cost: 14.88s
Train Epoch: 392 [81920/90000 (91%)]	Loss: 4.0053	Cost: 17.43s
Train Epoch: 392 	Average Loss: 5.6999
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9025

Learning rate: 1.973271571728442e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 20.8753	Cost: 40.77s
Train Epoch: 393 [40960/90000 (45%)]	Loss: 4.2621	Cost: 16.83s
Train Epoch: 393 [81920/90000 (91%)]	Loss: 3.9588	Cost: 16.86s
Train Epoch: 393 	Average Loss: 5.6849
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9412

Learning rate: 1.5109025494620685e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 20.8483	Cost: 39.82s
Train Epoch: 394 [40960/90000 (45%)]	Loss: 4.2995	Cost: 15.04s
Train Epoch: 394 [81920/90000 (91%)]	Loss: 3.9780	Cost: 17.23s
Train Epoch: 394 	Average Loss: 5.7156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9516

Learning rate: 1.1101250380300971e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 20.8199	Cost: 36.25s
Train Epoch: 395 [40960/90000 (45%)]	Loss: 4.2835	Cost: 16.43s
Train Epoch: 395 [81920/90000 (91%)]	Loss: 4.0416	Cost: 16.55s
Train Epoch: 395 	Average Loss: 5.7205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8288

Learning rate: 7.709637592770994e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 21.0299	Cost: 35.06s
Train Epoch: 396 [40960/90000 (45%)]	Loss: 4.3011	Cost: 10.09s
Train Epoch: 396 [81920/90000 (91%)]	Loss: 4.0558	Cost: 26.82s
Train Epoch: 396 	Average Loss: 5.7268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8993

Learning rate: 4.934396342684002e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 20.9239	Cost: 35.62s
Train Epoch: 397 [40960/90000 (45%)]	Loss: 4.2652	Cost: 12.60s
Train Epoch: 397 [81920/90000 (91%)]	Loss: 4.0273	Cost: 12.52s
Train Epoch: 397 	Average Loss: 5.6821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9586

Learning rate: 2.7756978199944282e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 20.8975	Cost: 39.98s
Train Epoch: 398 [40960/90000 (45%)]	Loss: 4.2953	Cost: 9.74s
Train Epoch: 398 [81920/90000 (91%)]	Loss: 4.0469	Cost: 28.26s
Train Epoch: 398 	Average Loss: 5.6972
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1203

Learning rate: 1.2336751833941234e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 20.8173	Cost: 36.61s
Train Epoch: 399 [40960/90000 (45%)]	Loss: 4.3707	Cost: 15.98s
Train Epoch: 399 [81920/90000 (91%)]	Loss: 3.9956	Cost: 17.41s
Train Epoch: 399 	Average Loss: 5.7163
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8672

Learning rate: 3.084235521033653e-09
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 20.9162	Cost: 44.92s
Train Epoch: 400 [40960/90000 (45%)]	Loss: 4.3152	Cost: 15.27s
Train Epoch: 400 [81920/90000 (91%)]	Loss: 4.0682	Cost: 17.34s
Train Epoch: 400 	Average Loss: 5.7152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0381

Stopping timer.
Training time (including validation): 318142.97478461266 seconds
Saving model
Transfer learning by starting with alpha=0.05!
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 23.1575	Cost: 38.16s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 21.6025	Cost: 11.19s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 20.5982	Cost: 26.96s
Train Epoch: 1 	Average Loss: 21.5978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1729

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999691576447898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 20.4367	Cost: 41.05s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 19.4811	Cost: 16.70s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 19.1876	Cost: 16.46s
Train Epoch: 2 	Average Loss: 19.5799
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5323

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 19.3083	Cost: 42.76s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 18.4715	Cost: 15.41s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 18.3369	Cost: 12.96s
Train Epoch: 3 	Average Loss: 18.5603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7916

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 18.6584	Cost: 36.29s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 17.9892	Cost: 15.15s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 17.9936	Cost: 12.23s
Train Epoch: 4 	Average Loss: 18.1088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4450

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.00019995065603657316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 18.3951	Cost: 35.18s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 17.7625	Cost: 9.73s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 17.5674	Cost: 17.42s
Train Epoch: 5 	Average Loss: 17.7576
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1928

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.0001999229036240723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 18.0545	Cost: 33.35s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 17.3728	Cost: 10.67s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 17.4996	Cost: 25.57s
Train Epoch: 6 	Average Loss: 17.5427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1913

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019988898749619702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 18.1417	Cost: 40.40s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 17.4115	Cost: 12.16s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 17.2848	Cost: 22.78s
Train Epoch: 7 	Average Loss: 17.4268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0388

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.00019984890974505381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 17.9728	Cost: 46.44s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 17.2084	Cost: 16.31s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 17.1045	Cost: 16.57s
Train Epoch: 8 	Average Loss: 17.2262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9343

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.00019980267284282717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 17.8309	Cost: 39.74s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 17.0429	Cost: 16.33s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 17.0146	Cost: 16.60s
Train Epoch: 9 	Average Loss: 17.1248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9371

Learning rate: 0.00019975027964162705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 17.8820	Cost: 37.96s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 17.0291	Cost: 16.71s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 17.0217	Cost: 16.23s
Train Epoch: 10 	Average Loss: 17.0776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9557

Learning rate: 0.00019969173337331284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 17.8939	Cost: 39.28s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 16.9422	Cost: 16.24s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 16.8472	Cost: 15.97s
Train Epoch: 11 	Average Loss: 17.0043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9468

Learning rate: 0.00019962703764929416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 17.9611	Cost: 38.06s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 16.8546	Cost: 15.93s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 16.7982	Cost: 10.78s
Train Epoch: 12 	Average Loss: 16.9280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9950

Learning rate: 0.00019955619646030802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 17.9595	Cost: 37.84s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 17.3476	Cost: 12.91s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 17.4059	Cost: 13.03s
Train Epoch: 13 	Average Loss: 17.3691
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4934

Learning rate: 0.00019947921417617267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 18.4450	Cost: 35.18s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 17.2477	Cost: 12.79s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 17.4559	Cost: 15.92s
Train Epoch: 14 	Average Loss: 17.4308
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5341

Learning rate: 0.000199396095545518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 18.4066	Cost: 35.72s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 17.2476	Cost: 10.71s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 17.0026	Cost: 27.04s
Train Epoch: 15 	Average Loss: 17.3269
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2805

Learning rate: 0.00019930684569549264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 18.2110	Cost: 44.92s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 16.9268	Cost: 16.95s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 16.7466	Cost: 16.03s
Train Epoch: 16 	Average Loss: 17.0079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0915

Learning rate: 0.0001992114701314478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 17.9817	Cost: 54.43s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 16.7496	Cost: 17.05s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 16.6478	Cost: 16.54s
Train Epoch: 17 	Average Loss: 16.8206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9896

Learning rate: 0.00019910997473659747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 17.9961	Cost: 41.19s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 16.5455	Cost: 15.93s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 16.6088	Cost: 12.75s
Train Epoch: 18 	Average Loss: 16.7156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0937

Learning rate: 0.00019900236577165574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 18.0350	Cost: 39.19s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 16.4463	Cost: 11.41s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 16.6098	Cost: 19.74s
Train Epoch: 19 	Average Loss: 16.7007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1438

Learning rate: 0.00019888864987445046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 18.2203	Cost: 34.04s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 16.6328	Cost: 12.61s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 16.4869	Cost: 16.30s
Train Epoch: 20 	Average Loss: 16.7335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1611

Learning rate: 0.00019876883405951377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 18.0606	Cost: 35.42s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 16.4380	Cost: 10.23s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 16.3406	Cost: 27.37s
Train Epoch: 21 	Average Loss: 16.5750
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1477

Learning rate: 0.00019864292571764955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 18.0231	Cost: 48.67s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 16.2711	Cost: 16.07s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 16.2190	Cost: 20.89s
Train Epoch: 22 	Average Loss: 16.4512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0992

Learning rate: 0.0001985109326154774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 18.0480	Cost: 54.18s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 16.1970	Cost: 16.61s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 16.2779	Cost: 16.49s
Train Epoch: 23 	Average Loss: 16.4115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2344

Learning rate: 0.00019837286289495361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 18.1868	Cost: 41.27s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 16.2433	Cost: 16.40s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 16.1429	Cost: 15.69s
Train Epoch: 24 	Average Loss: 16.3658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1976

Learning rate: 0.0001982287250728689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 18.1462	Cost: 40.88s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 16.0985	Cost: 16.35s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 16.2439	Cost: 13.82s
Train Epoch: 25 	Average Loss: 16.3403
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3082

Learning rate: 0.00019807852804032305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 18.3296	Cost: 41.24s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 16.0250	Cost: 16.42s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 16.2813	Cost: 13.92s
Train Epoch: 26 	Average Loss: 16.3661
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4246

Learning rate: 0.00019792228106217658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 18.3002	Cost: 40.78s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 16.9927	Cost: 14.07s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 16.8564	Cost: 12.81s
Train Epoch: 27 	Average Loss: 16.8326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7003

Learning rate: 0.0001977599937764791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 18.4875	Cost: 41.16s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 16.4274	Cost: 13.29s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 16.4063	Cost: 13.47s
Train Epoch: 28 	Average Loss: 16.6157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5575

Learning rate: 0.00019759167619387474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 18.4512	Cost: 39.66s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 16.2079	Cost: 13.12s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 16.1196	Cost: 13.90s
Train Epoch: 29 	Average Loss: 16.4269
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3699

Learning rate: 0.00019741733869698495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 18.2764	Cost: 40.27s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 16.0716	Cost: 15.03s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 16.0775	Cost: 12.79s
Train Epoch: 30 	Average Loss: 16.1977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3955

Learning rate: 0.00019723699203976766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 18.3804	Cost: 35.64s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 15.8789	Cost: 13.75s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 16.0127	Cost: 13.13s
Train Epoch: 31 	Average Loss: 16.2001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6761

Learning rate: 0.00019705064734685425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 18.6724	Cost: 37.55s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 16.4019	Cost: 12.11s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 16.3128	Cost: 17.07s
Train Epoch: 32 	Average Loss: 16.5649
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6447

Learning rate: 0.00019685831611286313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 18.6839	Cost: 35.90s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 15.9652	Cost: 12.48s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 15.9632	Cost: 12.68s
Train Epoch: 33 	Average Loss: 16.2684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4892

Learning rate: 0.00019666001020169073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 18.5705	Cost: 34.00s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 15.8217	Cost: 11.29s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 15.7617	Cost: 22.35s
Train Epoch: 34 	Average Loss: 16.0548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4392

Learning rate: 0.0001964557418457798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 18.5241	Cost: 35.25s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 15.7841	Cost: 10.68s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 15.7061	Cost: 25.63s
Train Epoch: 35 	Average Loss: 15.9760
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5942

Learning rate: 0.0001962455236453647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 18.5245	Cost: 58.36s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 15.6721	Cost: 16.94s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 15.6340	Cost: 15.91s
Train Epoch: 36 	Average Loss: 15.9184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5877

Learning rate: 0.00019602936856769428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 18.6015	Cost: 46.47s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 15.5567	Cost: 16.80s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 15.5986	Cost: 15.69s
Train Epoch: 37 	Average Loss: 15.8383
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6211

Learning rate: 0.0001958072899462319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 18.5434	Cost: 37.48s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 15.5298	Cost: 13.30s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 15.5245	Cost: 13.44s
Train Epoch: 38 	Average Loss: 15.7758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6651

Learning rate: 0.00019557930147983297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 18.6681	Cost: 36.45s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 15.4453	Cost: 13.85s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 15.4026	Cost: 12.85s
Train Epoch: 39 	Average Loss: 15.7242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6857

Learning rate: 0.00019534541723190008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 18.6312	Cost: 36.32s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 15.4242	Cost: 14.47s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 15.4213	Cost: 12.21s
Train Epoch: 40 	Average Loss: 15.6894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6614

Learning rate: 0.00019510565162951532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 18.7098	Cost: 38.55s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 15.3984	Cost: 12.26s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 15.3687	Cost: 15.38s
Train Epoch: 41 	Average Loss: 15.6707
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6735

Learning rate: 0.0001948600194625504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 18.6933	Cost: 33.93s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 15.3531	Cost: 12.91s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 15.3123	Cost: 16.93s
Train Epoch: 42 	Average Loss: 15.6093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8308

Learning rate: 0.00019460853588275446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 18.7499	Cost: 34.30s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 15.3220	Cost: 10.07s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 15.3044	Cost: 27.12s
Train Epoch: 43 	Average Loss: 15.5952
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7949

Learning rate: 0.0001943512164028193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 18.7652	Cost: 43.59s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 15.2990	Cost: 11.86s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 15.4278	Cost: 22.22s
Train Epoch: 44 	Average Loss: 15.6162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8995

Learning rate: 0.00019408807689542249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 18.7401	Cost: 54.42s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 15.2806	Cost: 15.76s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 15.2435	Cost: 16.18s
Train Epoch: 45 	Average Loss: 15.5519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8479

Learning rate: 0.00019381913359224837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 18.8264	Cost: 42.89s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 15.2424	Cost: 16.91s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 15.1205	Cost: 16.54s
Train Epoch: 46 	Average Loss: 15.5219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8549

Learning rate: 0.0001935444030829867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 18.8292	Cost: 37.51s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 15.1409	Cost: 13.08s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 15.1425	Cost: 13.46s
Train Epoch: 47 	Average Loss: 15.4658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9106

Learning rate: 0.00019326390231430937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 18.8686	Cost: 38.36s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 15.0519	Cost: 10.32s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 15.2017	Cost: 20.83s
Train Epoch: 48 	Average Loss: 15.4535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8748

Learning rate: 0.00019297764858882508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 18.8792	Cost: 33.35s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 15.0597	Cost: 13.22s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 15.0264	Cost: 15.91s
Train Epoch: 49 	Average Loss: 15.3926
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9403

Learning rate: 0.000192685659564012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 18.8323	Cost: 36.43s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 14.9303	Cost: 9.92s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 14.9517	Cost: 27.68s
Train Epoch: 50 	Average Loss: 15.2923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9906

Learning rate: 0.00019238795325112859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 18.7909	Cost: 52.96s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 14.9285	Cost: 16.49s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 14.8547	Cost: 16.66s
Train Epoch: 51 	Average Loss: 15.2805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9735

Learning rate: 0.00019208454801410258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 19.0475	Cost: 40.99s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 14.8171	Cost: 16.44s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 14.9591	Cost: 15.54s
Train Epoch: 52 	Average Loss: 15.3211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0769

Learning rate: 0.00019177546256839804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 19.0041	Cost: 36.94s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 14.7504	Cost: 12.38s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 14.7989	Cost: 19.95s
Train Epoch: 53 	Average Loss: 15.2264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1612

Learning rate: 0.0001914607159798613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 18.9461	Cost: 34.56s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 14.7535	Cost: 12.87s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 14.7005	Cost: 15.46s
Train Epoch: 54 	Average Loss: 15.1654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0497

Learning rate: 0.00019114032766354445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 19.0890	Cost: 31.00s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 14.6481	Cost: 11.94s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 14.7385	Cost: 28.71s
Train Epoch: 55 	Average Loss: 15.1132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4185

Learning rate: 0.00019081431738250806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 19.2334	Cost: 43.47s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 14.8758	Cost: 16.76s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 14.8320	Cost: 17.72s
Train Epoch: 56 	Average Loss: 15.3055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3699

Learning rate: 0.00019048270524660188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 19.3115	Cost: 44.02s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 14.6287	Cost: 16.99s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 14.6403	Cost: 16.40s
Train Epoch: 57 	Average Loss: 15.1282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3238

Learning rate: 0.0001901455117112245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 19.2380	Cost: 44.16s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 14.5202	Cost: 16.91s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 14.6802	Cost: 16.33s
Train Epoch: 58 	Average Loss: 15.0358
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3017

Learning rate: 0.0001898027575760615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 19.2507	Cost: 42.21s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 14.5044	Cost: 16.85s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 14.7373	Cost: 16.00s
Train Epoch: 59 	Average Loss: 15.0037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3505

Learning rate: 0.00018945446398380245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 19.3361	Cost: 40.62s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 14.5212	Cost: 16.62s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 14.5480	Cost: 10.15s
Train Epoch: 60 	Average Loss: 14.9928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3298

Learning rate: 0.00018910065241883672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 19.4559	Cost: 39.70s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 14.5213	Cost: 9.54s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 14.5795	Cost: 19.93s
Train Epoch: 61 	Average Loss: 15.0107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2663

Learning rate: 0.00018874134470592827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 19.2455	Cost: 32.13s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 14.4498	Cost: 11.73s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 14.5429	Cost: 21.76s
Train Epoch: 62 	Average Loss: 14.9271
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3094

Learning rate: 0.0001883765630088693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 19.3070	Cost: 31.07s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 14.2942	Cost: 11.66s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 14.3375	Cost: 28.75s
Train Epoch: 63 	Average Loss: 14.8592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4059

Learning rate: 0.00018800632982911313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 19.3357	Cost: 43.71s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 14.1786	Cost: 16.84s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 14.2681	Cost: 17.10s
Train Epoch: 64 	Average Loss: 14.7847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4068

Learning rate: 0.00018763066800438628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 19.3751	Cost: 50.34s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 14.1485	Cost: 15.05s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 14.1082	Cost: 16.87s
Train Epoch: 65 	Average Loss: 14.6796
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4793

Learning rate: 0.00018724960070727966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 19.3401	Cost: 43.11s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 14.1317	Cost: 16.71s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 14.1674	Cost: 16.42s
Train Epoch: 66 	Average Loss: 14.6100
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5201

Learning rate: 0.00018686315144381908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 19.4665	Cost: 40.01s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 14.1183	Cost: 13.45s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 14.0970	Cost: 13.39s
Train Epoch: 67 	Average Loss: 14.5919
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5676

Learning rate: 0.00018647134405201546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 19.4861	Cost: 37.39s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 14.2529	Cost: 14.03s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 14.4114	Cost: 15.05s
Train Epoch: 68 	Average Loss: 14.7634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4968

Learning rate: 0.00018607420270039433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 19.3870	Cost: 34.53s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 14.2376	Cost: 10.94s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 14.2227	Cost: 15.79s
Train Epoch: 69 	Average Loss: 14.6923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5549

Learning rate: 0.00018567175188650495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 19.4844	Cost: 35.54s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 14.0954	Cost: 10.80s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 14.0066	Cost: 22.72s
Train Epoch: 70 	Average Loss: 14.5527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5620

Learning rate: 0.0001852640164354092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 19.6593	Cost: 35.68s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 13.9084	Cost: 11.88s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 13.8670	Cost: 28.70s
Train Epoch: 71 	Average Loss: 14.4684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6695

Learning rate: 0.00018485102149815036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 19.5921	Cost: 52.03s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 13.8615	Cost: 14.76s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 13.9327	Cost: 17.42s
Train Epoch: 72 	Average Loss: 14.4972
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6299

Learning rate: 0.0001844327925502015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 19.6816	Cost: 49.09s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 13.9448	Cost: 15.73s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 13.8317	Cost: 16.46s
Train Epoch: 73 	Average Loss: 14.4533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6666

Learning rate: 0.00018400935538989417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 19.6797	Cost: 42.23s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 13.8477	Cost: 16.63s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 13.8112	Cost: 16.45s
Train Epoch: 74 	Average Loss: 14.4265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7618

Learning rate: 0.00018358073613682703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 19.7090	Cost: 38.00s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 13.7238	Cost: 14.22s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 13.9022	Cost: 14.06s
Train Epoch: 75 	Average Loss: 14.4246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8001

Learning rate: 0.00018314696123025452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 19.6475	Cost: 38.56s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 14.4293	Cost: 13.01s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 14.2479	Cost: 14.27s
Train Epoch: 76 	Average Loss: 14.7943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8047

Learning rate: 0.00018270805742745614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 19.6538	Cost: 35.26s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 14.1521	Cost: 12.93s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 14.0188	Cost: 16.50s
Train Epoch: 77 	Average Loss: 14.6713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7317

Learning rate: 0.00018226405180208597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 19.6828	Cost: 38.09s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 13.8971	Cost: 10.05s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 13.7615	Cost: 25.85s
Train Epoch: 78 	Average Loss: 14.4502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7225

Learning rate: 0.00018181497174250233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 19.7975	Cost: 46.74s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 13.6188	Cost: 14.69s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 13.6430	Cost: 21.03s
Train Epoch: 79 	Average Loss: 14.2145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8386

Learning rate: 0.00018136084495007872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 19.7564	Cost: 46.86s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 13.6173	Cost: 15.51s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 13.4919	Cost: 16.11s
Train Epoch: 80 	Average Loss: 14.1512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8820

Learning rate: 0.00018090169943749476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 19.8320	Cost: 40.74s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 13.5143	Cost: 16.87s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 13.3113	Cost: 17.26s
Train Epoch: 81 	Average Loss: 13.9754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0595

Learning rate: 0.00018043756352700846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 19.7341	Cost: 40.00s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 13.3475	Cost: 16.94s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 13.6589	Cost: 15.43s
Train Epoch: 82 	Average Loss: 14.0618
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0581

Learning rate: 0.00017996846584870908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 19.9164	Cost: 38.83s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 13.5064	Cost: 16.25s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 13.4470	Cost: 10.72s
Train Epoch: 83 	Average Loss: 14.0965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9956

Learning rate: 0.000179494435338751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 19.8909	Cost: 37.34s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 13.3405	Cost: 12.91s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 13.3140	Cost: 12.11s
Train Epoch: 84 	Average Loss: 13.9614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0524

Learning rate: 0.00017901550123756904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 19.9250	Cost: 35.37s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 13.3350	Cost: 10.65s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 13.3136	Cost: 14.43s
Train Epoch: 85 	Average Loss: 13.9445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0626

Learning rate: 0.00017853169308807448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 19.8807	Cost: 32.90s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 13.1419	Cost: 11.23s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 13.1747	Cost: 24.17s
Train Epoch: 86 	Average Loss: 13.8609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0310

Learning rate: 0.00017804304073383296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 19.9871	Cost: 36.52s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 13.1481	Cost: 12.24s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 13.3083	Cost: 28.29s
Train Epoch: 87 	Average Loss: 13.8341
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0992

Learning rate: 0.00017754957431722346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 20.1062	Cost: 52.98s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 13.1579	Cost: 16.15s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 13.1106	Cost: 16.33s
Train Epoch: 88 	Average Loss: 13.8750
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1305

Learning rate: 0.00017705132427757892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 19.8793	Cost: 40.70s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 13.1777	Cost: 16.01s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 13.2260	Cost: 11.28s
Train Epoch: 89 	Average Loss: 13.8706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1104

Learning rate: 0.00017654832134930882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 19.9789	Cost: 41.06s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 13.0404	Cost: 16.89s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 13.3255	Cost: 9.67s
Train Epoch: 90 	Average Loss: 13.8355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2699

Learning rate: 0.0001760405965600031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 19.9724	Cost: 44.66s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 13.2823	Cost: 13.31s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 13.0779	Cost: 13.96s
Train Epoch: 91 	Average Loss: 13.8775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1278

Learning rate: 0.00017552818122851838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 20.0648	Cost: 37.14s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 13.0680	Cost: 11.77s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 13.0642	Cost: 13.69s
Train Epoch: 92 	Average Loss: 13.7546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1996

Learning rate: 0.00017501110696304596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 20.1384	Cost: 36.57s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 13.1290	Cost: 11.88s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 12.8840	Cost: 15.37s
Train Epoch: 93 	Average Loss: 13.7015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2481

Learning rate: 0.0001744894056591622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 20.0635	Cost: 35.02s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 12.9460	Cost: 9.89s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 12.8614	Cost: 26.94s
Train Epoch: 94 	Average Loss: 13.5964
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2742

Learning rate: 0.00017396310949786096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 20.2318	Cost: 41.75s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 13.0136	Cost: 16.73s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 12.8043	Cost: 19.37s
Train Epoch: 95 	Average Loss: 13.6559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2716

Learning rate: 0.00017343225094356858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 20.2391	Cost: 40.52s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 12.8071	Cost: 16.69s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 17.3876	Cost: 15.67s
Train Epoch: 96 	Average Loss: 14.8752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5930

Learning rate: 0.00017289686274214118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 20.7677	Cost: 39.26s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 16.3357	Cost: 14.41s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 15.6176	Cost: 17.28s
Train Epoch: 97 	Average Loss: 16.6836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5822

Learning rate: 0.00017235697791884494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 19.4484	Cost: 35.45s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 14.9776	Cost: 15.14s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 14.5151	Cost: 16.03s
Train Epoch: 98 	Average Loss: 15.3263
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3263

Learning rate: 0.0001718126297763189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 19.3253	Cost: 36.16s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 13.9793	Cost: 10.77s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 13.8696	Cost: 22.47s
Train Epoch: 99 	Average Loss: 14.5178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5668

Learning rate: 0.00017126385189252056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 19.7579	Cost: 36.70s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 13.3837	Cost: 10.04s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 13.2977	Cost: 30.71s
Train Epoch: 100 	Average Loss: 14.0704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8791

Learning rate: 0.00017071067811865479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 19.8229	Cost: 47.66s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 13.0410	Cost: 15.64s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 13.0799	Cost: 16.95s
Train Epoch: 101 	Average Loss: 13.7493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9689

Learning rate: 0.00017015314257708562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 20.0005	Cost: 41.43s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 12.9054	Cost: 14.74s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 12.8121	Cost: 11.93s
Train Epoch: 102 	Average Loss: 13.5847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1348

Learning rate: 0.00016959127965923145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 20.1990	Cost: 35.92s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 12.6284	Cost: 15.21s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 12.7497	Cost: 11.49s
Train Epoch: 103 	Average Loss: 13.4266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2879

Learning rate: 0.00016902512402344375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 20.2598	Cost: 36.57s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 12.5349	Cost: 11.24s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 12.6022	Cost: 15.88s
Train Epoch: 104 	Average Loss: 13.3515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3870

Learning rate: 0.0001684547105928689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 20.5032	Cost: 35.24s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 12.4349	Cost: 12.65s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 12.6392	Cost: 13.10s
Train Epoch: 105 	Average Loss: 13.2983
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4659

Learning rate: 0.00016788007455329423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 20.2166	Cost: 32.47s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 12.4615	Cost: 10.86s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 12.4958	Cost: 26.91s
Train Epoch: 106 	Average Loss: 13.2412
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5308

Learning rate: 0.00016730125135097737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 20.3459	Cost: 37.52s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 12.3907	Cost: 14.23s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 12.4805	Cost: 21.24s
Train Epoch: 107 	Average Loss: 13.2024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5951

Learning rate: 0.00016671827669046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 20.5110	Cost: 42.48s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 12.3023	Cost: 17.16s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 12.6926	Cost: 16.30s
Train Epoch: 108 	Average Loss: 13.2165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5091

Learning rate: 0.0001661311865323652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 20.4263	Cost: 53.25s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 12.5969	Cost: 16.69s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 12.5279	Cost: 16.04s
Train Epoch: 109 	Average Loss: 13.2784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6158

Learning rate: 0.00016554001709117943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 20.4345	Cost: 39.75s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 12.3631	Cost: 14.14s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 12.3662	Cost: 13.23s
Train Epoch: 110 	Average Loss: 13.1748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6164

Learning rate: 0.00016494480483301838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 20.4210	Cost: 36.42s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 12.2865	Cost: 14.49s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 12.2531	Cost: 12.27s
Train Epoch: 111 	Average Loss: 13.0637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6230

Learning rate: 0.0001643455864733779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 20.6585	Cost: 38.58s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 12.2165	Cost: 13.11s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 12.2108	Cost: 13.56s
Train Epoch: 112 	Average Loss: 13.0096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6852

Learning rate: 0.000163742398974869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 20.6016	Cost: 38.55s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 12.1838	Cost: 15.48s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 12.1718	Cost: 13.67s
Train Epoch: 113 	Average Loss: 13.0416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7516

Learning rate: 0.00016313527954493778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 20.6338	Cost: 36.55s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 12.2227	Cost: 12.57s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 12.2343	Cost: 15.01s
Train Epoch: 114 	Average Loss: 13.0888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6128

Learning rate: 0.00016252426563357055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 20.5861	Cost: 35.79s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 12.2059	Cost: 10.64s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 12.3140	Cost: 22.10s
Train Epoch: 115 	Average Loss: 13.0952
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6675

Learning rate: 0.0001619093949309834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 20.6010	Cost: 37.46s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 12.1410	Cost: 10.40s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 12.1705	Cost: 28.05s
Train Epoch: 116 	Average Loss: 12.9831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7389

Learning rate: 0.00016129070536529766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 20.6596	Cost: 54.74s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 12.1137	Cost: 14.59s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 12.0811	Cost: 16.51s
Train Epoch: 117 	Average Loss: 12.9823
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7487

Learning rate: 0.00016066823510019996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 20.4355	Cost: 48.76s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 12.0852	Cost: 16.97s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 12.1204	Cost: 13.76s
Train Epoch: 118 	Average Loss: 12.9325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8399

Learning rate: 0.0001600420225325884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 20.5484	Cost: 39.57s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 11.9578	Cost: 16.43s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 12.0590	Cost: 13.49s
Train Epoch: 119 	Average Loss: 12.8303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8402

Learning rate: 0.00015941210629020385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 20.6390	Cost: 38.56s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 11.8678	Cost: 16.31s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 11.9462	Cost: 10.64s
Train Epoch: 120 	Average Loss: 12.7728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7664

Learning rate: 0.00015877852522924735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 20.5599	Cost: 37.32s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 11.7672	Cost: 10.19s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 11.9049	Cost: 21.29s
Train Epoch: 121 	Average Loss: 12.6884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9277

Learning rate: 0.00015814131843198305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 20.5794	Cost: 35.00s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 11.6886	Cost: 12.78s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 11.9307	Cost: 16.79s
Train Epoch: 122 	Average Loss: 12.6475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9365

Learning rate: 0.00015750052520432787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 20.7936	Cost: 32.69s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 11.7115	Cost: 11.41s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 11.8615	Cost: 27.82s
Train Epoch: 123 	Average Loss: 12.6212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9405

Learning rate: 0.0001568561850734264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 20.8009	Cost: 49.53s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 11.7873	Cost: 14.21s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 11.8366	Cost: 22.02s
Train Epoch: 124 	Average Loss: 12.6997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9596

Learning rate: 0.00015620833778521307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 20.6603	Cost: 50.09s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 11.5648	Cost: 14.75s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 11.8585	Cost: 16.56s
Train Epoch: 125 	Average Loss: 12.6228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0238

Learning rate: 0.00015555702330196023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 20.6928	Cost: 40.69s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 11.6020	Cost: 16.60s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 11.7852	Cost: 16.78s
Train Epoch: 126 	Average Loss: 12.6195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9725

Learning rate: 0.00015490228179981317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 20.6545	Cost: 38.67s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 11.5152	Cost: 16.17s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 11.7428	Cost: 14.61s
Train Epoch: 127 	Average Loss: 12.5014
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0410

Learning rate: 0.00015424415366631188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 20.8268	Cost: 39.16s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 11.5276	Cost: 14.82s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 11.6822	Cost: 13.71s
Train Epoch: 128 	Average Loss: 12.4957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0812

Learning rate: 0.00015358267949789966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 20.7053	Cost: 35.60s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 11.5444	Cost: 12.70s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 11.8318	Cost: 15.78s
Train Epoch: 129 	Average Loss: 12.4907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0109

Learning rate: 0.00015291790009741904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 20.9291	Cost: 33.21s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 11.4804	Cost: 11.12s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 11.7155	Cost: 25.28s
Train Epoch: 130 	Average Loss: 12.4114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1253

Learning rate: 0.00015224985647159487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 20.9502	Cost: 41.87s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 11.4964	Cost: 11.76s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 11.5509	Cost: 27.97s
Train Epoch: 131 	Average Loss: 12.3892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1144

Learning rate: 0.00015157858982850473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 20.6766	Cost: 51.94s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 11.4217	Cost: 16.52s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 11.5132	Cost: 15.44s
Train Epoch: 132 	Average Loss: 12.3242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2164

Learning rate: 0.0001509041415750371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 20.5587	Cost: 41.41s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 11.3666	Cost: 17.88s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 11.5479	Cost: 15.51s
Train Epoch: 133 	Average Loss: 12.2547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2258

Learning rate: 0.00015022655331433721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 20.9400	Cost: 36.39s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 11.4300	Cost: 12.43s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 11.5785	Cost: 14.11s
Train Epoch: 134 	Average Loss: 12.3389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2655

Learning rate: 0.00014954586684324072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 20.7242	Cost: 38.18s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 11.5012	Cost: 14.76s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 11.6763	Cost: 14.42s
Train Epoch: 135 	Average Loss: 12.3247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1716

Learning rate: 0.00014886212414969547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 21.0081	Cost: 35.66s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 11.5073	Cost: 12.57s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 11.6271	Cost: 14.37s
Train Epoch: 136 	Average Loss: 12.4316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1586

Learning rate: 0.0001481753674101715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 20.8923	Cost: 33.52s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 13.8854	Cost: 10.89s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 13.4337	Cost: 25.67s
Train Epoch: 137 	Average Loss: 14.0843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7031

Learning rate: 0.00014748563898705943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 20.4602	Cost: 43.91s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 12.7108	Cost: 9.79s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 12.4878	Cost: 27.85s
Train Epoch: 138 	Average Loss: 13.6048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4632

Learning rate: 0.00014679298142605734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 20.5416	Cost: 46.99s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 12.0043	Cost: 15.51s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 12.3335	Cost: 16.75s
Train Epoch: 139 	Average Loss: 13.0551
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8033

Learning rate: 0.00014609743745354624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 20.8646	Cost: 40.00s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 12.1698	Cost: 14.00s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 12.2274	Cost: 17.72s
Train Epoch: 140 	Average Loss: 13.0414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7079

Learning rate: 0.00014539904997395466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 20.8313	Cost: 39.35s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 12.0429	Cost: 16.32s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 12.0414	Cost: 13.23s
Train Epoch: 141 	Average Loss: 12.9408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8032

Learning rate: 0.0001446978620671121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 20.5748	Cost: 40.24s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 13.1446	Cost: 11.53s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 13.2029	Cost: 17.94s
Train Epoch: 142 	Average Loss: 13.5780
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9244

Learning rate: 0.0001439939169855915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 20.7070	Cost: 35.80s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 12.4584	Cost: 12.62s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 12.0883	Cost: 13.97s
Train Epoch: 143 	Average Loss: 13.2609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7108

Learning rate: 0.0001432872581520414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 20.7114	Cost: 35.25s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 11.6545	Cost: 10.41s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 11.3642	Cost: 25.72s
Train Epoch: 144 	Average Loss: 12.5113
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8461

Learning rate: 0.00014257792915650728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 20.8337	Cost: 43.08s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 11.2569	Cost: 12.22s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 11.0498	Cost: 26.77s
Train Epoch: 145 	Average Loss: 12.1236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0741

Learning rate: 0.0001418659737537428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 20.9906	Cost: 60.25s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 10.9240	Cost: 16.60s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 10.7839	Cost: 16.01s
Train Epoch: 146 	Average Loss: 11.8998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2981

Learning rate: 0.00014115143586051088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 21.0262	Cost: 41.81s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 11.1589	Cost: 14.66s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 10.9590	Cost: 12.98s
Train Epoch: 147 	Average Loss: 12.0854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2144

Learning rate: 0.0001404343595528745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 21.0704	Cost: 41.29s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 10.7303	Cost: 14.62s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 10.7082	Cost: 12.88s
Train Epoch: 148 	Average Loss: 11.8001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2807

Learning rate: 0.00013971478906347806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 21.1385	Cost: 38.17s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 10.6287	Cost: 15.97s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 10.6838	Cost: 10.94s
Train Epoch: 149 	Average Loss: 11.6348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3879

Learning rate: 0.00013899276877881884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 21.3237	Cost: 38.45s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 10.5123	Cost: 14.71s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 10.5170	Cost: 13.99s
Train Epoch: 150 	Average Loss: 11.5949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4964

Learning rate: 0.000138268343236509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 21.2703	Cost: 36.40s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 10.5236	Cost: 12.50s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 10.5234	Cost: 13.64s
Train Epoch: 151 	Average Loss: 11.4803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4988

Learning rate: 0.00013754155712252834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 21.4180	Cost: 32.76s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 10.3599	Cost: 12.67s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 10.4571	Cost: 19.69s
Train Epoch: 152 	Average Loss: 11.4737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5709

Learning rate: 0.00013681245526846785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 21.3472	Cost: 34.23s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 10.5608	Cost: 11.56s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 10.5429	Cost: 26.88s
Train Epoch: 153 	Average Loss: 11.5502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5534

Learning rate: 0.00013608108264876422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 21.3708	Cost: 48.94s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 10.2122	Cost: 13.92s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 10.3586	Cost: 17.61s
Train Epoch: 154 	Average Loss: 11.3956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6224

Learning rate: 0.00013534748437792575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 21.2222	Cost: 47.34s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 10.1189	Cost: 16.21s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 10.1090	Cost: 16.42s
Train Epoch: 155 	Average Loss: 11.2518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6925

Learning rate: 0.00013461170570774932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 21.6398	Cost: 40.37s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 10.1069	Cost: 15.06s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 10.1002	Cost: 12.15s
Train Epoch: 156 	Average Loss: 11.2388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7915

Learning rate: 0.0001338737920245292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 21.5318	Cost: 44.88s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 10.1556	Cost: 15.60s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 10.1069	Cost: 9.71s
Train Epoch: 157 	Average Loss: 11.2519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7773

Learning rate: 0.00013313378884625713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 21.6387	Cost: 40.88s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 9.9350	Cost: 10.38s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 10.0378	Cost: 17.96s
Train Epoch: 158 	Average Loss: 11.1531
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8248

Learning rate: 0.00013239174181981498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 21.4166	Cost: 35.05s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 10.0276	Cost: 12.96s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 10.0854	Cost: 12.70s
Train Epoch: 159 	Average Loss: 11.1089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8560

Learning rate: 0.00013164769671815865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 21.1970	Cost: 35.65s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 9.9107	Cost: 9.90s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 10.0294	Cost: 27.10s
Train Epoch: 160 	Average Loss: 11.0949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8880

Learning rate: 0.0001309016994374948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 21.6054	Cost: 43.00s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 10.0050	Cost: 17.11s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 10.2210	Cost: 17.76s
Train Epoch: 161 	Average Loss: 11.1638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0056

Learning rate: 0.00013015379599444962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 21.5631	Cost: 44.17s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 10.2659	Cost: 16.84s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 10.3217	Cost: 16.37s
Train Epoch: 162 	Average Loss: 11.2430
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9521

Learning rate: 0.00012940403252323043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 21.5015	Cost: 40.70s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 10.2173	Cost: 14.78s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 10.2386	Cost: 15.80s
Train Epoch: 163 	Average Loss: 11.3132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9946

Learning rate: 0.00012865245527277986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 21.6237	Cost: 37.92s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 10.1639	Cost: 14.85s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 10.2173	Cost: 17.85s
Train Epoch: 164 	Average Loss: 11.2765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8839

Learning rate: 0.00012789911060392294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 21.2798	Cost: 36.95s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 10.1543	Cost: 15.25s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 10.1888	Cost: 17.33s
Train Epoch: 165 	Average Loss: 11.2311
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8515

Learning rate: 0.00012714404498650745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 21.3546	Cost: 35.18s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 10.0507	Cost: 9.97s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 10.0147	Cost: 22.51s
Train Epoch: 166 	Average Loss: 11.2134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0223

Learning rate: 0.00012638730499653727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 21.5721	Cost: 37.93s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 10.0834	Cost: 9.98s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 9.8712	Cost: 23.88s
Train Epoch: 167 	Average Loss: 11.1345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8648

Learning rate: 0.00012562893731329965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 21.4443	Cost: 39.40s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 9.7203	Cost: 15.98s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 9.8289	Cost: 17.16s
Train Epoch: 168 	Average Loss: 10.9856
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0051

Learning rate: 0.00012486898871648546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 22.0031	Cost: 38.41s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 9.7819	Cost: 17.45s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 9.8383	Cost: 17.06s
Train Epoch: 169 	Average Loss: 10.9905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0405

Learning rate: 0.00012410750608330388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 21.8021	Cost: 37.29s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 9.7256	Cost: 14.71s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 9.8153	Cost: 16.48s
Train Epoch: 170 	Average Loss: 10.8649
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1047

Learning rate: 0.00012334453638559054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 21.6978	Cost: 39.96s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 9.7011	Cost: 15.84s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 9.8821	Cost: 13.32s
Train Epoch: 171 	Average Loss: 10.9230
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1291

Learning rate: 0.00012258012668691037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 21.6794	Cost: 43.45s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 9.7481	Cost: 15.04s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 9.8200	Cost: 11.65s
Train Epoch: 172 	Average Loss: 10.9096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1209

Learning rate: 0.00012181432413965427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 21.6525	Cost: 36.61s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 9.6606	Cost: 9.52s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 9.7424	Cost: 18.15s
Train Epoch: 173 	Average Loss: 10.7984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1129

Learning rate: 0.0001210471759821306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 21.7471	Cost: 31.84s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 9.6583	Cost: 11.01s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 9.7526	Cost: 26.01s
Train Epoch: 174 	Average Loss: 10.8007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1906

Learning rate: 0.00012027872953565127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 21.8406	Cost: 39.67s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 9.7108	Cost: 16.70s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 9.5606	Cost: 18.15s
Train Epoch: 175 	Average Loss: 10.7619
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1667

Learning rate: 0.00011950903220161285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 21.9226	Cost: 40.03s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 9.4897	Cost: 11.08s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 9.4455	Cost: 19.77s
Train Epoch: 176 	Average Loss: 10.6015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1196

Learning rate: 0.00011873813145857249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 21.7474	Cost: 44.68s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 9.5450	Cost: 14.69s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 9.7040	Cost: 19.47s
Train Epoch: 177 	Average Loss: 10.6840
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1942

Learning rate: 0.00011796607485931927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 21.5982	Cost: 42.72s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 9.8677	Cost: 16.93s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 9.7252	Cost: 16.63s
Train Epoch: 178 	Average Loss: 10.8113
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1198

Learning rate: 0.00011719291002794096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 22.1136	Cost: 38.83s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 9.6724	Cost: 15.03s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 9.6243	Cost: 16.12s
Train Epoch: 179 	Average Loss: 10.7722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2513

Learning rate: 0.0001164186846568863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 21.7924	Cost: 45.01s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 9.4984	Cost: 16.68s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 9.4276	Cost: 14.70s
Train Epoch: 180 	Average Loss: 10.6334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2260

Learning rate: 0.0001156434465040231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 21.2998	Cost: 42.94s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 9.4122	Cost: 16.17s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 9.3244	Cost: 10.67s
Train Epoch: 181 	Average Loss: 10.5718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2762

Learning rate: 0.00011486724338969234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 21.9068	Cost: 37.75s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 9.2771	Cost: 14.62s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 9.2957	Cost: 12.15s
Train Epoch: 182 	Average Loss: 10.5154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2400

Learning rate: 0.0001140901231937583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 22.0027	Cost: 35.73s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 9.2106	Cost: 16.21s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 9.1446	Cost: 9.54s
Train Epoch: 183 	Average Loss: 10.4065
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3280

Learning rate: 0.00011331213385265528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 21.5486	Cost: 36.39s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 11.0039	Cost: 9.53s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 10.3824	Cost: 19.51s
Train Epoch: 184 	Average Loss: 11.6705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6000

Learning rate: 0.00011253332335643047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 21.6989	Cost: 31.91s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 10.2444	Cost: 11.59s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 9.9512	Cost: 22.23s
Train Epoch: 185 	Average Loss: 11.3162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8783

Learning rate: 0.0001117537397457838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 21.9922	Cost: 33.11s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 9.5435	Cost: 11.80s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 9.4082	Cost: 29.35s
Train Epoch: 186 	Average Loss: 10.7536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1766

Learning rate: 0.00011097343110910456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 22.0835	Cost: 47.02s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 9.3249	Cost: 14.80s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 9.2011	Cost: 16.29s
Train Epoch: 187 	Average Loss: 10.5382
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1714

Learning rate: 0.00011019244557950502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 22.0134	Cost: 53.13s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 9.0319	Cost: 16.61s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 9.2633	Cost: 12.38s
Train Epoch: 188 	Average Loss: 10.3974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2782

Learning rate: 0.00010941083133185145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 21.6901	Cost: 46.61s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 9.1540	Cost: 13.17s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 9.0211	Cost: 13.53s
Train Epoch: 189 	Average Loss: 10.4140
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3579

Learning rate: 0.00010862863657979236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 22.1863	Cost: 45.10s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 8.9778	Cost: 13.90s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 8.9041	Cost: 12.85s
Train Epoch: 190 	Average Loss: 10.2172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5027

Learning rate: 0.00010784590957278452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 22.2342	Cost: 45.25s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 8.7957	Cost: 14.69s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 8.8297	Cost: 12.23s
Train Epoch: 191 	Average Loss: 10.0445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5498

Learning rate: 0.00010706269859311669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 21.9847	Cost: 51.67s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 8.7289	Cost: 11.62s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 8.7999	Cost: 17.11s
Train Epoch: 192 	Average Loss: 10.0167
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5768

Learning rate: 0.00010627905195293137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 21.9486	Cost: 35.98s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 8.7520	Cost: 12.60s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 8.6788	Cost: 13.79s
Train Epoch: 193 	Average Loss: 10.0745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4492

Learning rate: 0.00010549501799124461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 21.8716	Cost: 35.53s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 8.6269	Cost: 9.64s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 8.8962	Cost: 24.50s
Train Epoch: 194 	Average Loss: 9.9562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5575

Learning rate: 0.00010471064507096429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 22.0925	Cost: 42.21s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 8.6637	Cost: 17.21s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 8.7479	Cost: 18.74s
Train Epoch: 195 	Average Loss: 10.0029
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5701

Learning rate: 0.00010392598157590689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 21.9104	Cost: 43.19s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 8.7074	Cost: 16.20s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 8.5514	Cost: 16.38s
Train Epoch: 196 	Average Loss: 9.9016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7191

Learning rate: 0.00010314107590781285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 22.3975	Cost: 52.03s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 8.5447	Cost: 14.79s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 8.9511	Cost: 12.24s
Train Epoch: 197 	Average Loss: 9.8980
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5881

Learning rate: 0.00010235597648336105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 22.0218	Cost: 53.34s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 8.7490	Cost: 9.74s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 8.6402	Cost: 19.08s
Train Epoch: 198 	Average Loss: 9.9768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6474

Learning rate: 0.0001015707317311821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 22.2829	Cost: 34.36s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 8.5917	Cost: 12.76s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 8.6913	Cost: 14.44s
Train Epoch: 199 	Average Loss: 9.9386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7476

Learning rate: 0.00010078539008887115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 22.1996	Cost: 33.50s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 8.7821	Cost: 9.83s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 8.8616	Cost: 26.44s
Train Epoch: 200 	Average Loss: 10.0139
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6015

Learning rate: 0.00010000000000000002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 22.3415	Cost: 43.75s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 8.7663	Cost: 16.92s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 9.7125	Cost: 21.00s
Train Epoch: 201 	Average Loss: 10.2858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7105

Learning rate: 9.92146099111289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 22.3571	Cost: 43.17s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 9.4084	Cost: 13.29s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 9.0200	Cost: 14.93s
Train Epoch: 202 	Average Loss: 10.5582
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4375

Learning rate: 9.842926826881797e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 22.2729	Cost: 39.54s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 9.4573	Cost: 16.30s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 9.1312	Cost: 12.14s
Train Epoch: 203 	Average Loss: 10.4615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6323

Learning rate: 9.7644023516639e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 22.2578	Cost: 36.48s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 8.8631	Cost: 15.33s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 8.6614	Cost: 17.56s
Train Epoch: 204 	Average Loss: 10.1638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5708

Learning rate: 9.68589240921872e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 22.3445	Cost: 36.01s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 8.3863	Cost: 11.05s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 8.3035	Cost: 21.05s
Train Epoch: 205 	Average Loss: 9.7553
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6159

Learning rate: 9.607401842409317e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 22.5434	Cost: 35.55s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 8.2589	Cost: 9.81s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 8.3708	Cost: 23.01s
Train Epoch: 206 	Average Loss: 9.6769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8055

Learning rate: 9.528935492903578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 22.1892	Cost: 36.81s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 9.2533	Cost: 13.70s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 9.0455	Cost: 18.39s
Train Epoch: 207 	Average Loss: 10.4111
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6405

Learning rate: 9.450498200875547e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 22.0408	Cost: 40.40s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 8.5706	Cost: 17.08s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 8.4610	Cost: 18.40s
Train Epoch: 208 	Average Loss: 9.8812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6471

Learning rate: 9.372094804706868e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 22.2785	Cost: 54.70s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 8.3768	Cost: 16.35s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 8.1552	Cost: 16.52s
Train Epoch: 209 	Average Loss: 9.5605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7657

Learning rate: 9.293730140688336e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 22.1136	Cost: 40.00s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 8.1505	Cost: 16.85s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 8.1199	Cost: 19.00s
Train Epoch: 210 	Average Loss: 9.4471
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9640

Learning rate: 9.215409042721555e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 22.8476	Cost: 44.41s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 8.7770	Cost: 15.51s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 8.8257	Cost: 14.10s
Train Epoch: 211 	Average Loss: 9.9365
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6373

Learning rate: 9.13713634202077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 22.3096	Cost: 34.56s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 8.6011	Cost: 16.73s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 8.2409	Cost: 16.73s
Train Epoch: 212 	Average Loss: 9.8855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9236

Learning rate: 9.058916866814858e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 22.3806	Cost: 36.42s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 8.1991	Cost: 9.99s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 8.0775	Cost: 26.38s
Train Epoch: 213 	Average Loss: 9.5241
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9778

Learning rate: 8.9807554420495e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 22.2925	Cost: 40.36s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 7.9827	Cost: 9.79s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 7.7706	Cost: 25.74s
Train Epoch: 214 	Average Loss: 9.2707
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9893

Learning rate: 8.902656889089548e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 22.3347	Cost: 39.83s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 8.1150	Cost: 16.76s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 8.0555	Cost: 18.14s
Train Epoch: 215 	Average Loss: 9.2866
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9210

Learning rate: 8.824626025421624e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 22.5204	Cost: 43.71s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 7.9249	Cost: 16.93s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 8.0387	Cost: 17.21s
Train Epoch: 216 	Average Loss: 9.2914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9945

Learning rate: 8.746667664356959e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 22.2292	Cost: 41.12s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 8.7889	Cost: 16.09s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 8.4840	Cost: 13.02s
Train Epoch: 217 	Average Loss: 9.8892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9893

Learning rate: 8.668786614734478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 22.2284	Cost: 38.76s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 8.1630	Cost: 14.79s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 7.9503	Cost: 12.10s
Train Epoch: 218 	Average Loss: 9.4442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9703

Learning rate: 8.590987680624175e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 22.3786	Cost: 39.60s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 8.1541	Cost: 14.76s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 7.8649	Cost: 13.98s
Train Epoch: 219 	Average Loss: 9.3396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0430

Learning rate: 8.51327566103077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 22.1688	Cost: 35.55s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 7.8587	Cost: 12.77s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 7.8242	Cost: 15.58s
Train Epoch: 220 	Average Loss: 9.2026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9968

Learning rate: 8.435655349597692e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 22.1885	Cost: 35.85s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 7.9008	Cost: 9.99s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 7.5892	Cost: 27.00s
Train Epoch: 221 	Average Loss: 9.1477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1320

Learning rate: 8.35813153431137e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 22.3049	Cost: 52.14s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 7.6977	Cost: 16.61s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 7.5219	Cost: 17.71s
Train Epoch: 222 	Average Loss: 9.0014
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0513

Learning rate: 8.280708997205904e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 22.2024	Cost: 50.14s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 7.5506	Cost: 16.74s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 7.4564	Cost: 16.16s
Train Epoch: 223 	Average Loss: 8.9044
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1913

Learning rate: 8.203392514068074e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 22.0484	Cost: 39.59s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 7.4174	Cost: 16.63s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 7.3189	Cost: 14.26s
Train Epoch: 224 	Average Loss: 8.7863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3367

Learning rate: 8.126186854142755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 22.1722	Cost: 38.80s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 7.2673	Cost: 13.76s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 7.2189	Cost: 13.45s
Train Epoch: 225 	Average Loss: 8.7578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2144

Learning rate: 8.049096779838719e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 22.4856	Cost: 35.28s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 7.3392	Cost: 12.49s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 7.3210	Cost: 16.25s
Train Epoch: 226 	Average Loss: 8.7265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2369

Learning rate: 7.972127046434877e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 22.3421	Cost: 34.43s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 7.6228	Cost: 10.24s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 7.4066	Cost: 25.22s
Train Epoch: 227 	Average Loss: 8.9016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2986

Learning rate: 7.895282401786947e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 22.7881	Cost: 41.52s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 7.4445	Cost: 11.61s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 7.3405	Cost: 24.02s
Train Epoch: 228 	Average Loss: 8.8747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3365

Learning rate: 7.818567586034578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 22.4412	Cost: 43.55s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 7.3590	Cost: 16.34s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 7.5139	Cost: 16.81s
Train Epoch: 229 	Average Loss: 8.8481
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3324

Learning rate: 7.741987331308968e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 21.7798	Cost: 41.31s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 7.4063	Cost: 16.86s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 7.2456	Cost: 14.25s
Train Epoch: 230 	Average Loss: 8.8347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3072

Learning rate: 7.665546361440945e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 21.9100	Cost: 38.11s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 7.2197	Cost: 16.53s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 7.1764	Cost: 10.41s
Train Epoch: 231 	Average Loss: 8.6277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2971

Learning rate: 7.589249391669613e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 21.8895	Cost: 36.54s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 7.1039	Cost: 9.57s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 7.1628	Cost: 19.97s
Train Epoch: 232 	Average Loss: 8.4723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4144

Learning rate: 7.513101128351452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 22.0747	Cost: 32.55s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 7.0893	Cost: 9.81s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 7.0605	Cost: 26.17s
Train Epoch: 233 	Average Loss: 8.5336
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3792

Learning rate: 7.437106268670034e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 21.9114	Cost: 38.15s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 7.2248	Cost: 16.76s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 7.1177	Cost: 19.78s
Train Epoch: 234 	Average Loss: 8.5770
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3287

Learning rate: 7.361269500346273e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 22.0047	Cost: 54.67s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 6.9103	Cost: 14.89s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 7.0093	Cost: 16.40s
Train Epoch: 235 	Average Loss: 8.4533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3089

Learning rate: 7.28559550134926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 22.1568	Cost: 50.08s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 7.2480	Cost: 16.73s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 7.5107	Cost: 16.26s
Train Epoch: 236 	Average Loss: 8.7285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3877

Learning rate: 7.210088939607711e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 22.1677	Cost: 40.64s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 7.6728	Cost: 13.92s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 7.5533	Cost: 12.83s
Train Epoch: 237 	Average Loss: 8.9191
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4719

Learning rate: 7.13475447272202e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 22.1240	Cost: 37.59s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 7.4553	Cost: 15.02s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 7.4770	Cost: 11.61s
Train Epoch: 238 	Average Loss: 8.9015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4179

Learning rate: 7.059596747676965e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 21.9081	Cost: 37.47s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 7.6077	Cost: 13.74s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 7.6877	Cost: 9.38s
Train Epoch: 239 	Average Loss: 8.9373
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3656

Learning rate: 6.984620400555048e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 22.1155	Cost: 35.07s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 7.2841	Cost: 10.36s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 7.1623	Cost: 15.41s
Train Epoch: 240 	Average Loss: 8.7470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4023

Learning rate: 6.909830056250531e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 22.1280	Cost: 30.05s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 6.8824	Cost: 9.70s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 6.8558	Cost: 23.22s
Train Epoch: 241 	Average Loss: 8.3648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5359

Learning rate: 6.835230328184141e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 22.8019	Cost: 38.44s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 7.0023	Cost: 16.14s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 7.2955	Cost: 19.89s
Train Epoch: 242 	Average Loss: 8.5946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.7883

Learning rate: 6.760825818018508e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 22.0630	Cost: 35.03s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 7.2890	Cost: 16.28s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 6.9890	Cost: 16.32s
Train Epoch: 243 	Average Loss: 8.6436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3794

Learning rate: 6.686621115374292e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 21.8373	Cost: 39.77s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 6.8035	Cost: 16.32s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 6.7271	Cost: 16.12s
Train Epoch: 244 	Average Loss: 8.2359
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4621

Learning rate: 6.61262079754709e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 21.7054	Cost: 39.34s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 6.5049	Cost: 16.39s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 6.4841	Cost: 14.28s
Train Epoch: 245 	Average Loss: 7.9788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4237

Learning rate: 6.538829429225073e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 22.2630	Cost: 40.67s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 6.4571	Cost: 16.76s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 6.6843	Cost: 12.85s
Train Epoch: 246 	Average Loss: 8.0546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3198

Learning rate: 6.465251562207432e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 22.9530	Cost: 37.74s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 6.7156	Cost: 16.02s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 6.7311	Cost: 9.47s
Train Epoch: 247 	Average Loss: 8.2806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.7312

Learning rate: 6.391891735123586e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 22.1903	Cost: 33.64s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 6.6951	Cost: 9.49s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 7.0192	Cost: 16.40s
Train Epoch: 248 	Average Loss: 8.1876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.6913

Learning rate: 6.318754473153225e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 21.8962	Cost: 31.79s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 6.7475	Cost: 9.68s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 6.6610	Cost: 22.40s
Train Epoch: 249 	Average Loss: 8.2620
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5001

Learning rate: 6.245844287747173e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 22.2787	Cost: 40.95s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 6.5594	Cost: 16.65s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 6.6360	Cost: 16.64s
Train Epoch: 250 	Average Loss: 8.2153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9369

Learning rate: 6.173165676349108e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 22.2089	Cost: 43.10s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 6.6351	Cost: 16.60s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 6.6506	Cost: 14.48s
Train Epoch: 251 	Average Loss: 8.1475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.6106

Learning rate: 6.10072312211812e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 22.1311	Cost: 36.31s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 6.3478	Cost: 13.56s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 6.3059	Cost: 12.32s
Train Epoch: 252 	Average Loss: 7.8956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5900

Learning rate: 6.0285210936521955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 22.6392	Cost: 32.78s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 7.1870	Cost: 11.04s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 6.9143	Cost: 13.65s
Train Epoch: 253 	Average Loss: 8.2665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.8773

Learning rate: 5.956564044712553e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 21.7824	Cost: 30.92s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 6.7646	Cost: 11.62s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 6.7900	Cost: 11.91s
Train Epoch: 254 	Average Loss: 8.2904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.0215

Learning rate: 5.8848564139489155e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 22.2383	Cost: 31.56s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 6.7912	Cost: 9.68s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 6.7717	Cost: 27.74s
Train Epoch: 255 	Average Loss: 8.2489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5727

Learning rate: 5.813402624625721e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 22.2210	Cost: 43.06s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 6.6257	Cost: 17.15s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 6.5661	Cost: 12.24s
Train Epoch: 256 	Average Loss: 8.1035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.8015

Learning rate: 5.742207084349277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 22.9614	Cost: 37.30s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 6.6056	Cost: 13.12s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 6.7273	Cost: 12.52s
Train Epoch: 257 	Average Loss: 8.2181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.7162

Learning rate: 5.6712741847958634e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 23.3523	Cost: 34.18s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 7.4274	Cost: 12.59s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 7.2964	Cost: 12.47s
Train Epoch: 258 	Average Loss: 8.5838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.6375

Learning rate: 5.600608301440851e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 21.8256	Cost: 31.37s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 7.0435	Cost: 10.68s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 6.7660	Cost: 16.37s
Train Epoch: 259 	Average Loss: 8.4280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3861

Learning rate: 5.5302137932887924e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 21.7385	Cost: 33.84s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 6.5676	Cost: 9.65s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 6.3750	Cost: 27.41s
Train Epoch: 260 	Average Loss: 8.0298
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.7704

Learning rate: 5.460095002604535e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 22.5333	Cost: 43.16s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 6.3072	Cost: 16.85s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 6.3323	Cost: 13.08s
Train Epoch: 261 	Average Loss: 7.9119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9018

Learning rate: 5.390256254645381e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 22.0666	Cost: 39.21s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 6.0710	Cost: 15.36s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 6.0791	Cost: 11.19s
Train Epoch: 262 	Average Loss: 7.6834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.8332

Learning rate: 5.3207018573942705e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 22.1978	Cost: 37.10s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 6.0152	Cost: 13.88s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 5.9651	Cost: 10.86s
Train Epoch: 263 	Average Loss: 7.5769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.0080

Learning rate: 5.251436101294054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 22.1650	Cost: 35.11s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 5.9750	Cost: 10.40s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 5.9035	Cost: 15.34s
Train Epoch: 264 	Average Loss: 7.5248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.7788

Learning rate: 5.1824632589828485e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 22.2065	Cost: 30.92s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 5.8498	Cost: 9.69s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 5.7850	Cost: 22.77s
Train Epoch: 265 	Average Loss: 7.3944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9128

Learning rate: 5.1137875850304516e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 21.9627	Cost: 39.67s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 5.6706	Cost: 16.38s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 5.6834	Cost: 18.90s
Train Epoch: 266 	Average Loss: 7.2805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9420

Learning rate: 5.045413315675926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 21.8540	Cost: 43.00s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 5.7122	Cost: 16.94s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 5.6330	Cost: 11.88s
Train Epoch: 267 	Average Loss: 7.2565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.6424

Learning rate: 4.977344668566277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 22.0357	Cost: 36.83s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 6.0588	Cost: 11.55s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 6.2004	Cost: 13.76s
Train Epoch: 268 	Average Loss: 7.5151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4923

Learning rate: 4.909585842496289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 21.9450	Cost: 32.99s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 6.1548	Cost: 12.55s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 5.8921	Cost: 12.78s
Train Epoch: 269 	Average Loss: 7.3804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.7421

Learning rate: 4.842141017149528e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 22.0479	Cost: 30.22s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 5.7433	Cost: 9.67s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 5.7582	Cost: 25.17s
Train Epoch: 270 	Average Loss: 7.2264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.6718

Learning rate: 4.775014352840514e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 22.3698	Cost: 41.08s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 5.5759	Cost: 16.78s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 5.8633	Cost: 17.01s
Train Epoch: 271 	Average Loss: 7.2274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.8323

Learning rate: 4.708209990258097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 21.9591	Cost: 39.56s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 5.7275	Cost: 17.04s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 5.9335	Cost: 13.97s
Train Epoch: 272 	Average Loss: 7.2501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.7650

Learning rate: 4.641732050210033e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 21.8715	Cost: 36.76s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 5.8745	Cost: 16.19s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 6.0398	Cost: 10.37s
Train Epoch: 273 	Average Loss: 7.1930
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.1592

Learning rate: 4.575584633368813e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 22.0425	Cost: 34.93s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 6.0324	Cost: 10.37s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 6.1288	Cost: 16.44s
Train Epoch: 274 	Average Loss: 7.2942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.8471

Learning rate: 4.509771820018683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 22.3851	Cost: 31.68s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 6.1167	Cost: 12.60s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 5.9605	Cost: 12.41s
Train Epoch: 275 	Average Loss: 7.3362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9332

Learning rate: 4.4442976698039786e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 21.9578	Cost: 33.56s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 5.8942	Cost: 9.82s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 5.7746	Cost: 28.73s
Train Epoch: 276 	Average Loss: 7.2970
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9123

Learning rate: 4.379166221478695e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 22.0955	Cost: 43.40s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 5.7189	Cost: 16.82s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 5.6191	Cost: 13.95s
Train Epoch: 277 	Average Loss: 7.2908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5116

Learning rate: 4.3143814926573614e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 22.0519	Cost: 38.96s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 5.5810	Cost: 15.19s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 5.5134	Cost: 9.40s
Train Epoch: 278 	Average Loss: 7.1589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.6489

Learning rate: 4.249947479567216e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 22.1936	Cost: 33.55s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 5.3478	Cost: 9.74s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 5.3042	Cost: 17.54s
Train Epoch: 279 	Average Loss: 6.9890
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.7721

Learning rate: 4.1858681568016955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 21.9783	Cost: 31.08s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 5.2883	Cost: 9.66s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 5.3698	Cost: 12.30s
Train Epoch: 280 	Average Loss: 6.9515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.3540

Learning rate: 4.122147477075271e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 21.9776	Cost: 31.40s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 5.4172	Cost: 9.59s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 5.3835	Cost: 13.91s
Train Epoch: 281 	Average Loss: 7.1029
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9888

Learning rate: 4.058789370979617e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 21.9543	Cost: 31.83s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 5.2564	Cost: 9.72s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 5.1885	Cost: 13.64s
Train Epoch: 282 	Average Loss: 6.9122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9152

Learning rate: 3.995797746741162e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 23.3315	Cost: 30.93s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 5.3287	Cost: 9.77s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 6.0282	Cost: 14.59s
Train Epoch: 283 	Average Loss: 7.1550
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9997

Learning rate: 3.933176489980003e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 22.8205	Cost: 30.07s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 5.8548	Cost: 9.73s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 5.5161	Cost: 13.66s
Train Epoch: 284 	Average Loss: 7.3346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9113

Learning rate: 3.8709294634702356e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 22.1174	Cost: 31.74s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 5.1730	Cost: 9.65s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 5.1496	Cost: 13.44s
Train Epoch: 285 	Average Loss: 6.8582
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.8087

Learning rate: 3.809060506901661e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 21.9659	Cost: 30.56s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 5.2491	Cost: 10.07s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 5.1036	Cost: 20.28s
Train Epoch: 286 	Average Loss: 6.8111
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.8442

Learning rate: 3.747573436642949e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 22.1626	Cost: 32.29s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 5.0079	Cost: 9.87s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 4.8688	Cost: 22.12s
Train Epoch: 287 	Average Loss: 6.5922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.7691

Learning rate: 3.686472045506224e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 22.1721	Cost: 34.87s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 4.9029	Cost: 16.51s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 4.6548	Cost: 16.33s
Train Epoch: 288 	Average Loss: 6.4882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.1467

Learning rate: 3.625760102513104e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 22.1324	Cost: 34.29s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 4.8098	Cost: 16.44s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 4.6957	Cost: 16.55s
Train Epoch: 289 	Average Loss: 6.3950
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.0318

Learning rate: 3.5654413526622126e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 22.2877	Cost: 34.99s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 4.7595	Cost: 16.63s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 4.7395	Cost: 16.14s
Train Epoch: 290 	Average Loss: 6.3812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9413

Learning rate: 3.505519516698166e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 21.9313	Cost: 35.32s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 4.6821	Cost: 16.51s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 4.6804	Cost: 16.65s
Train Epoch: 291 	Average Loss: 6.3152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9411

Learning rate: 3.445998290882063e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 22.2186	Cost: 36.94s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 4.5911	Cost: 16.11s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 4.5224	Cost: 15.83s
Train Epoch: 292 	Average Loss: 6.2307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9063

Learning rate: 3.386881346763484e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 22.2082	Cost: 34.32s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 4.5847	Cost: 16.97s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 4.4967	Cost: 9.62s
Train Epoch: 293 	Average Loss: 6.1739
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9913

Learning rate: 3.328172330954006e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 22.1028	Cost: 34.47s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 4.5815	Cost: 14.85s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 4.4976	Cost: 9.54s
Train Epoch: 294 	Average Loss: 6.1931
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.1001

Learning rate: 3.269874864902267e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 22.0506	Cost: 32.74s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 4.4895	Cost: 9.71s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 4.3786	Cost: 14.65s
Train Epoch: 295 	Average Loss: 6.1180
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.0623

Learning rate: 3.2119925446705836e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 22.3406	Cost: 32.61s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 4.3755	Cost: 12.74s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 4.4293	Cost: 12.52s
Train Epoch: 296 	Average Loss: 6.1042
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.1742

Learning rate: 3.1545289407131144e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 22.1173	Cost: 30.77s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 4.4198	Cost: 9.76s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 4.3425	Cost: 21.15s
Train Epoch: 297 	Average Loss: 6.0399
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.1664

Learning rate: 3.09748759765563e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 22.3030	Cost: 34.16s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 4.3584	Cost: 13.38s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 4.3242	Cost: 19.22s
Train Epoch: 298 	Average Loss: 6.0154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4814

Learning rate: 3.0408720340768585e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 22.2445	Cost: 33.47s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 4.3662	Cost: 16.40s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 4.3336	Cost: 16.88s
Train Epoch: 299 	Average Loss: 6.0033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4868

Learning rate: 2.9846857422914446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 22.1941	Cost: 34.69s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 4.2887	Cost: 16.54s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 4.1138	Cost: 16.42s
Train Epoch: 300 	Average Loss: 5.9777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.9558

Learning rate: 2.9289321881345268e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 22.8673	Cost: 35.34s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 4.2627	Cost: 16.98s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 4.2019	Cost: 15.22s
Train Epoch: 301 	Average Loss: 5.9833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.2789

Learning rate: 2.8736148107479478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 22.5386	Cost: 36.26s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 4.1769	Cost: 13.46s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 4.2508	Cost: 9.55s
Train Epoch: 302 	Average Loss: 5.9720
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.7596

Learning rate: 2.8187370223681142e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 23.2075	Cost: 35.05s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 4.4158	Cost: 12.45s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 4.4328	Cost: 12.91s
Train Epoch: 303 	Average Loss: 6.1314
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.3639

Learning rate: 2.764302208115509e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 22.9004	Cost: 31.51s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 4.6694	Cost: 12.22s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 4.6416	Cost: 10.64s
Train Epoch: 304 	Average Loss: 6.3213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4708

Learning rate: 2.710313725785888e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 22.1104	Cost: 31.19s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 4.6558	Cost: 9.90s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 4.4450	Cost: 26.49s
Train Epoch: 305 	Average Loss: 6.2973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4094

Learning rate: 2.6567749056431446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 22.3456	Cost: 35.42s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 4.3156	Cost: 16.49s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 4.3301	Cost: 16.56s
Train Epoch: 306 	Average Loss: 6.0155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5574

Learning rate: 2.6036890502139035e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 22.9866	Cost: 34.62s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 4.3879	Cost: 15.93s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 6.0305	Cost: 17.15s
Train Epoch: 307 	Average Loss: 6.5202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.6181

Learning rate: 2.55105943408378e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 22.3726	Cost: 33.77s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 6.4448	Cost: 15.94s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 5.7578	Cost: 16.62s
Train Epoch: 308 	Average Loss: 7.7550
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.7343

Learning rate: 2.4988893036954053e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 24.0716	Cost: 34.65s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 6.4804	Cost: 16.89s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 5.1591	Cost: 17.13s
Train Epoch: 309 	Average Loss: 7.1158
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.3474

Learning rate: 2.4471818771481658e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 22.5705	Cost: 35.32s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 4.8799	Cost: 15.88s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 4.7106	Cost: 11.72s
Train Epoch: 310 	Average Loss: 6.5367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5632

Learning rate: 2.3959403439996917e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 23.3065	Cost: 33.87s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 4.8188	Cost: 14.67s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 4.6097	Cost: 9.59s
Train Epoch: 311 	Average Loss: 6.6959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4637

Learning rate: 2.345167865069121e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 23.0644	Cost: 34.65s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 4.6797	Cost: 11.48s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 4.6345	Cost: 13.50s
Train Epoch: 312 	Average Loss: 6.3507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5215

Learning rate: 2.2948675722421096e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 22.2446	Cost: 31.53s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 4.4676	Cost: 12.12s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 4.3427	Cost: 10.90s
Train Epoch: 313 	Average Loss: 6.1130
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.2304

Learning rate: 2.2450425682776575e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 22.3992	Cost: 29.94s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 4.2460	Cost: 9.75s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 4.1971	Cost: 22.40s
Train Epoch: 314 	Average Loss: 5.9549
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.8336

Learning rate: 2.1956959266167054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 22.1714	Cost: 33.21s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 4.1538	Cost: 12.68s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 4.1565	Cost: 19.60s
Train Epoch: 315 	Average Loss: 5.8470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.1668

Learning rate: 2.1468306911925506e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 22.6331	Cost: 35.76s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 4.1227	Cost: 16.43s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 4.0503	Cost: 16.29s
Train Epoch: 316 	Average Loss: 5.7966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.3104

Learning rate: 2.098449876243097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 22.3249	Cost: 33.70s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 4.0122	Cost: 16.42s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 3.9946	Cost: 17.38s
Train Epoch: 317 	Average Loss: 5.7358
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.2412

Learning rate: 2.050556466124901e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 22.4059	Cost: 34.21s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 3.9697	Cost: 17.07s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 3.9915	Cost: 17.04s
Train Epoch: 318 	Average Loss: 5.6880
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.3680

Learning rate: 2.0031534151290953e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 22.0813	Cost: 37.55s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 3.9728	Cost: 16.96s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 3.9078	Cost: 10.72s
Train Epoch: 319 	Average Loss: 5.6480
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.7320

Learning rate: 1.9562436472991562e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 22.2624	Cost: 35.76s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 3.8991	Cost: 12.28s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 3.8717	Cost: 12.04s
Train Epoch: 320 	Average Loss: 5.6037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5049

Learning rate: 1.9098300562505276e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 22.6708	Cost: 33.73s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 3.8079	Cost: 12.46s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 3.7561	Cost: 12.85s
Train Epoch: 321 	Average Loss: 5.5735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4499

Learning rate: 1.863915504992132e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 22.3486	Cost: 31.74s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 3.7962	Cost: 9.94s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 3.7603	Cost: 21.12s
Train Epoch: 322 	Average Loss: 5.5226
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.3059

Learning rate: 1.8185028257497683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 22.2863	Cost: 32.57s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 3.7328	Cost: 11.56s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 3.7800	Cost: 21.59s
Train Epoch: 323 	Average Loss: 5.5525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.2965

Learning rate: 1.7735948197914044e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 22.3584	Cost: 34.33s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 3.8891	Cost: 16.33s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 3.9586	Cost: 16.50s
Train Epoch: 324 	Average Loss: 5.7394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9210

Learning rate: 1.729194257254384e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 22.8152	Cost: 36.08s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 3.8996	Cost: 16.62s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 3.7550	Cost: 16.46s
Train Epoch: 325 	Average Loss: 5.5955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.8322

Learning rate: 1.685303876974551e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 22.3815	Cost: 35.30s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 3.7558	Cost: 16.93s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 3.6487	Cost: 16.39s
Train Epoch: 326 	Average Loss: 5.4804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.7959

Learning rate: 1.6419263863173007e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 22.3569	Cost: 38.74s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 3.6700	Cost: 15.20s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 3.5948	Cost: 9.53s
Train Epoch: 327 	Average Loss: 5.4103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.2803

Learning rate: 1.599064461010582e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 22.2570	Cost: 34.06s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 3.6565	Cost: 9.72s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 3.5667	Cost: 15.84s
Train Epoch: 328 	Average Loss: 5.3745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4146

Learning rate: 1.5567207449798525e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 22.2421	Cost: 32.44s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 3.5816	Cost: 9.78s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 3.5903	Cost: 21.19s
Train Epoch: 329 	Average Loss: 5.3446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.3561

Learning rate: 1.5148978501849652e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 22.2759	Cost: 32.99s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 3.6683	Cost: 12.75s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 3.5803	Cost: 17.92s
Train Epoch: 330 	Average Loss: 5.3389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.7876

Learning rate: 1.4735983564590815e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 22.2040	Cost: 34.79s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 3.5844	Cost: 16.43s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 3.6061	Cost: 17.00s
Train Epoch: 331 	Average Loss: 5.3288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.3429

Learning rate: 1.4328248113495055e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 22.4800	Cost: 34.47s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 3.5430	Cost: 16.64s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 3.4754	Cost: 16.84s
Train Epoch: 332 	Average Loss: 5.2789
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.3390

Learning rate: 1.3925797299605635e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 22.3858	Cost: 36.41s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 3.5224	Cost: 16.66s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 3.5075	Cost: 15.31s
Train Epoch: 333 	Average Loss: 5.2462
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5830

Learning rate: 1.3528655947984512e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 22.7199	Cost: 34.01s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 3.4544	Cost: 16.21s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 3.4174	Cost: 10.41s
Train Epoch: 334 	Average Loss: 5.2667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4942

Learning rate: 1.3136848556180878e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 22.4780	Cost: 33.22s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 3.4322	Cost: 11.09s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 3.3621	Cost: 12.57s
Train Epoch: 335 	Average Loss: 5.2223
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5885

Learning rate: 1.2750399292720314e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 22.6289	Cost: 32.06s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 3.4169	Cost: 12.69s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 3.4365	Cost: 12.71s
Train Epoch: 336 	Average Loss: 5.2267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4327

Learning rate: 1.2369331995613651e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 23.1353	Cost: 31.70s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 3.4890	Cost: 9.88s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 3.5533	Cost: 24.24s
Train Epoch: 337 	Average Loss: 5.2823
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.8249

Learning rate: 1.1993670170886837e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 22.2885	Cost: 33.78s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 3.4627	Cost: 16.22s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 3.5177	Cost: 16.77s
Train Epoch: 338 	Average Loss: 5.2358
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4162

Learning rate: 1.1623436991130663e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 22.3714	Cost: 36.35s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 3.3042	Cost: 16.50s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 3.3329	Cost: 16.56s
Train Epoch: 339 	Average Loss: 5.1776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4401

Learning rate: 1.1258655294071704e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 23.0701	Cost: 33.63s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 3.4045	Cost: 15.01s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 3.2787	Cost: 17.34s
Train Epoch: 340 	Average Loss: 5.1847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4216

Learning rate: 1.089934758116323e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 22.6330	Cost: 33.40s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 3.4716	Cost: 15.93s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 3.3702	Cost: 16.92s
Train Epoch: 341 	Average Loss: 5.1755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.2570

Learning rate: 1.054553601619753e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 22.5702	Cost: 35.56s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 3.3516	Cost: 17.33s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 3.3309	Cost: 17.32s
Train Epoch: 342 	Average Loss: 5.1399
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.6576

Learning rate: 1.0197242423938455e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 22.9365	Cost: 35.88s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 3.3058	Cost: 17.09s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 3.2635	Cost: 15.50s
Train Epoch: 343 	Average Loss: 5.1279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.6234

Learning rate: 9.854488288775428e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 22.4779	Cost: 34.41s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 3.2811	Cost: 15.08s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 3.2417	Cost: 12.82s
Train Epoch: 344 	Average Loss: 5.0902
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.6160

Learning rate: 9.517294753398073e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 22.8046	Cost: 33.98s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 3.2810	Cost: 14.93s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 3.2650	Cost: 9.66s
Train Epoch: 345 	Average Loss: 5.0912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.9731

Learning rate: 9.185682617491872e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 22.5387	Cost: 31.50s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 3.3114	Cost: 9.60s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 3.2493	Cost: 14.75s
Train Epoch: 346 	Average Loss: 5.0521
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5855

Learning rate: 8.859672336455501e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 22.5235	Cost: 32.96s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 3.2930	Cost: 12.54s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 3.1881	Cost: 12.57s
Train Epoch: 347 	Average Loss: 5.0488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.0244

Learning rate: 8.539284020138645e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 22.5139	Cost: 31.53s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 3.2520	Cost: 9.77s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 3.2196	Cost: 22.21s
Train Epoch: 348 	Average Loss: 5.0539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5947

Learning rate: 8.224537431601915e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 22.4592	Cost: 33.03s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 3.1824	Cost: 11.25s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 3.1622	Cost: 18.78s
Train Epoch: 349 	Average Loss: 4.9906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.6173

Learning rate: 7.915451985897387e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 22.5896	Cost: 37.85s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 3.3141	Cost: 16.86s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 3.1489	Cost: 16.58s
Train Epoch: 350 	Average Loss: 5.0075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5943

Learning rate: 7.612046748871354e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 22.3965	Cost: 39.80s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 3.1905	Cost: 15.68s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 3.2337	Cost: 16.44s
Train Epoch: 351 	Average Loss: 4.9893
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5078

Learning rate: 7.314340435987926e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 22.5672	Cost: 37.36s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 3.2605	Cost: 16.44s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 3.2008	Cost: 16.21s
Train Epoch: 352 	Average Loss: 5.0248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4939

Learning rate: 7.022351411174871e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 22.3461	Cost: 40.45s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 3.1547	Cost: 16.25s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 3.1063	Cost: 14.31s
Train Epoch: 353 	Average Loss: 4.9779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.8920

Learning rate: 6.736097685690606e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 22.2628	Cost: 38.62s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 3.0737	Cost: 15.79s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 3.1090	Cost: 9.57s
Train Epoch: 354 	Average Loss: 4.9610
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.0779

Learning rate: 6.455596917013267e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 22.5902	Cost: 33.44s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 3.1007	Cost: 9.61s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 3.1056	Cost: 14.68s
Train Epoch: 355 	Average Loss: 4.9511
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.8050

Learning rate: 6.1808664077516005e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 22.4636	Cost: 32.62s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 3.2045	Cost: 12.58s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 3.0872	Cost: 12.78s
Train Epoch: 356 	Average Loss: 4.9452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5100

Learning rate: 5.91192310457746e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 22.6116	Cost: 32.38s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 3.1178	Cost: 9.82s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 3.0954	Cost: 25.25s
Train Epoch: 357 	Average Loss: 4.9335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.6707

Learning rate: 5.648783597180656e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 22.4155	Cost: 34.73s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 3.1735	Cost: 14.56s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 3.0507	Cost: 17.89s
Train Epoch: 358 	Average Loss: 4.9190
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5969

Learning rate: 5.3914641172454745e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 22.5205	Cost: 35.94s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 3.1063	Cost: 16.40s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 3.0302	Cost: 16.40s
Train Epoch: 359 	Average Loss: 4.9049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.6508

Learning rate: 5.139980537449555e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 22.5085	Cost: 35.76s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 3.1549	Cost: 16.56s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 3.0597	Cost: 16.97s
Train Epoch: 360 	Average Loss: 4.9018
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.7905

Learning rate: 4.894348370484651e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 22.3379	Cost: 38.35s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 3.0735	Cost: 15.89s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 3.0572	Cost: 9.65s
Train Epoch: 361 	Average Loss: 4.8940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.8504

Learning rate: 4.6545827680998834e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 22.5028	Cost: 34.41s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 3.0253	Cost: 12.62s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 3.0119	Cost: 11.87s
Train Epoch: 362 	Average Loss: 4.8774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5868

Learning rate: 4.420698520166991e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 22.5266	Cost: 34.07s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 3.0309	Cost: 13.00s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 2.9844	Cost: 12.78s
Train Epoch: 363 	Average Loss: 4.8643
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.7020

Learning rate: 4.1927100537680815e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 22.5599	Cost: 31.45s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 3.1083	Cost: 10.27s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 3.0698	Cost: 17.43s
Train Epoch: 364 	Average Loss: 4.8715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5666

Learning rate: 3.970631432305708e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 22.4870	Cost: 31.68s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 3.0452	Cost: 9.70s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 3.0167	Cost: 21.88s
Train Epoch: 365 	Average Loss: 4.8541
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5514

Learning rate: 3.7544763546352753e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 22.6051	Cost: 33.26s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 3.0238	Cost: 16.49s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 3.0416	Cost: 16.38s
Train Epoch: 366 	Average Loss: 4.8514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.8093

Learning rate: 3.5442581542202067e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 22.4627	Cost: 34.28s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 3.0171	Cost: 16.89s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 3.0413	Cost: 17.17s
Train Epoch: 367 	Average Loss: 4.8460
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.8081

Learning rate: 3.339989798309276e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 22.5439	Cost: 34.78s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 2.9734	Cost: 17.05s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 2.9705	Cost: 16.92s
Train Epoch: 368 	Average Loss: 4.8327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.1732

Learning rate: 3.1416838871369064e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 22.5304	Cost: 34.84s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 3.0522	Cost: 16.98s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 3.0811	Cost: 14.96s
Train Epoch: 369 	Average Loss: 4.8353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.8525

Learning rate: 2.9493526531457563e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 22.6066	Cost: 34.40s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 3.0369	Cost: 16.36s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 3.0478	Cost: 10.34s
Train Epoch: 370 	Average Loss: 4.8339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.7610

Learning rate: 2.7630079602323468e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 22.5427	Cost: 34.10s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 3.0471	Cost: 10.75s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 2.9750	Cost: 12.98s
Train Epoch: 371 	Average Loss: 4.8508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.9886

Learning rate: 2.582661303015068e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 22.7166	Cost: 32.60s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 3.0026	Cost: 12.80s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 2.9818	Cost: 12.96s
Train Epoch: 372 	Average Loss: 4.8345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.2430

Learning rate: 2.40832380612527e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 22.4326	Cost: 30.82s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 3.0034	Cost: 9.91s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 2.9206	Cost: 18.88s
Train Epoch: 373 	Average Loss: 4.7889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.7426

Learning rate: 2.2400062235209426e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 22.4850	Cost: 32.91s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 2.9519	Cost: 11.07s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 3.0309	Cost: 20.15s
Train Epoch: 374 	Average Loss: 4.8016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.7711

Learning rate: 2.0777189378234156e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 22.6267	Cost: 35.04s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 3.0184	Cost: 16.42s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 2.9166	Cost: 16.46s
Train Epoch: 375 	Average Loss: 4.8110
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.9441

Learning rate: 1.9214719596769582e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 22.5676	Cost: 33.96s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 3.0178	Cost: 15.81s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 2.9582	Cost: 17.29s
Train Epoch: 376 	Average Loss: 4.8141
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.9221

Learning rate: 1.771274927131129e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 22.5564	Cost: 35.65s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 3.0094	Cost: 17.08s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 3.0297	Cost: 14.68s
Train Epoch: 377 	Average Loss: 4.7853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.8413

Learning rate: 1.6271371050464177e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 22.5982	Cost: 33.98s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 2.9713	Cost: 16.65s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 2.9956	Cost: 9.68s
Train Epoch: 378 	Average Loss: 4.7790
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.7395

Learning rate: 1.4890673845226142e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 22.3773	Cost: 33.73s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 3.0036	Cost: 9.59s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 2.9083	Cost: 17.03s
Train Epoch: 379 	Average Loss: 4.7698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.6176

Learning rate: 1.3570742823504575e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 22.4582	Cost: 31.74s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 2.9449	Cost: 12.52s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 2.9108	Cost: 11.01s
Train Epoch: 380 	Average Loss: 4.8030
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5869

Learning rate: 1.2311659404862349e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 22.3663	Cost: 31.05s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 2.9944	Cost: 9.93s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 2.9847	Cost: 22.62s
Train Epoch: 381 	Average Loss: 4.7894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.4250

Learning rate: 1.1113501255495491e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 22.4653	Cost: 34.06s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 3.0201	Cost: 13.67s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 3.0041	Cost: 19.25s
Train Epoch: 382 	Average Loss: 4.7773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.1060

Learning rate: 9.97634228344247e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 22.5476	Cost: 35.10s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 2.9465	Cost: 16.35s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 2.8919	Cost: 16.57s
Train Epoch: 383 	Average Loss: 4.7696
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.6311

Learning rate: 8.90025263402528e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 22.7308	Cost: 36.16s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 2.9879	Cost: 16.87s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 2.9501	Cost: 17.35s
Train Epoch: 384 	Average Loss: 4.7799
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.7230

Learning rate: 7.88529868552224e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 22.5931	Cost: 34.69s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 3.0080	Cost: 17.26s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 3.0600	Cost: 11.11s
Train Epoch: 385 	Average Loss: 4.7871
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.9849

Learning rate: 6.931543045073711e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 22.6935	Cost: 34.14s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 2.9973	Cost: 9.60s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 2.9509	Cost: 16.94s
Train Epoch: 386 	Average Loss: 4.7848
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.1029

Learning rate: 6.039044544820409e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 22.6430	Cost: 32.21s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 3.0792	Cost: 12.78s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 3.0156	Cost: 9.88s
Train Epoch: 387 	Average Loss: 4.7946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5604

Learning rate: 5.207858238273524e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 22.4098	Cost: 31.78s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 2.9539	Cost: 9.92s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 2.9605	Cost: 25.87s
Train Epoch: 388 	Average Loss: 4.7577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5786

Learning rate: 4.4380353969200063e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 22.4106	Cost: 35.08s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 2.9908	Cost: 16.40s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 2.9085	Cost: 16.32s
Train Epoch: 389 	Average Loss: 4.7746
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.8481

Learning rate: 3.7296235070587456e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 22.6656	Cost: 34.96s
Train Epoch: 390 [40960/90000 (45%)]	Loss: 2.9235	Cost: 16.53s
Train Epoch: 390 [81920/90000 (91%)]	Loss: 2.9416	Cost: 16.48s
Train Epoch: 390 	Average Loss: 4.7529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.9020

Learning rate: 3.082666266872038e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 22.5639	Cost: 36.95s
Train Epoch: 391 [40960/90000 (45%)]	Loss: 2.9687	Cost: 16.76s
Train Epoch: 391 [81920/90000 (91%)]	Loss: 2.9609	Cost: 15.65s
Train Epoch: 391 	Average Loss: 4.7486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.6803

Learning rate: 2.497203583729958e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 22.6155	Cost: 34.32s
Train Epoch: 392 [40960/90000 (45%)]	Loss: 2.9530	Cost: 13.71s
Train Epoch: 392 [81920/90000 (91%)]	Loss: 2.9072	Cost: 13.09s
Train Epoch: 392 	Average Loss: 4.7632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.8456

Learning rate: 1.973271571728442e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 22.5141	Cost: 35.71s
Train Epoch: 393 [40960/90000 (45%)]	Loss: 3.0257	Cost: 14.77s
Train Epoch: 393 [81920/90000 (91%)]	Loss: 2.9130	Cost: 10.22s
Train Epoch: 393 	Average Loss: 4.7654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.0123

Learning rate: 1.5109025494620685e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 22.5395	Cost: 32.80s
Train Epoch: 394 [40960/90000 (45%)]	Loss: 3.0206	Cost: 9.81s
Train Epoch: 394 [81920/90000 (91%)]	Loss: 2.9441	Cost: 15.76s
Train Epoch: 394 	Average Loss: 4.7605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.7779

Learning rate: 1.1101250380300971e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 22.6111	Cost: 31.86s
Train Epoch: 395 [40960/90000 (45%)]	Loss: 2.9853	Cost: 9.86s
Train Epoch: 395 [81920/90000 (91%)]	Loss: 2.9587	Cost: 20.58s
Train Epoch: 395 	Average Loss: 4.7748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.9288

Learning rate: 7.709637592770994e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 22.3660	Cost: 32.68s
Train Epoch: 396 [40960/90000 (45%)]	Loss: 3.0294	Cost: 11.42s
Train Epoch: 396 [81920/90000 (91%)]	Loss: 3.0093	Cost: 20.37s
Train Epoch: 396 	Average Loss: 4.7763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.7326

Learning rate: 4.934396342684002e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 22.4902	Cost: 36.22s
Train Epoch: 397 [40960/90000 (45%)]	Loss: 2.9573	Cost: 16.87s
Train Epoch: 397 [81920/90000 (91%)]	Loss: 2.9658	Cost: 16.50s
Train Epoch: 397 	Average Loss: 4.7444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.6159

Learning rate: 2.7756978199944282e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 22.5789	Cost: 35.37s
Train Epoch: 398 [40960/90000 (45%)]	Loss: 2.9902	Cost: 16.47s
Train Epoch: 398 [81920/90000 (91%)]	Loss: 2.9276	Cost: 16.58s
Train Epoch: 398 	Average Loss: 4.7800
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5253

Learning rate: 1.2336751833941234e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 22.6122	Cost: 36.25s
Train Epoch: 399 [40960/90000 (45%)]	Loss: 2.9616	Cost: 16.60s
Train Epoch: 399 [81920/90000 (91%)]	Loss: 2.9452	Cost: 15.57s
Train Epoch: 399 	Average Loss: 4.7700
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.3160

Learning rate: 3.084235521033653e-09
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 22.6968	Cost: 34.56s
Train Epoch: 400 [40960/90000 (45%)]	Loss: 2.9475	Cost: 14.74s
Train Epoch: 400 [81920/90000 (91%)]	Loss: 2.9441	Cost: 9.65s
Train Epoch: 400 	Average Loss: 4.7492
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.8116

Stopping timer.
Training time (including validation): 369090.39419698715 seconds
Saving model
Transfer learning by starting with alpha=0.02!
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 23.6603	Cost: 31.47s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 21.6299	Cost: 12.85s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 20.7681	Cost: 9.94s
Train Epoch: 1 	Average Loss: 21.8479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3054

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999691576447898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 20.5387	Cost: 32.31s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 19.6028	Cost: 9.75s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 19.2134	Cost: 21.56s
Train Epoch: 2 	Average Loss: 19.6798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6265

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 19.3678	Cost: 34.23s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 18.6598	Cost: 16.25s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 18.4774	Cost: 17.19s
Train Epoch: 3 	Average Loss: 18.7135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9496

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 18.7952	Cost: 34.52s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 18.1517	Cost: 16.05s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 18.1255	Cost: 16.50s
Train Epoch: 4 	Average Loss: 18.2285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6441

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.00019995065603657316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 18.5480	Cost: 35.54s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 17.8397	Cost: 16.82s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 17.8231	Cost: 16.67s
Train Epoch: 5 	Average Loss: 17.9348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4331

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.0001999229036240723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 18.5252	Cost: 34.16s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 17.6228	Cost: 16.62s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 17.6468	Cost: 16.14s
Train Epoch: 6 	Average Loss: 17.7082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3715

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019988898749619702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 18.3523	Cost: 31.76s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 17.3812	Cost: 16.26s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 17.3772	Cost: 10.54s
Train Epoch: 7 	Average Loss: 17.5568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2823

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.00019984890974505381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 18.3927	Cost: 32.95s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 17.2821	Cost: 9.64s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 17.3454	Cost: 15.95s
Train Epoch: 8 	Average Loss: 17.4458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2867

Learning rate: 0.00019980267284282717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 18.2363	Cost: 30.97s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 17.1415	Cost: 11.78s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 17.1661	Cost: 10.52s
Train Epoch: 9 	Average Loss: 17.3246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3364

Learning rate: 0.00019975027964162705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 18.3678	Cost: 29.80s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 17.0999	Cost: 9.67s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 17.0780	Cost: 23.32s
Train Epoch: 10 	Average Loss: 17.2278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2847

Learning rate: 0.00019969173337331284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 18.2625	Cost: 32.01s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 17.0493	Cost: 14.92s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 17.1706	Cost: 16.72s
Train Epoch: 11 	Average Loss: 17.1631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4172

Learning rate: 0.00019962703764929416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 18.3426	Cost: 33.90s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 16.9968	Cost: 17.03s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 17.0454	Cost: 16.52s
Train Epoch: 12 	Average Loss: 17.1448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3910

Learning rate: 0.00019955619646030802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 18.4835	Cost: 33.34s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 16.9002	Cost: 16.38s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 16.8261	Cost: 16.57s
Train Epoch: 13 	Average Loss: 17.0401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3613

Learning rate: 0.00019947921417617267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 18.4715	Cost: 33.98s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 16.7641	Cost: 16.56s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 16.6595	Cost: 17.39s
Train Epoch: 14 	Average Loss: 16.9116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4470

Learning rate: 0.000199396095545518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 18.4200	Cost: 37.85s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 16.6320	Cost: 17.11s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 16.5673	Cost: 13.79s
Train Epoch: 15 	Average Loss: 16.8148
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4322

Learning rate: 0.00019930684569549264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 18.5330	Cost: 37.97s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 16.5024	Cost: 15.75s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 16.5202	Cost: 9.61s
Train Epoch: 16 	Average Loss: 16.7202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5998

Learning rate: 0.0001992114701314478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 18.6182	Cost: 32.60s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 16.4505	Cost: 9.61s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 16.4346	Cost: 15.89s
Train Epoch: 17 	Average Loss: 16.6497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6139

Learning rate: 0.00019910997473659747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 18.6739	Cost: 32.35s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 16.3656	Cost: 12.76s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 16.4559	Cost: 10.48s
Train Epoch: 18 	Average Loss: 16.6065
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6538

Learning rate: 0.00019900236577165574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 18.6779	Cost: 29.73s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 16.2569	Cost: 9.86s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 16.3765	Cost: 20.77s
Train Epoch: 19 	Average Loss: 16.5418
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7141

Learning rate: 0.00019888864987445046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 18.8413	Cost: 33.10s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 16.1790	Cost: 12.45s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 16.2329	Cost: 17.51s
Train Epoch: 20 	Average Loss: 16.4601
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8122

Learning rate: 0.00019876883405951377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 18.8013	Cost: 31.92s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 16.0860	Cost: 16.36s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 16.1811	Cost: 16.11s
Train Epoch: 21 	Average Loss: 16.4090
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8505

Learning rate: 0.00019864292571764955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 18.8976	Cost: 31.53s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 16.1625	Cost: 16.96s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 16.1038	Cost: 16.37s
Train Epoch: 22 	Average Loss: 16.3720
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8979

Learning rate: 0.0001985109326154774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 19.0015	Cost: 33.32s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 16.0191	Cost: 16.73s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 15.9438	Cost: 16.88s
Train Epoch: 23 	Average Loss: 16.2935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0031

Learning rate: 0.00019837286289495361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 19.0422	Cost: 33.35s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 15.9708	Cost: 16.64s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 15.9157	Cost: 16.81s
Train Epoch: 24 	Average Loss: 16.2519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3680

Learning rate: 0.0001982287250728689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 19.3477	Cost: 35.02s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 16.8963	Cost: 16.65s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 16.6136	Cost: 16.59s
Train Epoch: 25 	Average Loss: 17.0466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0060

Learning rate: 0.00019807852804032305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 18.9355	Cost: 33.98s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 16.3550	Cost: 16.59s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 16.2425	Cost: 16.26s
Train Epoch: 26 	Average Loss: 16.5816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9192

Learning rate: 0.00019792228106217658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 19.0791	Cost: 35.85s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 16.1370	Cost: 14.78s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 15.9745	Cost: 11.76s
Train Epoch: 27 	Average Loss: 16.3446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9317

Learning rate: 0.0001977599937764791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 19.0685	Cost: 37.54s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 15.8184	Cost: 11.79s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 15.6970	Cost: 11.16s
Train Epoch: 28 	Average Loss: 16.1240
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0411

Learning rate: 0.00019759167619387474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 19.0102	Cost: 33.92s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 15.7121	Cost: 12.83s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 16.0364	Cost: 13.16s
Train Epoch: 29 	Average Loss: 16.1115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2596

Learning rate: 0.00019741733869698495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 19.1624	Cost: 31.05s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 15.9455	Cost: 9.84s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 15.7479	Cost: 21.77s
Train Epoch: 30 	Average Loss: 16.2438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0897

Learning rate: 0.00019723699203976766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 19.1449	Cost: 33.47s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 15.7294	Cost: 11.94s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 15.8876	Cost: 17.09s
Train Epoch: 31 	Average Loss: 16.0335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4635

Learning rate: 0.00019705064734685425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 19.4018	Cost: 34.12s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 15.6376	Cost: 16.65s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 15.5465	Cost: 16.45s
Train Epoch: 32 	Average Loss: 15.9828
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3647

Learning rate: 0.00019685831611286313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 19.3795	Cost: 34.83s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 15.6498	Cost: 16.57s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 15.5546	Cost: 16.55s
Train Epoch: 33 	Average Loss: 15.9347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4103

Learning rate: 0.00019666001020169073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 19.4700	Cost: 34.59s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 15.4692	Cost: 15.31s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 15.4519	Cost: 17.43s
Train Epoch: 34 	Average Loss: 15.8063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4392

Learning rate: 0.0001964557418457798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 19.4534	Cost: 31.90s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 15.3636	Cost: 15.67s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 15.2830	Cost: 16.75s
Train Epoch: 35 	Average Loss: 15.6792
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4898

Learning rate: 0.0001962455236453647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 19.5227	Cost: 35.15s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 15.3000	Cost: 16.71s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 15.2230	Cost: 15.23s
Train Epoch: 36 	Average Loss: 15.6466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5367

Learning rate: 0.00019602936856769428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 19.6115	Cost: 34.17s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 15.2067	Cost: 14.85s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 15.0653	Cost: 11.81s
Train Epoch: 37 	Average Loss: 15.5678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6002

Learning rate: 0.0001958072899462319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 19.6878	Cost: 31.11s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 15.1106	Cost: 16.17s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 15.0284	Cost: 10.50s
Train Epoch: 38 	Average Loss: 15.5595
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5666

Learning rate: 0.00019557930147983297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 19.7280	Cost: 34.43s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 15.0974	Cost: 10.46s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 15.0908	Cost: 13.24s
Train Epoch: 39 	Average Loss: 15.5354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6679

Learning rate: 0.00019534541723190008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 19.7423	Cost: 32.59s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 15.1247	Cost: 12.86s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 15.1704	Cost: 13.30s
Train Epoch: 40 	Average Loss: 15.5325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6104

Learning rate: 0.00019510565162951532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 19.5786	Cost: 29.79s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 15.0023	Cost: 12.09s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 15.0078	Cost: 10.39s
Train Epoch: 41 	Average Loss: 15.4196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7174

Learning rate: 0.0001948600194625504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 19.7514	Cost: 29.12s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 14.8771	Cost: 9.86s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 14.8569	Cost: 22.72s
Train Epoch: 42 	Average Loss: 15.4023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6957

Learning rate: 0.00019460853588275446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 19.7827	Cost: 32.56s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 14.9782	Cost: 11.21s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 14.8709	Cost: 20.43s
Train Epoch: 43 	Average Loss: 15.3386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7574

Learning rate: 0.0001943512164028193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 19.8522	Cost: 32.89s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 14.7872	Cost: 16.43s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 14.8043	Cost: 16.46s
Train Epoch: 44 	Average Loss: 15.2750
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8295

Learning rate: 0.00019408807689542249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 19.9678	Cost: 32.77s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 14.7516	Cost: 16.42s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 14.7432	Cost: 16.56s
Train Epoch: 45 	Average Loss: 15.1817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9243

Learning rate: 0.00019381913359224837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 19.8607	Cost: 34.95s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 14.6117	Cost: 16.22s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 14.6111	Cost: 16.57s
Train Epoch: 46 	Average Loss: 15.1201
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9812

Learning rate: 0.0001935444030829867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 19.8858	Cost: 33.56s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 14.6522	Cost: 16.48s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 14.6725	Cost: 16.65s
Train Epoch: 47 	Average Loss: 15.0970
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9967

Learning rate: 0.00019326390231430937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 19.9862	Cost: 34.31s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 14.5789	Cost: 16.81s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 14.5315	Cost: 16.55s
Train Epoch: 48 	Average Loss: 15.0295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0578

Learning rate: 0.00019297764858882508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 20.0204	Cost: 33.70s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 14.5977	Cost: 16.93s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 14.7010	Cost: 17.30s
Train Epoch: 49 	Average Loss: 15.0676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0924

Learning rate: 0.000192685659564012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 20.4407	Cost: 32.61s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 14.8610	Cost: 16.54s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 14.7200	Cost: 16.96s
Train Epoch: 50 	Average Loss: 15.3095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8734

Learning rate: 0.00019238795325112859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 19.9172	Cost: 33.71s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 14.5380	Cost: 16.93s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 14.4151	Cost: 13.99s
Train Epoch: 51 	Average Loss: 15.0544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0473

Learning rate: 0.00019208454801410258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 20.1383	Cost: 32.26s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 14.2916	Cost: 16.89s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 14.3101	Cost: 9.64s
Train Epoch: 52 	Average Loss: 14.8661
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1015

Learning rate: 0.00019177546256839804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 20.0479	Cost: 30.98s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 14.1842	Cost: 9.64s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 14.3173	Cost: 13.92s
Train Epoch: 53 	Average Loss: 14.7865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2547

Learning rate: 0.0001914607159798613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 20.2311	Cost: 33.00s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 14.1835	Cost: 12.85s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 14.2280	Cost: 12.80s
Train Epoch: 54 	Average Loss: 14.7582
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2042

Learning rate: 0.00019114032766354445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 20.1369	Cost: 30.75s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 14.1048	Cost: 9.68s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 14.2464	Cost: 18.28s
Train Epoch: 55 	Average Loss: 14.7313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3813

Learning rate: 0.00019081431738250806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 20.2928	Cost: 30.62s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 14.6698	Cost: 10.09s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 14.6459	Cost: 21.69s
Train Epoch: 56 	Average Loss: 15.1323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1833

Learning rate: 0.00019048270524660188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 20.1293	Cost: 33.09s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 14.4260	Cost: 16.69s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 14.2802	Cost: 16.39s
Train Epoch: 57 	Average Loss: 14.8820
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1712

Learning rate: 0.0001901455117112245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 20.1705	Cost: 33.90s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 14.1549	Cost: 16.40s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 14.6022	Cost: 16.57s
Train Epoch: 58 	Average Loss: 14.7733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4653

Learning rate: 0.0001898027575760615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 20.5042	Cost: 32.75s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 15.8405	Cost: 16.81s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 15.4298	Cost: 16.87s
Train Epoch: 59 	Average Loss: 16.0521
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9737

Learning rate: 0.00018945446398380245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 19.8983	Cost: 35.44s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 14.8422	Cost: 16.84s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 14.4034	Cost: 14.33s
Train Epoch: 60 	Average Loss: 15.2420
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9048

Learning rate: 0.00018910065241883672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 20.1469	Cost: 33.39s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 14.3249	Cost: 13.97s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 14.2064	Cost: 9.63s
Train Epoch: 61 	Average Loss: 14.8376
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0772

Learning rate: 0.00018874134470592827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 20.0900	Cost: 33.65s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 14.1611	Cost: 9.64s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 14.0599	Cost: 14.25s
Train Epoch: 62 	Average Loss: 14.7198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1472

Learning rate: 0.0001883765630088693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 20.2377	Cost: 30.79s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 13.8504	Cost: 12.70s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 13.7030	Cost: 9.57s
Train Epoch: 63 	Average Loss: 14.4338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3352

Learning rate: 0.00018800632982911313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 20.4956	Cost: 30.43s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 13.5943	Cost: 9.76s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 13.6142	Cost: 23.06s
Train Epoch: 64 	Average Loss: 14.2690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4215

Learning rate: 0.00018763066800438628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 20.5469	Cost: 32.02s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 13.6094	Cost: 12.02s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 13.7118	Cost: 17.55s
Train Epoch: 65 	Average Loss: 14.2240
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5804

Learning rate: 0.00018724960070727966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 20.4879	Cost: 34.97s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 13.5201	Cost: 16.96s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 13.7064	Cost: 16.60s
Train Epoch: 66 	Average Loss: 14.2235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6605

Learning rate: 0.00018686315144381908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 20.6833	Cost: 33.71s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 13.5824	Cost: 16.88s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 13.5651	Cost: 16.62s
Train Epoch: 67 	Average Loss: 14.2182
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6034

Learning rate: 0.00018647134405201546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 20.7172	Cost: 33.28s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 13.4501	Cost: 16.21s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 13.4895	Cost: 16.67s
Train Epoch: 68 	Average Loss: 14.1391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6961

Learning rate: 0.00018607420270039433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 20.9672	Cost: 33.52s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 13.3670	Cost: 16.54s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 13.3816	Cost: 17.01s
Train Epoch: 69 	Average Loss: 14.0860
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7065

Learning rate: 0.00018567175188650495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 20.7968	Cost: 34.32s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 13.4077	Cost: 16.97s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 13.3078	Cost: 17.17s
Train Epoch: 70 	Average Loss: 14.0505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8442

Learning rate: 0.0001852640164354092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 20.9808	Cost: 36.86s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 13.3476	Cost: 16.08s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 13.3684	Cost: 12.39s
Train Epoch: 71 	Average Loss: 14.0164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7971

Learning rate: 0.00018485102149815036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 20.7685	Cost: 32.65s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 13.2276	Cost: 16.73s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 13.2938	Cost: 9.87s
Train Epoch: 72 	Average Loss: 13.9223
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8536

Learning rate: 0.0001844327925502015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 20.9824	Cost: 32.73s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 13.2617	Cost: 14.43s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 13.3444	Cost: 9.61s
Train Epoch: 73 	Average Loss: 13.9331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9747

Learning rate: 0.00018400935538989417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 20.8130	Cost: 32.33s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 13.3610	Cost: 9.81s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 13.4048	Cost: 13.99s
Train Epoch: 74 	Average Loss: 13.9769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8538

Learning rate: 0.00018358073613682703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 20.8463	Cost: 31.96s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 13.2492	Cost: 12.87s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 13.2858	Cost: 12.78s
Train Epoch: 75 	Average Loss: 14.0164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8674

Learning rate: 0.00018314696123025452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 20.7848	Cost: 29.76s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 13.2326	Cost: 10.01s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 13.2829	Cost: 19.75s
Train Epoch: 76 	Average Loss: 13.9455
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8782

Learning rate: 0.00018270805742745614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 20.9249	Cost: 31.87s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 13.2314	Cost: 9.71s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 13.2548	Cost: 20.36s
Train Epoch: 77 	Average Loss: 13.9107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8880

Learning rate: 0.00018226405180208597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 20.9571	Cost: 32.59s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 13.1023	Cost: 16.51s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 13.0274	Cost: 16.45s
Train Epoch: 78 	Average Loss: 13.7852
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8901

Learning rate: 0.00018181497174250233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 20.9423	Cost: 34.56s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 13.0546	Cost: 16.56s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 12.9695	Cost: 16.91s
Train Epoch: 79 	Average Loss: 13.7111
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0006

Learning rate: 0.00018136084495007872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 20.9793	Cost: 35.77s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 12.8855	Cost: 14.47s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 12.8909	Cost: 16.67s
Train Epoch: 80 	Average Loss: 13.6496
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1603

Learning rate: 0.00018090169943749476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 21.0688	Cost: 31.70s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 12.8628	Cost: 15.15s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 13.1342	Cost: 16.68s
Train Epoch: 81 	Average Loss: 13.7194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1263

Learning rate: 0.00018043756352700846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 21.0873	Cost: 32.39s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 13.0520	Cost: 16.07s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 13.0097	Cost: 17.27s
Train Epoch: 82 	Average Loss: 13.7643
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0821

Learning rate: 0.00017996846584870908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 21.1027	Cost: 35.50s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 12.8352	Cost: 16.97s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 12.8043	Cost: 15.19s
Train Epoch: 83 	Average Loss: 13.5781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1235

Learning rate: 0.000179494435338751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 20.9952	Cost: 33.08s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 12.6725	Cost: 15.41s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 12.7358	Cost: 11.76s
Train Epoch: 84 	Average Loss: 13.5495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1330

Learning rate: 0.00017901550123756904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 21.2291	Cost: 34.07s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 12.7301	Cost: 10.42s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 12.7140	Cost: 12.75s
Train Epoch: 85 	Average Loss: 13.5241
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1734

Learning rate: 0.00017853169308807448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 21.1373	Cost: 33.08s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 12.5071	Cost: 12.68s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 12.6234	Cost: 12.60s
Train Epoch: 86 	Average Loss: 13.3685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2911

Learning rate: 0.00017804304073383296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 21.4798	Cost: 30.62s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 12.6129	Cost: 11.40s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 12.6474	Cost: 14.09s
Train Epoch: 87 	Average Loss: 13.4398
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2173

Learning rate: 0.00017754957431722346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 21.3499	Cost: 30.41s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 12.4645	Cost: 9.72s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 12.4734	Cost: 21.73s
Train Epoch: 88 	Average Loss: 13.3264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2938

Learning rate: 0.00017705132427757892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 21.3899	Cost: 32.44s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 12.3439	Cost: 15.09s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 12.4901	Cost: 17.12s
Train Epoch: 89 	Average Loss: 13.2592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2809

Learning rate: 0.00017654832134930882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 21.1783	Cost: 35.54s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 12.3441	Cost: 16.56s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 12.4766	Cost: 16.52s
Train Epoch: 90 	Average Loss: 13.2093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4134

Learning rate: 0.0001760405965600031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 21.5280	Cost: 34.73s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 12.3889	Cost: 14.50s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 12.5128	Cost: 16.60s
Train Epoch: 91 	Average Loss: 13.2126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3901

Learning rate: 0.00017552818122851838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 21.3946	Cost: 33.76s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 12.5353	Cost: 16.59s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 12.4136	Cost: 16.66s
Train Epoch: 92 	Average Loss: 13.2690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4028

Learning rate: 0.00017501110696304596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 21.3450	Cost: 35.30s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 12.4266	Cost: 17.12s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 12.4382	Cost: 17.15s
Train Epoch: 93 	Average Loss: 13.2284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4910

Learning rate: 0.0001744894056591622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 21.1658	Cost: 34.06s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 12.2914	Cost: 17.04s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 12.3359	Cost: 12.25s
Train Epoch: 94 	Average Loss: 13.1392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5033

Learning rate: 0.00017396310949786096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 21.1520	Cost: 36.86s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 12.2962	Cost: 15.71s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 12.4850	Cost: 10.96s
Train Epoch: 95 	Average Loss: 13.1443
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4264

Learning rate: 0.00017343225094356858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 21.2320	Cost: 33.25s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 12.3478	Cost: 14.24s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 12.2518	Cost: 9.68s
Train Epoch: 96 	Average Loss: 13.1957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5745

Learning rate: 0.00017289686274214118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 21.5544	Cost: 33.22s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 12.1656	Cost: 9.68s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 12.0540	Cost: 15.86s
Train Epoch: 97 	Average Loss: 13.0684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4107

Learning rate: 0.00017235697791884494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 21.5489	Cost: 30.90s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 12.0389	Cost: 11.48s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 12.0297	Cost: 12.44s
Train Epoch: 98 	Average Loss: 12.9441
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5981

Learning rate: 0.0001718126297763189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 21.6874	Cost: 29.99s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 12.1659	Cost: 9.69s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 12.2038	Cost: 22.52s
Train Epoch: 99 	Average Loss: 13.0293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5144

Learning rate: 0.00017126385189252056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 21.5154	Cost: 32.75s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 12.1176	Cost: 15.02s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 12.0526	Cost: 16.41s
Train Epoch: 100 	Average Loss: 13.0055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5639

Learning rate: 0.00017071067811865479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 21.3967	Cost: 34.75s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 11.9399	Cost: 16.48s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 12.0067	Cost: 17.26s
Train Epoch: 101 	Average Loss: 12.8299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7290

Learning rate: 0.00017015314257708562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 21.5159	Cost: 34.34s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 12.2028	Cost: 16.20s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 12.1337	Cost: 16.51s
Train Epoch: 102 	Average Loss: 13.0123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5600

Learning rate: 0.00016959127965923145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 21.3232	Cost: 34.12s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 11.9980	Cost: 16.86s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 12.0402	Cost: 16.57s
Train Epoch: 103 	Average Loss: 12.8414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6460

Learning rate: 0.00016902512402344375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 21.5191	Cost: 32.78s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 11.7262	Cost: 16.62s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 11.9110	Cost: 17.35s
Train Epoch: 104 	Average Loss: 12.7183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7531

Learning rate: 0.0001684547105928689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 21.2805	Cost: 33.72s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 11.8289	Cost: 17.01s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 11.7549	Cost: 16.92s
Train Epoch: 105 	Average Loss: 12.6646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7669

Learning rate: 0.00016788007455329423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 21.7453	Cost: 33.96s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 11.6971	Cost: 16.91s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 11.6665	Cost: 13.10s
Train Epoch: 106 	Average Loss: 12.6379
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8945

Learning rate: 0.00016730125135097737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 21.7698	Cost: 37.52s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 11.7011	Cost: 11.73s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 11.6281	Cost: 10.36s
Train Epoch: 107 	Average Loss: 12.5572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8470

Learning rate: 0.00016671827669046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 21.4628	Cost: 32.82s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 11.6897	Cost: 12.68s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 11.7712	Cost: 12.62s
Train Epoch: 108 	Average Loss: 12.6543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8806

Learning rate: 0.0001661311865323652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 21.6414	Cost: 30.91s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 11.6869	Cost: 11.89s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 11.6687	Cost: 11.18s
Train Epoch: 109 	Average Loss: 12.6222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8559

Learning rate: 0.00016554001709117943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 21.7373	Cost: 28.74s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 11.4893	Cost: 9.68s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 11.6570	Cost: 22.00s
Train Epoch: 110 	Average Loss: 12.4665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9332

Learning rate: 0.00016494480483301838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 21.6918	Cost: 31.50s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 11.4308	Cost: 12.23s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 11.6624	Cost: 16.53s
Train Epoch: 111 	Average Loss: 12.5271
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0408

Learning rate: 0.0001643455864733779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 21.6585	Cost: 33.74s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 11.6605	Cost: 15.25s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 12.0556	Cost: 16.61s
Train Epoch: 112 	Average Loss: 12.6845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8560

Learning rate: 0.000163742398974869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 21.4719	Cost: 35.22s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 11.5905	Cost: 16.27s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 11.3906	Cost: 16.63s
Train Epoch: 113 	Average Loss: 12.5670
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9550

Learning rate: 0.00016313527954493778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 21.9466	Cost: 34.14s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 11.4446	Cost: 16.63s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 11.1806	Cost: 16.52s
Train Epoch: 114 	Average Loss: 12.3636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1068

Learning rate: 0.00016252426563357055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 21.7613	Cost: 34.91s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 11.1221	Cost: 17.13s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 11.0145	Cost: 15.80s
Train Epoch: 115 	Average Loss: 12.1263
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3203

Learning rate: 0.0001619093949309834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 21.8541	Cost: 32.96s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 10.9176	Cost: 17.07s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 11.4775	Cost: 10.69s
Train Epoch: 116 	Average Loss: 12.0577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1093

Learning rate: 0.00016129070536529766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 21.5533	Cost: 32.45s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 11.2190	Cost: 10.71s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 11.1077	Cost: 11.51s
Train Epoch: 117 	Average Loss: 12.1614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3770

Learning rate: 0.00016066823510019996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 21.7140	Cost: 33.23s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 11.1026	Cost: 13.12s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 11.4952	Cost: 12.96s
Train Epoch: 118 	Average Loss: 12.1725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1865

Learning rate: 0.0001600420225325884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 21.7508	Cost: 31.65s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 11.2753	Cost: 10.28s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 11.3379	Cost: 15.73s
Train Epoch: 119 	Average Loss: 12.3403
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1532

Learning rate: 0.00015941210629020385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 21.6758	Cost: 30.96s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 11.0262	Cost: 9.70s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 11.6917	Cost: 21.19s
Train Epoch: 120 	Average Loss: 12.2731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0443

Learning rate: 0.00015877852522924735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 21.5911	Cost: 31.55s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 11.5469	Cost: 17.05s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 11.6574	Cost: 16.64s
Train Epoch: 121 	Average Loss: 12.5702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1159

Learning rate: 0.00015814131843198305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 21.4581	Cost: 32.07s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 11.2122	Cost: 16.50s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 11.2555	Cost: 16.60s
Train Epoch: 122 	Average Loss: 12.2367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1501

Learning rate: 0.00015750052520432787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 21.7318	Cost: 32.21s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 10.9229	Cost: 16.53s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 11.0130	Cost: 16.48s
Train Epoch: 123 	Average Loss: 12.0510
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3957

Learning rate: 0.0001568561850734264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 21.7536	Cost: 33.95s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 10.9531	Cost: 16.90s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 10.8455	Cost: 17.30s
Train Epoch: 124 	Average Loss: 12.0174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4065

Learning rate: 0.00015620833778521307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 21.8979	Cost: 34.30s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 10.9255	Cost: 16.91s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 10.6835	Cost: 16.59s
Train Epoch: 125 	Average Loss: 11.8157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5061

Learning rate: 0.00015555702330196023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 21.9018	Cost: 33.59s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 10.5876	Cost: 16.76s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 11.0344	Cost: 15.19s
Train Epoch: 126 	Average Loss: 11.7690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0939

Learning rate: 0.00015490228179981317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 21.7866	Cost: 34.11s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 10.8236	Cost: 14.69s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 10.9310	Cost: 12.07s
Train Epoch: 127 	Average Loss: 11.9173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4750

Learning rate: 0.00015424415366631188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 21.8011	Cost: 32.76s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 10.8212	Cost: 16.75s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 10.7482	Cost: 9.69s
Train Epoch: 128 	Average Loss: 11.8525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4979

Learning rate: 0.00015358267949789966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 21.7278	Cost: 32.74s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 10.7211	Cost: 9.88s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 10.8637	Cost: 13.92s
Train Epoch: 129 	Average Loss: 11.8139
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6087

Learning rate: 0.00015291790009741904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 21.9219	Cost: 32.75s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 10.9326	Cost: 12.93s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 10.7257	Cost: 12.57s
Train Epoch: 130 	Average Loss: 11.9570
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4121

Learning rate: 0.00015224985647159487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 22.4596	Cost: 29.84s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 11.3158	Cost: 12.72s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 11.0045	Cost: 9.42s
Train Epoch: 131 	Average Loss: 12.1896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2061

Learning rate: 0.00015157858982850473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 22.3195	Cost: 29.00s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 10.7488	Cost: 9.70s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 10.6834	Cost: 22.04s
Train Epoch: 132 	Average Loss: 11.8001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3781

Learning rate: 0.0001509041415750371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 22.0496	Cost: 32.13s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 10.4948	Cost: 12.00s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 10.4392	Cost: 18.22s
Train Epoch: 133 	Average Loss: 11.5539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7394

Learning rate: 0.00015022655331433721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 22.3198	Cost: 32.98s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 10.3710	Cost: 16.84s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 10.3420	Cost: 16.65s
Train Epoch: 134 	Average Loss: 11.4115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6661

Learning rate: 0.00014954586684324072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 22.5337	Cost: 33.46s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 10.4077	Cost: 16.12s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 10.1901	Cost: 16.29s
Train Epoch: 135 	Average Loss: 11.4793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6882

Learning rate: 0.00014886212414969547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 22.1639	Cost: 33.46s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 10.2148	Cost: 16.25s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 10.3896	Cost: 16.59s
Train Epoch: 136 	Average Loss: 11.3835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7788

Learning rate: 0.0001481753674101715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 22.5366	Cost: 33.32s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 10.8457	Cost: 14.81s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 10.7907	Cost: 16.84s
Train Epoch: 137 	Average Loss: 11.8394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6410

Learning rate: 0.00014748563898705943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 22.2996	Cost: 34.35s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 10.7505	Cost: 16.61s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 10.5428	Cost: 17.16s
Train Epoch: 138 	Average Loss: 11.7057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5621

Learning rate: 0.00014679298142605734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 22.1125	Cost: 36.62s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 10.5664	Cost: 16.64s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 10.2537	Cost: 16.62s
Train Epoch: 139 	Average Loss: 11.5834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7571

Learning rate: 0.00014609743745354624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 22.3426	Cost: 33.85s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 10.1350	Cost: 16.75s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 9.8767	Cost: 16.70s
Train Epoch: 140 	Average Loss: 11.1533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9764

Learning rate: 0.00014539904997395466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 22.1619	Cost: 34.29s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 9.8779	Cost: 17.00s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 9.9821	Cost: 12.68s
Train Epoch: 141 	Average Loss: 11.0150
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9523

Learning rate: 0.0001446978620671121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 21.9364	Cost: 31.54s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 10.0828	Cost: 15.63s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 9.8986	Cost: 11.10s
Train Epoch: 142 	Average Loss: 11.0986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9840

Learning rate: 0.0001439939169855915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 22.0904	Cost: 36.26s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 10.1762	Cost: 15.08s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 9.9977	Cost: 9.59s
Train Epoch: 143 	Average Loss: 11.1378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9568

Learning rate: 0.0001432872581520414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 21.9954	Cost: 31.99s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 10.0163	Cost: 9.73s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 10.2523	Cost: 14.57s
Train Epoch: 144 	Average Loss: 11.2060
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9528

Learning rate: 0.00014257792915650728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 22.0811	Cost: 32.23s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 10.1026	Cost: 12.79s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 10.3114	Cost: 12.45s
Train Epoch: 145 	Average Loss: 11.2441
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8359

Learning rate: 0.0001418659737537428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 21.8412	Cost: 29.69s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 9.9274	Cost: 9.87s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 9.8329	Cost: 18.99s
Train Epoch: 146 	Average Loss: 11.0614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1498

Learning rate: 0.00014115143586051088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 22.1177	Cost: 32.09s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 9.7310	Cost: 9.70s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 9.5861	Cost: 21.39s
Train Epoch: 147 	Average Loss: 10.8993
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1345

Learning rate: 0.0001404343595528745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 22.0638	Cost: 32.30s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 9.5609	Cost: 16.54s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 9.5036	Cost: 16.54s
Train Epoch: 148 	Average Loss: 10.7809
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1717

Learning rate: 0.00013971478906347806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 22.1574	Cost: 33.95s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 9.7156	Cost: 16.59s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 9.5788	Cost: 16.60s
Train Epoch: 149 	Average Loss: 10.8392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1886

Learning rate: 0.00013899276877881884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 23.1969	Cost: 34.32s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 10.5011	Cost: 15.65s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 10.1542	Cost: 16.61s
Train Epoch: 150 	Average Loss: 11.4081
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9730

Learning rate: 0.000138268343236509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 22.3917	Cost: 32.83s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 10.5472	Cost: 16.73s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 9.7888	Cost: 17.32s
Train Epoch: 151 	Average Loss: 11.4566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5646

Learning rate: 0.00013754155712252834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 22.5243	Cost: 34.21s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 9.8137	Cost: 16.60s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 9.5558	Cost: 16.49s
Train Epoch: 152 	Average Loss: 10.9041
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0960

Learning rate: 0.00013681245526846785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 22.2491	Cost: 34.56s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 9.6706	Cost: 16.99s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 9.6027	Cost: 13.67s
Train Epoch: 153 	Average Loss: 10.8524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1292

Learning rate: 0.00013608108264876422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 22.4018	Cost: 37.82s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 9.4563	Cost: 15.98s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 9.2513	Cost: 9.60s
Train Epoch: 154 	Average Loss: 10.6156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2387

Learning rate: 0.00013534748437792575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 22.0579	Cost: 32.75s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 9.4307	Cost: 9.64s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 9.5139	Cost: 16.97s
Train Epoch: 155 	Average Loss: 10.6827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0471

Learning rate: 0.00013461170570774932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 21.9158	Cost: 31.01s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 9.7053	Cost: 11.99s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 9.2188	Cost: 10.33s
Train Epoch: 156 	Average Loss: 10.8151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1830

Learning rate: 0.0001338737920245292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 22.8367	Cost: 29.51s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 9.3510	Cost: 9.75s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 9.2129	Cost: 21.67s
Train Epoch: 157 	Average Loss: 10.5644
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3535

Learning rate: 0.00013313378884625713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 22.7247	Cost: 31.55s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 9.4012	Cost: 11.33s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 9.2742	Cost: 19.86s
Train Epoch: 158 	Average Loss: 10.5625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2838

Learning rate: 0.00013239174181981498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 22.9210	Cost: 33.56s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 9.9757	Cost: 16.31s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 9.6230	Cost: 16.53s
Train Epoch: 159 	Average Loss: 11.0931
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1208

Learning rate: 0.00013164769671815865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 23.1064	Cost: 33.67s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 9.6252	Cost: 16.38s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 9.5610	Cost: 16.44s
Train Epoch: 160 	Average Loss: 10.8448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2513

Learning rate: 0.0001309016994374948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 22.4385	Cost: 33.52s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 9.6083	Cost: 14.61s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 10.0110	Cost: 17.01s
Train Epoch: 161 	Average Loss: 10.8978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1326

Learning rate: 0.00013015379599444962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 22.4033	Cost: 34.18s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 9.8022	Cost: 16.30s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 9.3949	Cost: 16.80s
Train Epoch: 162 	Average Loss: 10.9510
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4082

Learning rate: 0.00012940403252323043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 22.1474	Cost: 33.77s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 9.4598	Cost: 16.82s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 9.5003	Cost: 17.19s
Train Epoch: 163 	Average Loss: 10.6369
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3067

Learning rate: 0.00012865245527277986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 22.1093	Cost: 33.49s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 9.2652	Cost: 16.86s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 9.3004	Cost: 15.72s
Train Epoch: 164 	Average Loss: 10.4961
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4023

Learning rate: 0.00012789911060392294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 23.6001	Cost: 34.22s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 9.8479	Cost: 15.84s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 9.4482	Cost: 12.64s
Train Epoch: 165 	Average Loss: 10.9892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0830

Learning rate: 0.00012714404498650745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 23.4698	Cost: 34.13s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 9.3669	Cost: 14.66s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 9.1623	Cost: 9.61s
Train Epoch: 166 	Average Loss: 10.6264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4249

Learning rate: 0.00012638730499653727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 23.5790	Cost: 31.50s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 9.0527	Cost: 9.69s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 9.2469	Cost: 14.38s
Train Epoch: 167 	Average Loss: 10.4351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4229

Learning rate: 0.00012562893731329965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 22.8847	Cost: 32.22s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 9.4549	Cost: 12.83s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 9.1710	Cost: 12.97s
Train Epoch: 168 	Average Loss: 10.6401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5445

Learning rate: 0.00012486898871648546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 23.2940	Cost: 30.09s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 9.3419	Cost: 9.84s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 9.2120	Cost: 19.63s
Train Epoch: 169 	Average Loss: 10.4838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.6413

Learning rate: 0.00012410750608330388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 23.1318	Cost: 33.16s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 9.2778	Cost: 11.25s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 9.2187	Cost: 20.82s
Train Epoch: 170 	Average Loss: 10.4748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4693

Learning rate: 0.00012334453638559054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 22.1940	Cost: 32.14s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 9.1894	Cost: 16.85s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 9.0162	Cost: 16.68s
Train Epoch: 171 	Average Loss: 10.3499
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.6017

Learning rate: 0.00012258012668691037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 22.5317	Cost: 33.01s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 8.9835	Cost: 16.50s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 8.8134	Cost: 16.61s
Train Epoch: 172 	Average Loss: 10.0927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5703

Learning rate: 0.00012181432413965427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 23.3082	Cost: 33.72s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 9.0363	Cost: 16.56s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 9.5703	Cost: 16.56s
Train Epoch: 173 	Average Loss: 10.3797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.7726

Learning rate: 0.0001210471759821306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 22.8087	Cost: 33.75s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 9.8064	Cost: 16.43s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 9.2358	Cost: 16.85s
Train Epoch: 174 	Average Loss: 10.7852
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3558

Learning rate: 0.00012027872953565127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 22.7468	Cost: 34.63s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 9.2738	Cost: 16.91s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 8.8654	Cost: 15.19s
Train Epoch: 175 	Average Loss: 10.4442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4171

Learning rate: 0.00011950903220161285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 23.3016	Cost: 32.94s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 9.0671	Cost: 15.98s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 8.4988	Cost: 11.69s
Train Epoch: 176 	Average Loss: 10.1265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4895

Learning rate: 0.00011873813145857249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 23.0734	Cost: 33.30s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 8.6954	Cost: 13.68s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 8.4665	Cost: 9.76s
Train Epoch: 177 	Average Loss: 9.8968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.7397

Learning rate: 0.00011796607485931927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 22.8652	Cost: 31.80s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 8.5189	Cost: 9.87s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 8.3066	Cost: 15.39s
Train Epoch: 178 	Average Loss: 9.8137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.7417

Learning rate: 0.00011719291002794096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 22.6078	Cost: 30.26s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 8.6074	Cost: 11.62s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 8.2043	Cost: 11.81s
Train Epoch: 179 	Average Loss: 9.6808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.7454

Learning rate: 0.0001164186846568863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 22.9586	Cost: 31.71s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 8.3547	Cost: 9.68s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 8.1058	Cost: 21.76s
Train Epoch: 180 	Average Loss: 9.6243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9974

Learning rate: 0.0001156434465040231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 23.6454	Cost: 32.48s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 8.8748	Cost: 16.88s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 9.3601	Cost: 16.22s
Train Epoch: 181 	Average Loss: 10.2729
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4789

Learning rate: 0.00011486724338969234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 22.8095	Cost: 33.11s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 9.5345	Cost: 16.60s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 9.5987	Cost: 16.48s
Train Epoch: 182 	Average Loss: 10.8853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.7285

Learning rate: 0.0001140901231937583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 22.7447	Cost: 33.40s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 9.5647	Cost: 16.34s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 8.9583	Cost: 16.41s
Train Epoch: 183 	Average Loss: 10.7639
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.6577

Learning rate: 0.00011331213385265528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 22.7496	Cost: 34.85s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 8.7642	Cost: 16.53s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 8.4368	Cost: 16.71s
Train Epoch: 184 	Average Loss: 10.0486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.8605

Learning rate: 0.00011253332335643047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 22.3321	Cost: 35.07s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 8.5722	Cost: 15.86s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 8.2415	Cost: 14.22s
Train Epoch: 185 	Average Loss: 9.8396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.8076

Learning rate: 0.0001117537397457838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 22.3937	Cost: 32.51s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 8.3834	Cost: 16.28s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 8.1673	Cost: 10.27s
Train Epoch: 186 	Average Loss: 9.6372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.8230

Learning rate: 0.00011097343110910456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 23.2075	Cost: 36.12s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 8.5772	Cost: 10.36s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 8.2592	Cost: 13.55s
Train Epoch: 187 	Average Loss: 9.8372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4684

Learning rate: 0.00011019244557950502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 24.2572	Cost: 30.79s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 8.2778	Cost: 11.74s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 8.0250	Cost: 13.13s
Train Epoch: 188 	Average Loss: 9.6702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.0398

Learning rate: 0.00010941083133185145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 22.9475	Cost: 30.74s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 8.2712	Cost: 12.72s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 8.0975	Cost: 12.79s
Train Epoch: 189 	Average Loss: 9.5372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.1865

Learning rate: 0.00010862863657979236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 22.6652	Cost: 30.60s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 8.0707	Cost: 10.79s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 7.9126	Cost: 13.95s
Train Epoch: 190 	Average Loss: 9.3945
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.0438

Learning rate: 0.00010784590957278452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 22.6076	Cost: 30.66s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 8.0365	Cost: 9.74s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 8.4549	Cost: 22.62s
Train Epoch: 191 	Average Loss: 9.4894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.0432

Learning rate: 0.00010706269859311669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 23.2955	Cost: 32.39s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 9.0866	Cost: 15.02s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 8.6369	Cost: 16.33s
Train Epoch: 192 	Average Loss: 10.1240
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.7664

Learning rate: 0.00010627905195293137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 23.4972	Cost: 32.90s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 8.4331	Cost: 16.96s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 8.5306	Cost: 16.71s
Train Epoch: 193 	Average Loss: 9.9173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.1667

Learning rate: 0.00010549501799124461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 24.2288	Cost: 35.18s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 8.8252	Cost: 16.30s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 9.1744	Cost: 16.47s
Train Epoch: 194 	Average Loss: 10.1649
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5840

Learning rate: 0.00010471064507096429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 22.4865	Cost: 33.03s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 9.2972	Cost: 16.91s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 8.7439	Cost: 17.36s
Train Epoch: 195 	Average Loss: 10.3551
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.8691

Learning rate: 0.00010392598157590689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 22.8025	Cost: 34.27s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 8.7166	Cost: 16.75s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 9.0583	Cost: 15.91s
Train Epoch: 196 	Average Loss: 10.0666
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.8065

Learning rate: 0.00010314107590781285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 23.2209	Cost: 33.46s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 9.2740	Cost: 15.21s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 8.3783	Cost: 11.45s
Train Epoch: 197 	Average Loss: 10.2922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3028

Learning rate: 0.00010235597648336105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 22.9733	Cost: 36.61s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 8.3884	Cost: 12.85s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 8.0167	Cost: 10.30s
Train Epoch: 198 	Average Loss: 9.6787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9717

Learning rate: 0.0001015707317311821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 22.6629	Cost: 33.68s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 8.1421	Cost: 12.16s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 7.8533	Cost: 12.62s
Train Epoch: 199 	Average Loss: 9.3608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.0858

Learning rate: 0.00010078539008887115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 24.1518	Cost: 30.95s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 8.3644	Cost: 12.75s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 8.0103	Cost: 10.50s
Train Epoch: 200 	Average Loss: 9.5387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.0002

Learning rate: 0.00010000000000000002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 23.5832	Cost: 29.42s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 8.6563	Cost: 9.91s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 8.5418	Cost: 19.97s
Train Epoch: 201 	Average Loss: 9.9160
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.6435

Learning rate: 9.92146099111289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 23.2670	Cost: 31.51s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 8.8226	Cost: 9.72s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 8.3957	Cost: 19.71s
Train Epoch: 202 	Average Loss: 9.9643
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5275

Learning rate: 9.842926826881797e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 22.7654	Cost: 31.63s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 8.1895	Cost: 16.52s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 7.8780	Cost: 16.13s
Train Epoch: 203 	Average Loss: 9.3813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.2242

Learning rate: 9.7644023516639e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 22.6645	Cost: 33.63s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 8.0541	Cost: 16.45s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 7.6392	Cost: 16.87s
Train Epoch: 204 	Average Loss: 9.2162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.0896

Learning rate: 9.68589240921872e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 22.5055	Cost: 33.69s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 7.5928	Cost: 16.59s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 7.2323	Cost: 16.66s
Train Epoch: 205 	Average Loss: 8.8035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.1044

Learning rate: 9.607401842409317e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 22.9589	Cost: 32.60s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 7.4017	Cost: 15.27s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 7.0529	Cost: 17.53s
Train Epoch: 206 	Average Loss: 8.6537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.2403

Learning rate: 9.528935492903578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 22.5466	Cost: 33.17s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 7.1749	Cost: 16.71s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 6.8559	Cost: 17.12s
Train Epoch: 207 	Average Loss: 8.4164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.3403

Learning rate: 9.450498200875547e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 22.5348	Cost: 36.66s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 7.3564	Cost: 16.92s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 8.0497	Cost: 16.88s
Train Epoch: 208 	Average Loss: 8.7477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.1633

Learning rate: 9.372094804706868e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 23.8119	Cost: 33.99s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 8.7387	Cost: 16.80s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 8.6756	Cost: 16.19s
Train Epoch: 209 	Average Loss: 9.7846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.0266

Learning rate: 9.293730140688336e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 24.0290	Cost: 35.46s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 8.6008	Cost: 16.73s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 8.2047	Cost: 12.68s
Train Epoch: 210 	Average Loss: 9.7384
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.1551

Learning rate: 9.215409042721555e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 23.0424	Cost: 33.70s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 7.9698	Cost: 16.14s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 7.6183	Cost: 9.64s
Train Epoch: 211 	Average Loss: 9.2190
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.3504

Learning rate: 9.13713634202077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 24.4981	Cost: 32.51s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 7.8615	Cost: 9.64s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 7.6972	Cost: 15.49s
Train Epoch: 212 	Average Loss: 9.3483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.0271

Learning rate: 9.058916866814858e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 23.9596	Cost: 29.81s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 8.2336	Cost: 10.88s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 7.9472	Cost: 14.60s
Train Epoch: 213 	Average Loss: 9.4611
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4750

Learning rate: 8.9807554420495e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 22.7885	Cost: 31.18s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 7.9345	Cost: 9.74s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 7.5095	Cost: 21.77s
Train Epoch: 214 	Average Loss: 9.3093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.3821

Learning rate: 8.902656889089548e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 23.7372	Cost: 31.96s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 7.5683	Cost: 16.93s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 7.3456	Cost: 16.39s
Train Epoch: 215 	Average Loss: 9.1066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5947

Learning rate: 8.824626025421624e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 23.8850	Cost: 32.55s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 7.3372	Cost: 16.53s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 8.4561	Cost: 16.48s
Train Epoch: 216 	Average Loss: 9.1911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.8934

Learning rate: 8.746667664356959e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 22.9551	Cost: 34.47s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 8.4724	Cost: 16.67s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 8.0573	Cost: 16.61s
Train Epoch: 217 	Average Loss: 9.9753
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.3192

Learning rate: 8.668786614734478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 23.4047	Cost: 32.29s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 7.7943	Cost: 16.63s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 7.4571	Cost: 17.23s
Train Epoch: 218 	Average Loss: 9.3617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.2777

Learning rate: 8.590987680624175e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 24.0030	Cost: 32.64s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 7.6221	Cost: 15.97s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 7.1911	Cost: 17.48s
Train Epoch: 219 	Average Loss: 9.0180
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4173

Learning rate: 8.51327566103077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 23.2389	Cost: 34.95s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 7.2725	Cost: 16.99s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 7.0781	Cost: 14.69s
Train Epoch: 220 	Average Loss: 8.9157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.3546

Learning rate: 8.435655349597692e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 23.2789	Cost: 32.80s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 7.0268	Cost: 16.45s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 7.2478	Cost: 9.70s
Train Epoch: 221 	Average Loss: 8.7372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4390

Learning rate: 8.35813153431137e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 22.7597	Cost: 33.11s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 7.0203	Cost: 9.58s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 7.1535	Cost: 16.62s
Train Epoch: 222 	Average Loss: 8.7577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.9453

Learning rate: 8.280708997205904e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 22.6528	Cost: 31.28s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 7.5215	Cost: 12.75s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 7.6403	Cost: 10.88s
Train Epoch: 223 	Average Loss: 8.8980
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.2135

Learning rate: 8.203392514068074e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 23.7864	Cost: 29.23s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 7.9662	Cost: 9.80s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 7.4884	Cost: 21.76s
Train Epoch: 224 	Average Loss: 8.9904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.0558

Learning rate: 8.126186854142755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 23.0843	Cost: 31.70s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 7.3940	Cost: 9.71s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 7.2095	Cost: 20.65s
Train Epoch: 225 	Average Loss: 8.5497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4274

Learning rate: 8.049096779838719e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 24.2431	Cost: 31.37s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 7.5078	Cost: 16.32s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 7.1253	Cost: 16.32s
Train Epoch: 226 	Average Loss: 8.7120
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5934

Learning rate: 7.972127046434877e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 23.1061	Cost: 32.99s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 7.1058	Cost: 16.49s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 6.6691	Cost: 16.61s
Train Epoch: 227 	Average Loss: 8.3308
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5515

Learning rate: 7.895282401786947e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 23.0548	Cost: 32.68s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 6.7464	Cost: 16.61s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 6.3853	Cost: 16.55s
Train Epoch: 228 	Average Loss: 8.0609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4499

Learning rate: 7.818567586034578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 22.7121	Cost: 34.01s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 6.3934	Cost: 16.08s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 6.3050	Cost: 16.40s
Train Epoch: 229 	Average Loss: 7.7769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.0454

Learning rate: 7.741987331308968e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 22.7381	Cost: 32.97s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 6.5591	Cost: 16.77s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 6.2695	Cost: 16.52s
Train Epoch: 230 	Average Loss: 7.8108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.9185

Learning rate: 7.665546361440945e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 22.5406	Cost: 32.64s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 6.4089	Cost: 16.49s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 6.2208	Cost: 17.17s
Train Epoch: 231 	Average Loss: 7.7601
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.8313

Learning rate: 7.589249391669613e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 23.4620	Cost: 34.65s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 6.3857	Cost: 16.60s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 6.2512	Cost: 16.58s
Train Epoch: 232 	Average Loss: 7.7552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.9692

Learning rate: 7.513101128351452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 22.8248	Cost: 34.89s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 6.1745	Cost: 16.56s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 5.8535	Cost: 13.58s
Train Epoch: 233 	Average Loss: 7.5525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.7190

Learning rate: 7.437106268670034e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 22.7273	Cost: 33.58s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 6.4112	Cost: 15.38s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 7.2610	Cost: 9.78s
Train Epoch: 234 	Average Loss: 8.0112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.2082

Learning rate: 7.361269500346273e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 22.7398	Cost: 32.01s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 7.0233	Cost: 9.57s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 6.9070	Cost: 17.97s
Train Epoch: 235 	Average Loss: 8.4482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.9356

Learning rate: 7.28559550134926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 22.9776	Cost: 31.39s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 6.7213	Cost: 11.15s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 6.9671	Cost: 14.19s
Train Epoch: 236 	Average Loss: 8.2837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.3747

Learning rate: 7.210088939607711e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 22.5951	Cost: 30.71s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 7.1606	Cost: 9.75s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 6.6870	Cost: 21.72s
Train Epoch: 237 	Average Loss: 8.6574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.2998

Learning rate: 7.13475447272202e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 22.7450	Cost: 32.17s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 6.5107	Cost: 16.29s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 6.1849	Cost: 16.17s
Train Epoch: 238 	Average Loss: 7.8938
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.0838

Learning rate: 7.059596747676965e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 22.5674	Cost: 36.81s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 6.4306	Cost: 16.42s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 6.3005	Cost: 16.62s
Train Epoch: 239 	Average Loss: 7.9260
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.3541

Learning rate: 6.984620400555048e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 23.3060	Cost: 33.80s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 6.6992	Cost: 16.81s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 6.3791	Cost: 16.45s
Train Epoch: 240 	Average Loss: 8.1301
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.3786

Learning rate: 6.909830056250531e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 23.6503	Cost: 34.86s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 6.3972	Cost: 16.47s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 5.9561	Cost: 16.57s
Train Epoch: 241 	Average Loss: 7.7587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.2081

Learning rate: 6.835230328184141e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 24.8133	Cost: 34.15s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 6.8711	Cost: 16.43s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 7.1755	Cost: 16.39s
Train Epoch: 242 	Average Loss: 8.4508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.0095

Learning rate: 6.760825818018508e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 24.4022	Cost: 34.13s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 7.2064	Cost: 16.88s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 6.5159	Cost: 13.50s
Train Epoch: 243 	Average Loss: 8.5780
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.1024

Learning rate: 6.686621115374292e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 23.7544	Cost: 30.87s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 6.4896	Cost: 9.64s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 7.5694	Cost: 12.35s
Train Epoch: 244 	Average Loss: 8.2562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.2439

Learning rate: 6.61262079754709e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 22.5582	Cost: 29.96s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 8.2046	Cost: 9.99s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 7.2532	Cost: 12.54s
Train Epoch: 245 	Average Loss: 9.2564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.6399

Learning rate: 6.538829429225073e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 25.6708	Cost: 30.03s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 6.8543	Cost: 9.70s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 7.5787	Cost: 13.48s
Train Epoch: 246 	Average Loss: 8.5475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4795

Learning rate: 6.465251562207432e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 22.3011	Cost: 29.58s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 6.6841	Cost: 9.67s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 6.5950	Cost: 13.70s
Train Epoch: 247 	Average Loss: 8.2378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.0381

Learning rate: 6.391891735123586e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 24.2704	Cost: 30.11s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 7.1237	Cost: 9.68s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 6.6540	Cost: 12.64s
Train Epoch: 248 	Average Loss: 8.5621
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.9026

Learning rate: 6.318754473153225e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 22.9649	Cost: 32.35s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 6.4638	Cost: 9.72s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 6.0162	Cost: 19.76s
Train Epoch: 249 	Average Loss: 7.9501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.3070

Learning rate: 6.245844287747173e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 22.6599	Cost: 33.15s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 6.0886	Cost: 14.35s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 5.7433	Cost: 17.92s
Train Epoch: 250 	Average Loss: 7.5674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.1710

Learning rate: 6.173165676349108e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 23.5589	Cost: 33.26s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 7.0670	Cost: 16.56s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 6.6039	Cost: 16.07s
Train Epoch: 251 	Average Loss: 8.3958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.6927

Learning rate: 6.10072312211812e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 24.8233	Cost: 31.91s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 6.9172	Cost: 14.03s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 6.2780	Cost: 16.47s
Train Epoch: 252 	Average Loss: 8.1670
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.6718

Learning rate: 6.0285210936521955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 23.2588	Cost: 32.46s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 6.2080	Cost: 16.36s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 5.8876	Cost: 16.21s
Train Epoch: 253 	Average Loss: 7.6059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.9815

Learning rate: 5.956564044712553e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 23.5610	Cost: 35.16s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 6.0213	Cost: 16.46s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 5.7106	Cost: 16.52s
Train Epoch: 254 	Average Loss: 7.4876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.4377

Learning rate: 5.8848564139489155e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 23.0328	Cost: 33.20s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 5.8197	Cost: 16.59s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 5.3736	Cost: 16.53s
Train Epoch: 255 	Average Loss: 7.2254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.4186

Learning rate: 5.813402624625721e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 22.5378	Cost: 32.97s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 5.4372	Cost: 16.48s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 5.1531	Cost: 16.63s
Train Epoch: 256 	Average Loss: 6.9475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.5978

Learning rate: 5.742207084349277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 23.3780	Cost: 34.40s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 5.2992	Cost: 16.81s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 5.0575	Cost: 16.79s
Train Epoch: 257 	Average Loss: 6.8325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.1476

Learning rate: 5.6712741847958634e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 22.9931	Cost: 33.73s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 5.0880	Cost: 16.40s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 5.9364	Cost: 16.80s
Train Epoch: 258 	Average Loss: 6.7986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.3997

Learning rate: 5.600608301440851e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 22.8539	Cost: 35.50s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 5.4644	Cost: 16.91s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 5.5728	Cost: 16.67s
Train Epoch: 259 	Average Loss: 7.0665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.3088

Learning rate: 5.5302137932887924e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 25.4559	Cost: 35.62s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 5.8468	Cost: 16.86s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 5.7256	Cost: 13.74s
Train Epoch: 260 	Average Loss: 7.4387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.0858

Learning rate: 5.460095002604535e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 25.7073	Cost: 33.45s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 6.4595	Cost: 16.88s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 6.7493	Cost: 11.67s
Train Epoch: 261 	Average Loss: 7.8418
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.1158

Learning rate: 5.390256254645381e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 22.8936	Cost: 36.59s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 7.1488	Cost: 10.31s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 6.5009	Cost: 12.97s
Train Epoch: 262 	Average Loss: 8.4861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.3001

Learning rate: 5.3207018573942705e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 26.4442	Cost: 33.50s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 6.0342	Cost: 12.78s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 5.8030	Cost: 12.61s
Train Epoch: 263 	Average Loss: 7.7885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.8095

Learning rate: 5.251436101294054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 23.2616	Cost: 31.16s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 5.6400	Cost: 10.08s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 5.4443	Cost: 17.11s
Train Epoch: 264 	Average Loss: 7.2138
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.6693

Learning rate: 5.1824632589828485e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 23.1735	Cost: 33.49s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 5.4510	Cost: 9.71s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 5.4754	Cost: 19.10s
Train Epoch: 265 	Average Loss: 7.1516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.1796

Learning rate: 5.1137875850304516e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 22.5818	Cost: 37.05s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 5.9415	Cost: 16.37s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 5.3867	Cost: 16.44s
Train Epoch: 266 	Average Loss: 7.3310
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.9449

Learning rate: 5.045413315675926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 23.6564	Cost: 33.43s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 5.5423	Cost: 16.34s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 5.3553	Cost: 16.58s
Train Epoch: 267 	Average Loss: 7.0599
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.2379

Learning rate: 4.977344668566277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 24.5164	Cost: 33.67s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 5.7852	Cost: 16.75s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 5.5254	Cost: 16.46s
Train Epoch: 268 	Average Loss: 7.2195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.2854

Learning rate: 4.909585842496289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 22.9496	Cost: 32.55s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 5.4687	Cost: 15.59s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 5.4741	Cost: 16.89s
Train Epoch: 269 	Average Loss: 7.0894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.7766

Learning rate: 4.842141017149528e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 22.6683	Cost: 35.00s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 5.7180	Cost: 16.80s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 5.2311	Cost: 15.65s
Train Epoch: 270 	Average Loss: 7.0845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.9043

Learning rate: 4.775014352840514e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 24.2749	Cost: 32.35s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 5.4161	Cost: 15.65s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 5.1099	Cost: 11.03s
Train Epoch: 271 	Average Loss: 6.8800
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.0779

Learning rate: 4.708209990258097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 23.5756	Cost: 35.31s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 5.2175	Cost: 9.59s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 4.9156	Cost: 17.36s
Train Epoch: 272 	Average Loss: 6.6990
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.7291

Learning rate: 4.641732050210033e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 22.5098	Cost: 31.53s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 5.0530	Cost: 12.85s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 4.8212	Cost: 12.45s
Train Epoch: 273 	Average Loss: 6.6139
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.0911

Learning rate: 4.575584633368813e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 23.5062	Cost: 29.76s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 4.8106	Cost: 9.79s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 4.8428	Cost: 20.38s
Train Epoch: 274 	Average Loss: 6.5326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2176

Learning rate: 4.509771820018683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 22.4840	Cost: 31.86s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 5.9576	Cost: 10.47s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 5.7231	Cost: 22.50s
Train Epoch: 275 	Average Loss: 7.3506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.3575

Learning rate: 4.4442976698039786e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 23.8964	Cost: 31.44s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 5.6652	Cost: 16.40s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 5.4434	Cost: 16.45s
Train Epoch: 276 	Average Loss: 7.2372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.4130

Learning rate: 4.379166221478695e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 22.7805	Cost: 33.70s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 5.3702	Cost: 16.44s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 5.0977	Cost: 16.65s
Train Epoch: 277 	Average Loss: 6.9086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.6171

Learning rate: 4.3143814926573614e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 24.1291	Cost: 33.39s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 5.1959	Cost: 14.96s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 4.9086	Cost: 17.00s
Train Epoch: 278 	Average Loss: 6.7994
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.2667

Learning rate: 4.249947479567216e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 22.9320	Cost: 32.38s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 4.9786	Cost: 16.36s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 4.6870	Cost: 16.97s
Train Epoch: 279 	Average Loss: 6.4950
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.4747

Learning rate: 4.1858681568016955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 22.4151	Cost: 33.98s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 4.6752	Cost: 16.17s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 4.4172	Cost: 16.76s
Train Epoch: 280 	Average Loss: 6.2150
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.5864

Learning rate: 4.122147477075271e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 22.9616	Cost: 33.89s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 4.4578	Cost: 16.87s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 4.2199	Cost: 17.29s
Train Epoch: 281 	Average Loss: 6.0618
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.7510

Learning rate: 4.058789370979617e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 24.9464	Cost: 36.13s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 5.0147	Cost: 17.13s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 4.9962	Cost: 11.58s
Train Epoch: 282 	Average Loss: 6.6734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.7584

Learning rate: 3.995797746741162e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 23.2043	Cost: 35.28s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 4.7973	Cost: 9.65s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 4.4275	Cost: 14.97s
Train Epoch: 283 	Average Loss: 6.3563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.8584

Learning rate: 3.933176489980003e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 22.7918	Cost: 31.51s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 4.3869	Cost: 12.62s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 4.6680	Cost: 12.49s
Train Epoch: 284 	Average Loss: 6.1393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.4763

Learning rate: 3.8709294634702356e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 22.7525	Cost: 30.79s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 4.4843	Cost: 11.69s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 4.2807	Cost: 12.02s
Train Epoch: 285 	Average Loss: 6.1153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.7547

Learning rate: 3.809060506901661e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 22.7327	Cost: 29.60s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 4.3618	Cost: 9.70s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 4.0745	Cost: 21.65s
Train Epoch: 286 	Average Loss: 5.9100
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.4639

Learning rate: 3.747573436642949e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 22.6663	Cost: 33.43s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 4.0997	Cost: 13.30s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 3.9257	Cost: 17.16s
Train Epoch: 287 	Average Loss: 5.7694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.2395

Learning rate: 3.686472045506224e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 23.3347	Cost: 33.91s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 4.0433	Cost: 16.75s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 3.9793	Cost: 16.54s
Train Epoch: 288 	Average Loss: 5.8158
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.1718

Learning rate: 3.625760102513104e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 22.8455	Cost: 32.90s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 4.0392	Cost: 16.28s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 3.8511	Cost: 16.46s
Train Epoch: 289 	Average Loss: 5.7345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.8432

Learning rate: 3.5654413526622126e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 22.7334	Cost: 32.49s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 3.9797	Cost: 16.50s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 3.8282	Cost: 16.64s
Train Epoch: 290 	Average Loss: 5.6369
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.7923

Learning rate: 3.505519516698166e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 22.6931	Cost: 33.24s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 3.9347	Cost: 14.66s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 3.8432	Cost: 16.92s
Train Epoch: 291 	Average Loss: 5.6203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.5302

Learning rate: 3.445998290882063e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 22.4855	Cost: 33.40s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 4.1082	Cost: 16.70s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 3.7491	Cost: 17.30s
Train Epoch: 292 	Average Loss: 5.5706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.2842

Learning rate: 3.386881346763484e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 22.6725	Cost: 33.58s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 3.9181	Cost: 16.69s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 3.6926	Cost: 16.48s
Train Epoch: 293 	Average Loss: 5.4987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.0256

Learning rate: 3.328172330954006e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 22.6786	Cost: 33.23s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 3.7452	Cost: 16.80s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 3.5869	Cost: 13.51s
Train Epoch: 294 	Average Loss: 5.4274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.4525

Learning rate: 3.269874864902267e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 22.6373	Cost: 32.66s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 3.8086	Cost: 14.73s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 3.6130	Cost: 12.03s
Train Epoch: 295 	Average Loss: 5.4087
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.5183

Learning rate: 3.2119925446705836e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 26.2997	Cost: 34.11s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 4.1086	Cost: 16.02s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 3.9327	Cost: 9.78s
Train Epoch: 296 	Average Loss: 5.8268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.9322

Learning rate: 3.1545289407131144e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 22.7977	Cost: 31.48s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 3.8307	Cost: 9.60s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 3.6593	Cost: 13.99s
Train Epoch: 297 	Average Loss: 5.5045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.6545

Learning rate: 3.09748759765563e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 22.8755	Cost: 32.59s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 3.8019	Cost: 12.75s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 3.5345	Cost: 12.80s
Train Epoch: 298 	Average Loss: 5.3938
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.6253

Learning rate: 3.0408720340768585e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 22.7745	Cost: 30.71s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 3.6103	Cost: 9.86s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 3.4355	Cost: 17.56s
Train Epoch: 299 	Average Loss: 5.2913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.4932

Learning rate: 2.9846857422914446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 22.7586	Cost: 31.82s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 3.4831	Cost: 9.69s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 3.4282	Cost: 19.93s
Train Epoch: 300 	Average Loss: 5.2399
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.7502

Learning rate: 2.9289321881345268e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 23.1464	Cost: 32.15s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 3.5707	Cost: 16.78s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 3.3571	Cost: 16.46s
Train Epoch: 301 	Average Loss: 5.2259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.6116

Learning rate: 2.8736148107479478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 22.4644	Cost: 35.01s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 3.4713	Cost: 16.51s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 3.3944	Cost: 16.60s
Train Epoch: 302 	Average Loss: 5.1799
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2035

Learning rate: 2.8187370223681142e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 22.9291	Cost: 33.52s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 3.4133	Cost: 16.71s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 3.3631	Cost: 16.67s
Train Epoch: 303 	Average Loss: 5.1959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.9091

Learning rate: 2.764302208115509e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 22.8176	Cost: 35.16s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 3.4319	Cost: 16.88s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 3.2105	Cost: 14.39s
Train Epoch: 304 	Average Loss: 5.1031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.6947

Learning rate: 2.710313725785888e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 22.7753	Cost: 36.91s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 3.3591	Cost: 15.06s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 3.2869	Cost: 9.59s
Train Epoch: 305 	Average Loss: 5.0708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.8480

Learning rate: 2.6567749056431446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 22.6455	Cost: 31.98s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 3.2749	Cost: 9.71s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 3.2442	Cost: 13.96s
Train Epoch: 306 	Average Loss: 5.0345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.9402

Learning rate: 2.6036890502139035e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 22.9268	Cost: 31.18s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 3.3373	Cost: 12.91s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 3.7254	Cost: 9.83s
Train Epoch: 307 	Average Loss: 5.1572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.7136

Learning rate: 2.55105943408378e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 24.1891	Cost: 29.82s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 4.2815	Cost: 9.69s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 3.8821	Cost: 22.11s
Train Epoch: 308 	Average Loss: 5.8427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.7509

Learning rate: 2.4988893036954053e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 22.5859	Cost: 32.22s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 3.7274	Cost: 12.54s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 3.4370	Cost: 16.81s
Train Epoch: 309 	Average Loss: 5.4121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.7438

Learning rate: 2.4471818771481658e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 23.3229	Cost: 35.09s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 3.6789	Cost: 16.57s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 3.4443	Cost: 16.51s
Train Epoch: 310 	Average Loss: 5.3468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.9116

Learning rate: 2.3959403439996917e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 22.7702	Cost: 34.03s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 3.4879	Cost: 16.54s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 3.3102	Cost: 16.62s
Train Epoch: 311 	Average Loss: 5.2140
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.5366

Learning rate: 2.345167865069121e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 23.1266	Cost: 33.24s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 3.8581	Cost: 16.80s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 3.2833	Cost: 16.90s
Train Epoch: 312 	Average Loss: 5.1673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2870

Learning rate: 2.2948675722421096e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 22.7676	Cost: 35.94s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 3.3679	Cost: 17.45s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 3.2529	Cost: 14.41s
Train Epoch: 313 	Average Loss: 5.0857
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.7428

Learning rate: 2.2450425682776575e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 22.6709	Cost: 33.64s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 3.4022	Cost: 14.73s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 3.2874	Cost: 12.63s
Train Epoch: 314 	Average Loss: 5.0198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.7529

Learning rate: 2.1956959266167054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 23.3105	Cost: 31.91s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 3.4439	Cost: 14.72s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 3.2626	Cost: 12.40s
Train Epoch: 315 	Average Loss: 5.1443
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.6900

Learning rate: 2.1468306911925506e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 23.0467	Cost: 32.71s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 3.2751	Cost: 14.76s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 3.1759	Cost: 9.57s
Train Epoch: 316 	Average Loss: 5.0217
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2366

Learning rate: 2.098449876243097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 22.6600	Cost: 33.29s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 3.2710	Cost: 9.64s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 3.0880	Cost: 15.76s
Train Epoch: 317 	Average Loss: 4.9406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3357

Learning rate: 2.050556466124901e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 23.0871	Cost: 32.07s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 3.1940	Cost: 10.37s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 2.9988	Cost: 16.77s
Train Epoch: 318 	Average Loss: 4.8908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1322

Learning rate: 2.0031534151290953e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 22.9375	Cost: 31.95s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 3.1419	Cost: 9.71s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 3.0297	Cost: 19.87s
Train Epoch: 319 	Average Loss: 4.9267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.5064

Learning rate: 1.9562436472991562e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 22.7390	Cost: 31.98s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 3.4923	Cost: 15.66s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 3.3005	Cost: 16.28s
Train Epoch: 320 	Average Loss: 5.1306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.9799

Learning rate: 1.9098300562505276e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 22.7613	Cost: 32.97s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 3.2765	Cost: 16.56s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 3.1022	Cost: 16.43s
Train Epoch: 321 	Average Loss: 5.0312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3919

Learning rate: 1.863915504992132e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 22.8231	Cost: 35.67s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 3.0992	Cost: 16.12s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 3.0035	Cost: 16.55s
Train Epoch: 322 	Average Loss: 4.8606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.8845

Learning rate: 1.8185028257497683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 22.7307	Cost: 33.03s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 2.9604	Cost: 16.73s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 2.8817	Cost: 16.66s
Train Epoch: 323 	Average Loss: 4.7876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2571

Learning rate: 1.7735948197914044e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 22.7704	Cost: 33.09s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 3.0024	Cost: 16.57s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 2.9120	Cost: 16.57s
Train Epoch: 324 	Average Loss: 4.7281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.8889

Learning rate: 1.729194257254384e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 22.9536	Cost: 34.81s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 2.9709	Cost: 16.79s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 2.8065	Cost: 13.59s
Train Epoch: 325 	Average Loss: 4.6869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.7613

Learning rate: 1.685303876974551e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 22.8341	Cost: 36.62s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 2.8791	Cost: 12.73s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 2.8074	Cost: 10.09s
Train Epoch: 326 	Average Loss: 4.6408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.7917

Learning rate: 1.6419263863173007e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 22.9046	Cost: 30.43s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 2.8822	Cost: 10.01s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 2.7651	Cost: 13.73s
Train Epoch: 327 	Average Loss: 4.6129
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.6518

Learning rate: 1.599064461010582e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 22.8045	Cost: 32.08s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 3.0634	Cost: 12.70s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 2.9153	Cost: 11.14s
Train Epoch: 328 	Average Loss: 4.7690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1590

Learning rate: 1.5567207449798525e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 22.8703	Cost: 31.14s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 3.0033	Cost: 9.84s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 2.7885	Cost: 22.24s
Train Epoch: 329 	Average Loss: 4.7040
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.8890

Learning rate: 1.5148978501849652e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 22.5658	Cost: 31.82s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 2.8435	Cost: 11.77s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 2.7306	Cost: 17.16s
Train Epoch: 330 	Average Loss: 4.5921
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.9012

Learning rate: 1.4735983564590815e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 22.8394	Cost: 32.68s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 2.8123	Cost: 14.98s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 2.6295	Cost: 18.46s
Train Epoch: 331 	Average Loss: 4.5614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2321

Learning rate: 1.4328248113495055e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 22.8009	Cost: 32.18s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 2.6945	Cost: 16.37s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 2.6000	Cost: 16.44s
Train Epoch: 332 	Average Loss: 4.5108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.0160

Learning rate: 1.3925797299605635e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 22.6557	Cost: 32.84s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 2.7266	Cost: 16.25s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 2.6139	Cost: 16.33s
Train Epoch: 333 	Average Loss: 4.5092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3775

Learning rate: 1.3528655947984512e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 22.6711	Cost: 33.74s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 2.7215	Cost: 16.82s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 2.5886	Cost: 16.97s
Train Epoch: 334 	Average Loss: 4.4720
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1449

Learning rate: 1.3136848556180878e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 23.5386	Cost: 32.93s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 2.7337	Cost: 16.74s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 2.7197	Cost: 17.15s
Train Epoch: 335 	Average Loss: 4.5433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.9855

Learning rate: 1.2750399292720314e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 22.9433	Cost: 36.97s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 2.8468	Cost: 16.93s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 2.6656	Cost: 16.72s
Train Epoch: 336 	Average Loss: 4.5241
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.8222

Learning rate: 1.2369331995613651e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 22.7040	Cost: 34.13s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 2.6358	Cost: 16.89s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 2.5410	Cost: 12.84s
Train Epoch: 337 	Average Loss: 4.4436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.9667

Learning rate: 1.1993670170886837e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 23.8523	Cost: 32.27s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 2.7611	Cost: 16.91s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 2.5511	Cost: 9.66s
Train Epoch: 338 	Average Loss: 4.4961
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3936

Learning rate: 1.1623436991130663e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 22.8147	Cost: 34.91s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 2.6968	Cost: 9.54s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 2.5310	Cost: 15.99s
Train Epoch: 339 	Average Loss: 4.4327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.9038

Learning rate: 1.1258655294071704e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 22.6666	Cost: 31.54s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 2.5492	Cost: 12.72s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 2.5400	Cost: 12.62s
Train Epoch: 340 	Average Loss: 4.4101
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.6599

Learning rate: 1.089934758116323e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 22.8151	Cost: 30.00s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 2.5698	Cost: 9.89s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 2.4626	Cost: 18.10s
Train Epoch: 341 	Average Loss: 4.3704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1728

Learning rate: 1.054553601619753e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 22.8171	Cost: 31.83s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 2.5881	Cost: 9.71s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 2.5141	Cost: 20.50s
Train Epoch: 342 	Average Loss: 4.3709
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2466

Learning rate: 1.0197242423938455e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 22.7463	Cost: 31.71s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 2.6606	Cost: 16.63s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 2.4825	Cost: 15.91s
Train Epoch: 343 	Average Loss: 4.4087
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.2857

Learning rate: 9.854488288775428e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 22.8181	Cost: 33.70s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 2.6139	Cost: 16.42s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 2.5121	Cost: 16.47s
Train Epoch: 344 	Average Loss: 4.3682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3460

Learning rate: 9.517294753398073e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 22.7654	Cost: 32.85s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 2.5152	Cost: 16.71s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 2.4669	Cost: 16.39s
Train Epoch: 345 	Average Loss: 4.3505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.9609

Learning rate: 9.185682617491872e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 23.8781	Cost: 33.21s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 2.5526	Cost: 15.10s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 2.4307	Cost: 16.69s
Train Epoch: 346 	Average Loss: 4.3800
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.7151

Learning rate: 8.859672336455501e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 24.1453	Cost: 32.45s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 2.5143	Cost: 15.69s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 2.4481	Cost: 16.86s
Train Epoch: 347 	Average Loss: 4.3799
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3733

Learning rate: 8.539284020138645e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 22.9267	Cost: 36.22s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 2.5199	Cost: 17.40s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 2.4564	Cost: 16.44s
Train Epoch: 348 	Average Loss: 4.3110
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.4813

Learning rate: 8.224537431601915e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 23.0402	Cost: 33.87s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 2.4386	Cost: 14.51s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 2.3696	Cost: 12.16s
Train Epoch: 349 	Average Loss: 4.3057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.0616

Learning rate: 7.915451985897387e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 23.1863	Cost: 31.92s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 2.4985	Cost: 16.22s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 2.3906	Cost: 10.53s
Train Epoch: 350 	Average Loss: 4.2723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1001

Learning rate: 7.612046748871354e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 22.7113	Cost: 35.48s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 2.4144	Cost: 11.98s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 2.3490	Cost: 11.14s
Train Epoch: 351 	Average Loss: 4.2555
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.7189

Learning rate: 7.314340435987926e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 22.8605	Cost: 32.08s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 2.4006	Cost: 12.20s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 2.2503	Cost: 12.62s
Train Epoch: 352 	Average Loss: 4.2383
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2872

Learning rate: 7.022351411174871e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 23.3381	Cost: 30.96s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 2.4019	Cost: 12.73s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 2.3694	Cost: 10.82s
Train Epoch: 353 	Average Loss: 4.2408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3687

Learning rate: 6.736097685690606e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 22.7759	Cost: 29.48s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 2.3626	Cost: 9.83s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 2.2643	Cost: 20.58s
Train Epoch: 354 	Average Loss: 4.2720
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.0566

Learning rate: 6.455596917013267e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 23.4979	Cost: 32.09s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 2.5136	Cost: 10.56s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 2.2306	Cost: 20.11s
Train Epoch: 355 	Average Loss: 4.2429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3851

Learning rate: 6.1808664077516005e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 22.7875	Cost: 31.77s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 2.4379	Cost: 17.09s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 2.2479	Cost: 16.41s
Train Epoch: 356 	Average Loss: 4.1819
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.9970

Learning rate: 5.91192310457746e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 22.7389	Cost: 35.00s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 2.3791	Cost: 16.73s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 2.2599	Cost: 16.52s
Train Epoch: 357 	Average Loss: 4.1711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.0419

Learning rate: 5.648783597180656e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 22.8577	Cost: 34.53s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 2.3658	Cost: 16.82s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 2.2977	Cost: 16.48s
Train Epoch: 358 	Average Loss: 4.1716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1016

Learning rate: 5.3914641172454745e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 23.3450	Cost: 34.68s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 2.3568	Cost: 15.02s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 2.2903	Cost: 16.51s
Train Epoch: 359 	Average Loss: 4.1578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2978

Learning rate: 5.139980537449555e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 22.8002	Cost: 35.63s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 2.3120	Cost: 16.77s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 2.2448	Cost: 16.32s
Train Epoch: 360 	Average Loss: 4.1281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1984

Learning rate: 4.894348370484651e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 22.7937	Cost: 34.22s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 2.3648	Cost: 16.05s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 2.2658	Cost: 11.25s
Train Epoch: 361 	Average Loss: 4.1471
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1032

Learning rate: 4.6545827680998834e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 22.8074	Cost: 35.19s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 2.3803	Cost: 10.40s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 2.2095	Cost: 13.58s
Train Epoch: 362 	Average Loss: 4.1259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1860

Learning rate: 4.420698520166991e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 22.7425	Cost: 33.97s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 2.3647	Cost: 12.81s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 2.1523	Cost: 12.37s
Train Epoch: 363 	Average Loss: 4.1124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3565

Learning rate: 4.1927100537680815e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 22.8891	Cost: 31.61s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 2.3165	Cost: 11.24s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 2.1806	Cost: 13.58s
Train Epoch: 364 	Average Loss: 4.1169
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3751

Learning rate: 3.970631432305708e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 23.2912	Cost: 29.83s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 2.2651	Cost: 9.80s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 2.2259	Cost: 21.02s
Train Epoch: 365 	Average Loss: 4.1193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1223

Learning rate: 3.7544763546352753e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 23.2190	Cost: 33.09s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 2.3367	Cost: 14.02s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 2.1598	Cost: 17.73s
Train Epoch: 366 	Average Loss: 4.1106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3416

Learning rate: 3.5442581542202067e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 22.7797	Cost: 33.72s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 2.3171	Cost: 16.70s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 2.1313	Cost: 16.59s
Train Epoch: 367 	Average Loss: 4.0827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3773

Learning rate: 3.339989798309276e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 22.9613	Cost: 34.30s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 2.2629	Cost: 16.39s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 2.2298	Cost: 16.65s
Train Epoch: 368 	Average Loss: 4.0789
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1779

Learning rate: 3.1416838871369064e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 22.8101	Cost: 33.63s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 2.2915	Cost: 16.79s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 2.1554	Cost: 16.68s
Train Epoch: 369 	Average Loss: 4.0671
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.0577

Learning rate: 2.9493526531457563e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 22.9426	Cost: 34.85s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 2.2701	Cost: 17.09s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 2.1659	Cost: 16.56s
Train Epoch: 370 	Average Loss: 4.0655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3362

Learning rate: 2.7630079602323468e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 22.7955	Cost: 33.23s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 2.2711	Cost: 16.90s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 2.1553	Cost: 14.13s
Train Epoch: 371 	Average Loss: 4.0557
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3865

Learning rate: 2.582661303015068e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 23.1107	Cost: 31.92s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 2.2526	Cost: 16.32s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 2.0619	Cost: 10.52s
Train Epoch: 372 	Average Loss: 4.0804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.8362

Learning rate: 2.40832380612527e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 23.1646	Cost: 32.25s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 2.2218	Cost: 10.28s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 2.1266	Cost: 13.82s
Train Epoch: 373 	Average Loss: 4.0705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.7138

Learning rate: 2.2400062235209426e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 23.0117	Cost: 31.50s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 2.1947	Cost: 12.71s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 2.0689	Cost: 12.95s
Train Epoch: 374 	Average Loss: 4.0494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3013

Learning rate: 2.0777189378234156e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 22.8646	Cost: 30.37s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 2.2452	Cost: 10.01s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 2.1146	Cost: 18.15s
Train Epoch: 375 	Average Loss: 4.0341
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2731

Learning rate: 1.9214719596769582e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 22.9122	Cost: 32.05s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 2.1946	Cost: 9.69s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 2.0683	Cost: 19.00s
Train Epoch: 376 	Average Loss: 4.0318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.0998

Learning rate: 1.771274927131129e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 22.9302	Cost: 34.11s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 2.2169	Cost: 15.83s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 2.1057	Cost: 16.49s
Train Epoch: 377 	Average Loss: 4.0350
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.4787

Learning rate: 1.6271371050464177e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 22.8643	Cost: 32.85s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 2.1868	Cost: 16.94s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 2.0780	Cost: 16.52s
Train Epoch: 378 	Average Loss: 4.0201
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.5636

Learning rate: 1.4890673845226142e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 22.8237	Cost: 36.36s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 2.2088	Cost: 16.30s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 2.0311	Cost: 16.54s
Train Epoch: 379 	Average Loss: 4.0077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1259

Learning rate: 1.3570742823504575e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 22.8659	Cost: 32.66s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 2.2897	Cost: 16.92s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 2.1027	Cost: 16.69s
Train Epoch: 380 	Average Loss: 4.0321
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.0653

Learning rate: 1.2311659404862349e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 22.9018	Cost: 34.45s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 2.1992	Cost: 16.89s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 2.1608	Cost: 17.26s
Train Epoch: 381 	Average Loss: 4.0099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.4064

Learning rate: 1.1113501255495491e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 23.0670	Cost: 34.92s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 2.1874	Cost: 17.00s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 2.0721	Cost: 13.97s
Train Epoch: 382 	Average Loss: 4.0404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3454

Learning rate: 9.97634228344247e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 22.9192	Cost: 32.56s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 2.2072	Cost: 14.09s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 2.1152	Cost: 12.52s
Train Epoch: 383 	Average Loss: 4.0049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1372

Learning rate: 8.90025263402528e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 22.7116	Cost: 32.66s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 2.2077	Cost: 15.86s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 2.1242	Cost: 10.91s
Train Epoch: 384 	Average Loss: 4.0037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.0348

Learning rate: 7.88529868552224e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 23.2097	Cost: 33.00s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 2.1925	Cost: 16.61s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 2.1155	Cost: 9.84s
Train Epoch: 385 	Average Loss: 4.0241
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.4862

Learning rate: 6.931543045073711e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 22.9379	Cost: 36.16s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 2.2102	Cost: 9.67s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 2.0591	Cost: 14.83s
Train Epoch: 386 	Average Loss: 3.9995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2633

Learning rate: 6.039044544820409e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 22.8165	Cost: 31.41s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 2.1895	Cost: 12.77s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 2.0428	Cost: 12.51s
Train Epoch: 387 	Average Loss: 3.9956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.4240

Learning rate: 5.207858238273524e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 22.9594	Cost: 30.88s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 2.1952	Cost: 9.87s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 2.0639	Cost: 18.99s
Train Epoch: 388 	Average Loss: 4.0148
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.4501

Learning rate: 4.4380353969200063e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 22.7550	Cost: 31.94s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 2.1777	Cost: 9.68s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 2.0486	Cost: 18.39s
Train Epoch: 389 	Average Loss: 3.9844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.4978

Learning rate: 3.7296235070587456e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 22.9222	Cost: 31.51s
Train Epoch: 390 [40960/90000 (45%)]	Loss: 2.1728	Cost: 14.37s
Train Epoch: 390 [81920/90000 (91%)]	Loss: 2.1528	Cost: 16.24s
Train Epoch: 390 	Average Loss: 4.0125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.7741

Learning rate: 3.082666266872038e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 22.6849	Cost: 33.31s
Train Epoch: 391 [40960/90000 (45%)]	Loss: 2.1527	Cost: 16.90s
Train Epoch: 391 [81920/90000 (91%)]	Loss: 1.9996	Cost: 16.04s
Train Epoch: 391 	Average Loss: 3.9964
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.4030

Learning rate: 2.497203583729958e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 22.8245	Cost: 32.94s
Train Epoch: 392 [40960/90000 (45%)]	Loss: 2.1935	Cost: 16.22s
Train Epoch: 392 [81920/90000 (91%)]	Loss: 2.0600	Cost: 16.46s
Train Epoch: 392 	Average Loss: 3.9995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.4153

Learning rate: 1.973271571728442e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 22.8381	Cost: 32.82s
Train Epoch: 393 [40960/90000 (45%)]	Loss: 2.2038	Cost: 16.64s
Train Epoch: 393 [81920/90000 (91%)]	Loss: 2.1600	Cost: 16.57s
Train Epoch: 393 	Average Loss: 4.0104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.7057

Learning rate: 1.5109025494620685e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 22.6038	Cost: 34.22s
Train Epoch: 394 [40960/90000 (45%)]	Loss: 2.1787	Cost: 16.70s
Train Epoch: 394 [81920/90000 (91%)]	Loss: 2.0292	Cost: 16.64s
Train Epoch: 394 	Average Loss: 3.9947
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.9357

Learning rate: 1.1101250380300971e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 23.7289	Cost: 37.19s
Train Epoch: 395 [40960/90000 (45%)]	Loss: 2.1986	Cost: 16.28s
Train Epoch: 395 [81920/90000 (91%)]	Loss: 2.0839	Cost: 9.52s
Train Epoch: 395 	Average Loss: 4.0415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.5284

Learning rate: 7.709637592770994e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 22.9086	Cost: 33.34s
Train Epoch: 396 [40960/90000 (45%)]	Loss: 2.2317	Cost: 9.59s
Train Epoch: 396 [81920/90000 (91%)]	Loss: 2.1464	Cost: 16.26s
Train Epoch: 396 	Average Loss: 4.0497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.6351

Learning rate: 4.934396342684002e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 22.8194	Cost: 31.40s
Train Epoch: 397 [40960/90000 (45%)]	Loss: 2.1738	Cost: 12.70s
Train Epoch: 397 [81920/90000 (91%)]	Loss: 2.1127	Cost: 12.75s
Train Epoch: 397 	Average Loss: 3.9873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3297

Learning rate: 2.7756978199944282e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 22.8038	Cost: 29.79s
Train Epoch: 398 [40960/90000 (45%)]	Loss: 2.2415	Cost: 9.84s
Train Epoch: 398 [81920/90000 (91%)]	Loss: 2.0572	Cost: 20.90s
Train Epoch: 398 	Average Loss: 3.9859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2877

Learning rate: 1.2336751833941234e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 22.7315	Cost: 32.79s
Train Epoch: 399 [40960/90000 (45%)]	Loss: 2.2062	Cost: 11.06s
Train Epoch: 399 [81920/90000 (91%)]	Loss: 2.1070	Cost: 21.21s
Train Epoch: 399 	Average Loss: 3.9931
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.0828

Learning rate: 3.084235521033653e-09
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 23.0710	Cost: 34.40s
Train Epoch: 400 [40960/90000 (45%)]	Loss: 2.2274	Cost: 16.45s
Train Epoch: 400 [81920/90000 (91%)]	Loss: 2.0490	Cost: 16.75s
Train Epoch: 400 	Average Loss: 3.9987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3533

Stopping timer.
Training time (including validation): 415679.3713014126 seconds
Saving model
Transfer learning by starting with alpha=0.01!
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 23.0897	Cost: 31.50s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 21.4299	Cost: 15.61s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 20.4076	Cost: 16.91s
Train Epoch: 1 	Average Loss: 21.5469
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8961

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999691576447898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 20.2311	Cost: 32.97s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 19.2988	Cost: 16.86s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 18.8118	Cost: 15.71s
Train Epoch: 2 	Average Loss: 19.2785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3887

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 19.2217	Cost: 32.57s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 18.5386	Cost: 16.08s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 18.2368	Cost: 9.52s
Train Epoch: 3 	Average Loss: 18.5238
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8375

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 18.9058	Cost: 32.98s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 18.0097	Cost: 9.90s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 17.7797	Cost: 13.86s
Train Epoch: 4 	Average Loss: 18.0660
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5833

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.00019995065603657316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 18.6123	Cost: 31.80s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 17.7016	Cost: 11.13s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 17.5948	Cost: 13.24s
Train Epoch: 5 	Average Loss: 17.7513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5130

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.0001999229036240723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 18.5252	Cost: 32.13s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 17.4500	Cost: 9.70s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 17.3872	Cost: 19.72s
Train Epoch: 6 	Average Loss: 17.5527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4216

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019988898749619702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 18.4420	Cost: 32.89s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 17.2925	Cost: 16.46s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 17.3373	Cost: 16.56s
Train Epoch: 7 	Average Loss: 17.3706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5249

Learning rate: 0.00019984890974505381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 18.5901	Cost: 32.45s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 17.3948	Cost: 16.32s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 17.2376	Cost: 16.49s
Train Epoch: 8 	Average Loss: 17.4686
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4789

Learning rate: 0.00019980267284282717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 18.4975	Cost: 33.30s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 17.0821	Cost: 16.88s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 16.9502	Cost: 17.10s
Train Epoch: 9 	Average Loss: 17.2070
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4671

Learning rate: 0.00019975027964162705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 18.4137	Cost: 34.12s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 16.8943	Cost: 16.72s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 16.7958	Cost: 15.37s
Train Epoch: 10 	Average Loss: 17.0252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4252

Learning rate: 0.00019969173337331284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 18.5606	Cost: 33.61s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 16.8055	Cost: 14.71s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 16.7616	Cost: 12.19s
Train Epoch: 11 	Average Loss: 16.9710
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5835

Learning rate: 0.00019962703764929416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 18.6053	Cost: 35.85s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 16.7371	Cost: 11.83s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 16.6473	Cost: 12.12s
Train Epoch: 12 	Average Loss: 16.8270
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5911

Learning rate: 0.00019955619646030802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 18.6896	Cost: 34.05s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 16.5613	Cost: 12.79s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 16.4460	Cost: 12.56s
Train Epoch: 13 	Average Loss: 16.6812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6775

Learning rate: 0.00019947921417617267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 18.6567	Cost: 30.91s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 16.4420	Cost: 9.83s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 16.3150	Cost: 21.60s
Train Epoch: 14 	Average Loss: 16.5860
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7524

Learning rate: 0.000199396095545518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 18.7991	Cost: 33.06s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 16.2377	Cost: 14.07s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 16.1960	Cost: 18.03s
Train Epoch: 15 	Average Loss: 16.4768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8246

Learning rate: 0.00019930684569549264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 18.8192	Cost: 33.10s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 16.1087	Cost: 16.62s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 16.1636	Cost: 16.41s
Train Epoch: 16 	Average Loss: 16.3778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9695

Learning rate: 0.0001992114701314478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 19.0201	Cost: 35.29s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 16.0764	Cost: 16.75s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 15.9090	Cost: 16.58s
Train Epoch: 17 	Average Loss: 16.3013
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0036

Learning rate: 0.00019910997473659747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 19.0392	Cost: 32.66s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 15.9343	Cost: 16.84s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 15.8681	Cost: 16.94s
Train Epoch: 18 	Average Loss: 16.2103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0636

Learning rate: 0.00019900236577165574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 19.0534	Cost: 33.81s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 15.7886	Cost: 17.31s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 15.7493	Cost: 14.99s
Train Epoch: 19 	Average Loss: 16.0995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2162

Learning rate: 0.00019888864987445046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 19.3679	Cost: 37.92s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 15.6655	Cost: 16.98s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 15.6715	Cost: 9.62s
Train Epoch: 20 	Average Loss: 16.0581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2293

Learning rate: 0.00019876883405951377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 19.2765	Cost: 34.91s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 15.6396	Cost: 10.74s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 15.5290	Cost: 14.98s
Train Epoch: 21 	Average Loss: 15.9581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3064

Learning rate: 0.00019864292571764955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 19.4872	Cost: 32.29s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 15.7008	Cost: 12.69s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 15.4410	Cost: 12.85s
Train Epoch: 22 	Average Loss: 15.9445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3731

Learning rate: 0.0001985109326154774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 19.5746	Cost: 31.23s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 15.5789	Cost: 9.71s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 15.3870	Cost: 16.77s
Train Epoch: 23 	Average Loss: 15.8701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4313

Learning rate: 0.00019837286289495361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 19.6945	Cost: 31.98s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 15.3779	Cost: 9.73s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 15.3254	Cost: 22.40s
Train Epoch: 24 	Average Loss: 15.7629
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5811

Learning rate: 0.0001982287250728689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 19.7298	Cost: 32.32s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 15.3431	Cost: 16.92s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 15.2753	Cost: 16.34s
Train Epoch: 25 	Average Loss: 15.7170
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6744

Learning rate: 0.00019807852804032305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 19.5602	Cost: 34.54s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 15.3111	Cost: 16.61s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 15.2808	Cost: 16.46s
Train Epoch: 26 	Average Loss: 15.6732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6727

Learning rate: 0.00019792228106217658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 19.8155	Cost: 36.24s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 15.2762	Cost: 16.65s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 15.1085	Cost: 16.39s
Train Epoch: 27 	Average Loss: 15.6423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6718

Learning rate: 0.0001977599937764791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 19.7574	Cost: 37.05s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 15.1249	Cost: 15.94s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 15.1030	Cost: 11.03s
Train Epoch: 28 	Average Loss: 15.5547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6426

Learning rate: 0.00019759167619387474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 19.8216	Cost: 34.19s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 14.9706	Cost: 11.20s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 14.9598	Cost: 12.65s
Train Epoch: 29 	Average Loss: 15.4805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7915

Learning rate: 0.00019741733869698495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 19.8844	Cost: 32.31s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 14.9731	Cost: 12.66s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 14.9157	Cost: 13.01s
Train Epoch: 30 	Average Loss: 15.4041
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8127

Learning rate: 0.00019723699203976766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 19.9588	Cost: 31.75s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 14.9098	Cost: 9.96s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 14.8791	Cost: 21.83s
Train Epoch: 31 	Average Loss: 15.3478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8998

Learning rate: 0.00019705064734685425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 19.8656	Cost: 31.80s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 14.9527	Cost: 12.58s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 14.8751	Cost: 19.06s
Train Epoch: 32 	Average Loss: 15.3667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9861

Learning rate: 0.00019685831611286313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 19.8648	Cost: 33.60s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 14.7393	Cost: 16.44s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 15.0359	Cost: 16.39s
Train Epoch: 33 	Average Loss: 15.2960
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9515

Learning rate: 0.00019666001020169073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 19.9591	Cost: 33.50s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 14.7721	Cost: 16.69s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 14.7146	Cost: 16.64s
Train Epoch: 34 	Average Loss: 15.2606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0075

Learning rate: 0.0001964557418457798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 19.9988	Cost: 34.93s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 14.5716	Cost: 17.25s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 14.6728	Cost: 15.40s
Train Epoch: 35 	Average Loss: 15.1420
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1679

Learning rate: 0.0001962455236453647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 20.1310	Cost: 32.56s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 14.6200	Cost: 15.04s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 14.4705	Cost: 12.49s
Train Epoch: 36 	Average Loss: 15.1156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0976

Learning rate: 0.00019602936856769428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 20.2870	Cost: 36.68s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 14.6900	Cost: 11.74s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 14.4573	Cost: 10.09s
Train Epoch: 37 	Average Loss: 15.0990
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0688

Learning rate: 0.0001958072899462319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 20.2176	Cost: 33.95s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 14.4888	Cost: 12.99s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 14.3225	Cost: 12.74s
Train Epoch: 38 	Average Loss: 14.9586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1976

Learning rate: 0.00019557930147983297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 20.2080	Cost: 31.56s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 14.3264	Cost: 10.02s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 14.1929	Cost: 17.88s
Train Epoch: 39 	Average Loss: 14.8067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2096

Learning rate: 0.00019534541723190008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 20.1862	Cost: 30.36s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 14.1814	Cost: 9.72s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 14.1840	Cost: 22.17s
Train Epoch: 40 	Average Loss: 14.7668
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3541

Learning rate: 0.00019510565162951532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 20.3000	Cost: 35.70s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 14.1691	Cost: 16.27s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 14.0213	Cost: 16.56s
Train Epoch: 41 	Average Loss: 14.6971
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3974

Learning rate: 0.0001948600194625504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 20.3364	Cost: 34.87s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 14.0320	Cost: 17.30s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 14.2197	Cost: 16.91s
Train Epoch: 42 	Average Loss: 14.6645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4435

Learning rate: 0.00019460853588275446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 20.3643	Cost: 34.68s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 14.1324	Cost: 16.90s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 14.0883	Cost: 17.17s
Train Epoch: 43 	Average Loss: 14.7205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5960

Learning rate: 0.0001943512164028193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 20.5300	Cost: 37.18s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 13.9884	Cost: 16.05s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 13.9942	Cost: 10.66s
Train Epoch: 44 	Average Loss: 14.5883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5171

Learning rate: 0.00019408807689542249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 20.5869	Cost: 33.06s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 13.9705	Cost: 14.79s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 13.7274	Cost: 9.73s
Train Epoch: 45 	Average Loss: 14.4855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4973

Learning rate: 0.00019381913359224837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 20.7965	Cost: 31.63s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 13.7092	Cost: 9.73s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 13.7797	Cost: 15.20s
Train Epoch: 46 	Average Loss: 14.3735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6688

Learning rate: 0.0001935444030829867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 20.5744	Cost: 30.55s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 13.7249	Cost: 11.33s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 13.6946	Cost: 13.97s
Train Epoch: 47 	Average Loss: 14.3389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7047

Learning rate: 0.00019326390231430937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 20.5317	Cost: 29.98s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 13.6009	Cost: 9.71s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 13.7408	Cost: 22.58s
Train Epoch: 48 	Average Loss: 14.2845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7146

Learning rate: 0.00019297764858882508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 20.7917	Cost: 36.15s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 13.6241	Cost: 16.12s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 13.5906	Cost: 16.62s
Train Epoch: 49 	Average Loss: 14.2809
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8044

Learning rate: 0.000192685659564012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 20.6689	Cost: 34.38s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 13.5820	Cost: 16.92s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 13.6169	Cost: 17.01s
Train Epoch: 50 	Average Loss: 14.2256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7442

Learning rate: 0.00019238795325112859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 20.7614	Cost: 34.67s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 13.4990	Cost: 16.62s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 13.4534	Cost: 14.17s
Train Epoch: 51 	Average Loss: 14.1674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9257

Learning rate: 0.00019208454801410258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 20.8418	Cost: 35.39s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 13.5085	Cost: 16.93s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 13.2546	Cost: 9.65s
Train Epoch: 52 	Average Loss: 14.0866
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9324

Learning rate: 0.00019177546256839804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 20.7735	Cost: 33.24s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 13.4708	Cost: 11.81s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 14.2716	Cost: 10.93s
Train Epoch: 53 	Average Loss: 14.2827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9803

Learning rate: 0.0001914607159798613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 21.0075	Cost: 31.85s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 13.9970	Cost: 12.93s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 13.6034	Cost: 12.69s
Train Epoch: 54 	Average Loss: 14.5835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7027

Learning rate: 0.00019114032766354445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 20.6854	Cost: 32.17s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 13.5661	Cost: 11.16s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 13.5247	Cost: 13.93s
Train Epoch: 55 	Average Loss: 14.2235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7555

Learning rate: 0.00019081431738250806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 20.7646	Cost: 32.58s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 13.2482	Cost: 9.68s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 13.0027	Cost: 21.72s
Train Epoch: 56 	Average Loss: 13.8870
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9411

Learning rate: 0.00019048270524660188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 20.8541	Cost: 34.11s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 13.0240	Cost: 16.44s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 12.9224	Cost: 16.61s
Train Epoch: 57 	Average Loss: 13.7338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0835

Learning rate: 0.0001901455117112245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 21.0535	Cost: 33.76s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 13.6597	Cost: 16.92s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 13.3962	Cost: 17.19s
Train Epoch: 58 	Average Loss: 14.2080
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9731

Learning rate: 0.0001898027575760615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 21.0294	Cost: 33.56s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 13.1479	Cost: 16.90s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 12.9361	Cost: 16.75s
Train Epoch: 59 	Average Loss: 13.9147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0733

Learning rate: 0.00018945446398380245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 21.0524	Cost: 34.15s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 13.3358	Cost: 16.43s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 13.1387	Cost: 10.99s
Train Epoch: 60 	Average Loss: 13.9921
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1714

Learning rate: 0.00018910065241883672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 20.9128	Cost: 35.69s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 12.9845	Cost: 11.45s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 12.6901	Cost: 13.19s
Train Epoch: 61 	Average Loss: 13.7067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2066

Learning rate: 0.00018874134470592827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 21.1017	Cost: 31.96s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 12.7097	Cost: 12.97s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 12.6153	Cost: 12.68s
Train Epoch: 62 	Average Loss: 13.4867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3695

Learning rate: 0.0001883765630088693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 21.4210	Cost: 31.12s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 12.6387	Cost: 11.34s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 12.6340	Cost: 12.89s
Train Epoch: 63 	Average Loss: 13.5015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4180

Learning rate: 0.00018800632982911313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 21.5044	Cost: 29.01s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 12.6746	Cost: 9.69s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 12.6117	Cost: 21.78s
Train Epoch: 64 	Average Loss: 13.4584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4235

Learning rate: 0.00018763066800438628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 21.4898	Cost: 32.29s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 12.5687	Cost: 13.78s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 12.4625	Cost: 16.31s
Train Epoch: 65 	Average Loss: 13.3915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5001

Learning rate: 0.00018724960070727966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 21.4283	Cost: 33.62s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 12.6046	Cost: 16.49s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 12.5736	Cost: 16.71s
Train Epoch: 66 	Average Loss: 13.4210
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5637

Learning rate: 0.00018686315144381908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 21.3068	Cost: 33.51s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 12.6087	Cost: 16.20s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 12.5457	Cost: 16.41s
Train Epoch: 67 	Average Loss: 13.4546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5262

Learning rate: 0.00018647134405201546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 21.1590	Cost: 33.89s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 12.5041	Cost: 16.54s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 12.6763	Cost: 16.69s
Train Epoch: 68 	Average Loss: 13.4000
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6316

Learning rate: 0.00018607420270039433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 21.6137	Cost: 35.30s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 12.6457	Cost: 17.16s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 12.4900	Cost: 15.01s
Train Epoch: 69 	Average Loss: 13.5341
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4791

Learning rate: 0.00018567175188650495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 21.6471	Cost: 36.61s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 12.4235	Cost: 14.48s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 12.4911	Cost: 12.16s
Train Epoch: 70 	Average Loss: 13.3522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5729

Learning rate: 0.0001852640164354092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 21.5277	Cost: 34.91s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 12.4907	Cost: 15.53s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 12.2084	Cost: 9.75s
Train Epoch: 71 	Average Loss: 13.2919
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5398

Learning rate: 0.00018485102149815036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 21.7223	Cost: 33.48s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 12.3647	Cost: 10.07s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 11.9222	Cost: 14.69s
Train Epoch: 72 	Average Loss: 13.0992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7466

Learning rate: 0.0001844327925502015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 21.8137	Cost: 29.82s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 12.1994	Cost: 12.70s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 11.9728	Cost: 10.14s
Train Epoch: 73 	Average Loss: 12.9653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7980

Learning rate: 0.00018400935538989417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 21.8770	Cost: 30.89s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 12.1347	Cost: 9.73s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 12.0920	Cost: 21.70s
Train Epoch: 74 	Average Loss: 13.0697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7970

Learning rate: 0.00018358073613682703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 21.7114	Cost: 31.66s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 12.0928	Cost: 11.95s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 12.6632	Cost: 17.20s
Train Epoch: 75 	Average Loss: 13.1782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8439

Learning rate: 0.00018314696123025452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 21.7638	Cost: 34.23s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 12.3903	Cost: 16.46s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 12.1483	Cost: 16.41s
Train Epoch: 76 	Average Loss: 13.2650
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6394

Learning rate: 0.00018270805742745614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 21.7999	Cost: 35.18s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 12.0976	Cost: 16.43s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 11.9847	Cost: 16.52s
Train Epoch: 77 	Average Loss: 13.0263
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8768

Learning rate: 0.00018226405180208597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 21.7744	Cost: 35.22s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 11.9409	Cost: 16.76s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 11.8892	Cost: 16.90s
Train Epoch: 78 	Average Loss: 12.8610
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0242

Learning rate: 0.00018181497174250233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 21.6448	Cost: 33.52s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 12.5850	Cost: 16.81s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 13.3401	Cost: 14.20s
Train Epoch: 79 	Average Loss: 13.6348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8757

Learning rate: 0.00018136084495007872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 21.4681	Cost: 33.06s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 12.7887	Cost: 15.52s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 12.5535	Cost: 11.09s
Train Epoch: 80 	Average Loss: 13.6113
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4534

Learning rate: 0.00018090169943749476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 21.8254	Cost: 35.61s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 12.2771	Cost: 9.83s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 12.0228	Cost: 15.29s
Train Epoch: 81 	Average Loss: 13.1403
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5844

Learning rate: 0.00018043756352700846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 21.5189	Cost: 32.99s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 11.7219	Cost: 12.75s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 11.8635	Cost: 12.79s
Train Epoch: 82 	Average Loss: 12.7171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9551

Learning rate: 0.00017996846584870908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 21.7642	Cost: 29.32s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 11.5591	Cost: 9.99s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 11.5692	Cost: 17.49s
Train Epoch: 83 	Average Loss: 12.5528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0380

Learning rate: 0.000179494435338751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 21.8651	Cost: 31.87s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 11.5342	Cost: 9.72s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 11.6044	Cost: 20.51s
Train Epoch: 84 	Average Loss: 12.4868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2980

Learning rate: 0.00017901550123756904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 22.1929	Cost: 33.19s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 11.5399	Cost: 16.90s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 11.5633	Cost: 16.47s
Train Epoch: 85 	Average Loss: 12.5000
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2780

Learning rate: 0.00017853169308807448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 22.2445	Cost: 33.60s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 11.4154	Cost: 16.57s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 11.3466	Cost: 16.65s
Train Epoch: 86 	Average Loss: 12.3793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2449

Learning rate: 0.00017804304073383296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 22.5054	Cost: 34.03s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 11.3462	Cost: 15.46s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 11.3898	Cost: 16.94s
Train Epoch: 87 	Average Loss: 12.3423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1941

Learning rate: 0.00017754957431722346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 22.3526	Cost: 35.48s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 11.5438	Cost: 16.76s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 11.4000	Cost: 17.25s
Train Epoch: 88 	Average Loss: 12.4685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2352

Learning rate: 0.00017705132427757892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 22.5959	Cost: 34.95s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 11.5628	Cost: 16.83s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 11.5922	Cost: 16.68s
Train Epoch: 89 	Average Loss: 12.5571
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1331

Learning rate: 0.00017654832134930882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 22.1743	Cost: 34.66s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 11.2313	Cost: 17.21s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 11.1368	Cost: 11.96s
Train Epoch: 90 	Average Loss: 12.3510
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2718

Learning rate: 0.0001760405965600031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 22.2028	Cost: 37.19s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 11.0278	Cost: 11.77s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 10.9335	Cost: 11.66s
Train Epoch: 91 	Average Loss: 12.1283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5228

Learning rate: 0.00017552818122851838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 22.1441	Cost: 32.89s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 11.1348	Cost: 12.87s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 11.1884	Cost: 12.79s
Train Epoch: 92 	Average Loss: 12.1652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6374

Learning rate: 0.00017501110696304596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 22.0862	Cost: 31.65s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 11.1547	Cost: 10.27s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 11.2669	Cost: 15.83s
Train Epoch: 93 	Average Loss: 12.2210
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5437

Learning rate: 0.0001744894056591622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 22.7372	Cost: 30.81s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 11.4418	Cost: 9.68s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 11.2423	Cost: 21.92s
Train Epoch: 94 	Average Loss: 12.4847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2628

Learning rate: 0.00017396310949786096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 22.4935	Cost: 33.20s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 11.0858	Cost: 16.88s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 10.9071	Cost: 16.40s
Train Epoch: 95 	Average Loss: 12.1450
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4653

Learning rate: 0.00017343225094356858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 22.3003	Cost: 32.48s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 10.9332	Cost: 16.45s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 11.0122	Cost: 16.57s
Train Epoch: 96 	Average Loss: 12.0730
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5779

Learning rate: 0.00017289686274214118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 22.5186	Cost: 34.72s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 11.2299	Cost: 14.70s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 12.1107	Cost: 17.31s
Train Epoch: 97 	Average Loss: 12.4434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5177

Learning rate: 0.00017235697791884494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 22.6386	Cost: 37.23s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 12.5960	Cost: 15.53s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 12.0834	Cost: 11.70s
Train Epoch: 98 	Average Loss: 13.4445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9365

Learning rate: 0.0001718126297763189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 22.2869	Cost: 33.80s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 11.5708	Cost: 12.93s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 11.1942	Cost: 9.85s
Train Epoch: 99 	Average Loss: 12.5221
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2448

Learning rate: 0.00017126385189252056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 22.3271	Cost: 31.72s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 15.4553	Cost: 11.79s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 18.2120	Cost: 12.81s
Train Epoch: 100 	Average Loss: 15.6277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2786

Learning rate: 0.00017071067811865479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 21.7069	Cost: 30.18s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 16.9037	Cost: 12.94s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 16.0774	Cost: 10.95s
Train Epoch: 101 	Average Loss: 17.3143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3916

Learning rate: 0.00017015314257708562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 20.4015	Cost: 29.24s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 15.4658	Cost: 9.81s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 14.8505	Cost: 21.93s
Train Epoch: 102 	Average Loss: 15.8492
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1933

Learning rate: 0.00016959127965923145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 20.3144	Cost: 31.48s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 14.2825	Cost: 9.85s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 13.7963	Cost: 18.73s
Train Epoch: 103 	Average Loss: 14.7780
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5888

Learning rate: 0.00016902512402344375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 21.2990	Cost: 35.02s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 13.6180	Cost: 16.34s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 13.1938	Cost: 16.25s
Train Epoch: 104 	Average Loss: 14.2566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8920

Learning rate: 0.0001684547105928689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 21.5012	Cost: 35.42s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 12.9761	Cost: 15.45s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 12.6306	Cost: 16.62s
Train Epoch: 105 	Average Loss: 13.6720
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2651

Learning rate: 0.00016788007455329423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 21.3755	Cost: 33.71s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 12.4965	Cost: 16.84s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 12.3781	Cost: 16.87s
Train Epoch: 106 	Average Loss: 13.2808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6719

Learning rate: 0.00016730125135097737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 21.5468	Cost: 34.17s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 12.2973	Cost: 16.88s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 12.3762	Cost: 12.90s
Train Epoch: 107 	Average Loss: 13.1647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8271

Learning rate: 0.00016671827669046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 21.8670	Cost: 31.77s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 12.1830	Cost: 16.02s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 11.9569	Cost: 10.73s
Train Epoch: 108 	Average Loss: 13.0419
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9335

Learning rate: 0.0001661311865323652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 22.0668	Cost: 36.73s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 11.8991	Cost: 12.31s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 11.7185	Cost: 11.35s
Train Epoch: 109 	Average Loss: 12.7788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0314

Learning rate: 0.00016554001709117943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 22.3411	Cost: 33.68s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 11.6953	Cost: 12.81s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 11.4103	Cost: 12.76s
Train Epoch: 110 	Average Loss: 12.5724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2072

Learning rate: 0.00016494480483301838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 22.2469	Cost: 31.15s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 11.3138	Cost: 10.68s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 11.2014	Cost: 15.02s
Train Epoch: 111 	Average Loss: 12.2895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4546

Learning rate: 0.0001643455864733779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 22.5749	Cost: 30.77s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 11.1753	Cost: 9.77s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 11.0228	Cost: 22.11s
Train Epoch: 112 	Average Loss: 12.1616
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4613

Learning rate: 0.000163742398974869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 22.7941	Cost: 31.72s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 10.8677	Cost: 16.81s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 10.6411	Cost: 16.38s
Train Epoch: 113 	Average Loss: 11.9212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6719

Learning rate: 0.00016313527954493778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 22.8169	Cost: 32.39s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 10.6636	Cost: 16.39s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 10.5538	Cost: 16.25s
Train Epoch: 114 	Average Loss: 11.7458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7884

Learning rate: 0.00016252426563357055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 22.9875	Cost: 35.18s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 10.5454	Cost: 16.37s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 10.3913	Cost: 16.50s
Train Epoch: 115 	Average Loss: 11.6211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8626

Learning rate: 0.0001619093949309834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 22.8324	Cost: 33.22s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 10.9777	Cost: 16.68s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 10.9287	Cost: 16.83s
Train Epoch: 116 	Average Loss: 11.9784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0466

Learning rate: 0.00016129070536529766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 22.7159	Cost: 33.73s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 10.7063	Cost: 16.89s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 10.4535	Cost: 17.32s
Train Epoch: 117 	Average Loss: 11.7518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8939

Learning rate: 0.00016066823510019996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 22.7911	Cost: 37.61s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 10.4287	Cost: 16.27s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 10.2549	Cost: 11.33s
Train Epoch: 118 	Average Loss: 11.4875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0049

Learning rate: 0.0001600420225325884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 22.8450	Cost: 34.68s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 10.2728	Cost: 14.38s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 10.1077	Cost: 9.61s
Train Epoch: 119 	Average Loss: 11.3748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1204

Learning rate: 0.00015941210629020385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 23.2889	Cost: 33.83s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 10.0923	Cost: 9.99s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 9.8963	Cost: 15.98s
Train Epoch: 120 	Average Loss: 11.2298
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1909

Learning rate: 0.00015877852522924735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 22.8904	Cost: 30.49s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 9.8178	Cost: 9.85s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 9.8094	Cost: 17.21s
Train Epoch: 121 	Average Loss: 11.0808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4054

Learning rate: 0.00015814131843198305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 22.9580	Cost: 30.31s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 9.8775	Cost: 9.73s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 10.1258	Cost: 21.47s
Train Epoch: 122 	Average Loss: 11.1458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2589

Learning rate: 0.00015750052520432787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 23.2819	Cost: 32.84s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 10.0564	Cost: 16.80s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 9.8307	Cost: 16.55s
Train Epoch: 123 	Average Loss: 11.2256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2246

Learning rate: 0.0001568561850734264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 23.3286	Cost: 33.97s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 9.9532	Cost: 16.29s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 9.8540	Cost: 16.33s
Train Epoch: 124 	Average Loss: 11.1487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3393

Learning rate: 0.00015620833778521307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 23.4186	Cost: 32.63s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 9.8384	Cost: 16.60s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 9.6976	Cost: 16.60s
Train Epoch: 125 	Average Loss: 11.0423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3731

Learning rate: 0.00015555702330196023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 23.4624	Cost: 33.97s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 9.7408	Cost: 16.76s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 9.6123	Cost: 16.94s
Train Epoch: 126 	Average Loss: 10.9698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5283

Learning rate: 0.00015490228179981317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 23.5095	Cost: 33.58s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 9.7849	Cost: 16.74s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 9.7091	Cost: 14.72s
Train Epoch: 127 	Average Loss: 11.0107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4501

Learning rate: 0.00015424415366631188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 23.2486	Cost: 33.21s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 10.0541	Cost: 15.80s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 10.2069	Cost: 9.67s
Train Epoch: 128 	Average Loss: 11.2930
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3119

Learning rate: 0.00015358267949789966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 23.0364	Cost: 34.10s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 9.9180	Cost: 9.58s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 9.7877	Cost: 15.46s
Train Epoch: 129 	Average Loss: 11.1587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2542

Learning rate: 0.00015291790009741904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 23.5932	Cost: 30.92s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 9.8553	Cost: 9.76s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 9.6947	Cost: 18.79s
Train Epoch: 130 	Average Loss: 11.1490
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2039

Learning rate: 0.00015224985647159487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 23.2112	Cost: 32.49s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 9.8079	Cost: 9.72s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 9.4981	Cost: 19.71s
Train Epoch: 131 	Average Loss: 10.9962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3407

Learning rate: 0.00015157858982850473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 23.2985	Cost: 31.76s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 9.6175	Cost: 16.73s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 9.5715	Cost: 16.31s
Train Epoch: 132 	Average Loss: 10.8666
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4018

Learning rate: 0.0001509041415750371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 23.2526	Cost: 34.05s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 9.5980	Cost: 16.10s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 9.6455	Cost: 16.58s
Train Epoch: 133 	Average Loss: 10.9155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5274

Learning rate: 0.00015022655331433721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 23.4509	Cost: 35.81s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 9.6285	Cost: 16.59s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 9.5528	Cost: 17.20s
Train Epoch: 134 	Average Loss: 10.8997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4885

Learning rate: 0.00014954586684324072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 23.4888	Cost: 33.71s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 9.4284	Cost: 17.16s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 9.5182	Cost: 16.76s
Train Epoch: 135 	Average Loss: 10.7671
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5996

Learning rate: 0.00014886212414969547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 23.3674	Cost: 34.77s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 9.4684	Cost: 16.76s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 9.5462	Cost: 14.70s
Train Epoch: 136 	Average Loss: 10.8275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5794

Learning rate: 0.0001481753674101715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 23.4179	Cost: 32.26s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 9.5447	Cost: 16.74s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 9.5288	Cost: 10.01s
Train Epoch: 137 	Average Loss: 10.7944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.6136

Learning rate: 0.00014748563898705943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 23.4251	Cost: 33.22s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 9.7815	Cost: 9.57s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 9.8443	Cost: 14.65s
Train Epoch: 138 	Average Loss: 10.9853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4852

Learning rate: 0.00014679298142605734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 23.8421	Cost: 30.92s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 9.7213	Cost: 12.70s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 9.6541	Cost: 11.20s
Train Epoch: 139 	Average Loss: 10.9432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4793

Learning rate: 0.00014609743745354624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 23.2125	Cost: 30.08s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 9.6000	Cost: 9.86s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 9.6068	Cost: 21.69s
Train Epoch: 140 	Average Loss: 10.8438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4692

Learning rate: 0.00014539904997395466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 23.5137	Cost: 32.12s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 9.4671	Cost: 10.41s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 9.4664	Cost: 21.75s
Train Epoch: 141 	Average Loss: 10.7206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5831

Learning rate: 0.0001446978620671121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 23.2409	Cost: 33.49s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 9.2774	Cost: 16.58s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 9.3195	Cost: 16.49s
Train Epoch: 142 	Average Loss: 10.5773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.6526

Learning rate: 0.0001439939169855915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 23.3538	Cost: 33.27s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 9.2049	Cost: 16.76s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 9.1702	Cost: 16.82s
Train Epoch: 143 	Average Loss: 10.4694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.7321

Learning rate: 0.0001432872581520414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 23.5337	Cost: 34.41s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 9.1444	Cost: 17.01s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 9.1240	Cost: 16.69s
Train Epoch: 144 	Average Loss: 10.3913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9343

Learning rate: 0.00014257792915650728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 23.6166	Cost: 35.09s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 9.0868	Cost: 16.95s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 9.1338	Cost: 16.70s
Train Epoch: 145 	Average Loss: 10.3038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9259

Learning rate: 0.0001418659737537428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 23.7238	Cost: 35.14s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 9.1482	Cost: 17.11s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 9.0662	Cost: 13.84s
Train Epoch: 146 	Average Loss: 10.3675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.8575

Learning rate: 0.00014115143586051088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 23.7611	Cost: 33.11s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 8.9401	Cost: 15.93s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 8.8121	Cost: 9.59s
Train Epoch: 147 	Average Loss: 10.2004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9951

Learning rate: 0.0001404343595528745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 24.3998	Cost: 34.56s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 9.1944	Cost: 10.84s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 9.0033	Cost: 13.04s
Train Epoch: 148 	Average Loss: 10.4056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.8642

Learning rate: 0.00013971478906347806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 23.5458	Cost: 29.65s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 8.9895	Cost: 12.06s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 8.7330	Cost: 12.94s
Train Epoch: 149 	Average Loss: 10.2372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.1030

Learning rate: 0.00013899276877881884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 23.8432	Cost: 30.96s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 8.8114	Cost: 12.81s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 8.6243	Cost: 9.74s
Train Epoch: 150 	Average Loss: 10.1201
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.0985

Learning rate: 0.000138268343236509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 23.7087	Cost: 29.42s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 8.8938	Cost: 9.70s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 8.7121	Cost: 21.79s
Train Epoch: 151 	Average Loss: 10.1749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.0794

Learning rate: 0.00013754155712252834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 23.8538	Cost: 31.52s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 8.9452	Cost: 11.83s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 8.7653	Cost: 18.65s
Train Epoch: 152 	Average Loss: 10.2049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.1612

Learning rate: 0.00013681245526846785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 23.9488	Cost: 32.19s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 8.8078	Cost: 17.00s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 8.5707	Cost: 16.30s
Train Epoch: 153 	Average Loss: 10.0470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.0540

Learning rate: 0.00013608108264876422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 24.0780	Cost: 33.57s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 8.5988	Cost: 16.48s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 8.5092	Cost: 16.67s
Train Epoch: 154 	Average Loss: 9.9397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.1119

Learning rate: 0.00013534748437792575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 23.3470	Cost: 32.14s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 8.5452	Cost: 16.85s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 8.3108	Cost: 17.32s
Train Epoch: 155 	Average Loss: 9.8202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.3342

Learning rate: 0.00013461170570774932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 24.0351	Cost: 34.27s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 8.5440	Cost: 16.56s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 8.7782	Cost: 16.75s
Train Epoch: 156 	Average Loss: 9.9468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.1362

Learning rate: 0.0001338737920245292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 24.0190	Cost: 37.01s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 10.2367	Cost: 16.23s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 9.7173	Cost: 12.49s
Train Epoch: 157 	Average Loss: 11.2799
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.7376

Learning rate: 0.00013313378884625713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 23.9726	Cost: 34.53s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 10.0351	Cost: 16.18s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 9.5387	Cost: 9.55s
Train Epoch: 158 	Average Loss: 11.2421
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2475

Learning rate: 0.00013239174181981498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 23.1011	Cost: 34.04s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 9.1691	Cost: 9.61s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 8.7891	Cost: 17.56s
Train Epoch: 159 	Average Loss: 10.4383
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.7591

Learning rate: 0.00013164769671815865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 23.4454	Cost: 30.56s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 8.6637	Cost: 12.75s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 9.2266	Cost: 12.48s
Train Epoch: 160 	Average Loss: 10.1449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.2552

Learning rate: 0.0001309016994374948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 24.7816	Cost: 30.12s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 10.3648	Cost: 9.90s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 9.7907	Cost: 18.06s
Train Epoch: 161 	Average Loss: 11.5541
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3905

Learning rate: 0.00013015379599444962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 23.3456	Cost: 30.79s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 9.1807	Cost: 9.70s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 8.8862	Cost: 21.08s
Train Epoch: 162 	Average Loss: 10.5110
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5351

Learning rate: 0.00012940403252323043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 24.3446	Cost: 36.85s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 9.2884	Cost: 16.45s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 9.2101	Cost: 16.37s
Train Epoch: 163 	Average Loss: 10.4963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9631

Learning rate: 0.00012865245527277986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 24.0122	Cost: 34.52s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 9.1891	Cost: 16.48s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 8.7218	Cost: 16.61s
Train Epoch: 164 	Average Loss: 10.4040
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.8067

Learning rate: 0.00012789911060392294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 23.6364	Cost: 35.00s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 8.5728	Cost: 16.66s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 8.3787	Cost: 16.58s
Train Epoch: 165 	Average Loss: 9.9179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.1714

Learning rate: 0.00012714404498650745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 24.8592	Cost: 36.08s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 9.0508	Cost: 16.81s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 8.6799	Cost: 14.06s
Train Epoch: 166 	Average Loss: 10.2553
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.1193

Learning rate: 0.00012638730499653727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 23.5662	Cost: 36.97s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 8.3862	Cost: 15.70s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 8.1311	Cost: 9.55s
Train Epoch: 167 	Average Loss: 9.7564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.2515

Learning rate: 0.00012562893731329965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 24.4798	Cost: 33.55s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 8.4165	Cost: 10.73s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 8.2346	Cost: 12.43s
Train Epoch: 168 	Average Loss: 9.7939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.2859

Learning rate: 0.00012486898871648546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 24.2501	Cost: 31.07s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 8.1847	Cost: 12.85s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 7.8724	Cost: 12.83s
Train Epoch: 169 	Average Loss: 9.5409
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4311

Learning rate: 0.00012410750608330388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 24.3496	Cost: 31.04s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 8.0050	Cost: 9.67s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 8.0314	Cost: 19.77s
Train Epoch: 170 	Average Loss: 9.5434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5445

Learning rate: 0.00012334453638559054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 24.4752	Cost: 31.60s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 8.0041	Cost: 9.69s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 8.0421	Cost: 19.73s
Train Epoch: 171 	Average Loss: 9.5535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5753

Learning rate: 0.00012258012668691037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 23.9621	Cost: 32.70s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 7.8843	Cost: 15.25s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 8.1873	Cost: 16.61s
Train Epoch: 172 	Average Loss: 9.5452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4571

Learning rate: 0.00012181432413965427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 24.4283	Cost: 34.67s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 8.0861	Cost: 16.50s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 8.5754	Cost: 16.55s
Train Epoch: 173 	Average Loss: 9.7892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5923

Learning rate: 0.0001210471759821306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 25.8045	Cost: 34.41s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 9.2035	Cost: 16.24s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 8.7905	Cost: 16.32s
Train Epoch: 174 	Average Loss: 10.5922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.3150

Learning rate: 0.00012027872953565127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 24.0968	Cost: 33.12s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 8.3194	Cost: 16.52s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 7.9606	Cost: 16.88s
Train Epoch: 175 	Average Loss: 9.8309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.2523

Learning rate: 0.00011950903220161285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 24.2168	Cost: 34.65s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 7.8518	Cost: 16.93s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 7.7488	Cost: 15.46s
Train Epoch: 176 	Average Loss: 9.4319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5269

Learning rate: 0.00011873813145857249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 24.6486	Cost: 34.06s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 7.5845	Cost: 16.81s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 7.6517	Cost: 13.44s
Train Epoch: 177 	Average Loss: 9.2513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5936

Learning rate: 0.00011796607485931927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 25.1291	Cost: 36.79s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 7.7099	Cost: 12.65s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 7.8850	Cost: 9.78s
Train Epoch: 178 	Average Loss: 9.2865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.6599

Learning rate: 0.00011719291002794096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 24.3544	Cost: 32.11s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 8.0663	Cost: 12.22s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 7.8275	Cost: 12.64s
Train Epoch: 179 	Average Loss: 9.5292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.6968

Learning rate: 0.0001164186846568863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 24.9961	Cost: 30.91s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 7.6810	Cost: 11.94s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 7.5298	Cost: 10.67s
Train Epoch: 180 	Average Loss: 9.2454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5537

Learning rate: 0.0001156434465040231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 24.7193	Cost: 29.64s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 7.3881	Cost: 9.69s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 7.2993	Cost: 21.68s
Train Epoch: 181 	Average Loss: 9.0254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.8414

Learning rate: 0.00011486724338969234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 24.8997	Cost: 31.32s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 7.7308	Cost: 10.82s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 7.6992	Cost: 18.99s
Train Epoch: 182 	Average Loss: 9.2256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.9217

Learning rate: 0.0001140901231937583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 25.0878	Cost: 32.80s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 7.6082	Cost: 16.43s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 7.4593	Cost: 16.76s
Train Epoch: 183 	Average Loss: 9.1384
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.7411

Learning rate: 0.00011331213385265528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 24.0420	Cost: 34.07s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 7.3822	Cost: 16.55s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 7.3252	Cost: 16.59s
Train Epoch: 184 	Average Loss: 8.8866
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.0496

Learning rate: 0.00011253332335643047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 24.7377	Cost: 34.26s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 7.2810	Cost: 14.80s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 7.3994	Cost: 16.71s
Train Epoch: 185 	Average Loss: 8.8914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.0117

Learning rate: 0.0001117537397457838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 24.8082	Cost: 34.49s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 7.5780	Cost: 15.90s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 7.5262	Cost: 16.56s
Train Epoch: 186 	Average Loss: 9.0356
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.7753

Learning rate: 0.00011097343110910456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 24.6193	Cost: 33.09s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 7.4705	Cost: 16.89s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 7.3216	Cost: 17.32s
Train Epoch: 187 	Average Loss: 8.9498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.9757

Learning rate: 0.00011019244557950502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 24.4853	Cost: 35.74s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 7.3057	Cost: 16.88s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 7.4038	Cost: 16.62s
Train Epoch: 188 	Average Loss: 8.9091
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.0451

Learning rate: 0.00010941083133185145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 24.7706	Cost: 33.65s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 7.6111	Cost: 16.88s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 7.4547	Cost: 11.54s
Train Epoch: 189 	Average Loss: 9.1048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.8421

Learning rate: 0.00010862863657979236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 24.6171	Cost: 36.83s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 7.1997	Cost: 11.98s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 7.2251	Cost: 10.59s
Train Epoch: 190 	Average Loss: 8.8236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.9577

Learning rate: 0.00010784590957278452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 24.8443	Cost: 32.87s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 7.2375	Cost: 12.70s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 7.2179	Cost: 13.01s
Train Epoch: 191 	Average Loss: 8.8287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.8723

Learning rate: 0.00010706269859311669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 24.6385	Cost: 30.47s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 7.2233	Cost: 12.79s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 7.1923	Cost: 10.25s
Train Epoch: 192 	Average Loss: 8.7815
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.9913

Learning rate: 0.00010627905195293137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 25.0337	Cost: 28.96s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 7.2905	Cost: 9.95s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 7.1147	Cost: 21.68s
Train Epoch: 193 	Average Loss: 8.8438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.0649

Learning rate: 0.00010549501799124461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 24.6780	Cost: 31.38s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 7.2845	Cost: 10.57s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 7.0859	Cost: 20.62s
Train Epoch: 194 	Average Loss: 8.8028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.7974

Learning rate: 0.00010471064507096429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 24.6614	Cost: 36.16s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 7.2137	Cost: 16.62s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 7.1124	Cost: 16.38s
Train Epoch: 195 	Average Loss: 8.7636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.0620

Learning rate: 0.00010392598157590689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 24.6853	Cost: 33.30s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 7.0456	Cost: 16.50s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 7.0734	Cost: 16.57s
Train Epoch: 196 	Average Loss: 8.6123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.1685

Learning rate: 0.00010314107590781285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 24.5120	Cost: 33.64s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 7.5760	Cost: 16.46s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 7.1553	Cost: 17.06s
Train Epoch: 197 	Average Loss: 9.0769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.9576

Learning rate: 0.00010235597648336105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 24.5493	Cost: 32.82s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 7.1353	Cost: 16.08s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 6.7609	Cost: 16.93s
Train Epoch: 198 	Average Loss: 8.7294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.9850

Learning rate: 0.0001015707317311821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 24.9031	Cost: 33.57s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 6.8953	Cost: 16.57s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 6.6149	Cost: 17.09s
Train Epoch: 199 	Average Loss: 8.5813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.0899

Learning rate: 0.00010078539008887115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 24.5443	Cost: 34.43s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 6.8173	Cost: 16.93s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 6.5619	Cost: 16.90s
Train Epoch: 200 	Average Loss: 8.5105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.2981

Learning rate: 0.00010000000000000002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 24.8032	Cost: 35.69s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 7.1634	Cost: 16.74s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 7.0828	Cost: 14.38s
Train Epoch: 201 	Average Loss: 8.7224
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.1417

Learning rate: 9.92146099111289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 24.2512	Cost: 34.24s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 7.0121	Cost: 15.42s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 6.8024	Cost: 9.53s
Train Epoch: 202 	Average Loss: 8.7227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.3486

Learning rate: 9.842926826881797e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 24.0512	Cost: 33.55s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 6.8627	Cost: 9.64s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 6.7702	Cost: 14.94s
Train Epoch: 203 	Average Loss: 8.6362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.2600

Learning rate: 9.7644023516639e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 24.8126	Cost: 30.71s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 6.8812	Cost: 12.73s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 7.2435	Cost: 10.81s
Train Epoch: 204 	Average Loss: 8.7377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.1230

Learning rate: 9.68589240921872e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 23.7799	Cost: 29.39s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 7.3356	Cost: 9.89s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 7.7509	Cost: 19.55s
Train Epoch: 205 	Average Loss: 9.0328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.9385

Learning rate: 9.607401842409317e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 24.4269	Cost: 32.17s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 7.7391	Cost: 12.02s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 8.0915	Cost: 19.07s
Train Epoch: 206 	Average Loss: 9.1323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.6101

Learning rate: 9.528935492903578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 24.2276	Cost: 34.62s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 7.7062	Cost: 16.43s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 7.5202	Cost: 16.48s
Train Epoch: 207 	Average Loss: 8.9909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.6113

Learning rate: 9.450498200875547e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 24.2104	Cost: 28.90s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 7.3969	Cost: 9.63s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 7.1663	Cost: 11.85s
Train Epoch: 208 	Average Loss: 8.7225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.9466

Learning rate: 9.372094804706868e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 24.0527	Cost: 29.00s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 7.0001	Cost: 9.70s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 6.9396	Cost: 13.22s
Train Epoch: 209 	Average Loss: 8.5000
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.1929

Learning rate: 9.293730140688336e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 24.4921	Cost: 29.97s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 7.0720	Cost: 9.98s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 6.8413	Cost: 12.87s
Train Epoch: 210 	Average Loss: 8.4899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.2343

Learning rate: 9.215409042721555e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 24.2621	Cost: 28.16s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 6.8732	Cost: 9.63s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 7.0654	Cost: 13.17s
Train Epoch: 211 	Average Loss: 8.3234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.1395

Learning rate: 9.13713634202077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 24.6344	Cost: 28.62s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 7.0885	Cost: 9.67s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 7.2400	Cost: 13.11s
Train Epoch: 212 	Average Loss: 8.3580
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.2371

Learning rate: 9.058916866814858e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 26.3427	Cost: 29.06s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 8.0348	Cost: 9.64s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 7.8119	Cost: 12.79s
Train Epoch: 213 	Average Loss: 9.2712
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.1060

Learning rate: 8.9807554420495e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 24.8640	Cost: 30.28s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 7.7083	Cost: 9.83s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 7.5415	Cost: 21.82s
Train Epoch: 214 	Average Loss: 8.9355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.6140

Learning rate: 8.902656889089548e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 24.3111	Cost: 31.92s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 8.1948	Cost: 11.12s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 7.6136	Cost: 18.56s
Train Epoch: 215 	Average Loss: 9.2085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.3376

Learning rate: 8.824626025421624e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 24.3245	Cost: 32.87s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 7.3144	Cost: 13.57s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 7.0847	Cost: 16.32s
Train Epoch: 216 	Average Loss: 8.6401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.8320

Learning rate: 8.746667664356959e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 24.7369	Cost: 33.42s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 6.9615	Cost: 14.01s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 6.5967	Cost: 17.60s
Train Epoch: 217 	Average Loss: 8.2323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.0802

Learning rate: 8.668786614734478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 24.9727	Cost: 32.06s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 6.8169	Cost: 16.29s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 6.4896	Cost: 16.32s
Train Epoch: 218 	Average Loss: 8.0695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.2372

Learning rate: 8.590987680624175e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 24.6865	Cost: 32.73s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 6.6439	Cost: 16.52s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 6.2388	Cost: 16.47s
Train Epoch: 219 	Average Loss: 7.9817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.3737

Learning rate: 8.51327566103077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 24.6459	Cost: 32.26s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 6.2852	Cost: 16.69s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 6.0646	Cost: 16.58s
Train Epoch: 220 	Average Loss: 7.8287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.4372

Learning rate: 8.435655349597692e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 24.2986	Cost: 35.06s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 6.0732	Cost: 16.56s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 5.8985	Cost: 16.51s
Train Epoch: 221 	Average Loss: 7.7015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.7722

Learning rate: 8.35813153431137e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 23.8376	Cost: 32.26s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 6.0117	Cost: 16.47s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 6.4913	Cost: 16.59s
Train Epoch: 222 	Average Loss: 7.8094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.6219

Learning rate: 8.280708997205904e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 24.2564	Cost: 34.11s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 6.8750	Cost: 16.31s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 6.4491	Cost: 16.67s
Train Epoch: 223 	Average Loss: 8.3581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.7207

Learning rate: 8.203392514068074e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 24.7347	Cost: 36.51s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 6.4330	Cost: 16.89s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 6.5427	Cost: 16.65s
Train Epoch: 224 	Average Loss: 8.1005
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.5291

Learning rate: 8.126186854142755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 23.9081	Cost: 34.29s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 6.3230	Cost: 16.99s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 6.1727	Cost: 14.22s
Train Epoch: 225 	Average Loss: 7.9467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.8063

Learning rate: 8.049096779838719e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 25.2125	Cost: 33.00s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 6.4395	Cost: 15.79s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 6.2368	Cost: 10.86s
Train Epoch: 226 	Average Loss: 8.0714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1421

Learning rate: 7.972127046434877e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 24.1097	Cost: 33.74s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 6.2180	Cost: 9.76s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 5.8201	Cost: 14.02s
Train Epoch: 227 	Average Loss: 7.6822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.8495

Learning rate: 7.895282401786947e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 25.8819	Cost: 31.96s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 6.1566	Cost: 12.85s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 5.8741	Cost: 12.72s
Train Epoch: 228 	Average Loss: 7.7392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.6231

Learning rate: 7.818567586034578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 24.0663	Cost: 30.09s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 6.0616	Cost: 11.33s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 5.7675	Cost: 11.69s
Train Epoch: 229 	Average Loss: 7.5312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.6470

Learning rate: 7.741987331308968e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 24.1184	Cost: 30.46s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 5.5854	Cost: 9.67s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 5.5103	Cost: 21.81s
Train Epoch: 230 	Average Loss: 7.3103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.9432

Learning rate: 7.665546361440945e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 25.2715	Cost: 32.53s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 6.0257	Cost: 14.00s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 5.7499	Cost: 17.80s
Train Epoch: 231 	Average Loss: 7.6444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.7742

Learning rate: 7.589249391669613e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 24.7491	Cost: 33.41s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 6.9220	Cost: 16.48s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 6.5108	Cost: 16.38s
Train Epoch: 232 	Average Loss: 8.2569
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.3133

Learning rate: 7.513101128351452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 23.7561	Cost: 34.04s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 5.9348	Cost: 16.68s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 5.8779	Cost: 17.29s
Train Epoch: 233 	Average Loss: 7.6281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.7229

Learning rate: 7.437106268670034e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 24.3950	Cost: 33.29s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 5.9071	Cost: 15.39s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 5.7661	Cost: 16.87s
Train Epoch: 234 	Average Loss: 7.5792
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2028

Learning rate: 7.361269500346273e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 23.5018	Cost: 34.30s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 5.5214	Cost: 17.21s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 5.5856	Cost: 17.38s
Train Epoch: 235 	Average Loss: 7.2959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.9846

Learning rate: 7.28559550134926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 23.4645	Cost: 33.96s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 5.4231	Cost: 16.76s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 5.3582	Cost: 14.40s
Train Epoch: 236 	Average Loss: 7.0600
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1739

Learning rate: 7.210088939607711e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 24.5105	Cost: 38.04s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 6.1581	Cost: 13.24s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 6.4318	Cost: 9.46s
Train Epoch: 237 	Average Loss: 7.8240
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.9114

Learning rate: 7.13475447272202e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 25.0584	Cost: 34.52s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 6.7197	Cost: 9.90s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 6.2856	Cost: 15.03s
Train Epoch: 238 	Average Loss: 8.2146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.6418

Learning rate: 7.059596747676965e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 23.6884	Cost: 30.13s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 5.9900	Cost: 11.50s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 5.8244	Cost: 12.21s
Train Epoch: 239 	Average Loss: 7.5638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.9993

Learning rate: 6.984620400555048e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 23.6304	Cost: 31.35s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 5.6871	Cost: 9.68s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 5.5219	Cost: 22.54s
Train Epoch: 240 	Average Loss: 7.2759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1600

Learning rate: 6.909830056250531e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 24.1587	Cost: 32.57s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 5.5944	Cost: 14.04s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 5.3764	Cost: 19.52s
Train Epoch: 241 	Average Loss: 7.1060
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.9424

Learning rate: 6.835230328184141e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 23.3921	Cost: 32.96s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 5.1139	Cost: 16.49s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 5.1035	Cost: 16.61s
Train Epoch: 242 	Average Loss: 6.7373
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.0677

Learning rate: 6.760825818018508e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 24.4560	Cost: 33.37s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 5.3355	Cost: 17.16s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 5.1885	Cost: 17.17s
Train Epoch: 243 	Average Loss: 6.8726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3476

Learning rate: 6.686621115374292e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 23.9176	Cost: 32.96s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 5.4386	Cost: 16.80s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 4.9625	Cost: 16.91s
Train Epoch: 244 	Average Loss: 6.8367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2405

Learning rate: 6.61262079754709e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 23.4427	Cost: 35.25s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 4.9459	Cost: 16.89s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 4.7149	Cost: 13.66s
Train Epoch: 245 	Average Loss: 6.5550
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1776

Learning rate: 6.538829429225073e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 23.4274	Cost: 33.96s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 4.7023	Cost: 16.17s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 4.5526	Cost: 9.64s
Train Epoch: 246 	Average Loss: 6.3419
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2912

Learning rate: 6.465251562207432e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 25.0522	Cost: 32.97s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 4.8631	Cost: 9.64s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 4.8044	Cost: 13.87s
Train Epoch: 247 	Average Loss: 6.5164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3435

Learning rate: 6.391891735123586e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 23.5925	Cost: 30.94s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 4.6710	Cost: 12.96s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 4.5839	Cost: 12.83s
Train Epoch: 248 	Average Loss: 6.3455
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3185

Learning rate: 6.318754473153225e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 23.9591	Cost: 29.65s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 4.5394	Cost: 9.80s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 4.5171	Cost: 17.33s
Train Epoch: 249 	Average Loss: 6.3243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.4055

Learning rate: 6.245844287747173e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 24.1902	Cost: 30.93s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 5.6430	Cost: 9.70s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 5.4966	Cost: 21.68s
Train Epoch: 250 	Average Loss: 7.0598
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.4881

Learning rate: 6.173165676349108e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 23.3072	Cost: 35.17s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 5.1755	Cost: 16.81s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 5.1191	Cost: 16.35s
Train Epoch: 251 	Average Loss: 6.8724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.0551

Learning rate: 6.10072312211812e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 23.8660	Cost: 36.97s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 4.9002	Cost: 16.60s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 4.7874	Cost: 16.58s
Train Epoch: 252 	Average Loss: 6.5942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2419

Learning rate: 6.0285210936521955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 23.3567	Cost: 32.20s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 4.6652	Cost: 16.54s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 4.5355	Cost: 16.63s
Train Epoch: 253 	Average Loss: 6.3154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.6124

Learning rate: 5.956564044712553e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 24.3627	Cost: 33.02s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 4.7788	Cost: 16.57s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 5.2083	Cost: 16.74s
Train Epoch: 254 	Average Loss: 6.6397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.0301

Learning rate: 5.8848564139489155e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 23.7834	Cost: 33.45s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 5.0972	Cost: 14.20s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 4.9437	Cost: 16.93s
Train Epoch: 255 	Average Loss: 6.7194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.0919

Learning rate: 5.813402624625721e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 23.4339	Cost: 33.19s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 4.7019	Cost: 15.16s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 4.5582	Cost: 16.55s
Train Epoch: 256 	Average Loss: 6.3218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1109

Learning rate: 5.742207084349277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 24.4352	Cost: 34.48s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 4.9295	Cost: 16.91s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 4.7960	Cost: 14.56s
Train Epoch: 257 	Average Loss: 6.5076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2506

Learning rate: 5.6712741847958634e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 23.0897	Cost: 32.61s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 4.5735	Cost: 15.72s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 4.4256	Cost: 11.05s
Train Epoch: 258 	Average Loss: 6.1882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2473

Learning rate: 5.600608301440851e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 23.3370	Cost: 33.68s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 4.3046	Cost: 15.33s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 4.2139	Cost: 9.61s
Train Epoch: 259 	Average Loss: 5.9383
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.4571

Learning rate: 5.5302137932887924e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 23.0555	Cost: 32.22s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 4.1348	Cost: 9.76s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 4.1123	Cost: 14.61s
Train Epoch: 260 	Average Loss: 5.8569
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3126

Learning rate: 5.460095002604535e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 23.1550	Cost: 30.63s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 4.0240	Cost: 12.40s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 3.9721	Cost: 9.64s
Train Epoch: 261 	Average Loss: 5.7492
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3421

Learning rate: 5.390256254645381e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 23.0433	Cost: 30.93s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 4.0308	Cost: 9.69s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 3.9721	Cost: 22.26s
Train Epoch: 262 	Average Loss: 5.7402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.6738

Learning rate: 5.3207018573942705e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 23.8459	Cost: 31.99s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 4.0985	Cost: 14.55s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 3.9252	Cost: 16.67s
Train Epoch: 263 	Average Loss: 5.7950
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1562

Learning rate: 5.251436101294054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 23.1407	Cost: 32.97s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 3.9529	Cost: 16.85s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 4.5842	Cost: 16.54s
Train Epoch: 264 	Average Loss: 5.8573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.8647

Learning rate: 5.1824632589828485e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 23.2153	Cost: 33.51s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 4.2392	Cost: 16.52s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 5.4661	Cost: 16.19s
Train Epoch: 265 	Average Loss: 6.2208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1862

Learning rate: 5.1137875850304516e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 23.4273	Cost: 34.92s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 6.5961	Cost: 16.68s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 6.1136	Cost: 16.64s
Train Epoch: 266 	Average Loss: 8.0749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2391

Learning rate: 5.045413315675926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 28.1997	Cost: 35.25s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 5.6627	Cost: 14.74s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 5.7546	Cost: 16.72s
Train Epoch: 267 	Average Loss: 7.7199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.2512

Learning rate: 4.977344668566277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 26.7222	Cost: 32.67s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 6.6961	Cost: 15.89s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 6.7060	Cost: 16.57s
Train Epoch: 268 	Average Loss: 8.5338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.6047

Learning rate: 4.909585842496289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 24.7012	Cost: 34.34s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 6.9503	Cost: 16.88s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 6.3537	Cost: 16.32s
Train Epoch: 269 	Average Loss: 7.9293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.2383

Learning rate: 4.842141017149528e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 23.9599	Cost: 33.96s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 6.2156	Cost: 16.70s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 5.5597	Cost: 9.92s
Train Epoch: 270 	Average Loss: 7.5747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2078

Learning rate: 4.775014352840514e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 25.9616	Cost: 32.23s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 6.0186	Cost: 15.05s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 5.5540	Cost: 9.60s
Train Epoch: 271 	Average Loss: 7.4535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.7566

Learning rate: 4.708209990258097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 23.3387	Cost: 32.69s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 5.2682	Cost: 9.63s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 4.8541	Cost: 18.02s
Train Epoch: 272 	Average Loss: 6.8124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.5794


Let us continue!
Stopping timer.
Training time (including validation): 447512.74285650253 seconds
Saving model
Transfer learning by starting with alpha=0.005!
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 23.8219	Cost: 31.26s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 21.7897	Cost: 12.92s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 20.8786	Cost: 11.71s
Train Epoch: 1 	Average Loss: 21.9030
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4108

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999691576447898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 20.6592	Cost: 29.72s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 19.7265	Cost: 9.74s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 19.3762	Cost: 21.64s
Train Epoch: 2 	Average Loss: 19.7728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9192

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 19.6764	Cost: 31.97s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 18.8221	Cost: 12.85s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 18.7464	Cost: 18.21s
Train Epoch: 3 	Average Loss: 18.8753
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3377

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 19.3493	Cost: 32.52s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 18.3095	Cost: 16.68s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 18.1662	Cost: 16.53s
Train Epoch: 4 	Average Loss: 18.4026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9336

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.00019995065603657316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 18.8064	Cost: 32.18s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 17.8770	Cost: 16.45s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 18.3176	Cost: 16.45s
Train Epoch: 5 	Average Loss: 18.1504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0123

Learning rate: 0.0001999229036240723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 19.0158	Cost: 32.79s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 18.0187	Cost: 16.50s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 17.8079	Cost: 16.56s
Train Epoch: 6 	Average Loss: 18.0215
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6919

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019988898749619702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 18.7023	Cost: 33.15s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 17.5978	Cost: 16.94s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 17.4350	Cost: 17.00s
Train Epoch: 7 	Average Loss: 17.6321
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5277

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.00019984890974505381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 18.5443	Cost: 37.67s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 17.2903	Cost: 11.01s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 17.3334	Cost: 13.03s
Train Epoch: 8 	Average Loss: 17.3956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4561

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.00019980267284282717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 18.5049	Cost: 32.54s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 17.1114	Cost: 12.66s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 16.9859	Cost: 13.03s
Train Epoch: 9 	Average Loss: 17.2276
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4176

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019975027964162705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 18.5495	Cost: 28.28s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 16.9524	Cost: 9.75s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 16.8215	Cost: 17.83s
Train Epoch: 10 	Average Loss: 17.0736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4817

Learning rate: 0.00019969173337331284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 18.4698	Cost: 31.05s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 16.8605	Cost: 9.70s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 16.7209	Cost: 20.72s
Train Epoch: 11 	Average Loss: 16.9405
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4865

Learning rate: 0.00019962703764929416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 18.5338	Cost: 32.14s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 16.7527	Cost: 16.90s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 16.5879	Cost: 16.24s
Train Epoch: 12 	Average Loss: 16.8548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5658

Learning rate: 0.00019955619646030802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 18.5985	Cost: 34.04s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 16.6432	Cost: 16.58s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 16.4931	Cost: 16.57s
Train Epoch: 13 	Average Loss: 16.7333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5720

Learning rate: 0.00019947921417617267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 18.6551	Cost: 32.26s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 16.4353	Cost: 16.53s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 16.2234	Cost: 16.56s
Train Epoch: 14 	Average Loss: 16.5700
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6087

Learning rate: 0.000199396095545518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 18.7031	Cost: 33.45s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 16.3284	Cost: 16.25s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 16.2411	Cost: 16.68s
Train Epoch: 15 	Average Loss: 16.4774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6688

Learning rate: 0.00019930684569549264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 18.6994	Cost: 31.54s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 16.1335	Cost: 16.31s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 16.0614	Cost: 16.61s
Train Epoch: 16 	Average Loss: 16.3453
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8795

Learning rate: 0.0001992114701314478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 18.9390	Cost: 33.40s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 16.0498	Cost: 16.92s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 15.9270	Cost: 16.88s
Train Epoch: 17 	Average Loss: 16.2479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8510

Learning rate: 0.00019910997473659747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 18.9370	Cost: 33.70s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 15.9301	Cost: 17.05s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 15.7479	Cost: 11.89s
Train Epoch: 18 	Average Loss: 16.1141
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.9909

Learning rate: 0.00019900236577165574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 19.0207	Cost: 34.45s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 15.7746	Cost: 14.45s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 15.6428	Cost: 9.51s
Train Epoch: 19 	Average Loss: 15.9888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0772

Learning rate: 0.00019888864987445046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 19.1413	Cost: 32.14s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 15.6010	Cost: 9.58s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 15.5015	Cost: 15.19s
Train Epoch: 20 	Average Loss: 15.8953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.1994

Learning rate: 0.00019876883405951377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 19.3185	Cost: 30.15s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 15.5057	Cost: 9.95s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 15.3726	Cost: 16.34s
Train Epoch: 21 	Average Loss: 15.8283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3555

Learning rate: 0.00019864292571764955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 19.3072	Cost: 30.34s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 15.3516	Cost: 9.71s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 15.2084	Cost: 21.65s
Train Epoch: 22 	Average Loss: 15.6651
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4727

Learning rate: 0.0001985109326154774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 19.7008	Cost: 33.99s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 15.3392	Cost: 16.60s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 15.1386	Cost: 16.43s
Train Epoch: 23 	Average Loss: 15.6404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5657

Learning rate: 0.00019837286289495361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 19.6057	Cost: 34.59s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 15.3250	Cost: 16.34s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 15.1178	Cost: 16.56s
Train Epoch: 24 	Average Loss: 15.6445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6232

Learning rate: 0.0001982287250728689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 19.6283	Cost: 33.53s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 15.0950	Cost: 15.48s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 14.9479	Cost: 16.94s
Train Epoch: 25 	Average Loss: 15.4502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6975

Learning rate: 0.00019807852804032305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 19.7232	Cost: 34.14s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 14.9095	Cost: 16.74s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 14.7515	Cost: 16.96s
Train Epoch: 26 	Average Loss: 15.2982
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8249

Learning rate: 0.00019792228106217658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 19.9672	Cost: 32.82s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 14.7544	Cost: 17.28s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 15.2964	Cost: 17.37s
Train Epoch: 27 	Average Loss: 15.3247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2318

Learning rate: 0.0001977599937764791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 20.2205	Cost: 33.29s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 15.5127	Cost: 16.15s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 15.0600	Cost: 16.40s
Train Epoch: 28 	Average Loss: 15.7529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6337

Learning rate: 0.00019759167619387474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 19.6597	Cost: 33.33s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 14.9158	Cost: 17.06s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 14.6438	Cost: 14.07s
Train Epoch: 29 	Average Loss: 15.3497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8024

Learning rate: 0.00019741733869698495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 19.9949	Cost: 36.32s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 14.6644	Cost: 14.18s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 14.4273	Cost: 9.63s
Train Epoch: 30 	Average Loss: 15.0862
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0861

Learning rate: 0.00019723699203976766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 20.2381	Cost: 34.40s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 14.5904	Cost: 11.11s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 14.3214	Cost: 13.59s
Train Epoch: 31 	Average Loss: 14.9777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3003

Learning rate: 0.00019705064734685425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 20.3384	Cost: 31.27s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 14.5875	Cost: 12.32s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 14.3582	Cost: 9.71s
Train Epoch: 32 	Average Loss: 14.9922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2341

Learning rate: 0.00019685831611286313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 20.2821	Cost: 28.35s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 14.3749	Cost: 9.78s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 14.1915	Cost: 21.91s
Train Epoch: 33 	Average Loss: 14.8491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4378

Learning rate: 0.00019666001020169073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 20.6689	Cost: 32.30s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 14.4188	Cost: 12.16s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 14.1259	Cost: 16.81s
Train Epoch: 34 	Average Loss: 14.8875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4456

Learning rate: 0.0001964557418457798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 20.5571	Cost: 32.29s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 14.2720	Cost: 15.55s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 14.2406	Cost: 16.30s
Train Epoch: 35 	Average Loss: 14.8191
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5221

Learning rate: 0.0001962455236453647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 20.4833	Cost: 33.00s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 14.4448	Cost: 17.08s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 14.5965	Cost: 16.51s
Train Epoch: 36 	Average Loss: 14.9696
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5215

Learning rate: 0.00019602936856769428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 20.5000	Cost: 34.54s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 14.5727	Cost: 16.85s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 14.3141	Cost: 16.60s
Train Epoch: 37 	Average Loss: 15.0071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4659

Learning rate: 0.0001958072899462319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 20.5101	Cost: 35.04s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 14.2063	Cost: 16.87s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 13.8928	Cost: 16.65s
Train Epoch: 38 	Average Loss: 14.6866
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5385

Learning rate: 0.00019557930147983297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 20.6594	Cost: 32.72s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 13.9488	Cost: 15.22s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 13.6649	Cost: 16.68s
Train Epoch: 39 	Average Loss: 14.4983
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6270

Learning rate: 0.00019534541723190008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 20.6503	Cost: 35.03s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 13.8504	Cost: 15.00s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 13.7863	Cost: 16.95s
Train Epoch: 40 	Average Loss: 14.3828
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8260

Learning rate: 0.00019510565162951532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 20.8672	Cost: 36.27s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 13.8590	Cost: 16.78s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 13.6472	Cost: 16.90s
Train Epoch: 41 	Average Loss: 14.4362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7996

Learning rate: 0.0001948600194625504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 20.9429	Cost: 34.82s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 13.7962	Cost: 17.29s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 13.5503	Cost: 14.28s
Train Epoch: 42 	Average Loss: 14.3871
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8273

Learning rate: 0.00019460853588275446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 20.9242	Cost: 32.68s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 13.5375	Cost: 16.06s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 13.4355	Cost: 12.03s
Train Epoch: 43 	Average Loss: 14.2077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.9486

Learning rate: 0.0001943512164028193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 20.7413	Cost: 33.71s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 13.3735	Cost: 16.60s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 13.3894	Cost: 9.55s
Train Epoch: 44 	Average Loss: 14.1233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0597

Learning rate: 0.00019408807689542249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 20.9898	Cost: 32.73s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 13.4323	Cost: 9.69s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 13.4111	Cost: 14.55s
Train Epoch: 45 	Average Loss: 14.0847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1818

Learning rate: 0.00019381913359224837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 21.2318	Cost: 31.34s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 13.4411	Cost: 12.69s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 14.6127	Cost: 12.49s
Train Epoch: 46 	Average Loss: 14.4418
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2674

Learning rate: 0.0001935444030829867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 21.1351	Cost: 29.47s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 14.3883	Cost: 10.58s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 14.1552	Cost: 15.21s
Train Epoch: 47 	Average Loss: 14.9636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.5788

Learning rate: 0.00019326390231430937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 20.6545	Cost: 30.97s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 13.7359	Cost: 9.72s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 14.2839	Cost: 20.10s
Train Epoch: 48 	Average Loss: 14.6480
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7853

Learning rate: 0.00019297764858882508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 20.9842	Cost: 32.29s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 13.7985	Cost: 14.48s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 13.5201	Cost: 16.69s
Train Epoch: 49 	Average Loss: 14.4485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7393

Learning rate: 0.000192685659564012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 21.0830	Cost: 31.92s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 13.2725	Cost: 17.00s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 13.1087	Cost: 16.32s
Train Epoch: 50 	Average Loss: 13.9629
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0361

Learning rate: 0.00019238795325112859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 21.2336	Cost: 33.84s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 12.9215	Cost: 16.33s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 12.7782	Cost: 16.51s
Train Epoch: 51 	Average Loss: 13.6661
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1761

Learning rate: 0.00019208454801410258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 21.3649	Cost: 33.10s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 12.6971	Cost: 16.58s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 12.6159	Cost: 16.90s
Train Epoch: 52 	Average Loss: 13.5143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.3425

Learning rate: 0.00019177546256839804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 21.4394	Cost: 31.82s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 12.5638	Cost: 15.27s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 12.5711	Cost: 16.68s
Train Epoch: 53 	Average Loss: 13.4374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5666

Learning rate: 0.0001914607159798613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 21.6845	Cost: 33.17s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 12.7518	Cost: 16.41s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 12.5385	Cost: 16.61s
Train Epoch: 54 	Average Loss: 13.4430
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.5749

Learning rate: 0.00019114032766354445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 21.3902	Cost: 33.05s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 12.6135	Cost: 16.78s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 12.7636	Cost: 16.78s
Train Epoch: 55 	Average Loss: 13.4316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7288

Learning rate: 0.00019081431738250806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 21.7368	Cost: 33.44s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 12.8779	Cost: 15.97s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 12.7891	Cost: 16.69s
Train Epoch: 56 	Average Loss: 13.7041
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6195

Learning rate: 0.00019048270524660188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 21.4231	Cost: 33.43s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 12.7197	Cost: 16.50s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 12.6392	Cost: 17.19s
Train Epoch: 57 	Average Loss: 13.5596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7251

Learning rate: 0.0001901455117112245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 21.9699	Cost: 33.35s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 12.8472	Cost: 17.11s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 12.6107	Cost: 14.48s
Train Epoch: 58 	Average Loss: 13.6027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4872

Learning rate: 0.0001898027575760615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 21.4766	Cost: 32.11s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 12.6174	Cost: 15.31s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 12.5693	Cost: 11.41s
Train Epoch: 59 	Average Loss: 13.4499
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6276

Learning rate: 0.00018945446398380245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 21.7316	Cost: 35.78s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 12.5241	Cost: 11.03s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 12.4576	Cost: 11.20s
Train Epoch: 60 	Average Loss: 13.3727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6645

Learning rate: 0.00018910065241883672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 21.5389	Cost: 32.25s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 12.4416	Cost: 12.77s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 12.5516	Cost: 12.52s
Train Epoch: 61 	Average Loss: 13.3344
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7328

Learning rate: 0.00018874134470592827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 21.4905	Cost: 30.87s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 12.4305	Cost: 12.70s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 12.4857	Cost: 9.91s
Train Epoch: 62 	Average Loss: 13.3051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.7140

Learning rate: 0.0001883765630088693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 21.7606	Cost: 29.33s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 12.5779	Cost: 9.90s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 12.4534	Cost: 22.48s
Train Epoch: 63 	Average Loss: 13.3619
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6784

Learning rate: 0.00018800632982911313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 21.6930	Cost: 32.47s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 12.2583	Cost: 12.68s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 12.2159	Cost: 16.84s
Train Epoch: 64 	Average Loss: 13.1975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8381

Learning rate: 0.00018763066800438628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 21.6596	Cost: 32.52s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 12.1220	Cost: 16.57s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 12.2332	Cost: 16.29s
Train Epoch: 65 	Average Loss: 13.0907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8019

Learning rate: 0.00018724960070727966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 21.7954	Cost: 33.90s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 12.1560	Cost: 16.46s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 12.1745	Cost: 16.56s
Train Epoch: 66 	Average Loss: 13.0708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9127

Learning rate: 0.00018686315144381908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 21.8823	Cost: 32.46s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 12.1055	Cost: 16.95s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 12.2100	Cost: 16.83s
Train Epoch: 67 	Average Loss: 13.0482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.9408

Learning rate: 0.00018647134405201546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 21.8490	Cost: 32.76s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 12.0673	Cost: 15.30s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 12.2378	Cost: 17.13s
Train Epoch: 68 	Average Loss: 13.0927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.8907

Learning rate: 0.00018607420270039433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 21.6503	Cost: 33.23s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 11.9443	Cost: 17.16s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 12.0825	Cost: 17.41s
Train Epoch: 69 	Average Loss: 12.9148
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.0918

Learning rate: 0.00018567175188650495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 21.9387	Cost: 35.06s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 11.8853	Cost: 17.00s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 11.7872	Cost: 16.56s
Train Epoch: 70 	Average Loss: 12.8046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.1466

Learning rate: 0.0001852640164354092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 22.6358	Cost: 33.20s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 11.9341	Cost: 16.77s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 13.1209	Cost: 17.39s
Train Epoch: 71 	Average Loss: 13.1313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3767

Learning rate: 0.00018485102149815036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 22.6009	Cost: 32.14s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 13.1993	Cost: 17.04s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 12.5784	Cost: 16.44s
Train Epoch: 72 	Average Loss: 13.8644
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.4182

Learning rate: 0.0001844327925502015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 21.5192	Cost: 33.47s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 12.1142	Cost: 16.91s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 11.8316	Cost: 12.46s
Train Epoch: 73 	Average Loss: 12.9730
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.6866

Learning rate: 0.00018400935538989417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 22.0089	Cost: 36.13s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 11.5449	Cost: 10.52s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 11.4055	Cost: 12.27s
Train Epoch: 74 	Average Loss: 12.5280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.2367

Learning rate: 0.00018358073613682703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 22.1964	Cost: 32.76s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 11.3372	Cost: 13.16s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 11.3430	Cost: 13.18s
Train Epoch: 75 	Average Loss: 12.3718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.3616

Learning rate: 0.00018314696123025452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 22.2482	Cost: 30.23s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 11.0893	Cost: 10.80s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 11.4644	Cost: 13.53s
Train Epoch: 76 	Average Loss: 12.2614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6167

Learning rate: 0.00018270805742745614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 22.4241	Cost: 30.04s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 11.4276	Cost: 9.84s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 11.2213	Cost: 22.69s
Train Epoch: 77 	Average Loss: 12.3958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5613

Learning rate: 0.00018226405180208597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 22.4521	Cost: 32.25s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 11.2469	Cost: 15.88s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 11.1734	Cost: 16.44s
Train Epoch: 78 	Average Loss: 12.2233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.5325

Learning rate: 0.00018181497174250233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 22.5222	Cost: 31.20s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 11.0856	Cost: 15.50s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 11.0226	Cost: 16.30s
Train Epoch: 79 	Average Loss: 12.1385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7208

Learning rate: 0.00018136084495007872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 22.5748	Cost: 34.31s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 11.0201	Cost: 16.51s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 11.1494	Cost: 16.27s
Train Epoch: 80 	Average Loss: 12.1460
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7984

Learning rate: 0.00018090169943749476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 22.7348	Cost: 33.60s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 11.0502	Cost: 16.41s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 11.1587	Cost: 16.22s
Train Epoch: 81 	Average Loss: 12.1976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7634

Learning rate: 0.00018043756352700846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 22.5920	Cost: 32.93s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 11.0691	Cost: 16.82s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 11.2671	Cost: 16.84s
Train Epoch: 82 	Average Loss: 12.2490
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6927

Learning rate: 0.00017996846584870908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 22.6995	Cost: 34.06s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 11.1821	Cost: 16.18s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 11.2729	Cost: 16.96s
Train Epoch: 83 	Average Loss: 12.2944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7264

Learning rate: 0.000179494435338751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 22.6601	Cost: 36.16s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 11.7139	Cost: 16.85s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 11.6295	Cost: 15.25s
Train Epoch: 84 	Average Loss: 12.6719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.4852

Learning rate: 0.00017901550123756904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 22.1892	Cost: 32.68s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 11.2776	Cost: 17.27s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 11.1850	Cost: 11.89s
Train Epoch: 85 	Average Loss: 12.3369
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6128

Learning rate: 0.00017853169308807448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 22.3326	Cost: 36.50s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 11.0163	Cost: 10.22s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 10.9932	Cost: 14.54s
Train Epoch: 86 	Average Loss: 12.1240
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7077

Learning rate: 0.00017804304073383296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 22.5829	Cost: 31.19s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 10.9949	Cost: 12.92s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 10.7991	Cost: 13.28s
Train Epoch: 87 	Average Loss: 12.0479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7750

Learning rate: 0.00017754957431722346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 22.3513	Cost: 29.82s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 10.7856	Cost: 11.51s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 10.7978	Cost: 11.93s
Train Epoch: 88 	Average Loss: 11.9526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8895

Learning rate: 0.00017705132427757892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 22.2564	Cost: 29.88s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 10.9266	Cost: 9.68s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 10.8974	Cost: 21.33s
Train Epoch: 89 	Average Loss: 12.0037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8487

Learning rate: 0.00017654832134930882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 22.0080	Cost: 32.09s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 10.7671	Cost: 13.52s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 10.9775	Cost: 16.67s
Train Epoch: 90 	Average Loss: 12.0179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0690

Learning rate: 0.0001760405965600031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 22.4776	Cost: 33.58s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 10.9079	Cost: 16.74s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 10.7936	Cost: 16.58s
Train Epoch: 91 	Average Loss: 12.1890
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.7109

Learning rate: 0.00017552818122851838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 22.3445	Cost: 32.86s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 10.6660	Cost: 16.68s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 10.7563	Cost: 17.24s
Train Epoch: 92 	Average Loss: 11.9499
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9710

Learning rate: 0.00017501110696304596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 22.3426	Cost: 32.40s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 10.6470	Cost: 16.49s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 10.6410	Cost: 16.62s
Train Epoch: 93 	Average Loss: 11.8407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0280

Learning rate: 0.0001744894056591622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 22.6504	Cost: 33.14s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 10.8173	Cost: 16.53s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 10.8295	Cost: 16.52s
Train Epoch: 94 	Average Loss: 11.9471
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9465

Learning rate: 0.00017396310949786096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 22.1262	Cost: 33.01s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 10.7087	Cost: 16.98s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 10.6250	Cost: 17.32s
Train Epoch: 95 	Average Loss: 11.8346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0875

Learning rate: 0.00017343225094356858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 21.8483	Cost: 33.42s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 10.3830	Cost: 16.13s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 10.7176	Cost: 16.47s
Train Epoch: 96 	Average Loss: 11.7259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0176

Learning rate: 0.00017289686274214118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 22.2911	Cost: 34.70s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 10.5270	Cost: 17.26s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 10.6048	Cost: 17.31s
Train Epoch: 97 	Average Loss: 11.7734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1392

Learning rate: 0.00017235697791884494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 22.3840	Cost: 33.20s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 10.4248	Cost: 16.86s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 10.5517	Cost: 16.23s
Train Epoch: 98 	Average Loss: 11.6684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0670

Learning rate: 0.0001718126297763189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 22.3158	Cost: 36.54s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 10.5833	Cost: 16.63s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 11.3689	Cost: 11.94s
Train Epoch: 99 	Average Loss: 11.9699
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1877

Learning rate: 0.00017126385189252056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 23.6461	Cost: 35.96s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 11.2526	Cost: 11.10s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 10.9782	Cost: 11.36s
Train Epoch: 100 	Average Loss: 12.3895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.6181

Learning rate: 0.00017071067811865479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 22.5224	Cost: 34.40s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 10.6225	Cost: 12.79s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 10.4368	Cost: 12.56s
Train Epoch: 101 	Average Loss: 11.7938
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9059

Learning rate: 0.00017015314257708562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 22.4924	Cost: 30.07s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 10.4540	Cost: 12.73s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 10.3084	Cost: 11.43s
Train Epoch: 102 	Average Loss: 11.4775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2766

Learning rate: 0.00016959127965923145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 22.7743	Cost: 30.42s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 10.3064	Cost: 9.86s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 10.1103	Cost: 21.55s
Train Epoch: 103 	Average Loss: 11.3585
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3056

Learning rate: 0.00016902512402344375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 22.2653	Cost: 33.80s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 9.9142	Cost: 11.26s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 9.8879	Cost: 20.16s
Train Epoch: 104 	Average Loss: 11.1471
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3242

Learning rate: 0.0001684547105928689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 22.8339	Cost: 33.10s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 10.3692	Cost: 17.05s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 10.3786	Cost: 16.59s
Train Epoch: 105 	Average Loss: 11.4268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4393

Learning rate: 0.00016788007455329423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 22.3519	Cost: 32.99s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 10.0712	Cost: 16.48s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 10.2826	Cost: 16.73s
Train Epoch: 106 	Average Loss: 11.4534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5593

Learning rate: 0.00016730125135097737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 22.2318	Cost: 34.10s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 10.1402	Cost: 16.61s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 10.1601	Cost: 17.06s
Train Epoch: 107 	Average Loss: 11.3958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3873

Learning rate: 0.00016671827669046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 22.5433	Cost: 33.44s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 10.0450	Cost: 16.58s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 10.1577	Cost: 16.87s
Train Epoch: 108 	Average Loss: 11.4107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2737

Learning rate: 0.0001661311865323652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 22.3128	Cost: 32.81s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 10.2745	Cost: 16.44s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 10.5670	Cost: 16.80s
Train Epoch: 109 	Average Loss: 11.5736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5691

Learning rate: 0.00016554001709117943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 22.3849	Cost: 35.12s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 10.4760	Cost: 17.05s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 10.6989	Cost: 16.72s
Train Epoch: 110 	Average Loss: 11.7875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3231

Learning rate: 0.00016494480483301838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 22.4750	Cost: 33.70s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 10.5378	Cost: 16.79s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 10.4182	Cost: 11.66s
Train Epoch: 111 	Average Loss: 11.7409
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2496

Learning rate: 0.0001643455864733779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 22.9065	Cost: 35.69s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 10.3688	Cost: 13.42s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 10.1897	Cost: 9.49s
Train Epoch: 112 	Average Loss: 11.6262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.2450

Learning rate: 0.000163742398974869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 24.3219	Cost: 31.73s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 9.9912	Cost: 9.72s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 9.8792	Cost: 16.42s
Train Epoch: 113 	Average Loss: 11.3208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.6013

Learning rate: 0.00016313527954493778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 22.2367	Cost: 30.69s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 9.6333	Cost: 11.38s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 9.7209	Cost: 11.69s
Train Epoch: 114 	Average Loss: 10.9530
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4906

Learning rate: 0.00016252426563357055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 23.7290	Cost: 30.49s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 9.9275	Cost: 9.69s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 9.5513	Cost: 22.36s
Train Epoch: 115 	Average Loss: 11.0698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3761

Learning rate: 0.0001619093949309834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 23.0649	Cost: 32.30s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 9.7385	Cost: 16.36s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 9.5118	Cost: 16.58s
Train Epoch: 116 	Average Loss: 10.9259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.6154

Learning rate: 0.00016129070536529766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 23.5130	Cost: 34.19s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 10.1460	Cost: 16.31s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 9.7736	Cost: 16.57s
Train Epoch: 117 	Average Loss: 11.2260
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3297

Learning rate: 0.00016066823510019996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 22.8703	Cost: 35.99s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 10.0138	Cost: 14.47s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 9.7936	Cost: 16.44s
Train Epoch: 118 	Average Loss: 11.1041
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5450

Learning rate: 0.0001600420225325884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 23.5467	Cost: 32.26s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 9.9824	Cost: 16.70s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 9.7424	Cost: 17.18s
Train Epoch: 119 	Average Loss: 11.1867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4107

Learning rate: 0.00015941210629020385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 22.3047	Cost: 35.35s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 9.7275	Cost: 16.98s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 9.4024	Cost: 17.48s
Train Epoch: 120 	Average Loss: 10.8597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.6033

Learning rate: 0.00015877852522924735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 22.3789	Cost: 34.00s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 9.1794	Cost: 17.19s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 10.4489	Cost: 15.17s
Train Epoch: 121 	Average Loss: 10.7849
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.6834

Learning rate: 0.00015814131843198305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 22.8896	Cost: 35.87s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 10.8862	Cost: 14.59s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 10.0734	Cost: 12.04s
Train Epoch: 122 	Average Loss: 11.9004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.0869

Learning rate: 0.00015750052520432787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 22.2309	Cost: 36.73s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 9.7587	Cost: 12.77s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 9.4774	Cost: 9.73s
Train Epoch: 123 	Average Loss: 11.0196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.6724

Learning rate: 0.0001568561850734264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 22.6910	Cost: 34.38s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 9.5124	Cost: 11.06s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 9.3396	Cost: 12.45s
Train Epoch: 124 	Average Loss: 10.7904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4203

Learning rate: 0.00015620833778521307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 22.5721	Cost: 30.97s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 9.1864	Cost: 12.74s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 9.1294	Cost: 11.45s
Train Epoch: 125 	Average Loss: 10.4925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.7860

Learning rate: 0.00015555702330196023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 22.3967	Cost: 28.86s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 8.9238	Cost: 9.82s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 8.8201	Cost: 21.04s
Train Epoch: 126 	Average Loss: 10.2748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9950

Learning rate: 0.00015490228179981317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 22.3696	Cost: 32.31s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 8.7343	Cost: 12.28s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 8.8622	Cost: 16.65s
Train Epoch: 127 	Average Loss: 10.1513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9567

Learning rate: 0.00015424415366631188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 22.6641	Cost: 33.37s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 8.8467	Cost: 16.52s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 9.1877	Cost: 16.40s
Train Epoch: 128 	Average Loss: 10.3625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.7073

Learning rate: 0.00015358267949789966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 22.8292	Cost: 34.24s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 9.2025	Cost: 16.35s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 9.1927	Cost: 17.00s
Train Epoch: 129 	Average Loss: 10.5669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.7563

Learning rate: 0.00015291790009741904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 22.0688	Cost: 34.09s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 8.8623	Cost: 16.68s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 8.8409	Cost: 16.64s
Train Epoch: 130 	Average Loss: 10.2848
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.8320

Learning rate: 0.00015224985647159487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 21.9577	Cost: 34.44s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 8.8141	Cost: 17.27s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 8.8004	Cost: 17.38s
Train Epoch: 131 	Average Loss: 10.1031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.8941

Learning rate: 0.00015157858982850473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 22.1854	Cost: 33.57s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 8.7617	Cost: 16.71s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 9.2643	Cost: 15.27s
Train Epoch: 132 	Average Loss: 10.1707
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.0411

Learning rate: 0.0001509041415750371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 22.7673	Cost: 32.87s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 10.1632	Cost: 17.08s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 10.1296	Cost: 13.89s
Train Epoch: 133 	Average Loss: 11.3132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5353

Learning rate: 0.00015022655331433721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 22.2241	Cost: 36.38s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 9.7036	Cost: 14.49s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 9.8512	Cost: 9.55s
Train Epoch: 134 	Average Loss: 10.9942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4586

Learning rate: 0.00014954586684324072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 21.8002	Cost: 33.07s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 9.6634	Cost: 10.26s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 9.5959	Cost: 16.12s
Train Epoch: 135 	Average Loss: 10.9231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.1942

Learning rate: 0.00014886212414969547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 21.7995	Cost: 29.90s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 8.9326	Cost: 12.77s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 9.1519	Cost: 10.52s
Train Epoch: 136 	Average Loss: 10.3004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.6342

Learning rate: 0.0001481753674101715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 21.8324	Cost: 30.72s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 9.0889	Cost: 9.76s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 9.4329	Cost: 22.11s
Train Epoch: 137 	Average Loss: 10.4536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.1877

Learning rate: 0.00014748563898705943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 22.2695	Cost: 33.30s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 9.4382	Cost: 14.39s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 9.1582	Cost: 16.31s
Train Epoch: 138 	Average Loss: 10.5836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.8206

Learning rate: 0.00014679298142605734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 23.4517	Cost: 31.80s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 10.1089	Cost: 16.46s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 10.1430	Cost: 15.99s
Train Epoch: 139 	Average Loss: 11.1802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3115

Learning rate: 0.00014609743745354624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 22.0793	Cost: 32.63s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 9.5983	Cost: 16.52s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 9.1663	Cost: 16.15s
Train Epoch: 140 	Average Loss: 10.6196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.7901

Learning rate: 0.00014539904997395466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 23.6495	Cost: 34.31s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 9.9061	Cost: 16.53s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 9.7052	Cost: 16.40s
Train Epoch: 141 	Average Loss: 10.8646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.6051

Learning rate: 0.0001446978620671121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 23.3863	Cost: 32.88s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 10.2480	Cost: 16.17s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 10.0783	Cost: 16.60s
Train Epoch: 142 	Average Loss: 11.3997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3786

Learning rate: 0.0001439939169855915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 21.8499	Cost: 35.03s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 10.8264	Cost: 16.59s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 10.4684	Cost: 16.82s
Train Epoch: 143 	Average Loss: 11.8285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.9379

Learning rate: 0.0001432872581520414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 22.7432	Cost: 32.98s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 10.0712	Cost: 16.78s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 9.5832	Cost: 16.89s
Train Epoch: 144 	Average Loss: 11.2099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5923

Learning rate: 0.00014257792915650728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 21.7444	Cost: 32.46s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 9.2227	Cost: 16.41s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 8.7804	Cost: 17.33s
Train Epoch: 145 	Average Loss: 10.3618
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.8111

Learning rate: 0.0001418659737537428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 21.8904	Cost: 35.01s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 8.7479	Cost: 16.72s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 8.6948	Cost: 15.93s
Train Epoch: 146 	Average Loss: 10.0169
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.1715

Learning rate: 0.00014115143586051088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 22.3756	Cost: 32.24s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 8.9148	Cost: 17.02s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 8.7381	Cost: 15.38s
Train Epoch: 147 	Average Loss: 10.2330
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.8667

Learning rate: 0.0001404343595528745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 25.2008	Cost: 38.23s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 8.7877	Cost: 15.63s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 8.5467	Cost: 9.50s
Train Epoch: 148 	Average Loss: 10.2373
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.0336

Learning rate: 0.00013971478906347806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 24.2009	Cost: 31.97s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 9.1037	Cost: 9.61s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 9.3679	Cost: 17.00s
Train Epoch: 149 	Average Loss: 10.6451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4867

Learning rate: 0.00013899276877881884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 21.7375	Cost: 31.23s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 9.1985	Cost: 12.75s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 8.9426	Cost: 12.75s
Train Epoch: 150 	Average Loss: 10.6601
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.6636

Learning rate: 0.000138268343236509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 21.9408	Cost: 29.71s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 8.8872	Cost: 10.47s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 9.1508	Cost: 15.01s
Train Epoch: 151 	Average Loss: 10.4689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4379

Learning rate: 0.00013754155712252834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 22.2037	Cost: 28.80s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 8.7827	Cost: 9.71s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 9.4740	Cost: 21.95s
Train Epoch: 152 	Average Loss: 10.4651
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.8687

Learning rate: 0.00013681245526846785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 21.6746	Cost: 30.71s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 8.9400	Cost: 9.79s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 8.7735	Cost: 17.40s
Train Epoch: 153 	Average Loss: 10.2814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.7911

Learning rate: 0.00013608108264876422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 21.7724	Cost: 33.35s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 8.3264	Cost: 14.57s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 9.4123	Cost: 16.45s
Train Epoch: 154 	Average Loss: 9.9653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4802

Learning rate: 0.00013534748437792575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 22.5141	Cost: 32.07s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 9.3281	Cost: 16.98s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 9.5965	Cost: 16.73s
Train Epoch: 155 	Average Loss: 10.7887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3921

Learning rate: 0.00013461170570774932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 21.5980	Cost: 33.38s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 8.8766	Cost: 16.23s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 9.0241	Cost: 16.58s
Train Epoch: 156 	Average Loss: 10.1892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9432

Learning rate: 0.0001338737920245292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 21.6664	Cost: 33.56s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 8.6812	Cost: 16.79s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 8.7827	Cost: 17.31s
Train Epoch: 157 	Average Loss: 10.0322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.8148

Learning rate: 0.00013313378884625713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 22.0222	Cost: 32.83s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 8.4512	Cost: 16.79s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 8.1326	Cost: 16.65s
Train Epoch: 158 	Average Loss: 9.6466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9754

Learning rate: 0.00013239174181981498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 21.9822	Cost: 34.23s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 7.9553	Cost: 16.64s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 7.7272	Cost: 16.62s
Train Epoch: 159 	Average Loss: 9.2069
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9991

Learning rate: 0.00013164769671815865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 21.6621	Cost: 34.08s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 7.5090	Cost: 16.88s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 7.3831	Cost: 16.64s
Train Epoch: 160 	Average Loss: 8.8566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.9781

Learning rate: 0.0001309016994374948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 21.7050	Cost: 33.27s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 7.3276	Cost: 16.95s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 7.2248	Cost: 14.83s
Train Epoch: 161 	Average Loss: 8.6815
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.1752

Learning rate: 0.00013015379599444962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 21.7386	Cost: 35.55s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 7.2132	Cost: 15.97s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 7.1273	Cost: 10.64s
Train Epoch: 162 	Average Loss: 8.5797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.2066

Learning rate: 0.00012940403252323043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 21.6985	Cost: 36.48s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 7.1464	Cost: 12.92s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 7.1283	Cost: 10.00s
Train Epoch: 163 	Average Loss: 8.5439
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4077

Learning rate: 0.00012865245527277986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 21.8314	Cost: 32.66s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 7.2882	Cost: 11.76s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 7.3195	Cost: 12.71s
Train Epoch: 164 	Average Loss: 8.6965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.2545

Learning rate: 0.00012789911060392294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 21.7836	Cost: 31.67s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 7.2785	Cost: 12.75s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 7.1852	Cost: 9.80s
Train Epoch: 165 	Average Loss: 8.6090
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.3033

Learning rate: 0.00012714404498650745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 21.5910	Cost: 28.85s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 7.2038	Cost: 9.79s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 7.3100	Cost: 22.58s
Train Epoch: 166 	Average Loss: 8.5723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.3147

Learning rate: 0.00012638730499653727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 21.6043	Cost: 31.94s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 7.0870	Cost: 14.06s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 7.0898	Cost: 16.42s
Train Epoch: 167 	Average Loss: 8.4958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.1648

Learning rate: 0.00012562893731329965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 21.5907	Cost: 31.26s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 6.9394	Cost: 15.59s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 8.0622	Cost: 16.66s
Train Epoch: 168 	Average Loss: 8.6550
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.7721

Learning rate: 0.00012486898871648546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 21.7331	Cost: 35.52s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 9.2136	Cost: 16.33s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 8.7868	Cost: 16.81s
Train Epoch: 169 	Average Loss: 10.1423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.7899

Learning rate: 0.00012410750608330388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 25.3367	Cost: 33.84s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 11.1009	Cost: 16.46s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 10.5114	Cost: 16.59s
Train Epoch: 170 	Average Loss: 11.9720
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.5233

Learning rate: 0.00012334453638559054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 22.3720	Cost: 31.75s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 10.6799	Cost: 16.72s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 9.7199	Cost: 16.92s
Train Epoch: 171 	Average Loss: 11.4052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.6070

Learning rate: 0.00012258012668691037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 22.4528	Cost: 33.44s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 9.3448	Cost: 15.58s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 9.7990	Cost: 17.47s
Train Epoch: 172 	Average Loss: 10.8717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 22.8838

Learning rate: 0.00012181432413965427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 21.5668	Cost: 33.19s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 9.8726	Cost: 16.72s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 9.1370	Cost: 16.63s
Train Epoch: 173 	Average Loss: 11.2388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.8008

Learning rate: 0.0001210471759821306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 25.4770	Cost: 34.74s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 8.5682	Cost: 16.84s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 8.0546	Cost: 15.03s
Train Epoch: 174 	Average Loss: 10.1317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.7885

Learning rate: 0.00012027872953565127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 21.9993	Cost: 33.33s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 7.7620	Cost: 16.63s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 7.4158	Cost: 10.01s
Train Epoch: 175 	Average Loss: 9.1401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4632

Learning rate: 0.00011950903220161285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 21.7611	Cost: 35.15s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 7.1796	Cost: 11.27s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 6.9541	Cost: 12.66s
Train Epoch: 176 	Average Loss: 8.5927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.2068

Learning rate: 0.00011873813145857249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 21.5036	Cost: 33.15s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 6.7715	Cost: 12.66s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 6.7929	Cost: 12.72s
Train Epoch: 177 	Average Loss: 8.2369
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.1955

Learning rate: 0.00011796607485931927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 21.7019	Cost: 29.75s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 6.7220	Cost: 12.54s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 6.6497	Cost: 9.61s
Train Epoch: 178 	Average Loss: 8.1321
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4703

Learning rate: 0.00011719291002794096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 24.7634	Cost: 29.60s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 9.4109	Cost: 9.83s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 9.7870	Cost: 21.51s
Train Epoch: 179 	Average Loss: 10.7953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.1474

Learning rate: 0.0001164186846568863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 25.8936	Cost: 30.95s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 10.3841	Cost: 10.21s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 9.2507	Cost: 19.20s
Train Epoch: 180 	Average Loss: 11.3869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.1042

Learning rate: 0.0001156434465040231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 22.4196	Cost: 32.34s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 8.4556	Cost: 15.75s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 7.8086	Cost: 16.57s
Train Epoch: 181 	Average Loss: 9.7670
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.1879

Learning rate: 0.00011486724338969234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 25.9441	Cost: 35.28s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 7.5406	Cost: 16.37s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 7.1173	Cost: 16.45s
Train Epoch: 182 	Average Loss: 9.0224
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.0681

Learning rate: 0.0001140901231937583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 22.1548	Cost: 32.48s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 6.9364	Cost: 16.44s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 6.8224	Cost: 16.55s
Train Epoch: 183 	Average Loss: 8.4308
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.7211

Learning rate: 0.00011331213385265528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 21.9518	Cost: 32.95s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 6.6838	Cost: 15.84s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 6.5235	Cost: 16.80s
Train Epoch: 184 	Average Loss: 8.1822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.8169

Learning rate: 0.00011253332335643047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 21.7779	Cost: 33.99s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 6.5043	Cost: 16.56s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 7.8617	Cost: 16.54s
Train Epoch: 185 	Average Loss: 8.3934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5927

Learning rate: 0.0001117537397457838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 22.2683	Cost: 33.65s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 8.7875	Cost: 16.62s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 8.6884	Cost: 16.76s
Train Epoch: 186 	Average Loss: 10.2019
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.9989

Learning rate: 0.00011097343110910456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 22.2896	Cost: 36.47s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 8.4646	Cost: 15.66s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 8.0367	Cost: 12.16s
Train Epoch: 187 	Average Loss: 9.8119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.5598

Learning rate: 0.00011019244557950502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 21.8060	Cost: 32.95s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 7.5990	Cost: 12.45s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 7.2654	Cost: 9.42s
Train Epoch: 188 	Average Loss: 8.9628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.0648

Learning rate: 0.00010941083133185145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 21.8850	Cost: 31.43s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 7.1701	Cost: 9.73s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 7.5915	Cost: 15.15s
Train Epoch: 189 	Average Loss: 8.6685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.2764

Learning rate: 0.00010862863657979236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 21.7211	Cost: 30.78s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 7.6144	Cost: 10.62s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 7.5400	Cost: 15.35s
Train Epoch: 190 	Average Loss: 9.0322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.6849

Learning rate: 0.00010784590957278452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 21.5593	Cost: 30.10s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 7.1243	Cost: 9.71s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 8.2055	Cost: 20.88s
Train Epoch: 191 	Average Loss: 8.6353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.8624

Learning rate: 0.00010706269859311669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 21.6046	Cost: 31.65s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 7.4476	Cost: 13.39s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 7.1648	Cost: 16.76s
Train Epoch: 192 	Average Loss: 8.9488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.8695

Learning rate: 0.00010627905195293137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 21.7393	Cost: 31.97s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 6.7690	Cost: 16.96s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 6.6482	Cost: 16.44s
Train Epoch: 193 	Average Loss: 8.3704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.0420

Learning rate: 0.00010549501799124461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 21.7014	Cost: 32.94s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 6.3576	Cost: 16.76s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 6.3061	Cost: 16.60s
Train Epoch: 194 	Average Loss: 7.8099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.7398

Learning rate: 0.00010471064507096429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 22.0291	Cost: 32.95s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 6.0814	Cost: 16.61s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 6.1333	Cost: 16.62s
Train Epoch: 195 	Average Loss: 7.6076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4949

Learning rate: 0.00010392598157590689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 21.9248	Cost: 32.89s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 5.9900	Cost: 16.47s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 9.4074	Cost: 16.63s
Train Epoch: 196 	Average Loss: 8.0769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.3995

Learning rate: 0.00010314107590781285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 21.8320	Cost: 32.57s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 9.1740	Cost: 16.76s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 8.9767	Cost: 16.92s
Train Epoch: 197 	Average Loss: 10.6270
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.1906

Learning rate: 0.00010235597648336105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 22.0553	Cost: 33.14s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 9.2623	Cost: 16.60s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 8.2049	Cost: 16.63s
Train Epoch: 198 	Average Loss: 10.2511
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.8853

Learning rate: 0.0001015707317311821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 26.7600	Cost: 32.75s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 7.7776	Cost: 17.31s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 7.2299	Cost: 16.99s
Train Epoch: 199 	Average Loss: 9.2429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.7154

Learning rate: 0.00010078539008887115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 21.6644	Cost: 36.67s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 6.7116	Cost: 17.04s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 6.4759	Cost: 13.72s
Train Epoch: 200 	Average Loss: 8.1479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.8061

Learning rate: 0.00010000000000000002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 23.9188	Cost: 31.93s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 8.8805	Cost: 16.06s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 8.7322	Cost: 11.10s
Train Epoch: 201 	Average Loss: 9.9398
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.8906

Learning rate: 9.92146099111289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 22.1309	Cost: 32.84s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 7.8049	Cost: 10.90s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 8.0541	Cost: 13.09s
Train Epoch: 202 	Average Loss: 9.3293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.8428

Learning rate: 9.842926826881797e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 21.9684	Cost: 32.19s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 7.4650	Cost: 12.74s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 7.1669	Cost: 12.93s
Train Epoch: 203 	Average Loss: 8.8129
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.8487

Learning rate: 9.7644023516639e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 23.6703	Cost: 30.39s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 9.3194	Cost: 9.91s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 7.6611	Cost: 15.19s
Train Epoch: 204 	Average Loss: 9.3049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.2649

Learning rate: 9.68589240921872e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 21.6871	Cost: 31.31s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 7.3873	Cost: 9.71s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 7.3199	Cost: 20.61s
Train Epoch: 205 	Average Loss: 8.8427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.4713

Learning rate: 9.607401842409317e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 21.9577	Cost: 31.98s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 7.5728	Cost: 15.43s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 7.1163	Cost: 16.24s
Train Epoch: 206 	Average Loss: 8.8957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 24.3495

Learning rate: 9.528935492903578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 21.6802	Cost: 32.97s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 6.7070	Cost: 16.17s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 6.5749	Cost: 16.44s
Train Epoch: 207 	Average Loss: 8.4195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.7115

Learning rate: 9.450498200875547e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 22.0046	Cost: 34.64s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 6.4433	Cost: 16.20s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 6.2052	Cost: 16.52s
Train Epoch: 208 	Average Loss: 8.1151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.4038

Learning rate: 9.372094804706868e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 21.7139	Cost: 33.60s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 6.0864	Cost: 14.96s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 9.7389	Cost: 16.93s
Train Epoch: 209 	Average Loss: 8.2251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4906

Learning rate: 9.293730140688336e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 22.1798	Cost: 31.92s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 9.6813	Cost: 16.43s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 9.3880	Cost: 17.01s
Train Epoch: 210 	Average Loss: 10.9549
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 23.4467

Learning rate: 9.215409042721555e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 23.2146	Cost: 33.44s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 8.1162	Cost: 16.33s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 7.6061	Cost: 17.34s
Train Epoch: 211 	Average Loss: 9.5883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.4607

Learning rate: 9.13713634202077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 26.8003	Cost: 34.19s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 6.9678	Cost: 17.39s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 6.8484	Cost: 16.83s
Train Epoch: 212 	Average Loss: 8.7861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1250

Learning rate: 9.058916866814858e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 22.0526	Cost: 33.28s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 6.7529	Cost: 16.86s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 6.5596	Cost: 16.82s
Train Epoch: 213 	Average Loss: 8.4724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.9449

Learning rate: 8.9807554420495e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 26.5592	Cost: 33.56s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 6.3101	Cost: 16.74s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 6.0946	Cost: 14.15s
Train Epoch: 214 	Average Loss: 8.1992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.5960

Learning rate: 8.902656889089548e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 26.6712	Cost: 37.40s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 6.0165	Cost: 11.99s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 5.9010	Cost: 11.47s
Train Epoch: 215 	Average Loss: 7.9019
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.6134

Learning rate: 8.824626025421624e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 26.3915	Cost: 30.50s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 5.7941	Cost: 12.29s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 5.7093	Cost: 12.86s
Train Epoch: 216 	Average Loss: 7.7090
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.6777

Learning rate: 8.746667664356959e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 26.8272	Cost: 31.30s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 5.7122	Cost: 12.78s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 5.6029	Cost: 11.27s
Train Epoch: 217 	Average Loss: 7.6223
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.7420

Learning rate: 8.668786614734478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 26.7061	Cost: 28.96s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 5.7260	Cost: 9.71s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 5.5703	Cost: 17.73s
Train Epoch: 218 	Average Loss: 7.5709
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.6639

Learning rate: 8.590987680624175e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 26.9066	Cost: 31.64s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 5.4795	Cost: 9.70s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 5.6157	Cost: 18.85s
Train Epoch: 219 	Average Loss: 7.4507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3022

Learning rate: 8.51327566103077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 26.4267	Cost: 31.79s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 5.7686	Cost: 15.95s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 5.7118	Cost: 16.55s
Train Epoch: 220 	Average Loss: 7.6869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.7042

Learning rate: 8.435655349597692e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 26.7147	Cost: 32.16s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 6.0111	Cost: 16.51s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 5.6229	Cost: 16.42s
Train Epoch: 221 	Average Loss: 7.6927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.6643

Learning rate: 8.35813153431137e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 23.7933	Cost: 34.40s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 6.0081	Cost: 16.80s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 6.2585	Cost: 16.56s
Train Epoch: 222 	Average Loss: 7.5872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1947

Learning rate: 8.280708997205904e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 26.0127	Cost: 34.68s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 6.3874	Cost: 16.97s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 5.9687	Cost: 16.68s
Train Epoch: 223 	Average Loss: 8.1567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.5832

Learning rate: 8.203392514068074e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 25.6309	Cost: 33.56s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 6.3362	Cost: 16.51s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 6.0460	Cost: 16.93s
Train Epoch: 224 	Average Loss: 8.0107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3659

Learning rate: 8.126186854142755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 27.0997	Cost: 33.16s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 5.7633	Cost: 17.00s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 5.5550	Cost: 16.36s
Train Epoch: 225 	Average Loss: 7.7013
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.8205

Learning rate: 8.049096779838719e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 24.2104	Cost: 36.75s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 5.9454	Cost: 15.72s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 5.7511	Cost: 10.87s
Train Epoch: 226 	Average Loss: 7.5346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.6410

Learning rate: 7.972127046434877e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 24.5787	Cost: 32.48s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 6.2188	Cost: 14.55s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 5.9146	Cost: 9.54s
Train Epoch: 227 	Average Loss: 7.9467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.4535

Learning rate: 7.895282401786947e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 26.6487	Cost: 31.52s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 5.8798	Cost: 10.27s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 5.7537	Cost: 16.15s
Train Epoch: 228 	Average Loss: 7.7620
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2156

Learning rate: 7.818567586034578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 25.0573	Cost: 30.81s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 6.0139	Cost: 12.76s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 6.2246	Cost: 12.53s
Train Epoch: 229 	Average Loss: 7.7452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.9094

Learning rate: 7.741987331308968e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 23.6066	Cost: 29.52s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 6.2825	Cost: 10.33s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 5.9097	Cost: 15.05s
Train Epoch: 230 	Average Loss: 7.9732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3651

Learning rate: 7.665546361440945e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 23.5783	Cost: 28.62s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 5.6994	Cost: 9.72s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 5.4769	Cost: 20.29s
Train Epoch: 231 	Average Loss: 7.3095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.8197

Learning rate: 7.589249391669613e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 27.0858	Cost: 32.63s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 5.3382	Cost: 13.43s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 5.4458	Cost: 16.30s
Train Epoch: 232 	Average Loss: 7.2535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3989

Learning rate: 7.513101128351452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 22.7962	Cost: 32.10s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 5.4683	Cost: 15.02s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 5.5653	Cost: 16.45s
Train Epoch: 233 	Average Loss: 7.1882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2466

Learning rate: 7.437106268670034e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 24.1183	Cost: 33.55s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 6.2563	Cost: 16.80s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 6.1672	Cost: 16.55s
Train Epoch: 234 	Average Loss: 7.7779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.8749

Learning rate: 7.361269500346273e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 23.5173	Cost: 33.41s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 6.4200	Cost: 16.85s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 5.8227	Cost: 17.29s
Train Epoch: 235 	Average Loss: 7.6055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.0344

Learning rate: 7.28559550134926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 22.4860	Cost: 33.77s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 5.5406	Cost: 16.37s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 5.2944	Cost: 16.44s
Train Epoch: 236 	Average Loss: 7.0803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.6869

Learning rate: 7.210088939607711e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 24.2270	Cost: 33.36s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 6.0222	Cost: 15.22s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 5.9705	Cost: 17.36s
Train Epoch: 237 	Average Loss: 7.7405
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.5814

Learning rate: 7.13475447272202e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 27.3604	Cost: 31.02s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 5.7402	Cost: 16.78s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 5.8281	Cost: 17.34s
Train Epoch: 238 	Average Loss: 7.7243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.0441

Learning rate: 7.059596747676965e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 23.9958	Cost: 33.86s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 6.1780	Cost: 16.88s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 6.1367	Cost: 15.20s
Train Epoch: 239 	Average Loss: 7.9130
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.0894

Learning rate: 6.984620400555048e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 24.4865	Cost: 36.69s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 6.6177	Cost: 15.71s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 6.4099	Cost: 9.54s
Train Epoch: 240 	Average Loss: 8.1113
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1025

Learning rate: 6.909830056250531e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 23.8187	Cost: 33.41s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 7.0451	Cost: 9.59s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 6.0547	Cost: 16.74s
Train Epoch: 241 	Average Loss: 8.0580
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.1212

Learning rate: 6.835230328184141e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 27.4454	Cost: 31.82s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 5.9922	Cost: 13.22s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 5.5552	Cost: 12.59s
Train Epoch: 242 	Average Loss: 7.6939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1515

Learning rate: 6.760825818018508e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 24.2714	Cost: 28.46s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 6.9008	Cost: 9.82s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 5.7103	Cost: 17.39s
Train Epoch: 243 	Average Loss: 7.6190
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.0497

Learning rate: 6.686621115374292e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 22.6282	Cost: 32.02s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 5.5993	Cost: 9.71s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 5.2938	Cost: 18.82s
Train Epoch: 244 	Average Loss: 7.1859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2761

Learning rate: 6.61262079754709e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 22.8518	Cost: 33.07s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 5.3941	Cost: 16.00s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 5.7022	Cost: 16.46s
Train Epoch: 245 	Average Loss: 7.1191
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1921

Learning rate: 6.538829429225073e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 25.1441	Cost: 30.81s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 6.2009	Cost: 16.25s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 5.7623	Cost: 16.41s
Train Epoch: 246 	Average Loss: 8.0129
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2261

Learning rate: 6.465251562207432e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 24.2992	Cost: 31.81s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 5.5919	Cost: 16.98s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 6.0543	Cost: 16.46s
Train Epoch: 247 	Average Loss: 7.5935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2067

Learning rate: 6.391891735123586e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 22.4834	Cost: 33.73s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 5.9842	Cost: 16.42s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 5.8967	Cost: 16.34s
Train Epoch: 248 	Average Loss: 7.8209
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.1433

Learning rate: 6.318754473153225e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 26.8648	Cost: 33.41s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 5.4423	Cost: 16.44s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 5.4278	Cost: 16.62s
Train Epoch: 249 	Average Loss: 7.3532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3423

Learning rate: 6.245844287747173e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 22.8294	Cost: 34.23s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 5.5851	Cost: 17.11s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 5.5895	Cost: 17.28s
Train Epoch: 250 	Average Loss: 7.2324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.7378

Learning rate: 6.173165676349108e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 22.3561	Cost: 33.88s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 5.5390	Cost: 16.58s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 5.3171	Cost: 16.64s
Train Epoch: 251 	Average Loss: 6.9761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.6102

Learning rate: 6.10072312211812e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 23.0415	Cost: 35.50s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 5.1175	Cost: 16.90s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 4.8927	Cost: 15.94s
Train Epoch: 252 	Average Loss: 6.6413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.4195

Learning rate: 6.0285210936521955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 24.8109	Cost: 32.16s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 6.6867	Cost: 16.95s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 5.5190	Cost: 13.98s
Train Epoch: 253 	Average Loss: 7.4531
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1682

Learning rate: 5.956564044712553e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 23.5857	Cost: 32.96s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 5.5351	Cost: 15.84s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 5.7803	Cost: 11.00s
Train Epoch: 254 	Average Loss: 6.9630
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.4518

Learning rate: 5.8848564139489155e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 22.7203	Cost: 31.79s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 5.1327	Cost: 14.80s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 4.8400	Cost: 9.70s
Train Epoch: 255 	Average Loss: 6.6100
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.5521

Learning rate: 5.813402624625721e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 22.8239	Cost: 32.05s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 4.7776	Cost: 9.71s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 4.7341	Cost: 14.95s
Train Epoch: 256 	Average Loss: 6.5536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.6667

Learning rate: 5.742207084349277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 23.9294	Cost: 29.71s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 5.4215	Cost: 12.77s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 5.3383	Cost: 12.35s
Train Epoch: 257 	Average Loss: 7.0505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2445

Learning rate: 5.6712741847958634e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 22.4418	Cost: 29.57s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 4.9861	Cost: 9.92s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 4.6463	Cost: 18.84s
Train Epoch: 258 	Average Loss: 6.5152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.5431

Learning rate: 5.600608301440851e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 27.6328	Cost: 31.51s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 5.2774	Cost: 9.68s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 4.7106	Cost: 19.52s
Train Epoch: 259 	Average Loss: 6.6655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3342

Learning rate: 5.5302137932887924e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 22.7702	Cost: 31.82s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 4.6837	Cost: 14.74s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 4.3574	Cost: 16.51s
Train Epoch: 260 	Average Loss: 6.3046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.9171

Learning rate: 5.460095002604535e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 22.4728	Cost: 35.01s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 4.8999	Cost: 16.34s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 5.2552	Cost: 16.52s
Train Epoch: 261 	Average Loss: 6.5303
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.7809

Learning rate: 5.390256254645381e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 27.6209	Cost: 31.53s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 6.0265	Cost: 16.58s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 5.7443	Cost: 16.68s
Train Epoch: 262 	Average Loss: 7.7678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.4433

Learning rate: 5.3207018573942705e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 27.8583	Cost: 33.96s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 6.0001	Cost: 17.06s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 5.6359	Cost: 17.19s
Train Epoch: 263 	Average Loss: 7.8462
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.7761

Learning rate: 5.251436101294054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 24.5198	Cost: 34.99s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 5.5756	Cost: 16.58s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 5.2553	Cost: 16.62s
Train Epoch: 264 	Average Loss: 7.2282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.8197

Learning rate: 5.1824632589828485e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 22.6154	Cost: 32.19s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 4.9157	Cost: 16.72s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 4.7383	Cost: 16.61s
Train Epoch: 265 	Average Loss: 6.6093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2187

Learning rate: 5.1137875850304516e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 28.2607	Cost: 33.14s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 4.6981	Cost: 16.89s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 4.5740	Cost: 15.99s
Train Epoch: 266 	Average Loss: 6.8704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.7747

Learning rate: 5.045413315675926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 22.9286	Cost: 35.18s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 4.6286	Cost: 15.69s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 6.0103	Cost: 10.88s
Train Epoch: 267 	Average Loss: 6.5773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.0518

Learning rate: 4.977344668566277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 22.7214	Cost: 34.45s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 5.0147	Cost: 12.79s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 4.9649	Cost: 9.67s
Train Epoch: 268 	Average Loss: 7.0276
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.6297

Learning rate: 4.909585842496289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 27.5702	Cost: 33.51s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 5.3715	Cost: 11.43s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 5.2264	Cost: 13.30s
Train Epoch: 269 	Average Loss: 7.2711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.5595

Learning rate: 4.842141017149528e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 23.2145	Cost: 30.94s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 4.9565	Cost: 12.76s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 4.5693	Cost: 9.66s
Train Epoch: 270 	Average Loss: 6.6171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3746

Learning rate: 4.775014352840514e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 23.4445	Cost: 28.69s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 4.6418	Cost: 9.76s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 5.0674	Cost: 19.43s
Train Epoch: 271 	Average Loss: 6.5922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.7958

Learning rate: 4.708209990258097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 22.2858	Cost: 30.88s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 4.7457	Cost: 9.68s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 4.4600	Cost: 18.83s
Train Epoch: 272 	Average Loss: 6.6690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.2476

Learning rate: 4.641732050210033e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 23.2572	Cost: 32.01s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 4.3417	Cost: 14.72s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 4.1114	Cost: 16.42s
Train Epoch: 273 	Average Loss: 6.0715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.7945

Learning rate: 4.575584633368813e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 22.5105	Cost: 32.24s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 4.1036	Cost: 16.78s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 3.9497	Cost: 16.90s
Train Epoch: 274 	Average Loss: 5.7931
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.6365

Learning rate: 4.509771820018683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 22.6860	Cost: 33.10s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 3.9856	Cost: 16.50s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 3.7114	Cost: 16.85s
Train Epoch: 275 	Average Loss: 5.6085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1976

Learning rate: 4.4442976698039786e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 22.5170	Cost: 33.09s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 3.7633	Cost: 16.48s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 3.6174	Cost: 16.65s
Train Epoch: 276 	Average Loss: 5.4916
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.9554

Learning rate: 4.379166221478695e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 22.4906	Cost: 33.59s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 3.7317	Cost: 16.90s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 3.5788	Cost: 16.88s
Train Epoch: 277 	Average Loss: 5.4177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.9834

Learning rate: 4.3143814926573614e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 22.5813	Cost: 32.04s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 3.6210	Cost: 16.86s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 3.4528	Cost: 16.53s
Train Epoch: 278 	Average Loss: 5.3017
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1245

Learning rate: 4.249947479567216e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 26.0708	Cost: 33.94s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 4.0116	Cost: 16.87s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 3.9771	Cost: 17.08s
Train Epoch: 279 	Average Loss: 5.7898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.0864

Learning rate: 4.1858681568016955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 22.2991	Cost: 32.90s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 3.8307	Cost: 17.03s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 3.6120	Cost: 15.67s
Train Epoch: 280 	Average Loss: 5.5438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.5732

Learning rate: 4.122147477075271e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 22.6466	Cost: 35.38s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 3.5768	Cost: 15.06s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 3.6830	Cost: 11.50s
Train Epoch: 281 	Average Loss: 5.4921
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.5926

Learning rate: 4.058789370979617e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 22.3201	Cost: 33.94s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 4.0958	Cost: 9.68s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 3.8427	Cost: 14.56s
Train Epoch: 282 	Average Loss: 5.7532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.3296

Learning rate: 3.995797746741162e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 22.8088	Cost: 32.27s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 4.2232	Cost: 12.81s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 3.9055	Cost: 12.69s
Train Epoch: 283 	Average Loss: 5.7865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.4216

Learning rate: 3.933176489980003e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 22.3045	Cost: 30.47s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 3.7701	Cost: 12.65s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 3.4916	Cost: 11.99s
Train Epoch: 284 	Average Loss: 5.4636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.9263

Learning rate: 3.8709294634702356e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 22.5165	Cost: 28.49s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 3.5179	Cost: 9.82s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 3.4081	Cost: 19.71s
Train Epoch: 285 	Average Loss: 5.2250
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1641

Learning rate: 3.809060506901661e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 29.2521	Cost: 30.26s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 3.3995	Cost: 9.71s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 4.1949	Cost: 18.74s
Train Epoch: 286 	Average Loss: 5.9471
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.3557

Learning rate: 3.747573436642949e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 22.5313	Cost: 31.29s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 4.4896	Cost: 15.12s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 4.2049	Cost: 16.64s
Train Epoch: 287 	Average Loss: 6.4156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.3436

Learning rate: 3.686472045506224e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 24.1490	Cost: 32.58s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 4.1138	Cost: 16.35s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 4.5022	Cost: 16.60s
Train Epoch: 288 	Average Loss: 5.9586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.2015

Learning rate: 3.625760102513104e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 24.5044	Cost: 34.32s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 4.2999	Cost: 16.94s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 4.2004	Cost: 16.93s
Train Epoch: 289 	Average Loss: 6.0168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2476

Learning rate: 3.5654413526622126e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 24.5595	Cost: 34.51s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 4.3400	Cost: 17.35s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 4.5796	Cost: 16.41s
Train Epoch: 290 	Average Loss: 6.1288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 25.4654

Learning rate: 3.505519516698166e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 28.2101	Cost: 34.01s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 4.4028	Cost: 17.48s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 4.1063	Cost: 11.44s
Train Epoch: 291 	Average Loss: 6.2111
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1696

Learning rate: 3.445998290882063e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 22.7053	Cost: 37.18s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 4.0083	Cost: 12.97s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 3.6399	Cost: 10.18s
Train Epoch: 292 	Average Loss: 5.6155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.0573

Learning rate: 3.386881346763484e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 22.3637	Cost: 32.77s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 3.5034	Cost: 9.91s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 3.3845	Cost: 14.88s
Train Epoch: 293 	Average Loss: 5.2834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.0219

Learning rate: 3.328172330954006e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 22.2997	Cost: 30.61s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 3.3924	Cost: 11.03s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 3.2668	Cost: 13.35s
Train Epoch: 294 	Average Loss: 5.1065
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3813

Learning rate: 3.269874864902267e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 22.3923	Cost: 29.11s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 3.6032	Cost: 9.72s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 3.4606	Cost: 20.56s
Train Epoch: 295 	Average Loss: 5.3247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.4665

Learning rate: 3.2119925446705836e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 22.2235	Cost: 32.77s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 3.4660	Cost: 13.61s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 3.5986	Cost: 17.61s
Train Epoch: 296 	Average Loss: 5.3139
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.1390

Learning rate: 3.1545289407131144e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 22.7100	Cost: 33.92s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 3.5513	Cost: 16.37s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 3.2989	Cost: 17.15s
Train Epoch: 297 	Average Loss: 5.3248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.3437

Learning rate: 3.09748759765563e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 22.9539	Cost: 33.48s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 3.4096	Cost: 16.21s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 3.1804	Cost: 16.52s
Train Epoch: 298 	Average Loss: 5.1122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.1495

Learning rate: 3.0408720340768585e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 23.5257	Cost: 33.65s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 3.2365	Cost: 16.80s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 3.0787	Cost: 16.50s
Train Epoch: 299 	Average Loss: 5.0706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.2233

Learning rate: 2.9846857422914446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 22.3144	Cost: 33.92s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 3.1868	Cost: 17.03s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 3.0135	Cost: 16.94s
Train Epoch: 300 	Average Loss: 4.8853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.1766

Learning rate: 2.9289321881345268e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 22.4345	Cost: 35.71s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 2.9933	Cost: 16.87s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 2.8983	Cost: 11.26s
Train Epoch: 301 	Average Loss: 4.7810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.5151

Learning rate: 2.8736148107479478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 29.4374	Cost: 33.16s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 3.2851	Cost: 11.40s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 3.1738	Cost: 10.78s
Train Epoch: 302 	Average Loss: 5.2903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.7228

Learning rate: 2.8187370223681142e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 22.4862	Cost: 33.34s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 3.1495	Cost: 12.73s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 2.9465	Cost: 12.64s
Train Epoch: 303 	Average Loss: 4.8842
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.4569

Learning rate: 2.764302208115509e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 22.6403	Cost: 30.43s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 2.8975	Cost: 12.77s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 2.8480	Cost: 10.87s
Train Epoch: 304 	Average Loss: 4.7292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.7407

Learning rate: 2.710313725785888e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 22.5680	Cost: 28.75s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 2.9227	Cost: 9.74s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 2.7597	Cost: 16.05s
Train Epoch: 305 	Average Loss: 4.6619
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.6958

Learning rate: 2.6567749056431446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 23.5082	Cost: 28.73s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 2.8785	Cost: 9.64s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 2.7935	Cost: 12.22s
Train Epoch: 306 	Average Loss: 4.6768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3813

Learning rate: 2.6036890502139035e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 22.3791	Cost: 29.28s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 2.8371	Cost: 9.89s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 2.7959	Cost: 11.44s
Train Epoch: 307 	Average Loss: 4.6621
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.9281

Learning rate: 2.55105943408378e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 22.3842	Cost: 29.30s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 2.8748	Cost: 9.73s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 2.7759	Cost: 11.42s
Train Epoch: 308 	Average Loss: 4.6744
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.3605

Learning rate: 2.4988893036954053e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 22.8754	Cost: 29.61s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 2.8514	Cost: 9.72s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 2.7193	Cost: 12.16s
Train Epoch: 309 	Average Loss: 4.6089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2712

Learning rate: 2.4471818771481658e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 24.5716	Cost: 28.93s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 2.8540	Cost: 9.51s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 2.8707	Cost: 12.28s
Train Epoch: 310 	Average Loss: 4.7488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.5166

Learning rate: 2.3959403439996917e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 22.4709	Cost: 29.82s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 2.9084	Cost: 9.59s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 2.7267	Cost: 11.59s
Train Epoch: 311 	Average Loss: 4.5922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.6641

Learning rate: 2.345167865069121e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 22.5827	Cost: 27.93s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 2.7137	Cost: 9.53s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 2.4976	Cost: 12.09s
Train Epoch: 312 	Average Loss: 4.4901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.5254

Learning rate: 2.2948675722421096e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 22.3869	Cost: 29.63s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 2.6101	Cost: 9.53s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 2.4560	Cost: 11.85s
Train Epoch: 313 	Average Loss: 4.4353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.7681

Learning rate: 2.2450425682776575e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 22.5470	Cost: 27.91s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 2.5965	Cost: 9.54s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 2.5037	Cost: 11.86s
Train Epoch: 314 	Average Loss: 4.3779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.5293

Learning rate: 2.1956959266167054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 22.3584	Cost: 29.33s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 2.5691	Cost: 9.58s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 2.3905	Cost: 12.59s
Train Epoch: 315 	Average Loss: 4.3246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.4090

Learning rate: 2.1468306911925506e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 22.9156	Cost: 29.24s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 2.4938	Cost: 9.56s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 2.5024	Cost: 11.68s
Train Epoch: 316 	Average Loss: 4.3532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.4158

Learning rate: 2.098449876243097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 22.4909	Cost: 28.87s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 2.4922	Cost: 9.52s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 2.4710	Cost: 11.93s
Train Epoch: 317 	Average Loss: 4.3261
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.9281

Learning rate: 2.050556466124901e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 22.7685	Cost: 28.40s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 2.4723	Cost: 9.70s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 2.4949	Cost: 12.19s
Train Epoch: 318 	Average Loss: 4.2768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.6907

Learning rate: 2.0031534151290953e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 22.5742	Cost: 30.06s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 2.4390	Cost: 9.73s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 2.3808	Cost: 11.93s
Train Epoch: 319 	Average Loss: 4.2487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.5663

Learning rate: 1.9562436472991562e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 22.4597	Cost: 29.69s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 2.4431	Cost: 9.59s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 2.3502	Cost: 11.90s
Train Epoch: 320 	Average Loss: 4.2026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.4948

Learning rate: 1.9098300562505276e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 22.4372	Cost: 30.83s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 2.3143	Cost: 10.24s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 2.3256	Cost: 11.49s
Train Epoch: 321 	Average Loss: 4.2625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 28.1473

Learning rate: 1.863915504992132e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 22.4403	Cost: 30.84s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 2.4236	Cost: 9.52s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 3.4859	Cost: 12.56s
Train Epoch: 322 	Average Loss: 4.2617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.2634

Learning rate: 1.8185028257497683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 22.6049	Cost: 28.79s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 2.5302	Cost: 9.73s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 2.4474	Cost: 11.57s
Train Epoch: 323 	Average Loss: 4.3611
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.2883

Learning rate: 1.7735948197914044e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 22.9002	Cost: 28.85s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 2.4763	Cost: 9.53s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 2.3260	Cost: 11.65s
Train Epoch: 324 	Average Loss: 4.2769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.3993

Learning rate: 1.729194257254384e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 22.2604	Cost: 30.29s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 2.3560	Cost: 9.55s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 2.2391	Cost: 12.77s
Train Epoch: 325 	Average Loss: 4.2089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.6862

Learning rate: 1.685303876974551e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 22.4422	Cost: 29.02s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 2.3578	Cost: 10.19s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 2.3118	Cost: 12.50s
Train Epoch: 326 	Average Loss: 4.1954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 28.2644

Learning rate: 1.6419263863173007e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 22.5195	Cost: 28.99s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 2.2545	Cost: 9.52s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 2.3044	Cost: 11.64s
Train Epoch: 327 	Average Loss: 4.1920
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.6448

Learning rate: 1.599064461010582e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 23.2087	Cost: 30.35s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 2.3830	Cost: 9.55s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 2.2404	Cost: 12.17s
Train Epoch: 328 	Average Loss: 4.1906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.9569

Learning rate: 1.5567207449798525e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 22.7663	Cost: 29.24s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 2.3076	Cost: 9.56s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 2.2462	Cost: 11.58s
Train Epoch: 329 	Average Loss: 4.1128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.5795

Learning rate: 1.5148978501849652e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 22.5366	Cost: 29.41s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 2.1968	Cost: 10.21s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 2.1361	Cost: 12.32s
Train Epoch: 330 	Average Loss: 4.0745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.5957

Learning rate: 1.4735983564590815e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 22.8509	Cost: 29.19s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 2.2939	Cost: 9.62s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 2.1131	Cost: 12.14s
Train Epoch: 331 	Average Loss: 4.1754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 28.8258

Learning rate: 1.4328248113495055e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 22.6280	Cost: 29.83s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 2.6981	Cost: 9.54s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 2.2820	Cost: 12.21s
Train Epoch: 332 	Average Loss: 4.2518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.1648

Learning rate: 1.3925797299605635e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 22.4156	Cost: 29.48s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 2.3478	Cost: 9.78s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 2.1868	Cost: 12.39s
Train Epoch: 333 	Average Loss: 4.1364
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.6720

Learning rate: 1.3528655947984512e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 22.6345	Cost: 29.87s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 2.2605	Cost: 10.01s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 2.1534	Cost: 12.03s
Train Epoch: 334 	Average Loss: 4.0370
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.7374

Learning rate: 1.3136848556180878e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 22.9696	Cost: 29.22s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 2.1164	Cost: 9.77s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 2.0841	Cost: 11.64s
Train Epoch: 335 	Average Loss: 4.0832
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 28.3250

Learning rate: 1.2750399292720314e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 22.8768	Cost: 29.86s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 2.1494	Cost: 9.58s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 2.1338	Cost: 12.40s
Train Epoch: 336 	Average Loss: 4.0279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.8396

Learning rate: 1.2369331995613651e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 22.7733	Cost: 28.42s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 2.1799	Cost: 9.59s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 2.3053	Cost: 11.88s
Train Epoch: 337 	Average Loss: 4.1012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.8629

Learning rate: 1.1993670170886837e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 23.0085	Cost: 29.76s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 2.3864	Cost: 9.53s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 2.3032	Cost: 11.91s
Train Epoch: 338 	Average Loss: 4.2154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.7877

Learning rate: 1.1623436991130663e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 22.8568	Cost: 28.22s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 2.1651	Cost: 9.62s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 2.1309	Cost: 11.88s
Train Epoch: 339 	Average Loss: 4.0625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.5132

Learning rate: 1.1258655294071704e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 22.6394	Cost: 30.22s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 2.1787	Cost: 10.01s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 2.0108	Cost: 12.26s
Train Epoch: 340 	Average Loss: 4.0126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.2585

Learning rate: 1.089934758116323e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 22.4653	Cost: 29.93s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 2.0902	Cost: 9.58s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 1.9650	Cost: 12.75s
Train Epoch: 341 	Average Loss: 3.9416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.8447

Learning rate: 1.054553601619753e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 22.4771	Cost: 29.73s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 2.0034	Cost: 10.21s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 1.9364	Cost: 12.00s
Train Epoch: 342 	Average Loss: 3.9001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.0855

Learning rate: 1.0197242423938455e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 22.5951	Cost: 28.77s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 2.1010	Cost: 9.65s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 1.9148	Cost: 12.14s
Train Epoch: 343 	Average Loss: 3.8918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.0979

Learning rate: 9.854488288775428e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 22.5608	Cost: 28.89s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 1.9766	Cost: 10.25s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 1.9144	Cost: 12.22s
Train Epoch: 344 	Average Loss: 3.8789
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.3387

Learning rate: 9.517294753398073e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 23.5406	Cost: 29.59s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 2.0402	Cost: 9.53s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 1.9083	Cost: 12.09s
Train Epoch: 345 	Average Loss: 3.9376
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.2383

Learning rate: 9.185682617491872e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 22.8738	Cost: 30.77s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 1.9654	Cost: 9.52s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 1.9051	Cost: 12.54s
Train Epoch: 346 	Average Loss: 3.8983
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.9702

Learning rate: 8.859672336455501e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 23.0772	Cost: 29.81s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 2.0069	Cost: 9.51s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 1.9360	Cost: 12.95s
Train Epoch: 347 	Average Loss: 3.8710
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.7458

Learning rate: 8.539284020138645e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 22.5371	Cost: 28.90s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 1.9749	Cost: 9.62s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 1.8349	Cost: 12.13s
Train Epoch: 348 	Average Loss: 3.8268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.3947

Learning rate: 8.224537431601915e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 25.7285	Cost: 29.84s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 2.0249	Cost: 9.93s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 1.9290	Cost: 12.26s
Train Epoch: 349 	Average Loss: 4.2500
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 29.4630

Learning rate: 7.915451985897387e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 23.1800	Cost: 29.69s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 2.0880	Cost: 10.30s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 2.0540	Cost: 12.00s
Train Epoch: 350 	Average Loss: 4.0377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.2397

Learning rate: 7.612046748871354e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 23.0296	Cost: 28.87s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 2.0284	Cost: 9.65s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 1.9271	Cost: 11.67s
Train Epoch: 351 	Average Loss: 3.9142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.6719

Learning rate: 7.314340435987926e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 22.5338	Cost: 28.51s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 2.0295	Cost: 9.66s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 1.8360	Cost: 11.98s
Train Epoch: 352 	Average Loss: 3.8348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.6990

Learning rate: 7.022351411174871e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 22.5778	Cost: 28.98s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 1.9165	Cost: 9.46s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 1.8211	Cost: 12.09s
Train Epoch: 353 	Average Loss: 3.8123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.4546

Learning rate: 6.736097685690606e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 22.4557	Cost: 28.38s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 1.9748	Cost: 9.44s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 1.8013	Cost: 11.77s
Train Epoch: 354 	Average Loss: 3.7835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.0131

Learning rate: 6.455596917013267e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 22.5485	Cost: 28.53s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 1.9236	Cost: 9.43s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 1.8944	Cost: 12.98s
Train Epoch: 355 	Average Loss: 3.7557
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.5325

Learning rate: 6.1808664077516005e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 22.7638	Cost: 28.69s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 1.8753	Cost: 9.42s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 1.7160	Cost: 11.64s
Train Epoch: 356 	Average Loss: 3.7353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.6929

Learning rate: 5.91192310457746e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 23.2526	Cost: 28.28s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 1.9092	Cost: 9.42s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 1.8492	Cost: 11.77s
Train Epoch: 357 	Average Loss: 3.7886
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.3981

Learning rate: 5.648783597180656e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 22.5240	Cost: 29.01s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 1.9234	Cost: 9.44s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 1.7300	Cost: 12.41s
Train Epoch: 358 	Average Loss: 3.7166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.8259

Learning rate: 5.3914641172454745e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 22.5105	Cost: 29.87s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 1.8082	Cost: 9.43s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 1.7010	Cost: 12.39s
Train Epoch: 359 	Average Loss: 3.7128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.1824

Learning rate: 5.139980537449555e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 22.4797	Cost: 28.20s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 1.8083	Cost: 9.46s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 1.7346	Cost: 11.59s
Train Epoch: 360 	Average Loss: 3.6933
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.5638

Learning rate: 4.894348370484651e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 22.8167	Cost: 28.20s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 1.8705	Cost: 9.40s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 1.7092	Cost: 11.77s
Train Epoch: 361 	Average Loss: 3.7023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.8709

Learning rate: 4.6545827680998834e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 22.8680	Cost: 27.88s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 1.8400	Cost: 9.42s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 1.8175	Cost: 11.67s
Train Epoch: 362 	Average Loss: 3.7316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.1197

Learning rate: 4.420698520166991e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 22.6418	Cost: 29.89s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 1.8353	Cost: 9.46s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 1.7186	Cost: 12.65s
Train Epoch: 363 	Average Loss: 3.6836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.9683

Learning rate: 4.1927100537680815e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 22.4976	Cost: 28.22s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 1.7301	Cost: 9.43s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 1.6455	Cost: 11.92s
Train Epoch: 364 	Average Loss: 3.6616
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.5917

Learning rate: 3.970631432305708e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 22.5083	Cost: 27.77s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 1.7821	Cost: 9.41s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 1.7145	Cost: 12.01s
Train Epoch: 365 	Average Loss: 3.6593
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.1006

Learning rate: 3.7544763546352753e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 22.4881	Cost: 29.15s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 1.7115	Cost: 9.41s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 1.5786	Cost: 11.61s
Train Epoch: 366 	Average Loss: 3.6289
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.5716

Learning rate: 3.5442581542202067e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 22.4113	Cost: 28.97s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 1.7756	Cost: 9.41s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 1.6610	Cost: 11.67s
Train Epoch: 367 	Average Loss: 3.6571
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.8064

Learning rate: 3.339989798309276e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 22.6264	Cost: 27.88s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 1.7720	Cost: 9.42s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 1.6801	Cost: 11.72s
Train Epoch: 368 	Average Loss: 3.6489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.8892

Learning rate: 3.1416838871369064e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 22.5722	Cost: 29.69s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 1.7840	Cost: 9.48s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 1.7164	Cost: 12.62s
Train Epoch: 369 	Average Loss: 3.6324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.6315

Learning rate: 2.9493526531457563e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 22.7655	Cost: 28.74s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 1.7980	Cost: 9.44s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 1.6746	Cost: 11.59s
Train Epoch: 370 	Average Loss: 3.6357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.7362

Learning rate: 2.7630079602323468e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 22.7622	Cost: 28.38s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 1.7308	Cost: 9.42s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 1.6811	Cost: 12.19s
Train Epoch: 371 	Average Loss: 3.6239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.8916

Learning rate: 2.582661303015068e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 22.4176	Cost: 28.25s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 1.7716	Cost: 9.41s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 1.6216	Cost: 11.82s
Train Epoch: 372 	Average Loss: 3.6012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.7887

Learning rate: 2.40832380612527e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 22.5373	Cost: 28.18s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 1.6916	Cost: 9.42s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 1.6654	Cost: 12.04s
Train Epoch: 373 	Average Loss: 3.6123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.0082

Learning rate: 2.2400062235209426e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 22.6920	Cost: 29.66s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 1.7254	Cost: 9.46s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 1.6573	Cost: 12.28s
Train Epoch: 374 	Average Loss: 3.6204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.8990

Learning rate: 2.0777189378234156e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 22.6393	Cost: 28.04s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 1.7121	Cost: 9.40s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 1.6050	Cost: 11.60s
Train Epoch: 375 	Average Loss: 3.5882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.8518

Learning rate: 1.9214719596769582e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 22.6324	Cost: 28.14s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 1.7570	Cost: 9.44s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 1.7027	Cost: 12.00s
Train Epoch: 376 	Average Loss: 3.6087
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.8203

Learning rate: 1.771274927131129e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 22.4815	Cost: 28.30s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 1.7022	Cost: 9.42s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 1.6479	Cost: 12.09s
Train Epoch: 377 	Average Loss: 3.5965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.5207

Learning rate: 1.6271371050464177e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 22.5445	Cost: 28.57s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 1.7168	Cost: 9.53s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 1.5493	Cost: 12.11s
Train Epoch: 378 	Average Loss: 3.5846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.7853

Learning rate: 1.4890673845226142e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 22.7524	Cost: 28.41s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 1.6308	Cost: 9.45s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 1.6105	Cost: 12.68s
Train Epoch: 379 	Average Loss: 3.5907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.6581

Learning rate: 1.3570742823504575e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 24.0757	Cost: 28.11s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 1.6937	Cost: 9.45s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 1.6604	Cost: 12.18s
Train Epoch: 380 	Average Loss: 3.6712
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.1320

Learning rate: 1.2311659404862349e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 22.4810	Cost: 28.42s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 1.6420	Cost: 9.48s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 1.6129	Cost: 12.18s
Train Epoch: 381 	Average Loss: 3.5636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.7623

Learning rate: 1.1113501255495491e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 22.3210	Cost: 27.99s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 1.6800	Cost: 9.42s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 1.6354	Cost: 11.48s
Train Epoch: 382 	Average Loss: 3.5552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.6471

Learning rate: 9.97634228344247e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 22.4501	Cost: 27.90s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 1.6472	Cost: 9.43s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 1.6280	Cost: 11.60s
Train Epoch: 383 	Average Loss: 3.5631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.6053

Learning rate: 8.90025263402528e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 22.8579	Cost: 27.63s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 1.6832	Cost: 9.48s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 1.5683	Cost: 11.87s
Train Epoch: 384 	Average Loss: 3.5809
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.3375

Learning rate: 7.88529868552224e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 22.9023	Cost: 28.99s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 1.6236	Cost: 9.47s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 1.6418	Cost: 11.76s
Train Epoch: 385 	Average Loss: 3.5866
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.0495

Learning rate: 6.931543045073711e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 22.4122	Cost: 27.65s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 1.6529	Cost: 9.43s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 1.6184	Cost: 12.63s
Train Epoch: 386 	Average Loss: 3.5701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.5374

Learning rate: 6.039044544820409e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 22.9331	Cost: 28.07s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 1.7078	Cost: 9.43s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 1.5720	Cost: 11.72s
Train Epoch: 387 	Average Loss: 3.6092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.6469

Learning rate: 5.207858238273524e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 22.5107	Cost: 30.16s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 1.6529	Cost: 9.44s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 1.5717	Cost: 12.55s
Train Epoch: 388 	Average Loss: 3.5766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.1578

Learning rate: 4.4380353969200063e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 22.9881	Cost: 28.03s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 1.6870	Cost: 9.40s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 1.6130	Cost: 11.73s
Train Epoch: 389 	Average Loss: 3.5962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 28.1090

Learning rate: 3.7296235070587456e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 22.6322	Cost: 29.56s
Train Epoch: 390 [40960/90000 (45%)]	Loss: 1.6763	Cost: 9.43s
Train Epoch: 390 [81920/90000 (91%)]	Loss: 1.6208	Cost: 12.52s
Train Epoch: 390 	Average Loss: 3.5863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.2643

Learning rate: 3.082666266872038e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 22.6097	Cost: 28.98s
Train Epoch: 391 [40960/90000 (45%)]	Loss: 1.6265	Cost: 9.43s
Train Epoch: 391 [81920/90000 (91%)]	Loss: 1.6562	Cost: 12.41s
Train Epoch: 391 	Average Loss: 3.5496
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.6517

Learning rate: 2.497203583729958e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 22.9400	Cost: 27.55s
Train Epoch: 392 [40960/90000 (45%)]	Loss: 1.6760	Cost: 9.43s
Train Epoch: 392 [81920/90000 (91%)]	Loss: 1.5476	Cost: 11.85s
Train Epoch: 392 	Average Loss: 3.5876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.6622

Learning rate: 1.973271571728442e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 22.6175	Cost: 28.63s
Train Epoch: 393 [40960/90000 (45%)]	Loss: 1.5946	Cost: 9.44s
Train Epoch: 393 [81920/90000 (91%)]	Loss: 1.5581	Cost: 11.68s
Train Epoch: 393 	Average Loss: 3.6066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 28.0328

Learning rate: 1.5109025494620685e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 22.5759	Cost: 27.91s
Train Epoch: 394 [40960/90000 (45%)]	Loss: 1.7005	Cost: 9.45s
Train Epoch: 394 [81920/90000 (91%)]	Loss: 1.6219	Cost: 11.31s
Train Epoch: 394 	Average Loss: 3.5551
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.7916

Learning rate: 1.1101250380300971e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 22.5011	Cost: 27.66s
Train Epoch: 395 [40960/90000 (45%)]	Loss: 1.6443	Cost: 9.43s
Train Epoch: 395 [81920/90000 (91%)]	Loss: 1.6247	Cost: 11.91s
Train Epoch: 395 	Average Loss: 3.5581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.9516

Learning rate: 7.709637592770994e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 22.4930	Cost: 28.51s
Train Epoch: 396 [40960/90000 (45%)]	Loss: 1.6735	Cost: 9.42s
Train Epoch: 396 [81920/90000 (91%)]	Loss: 1.5531	Cost: 11.44s
Train Epoch: 396 	Average Loss: 3.5436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.7360

Learning rate: 4.934396342684002e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 22.5870	Cost: 28.05s
Train Epoch: 397 [40960/90000 (45%)]	Loss: 1.6864	Cost: 9.42s
Train Epoch: 397 [81920/90000 (91%)]	Loss: 1.5782	Cost: 11.88s
Train Epoch: 397 	Average Loss: 3.5748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.7541

Learning rate: 2.7756978199944282e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 22.4986	Cost: 28.19s
Train Epoch: 398 [40960/90000 (45%)]	Loss: 1.7048	Cost: 9.41s
Train Epoch: 398 [81920/90000 (91%)]	Loss: 1.5570	Cost: 11.48s
Train Epoch: 398 	Average Loss: 3.5602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.6305

Learning rate: 1.2336751833941234e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 22.6464	Cost: 27.70s
Train Epoch: 399 [40960/90000 (45%)]	Loss: 1.7128	Cost: 9.42s
Train Epoch: 399 [81920/90000 (91%)]	Loss: 1.5768	Cost: 11.93s
Train Epoch: 399 	Average Loss: 3.5620
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 27.1424

Learning rate: 3.084235521033653e-09
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 22.4337	Cost: 27.67s
Train Epoch: 400 [40960/90000 (45%)]	Loss: 1.7071	Cost: 9.44s
Train Epoch: 400 [81920/90000 (91%)]	Loss: 1.5971	Cost: 11.91s
Train Epoch: 400 	Average Loss: 3.5608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 26.8307

Stopping timer.
Training time (including validation): 491761.2996878624 seconds
Saving model
Program complete
