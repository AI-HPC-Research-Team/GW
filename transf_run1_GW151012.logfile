Nestedspace(activation='elu', apply_unconditional_transform=False, base_transform_type='rq-coupling', basis_dir='data/GW151012_sample_prior_basis/', batch_norm=True, batch_size=4096, bw_dstar=None, cuda=True, data_dir='data/GW151012_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, dropout_probability=0.0, epochs=10000, flow_lr=None, hidden_dims=512, kl_annealing=True, lr=0.0002, lr_anneal_method='cosine', lr_annealing=True, mixed_alpha=1.0, mode='train', model_dir='models/GW151012_sample_uniform_100basis_all_mixed_prior_transfered/', model_source='new', model_type='nde', nbins=8, nflows=15, nsample=100000, nsamples_target_event=50000, num_transform_blocks=10, output_freq=10, sampling_from='mixed', save=True, save_aux_filename='waveforms_supplementary.hdf5', save_model_name='model.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, tail_bound=1.0, transfer_epochs=400, truncate_basis=100)
Waveform directory data/GW151012_sample_prior_basis/
Model directory models/GW151012_sample_uniform_100basis_all_mixed_prior_transfered/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Detectors: ['H1', 'L1']

Constructing model of type nde

Initial learning rate 0.0002
Using cosine LR annealing.

Model hyperparameters:
input_dim 	 15
num_flow_steps 	 15
context_dim 	 400
base_transform_kwargs
	 hidden_dim 	 512
	 num_transform_blocks 	 10
	 activation 	 elu
	 dropout_probability 	 0.0
	 batch_norm 	 True
	 num_bins 	 8
	 tail_bound 	 1.0
	 apply_unconditional_transform 	 False
	 base_transform_type 	 rq-coupling

Training for 10000 epochs
Starting timer
Now, transfer learning from alpha=1.0!
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 27.5147	Cost: 37.00s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 21.5890	Cost: 9.47s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 20.2474	Cost: 17.20s
Train Epoch: 1 	Average Loss: 21.7170
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4847

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999999506519785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 20.2303	Cost: 38.16s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 19.2570	Cost: 9.46s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 18.8924	Cost: 19.65s
Train Epoch: 2 	Average Loss: 19.3739
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8070

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019999998026079186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 18.8076	Cost: 38.65s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 18.3861	Cost: 9.66s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 17.8257	Cost: 18.27s
Train Epoch: 3 	Average Loss: 18.3131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8653

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019999995558678347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 17.7889	Cost: 35.61s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 17.3393	Cost: 9.70s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 16.8151	Cost: 17.33s
Train Epoch: 4 	Average Loss: 17.2585
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9249

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.0001999999210431752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 16.7300	Cost: 35.00s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 16.2502	Cost: 10.06s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 15.9493	Cost: 18.03s
Train Epoch: 5 	Average Loss: 16.3038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0721

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.00019999987662997035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 15.9499	Cost: 38.88s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 15.6136	Cost: 9.69s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 15.3209	Cost: 17.54s
Train Epoch: 6 	Average Loss: 15.6445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4647

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019999982234717337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 15.2729	Cost: 38.54s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 15.1954	Cost: 10.11s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 14.8170	Cost: 19.85s
Train Epoch: 7 	Average Loss: 15.1208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0977

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.0001999997581947896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 14.8778	Cost: 37.12s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 14.7193	Cost: 9.80s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 14.4349	Cost: 22.62s
Train Epoch: 8 	Average Loss: 14.6610
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7375

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.0001999996841728254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 14.4689	Cost: 34.93s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 14.2485	Cost: 9.60s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 14.0925	Cost: 23.72s
Train Epoch: 9 	Average Loss: 14.2992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3754

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019999960028128805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 14.1649	Cost: 36.72s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 14.0893	Cost: 9.55s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 13.8299	Cost: 21.86s
Train Epoch: 10 	Average Loss: 14.0357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0463

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 0.00019999950652018584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 13.8848	Cost: 37.10s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 13.8250	Cost: 9.61s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 13.5508	Cost: 17.86s
Train Epoch: 11 	Average Loss: 13.7407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6757

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 0.00019999940288952797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 13.5677	Cost: 38.45s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 13.5931	Cost: 9.44s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 13.4060	Cost: 20.04s
Train Epoch: 12 	Average Loss: 13.4987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4696

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 0.00019999928938932473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 13.3666	Cost: 35.57s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 13.3258	Cost: 9.43s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 13.2621	Cost: 17.94s
Train Epoch: 13 	Average Loss: 13.2984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3568

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Learning rate: 0.0001999991660195873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 13.1993	Cost: 35.42s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 13.1570	Cost: 9.44s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 13.1052	Cost: 18.36s
Train Epoch: 14 	Average Loss: 13.1611
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1016

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Learning rate: 0.0001999990327803279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 13.1777	Cost: 38.52s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 13.0480	Cost: 9.73s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 12.8963	Cost: 17.77s
Train Epoch: 15 	Average Loss: 12.9581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9040

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Learning rate: 0.00019999888967155963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 12.9674	Cost: 37.78s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 12.8295	Cost: 9.61s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 12.6946	Cost: 20.42s
Train Epoch: 16 	Average Loss: 12.8192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8163

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Learning rate: 0.0001999987366932966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 12.8289	Cost: 38.23s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 12.7695	Cost: 9.64s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 12.5924	Cost: 20.32s
Train Epoch: 17 	Average Loss: 12.6979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6029

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Learning rate: 0.00019999857384555393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 12.7491	Cost: 35.07s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 12.5621	Cost: 9.63s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 12.4576	Cost: 21.26s
Train Epoch: 18 	Average Loss: 12.5788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5904

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Learning rate: 0.0001999984011283477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 12.5019	Cost: 35.21s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 12.4818	Cost: 9.95s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 12.3179	Cost: 22.60s
Train Epoch: 19 	Average Loss: 12.4401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4177

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Learning rate: 0.00019999821854169497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 12.5312	Cost: 35.15s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 12.3373	Cost: 9.59s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 12.1858	Cost: 23.72s
Train Epoch: 20 	Average Loss: 12.3301
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3062

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Learning rate: 0.00019999802608561374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 12.2359	Cost: 37.33s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 12.1624	Cost: 9.52s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 12.2215	Cost: 21.65s
Train Epoch: 21 	Average Loss: 12.2316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2822

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Learning rate: 0.000199997823760123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 12.1841	Cost: 37.14s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 12.2553	Cost: 9.47s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 11.9563	Cost: 18.91s
Train Epoch: 22 	Average Loss: 12.1054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0832

Saving model as e22_model.pt & e22_waveforms_supplementary.hdf5
Learning rate: 0.00019999761156524272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 12.0289	Cost: 38.95s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 12.0540	Cost: 9.59s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 11.8904	Cost: 17.67s
Train Epoch: 23 	Average Loss: 12.0146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8903

Saving model as e23_model.pt & e23_waveforms_supplementary.hdf5
Learning rate: 0.00019999738950099387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 11.9671	Cost: 38.51s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 12.0397	Cost: 9.67s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 11.8098	Cost: 19.75s
Train Epoch: 24 	Average Loss: 11.9493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0413

Learning rate: 0.00019999715756739833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 11.8861	Cost: 40.20s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 11.7763	Cost: 9.43s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 11.5696	Cost: 19.85s
Train Epoch: 25 	Average Loss: 11.8086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8724

Saving model as e25_model.pt & e25_waveforms_supplementary.hdf5
Learning rate: 0.000199996915764479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 11.7413	Cost: 38.07s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 11.8483	Cost: 9.45s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 11.6649	Cost: 20.69s
Train Epoch: 26 	Average Loss: 11.7503
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7115

Saving model as e26_model.pt & e26_waveforms_supplementary.hdf5
Learning rate: 0.00019999666409225975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 11.7579	Cost: 37.34s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 11.6952	Cost: 9.47s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 11.5979	Cost: 19.64s
Train Epoch: 27 	Average Loss: 11.6522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5567

Saving model as e27_model.pt & e27_waveforms_supplementary.hdf5
Learning rate: 0.00019999640255076543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 11.5818	Cost: 37.77s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 11.4293	Cost: 9.40s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 11.3152	Cost: 20.68s
Train Epoch: 28 	Average Loss: 11.4648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4164

Saving model as e28_model.pt & e28_waveforms_supplementary.hdf5
Learning rate: 0.00019999613114002186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 11.4244	Cost: 36.68s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 11.2683	Cost: 10.13s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 11.2530	Cost: 21.52s
Train Epoch: 29 	Average Loss: 11.3332
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3693

Saving model as e29_model.pt & e29_waveforms_supplementary.hdf5
Learning rate: 0.0001999958498600558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 11.3105	Cost: 36.97s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 11.3764	Cost: 9.55s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 11.1509	Cost: 24.03s
Train Epoch: 30 	Average Loss: 11.2724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1797

Saving model as e30_model.pt & e30_waveforms_supplementary.hdf5
Learning rate: 0.000199995558710895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 11.2240	Cost: 36.19s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 11.1834	Cost: 9.53s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 11.0387	Cost: 21.86s
Train Epoch: 31 	Average Loss: 11.1863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2844

Learning rate: 0.00019999525769256825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 11.1344	Cost: 36.81s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 11.1414	Cost: 9.45s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 11.0069	Cost: 20.24s
Train Epoch: 32 	Average Loss: 11.0960
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9984

Saving model as e32_model.pt & e32_waveforms_supplementary.hdf5
Learning rate: 0.00019999494680510518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 11.0520	Cost: 37.24s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 11.0481	Cost: 9.44s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 10.9842	Cost: 18.98s
Train Epoch: 33 	Average Loss: 11.0300
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9769

Saving model as e33_model.pt & e33_waveforms_supplementary.hdf5
Learning rate: 0.00019999462604853658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 11.0412	Cost: 38.97s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 10.9367	Cost: 9.48s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 11.0041	Cost: 20.06s
Train Epoch: 34 	Average Loss: 10.9198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9496

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Learning rate: 0.00019999429542289402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 10.9199	Cost: 39.98s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 10.8323	Cost: 9.65s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 10.8234	Cost: 18.52s
Train Epoch: 35 	Average Loss: 10.8745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8153

Saving model as e35_model.pt & e35_waveforms_supplementary.hdf5
Learning rate: 0.00019999395492821016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 10.9135	Cost: 37.58s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 10.8012	Cost: 10.17s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 10.7056	Cost: 17.94s
Train Epoch: 36 	Average Loss: 10.8224
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7080

Saving model as e36_model.pt & e36_waveforms_supplementary.hdf5
Learning rate: 0.0001999936045645186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 10.7521	Cost: 37.76s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 10.5869	Cost: 9.69s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 10.7209	Cost: 19.41s
Train Epoch: 37 	Average Loss: 10.6810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6338

Saving model as e37_model.pt & e37_waveforms_supplementary.hdf5
Learning rate: 0.00019999324433185394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 10.6930	Cost: 37.30s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 10.6665	Cost: 10.13s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 10.5004	Cost: 20.33s
Train Epoch: 38 	Average Loss: 10.6701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6424

Learning rate: 0.0001999928742302517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 10.5588	Cost: 37.51s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 10.6578	Cost: 9.76s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 10.3762	Cost: 22.54s
Train Epoch: 39 	Average Loss: 10.5451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5524

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Learning rate: 0.00019999249425974844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 10.4114	Cost: 36.32s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 10.4076	Cost: 9.55s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 10.3716	Cost: 24.18s
Train Epoch: 40 	Average Loss: 10.4454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3993

Saving model as e40_model.pt & e40_waveforms_supplementary.hdf5
Learning rate: 0.00019999210442038165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 10.6077	Cost: 36.82s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 10.4650	Cost: 9.47s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 10.2992	Cost: 21.64s
Train Epoch: 41 	Average Loss: 10.4064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5399

Learning rate: 0.00019999170471218976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 10.3688	Cost: 36.92s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 10.4268	Cost: 9.44s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 10.2549	Cost: 18.53s
Train Epoch: 42 	Average Loss: 10.2940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2972

Saving model as e42_model.pt & e42_waveforms_supplementary.hdf5
Learning rate: 0.0001999912951352123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 10.3076	Cost: 37.24s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 10.1526	Cost: 9.47s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 10.1081	Cost: 18.41s
Train Epoch: 43 	Average Loss: 10.2427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0786

Saving model as e43_model.pt & e43_waveforms_supplementary.hdf5
Learning rate: 0.00019999087568948966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 10.1507	Cost: 38.43s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 10.2029	Cost: 9.64s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 10.1530	Cost: 19.29s
Train Epoch: 44 	Average Loss: 10.1831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2024

Learning rate: 0.0001999904463750632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 10.1865	Cost: 34.93s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 10.1348	Cost: 9.72s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 10.0750	Cost: 17.80s
Train Epoch: 45 	Average Loss: 10.1515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0642

Saving model as e45_model.pt & e45_waveforms_supplementary.hdf5
Learning rate: 0.00019999000719197536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 9.9829	Cost: 38.95s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 10.2593	Cost: 9.81s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 9.9728	Cost: 20.07s
Train Epoch: 46 	Average Loss: 10.0617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0447

Saving model as e46_model.pt & e46_waveforms_supplementary.hdf5
Learning rate: 0.00019998955814026943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 9.9749	Cost: 38.56s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 9.9382	Cost: 9.72s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 9.9203	Cost: 19.06s
Train Epoch: 47 	Average Loss: 9.9708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9294

Saving model as e47_model.pt & e47_waveforms_supplementary.hdf5
Learning rate: 0.00019998909921998973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 10.0888	Cost: 38.07s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 9.9417	Cost: 9.70s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 9.7817	Cost: 20.84s
Train Epoch: 48 	Average Loss: 9.9407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9540

Learning rate: 0.0001999886304311816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 9.9543	Cost: 37.19s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 9.9277	Cost: 9.63s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 9.7760	Cost: 23.69s
Train Epoch: 49 	Average Loss: 9.8817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8978

Saving model as e49_model.pt & e49_waveforms_supplementary.hdf5
Learning rate: 0.00019998815177389132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 9.7547	Cost: 36.59s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 9.8732	Cost: 9.56s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 9.6475	Cost: 23.49s
Train Epoch: 50 	Average Loss: 9.7702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7027

Saving model as e50_model.pt & e50_waveforms_supplementary.hdf5
Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 9.6521	Cost: 37.35s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 9.6584	Cost: 9.50s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 9.7934	Cost: 21.04s
Train Epoch: 51 	Average Loss: 9.6928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6788

Saving model as e51_model.pt & e51_waveforms_supplementary.hdf5
Learning rate: 0.00019998716485405404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 9.6888	Cost: 37.48s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 9.7000	Cost: 9.44s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 9.5660	Cost: 18.96s
Train Epoch: 52 	Average Loss: 9.7162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7927

Learning rate: 0.0001999866565916045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 9.7141	Cost: 36.51s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 9.7045	Cost: 9.53s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 9.5763	Cost: 20.20s
Train Epoch: 53 	Average Loss: 9.6475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7715

Learning rate: 0.0001999861384608676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 9.8818	Cost: 37.37s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 9.5708	Cost: 9.60s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 9.4656	Cost: 18.03s
Train Epoch: 54 	Average Loss: 9.6034
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6011

Saving model as e54_model.pt & e54_waveforms_supplementary.hdf5
Learning rate: 0.00019998561046189446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 9.5864	Cost: 36.10s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 9.6409	Cost: 9.66s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 9.4768	Cost: 18.17s
Train Epoch: 55 	Average Loss: 9.5886
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4908

Saving model as e55_model.pt & e55_waveforms_supplementary.hdf5
Learning rate: 0.00019998507259473718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 9.5663	Cost: 39.15s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 9.4593	Cost: 10.15s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 9.2938	Cost: 19.93s
Train Epoch: 56 	Average Loss: 9.5007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4526

Saving model as e56_model.pt & e56_waveforms_supplementary.hdf5
Learning rate: 0.00019998452485944885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 9.5155	Cost: 38.15s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 9.3738	Cost: 9.73s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 9.4515	Cost: 19.16s
Train Epoch: 57 	Average Loss: 9.3891
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3783

Saving model as e57_model.pt & e57_waveforms_supplementary.hdf5
Learning rate: 0.00019998396725608354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 9.4123	Cost: 35.40s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 9.3141	Cost: 9.66s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 9.2215	Cost: 19.95s
Train Epoch: 58 	Average Loss: 9.4093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5462

Learning rate: 0.00019998339978469627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 9.6073	Cost: 34.53s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 9.3161	Cost: 9.65s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 9.1679	Cost: 20.42s
Train Epoch: 59 	Average Loss: 9.3516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3257

Saving model as e59_model.pt & e59_waveforms_supplementary.hdf5
Learning rate: 0.00019998282244534305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 9.3979	Cost: 37.08s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 9.3480	Cost: 9.77s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 9.2394	Cost: 23.14s
Train Epoch: 60 	Average Loss: 9.3159
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2732

Saving model as e60_model.pt & e60_waveforms_supplementary.hdf5
Learning rate: 0.00019998223523808088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 9.4353	Cost: 36.81s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 9.2403	Cost: 9.56s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 9.0906	Cost: 23.23s
Train Epoch: 61 	Average Loss: 9.2732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3131

Learning rate: 0.0001999816381629677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 9.2612	Cost: 36.85s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 9.1759	Cost: 9.51s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 9.0975	Cost: 21.39s
Train Epoch: 62 	Average Loss: 9.2165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3770

Learning rate: 0.00019998103122006246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 9.4125	Cost: 36.46s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 9.1699	Cost: 9.45s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 9.1627	Cost: 18.57s
Train Epoch: 63 	Average Loss: 9.1989
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1458

Saving model as e63_model.pt & e63_waveforms_supplementary.hdf5
Learning rate: 0.00019998041440942506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 9.2063	Cost: 37.39s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 9.2117	Cost: 9.43s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 9.0656	Cost: 17.98s
Train Epoch: 64 	Average Loss: 9.1468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0895

Saving model as e64_model.pt & e64_waveforms_supplementary.hdf5
Learning rate: 0.00019997978773111632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 9.0769	Cost: 39.28s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 9.1146	Cost: 9.64s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 8.9394	Cost: 19.68s
Train Epoch: 65 	Average Loss: 9.0729
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0083

Saving model as e65_model.pt & e65_waveforms_supplementary.hdf5
Learning rate: 0.00019997915118519813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 8.9557	Cost: 36.05s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 9.0285	Cost: 9.62s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 9.0025	Cost: 18.57s
Train Epoch: 66 	Average Loss: 9.0622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1599

Learning rate: 0.0001999785047717333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 9.1521	Cost: 37.95s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 9.0608	Cost: 9.63s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 8.9691	Cost: 21.59s
Train Epoch: 67 	Average Loss: 9.0334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0596

Learning rate: 0.00019997784849078566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 9.0140	Cost: 37.69s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 8.8953	Cost: 9.52s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 8.8492	Cost: 19.87s
Train Epoch: 68 	Average Loss: 8.9319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0343

Learning rate: 0.00019997718234242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 9.1239	Cost: 37.99s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 8.8960	Cost: 9.76s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 8.7567	Cost: 18.85s
Train Epoch: 69 	Average Loss: 8.9350
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9878

Saving model as e69_model.pt & e69_waveforms_supplementary.hdf5
Learning rate: 0.00019997650632670199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 9.0231	Cost: 37.44s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 8.8297	Cost: 9.52s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 8.7533	Cost: 22.40s
Train Epoch: 70 	Average Loss: 8.8848
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9596

Saving model as e70_model.pt & e70_waveforms_supplementary.hdf5
Learning rate: 0.0001999758204436984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 8.9691	Cost: 36.14s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 8.9583	Cost: 9.85s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 8.7995	Cost: 22.70s
Train Epoch: 71 	Average Loss: 8.8837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8605

Saving model as e71_model.pt & e71_waveforms_supplementary.hdf5
Learning rate: 0.00019997512469347695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 8.7966	Cost: 36.18s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 8.7846	Cost: 9.58s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 8.8622	Cost: 22.51s
Train Epoch: 72 	Average Loss: 8.8322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8187

Saving model as e72_model.pt & e72_waveforms_supplementary.hdf5
Learning rate: 0.00019997441907610624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 8.8259	Cost: 37.28s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 8.7701	Cost: 9.47s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 8.6966	Cost: 20.58s
Train Epoch: 73 	Average Loss: 8.7905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8615

Learning rate: 0.00019997370359165596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 8.8482	Cost: 36.64s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 8.6791	Cost: 9.46s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 8.7318	Cost: 18.39s
Train Epoch: 74 	Average Loss: 8.7941
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7796

Saving model as e74_model.pt & e74_waveforms_supplementary.hdf5
Learning rate: 0.0001999729782401967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 8.7966	Cost: 37.76s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 8.7616	Cost: 9.49s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 8.6074	Cost: 18.17s
Train Epoch: 75 	Average Loss: 8.7164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7927

Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 8.6943	Cost: 39.22s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 8.7439	Cost: 9.48s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 8.5466	Cost: 19.95s
Train Epoch: 76 	Average Loss: 8.6389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5926

Saving model as e76_model.pt & e76_waveforms_supplementary.hdf5
Learning rate: 0.00019997149793653861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 8.6373	Cost: 36.84s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 8.6458	Cost: 9.52s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 8.5359	Cost: 20.15s
Train Epoch: 77 	Average Loss: 8.6717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6761

Learning rate: 0.00019997074298448586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 8.7956	Cost: 36.27s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 8.6201	Cost: 9.65s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 8.5437	Cost: 19.41s
Train Epoch: 78 	Average Loss: 8.5842
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6375

Learning rate: 0.00019996997816571638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 8.6353	Cost: 39.12s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 8.5220	Cost: 9.87s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 8.4248	Cost: 21.01s
Train Epoch: 79 	Average Loss: 8.5746
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7510

Learning rate: 0.00019996920348030559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 8.8425	Cost: 37.78s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 8.6020	Cost: 9.60s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 8.3740	Cost: 19.79s
Train Epoch: 80 	Average Loss: 8.5812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5142

Saving model as e80_model.pt & e80_waveforms_supplementary.hdf5
Learning rate: 0.00019996841892832998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 8.4806	Cost: 38.79s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 8.4481	Cost: 10.18s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 8.4742	Cost: 19.20s
Train Epoch: 81 	Average Loss: 8.4861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5524

Learning rate: 0.00019996762450986697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 8.5698	Cost: 37.35s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 8.4149	Cost: 10.21s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 8.2762	Cost: 20.81s
Train Epoch: 82 	Average Loss: 8.4721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3709

Saving model as e82_model.pt & e82_waveforms_supplementary.hdf5
Learning rate: 0.00019996682022499498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 8.3884	Cost: 36.22s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 8.4242	Cost: 10.01s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 8.2971	Cost: 22.68s
Train Epoch: 83 	Average Loss: 8.4371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4210

Learning rate: 0.0001999660060737934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 8.4484	Cost: 36.74s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 8.4479	Cost: 9.54s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 8.2340	Cost: 23.68s
Train Epoch: 84 	Average Loss: 8.3811
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3106

Saving model as e84_model.pt & e84_waveforms_supplementary.hdf5
Learning rate: 0.00019996518205634255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 8.4094	Cost: 36.70s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 8.3202	Cost: 9.67s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 8.2449	Cost: 20.96s
Train Epoch: 85 	Average Loss: 8.3504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4280

Learning rate: 0.0001999643481727238
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 8.4361	Cost: 36.66s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 8.4174	Cost: 9.46s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 8.1572	Cost: 18.82s
Train Epoch: 86 	Average Loss: 8.3403
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3136

Learning rate: 0.0001999635044230194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 8.2651	Cost: 37.73s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 8.2332	Cost: 9.43s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 8.1184	Cost: 18.59s
Train Epoch: 87 	Average Loss: 8.2630
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3924

Learning rate: 0.00019996265080731267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 8.3855	Cost: 37.74s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 8.2399	Cost: 9.48s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 8.2442	Cost: 19.92s
Train Epoch: 88 	Average Loss: 8.2887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4259

Learning rate: 0.00019996178732568782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 8.2855	Cost: 39.36s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 8.2861	Cost: 9.66s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 8.1611	Cost: 19.89s
Train Epoch: 89 	Average Loss: 8.2594
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3065

Saving model as e89_model.pt & e89_waveforms_supplementary.hdf5
Learning rate: 0.00019996091397823007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 8.3773	Cost: 35.23s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 8.2297	Cost: 9.55s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 8.1105	Cost: 18.24s
Train Epoch: 90 	Average Loss: 8.2743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2930

Saving model as e90_model.pt & e90_waveforms_supplementary.hdf5
Learning rate: 0.00019996003076502562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 8.2132	Cost: 39.11s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 8.2743	Cost: 9.45s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 8.1803	Cost: 20.92s
Train Epoch: 91 	Average Loss: 8.1878
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2515

Saving model as e91_model.pt & e91_waveforms_supplementary.hdf5
Learning rate: 0.0001999591376861617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 8.2384	Cost: 38.67s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 8.1688	Cost: 9.88s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 8.0613	Cost: 19.87s
Train Epoch: 92 	Average Loss: 8.1532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1598

Saving model as e92_model.pt & e92_waveforms_supplementary.hdf5
Learning rate: 0.0001999582347417264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 8.2110	Cost: 36.36s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 8.2045	Cost: 9.45s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 8.2493	Cost: 22.13s
Train Epoch: 93 	Average Loss: 8.1951
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2034

Learning rate: 0.00019995732193180883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 8.1109	Cost: 35.55s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 8.1581	Cost: 9.59s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 8.0892	Cost: 23.46s
Train Epoch: 94 	Average Loss: 8.1507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2451

Learning rate: 0.00019995639925649909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 8.2248	Cost: 37.04s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 8.0857	Cost: 9.79s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 8.0884	Cost: 23.02s
Train Epoch: 95 	Average Loss: 8.1026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1470

Saving model as e95_model.pt & e95_waveforms_supplementary.hdf5
Learning rate: 0.00019995546671588827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 8.0049	Cost: 37.56s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 8.1481	Cost: 9.46s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 8.1156	Cost: 19.43s
Train Epoch: 96 	Average Loss: 8.1268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0392

Saving model as e96_model.pt & e96_waveforms_supplementary.hdf5
Learning rate: 0.0001999545243100684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 8.0576	Cost: 36.87s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 8.0143	Cost: 9.50s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 7.9880	Cost: 17.99s
Train Epoch: 97 	Average Loss: 8.0734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0833

Learning rate: 0.00019995357203913245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 8.0928	Cost: 36.51s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 8.1967	Cost: 9.50s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 7.9262	Cost: 17.68s
Train Epoch: 98 	Average Loss: 8.0364
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0250

Saving model as e98_model.pt & e98_waveforms_supplementary.hdf5
Learning rate: 0.00019995260990317447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 8.0527	Cost: 36.56s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 7.9922	Cost: 9.67s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 7.8898	Cost: 18.12s
Train Epoch: 99 	Average Loss: 7.9956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0380

Learning rate: 0.00019995163790228936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 7.9949	Cost: 36.64s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 8.0875	Cost: 9.79s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 7.9425	Cost: 17.51s
Train Epoch: 100 	Average Loss: 8.0642
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1394

Learning rate: 0.0001999506560365731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 8.0163	Cost: 39.82s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 7.9850	Cost: 9.79s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 7.9081	Cost: 17.31s
Train Epoch: 101 	Average Loss: 7.9944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0357

Learning rate: 0.00019994966430612258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 7.9678	Cost: 37.90s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 7.9745	Cost: 9.76s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 7.9517	Cost: 19.98s
Train Epoch: 102 	Average Loss: 7.9574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0126

Saving model as e102_model.pt & e102_waveforms_supplementary.hdf5
Learning rate: 0.00019994866271103568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 8.0756	Cost: 37.76s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 7.9079	Cost: 9.63s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 7.8948	Cost: 19.05s
Train Epoch: 103 	Average Loss: 7.8987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0416

Learning rate: 0.0001999476512514112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 7.8952	Cost: 35.22s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 7.9301	Cost: 9.79s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 7.8880	Cost: 19.48s
Train Epoch: 104 	Average Loss: 7.9019
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9849

Saving model as e104_model.pt & e104_waveforms_supplementary.hdf5
Learning rate: 0.00019994662992734905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 8.0447	Cost: 37.11s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 7.8608	Cost: 9.81s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 7.8009	Cost: 22.24s
Train Epoch: 105 	Average Loss: 7.8771
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9002

Saving model as e105_model.pt & e105_waveforms_supplementary.hdf5
Learning rate: 0.00019994559873894998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 8.0067	Cost: 36.20s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 7.8383	Cost: 9.61s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 7.8628	Cost: 24.09s
Train Epoch: 106 	Average Loss: 7.8301
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8440

Saving model as e106_model.pt & e106_waveforms_supplementary.hdf5
Learning rate: 0.00019994455768631577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 7.8366	Cost: 37.35s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 7.7779	Cost: 9.71s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 7.8295	Cost: 23.05s
Train Epoch: 107 	Average Loss: 7.8472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9605

Learning rate: 0.00019994350676954918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 7.8924	Cost: 36.49s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 7.7931	Cost: 9.63s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 7.6587	Cost: 21.14s
Train Epoch: 108 	Average Loss: 7.8042
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8287

Saving model as e108_model.pt & e108_waveforms_supplementary.hdf5
Learning rate: 0.00019994244598875392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 7.9082	Cost: 38.08s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 7.7540	Cost: 9.47s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 7.6933	Cost: 18.07s
Train Epoch: 109 	Average Loss: 7.7926
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7914

Saving model as e109_model.pt & e109_waveforms_supplementary.hdf5
Learning rate: 0.00019994137534403472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 7.8963	Cost: 38.83s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 7.7919	Cost: 9.56s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 7.7901	Cost: 20.87s
Train Epoch: 110 	Average Loss: 7.7479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8005

Learning rate: 0.00019994029483549723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 7.7489	Cost: 36.33s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 7.7809	Cost: 9.60s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 7.7591	Cost: 17.79s
Train Epoch: 111 	Average Loss: 7.7860
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7377

Saving model as e111_model.pt & e111_waveforms_supplementary.hdf5
Learning rate: 0.00019993920446324803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 7.8582	Cost: 38.04s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 7.8106	Cost: 9.92s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 7.6417	Cost: 17.54s
Train Epoch: 112 	Average Loss: 7.7598
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8469

Learning rate: 0.00019993810422739487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 7.8515	Cost: 35.71s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 7.8300	Cost: 10.21s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 7.6470	Cost: 17.15s
Train Epoch: 113 	Average Loss: 7.7319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8327

Learning rate: 0.00019993699412804622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 7.8138	Cost: 38.27s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 7.7061	Cost: 9.86s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 7.7908	Cost: 18.83s
Train Epoch: 114 	Average Loss: 7.7613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8052

Learning rate: 0.00019993587416531166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 7.8573	Cost: 38.84s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 7.7224	Cost: 9.97s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 7.5243	Cost: 20.34s
Train Epoch: 115 	Average Loss: 7.6946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7058

Saving model as e115_model.pt & e115_waveforms_supplementary.hdf5
Learning rate: 0.00019993474433930176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 7.8126	Cost: 36.75s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 7.6702	Cost: 9.69s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 7.6170	Cost: 22.27s
Train Epoch: 116 	Average Loss: 7.6480
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7019

Saving model as e116_model.pt & e116_waveforms_supplementary.hdf5
Learning rate: 0.000199933604650128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 7.7377	Cost: 35.15s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 7.6315	Cost: 9.70s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 7.5003	Cost: 23.35s
Train Epoch: 117 	Average Loss: 7.6388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6636

Saving model as e117_model.pt & e117_waveforms_supplementary.hdf5
Learning rate: 0.0001999324550979029
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 7.6814	Cost: 37.07s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 7.6635	Cost: 9.55s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 7.7642	Cost: 22.61s
Train Epoch: 118 	Average Loss: 7.6874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9378

Learning rate: 0.00019993129568273988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 7.9707	Cost: 36.98s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 7.7145	Cost: 9.48s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 7.6126	Cost: 20.56s
Train Epoch: 119 	Average Loss: 7.7053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7040

Learning rate: 0.0001999301264047534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 7.7047	Cost: 37.83s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 7.5842	Cost: 9.47s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 7.7287	Cost: 19.46s
Train Epoch: 120 	Average Loss: 7.6355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5803

Saving model as e120_model.pt & e120_waveforms_supplementary.hdf5
Learning rate: 0.00019992894726405882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 7.6224	Cost: 39.69s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 7.5610	Cost: 9.45s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 7.7336	Cost: 18.99s
Train Epoch: 121 	Average Loss: 7.5811
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7851

Learning rate: 0.00019992775826077256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 7.8408	Cost: 37.16s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 7.6947	Cost: 9.51s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 7.5186	Cost: 18.16s
Train Epoch: 122 	Average Loss: 7.6718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6964

Learning rate: 0.00019992655939501196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 7.5967	Cost: 36.06s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 7.6052	Cost: 9.66s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 7.5140	Cost: 18.23s
Train Epoch: 123 	Average Loss: 7.5462
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6703

Learning rate: 0.00019992535066689534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 7.5829	Cost: 40.42s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 7.5014	Cost: 9.77s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 7.4874	Cost: 18.83s
Train Epoch: 124 	Average Loss: 7.5634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5730

Saving model as e124_model.pt & e124_waveforms_supplementary.hdf5
Learning rate: 0.00019992413207654198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 7.5886	Cost: 34.61s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 7.5935	Cost: 9.66s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 7.7196	Cost: 17.93s
Train Epoch: 125 	Average Loss: 7.6001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6161

Learning rate: 0.0001999229036240722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 7.6921	Cost: 37.21s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 7.6814	Cost: 9.84s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 7.5567	Cost: 19.22s
Train Epoch: 126 	Average Loss: 7.5801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5608

Saving model as e126_model.pt & e126_waveforms_supplementary.hdf5
Learning rate: 0.0001999216653096072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 7.5053	Cost: 38.80s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 7.4785	Cost: 9.55s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 7.4598	Cost: 20.52s
Train Epoch: 127 	Average Loss: 7.4874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5468

Saving model as e127_model.pt & e127_waveforms_supplementary.hdf5
Learning rate: 0.00019992041713326917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 7.6100	Cost: 36.87s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 7.4776	Cost: 10.08s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 7.4029	Cost: 22.64s
Train Epoch: 128 	Average Loss: 7.4956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5380

Saving model as e128_model.pt & e128_waveforms_supplementary.hdf5
Learning rate: 0.00019991915909518135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 7.4767	Cost: 35.95s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 7.4137	Cost: 9.55s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 7.4201	Cost: 23.61s
Train Epoch: 129 	Average Loss: 7.4738
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5463

Learning rate: 0.0001999178911954679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 7.5390	Cost: 37.53s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 7.5550	Cost: 9.50s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 7.3970	Cost: 22.52s
Train Epoch: 130 	Average Loss: 7.4668
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6834

Learning rate: 0.0001999166134342539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 7.7419	Cost: 36.95s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 7.6340	Cost: 9.46s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 7.3532	Cost: 18.28s
Train Epoch: 131 	Average Loss: 7.5141
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5600

Learning rate: 0.00019991532581166554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 7.6170	Cost: 37.85s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 7.5045	Cost: 9.46s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 7.3947	Cost: 18.29s
Train Epoch: 132 	Average Loss: 7.4462
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4651

Saving model as e132_model.pt & e132_waveforms_supplementary.hdf5
Learning rate: 0.00019991402832782987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 7.5269	Cost: 37.05s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 7.3799	Cost: 9.54s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 7.3059	Cost: 18.58s
Train Epoch: 133 	Average Loss: 7.4248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4756

Learning rate: 0.00019991272098287494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 7.4334	Cost: 36.90s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 7.4398	Cost: 9.94s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 7.3657	Cost: 18.06s
Train Epoch: 134 	Average Loss: 7.4670
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4911

Learning rate: 0.00019991140377692977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 7.5402	Cost: 40.27s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 7.3586	Cost: 9.74s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 7.2944	Cost: 18.66s
Train Epoch: 135 	Average Loss: 7.3977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4998

Learning rate: 0.0001999100767101244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 7.4810	Cost: 35.23s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 7.4333	Cost: 10.23s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 7.4360	Cost: 18.22s
Train Epoch: 136 	Average Loss: 7.3818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4452

Saving model as e136_model.pt & e136_waveforms_supplementary.hdf5
Learning rate: 0.00019990873978258976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 7.4332	Cost: 38.33s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 7.3664	Cost: 9.68s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 7.3613	Cost: 20.29s
Train Epoch: 137 	Average Loss: 7.3770
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4250

Saving model as e137_model.pt & e137_waveforms_supplementary.hdf5
Learning rate: 0.0001999073929944578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 7.5033	Cost: 38.53s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 7.3204	Cost: 9.58s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 7.2747	Cost: 20.98s
Train Epoch: 138 	Average Loss: 7.3377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4348

Learning rate: 0.00019990603634586154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 7.4008	Cost: 37.55s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 7.3542	Cost: 9.94s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 7.2169	Cost: 22.28s
Train Epoch: 139 	Average Loss: 7.3270
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4417

Learning rate: 0.00019990466983693474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 7.4091	Cost: 36.33s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 7.3022	Cost: 9.62s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 7.2191	Cost: 23.97s
Train Epoch: 140 	Average Loss: 7.3193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4798

Learning rate: 0.00019990329346781236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 7.4520	Cost: 35.68s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 7.3068	Cost: 9.55s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 7.1510	Cost: 23.15s
Train Epoch: 141 	Average Loss: 7.2834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4392

Learning rate: 0.00019990190723863022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 7.5012	Cost: 36.42s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 7.2863	Cost: 9.51s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 7.1509	Cost: 21.96s
Train Epoch: 142 	Average Loss: 7.3000
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4120

Saving model as e142_model.pt & e142_waveforms_supplementary.hdf5
Learning rate: 0.00019990051114952508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 7.4764	Cost: 38.00s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 7.2565	Cost: 9.44s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 7.1927	Cost: 18.29s
Train Epoch: 143 	Average Loss: 7.3030
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5856

Learning rate: 0.0001998991052006348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 7.5575	Cost: 38.86s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 7.3151	Cost: 9.54s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 7.1546	Cost: 17.84s
Train Epoch: 144 	Average Loss: 7.3362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4695

Learning rate: 0.0001998976893920981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 7.5218	Cost: 37.30s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 7.4033	Cost: 9.66s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 7.2569	Cost: 19.55s
Train Epoch: 145 	Average Loss: 7.3413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4164

Learning rate: 0.00019989626372405477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 7.4234	Cost: 35.90s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 7.2007	Cost: 9.65s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 7.0978	Cost: 19.08s
Train Epoch: 146 	Average Loss: 7.2631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5325

Learning rate: 0.00019989482819664545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 7.4746	Cost: 38.67s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 7.2795	Cost: 10.27s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 7.1785	Cost: 19.95s
Train Epoch: 147 	Average Loss: 7.2040
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3174

Saving model as e147_model.pt & e147_waveforms_supplementary.hdf5
Learning rate: 0.00019989338281001189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 7.3426	Cost: 38.23s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 7.2404	Cost: 9.64s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 7.0812	Cost: 20.83s
Train Epoch: 148 	Average Loss: 7.2291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3153

Saving model as e148_model.pt & e148_waveforms_supplementary.hdf5
Learning rate: 0.00019989192756429667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 7.2593	Cost: 38.37s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 7.2203	Cost: 9.67s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 7.2111	Cost: 19.83s
Train Epoch: 149 	Average Loss: 7.2574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3466

Learning rate: 0.00019989046245964345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 7.3220	Cost: 36.60s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 7.2003	Cost: 9.77s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 7.1150	Cost: 21.03s
Train Epoch: 150 	Average Loss: 7.1776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2823

Saving model as e150_model.pt & e150_waveforms_supplementary.hdf5
Learning rate: 0.00019988898749619688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 7.2601	Cost: 36.72s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 7.0722	Cost: 9.82s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 7.0585	Cost: 23.18s
Train Epoch: 151 	Average Loss: 7.1724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3025

Learning rate: 0.00019988750267410245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 7.3362	Cost: 35.10s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 7.0995	Cost: 9.57s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 7.0809	Cost: 23.77s
Train Epoch: 152 	Average Loss: 7.1596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5187

Learning rate: 0.0001998860079935067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 7.3313	Cost: 36.70s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 7.1775	Cost: 9.55s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 7.0509	Cost: 23.16s
Train Epoch: 153 	Average Loss: 7.1589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2165

Saving model as e153_model.pt & e153_waveforms_supplementary.hdf5
Learning rate: 0.00019988450345455726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 7.2460	Cost: 37.36s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 7.2511	Cost: 9.47s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 7.1194	Cost: 20.09s
Train Epoch: 154 	Average Loss: 7.2059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3330

Learning rate: 0.00019988298905740252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 7.3549	Cost: 36.62s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 7.2192	Cost: 9.45s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 7.0096	Cost: 18.68s
Train Epoch: 155 	Average Loss: 7.1509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2646

Learning rate: 0.000199881464802192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 7.2900	Cost: 37.64s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 7.1849	Cost: 9.49s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 7.0986	Cost: 18.32s
Train Epoch: 156 	Average Loss: 7.1666
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2532

Learning rate: 0.0001998799306890761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 7.2885	Cost: 37.53s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 7.0815	Cost: 9.46s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 6.9103	Cost: 18.02s
Train Epoch: 157 	Average Loss: 7.0965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2154

Saving model as e157_model.pt & e157_waveforms_supplementary.hdf5
Learning rate: 0.00019987838671820622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 7.3874	Cost: 36.30s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 7.0658	Cost: 9.65s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 7.1308	Cost: 18.48s
Train Epoch: 158 	Average Loss: 7.1142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2585

Learning rate: 0.00019987683288973478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 7.2148	Cost: 36.38s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 7.1212	Cost: 9.64s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 7.0467	Cost: 17.72s
Train Epoch: 159 	Average Loss: 7.0772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2387

Learning rate: 0.00019987526920381513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 7.2380	Cost: 38.93s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 7.0966	Cost: 9.46s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 7.0847	Cost: 21.21s
Train Epoch: 160 	Average Loss: 7.0765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1594

Saving model as e160_model.pt & e160_waveforms_supplementary.hdf5
Learning rate: 0.00019987369566060162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 7.1763	Cost: 35.85s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 7.1135	Cost: 9.56s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 6.9803	Cost: 17.62s
Train Epoch: 161 	Average Loss: 7.0840
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2189

Learning rate: 0.0001998721122602495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 7.2219	Cost: 38.50s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 7.0693	Cost: 9.90s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 6.9812	Cost: 18.57s
Train Epoch: 162 	Average Loss: 7.0705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2064

Learning rate: 0.00019987051900291508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 7.2666	Cost: 35.37s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 7.0881	Cost: 9.51s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 6.9729	Cost: 19.34s
Train Epoch: 163 	Average Loss: 7.0549
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1993

Learning rate: 0.00019986891588875562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 7.0820	Cost: 35.07s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 7.0777	Cost: 10.16s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 6.8911	Cost: 19.91s
Train Epoch: 164 	Average Loss: 7.0257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2309

Learning rate: 0.0001998673029179293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 7.1604	Cost: 37.96s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 7.0330	Cost: 9.96s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 6.9990	Cost: 21.66s
Train Epoch: 165 	Average Loss: 7.0354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2298

Learning rate: 0.00019986568009059536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 7.2231	Cost: 37.29s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 7.0746	Cost: 9.75s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 6.8386	Cost: 22.97s
Train Epoch: 166 	Average Loss: 7.0119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1444

Saving model as e166_model.pt & e166_waveforms_supplementary.hdf5
Learning rate: 0.00019986404740691393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 7.2049	Cost: 36.34s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 6.9575	Cost: 9.59s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 6.9492	Cost: 23.56s
Train Epoch: 167 	Average Loss: 7.0064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1807

Learning rate: 0.00019986240486704617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 7.1392	Cost: 36.50s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 6.9659	Cost: 9.55s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 6.8389	Cost: 22.82s
Train Epoch: 168 	Average Loss: 6.9784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1432

Saving model as e168_model.pt & e168_waveforms_supplementary.hdf5
Learning rate: 0.00019986075247115415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 7.1434	Cost: 37.25s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 7.0076	Cost: 9.46s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 6.8464	Cost: 19.08s
Train Epoch: 169 	Average Loss: 6.9864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1068

Saving model as e169_model.pt & e169_waveforms_supplementary.hdf5
Learning rate: 0.00019985909021940103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 7.1175	Cost: 39.37s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 6.9504	Cost: 9.75s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 6.8527	Cost: 17.91s
Train Epoch: 170 	Average Loss: 6.9578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1007

Saving model as e170_model.pt & e170_waveforms_supplementary.hdf5
Learning rate: 0.0001998574181119508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 7.0579	Cost: 39.87s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 6.8994	Cost: 9.48s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 6.8691	Cost: 20.30s
Train Epoch: 171 	Average Loss: 6.9232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0621

Saving model as e171_model.pt & e171_waveforms_supplementary.hdf5
Learning rate: 0.00019985573614896853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 7.0759	Cost: 35.86s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 6.9137	Cost: 9.98s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 6.8264	Cost: 17.31s
Train Epoch: 172 	Average Loss: 6.9211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0480

Saving model as e172_model.pt & e172_waveforms_supplementary.hdf5
Learning rate: 0.00019985404433062024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 6.9754	Cost: 36.11s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 6.8879	Cost: 9.85s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 6.8499	Cost: 18.30s
Train Epoch: 173 	Average Loss: 6.8953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0538

Learning rate: 0.00019985234265707287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 7.0345	Cost: 38.71s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 6.8230	Cost: 9.79s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 6.8291	Cost: 20.73s
Train Epoch: 174 	Average Loss: 6.8984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0578

Learning rate: 0.00019985063112849436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 7.0513	Cost: 34.92s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 6.8174	Cost: 9.71s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 6.7899	Cost: 18.34s
Train Epoch: 175 	Average Loss: 6.8975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0050

Saving model as e175_model.pt & e175_waveforms_supplementary.hdf5
Learning rate: 0.00019984890974505368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 7.0897	Cost: 35.09s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 6.8801	Cost: 9.61s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 6.7806	Cost: 21.02s
Train Epoch: 176 	Average Loss: 6.8810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0838

Learning rate: 0.00019984717850692066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 7.0750	Cost: 35.06s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 6.9080	Cost: 9.59s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 6.8392	Cost: 22.42s
Train Epoch: 177 	Average Loss: 6.8980
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9735

Saving model as e177_model.pt & e177_waveforms_supplementary.hdf5
Learning rate: 0.00019984543741426617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 7.0879	Cost: 35.03s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 6.8180	Cost: 9.92s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 6.7138	Cost: 21.72s
Train Epoch: 178 	Average Loss: 6.8387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1083

Learning rate: 0.0001998436864672621
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 7.0263	Cost: 37.02s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 6.9722	Cost: 9.78s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 6.7645	Cost: 23.65s
Train Epoch: 179 	Average Loss: 6.8417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0233

Learning rate: 0.00019984192566608125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 6.9982	Cost: 36.11s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 6.6767	Cost: 9.53s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 6.6800	Cost: 24.35s
Train Epoch: 180 	Average Loss: 6.8256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9576

Saving model as e180_model.pt & e180_waveforms_supplementary.hdf5
Learning rate: 0.00019984015501089739
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 7.1179	Cost: 37.41s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 6.8515	Cost: 9.49s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 6.7743	Cost: 21.55s
Train Epoch: 181 	Average Loss: 6.8226
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0752

Learning rate: 0.00019983837450188524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 7.0531	Cost: 36.96s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 6.7881	Cost: 9.45s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 6.7094	Cost: 18.35s
Train Epoch: 182 	Average Loss: 6.7839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9855

Learning rate: 0.0001998365841392206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 7.0330	Cost: 38.57s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 6.8089	Cost: 9.56s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 6.7078	Cost: 19.33s
Train Epoch: 183 	Average Loss: 6.7911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9990

Learning rate: 0.00019983478392308012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 7.0671	Cost: 39.19s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 6.8467	Cost: 9.46s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 6.7162	Cost: 20.11s
Train Epoch: 184 	Average Loss: 6.7812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9374

Saving model as e184_model.pt & e184_waveforms_supplementary.hdf5
Learning rate: 0.0001998329738536415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 7.0313	Cost: 37.00s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 6.8274	Cost: 9.67s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 6.7333	Cost: 20.27s
Train Epoch: 185 	Average Loss: 6.8254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9726

Learning rate: 0.00019983115393108338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 7.0323	Cost: 36.72s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 6.7172	Cost: 9.63s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 6.6231	Cost: 20.98s
Train Epoch: 186 	Average Loss: 6.7637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8996

Saving model as e186_model.pt & e186_waveforms_supplementary.hdf5
Learning rate: 0.0001998293241555854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 6.9345	Cost: 39.11s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 6.6825	Cost: 9.57s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 6.7205	Cost: 20.40s
Train Epoch: 187 	Average Loss: 6.7481
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9680

Learning rate: 0.0001998274845273281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 7.0004	Cost: 35.09s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 6.8141	Cost: 10.07s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 6.6537	Cost: 16.96s
Train Epoch: 188 	Average Loss: 6.8248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0714

Learning rate: 0.00019982563504649309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 7.1241	Cost: 38.58s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 6.7232	Cost: 9.65s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 6.6857	Cost: 21.16s
Train Epoch: 189 	Average Loss: 6.7753
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9552

Learning rate: 0.00019982377571326284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 6.8626	Cost: 38.14s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 6.6700	Cost: 10.26s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 6.5316	Cost: 20.81s
Train Epoch: 190 	Average Loss: 6.6589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8941

Saving model as e190_model.pt & e190_waveforms_supplementary.hdf5
Learning rate: 0.00019982190652782097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 7.0079	Cost: 37.34s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 6.7185	Cost: 9.81s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 6.5238	Cost: 23.11s
Train Epoch: 191 	Average Loss: 6.6888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0096

Learning rate: 0.0001998200274903519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 7.0480	Cost: 36.44s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 6.6824	Cost: 9.60s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 6.5488	Cost: 24.28s
Train Epoch: 192 	Average Loss: 6.6867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9160

Learning rate: 0.00019981813860104106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 6.9131	Cost: 37.37s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 6.5074	Cost: 9.54s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 6.5757	Cost: 22.75s
Train Epoch: 193 	Average Loss: 6.6606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9406

Learning rate: 0.0001998162398600749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 6.8514	Cost: 36.93s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 6.6653	Cost: 9.46s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 6.6999	Cost: 20.94s
Train Epoch: 194 	Average Loss: 6.6773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9552

Learning rate: 0.00019981433126764085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 6.9003	Cost: 36.68s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 6.5758	Cost: 9.44s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 6.6074	Cost: 18.75s
Train Epoch: 195 	Average Loss: 6.6300
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8834

Saving model as e195_model.pt & e195_waveforms_supplementary.hdf5
Learning rate: 0.00019981241282392723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 6.9182	Cost: 37.27s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 6.6731	Cost: 9.52s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 6.4611	Cost: 18.25s
Train Epoch: 196 	Average Loss: 6.6237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9436

Learning rate: 0.0001998104845291234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 6.8832	Cost: 36.33s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 6.5064	Cost: 9.57s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 6.4428	Cost: 19.93s
Train Epoch: 197 	Average Loss: 6.5922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8653

Saving model as e197_model.pt & e197_waveforms_supplementary.hdf5
Learning rate: 0.00019980854638341968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 6.8533	Cost: 40.58s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 6.4501	Cost: 9.59s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 6.3950	Cost: 17.92s
Train Epoch: 198 	Average Loss: 6.5861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8536

Saving model as e198_model.pt & e198_waveforms_supplementary.hdf5
Learning rate: 0.00019980659838700736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 6.8695	Cost: 39.21s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 6.5929	Cost: 9.62s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 6.5118	Cost: 20.48s
Train Epoch: 199 	Average Loss: 6.5881
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8412

Saving model as e199_model.pt & e199_waveforms_supplementary.hdf5
Learning rate: 0.0001998046405400787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 6.7243	Cost: 35.14s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 6.5297	Cost: 9.71s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 6.4120	Cost: 17.89s
Train Epoch: 200 	Average Loss: 6.5685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8260

Saving model as e200_model.pt & e200_waveforms_supplementary.hdf5
Learning rate: 0.00019980267284282693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 6.8098	Cost: 34.98s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 6.5519	Cost: 10.11s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 6.4130	Cost: 19.98s
Train Epoch: 201 	Average Loss: 6.5461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7710

Saving model as e201_model.pt & e201_waveforms_supplementary.hdf5
Learning rate: 0.00019980069529544622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 6.6381	Cost: 37.51s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 6.5492	Cost: 9.72s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 6.5084	Cost: 22.91s
Train Epoch: 202 	Average Loss: 6.5452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9147

Learning rate: 0.0001997987078981318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 6.7032	Cost: 34.79s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 6.5015	Cost: 9.63s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 6.5041	Cost: 24.14s
Train Epoch: 203 	Average Loss: 6.5985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7867

Learning rate: 0.00019979671065107978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 6.8009	Cost: 35.69s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 6.4434	Cost: 9.53s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 6.3896	Cost: 23.43s
Train Epoch: 204 	Average Loss: 6.5160
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8013

Learning rate: 0.0001997947035544873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 6.7052	Cost: 37.25s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 6.4797	Cost: 9.50s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 6.3482	Cost: 21.33s
Train Epoch: 205 	Average Loss: 6.5185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7825

Learning rate: 0.00019979268660855247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 6.8923	Cost: 37.21s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 6.4596	Cost: 9.45s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 6.3996	Cost: 18.66s
Train Epoch: 206 	Average Loss: 6.4921
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7939

Learning rate: 0.00019979065981347432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 6.7652	Cost: 37.87s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 6.5204	Cost: 9.51s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 6.3845	Cost: 18.24s
Train Epoch: 207 	Average Loss: 6.4880
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7514

Saving model as e207_model.pt & e207_waveforms_supplementary.hdf5
Learning rate: 0.0001997886231694529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 6.9374	Cost: 36.54s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 6.6151	Cost: 9.57s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 6.3597	Cost: 17.98s
Train Epoch: 208 	Average Loss: 6.5498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7427

Saving model as e208_model.pt & e208_waveforms_supplementary.hdf5
Learning rate: 0.0001997865766766892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 6.6940	Cost: 40.27s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 6.4566	Cost: 9.84s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 6.3195	Cost: 19.08s
Train Epoch: 209 	Average Loss: 6.4472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7036

Saving model as e209_model.pt & e209_waveforms_supplementary.hdf5
Learning rate: 0.00019978452033538524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 6.7642	Cost: 36.27s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 6.4338	Cost: 10.29s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 6.3906	Cost: 17.38s
Train Epoch: 210 	Average Loss: 6.4613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7225

Learning rate: 0.00019978245414574395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 6.6464	Cost: 37.88s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 6.3972	Cost: 9.95s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 6.2740	Cost: 22.90s
Train Epoch: 211 	Average Loss: 6.4139
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6913

Saving model as e211_model.pt & e211_waveforms_supplementary.hdf5
Learning rate: 0.00019978037810796924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 6.6796	Cost: 36.37s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 6.3732	Cost: 9.67s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 6.3295	Cost: 19.20s
Train Epoch: 212 	Average Loss: 6.4256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7435

Learning rate: 0.000199778292222266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 6.7290	Cost: 39.13s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 6.4588	Cost: 9.50s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 6.2678	Cost: 22.30s
Train Epoch: 213 	Average Loss: 6.4401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7859

Learning rate: 0.00019977619648884015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 6.8317	Cost: 37.88s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 6.3582	Cost: 9.53s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 6.3148	Cost: 24.03s
Train Epoch: 214 	Average Loss: 6.4137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6921

Learning rate: 0.0001997740909078985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 6.6918	Cost: 37.31s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 6.3891	Cost: 9.57s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 6.1739	Cost: 23.59s
Train Epoch: 215 	Average Loss: 6.3355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6003

Saving model as e215_model.pt & e215_waveforms_supplementary.hdf5
Learning rate: 0.0001997719754796489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 6.6593	Cost: 37.96s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 6.3672	Cost: 10.08s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 6.2249	Cost: 20.08s
Train Epoch: 216 	Average Loss: 6.3487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6404

Learning rate: 0.00019976985020430003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 6.6245	Cost: 46.50s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 6.4567	Cost: 16.11s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 6.2163	Cost: 15.19s
Train Epoch: 217 	Average Loss: 6.3135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6487

Learning rate: 0.00019976771508206176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 6.6960	Cost: 54.37s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 6.2684	Cost: 10.02s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 6.1237	Cost: 20.16s
Train Epoch: 218 	Average Loss: 6.3237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6217

Learning rate: 0.00019976557011314476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 6.6653	Cost: 38.63s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 6.2301	Cost: 9.74s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 6.1964	Cost: 31.95s
Train Epoch: 219 	Average Loss: 6.3099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5359

Saving model as e219_model.pt & e219_waveforms_supplementary.hdf5
Learning rate: 0.00019976341529776072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 6.7847	Cost: 43.31s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 6.2567	Cost: 16.87s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 6.2291	Cost: 21.77s
Train Epoch: 220 	Average Loss: 6.3050
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6481

Learning rate: 0.00019976125063612233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 6.7148	Cost: 45.54s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 6.2172	Cost: 14.63s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 6.1004	Cost: 22.43s
Train Epoch: 221 	Average Loss: 6.2911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6629

Learning rate: 0.00019975907612844327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 6.7181	Cost: 45.16s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 6.2492	Cost: 16.48s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 6.1934	Cost: 19.07s
Train Epoch: 222 	Average Loss: 6.3004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5934

Learning rate: 0.00019975689177493812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 6.7189	Cost: 57.04s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 6.2290	Cost: 15.49s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 6.1832	Cost: 16.98s
Train Epoch: 223 	Average Loss: 6.2849
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6265

Learning rate: 0.00019975469757582245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 6.7211	Cost: 41.98s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 6.3649	Cost: 9.57s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 6.1195	Cost: 24.22s
Train Epoch: 224 	Average Loss: 6.2698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5439

Learning rate: 0.00019975249353131286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 6.5488	Cost: 38.85s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 6.5054	Cost: 11.77s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 6.1229	Cost: 21.18s
Train Epoch: 225 	Average Loss: 6.2823
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6253

Learning rate: 0.00019975027964162683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 6.6276	Cost: 38.97s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 6.2675	Cost: 11.16s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 6.0696	Cost: 31.02s
Train Epoch: 226 	Average Loss: 6.2271
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5031

Saving model as e226_model.pt & e226_waveforms_supplementary.hdf5
Learning rate: 0.0001997480559069829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 6.5209	Cost: 54.24s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 6.1359	Cost: 16.57s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 6.0570	Cost: 19.71s
Train Epoch: 227 	Average Loss: 6.2161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5456

Learning rate: 0.00019974582232760058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 6.4802	Cost: 47.14s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 6.0952	Cost: 16.55s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 6.2164	Cost: 16.43s
Train Epoch: 228 	Average Loss: 6.1270
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5175

Learning rate: 0.0001997435789037002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 6.6007	Cost: 44.12s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 6.1252	Cost: 14.63s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 6.0433	Cost: 14.78s
Train Epoch: 229 	Average Loss: 6.1988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5344

Learning rate: 0.0001997413256355033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 6.5814	Cost: 42.83s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 6.2600	Cost: 12.15s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 6.0709	Cost: 20.51s
Train Epoch: 230 	Average Loss: 6.1519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5093

Learning rate: 0.0001997390625232322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 6.5048	Cost: 41.96s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 6.1015	Cost: 16.16s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 6.0539	Cost: 18.13s
Train Epoch: 231 	Average Loss: 6.1227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5431

Learning rate: 0.00019973678956711026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 6.5217	Cost: 42.23s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 6.0174	Cost: 9.75s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 5.9346	Cost: 24.36s
Train Epoch: 232 	Average Loss: 6.1099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5312

Learning rate: 0.00019973450676736185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 6.6771	Cost: 42.57s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 6.0557	Cost: 9.74s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 6.0349	Cost: 30.78s
Train Epoch: 233 	Average Loss: 6.1053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5204

Learning rate: 0.00019973221412421225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 6.4224	Cost: 42.27s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 6.0860	Cost: 14.97s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 5.9273	Cost: 25.83s
Train Epoch: 234 	Average Loss: 6.0752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4033

Saving model as e234_model.pt & e234_waveforms_supplementary.hdf5
Learning rate: 0.0001997299116378877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 6.5208	Cost: 44.37s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 6.0722	Cost: 16.49s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 6.0172	Cost: 17.16s
Train Epoch: 235 	Average Loss: 6.0639
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4259

Learning rate: 0.0001997275993086155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 6.5130	Cost: 43.61s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 5.9237	Cost: 12.65s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 5.8958	Cost: 21.87s
Train Epoch: 236 	Average Loss: 6.0402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4043

Learning rate: 0.0001997252771366239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 6.4074	Cost: 42.39s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 6.0332	Cost: 17.27s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 5.8449	Cost: 15.79s
Train Epoch: 237 	Average Loss: 6.0362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4907

Learning rate: 0.000199722945122142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 6.3861	Cost: 44.04s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 5.9981	Cost: 9.68s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 5.8490	Cost: 25.20s
Train Epoch: 238 	Average Loss: 6.0411
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4421

Learning rate: 0.0001997206032654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 6.5127	Cost: 42.21s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 6.1227	Cost: 12.56s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 5.8842	Cost: 14.87s
Train Epoch: 239 	Average Loss: 6.0426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4758

Learning rate: 0.00019971825156662903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 6.3827	Cost: 38.70s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 6.0142	Cost: 9.75s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 5.8321	Cost: 31.59s
Train Epoch: 240 	Average Loss: 5.9955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5151

Learning rate: 0.00019971589002606117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 6.4531	Cost: 43.22s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 5.9982	Cost: 17.23s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 5.8142	Cost: 22.98s
Train Epoch: 241 	Average Loss: 5.9576
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4981

Learning rate: 0.00019971351864392958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 6.4412	Cost: 50.19s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 5.9345	Cost: 16.48s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 5.9349	Cost: 14.21s
Train Epoch: 242 	Average Loss: 5.9651
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4389

Learning rate: 0.00019971113742046817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 6.5183	Cost: 56.62s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 5.8576	Cost: 16.46s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 5.8133	Cost: 14.60s
Train Epoch: 243 	Average Loss: 5.9842
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4465

Learning rate: 0.00019970874635591207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 6.3964	Cost: 44.15s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 5.9406	Cost: 11.47s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 5.7248	Cost: 22.47s
Train Epoch: 244 	Average Loss: 5.9304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3091

Saving model as e244_model.pt & e244_waveforms_supplementary.hdf5
Learning rate: 0.00019970634545049727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 6.3593	Cost: 38.84s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 5.8159	Cost: 11.91s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 5.9506	Cost: 18.36s
Train Epoch: 245 	Average Loss: 5.9260
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4145

Learning rate: 0.0001997039347044607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 6.4280	Cost: 37.50s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 5.8431	Cost: 10.00s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 5.7503	Cost: 25.75s
Train Epoch: 246 	Average Loss: 5.8980
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4346

Learning rate: 0.00019970151411804023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 6.3774	Cost: 38.99s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 5.9117	Cost: 10.27s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 5.6914	Cost: 31.81s
Train Epoch: 247 	Average Loss: 5.9263
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3472

Learning rate: 0.00019969908369147485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 6.3334	Cost: 50.50s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 5.9620	Cost: 16.62s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 5.6604	Cost: 19.82s
Train Epoch: 248 	Average Loss: 5.8844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2992

Saving model as e248_model.pt & e248_waveforms_supplementary.hdf5
Learning rate: 0.00019969664342500438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 6.3908	Cost: 45.27s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 5.8417	Cost: 12.91s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 5.6981	Cost: 17.73s
Train Epoch: 249 	Average Loss: 5.8675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4429

Learning rate: 0.00019969419331886966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 6.4915	Cost: 42.52s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 5.7689	Cost: 13.49s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 5.6697	Cost: 17.80s
Train Epoch: 250 	Average Loss: 5.8427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2540

Saving model as e250_model.pt & e250_waveforms_supplementary.hdf5
Learning rate: 0.0001996917333733126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 6.2116	Cost: 40.12s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 5.7727	Cost: 9.63s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 5.7220	Cost: 24.58s
Train Epoch: 251 	Average Loss: 5.8056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3103

Learning rate: 0.00019968926358857587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 6.4292	Cost: 43.28s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 5.8069	Cost: 9.97s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 5.6269	Cost: 28.52s
Train Epoch: 252 	Average Loss: 5.8171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3230

Learning rate: 0.00019968678396490325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 6.2706	Cost: 46.17s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 5.6792	Cost: 17.15s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 5.6864	Cost: 21.49s
Train Epoch: 253 	Average Loss: 5.7916
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2845

Learning rate: 0.00019968429450253954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 6.2394	Cost: 44.47s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 5.7965	Cost: 16.51s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 5.5970	Cost: 16.61s
Train Epoch: 254 	Average Loss: 5.7940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2322

Saving model as e254_model.pt & e254_waveforms_supplementary.hdf5
Learning rate: 0.0001996817952017304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 6.2840	Cost: 44.24s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 5.7879	Cost: 12.38s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 5.5829	Cost: 21.21s
Train Epoch: 255 	Average Loss: 5.7524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2976

Learning rate: 0.00019967928606272244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 6.2222	Cost: 42.50s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 5.7736	Cost: 16.71s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 5.5286	Cost: 17.52s
Train Epoch: 256 	Average Loss: 5.7218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1988

Saving model as e256_model.pt & e256_waveforms_supplementary.hdf5
Learning rate: 0.0001996767670857634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 6.3274	Cost: 41.03s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 5.7224	Cost: 9.82s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 5.5263	Cost: 26.40s
Train Epoch: 257 	Average Loss: 5.6906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2080

Learning rate: 0.00019967423827110182
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 6.2190	Cost: 42.21s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 5.5668	Cost: 9.69s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 5.5590	Cost: 31.31s
Train Epoch: 258 	Average Loss: 5.6761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2298

Learning rate: 0.00019967169961898734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 6.3439	Cost: 42.94s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 5.6454	Cost: 17.24s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 5.4679	Cost: 22.37s
Train Epoch: 259 	Average Loss: 5.7008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2272

Learning rate: 0.00019966915112967047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 6.1687	Cost: 46.76s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 5.7928	Cost: 16.76s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 5.5462	Cost: 18.94s
Train Epoch: 260 	Average Loss: 5.7137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2158

Learning rate: 0.00019966659280340273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 6.3272	Cost: 44.76s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 5.5567	Cost: 13.44s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 5.4944	Cost: 18.58s
Train Epoch: 261 	Average Loss: 5.6697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2131

Learning rate: 0.00019966402464043667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 6.1129	Cost: 44.48s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 5.4899	Cost: 13.29s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 5.3595	Cost: 19.49s
Train Epoch: 262 	Average Loss: 5.6304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1046

Saving model as e262_model.pt & e262_waveforms_supplementary.hdf5
Learning rate: 0.00019966144664102572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 6.0297	Cost: 42.54s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 5.5863	Cost: 12.78s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 5.3466	Cost: 15.53s
Train Epoch: 263 	Average Loss: 5.6007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2348

Learning rate: 0.00019965885880542434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 6.1168	Cost: 38.84s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 5.5980	Cost: 9.73s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 5.5291	Cost: 31.77s
Train Epoch: 264 	Average Loss: 5.6625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1991

Learning rate: 0.00019965626113388794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 6.2441	Cost: 43.77s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 5.5251	Cost: 17.10s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 5.3727	Cost: 22.51s
Train Epoch: 265 	Average Loss: 5.5862
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1247

Learning rate: 0.00019965365362667288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 6.0963	Cost: 46.41s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 5.4830	Cost: 16.72s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 5.3468	Cost: 19.61s
Train Epoch: 266 	Average Loss: 5.5174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1311

Learning rate: 0.0001996510362840365
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 6.1234	Cost: 49.79s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 5.5436	Cost: 15.98s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 5.3297	Cost: 17.28s
Train Epoch: 267 	Average Loss: 5.5110
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2316

Learning rate: 0.00019964840910623716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 6.2441	Cost: 44.95s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 5.5200	Cost: 15.39s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 5.3962	Cost: 18.15s
Train Epoch: 268 	Average Loss: 5.5293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1453

Learning rate: 0.00019964577209353413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 6.0874	Cost: 42.90s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 5.4982	Cost: 9.53s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 5.4071	Cost: 24.10s
Train Epoch: 269 	Average Loss: 5.5580
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1590

Learning rate: 0.00019964312524618766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 6.0223	Cost: 37.35s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 5.4686	Cost: 12.89s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 5.2890	Cost: 20.52s
Train Epoch: 270 	Average Loss: 5.4728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9975

Saving model as e270_model.pt & e270_waveforms_supplementary.hdf5
Learning rate: 0.000199640468564459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 5.9976	Cost: 43.46s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 5.3508	Cost: 9.73s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 5.1498	Cost: 32.94s
Train Epoch: 271 	Average Loss: 5.4200
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9579

Saving model as e271_model.pt & e271_waveforms_supplementary.hdf5
Learning rate: 0.00019963780204861037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 6.0720	Cost: 45.99s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 5.6381	Cost: 15.04s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 5.3273	Cost: 17.50s
Train Epoch: 272 	Average Loss: 5.4798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0709

Learning rate: 0.0001996351256989049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 5.9364	Cost: 45.19s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 5.4475	Cost: 16.23s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 5.2738	Cost: 16.68s
Train Epoch: 273 	Average Loss: 5.4465
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9711

Learning rate: 0.0001996324395156068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 5.9128	Cost: 44.50s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 5.3736	Cost: 16.25s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 5.3157	Cost: 17.45s
Train Epoch: 274 	Average Loss: 5.4012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0068

Learning rate: 0.00019962974349898107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 5.9572	Cost: 43.12s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 5.3814	Cost: 15.17s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 5.1579	Cost: 19.41s
Train Epoch: 275 	Average Loss: 5.3946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0312

Learning rate: 0.0001996270376492939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 6.0368	Cost: 42.81s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 5.3874	Cost: 9.75s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 5.1375	Cost: 24.39s
Train Epoch: 276 	Average Loss: 5.3489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9736

Learning rate: 0.00019962432196681234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 5.9748	Cost: 41.97s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 5.2038	Cost: 9.82s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 5.1945	Cost: 30.63s
Train Epoch: 277 	Average Loss: 5.3385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9359

Saving model as e277_model.pt & e277_waveforms_supplementary.hdf5
Learning rate: 0.00019962159645180437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 5.9074	Cost: 44.68s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 5.2362	Cost: 16.72s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 5.1747	Cost: 20.20s
Train Epoch: 278 	Average Loss: 5.3184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8846

Saving model as e278_model.pt & e278_waveforms_supplementary.hdf5
Learning rate: 0.00019961886110453903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 5.9267	Cost: 44.79s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 5.2576	Cost: 16.67s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 5.1631	Cost: 17.66s
Train Epoch: 279 	Average Loss: 5.3249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1338

Learning rate: 0.00019961611592528625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 5.9505	Cost: 42.39s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 5.2375	Cost: 13.92s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 5.1138	Cost: 20.44s
Train Epoch: 280 	Average Loss: 5.3036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9293

Learning rate: 0.000199613360914317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 5.8375	Cost: 43.22s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 5.2128	Cost: 16.15s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 5.0778	Cost: 17.44s
Train Epoch: 281 	Average Loss: 5.2875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9938

Learning rate: 0.00019961059607190318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 5.8994	Cost: 42.16s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 5.3428	Cost: 9.67s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 5.1587	Cost: 23.88s
Train Epoch: 282 	Average Loss: 5.3158
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0613

Learning rate: 0.00019960782139831766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 5.8958	Cost: 39.59s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 5.1897	Cost: 13.10s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 5.0689	Cost: 16.36s
Train Epoch: 283 	Average Loss: 5.2636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9368

Learning rate: 0.00019960503689383428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 5.9740	Cost: 36.39s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 5.1601	Cost: 12.76s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 5.2168	Cost: 14.24s
Train Epoch: 284 	Average Loss: 5.2290
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9601

Learning rate: 0.0001996022425587279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 5.9372	Cost: 37.91s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 5.1015	Cost: 10.77s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 5.0132	Cost: 29.56s
Train Epoch: 285 	Average Loss: 5.1856
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8920

Learning rate: 0.0001995994383932743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 5.8250	Cost: 41.88s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 5.1359	Cost: 12.33s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 5.0832	Cost: 27.09s
Train Epoch: 286 	Average Loss: 5.1841
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8980

Learning rate: 0.0001995966243977502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 5.8442	Cost: 46.33s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 5.0958	Cost: 13.45s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 5.1188	Cost: 20.69s
Train Epoch: 287 	Average Loss: 5.1962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8763

Saving model as e287_model.pt & e287_waveforms_supplementary.hdf5
Learning rate: 0.0001995938005724334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 5.7938	Cost: 45.79s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 5.1180	Cost: 14.98s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 5.0241	Cost: 14.11s
Train Epoch: 288 	Average Loss: 5.1491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8676

Saving model as e288_model.pt & e288_waveforms_supplementary.hdf5
Learning rate: 0.00019959096691760252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 5.8439	Cost: 42.11s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 5.0526	Cost: 13.20s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 4.9679	Cost: 17.12s
Train Epoch: 289 	Average Loss: 5.1371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7950

Saving model as e289_model.pt & e289_waveforms_supplementary.hdf5
Learning rate: 0.00019958812343353726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 5.7323	Cost: 42.93s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 5.0765	Cost: 12.20s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 4.9152	Cost: 22.48s
Train Epoch: 290 	Average Loss: 5.0899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8028

Learning rate: 0.0001995852701205183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 5.8121	Cost: 40.94s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 5.1279	Cost: 12.81s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 4.8650	Cost: 20.11s
Train Epoch: 291 	Average Loss: 5.1044
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8166

Learning rate: 0.0001995824069788272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 5.7153	Cost: 41.32s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 4.9802	Cost: 10.41s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 4.8554	Cost: 29.40s
Train Epoch: 292 	Average Loss: 5.0477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8234

Learning rate: 0.00019957953400874656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 5.8034	Cost: 40.40s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 5.0539	Cost: 15.99s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 4.8278	Cost: 21.98s
Train Epoch: 293 	Average Loss: 5.0450
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8554

Learning rate: 0.00019957665121055995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 5.8936	Cost: 47.18s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 5.0137	Cost: 17.03s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 4.7460	Cost: 17.25s
Train Epoch: 294 	Average Loss: 5.0078
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7826

Saving model as e294_model.pt & e294_waveforms_supplementary.hdf5
Learning rate: 0.00019957375858455185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 5.7571	Cost: 46.38s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 4.9279	Cost: 12.36s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 4.7382	Cost: 21.00s
Train Epoch: 295 	Average Loss: 4.9788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7043

Saving model as e295_model.pt & e295_waveforms_supplementary.hdf5
Learning rate: 0.00019957085613100776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 5.7281	Cost: 42.99s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 5.0805	Cost: 16.18s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 4.7386	Cost: 17.31s
Train Epoch: 296 	Average Loss: 4.9770
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7447

Learning rate: 0.00019956794385021415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 5.8466	Cost: 43.52s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 4.8787	Cost: 9.68s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 4.7469	Cost: 22.03s
Train Epoch: 297 	Average Loss: 4.9765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7307

Learning rate: 0.00019956502174245846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 5.7238	Cost: 40.01s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 4.9014	Cost: 9.85s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 4.6684	Cost: 30.02s
Train Epoch: 298 	Average Loss: 4.9459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8175

Learning rate: 0.0001995620898080291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 5.9030	Cost: 43.30s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 4.8721	Cost: 17.09s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 4.6586	Cost: 20.41s
Train Epoch: 299 	Average Loss: 4.9342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6901

Saving model as e299_model.pt & e299_waveforms_supplementary.hdf5
Learning rate: 0.00019955914804721542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 5.6723	Cost: 44.17s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 4.8182	Cost: 16.82s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 4.8008	Cost: 17.48s
Train Epoch: 300 	Average Loss: 4.8949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7586

Learning rate: 0.00019955619646030775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 5.8017	Cost: 44.07s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 4.8639	Cost: 13.59s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 4.6387	Cost: 18.75s
Train Epoch: 301 	Average Loss: 4.9010
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6370

Saving model as e301_model.pt & e301_waveforms_supplementary.hdf5
Learning rate: 0.0001995532350475974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 5.5954	Cost: 43.27s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 4.7491	Cost: 11.75s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 4.6686	Cost: 22.81s
Train Epoch: 302 	Average Loss: 4.8449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6689

Learning rate: 0.00019955026380937669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 5.6803	Cost: 47.21s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 4.8318	Cost: 12.79s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 4.6576	Cost: 17.22s
Train Epoch: 303 	Average Loss: 4.8690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7686

Learning rate: 0.00019954728274593884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 5.6225	Cost: 38.71s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 4.7995	Cost: 12.85s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 4.6022	Cost: 17.55s
Train Epoch: 304 	Average Loss: 4.8559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6298

Saving model as e304_model.pt & e304_waveforms_supplementary.hdf5
Learning rate: 0.00019954429185757805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 5.6169	Cost: 37.18s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 4.8210	Cost: 10.25s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 4.5903	Cost: 33.09s
Train Epoch: 305 	Average Loss: 4.8351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6593

Learning rate: 0.00019954129114458955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 5.6537	Cost: 43.22s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 4.7784	Cost: 13.51s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 4.5873	Cost: 28.62s
Train Epoch: 306 	Average Loss: 4.8352
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5832

Saving model as e306_model.pt & e306_waveforms_supplementary.hdf5
Learning rate: 0.00019953828060726943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 5.5928	Cost: 55.36s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 4.6133	Cost: 12.82s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 4.4720	Cost: 16.39s
Train Epoch: 307 	Average Loss: 4.7341
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5190

Saving model as e307_model.pt & e307_waveforms_supplementary.hdf5
Learning rate: 0.00019953526024591494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 5.4884	Cost: 45.92s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 4.6418	Cost: 16.43s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 4.4423	Cost: 15.56s
Train Epoch: 308 	Average Loss: 4.6797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5605

Learning rate: 0.00019953223006082406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 5.6334	Cost: 44.35s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 4.6174	Cost: 12.11s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 4.5778	Cost: 21.83s
Train Epoch: 309 	Average Loss: 4.7385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5203

Learning rate: 0.00019952919005229592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 5.5564	Cost: 38.98s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 4.6709	Cost: 12.80s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 4.6498	Cost: 21.04s
Train Epoch: 310 	Average Loss: 4.7205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5614

Learning rate: 0.00019952614022063054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 5.5980	Cost: 37.95s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 4.6144	Cost: 9.82s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 4.5091	Cost: 32.02s
Train Epoch: 311 	Average Loss: 4.6942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6768

Learning rate: 0.00019952308056612892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 5.5777	Cost: 42.39s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 4.5566	Cost: 14.82s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 4.4124	Cost: 22.95s
Train Epoch: 312 	Average Loss: 4.6306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5041

Saving model as e312_model.pt & e312_waveforms_supplementary.hdf5
Learning rate: 0.00019952001108909304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 5.7133	Cost: 45.69s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 4.5449	Cost: 16.91s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 4.4045	Cost: 17.47s
Train Epoch: 313 	Average Loss: 4.6630
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4812

Saving model as e313_model.pt & e313_waveforms_supplementary.hdf5
Learning rate: 0.00019951693178982586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 5.4387	Cost: 43.74s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 4.6472	Cost: 12.33s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 4.3998	Cost: 18.70s
Train Epoch: 314 	Average Loss: 4.6323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6018

Learning rate: 0.00019951384266863126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 5.6118	Cost: 42.61s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 4.5664	Cost: 16.54s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 4.2670	Cost: 16.64s
Train Epoch: 315 	Average Loss: 4.6106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5439

Learning rate: 0.00019951074372581416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 5.4735	Cost: 41.52s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 4.5148	Cost: 11.38s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 4.4314	Cost: 25.10s
Train Epoch: 316 	Average Loss: 4.6002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4494

Saving model as e316_model.pt & e316_waveforms_supplementary.hdf5
Learning rate: 0.00019950763496168037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 5.4736	Cost: 44.71s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 4.5467	Cost: 12.68s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 4.3304	Cost: 17.98s
Train Epoch: 317 	Average Loss: 4.5616
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4906

Learning rate: 0.00019950451637653678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 5.5337	Cost: 39.85s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 4.4752	Cost: 9.95s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 4.2859	Cost: 31.34s
Train Epoch: 318 	Average Loss: 4.5493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4066

Saving model as e318_model.pt & e318_waveforms_supplementary.hdf5
Learning rate: 0.00019950138797069118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 5.3438	Cost: 42.68s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 4.4824	Cost: 15.24s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 4.3813	Cost: 21.94s
Train Epoch: 319 	Average Loss: 4.5274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4783

Learning rate: 0.00019949824974445222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 5.3718	Cost: 45.03s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 4.4480	Cost: 16.77s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 4.2472	Cost: 17.80s
Train Epoch: 320 	Average Loss: 4.5096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3721

Saving model as e320_model.pt & e320_waveforms_supplementary.hdf5
Learning rate: 0.00019949510169812976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 5.4539	Cost: 44.89s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 4.3855	Cost: 16.70s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 4.2466	Cost: 15.00s
Train Epoch: 321 	Average Loss: 4.4609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4463

Learning rate: 0.00019949194383203438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 5.4115	Cost: 42.96s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 4.6642	Cost: 9.60s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 4.2315	Cost: 24.17s
Train Epoch: 322 	Average Loss: 4.4913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3950

Learning rate: 0.00019948877614647787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 5.2204	Cost: 41.53s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 4.3247	Cost: 9.81s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 4.1949	Cost: 30.85s
Train Epoch: 323 	Average Loss: 4.3889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3294

Saving model as e323_model.pt & e323_waveforms_supplementary.hdf5
Learning rate: 0.0001994855986417728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 5.2724	Cost: 43.84s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 4.4760	Cost: 17.15s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 4.2422	Cost: 19.86s
Train Epoch: 324 	Average Loss: 4.4161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3831

Learning rate: 0.0001994824113182328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 5.3610	Cost: 44.53s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 4.2811	Cost: 16.60s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 4.1369	Cost: 19.05s
Train Epoch: 325 	Average Loss: 4.3733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3560

Learning rate: 0.00019947921417617242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 5.4359	Cost: 45.22s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 4.4662	Cost: 12.57s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 4.0708	Cost: 20.89s
Train Epoch: 326 	Average Loss: 4.3587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4056

Learning rate: 0.0001994760072159072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 5.5586	Cost: 42.29s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 4.2956	Cost: 16.26s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 4.1431	Cost: 17.15s
Train Epoch: 327 	Average Loss: 4.3747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3063

Saving model as e327_model.pt & e327_waveforms_supplementary.hdf5
Learning rate: 0.00019947279043775368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 5.2759	Cost: 47.35s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 4.3761	Cost: 9.69s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 4.2026	Cost: 21.70s
Train Epoch: 328 	Average Loss: 4.3654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4589

Learning rate: 0.00019946956384202932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 5.2623	Cost: 41.74s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 4.2922	Cost: 12.69s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 4.0244	Cost: 18.03s
Train Epoch: 329 	Average Loss: 4.3274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2961

Saving model as e329_model.pt & e329_waveforms_supplementary.hdf5
Learning rate: 0.00019946632742905265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 5.3179	Cost: 39.57s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 4.2389	Cost: 9.76s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 4.0899	Cost: 29.76s
Train Epoch: 330 	Average Loss: 4.2894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2300

Saving model as e330_model.pt & e330_waveforms_supplementary.hdf5
Learning rate: 0.000199463081199143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 5.2875	Cost: 45.50s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 4.2859	Cost: 15.41s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 4.1212	Cost: 22.16s
Train Epoch: 331 	Average Loss: 4.2981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2370

Learning rate: 0.0001994598251526208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 5.1456	Cost: 45.27s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 4.2944	Cost: 17.13s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 3.9886	Cost: 13.40s
Train Epoch: 332 	Average Loss: 4.2216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2445

Learning rate: 0.00019945655928980737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 5.0699	Cost: 51.59s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 4.3444	Cost: 13.06s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 4.1591	Cost: 18.59s
Train Epoch: 333 	Average Loss: 4.2643
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2271

Saving model as e333_model.pt & e333_waveforms_supplementary.hdf5
Learning rate: 0.0001994532836110251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 5.3005	Cost: 40.06s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 4.1889	Cost: 12.79s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 4.0402	Cost: 16.29s
Train Epoch: 334 	Average Loss: 4.2324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1767

Saving model as e334_model.pt & e334_waveforms_supplementary.hdf5
Learning rate: 0.00019944999811659725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 5.2181	Cost: 40.84s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 4.0551	Cost: 11.23s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 3.9726	Cost: 19.19s
Train Epoch: 335 	Average Loss: 4.2013
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1805

Learning rate: 0.00019944670280684805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 5.2538	Cost: 35.70s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 4.1146	Cost: 9.61s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 3.9208	Cost: 25.96s
Train Epoch: 336 	Average Loss: 4.1652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1685

Saving model as e336_model.pt & e336_waveforms_supplementary.hdf5
Learning rate: 0.00019944339768210285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 4.9265	Cost: 39.36s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 4.0227	Cost: 11.29s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 3.9564	Cost: 30.01s
Train Epoch: 337 	Average Loss: 4.1276
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1023

Saving model as e337_model.pt & e337_waveforms_supplementary.hdf5
Learning rate: 0.0001994400827426877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 5.2421	Cost: 45.85s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 3.9842	Cost: 15.47s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 3.9152	Cost: 21.65s
Train Epoch: 338 	Average Loss: 4.1333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2212

Learning rate: 0.0001994367579889299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 5.1025	Cost: 53.11s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 4.0014	Cost: 16.70s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 3.8729	Cost: 14.81s
Train Epoch: 339 	Average Loss: 4.0927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1568

Learning rate: 0.0001994334234211575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 5.0863	Cost: 44.65s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 4.0143	Cost: 14.17s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 3.8042	Cost: 17.09s
Train Epoch: 340 	Average Loss: 4.0613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0463

Saving model as e340_model.pt & e340_waveforms_supplementary.hdf5
Learning rate: 0.00019943007903969968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 5.0281	Cost: 41.27s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 4.0564	Cost: 9.54s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 3.8941	Cost: 23.29s
Train Epoch: 341 	Average Loss: 4.0823
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1324

Learning rate: 0.00019942672484488645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 5.2075	Cost: 40.23s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 3.9807	Cost: 12.68s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 3.8136	Cost: 19.51s
Train Epoch: 342 	Average Loss: 4.0575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0622

Learning rate: 0.0001994233608370489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 5.2137	Cost: 40.93s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 4.0180	Cost: 10.10s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 3.6791	Cost: 31.05s
Train Epoch: 343 	Average Loss: 4.0205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0914

Learning rate: 0.00019941998701651908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 4.9759	Cost: 43.28s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 3.9275	Cost: 13.32s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 3.7367	Cost: 24.79s
Train Epoch: 344 	Average Loss: 4.0142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1961

Learning rate: 0.00019941660338362987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 5.1563	Cost: 45.99s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 3.8973	Cost: 16.74s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 3.7290	Cost: 16.40s
Train Epoch: 345 	Average Loss: 3.9710
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9977

Saving model as e345_model.pt & e345_waveforms_supplementary.hdf5
Learning rate: 0.0001994132099387153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 4.9093	Cost: 44.81s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 3.8462	Cost: 11.77s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 3.6066	Cost: 19.05s
Train Epoch: 346 	Average Loss: 3.9264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0700

Learning rate: 0.00019940980668211027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 5.0297	Cost: 42.64s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 3.8585	Cost: 16.07s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 3.6839	Cost: 12.93s
Train Epoch: 347 	Average Loss: 3.9125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9572

Saving model as e347_model.pt & e347_waveforms_supplementary.hdf5
Learning rate: 0.00019940639361415064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 4.8638	Cost: 39.44s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 3.8966	Cost: 9.55s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 3.6112	Cost: 23.07s
Train Epoch: 348 	Average Loss: 3.8833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9180

Saving model as e348_model.pt & e348_waveforms_supplementary.hdf5
Learning rate: 0.00019940297073517331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 4.9465	Cost: 38.12s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 3.7775	Cost: 10.04s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 3.6617	Cost: 31.14s
Train Epoch: 349 	Average Loss: 3.8802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9780

Learning rate: 0.00019939953804551608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 5.0325	Cost: 42.90s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 3.8168	Cost: 17.56s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 3.6101	Cost: 20.87s
Train Epoch: 350 	Average Loss: 3.8872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9977

Learning rate: 0.00019939609554551777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 4.8956	Cost: 46.94s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 3.7289	Cost: 17.06s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 3.6192	Cost: 16.97s
Train Epoch: 351 	Average Loss: 3.8602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9456

Learning rate: 0.0001993926432355181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 4.8792	Cost: 44.52s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 3.7834	Cost: 14.81s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 3.5646	Cost: 18.37s
Train Epoch: 352 	Average Loss: 3.8280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0138

Learning rate: 0.00019938918111585784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 4.9914	Cost: 41.92s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 3.7746	Cost: 16.38s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 3.5816	Cost: 17.91s
Train Epoch: 353 	Average Loss: 3.8071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8669

Saving model as e353_model.pt & e353_waveforms_supplementary.hdf5
Learning rate: 0.00019938570918687863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 5.0210	Cost: 40.63s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 3.7008	Cost: 9.68s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 3.5082	Cost: 26.57s
Train Epoch: 354 	Average Loss: 3.7721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8959

Learning rate: 0.0001993822274489232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 4.8128	Cost: 41.47s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 3.7713	Cost: 12.67s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 3.5424	Cost: 18.09s
Train Epoch: 355 	Average Loss: 3.7695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9387

Learning rate: 0.00019937873590233516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 4.8976	Cost: 43.30s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 3.6830	Cost: 10.01s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 3.6400	Cost: 30.79s
Train Epoch: 356 	Average Loss: 3.7528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9837

Learning rate: 0.0001993752345474591
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 4.9795	Cost: 41.77s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 3.6438	Cost: 17.02s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 3.3498	Cost: 19.63s
Train Epoch: 357 	Average Loss: 3.7079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8889

Learning rate: 0.0001993717233846406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 4.8529	Cost: 46.04s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 3.6459	Cost: 16.55s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 3.3537	Cost: 18.33s
Train Epoch: 358 	Average Loss: 3.6649
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9207

Learning rate: 0.0001993682024142262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 4.8399	Cost: 45.10s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 3.7507	Cost: 13.94s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 3.5385	Cost: 17.54s
Train Epoch: 359 	Average Loss: 3.7119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9251

Learning rate: 0.00019936467163656337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 4.9505	Cost: 45.58s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 3.6748	Cost: 15.83s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 3.4294	Cost: 19.00s
Train Epoch: 360 	Average Loss: 3.7102
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8271

Saving model as e360_model.pt & e360_waveforms_supplementary.hdf5
Learning rate: 0.00019936113105200064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 4.8098	Cost: 41.49s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 3.5962	Cost: 9.75s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 3.3463	Cost: 21.21s
Train Epoch: 361 	Average Loss: 3.5925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8367

Learning rate: 0.00019935758066088742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 4.8787	Cost: 42.31s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 3.5082	Cost: 10.01s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 3.3393	Cost: 28.99s
Train Epoch: 362 	Average Loss: 3.5986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9411

Learning rate: 0.00019935402046357414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 4.8973	Cost: 45.60s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 3.5815	Cost: 16.97s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 3.2999	Cost: 21.17s
Train Epoch: 363 	Average Loss: 3.6192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8287

Learning rate: 0.00019935045046041218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 4.7091	Cost: 44.46s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 3.5020	Cost: 16.46s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 3.2099	Cost: 17.81s
Train Epoch: 364 	Average Loss: 3.5169
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7670

Saving model as e364_model.pt & e364_waveforms_supplementary.hdf5
Learning rate: 0.00019934687065175386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 4.6773	Cost: 43.99s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 3.4592	Cost: 16.80s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 3.3355	Cost: 16.87s
Train Epoch: 365 	Average Loss: 3.5875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8558

Learning rate: 0.00019934328103795248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 4.7975	Cost: 43.59s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 3.4572	Cost: 16.16s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 3.2288	Cost: 16.58s
Train Epoch: 366 	Average Loss: 3.5732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6727

Saving model as e366_model.pt & e366_waveforms_supplementary.hdf5
Learning rate: 0.00019933968161936236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 4.7216	Cost: 41.53s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 3.6418	Cost: 9.70s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 3.2254	Cost: 22.79s
Train Epoch: 367 	Average Loss: 3.5662
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7945

Learning rate: 0.00019933607239633875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 4.7338	Cost: 42.33s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 3.4144	Cost: 11.06s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 3.1891	Cost: 27.23s
Train Epoch: 368 	Average Loss: 3.5048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7284

Learning rate: 0.00019933245336923783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 4.6606	Cost: 39.27s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 3.4714	Cost: 9.59s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 3.2100	Cost: 35.54s
Train Epoch: 369 	Average Loss: 3.4969
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6757

Learning rate: 0.0001993288245384168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 4.5764	Cost: 44.16s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 3.3451	Cost: 16.16s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 3.2906	Cost: 20.83s
Train Epoch: 370 	Average Loss: 3.4588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6558

Saving model as e370_model.pt & e370_waveforms_supplementary.hdf5
Learning rate: 0.00019932518590423377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 4.5201	Cost: 44.31s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 3.3216	Cost: 14.61s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 3.2373	Cost: 16.28s
Train Epoch: 371 	Average Loss: 3.4298
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6519

Saving model as e371_model.pt & e371_waveforms_supplementary.hdf5
Learning rate: 0.00019932153746704794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 4.7038	Cost: 56.69s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 3.3135	Cost: 13.55s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 2.9993	Cost: 16.45s
Train Epoch: 372 	Average Loss: 3.3781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5370

Saving model as e372_model.pt & e372_waveforms_supplementary.hdf5
Learning rate: 0.00019931787922721937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 4.6299	Cost: 40.73s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 3.2774	Cost: 9.58s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 3.1140	Cost: 22.22s
Train Epoch: 373 	Average Loss: 3.3682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5830

Learning rate: 0.00019931421118510906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 4.5863	Cost: 40.00s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 3.2668	Cost: 10.12s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 3.0499	Cost: 30.34s
Train Epoch: 374 	Average Loss: 3.3493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6589

Learning rate: 0.0001993105333410791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 4.4196	Cost: 44.13s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 3.3502	Cost: 17.53s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 3.0862	Cost: 23.15s
Train Epoch: 375 	Average Loss: 3.3724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6311

Learning rate: 0.00019930684569549248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 4.5525	Cost: 52.41s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 3.2722	Cost: 15.75s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 3.1133	Cost: 14.72s
Train Epoch: 376 	Average Loss: 3.3245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5711

Learning rate: 0.0001993031482487131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 4.4481	Cost: 52.14s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 3.2114	Cost: 14.62s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 3.0826	Cost: 14.94s
Train Epoch: 377 	Average Loss: 3.2881
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6026

Learning rate: 0.0001992994410011059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 4.3431	Cost: 46.03s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 3.2125	Cost: 15.14s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 3.0108	Cost: 15.52s
Train Epoch: 378 	Average Loss: 3.2561
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5633

Learning rate: 0.00019929572395303678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 4.5645	Cost: 43.44s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 3.2663	Cost: 9.64s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 2.9419	Cost: 24.81s
Train Epoch: 379 	Average Loss: 3.2532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4968

Saving model as e379_model.pt & e379_waveforms_supplementary.hdf5
Learning rate: 0.0001992919971048726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 4.5208	Cost: 39.20s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 3.1836	Cost: 9.94s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 2.9576	Cost: 24.08s
Train Epoch: 380 	Average Loss: 3.2563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4439

Saving model as e380_model.pt & e380_waveforms_supplementary.hdf5
Learning rate: 0.0001992882604569812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 4.4205	Cost: 37.49s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 3.1043	Cost: 11.32s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 3.0306	Cost: 28.18s
Train Epoch: 381 	Average Loss: 3.2351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4506

Learning rate: 0.00019928451400973133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 4.5113	Cost: 48.64s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 3.1359	Cost: 16.66s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 2.9513	Cost: 22.64s
Train Epoch: 382 	Average Loss: 3.2086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5872

Learning rate: 0.0001992807577634928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 4.5204	Cost: 53.13s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 3.1194	Cost: 16.39s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 2.8473	Cost: 16.42s
Train Epoch: 383 	Average Loss: 3.1949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5397

Learning rate: 0.00019927699171863632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 4.4519	Cost: 47.99s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 3.0077	Cost: 14.84s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 2.9022	Cost: 14.62s
Train Epoch: 384 	Average Loss: 3.1660
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4391

Saving model as e384_model.pt & e384_waveforms_supplementary.hdf5
Learning rate: 0.00019927321587553357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 4.5048	Cost: 43.82s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 3.0018	Cost: 16.85s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 2.8837	Cost: 12.58s
Train Epoch: 385 	Average Loss: 3.1442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5096

Learning rate: 0.00019926943023455717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 4.3925	Cost: 42.20s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 2.9877	Cost: 14.43s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 2.8081	Cost: 19.47s
Train Epoch: 386 	Average Loss: 3.0679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3051

Saving model as e386_model.pt & e386_waveforms_supplementary.hdf5
Learning rate: 0.00019926563479608086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 4.4938	Cost: 39.88s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 3.0865	Cost: 9.82s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 2.7941	Cost: 25.93s
Train Epoch: 387 	Average Loss: 3.0711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4599

Learning rate: 0.00019926182956047912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 4.3041	Cost: 42.85s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 2.9938	Cost: 9.61s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 2.7262	Cost: 30.13s
Train Epoch: 388 	Average Loss: 3.0424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4153

Learning rate: 0.00019925801452812757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 4.3383	Cost: 43.99s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 2.9943	Cost: 14.64s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 2.6576	Cost: 27.77s
Train Epoch: 389 	Average Loss: 3.0127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4360

Learning rate: 0.00019925418969940278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 4.3841	Cost: 43.77s
Train Epoch: 390 [40960/90000 (45%)]	Loss: 2.9076	Cost: 16.09s
Train Epoch: 390 [81920/90000 (91%)]	Loss: 2.7763	Cost: 17.29s
Train Epoch: 390 	Average Loss: 3.0063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4005

Learning rate: 0.00019925035507468219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 4.3001	Cost: 45.45s
Train Epoch: 391 [40960/90000 (45%)]	Loss: 2.9462	Cost: 16.82s
Train Epoch: 391 [81920/90000 (91%)]	Loss: 2.7824	Cost: 15.57s
Train Epoch: 391 	Average Loss: 2.9745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3116

Learning rate: 0.00019924651065434423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 4.2516	Cost: 42.96s
Train Epoch: 392 [40960/90000 (45%)]	Loss: 2.9651	Cost: 13.39s
Train Epoch: 392 [81920/90000 (91%)]	Loss: 2.6803	Cost: 21.03s
Train Epoch: 392 	Average Loss: 2.9802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3022

Saving model as e392_model.pt & e392_waveforms_supplementary.hdf5
Learning rate: 0.0001992426564387684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 4.4021	Cost: 43.26s
Train Epoch: 393 [40960/90000 (45%)]	Loss: 2.9880	Cost: 9.72s
Train Epoch: 393 [81920/90000 (91%)]	Loss: 2.6425	Cost: 27.00s
Train Epoch: 393 	Average Loss: 2.9341
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3361

Learning rate: 0.00019923879242833502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 4.1818	Cost: 42.99s
Train Epoch: 394 [40960/90000 (45%)]	Loss: 2.8671	Cost: 9.64s
Train Epoch: 394 [81920/90000 (91%)]	Loss: 2.6068	Cost: 30.65s
Train Epoch: 394 	Average Loss: 2.9012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3065

Learning rate: 0.00019923491862342552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 4.1143	Cost: 42.73s
Train Epoch: 395 [40960/90000 (45%)]	Loss: 2.8281	Cost: 15.48s
Train Epoch: 395 [81920/90000 (91%)]	Loss: 2.5527	Cost: 24.94s
Train Epoch: 395 	Average Loss: 2.8946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3110

Learning rate: 0.0001992310350244222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 4.1653	Cost: 44.55s
Train Epoch: 396 [40960/90000 (45%)]	Loss: 2.8817	Cost: 16.49s
Train Epoch: 396 [81920/90000 (91%)]	Loss: 2.6141	Cost: 17.26s
Train Epoch: 396 	Average Loss: 2.9702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3017

Saving model as e396_model.pt & e396_waveforms_supplementary.hdf5
Learning rate: 0.0001992271416317084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 4.3546	Cost: 42.78s
Train Epoch: 397 [40960/90000 (45%)]	Loss: 2.8627	Cost: 13.64s
Train Epoch: 397 [81920/90000 (91%)]	Loss: 2.8116	Cost: 20.92s
Train Epoch: 397 	Average Loss: 3.0032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3502

Learning rate: 0.0001992232384456683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 4.3862	Cost: 42.28s
Train Epoch: 398 [40960/90000 (45%)]	Loss: 2.8230	Cost: 15.47s
Train Epoch: 398 [81920/90000 (91%)]	Loss: 2.6573	Cost: 19.32s
Train Epoch: 398 	Average Loss: 2.9171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2930

Saving model as e398_model.pt & e398_waveforms_supplementary.hdf5
Learning rate: 0.00019921932546668718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 4.2032	Cost: 45.72s
Train Epoch: 399 [40960/90000 (45%)]	Loss: 2.8106	Cost: 12.54s
Train Epoch: 399 [81920/90000 (91%)]	Loss: 2.4595	Cost: 18.15s
Train Epoch: 399 	Average Loss: 2.8725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2159

Saving model as e399_model.pt & e399_waveforms_supplementary.hdf5
Learning rate: 0.00019921540269515121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 4.1084	Cost: 40.53s
Train Epoch: 400 [40960/90000 (45%)]	Loss: 2.7701	Cost: 9.96s
Train Epoch: 400 [81920/90000 (91%)]	Loss: 2.4730	Cost: 32.37s
Train Epoch: 400 	Average Loss: 2.7718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1031

Saving model as e400_model.pt & e400_waveforms_supplementary.hdf5
Stopping timer.
Training time (including validation): 51297.82214593887 seconds
Saving model
Transfer learning by starting with alpha=0.8!
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 50.2654	Cost: 46.45s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 23.6729	Cost: 10.87s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 18.9074	Cost: 26.25s
Train Epoch: 1 	Average Loss: 26.2569
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6440

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999691576447898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 18.2197	Cost: 51.98s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 15.5991	Cost: 14.26s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 14.1116	Cost: 15.81s
Train Epoch: 2 	Average Loss: 15.7214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1559

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 13.8609	Cost: 47.73s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 12.3778	Cost: 9.80s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 11.6639	Cost: 20.96s
Train Epoch: 3 	Average Loss: 12.6098
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5532

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 11.3836	Cost: 38.95s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 11.0434	Cost: 9.60s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 10.5491	Cost: 24.75s
Train Epoch: 4 	Average Loss: 10.9221
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6683

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.00019995065603657316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 10.8966	Cost: 38.22s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 10.0607	Cost: 9.91s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 9.9188	Cost: 25.93s
Train Epoch: 5 	Average Loss: 10.1925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8329

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.0001999229036240723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 9.8497	Cost: 39.76s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 9.3321	Cost: 15.05s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 9.4875	Cost: 18.88s
Train Epoch: 6 	Average Loss: 9.4568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1598

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019988898749619702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 9.2075	Cost: 40.05s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 9.1374	Cost: 14.10s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 8.6965	Cost: 15.29s
Train Epoch: 7 	Average Loss: 9.0489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7953

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.00019984890974505381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 9.3531	Cost: 40.26s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 8.4972	Cost: 9.57s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 8.3131	Cost: 18.60s
Train Epoch: 8 	Average Loss: 8.6335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2904

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.00019980267284282717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 8.6675	Cost: 36.88s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 8.1504	Cost: 11.11s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 8.2041	Cost: 30.77s
Train Epoch: 9 	Average Loss: 8.2973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1374

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019975027964162705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 8.2573	Cost: 47.86s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 7.9791	Cost: 16.54s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 8.0672	Cost: 20.25s
Train Epoch: 10 	Average Loss: 8.0561
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0469

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 0.00019969173337331284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 8.5483	Cost: 46.12s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 7.8581	Cost: 16.78s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 7.8832	Cost: 13.03s
Train Epoch: 11 	Average Loss: 7.9674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9671

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 0.00019962703764929416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 8.1401	Cost: 46.99s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 7.6777	Cost: 9.85s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 7.6115	Cost: 21.73s
Train Epoch: 12 	Average Loss: 7.6606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5230

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 0.00019955619646030802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 7.7248	Cost: 37.48s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 7.5120	Cost: 9.81s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 7.3789	Cost: 27.34s
Train Epoch: 13 	Average Loss: 7.4698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5773

Learning rate: 0.00019947921417617267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 7.8415	Cost: 38.81s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 7.2287	Cost: 13.73s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 7.2277	Cost: 23.53s
Train Epoch: 14 	Average Loss: 7.3839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4191

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Learning rate: 0.000199396095545518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 7.7852	Cost: 38.13s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 7.3170	Cost: 17.24s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 7.4315	Cost: 16.68s
Train Epoch: 15 	Average Loss: 7.2978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3397

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Learning rate: 0.00019930684569549264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 7.5136	Cost: 41.28s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 6.8175	Cost: 13.39s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 6.9336	Cost: 15.40s
Train Epoch: 16 	Average Loss: 7.1912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3668

Learning rate: 0.0001992114701314478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 7.4780	Cost: 42.44s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 6.8462	Cost: 16.14s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 6.9359	Cost: 14.89s
Train Epoch: 17 	Average Loss: 6.9998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1166

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Learning rate: 0.00019910997473659747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 7.1845	Cost: 37.31s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 6.7904	Cost: 9.76s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 6.8525	Cost: 25.39s
Train Epoch: 18 	Average Loss: 6.8951
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0791

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Learning rate: 0.00019900236577165574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 6.9403	Cost: 45.73s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 6.8276	Cost: 9.91s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 6.7783	Cost: 28.11s
Train Epoch: 19 	Average Loss: 6.8073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8943

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Learning rate: 0.00019888864987445046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 7.4741	Cost: 44.28s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 6.4478	Cost: 14.44s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 6.5606	Cost: 18.14s
Train Epoch: 20 	Average Loss: 6.7179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8572

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Learning rate: 0.00019876883405951377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 7.0714	Cost: 48.72s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 6.6233	Cost: 15.08s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 6.3726	Cost: 12.94s
Train Epoch: 21 	Average Loss: 6.6253
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7199

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Learning rate: 0.00019864292571764955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 6.9994	Cost: 41.52s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 6.4046	Cost: 13.62s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 6.4059	Cost: 18.52s
Train Epoch: 22 	Average Loss: 6.4773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7208

Learning rate: 0.0001985109326154774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 7.1117	Cost: 39.41s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 6.2742	Cost: 12.76s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 6.5187	Cost: 14.27s
Train Epoch: 23 	Average Loss: 6.4289
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7631

Learning rate: 0.00019837286289495361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 6.8287	Cost: 34.55s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 6.2733	Cost: 9.94s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 6.2422	Cost: 28.91s
Train Epoch: 24 	Average Loss: 6.3819
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5009

Saving model as e24_model.pt & e24_waveforms_supplementary.hdf5
Learning rate: 0.0001982287250728689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 6.8578	Cost: 35.15s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 6.2229	Cost: 15.15s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 6.3969	Cost: 26.54s
Train Epoch: 25 	Average Loss: 6.2562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6794

Learning rate: 0.00019807852804032305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 6.8951	Cost: 45.93s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 6.1225	Cost: 16.71s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 6.3719	Cost: 16.62s
Train Epoch: 26 	Average Loss: 6.2693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5220

Learning rate: 0.00019792228106217658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 6.6858	Cost: 50.83s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 6.0459	Cost: 12.23s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 6.1927	Cost: 21.33s
Train Epoch: 27 	Average Loss: 6.1813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3720

Saving model as e27_model.pt & e27_waveforms_supplementary.hdf5
Learning rate: 0.0001977599937764791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 6.8393	Cost: 40.87s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 6.0513	Cost: 11.12s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 5.9290	Cost: 21.07s
Train Epoch: 28 	Average Loss: 6.0562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2380

Saving model as e28_model.pt & e28_waveforms_supplementary.hdf5
Learning rate: 0.00019759167619387474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 6.7168	Cost: 37.14s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 6.0875	Cost: 10.00s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 6.1126	Cost: 23.15s
Train Epoch: 29 	Average Loss: 5.9767
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3191

Learning rate: 0.00019741733869698495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 6.6741	Cost: 42.39s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 5.8175	Cost: 16.93s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 5.7248	Cost: 17.34s
Train Epoch: 30 	Average Loss: 5.9618
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3665

Learning rate: 0.00019723699203976766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 6.5860	Cost: 38.79s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 5.8372	Cost: 13.83s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 5.8526	Cost: 18.18s
Train Epoch: 31 	Average Loss: 5.9432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2256

Saving model as e31_model.pt & e31_waveforms_supplementary.hdf5
Learning rate: 0.00019705064734685425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 6.6038	Cost: 39.85s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 5.7350	Cost: 15.70s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 5.8579	Cost: 14.00s
Train Epoch: 32 	Average Loss: 5.8481
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2526

Learning rate: 0.00019685831611286313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 6.5902	Cost: 42.39s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 5.6056	Cost: 16.46s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 5.9142	Cost: 13.64s
Train Epoch: 33 	Average Loss: 5.8293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2076

Saving model as e33_model.pt & e33_waveforms_supplementary.hdf5
Learning rate: 0.00019666001020169073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 6.2467	Cost: 38.47s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 5.5299	Cost: 9.85s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 5.8378	Cost: 24.18s
Train Epoch: 34 	Average Loss: 5.8377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1332

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Learning rate: 0.0001964557418457798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 6.3346	Cost: 41.97s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 5.5917	Cost: 11.39s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 5.6070	Cost: 25.24s
Train Epoch: 35 	Average Loss: 5.6639
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1151

Saving model as e35_model.pt & e35_waveforms_supplementary.hdf5
Learning rate: 0.0001962455236453647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 6.3694	Cost: 45.67s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 5.3023	Cost: 9.95s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 5.6936	Cost: 25.46s
Train Epoch: 36 	Average Loss: 5.6611
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0858

Saving model as e36_model.pt & e36_waveforms_supplementary.hdf5
Learning rate: 0.00019602936856769428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 6.3902	Cost: 43.61s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 5.4314	Cost: 15.32s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 5.4809	Cost: 17.98s
Train Epoch: 37 	Average Loss: 5.5970
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1090

Learning rate: 0.0001958072899462319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 6.1018	Cost: 40.11s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 5.3807	Cost: 16.54s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 5.5094	Cost: 18.28s
Train Epoch: 38 	Average Loss: 5.5244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9466

Saving model as e38_model.pt & e38_waveforms_supplementary.hdf5
Learning rate: 0.00019557930147983297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 6.1936	Cost: 38.47s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 5.5453	Cost: 16.77s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 5.4012	Cost: 17.34s
Train Epoch: 39 	Average Loss: 5.5264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9010

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Learning rate: 0.00019534541723190008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 6.3458	Cost: 43.90s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 5.3042	Cost: 13.58s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 5.3206	Cost: 13.53s
Train Epoch: 40 	Average Loss: 5.4568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9753

Learning rate: 0.00019510565162951532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 6.0852	Cost: 35.51s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 5.4166	Cost: 12.99s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 5.8847	Cost: 20.39s
Train Epoch: 41 	Average Loss: 5.4305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1221

Learning rate: 0.0001948600194625504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 6.1002	Cost: 38.29s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 5.6202	Cost: 10.75s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 5.3539	Cost: 30.98s
Train Epoch: 42 	Average Loss: 5.4119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9840

Learning rate: 0.00019460853588275446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 6.0983	Cost: 47.59s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 5.4316	Cost: 15.32s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 5.2700	Cost: 20.59s
Train Epoch: 43 	Average Loss: 5.4249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8645

Saving model as e43_model.pt & e43_waveforms_supplementary.hdf5
Learning rate: 0.0001943512164028193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 5.9819	Cost: 48.48s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 5.3067	Cost: 15.67s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 5.2338	Cost: 15.48s
Train Epoch: 44 	Average Loss: 5.3118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7861

Saving model as e44_model.pt & e44_waveforms_supplementary.hdf5
Learning rate: 0.00019408807689542249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 5.9865	Cost: 46.77s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 5.0610	Cost: 9.91s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 5.0063	Cost: 19.99s
Train Epoch: 45 	Average Loss: 5.2150
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7434

Saving model as e45_model.pt & e45_waveforms_supplementary.hdf5
Learning rate: 0.00019381913359224837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 5.7879	Cost: 39.50s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 4.9861	Cost: 9.84s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 5.1582	Cost: 25.08s
Train Epoch: 46 	Average Loss: 5.1887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8011

Learning rate: 0.0001935444030829867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 5.8059	Cost: 39.00s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 4.8600	Cost: 9.76s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 4.9838	Cost: 25.03s
Train Epoch: 47 	Average Loss: 5.1566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7678

Learning rate: 0.00019326390231430937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 5.7945	Cost: 45.22s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 4.9531	Cost: 15.64s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 5.0206	Cost: 18.22s
Train Epoch: 48 	Average Loss: 5.1350
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7273

Saving model as e48_model.pt & e48_waveforms_supplementary.hdf5
Learning rate: 0.00019297764858882508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 5.6548	Cost: 38.70s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 5.0058	Cost: 16.65s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 5.1424	Cost: 16.59s
Train Epoch: 49 	Average Loss: 5.0693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8442

Learning rate: 0.000192685659564012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 6.0351	Cost: 39.86s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 4.8998	Cost: 12.47s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 4.8432	Cost: 15.92s
Train Epoch: 50 	Average Loss: 5.0892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7488

Learning rate: 0.00019238795325112859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 5.9469	Cost: 39.97s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 4.7635	Cost: 12.62s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 4.9198	Cost: 16.14s
Train Epoch: 51 	Average Loss: 5.0022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5791

Saving model as e51_model.pt & e51_waveforms_supplementary.hdf5
Learning rate: 0.00019208454801410258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 6.0602	Cost: 36.54s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 4.8986	Cost: 11.67s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 4.9183	Cost: 25.11s
Train Epoch: 52 	Average Loss: 4.9151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5404

Saving model as e52_model.pt & e52_waveforms_supplementary.hdf5
Learning rate: 0.00019177546256839804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 5.7912	Cost: 41.27s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 4.6752	Cost: 9.90s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 4.9113	Cost: 23.36s
Train Epoch: 53 	Average Loss: 4.8673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6621

Learning rate: 0.0001914607159798613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 5.8763	Cost: 42.52s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 4.7786	Cost: 16.84s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 4.9282	Cost: 19.58s
Train Epoch: 54 	Average Loss: 4.8482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5664

Learning rate: 0.00019114032766354445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 5.6745	Cost: 47.02s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 4.5673	Cost: 15.74s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 4.9932	Cost: 16.88s
Train Epoch: 55 	Average Loss: 4.8272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5587

Learning rate: 0.00019081431738250806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 5.7006	Cost: 51.27s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 4.5304	Cost: 13.61s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 4.7704	Cost: 16.08s
Train Epoch: 56 	Average Loss: 4.7936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6739

Learning rate: 0.00019048270524660188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 5.6990	Cost: 50.19s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 4.4806	Cost: 11.83s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 4.9541	Cost: 19.28s
Train Epoch: 57 	Average Loss: 4.8295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6489

Learning rate: 0.0001901455117112245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 5.6873	Cost: 36.94s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 4.7749	Cost: 9.72s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 4.6144	Cost: 22.30s
Train Epoch: 58 	Average Loss: 4.8041
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5194

Saving model as e58_model.pt & e58_waveforms_supplementary.hdf5
Learning rate: 0.0001898027575760615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 5.8027	Cost: 38.46s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 4.6600	Cost: 9.82s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 4.6249	Cost: 27.48s
Train Epoch: 59 	Average Loss: 4.7510
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4251

Saving model as e59_model.pt & e59_waveforms_supplementary.hdf5
Learning rate: 0.00018945446398380245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 5.6303	Cost: 37.32s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 4.2908	Cost: 17.50s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 4.5928	Cost: 22.91s
Train Epoch: 60 	Average Loss: 4.6467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3758

Saving model as e60_model.pt & e60_waveforms_supplementary.hdf5
Learning rate: 0.00018910065241883672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 5.6000	Cost: 37.38s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 4.4888	Cost: 16.79s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 4.5124	Cost: 21.41s
Train Epoch: 61 	Average Loss: 4.6212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4680

Learning rate: 0.00018874134470592827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 5.4480	Cost: 43.84s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 4.4755	Cost: 10.11s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 4.6902	Cost: 30.19s
Train Epoch: 62 	Average Loss: 4.5683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4408

Learning rate: 0.0001883765630088693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 5.6436	Cost: 46.24s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 4.4470	Cost: 9.98s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 4.4740	Cost: 27.10s
Train Epoch: 63 	Average Loss: 4.6090
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4344

Learning rate: 0.00018800632982911313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 5.4679	Cost: 45.19s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 4.2782	Cost: 13.91s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 4.4434	Cost: 21.25s
Train Epoch: 64 	Average Loss: 4.4652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3173

Saving model as e64_model.pt & e64_waveforms_supplementary.hdf5
Learning rate: 0.00018763066800438628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 5.2919	Cost: 39.53s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 4.4696	Cost: 14.00s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 4.3827	Cost: 20.92s
Train Epoch: 65 	Average Loss: 4.5116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2670

Saving model as e65_model.pt & e65_waveforms_supplementary.hdf5
Learning rate: 0.00018724960070727966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 5.7279	Cost: 37.20s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 4.2826	Cost: 13.35s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 4.5001	Cost: 13.52s
Train Epoch: 66 	Average Loss: 4.4202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2039

Saving model as e66_model.pt & e66_waveforms_supplementary.hdf5
Learning rate: 0.00018686315144381908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 5.5798	Cost: 37.52s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 4.2907	Cost: 10.62s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 4.4442	Cost: 16.16s
Train Epoch: 67 	Average Loss: 4.3967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2932

Learning rate: 0.00018647134405201546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 5.5720	Cost: 36.24s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 4.2115	Cost: 13.15s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 4.4962	Cost: 19.37s
Train Epoch: 68 	Average Loss: 4.4122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3800

Learning rate: 0.00018607420270039433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 5.4673	Cost: 38.94s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 4.3410	Cost: 11.34s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 4.1820	Cost: 27.62s
Train Epoch: 69 	Average Loss: 4.4328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2817

Learning rate: 0.00018567175188650495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 5.1912	Cost: 47.14s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 4.3012	Cost: 16.88s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 4.4630	Cost: 19.63s
Train Epoch: 70 	Average Loss: 4.4391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2790

Learning rate: 0.0001852640164354092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 5.4775	Cost: 45.65s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 4.1823	Cost: 12.59s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 4.2374	Cost: 21.23s
Train Epoch: 71 	Average Loss: 4.3125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1719

Saving model as e71_model.pt & e71_waveforms_supplementary.hdf5
Learning rate: 0.00018485102149815036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 5.1764	Cost: 53.36s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 4.1032	Cost: 15.37s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 4.2376	Cost: 11.59s
Train Epoch: 72 	Average Loss: 4.2432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2187

Learning rate: 0.0001844327925502015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 5.5040	Cost: 48.83s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 4.0890	Cost: 16.87s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 4.1866	Cost: 14.94s
Train Epoch: 73 	Average Loss: 4.2327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2313

Learning rate: 0.00018400935538989417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 5.2153	Cost: 48.05s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 4.0268	Cost: 9.78s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 4.1088	Cost: 19.99s
Train Epoch: 74 	Average Loss: 4.2130
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1486

Saving model as e74_model.pt & e74_waveforms_supplementary.hdf5
Learning rate: 0.00018358073613682703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 5.3171	Cost: 37.78s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 3.7311	Cost: 10.68s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 4.0615	Cost: 21.33s
Train Epoch: 75 	Average Loss: 4.1547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1466

Saving model as e75_model.pt & e75_waveforms_supplementary.hdf5
Learning rate: 0.00018314696123025452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 5.4520	Cost: 34.64s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 3.8168	Cost: 10.09s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 4.3156	Cost: 23.97s
Train Epoch: 76 	Average Loss: 4.1826
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1210

Saving model as e76_model.pt & e76_waveforms_supplementary.hdf5
Learning rate: 0.00018270805742745614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 5.3641	Cost: 36.30s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 3.8251	Cost: 15.41s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 4.0419	Cost: 21.36s
Train Epoch: 77 	Average Loss: 4.1218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0933

Saving model as e77_model.pt & e77_waveforms_supplementary.hdf5
Learning rate: 0.00018226405180208597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 5.2081	Cost: 42.94s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 3.7998	Cost: 16.18s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 4.1879	Cost: 16.50s
Train Epoch: 78 	Average Loss: 4.0873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2406

Learning rate: 0.00018181497174250233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 5.3984	Cost: 42.15s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 3.8916	Cost: 15.71s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 3.8711	Cost: 14.92s
Train Epoch: 79 	Average Loss: 4.1244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9919

Saving model as e79_model.pt & e79_waveforms_supplementary.hdf5
Learning rate: 0.00018136084495007872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 5.1367	Cost: 41.63s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 3.6800	Cost: 17.02s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 4.2199	Cost: 15.39s
Train Epoch: 80 	Average Loss: 4.0552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0209

Learning rate: 0.00018090169943749476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 5.3410	Cost: 38.88s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 3.7983	Cost: 9.92s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 4.0388	Cost: 24.50s
Train Epoch: 81 	Average Loss: 4.0211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0103

Learning rate: 0.00018043756352700846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 5.0677	Cost: 40.25s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 3.6999	Cost: 12.91s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 4.0610	Cost: 21.13s
Train Epoch: 82 	Average Loss: 3.9430
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0507

Learning rate: 0.00017996846584870908
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 5.1514	Cost: 41.52s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 3.5847	Cost: 9.95s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 3.8737	Cost: 26.97s
Train Epoch: 83 	Average Loss: 3.8998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9384

Saving model as e83_model.pt & e83_waveforms_supplementary.hdf5
Learning rate: 0.000179494435338751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 5.4007	Cost: 44.97s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 3.7600	Cost: 14.71s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 3.7847	Cost: 18.88s
Train Epoch: 84 	Average Loss: 3.9037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8964

Saving model as e84_model.pt & e84_waveforms_supplementary.hdf5
Learning rate: 0.00017901550123756904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 5.4156	Cost: 42.14s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 3.5552	Cost: 16.67s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 3.8011	Cost: 15.28s
Train Epoch: 85 	Average Loss: 3.8544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8591

Saving model as e85_model.pt & e85_waveforms_supplementary.hdf5
Learning rate: 0.00017853169308807448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 5.2391	Cost: 46.67s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 3.4982	Cost: 10.83s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 3.8543	Cost: 22.08s
Train Epoch: 86 	Average Loss: 3.8466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9420

Learning rate: 0.00017804304073383296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 5.2933	Cost: 36.29s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 3.7653	Cost: 11.16s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 3.7319	Cost: 19.22s
Train Epoch: 87 	Average Loss: 3.8631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9141

Learning rate: 0.00017754957431722346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 4.8938	Cost: 36.97s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 3.5888	Cost: 9.94s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 3.5605	Cost: 27.55s
Train Epoch: 88 	Average Loss: 3.7485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9796

Learning rate: 0.00017705132427757892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 4.7620	Cost: 34.65s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 3.4944	Cost: 15.33s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 3.6833	Cost: 19.85s
Train Epoch: 89 	Average Loss: 3.7219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7923

Saving model as e89_model.pt & e89_waveforms_supplementary.hdf5
Learning rate: 0.00017654832134930882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 4.9723	Cost: 35.88s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 3.4759	Cost: 13.32s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 3.7913	Cost: 25.27s
Train Epoch: 90 	Average Loss: 3.6538
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8719

Learning rate: 0.0001760405965600031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 5.1209	Cost: 40.70s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 3.2628	Cost: 17.00s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 3.5725	Cost: 20.72s
Train Epoch: 91 	Average Loss: 3.6706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8301

Learning rate: 0.00017552818122851838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 4.8847	Cost: 40.64s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 3.5889	Cost: 9.77s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 3.6046	Cost: 23.84s
Train Epoch: 92 	Average Loss: 3.6245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7138

Saving model as e92_model.pt & e92_waveforms_supplementary.hdf5
Learning rate: 0.00017501110696304596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 5.0341	Cost: 42.54s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 3.3595	Cost: 9.87s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 3.7487	Cost: 25.28s
Train Epoch: 93 	Average Loss: 3.6332
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7754

Learning rate: 0.0001744894056591622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 5.0401	Cost: 42.31s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 3.2860	Cost: 16.82s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 3.4660	Cost: 18.07s
Train Epoch: 94 	Average Loss: 3.5545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7848

Learning rate: 0.00017396310949786096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 4.8497	Cost: 37.61s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 3.3801	Cost: 15.60s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 3.6240	Cost: 17.89s
Train Epoch: 95 	Average Loss: 3.5222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6151

Saving model as e95_model.pt & e95_waveforms_supplementary.hdf5
Learning rate: 0.00017343225094356858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 5.0003	Cost: 41.60s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 3.3333	Cost: 16.48s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 3.5485	Cost: 9.75s
Train Epoch: 96 	Average Loss: 3.5606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7177

Learning rate: 0.00017289686274214118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 4.9319	Cost: 41.52s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 3.2540	Cost: 9.58s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 3.5063	Cost: 19.37s
Train Epoch: 97 	Average Loss: 3.5112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7238

Learning rate: 0.00017235697791884494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 4.9161	Cost: 38.34s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 3.3432	Cost: 10.53s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 3.3818	Cost: 28.55s
Train Epoch: 98 	Average Loss: 3.5301
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7893

Learning rate: 0.0001718126297763189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 4.7764	Cost: 39.81s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 3.3005	Cost: 11.53s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 3.1945	Cost: 25.70s
Train Epoch: 99 	Average Loss: 3.5021
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7949

Learning rate: 0.00017126385189252056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 4.9084	Cost: 60.42s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 2.9645	Cost: 14.30s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 3.4777	Cost: 14.60s
Train Epoch: 100 	Average Loss: 3.4225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7123

Learning rate: 0.00017071067811865479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 4.5808	Cost: 54.60s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 3.2521	Cost: 13.51s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 3.2029	Cost: 16.75s
Train Epoch: 101 	Average Loss: 3.4112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7263

Learning rate: 0.00017015314257708562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 4.6998	Cost: 38.33s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 2.9627	Cost: 9.61s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 3.3464	Cost: 21.07s
Train Epoch: 102 	Average Loss: 3.3270
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6434

Learning rate: 0.00016959127965923145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 4.7422	Cost: 36.99s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 3.1718	Cost: 10.04s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 3.2075	Cost: 22.65s
Train Epoch: 103 	Average Loss: 3.3565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6587

Learning rate: 0.00016902512402344375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 4.5888	Cost: 37.77s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 3.0520	Cost: 11.85s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 3.1137	Cost: 24.41s
Train Epoch: 104 	Average Loss: 3.2935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6318

Learning rate: 0.0001684547105928689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 4.7164	Cost: 38.94s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 2.9648	Cost: 14.90s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 3.2209	Cost: 22.26s
Train Epoch: 105 	Average Loss: 3.3139
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6384

Learning rate: 0.00016788007455329423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 4.5395	Cost: 38.69s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 3.1015	Cost: 16.91s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 3.1291	Cost: 15.98s
Train Epoch: 106 	Average Loss: 3.2894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5815

Saving model as e106_model.pt & e106_waveforms_supplementary.hdf5
Learning rate: 0.00016730125135097737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 4.6943	Cost: 38.81s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 2.9477	Cost: 13.42s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 3.1584	Cost: 22.82s
Train Epoch: 107 	Average Loss: 3.2143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6150

Learning rate: 0.00016671827669046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 4.5399	Cost: 40.00s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 2.8027	Cost: 9.99s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 3.0438	Cost: 26.62s
Train Epoch: 108 	Average Loss: 3.1801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6024

Learning rate: 0.0001661311865323652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 4.6667	Cost: 46.27s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 3.0098	Cost: 9.86s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 3.0536	Cost: 28.11s
Train Epoch: 109 	Average Loss: 3.1738
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4465

Saving model as e109_model.pt & e109_waveforms_supplementary.hdf5
Learning rate: 0.00016554001709117943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 4.7470	Cost: 40.87s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 3.0274	Cost: 13.41s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 2.9732	Cost: 22.87s
Train Epoch: 110 	Average Loss: 3.1475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6637

Learning rate: 0.00016494480483301838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 4.8401	Cost: 41.70s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 2.9182	Cost: 14.88s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 2.9697	Cost: 19.00s
Train Epoch: 111 	Average Loss: 3.1136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4619

Learning rate: 0.0001643455864733779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 4.5367	Cost: 37.97s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 2.8649	Cost: 13.18s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 3.1184	Cost: 14.08s
Train Epoch: 112 	Average Loss: 3.0958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5098

Learning rate: 0.000163742398974869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 4.7707	Cost: 36.26s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 2.9121	Cost: 13.15s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 3.1237	Cost: 14.23s
Train Epoch: 113 	Average Loss: 3.1773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5430

Learning rate: 0.00016313527954493778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 4.6351	Cost: 37.95s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 2.7583	Cost: 11.97s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 2.8361	Cost: 15.17s
Train Epoch: 114 	Average Loss: 3.0291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3605

Saving model as e114_model.pt & e114_waveforms_supplementary.hdf5
Learning rate: 0.00016252426563357055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 4.6475	Cost: 35.17s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 2.6586	Cost: 13.03s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 2.8368	Cost: 22.13s
Train Epoch: 115 	Average Loss: 2.9852
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5693

Learning rate: 0.0001619093949309834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 4.3995	Cost: 39.06s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 2.8471	Cost: 11.01s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 2.8865	Cost: 27.28s
Train Epoch: 116 	Average Loss: 2.9611
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4662

Learning rate: 0.00016129070536529766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 4.4667	Cost: 40.57s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 2.8318	Cost: 10.55s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 2.7434	Cost: 28.50s
Train Epoch: 117 	Average Loss: 2.9843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5470

Learning rate: 0.00016066823510019996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 4.4381	Cost: 46.92s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 2.7474	Cost: 13.19s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 2.9711	Cost: 22.03s
Train Epoch: 118 	Average Loss: 3.0343
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3963

Learning rate: 0.0001600420225325884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 4.3146	Cost: 49.66s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 2.6837	Cost: 16.94s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 3.0222	Cost: 15.71s
Train Epoch: 119 	Average Loss: 2.9532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3620

Learning rate: 0.00015941210629020385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 4.3930	Cost: 60.01s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 2.5637	Cost: 9.71s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 2.8429	Cost: 19.83s
Train Epoch: 120 	Average Loss: 2.9090
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3430

Saving model as e120_model.pt & e120_waveforms_supplementary.hdf5
Learning rate: 0.00015877852522924735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 4.4964	Cost: 36.91s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 2.6850	Cost: 9.72s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 2.7400	Cost: 26.70s
Train Epoch: 121 	Average Loss: 2.9162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4451

Learning rate: 0.00015814131843198305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 4.2224	Cost: 38.19s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 2.4789	Cost: 10.16s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 2.6590	Cost: 26.32s
Train Epoch: 122 	Average Loss: 2.7932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4549

Learning rate: 0.00015750052520432787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 4.2054	Cost: 37.32s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 2.5088	Cost: 14.17s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 2.5414	Cost: 18.97s
Train Epoch: 123 	Average Loss: 2.7839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2069

Saving model as e123_model.pt & e123_waveforms_supplementary.hdf5
Learning rate: 0.0001568561850734264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 4.2839	Cost: 38.80s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 2.6444	Cost: 16.48s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 2.6417	Cost: 16.78s
Train Epoch: 124 	Average Loss: 2.7370
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3783

Learning rate: 0.00015620833778521307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 4.3254	Cost: 41.08s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 2.4854	Cost: 15.66s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 2.7202	Cost: 14.30s
Train Epoch: 125 	Average Loss: 2.7538
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1391

Saving model as e125_model.pt & e125_waveforms_supplementary.hdf5
Learning rate: 0.00015555702330196023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 4.1127	Cost: 41.05s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 2.2764	Cost: 13.33s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 2.6500	Cost: 16.73s
Train Epoch: 126 	Average Loss: 2.7126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1224

Saving model as e126_model.pt & e126_waveforms_supplementary.hdf5
Learning rate: 0.00015490228179981317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 4.3225	Cost: 36.39s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 2.4684	Cost: 10.74s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 2.5448	Cost: 23.13s
Train Epoch: 127 	Average Loss: 2.6781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2062

Learning rate: 0.00015424415366631188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 4.4244	Cost: 41.44s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 2.4941	Cost: 10.29s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 2.8178	Cost: 27.22s
Train Epoch: 128 	Average Loss: 2.7717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2540

Learning rate: 0.00015358267949789966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 4.6913	Cost: 46.16s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 2.6259	Cost: 14.14s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 2.6857	Cost: 22.09s
Train Epoch: 129 	Average Loss: 2.7937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3399

Learning rate: 0.00015291790009741904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 4.4909	Cost: 43.16s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 2.4304	Cost: 14.85s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 2.7165	Cost: 19.43s
Train Epoch: 130 	Average Loss: 2.7467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2125

Learning rate: 0.00015224985647159487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 4.2608	Cost: 44.13s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 2.4299	Cost: 13.90s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 2.7641	Cost: 13.37s
Train Epoch: 131 	Average Loss: 2.6586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2590

Learning rate: 0.00015157858982850473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 4.4709	Cost: 45.89s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 2.3814	Cost: 16.44s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 2.2851	Cost: 13.33s
Train Epoch: 132 	Average Loss: 2.5867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3005

Learning rate: 0.0001509041415750371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 4.0608	Cost: 43.88s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 2.2605	Cost: 11.01s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 2.3778	Cost: 19.11s
Train Epoch: 133 	Average Loss: 2.4987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1164

Saving model as e133_model.pt & e133_waveforms_supplementary.hdf5
Learning rate: 0.00015022655331433721
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 4.0199	Cost: 38.46s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 2.1596	Cost: 9.87s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 2.3610	Cost: 21.85s
Train Epoch: 134 	Average Loss: 2.4483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1542

Learning rate: 0.00014954586684324072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 4.1812	Cost: 37.20s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 2.1489	Cost: 9.80s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 2.3455	Cost: 28.11s
Train Epoch: 135 	Average Loss: 2.4180
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0570

Saving model as e135_model.pt & e135_waveforms_supplementary.hdf5
Learning rate: 0.00014886212414969547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 4.1596	Cost: 42.04s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 2.0700	Cost: 13.93s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 2.3067	Cost: 23.49s
Train Epoch: 136 	Average Loss: 2.3872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1023

Learning rate: 0.0001481753674101715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 4.2699	Cost: 40.32s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 2.3824	Cost: 13.50s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 2.4520	Cost: 25.09s
Train Epoch: 137 	Average Loss: 2.5012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2285

Learning rate: 0.00014748563898705943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 4.2918	Cost: 39.51s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 2.1366	Cost: 9.93s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 2.2678	Cost: 26.09s
Train Epoch: 138 	Average Loss: 2.4417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0718

Learning rate: 0.00014679298142605734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 4.2523	Cost: 41.48s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 2.0867	Cost: 11.62s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 2.3180	Cost: 20.28s
Train Epoch: 139 	Average Loss: 2.3890
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1943

Learning rate: 0.00014609743745354624
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 3.9555	Cost: 38.19s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 2.1777	Cost: 9.91s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 2.2865	Cost: 26.27s
Train Epoch: 140 	Average Loss: 2.4080
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8973

Saving model as e140_model.pt & e140_waveforms_supplementary.hdf5
Learning rate: 0.00014539904997395466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 4.1051	Cost: 45.15s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 1.8822	Cost: 16.88s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 2.2118	Cost: 19.37s
Train Epoch: 141 	Average Loss: 2.3769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0615

Learning rate: 0.0001446978620671121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 3.9713	Cost: 39.66s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 2.1763	Cost: 14.32s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 2.3164	Cost: 19.74s
Train Epoch: 142 	Average Loss: 2.3528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1296

Learning rate: 0.0001439939169855915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 4.0955	Cost: 39.25s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 2.0345	Cost: 16.74s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 2.1250	Cost: 15.89s
Train Epoch: 143 	Average Loss: 2.3451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0312

Learning rate: 0.0001432872581520414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 4.1280	Cost: 37.40s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 2.0215	Cost: 14.05s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 2.1617	Cost: 13.20s
Train Epoch: 144 	Average Loss: 2.3104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0183

Learning rate: 0.00014257792915650728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 4.1149	Cost: 42.45s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 2.0912	Cost: 9.95s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 2.3752	Cost: 18.52s
Train Epoch: 145 	Average Loss: 2.2817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0350

Learning rate: 0.0001418659737537428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 4.0865	Cost: 36.78s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 1.9521	Cost: 11.05s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 2.5476	Cost: 31.64s
Train Epoch: 146 	Average Loss: 2.2976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4916

Learning rate: 0.00014115143586051088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 4.2962	Cost: 38.84s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 2.4298	Cost: 15.15s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 2.3401	Cost: 22.92s
Train Epoch: 147 	Average Loss: 2.7048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2376

Learning rate: 0.0001404343595528745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 4.3168	Cost: 54.61s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 2.4364	Cost: 16.52s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 2.4032	Cost: 18.18s
Train Epoch: 148 	Average Loss: 2.4884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9904

Learning rate: 0.00013971478906347806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 3.9490	Cost: 46.67s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 1.9976	Cost: 14.51s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 2.0429	Cost: 14.77s
Train Epoch: 149 	Average Loss: 2.2061
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8232

Saving model as e149_model.pt & e149_waveforms_supplementary.hdf5
Learning rate: 0.00013899276877881884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 3.6583	Cost: 45.58s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 1.9750	Cost: 9.82s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 2.2843	Cost: 22.49s
Train Epoch: 150 	Average Loss: 2.0991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9732

Learning rate: 0.000138268343236509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 4.0253	Cost: 42.84s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 1.7949	Cost: 9.80s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 2.1951	Cost: 26.41s
Train Epoch: 151 	Average Loss: 2.1307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8278

Learning rate: 0.00013754155712252834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 3.8709	Cost: 37.85s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 1.7630	Cost: 9.88s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 1.9890	Cost: 26.84s
Train Epoch: 152 	Average Loss: 2.0546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9002

Learning rate: 0.00013681245526846785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 3.8822	Cost: 42.38s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 1.8046	Cost: 13.60s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 1.9984	Cost: 19.69s
Train Epoch: 153 	Average Loss: 2.0429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8392

Learning rate: 0.00013608108264876422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 3.8960	Cost: 34.90s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 1.8136	Cost: 9.93s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 2.1023	Cost: 16.80s
Train Epoch: 154 	Average Loss: 2.0312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7640

Saving model as e154_model.pt & e154_waveforms_supplementary.hdf5
Learning rate: 0.00013534748437792575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 4.2245	Cost: 34.52s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 1.8034	Cost: 9.48s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 2.0757	Cost: 19.13s
Train Epoch: 155 	Average Loss: 2.0481
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9176

Learning rate: 0.00013461170570774932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 3.9255	Cost: 33.99s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 1.7423	Cost: 9.46s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 1.9506	Cost: 20.62s
Train Epoch: 156 	Average Loss: 2.0122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7050

Saving model as e156_model.pt & e156_waveforms_supplementary.hdf5
Learning rate: 0.0001338737920245292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 3.8558	Cost: 34.54s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 1.7949	Cost: 9.45s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 1.7065	Cost: 21.27s
Train Epoch: 157 	Average Loss: 1.9124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6857

Saving model as e157_model.pt & e157_waveforms_supplementary.hdf5
Learning rate: 0.00013313378884625713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 3.8969	Cost: 34.62s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 1.3752	Cost: 9.52s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 1.6562	Cost: 22.51s
Train Epoch: 158 	Average Loss: 1.8948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7812

Learning rate: 0.00013239174181981498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 3.6614	Cost: 33.58s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 1.6527	Cost: 9.49s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 1.7944	Cost: 23.10s
Train Epoch: 159 	Average Loss: 1.8201
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7291

Learning rate: 0.00013164769671815865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 3.6243	Cost: 37.31s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 1.6425	Cost: 10.01s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 1.7607	Cost: 25.66s
Train Epoch: 160 	Average Loss: 1.7839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7025

Learning rate: 0.0001309016994374948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 3.6218	Cost: 45.66s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 1.6134	Cost: 16.79s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 1.7297	Cost: 17.04s
Train Epoch: 161 	Average Loss: 1.7691
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5255

Saving model as e161_model.pt & e161_waveforms_supplementary.hdf5
Learning rate: 0.00013015379599444962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 3.4817	Cost: 52.91s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 1.6566	Cost: 14.88s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 1.6025	Cost: 14.45s
Train Epoch: 162 	Average Loss: 1.7615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6450

Learning rate: 0.00012940403252323043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 3.6450	Cost: 36.86s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 1.6186	Cost: 12.20s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 1.5212	Cost: 18.13s
Train Epoch: 163 	Average Loss: 1.7680
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7623

Learning rate: 0.00012865245527277986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 3.7633	Cost: 35.38s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 1.4078	Cost: 9.97s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 1.5336	Cost: 26.17s
Train Epoch: 164 	Average Loss: 1.7463
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8188

Learning rate: 0.00012789911060392294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 3.7719	Cost: 38.14s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 1.5126	Cost: 16.43s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 1.6209	Cost: 16.95s
Train Epoch: 165 	Average Loss: 1.7424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4946

Saving model as e165_model.pt & e165_waveforms_supplementary.hdf5
Learning rate: 0.00012714404498650745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 3.6498	Cost: 42.18s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 1.4263	Cost: 17.04s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 1.7158	Cost: 16.06s
Train Epoch: 166 	Average Loss: 1.7087
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5432

Learning rate: 0.00012638730499653727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 3.4580	Cost: 37.56s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 1.1487	Cost: 9.86s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 1.3180	Cost: 24.05s
Train Epoch: 167 	Average Loss: 1.6104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7005

Learning rate: 0.00012562893731329965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 3.6935	Cost: 43.51s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 1.2774	Cost: 10.08s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 1.6408	Cost: 28.47s
Train Epoch: 168 	Average Loss: 1.7157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6809

Learning rate: 0.00012486898871648546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 3.5038	Cost: 51.10s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 1.3096	Cost: 16.18s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 1.4867	Cost: 16.65s
Train Epoch: 169 	Average Loss: 1.6273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6852

Learning rate: 0.00012410750608330388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 3.6840	Cost: 46.16s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 1.3849	Cost: 14.76s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 1.5380	Cost: 17.15s
Train Epoch: 170 	Average Loss: 1.7033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5691

Learning rate: 0.00012334453638559054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 3.7827	Cost: 43.49s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 1.3077	Cost: 9.76s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 1.5191	Cost: 22.16s
Train Epoch: 171 	Average Loss: 1.6312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5871

Learning rate: 0.00012258012668691037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 3.6615	Cost: 37.68s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 1.3357	Cost: 9.83s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 1.3061	Cost: 27.42s
Train Epoch: 172 	Average Loss: 1.5451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6272

Learning rate: 0.00012181432413965427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 3.5839	Cost: 37.81s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 1.1118	Cost: 14.20s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 1.1043	Cost: 20.45s
Train Epoch: 173 	Average Loss: 1.4762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3315

Saving model as e173_model.pt & e173_waveforms_supplementary.hdf5
Learning rate: 0.0001210471759821306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 3.4791	Cost: 40.87s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 1.0989	Cost: 16.38s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 1.0519	Cost: 18.76s
Train Epoch: 174 	Average Loss: 1.3995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6400

Learning rate: 0.00012027872953565127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 3.5805	Cost: 36.62s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 1.1363	Cost: 9.66s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 1.2993	Cost: 25.57s
Train Epoch: 175 	Average Loss: 1.4607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5692

Learning rate: 0.00011950903220161285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 3.6165	Cost: 39.70s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 1.1049	Cost: 9.85s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 1.1828	Cost: 26.70s
Train Epoch: 176 	Average Loss: 1.4134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4576

Learning rate: 0.00011873813145857249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 3.4839	Cost: 51.21s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 1.3554	Cost: 15.58s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 1.1771	Cost: 17.19s
Train Epoch: 177 	Average Loss: 1.3796
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6018

Learning rate: 0.00011796607485931927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 3.6331	Cost: 53.56s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 1.0327	Cost: 14.18s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 1.3072	Cost: 14.33s
Train Epoch: 178 	Average Loss: 1.3537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3995

Learning rate: 0.00011719291002794096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 3.5611	Cost: 36.97s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 1.0401	Cost: 12.59s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 1.3957	Cost: 17.50s
Train Epoch: 179 	Average Loss: 1.3801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4282

Learning rate: 0.0001164186846568863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 3.5524	Cost: 36.89s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 1.4401	Cost: 10.47s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 1.2076	Cost: 26.15s
Train Epoch: 180 	Average Loss: 1.4361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4236

Learning rate: 0.0001156434465040231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 3.1372	Cost: 41.20s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 1.0988	Cost: 14.91s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 1.3299	Cost: 20.57s
Train Epoch: 181 	Average Loss: 1.2912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3607

Learning rate: 0.00011486724338969234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 3.2246	Cost: 42.42s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 0.9638	Cost: 14.26s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 1.1899	Cost: 21.55s
Train Epoch: 182 	Average Loss: 1.3296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6005

Learning rate: 0.0001140901231937583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 3.1730	Cost: 43.79s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 1.0760	Cost: 10.45s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 1.1874	Cost: 28.43s
Train Epoch: 183 	Average Loss: 1.3008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3666

Learning rate: 0.00011331213385265528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 3.1928	Cost: 47.77s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 0.8350	Cost: 16.80s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 1.1811	Cost: 18.08s
Train Epoch: 184 	Average Loss: 1.2007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4057

Learning rate: 0.00011253332335643047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 3.4900	Cost: 39.62s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 0.9231	Cost: 16.64s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 0.9675	Cost: 14.08s
Train Epoch: 185 	Average Loss: 1.2749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3973

Learning rate: 0.0001117537397457838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 3.3750	Cost: 42.74s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 0.6801	Cost: 14.98s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 0.9775	Cost: 12.86s
Train Epoch: 186 	Average Loss: 1.1068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3373

Learning rate: 0.00011097343110910456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 3.3614	Cost: 43.27s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 0.7445	Cost: 9.63s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 1.0165	Cost: 19.57s
Train Epoch: 187 	Average Loss: 1.1176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1593

Saving model as e187_model.pt & e187_waveforms_supplementary.hdf5
Learning rate: 0.00011019244557950502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 3.3677	Cost: 34.42s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 0.8583	Cost: 9.88s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 0.9199	Cost: 26.71s
Train Epoch: 188 	Average Loss: 1.1142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1877

Learning rate: 0.00010941083133185145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 3.1709	Cost: 39.20s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 1.0747	Cost: 16.70s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 1.1563	Cost: 18.94s
Train Epoch: 189 	Average Loss: 1.2992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3363

Learning rate: 0.00010862863657979236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 3.3228	Cost: 39.99s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 0.7947	Cost: 16.79s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 1.0151	Cost: 13.60s
Train Epoch: 190 	Average Loss: 1.2393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3995

Learning rate: 0.00010784590957278452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 3.2911	Cost: 41.96s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 0.7570	Cost: 9.77s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 1.2274	Cost: 18.35s
Train Epoch: 191 	Average Loss: 1.1286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4283

Learning rate: 0.00010706269859311669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 3.4777	Cost: 34.45s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 0.9573	Cost: 9.85s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 0.9949	Cost: 31.54s
Train Epoch: 192 	Average Loss: 1.0797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3374

Learning rate: 0.00010627905195293137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 3.2174	Cost: 37.73s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 0.9541	Cost: 17.23s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 0.8091	Cost: 24.09s
Train Epoch: 193 	Average Loss: 1.0275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0453

Saving model as e193_model.pt & e193_waveforms_supplementary.hdf5
Learning rate: 0.00010549501799124461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 3.1661	Cost: 46.13s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 0.7678	Cost: 11.00s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 0.8816	Cost: 26.00s
Train Epoch: 194 	Average Loss: 1.0650
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3375

Learning rate: 0.00010471064507096429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 3.9107	Cost: 40.66s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 0.6600	Cost: 9.76s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 0.7514	Cost: 27.96s
Train Epoch: 195 	Average Loss: 1.0382
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1781

Learning rate: 0.00010392598157590689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 3.0765	Cost: 42.73s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 0.6503	Cost: 17.33s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 0.9263	Cost: 17.24s
Train Epoch: 196 	Average Loss: 0.9831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3647

Learning rate: 0.00010314107590781285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 3.4665	Cost: 40.92s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 0.8423	Cost: 15.05s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 0.9166	Cost: 13.54s
Train Epoch: 197 	Average Loss: 1.1032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2773

Learning rate: 0.00010235597648336105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 3.4120	Cost: 38.39s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 0.6946	Cost: 9.92s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 0.7983	Cost: 19.24s
Train Epoch: 198 	Average Loss: 1.0161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3648

Learning rate: 0.0001015707317311821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 3.1580	Cost: 35.62s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 0.6013	Cost: 9.92s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 0.4894	Cost: 31.09s
Train Epoch: 199 	Average Loss: 0.9935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1457

Learning rate: 0.00010078539008887115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 3.0032	Cost: 38.82s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 0.4957	Cost: 16.99s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 0.7848	Cost: 22.59s
Train Epoch: 200 	Average Loss: 0.8550
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0447

Saving model as e200_model.pt & e200_waveforms_supplementary.hdf5
Learning rate: 0.00010000000000000002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 3.1827	Cost: 37.98s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 0.3719	Cost: 13.91s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 0.4339	Cost: 18.07s
Train Epoch: 201 	Average Loss: 0.7606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0816

Learning rate: 9.92146099111289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 3.3018	Cost: 43.99s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 0.9952	Cost: 12.78s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 1.1752	Cost: 18.86s
Train Epoch: 202 	Average Loss: 1.1729
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2639

Learning rate: 9.842926826881797e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 3.5882	Cost: 42.08s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 1.0359	Cost: 10.10s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 0.9664	Cost: 26.10s
Train Epoch: 203 	Average Loss: 1.1115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1541

Learning rate: 9.7644023516639e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 3.1146	Cost: 45.83s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 0.8399	Cost: 16.53s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 1.0098	Cost: 16.87s
Train Epoch: 204 	Average Loss: 1.0987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2166

Learning rate: 9.68589240921872e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 3.2773	Cost: 45.05s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 0.6539	Cost: 15.19s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 0.9160	Cost: 11.89s
Train Epoch: 205 	Average Loss: 1.0473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4256

Learning rate: 9.607401842409317e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 3.2270	Cost: 38.98s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 0.6856	Cost: 12.55s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 0.6011	Cost: 16.76s
Train Epoch: 206 	Average Loss: 0.9166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2582

Learning rate: 9.528935492903578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 2.9800	Cost: 38.20s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 0.5498	Cost: 12.45s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 0.6635	Cost: 16.95s
Train Epoch: 207 	Average Loss: 0.7765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0884

Learning rate: 9.450498200875547e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 3.1349	Cost: 36.56s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 0.3750	Cost: 9.87s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 0.5728	Cost: 27.48s
Train Epoch: 208 	Average Loss: 0.7266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0529

Learning rate: 9.372094804706868e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 2.9685	Cost: 38.20s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 0.2949	Cost: 16.61s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 0.3926	Cost: 16.69s
Train Epoch: 209 	Average Loss: 0.6182
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9883

Saving model as e209_model.pt & e209_waveforms_supplementary.hdf5
Learning rate: 9.293730140688336e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 3.2027	Cost: 37.82s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 0.4029	Cost: 15.85s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 0.4567	Cost: 11.81s
Train Epoch: 210 	Average Loss: 0.6118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9087

Saving model as e210_model.pt & e210_waveforms_supplementary.hdf5
Learning rate: 9.215409042721555e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 2.8993	Cost: 36.06s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 0.0856	Cost: 9.69s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 0.2887	Cost: 20.53s
Train Epoch: 211 	Average Loss: 0.5774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9431

Learning rate: 9.13713634202077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 2.9190	Cost: 38.78s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 0.5695	Cost: 10.63s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 0.4935	Cost: 27.01s
Train Epoch: 212 	Average Loss: 0.5318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0532

Learning rate: 9.058916866814858e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 2.9352	Cost: 49.24s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 0.2074	Cost: 17.34s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 0.3757	Cost: 19.00s
Train Epoch: 213 	Average Loss: 0.5236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9606

Learning rate: 8.9807554420495e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 3.1186	Cost: 54.26s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 0.1074	Cost: 15.09s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 0.4328	Cost: 13.82s
Train Epoch: 214 	Average Loss: 0.5708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9556

Learning rate: 8.902656889089548e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 2.9169	Cost: 37.93s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 0.1867	Cost: 11.69s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 0.5050	Cost: 18.39s
Train Epoch: 215 	Average Loss: 0.5652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9916

Learning rate: 8.824626025421624e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 3.0588	Cost: 37.52s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 0.1823	Cost: 9.73s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 0.2909	Cost: 27.32s
Train Epoch: 216 	Average Loss: 0.4893
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9980

Learning rate: 8.746667664356959e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 2.9665	Cost: 41.11s
Train Epoch: 217 [40960/90000 (45%)]	Loss: -0.0259	Cost: 16.10s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 0.2251	Cost: 20.83s
Train Epoch: 217 	Average Loss: 0.4911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9190

Learning rate: 8.668786614734478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 2.9461	Cost: 42.82s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 0.0674	Cost: 9.77s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 0.4127	Cost: 26.01s
Train Epoch: 218 	Average Loss: 0.4081
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9881

Learning rate: 8.590987680624175e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 2.8429	Cost: 46.03s
Train Epoch: 219 [40960/90000 (45%)]	Loss: -0.0983	Cost: 12.02s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 0.1444	Cost: 20.88s
Train Epoch: 219 	Average Loss: 0.3424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7360

Saving model as e219_model.pt & e219_waveforms_supplementary.hdf5
Learning rate: 8.51327566103077e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 2.6535	Cost: 43.21s
Train Epoch: 220 [40960/90000 (45%)]	Loss: -0.0124	Cost: 14.50s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 0.2087	Cost: 21.10s
Train Epoch: 220 	Average Loss: 0.3015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8399

Learning rate: 8.435655349597692e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 2.9241	Cost: 45.85s
Train Epoch: 221 [40960/90000 (45%)]	Loss: -0.0930	Cost: 14.83s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 0.1587	Cost: 18.36s
Train Epoch: 221 	Average Loss: 0.3393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8791

Learning rate: 8.35813153431137e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 3.0605	Cost: 43.79s
Train Epoch: 222 [40960/90000 (45%)]	Loss: -0.1937	Cost: 15.15s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 0.0986	Cost: 15.11s
Train Epoch: 222 	Average Loss: 0.3355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8649

Learning rate: 8.280708997205904e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 3.0228	Cost: 42.19s
Train Epoch: 223 [40960/90000 (45%)]	Loss: -0.1132	Cost: 9.63s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 0.2716	Cost: 20.09s
Train Epoch: 223 	Average Loss: 0.3944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9236

Learning rate: 8.203392514068074e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 2.8213	Cost: 34.69s
Train Epoch: 224 [40960/90000 (45%)]	Loss: -0.1892	Cost: 9.83s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 0.0853	Cost: 27.76s
Train Epoch: 224 	Average Loss: 0.2451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8236

Learning rate: 8.126186854142755e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 2.4267	Cost: 36.82s
Train Epoch: 225 [40960/90000 (45%)]	Loss: -0.2922	Cost: 16.51s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 0.1290	Cost: 19.19s
Train Epoch: 225 	Average Loss: 0.2140
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7547

Learning rate: 8.049096779838719e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 2.7137	Cost: 39.74s
Train Epoch: 226 [40960/90000 (45%)]	Loss: -0.2262	Cost: 16.90s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 0.0544	Cost: 16.90s
Train Epoch: 226 	Average Loss: 0.2060
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8339

Learning rate: 7.972127046434877e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 2.8613	Cost: 43.67s
Train Epoch: 227 [40960/90000 (45%)]	Loss: -0.0086	Cost: 10.73s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 0.1260	Cost: 21.13s
Train Epoch: 227 	Average Loss: 0.1858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8542

Learning rate: 7.895282401786947e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 2.6176	Cost: 42.09s
Train Epoch: 228 [40960/90000 (45%)]	Loss: -0.2605	Cost: 9.83s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 0.0431	Cost: 27.71s
Train Epoch: 228 	Average Loss: 0.1449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7103

Saving model as e228_model.pt & e228_waveforms_supplementary.hdf5
Learning rate: 7.818567586034578e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 2.8790	Cost: 50.42s
Train Epoch: 229 [40960/90000 (45%)]	Loss: -0.4413	Cost: 16.76s
Train Epoch: 229 [81920/90000 (91%)]	Loss: -0.1144	Cost: 17.39s
Train Epoch: 229 	Average Loss: 0.1361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7526

Learning rate: 7.741987331308968e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 2.9910	Cost: 46.11s
Train Epoch: 230 [40960/90000 (45%)]	Loss: -0.3685	Cost: 13.83s
Train Epoch: 230 [81920/90000 (91%)]	Loss: -0.0453	Cost: 14.47s
Train Epoch: 230 	Average Loss: 0.1251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7930

Learning rate: 7.665546361440945e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 2.6288	Cost: 45.46s
Train Epoch: 231 [40960/90000 (45%)]	Loss: -0.2715	Cost: 9.54s
Train Epoch: 231 [81920/90000 (91%)]	Loss: -0.1135	Cost: 21.40s
Train Epoch: 231 	Average Loss: 0.1074
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7051

Saving model as e231_model.pt & e231_waveforms_supplementary.hdf5
Learning rate: 7.589249391669613e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 2.8919	Cost: 34.40s
Train Epoch: 232 [40960/90000 (45%)]	Loss: -0.2417	Cost: 10.30s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 0.0452	Cost: 26.55s
Train Epoch: 232 	Average Loss: 0.1350
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7376

Learning rate: 7.513101128351452e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 2.6632	Cost: 38.97s
Train Epoch: 233 [40960/90000 (45%)]	Loss: -0.1766	Cost: 17.11s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 0.0516	Cost: 18.64s
Train Epoch: 233 	Average Loss: 0.1124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7079

Learning rate: 7.437106268670034e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 2.4228	Cost: 39.60s
Train Epoch: 234 [40960/90000 (45%)]	Loss: -0.2893	Cost: 16.46s
Train Epoch: 234 [81920/90000 (91%)]	Loss: -0.3059	Cost: 16.87s
Train Epoch: 234 	Average Loss: 0.0331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6499

Saving model as e234_model.pt & e234_waveforms_supplementary.hdf5
Learning rate: 7.361269500346273e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 2.5965	Cost: 41.00s
Train Epoch: 235 [40960/90000 (45%)]	Loss: -0.3619	Cost: 10.31s
Train Epoch: 235 [81920/90000 (91%)]	Loss: -0.2150	Cost: 20.51s
Train Epoch: 235 	Average Loss: 0.0155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7076

Learning rate: 7.28559550134926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 2.6987	Cost: 37.34s
Train Epoch: 236 [40960/90000 (45%)]	Loss: -0.3812	Cost: 10.02s
Train Epoch: 236 [81920/90000 (91%)]	Loss: -0.0139	Cost: 24.04s
Train Epoch: 236 	Average Loss: 0.0533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7095

Learning rate: 7.210088939607711e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 2.8244	Cost: 45.44s
Train Epoch: 237 [40960/90000 (45%)]	Loss: -0.1925	Cost: 12.95s
Train Epoch: 237 [81920/90000 (91%)]	Loss: -0.1829	Cost: 24.27s
Train Epoch: 237 	Average Loss: 0.0977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6223

Saving model as e237_model.pt & e237_waveforms_supplementary.hdf5
Learning rate: 7.13475447272202e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 2.6700	Cost: 56.57s
Train Epoch: 238 [40960/90000 (45%)]	Loss: -0.4837	Cost: 15.07s
Train Epoch: 238 [81920/90000 (91%)]	Loss: -0.2438	Cost: 12.37s
Train Epoch: 238 	Average Loss: -0.0086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6510

Learning rate: 7.059596747676965e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 2.5876	Cost: 38.54s
Train Epoch: 239 [40960/90000 (45%)]	Loss: -0.3031	Cost: 11.35s
Train Epoch: 239 [81920/90000 (91%)]	Loss: -0.1753	Cost: 16.74s
Train Epoch: 239 	Average Loss: 0.0196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7458

Learning rate: 6.984620400555048e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 2.6083	Cost: 35.07s
Train Epoch: 240 [40960/90000 (45%)]	Loss: -0.3808	Cost: 9.79s
Train Epoch: 240 [81920/90000 (91%)]	Loss: -0.2351	Cost: 26.93s
Train Epoch: 240 	Average Loss: 0.0374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5763

Saving model as e240_model.pt & e240_waveforms_supplementary.hdf5
Learning rate: 6.909830056250531e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 2.5628	Cost: 37.46s
Train Epoch: 241 [40960/90000 (45%)]	Loss: -0.4452	Cost: 13.58s
Train Epoch: 241 [81920/90000 (91%)]	Loss: -0.2211	Cost: 22.40s
Train Epoch: 241 	Average Loss: -0.0786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7105

Learning rate: 6.835230328184141e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 2.5361	Cost: 37.87s
Train Epoch: 242 [40960/90000 (45%)]	Loss: -0.5674	Cost: 16.59s
Train Epoch: 242 [81920/90000 (91%)]	Loss: -0.4789	Cost: 16.69s
Train Epoch: 242 	Average Loss: -0.1196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6605

Learning rate: 6.760825818018508e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 2.2620	Cost: 43.41s
Train Epoch: 243 [40960/90000 (45%)]	Loss: -0.4183	Cost: 9.69s
Train Epoch: 243 [81920/90000 (91%)]	Loss: -0.2846	Cost: 20.08s
Train Epoch: 243 	Average Loss: -0.1689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5158

Saving model as e243_model.pt & e243_waveforms_supplementary.hdf5
Learning rate: 6.686621115374292e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 2.3003	Cost: 37.96s
Train Epoch: 244 [40960/90000 (45%)]	Loss: -0.5572	Cost: 11.16s
Train Epoch: 244 [81920/90000 (91%)]	Loss: -0.3806	Cost: 27.52s
Train Epoch: 244 	Average Loss: -0.1252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6575

Learning rate: 6.61262079754709e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 2.5770	Cost: 54.65s
Train Epoch: 245 [40960/90000 (45%)]	Loss: -0.6439	Cost: 16.55s
Train Epoch: 245 [81920/90000 (91%)]	Loss: -0.1890	Cost: 17.59s
Train Epoch: 245 	Average Loss: -0.2053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6388

Learning rate: 6.538829429225073e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 2.5386	Cost: 46.84s
Train Epoch: 246 [40960/90000 (45%)]	Loss: -0.6091	Cost: 9.84s
Train Epoch: 246 [81920/90000 (91%)]	Loss: -0.1939	Cost: 20.73s
Train Epoch: 246 	Average Loss: -0.1458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6652

Learning rate: 6.465251562207432e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 2.5900	Cost: 37.55s
Train Epoch: 247 [40960/90000 (45%)]	Loss: -0.4301	Cost: 10.00s
Train Epoch: 247 [81920/90000 (91%)]	Loss: -0.4479	Cost: 27.10s
Train Epoch: 247 	Average Loss: -0.1507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4700

Saving model as e247_model.pt & e247_waveforms_supplementary.hdf5
Learning rate: 6.391891735123586e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 2.5240	Cost: 39.81s
Train Epoch: 248 [40960/90000 (45%)]	Loss: -0.4465	Cost: 16.41s
Train Epoch: 248 [81920/90000 (91%)]	Loss: -0.5145	Cost: 18.84s
Train Epoch: 248 	Average Loss: -0.2012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4872

Learning rate: 6.318754473153225e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 2.3765	Cost: 38.79s
Train Epoch: 249 [40960/90000 (45%)]	Loss: -0.4971	Cost: 16.75s
Train Epoch: 249 [81920/90000 (91%)]	Loss: -0.3136	Cost: 16.59s
Train Epoch: 249 	Average Loss: -0.2331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5601

Learning rate: 6.245844287747173e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 2.2598	Cost: 41.67s
Train Epoch: 250 [40960/90000 (45%)]	Loss: -0.6369	Cost: 15.93s
Train Epoch: 250 [81920/90000 (91%)]	Loss: -0.5041	Cost: 12.39s
Train Epoch: 250 	Average Loss: -0.3700
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4611

Saving model as e250_model.pt & e250_waveforms_supplementary.hdf5
Learning rate: 6.173165676349108e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 2.1532	Cost: 36.05s
Train Epoch: 251 [40960/90000 (45%)]	Loss: -0.8957	Cost: 11.62s
Train Epoch: 251 [81920/90000 (91%)]	Loss: -0.5770	Cost: 23.75s
Train Epoch: 251 	Average Loss: -0.3572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4703

Learning rate: 6.10072312211812e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 2.2897	Cost: 38.19s
Train Epoch: 252 [40960/90000 (45%)]	Loss: -0.7240	Cost: 11.22s
Train Epoch: 252 [81920/90000 (91%)]	Loss: -0.5870	Cost: 27.65s
Train Epoch: 252 	Average Loss: -0.3604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4077

Saving model as e252_model.pt & e252_waveforms_supplementary.hdf5
Learning rate: 6.0285210936521955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 2.4800	Cost: 43.82s
Train Epoch: 253 [40960/90000 (45%)]	Loss: -0.8693	Cost: 16.76s
Train Epoch: 253 [81920/90000 (91%)]	Loss: -0.6517	Cost: 19.67s
Train Epoch: 253 	Average Loss: -0.3928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4280

Learning rate: 5.956564044712553e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 2.5392	Cost: 44.34s
Train Epoch: 254 [40960/90000 (45%)]	Loss: -0.8452	Cost: 16.25s
Train Epoch: 254 [81920/90000 (91%)]	Loss: -0.4696	Cost: 19.44s
Train Epoch: 254 	Average Loss: -0.3783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3908

Saving model as e254_model.pt & e254_waveforms_supplementary.hdf5
Learning rate: 5.8848564139489155e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 2.2321	Cost: 52.29s
Train Epoch: 255 [40960/90000 (45%)]	Loss: -0.7559	Cost: 12.37s
Train Epoch: 255 [81920/90000 (91%)]	Loss: -0.6991	Cost: 18.07s
Train Epoch: 255 	Average Loss: -0.4259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4978

Learning rate: 5.813402624625721e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 2.1010	Cost: 37.25s
Train Epoch: 256 [40960/90000 (45%)]	Loss: -0.6957	Cost: 9.94s
Train Epoch: 256 [81920/90000 (91%)]	Loss: -0.4256	Cost: 26.35s
Train Epoch: 256 	Average Loss: -0.4515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4750

Learning rate: 5.742207084349277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 2.2507	Cost: 37.99s
Train Epoch: 257 [40960/90000 (45%)]	Loss: -0.9201	Cost: 16.66s
Train Epoch: 257 [81920/90000 (91%)]	Loss: -0.6883	Cost: 17.49s
Train Epoch: 257 	Average Loss: -0.4910
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4157

Learning rate: 5.6712741847958634e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 2.5553	Cost: 36.36s
Train Epoch: 258 [40960/90000 (45%)]	Loss: -0.7264	Cost: 16.82s
Train Epoch: 258 [81920/90000 (91%)]	Loss: -0.6317	Cost: 16.55s
Train Epoch: 258 	Average Loss: -0.4681
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3726

Saving model as e258_model.pt & e258_waveforms_supplementary.hdf5
Learning rate: 5.600608301440851e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 2.4283	Cost: 36.34s
Train Epoch: 259 [40960/90000 (45%)]	Loss: -0.9617	Cost: 14.70s
Train Epoch: 259 [81920/90000 (91%)]	Loss: -0.7299	Cost: 12.18s
Train Epoch: 259 	Average Loss: -0.5179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3627

Saving model as e259_model.pt & e259_waveforms_supplementary.hdf5
Learning rate: 5.5302137932887924e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 2.4753	Cost: 34.91s
Train Epoch: 260 [40960/90000 (45%)]	Loss: -0.8117	Cost: 9.61s
Train Epoch: 260 [81920/90000 (91%)]	Loss: -0.7280	Cost: 17.87s
Train Epoch: 260 	Average Loss: -0.5267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3983

Learning rate: 5.460095002604535e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 2.0840	Cost: 35.11s
Train Epoch: 261 [40960/90000 (45%)]	Loss: -1.0927	Cost: 9.88s
Train Epoch: 261 [81920/90000 (91%)]	Loss: -0.8000	Cost: 29.67s
Train Epoch: 261 	Average Loss: -0.6236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5116

Learning rate: 5.390256254645381e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 2.4234	Cost: 36.63s
Train Epoch: 262 [40960/90000 (45%)]	Loss: -0.8586	Cost: 17.73s
Train Epoch: 262 [81920/90000 (91%)]	Loss: -0.6770	Cost: 24.28s
Train Epoch: 262 	Average Loss: -0.4950
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4261

Learning rate: 5.3207018573942705e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 2.0985	Cost: 40.76s
Train Epoch: 263 [40960/90000 (45%)]	Loss: -0.9567	Cost: 16.59s
Train Epoch: 263 [81920/90000 (91%)]	Loss: -0.8484	Cost: 15.81s
Train Epoch: 263 	Average Loss: -0.6079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2506

Saving model as e263_model.pt & e263_waveforms_supplementary.hdf5
Learning rate: 5.251436101294054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 2.5125	Cost: 38.07s
Train Epoch: 264 [40960/90000 (45%)]	Loss: -0.9189	Cost: 9.74s
Train Epoch: 264 [81920/90000 (91%)]	Loss: -0.7698	Cost: 23.73s
Train Epoch: 264 	Average Loss: -0.5852
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3885

Learning rate: 5.1824632589828485e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 2.2163	Cost: 41.39s
Train Epoch: 265 [40960/90000 (45%)]	Loss: -1.1159	Cost: 10.09s
Train Epoch: 265 [81920/90000 (91%)]	Loss: -0.7210	Cost: 26.85s
Train Epoch: 265 	Average Loss: -0.6329
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2582

Learning rate: 5.1137875850304516e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 2.2707	Cost: 39.03s
Train Epoch: 266 [40960/90000 (45%)]	Loss: -0.7916	Cost: 15.90s
Train Epoch: 266 [81920/90000 (91%)]	Loss: -0.7012	Cost: 19.29s
Train Epoch: 266 	Average Loss: -0.5887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2973

Learning rate: 5.045413315675926e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 2.1313	Cost: 40.34s
Train Epoch: 267 [40960/90000 (45%)]	Loss: -1.1235	Cost: 15.55s
Train Epoch: 267 [81920/90000 (91%)]	Loss: -0.7543	Cost: 18.19s
Train Epoch: 267 	Average Loss: -0.6475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4151

Learning rate: 4.977344668566277e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 2.2893	Cost: 43.02s
Train Epoch: 268 [40960/90000 (45%)]	Loss: -1.0225	Cost: 12.51s
Train Epoch: 268 [81920/90000 (91%)]	Loss: -0.7574	Cost: 16.09s
Train Epoch: 268 	Average Loss: -0.5888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2382

Saving model as e268_model.pt & e268_waveforms_supplementary.hdf5
Learning rate: 4.909585842496289e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 2.0112	Cost: 37.16s
Train Epoch: 269 [40960/90000 (45%)]	Loss: -1.1590	Cost: 11.96s
Train Epoch: 269 [81920/90000 (91%)]	Loss: -0.7976	Cost: 26.84s
Train Epoch: 269 	Average Loss: -0.6725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2463

Learning rate: 4.842141017149528e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 2.1707	Cost: 46.92s
Train Epoch: 270 [40960/90000 (45%)]	Loss: -1.1785	Cost: 16.73s
Train Epoch: 270 [81920/90000 (91%)]	Loss: -0.9011	Cost: 20.85s
Train Epoch: 270 	Average Loss: -0.6768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3293

Learning rate: 4.775014352840514e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 1.8623	Cost: 51.15s
Train Epoch: 271 [40960/90000 (45%)]	Loss: -1.2099	Cost: 14.80s
Train Epoch: 271 [81920/90000 (91%)]	Loss: -0.8155	Cost: 14.33s
Train Epoch: 271 	Average Loss: -0.7448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2315

Saving model as e271_model.pt & e271_waveforms_supplementary.hdf5
Learning rate: 4.708209990258097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 2.1124	Cost: 45.30s
Train Epoch: 272 [40960/90000 (45%)]	Loss: -1.3126	Cost: 9.84s
Train Epoch: 272 [81920/90000 (91%)]	Loss: -0.9171	Cost: 21.28s
Train Epoch: 272 	Average Loss: -0.8037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2387

Learning rate: 4.641732050210033e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 2.2367	Cost: 38.56s
Train Epoch: 273 [40960/90000 (45%)]	Loss: -1.5247	Cost: 9.95s
Train Epoch: 273 [81920/90000 (91%)]	Loss: -1.1380	Cost: 22.59s
Train Epoch: 273 	Average Loss: -0.8289
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1429

Saving model as e273_model.pt & e273_waveforms_supplementary.hdf5
Learning rate: 4.575584633368813e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 2.0816	Cost: 38.52s
Train Epoch: 274 [40960/90000 (45%)]	Loss: -1.4102	Cost: 10.27s
Train Epoch: 274 [81920/90000 (91%)]	Loss: -0.9698	Cost: 27.29s
Train Epoch: 274 	Average Loss: -0.8606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1198

Saving model as e274_model.pt & e274_waveforms_supplementary.hdf5
Learning rate: 4.509771820018683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 2.0700	Cost: 39.46s
Train Epoch: 275 [40960/90000 (45%)]	Loss: -1.2115	Cost: 16.32s
Train Epoch: 275 [81920/90000 (91%)]	Loss: -1.0131	Cost: 13.69s
Train Epoch: 275 	Average Loss: -0.8302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0535

Saving model as e275_model.pt & e275_waveforms_supplementary.hdf5
Learning rate: 4.4442976698039786e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 2.0658	Cost: 40.46s
Train Epoch: 276 [40960/90000 (45%)]	Loss: -1.2022	Cost: 9.95s
Train Epoch: 276 [81920/90000 (91%)]	Loss: -0.8941	Cost: 19.74s
Train Epoch: 276 	Average Loss: -0.8490
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2681

Learning rate: 4.379166221478695e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 1.8547	Cost: 34.39s
Train Epoch: 277 [40960/90000 (45%)]	Loss: -1.3374	Cost: 9.77s
Train Epoch: 277 [81920/90000 (91%)]	Loss: -0.8907	Cost: 28.11s
Train Epoch: 277 	Average Loss: -0.9181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1811

Learning rate: 4.3143814926573614e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 2.0935	Cost: 37.31s
Train Epoch: 278 [40960/90000 (45%)]	Loss: -1.3524	Cost: 15.90s
Train Epoch: 278 [81920/90000 (91%)]	Loss: -1.0637	Cost: 21.50s
Train Epoch: 278 	Average Loss: -0.8994
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0677

Learning rate: 4.249947479567216e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 1.9969	Cost: 42.54s
Train Epoch: 279 [40960/90000 (45%)]	Loss: -1.4051	Cost: 9.84s
Train Epoch: 279 [81920/90000 (91%)]	Loss: -1.1985	Cost: 25.80s
Train Epoch: 279 	Average Loss: -0.9454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1827

Learning rate: 4.1858681568016955e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 2.1854	Cost: 43.20s
Train Epoch: 280 [40960/90000 (45%)]	Loss: -1.5154	Cost: 9.84s
Train Epoch: 280 [81920/90000 (91%)]	Loss: -0.9213	Cost: 27.17s
Train Epoch: 280 	Average Loss: -0.9057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1018

Learning rate: 4.122147477075271e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 1.9318	Cost: 44.83s
Train Epoch: 281 [40960/90000 (45%)]	Loss: -1.2323	Cost: 16.79s
Train Epoch: 281 [81920/90000 (91%)]	Loss: -1.0419	Cost: 17.10s
Train Epoch: 281 	Average Loss: -0.8152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0908

Learning rate: 4.058789370979617e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 2.2046	Cost: 42.33s
Train Epoch: 282 [40960/90000 (45%)]	Loss: -1.3757	Cost: 16.14s
Train Epoch: 282 [81920/90000 (91%)]	Loss: -1.0807	Cost: 16.33s
Train Epoch: 282 	Average Loss: -0.8741
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9390

Saving model as e282_model.pt & e282_waveforms_supplementary.hdf5
Learning rate: 3.995797746741162e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 1.9359	Cost: 42.04s
Train Epoch: 283 [40960/90000 (45%)]	Loss: -1.0104	Cost: 9.63s
Train Epoch: 283 [81920/90000 (91%)]	Loss: -0.9734	Cost: 20.32s
Train Epoch: 283 	Average Loss: -0.7890
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2164

Learning rate: 3.933176489980003e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 2.3477	Cost: 35.13s
Train Epoch: 284 [40960/90000 (45%)]	Loss: -1.2017	Cost: 9.94s
Train Epoch: 284 [81920/90000 (91%)]	Loss: -1.1696	Cost: 27.45s
Train Epoch: 284 	Average Loss: -0.8322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0567

Learning rate: 3.8709294634702356e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 2.1400	Cost: 36.89s
Train Epoch: 285 [40960/90000 (45%)]	Loss: -1.4728	Cost: 15.74s
Train Epoch: 285 [81920/90000 (91%)]	Loss: -1.2541	Cost: 22.79s
Train Epoch: 285 	Average Loss: -0.9690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1065

Learning rate: 3.809060506901661e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 1.8247	Cost: 37.52s
Train Epoch: 286 [40960/90000 (45%)]	Loss: -1.4635	Cost: 16.83s
Train Epoch: 286 [81920/90000 (91%)]	Loss: -1.1101	Cost: 20.27s
Train Epoch: 286 	Average Loss: -1.0212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1711

Learning rate: 3.747573436642949e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 2.0961	Cost: 39.95s
Train Epoch: 287 [40960/90000 (45%)]	Loss: -1.2716	Cost: 11.07s
Train Epoch: 287 [81920/90000 (91%)]	Loss: -1.2760	Cost: 28.59s
Train Epoch: 287 	Average Loss: -0.9792
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8942

Saving model as e287_model.pt & e287_waveforms_supplementary.hdf5
Learning rate: 3.686472045506224e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 2.1655	Cost: 41.33s
Train Epoch: 288 [40960/90000 (45%)]	Loss: -1.3919	Cost: 9.93s
Train Epoch: 288 [81920/90000 (91%)]	Loss: -1.2742	Cost: 26.47s
Train Epoch: 288 	Average Loss: -1.0076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0207

Learning rate: 3.625760102513104e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 1.9382	Cost: 44.14s
Train Epoch: 289 [40960/90000 (45%)]	Loss: -1.4423	Cost: 16.39s
Train Epoch: 289 [81920/90000 (91%)]	Loss: -1.3114	Cost: 16.93s
Train Epoch: 289 	Average Loss: -1.0706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1667

Learning rate: 3.5654413526622126e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 1.8327	Cost: 49.43s
Train Epoch: 290 [40960/90000 (45%)]	Loss: -1.5437	Cost: 16.02s
Train Epoch: 290 [81920/90000 (91%)]	Loss: -1.0741	Cost: 16.56s
Train Epoch: 290 	Average Loss: -1.0993
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9932

Learning rate: 3.505519516698166e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 1.7342	Cost: 41.11s
Train Epoch: 291 [40960/90000 (45%)]	Loss: -1.5762	Cost: 9.81s
Train Epoch: 291 [81920/90000 (91%)]	Loss: -1.2131	Cost: 20.11s
Train Epoch: 291 	Average Loss: -1.1571
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1597

Learning rate: 3.445998290882063e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 1.9700	Cost: 34.65s
Train Epoch: 292 [40960/90000 (45%)]	Loss: -1.4731	Cost: 9.77s
Train Epoch: 292 [81920/90000 (91%)]	Loss: -1.4881	Cost: 27.75s
Train Epoch: 292 	Average Loss: -1.1557
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9772

Learning rate: 3.386881346763484e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 1.9569	Cost: 37.39s
Train Epoch: 293 [40960/90000 (45%)]	Loss: -1.6337	Cost: 17.10s
Train Epoch: 293 [81920/90000 (91%)]	Loss: -1.4170	Cost: 23.83s
Train Epoch: 293 	Average Loss: -1.2003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8851

Saving model as e293_model.pt & e293_waveforms_supplementary.hdf5
Learning rate: 3.328172330954006e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 1.7498	Cost: 41.97s
Train Epoch: 294 [40960/90000 (45%)]	Loss: -1.7053	Cost: 14.95s
Train Epoch: 294 [81920/90000 (91%)]	Loss: -1.3324	Cost: 18.09s
Train Epoch: 294 	Average Loss: -1.2261
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9678

Learning rate: 3.269874864902267e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 2.0118	Cost: 42.87s
Train Epoch: 295 [40960/90000 (45%)]	Loss: -1.5632	Cost: 12.84s
Train Epoch: 295 [81920/90000 (91%)]	Loss: -1.4663	Cost: 16.96s
Train Epoch: 295 	Average Loss: -1.2049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8475

Saving model as e295_model.pt & e295_waveforms_supplementary.hdf5
Learning rate: 3.2119925446705836e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 1.6482	Cost: 41.09s
Train Epoch: 296 [40960/90000 (45%)]	Loss: -1.7005	Cost: 9.91s
Train Epoch: 296 [81920/90000 (91%)]	Loss: -1.4980	Cost: 25.42s
Train Epoch: 296 	Average Loss: -1.2717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8755

Learning rate: 3.1545289407131144e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 1.7341	Cost: 39.85s
Train Epoch: 297 [40960/90000 (45%)]	Loss: -1.6910	Cost: 16.59s
Train Epoch: 297 [81920/90000 (91%)]	Loss: -1.5125	Cost: 18.12s
Train Epoch: 297 	Average Loss: -1.2874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8735

Learning rate: 3.09748759765563e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 1.8695	Cost: 41.18s
Train Epoch: 298 [40960/90000 (45%)]	Loss: -1.7512	Cost: 16.71s
Train Epoch: 298 [81920/90000 (91%)]	Loss: -1.5193	Cost: 12.95s
Train Epoch: 298 	Average Loss: -1.2760
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8960

Learning rate: 3.0408720340768585e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 1.7577	Cost: 38.76s
Train Epoch: 299 [40960/90000 (45%)]	Loss: -1.8607	Cost: 10.51s
Train Epoch: 299 [81920/90000 (91%)]	Loss: -1.4124	Cost: 19.02s
Train Epoch: 299 	Average Loss: -1.3057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7926

Saving model as e299_model.pt & e299_waveforms_supplementary.hdf5
Learning rate: 2.9846857422914446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 1.7139	Cost: 35.05s
Train Epoch: 300 [40960/90000 (45%)]	Loss: -1.9087	Cost: 10.86s
Train Epoch: 300 [81920/90000 (91%)]	Loss: -1.5541	Cost: 30.97s
Train Epoch: 300 	Average Loss: -1.2924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8699

Learning rate: 2.9289321881345268e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 1.9874	Cost: 40.77s
Train Epoch: 301 [40960/90000 (45%)]	Loss: -1.8113	Cost: 17.14s
Train Epoch: 301 [81920/90000 (91%)]	Loss: -1.4838	Cost: 20.38s
Train Epoch: 301 	Average Loss: -1.2990
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8805

Learning rate: 2.8736148107479478e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 1.5499	Cost: 58.00s
Train Epoch: 302 [40960/90000 (45%)]	Loss: -1.7106	Cost: 14.37s
Train Epoch: 302 [81920/90000 (91%)]	Loss: -1.6539	Cost: 18.20s
Train Epoch: 302 	Average Loss: -1.3319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8111

Learning rate: 2.8187370223681142e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 1.9580	Cost: 38.23s
Train Epoch: 303 [40960/90000 (45%)]	Loss: -1.8924	Cost: 9.78s
Train Epoch: 303 [81920/90000 (91%)]	Loss: -1.5267	Cost: 25.47s
Train Epoch: 303 	Average Loss: -1.3148
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8385

Learning rate: 2.764302208115509e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 1.7174	Cost: 37.52s
Train Epoch: 304 [40960/90000 (45%)]	Loss: -1.5851	Cost: 9.93s
Train Epoch: 304 [81920/90000 (91%)]	Loss: -1.6517	Cost: 26.30s
Train Epoch: 304 	Average Loss: -1.3589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9454

Learning rate: 2.710313725785888e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 1.4762	Cost: 38.98s
Train Epoch: 305 [40960/90000 (45%)]	Loss: -1.6958	Cost: 16.73s
Train Epoch: 305 [81920/90000 (91%)]	Loss: -1.4727	Cost: 16.75s
Train Epoch: 305 	Average Loss: -1.3302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9155

Learning rate: 2.6567749056431446e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 1.9883	Cost: 40.43s
Train Epoch: 306 [40960/90000 (45%)]	Loss: -1.8314	Cost: 12.11s
Train Epoch: 306 [81920/90000 (91%)]	Loss: -1.6381	Cost: 16.52s
Train Epoch: 306 	Average Loss: -1.3913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7188

Saving model as e306_model.pt & e306_waveforms_supplementary.hdf5
Learning rate: 2.6036890502139035e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 1.6703	Cost: 35.65s
Train Epoch: 307 [40960/90000 (45%)]	Loss: -1.8109	Cost: 13.00s
Train Epoch: 307 [81920/90000 (91%)]	Loss: -1.6181	Cost: 21.71s
Train Epoch: 307 	Average Loss: -1.4232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8824

Learning rate: 2.55105943408378e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 1.8432	Cost: 37.70s
Train Epoch: 308 [40960/90000 (45%)]	Loss: -1.8356	Cost: 11.37s
Train Epoch: 308 [81920/90000 (91%)]	Loss: -1.7611	Cost: 32.42s
Train Epoch: 308 	Average Loss: -1.4353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7509

Learning rate: 2.4988893036954053e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 1.9801	Cost: 52.41s
Train Epoch: 309 [40960/90000 (45%)]	Loss: -1.9488	Cost: 16.81s
Train Epoch: 309 [81920/90000 (91%)]	Loss: -1.4444	Cost: 18.06s
Train Epoch: 309 	Average Loss: -1.4631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8834

Learning rate: 2.4471818771481658e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 1.4043	Cost: 54.03s
Train Epoch: 310 [40960/90000 (45%)]	Loss: -1.7883	Cost: 15.79s
Train Epoch: 310 [81920/90000 (91%)]	Loss: -1.7334	Cost: 14.71s
Train Epoch: 310 	Average Loss: -1.4585
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8980

Learning rate: 2.3959403439996917e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 1.6551	Cost: 39.59s
Train Epoch: 311 [40960/90000 (45%)]	Loss: -1.9958	Cost: 9.67s
Train Epoch: 311 [81920/90000 (91%)]	Loss: -1.7280	Cost: 23.09s
Train Epoch: 311 	Average Loss: -1.5384
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8186

Learning rate: 2.345167865069121e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 1.6198	Cost: 33.75s
Train Epoch: 312 [40960/90000 (45%)]	Loss: -1.8365	Cost: 10.03s
Train Epoch: 312 [81920/90000 (91%)]	Loss: -1.8194	Cost: 27.32s
Train Epoch: 312 	Average Loss: -1.4943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7480

Learning rate: 2.2948675722421096e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 1.5862	Cost: 38.24s
Train Epoch: 313 [40960/90000 (45%)]	Loss: -1.9870	Cost: 14.59s
Train Epoch: 313 [81920/90000 (91%)]	Loss: -1.7987	Cost: 17.10s
Train Epoch: 313 	Average Loss: -1.5362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7953

Learning rate: 2.2450425682776575e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 1.7835	Cost: 42.16s
Train Epoch: 314 [40960/90000 (45%)]	Loss: -1.9030	Cost: 16.91s
Train Epoch: 314 [81920/90000 (91%)]	Loss: -1.6757	Cost: 13.20s
Train Epoch: 314 	Average Loss: -1.5154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6525

Saving model as e314_model.pt & e314_waveforms_supplementary.hdf5
Learning rate: 2.1956959266167054e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 1.4271	Cost: 39.06s
Train Epoch: 315 [40960/90000 (45%)]	Loss: -1.9872	Cost: 9.73s
Train Epoch: 315 [81920/90000 (91%)]	Loss: -1.8306	Cost: 22.66s
Train Epoch: 315 	Average Loss: -1.5484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7436

Learning rate: 2.1468306911925506e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 1.6823	Cost: 37.37s
Train Epoch: 316 [40960/90000 (45%)]	Loss: -1.9790	Cost: 10.44s
Train Epoch: 316 [81920/90000 (91%)]	Loss: -1.6731	Cost: 26.53s
Train Epoch: 316 	Average Loss: -1.5903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6776

Learning rate: 2.098449876243097e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 1.6587	Cost: 53.80s
Train Epoch: 317 [40960/90000 (45%)]	Loss: -2.1198	Cost: 16.71s
Train Epoch: 317 [81920/90000 (91%)]	Loss: -1.9837	Cost: 18.41s
Train Epoch: 317 	Average Loss: -1.6117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6791

Learning rate: 2.050556466124901e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 1.2158	Cost: 51.87s
Train Epoch: 318 [40960/90000 (45%)]	Loss: -2.0032	Cost: 13.99s
Train Epoch: 318 [81920/90000 (91%)]	Loss: -1.8296	Cost: 17.74s
Train Epoch: 318 	Average Loss: -1.6505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8681

Learning rate: 2.0031534151290953e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 1.3078	Cost: 48.83s
Train Epoch: 319 [40960/90000 (45%)]	Loss: -2.0495	Cost: 9.54s
Train Epoch: 319 [81920/90000 (91%)]	Loss: -1.9109	Cost: 20.76s
Train Epoch: 319 	Average Loss: -1.6623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7143

Learning rate: 1.9562436472991562e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 1.5906	Cost: 34.02s
Train Epoch: 320 [40960/90000 (45%)]	Loss: -2.0515	Cost: 9.67s
Train Epoch: 320 [81920/90000 (91%)]	Loss: -1.7603	Cost: 25.85s
Train Epoch: 320 	Average Loss: -1.6558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6673

Learning rate: 1.9098300562505276e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 1.3489	Cost: 39.79s
Train Epoch: 321 [40960/90000 (45%)]	Loss: -2.0995	Cost: 10.67s
Train Epoch: 321 [81920/90000 (91%)]	Loss: -1.8251	Cost: 24.81s
Train Epoch: 321 	Average Loss: -1.7096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7007

Learning rate: 1.863915504992132e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 1.2246	Cost: 42.76s
Train Epoch: 322 [40960/90000 (45%)]	Loss: -2.1891	Cost: 16.45s
Train Epoch: 322 [81920/90000 (91%)]	Loss: -1.8230	Cost: 16.58s
Train Epoch: 322 	Average Loss: -1.7050
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6754

Learning rate: 1.8185028257497683e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 1.5688	Cost: 43.26s
Train Epoch: 323 [40960/90000 (45%)]	Loss: -2.0981	Cost: 9.66s
Train Epoch: 323 [81920/90000 (91%)]	Loss: -1.8314	Cost: 19.13s
Train Epoch: 323 	Average Loss: -1.6986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4879

Saving model as e323_model.pt & e323_waveforms_supplementary.hdf5
Learning rate: 1.7735948197914044e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 1.5989	Cost: 34.34s
Train Epoch: 324 [40960/90000 (45%)]	Loss: -2.0862	Cost: 10.62s
Train Epoch: 324 [81920/90000 (91%)]	Loss: -1.8885	Cost: 28.05s
Train Epoch: 324 	Average Loss: -1.7020
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6339

Learning rate: 1.729194257254384e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 1.3280	Cost: 40.16s
Train Epoch: 325 [40960/90000 (45%)]	Loss: -2.1394	Cost: 16.79s
Train Epoch: 325 [81920/90000 (91%)]	Loss: -1.9083	Cost: 20.45s
Train Epoch: 325 	Average Loss: -1.7346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6374

Learning rate: 1.685303876974551e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 1.3652	Cost: 52.37s
Train Epoch: 326 [40960/90000 (45%)]	Loss: -2.1718	Cost: 12.92s
Train Epoch: 326 [81920/90000 (91%)]	Loss: -1.9017	Cost: 21.26s
Train Epoch: 326 	Average Loss: -1.7449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7158

Learning rate: 1.6419263863173007e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 1.6338	Cost: 38.76s
Train Epoch: 327 [40960/90000 (45%)]	Loss: -2.1754	Cost: 11.71s
Train Epoch: 327 [81920/90000 (91%)]	Loss: -1.9100	Cost: 17.62s
Train Epoch: 327 	Average Loss: -1.6948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6263

Learning rate: 1.599064461010582e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 1.5151	Cost: 39.98s
Train Epoch: 328 [40960/90000 (45%)]	Loss: -2.2031	Cost: 9.99s
Train Epoch: 328 [81920/90000 (91%)]	Loss: -1.9181	Cost: 27.13s
Train Epoch: 328 	Average Loss: -1.7309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6584

Learning rate: 1.5567207449798525e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 1.3197	Cost: 39.00s
Train Epoch: 329 [40960/90000 (45%)]	Loss: -2.2846	Cost: 16.84s
Train Epoch: 329 [81920/90000 (91%)]	Loss: -1.8244	Cost: 17.86s
Train Epoch: 329 	Average Loss: -1.7489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6009

Learning rate: 1.5148978501849652e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 1.6249	Cost: 44.30s
Train Epoch: 330 [40960/90000 (45%)]	Loss: -2.2065	Cost: 10.12s
Train Epoch: 330 [81920/90000 (91%)]	Loss: -2.0621	Cost: 19.33s
Train Epoch: 330 	Average Loss: -1.8128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5235

Learning rate: 1.4735983564590815e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 1.7453	Cost: 35.18s
Train Epoch: 331 [40960/90000 (45%)]	Loss: -2.4800	Cost: 10.51s
Train Epoch: 331 [81920/90000 (91%)]	Loss: -1.9625	Cost: 33.02s
Train Epoch: 331 	Average Loss: -1.7983
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5565

Learning rate: 1.4328248113495055e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 1.2475	Cost: 44.96s
Train Epoch: 332 [40960/90000 (45%)]	Loss: -2.2199	Cost: 16.97s
Train Epoch: 332 [81920/90000 (91%)]	Loss: -2.1298	Cost: 20.77s
Train Epoch: 332 	Average Loss: -1.8438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5902

Learning rate: 1.3925797299605635e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 1.1629	Cost: 51.31s
Train Epoch: 333 [40960/90000 (45%)]	Loss: -2.2834	Cost: 15.42s
Train Epoch: 333 [81920/90000 (91%)]	Loss: -2.0749	Cost: 15.85s
Train Epoch: 333 	Average Loss: -1.8147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4909

Learning rate: 1.3528655947984512e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 1.6662	Cost: 41.49s
Train Epoch: 334 [40960/90000 (45%)]	Loss: -2.2452	Cost: 10.18s
Train Epoch: 334 [81920/90000 (91%)]	Loss: -2.0336	Cost: 19.74s
Train Epoch: 334 	Average Loss: -1.7618
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5105

Learning rate: 1.3136848556180878e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 1.5662	Cost: 41.13s
Train Epoch: 335 [40960/90000 (45%)]	Loss: -2.2882	Cost: 10.02s
Train Epoch: 335 [81920/90000 (91%)]	Loss: -2.0286	Cost: 27.04s
Train Epoch: 335 	Average Loss: -1.8076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5873

Learning rate: 1.2750399292720314e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 1.2712	Cost: 40.47s
Train Epoch: 336 [40960/90000 (45%)]	Loss: -2.3283	Cost: 16.63s
Train Epoch: 336 [81920/90000 (91%)]	Loss: -1.8428	Cost: 17.89s
Train Epoch: 336 	Average Loss: -1.8453
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5384

Learning rate: 1.2369331995613651e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 1.3311	Cost: 40.80s
Train Epoch: 337 [40960/90000 (45%)]	Loss: -2.2216	Cost: 15.62s
Train Epoch: 337 [81920/90000 (91%)]	Loss: -1.8876	Cost: 13.92s
Train Epoch: 337 	Average Loss: -1.7781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6213

Learning rate: 1.1993670170886837e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 1.4538	Cost: 35.20s
Train Epoch: 338 [40960/90000 (45%)]	Loss: -2.5235	Cost: 9.82s
Train Epoch: 338 [81920/90000 (91%)]	Loss: -2.0372	Cost: 18.47s
Train Epoch: 338 	Average Loss: -1.8584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3530

Saving model as e338_model.pt & e338_waveforms_supplementary.hdf5
Learning rate: 1.1623436991130663e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 1.5682	Cost: 35.47s
Train Epoch: 339 [40960/90000 (45%)]	Loss: -2.4653	Cost: 10.89s
Train Epoch: 339 [81920/90000 (91%)]	Loss: -2.0768	Cost: 30.16s
Train Epoch: 339 	Average Loss: -1.8910
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5503

Learning rate: 1.1258655294071704e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 1.2466	Cost: 38.05s
Train Epoch: 340 [40960/90000 (45%)]	Loss: -2.4235	Cost: 17.42s
Train Epoch: 340 [81920/90000 (91%)]	Loss: -2.2043	Cost: 26.25s
Train Epoch: 340 	Average Loss: -1.9249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6801

Learning rate: 1.089934758116323e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 1.2595	Cost: 47.16s
Train Epoch: 341 [40960/90000 (45%)]	Loss: -2.3012	Cost: 11.28s
Train Epoch: 341 [81920/90000 (91%)]	Loss: -2.0291	Cost: 24.97s
Train Epoch: 341 	Average Loss: -1.9110
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4516

Learning rate: 1.054553601619753e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 1.3449	Cost: 39.51s
Train Epoch: 342 [40960/90000 (45%)]	Loss: -2.3411	Cost: 10.02s
Train Epoch: 342 [81920/90000 (91%)]	Loss: -2.1359	Cost: 25.11s
Train Epoch: 342 	Average Loss: -1.9314
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4741

Learning rate: 1.0197242423938455e-05
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 1.5990	Cost: 37.35s
Train Epoch: 343 [40960/90000 (45%)]	Loss: -2.4800	Cost: 13.82s
Train Epoch: 343 [81920/90000 (91%)]	Loss: -2.1894	Cost: 21.16s
Train Epoch: 343 	Average Loss: -1.9414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4615

Learning rate: 9.854488288775428e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 1.5725	Cost: 42.25s
Train Epoch: 344 [40960/90000 (45%)]	Loss: -2.5957	Cost: 16.34s
Train Epoch: 344 [81920/90000 (91%)]	Loss: -2.2077	Cost: 16.32s
Train Epoch: 344 	Average Loss: -1.9581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4503

Learning rate: 9.517294753398073e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 1.6375	Cost: 43.73s
Train Epoch: 345 [40960/90000 (45%)]	Loss: -2.2914	Cost: 12.84s
Train Epoch: 345 [81920/90000 (91%)]	Loss: -2.2026	Cost: 14.86s
Train Epoch: 345 	Average Loss: -1.9560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4367

Learning rate: 9.185682617491872e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 1.6503	Cost: 35.72s
Train Epoch: 346 [40960/90000 (45%)]	Loss: -2.3627	Cost: 12.80s
Train Epoch: 346 [81920/90000 (91%)]	Loss: -2.2101	Cost: 19.43s
Train Epoch: 346 	Average Loss: -1.9052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3890

Learning rate: 8.859672336455501e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 1.5670	Cost: 36.20s
Train Epoch: 347 [40960/90000 (45%)]	Loss: -2.4771	Cost: 11.56s
Train Epoch: 347 [81920/90000 (91%)]	Loss: -2.1108	Cost: 27.32s
Train Epoch: 347 	Average Loss: -1.9803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3869

Learning rate: 8.539284020138645e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 1.4327	Cost: 42.31s
Train Epoch: 348 [40960/90000 (45%)]	Loss: -2.3752	Cost: 17.03s
Train Epoch: 348 [81920/90000 (91%)]	Loss: -2.2629	Cost: 18.77s
Train Epoch: 348 	Average Loss: -1.9881
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5133

Learning rate: 8.224537431601915e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 1.1289	Cost: 52.93s
Train Epoch: 349 [40960/90000 (45%)]	Loss: -2.4078	Cost: 16.15s
Train Epoch: 349 [81920/90000 (91%)]	Loss: -2.2314	Cost: 16.47s
Train Epoch: 349 	Average Loss: -1.9971
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4344

Learning rate: 7.915451985897387e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 1.4379	Cost: 54.56s
Train Epoch: 350 [40960/90000 (45%)]	Loss: -2.3226	Cost: 9.65s
Train Epoch: 350 [81920/90000 (91%)]	Loss: -2.3725	Cost: 21.67s
Train Epoch: 350 	Average Loss: -2.0071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4746

Learning rate: 7.612046748871354e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 1.1051	Cost: 41.14s
Train Epoch: 351 [40960/90000 (45%)]	Loss: -2.4649	Cost: 9.84s
Train Epoch: 351 [81920/90000 (91%)]	Loss: -2.5058	Cost: 26.57s
Train Epoch: 351 	Average Loss: -2.0390
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4527

Learning rate: 7.314340435987926e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 1.0907	Cost: 43.66s
Train Epoch: 352 [40960/90000 (45%)]	Loss: -2.2288	Cost: 16.21s
Train Epoch: 352 [81920/90000 (91%)]	Loss: -2.4451	Cost: 19.38s
Train Epoch: 352 	Average Loss: -1.9746
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5507

Learning rate: 7.022351411174871e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 1.1971	Cost: 37.53s
Train Epoch: 353 [40960/90000 (45%)]	Loss: -2.4643	Cost: 15.24s
Train Epoch: 353 [81920/90000 (91%)]	Loss: -2.2366	Cost: 11.64s
Train Epoch: 353 	Average Loss: -2.0001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4315

Learning rate: 6.736097685690606e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 1.3181	Cost: 41.70s
Train Epoch: 354 [40960/90000 (45%)]	Loss: -2.5516	Cost: 9.81s
Train Epoch: 354 [81920/90000 (91%)]	Loss: -2.3662	Cost: 19.82s
Train Epoch: 354 	Average Loss: -2.0617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3477

Saving model as e354_model.pt & e354_waveforms_supplementary.hdf5
Learning rate: 6.455596917013267e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 1.0577	Cost: 34.74s
Train Epoch: 355 [40960/90000 (45%)]	Loss: -2.5442	Cost: 9.89s
Train Epoch: 355 [81920/90000 (91%)]	Loss: -2.2872	Cost: 28.27s
Train Epoch: 355 	Average Loss: -2.0790
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3401

Saving model as e355_model.pt & e355_waveforms_supplementary.hdf5
Learning rate: 6.1808664077516005e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 1.4088	Cost: 40.61s
Train Epoch: 356 [40960/90000 (45%)]	Loss: -2.6024	Cost: 16.53s
Train Epoch: 356 [81920/90000 (91%)]	Loss: -2.2965	Cost: 21.51s
Train Epoch: 356 	Average Loss: -2.0157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4753

Learning rate: 5.91192310457746e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 1.1842	Cost: 37.80s
Train Epoch: 357 [40960/90000 (45%)]	Loss: -2.4849	Cost: 15.41s
Train Epoch: 357 [81920/90000 (91%)]	Loss: -2.2608	Cost: 17.41s
Train Epoch: 357 	Average Loss: -2.0279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3286

Saving model as e357_model.pt & e357_waveforms_supplementary.hdf5
Learning rate: 5.648783597180656e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 0.9329	Cost: 41.64s
Train Epoch: 358 [40960/90000 (45%)]	Loss: -2.5424	Cost: 9.86s
Train Epoch: 358 [81920/90000 (91%)]	Loss: -2.2765	Cost: 26.33s
Train Epoch: 358 	Average Loss: -2.0715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4676

Learning rate: 5.3914641172454745e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 1.3512	Cost: 43.78s
Train Epoch: 359 [40960/90000 (45%)]	Loss: -2.4632	Cost: 10.00s
Train Epoch: 359 [81920/90000 (91%)]	Loss: -2.2492	Cost: 25.21s
Train Epoch: 359 	Average Loss: -2.0613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3504

Learning rate: 5.139980537449555e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 1.4003	Cost: 43.37s
Train Epoch: 360 [40960/90000 (45%)]	Loss: -2.6722	Cost: 13.99s
Train Epoch: 360 [81920/90000 (91%)]	Loss: -2.2977	Cost: 20.80s
Train Epoch: 360 	Average Loss: -2.1030
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3808

Learning rate: 4.894348370484651e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 1.3192	Cost: 45.12s
Train Epoch: 361 [40960/90000 (45%)]	Loss: -2.5633	Cost: 15.75s
Train Epoch: 361 [81920/90000 (91%)]	Loss: -2.4131	Cost: 12.73s
Train Epoch: 361 	Average Loss: -2.1049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3350

Learning rate: 4.6545827680998834e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 0.9778	Cost: 39.04s
Train Epoch: 362 [40960/90000 (45%)]	Loss: -2.3978	Cost: 9.65s
Train Epoch: 362 [81920/90000 (91%)]	Loss: -2.4898	Cost: 20.08s
Train Epoch: 362 	Average Loss: -2.1116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3472

Learning rate: 4.420698520166991e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 1.1693	Cost: 34.94s
Train Epoch: 363 [40960/90000 (45%)]	Loss: -2.6250	Cost: 9.75s
Train Epoch: 363 [81920/90000 (91%)]	Loss: -2.4756	Cost: 28.11s
Train Epoch: 363 	Average Loss: -2.1164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4451

Learning rate: 4.1927100537680815e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 1.2024	Cost: 39.04s
Train Epoch: 364 [40960/90000 (45%)]	Loss: -2.6188	Cost: 12.85s
Train Epoch: 364 [81920/90000 (91%)]	Loss: -2.3899	Cost: 17.91s
Train Epoch: 364 	Average Loss: -2.1271
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2457

Saving model as e364_model.pt & e364_waveforms_supplementary.hdf5
Learning rate: 3.970631432305708e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 1.2728	Cost: 43.10s
Train Epoch: 365 [40960/90000 (45%)]	Loss: -2.5828	Cost: 11.78s
Train Epoch: 365 [81920/90000 (91%)]	Loss: -2.4702	Cost: 17.97s
Train Epoch: 365 	Average Loss: -2.1427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4841

Learning rate: 3.7544763546352753e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 1.5591	Cost: 38.90s
Train Epoch: 366 [40960/90000 (45%)]	Loss: -2.5811	Cost: 10.38s
Train Epoch: 366 [81920/90000 (91%)]	Loss: -2.2852	Cost: 27.53s
Train Epoch: 366 	Average Loss: -2.0959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2615

Learning rate: 3.5442581542202067e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 1.0326	Cost: 42.21s
Train Epoch: 367 [40960/90000 (45%)]	Loss: -2.6687	Cost: 12.05s
Train Epoch: 367 [81920/90000 (91%)]	Loss: -2.2686	Cost: 26.06s
Train Epoch: 367 	Average Loss: -2.1677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2609

Learning rate: 3.339989798309276e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 1.2307	Cost: 53.79s
Train Epoch: 368 [40960/90000 (45%)]	Loss: -2.7553	Cost: 16.65s
Train Epoch: 368 [81920/90000 (91%)]	Loss: -2.3586	Cost: 16.89s
Train Epoch: 368 	Average Loss: -2.1482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3473

Learning rate: 3.1416838871369064e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 1.3924	Cost: 48.09s
Train Epoch: 369 [40960/90000 (45%)]	Loss: -2.6845	Cost: 15.30s
Train Epoch: 369 [81920/90000 (91%)]	Loss: -2.3857	Cost: 15.61s
Train Epoch: 369 	Average Loss: -2.0840
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3367

Learning rate: 2.9493526531457563e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 1.1450	Cost: 52.31s
Train Epoch: 370 [40960/90000 (45%)]	Loss: -2.6544	Cost: 10.04s
Train Epoch: 370 [81920/90000 (91%)]	Loss: -2.5543	Cost: 20.24s
Train Epoch: 370 	Average Loss: -2.1757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3850

Learning rate: 2.7630079602323468e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 1.1027	Cost: 39.75s
Train Epoch: 371 [40960/90000 (45%)]	Loss: -2.7058	Cost: 9.87s
Train Epoch: 371 [81920/90000 (91%)]	Loss: -2.4846	Cost: 27.47s
Train Epoch: 371 	Average Loss: -2.1718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3427

Learning rate: 2.582661303015068e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 1.0098	Cost: 43.43s
Train Epoch: 372 [40960/90000 (45%)]	Loss: -2.5929	Cost: 16.06s
Train Epoch: 372 [81920/90000 (91%)]	Loss: -2.3006	Cost: 19.20s
Train Epoch: 372 	Average Loss: -2.1470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4211

Learning rate: 2.40832380612527e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 1.4034	Cost: 39.66s
Train Epoch: 373 [40960/90000 (45%)]	Loss: -2.6588	Cost: 11.79s
Train Epoch: 373 [81920/90000 (91%)]	Loss: -2.2548	Cost: 18.07s
Train Epoch: 373 	Average Loss: -2.1611
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3396

Learning rate: 2.2400062235209426e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 1.0158	Cost: 35.08s
Train Epoch: 374 [40960/90000 (45%)]	Loss: -2.5576	Cost: 12.98s
Train Epoch: 374 [81920/90000 (91%)]	Loss: -2.3377	Cost: 19.15s
Train Epoch: 374 	Average Loss: -2.1705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5057

Learning rate: 2.0777189378234156e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 1.2152	Cost: 37.84s
Train Epoch: 375 [40960/90000 (45%)]	Loss: -2.5711	Cost: 11.51s
Train Epoch: 375 [81920/90000 (91%)]	Loss: -2.2835	Cost: 33.50s
Train Epoch: 375 	Average Loss: -2.1669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2698

Learning rate: 1.9214719596769582e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 1.1057	Cost: 61.43s
Train Epoch: 376 [40960/90000 (45%)]	Loss: -2.4960	Cost: 13.60s
Train Epoch: 376 [81920/90000 (91%)]	Loss: -2.4157	Cost: 13.96s
Train Epoch: 376 	Average Loss: -2.1704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2799

Learning rate: 1.771274927131129e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 0.8586	Cost: 37.86s
Train Epoch: 377 [40960/90000 (45%)]	Loss: -2.5542	Cost: 12.23s
Train Epoch: 377 [81920/90000 (91%)]	Loss: -2.5541	Cost: 17.62s
Train Epoch: 377 	Average Loss: -2.1879
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3031

Learning rate: 1.6271371050464177e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 1.4447	Cost: 33.10s
Train Epoch: 378 [40960/90000 (45%)]	Loss: -2.5758	Cost: 9.89s
Train Epoch: 378 [81920/90000 (91%)]	Loss: -2.4116	Cost: 28.00s
Train Epoch: 378 	Average Loss: -2.1724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3805

Learning rate: 1.4890673845226142e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 1.1999	Cost: 37.17s
Train Epoch: 379 [40960/90000 (45%)]	Loss: -2.7003	Cost: 16.83s
Train Epoch: 379 [81920/90000 (91%)]	Loss: -2.6101	Cost: 18.67s
Train Epoch: 379 	Average Loss: -2.2178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4518

Learning rate: 1.3570742823504575e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 1.0441	Cost: 37.99s
Train Epoch: 380 [40960/90000 (45%)]	Loss: -2.6906	Cost: 16.86s
Train Epoch: 380 [81920/90000 (91%)]	Loss: -2.5745	Cost: 16.50s
Train Epoch: 380 	Average Loss: -2.1773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4427

Learning rate: 1.2311659404862349e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 0.9520	Cost: 41.87s
Train Epoch: 381 [40960/90000 (45%)]	Loss: -2.5309	Cost: 14.08s
Train Epoch: 381 [81920/90000 (91%)]	Loss: -2.4056	Cost: 17.08s
Train Epoch: 381 	Average Loss: -2.1801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3102

Learning rate: 1.1113501255495491e-06
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 1.0684	Cost: 41.41s
Train Epoch: 382 [40960/90000 (45%)]	Loss: -2.5299	Cost: 11.29s
Train Epoch: 382 [81920/90000 (91%)]	Loss: -2.3730	Cost: 25.14s
Train Epoch: 382 	Average Loss: -2.1791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4310

Learning rate: 9.97634228344247e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 1.1342	Cost: 43.22s
Train Epoch: 383 [40960/90000 (45%)]	Loss: -2.6265	Cost: 12.13s
Train Epoch: 383 [81920/90000 (91%)]	Loss: -2.2410	Cost: 24.71s
Train Epoch: 383 	Average Loss: -2.1716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3819

Learning rate: 8.90025263402528e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 1.3211	Cost: 50.40s
Train Epoch: 384 [40960/90000 (45%)]	Loss: -2.6902	Cost: 17.01s
Train Epoch: 384 [81920/90000 (91%)]	Loss: -2.4820	Cost: 17.21s
Train Epoch: 384 	Average Loss: -2.1976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3807

Learning rate: 7.88529868552224e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 1.2651	Cost: 44.38s
Train Epoch: 385 [40960/90000 (45%)]	Loss: -2.6364	Cost: 16.27s
Train Epoch: 385 [81920/90000 (91%)]	Loss: -2.4444	Cost: 14.13s
Train Epoch: 385 	Average Loss: -2.1762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4841

Learning rate: 6.931543045073711e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 1.3280	Cost: 38.79s
Train Epoch: 386 [40960/90000 (45%)]	Loss: -2.6687	Cost: 9.55s
Train Epoch: 386 [81920/90000 (91%)]	Loss: -2.4174	Cost: 21.01s
Train Epoch: 386 	Average Loss: -2.1706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4300

Learning rate: 6.039044544820409e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 1.2568	Cost: 36.29s
Train Epoch: 387 [40960/90000 (45%)]	Loss: -2.6851	Cost: 9.88s
Train Epoch: 387 [81920/90000 (91%)]	Loss: -2.4479	Cost: 27.53s
Train Epoch: 387 	Average Loss: -2.1692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2743

Learning rate: 5.207858238273524e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 1.4042	Cost: 40.77s
Train Epoch: 388 [40960/90000 (45%)]	Loss: -2.6967	Cost: 16.14s
Train Epoch: 388 [81920/90000 (91%)]	Loss: -2.4477	Cost: 16.58s
Train Epoch: 388 	Average Loss: -2.1896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3864

Learning rate: 4.4380353969200063e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 1.4798	Cost: 42.04s
Train Epoch: 389 [40960/90000 (45%)]	Loss: -2.4879	Cost: 13.26s
Train Epoch: 389 [81920/90000 (91%)]	Loss: -2.4518	Cost: 15.57s
Train Epoch: 389 	Average Loss: -2.1797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3287

Learning rate: 3.7296235070587456e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 1.4258	Cost: 40.72s
Train Epoch: 390 [40960/90000 (45%)]	Loss: -2.7688	Cost: 9.61s
Train Epoch: 390 [81920/90000 (91%)]	Loss: -2.5241	Cost: 23.93s
Train Epoch: 390 	Average Loss: -2.1838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4755

Learning rate: 3.082666266872038e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 0.8439	Cost: 34.52s
Train Epoch: 391 [40960/90000 (45%)]	Loss: -2.8972	Cost: 9.88s
Train Epoch: 391 [81920/90000 (91%)]	Loss: -2.4435	Cost: 25.90s
Train Epoch: 391 	Average Loss: -2.2405
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2102

Saving model as e391_model.pt & e391_waveforms_supplementary.hdf5
Learning rate: 2.497203583729958e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 1.2078	Cost: 36.55s
Train Epoch: 392 [40960/90000 (45%)]	Loss: -2.6752	Cost: 16.58s
Train Epoch: 392 [81920/90000 (91%)]	Loss: -2.4437	Cost: 16.30s
Train Epoch: 392 	Average Loss: -2.2052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4407

Learning rate: 1.973271571728442e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 1.0397	Cost: 36.29s
Train Epoch: 393 [40960/90000 (45%)]	Loss: -2.6488	Cost: 16.15s
Train Epoch: 393 [81920/90000 (91%)]	Loss: -2.4210	Cost: 16.16s
Train Epoch: 393 	Average Loss: -2.2097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2107

Learning rate: 1.5109025494620685e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 0.9882	Cost: 40.19s
Train Epoch: 394 [40960/90000 (45%)]	Loss: -2.8746	Cost: 16.71s
Train Epoch: 394 [81920/90000 (91%)]	Loss: -2.4460	Cost: 16.30s
Train Epoch: 394 	Average Loss: -2.2269
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3003

Learning rate: 1.1101250380300971e-07
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 1.6942	Cost: 38.34s
Train Epoch: 395 [40960/90000 (45%)]	Loss: -2.6982	Cost: 16.04s
Train Epoch: 395 [81920/90000 (91%)]	Loss: -2.4233	Cost: 15.75s
Train Epoch: 395 	Average Loss: -2.1897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3715

Learning rate: 7.709637592770994e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 1.3477	Cost: 44.26s
Train Epoch: 396 [40960/90000 (45%)]	Loss: -2.6114	Cost: 13.40s
Train Epoch: 396 [81920/90000 (91%)]	Loss: -2.3026	Cost: 17.05s
Train Epoch: 396 	Average Loss: -2.1902
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3412

Learning rate: 4.934396342684002e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 1.4234	Cost: 38.14s
Train Epoch: 397 [40960/90000 (45%)]	Loss: -2.7856	Cost: 12.57s
Train Epoch: 397 [81920/90000 (91%)]	Loss: -2.5066	Cost: 14.03s
Train Epoch: 397 	Average Loss: -2.1698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4392

Learning rate: 2.7756978199944282e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 0.9831	Cost: 33.23s
Train Epoch: 398 [40960/90000 (45%)]	Loss: -2.7469	Cost: 9.97s
Train Epoch: 398 [81920/90000 (91%)]	Loss: -2.6184	Cost: 27.54s
Train Epoch: 398 	Average Loss: -2.2213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4008

Learning rate: 1.2336751833941234e-08
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 1.2960	Cost: 39.39s
Train Epoch: 399 [40960/90000 (45%)]	Loss: -2.6457	Cost: 16.01s
Train Epoch: 399 [81920/90000 (91%)]	Loss: -2.3983	Cost: 21.14s
Train Epoch: 399 	Average Loss: -2.1829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4027

Learning rate: 3.084235521033653e-09
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 1.1634	Cost: 41.05s
Train Epoch: 400 [40960/90000 (45%)]	Loss: -2.7787	Cost: 12.62s
Train Epoch: 400 [81920/90000 (91%)]	Loss: -2.4042	Cost: 20.51s
Train Epoch: 400 	Average Loss: -2.2114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4358

Stopping timer.
Training time (including validation): 107313.79731559753 seconds
Saving model
Transfer learning by starting with alpha=0.6!
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 29.7717	Cost: 35.66s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 15.1280	Cost: 11.85s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 12.7424	Cost: 28.17s
Train Epoch: 1 	Average Loss: 16.2160
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0290

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999691576447898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 12.6884	Cost: 39.63s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 11.7696	Cost: 15.49s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 10.7924	Cost: 22.13s
Train Epoch: 2 	Average Loss: 11.6951
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0308

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.00019998766324816605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 10.8397	Cost: 42.80s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 10.2474	Cost: 15.90s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 9.9635	Cost: 12.80s
Train Epoch: 3 	Average Loss: 10.3106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1235

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.00019997224302180006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 9.9595	Cost: 46.64s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 9.5321	Cost: 9.83s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 9.2814	Cost: 23.10s
Train Epoch: 4 	Average Loss: 9.4918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5363

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.00019995065603657316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 9.4797	Cost: 40.62s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 8.9476	Cost: 9.88s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 8.6317	Cost: 24.82s
Train Epoch: 5 	Average Loss: 8.9600
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2412

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.0001999229036240723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 9.0429	Cost: 44.58s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 8.6003	Cost: 16.53s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 8.2108	Cost: 16.06s
Train Epoch: 6 	Average Loss: 8.5778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9587

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019988898749619702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 8.2806	Cost: 43.40s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 8.3285	Cost: 10.53s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 8.0406	Cost: 21.04s
Train Epoch: 7 	Average Loss: 8.1698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7277

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.00019984890974505381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 8.4122	Cost: 37.78s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 8.0139	Cost: 9.91s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 7.7254	Cost: 25.85s
Train Epoch: 8 	Average Loss: 7.9036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5662

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.00019980267284282717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 8.1380	Cost: 38.77s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 7.7828	Cost: 15.36s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 7.5546	Cost: 21.62s
Train Epoch: 9 	Average Loss: 7.6489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4313

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019975027964162705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 8.0049	Cost: 42.72s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 7.3661	Cost: 9.80s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 7.3859	Cost: 29.44s
Train Epoch: 10 	Average Loss: 7.4502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4355

Learning rate: 0.00019969173337331284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 7.6782	Cost: 46.14s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 7.2784	Cost: 10.04s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 7.1491	Cost: 25.57s
Train Epoch: 11 	Average Loss: 7.3166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2458

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 0.00019962703764929416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 7.9917	Cost: 44.75s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 7.4471	Cost: 16.47s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 7.2731	Cost: 16.13s
Train Epoch: 12 	Average Loss: 7.3016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3899

Learning rate: 0.00019955619646030802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 7.9145	Cost: 51.48s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 7.0813	Cost: 14.63s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 7.2500	Cost: 15.76s
Train Epoch: 13 	Average Loss: 7.2364
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2839

Learning rate: 0.00019947921417617267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 7.8921	Cost: 43.71s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 7.0879	Cost: 12.77s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 7.4191	Cost: 15.95s
Train Epoch: 14 	Average Loss: 7.2527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5420

Learning rate: 0.000199396095545518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 7.9439	Cost: 37.50s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 7.2729	Cost: 12.59s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 7.1258	Cost: 16.51s
Train Epoch: 15 	Average Loss: 7.1961
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2694

Learning rate: 0.00019930684569549264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 7.6113	Cost: 34.51s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 6.9820	Cost: 9.97s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 6.7720	Cost: 26.55s
Train Epoch: 16 	Average Loss: 6.9874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2014

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Learning rate: 0.0001992114701314478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 7.6014	Cost: 37.50s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 7.1295	Cost: 16.69s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 6.7685	Cost: 16.79s
Train Epoch: 17 	Average Loss: 6.9876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0659

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Learning rate: 0.00019910997473659747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 7.7887	Cost: 38.56s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 7.0330	Cost: 16.62s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 6.8699	Cost: 16.87s
Train Epoch: 18 	Average Loss: 6.8397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1814

Learning rate: 0.00019900236577165574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 7.5305	Cost: 37.51s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 6.7559	Cost: 16.71s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 6.7026	Cost: 10.22s
Train Epoch: 19 	Average Loss: 6.8324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0385

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Learning rate: 0.00019888864987445046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 7.3880	Cost: 37.90s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 7.0846	Cost: 9.76s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 7.0247	Cost: 19.20s
Train Epoch: 20 	Average Loss: 6.8792
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2940

Learning rate: 0.00019876883405951377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 7.5264	Cost: 34.40s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 6.8052	Cost: 10.53s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 6.4169	Cost: 30.32s
Train Epoch: 21 	Average Loss: 6.7978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9522

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Learning rate: 0.00019864292571764955
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 7.4578	Cost: 36.99s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 6.5512	Cost: 17.54s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 6.6797	Cost: 24.95s
Train Epoch: 22 	Average Loss: 6.6607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8532

Saving model as e22_model.pt & e22_waveforms_supplementary.hdf5
Learning rate: 0.0001985109326154774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 7.8502	Cost: 36.46s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 6.6431	Cost: 16.99s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 6.6065	Cost: 15.33s
Train Epoch: 23 	Average Loss: 6.6099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9745

Learning rate: 0.00019837286289495361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 7.1992	Cost: 39.21s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 6.6405	Cost: 9.97s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 6.4153	Cost: 27.54s
Train Epoch: 24 	Average Loss: 6.5555
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8898

Learning rate: 0.0001982287250728689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 7.6340	Cost: 41.34s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 6.6042	Cost: 9.83s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 6.5090	Cost: 27.62s
Train Epoch: 25 	Average Loss: 6.5636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0039

Learning rate: 0.00019807852804032305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 7.2873	Cost: 45.69s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 6.6472	Cost: 16.05s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 6.4430	Cost: 19.81s
Train Epoch: 26 	Average Loss: 6.5058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0647

Learning rate: 0.00019792228106217658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 7.1557	Cost: 50.12s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 6.4636	Cost: 16.34s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 6.1630	Cost: 13.03s
Train Epoch: 27 	Average Loss: 6.4061
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0401

Learning rate: 0.0001977599937764791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 7.5448	Cost: 44.87s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 6.2744	Cost: 11.03s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 6.3716	Cost: 18.40s
Train Epoch: 28 	Average Loss: 6.3893
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8738

Learning rate: 0.00019759167619387474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 7.3665	Cost: 38.09s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 6.3718	Cost: 11.32s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 6.2227	Cost: 19.73s
Train Epoch: 29 	Average Loss: 6.3386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9198

Learning rate: 0.00019741733869698495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 7.1766	Cost: 40.41s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 6.2878	Cost: 9.88s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 6.6643	Cost: 23.30s
Train Epoch: 30 	Average Loss: 6.4018
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9875

Learning rate: 0.00019723699203976766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 7.6600	Cost: 44.39s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 6.7306	Cost: 16.78s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 6.2359	Cost: 16.86s
Train Epoch: 31 	Average Loss: 6.4824
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0108

Learning rate: 0.00019705064734685425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 7.4905	Cost: 44.28s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 6.3536	Cost: 14.68s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 6.5068	Cost: 15.22s
Train Epoch: 32 	Average Loss: 6.3829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9642

Learning rate: 0.00019685831611286313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 7.5132	Cost: 40.67s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 6.3942	Cost: 9.54s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 6.2481	Cost: 22.04s
Train Epoch: 33 	Average Loss: 6.3285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0491

Learning rate: 0.00019666001020169073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 7.2072	Cost: 34.41s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 6.2808	Cost: 10.69s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 6.1523	Cost: 18.48s
Train Epoch: 34 	Average Loss: 6.3246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8410

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Learning rate: 0.0001964557418457798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 7.2379	Cost: 36.22s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 6.1906	Cost: 14.04s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 6.0636	Cost: 18.57s
Train Epoch: 35 	Average Loss: 6.1531
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8456

Learning rate: 0.0001962455236453647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 7.3829	Cost: 37.72s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 6.5059	Cost: 16.92s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 6.2517	Cost: 16.70s
Train Epoch: 36 	Average Loss: 6.2711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9876

Learning rate: 0.00019602936856769428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 7.2493	Cost: 37.91s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 6.0490	Cost: 14.50s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 6.3655	Cost: 13.90s
Train Epoch: 37 	Average Loss: 6.2281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0360

Learning rate: 0.0001958072899462319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 7.1602	Cost: 39.19s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 6.1070	Cost: 9.63s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 5.9317	Cost: 26.01s
Train Epoch: 38 	Average Loss: 6.1129
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9148

Learning rate: 0.00019557930147983297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 7.2608	Cost: 32.63s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 6.0757	Cost: 11.63s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 5.7615	Cost: 30.21s
Train Epoch: 39 	Average Loss: 6.0609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7970

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Learning rate: 0.00019534541723190008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 7.0803	Cost: 37.99s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 5.9590	Cost: 17.57s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 5.7563	Cost: 17.54s
Train Epoch: 40 	Average Loss: 6.0194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8540

Learning rate: 0.00019510565162951532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 7.1628	Cost: 48.74s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 5.7570	Cost: 15.13s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 5.6558	Cost: 14.77s
Train Epoch: 41 	Average Loss: 5.9598
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9002

Learning rate: 0.0001948600194625504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 7.1208	Cost: 48.45s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 6.0135	Cost: 9.85s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 5.9177	Cost: 23.72s
Train Epoch: 42 	Average Loss: 5.9614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8267

Learning rate: 0.00019460853588275446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 7.0402	Cost: 36.68s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 5.9515	Cost: 9.68s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 5.8771	Cost: 25.00s
Train Epoch: 43 	Average Loss: 5.9080
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7837

Saving model as e43_model.pt & e43_waveforms_supplementary.hdf5
Learning rate: 0.0001943512164028193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 7.2224	Cost: 40.80s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 6.3290	Cost: 14.27s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 6.1385	Cost: 20.04s
Train Epoch: 44 	Average Loss: 6.1419
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8971

Learning rate: 0.00019408807689542249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 7.3882	Cost: 40.85s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 5.8768	Cost: 16.79s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 5.7690	Cost: 16.65s
Train Epoch: 45 	Average Loss: 6.0637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6683

Saving model as e45_model.pt & e45_waveforms_supplementary.hdf5
Learning rate: 0.00019381913359224837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 6.8320	Cost: 35.89s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 5.7991	Cost: 14.56s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 5.6048	Cost: 12.52s
Train Epoch: 46 	Average Loss: 5.8408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5143

Saving model as e46_model.pt & e46_waveforms_supplementary.hdf5
Learning rate: 0.0001935444030829867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 6.9621	Cost: 38.96s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 5.8161	Cost: 9.65s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 5.6594	Cost: 17.70s
Train Epoch: 47 	Average Loss: 5.8346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6554

Learning rate: 0.00019326390231430937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 7.0824	Cost: 34.89s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 5.5957	Cost: 9.79s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 5.6699	Cost: 26.89s
Train Epoch: 48 	Average Loss: 5.8273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7046

Learning rate: 0.00019297764858882508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 7.0743	Cost: 37.36s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 5.8519	Cost: 17.74s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 5.8293	Cost: 21.52s
Train Epoch: 49 	Average Loss: 5.9568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7103

Learning rate: 0.000192685659564012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 7.1646	Cost: 40.30s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 5.5527	Cost: 15.35s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 5.5121	Cost: 22.95s
Train Epoch: 50 	Average Loss: 5.8275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6776

Learning rate: 0.00019238795325112859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 6.6813	Cost: 40.15s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 5.5312	Cost: 12.33s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 5.5831	Cost: 22.37s
Train Epoch: 51 	Average Loss: 5.7690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5851

Learning rate: 0.00019208454801410258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 6.9761	Cost: 38.73s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 5.6948	Cost: 10.13s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 5.6183	Cost: 26.23s
Train Epoch: 52 	Average Loss: 5.6960
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6055

Learning rate: 0.00019177546256839804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 7.1320	Cost: 44.32s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 5.5388	Cost: 16.76s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 5.3162	Cost: 16.78s
Train Epoch: 53 	Average Loss: 5.6803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7817

Learning rate: 0.0001914607159798613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 6.7485	Cost: 46.24s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 5.4930	Cost: 13.92s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 5.4031	Cost: 12.74s
Train Epoch: 54 	Average Loss: 5.5677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7114

Learning rate: 0.00019114032766354445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 6.7852	Cost: 48.41s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 5.4639	Cost: 9.82s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 5.4708	Cost: 18.89s
Train Epoch: 55 	Average Loss: 5.5627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7540

Learning rate: 0.00019081431738250806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 7.0120	Cost: 36.18s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 5.4859	Cost: 9.57s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 5.3914	Cost: 22.95s
Train Epoch: 56 	Average Loss: 5.5067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6937

Learning rate: 0.00019048270524660188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 6.8517	Cost: 38.78s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 5.4836	Cost: 9.98s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 5.3411	Cost: 25.19s
Train Epoch: 57 	Average Loss: 5.5952
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6480

Learning rate: 0.0001901455117112245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 6.8861	Cost: 42.59s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 5.4244	Cost: 16.61s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 5.6457	Cost: 17.57s
Train Epoch: 58 	Average Loss: 5.6579
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9693

Learning rate: 0.0001898027575760615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 7.2091	Cost: 42.05s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 5.6061	Cost: 10.67s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 5.6107	Cost: 17.51s
Train Epoch: 59 	Average Loss: 5.8325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7235

Learning rate: 0.00018945446398380245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 6.9615	Cost: 34.25s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 5.7046	Cost: 10.91s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 5.7474	Cost: 28.15s
Train Epoch: 60 	Average Loss: 5.8529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8497

Learning rate: 0.00018910065241883672
