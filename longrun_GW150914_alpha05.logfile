Nestedspace(activation='elu', apply_unconditional_transform=False, base_transform_type='rq-coupling', basis_dir='data/GW150914_sample_prior_basis/', batch_norm=True, batch_size=2048, bw_dstar=None, cuda=True, data_dir='data/GW150914_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, dropout_probability=0.0, epochs=100000, flow_lr=None, hidden_dims=512, kl_annealing=True, lr=0.0002, lr_anneal_method='cosine', lr_annealing=True, mixed_alpha=0.1, mode='train', model_dir='models/GW150914_sample_uniform_100basis_all_mixed_prior_a01/', model_source='new', model_type='nde', nbins=8, nflows=15, nsample=100000, nsamples_target_event=50000, num_transform_blocks=10, output_freq=10, sampling_from='mixed', save=True, save_aux_filename='waveforms_supplementary.hdf5', save_model_name='model.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, tail_bound=1.0, transfer_epochs=0, truncate_basis=100)
Waveform directory data/GW150914_sample_prior_basis/
Model directory models/GW150914_sample_uniform_100basis_all_mixed_prior_a01/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
Loading load_all_bilby_samples...
Loading load_all_event_strain...
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
Detectors: ['H1', 'L1']

Constructing model of type nde

Initial learning rate 0.0002
Using cosine LR annealing.

Model hyperparameters:
input_dim 	 15
num_flow_steps 	 15
context_dim 	 400
base_transform_kwargs
	 hidden_dim 	 512
	 num_transform_blocks 	 10
	 activation 	 elu
	 dropout_probability 	 0.0
	 batch_norm 	 True
	 num_bins 	 8
	 tail_bound 	 1.0
	 apply_unconditional_transform 	 False
	 base_transform_type 	 rq-coupling

Training for 100000 epochs
Starting timer
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 27.4505	Cost: 28.76s
Train Epoch: 1 [20480/90000 (23%)]	Loss: 21.9966	Cost: 6.06s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 21.4572	Cost: 10.33s
Train Epoch: 1 [61440/90000 (68%)]	Loss: 21.3671	Cost: 6.30s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 21.2628	Cost: 9.10s
Train Epoch: 1 	Average Loss: 21.8887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2882

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999995065198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 21.1960	Cost: 27.36s
Train Epoch: 2 [20480/90000 (23%)]	Loss: 21.1810	Cost: 12.07s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 21.1325	Cost: 11.97s
Train Epoch: 2 [61440/90000 (68%)]	Loss: 21.1367	Cost: 10.43s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 21.1352	Cost: 5.93s
Train Epoch: 2 	Average Loss: 21.1440
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1266

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999998026079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 21.1044	Cost: 27.51s
Train Epoch: 3 [20480/90000 (23%)]	Loss: 21.0221	Cost: 6.84s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 20.9436	Cost: 9.56s
Train Epoch: 3 [61440/90000 (68%)]	Loss: 20.9858	Cost: 6.64s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 20.9317	Cost: 16.07s
Train Epoch: 3 	Average Loss: 20.9762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0164

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999995558678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 20.9246	Cost: 27.16s
Train Epoch: 4 [20480/90000 (23%)]	Loss: 20.8710	Cost: 11.88s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 20.8607	Cost: 10.50s
Train Epoch: 4 [61440/90000 (68%)]	Loss: 20.8136	Cost: 5.85s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 20.7547	Cost: 6.74s
Train Epoch: 4 	Average Loss: 20.7979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8335

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999921043165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 20.6368	Cost: 21.90s
Train Epoch: 5 [20480/90000 (23%)]	Loss: 20.6351	Cost: 6.86s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 20.6394	Cost: 7.44s
Train Epoch: 5 [61440/90000 (68%)]	Loss: 20.5610	Cost: 6.14s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 20.5986	Cost: 13.07s
Train Epoch: 5 	Average Loss: 20.6158
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6328

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999876629945
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 20.5328	Cost: 27.10s
Train Epoch: 6 [20480/90000 (23%)]	Loss: 20.4984	Cost: 8.49s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 20.4818	Cost: 6.24s
Train Epoch: 6 [61440/90000 (68%)]	Loss: 20.3715	Cost: 7.14s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 20.3636	Cost: 6.52s
Train Epoch: 6 	Average Loss: 20.4429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4575

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999822347122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 20.4113	Cost: 25.40s
Train Epoch: 7 [20480/90000 (23%)]	Loss: 20.3166	Cost: 8.25s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 20.3379	Cost: 12.07s
Train Epoch: 7 [61440/90000 (68%)]	Loss: 20.2875	Cost: 12.09s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 20.2104	Cost: 11.88s
Train Epoch: 7 	Average Loss: 20.2809
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3110

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999758194695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 20.1790	Cost: 22.19s
Train Epoch: 8 [20480/90000 (23%)]	Loss: 20.2214	Cost: 6.34s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 20.0843	Cost: 6.51s
Train Epoch: 8 [61440/90000 (68%)]	Loss: 20.0481	Cost: 7.92s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 19.9950	Cost: 6.43s
Train Epoch: 8 	Average Loss: 20.1328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1898

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999684172664
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 20.0582	Cost: 26.65s
Train Epoch: 9 [20480/90000 (23%)]	Loss: 19.9668	Cost: 9.61s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 19.9496	Cost: 6.19s
Train Epoch: 9 [61440/90000 (68%)]	Loss: 19.8929	Cost: 6.18s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 19.8253	Cost: 8.87s
Train Epoch: 9 	Average Loss: 19.9220
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9879

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999600281025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 19.7325	Cost: 26.24s
Train Epoch: 10 [20480/90000 (23%)]	Loss: 19.7298	Cost: 10.15s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 19.6697	Cost: 12.29s
Train Epoch: 10 [61440/90000 (68%)]	Loss: 19.6052	Cost: 11.92s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 19.6249	Cost: 11.80s
Train Epoch: 10 	Average Loss: 19.6899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7657

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999506519785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 19.6384	Cost: 22.40s
Train Epoch: 11 [20480/90000 (23%)]	Loss: 19.5211	Cost: 6.42s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 19.4455	Cost: 7.69s
Train Epoch: 11 [61440/90000 (68%)]	Loss: 19.5196	Cost: 6.88s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 19.4605	Cost: 6.42s
Train Epoch: 11 	Average Loss: 19.4753
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5614

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999402888941
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 19.3434	Cost: 23.31s
Train Epoch: 12 [20480/90000 (23%)]	Loss: 19.3715	Cost: 6.09s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 19.3208	Cost: 7.17s
Train Epoch: 12 [61440/90000 (68%)]	Loss: 19.1765	Cost: 6.10s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 19.1983	Cost: 5.91s
Train Epoch: 12 	Average Loss: 19.2936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3664

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999289388494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 19.2244	Cost: 27.33s
Train Epoch: 13 [20480/90000 (23%)]	Loss: 19.2382	Cost: 12.20s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 19.0950	Cost: 12.17s
Train Epoch: 13 [61440/90000 (68%)]	Loss: 19.0625	Cost: 11.96s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 19.0081	Cost: 11.86s
Train Epoch: 13 	Average Loss: 19.1320
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2477

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999916601844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 19.0037	Cost: 22.24s
Train Epoch: 14 [20480/90000 (23%)]	Loss: 19.0592	Cost: 6.39s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 19.0061	Cost: 7.47s
Train Epoch: 14 [61440/90000 (68%)]	Loss: 18.9107	Cost: 6.98s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 18.9431	Cost: 6.27s
Train Epoch: 14 	Average Loss: 18.9609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0302

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999032778784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 18.9149	Cost: 25.35s
Train Epoch: 15 [20480/90000 (23%)]	Loss: 18.9021	Cost: 6.16s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 18.8282	Cost: 6.91s
Train Epoch: 15 [61440/90000 (68%)]	Loss: 18.7518	Cost: 6.76s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 18.7991	Cost: 6.07s
Train Epoch: 15 	Average Loss: 18.8264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8698

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999998889669524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 18.7015	Cost: 31.42s
Train Epoch: 16 [20480/90000 (23%)]	Loss: 18.5969	Cost: 8.46s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 18.6458	Cost: 12.69s
Train Epoch: 16 [61440/90000 (68%)]	Loss: 18.6859	Cost: 12.03s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 18.6485	Cost: 11.88s
Train Epoch: 16 	Average Loss: 18.6579
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7937

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999873669066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 18.7093	Cost: 22.25s
Train Epoch: 17 [20480/90000 (23%)]	Loss: 18.5949	Cost: 6.30s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 18.5050	Cost: 6.22s
Train Epoch: 17 [61440/90000 (68%)]	Loss: 18.4957	Cost: 6.30s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 18.4632	Cost: 10.77s
Train Epoch: 17 	Average Loss: 18.4877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6405

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999998573842195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 18.4431	Cost: 38.24s
Train Epoch: 18 [20480/90000 (23%)]	Loss: 18.4218	Cost: 6.13s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 18.3085	Cost: 8.32s
Train Epoch: 18 [61440/90000 (68%)]	Loss: 18.3217	Cost: 6.26s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 18.3720	Cost: 6.10s
Train Epoch: 18 	Average Loss: 18.3787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4813

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999998401124124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 18.3701	Cost: 26.52s
Train Epoch: 19 [20480/90000 (23%)]	Loss: 18.2213	Cost: 12.13s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 18.0477	Cost: 12.02s
Train Epoch: 19 [61440/90000 (68%)]	Loss: 18.1366	Cost: 11.94s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 18.1388	Cost: 6.79s
Train Epoch: 19 	Average Loss: 18.2077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3897

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999998218536453
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 18.2200	Cost: 21.84s
Train Epoch: 20 [20480/90000 (23%)]	Loss: 18.1056	Cost: 6.02s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 18.1806	Cost: 8.23s
Train Epoch: 20 [61440/90000 (68%)]	Loss: 18.0929	Cost: 6.31s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 18.1393	Cost: 8.32s
Train Epoch: 20 	Average Loss: 18.1033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3003

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999998026079178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 17.9924	Cost: 23.37s
Train Epoch: 21 [20480/90000 (23%)]	Loss: 17.9221	Cost: 6.27s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 18.0432	Cost: 6.38s
Train Epoch: 21 [61440/90000 (68%)]	Loss: 17.9024	Cost: 6.52s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 17.9494	Cost: 6.20s
Train Epoch: 21 	Average Loss: 17.9771
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1401

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199999978237523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 17.8850	Cost: 26.43s
Train Epoch: 22 [20480/90000 (23%)]	Loss: 17.8986	Cost: 6.88s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 17.9309	Cost: 6.04s
Train Epoch: 22 [61440/90000 (68%)]	Loss: 17.9256	Cost: 6.81s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 17.7696	Cost: 6.10s
Train Epoch: 22 	Average Loss: 17.8755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0525

Saving model as e22_model.pt & e22_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999997611555822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 17.8236	Cost: 32.42s
Train Epoch: 23 [20480/90000 (23%)]	Loss: 17.8312	Cost: 11.95s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 17.5834	Cost: 11.95s
Train Epoch: 23 [61440/90000 (68%)]	Loss: 17.8558	Cost: 9.22s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 17.7512	Cost: 6.11s
Train Epoch: 23 	Average Loss: 17.7432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9209

Saving model as e23_model.pt & e23_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999997389489742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 17.7344	Cost: 21.94s
Train Epoch: 24 [20480/90000 (23%)]	Loss: 17.7585	Cost: 6.15s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 17.6519	Cost: 7.97s
Train Epoch: 24 [61440/90000 (68%)]	Loss: 17.5953	Cost: 9.97s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 17.6802	Cost: 12.18s
Train Epoch: 24 	Average Loss: 17.6358
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7998

Saving model as e24_model.pt & e24_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999997157554058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 17.6866	Cost: 23.95s
Train Epoch: 25 [20480/90000 (23%)]	Loss: 17.6456	Cost: 6.37s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 17.7175	Cost: 6.62s
Train Epoch: 25 [61440/90000 (68%)]	Loss: 17.4758	Cost: 6.23s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 17.5781	Cost: 7.48s
Train Epoch: 25 	Average Loss: 17.5201
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6682

Saving model as e25_model.pt & e25_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999996915748774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 17.4493	Cost: 24.25s
Train Epoch: 26 [20480/90000 (23%)]	Loss: 17.5044	Cost: 6.80s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 17.3789	Cost: 6.46s
Train Epoch: 26 [61440/90000 (68%)]	Loss: 17.3595	Cost: 6.40s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 17.3811	Cost: 6.81s
Train Epoch: 26 	Average Loss: 17.3940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5766

Saving model as e26_model.pt & e26_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999996664073888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 17.2352	Cost: 27.77s
Train Epoch: 27 [20480/90000 (23%)]	Loss: 17.4001	Cost: 12.02s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 17.2938	Cost: 10.30s
Train Epoch: 27 [61440/90000 (68%)]	Loss: 17.2884	Cost: 6.13s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 17.1818	Cost: 6.19s
Train Epoch: 27 	Average Loss: 17.2523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5370

Saving model as e27_model.pt & e27_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999996402529402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 17.2840	Cost: 24.71s
Train Epoch: 28 [20480/90000 (23%)]	Loss: 17.3188	Cost: 7.11s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 17.1565	Cost: 12.09s
Train Epoch: 28 [61440/90000 (68%)]	Loss: 17.1499	Cost: 12.00s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 17.0604	Cost: 11.82s
Train Epoch: 28 	Average Loss: 17.1445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2980

Saving model as e28_model.pt & e28_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999996131115315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 17.1068	Cost: 22.36s
Train Epoch: 29 [20480/90000 (23%)]	Loss: 17.1771	Cost: 6.12s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 16.9251	Cost: 8.14s
Train Epoch: 29 [61440/90000 (68%)]	Loss: 17.0844	Cost: 6.24s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 16.8977	Cost: 6.91s
Train Epoch: 29 	Average Loss: 17.0174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2461

Saving model as e29_model.pt & e29_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999995849831625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 17.0857	Cost: 23.51s
Train Epoch: 30 [20480/90000 (23%)]	Loss: 17.0851	Cost: 7.06s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 16.9530	Cost: 7.71s
Train Epoch: 30 [61440/90000 (68%)]	Loss: 16.9068	Cost: 6.59s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 16.9532	Cost: 9.89s
Train Epoch: 30 	Average Loss: 16.9277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1638

Saving model as e30_model.pt & e30_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999995558678336
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 16.8098	Cost: 23.46s
Train Epoch: 31 [20480/90000 (23%)]	Loss: 16.7488	Cost: 7.27s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 16.8387	Cost: 6.49s
Train Epoch: 31 [61440/90000 (68%)]	Loss: 16.8108	Cost: 6.36s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 16.7157	Cost: 6.28s
Train Epoch: 31 	Average Loss: 16.7844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9781

Saving model as e31_model.pt & e31_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999525765545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 16.5647	Cost: 22.97s
Train Epoch: 32 [20480/90000 (23%)]	Loss: 16.8568	Cost: 6.09s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 16.6411	Cost: 7.10s
Train Epoch: 32 [61440/90000 (68%)]	Loss: 16.6646	Cost: 6.40s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 16.7731	Cost: 6.45s
Train Epoch: 32 	Average Loss: 16.6728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8145

Saving model as e32_model.pt & e32_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999494676296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 16.5809	Cost: 27.54s
Train Epoch: 33 [20480/90000 (23%)]	Loss: 16.6977	Cost: 11.07s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 16.6023	Cost: 9.53s
Train Epoch: 33 [61440/90000 (68%)]	Loss: 16.4774	Cost: 5.83s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 16.5585	Cost: 6.68s
Train Epoch: 33 	Average Loss: 16.5792
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7946

Saving model as e33_model.pt & e33_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999994626000874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 16.5233	Cost: 28.48s
Train Epoch: 34 [20480/90000 (23%)]	Loss: 16.6032	Cost: 12.32s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 16.4641	Cost: 12.11s
Train Epoch: 34 [61440/90000 (68%)]	Loss: 16.5129	Cost: 11.85s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 16.5204	Cost: 8.63s
Train Epoch: 34 	Average Loss: 16.4868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7381

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999994295369188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 16.2888	Cost: 35.61s
Train Epoch: 35 [20480/90000 (23%)]	Loss: 16.4637	Cost: 12.22s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 16.3528	Cost: 11.94s
Train Epoch: 35 [61440/90000 (68%)]	Loss: 16.3858	Cost: 8.59s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 16.3363	Cost: 5.77s
Train Epoch: 35 	Average Loss: 16.3787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5558

Saving model as e35_model.pt & e35_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199999939548679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 16.3737	Cost: 26.61s
Train Epoch: 36 [20480/90000 (23%)]	Loss: 16.2786	Cost: 11.83s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 16.2722	Cost: 12.23s
Train Epoch: 36 [61440/90000 (68%)]	Loss: 16.2635	Cost: 11.80s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 16.3565	Cost: 11.94s
Train Epoch: 36 	Average Loss: 16.2836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4852

Saving model as e36_model.pt & e36_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999993604497015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 16.2167	Cost: 22.60s
Train Epoch: 37 [20480/90000 (23%)]	Loss: 16.2498	Cost: 6.28s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 16.2903	Cost: 6.52s
Train Epoch: 37 [61440/90000 (68%)]	Loss: 16.2289	Cost: 8.04s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 16.1668	Cost: 6.23s
Train Epoch: 37 	Average Loss: 16.2175
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4682

Saving model as e37_model.pt & e37_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999993244256535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 16.1418	Cost: 25.78s
Train Epoch: 38 [20480/90000 (23%)]	Loss: 16.2208	Cost: 9.63s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 16.1173	Cost: 6.18s
Train Epoch: 38 [61440/90000 (68%)]	Loss: 16.1284	Cost: 6.74s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 16.0804	Cost: 6.10s
Train Epoch: 38 	Average Loss: 16.1215
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3079

Saving model as e38_model.pt & e38_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999992874146456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 16.1545	Cost: 32.04s
Train Epoch: 39 [20480/90000 (23%)]	Loss: 16.1175	Cost: 12.00s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 16.0126	Cost: 12.19s
Train Epoch: 39 [61440/90000 (68%)]	Loss: 16.1306	Cost: 11.78s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 16.1404	Cost: 8.62s
Train Epoch: 39 	Average Loss: 16.0435
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2431

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999249416678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 15.8674	Cost: 27.85s
Train Epoch: 40 [20480/90000 (23%)]	Loss: 15.9746	Cost: 6.21s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 15.9464	Cost: 12.47s
Train Epoch: 40 [61440/90000 (68%)]	Loss: 16.1688	Cost: 12.14s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 15.9731	Cost: 11.88s
Train Epoch: 40 	Average Loss: 15.9625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2273

Saving model as e40_model.pt & e40_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999992104317507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 15.8266	Cost: 23.05s
Train Epoch: 41 [20480/90000 (23%)]	Loss: 15.9809	Cost: 6.92s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 15.9893	Cost: 7.45s
Train Epoch: 41 [61440/90000 (68%)]	Loss: 15.9523	Cost: 6.29s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 15.8557	Cost: 12.55s
Train Epoch: 41 	Average Loss: 15.8951
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2479

Learning rate: 0.00019999991704598637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 15.8076	Cost: 26.01s
Train Epoch: 42 [20480/90000 (23%)]	Loss: 15.8442	Cost: 10.94s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 15.8554	Cost: 12.06s
Train Epoch: 42 [61440/90000 (68%)]	Loss: 15.9942	Cost: 11.86s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 15.8599	Cost: 11.80s
Train Epoch: 42 	Average Loss: 15.8360
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0228

Saving model as e42_model.pt & e42_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999991295010171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 15.7771	Cost: 27.30s
Train Epoch: 43 [20480/90000 (23%)]	Loss: 15.7682	Cost: 6.37s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 15.7185	Cost: 6.53s
Train Epoch: 43 [61440/90000 (68%)]	Loss: 15.7611	Cost: 6.21s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 15.7576	Cost: 14.01s
Train Epoch: 43 	Average Loss: 15.7553
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0343

Learning rate: 0.00019999990875552108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 15.8124	Cost: 22.18s
Train Epoch: 44 [20480/90000 (23%)]	Loss: 15.7686	Cost: 6.85s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 15.6264	Cost: 7.40s
Train Epoch: 44 [61440/90000 (68%)]	Loss: 15.7858	Cost: 6.29s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 15.7663	Cost: 10.94s
Train Epoch: 44 	Average Loss: 15.6760
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9009

Saving model as e44_model.pt & e44_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999990446224451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 15.5437	Cost: 22.04s
Train Epoch: 45 [20480/90000 (23%)]	Loss: 15.5671	Cost: 6.16s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 15.6792	Cost: 6.35s
Train Epoch: 45 [61440/90000 (68%)]	Loss: 15.5271	Cost: 6.14s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 15.7042	Cost: 7.78s
Train Epoch: 45 	Average Loss: 15.6185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8477

Saving model as e45_model.pt & e45_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199999900070272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 15.6371	Cost: 25.69s
Train Epoch: 46 [20480/90000 (23%)]	Loss: 15.5039	Cost: 6.21s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 15.6222	Cost: 7.77s
Train Epoch: 46 [61440/90000 (68%)]	Loss: 15.5324	Cost: 6.37s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 15.6270	Cost: 6.06s
Train Epoch: 46 	Average Loss: 15.5631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7974

Saving model as e46_model.pt & e46_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999989557960353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 15.6891	Cost: 26.74s
Train Epoch: 47 [20480/90000 (23%)]	Loss: 15.5071	Cost: 11.66s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 15.5691	Cost: 6.50s
Train Epoch: 47 [61440/90000 (68%)]	Loss: 15.4645	Cost: 5.90s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 15.4568	Cost: 6.86s
Train Epoch: 47 	Average Loss: 15.5200
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7771

Saving model as e47_model.pt & e47_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999998909902391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 15.3976	Cost: 28.73s
Train Epoch: 48 [20480/90000 (23%)]	Loss: 15.6733	Cost: 12.04s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 15.4083	Cost: 12.10s
Train Epoch: 48 [61440/90000 (68%)]	Loss: 15.3268	Cost: 6.20s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 15.5378	Cost: 5.99s
Train Epoch: 48 	Average Loss: 15.4629
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6436

Saving model as e48_model.pt & e48_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999988630217875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 15.3673	Cost: 24.02s
Train Epoch: 49 [20480/90000 (23%)]	Loss: 15.4812	Cost: 6.51s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 15.4727	Cost: 13.82s
Train Epoch: 49 [61440/90000 (68%)]	Loss: 15.3960	Cost: 12.11s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 15.4609	Cost: 11.85s
Train Epoch: 49 	Average Loss: 15.4119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6721

Learning rate: 0.00019999988151542247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 15.4716	Cost: 27.52s
Train Epoch: 50 [20480/90000 (23%)]	Loss: 15.3194	Cost: 12.23s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 15.2866	Cost: 12.23s
Train Epoch: 50 [61440/90000 (68%)]	Loss: 15.4651	Cost: 11.81s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 15.3711	Cost: 11.82s
Train Epoch: 50 	Average Loss: 15.3511
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6232

Saving model as e50_model.pt & e50_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999987662997027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 15.2690	Cost: 23.00s
Train Epoch: 51 [20480/90000 (23%)]	Loss: 15.3266	Cost: 6.52s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 15.2515	Cost: 8.06s
Train Epoch: 51 [61440/90000 (68%)]	Loss: 15.1901	Cost: 12.09s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 15.3018	Cost: 11.76s
Train Epoch: 51 	Average Loss: 15.2858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5733

Saving model as e51_model.pt & e51_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999987164582216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 15.3017	Cost: 22.43s
Train Epoch: 52 [20480/90000 (23%)]	Loss: 15.2233	Cost: 7.91s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 15.2818	Cost: 6.87s
Train Epoch: 52 [61440/90000 (68%)]	Loss: 15.3095	Cost: 6.09s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 15.3058	Cost: 15.14s
Train Epoch: 52 	Average Loss: 15.2584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5360

Saving model as e52_model.pt & e52_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999998665629781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 15.1130	Cost: 22.66s
Train Epoch: 53 [20480/90000 (23%)]	Loss: 15.2749	Cost: 6.49s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 15.2154	Cost: 6.56s
Train Epoch: 53 [61440/90000 (68%)]	Loss: 15.3065	Cost: 6.18s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 15.3685	Cost: 6.40s
Train Epoch: 53 	Average Loss: 15.2178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4757

Saving model as e53_model.pt & e53_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999986138143815
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 15.1505	Cost: 24.58s
Train Epoch: 54 [20480/90000 (23%)]	Loss: 15.2788	Cost: 6.46s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 15.2136	Cost: 6.51s
Train Epoch: 54 [61440/90000 (68%)]	Loss: 15.1464	Cost: 6.29s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 15.1145	Cost: 6.16s
Train Epoch: 54 	Average Loss: 15.1457
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4175

Saving model as e54_model.pt & e54_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999985610120227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 15.0574	Cost: 22.54s
Train Epoch: 55 [20480/90000 (23%)]	Loss: 15.1889	Cost: 6.25s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 15.2144	Cost: 6.49s
Train Epoch: 55 [61440/90000 (68%)]	Loss: 15.0902	Cost: 6.17s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 15.0758	Cost: 6.74s
Train Epoch: 55 	Average Loss: 15.1068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3357

Saving model as e55_model.pt & e55_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999998507222705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 15.1381	Cost: 22.78s
Train Epoch: 56 [20480/90000 (23%)]	Loss: 15.0254	Cost: 6.74s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 15.0515	Cost: 6.44s
Train Epoch: 56 [61440/90000 (68%)]	Loss: 15.0269	Cost: 6.25s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 14.9809	Cost: 6.25s
Train Epoch: 56 	Average Loss: 15.0712
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2871

Saving model as e56_model.pt & e56_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999984524464283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 15.0210	Cost: 24.03s
Train Epoch: 57 [20480/90000 (23%)]	Loss: 15.0194	Cost: 6.93s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 14.9297	Cost: 6.50s
Train Epoch: 57 [61440/90000 (68%)]	Loss: 15.0141	Cost: 6.39s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 15.1617	Cost: 6.07s
Train Epoch: 57 	Average Loss: 15.0152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2774

Saving model as e57_model.pt & e57_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999998396683193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 14.9262	Cost: 23.41s
Train Epoch: 58 [20480/90000 (23%)]	Loss: 15.2031	Cost: 6.57s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 15.0189	Cost: 8.92s
Train Epoch: 58 [61440/90000 (68%)]	Loss: 14.9992	Cost: 6.49s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 15.0212	Cost: 9.67s
Train Epoch: 58 	Average Loss: 14.9641
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2252

Saving model as e58_model.pt & e58_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999983399329984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 14.9218	Cost: 23.84s
Train Epoch: 59 [20480/90000 (23%)]	Loss: 15.1562	Cost: 6.07s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 14.8327	Cost: 8.65s
Train Epoch: 59 [61440/90000 (68%)]	Loss: 14.9252	Cost: 6.10s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 14.9200	Cost: 6.03s
Train Epoch: 59 	Average Loss: 14.9385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1809

Saving model as e59_model.pt & e59_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999982821958452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 14.7980	Cost: 23.90s
Train Epoch: 60 [20480/90000 (23%)]	Loss: 14.9050	Cost: 6.29s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 14.8817	Cost: 6.98s
Train Epoch: 60 [61440/90000 (68%)]	Loss: 15.0070	Cost: 6.17s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 14.7928	Cost: 6.11s
Train Epoch: 60 	Average Loss: 14.8872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1258

Saving model as e60_model.pt & e60_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999982234717332
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 14.9213	Cost: 28.45s
Train Epoch: 61 [20480/90000 (23%)]	Loss: 14.8445	Cost: 12.24s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 14.8396	Cost: 12.32s
Train Epoch: 61 [61440/90000 (68%)]	Loss: 14.9741	Cost: 9.48s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 14.8682	Cost: 6.07s
Train Epoch: 61 	Average Loss: 14.8528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1220

Saving model as e61_model.pt & e61_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999981637606627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 14.8606	Cost: 23.38s
Train Epoch: 62 [20480/90000 (23%)]	Loss: 14.8171	Cost: 6.39s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 14.8410	Cost: 12.90s
Train Epoch: 62 [61440/90000 (68%)]	Loss: 14.8312	Cost: 12.08s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 15.0320	Cost: 11.81s
Train Epoch: 62 	Average Loss: 14.8134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1363

Learning rate: 0.00019999981030626333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 14.7829	Cost: 26.48s
Train Epoch: 63 [20480/90000 (23%)]	Loss: 14.7559	Cost: 11.86s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 14.6685	Cost: 12.19s
Train Epoch: 63 [61440/90000 (68%)]	Loss: 14.9177	Cost: 11.85s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 14.7535	Cost: 11.79s
Train Epoch: 63 	Average Loss: 14.7627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0797

Saving model as e63_model.pt & e63_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999980413776456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 14.7084	Cost: 22.51s
Train Epoch: 64 [20480/90000 (23%)]	Loss: 14.8230	Cost: 6.49s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 14.8083	Cost: 9.11s
Train Epoch: 64 [61440/90000 (68%)]	Loss: 14.6688	Cost: 12.16s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 14.7308	Cost: 12.29s
Train Epoch: 64 	Average Loss: 14.7360
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0248

Saving model as e64_model.pt & e64_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999979787056995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 14.7599	Cost: 22.27s
Train Epoch: 65 [20480/90000 (23%)]	Loss: 14.6810	Cost: 6.68s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 14.7497	Cost: 11.06s
Train Epoch: 65 [61440/90000 (68%)]	Loss: 14.8444	Cost: 12.16s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 14.6947	Cost: 12.29s
Train Epoch: 65 	Average Loss: 14.6853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9730

Saving model as e65_model.pt & e65_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999979150467947
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 14.7356	Cost: 23.36s
Train Epoch: 66 [20480/90000 (23%)]	Loss: 14.7305	Cost: 6.18s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 14.7220	Cost: 13.19s
Train Epoch: 66 [61440/90000 (68%)]	Loss: 14.6230	Cost: 11.94s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 14.6604	Cost: 11.79s
Train Epoch: 66 	Average Loss: 14.6448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9547

Saving model as e66_model.pt & e66_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999978504009312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 14.6393	Cost: 26.36s
Train Epoch: 67 [20480/90000 (23%)]	Loss: 14.5918	Cost: 7.92s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 14.6476	Cost: 12.32s
Train Epoch: 67 [61440/90000 (68%)]	Loss: 14.6428	Cost: 12.03s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 14.5959	Cost: 11.85s
Train Epoch: 67 	Average Loss: 14.6207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.8281

Saving model as e67_model.pt & e67_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999977847681098
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 14.5786	Cost: 25.95s
Train Epoch: 68 [20480/90000 (23%)]	Loss: 14.6939	Cost: 6.68s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 14.6021	Cost: 10.78s
Train Epoch: 68 [61440/90000 (68%)]	Loss: 14.5508	Cost: 12.34s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 14.6182	Cost: 12.11s
Train Epoch: 68 	Average Loss: 14.5877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.8830

Learning rate: 0.00019999977181483299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 14.5803	Cost: 26.11s
Train Epoch: 69 [20480/90000 (23%)]	Loss: 14.7314	Cost: 12.27s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 14.3477	Cost: 12.58s
Train Epoch: 69 [61440/90000 (68%)]	Loss: 14.7011	Cost: 12.20s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 14.5961	Cost: 11.96s
Train Epoch: 69 	Average Loss: 14.5322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.8213

Saving model as e69_model.pt & e69_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999997650541592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 14.4926	Cost: 22.45s
Train Epoch: 70 [20480/90000 (23%)]	Loss: 14.6095	Cost: 6.39s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 14.5016	Cost: 8.18s
Train Epoch: 70 [61440/90000 (68%)]	Loss: 14.5754	Cost: 10.17s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 14.7001	Cost: 12.73s
Train Epoch: 70 	Average Loss: 14.5070
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7320

Saving model as e70_model.pt & e70_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999997581947896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 14.4677	Cost: 21.94s
Train Epoch: 71 [20480/90000 (23%)]	Loss: 14.5345	Cost: 6.13s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 14.4558	Cost: 7.68s
Train Epoch: 71 [61440/90000 (68%)]	Loss: 14.3831	Cost: 6.86s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 14.5297	Cost: 14.79s
Train Epoch: 71 	Average Loss: 14.4808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7559

Learning rate: 0.0001999997512367242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 14.5342	Cost: 28.36s
Train Epoch: 72 [20480/90000 (23%)]	Loss: 14.5218	Cost: 12.36s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 14.3866	Cost: 12.21s
Train Epoch: 72 [61440/90000 (68%)]	Loss: 14.4795	Cost: 11.88s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 14.4576	Cost: 11.96s
Train Epoch: 72 	Average Loss: 14.4480
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7192

Saving model as e72_model.pt & e72_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199999744179963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 14.4563	Cost: 22.33s
Train Epoch: 73 [20480/90000 (23%)]	Loss: 14.5921	Cost: 6.30s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 14.3958	Cost: 11.05s
Train Epoch: 73 [61440/90000 (68%)]	Loss: 14.5404	Cost: 12.38s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 14.4161	Cost: 12.00s
Train Epoch: 73 	Average Loss: 14.4175
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6956

Saving model as e73_model.pt & e73_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199999737024506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 14.3860	Cost: 24.53s
Train Epoch: 74 [20480/90000 (23%)]	Loss: 14.4181	Cost: 6.60s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 14.3458	Cost: 12.92s
Train Epoch: 74 [61440/90000 (68%)]	Loss: 14.4394	Cost: 12.17s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 14.3632	Cost: 11.88s
Train Epoch: 74 	Average Loss: 14.3626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6911

Saving model as e74_model.pt & e74_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999972977035322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 14.5014	Cost: 27.73s
Train Epoch: 75 [20480/90000 (23%)]	Loss: 14.3505	Cost: 12.43s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 14.3621	Cost: 11.94s
Train Epoch: 75 [61440/90000 (68%)]	Loss: 14.2790	Cost: 11.80s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 14.4214	Cost: 11.83s
Train Epoch: 75 	Average Loss: 14.3540
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6153

Saving model as e75_model.pt & e75_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999972241750466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 14.4315	Cost: 23.54s
Train Epoch: 76 [20480/90000 (23%)]	Loss: 14.4347	Cost: 6.26s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 14.4443	Cost: 8.35s
Train Epoch: 76 [61440/90000 (68%)]	Loss: 14.3700	Cost: 8.79s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 14.2456	Cost: 12.72s
Train Epoch: 76 	Average Loss: 14.3170
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5663

Saving model as e76_model.pt & e76_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999997149659603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 14.4410	Cost: 23.26s
Train Epoch: 77 [20480/90000 (23%)]	Loss: 14.3060	Cost: 7.07s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 14.3646	Cost: 6.57s
Train Epoch: 77 [61440/90000 (68%)]	Loss: 14.2198	Cost: 6.43s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 14.3596	Cost: 6.06s
Train Epoch: 77 	Average Loss: 14.2511
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5034

Saving model as e77_model.pt & e77_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999997074157202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 14.3984	Cost: 23.70s
Train Epoch: 78 [20480/90000 (23%)]	Loss: 14.3472	Cost: 6.36s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 14.1572	Cost: 6.51s
Train Epoch: 78 [61440/90000 (68%)]	Loss: 14.3150	Cost: 6.16s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 14.2729	Cost: 6.11s
Train Epoch: 78 	Average Loss: 14.2701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4976

Saving model as e78_model.pt & e78_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999969976678433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 14.1954	Cost: 23.61s
Train Epoch: 79 [20480/90000 (23%)]	Loss: 14.3066	Cost: 7.00s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 14.1579	Cost: 6.43s
Train Epoch: 79 [61440/90000 (68%)]	Loss: 14.2445	Cost: 6.18s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 14.1957	Cost: 6.07s
Train Epoch: 79 	Average Loss: 14.1991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5053

Learning rate: 0.00019999969201915272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 14.3483	Cost: 23.01s
Train Epoch: 80 [20480/90000 (23%)]	Loss: 14.3207	Cost: 6.28s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 14.0236	Cost: 6.44s
Train Epoch: 80 [61440/90000 (68%)]	Loss: 14.2756	Cost: 6.17s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 14.2787	Cost: 6.25s
Train Epoch: 80 	Average Loss: 14.1733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4919

Saving model as e80_model.pt & e80_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999968417282538
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 14.1975	Cost: 26.11s
Train Epoch: 81 [20480/90000 (23%)]	Loss: 14.2751	Cost: 11.93s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 14.2208	Cost: 10.75s
Train Epoch: 81 [61440/90000 (68%)]	Loss: 14.1468	Cost: 5.74s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 14.2149	Cost: 6.56s
Train Epoch: 81 	Average Loss: 14.1651
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4332

Saving model as e81_model.pt & e81_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999996762278023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 14.1424	Cost: 27.92s
Train Epoch: 82 [20480/90000 (23%)]	Loss: 14.1512	Cost: 12.28s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 14.1805	Cost: 12.08s
Train Epoch: 82 [61440/90000 (68%)]	Loss: 14.1264	Cost: 11.84s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 14.1832	Cost: 8.63s
Train Epoch: 82 	Average Loss: 14.1355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4076

Saving model as e82_model.pt & e82_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999996681840835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 14.1269	Cost: 22.14s
Train Epoch: 83 [20480/90000 (23%)]	Loss: 14.1838	Cost: 6.28s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 13.9237	Cost: 12.04s
Train Epoch: 83 [61440/90000 (68%)]	Loss: 14.1727	Cost: 12.15s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 14.0765	Cost: 11.90s
Train Epoch: 83 	Average Loss: 14.0636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3093

Saving model as e83_model.pt & e83_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999966004166902
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 14.0368	Cost: 28.09s
Train Epoch: 84 [20480/90000 (23%)]	Loss: 14.1037	Cost: 7.06s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 14.0574	Cost: 9.88s
Train Epoch: 84 [61440/90000 (68%)]	Loss: 14.0750	Cost: 11.83s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 14.0825	Cost: 12.13s
Train Epoch: 84 	Average Loss: 14.0487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.2862

Saving model as e84_model.pt & e84_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999996518005588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 14.0378	Cost: 25.05s
Train Epoch: 85 [20480/90000 (23%)]	Loss: 14.0706	Cost: 6.17s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 14.0148	Cost: 6.90s
Train Epoch: 85 [61440/90000 (68%)]	Loss: 14.1170	Cost: 6.13s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 14.0910	Cost: 17.68s
Train Epoch: 85 	Average Loss: 14.0037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.2628

Saving model as e85_model.pt & e85_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999964346075288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 14.0907	Cost: 22.52s
Train Epoch: 86 [20480/90000 (23%)]	Loss: 13.9903	Cost: 6.37s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 14.0708	Cost: 6.81s
Train Epoch: 86 [61440/90000 (68%)]	Loss: 13.9016	Cost: 6.33s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 14.0586	Cost: 14.03s
Train Epoch: 86 	Average Loss: 13.9901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4152

Learning rate: 0.00019999963502225128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 14.0280	Cost: 22.35s
Train Epoch: 87 [20480/90000 (23%)]	Loss: 14.1543	Cost: 6.44s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 13.8670	Cost: 13.12s
Train Epoch: 87 [61440/90000 (68%)]	Loss: 13.9697	Cost: 12.31s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 14.1569	Cost: 12.20s
Train Epoch: 87 	Average Loss: 13.9612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.2420

Saving model as e87_model.pt & e87_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999962648505396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 14.1321	Cost: 23.36s
Train Epoch: 88 [20480/90000 (23%)]	Loss: 14.0304	Cost: 8.65s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 14.0519	Cost: 13.66s
Train Epoch: 88 [61440/90000 (68%)]	Loss: 14.1113	Cost: 12.47s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 13.9191	Cost: 12.08s
Train Epoch: 88 	Average Loss: 13.9433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1910

Saving model as e88_model.pt & e88_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199999617849161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 13.9552	Cost: 24.60s
Train Epoch: 89 [20480/90000 (23%)]	Loss: 14.0220	Cost: 8.17s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 13.8545	Cost: 16.88s
Train Epoch: 89 [61440/90000 (68%)]	Loss: 13.8712	Cost: 12.23s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 13.9640	Cost: 11.88s
Train Epoch: 89 	Average Loss: 13.8963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1749

Saving model as e89_model.pt & e89_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999960911457236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 13.7884	Cost: 22.87s
Train Epoch: 90 [20480/90000 (23%)]	Loss: 13.8870	Cost: 6.34s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 13.8817	Cost: 9.98s
Train Epoch: 90 [61440/90000 (68%)]	Loss: 13.9646	Cost: 11.97s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 14.0358	Cost: 11.93s
Train Epoch: 90 	Average Loss: 13.8903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1922

Learning rate: 0.00019999960028128805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 13.7617	Cost: 26.19s
Train Epoch: 91 [20480/90000 (23%)]	Loss: 13.7613	Cost: 12.21s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 13.7760	Cost: 12.05s
Train Epoch: 91 [61440/90000 (68%)]	Loss: 13.8109	Cost: 11.80s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 13.9316	Cost: 8.01s
Train Epoch: 91 	Average Loss: 13.8436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1034

Saving model as e91_model.pt & e91_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999959134930808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 13.8068	Cost: 24.58s
Train Epoch: 92 [20480/90000 (23%)]	Loss: 13.8896	Cost: 6.59s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 13.8760	Cost: 12.25s
Train Epoch: 92 [61440/90000 (68%)]	Loss: 13.7854	Cost: 12.02s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 13.9269	Cost: 11.86s
Train Epoch: 92 	Average Loss: 13.8363
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1377

Learning rate: 0.0001999995823186325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 13.8489	Cost: 32.23s
Train Epoch: 93 [20480/90000 (23%)]	Loss: 13.7957	Cost: 12.13s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 13.8402	Cost: 11.95s
Train Epoch: 93 [61440/90000 (68%)]	Loss: 13.8404	Cost: 6.23s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 13.7558	Cost: 6.41s
Train Epoch: 93 	Average Loss: 13.8028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1228

Learning rate: 0.00019999957318926127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 13.7166	Cost: 26.46s
Train Epoch: 94 [20480/90000 (23%)]	Loss: 13.8286	Cost: 7.43s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 13.8058	Cost: 6.13s
Train Epoch: 94 [61440/90000 (68%)]	Loss: 13.7458	Cost: 6.91s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 13.8257	Cost: 6.00s
Train Epoch: 94 	Average Loss: 13.7602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0915

Saving model as e94_model.pt & e94_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999956396119442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 13.7046	Cost: 26.82s
Train Epoch: 95 [20480/90000 (23%)]	Loss: 13.7134	Cost: 11.78s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 13.7272	Cost: 10.48s
Train Epoch: 95 [61440/90000 (68%)]	Loss: 13.6748	Cost: 5.79s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 13.6933	Cost: 6.73s
Train Epoch: 95 	Average Loss: 13.7224
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0484

Saving model as e95_model.pt & e95_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999955463443194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 13.6851	Cost: 23.06s
Train Epoch: 96 [20480/90000 (23%)]	Loss: 13.6910	Cost: 6.29s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 13.6673	Cost: 12.53s
Train Epoch: 96 [61440/90000 (68%)]	Loss: 13.7166	Cost: 12.08s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 13.7101	Cost: 11.84s
Train Epoch: 96 	Average Loss: 13.7197
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9230

Saving model as e96_model.pt & e96_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999954520897388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 13.6833	Cost: 26.23s
Train Epoch: 97 [20480/90000 (23%)]	Loss: 13.7810	Cost: 6.24s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 13.6590	Cost: 6.49s
Train Epoch: 97 [61440/90000 (68%)]	Loss: 13.7931	Cost: 6.18s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 13.7510	Cost: 5.92s
Train Epoch: 97 	Average Loss: 13.6909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0550

Learning rate: 0.00019999953568482025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 13.7184	Cost: 21.67s
Train Epoch: 98 [20480/90000 (23%)]	Loss: 13.5945	Cost: 7.90s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 13.8188	Cost: 6.74s
Train Epoch: 98 [61440/90000 (68%)]	Loss: 13.6860	Cost: 6.27s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 13.6625	Cost: 14.35s
Train Epoch: 98 	Average Loss: 13.6444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0025

Learning rate: 0.000199999526061971
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 13.4648	Cost: 23.60s
Train Epoch: 99 [20480/90000 (23%)]	Loss: 13.6517	Cost: 6.30s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 13.5001	Cost: 12.20s
Train Epoch: 99 [61440/90000 (68%)]	Loss: 13.7938	Cost: 12.32s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 13.6857	Cost: 12.15s
Train Epoch: 99 	Average Loss: 13.6081
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8843

Saving model as e99_model.pt & e99_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999951634042617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 13.6224	Cost: 22.05s
Train Epoch: 100 [20480/90000 (23%)]	Loss: 13.6991	Cost: 6.35s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 13.5458	Cost: 7.56s
Train Epoch: 100 [61440/90000 (68%)]	Loss: 13.5945	Cost: 8.76s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 13.5396	Cost: 12.81s
Train Epoch: 100 	Average Loss: 13.5910
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8886

Learning rate: 0.00019999950652018581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 13.8190	Cost: 26.42s
Train Epoch: 101 [20480/90000 (23%)]	Loss: 13.6394	Cost: 11.24s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 13.5757	Cost: 12.43s
Train Epoch: 101 [61440/90000 (68%)]	Loss: 13.5880	Cost: 11.96s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 13.6106	Cost: 11.84s
Train Epoch: 101 	Average Loss: 13.6035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9126

Learning rate: 0.00019999949660124986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 13.5862	Cost: 24.89s
Train Epoch: 102 [20480/90000 (23%)]	Loss: 13.7140	Cost: 12.13s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 13.5318	Cost: 12.17s
Train Epoch: 102 [61440/90000 (68%)]	Loss: 13.7199	Cost: 11.87s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 13.4511	Cost: 11.64s
Train Epoch: 102 	Average Loss: 13.5532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8496

Saving model as e102_model.pt & e102_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999948658361836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 13.6974	Cost: 21.84s
Train Epoch: 103 [20480/90000 (23%)]	Loss: 13.5641	Cost: 6.36s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 13.3553	Cost: 7.44s
Train Epoch: 103 [61440/90000 (68%)]	Loss: 13.6312	Cost: 6.25s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 13.4888	Cost: 16.72s
Train Epoch: 103 	Average Loss: 13.5470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9016

Learning rate: 0.00019999947646729134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 13.6914	Cost: 24.14s
Train Epoch: 104 [20480/90000 (23%)]	Loss: 13.5648	Cost: 7.43s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 13.2962	Cost: 12.04s
Train Epoch: 104 [61440/90000 (68%)]	Loss: 13.6216	Cost: 12.25s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 13.5866	Cost: 12.04s
Train Epoch: 104 	Average Loss: 13.5071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9076

Learning rate: 0.00019999946625226878
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 13.4872	Cost: 25.60s
Train Epoch: 105 [20480/90000 (23%)]	Loss: 13.3091	Cost: 11.86s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 13.3908	Cost: 11.92s
Train Epoch: 105 [61440/90000 (68%)]	Loss: 13.6420	Cost: 11.86s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 13.4637	Cost: 10.31s
Train Epoch: 105 	Average Loss: 13.4889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7882

Saving model as e105_model.pt & e105_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999945593855072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 13.5445	Cost: 21.21s
Train Epoch: 106 [20480/90000 (23%)]	Loss: 13.6005	Cost: 6.16s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 13.4967	Cost: 10.15s
Train Epoch: 106 [61440/90000 (68%)]	Loss: 13.4736	Cost: 12.25s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 13.4426	Cost: 12.25s
Train Epoch: 106 	Average Loss: 13.4569
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7748

Saving model as e106_model.pt & e106_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999944552613714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 13.6111	Cost: 21.88s
Train Epoch: 107 [20480/90000 (23%)]	Loss: 13.4977	Cost: 6.26s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 13.3138	Cost: 6.90s
Train Epoch: 107 [61440/90000 (68%)]	Loss: 13.4243	Cost: 6.01s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 13.4715	Cost: 7.69s
Train Epoch: 107 	Average Loss: 13.4420
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7382

Saving model as e107_model.pt & e107_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999943501502806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 13.3532	Cost: 26.99s
Train Epoch: 108 [20480/90000 (23%)]	Loss: 13.5997	Cost: 11.88s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 13.3214	Cost: 10.56s
Train Epoch: 108 [61440/90000 (68%)]	Loss: 13.5653	Cost: 5.80s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 13.3889	Cost: 6.25s
Train Epoch: 108 	Average Loss: 13.4195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7855

Learning rate: 0.0001999994244052235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 13.6027	Cost: 26.77s
Train Epoch: 109 [20480/90000 (23%)]	Loss: 13.4892	Cost: 10.63s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 13.3184	Cost: 6.16s
Train Epoch: 109 [61440/90000 (68%)]	Loss: 13.5408	Cost: 6.19s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 13.2497	Cost: 6.91s
Train Epoch: 109 	Average Loss: 13.3942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8112

Learning rate: 0.00019999941369672346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 13.4984	Cost: 24.71s
Train Epoch: 110 [20480/90000 (23%)]	Loss: 13.4459	Cost: 6.05s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 13.3561	Cost: 6.91s
Train Epoch: 110 [61440/90000 (68%)]	Loss: 13.4133	Cost: 6.77s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 13.4670	Cost: 6.16s
Train Epoch: 110 	Average Loss: 13.3873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6950

Saving model as e110_model.pt & e110_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999940288952794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 13.4017	Cost: 28.09s
Train Epoch: 111 [20480/90000 (23%)]	Loss: 13.3565	Cost: 12.56s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 13.3266	Cost: 11.69s
Train Epoch: 111 [61440/90000 (68%)]	Loss: 13.3639	Cost: 11.79s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 13.4846	Cost: 8.03s
Train Epoch: 111 	Average Loss: 13.3692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7014

Learning rate: 0.000199999391983637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 13.4323	Cost: 26.10s
Train Epoch: 112 [20480/90000 (23%)]	Loss: 13.3363	Cost: 12.06s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 13.3988	Cost: 11.96s
Train Epoch: 112 [61440/90000 (68%)]	Loss: 13.4127	Cost: 6.21s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 13.3781	Cost: 5.69s
Train Epoch: 112 	Average Loss: 13.3399
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6153

Saving model as e112_model.pt & e112_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999993809790506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 13.5106	Cost: 28.28s
Train Epoch: 113 [20480/90000 (23%)]	Loss: 13.3971	Cost: 12.38s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 13.3612	Cost: 11.58s
Train Epoch: 113 [61440/90000 (68%)]	Loss: 13.3053	Cost: 7.48s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 13.3804	Cost: 5.80s
Train Epoch: 113 	Average Loss: 13.3083
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6851

Learning rate: 0.00019999936987576873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 13.2665	Cost: 22.77s
Train Epoch: 114 [20480/90000 (23%)]	Loss: 13.3307	Cost: 6.14s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 13.3048	Cost: 8.69s
Train Epoch: 114 [61440/90000 (68%)]	Loss: 13.3327	Cost: 6.21s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 13.3421	Cost: 7.10s
Train Epoch: 114 	Average Loss: 13.2969
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5901

Saving model as e114_model.pt & e114_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999935867379148
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 13.4858	Cost: 26.55s
Train Epoch: 115 [20480/90000 (23%)]	Loss: 13.2660	Cost: 9.33s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 13.2973	Cost: 6.03s
Train Epoch: 115 [61440/90000 (68%)]	Loss: 13.4034	Cost: 6.38s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 13.2573	Cost: 6.42s
Train Epoch: 115 	Average Loss: 13.2954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5828

Saving model as e115_model.pt & e115_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999934737311882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 13.2761	Cost: 24.53s
Train Epoch: 116 [20480/90000 (23%)]	Loss: 13.4161	Cost: 10.60s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 13.2372	Cost: 12.21s
Train Epoch: 116 [61440/90000 (68%)]	Loss: 13.2887	Cost: 11.94s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 13.3038	Cost: 11.89s
Train Epoch: 116 	Average Loss: 13.2546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5110

Saving model as e116_model.pt & e116_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999933597375074
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 13.2596	Cost: 23.24s
Train Epoch: 117 [20480/90000 (23%)]	Loss: 13.2451	Cost: 6.30s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 13.1844	Cost: 6.77s
Train Epoch: 117 [61440/90000 (68%)]	Loss: 13.2933	Cost: 6.24s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 13.1408	Cost: 15.76s
Train Epoch: 117 	Average Loss: 13.2189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4992

Saving model as e117_model.pt & e117_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999993244756873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 13.1405	Cost: 23.45s
Train Epoch: 118 [20480/90000 (23%)]	Loss: 13.2458	Cost: 6.31s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 13.1735	Cost: 6.42s
Train Epoch: 118 [61440/90000 (68%)]	Loss: 13.2835	Cost: 6.03s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 13.2945	Cost: 9.38s
Train Epoch: 118 	Average Loss: 13.2113
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5625

Learning rate: 0.00019999931287892846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 13.1746	Cost: 22.83s
Train Epoch: 119 [20480/90000 (23%)]	Loss: 13.2556	Cost: 6.40s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 13.1243	Cost: 12.48s
Train Epoch: 119 [61440/90000 (68%)]	Loss: 13.2323	Cost: 12.16s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 13.1456	Cost: 11.90s
Train Epoch: 119 	Average Loss: 13.1761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5054

Learning rate: 0.00019999930118347426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 13.2159	Cost: 25.27s
Train Epoch: 120 [20480/90000 (23%)]	Loss: 13.3236	Cost: 11.85s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 13.2533	Cost: 12.11s
Train Epoch: 120 [61440/90000 (68%)]	Loss: 13.0553	Cost: 11.84s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 13.2198	Cost: 10.95s
Train Epoch: 120 	Average Loss: 13.1710
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4693

Saving model as e120_model.pt & e120_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999992893893247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 13.1553	Cost: 22.37s
Train Epoch: 121 [20480/90000 (23%)]	Loss: 13.3943	Cost: 6.41s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 13.1451	Cost: 7.96s
Train Epoch: 121 [61440/90000 (68%)]	Loss: 13.1365	Cost: 8.22s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 13.1126	Cost: 13.91s
Train Epoch: 121 	Average Loss: 13.1736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4702

Learning rate: 0.0001999992774964798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 13.1444	Cost: 23.84s
Train Epoch: 122 [20480/90000 (23%)]	Loss: 13.2790	Cost: 6.24s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 13.0761	Cost: 12.28s
Train Epoch: 122 [61440/90000 (68%)]	Loss: 13.3679	Cost: 12.23s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 13.2831	Cost: 11.85s
Train Epoch: 122 	Average Loss: 13.1339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4837

Learning rate: 0.00019999926550493962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 13.2119	Cost: 26.39s
Train Epoch: 123 [20480/90000 (23%)]	Loss: 13.1883	Cost: 12.22s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 13.1426	Cost: 12.09s
Train Epoch: 123 [61440/90000 (68%)]	Loss: 13.0938	Cost: 11.87s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 13.0372	Cost: 9.16s
Train Epoch: 123 	Average Loss: 13.1075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4310

Saving model as e123_model.pt & e123_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999925341470404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 13.2703	Cost: 23.15s
Train Epoch: 124 [20480/90000 (23%)]	Loss: 13.1560	Cost: 6.39s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 13.2642	Cost: 13.27s
Train Epoch: 124 [61440/90000 (68%)]	Loss: 13.0793	Cost: 12.12s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 13.1608	Cost: 11.87s
Train Epoch: 124 	Average Loss: 13.1021
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4056

Saving model as e124_model.pt & e124_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999992412257732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 13.1938	Cost: 22.25s
Train Epoch: 125 [20480/90000 (23%)]	Loss: 13.1851	Cost: 6.08s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 13.0131	Cost: 6.31s
Train Epoch: 125 [61440/90000 (68%)]	Loss: 13.1001	Cost: 6.26s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 13.2355	Cost: 15.06s
Train Epoch: 125 	Average Loss: 13.0946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4298

Learning rate: 0.00019999922893814705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 13.0028	Cost: 22.78s
Train Epoch: 126 [20480/90000 (23%)]	Loss: 13.1475	Cost: 6.36s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 13.0096	Cost: 11.49s
Train Epoch: 126 [61440/90000 (68%)]	Loss: 13.0107	Cost: 12.11s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 12.9737	Cost: 11.84s
Train Epoch: 126 	Average Loss: 13.0427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3679

Saving model as e126_model.pt & e126_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999921655182562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 13.1876	Cost: 22.15s
Train Epoch: 127 [20480/90000 (23%)]	Loss: 12.9240	Cost: 6.42s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 13.0100	Cost: 6.50s
Train Epoch: 127 [61440/90000 (68%)]	Loss: 13.0823	Cost: 6.13s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 13.0778	Cost: 9.70s
Train Epoch: 127 	Average Loss: 13.0188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3723

Learning rate: 0.0001999992040668089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 12.9328	Cost: 23.07s
Train Epoch: 128 [20480/90000 (23%)]	Loss: 13.0331	Cost: 6.21s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 13.0016	Cost: 12.06s
Train Epoch: 128 [61440/90000 (68%)]	Loss: 13.1343	Cost: 12.07s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 13.0854	Cost: 11.83s
Train Epoch: 128 	Average Loss: 13.0222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3268

Saving model as e128_model.pt & e128_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999919148309698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 12.9592	Cost: 22.28s
Train Epoch: 129 [20480/90000 (23%)]	Loss: 12.9971	Cost: 6.41s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 12.9981	Cost: 8.32s
Train Epoch: 129 [61440/90000 (68%)]	Loss: 12.9400	Cost: 8.88s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 13.0801	Cost: 13.32s
Train Epoch: 129 	Average Loss: 12.9901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3508

Learning rate: 0.00019999917880068977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 13.1022	Cost: 27.93s
Train Epoch: 130 [20480/90000 (23%)]	Loss: 12.9208	Cost: 12.33s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 12.9213	Cost: 12.19s
Train Epoch: 130 [61440/90000 (68%)]	Loss: 12.9462	Cost: 11.89s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 13.0333	Cost: 11.87s
Train Epoch: 130 	Average Loss: 13.0031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3384

Learning rate: 0.00019999916601958734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 12.9441	Cost: 28.01s
Train Epoch: 131 [20480/90000 (23%)]	Loss: 12.8492	Cost: 12.15s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 13.0162	Cost: 12.16s
Train Epoch: 131 [61440/90000 (68%)]	Loss: 12.9939	Cost: 11.78s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 13.1542	Cost: 7.51s
Train Epoch: 131 	Average Loss: 12.9722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3180

Saving model as e131_model.pt & e131_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999915313978966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 13.1860	Cost: 21.84s
Train Epoch: 132 [20480/90000 (23%)]	Loss: 12.9248	Cost: 6.23s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 13.0192	Cost: 9.90s
Train Epoch: 132 [61440/90000 (68%)]	Loss: 13.0071	Cost: 12.18s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 13.0178	Cost: 11.99s
Train Epoch: 132 	Average Loss: 12.9550
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2791

Saving model as e132_model.pt & e132_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999914016129682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 13.1076	Cost: 22.45s
Train Epoch: 133 [20480/90000 (23%)]	Loss: 13.0511	Cost: 6.29s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 13.0021	Cost: 6.53s
Train Epoch: 133 [61440/90000 (68%)]	Loss: 13.0574	Cost: 6.24s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 12.8934	Cost: 6.28s
Train Epoch: 133 	Average Loss: 12.9353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2876

Learning rate: 0.00019999912708410875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 13.0191	Cost: 21.70s
Train Epoch: 134 [20480/90000 (23%)]	Loss: 12.9550	Cost: 6.42s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 12.9084	Cost: 11.47s
Train Epoch: 134 [61440/90000 (68%)]	Loss: 12.9040	Cost: 12.18s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 12.8488	Cost: 11.93s
Train Epoch: 134 	Average Loss: 12.8999
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1791

Saving model as e134_model.pt & e134_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999911390822548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 13.0012	Cost: 22.05s
Train Epoch: 135 [20480/90000 (23%)]	Loss: 12.9179	Cost: 6.28s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 12.7677	Cost: 7.82s
Train Epoch: 135 [61440/90000 (68%)]	Loss: 12.9902	Cost: 8.83s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 12.8569	Cost: 13.09s
Train Epoch: 135 	Average Loss: 12.8971
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2288

Learning rate: 0.00019999910063364705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 13.0954	Cost: 37.07s
Train Epoch: 136 [20480/90000 (23%)]	Loss: 13.0093	Cost: 11.91s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 12.9583	Cost: 12.25s
Train Epoch: 136 [61440/90000 (68%)]	Loss: 12.9358	Cost: 11.86s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 12.8906	Cost: 9.79s
Train Epoch: 136 	Average Loss: 12.8894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2052

Learning rate: 0.00019999908726037348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 12.9935	Cost: 32.36s
Train Epoch: 137 [20480/90000 (23%)]	Loss: 12.9912	Cost: 10.08s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 12.9516	Cost: 7.42s
Train Epoch: 137 [61440/90000 (68%)]	Loss: 13.0219	Cost: 6.35s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 12.8916	Cost: 9.49s
Train Epoch: 137 	Average Loss: 12.8903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2640

Learning rate: 0.00019999907378840477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 12.9138	Cost: 23.58s
Train Epoch: 138 [20480/90000 (23%)]	Loss: 12.8642	Cost: 6.28s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 12.8307	Cost: 6.73s
Train Epoch: 138 [61440/90000 (68%)]	Loss: 12.8637	Cost: 6.22s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 12.9085	Cost: 6.09s
Train Epoch: 138 	Average Loss: 12.8441
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2869

Learning rate: 0.00019999906021774094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 12.8592	Cost: 22.07s
Train Epoch: 139 [20480/90000 (23%)]	Loss: 12.9109	Cost: 6.23s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 12.7482	Cost: 7.64s
Train Epoch: 139 [61440/90000 (68%)]	Loss: 12.8316	Cost: 6.30s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 12.9167	Cost: 15.49s
Train Epoch: 139 	Average Loss: 12.8223
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1587

Saving model as e139_model.pt & e139_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999904654838195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 12.8502	Cost: 26.50s
Train Epoch: 140 [20480/90000 (23%)]	Loss: 12.8806	Cost: 6.33s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 12.6531	Cost: 6.56s
Train Epoch: 140 [61440/90000 (68%)]	Loss: 12.8189	Cost: 6.21s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 12.8558	Cost: 18.00s
Train Epoch: 140 	Average Loss: 12.7999
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0994

Saving model as e140_model.pt & e140_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999990327803279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 12.9153	Cost: 23.34s
Train Epoch: 141 [20480/90000 (23%)]	Loss: 12.8445	Cost: 6.39s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 12.7667	Cost: 6.70s
Train Epoch: 141 [61440/90000 (68%)]	Loss: 12.8783	Cost: 6.14s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 12.6952	Cost: 6.38s
Train Epoch: 141 	Average Loss: 12.7795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1120

Learning rate: 0.00019999901891357876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 12.7622	Cost: 22.39s
Train Epoch: 142 [20480/90000 (23%)]	Loss: 12.6715	Cost: 6.20s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 12.7267	Cost: 7.36s
Train Epoch: 142 [61440/90000 (68%)]	Loss: 12.6767	Cost: 9.35s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 12.8191	Cost: 12.16s
Train Epoch: 142 	Average Loss: 12.7518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1412

Learning rate: 0.0001999990049481345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 12.8346	Cost: 27.33s
Train Epoch: 143 [20480/90000 (23%)]	Loss: 12.8257	Cost: 12.07s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 12.7507	Cost: 12.10s
Train Epoch: 143 [61440/90000 (68%)]	Loss: 12.8449	Cost: 11.91s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 12.8436	Cost: 9.87s
Train Epoch: 143 	Average Loss: 12.7799
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1266

Learning rate: 0.00019999899088399522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 12.9163	Cost: 29.25s
Train Epoch: 144 [20480/90000 (23%)]	Loss: 12.9008	Cost: 11.77s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 12.6055	Cost: 11.92s
Train Epoch: 144 [61440/90000 (68%)]	Loss: 12.6472	Cost: 10.43s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 12.9290	Cost: 5.83s
Train Epoch: 144 	Average Loss: 12.7433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1205

Learning rate: 0.0001999989767211609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 12.7245	Cost: 26.10s
Train Epoch: 145 [20480/90000 (23%)]	Loss: 12.8224	Cost: 11.98s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 12.7322	Cost: 6.95s
Train Epoch: 145 [61440/90000 (68%)]	Loss: 12.7986	Cost: 5.84s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 12.8627	Cost: 6.77s
Train Epoch: 145 	Average Loss: 12.7396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0821

Saving model as e145_model.pt & e145_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999896245963153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 12.6653	Cost: 30.18s
Train Epoch: 146 [20480/90000 (23%)]	Loss: 12.9846	Cost: 11.58s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 12.7366	Cost: 11.14s
Train Epoch: 146 [61440/90000 (68%)]	Loss: 12.8057	Cost: 5.82s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 12.6931	Cost: 6.57s
Train Epoch: 146 	Average Loss: 12.7250
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0573

Saving model as e146_model.pt & e146_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999894809940715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 12.7010	Cost: 25.40s
Train Epoch: 147 [20480/90000 (23%)]	Loss: 12.8457	Cost: 11.22s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 12.6125	Cost: 12.15s
Train Epoch: 147 [61440/90000 (68%)]	Loss: 12.7424	Cost: 11.80s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 12.6664	Cost: 11.82s
Train Epoch: 147 	Average Loss: 12.6704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0718

Learning rate: 0.00019999893364048776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 12.6688	Cost: 29.31s
Train Epoch: 148 [20480/90000 (23%)]	Loss: 12.7054	Cost: 11.61s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 12.7453	Cost: 12.06s
Train Epoch: 148 [61440/90000 (68%)]	Loss: 12.7486	Cost: 11.79s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 12.8136	Cost: 6.23s
Train Epoch: 148 	Average Loss: 12.6733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0090

Saving model as e148_model.pt & e148_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999891908287334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 12.6996	Cost: 23.84s
Train Epoch: 149 [20480/90000 (23%)]	Loss: 12.7499	Cost: 6.26s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 12.7830	Cost: 12.24s
Train Epoch: 149 [61440/90000 (68%)]	Loss: 12.6179	Cost: 11.92s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 12.6423	Cost: 11.83s
Train Epoch: 149 	Average Loss: 12.6750
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9769

Saving model as e149_model.pt & e149_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999890442656397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 12.4762	Cost: 22.10s
Train Epoch: 150 [20480/90000 (23%)]	Loss: 12.7070	Cost: 6.22s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 12.6154	Cost: 10.96s
Train Epoch: 150 [61440/90000 (68%)]	Loss: 12.5873	Cost: 12.11s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 12.6983	Cost: 12.29s
Train Epoch: 150 	Average Loss: 12.6483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9580

Saving model as e150_model.pt & e150_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999888967155965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 12.6665	Cost: 22.65s
Train Epoch: 151 [20480/90000 (23%)]	Loss: 12.5410	Cost: 6.26s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 12.7407	Cost: 7.09s
Train Epoch: 151 [61440/90000 (68%)]	Loss: 12.6472	Cost: 6.29s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 12.6808	Cost: 16.59s
Train Epoch: 151 	Average Loss: 12.6166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0265

Learning rate: 0.00019999887481786036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 12.7496	Cost: 24.00s
Train Epoch: 152 [20480/90000 (23%)]	Loss: 12.6873	Cost: 11.14s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 12.5887	Cost: 12.17s
Train Epoch: 152 [61440/90000 (68%)]	Loss: 12.5565	Cost: 11.83s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 12.7462	Cost: 11.53s
Train Epoch: 152 	Average Loss: 12.6175
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9952

Learning rate: 0.00019999885986546616
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 12.6875	Cost: 33.87s
Train Epoch: 153 [20480/90000 (23%)]	Loss: 12.8000	Cost: 12.17s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 12.6123	Cost: 12.21s
Train Epoch: 153 [61440/90000 (68%)]	Loss: 12.6236	Cost: 8.33s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 12.6109	Cost: 6.08s
Train Epoch: 153 	Average Loss: 12.5907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9414

Saving model as e153_model.pt & e153_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999884481437704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 12.6638	Cost: 27.77s
Train Epoch: 154 [20480/90000 (23%)]	Loss: 12.6051	Cost: 11.97s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 12.6940	Cost: 12.10s
Train Epoch: 154 [61440/90000 (68%)]	Loss: 12.6313	Cost: 11.80s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 12.6217	Cost: 7.97s
Train Epoch: 154 	Average Loss: 12.5986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9874

Learning rate: 0.000199998829664593
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 12.4374	Cost: 27.11s
Train Epoch: 155 [20480/90000 (23%)]	Loss: 12.7290	Cost: 11.63s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 12.6762	Cost: 7.60s
Train Epoch: 155 [61440/90000 (68%)]	Loss: 12.6250	Cost: 5.87s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 12.5457	Cost: 6.75s
Train Epoch: 155 	Average Loss: 12.5769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8992

Saving model as e155_model.pt & e155_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999881441611406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 12.4587	Cost: 27.48s
Train Epoch: 156 [20480/90000 (23%)]	Loss: 12.6980	Cost: 11.84s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 12.6082	Cost: 12.18s
Train Epoch: 156 [61440/90000 (68%)]	Loss: 12.5405	Cost: 6.39s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 12.5467	Cost: 5.99s
Train Epoch: 156 	Average Loss: 12.5675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8816

Saving model as e156_model.pt & e156_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999879906894028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 12.6321	Cost: 27.78s
Train Epoch: 157 [20480/90000 (23%)]	Loss: 12.6796	Cost: 12.14s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 12.5940	Cost: 12.17s
Train Epoch: 157 [61440/90000 (68%)]	Loss: 12.5753	Cost: 11.84s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 12.4148	Cost: 11.90s
Train Epoch: 157 	Average Loss: 12.5172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8288

Saving model as e157_model.pt & e157_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999878362307163
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 12.5653	Cost: 24.45s
Train Epoch: 158 [20480/90000 (23%)]	Loss: 12.6554	Cost: 8.10s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 12.6016	Cost: 12.23s
Train Epoch: 158 [61440/90000 (68%)]	Loss: 12.6508	Cost: 12.13s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 12.5486	Cost: 12.08s
Train Epoch: 158 	Average Loss: 12.5027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9105

Learning rate: 0.0001999987680785081
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 12.4210	Cost: 29.82s
Train Epoch: 159 [20480/90000 (23%)]	Loss: 12.4875	Cost: 12.37s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 12.4743	Cost: 12.27s
Train Epoch: 159 [61440/90000 (68%)]	Loss: 12.5230	Cost: 11.83s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 12.6442	Cost: 11.80s
Train Epoch: 159 	Average Loss: 12.5255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9089

Learning rate: 0.00019999875243524977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 12.5069	Cost: 32.54s
Train Epoch: 160 [20480/90000 (23%)]	Loss: 12.6179	Cost: 11.19s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 12.6295	Cost: 12.39s
Train Epoch: 160 [61440/90000 (68%)]	Loss: 12.5237	Cost: 12.01s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 12.5866	Cost: 6.30s
Train Epoch: 160 	Average Loss: 12.4719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8746

Learning rate: 0.00019999873669329665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 12.4413	Cost: 29.22s
Train Epoch: 161 [20480/90000 (23%)]	Loss: 12.5251	Cost: 9.36s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 12.5509	Cost: 6.19s
Train Epoch: 161 [61440/90000 (68%)]	Loss: 12.3393	Cost: 5.98s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 12.5672	Cost: 6.80s
Train Epoch: 161 	Average Loss: 12.4708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8726

Learning rate: 0.0001999987208526487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 12.5553	Cost: 23.90s
Train Epoch: 162 [20480/90000 (23%)]	Loss: 12.6353	Cost: 6.30s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 12.5129	Cost: 7.04s
Train Epoch: 162 [61440/90000 (68%)]	Loss: 12.5695	Cost: 6.20s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 12.5909	Cost: 6.12s
Train Epoch: 162 	Average Loss: 12.4596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8254

Saving model as e162_model.pt & e162_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199998704913306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 12.6307	Cost: 27.23s
Train Epoch: 163 [20480/90000 (23%)]	Loss: 12.6364	Cost: 11.88s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 12.3723	Cost: 11.98s
Train Epoch: 163 [61440/90000 (68%)]	Loss: 12.4229	Cost: 6.80s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 12.5857	Cost: 5.92s
Train Epoch: 163 	Average Loss: 12.4500
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8473

Learning rate: 0.00019999868887526852
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 12.5694	Cost: 25.97s
Train Epoch: 164 [20480/90000 (23%)]	Loss: 12.3679	Cost: 8.11s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 12.5722	Cost: 6.06s
Train Epoch: 164 [61440/90000 (68%)]	Loss: 12.3235	Cost: 6.90s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 12.3158	Cost: 6.07s
Train Epoch: 164 	Average Loss: 12.4296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8816

Learning rate: 0.0001999986727385363
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 12.3933	Cost: 23.72s
Train Epoch: 165 [20480/90000 (23%)]	Loss: 12.6006	Cost: 6.03s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 12.5292	Cost: 7.20s
Train Epoch: 165 [61440/90000 (68%)]	Loss: 12.4561	Cost: 6.22s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 12.4381	Cost: 6.09s
Train Epoch: 165 	Average Loss: 12.4352
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7280

Saving model as e165_model.pt & e165_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999986565031093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 12.4181	Cost: 28.60s
Train Epoch: 166 [20480/90000 (23%)]	Loss: 12.4628	Cost: 12.20s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 12.6053	Cost: 7.11s
Train Epoch: 166 [61440/90000 (68%)]	Loss: 12.4195	Cost: 5.82s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 12.3796	Cost: 6.64s
Train Epoch: 166 	Average Loss: 12.3907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7851

Learning rate: 0.00019999864016898762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 12.3972	Cost: 24.07s
Train Epoch: 167 [20480/90000 (23%)]	Loss: 12.4409	Cost: 6.06s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 12.3516	Cost: 8.11s
Train Epoch: 167 [61440/90000 (68%)]	Loss: 12.5276	Cost: 6.17s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 12.4831	Cost: 6.04s
Train Epoch: 167 	Average Loss: 12.4014
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7517

Learning rate: 0.00019999862373617122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 12.3509	Cost: 22.34s
Train Epoch: 168 [20480/90000 (23%)]	Loss: 12.5121	Cost: 6.22s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 12.3659	Cost: 6.96s
Train Epoch: 168 [61440/90000 (68%)]	Loss: 12.4393	Cost: 6.21s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 12.4662	Cost: 14.69s
Train Epoch: 168 	Average Loss: 12.3876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6841

Saving model as e168_model.pt & e168_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999860720466015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 12.4088	Cost: 23.15s
Train Epoch: 169 [20480/90000 (23%)]	Loss: 12.4274	Cost: 6.36s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 12.4814	Cost: 6.45s
Train Epoch: 169 [61440/90000 (68%)]	Loss: 12.2970	Cost: 6.15s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 12.3448	Cost: 6.35s
Train Epoch: 169 	Average Loss: 12.3434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7250

Learning rate: 0.0001999985905744544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 12.3554	Cost: 25.31s
Train Epoch: 170 [20480/90000 (23%)]	Loss: 12.3934	Cost: 6.19s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 12.2648	Cost: 11.44s
Train Epoch: 170 [61440/90000 (68%)]	Loss: 12.3102	Cost: 12.30s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 12.4332	Cost: 11.96s
Train Epoch: 170 	Average Loss: 12.3554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6509

Saving model as e170_model.pt & e170_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199998573845554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 12.3730	Cost: 21.89s
Train Epoch: 171 [20480/90000 (23%)]	Loss: 12.2963	Cost: 6.22s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 12.3763	Cost: 7.33s
Train Epoch: 171 [61440/90000 (68%)]	Loss: 12.4497	Cost: 6.35s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 12.5710	Cost: 16.24s
Train Epoch: 171 	Average Loss: 12.3512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6844

Learning rate: 0.00019999855701795897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 12.4879	Cost: 26.01s
Train Epoch: 172 [20480/90000 (23%)]	Loss: 12.3938	Cost: 11.70s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 12.1534	Cost: 12.77s
Train Epoch: 172 [61440/90000 (68%)]	Loss: 12.2677	Cost: 12.25s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 12.2453	Cost: 12.15s
Train Epoch: 172 	Average Loss: 12.3186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6922

Learning rate: 0.00019999854009166934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 12.3594	Cost: 27.34s
Train Epoch: 173 [20480/90000 (23%)]	Loss: 12.4975	Cost: 11.77s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 12.2200	Cost: 11.98s
Train Epoch: 173 [61440/90000 (68%)]	Loss: 12.3049	Cost: 8.05s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 12.3168	Cost: 5.79s
Train Epoch: 173 	Average Loss: 12.2963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6585

Learning rate: 0.00019999852306668508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 12.5089	Cost: 26.79s
Train Epoch: 174 [20480/90000 (23%)]	Loss: 12.3352	Cost: 7.19s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 12.2198	Cost: 6.25s
Train Epoch: 174 [61440/90000 (68%)]	Loss: 12.2280	Cost: 7.01s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 12.2893	Cost: 6.09s
Train Epoch: 174 	Average Loss: 12.2812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7668

Learning rate: 0.00019999850594300622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 12.4403	Cost: 24.29s
Train Epoch: 175 [20480/90000 (23%)]	Loss: 12.2127	Cost: 7.05s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 12.2129	Cost: 6.46s
Train Epoch: 175 [61440/90000 (68%)]	Loss: 12.2633	Cost: 5.97s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 12.2340	Cost: 6.29s
Train Epoch: 175 	Average Loss: 12.2632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6219

Saving model as e175_model.pt & e175_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999848872063282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 12.2831	Cost: 26.51s
Train Epoch: 176 [20480/90000 (23%)]	Loss: 12.2681	Cost: 10.23s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 12.2634	Cost: 6.25s
Train Epoch: 176 [61440/90000 (68%)]	Loss: 12.4212	Cost: 6.42s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 12.2469	Cost: 6.33s
Train Epoch: 176 	Average Loss: 12.2724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6165

Saving model as e176_model.pt & e176_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999847139956484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 12.2078	Cost: 27.15s
Train Epoch: 177 [20480/90000 (23%)]	Loss: 12.4380	Cost: 12.06s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 12.2372	Cost: 12.15s
Train Epoch: 177 [61440/90000 (68%)]	Loss: 12.2748	Cost: 11.79s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 12.2572	Cost: 11.77s
Train Epoch: 177 	Average Loss: 12.2487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6002

Saving model as e177_model.pt & e177_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999845397980232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 12.4731	Cost: 21.98s
Train Epoch: 178 [20480/90000 (23%)]	Loss: 12.3189	Cost: 6.58s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 12.2271	Cost: 7.88s
Train Epoch: 178 [61440/90000 (68%)]	Loss: 12.3799	Cost: 8.61s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 12.3219	Cost: 13.46s
Train Epoch: 178 	Average Loss: 12.2656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5363

Saving model as e178_model.pt & e178_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999843646134532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 12.2063	Cost: 22.25s
Train Epoch: 179 [20480/90000 (23%)]	Loss: 12.3914	Cost: 6.30s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 12.1427	Cost: 6.57s
Train Epoch: 179 [61440/90000 (68%)]	Loss: 12.2777	Cost: 6.14s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 12.2602	Cost: 6.39s
Train Epoch: 179 	Average Loss: 12.2054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5967

Learning rate: 0.00019999841884419376
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 12.1444	Cost: 22.43s
Train Epoch: 180 [20480/90000 (23%)]	Loss: 12.3821	Cost: 6.71s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 12.1426	Cost: 12.43s
Train Epoch: 180 [61440/90000 (68%)]	Loss: 12.2251	Cost: 11.82s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 12.2493	Cost: 11.91s
Train Epoch: 180 	Average Loss: 12.2030
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6213

Learning rate: 0.00019999840112834775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 12.2377	Cost: 28.35s
Train Epoch: 181 [20480/90000 (23%)]	Loss: 12.2345	Cost: 12.13s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 12.1710	Cost: 12.17s
Train Epoch: 181 [61440/90000 (68%)]	Loss: 12.1300	Cost: 11.79s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 12.2435	Cost: 11.80s
Train Epoch: 181 	Average Loss: 12.1874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5324

Saving model as e181_model.pt & e181_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999838331380727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 12.1540	Cost: 28.66s
Train Epoch: 182 [20480/90000 (23%)]	Loss: 12.2532	Cost: 6.62s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 12.0863	Cost: 13.26s
Train Epoch: 182 [61440/90000 (68%)]	Loss: 12.1831	Cost: 12.24s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 12.1890	Cost: 11.94s
Train Epoch: 182 	Average Loss: 12.1644
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5324

Learning rate: 0.00019999836540057235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 12.3853	Cost: 27.95s
Train Epoch: 183 [20480/90000 (23%)]	Loss: 12.1604	Cost: 11.87s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 12.1749	Cost: 12.04s
Train Epoch: 183 [61440/90000 (68%)]	Loss: 12.0343	Cost: 11.78s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 12.1392	Cost: 8.60s
Train Epoch: 183 	Average Loss: 12.1532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5046

Saving model as e183_model.pt & e183_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199998347388643
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 12.3429	Cost: 25.13s
Train Epoch: 184 [20480/90000 (23%)]	Loss: 12.1286	Cost: 9.08s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 12.1185	Cost: 12.29s
Train Epoch: 184 [61440/90000 (68%)]	Loss: 12.1386	Cost: 12.38s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 12.2497	Cost: 12.09s
Train Epoch: 184 	Average Loss: 12.1568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5296

Learning rate: 0.00019999832927801924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 12.3621	Cost: 32.00s
Train Epoch: 185 [20480/90000 (23%)]	Loss: 11.9638	Cost: 10.56s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 11.9802	Cost: 12.12s
Train Epoch: 185 [61440/90000 (68%)]	Loss: 12.1498	Cost: 11.85s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 12.0363	Cost: 6.24s
Train Epoch: 185 	Average Loss: 12.1051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4542

Saving model as e185_model.pt & e185_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999831106870108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 12.3067	Cost: 24.07s
Train Epoch: 186 [20480/90000 (23%)]	Loss: 12.2430	Cost: 7.02s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 12.1403	Cost: 12.39s
Train Epoch: 186 [61440/90000 (68%)]	Loss: 12.2446	Cost: 12.07s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 12.2391	Cost: 11.84s
Train Epoch: 186 	Average Loss: 12.1348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5262

Learning rate: 0.00019999829276068855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 12.2295	Cost: 50.06s
Train Epoch: 187 [20480/90000 (23%)]	Loss: 12.1251	Cost: 10.12s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 12.0856	Cost: 12.14s
Train Epoch: 187 [61440/90000 (68%)]	Loss: 12.0832	Cost: 11.85s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 12.2248	Cost: 6.88s
Train Epoch: 187 	Average Loss: 12.1202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5334

Learning rate: 0.00019999827435398168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 12.1791	Cost: 28.67s
Train Epoch: 188 [20480/90000 (23%)]	Loss: 12.1441	Cost: 11.88s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 12.1092	Cost: 11.68s
Train Epoch: 188 [61440/90000 (68%)]	Loss: 12.0995	Cost: 5.79s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 12.0717	Cost: 6.27s
Train Epoch: 188 	Average Loss: 12.1055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5240

Learning rate: 0.00019999825584858045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 12.0979	Cost: 38.24s
Train Epoch: 189 [20480/90000 (23%)]	Loss: 12.1121	Cost: 9.37s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 12.2825	Cost: 6.27s
Train Epoch: 189 [61440/90000 (68%)]	Loss: 12.0857	Cost: 6.22s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 12.0764	Cost: 7.86s
Train Epoch: 189 	Average Loss: 12.1081
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5154

Learning rate: 0.00019999823724448486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 12.1276	Cost: 23.56s
Train Epoch: 190 [20480/90000 (23%)]	Loss: 12.0270	Cost: 6.35s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 12.1605	Cost: 6.53s
Train Epoch: 190 [61440/90000 (68%)]	Loss: 12.1276	Cost: 6.54s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 12.1869	Cost: 8.64s
Train Epoch: 190 	Average Loss: 12.0744
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4157

Saving model as e190_model.pt & e190_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199998218541695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 12.0902	Cost: 26.64s
Train Epoch: 191 [20480/90000 (23%)]	Loss: 12.0305	Cost: 9.34s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 12.0409	Cost: 6.19s
Train Epoch: 191 [61440/90000 (68%)]	Loss: 12.0480	Cost: 6.65s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 12.0480	Cost: 5.98s
Train Epoch: 191 	Average Loss: 12.0680
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3937

Saving model as e191_model.pt & e191_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999819974021087
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 12.2645	Cost: 27.68s
Train Epoch: 192 [20480/90000 (23%)]	Loss: 12.1340	Cost: 11.89s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 11.9563	Cost: 12.13s
Train Epoch: 192 [61440/90000 (68%)]	Loss: 12.1204	Cost: 11.82s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 12.0793	Cost: 11.78s
Train Epoch: 192 	Average Loss: 12.0734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4251

Learning rate: 0.00019999818084003246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 12.1736	Cost: 26.93s
Train Epoch: 193 [20480/90000 (23%)]	Loss: 12.1062	Cost: 11.94s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 12.0381	Cost: 11.97s
Train Epoch: 193 [61440/90000 (68%)]	Loss: 12.0576	Cost: 11.78s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 12.0244	Cost: 7.38s
Train Epoch: 193 	Average Loss: 12.0462
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4780

Learning rate: 0.00019999816184115978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 12.2063	Cost: 26.59s
Train Epoch: 194 [20480/90000 (23%)]	Loss: 12.1906	Cost: 12.17s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 11.8913	Cost: 8.79s
Train Epoch: 194 [61440/90000 (68%)]	Loss: 12.0694	Cost: 5.82s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 11.9823	Cost: 6.91s
Train Epoch: 194 	Average Loss: 12.0242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4122

Learning rate: 0.00019999814274359288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 12.0290	Cost: 25.81s
Train Epoch: 195 [20480/90000 (23%)]	Loss: 11.9549	Cost: 6.45s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 12.0504	Cost: 6.55s
Train Epoch: 195 [61440/90000 (68%)]	Loss: 12.0440	Cost: 6.50s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 12.0863	Cost: 6.16s
Train Epoch: 195 	Average Loss: 12.0250
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3299

Saving model as e195_model.pt & e195_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999812354733177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 12.0100	Cost: 23.22s
Train Epoch: 196 [20480/90000 (23%)]	Loss: 12.1425	Cost: 6.37s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 11.9354	Cost: 6.32s
Train Epoch: 196 [61440/90000 (68%)]	Loss: 11.9919	Cost: 6.52s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 12.1124	Cost: 6.12s
Train Epoch: 196 	Average Loss: 12.0096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4037

Learning rate: 0.00019999810425237646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 12.0986	Cost: 24.11s
Train Epoch: 197 [20480/90000 (23%)]	Loss: 12.0656	Cost: 6.47s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 11.9816	Cost: 13.69s
Train Epoch: 197 [61440/90000 (68%)]	Loss: 12.0554	Cost: 11.95s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 11.8920	Cost: 11.88s
Train Epoch: 197 	Average Loss: 11.9806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4071

Learning rate: 0.00019999808485872698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 12.2306	Cost: 30.21s
Train Epoch: 198 [20480/90000 (23%)]	Loss: 11.9013	Cost: 11.26s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 11.8669	Cost: 12.06s
Train Epoch: 198 [61440/90000 (68%)]	Loss: 12.0448	Cost: 11.72s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 12.0219	Cost: 5.94s
Train Epoch: 198 	Average Loss: 11.9756
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3126

Saving model as e198_model.pt & e198_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999806536638337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 11.9960	Cost: 28.00s
Train Epoch: 199 [20480/90000 (23%)]	Loss: 12.0613	Cost: 11.87s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 11.9663	Cost: 12.16s
Train Epoch: 199 [61440/90000 (68%)]	Loss: 11.9811	Cost: 12.09s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 12.0259	Cost: 12.10s
Train Epoch: 199 	Average Loss: 11.9860
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3401

Learning rate: 0.00019999804577534562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 12.0653	Cost: 33.68s
Train Epoch: 200 [20480/90000 (23%)]	Loss: 12.0340	Cost: 12.06s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 11.9757	Cost: 12.19s
Train Epoch: 200 [61440/90000 (68%)]	Loss: 11.9379	Cost: 8.04s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 12.0212	Cost: 5.85s
Train Epoch: 200 	Average Loss: 11.9552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3134

Learning rate: 0.00019999802608561374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 11.8587	Cost: 28.89s
Train Epoch: 201 [20480/90000 (23%)]	Loss: 12.0047	Cost: 11.87s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 11.9883	Cost: 6.52s
Train Epoch: 201 [61440/90000 (68%)]	Loss: 12.0214	Cost: 6.04s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 11.7463	Cost: 7.06s
Train Epoch: 201 	Average Loss: 11.9376
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3405

Learning rate: 0.00019999800629718777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 12.0169	Cost: 36.80s
Train Epoch: 202 [20480/90000 (23%)]	Loss: 12.0293	Cost: 12.06s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 11.8858	Cost: 6.46s
Train Epoch: 202 [61440/90000 (68%)]	Loss: 11.8791	Cost: 5.96s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 11.9160	Cost: 6.73s
Train Epoch: 202 	Average Loss: 11.9264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3565

Learning rate: 0.00019999798641006774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 12.0327	Cost: 23.42s
Train Epoch: 203 [20480/90000 (23%)]	Loss: 12.0264	Cost: 6.34s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 11.9040	Cost: 7.46s
Train Epoch: 203 [61440/90000 (68%)]	Loss: 12.1158	Cost: 6.05s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 11.9795	Cost: 6.08s
Train Epoch: 203 	Average Loss: 11.9141
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3022

Saving model as e203_model.pt & e203_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999796642425366
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 12.1972	Cost: 29.87s
Train Epoch: 204 [20480/90000 (23%)]	Loss: 12.0687	Cost: 9.55s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 11.8648	Cost: 12.17s
Train Epoch: 204 [61440/90000 (68%)]	Loss: 11.9640	Cost: 11.82s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 11.9190	Cost: 7.43s
Train Epoch: 204 	Average Loss: 11.9211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2095

Saving model as e204_model.pt & e204_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999794633974552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 11.8996	Cost: 26.27s
Train Epoch: 205 [20480/90000 (23%)]	Loss: 12.0874	Cost: 10.23s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 11.9397	Cost: 12.23s
Train Epoch: 205 [61440/90000 (68%)]	Loss: 11.9383	Cost: 12.00s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 12.1943	Cost: 12.13s
Train Epoch: 205 	Average Loss: 11.9002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2706

Learning rate: 0.00019999792615654335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 11.8768	Cost: 31.69s
Train Epoch: 206 [20480/90000 (23%)]	Loss: 11.9649	Cost: 12.23s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 11.7472	Cost: 11.86s
Train Epoch: 206 [61440/90000 (68%)]	Loss: 11.9655	Cost: 5.90s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 11.8551	Cost: 5.86s
Train Epoch: 206 	Average Loss: 11.8630
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2906

Learning rate: 0.00019999790587464718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 11.7558	Cost: 26.14s
Train Epoch: 207 [20480/90000 (23%)]	Loss: 11.9092	Cost: 8.80s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 12.0264	Cost: 6.20s
Train Epoch: 207 [61440/90000 (68%)]	Loss: 11.8968	Cost: 7.00s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 11.9128	Cost: 6.44s
Train Epoch: 207 	Average Loss: 11.8679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3456

Learning rate: 0.00019999788549405706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 11.9249	Cost: 23.11s
Train Epoch: 208 [20480/90000 (23%)]	Loss: 12.0132	Cost: 6.32s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 11.8779	Cost: 6.46s
Train Epoch: 208 [61440/90000 (68%)]	Loss: 11.8708	Cost: 6.27s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 11.9483	Cost: 6.38s
Train Epoch: 208 	Average Loss: 11.8486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2969

Learning rate: 0.00019999786501477296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 11.8676	Cost: 23.66s
Train Epoch: 209 [20480/90000 (23%)]	Loss: 11.8225	Cost: 6.42s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 11.8506	Cost: 11.71s
Train Epoch: 209 [61440/90000 (68%)]	Loss: 11.7780	Cost: 11.90s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 11.9240	Cost: 11.90s
Train Epoch: 209 	Average Loss: 11.8582
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2617

Learning rate: 0.00019999784443679492
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 11.9098	Cost: 28.71s
Train Epoch: 210 [20480/90000 (23%)]	Loss: 11.8883	Cost: 12.38s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 11.8238	Cost: 12.06s
Train Epoch: 210 [61440/90000 (68%)]	Loss: 11.8863	Cost: 11.99s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 11.7910	Cost: 7.64s
Train Epoch: 210 	Average Loss: 11.8004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2424

Learning rate: 0.000199997823760123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 11.8576	Cost: 25.82s
Train Epoch: 211 [20480/90000 (23%)]	Loss: 11.7999	Cost: 6.06s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 11.7732	Cost: 7.43s
Train Epoch: 211 [61440/90000 (68%)]	Loss: 11.8723	Cost: 6.27s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 12.1326	Cost: 7.17s
Train Epoch: 211 	Average Loss: 11.8454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2742

Learning rate: 0.00019999780298475715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 11.8626	Cost: 28.77s
Train Epoch: 212 [20480/90000 (23%)]	Loss: 11.8906	Cost: 6.55s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 11.8199	Cost: 14.75s
Train Epoch: 212 [61440/90000 (68%)]	Loss: 11.9030	Cost: 12.19s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 11.8887	Cost: 11.95s
Train Epoch: 212 	Average Loss: 11.8517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2812

Learning rate: 0.00019999778211069746
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 11.7277	Cost: 26.70s
Train Epoch: 213 [20480/90000 (23%)]	Loss: 11.9358	Cost: 12.19s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 11.8377	Cost: 12.03s
Train Epoch: 213 [61440/90000 (68%)]	Loss: 11.8093	Cost: 11.80s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 11.9105	Cost: 6.81s
Train Epoch: 213 	Average Loss: 11.7875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1280

Saving model as e213_model.pt & e213_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999977611379439
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 11.8023	Cost: 27.36s
Train Epoch: 214 [20480/90000 (23%)]	Loss: 11.9176	Cost: 12.05s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 11.7461	Cost: 12.18s
Train Epoch: 214 [61440/90000 (68%)]	Loss: 11.7528	Cost: 12.17s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 11.8232	Cost: 10.32s
Train Epoch: 214 	Average Loss: 11.8111
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1628

Learning rate: 0.00019999774006649652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 11.9481	Cost: 27.58s
Train Epoch: 215 [20480/90000 (23%)]	Loss: 11.8240	Cost: 12.09s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 11.8841	Cost: 11.49s
Train Epoch: 215 [61440/90000 (68%)]	Loss: 11.9337	Cost: 6.09s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 11.8895	Cost: 6.05s
Train Epoch: 215 	Average Loss: 11.8051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2432

Learning rate: 0.00019999771889635528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 11.9047	Cost: 27.75s
Train Epoch: 216 [20480/90000 (23%)]	Loss: 11.8618	Cost: 11.38s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 11.7532	Cost: 6.12s
Train Epoch: 216 [61440/90000 (68%)]	Loss: 11.8640	Cost: 5.94s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 11.9934	Cost: 6.86s
Train Epoch: 216 	Average Loss: 11.7829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2089

Learning rate: 0.00019999769762752028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 12.0510	Cost: 24.36s
Train Epoch: 217 [20480/90000 (23%)]	Loss: 11.8203	Cost: 6.13s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 11.7725	Cost: 7.23s
Train Epoch: 217 [61440/90000 (68%)]	Loss: 11.8492	Cost: 7.01s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 11.7511	Cost: 8.82s
Train Epoch: 217 	Average Loss: 11.7521
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1415

Learning rate: 0.00019999767625999152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 11.8421	Cost: 23.23s
Train Epoch: 218 [20480/90000 (23%)]	Loss: 11.8533	Cost: 6.48s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 11.8063	Cost: 6.90s
Train Epoch: 218 [61440/90000 (68%)]	Loss: 11.9711	Cost: 6.80s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 11.7615	Cost: 15.87s
Train Epoch: 218 	Average Loss: 11.7658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1652

Learning rate: 0.00019999765479376897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 11.9705	Cost: 30.71s
Train Epoch: 219 [20480/90000 (23%)]	Loss: 11.9377	Cost: 11.80s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 11.7728	Cost: 12.07s
Train Epoch: 219 [61440/90000 (68%)]	Loss: 11.8466	Cost: 8.75s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 11.8773	Cost: 5.91s
Train Epoch: 219 	Average Loss: 11.7803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1494

Learning rate: 0.00019999763322885272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 11.8059	Cost: 26.61s
Train Epoch: 220 [20480/90000 (23%)]	Loss: 11.7446	Cost: 6.10s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 11.6531	Cost: 10.78s
Train Epoch: 220 [61440/90000 (68%)]	Loss: 11.7613	Cost: 6.66s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 11.6018	Cost: 8.79s
Train Epoch: 220 	Average Loss: 11.7052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1810

Learning rate: 0.00019999761156524275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 11.7765	Cost: 22.06s
Train Epoch: 221 [20480/90000 (23%)]	Loss: 11.9418	Cost: 6.26s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 11.6515	Cost: 6.64s
Train Epoch: 221 [61440/90000 (68%)]	Loss: 11.6922	Cost: 6.59s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 11.7216	Cost: 15.53s
Train Epoch: 221 	Average Loss: 11.7183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1721

Learning rate: 0.0001999975898029391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 11.9184	Cost: 31.16s
Train Epoch: 222 [20480/90000 (23%)]	Loss: 11.7537	Cost: 11.22s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 11.8206	Cost: 12.08s
Train Epoch: 222 [61440/90000 (68%)]	Loss: 11.7720	Cost: 11.75s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 11.6235	Cost: 6.11s
Train Epoch: 222 	Average Loss: 11.7320
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0670

Saving model as e222_model.pt & e222_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999756794194176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 11.7717	Cost: 28.44s
Train Epoch: 223 [20480/90000 (23%)]	Loss: 11.8192	Cost: 12.31s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 11.5769	Cost: 12.07s
Train Epoch: 223 [61440/90000 (68%)]	Loss: 11.7128	Cost: 11.86s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 11.7083	Cost: 9.85s
Train Epoch: 223 	Average Loss: 11.7066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0330

Saving model as e223_model.pt & e223_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999975459822508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 11.8607	Cost: 22.54s
Train Epoch: 224 [20480/90000 (23%)]	Loss: 11.7614	Cost: 6.20s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 11.7681	Cost: 14.89s
Train Epoch: 224 [61440/90000 (68%)]	Loss: 11.8769	Cost: 12.14s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 11.6859	Cost: 11.84s
Train Epoch: 224 	Average Loss: 11.6958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0912

Learning rate: 0.0001999975239238662
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 11.7691	Cost: 31.81s
Train Epoch: 225 [20480/90000 (23%)]	Loss: 11.7038	Cost: 11.47s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 11.7882	Cost: 13.28s
Train Epoch: 225 [61440/90000 (68%)]	Loss: 11.6452	Cost: 12.11s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 11.6454	Cost: 11.76s
Train Epoch: 225 	Average Loss: 11.6645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1181

Learning rate: 0.000199997501766788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 11.7595	Cost: 27.29s
Train Epoch: 226 [20480/90000 (23%)]	Loss: 11.8315	Cost: 8.81s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 11.7053	Cost: 6.36s
Train Epoch: 226 [61440/90000 (68%)]	Loss: 11.7267	Cost: 6.10s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 11.7965	Cost: 7.84s
Train Epoch: 226 	Average Loss: 11.6435
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0956

Learning rate: 0.00019999747951101625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 11.8285	Cost: 23.65s
Train Epoch: 227 [20480/90000 (23%)]	Loss: 11.8315	Cost: 6.26s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 11.7101	Cost: 6.48s
Train Epoch: 227 [61440/90000 (68%)]	Loss: 11.6472	Cost: 6.26s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 11.7051	Cost: 5.97s
Train Epoch: 227 	Average Loss: 11.6815
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0209

Saving model as e227_model.pt & e227_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999974571565509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 11.6585	Cost: 23.01s
Train Epoch: 228 [20480/90000 (23%)]	Loss: 11.6792	Cost: 7.20s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 11.6521	Cost: 6.44s
Train Epoch: 228 [61440/90000 (68%)]	Loss: 11.5668	Cost: 6.13s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 11.6378	Cost: 5.93s
Train Epoch: 228 	Average Loss: 11.6395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0551

Learning rate: 0.00019999743470339206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 12.0169	Cost: 28.45s
Train Epoch: 229 [20480/90000 (23%)]	Loss: 11.6960	Cost: 7.64s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 11.4434	Cost: 11.94s
Train Epoch: 229 [61440/90000 (68%)]	Loss: 11.5828	Cost: 11.81s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 11.5585	Cost: 12.05s
Train Epoch: 229 	Average Loss: 11.6294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0626

Learning rate: 0.0001999974121515397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 11.8496	Cost: 24.28s
Train Epoch: 230 [20480/90000 (23%)]	Loss: 11.8297	Cost: 11.32s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 11.5339	Cost: 12.16s
Train Epoch: 230 [61440/90000 (68%)]	Loss: 11.7137	Cost: 11.81s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 11.5771	Cost: 11.80s
Train Epoch: 230 	Average Loss: 11.6199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1008

Learning rate: 0.00019999738950099387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 11.6995	Cost: 28.08s
Train Epoch: 231 [20480/90000 (23%)]	Loss: 11.7203	Cost: 12.17s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 11.5754	Cost: 12.09s
Train Epoch: 231 [61440/90000 (68%)]	Loss: 11.6739	Cost: 11.80s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 11.6585	Cost: 8.03s
Train Epoch: 231 	Average Loss: 11.6295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0314

Learning rate: 0.00019999736675175452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 11.5473	Cost: 27.03s
Train Epoch: 232 [20480/90000 (23%)]	Loss: 11.8451	Cost: 11.92s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 11.5731	Cost: 12.34s
Train Epoch: 232 [61440/90000 (68%)]	Loss: 11.7380	Cost: 6.38s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 11.7304	Cost: 5.98s
Train Epoch: 232 	Average Loss: 11.6054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9135

Saving model as e232_model.pt & e232_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999734390382178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 11.8105	Cost: 24.95s
Train Epoch: 233 [20480/90000 (23%)]	Loss: 11.7927	Cost: 8.86s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 11.6204	Cost: 12.29s
Train Epoch: 233 [61440/90000 (68%)]	Loss: 11.6278	Cost: 11.93s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 11.8070	Cost: 11.83s
Train Epoch: 233 	Average Loss: 11.6111
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0028

Learning rate: 0.00019999732095719557
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 11.7557	Cost: 31.74s
Train Epoch: 234 [20480/90000 (23%)]	Loss: 11.6439	Cost: 11.24s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 11.5483	Cost: 12.18s
Train Epoch: 234 [61440/90000 (68%)]	Loss: 11.8325	Cost: 11.59s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 11.5117	Cost: 5.81s
Train Epoch: 234 	Average Loss: 11.5849
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9936

Learning rate: 0.00019999729791187596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 11.7102	Cost: 27.22s
Train Epoch: 235 [20480/90000 (23%)]	Loss: 11.5828	Cost: 12.12s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 11.4709	Cost: 7.55s
Train Epoch: 235 [61440/90000 (68%)]	Loss: 11.6231	Cost: 5.82s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 11.7253	Cost: 6.66s
Train Epoch: 235 	Average Loss: 11.6031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0509

Learning rate: 0.000199997274767863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 11.7000	Cost: 23.34s
Train Epoch: 236 [20480/90000 (23%)]	Loss: 11.7874	Cost: 7.25s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 11.6315	Cost: 6.47s
Train Epoch: 236 [61440/90000 (68%)]	Loss: 11.6081	Cost: 6.20s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 11.6640	Cost: 5.93s
Train Epoch: 236 	Average Loss: 11.5961
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0369

Learning rate: 0.0001999972515251567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 11.6253	Cost: 24.91s
Train Epoch: 237 [20480/90000 (23%)]	Loss: 11.5185	Cost: 6.13s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 11.6007	Cost: 7.58s
Train Epoch: 237 [61440/90000 (68%)]	Loss: 11.5878	Cost: 6.19s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 11.7268	Cost: 16.88s
Train Epoch: 237 	Average Loss: 11.5603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9125

Saving model as e237_model.pt & e237_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999722818375706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 11.7010	Cost: 23.81s
Train Epoch: 238 [20480/90000 (23%)]	Loss: 11.6917	Cost: 6.09s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 11.5954	Cost: 7.36s
Train Epoch: 238 [61440/90000 (68%)]	Loss: 11.5908	Cost: 10.09s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 11.6343	Cost: 12.16s
Train Epoch: 238 	Average Loss: 11.5756
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0002

Learning rate: 0.00019999720474366407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 11.8262	Cost: 26.36s
Train Epoch: 239 [20480/90000 (23%)]	Loss: 11.5671	Cost: 12.20s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 11.3526	Cost: 12.13s
Train Epoch: 239 [61440/90000 (68%)]	Loss: 11.3888	Cost: 11.88s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 11.5398	Cost: 11.95s
Train Epoch: 239 	Average Loss: 11.5517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9454

Learning rate: 0.00019999718120487783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 11.4486	Cost: 30.57s
Train Epoch: 240 [20480/90000 (23%)]	Loss: 11.4491	Cost: 12.04s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 11.5152	Cost: 12.23s
Train Epoch: 240 [61440/90000 (68%)]	Loss: 11.6386	Cost: 8.83s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 11.5515	Cost: 6.09s
Train Epoch: 240 	Average Loss: 11.5242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9470

Learning rate: 0.00019999715756739835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 11.6036	Cost: 30.39s
Train Epoch: 241 [20480/90000 (23%)]	Loss: 11.5307	Cost: 11.08s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 11.4274	Cost: 8.20s
Train Epoch: 241 [61440/90000 (68%)]	Loss: 11.5654	Cost: 5.93s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 11.5446	Cost: 6.78s
Train Epoch: 241 	Average Loss: 11.5187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9736

Learning rate: 0.00019999713383122558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 11.7508	Cost: 24.54s
Train Epoch: 242 [20480/90000 (23%)]	Loss: 11.6152	Cost: 6.10s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 11.3459	Cost: 10.70s
Train Epoch: 242 [61440/90000 (68%)]	Loss: 11.5957	Cost: 6.44s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 11.6086	Cost: 9.03s
Train Epoch: 242 	Average Loss: 11.5211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9949

Learning rate: 0.0001999971099963596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 11.7179	Cost: 22.92s
Train Epoch: 243 [20480/90000 (23%)]	Loss: 11.5069	Cost: 6.28s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 11.5139	Cost: 12.75s
Train Epoch: 243 [61440/90000 (68%)]	Loss: 11.6026	Cost: 12.07s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 11.4426	Cost: 11.91s
Train Epoch: 243 	Average Loss: 11.5250
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8851

Saving model as e243_model.pt & e243_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999708606280046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 11.5498	Cost: 25.68s
Train Epoch: 244 [20480/90000 (23%)]	Loss: 11.5761	Cost: 8.10s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 11.3396	Cost: 13.18s
Train Epoch: 244 [61440/90000 (68%)]	Loss: 11.6099	Cost: 12.35s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 11.6727	Cost: 12.18s
Train Epoch: 244 	Average Loss: 11.4936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9380

Learning rate: 0.00019999706203054814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 11.5373	Cost: 28.65s
Train Epoch: 245 [20480/90000 (23%)]	Loss: 11.6245	Cost: 11.32s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 11.5682	Cost: 12.20s
Train Epoch: 245 [61440/90000 (68%)]	Loss: 11.4173	Cost: 11.58s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 11.4342	Cost: 5.92s
Train Epoch: 245 	Average Loss: 11.4904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9315

Learning rate: 0.00019999703789960266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 11.6475	Cost: 34.44s
Train Epoch: 246 [20480/90000 (23%)]	Loss: 11.5746	Cost: 10.57s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 11.5924	Cost: 6.14s
Train Epoch: 246 [61440/90000 (68%)]	Loss: 11.4400	Cost: 6.11s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 11.5192	Cost: 6.66s
Train Epoch: 246 	Average Loss: 11.4970
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9161

Learning rate: 0.00019999701366996408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 11.7829	Cost: 24.70s
Train Epoch: 247 [20480/90000 (23%)]	Loss: 11.5398	Cost: 6.31s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 11.2863	Cost: 7.07s
Train Epoch: 247 [61440/90000 (68%)]	Loss: 11.5430	Cost: 6.14s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 11.3836	Cost: 6.06s
Train Epoch: 247 	Average Loss: 11.4771
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8809

Saving model as e247_model.pt & e247_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999969893416324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 11.7524	Cost: 36.07s
Train Epoch: 248 [20480/90000 (23%)]	Loss: 11.5134	Cost: 11.94s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 11.3738	Cost: 7.02s
Train Epoch: 248 [61440/90000 (68%)]	Loss: 11.5028	Cost: 5.95s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 11.4819	Cost: 6.79s
Train Epoch: 248 	Average Loss: 11.4704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9301

Learning rate: 0.00019999696491460766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 11.5726	Cost: 28.24s
Train Epoch: 249 [20480/90000 (23%)]	Loss: 11.4603	Cost: 11.57s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 11.4016	Cost: 7.57s
Train Epoch: 249 [61440/90000 (68%)]	Loss: 11.4770	Cost: 5.84s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 11.5792	Cost: 6.63s
Train Epoch: 249 	Average Loss: 11.4533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8900

Learning rate: 0.00019999694038888986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 11.5751	Cost: 26.81s
Train Epoch: 250 [20480/90000 (23%)]	Loss: 11.5765	Cost: 8.83s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 11.4006	Cost: 6.22s
Train Epoch: 250 [61440/90000 (68%)]	Loss: 11.5255	Cost: 6.89s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 11.4108	Cost: 6.04s
Train Epoch: 250 	Average Loss: 11.4548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8973

Learning rate: 0.00019999691576447903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 11.3770	Cost: 24.14s
Train Epoch: 251 [20480/90000 (23%)]	Loss: 11.6098	Cost: 6.07s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 11.4561	Cost: 8.21s
Train Epoch: 251 [61440/90000 (68%)]	Loss: 11.3905	Cost: 6.14s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 11.4293	Cost: 6.13s
Train Epoch: 251 	Average Loss: 11.4160
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8149

Saving model as e251_model.pt & e251_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999968910413752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 11.6503	Cost: 28.36s
Train Epoch: 252 [20480/90000 (23%)]	Loss: 11.4903	Cost: 12.43s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 11.5818	Cost: 11.01s
Train Epoch: 252 [61440/90000 (68%)]	Loss: 11.3748	Cost: 5.81s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 11.4495	Cost: 6.20s
Train Epoch: 252 	Average Loss: 11.4204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8694

Learning rate: 0.0001999968662195784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 11.4546	Cost: 31.60s
Train Epoch: 253 [20480/90000 (23%)]	Loss: 11.5141	Cost: 8.52s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 11.4249	Cost: 6.86s
Train Epoch: 253 [61440/90000 (68%)]	Loss: 11.4010	Cost: 6.18s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 11.4199	Cost: 11.06s
Train Epoch: 253 	Average Loss: 11.4176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8879

Learning rate: 0.00019999684129908864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 11.5575	Cost: 23.34s
Train Epoch: 254 [20480/90000 (23%)]	Loss: 11.5549	Cost: 6.24s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 11.4282	Cost: 6.49s
Train Epoch: 254 [61440/90000 (68%)]	Loss: 11.3213	Cost: 6.16s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 11.2884	Cost: 5.94s
Train Epoch: 254 	Average Loss: 11.4244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8429

Learning rate: 0.00019999681627990595
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 11.5772	Cost: 22.80s
Train Epoch: 255 [20480/90000 (23%)]	Loss: 11.5469	Cost: 6.80s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 11.3457	Cost: 7.99s
Train Epoch: 255 [61440/90000 (68%)]	Loss: 11.6466	Cost: 10.08s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 11.4911	Cost: 12.05s
Train Epoch: 255 	Average Loss: 11.4422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8345

Learning rate: 0.00019999679116203034
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 11.5095	Cost: 28.22s
Train Epoch: 256 [20480/90000 (23%)]	Loss: 11.5243	Cost: 12.35s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 11.5169	Cost: 12.15s
Train Epoch: 256 [61440/90000 (68%)]	Loss: 11.4230	Cost: 11.87s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 11.3915	Cost: 10.60s
Train Epoch: 256 	Average Loss: 11.4095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7981

Saving model as e256_model.pt & e256_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999967659454619
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 11.4427	Cost: 32.70s
Train Epoch: 257 [20480/90000 (23%)]	Loss: 11.3189	Cost: 13.02s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 11.3257	Cost: 13.56s
Train Epoch: 257 [61440/90000 (68%)]	Loss: 11.5027	Cost: 11.95s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 11.4558	Cost: 11.95s
Train Epoch: 257 	Average Loss: 11.4060
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8292

Learning rate: 0.00019999674063020056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 11.4361	Cost: 31.43s
Train Epoch: 258 [20480/90000 (23%)]	Loss: 11.4025	Cost: 12.19s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 11.3325	Cost: 11.72s
Train Epoch: 258 [61440/90000 (68%)]	Loss: 11.2971	Cost: 9.18s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 11.2940	Cost: 5.87s
Train Epoch: 258 	Average Loss: 11.3615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7812

Saving model as e258_model.pt & e258_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999671521624642
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 11.4724	Cost: 26.75s
Train Epoch: 259 [20480/90000 (23%)]	Loss: 11.3749	Cost: 10.87s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 11.2531	Cost: 12.03s
Train Epoch: 259 [61440/90000 (68%)]	Loss: 11.3993	Cost: 11.83s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 11.2835	Cost: 11.80s
Train Epoch: 259 	Average Loss: 11.3463
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7172

Saving model as e259_model.pt & e259_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999966897035995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 11.4311	Cost: 22.55s
Train Epoch: 260 [20480/90000 (23%)]	Loss: 11.3739	Cost: 6.20s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 11.2394	Cost: 8.02s
Train Epoch: 260 [61440/90000 (68%)]	Loss: 11.1781	Cost: 7.92s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 11.4154	Cost: 13.85s
Train Epoch: 260 	Average Loss: 11.3350
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8744

Learning rate: 0.00019999666409225978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 11.4498	Cost: 31.39s
Train Epoch: 261 [20480/90000 (23%)]	Loss: 11.4043	Cost: 12.91s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 11.2720	Cost: 12.58s
Train Epoch: 261 [61440/90000 (68%)]	Loss: 11.4477	Cost: 12.13s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 11.3922	Cost: 11.83s
Train Epoch: 261 	Average Loss: 11.3489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7495

Learning rate: 0.00019999663838222732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 11.3245	Cost: 28.20s
Train Epoch: 262 [20480/90000 (23%)]	Loss: 11.4064	Cost: 12.17s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 11.2917	Cost: 8.87s
Train Epoch: 262 [61440/90000 (68%)]	Loss: 11.3775	Cost: 6.10s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 11.3267	Cost: 6.83s
Train Epoch: 262 	Average Loss: 11.3730
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8220

Learning rate: 0.00019999661257350212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 11.3447	Cost: 25.02s
Train Epoch: 263 [20480/90000 (23%)]	Loss: 11.4624	Cost: 6.95s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 11.2562	Cost: 6.48s
Train Epoch: 263 [61440/90000 (68%)]	Loss: 11.2435	Cost: 6.35s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 11.1943	Cost: 7.19s
Train Epoch: 263 	Average Loss: 11.3212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7317

Learning rate: 0.00019999658666608423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 11.5546	Cost: 23.15s
Train Epoch: 264 [20480/90000 (23%)]	Loss: 11.3602	Cost: 6.42s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 11.1821	Cost: 8.28s
Train Epoch: 264 [61440/90000 (68%)]	Loss: 11.3583	Cost: 11.14s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 11.2606	Cost: 12.10s
Train Epoch: 264 	Average Loss: 11.3018
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8162

Learning rate: 0.00019999656065997363
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 11.3460	Cost: 27.85s
Train Epoch: 265 [20480/90000 (23%)]	Loss: 11.5560	Cost: 11.19s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 11.3632	Cost: 12.24s
Train Epoch: 265 [61440/90000 (68%)]	Loss: 11.4299	Cost: 11.88s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 11.3925	Cost: 11.78s
Train Epoch: 265 	Average Loss: 11.3332
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7317

Learning rate: 0.00019999653455517042
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 11.3987	Cost: 39.35s
Train Epoch: 266 [20480/90000 (23%)]	Loss: 11.2848	Cost: 11.23s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 11.3615	Cost: 12.39s
Train Epoch: 266 [61440/90000 (68%)]	Loss: 11.4571	Cost: 11.97s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 11.3432	Cost: 8.06s
Train Epoch: 266 	Average Loss: 11.2988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7111

Saving model as e266_model.pt & e266_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999650835167456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 11.4778	Cost: 22.91s
Train Epoch: 267 [20480/90000 (23%)]	Loss: 11.2716	Cost: 6.43s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 11.3951	Cost: 12.79s
Train Epoch: 267 [61440/90000 (68%)]	Loss: 11.3421	Cost: 12.09s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 11.3524	Cost: 11.85s
Train Epoch: 267 	Average Loss: 11.3182
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7819

Learning rate: 0.00019999648204948613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 11.2114	Cost: 26.83s
Train Epoch: 268 [20480/90000 (23%)]	Loss: 11.3450	Cost: 11.88s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 11.2668	Cost: 12.12s
Train Epoch: 268 [61440/90000 (68%)]	Loss: 11.3638	Cost: 11.78s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 11.3529	Cost: 11.14s
Train Epoch: 268 	Average Loss: 11.2843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6632

Saving model as e268_model.pt & e268_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999964556486051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 11.3514	Cost: 25.48s
Train Epoch: 269 [20480/90000 (23%)]	Loss: 11.3852	Cost: 10.08s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 11.2142	Cost: 12.18s
Train Epoch: 269 [61440/90000 (68%)]	Loss: 11.3219	Cost: 11.86s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 11.4797	Cost: 11.87s
Train Epoch: 269 	Average Loss: 11.2849
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7605

Learning rate: 0.00019999642914903155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 11.3804	Cost: 29.14s
Train Epoch: 270 [20480/90000 (23%)]	Loss: 11.3403	Cost: 12.36s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 11.3205	Cost: 12.24s
Train Epoch: 270 [61440/90000 (68%)]	Loss: 11.5027	Cost: 8.65s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 11.2472	Cost: 5.81s
Train Epoch: 270 	Average Loss: 11.2777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6673

Learning rate: 0.00019999640255076545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 11.0701	Cost: 27.67s
Train Epoch: 271 [20480/90000 (23%)]	Loss: 11.3519	Cost: 12.07s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 11.3872	Cost: 7.16s
Train Epoch: 271 [61440/90000 (68%)]	Loss: 11.3036	Cost: 6.26s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 11.2991	Cost: 6.44s
Train Epoch: 271 	Average Loss: 11.2709
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7402

Learning rate: 0.0001999963758538069
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 11.4382	Cost: 33.40s
Train Epoch: 272 [20480/90000 (23%)]	Loss: 11.2786	Cost: 9.78s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 11.1929	Cost: 10.65s
Train Epoch: 272 [61440/90000 (68%)]	Loss: 11.2976	Cost: 5.85s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 11.3297	Cost: 6.75s
Train Epoch: 272 	Average Loss: 11.2804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6339

Saving model as e272_model.pt & e272_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999634905815583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 11.4781	Cost: 32.18s
Train Epoch: 273 [20480/90000 (23%)]	Loss: 11.4720	Cost: 12.11s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 11.2530	Cost: 11.95s
Train Epoch: 273 [61440/90000 (68%)]	Loss: 11.2456	Cost: 8.75s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 11.3339	Cost: 5.80s
Train Epoch: 273 	Average Loss: 11.2497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6024

Saving model as e273_model.pt & e273_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999632216381234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 11.3866	Cost: 27.43s
Train Epoch: 274 [20480/90000 (23%)]	Loss: 11.4848	Cost: 12.17s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 11.2345	Cost: 12.14s
Train Epoch: 274 [61440/90000 (68%)]	Loss: 11.2221	Cost: 11.80s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 11.2943	Cost: 10.97s
Train Epoch: 274 	Average Loss: 11.2371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7146

Learning rate: 0.00019999629517077644
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 11.1524	Cost: 29.12s
Train Epoch: 275 [20480/90000 (23%)]	Loss: 11.1550	Cost: 10.26s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 11.1924	Cost: 11.97s
Train Epoch: 275 [61440/90000 (68%)]	Loss: 11.2652	Cost: 11.69s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 11.3198	Cost: 6.77s
Train Epoch: 275 	Average Loss: 11.2288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7159

Learning rate: 0.00019999626807904816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 11.2784	Cost: 27.27s
Train Epoch: 276 [20480/90000 (23%)]	Loss: 11.2174	Cost: 10.86s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 11.0935	Cost: 6.10s
Train Epoch: 276 [61440/90000 (68%)]	Loss: 11.3874	Cost: 5.86s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 11.2159	Cost: 6.87s
Train Epoch: 276 	Average Loss: 11.2403
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8147

Learning rate: 0.0001999962408886275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 11.4559	Cost: 24.54s
Train Epoch: 277 [20480/90000 (23%)]	Loss: 11.3510	Cost: 6.47s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 11.1043	Cost: 6.49s
Train Epoch: 277 [61440/90000 (68%)]	Loss: 11.1980	Cost: 6.52s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 11.4061	Cost: 6.51s
Train Epoch: 277 	Average Loss: 11.2311
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6488

Learning rate: 0.00019999621359951451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 11.3617	Cost: 23.86s
Train Epoch: 278 [20480/90000 (23%)]	Loss: 11.2243	Cost: 6.38s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 11.2469	Cost: 13.41s
Train Epoch: 278 [61440/90000 (68%)]	Loss: 11.2850	Cost: 12.09s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 11.3355	Cost: 12.18s
Train Epoch: 278 	Average Loss: 11.2170
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6507

Learning rate: 0.00019999618621170925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 11.3658	Cost: 28.76s
Train Epoch: 279 [20480/90000 (23%)]	Loss: 11.4081	Cost: 12.27s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 11.1660	Cost: 11.85s
Train Epoch: 279 [61440/90000 (68%)]	Loss: 11.2518	Cost: 8.61s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 11.1566	Cost: 5.78s
Train Epoch: 279 	Average Loss: 11.1900
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6670

Learning rate: 0.00019999615872521166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 11.3802	Cost: 29.83s
Train Epoch: 280 [20480/90000 (23%)]	Loss: 11.2599	Cost: 6.08s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 11.2801	Cost: 11.85s
Train Epoch: 280 [61440/90000 (68%)]	Loss: 11.1634	Cost: 6.46s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 11.2423	Cost: 10.52s
Train Epoch: 280 	Average Loss: 11.2011
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5649

Saving model as e280_model.pt & e280_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999613114002183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 11.2996	Cost: 22.30s
Train Epoch: 281 [20480/90000 (23%)]	Loss: 11.2932	Cost: 6.26s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 11.1005	Cost: 6.44s
Train Epoch: 281 [61440/90000 (68%)]	Loss: 11.1480	Cost: 6.18s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 11.3514	Cost: 6.19s
Train Epoch: 281 	Average Loss: 11.1992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6576

Learning rate: 0.0001999961034561398
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 11.2747	Cost: 28.70s
Train Epoch: 282 [20480/90000 (23%)]	Loss: 11.2921	Cost: 13.26s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 11.2115	Cost: 13.94s
Train Epoch: 282 [61440/90000 (68%)]	Loss: 11.2137	Cost: 12.11s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 11.1747	Cost: 11.76s
Train Epoch: 282 	Average Loss: 11.1925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7369

Learning rate: 0.0001999960756735655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 11.2320	Cost: 27.69s
Train Epoch: 283 [20480/90000 (23%)]	Loss: 11.1666	Cost: 12.01s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 10.9068	Cost: 10.53s
Train Epoch: 283 [61440/90000 (68%)]	Loss: 11.1015	Cost: 6.06s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 11.2293	Cost: 6.31s
Train Epoch: 283 	Average Loss: 11.1753
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5573

Saving model as e283_model.pt & e283_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999960477922991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 11.1934	Cost: 26.26s
Train Epoch: 284 [20480/90000 (23%)]	Loss: 11.2849	Cost: 11.86s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 11.1517	Cost: 12.06s
Train Epoch: 284 [61440/90000 (68%)]	Loss: 11.2062	Cost: 11.88s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 11.1931	Cost: 8.24s
Train Epoch: 284 	Average Loss: 11.1566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5848

Learning rate: 0.00019999601981234054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 11.1808	Cost: 27.48s
Train Epoch: 285 [20480/90000 (23%)]	Loss: 11.3497	Cost: 10.85s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 11.2132	Cost: 6.13s
Train Epoch: 285 [61440/90000 (68%)]	Loss: 11.1954	Cost: 5.94s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 11.3381	Cost: 6.83s
Train Epoch: 285 	Average Loss: 11.1424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5692

Learning rate: 0.00019999599173368987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 11.1292	Cost: 25.56s
Train Epoch: 286 [20480/90000 (23%)]	Loss: 11.3845	Cost: 5.94s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 11.0618	Cost: 6.92s
Train Epoch: 286 [61440/90000 (68%)]	Loss: 11.1689	Cost: 6.19s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 11.2309	Cost: 6.12s
Train Epoch: 286 	Average Loss: 11.1386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6374

Learning rate: 0.00019999596355634708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 11.1734	Cost: 22.24s
Train Epoch: 287 [20480/90000 (23%)]	Loss: 11.2364	Cost: 6.36s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 11.0103	Cost: 6.33s
Train Epoch: 287 [61440/90000 (68%)]	Loss: 11.1089	Cost: 6.32s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 11.0956	Cost: 9.47s
Train Epoch: 287 	Average Loss: 11.1384
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5249

Saving model as e287_model.pt & e287_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999593528031228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 11.4144	Cost: 22.87s
Train Epoch: 288 [20480/90000 (23%)]	Loss: 11.3419	Cost: 7.08s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 11.0313	Cost: 6.54s
Train Epoch: 288 [61440/90000 (68%)]	Loss: 11.1300	Cost: 6.17s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 11.4184	Cost: 6.05s
Train Epoch: 288 	Average Loss: 11.1664
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6151

Learning rate: 0.0001999959069055854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 11.3471	Cost: 22.36s
Train Epoch: 289 [20480/90000 (23%)]	Loss: 11.2197	Cost: 6.28s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 11.0439	Cost: 8.02s
Train Epoch: 289 [61440/90000 (68%)]	Loss: 11.3331	Cost: 8.18s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 11.0657	Cost: 14.78s
Train Epoch: 289 	Average Loss: 11.1245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6186

Learning rate: 0.00019999587843216654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 11.1955	Cost: 27.45s
Train Epoch: 290 [20480/90000 (23%)]	Loss: 11.2389	Cost: 11.94s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 11.0988	Cost: 12.23s
Train Epoch: 290 [61440/90000 (68%)]	Loss: 11.1432	Cost: 11.79s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 11.1748	Cost: 11.79s
Train Epoch: 290 	Average Loss: 11.1217
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4796

Saving model as e290_model.pt & e290_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999584986005571
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 11.2926	Cost: 22.88s
Train Epoch: 291 [20480/90000 (23%)]	Loss: 11.3630	Cost: 6.14s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 11.1666	Cost: 11.22s
Train Epoch: 291 [61440/90000 (68%)]	Loss: 11.0592	Cost: 12.13s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 11.1996	Cost: 12.01s
Train Epoch: 291 	Average Loss: 11.1156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5649

Learning rate: 0.00019999582118925292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 11.2295	Cost: 31.65s
Train Epoch: 292 [20480/90000 (23%)]	Loss: 11.1321	Cost: 12.45s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 11.0577	Cost: 12.66s
Train Epoch: 292 [61440/90000 (68%)]	Loss: 11.1608	Cost: 12.17s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 11.0693	Cost: 11.93s
Train Epoch: 292 	Average Loss: 11.1103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4924

Learning rate: 0.00019999579241975824
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 11.0522	Cost: 28.51s
Train Epoch: 293 [20480/90000 (23%)]	Loss: 11.1886	Cost: 11.76s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 11.0241	Cost: 11.98s
Train Epoch: 293 [61440/90000 (68%)]	Loss: 11.2262	Cost: 11.25s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 10.9222	Cost: 6.05s
Train Epoch: 293 	Average Loss: 11.1071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5561

Learning rate: 0.00019999576355157165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 11.2605	Cost: 40.02s
Train Epoch: 294 [20480/90000 (23%)]	Loss: 11.1549	Cost: 11.96s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 11.1077	Cost: 7.87s
Train Epoch: 294 [61440/90000 (68%)]	Loss: 11.2237	Cost: 5.93s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 11.0742	Cost: 6.76s
Train Epoch: 294 	Average Loss: 11.1072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4417

Saving model as e294_model.pt & e294_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999957345846932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 11.2288	Cost: 28.36s
Train Epoch: 295 [20480/90000 (23%)]	Loss: 11.2823	Cost: 11.93s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 11.1301	Cost: 11.93s
Train Epoch: 295 [61440/90000 (68%)]	Loss: 11.0603	Cost: 6.23s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 11.1100	Cost: 6.16s
Train Epoch: 295 	Average Loss: 11.0831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5447

Learning rate: 0.0001999957055191229
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 11.1155	Cost: 27.69s
Train Epoch: 296 [20480/90000 (23%)]	Loss: 11.2063	Cost: 7.70s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 11.1549	Cost: 6.12s
Train Epoch: 296 [61440/90000 (68%)]	Loss: 11.1641	Cost: 6.90s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 11.1774	Cost: 6.01s
Train Epoch: 296 	Average Loss: 11.0941
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5199

Learning rate: 0.0001999956763548608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 11.2076	Cost: 23.63s
Train Epoch: 297 [20480/90000 (23%)]	Loss: 11.3674	Cost: 6.26s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 10.7529	Cost: 6.68s
Train Epoch: 297 [61440/90000 (68%)]	Loss: 11.0539	Cost: 6.18s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 11.1996	Cost: 6.08s
Train Epoch: 297 	Average Loss: 11.0963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5161

Learning rate: 0.00019999564709190693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 11.3682	Cost: 32.53s
Train Epoch: 298 [20480/90000 (23%)]	Loss: 11.1237	Cost: 10.05s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 10.9665	Cost: 12.39s
Train Epoch: 298 [61440/90000 (68%)]	Loss: 11.1407	Cost: 12.10s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 11.2086	Cost: 11.77s
Train Epoch: 298 	Average Loss: 11.0845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5173

Learning rate: 0.00019999561773026132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 11.3837	Cost: 33.00s
Train Epoch: 299 [20480/90000 (23%)]	Loss: 11.1372	Cost: 12.31s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 11.1181	Cost: 10.19s
Train Epoch: 299 [61440/90000 (68%)]	Loss: 11.0992	Cost: 6.18s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 11.1089	Cost: 7.99s
Train Epoch: 299 	Average Loss: 11.0302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4820

Learning rate: 0.00019999558826992397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 11.2454	Cost: 23.96s
Train Epoch: 300 [20480/90000 (23%)]	Loss: 11.1502	Cost: 6.28s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 11.0382	Cost: 7.19s
Train Epoch: 300 [61440/90000 (68%)]	Loss: 11.1865	Cost: 6.42s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 10.9756	Cost: 6.14s
Train Epoch: 300 	Average Loss: 11.0321
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5599

Learning rate: 0.00019999555871089494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 11.1897	Cost: 22.10s
Train Epoch: 301 [20480/90000 (23%)]	Loss: 10.9849	Cost: 6.33s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 10.8839	Cost: 6.51s
Train Epoch: 301 [61440/90000 (68%)]	Loss: 11.1437	Cost: 6.28s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 11.0325	Cost: 6.50s
Train Epoch: 301 	Average Loss: 11.0274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4119

Saving model as e301_model.pt & e301_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999552905317427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 11.2523	Cost: 23.64s
Train Epoch: 302 [20480/90000 (23%)]	Loss: 11.1021	Cost: 6.64s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 10.7207	Cost: 6.42s
Train Epoch: 302 [61440/90000 (68%)]	Loss: 11.0856	Cost: 6.42s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 11.1989	Cost: 6.56s
Train Epoch: 302 	Average Loss: 11.0338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5314

Learning rate: 0.00019999549929676196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 11.2196	Cost: 23.07s
Train Epoch: 303 [20480/90000 (23%)]	Loss: 11.1125	Cost: 6.49s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 10.9170	Cost: 12.55s
Train Epoch: 303 [61440/90000 (68%)]	Loss: 11.0782	Cost: 12.08s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 11.0341	Cost: 11.80s
Train Epoch: 303 	Average Loss: 11.0132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4680

Learning rate: 0.00019999546944165803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 11.1644	Cost: 28.19s
Train Epoch: 304 [20480/90000 (23%)]	Loss: 11.0628	Cost: 12.04s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 11.0131	Cost: 12.11s
Train Epoch: 304 [61440/90000 (68%)]	Loss: 11.0554	Cost: 11.80s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 10.9210	Cost: 11.80s
Train Epoch: 304 	Average Loss: 11.0188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5080

Learning rate: 0.00019999543948786254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 11.0346	Cost: 27.00s
Train Epoch: 305 [20480/90000 (23%)]	Loss: 11.0325	Cost: 10.83s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 10.9084	Cost: 12.04s
Train Epoch: 305 [61440/90000 (68%)]	Loss: 10.9017	Cost: 11.83s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 10.9301	Cost: 6.22s
Train Epoch: 305 	Average Loss: 10.9885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4468

Learning rate: 0.0001999954094353755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 11.2647	Cost: 26.73s
Train Epoch: 306 [20480/90000 (23%)]	Loss: 11.1653	Cost: 11.73s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 10.9839	Cost: 11.09s
Train Epoch: 306 [61440/90000 (68%)]	Loss: 11.0797	Cost: 5.82s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 11.1024	Cost: 6.51s
Train Epoch: 306 	Average Loss: 11.0315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6199

Learning rate: 0.00019999537928419694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 11.0973	Cost: 27.05s
Train Epoch: 307 [20480/90000 (23%)]	Loss: 10.9008	Cost: 10.73s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 11.0839	Cost: 6.05s
Train Epoch: 307 [61440/90000 (68%)]	Loss: 11.2357	Cost: 5.92s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 11.1185	Cost: 6.86s
Train Epoch: 307 	Average Loss: 11.0184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5263

Learning rate: 0.00019999534903432692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 11.2033	Cost: 25.10s
Train Epoch: 308 [20480/90000 (23%)]	Loss: 11.2718	Cost: 6.29s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 10.9420	Cost: 6.91s
Train Epoch: 308 [61440/90000 (68%)]	Loss: 11.1916	Cost: 7.02s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 10.9257	Cost: 6.13s
Train Epoch: 308 	Average Loss: 10.9865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4172

Learning rate: 0.00019999531868576542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 11.0462	Cost: 24.78s
Train Epoch: 309 [20480/90000 (23%)]	Loss: 11.1373	Cost: 6.44s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 10.9086	Cost: 6.56s
Train Epoch: 309 [61440/90000 (68%)]	Loss: 11.1244	Cost: 6.45s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 10.9769	Cost: 6.56s
Train Epoch: 309 	Average Loss: 11.0039
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3770

Saving model as e309_model.pt & e309_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999528823851252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 11.2862	Cost: 23.30s
Train Epoch: 310 [20480/90000 (23%)]	Loss: 10.9759	Cost: 7.04s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 10.7939	Cost: 6.45s
Train Epoch: 310 [61440/90000 (68%)]	Loss: 10.9139	Cost: 6.29s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 10.9375	Cost: 6.15s
Train Epoch: 310 	Average Loss: 10.9845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3689

Saving model as e310_model.pt & e310_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999525769256822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 11.0058	Cost: 27.85s
Train Epoch: 311 [20480/90000 (23%)]	Loss: 11.0019	Cost: 6.18s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 11.0501	Cost: 6.53s
Train Epoch: 311 [61440/90000 (68%)]	Loss: 11.0447	Cost: 6.24s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 10.9286	Cost: 7.02s
Train Epoch: 311 	Average Loss: 10.9505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4869

Learning rate: 0.00019999522704793255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 11.2374	Cost: 23.53s
Train Epoch: 312 [20480/90000 (23%)]	Loss: 11.0108	Cost: 6.34s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 10.7898	Cost: 12.90s
Train Epoch: 312 [61440/90000 (68%)]	Loss: 10.8907	Cost: 12.25s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 10.9095	Cost: 11.92s
Train Epoch: 312 	Average Loss: 10.9675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4555

Learning rate: 0.00019999519630460553
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 11.0913	Cost: 29.84s
Train Epoch: 313 [20480/90000 (23%)]	Loss: 11.0581	Cost: 12.22s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 11.0284	Cost: 12.16s
Train Epoch: 313 [61440/90000 (68%)]	Loss: 10.9766	Cost: 12.07s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 10.9041	Cost: 11.70s
Train Epoch: 313 	Average Loss: 10.9817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4101

Learning rate: 0.00019999516546258725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 10.9981	Cost: 33.89s
Train Epoch: 314 [20480/90000 (23%)]	Loss: 10.9101	Cost: 12.02s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 10.9265	Cost: 12.22s
Train Epoch: 314 [61440/90000 (68%)]	Loss: 11.0648	Cost: 11.81s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 10.9921	Cost: 7.40s
Train Epoch: 314 	Average Loss: 10.9427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4121

Learning rate: 0.00019999513452187764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 11.1407	Cost: 27.31s
Train Epoch: 315 [20480/90000 (23%)]	Loss: 11.0522	Cost: 12.22s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 10.7043	Cost: 10.94s
Train Epoch: 315 [61440/90000 (68%)]	Loss: 10.8868	Cost: 6.07s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 10.9965	Cost: 6.26s
Train Epoch: 315 	Average Loss: 10.9277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4157

Learning rate: 0.0001999951034824768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 10.9717	Cost: 24.05s
Train Epoch: 316 [20480/90000 (23%)]	Loss: 11.0417	Cost: 6.05s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 10.9734	Cost: 7.16s
Train Epoch: 316 [61440/90000 (68%)]	Loss: 10.9414	Cost: 6.32s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 10.8743	Cost: 6.14s
Train Epoch: 316 	Average Loss: 10.9433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4774

Learning rate: 0.00019999507234438478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 11.0752	Cost: 27.63s
Train Epoch: 317 [20480/90000 (23%)]	Loss: 11.0005	Cost: 7.37s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 11.0065	Cost: 11.53s
Train Epoch: 317 [61440/90000 (68%)]	Loss: 10.9264	Cost: 12.19s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 10.8914	Cost: 12.12s
Train Epoch: 317 	Average Loss: 10.9270
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3310

Saving model as e317_model.pt & e317_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999504110760157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 11.0545	Cost: 28.84s
Train Epoch: 318 [20480/90000 (23%)]	Loss: 10.9586	Cost: 6.52s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 10.9416	Cost: 8.58s
Train Epoch: 318 [61440/90000 (68%)]	Loss: 11.0526	Cost: 6.24s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 11.0309	Cost: 16.80s
Train Epoch: 318 	Average Loss: 10.9286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4360

Learning rate: 0.0001999950097721272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 11.0251	Cost: 25.00s
Train Epoch: 319 [20480/90000 (23%)]	Loss: 10.9907	Cost: 8.20s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 10.9730	Cost: 12.23s
Train Epoch: 319 [61440/90000 (68%)]	Loss: 10.7673	Cost: 11.95s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 10.9840	Cost: 11.79s
Train Epoch: 319 	Average Loss: 10.9092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3487

Learning rate: 0.00019999497833796175
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 11.0791	Cost: 26.83s
Train Epoch: 320 [20480/90000 (23%)]	Loss: 10.8992	Cost: 12.16s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 10.8841	Cost: 11.96s
Train Epoch: 320 [61440/90000 (68%)]	Loss: 10.8172	Cost: 11.58s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 10.9418	Cost: 5.82s
Train Epoch: 320 	Average Loss: 10.9067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3407

Learning rate: 0.00019999494680510515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 10.9999	Cost: 25.64s
Train Epoch: 321 [20480/90000 (23%)]	Loss: 11.1223	Cost: 11.92s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 10.7260	Cost: 9.37s
Train Epoch: 321 [61440/90000 (68%)]	Loss: 10.9566	Cost: 5.81s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 11.0957	Cost: 6.79s
Train Epoch: 321 	Average Loss: 10.9119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4202

Learning rate: 0.00019999491517355754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 10.8875	Cost: 26.53s
Train Epoch: 322 [20480/90000 (23%)]	Loss: 10.9564	Cost: 6.00s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 10.9114	Cost: 8.83s
Train Epoch: 322 [61440/90000 (68%)]	Loss: 10.9671	Cost: 6.29s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 10.9109	Cost: 6.69s
Train Epoch: 322 	Average Loss: 10.8917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3094

Saving model as e322_model.pt & e322_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999488344331888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 11.1761	Cost: 34.92s
Train Epoch: 323 [20480/90000 (23%)]	Loss: 10.9575	Cost: 12.43s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 10.7910	Cost: 12.09s
Train Epoch: 323 [61440/90000 (68%)]	Loss: 10.9782	Cost: 6.34s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 10.8947	Cost: 5.92s
Train Epoch: 323 	Average Loss: 10.8727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3130

Learning rate: 0.00019999485161438922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 10.8511	Cost: 28.29s
Train Epoch: 324 [20480/90000 (23%)]	Loss: 10.8222	Cost: 9.17s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 10.7194	Cost: 6.33s
Train Epoch: 324 [61440/90000 (68%)]	Loss: 10.8509	Cost: 6.90s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 10.8485	Cost: 6.48s
Train Epoch: 324 	Average Loss: 10.8948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3503

Learning rate: 0.0001999948196867686
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 10.9660	Cost: 28.14s
Train Epoch: 325 [20480/90000 (23%)]	Loss: 10.9520	Cost: 6.41s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 10.6967	Cost: 6.48s
Train Epoch: 325 [61440/90000 (68%)]	Loss: 10.9368	Cost: 6.34s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 10.8502	Cost: 8.79s
Train Epoch: 325 	Average Loss: 10.8722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3481

Learning rate: 0.00019999478766045706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 10.9692	Cost: 22.44s
Train Epoch: 326 [20480/90000 (23%)]	Loss: 10.9451	Cost: 6.29s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 10.8059	Cost: 8.02s
Train Epoch: 326 [61440/90000 (68%)]	Loss: 10.7316	Cost: 8.33s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 11.0426	Cost: 13.29s
Train Epoch: 326 	Average Loss: 10.8597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3061

Saving model as e326_model.pt & e326_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999475553545462
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 11.0709	Cost: 23.25s
Train Epoch: 327 [20480/90000 (23%)]	Loss: 10.9093	Cost: 6.31s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 10.8996	Cost: 7.03s
Train Epoch: 327 [61440/90000 (68%)]	Loss: 10.9381	Cost: 6.06s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 11.0544	Cost: 8.32s
Train Epoch: 327 	Average Loss: 10.8733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3405

Learning rate: 0.0001999947233117613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 10.9331	Cost: 32.15s
Train Epoch: 328 [20480/90000 (23%)]	Loss: 10.9806	Cost: 7.72s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 10.6784	Cost: 14.07s
Train Epoch: 328 [61440/90000 (68%)]	Loss: 10.7442	Cost: 12.18s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 10.9313	Cost: 12.06s
Train Epoch: 328 	Average Loss: 10.8282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3290

Learning rate: 0.00019999469098937715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 11.2058	Cost: 28.02s
Train Epoch: 329 [20480/90000 (23%)]	Loss: 10.8977	Cost: 12.18s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 10.9065	Cost: 12.16s
Train Epoch: 329 [61440/90000 (68%)]	Loss: 10.8932	Cost: 12.17s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 11.0780	Cost: 8.99s
Train Epoch: 329 	Average Loss: 10.8620
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3538

Learning rate: 0.00019999465856830218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 11.0991	Cost: 36.01s
Train Epoch: 330 [20480/90000 (23%)]	Loss: 10.9006	Cost: 12.26s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 10.9980	Cost: 11.82s
Train Epoch: 330 [61440/90000 (68%)]	Loss: 10.9485	Cost: 10.00s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 10.9107	Cost: 6.07s
Train Epoch: 330 	Average Loss: 10.8862
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3611

Learning rate: 0.00019999462604853647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 10.9774	Cost: 27.55s
Train Epoch: 331 [20480/90000 (23%)]	Loss: 10.9640	Cost: 10.46s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 10.8140	Cost: 8.92s
Train Epoch: 331 [61440/90000 (68%)]	Loss: 11.1000	Cost: 5.89s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 10.9194	Cost: 6.83s
Train Epoch: 331 	Average Loss: 10.8687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2291

Saving model as e331_model.pt & e331_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999459343008003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 10.9767	Cost: 28.97s
Train Epoch: 332 [20480/90000 (23%)]	Loss: 10.9755	Cost: 12.58s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 10.7529	Cost: 12.38s
Train Epoch: 332 [61440/90000 (68%)]	Loss: 10.8575	Cost: 8.42s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 10.8881	Cost: 6.17s
Train Epoch: 332 	Average Loss: 10.8003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3000

Learning rate: 0.00019999456071293284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 10.9861	Cost: 25.23s
Train Epoch: 333 [20480/90000 (23%)]	Loss: 10.9941	Cost: 6.24s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 10.7275	Cost: 8.17s
Train Epoch: 333 [61440/90000 (68%)]	Loss: 10.8693	Cost: 6.27s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 10.9899	Cost: 6.08s
Train Epoch: 333 	Average Loss: 10.8572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3279

Learning rate: 0.00019999452789709498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 10.8963	Cost: 24.11s
Train Epoch: 334 [20480/90000 (23%)]	Loss: 10.7428	Cost: 6.22s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 10.8354	Cost: 6.82s
Train Epoch: 334 [61440/90000 (68%)]	Loss: 10.7643	Cost: 6.13s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 10.9287	Cost: 8.22s
Train Epoch: 334 	Average Loss: 10.8027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3227

Learning rate: 0.0001999944949825665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 11.1707	Cost: 23.47s
Train Epoch: 335 [20480/90000 (23%)]	Loss: 10.9050	Cost: 6.73s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 10.5767	Cost: 9.41s
Train Epoch: 335 [61440/90000 (68%)]	Loss: 10.8334	Cost: 11.07s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 10.7715	Cost: 11.77s
Train Epoch: 335 	Average Loss: 10.7722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3373

Learning rate: 0.0001999944619693474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 10.9380	Cost: 26.39s
Train Epoch: 336 [20480/90000 (23%)]	Loss: 10.9724	Cost: 12.01s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 10.7396	Cost: 12.20s
Train Epoch: 336 [61440/90000 (68%)]	Loss: 10.7482	Cost: 11.96s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 10.8257	Cost: 11.91s
Train Epoch: 336 	Average Loss: 10.7904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2677

Learning rate: 0.00019999442885743776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 10.9798	Cost: 26.92s
Train Epoch: 337 [20480/90000 (23%)]	Loss: 10.7452	Cost: 12.05s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 10.7326	Cost: 12.12s
Train Epoch: 337 [61440/90000 (68%)]	Loss: 10.6969	Cost: 12.13s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 10.8980	Cost: 8.92s
Train Epoch: 337 	Average Loss: 10.7929
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2594

Learning rate: 0.00019999439564683753
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 10.7218	Cost: 38.39s
Train Epoch: 338 [20480/90000 (23%)]	Loss: 10.7663	Cost: 11.73s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 10.6123	Cost: 11.78s
Train Epoch: 338 [61440/90000 (68%)]	Loss: 10.6881	Cost: 6.01s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 10.8774	Cost: 5.98s
Train Epoch: 338 	Average Loss: 10.7827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2896

Learning rate: 0.0001999943623375468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 10.9915	Cost: 26.39s
Train Epoch: 339 [20480/90000 (23%)]	Loss: 10.7370	Cost: 9.40s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 10.7745	Cost: 6.16s
Train Epoch: 339 [61440/90000 (68%)]	Loss: 10.6841	Cost: 6.63s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 10.7614	Cost: 6.38s
Train Epoch: 339 	Average Loss: 10.7848
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2591

Learning rate: 0.0001999943289295656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 10.7852	Cost: 27.30s
Train Epoch: 340 [20480/90000 (23%)]	Loss: 10.7891	Cost: 6.28s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 10.7989	Cost: 7.59s
Train Epoch: 340 [61440/90000 (68%)]	Loss: 10.7847	Cost: 6.40s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 10.8998	Cost: 10.02s
Train Epoch: 340 	Average Loss: 10.7760
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2760

Learning rate: 0.00019999429542289394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 11.0565	Cost: 24.72s
Train Epoch: 341 [20480/90000 (23%)]	Loss: 10.8899	Cost: 6.70s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 10.7227	Cost: 16.43s
Train Epoch: 341 [61440/90000 (68%)]	Loss: 10.8715	Cost: 12.68s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 10.7132	Cost: 12.17s
Train Epoch: 341 	Average Loss: 10.7913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2401

Learning rate: 0.00019999426181753187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 10.8687	Cost: 33.78s
Train Epoch: 342 [20480/90000 (23%)]	Loss: 10.8214	Cost: 10.97s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 10.6131	Cost: 12.30s
Train Epoch: 342 [61440/90000 (68%)]	Loss: 10.8388	Cost: 12.00s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 10.8905	Cost: 6.37s
Train Epoch: 342 	Average Loss: 10.7470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2112

Saving model as e342_model.pt & e342_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999942281134794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 10.9702	Cost: 29.44s
Train Epoch: 343 [20480/90000 (23%)]	Loss: 10.9477	Cost: 12.26s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 10.5974	Cost: 12.24s
Train Epoch: 343 [61440/90000 (68%)]	Loss: 10.6362	Cost: 11.93s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 10.7966	Cost: 11.98s
Train Epoch: 343 	Average Loss: 10.7626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2287

Learning rate: 0.0001999941943107366
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 10.8870	Cost: 30.24s
Train Epoch: 344 [20480/90000 (23%)]	Loss: 10.8245	Cost: 13.06s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 10.5947	Cost: 12.76s
Train Epoch: 344 [61440/90000 (68%)]	Loss: 10.7100	Cost: 10.14s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 10.7749	Cost: 6.20s
Train Epoch: 344 	Average Loss: 10.7467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2204

Learning rate: 0.00019999416040930349
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 11.0756	Cost: 36.18s
Train Epoch: 345 [20480/90000 (23%)]	Loss: 10.8598	Cost: 11.82s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 10.6069	Cost: 12.12s
Train Epoch: 345 [61440/90000 (68%)]	Loss: 10.7603	Cost: 6.36s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 10.8828	Cost: 5.92s
Train Epoch: 345 	Average Loss: 10.7559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2671

Learning rate: 0.0001999941264091801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 10.8770	Cost: 30.37s
Train Epoch: 346 [20480/90000 (23%)]	Loss: 10.8791	Cost: 11.82s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 10.8161	Cost: 6.34s
Train Epoch: 346 [61440/90000 (68%)]	Loss: 10.6842	Cost: 5.95s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 10.9219	Cost: 7.08s
Train Epoch: 346 	Average Loss: 10.7561
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1823

Saving model as e346_model.pt & e346_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999409231036646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 10.9028	Cost: 27.69s
Train Epoch: 347 [20480/90000 (23%)]	Loss: 10.7645	Cost: 12.26s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 10.5450	Cost: 12.04s
Train Epoch: 347 [61440/90000 (68%)]	Loss: 10.7557	Cost: 11.85s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 10.7630	Cost: 10.56s
Train Epoch: 347 	Average Loss: 10.7103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1227

Saving model as e347_model.pt & e347_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999940581128626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 11.0818	Cost: 23.09s
Train Epoch: 348 [20480/90000 (23%)]	Loss: 10.8659	Cost: 6.46s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 10.5984	Cost: 13.53s
Train Epoch: 348 [61440/90000 (68%)]	Loss: 10.8728	Cost: 11.99s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 10.8349	Cost: 11.87s
Train Epoch: 348 	Average Loss: 10.7064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2661

Learning rate: 0.00019999402381666855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 10.7889	Cost: 23.79s
Train Epoch: 349 [20480/90000 (23%)]	Loss: 10.7435	Cost: 11.89s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 10.6405	Cost: 12.15s
Train Epoch: 349 [61440/90000 (68%)]	Loss: 10.7224	Cost: 11.85s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 10.7838	Cost: 11.86s
Train Epoch: 349 	Average Loss: 10.7048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2241

Learning rate: 0.0001999939894217844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 10.7295	Cost: 37.54s
Train Epoch: 350 [20480/90000 (23%)]	Loss: 10.7710	Cost: 13.48s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 10.7536	Cost: 12.20s
Train Epoch: 350 [61440/90000 (68%)]	Loss: 10.7022	Cost: 11.95s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 10.7269	Cost: 11.68s
Train Epoch: 350 	Average Loss: 10.7194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2158

Learning rate: 0.0001999939549282101
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 10.8148	Cost: 25.65s
Train Epoch: 351 [20480/90000 (23%)]	Loss: 10.8184	Cost: 12.09s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 10.8219	Cost: 12.00s
Train Epoch: 351 [61440/90000 (68%)]	Loss: 10.6506	Cost: 11.84s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 10.7668	Cost: 8.51s
Train Epoch: 351 	Average Loss: 10.6961
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1736

Learning rate: 0.00019999392033594573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 10.8310	Cost: 26.64s
Train Epoch: 352 [20480/90000 (23%)]	Loss: 10.6720	Cost: 12.01s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 10.6753	Cost: 11.99s
Train Epoch: 352 [61440/90000 (68%)]	Loss: 10.6797	Cost: 6.22s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 10.6542	Cost: 5.94s
Train Epoch: 352 	Average Loss: 10.6879
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1884

Learning rate: 0.0001999938856449913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 10.9464	Cost: 26.64s
Train Epoch: 353 [20480/90000 (23%)]	Loss: 10.7901	Cost: 10.68s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 10.6164	Cost: 6.29s
Train Epoch: 353 [61440/90000 (68%)]	Loss: 10.6419	Cost: 6.37s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 10.8124	Cost: 6.36s
Train Epoch: 353 	Average Loss: 10.7404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2014

Learning rate: 0.00019999385085534688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 10.6357	Cost: 25.53s
Train Epoch: 354 [20480/90000 (23%)]	Loss: 10.7119	Cost: 6.31s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 10.6639	Cost: 6.24s
Train Epoch: 354 [61440/90000 (68%)]	Loss: 10.7230	Cost: 7.10s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 10.6885	Cost: 6.18s
Train Epoch: 354 	Average Loss: 10.6818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1857

Learning rate: 0.00019999381596701247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 11.0267	Cost: 23.56s
Train Epoch: 355 [20480/90000 (23%)]	Loss: 10.7222	Cost: 6.16s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 10.5986	Cost: 6.80s
Train Epoch: 355 [61440/90000 (68%)]	Loss: 10.4956	Cost: 6.16s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 10.6275	Cost: 5.99s
Train Epoch: 355 	Average Loss: 10.6824
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2027

Learning rate: 0.00019999378097998813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 10.9219	Cost: 22.60s
Train Epoch: 356 [20480/90000 (23%)]	Loss: 10.8324	Cost: 6.74s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 10.6278	Cost: 12.32s
Train Epoch: 356 [61440/90000 (68%)]	Loss: 10.6714	Cost: 12.16s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 10.7882	Cost: 11.86s
Train Epoch: 356 	Average Loss: 10.6606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1386

Learning rate: 0.00019999374589427387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 10.8462	Cost: 31.78s
Train Epoch: 357 [20480/90000 (23%)]	Loss: 10.7686	Cost: 12.31s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 10.4522	Cost: 11.94s
Train Epoch: 357 [61440/90000 (68%)]	Loss: 10.7325	Cost: 8.65s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 10.5697	Cost: 5.82s
Train Epoch: 357 	Average Loss: 10.6752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1643

Learning rate: 0.00019999371070986973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 10.8613	Cost: 26.66s
Train Epoch: 358 [20480/90000 (23%)]	Loss: 10.8269	Cost: 11.93s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 10.5427	Cost: 6.44s
Train Epoch: 358 [61440/90000 (68%)]	Loss: 10.5851	Cost: 5.88s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 10.6452	Cost: 6.83s
Train Epoch: 358 	Average Loss: 10.6842
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1990

Learning rate: 0.00019999367542677577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 10.7437	Cost: 23.03s
Train Epoch: 359 [20480/90000 (23%)]	Loss: 10.7759	Cost: 7.13s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 10.6374	Cost: 6.46s
Train Epoch: 359 [61440/90000 (68%)]	Loss: 10.5273	Cost: 5.96s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 10.8028	Cost: 6.23s
Train Epoch: 359 	Average Loss: 10.6415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2174

Learning rate: 0.00019999364004499203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 10.7621	Cost: 23.93s
Train Epoch: 360 [20480/90000 (23%)]	Loss: 10.8244	Cost: 6.33s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 10.5155	Cost: 12.77s
Train Epoch: 360 [61440/90000 (68%)]	Loss: 10.5798	Cost: 12.25s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 10.7662	Cost: 11.93s
Train Epoch: 360 	Average Loss: 10.6478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1526

Learning rate: 0.0001999936045645185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 11.0502	Cost: 33.86s
Train Epoch: 361 [20480/90000 (23%)]	Loss: 10.7243	Cost: 13.69s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 10.3954	Cost: 12.16s
Train Epoch: 361 [61440/90000 (68%)]	Loss: 10.5861	Cost: 12.03s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 10.7212	Cost: 7.50s
Train Epoch: 361 	Average Loss: 10.6423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1354

Learning rate: 0.00019999356898535523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 10.9641	Cost: 23.58s
Train Epoch: 362 [20480/90000 (23%)]	Loss: 10.7420	Cost: 6.65s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 10.4435	Cost: 6.57s
Train Epoch: 362 [61440/90000 (68%)]	Loss: 10.7810	Cost: 6.42s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 10.7030	Cost: 8.41s
Train Epoch: 362 	Average Loss: 10.6136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0250

Saving model as e362_model.pt & e362_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999935333075023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 10.8516	Cost: 23.02s
Train Epoch: 363 [20480/90000 (23%)]	Loss: 10.5961	Cost: 6.05s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 10.7410	Cost: 7.38s
Train Epoch: 363 [61440/90000 (68%)]	Loss: 10.5941	Cost: 6.47s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 10.7639	Cost: 9.39s
Train Epoch: 363 	Average Loss: 10.6318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1998

Learning rate: 0.0001999934975309597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 10.6649	Cost: 23.64s
Train Epoch: 364 [20480/90000 (23%)]	Loss: 10.6908	Cost: 6.35s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 10.4888	Cost: 8.24s
Train Epoch: 364 [61440/90000 (68%)]	Loss: 10.6169	Cost: 11.34s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 10.6978	Cost: 12.06s
Train Epoch: 364 	Average Loss: 10.6510
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2279

Learning rate: 0.00019999346165572743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 10.8103	Cost: 36.09s
Train Epoch: 365 [20480/90000 (23%)]	Loss: 10.6787	Cost: 11.82s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 10.6654	Cost: 12.11s
Train Epoch: 365 [61440/90000 (68%)]	Loss: 10.6079	Cost: 7.45s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 10.7776	Cost: 5.82s
Train Epoch: 365 	Average Loss: 10.6319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1902

Learning rate: 0.00019999342568180562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 10.7139	Cost: 24.55s
Train Epoch: 366 [20480/90000 (23%)]	Loss: 10.6592	Cost: 6.11s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 10.6467	Cost: 11.75s
Train Epoch: 366 [61440/90000 (68%)]	Loss: 10.7214	Cost: 6.44s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 10.7879	Cost: 10.48s
Train Epoch: 366 	Average Loss: 10.6131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1073

Learning rate: 0.00019999338960919423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 10.7219	Cost: 23.43s
Train Epoch: 367 [20480/90000 (23%)]	Loss: 10.5990	Cost: 6.21s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 10.5308	Cost: 12.56s
Train Epoch: 367 [61440/90000 (68%)]	Loss: 10.5679	Cost: 12.12s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 10.5713	Cost: 11.84s
Train Epoch: 367 	Average Loss: 10.6069
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2030

Learning rate: 0.0001999933534378933
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 11.0694	Cost: 30.68s
Train Epoch: 368 [20480/90000 (23%)]	Loss: 10.4975	Cost: 12.01s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 10.4774	Cost: 11.97s
Train Epoch: 368 [61440/90000 (68%)]	Loss: 10.6955	Cost: 10.39s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 10.6833	Cost: 5.86s
Train Epoch: 368 	Average Loss: 10.6459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0983

Learning rate: 0.00019999331716790292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 10.8343	Cost: 26.51s
Train Epoch: 369 [20480/90000 (23%)]	Loss: 10.7619	Cost: 8.73s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 10.4163	Cost: 6.22s
Train Epoch: 369 [61440/90000 (68%)]	Loss: 10.6033	Cost: 6.91s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 10.6937	Cost: 5.99s
Train Epoch: 369 	Average Loss: 10.6068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1633

Learning rate: 0.00019999328079922307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 10.7252	Cost: 23.77s
Train Epoch: 370 [20480/90000 (23%)]	Loss: 10.7247	Cost: 6.33s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 10.4846	Cost: 6.81s
Train Epoch: 370 [61440/90000 (68%)]	Loss: 10.6281	Cost: 6.43s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 10.8125	Cost: 6.05s
Train Epoch: 370 	Average Loss: 10.6108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1585

Learning rate: 0.00019999324433185383
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 10.7351	Cost: 26.45s
Train Epoch: 371 [20480/90000 (23%)]	Loss: 10.5950	Cost: 6.20s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 10.5501	Cost: 9.94s
Train Epoch: 371 [61440/90000 (68%)]	Loss: 10.6478	Cost: 10.01s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 10.6096	Cost: 13.42s
Train Epoch: 371 	Average Loss: 10.5928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1139

Learning rate: 0.0001999932077657952
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 10.5513	Cost: 24.34s
Train Epoch: 372 [20480/90000 (23%)]	Loss: 10.6298	Cost: 7.65s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 10.5070	Cost: 12.35s
Train Epoch: 372 [61440/90000 (68%)]	Loss: 10.5903	Cost: 12.00s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 10.7301	Cost: 11.84s
Train Epoch: 372 	Average Loss: 10.5816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
