Nestedspace(activation='elu', apply_unconditional_transform=False, base_transform_type='rq-coupling', basis_dir='data/GW150914_sample_prior_basis/', batch_norm=True, batch_size=2048, bw_dstar=None, cuda=True, data_dir='data/GW150914_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, dropout_probability=0.0, epochs=100000, flow_lr=None, hidden_dims=512, kl_annealing=True, lr=0.0002, lr_anneal_method='cosine', lr_annealing=True, mixed_alpha=0.1, mode='train', model_dir='models/GW150914_sample_uniform_100basis_all_mixed_prior_a01/', model_source='new', model_type='nde', nbins=8, nflows=15, nsample=100000, nsamples_target_event=50000, num_transform_blocks=10, output_freq=10, sampling_from='mixed', save=True, save_aux_filename='waveforms_supplementary.hdf5', save_model_name='model.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, tail_bound=1.0, transfer_epochs=0, truncate_basis=100)
Waveform directory data/GW150914_sample_prior_basis/
Model directory models/GW150914_sample_uniform_100basis_all_mixed_prior_a01/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
Loading load_all_bilby_samples...
Loading load_all_event_strain...
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
init relative whitening...
Building time translation matrices.
Detectors: ['H1', 'L1']

Constructing model of type nde

Initial learning rate 0.0002
Using cosine LR annealing.

Model hyperparameters:
input_dim 	 15
num_flow_steps 	 15
context_dim 	 400
base_transform_kwargs
	 hidden_dim 	 512
	 num_transform_blocks 	 10
	 activation 	 elu
	 dropout_probability 	 0.0
	 batch_norm 	 True
	 num_bins 	 8
	 tail_bound 	 1.0
	 apply_unconditional_transform 	 False
	 base_transform_type 	 rq-coupling

Training for 100000 epochs
Starting timer
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 27.4505	Cost: 28.76s
Train Epoch: 1 [20480/90000 (23%)]	Loss: 21.9966	Cost: 6.06s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 21.4572	Cost: 10.33s
Train Epoch: 1 [61440/90000 (68%)]	Loss: 21.3671	Cost: 6.30s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 21.2628	Cost: 9.10s
Train Epoch: 1 	Average Loss: 21.8887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2882

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999995065198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 21.1960	Cost: 27.36s
Train Epoch: 2 [20480/90000 (23%)]	Loss: 21.1810	Cost: 12.07s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 21.1325	Cost: 11.97s
Train Epoch: 2 [61440/90000 (68%)]	Loss: 21.1367	Cost: 10.43s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 21.1352	Cost: 5.93s
Train Epoch: 2 	Average Loss: 21.1440
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1266

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999998026079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 21.1044	Cost: 27.51s
Train Epoch: 3 [20480/90000 (23%)]	Loss: 21.0221	Cost: 6.84s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 20.9436	Cost: 9.56s
Train Epoch: 3 [61440/90000 (68%)]	Loss: 20.9858	Cost: 6.64s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 20.9317	Cost: 16.07s
Train Epoch: 3 	Average Loss: 20.9762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0164

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999995558678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 20.9246	Cost: 27.16s
Train Epoch: 4 [20480/90000 (23%)]	Loss: 20.8710	Cost: 11.88s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 20.8607	Cost: 10.50s
Train Epoch: 4 [61440/90000 (68%)]	Loss: 20.8136	Cost: 5.85s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 20.7547	Cost: 6.74s
Train Epoch: 4 	Average Loss: 20.7979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8335

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999921043165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 20.6368	Cost: 21.90s
Train Epoch: 5 [20480/90000 (23%)]	Loss: 20.6351	Cost: 6.86s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 20.6394	Cost: 7.44s
Train Epoch: 5 [61440/90000 (68%)]	Loss: 20.5610	Cost: 6.14s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 20.5986	Cost: 13.07s
Train Epoch: 5 	Average Loss: 20.6158
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.6328

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999876629945
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 20.5328	Cost: 27.10s
Train Epoch: 6 [20480/90000 (23%)]	Loss: 20.4984	Cost: 8.49s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 20.4818	Cost: 6.24s
Train Epoch: 6 [61440/90000 (68%)]	Loss: 20.3715	Cost: 7.14s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 20.3636	Cost: 6.52s
Train Epoch: 6 	Average Loss: 20.4429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4575

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999822347122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 20.4113	Cost: 25.40s
Train Epoch: 7 [20480/90000 (23%)]	Loss: 20.3166	Cost: 8.25s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 20.3379	Cost: 12.07s
Train Epoch: 7 [61440/90000 (68%)]	Loss: 20.2875	Cost: 12.09s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 20.2104	Cost: 11.88s
Train Epoch: 7 	Average Loss: 20.2809
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3110

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999758194695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 20.1790	Cost: 22.19s
Train Epoch: 8 [20480/90000 (23%)]	Loss: 20.2214	Cost: 6.34s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 20.0843	Cost: 6.51s
Train Epoch: 8 [61440/90000 (68%)]	Loss: 20.0481	Cost: 7.92s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 19.9950	Cost: 6.43s
Train Epoch: 8 	Average Loss: 20.1328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1898

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999684172664
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 20.0582	Cost: 26.65s
Train Epoch: 9 [20480/90000 (23%)]	Loss: 19.9668	Cost: 9.61s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 19.9496	Cost: 6.19s
Train Epoch: 9 [61440/90000 (68%)]	Loss: 19.8929	Cost: 6.18s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 19.8253	Cost: 8.87s
Train Epoch: 9 	Average Loss: 19.9220
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9879

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999600281025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 19.7325	Cost: 26.24s
Train Epoch: 10 [20480/90000 (23%)]	Loss: 19.7298	Cost: 10.15s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 19.6697	Cost: 12.29s
Train Epoch: 10 [61440/90000 (68%)]	Loss: 19.6052	Cost: 11.92s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 19.6249	Cost: 11.80s
Train Epoch: 10 	Average Loss: 19.6899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.7657

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999506519785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 19.6384	Cost: 22.40s
Train Epoch: 11 [20480/90000 (23%)]	Loss: 19.5211	Cost: 6.42s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 19.4455	Cost: 7.69s
Train Epoch: 11 [61440/90000 (68%)]	Loss: 19.5196	Cost: 6.88s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 19.4605	Cost: 6.42s
Train Epoch: 11 	Average Loss: 19.4753
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.5614

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999402888941
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 19.3434	Cost: 23.31s
Train Epoch: 12 [20480/90000 (23%)]	Loss: 19.3715	Cost: 6.09s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 19.3208	Cost: 7.17s
Train Epoch: 12 [61440/90000 (68%)]	Loss: 19.1765	Cost: 6.10s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 19.1983	Cost: 5.91s
Train Epoch: 12 	Average Loss: 19.2936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3664

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999289388494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 19.2244	Cost: 27.33s
Train Epoch: 13 [20480/90000 (23%)]	Loss: 19.2382	Cost: 12.20s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 19.0950	Cost: 12.17s
Train Epoch: 13 [61440/90000 (68%)]	Loss: 19.0625	Cost: 11.96s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 19.0081	Cost: 11.86s
Train Epoch: 13 	Average Loss: 19.1320
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2477

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999916601844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 19.0037	Cost: 22.24s
Train Epoch: 14 [20480/90000 (23%)]	Loss: 19.0592	Cost: 6.39s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 19.0061	Cost: 7.47s
Train Epoch: 14 [61440/90000 (68%)]	Loss: 18.9107	Cost: 6.98s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 18.9431	Cost: 6.27s
Train Epoch: 14 	Average Loss: 18.9609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0302

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999999032778784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 18.9149	Cost: 25.35s
Train Epoch: 15 [20480/90000 (23%)]	Loss: 18.9021	Cost: 6.16s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 18.8282	Cost: 6.91s
Train Epoch: 15 [61440/90000 (68%)]	Loss: 18.7518	Cost: 6.76s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 18.7991	Cost: 6.07s
Train Epoch: 15 	Average Loss: 18.8264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8698

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999998889669524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 18.7015	Cost: 31.42s
Train Epoch: 16 [20480/90000 (23%)]	Loss: 18.5969	Cost: 8.46s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 18.6458	Cost: 12.69s
Train Epoch: 16 [61440/90000 (68%)]	Loss: 18.6859	Cost: 12.03s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 18.6485	Cost: 11.88s
Train Epoch: 16 	Average Loss: 18.6579
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7937

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999873669066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 18.7093	Cost: 22.25s
Train Epoch: 17 [20480/90000 (23%)]	Loss: 18.5949	Cost: 6.30s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 18.5050	Cost: 6.22s
Train Epoch: 17 [61440/90000 (68%)]	Loss: 18.4957	Cost: 6.30s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 18.4632	Cost: 10.77s
Train Epoch: 17 	Average Loss: 18.4877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.6405

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999998573842195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 18.4431	Cost: 38.24s
Train Epoch: 18 [20480/90000 (23%)]	Loss: 18.4218	Cost: 6.13s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 18.3085	Cost: 8.32s
Train Epoch: 18 [61440/90000 (68%)]	Loss: 18.3217	Cost: 6.26s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 18.3720	Cost: 6.10s
Train Epoch: 18 	Average Loss: 18.3787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.4813

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999998401124124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 18.3701	Cost: 26.52s
Train Epoch: 19 [20480/90000 (23%)]	Loss: 18.2213	Cost: 12.13s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 18.0477	Cost: 12.02s
Train Epoch: 19 [61440/90000 (68%)]	Loss: 18.1366	Cost: 11.94s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 18.1388	Cost: 6.79s
Train Epoch: 19 	Average Loss: 18.2077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3897

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999998218536453
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 18.2200	Cost: 21.84s
Train Epoch: 20 [20480/90000 (23%)]	Loss: 18.1056	Cost: 6.02s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 18.1806	Cost: 8.23s
Train Epoch: 20 [61440/90000 (68%)]	Loss: 18.0929	Cost: 6.31s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 18.1393	Cost: 8.32s
Train Epoch: 20 	Average Loss: 18.1033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3003

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999998026079178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 17.9924	Cost: 23.37s
Train Epoch: 21 [20480/90000 (23%)]	Loss: 17.9221	Cost: 6.27s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 18.0432	Cost: 6.38s
Train Epoch: 21 [61440/90000 (68%)]	Loss: 17.9024	Cost: 6.52s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 17.9494	Cost: 6.20s
Train Epoch: 21 	Average Loss: 17.9771
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1401

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199999978237523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 17.8850	Cost: 26.43s
Train Epoch: 22 [20480/90000 (23%)]	Loss: 17.8986	Cost: 6.88s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 17.9309	Cost: 6.04s
Train Epoch: 22 [61440/90000 (68%)]	Loss: 17.9256	Cost: 6.81s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 17.7696	Cost: 6.10s
Train Epoch: 22 	Average Loss: 17.8755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0525

Saving model as e22_model.pt & e22_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999997611555822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 17.8236	Cost: 32.42s
Train Epoch: 23 [20480/90000 (23%)]	Loss: 17.8312	Cost: 11.95s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 17.5834	Cost: 11.95s
Train Epoch: 23 [61440/90000 (68%)]	Loss: 17.8558	Cost: 9.22s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 17.7512	Cost: 6.11s
Train Epoch: 23 	Average Loss: 17.7432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9209

Saving model as e23_model.pt & e23_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999997389489742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 17.7344	Cost: 21.94s
Train Epoch: 24 [20480/90000 (23%)]	Loss: 17.7585	Cost: 6.15s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 17.6519	Cost: 7.97s
Train Epoch: 24 [61440/90000 (68%)]	Loss: 17.5953	Cost: 9.97s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 17.6802	Cost: 12.18s
Train Epoch: 24 	Average Loss: 17.6358
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7998

Saving model as e24_model.pt & e24_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999997157554058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 17.6866	Cost: 23.95s
Train Epoch: 25 [20480/90000 (23%)]	Loss: 17.6456	Cost: 6.37s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 17.7175	Cost: 6.62s
Train Epoch: 25 [61440/90000 (68%)]	Loss: 17.4758	Cost: 6.23s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 17.5781	Cost: 7.48s
Train Epoch: 25 	Average Loss: 17.5201
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6682

Saving model as e25_model.pt & e25_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999996915748774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 17.4493	Cost: 24.25s
Train Epoch: 26 [20480/90000 (23%)]	Loss: 17.5044	Cost: 6.80s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 17.3789	Cost: 6.46s
Train Epoch: 26 [61440/90000 (68%)]	Loss: 17.3595	Cost: 6.40s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 17.3811	Cost: 6.81s
Train Epoch: 26 	Average Loss: 17.3940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5766

Saving model as e26_model.pt & e26_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999996664073888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 17.2352	Cost: 27.77s
Train Epoch: 27 [20480/90000 (23%)]	Loss: 17.4001	Cost: 12.02s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 17.2938	Cost: 10.30s
Train Epoch: 27 [61440/90000 (68%)]	Loss: 17.2884	Cost: 6.13s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 17.1818	Cost: 6.19s
Train Epoch: 27 	Average Loss: 17.2523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5370

Saving model as e27_model.pt & e27_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999996402529402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 17.2840	Cost: 24.71s
Train Epoch: 28 [20480/90000 (23%)]	Loss: 17.3188	Cost: 7.11s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 17.1565	Cost: 12.09s
Train Epoch: 28 [61440/90000 (68%)]	Loss: 17.1499	Cost: 12.00s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 17.0604	Cost: 11.82s
Train Epoch: 28 	Average Loss: 17.1445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2980

Saving model as e28_model.pt & e28_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999996131115315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 17.1068	Cost: 22.36s
Train Epoch: 29 [20480/90000 (23%)]	Loss: 17.1771	Cost: 6.12s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 16.9251	Cost: 8.14s
Train Epoch: 29 [61440/90000 (68%)]	Loss: 17.0844	Cost: 6.24s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 16.8977	Cost: 6.91s
Train Epoch: 29 	Average Loss: 17.0174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2461

Saving model as e29_model.pt & e29_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999995849831625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 17.0857	Cost: 23.51s
Train Epoch: 30 [20480/90000 (23%)]	Loss: 17.0851	Cost: 7.06s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 16.9530	Cost: 7.71s
Train Epoch: 30 [61440/90000 (68%)]	Loss: 16.9068	Cost: 6.59s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 16.9532	Cost: 9.89s
Train Epoch: 30 	Average Loss: 16.9277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1638

Saving model as e30_model.pt & e30_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999995558678336
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 16.8098	Cost: 23.46s
Train Epoch: 31 [20480/90000 (23%)]	Loss: 16.7488	Cost: 7.27s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 16.8387	Cost: 6.49s
Train Epoch: 31 [61440/90000 (68%)]	Loss: 16.8108	Cost: 6.36s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 16.7157	Cost: 6.28s
Train Epoch: 31 	Average Loss: 16.7844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9781

Saving model as e31_model.pt & e31_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999525765545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 16.5647	Cost: 22.97s
Train Epoch: 32 [20480/90000 (23%)]	Loss: 16.8568	Cost: 6.09s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 16.6411	Cost: 7.10s
Train Epoch: 32 [61440/90000 (68%)]	Loss: 16.6646	Cost: 6.40s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 16.7731	Cost: 6.45s
Train Epoch: 32 	Average Loss: 16.6728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8145

Saving model as e32_model.pt & e32_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999494676296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 16.5809	Cost: 27.54s
Train Epoch: 33 [20480/90000 (23%)]	Loss: 16.6977	Cost: 11.07s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 16.6023	Cost: 9.53s
Train Epoch: 33 [61440/90000 (68%)]	Loss: 16.4774	Cost: 5.83s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 16.5585	Cost: 6.68s
Train Epoch: 33 	Average Loss: 16.5792
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7946

Saving model as e33_model.pt & e33_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999994626000874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 16.5233	Cost: 28.48s
Train Epoch: 34 [20480/90000 (23%)]	Loss: 16.6032	Cost: 12.32s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 16.4641	Cost: 12.11s
Train Epoch: 34 [61440/90000 (68%)]	Loss: 16.5129	Cost: 11.85s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 16.5204	Cost: 8.63s
Train Epoch: 34 	Average Loss: 16.4868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7381

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999994295369188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 16.2888	Cost: 35.61s
Train Epoch: 35 [20480/90000 (23%)]	Loss: 16.4637	Cost: 12.22s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 16.3528	Cost: 11.94s
Train Epoch: 35 [61440/90000 (68%)]	Loss: 16.3858	Cost: 8.59s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 16.3363	Cost: 5.77s
Train Epoch: 35 	Average Loss: 16.3787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5558

Saving model as e35_model.pt & e35_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199999939548679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 16.3737	Cost: 26.61s
Train Epoch: 36 [20480/90000 (23%)]	Loss: 16.2786	Cost: 11.83s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 16.2722	Cost: 12.23s
Train Epoch: 36 [61440/90000 (68%)]	Loss: 16.2635	Cost: 11.80s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 16.3565	Cost: 11.94s
Train Epoch: 36 	Average Loss: 16.2836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4852

Saving model as e36_model.pt & e36_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999993604497015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 16.2167	Cost: 22.60s
Train Epoch: 37 [20480/90000 (23%)]	Loss: 16.2498	Cost: 6.28s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 16.2903	Cost: 6.52s
Train Epoch: 37 [61440/90000 (68%)]	Loss: 16.2289	Cost: 8.04s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 16.1668	Cost: 6.23s
Train Epoch: 37 	Average Loss: 16.2175
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4682

Saving model as e37_model.pt & e37_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999993244256535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 16.1418	Cost: 25.78s
Train Epoch: 38 [20480/90000 (23%)]	Loss: 16.2208	Cost: 9.63s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 16.1173	Cost: 6.18s
Train Epoch: 38 [61440/90000 (68%)]	Loss: 16.1284	Cost: 6.74s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 16.0804	Cost: 6.10s
Train Epoch: 38 	Average Loss: 16.1215
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3079

Saving model as e38_model.pt & e38_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999992874146456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 16.1545	Cost: 32.04s
Train Epoch: 39 [20480/90000 (23%)]	Loss: 16.1175	Cost: 12.00s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 16.0126	Cost: 12.19s
Train Epoch: 39 [61440/90000 (68%)]	Loss: 16.1306	Cost: 11.78s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 16.1404	Cost: 8.62s
Train Epoch: 39 	Average Loss: 16.0435
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2431

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999999249416678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 15.8674	Cost: 27.85s
Train Epoch: 40 [20480/90000 (23%)]	Loss: 15.9746	Cost: 6.21s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 15.9464	Cost: 12.47s
Train Epoch: 40 [61440/90000 (68%)]	Loss: 16.1688	Cost: 12.14s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 15.9731	Cost: 11.88s
Train Epoch: 40 	Average Loss: 15.9625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2273

Saving model as e40_model.pt & e40_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999992104317507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 15.8266	Cost: 23.05s
Train Epoch: 41 [20480/90000 (23%)]	Loss: 15.9809	Cost: 6.92s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 15.9893	Cost: 7.45s
Train Epoch: 41 [61440/90000 (68%)]	Loss: 15.9523	Cost: 6.29s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 15.8557	Cost: 12.55s
Train Epoch: 41 	Average Loss: 15.8951
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2479

Learning rate: 0.00019999991704598637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 15.8076	Cost: 26.01s
Train Epoch: 42 [20480/90000 (23%)]	Loss: 15.8442	Cost: 10.94s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 15.8554	Cost: 12.06s
Train Epoch: 42 [61440/90000 (68%)]	Loss: 15.9942	Cost: 11.86s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 15.8599	Cost: 11.80s
Train Epoch: 42 	Average Loss: 15.8360
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0228

Saving model as e42_model.pt & e42_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999991295010171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 15.7771	Cost: 27.30s
Train Epoch: 43 [20480/90000 (23%)]	Loss: 15.7682	Cost: 6.37s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 15.7185	Cost: 6.53s
Train Epoch: 43 [61440/90000 (68%)]	Loss: 15.7611	Cost: 6.21s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 15.7576	Cost: 14.01s
Train Epoch: 43 	Average Loss: 15.7553
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0343

Learning rate: 0.00019999990875552108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 15.8124	Cost: 22.18s
Train Epoch: 44 [20480/90000 (23%)]	Loss: 15.7686	Cost: 6.85s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 15.6264	Cost: 7.40s
Train Epoch: 44 [61440/90000 (68%)]	Loss: 15.7858	Cost: 6.29s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 15.7663	Cost: 10.94s
Train Epoch: 44 	Average Loss: 15.6760
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9009

Saving model as e44_model.pt & e44_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999990446224451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 15.5437	Cost: 22.04s
Train Epoch: 45 [20480/90000 (23%)]	Loss: 15.5671	Cost: 6.16s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 15.6792	Cost: 6.35s
Train Epoch: 45 [61440/90000 (68%)]	Loss: 15.5271	Cost: 6.14s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 15.7042	Cost: 7.78s
Train Epoch: 45 	Average Loss: 15.6185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8477

Saving model as e45_model.pt & e45_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199999900070272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 15.6371	Cost: 25.69s
Train Epoch: 46 [20480/90000 (23%)]	Loss: 15.5039	Cost: 6.21s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 15.6222	Cost: 7.77s
Train Epoch: 46 [61440/90000 (68%)]	Loss: 15.5324	Cost: 6.37s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 15.6270	Cost: 6.06s
Train Epoch: 46 	Average Loss: 15.5631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7974

Saving model as e46_model.pt & e46_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999989557960353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 15.6891	Cost: 26.74s
Train Epoch: 47 [20480/90000 (23%)]	Loss: 15.5071	Cost: 11.66s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 15.5691	Cost: 6.50s
Train Epoch: 47 [61440/90000 (68%)]	Loss: 15.4645	Cost: 5.90s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 15.4568	Cost: 6.86s
Train Epoch: 47 	Average Loss: 15.5200
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7771

Saving model as e47_model.pt & e47_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999998909902391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 15.3976	Cost: 28.73s
Train Epoch: 48 [20480/90000 (23%)]	Loss: 15.6733	Cost: 12.04s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 15.4083	Cost: 12.10s
Train Epoch: 48 [61440/90000 (68%)]	Loss: 15.3268	Cost: 6.20s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 15.5378	Cost: 5.99s
Train Epoch: 48 	Average Loss: 15.4629
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6436

Saving model as e48_model.pt & e48_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999988630217875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 15.3673	Cost: 24.02s
Train Epoch: 49 [20480/90000 (23%)]	Loss: 15.4812	Cost: 6.51s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 15.4727	Cost: 13.82s
Train Epoch: 49 [61440/90000 (68%)]	Loss: 15.3960	Cost: 12.11s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 15.4609	Cost: 11.85s
Train Epoch: 49 	Average Loss: 15.4119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6721

Learning rate: 0.00019999988151542247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 15.4716	Cost: 27.52s
Train Epoch: 50 [20480/90000 (23%)]	Loss: 15.3194	Cost: 12.23s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 15.2866	Cost: 12.23s
Train Epoch: 50 [61440/90000 (68%)]	Loss: 15.4651	Cost: 11.81s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 15.3711	Cost: 11.82s
Train Epoch: 50 	Average Loss: 15.3511
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6232

Saving model as e50_model.pt & e50_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999987662997027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 15.2690	Cost: 23.00s
Train Epoch: 51 [20480/90000 (23%)]	Loss: 15.3266	Cost: 6.52s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 15.2515	Cost: 8.06s
Train Epoch: 51 [61440/90000 (68%)]	Loss: 15.1901	Cost: 12.09s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 15.3018	Cost: 11.76s
Train Epoch: 51 	Average Loss: 15.2858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5733

Saving model as e51_model.pt & e51_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999987164582216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 15.3017	Cost: 22.43s
Train Epoch: 52 [20480/90000 (23%)]	Loss: 15.2233	Cost: 7.91s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 15.2818	Cost: 6.87s
Train Epoch: 52 [61440/90000 (68%)]	Loss: 15.3095	Cost: 6.09s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 15.3058	Cost: 15.14s
Train Epoch: 52 	Average Loss: 15.2584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5360

Saving model as e52_model.pt & e52_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999998665629781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 15.1130	Cost: 22.66s
Train Epoch: 53 [20480/90000 (23%)]	Loss: 15.2749	Cost: 6.49s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 15.2154	Cost: 6.56s
Train Epoch: 53 [61440/90000 (68%)]	Loss: 15.3065	Cost: 6.18s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 15.3685	Cost: 6.40s
Train Epoch: 53 	Average Loss: 15.2178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4757

Saving model as e53_model.pt & e53_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999986138143815
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 15.1505	Cost: 24.58s
Train Epoch: 54 [20480/90000 (23%)]	Loss: 15.2788	Cost: 6.46s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 15.2136	Cost: 6.51s
Train Epoch: 54 [61440/90000 (68%)]	Loss: 15.1464	Cost: 6.29s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 15.1145	Cost: 6.16s
Train Epoch: 54 	Average Loss: 15.1457
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4175

Saving model as e54_model.pt & e54_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999985610120227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 15.0574	Cost: 22.54s
Train Epoch: 55 [20480/90000 (23%)]	Loss: 15.1889	Cost: 6.25s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 15.2144	Cost: 6.49s
Train Epoch: 55 [61440/90000 (68%)]	Loss: 15.0902	Cost: 6.17s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 15.0758	Cost: 6.74s
Train Epoch: 55 	Average Loss: 15.1068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3357

Saving model as e55_model.pt & e55_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999998507222705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 15.1381	Cost: 22.78s
Train Epoch: 56 [20480/90000 (23%)]	Loss: 15.0254	Cost: 6.74s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 15.0515	Cost: 6.44s
Train Epoch: 56 [61440/90000 (68%)]	Loss: 15.0269	Cost: 6.25s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 14.9809	Cost: 6.25s
Train Epoch: 56 	Average Loss: 15.0712
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2871

Saving model as e56_model.pt & e56_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999984524464283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 15.0210	Cost: 24.03s
Train Epoch: 57 [20480/90000 (23%)]	Loss: 15.0194	Cost: 6.93s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 14.9297	Cost: 6.50s
Train Epoch: 57 [61440/90000 (68%)]	Loss: 15.0141	Cost: 6.39s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 15.1617	Cost: 6.07s
Train Epoch: 57 	Average Loss: 15.0152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2774

Saving model as e57_model.pt & e57_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999998396683193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 14.9262	Cost: 23.41s
Train Epoch: 58 [20480/90000 (23%)]	Loss: 15.2031	Cost: 6.57s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 15.0189	Cost: 8.92s
Train Epoch: 58 [61440/90000 (68%)]	Loss: 14.9992	Cost: 6.49s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 15.0212	Cost: 9.67s
Train Epoch: 58 	Average Loss: 14.9641
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2252

Saving model as e58_model.pt & e58_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999983399329984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 14.9218	Cost: 23.84s
Train Epoch: 59 [20480/90000 (23%)]	Loss: 15.1562	Cost: 6.07s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 14.8327	Cost: 8.65s
Train Epoch: 59 [61440/90000 (68%)]	Loss: 14.9252	Cost: 6.10s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 14.9200	Cost: 6.03s
Train Epoch: 59 	Average Loss: 14.9385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1809

Saving model as e59_model.pt & e59_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999982821958452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 14.7980	Cost: 23.90s
Train Epoch: 60 [20480/90000 (23%)]	Loss: 14.9050	Cost: 6.29s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 14.8817	Cost: 6.98s
Train Epoch: 60 [61440/90000 (68%)]	Loss: 15.0070	Cost: 6.17s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 14.7928	Cost: 6.11s
Train Epoch: 60 	Average Loss: 14.8872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1258

Saving model as e60_model.pt & e60_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999982234717332
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 14.9213	Cost: 28.45s
Train Epoch: 61 [20480/90000 (23%)]	Loss: 14.8445	Cost: 12.24s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 14.8396	Cost: 12.32s
Train Epoch: 61 [61440/90000 (68%)]	Loss: 14.9741	Cost: 9.48s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 14.8682	Cost: 6.07s
Train Epoch: 61 	Average Loss: 14.8528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1220

Saving model as e61_model.pt & e61_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999981637606627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 14.8606	Cost: 23.38s
Train Epoch: 62 [20480/90000 (23%)]	Loss: 14.8171	Cost: 6.39s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 14.8410	Cost: 12.90s
Train Epoch: 62 [61440/90000 (68%)]	Loss: 14.8312	Cost: 12.08s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 15.0320	Cost: 11.81s
Train Epoch: 62 	Average Loss: 14.8134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1363

Learning rate: 0.00019999981030626333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 14.7829	Cost: 26.48s
Train Epoch: 63 [20480/90000 (23%)]	Loss: 14.7559	Cost: 11.86s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 14.6685	Cost: 12.19s
Train Epoch: 63 [61440/90000 (68%)]	Loss: 14.9177	Cost: 11.85s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 14.7535	Cost: 11.79s
Train Epoch: 63 	Average Loss: 14.7627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0797

Saving model as e63_model.pt & e63_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999980413776456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 14.7084	Cost: 22.51s
Train Epoch: 64 [20480/90000 (23%)]	Loss: 14.8230	Cost: 6.49s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 14.8083	Cost: 9.11s
Train Epoch: 64 [61440/90000 (68%)]	Loss: 14.6688	Cost: 12.16s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 14.7308	Cost: 12.29s
Train Epoch: 64 	Average Loss: 14.7360
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0248

Saving model as e64_model.pt & e64_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999979787056995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 14.7599	Cost: 22.27s
Train Epoch: 65 [20480/90000 (23%)]	Loss: 14.6810	Cost: 6.68s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 14.7497	Cost: 11.06s
Train Epoch: 65 [61440/90000 (68%)]	Loss: 14.8444	Cost: 12.16s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 14.6947	Cost: 12.29s
Train Epoch: 65 	Average Loss: 14.6853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9730

Saving model as e65_model.pt & e65_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999979150467947
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 14.7356	Cost: 23.36s
Train Epoch: 66 [20480/90000 (23%)]	Loss: 14.7305	Cost: 6.18s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 14.7220	Cost: 13.19s
Train Epoch: 66 [61440/90000 (68%)]	Loss: 14.6230	Cost: 11.94s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 14.6604	Cost: 11.79s
Train Epoch: 66 	Average Loss: 14.6448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9547

Saving model as e66_model.pt & e66_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999978504009312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 14.6393	Cost: 26.36s
Train Epoch: 67 [20480/90000 (23%)]	Loss: 14.5918	Cost: 7.92s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 14.6476	Cost: 12.32s
Train Epoch: 67 [61440/90000 (68%)]	Loss: 14.6428	Cost: 12.03s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 14.5959	Cost: 11.85s
Train Epoch: 67 	Average Loss: 14.6207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.8281

Saving model as e67_model.pt & e67_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999977847681098
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 14.5786	Cost: 25.95s
Train Epoch: 68 [20480/90000 (23%)]	Loss: 14.6939	Cost: 6.68s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 14.6021	Cost: 10.78s
Train Epoch: 68 [61440/90000 (68%)]	Loss: 14.5508	Cost: 12.34s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 14.6182	Cost: 12.11s
Train Epoch: 68 	Average Loss: 14.5877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.8830

Learning rate: 0.00019999977181483299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 14.5803	Cost: 26.11s
Train Epoch: 69 [20480/90000 (23%)]	Loss: 14.7314	Cost: 12.27s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 14.3477	Cost: 12.58s
Train Epoch: 69 [61440/90000 (68%)]	Loss: 14.7011	Cost: 12.20s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 14.5961	Cost: 11.96s
Train Epoch: 69 	Average Loss: 14.5322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.8213

Saving model as e69_model.pt & e69_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999997650541592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 14.4926	Cost: 22.45s
Train Epoch: 70 [20480/90000 (23%)]	Loss: 14.6095	Cost: 6.39s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 14.5016	Cost: 8.18s
Train Epoch: 70 [61440/90000 (68%)]	Loss: 14.5754	Cost: 10.17s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 14.7001	Cost: 12.73s
Train Epoch: 70 	Average Loss: 14.5070
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7320

Saving model as e70_model.pt & e70_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999997581947896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 14.4677	Cost: 21.94s
Train Epoch: 71 [20480/90000 (23%)]	Loss: 14.5345	Cost: 6.13s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 14.4558	Cost: 7.68s
Train Epoch: 71 [61440/90000 (68%)]	Loss: 14.3831	Cost: 6.86s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 14.5297	Cost: 14.79s
Train Epoch: 71 	Average Loss: 14.4808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7559

Learning rate: 0.0001999997512367242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 14.5342	Cost: 28.36s
Train Epoch: 72 [20480/90000 (23%)]	Loss: 14.5218	Cost: 12.36s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 14.3866	Cost: 12.21s
Train Epoch: 72 [61440/90000 (68%)]	Loss: 14.4795	Cost: 11.88s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 14.4576	Cost: 11.96s
Train Epoch: 72 	Average Loss: 14.4480
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7192

Saving model as e72_model.pt & e72_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199999744179963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 14.4563	Cost: 22.33s
Train Epoch: 73 [20480/90000 (23%)]	Loss: 14.5921	Cost: 6.30s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 14.3958	Cost: 11.05s
Train Epoch: 73 [61440/90000 (68%)]	Loss: 14.5404	Cost: 12.38s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 14.4161	Cost: 12.00s
Train Epoch: 73 	Average Loss: 14.4175
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6956

Saving model as e73_model.pt & e73_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199999737024506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 14.3860	Cost: 24.53s
Train Epoch: 74 [20480/90000 (23%)]	Loss: 14.4181	Cost: 6.60s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 14.3458	Cost: 12.92s
Train Epoch: 74 [61440/90000 (68%)]	Loss: 14.4394	Cost: 12.17s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 14.3632	Cost: 11.88s
Train Epoch: 74 	Average Loss: 14.3626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6911

Saving model as e74_model.pt & e74_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999972977035322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 14.5014	Cost: 27.73s
Train Epoch: 75 [20480/90000 (23%)]	Loss: 14.3505	Cost: 12.43s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 14.3621	Cost: 11.94s
Train Epoch: 75 [61440/90000 (68%)]	Loss: 14.2790	Cost: 11.80s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 14.4214	Cost: 11.83s
Train Epoch: 75 	Average Loss: 14.3540
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6153

Saving model as e75_model.pt & e75_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999972241750466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 14.4315	Cost: 23.54s
Train Epoch: 76 [20480/90000 (23%)]	Loss: 14.4347	Cost: 6.26s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 14.4443	Cost: 8.35s
Train Epoch: 76 [61440/90000 (68%)]	Loss: 14.3700	Cost: 8.79s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 14.2456	Cost: 12.72s
Train Epoch: 76 	Average Loss: 14.3170
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5663

Saving model as e76_model.pt & e76_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999997149659603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 14.4410	Cost: 23.26s
Train Epoch: 77 [20480/90000 (23%)]	Loss: 14.3060	Cost: 7.07s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 14.3646	Cost: 6.57s
Train Epoch: 77 [61440/90000 (68%)]	Loss: 14.2198	Cost: 6.43s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 14.3596	Cost: 6.06s
Train Epoch: 77 	Average Loss: 14.2511
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5034

Saving model as e77_model.pt & e77_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999997074157202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 14.3984	Cost: 23.70s
Train Epoch: 78 [20480/90000 (23%)]	Loss: 14.3472	Cost: 6.36s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 14.1572	Cost: 6.51s
Train Epoch: 78 [61440/90000 (68%)]	Loss: 14.3150	Cost: 6.16s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 14.2729	Cost: 6.11s
Train Epoch: 78 	Average Loss: 14.2701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4976

Saving model as e78_model.pt & e78_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999969976678433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 14.1954	Cost: 23.61s
Train Epoch: 79 [20480/90000 (23%)]	Loss: 14.3066	Cost: 7.00s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 14.1579	Cost: 6.43s
Train Epoch: 79 [61440/90000 (68%)]	Loss: 14.2445	Cost: 6.18s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 14.1957	Cost: 6.07s
Train Epoch: 79 	Average Loss: 14.1991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5053

Learning rate: 0.00019999969201915272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 14.3483	Cost: 23.01s
Train Epoch: 80 [20480/90000 (23%)]	Loss: 14.3207	Cost: 6.28s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 14.0236	Cost: 6.44s
Train Epoch: 80 [61440/90000 (68%)]	Loss: 14.2756	Cost: 6.17s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 14.2787	Cost: 6.25s
Train Epoch: 80 	Average Loss: 14.1733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4919

Saving model as e80_model.pt & e80_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999968417282538
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 14.1975	Cost: 26.11s
Train Epoch: 81 [20480/90000 (23%)]	Loss: 14.2751	Cost: 11.93s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 14.2208	Cost: 10.75s
Train Epoch: 81 [61440/90000 (68%)]	Loss: 14.1468	Cost: 5.74s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 14.2149	Cost: 6.56s
Train Epoch: 81 	Average Loss: 14.1651
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4332

Saving model as e81_model.pt & e81_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999996762278023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 14.1424	Cost: 27.92s
Train Epoch: 82 [20480/90000 (23%)]	Loss: 14.1512	Cost: 12.28s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 14.1805	Cost: 12.08s
Train Epoch: 82 [61440/90000 (68%)]	Loss: 14.1264	Cost: 11.84s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 14.1832	Cost: 8.63s
Train Epoch: 82 	Average Loss: 14.1355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4076

Saving model as e82_model.pt & e82_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999996681840835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 14.1269	Cost: 22.14s
Train Epoch: 83 [20480/90000 (23%)]	Loss: 14.1838	Cost: 6.28s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 13.9237	Cost: 12.04s
Train Epoch: 83 [61440/90000 (68%)]	Loss: 14.1727	Cost: 12.15s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 14.0765	Cost: 11.90s
Train Epoch: 83 	Average Loss: 14.0636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3093

Saving model as e83_model.pt & e83_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999966004166902
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 14.0368	Cost: 28.09s
Train Epoch: 84 [20480/90000 (23%)]	Loss: 14.1037	Cost: 7.06s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 14.0574	Cost: 9.88s
Train Epoch: 84 [61440/90000 (68%)]	Loss: 14.0750	Cost: 11.83s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 14.0825	Cost: 12.13s
Train Epoch: 84 	Average Loss: 14.0487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.2862

Saving model as e84_model.pt & e84_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999996518005588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 14.0378	Cost: 25.05s
Train Epoch: 85 [20480/90000 (23%)]	Loss: 14.0706	Cost: 6.17s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 14.0148	Cost: 6.90s
Train Epoch: 85 [61440/90000 (68%)]	Loss: 14.1170	Cost: 6.13s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 14.0910	Cost: 17.68s
Train Epoch: 85 	Average Loss: 14.0037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.2628

Saving model as e85_model.pt & e85_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999964346075288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 14.0907	Cost: 22.52s
Train Epoch: 86 [20480/90000 (23%)]	Loss: 13.9903	Cost: 6.37s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 14.0708	Cost: 6.81s
Train Epoch: 86 [61440/90000 (68%)]	Loss: 13.9016	Cost: 6.33s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 14.0586	Cost: 14.03s
Train Epoch: 86 	Average Loss: 13.9901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4152

Learning rate: 0.00019999963502225128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 14.0280	Cost: 22.35s
Train Epoch: 87 [20480/90000 (23%)]	Loss: 14.1543	Cost: 6.44s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 13.8670	Cost: 13.12s
Train Epoch: 87 [61440/90000 (68%)]	Loss: 13.9697	Cost: 12.31s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 14.1569	Cost: 12.20s
Train Epoch: 87 	Average Loss: 13.9612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.2420

Saving model as e87_model.pt & e87_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999962648505396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 14.1321	Cost: 23.36s
Train Epoch: 88 [20480/90000 (23%)]	Loss: 14.0304	Cost: 8.65s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 14.0519	Cost: 13.66s
Train Epoch: 88 [61440/90000 (68%)]	Loss: 14.1113	Cost: 12.47s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 13.9191	Cost: 12.08s
Train Epoch: 88 	Average Loss: 13.9433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1910

Saving model as e88_model.pt & e88_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199999617849161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 13.9552	Cost: 24.60s
Train Epoch: 89 [20480/90000 (23%)]	Loss: 14.0220	Cost: 8.17s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 13.8545	Cost: 16.88s
Train Epoch: 89 [61440/90000 (68%)]	Loss: 13.8712	Cost: 12.23s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 13.9640	Cost: 11.88s
Train Epoch: 89 	Average Loss: 13.8963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1749

Saving model as e89_model.pt & e89_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999960911457236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 13.7884	Cost: 22.87s
Train Epoch: 90 [20480/90000 (23%)]	Loss: 13.8870	Cost: 6.34s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 13.8817	Cost: 9.98s
Train Epoch: 90 [61440/90000 (68%)]	Loss: 13.9646	Cost: 11.97s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 14.0358	Cost: 11.93s
Train Epoch: 90 	Average Loss: 13.8903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1922

Learning rate: 0.00019999960028128805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 13.7617	Cost: 26.19s
Train Epoch: 91 [20480/90000 (23%)]	Loss: 13.7613	Cost: 12.21s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 13.7760	Cost: 12.05s
Train Epoch: 91 [61440/90000 (68%)]	Loss: 13.8109	Cost: 11.80s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 13.9316	Cost: 8.01s
Train Epoch: 91 	Average Loss: 13.8436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1034

Saving model as e91_model.pt & e91_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999959134930808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 13.8068	Cost: 24.58s
Train Epoch: 92 [20480/90000 (23%)]	Loss: 13.8896	Cost: 6.59s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 13.8760	Cost: 12.25s
Train Epoch: 92 [61440/90000 (68%)]	Loss: 13.7854	Cost: 12.02s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 13.9269	Cost: 11.86s
Train Epoch: 92 	Average Loss: 13.8363
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1377

Learning rate: 0.0001999995823186325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 13.8489	Cost: 32.23s
Train Epoch: 93 [20480/90000 (23%)]	Loss: 13.7957	Cost: 12.13s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 13.8402	Cost: 11.95s
Train Epoch: 93 [61440/90000 (68%)]	Loss: 13.8404	Cost: 6.23s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 13.7558	Cost: 6.41s
Train Epoch: 93 	Average Loss: 13.8028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1228

Learning rate: 0.00019999957318926127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 13.7166	Cost: 26.46s
Train Epoch: 94 [20480/90000 (23%)]	Loss: 13.8286	Cost: 7.43s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 13.8058	Cost: 6.13s
Train Epoch: 94 [61440/90000 (68%)]	Loss: 13.7458	Cost: 6.91s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 13.8257	Cost: 6.00s
Train Epoch: 94 	Average Loss: 13.7602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0915

Saving model as e94_model.pt & e94_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999956396119442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 13.7046	Cost: 26.82s
Train Epoch: 95 [20480/90000 (23%)]	Loss: 13.7134	Cost: 11.78s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 13.7272	Cost: 10.48s
Train Epoch: 95 [61440/90000 (68%)]	Loss: 13.6748	Cost: 5.79s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 13.6933	Cost: 6.73s
Train Epoch: 95 	Average Loss: 13.7224
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0484

Saving model as e95_model.pt & e95_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999955463443194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 13.6851	Cost: 23.06s
Train Epoch: 96 [20480/90000 (23%)]	Loss: 13.6910	Cost: 6.29s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 13.6673	Cost: 12.53s
Train Epoch: 96 [61440/90000 (68%)]	Loss: 13.7166	Cost: 12.08s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 13.7101	Cost: 11.84s
Train Epoch: 96 	Average Loss: 13.7197
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9230

Saving model as e96_model.pt & e96_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999954520897388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 13.6833	Cost: 26.23s
Train Epoch: 97 [20480/90000 (23%)]	Loss: 13.7810	Cost: 6.24s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 13.6590	Cost: 6.49s
Train Epoch: 97 [61440/90000 (68%)]	Loss: 13.7931	Cost: 6.18s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 13.7510	Cost: 5.92s
Train Epoch: 97 	Average Loss: 13.6909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0550

Learning rate: 0.00019999953568482025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 13.7184	Cost: 21.67s
Train Epoch: 98 [20480/90000 (23%)]	Loss: 13.5945	Cost: 7.90s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 13.8188	Cost: 6.74s
Train Epoch: 98 [61440/90000 (68%)]	Loss: 13.6860	Cost: 6.27s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 13.6625	Cost: 14.35s
Train Epoch: 98 	Average Loss: 13.6444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0025

Learning rate: 0.000199999526061971
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 13.4648	Cost: 23.60s
Train Epoch: 99 [20480/90000 (23%)]	Loss: 13.6517	Cost: 6.30s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 13.5001	Cost: 12.20s
Train Epoch: 99 [61440/90000 (68%)]	Loss: 13.7938	Cost: 12.32s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 13.6857	Cost: 12.15s
Train Epoch: 99 	Average Loss: 13.6081
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8843

Saving model as e99_model.pt & e99_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999951634042617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 13.6224	Cost: 22.05s
Train Epoch: 100 [20480/90000 (23%)]	Loss: 13.6991	Cost: 6.35s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 13.5458	Cost: 7.56s
Train Epoch: 100 [61440/90000 (68%)]	Loss: 13.5945	Cost: 8.76s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 13.5396	Cost: 12.81s
Train Epoch: 100 	Average Loss: 13.5910
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8886

Learning rate: 0.00019999950652018581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 13.8190	Cost: 26.42s
Train Epoch: 101 [20480/90000 (23%)]	Loss: 13.6394	Cost: 11.24s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 13.5757	Cost: 12.43s
Train Epoch: 101 [61440/90000 (68%)]	Loss: 13.5880	Cost: 11.96s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 13.6106	Cost: 11.84s
Train Epoch: 101 	Average Loss: 13.6035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9126

Learning rate: 0.00019999949660124986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 13.5862	Cost: 24.89s
Train Epoch: 102 [20480/90000 (23%)]	Loss: 13.7140	Cost: 12.13s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 13.5318	Cost: 12.17s
Train Epoch: 102 [61440/90000 (68%)]	Loss: 13.7199	Cost: 11.87s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 13.4511	Cost: 11.64s
Train Epoch: 102 	Average Loss: 13.5532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8496

Saving model as e102_model.pt & e102_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999948658361836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 13.6974	Cost: 21.84s
Train Epoch: 103 [20480/90000 (23%)]	Loss: 13.5641	Cost: 6.36s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 13.3553	Cost: 7.44s
Train Epoch: 103 [61440/90000 (68%)]	Loss: 13.6312	Cost: 6.25s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 13.4888	Cost: 16.72s
Train Epoch: 103 	Average Loss: 13.5470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9016

Learning rate: 0.00019999947646729134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 13.6914	Cost: 24.14s
Train Epoch: 104 [20480/90000 (23%)]	Loss: 13.5648	Cost: 7.43s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 13.2962	Cost: 12.04s
Train Epoch: 104 [61440/90000 (68%)]	Loss: 13.6216	Cost: 12.25s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 13.5866	Cost: 12.04s
Train Epoch: 104 	Average Loss: 13.5071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9076

Learning rate: 0.00019999946625226878
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 13.4872	Cost: 25.60s
Train Epoch: 105 [20480/90000 (23%)]	Loss: 13.3091	Cost: 11.86s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 13.3908	Cost: 11.92s
Train Epoch: 105 [61440/90000 (68%)]	Loss: 13.6420	Cost: 11.86s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 13.4637	Cost: 10.31s
Train Epoch: 105 	Average Loss: 13.4889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7882

Saving model as e105_model.pt & e105_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999945593855072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 13.5445	Cost: 21.21s
Train Epoch: 106 [20480/90000 (23%)]	Loss: 13.6005	Cost: 6.16s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 13.4967	Cost: 10.15s
Train Epoch: 106 [61440/90000 (68%)]	Loss: 13.4736	Cost: 12.25s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 13.4426	Cost: 12.25s
Train Epoch: 106 	Average Loss: 13.4569
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7748

Saving model as e106_model.pt & e106_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999944552613714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 13.6111	Cost: 21.88s
Train Epoch: 107 [20480/90000 (23%)]	Loss: 13.4977	Cost: 6.26s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 13.3138	Cost: 6.90s
Train Epoch: 107 [61440/90000 (68%)]	Loss: 13.4243	Cost: 6.01s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 13.4715	Cost: 7.69s
Train Epoch: 107 	Average Loss: 13.4420
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7382

Saving model as e107_model.pt & e107_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999943501502806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 13.3532	Cost: 26.99s
Train Epoch: 108 [20480/90000 (23%)]	Loss: 13.5997	Cost: 11.88s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 13.3214	Cost: 10.56s
Train Epoch: 108 [61440/90000 (68%)]	Loss: 13.5653	Cost: 5.80s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 13.3889	Cost: 6.25s
Train Epoch: 108 	Average Loss: 13.4195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7855

Learning rate: 0.0001999994244052235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 13.6027	Cost: 26.77s
Train Epoch: 109 [20480/90000 (23%)]	Loss: 13.4892	Cost: 10.63s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 13.3184	Cost: 6.16s
Train Epoch: 109 [61440/90000 (68%)]	Loss: 13.5408	Cost: 6.19s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 13.2497	Cost: 6.91s
Train Epoch: 109 	Average Loss: 13.3942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8112

Learning rate: 0.00019999941369672346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 13.4984	Cost: 24.71s
Train Epoch: 110 [20480/90000 (23%)]	Loss: 13.4459	Cost: 6.05s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 13.3561	Cost: 6.91s
Train Epoch: 110 [61440/90000 (68%)]	Loss: 13.4133	Cost: 6.77s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 13.4670	Cost: 6.16s
Train Epoch: 110 	Average Loss: 13.3873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6950

Saving model as e110_model.pt & e110_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999940288952794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 13.4017	Cost: 28.09s
Train Epoch: 111 [20480/90000 (23%)]	Loss: 13.3565	Cost: 12.56s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 13.3266	Cost: 11.69s
Train Epoch: 111 [61440/90000 (68%)]	Loss: 13.3639	Cost: 11.79s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 13.4846	Cost: 8.03s
Train Epoch: 111 	Average Loss: 13.3692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7014

Learning rate: 0.000199999391983637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 13.4323	Cost: 26.10s
Train Epoch: 112 [20480/90000 (23%)]	Loss: 13.3363	Cost: 12.06s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 13.3988	Cost: 11.96s
Train Epoch: 112 [61440/90000 (68%)]	Loss: 13.4127	Cost: 6.21s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 13.3781	Cost: 5.69s
Train Epoch: 112 	Average Loss: 13.3399
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6153

Saving model as e112_model.pt & e112_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999993809790506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 13.5106	Cost: 28.28s
Train Epoch: 113 [20480/90000 (23%)]	Loss: 13.3971	Cost: 12.38s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 13.3612	Cost: 11.58s
Train Epoch: 113 [61440/90000 (68%)]	Loss: 13.3053	Cost: 7.48s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 13.3804	Cost: 5.80s
Train Epoch: 113 	Average Loss: 13.3083
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6851

Learning rate: 0.00019999936987576873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 13.2665	Cost: 22.77s
Train Epoch: 114 [20480/90000 (23%)]	Loss: 13.3307	Cost: 6.14s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 13.3048	Cost: 8.69s
Train Epoch: 114 [61440/90000 (68%)]	Loss: 13.3327	Cost: 6.21s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 13.3421	Cost: 7.10s
Train Epoch: 114 	Average Loss: 13.2969
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5901

Saving model as e114_model.pt & e114_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999935867379148
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 13.4858	Cost: 26.55s
Train Epoch: 115 [20480/90000 (23%)]	Loss: 13.2660	Cost: 9.33s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 13.2973	Cost: 6.03s
Train Epoch: 115 [61440/90000 (68%)]	Loss: 13.4034	Cost: 6.38s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 13.2573	Cost: 6.42s
Train Epoch: 115 	Average Loss: 13.2954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5828

Saving model as e115_model.pt & e115_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999934737311882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 13.2761	Cost: 24.53s
Train Epoch: 116 [20480/90000 (23%)]	Loss: 13.4161	Cost: 10.60s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 13.2372	Cost: 12.21s
Train Epoch: 116 [61440/90000 (68%)]	Loss: 13.2887	Cost: 11.94s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 13.3038	Cost: 11.89s
Train Epoch: 116 	Average Loss: 13.2546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5110

Saving model as e116_model.pt & e116_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999933597375074
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 13.2596	Cost: 23.24s
Train Epoch: 117 [20480/90000 (23%)]	Loss: 13.2451	Cost: 6.30s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 13.1844	Cost: 6.77s
Train Epoch: 117 [61440/90000 (68%)]	Loss: 13.2933	Cost: 6.24s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 13.1408	Cost: 15.76s
Train Epoch: 117 	Average Loss: 13.2189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4992

Saving model as e117_model.pt & e117_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999993244756873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 13.1405	Cost: 23.45s
Train Epoch: 118 [20480/90000 (23%)]	Loss: 13.2458	Cost: 6.31s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 13.1735	Cost: 6.42s
Train Epoch: 118 [61440/90000 (68%)]	Loss: 13.2835	Cost: 6.03s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 13.2945	Cost: 9.38s
Train Epoch: 118 	Average Loss: 13.2113
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5625

Learning rate: 0.00019999931287892846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 13.1746	Cost: 22.83s
Train Epoch: 119 [20480/90000 (23%)]	Loss: 13.2556	Cost: 6.40s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 13.1243	Cost: 12.48s
Train Epoch: 119 [61440/90000 (68%)]	Loss: 13.2323	Cost: 12.16s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 13.1456	Cost: 11.90s
Train Epoch: 119 	Average Loss: 13.1761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5054

Learning rate: 0.00019999930118347426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 13.2159	Cost: 25.27s
Train Epoch: 120 [20480/90000 (23%)]	Loss: 13.3236	Cost: 11.85s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 13.2533	Cost: 12.11s
Train Epoch: 120 [61440/90000 (68%)]	Loss: 13.0553	Cost: 11.84s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 13.2198	Cost: 10.95s
Train Epoch: 120 	Average Loss: 13.1710
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4693

Saving model as e120_model.pt & e120_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999992893893247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 13.1553	Cost: 22.37s
Train Epoch: 121 [20480/90000 (23%)]	Loss: 13.3943	Cost: 6.41s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 13.1451	Cost: 7.96s
Train Epoch: 121 [61440/90000 (68%)]	Loss: 13.1365	Cost: 8.22s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 13.1126	Cost: 13.91s
Train Epoch: 121 	Average Loss: 13.1736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4702

Learning rate: 0.0001999992774964798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 13.1444	Cost: 23.84s
Train Epoch: 122 [20480/90000 (23%)]	Loss: 13.2790	Cost: 6.24s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 13.0761	Cost: 12.28s
Train Epoch: 122 [61440/90000 (68%)]	Loss: 13.3679	Cost: 12.23s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 13.2831	Cost: 11.85s
Train Epoch: 122 	Average Loss: 13.1339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4837

Learning rate: 0.00019999926550493962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 13.2119	Cost: 26.39s
Train Epoch: 123 [20480/90000 (23%)]	Loss: 13.1883	Cost: 12.22s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 13.1426	Cost: 12.09s
Train Epoch: 123 [61440/90000 (68%)]	Loss: 13.0938	Cost: 11.87s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 13.0372	Cost: 9.16s
Train Epoch: 123 	Average Loss: 13.1075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4310

Saving model as e123_model.pt & e123_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999925341470404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 13.2703	Cost: 23.15s
Train Epoch: 124 [20480/90000 (23%)]	Loss: 13.1560	Cost: 6.39s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 13.2642	Cost: 13.27s
Train Epoch: 124 [61440/90000 (68%)]	Loss: 13.0793	Cost: 12.12s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 13.1608	Cost: 11.87s
Train Epoch: 124 	Average Loss: 13.1021
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4056

Saving model as e124_model.pt & e124_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999992412257732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 13.1938	Cost: 22.25s
Train Epoch: 125 [20480/90000 (23%)]	Loss: 13.1851	Cost: 6.08s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 13.0131	Cost: 6.31s
Train Epoch: 125 [61440/90000 (68%)]	Loss: 13.1001	Cost: 6.26s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 13.2355	Cost: 15.06s
Train Epoch: 125 	Average Loss: 13.0946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4298

Learning rate: 0.00019999922893814705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 13.0028	Cost: 22.78s
Train Epoch: 126 [20480/90000 (23%)]	Loss: 13.1475	Cost: 6.36s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 13.0096	Cost: 11.49s
Train Epoch: 126 [61440/90000 (68%)]	Loss: 13.0107	Cost: 12.11s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 12.9737	Cost: 11.84s
Train Epoch: 126 	Average Loss: 13.0427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3679

Saving model as e126_model.pt & e126_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999921655182562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 13.1876	Cost: 22.15s
Train Epoch: 127 [20480/90000 (23%)]	Loss: 12.9240	Cost: 6.42s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 13.0100	Cost: 6.50s
Train Epoch: 127 [61440/90000 (68%)]	Loss: 13.0823	Cost: 6.13s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 13.0778	Cost: 9.70s
Train Epoch: 127 	Average Loss: 13.0188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3723

Learning rate: 0.0001999992040668089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 12.9328	Cost: 23.07s
Train Epoch: 128 [20480/90000 (23%)]	Loss: 13.0331	Cost: 6.21s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 13.0016	Cost: 12.06s
Train Epoch: 128 [61440/90000 (68%)]	Loss: 13.1343	Cost: 12.07s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 13.0854	Cost: 11.83s
Train Epoch: 128 	Average Loss: 13.0222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3268

Saving model as e128_model.pt & e128_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999919148309698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 12.9592	Cost: 22.28s
Train Epoch: 129 [20480/90000 (23%)]	Loss: 12.9971	Cost: 6.41s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 12.9981	Cost: 8.32s
Train Epoch: 129 [61440/90000 (68%)]	Loss: 12.9400	Cost: 8.88s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 13.0801	Cost: 13.32s
Train Epoch: 129 	Average Loss: 12.9901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3508

Learning rate: 0.00019999917880068977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 13.1022	Cost: 27.93s
Train Epoch: 130 [20480/90000 (23%)]	Loss: 12.9208	Cost: 12.33s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 12.9213	Cost: 12.19s
Train Epoch: 130 [61440/90000 (68%)]	Loss: 12.9462	Cost: 11.89s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 13.0333	Cost: 11.87s
Train Epoch: 130 	Average Loss: 13.0031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3384

Learning rate: 0.00019999916601958734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 12.9441	Cost: 28.01s
Train Epoch: 131 [20480/90000 (23%)]	Loss: 12.8492	Cost: 12.15s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 13.0162	Cost: 12.16s
Train Epoch: 131 [61440/90000 (68%)]	Loss: 12.9939	Cost: 11.78s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 13.1542	Cost: 7.51s
Train Epoch: 131 	Average Loss: 12.9722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3180

Saving model as e131_model.pt & e131_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999915313978966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 13.1860	Cost: 21.84s
Train Epoch: 132 [20480/90000 (23%)]	Loss: 12.9248	Cost: 6.23s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 13.0192	Cost: 9.90s
Train Epoch: 132 [61440/90000 (68%)]	Loss: 13.0071	Cost: 12.18s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 13.0178	Cost: 11.99s
Train Epoch: 132 	Average Loss: 12.9550
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2791

Saving model as e132_model.pt & e132_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999914016129682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 13.1076	Cost: 22.45s
Train Epoch: 133 [20480/90000 (23%)]	Loss: 13.0511	Cost: 6.29s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 13.0021	Cost: 6.53s
Train Epoch: 133 [61440/90000 (68%)]	Loss: 13.0574	Cost: 6.24s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 12.8934	Cost: 6.28s
Train Epoch: 133 	Average Loss: 12.9353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2876

Learning rate: 0.00019999912708410875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 13.0191	Cost: 21.70s
Train Epoch: 134 [20480/90000 (23%)]	Loss: 12.9550	Cost: 6.42s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 12.9084	Cost: 11.47s
Train Epoch: 134 [61440/90000 (68%)]	Loss: 12.9040	Cost: 12.18s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 12.8488	Cost: 11.93s
Train Epoch: 134 	Average Loss: 12.8999
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1791

Saving model as e134_model.pt & e134_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999911390822548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 13.0012	Cost: 22.05s
Train Epoch: 135 [20480/90000 (23%)]	Loss: 12.9179	Cost: 6.28s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 12.7677	Cost: 7.82s
Train Epoch: 135 [61440/90000 (68%)]	Loss: 12.9902	Cost: 8.83s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 12.8569	Cost: 13.09s
Train Epoch: 135 	Average Loss: 12.8971
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2288

Learning rate: 0.00019999910063364705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 13.0954	Cost: 37.07s
Train Epoch: 136 [20480/90000 (23%)]	Loss: 13.0093	Cost: 11.91s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 12.9583	Cost: 12.25s
Train Epoch: 136 [61440/90000 (68%)]	Loss: 12.9358	Cost: 11.86s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 12.8906	Cost: 9.79s
Train Epoch: 136 	Average Loss: 12.8894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2052

Learning rate: 0.00019999908726037348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 12.9935	Cost: 32.36s
Train Epoch: 137 [20480/90000 (23%)]	Loss: 12.9912	Cost: 10.08s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 12.9516	Cost: 7.42s
Train Epoch: 137 [61440/90000 (68%)]	Loss: 13.0219	Cost: 6.35s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 12.8916	Cost: 9.49s
Train Epoch: 137 	Average Loss: 12.8903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2640

Learning rate: 0.00019999907378840477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 12.9138	Cost: 23.58s
Train Epoch: 138 [20480/90000 (23%)]	Loss: 12.8642	Cost: 6.28s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 12.8307	Cost: 6.73s
Train Epoch: 138 [61440/90000 (68%)]	Loss: 12.8637	Cost: 6.22s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 12.9085	Cost: 6.09s
Train Epoch: 138 	Average Loss: 12.8441
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2869

Learning rate: 0.00019999906021774094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 12.8592	Cost: 22.07s
Train Epoch: 139 [20480/90000 (23%)]	Loss: 12.9109	Cost: 6.23s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 12.7482	Cost: 7.64s
Train Epoch: 139 [61440/90000 (68%)]	Loss: 12.8316	Cost: 6.30s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 12.9167	Cost: 15.49s
Train Epoch: 139 	Average Loss: 12.8223
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1587

Saving model as e139_model.pt & e139_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999904654838195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 12.8502	Cost: 26.50s
Train Epoch: 140 [20480/90000 (23%)]	Loss: 12.8806	Cost: 6.33s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 12.6531	Cost: 6.56s
Train Epoch: 140 [61440/90000 (68%)]	Loss: 12.8189	Cost: 6.21s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 12.8558	Cost: 18.00s
Train Epoch: 140 	Average Loss: 12.7999
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0994

Saving model as e140_model.pt & e140_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999990327803279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 12.9153	Cost: 23.34s
Train Epoch: 141 [20480/90000 (23%)]	Loss: 12.8445	Cost: 6.39s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 12.7667	Cost: 6.70s
Train Epoch: 141 [61440/90000 (68%)]	Loss: 12.8783	Cost: 6.14s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 12.6952	Cost: 6.38s
Train Epoch: 141 	Average Loss: 12.7795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1120

Learning rate: 0.00019999901891357876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 12.7622	Cost: 22.39s
Train Epoch: 142 [20480/90000 (23%)]	Loss: 12.6715	Cost: 6.20s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 12.7267	Cost: 7.36s
Train Epoch: 142 [61440/90000 (68%)]	Loss: 12.6767	Cost: 9.35s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 12.8191	Cost: 12.16s
Train Epoch: 142 	Average Loss: 12.7518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1412

Learning rate: 0.0001999990049481345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 12.8346	Cost: 27.33s
Train Epoch: 143 [20480/90000 (23%)]	Loss: 12.8257	Cost: 12.07s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 12.7507	Cost: 12.10s
Train Epoch: 143 [61440/90000 (68%)]	Loss: 12.8449	Cost: 11.91s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 12.8436	Cost: 9.87s
Train Epoch: 143 	Average Loss: 12.7799
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1266

Learning rate: 0.00019999899088399522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 12.9163	Cost: 29.25s
Train Epoch: 144 [20480/90000 (23%)]	Loss: 12.9008	Cost: 11.77s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 12.6055	Cost: 11.92s
Train Epoch: 144 [61440/90000 (68%)]	Loss: 12.6472	Cost: 10.43s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 12.9290	Cost: 5.83s
Train Epoch: 144 	Average Loss: 12.7433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1205

Learning rate: 0.0001999989767211609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 12.7245	Cost: 26.10s
Train Epoch: 145 [20480/90000 (23%)]	Loss: 12.8224	Cost: 11.98s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 12.7322	Cost: 6.95s
Train Epoch: 145 [61440/90000 (68%)]	Loss: 12.7986	Cost: 5.84s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 12.8627	Cost: 6.77s
Train Epoch: 145 	Average Loss: 12.7396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0821

Saving model as e145_model.pt & e145_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999896245963153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 12.6653	Cost: 30.18s
Train Epoch: 146 [20480/90000 (23%)]	Loss: 12.9846	Cost: 11.58s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 12.7366	Cost: 11.14s
Train Epoch: 146 [61440/90000 (68%)]	Loss: 12.8057	Cost: 5.82s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 12.6931	Cost: 6.57s
Train Epoch: 146 	Average Loss: 12.7250
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0573

Saving model as e146_model.pt & e146_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999894809940715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 12.7010	Cost: 25.40s
Train Epoch: 147 [20480/90000 (23%)]	Loss: 12.8457	Cost: 11.22s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 12.6125	Cost: 12.15s
Train Epoch: 147 [61440/90000 (68%)]	Loss: 12.7424	Cost: 11.80s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 12.6664	Cost: 11.82s
Train Epoch: 147 	Average Loss: 12.6704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0718

Learning rate: 0.00019999893364048776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 12.6688	Cost: 29.31s
Train Epoch: 148 [20480/90000 (23%)]	Loss: 12.7054	Cost: 11.61s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 12.7453	Cost: 12.06s
Train Epoch: 148 [61440/90000 (68%)]	Loss: 12.7486	Cost: 11.79s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 12.8136	Cost: 6.23s
Train Epoch: 148 	Average Loss: 12.6733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0090

Saving model as e148_model.pt & e148_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999891908287334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 12.6996	Cost: 23.84s
Train Epoch: 149 [20480/90000 (23%)]	Loss: 12.7499	Cost: 6.26s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 12.7830	Cost: 12.24s
Train Epoch: 149 [61440/90000 (68%)]	Loss: 12.6179	Cost: 11.92s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 12.6423	Cost: 11.83s
Train Epoch: 149 	Average Loss: 12.6750
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9769

Saving model as e149_model.pt & e149_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999890442656397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 12.4762	Cost: 22.10s
Train Epoch: 150 [20480/90000 (23%)]	Loss: 12.7070	Cost: 6.22s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 12.6154	Cost: 10.96s
Train Epoch: 150 [61440/90000 (68%)]	Loss: 12.5873	Cost: 12.11s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 12.6983	Cost: 12.29s
Train Epoch: 150 	Average Loss: 12.6483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9580

Saving model as e150_model.pt & e150_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999888967155965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 12.6665	Cost: 22.65s
Train Epoch: 151 [20480/90000 (23%)]	Loss: 12.5410	Cost: 6.26s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 12.7407	Cost: 7.09s
Train Epoch: 151 [61440/90000 (68%)]	Loss: 12.6472	Cost: 6.29s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 12.6808	Cost: 16.59s
Train Epoch: 151 	Average Loss: 12.6166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0265

Learning rate: 0.00019999887481786036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 12.7496	Cost: 24.00s
Train Epoch: 152 [20480/90000 (23%)]	Loss: 12.6873	Cost: 11.14s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 12.5887	Cost: 12.17s
Train Epoch: 152 [61440/90000 (68%)]	Loss: 12.5565	Cost: 11.83s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 12.7462	Cost: 11.53s
Train Epoch: 152 	Average Loss: 12.6175
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9952

Learning rate: 0.00019999885986546616
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 12.6875	Cost: 33.87s
Train Epoch: 153 [20480/90000 (23%)]	Loss: 12.8000	Cost: 12.17s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 12.6123	Cost: 12.21s
Train Epoch: 153 [61440/90000 (68%)]	Loss: 12.6236	Cost: 8.33s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 12.6109	Cost: 6.08s
Train Epoch: 153 	Average Loss: 12.5907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9414

Saving model as e153_model.pt & e153_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999884481437704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 12.6638	Cost: 27.77s
Train Epoch: 154 [20480/90000 (23%)]	Loss: 12.6051	Cost: 11.97s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 12.6940	Cost: 12.10s
Train Epoch: 154 [61440/90000 (68%)]	Loss: 12.6313	Cost: 11.80s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 12.6217	Cost: 7.97s
Train Epoch: 154 	Average Loss: 12.5986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9874

Learning rate: 0.000199998829664593
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 12.4374	Cost: 27.11s
Train Epoch: 155 [20480/90000 (23%)]	Loss: 12.7290	Cost: 11.63s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 12.6762	Cost: 7.60s
Train Epoch: 155 [61440/90000 (68%)]	Loss: 12.6250	Cost: 5.87s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 12.5457	Cost: 6.75s
Train Epoch: 155 	Average Loss: 12.5769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8992

Saving model as e155_model.pt & e155_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999881441611406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 12.4587	Cost: 27.48s
Train Epoch: 156 [20480/90000 (23%)]	Loss: 12.6980	Cost: 11.84s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 12.6082	Cost: 12.18s
Train Epoch: 156 [61440/90000 (68%)]	Loss: 12.5405	Cost: 6.39s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 12.5467	Cost: 5.99s
Train Epoch: 156 	Average Loss: 12.5675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8816

Saving model as e156_model.pt & e156_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999879906894028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 12.6321	Cost: 27.78s
Train Epoch: 157 [20480/90000 (23%)]	Loss: 12.6796	Cost: 12.14s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 12.5940	Cost: 12.17s
Train Epoch: 157 [61440/90000 (68%)]	Loss: 12.5753	Cost: 11.84s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 12.4148	Cost: 11.90s
Train Epoch: 157 	Average Loss: 12.5172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8288

Saving model as e157_model.pt & e157_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999878362307163
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 12.5653	Cost: 24.45s
Train Epoch: 158 [20480/90000 (23%)]	Loss: 12.6554	Cost: 8.10s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 12.6016	Cost: 12.23s
Train Epoch: 158 [61440/90000 (68%)]	Loss: 12.6508	Cost: 12.13s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 12.5486	Cost: 12.08s
Train Epoch: 158 	Average Loss: 12.5027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9105

Learning rate: 0.0001999987680785081
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 12.4210	Cost: 29.82s
Train Epoch: 159 [20480/90000 (23%)]	Loss: 12.4875	Cost: 12.37s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 12.4743	Cost: 12.27s
Train Epoch: 159 [61440/90000 (68%)]	Loss: 12.5230	Cost: 11.83s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 12.6442	Cost: 11.80s
Train Epoch: 159 	Average Loss: 12.5255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9089

Learning rate: 0.00019999875243524977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 12.5069	Cost: 32.54s
Train Epoch: 160 [20480/90000 (23%)]	Loss: 12.6179	Cost: 11.19s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 12.6295	Cost: 12.39s
Train Epoch: 160 [61440/90000 (68%)]	Loss: 12.5237	Cost: 12.01s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 12.5866	Cost: 6.30s
Train Epoch: 160 	Average Loss: 12.4719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8746

Learning rate: 0.00019999873669329665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 12.4413	Cost: 29.22s
Train Epoch: 161 [20480/90000 (23%)]	Loss: 12.5251	Cost: 9.36s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 12.5509	Cost: 6.19s
Train Epoch: 161 [61440/90000 (68%)]	Loss: 12.3393	Cost: 5.98s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 12.5672	Cost: 6.80s
Train Epoch: 161 	Average Loss: 12.4708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8726

Learning rate: 0.0001999987208526487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 12.5553	Cost: 23.90s
Train Epoch: 162 [20480/90000 (23%)]	Loss: 12.6353	Cost: 6.30s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 12.5129	Cost: 7.04s
Train Epoch: 162 [61440/90000 (68%)]	Loss: 12.5695	Cost: 6.20s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 12.5909	Cost: 6.12s
Train Epoch: 162 	Average Loss: 12.4596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8254

Saving model as e162_model.pt & e162_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199998704913306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 12.6307	Cost: 27.23s
Train Epoch: 163 [20480/90000 (23%)]	Loss: 12.6364	Cost: 11.88s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 12.3723	Cost: 11.98s
Train Epoch: 163 [61440/90000 (68%)]	Loss: 12.4229	Cost: 6.80s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 12.5857	Cost: 5.92s
Train Epoch: 163 	Average Loss: 12.4500
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8473

Learning rate: 0.00019999868887526852
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 12.5694	Cost: 25.97s
Train Epoch: 164 [20480/90000 (23%)]	Loss: 12.3679	Cost: 8.11s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 12.5722	Cost: 6.06s
Train Epoch: 164 [61440/90000 (68%)]	Loss: 12.3235	Cost: 6.90s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 12.3158	Cost: 6.07s
Train Epoch: 164 	Average Loss: 12.4296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8816

Learning rate: 0.0001999986727385363
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 12.3933	Cost: 23.72s
Train Epoch: 165 [20480/90000 (23%)]	Loss: 12.6006	Cost: 6.03s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 12.5292	Cost: 7.20s
Train Epoch: 165 [61440/90000 (68%)]	Loss: 12.4561	Cost: 6.22s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 12.4381	Cost: 6.09s
Train Epoch: 165 	Average Loss: 12.4352
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7280

Saving model as e165_model.pt & e165_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999986565031093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 12.4181	Cost: 28.60s
Train Epoch: 166 [20480/90000 (23%)]	Loss: 12.4628	Cost: 12.20s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 12.6053	Cost: 7.11s
Train Epoch: 166 [61440/90000 (68%)]	Loss: 12.4195	Cost: 5.82s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 12.3796	Cost: 6.64s
Train Epoch: 166 	Average Loss: 12.3907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7851

Learning rate: 0.00019999864016898762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 12.3972	Cost: 24.07s
Train Epoch: 167 [20480/90000 (23%)]	Loss: 12.4409	Cost: 6.06s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 12.3516	Cost: 8.11s
Train Epoch: 167 [61440/90000 (68%)]	Loss: 12.5276	Cost: 6.17s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 12.4831	Cost: 6.04s
Train Epoch: 167 	Average Loss: 12.4014
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7517

Learning rate: 0.00019999862373617122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 12.3509	Cost: 22.34s
Train Epoch: 168 [20480/90000 (23%)]	Loss: 12.5121	Cost: 6.22s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 12.3659	Cost: 6.96s
Train Epoch: 168 [61440/90000 (68%)]	Loss: 12.4393	Cost: 6.21s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 12.4662	Cost: 14.69s
Train Epoch: 168 	Average Loss: 12.3876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6841

Saving model as e168_model.pt & e168_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999860720466015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 12.4088	Cost: 23.15s
Train Epoch: 169 [20480/90000 (23%)]	Loss: 12.4274	Cost: 6.36s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 12.4814	Cost: 6.45s
Train Epoch: 169 [61440/90000 (68%)]	Loss: 12.2970	Cost: 6.15s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 12.3448	Cost: 6.35s
Train Epoch: 169 	Average Loss: 12.3434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7250

Learning rate: 0.0001999985905744544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 12.3554	Cost: 25.31s
Train Epoch: 170 [20480/90000 (23%)]	Loss: 12.3934	Cost: 6.19s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 12.2648	Cost: 11.44s
Train Epoch: 170 [61440/90000 (68%)]	Loss: 12.3102	Cost: 12.30s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 12.4332	Cost: 11.96s
Train Epoch: 170 	Average Loss: 12.3554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6509

Saving model as e170_model.pt & e170_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199998573845554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 12.3730	Cost: 21.89s
Train Epoch: 171 [20480/90000 (23%)]	Loss: 12.2963	Cost: 6.22s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 12.3763	Cost: 7.33s
Train Epoch: 171 [61440/90000 (68%)]	Loss: 12.4497	Cost: 6.35s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 12.5710	Cost: 16.24s
Train Epoch: 171 	Average Loss: 12.3512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6844

Learning rate: 0.00019999855701795897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 12.4879	Cost: 26.01s
Train Epoch: 172 [20480/90000 (23%)]	Loss: 12.3938	Cost: 11.70s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 12.1534	Cost: 12.77s
Train Epoch: 172 [61440/90000 (68%)]	Loss: 12.2677	Cost: 12.25s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 12.2453	Cost: 12.15s
Train Epoch: 172 	Average Loss: 12.3186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6922

Learning rate: 0.00019999854009166934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 12.3594	Cost: 27.34s
Train Epoch: 173 [20480/90000 (23%)]	Loss: 12.4975	Cost: 11.77s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 12.2200	Cost: 11.98s
Train Epoch: 173 [61440/90000 (68%)]	Loss: 12.3049	Cost: 8.05s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 12.3168	Cost: 5.79s
Train Epoch: 173 	Average Loss: 12.2963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6585

Learning rate: 0.00019999852306668508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 12.5089	Cost: 26.79s
Train Epoch: 174 [20480/90000 (23%)]	Loss: 12.3352	Cost: 7.19s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 12.2198	Cost: 6.25s
Train Epoch: 174 [61440/90000 (68%)]	Loss: 12.2280	Cost: 7.01s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 12.2893	Cost: 6.09s
Train Epoch: 174 	Average Loss: 12.2812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7668

Learning rate: 0.00019999850594300622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 12.4403	Cost: 24.29s
Train Epoch: 175 [20480/90000 (23%)]	Loss: 12.2127	Cost: 7.05s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 12.2129	Cost: 6.46s
Train Epoch: 175 [61440/90000 (68%)]	Loss: 12.2633	Cost: 5.97s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 12.2340	Cost: 6.29s
Train Epoch: 175 	Average Loss: 12.2632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6219

Saving model as e175_model.pt & e175_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999848872063282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 12.2831	Cost: 26.51s
Train Epoch: 176 [20480/90000 (23%)]	Loss: 12.2681	Cost: 10.23s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 12.2634	Cost: 6.25s
Train Epoch: 176 [61440/90000 (68%)]	Loss: 12.4212	Cost: 6.42s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 12.2469	Cost: 6.33s
Train Epoch: 176 	Average Loss: 12.2724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6165

Saving model as e176_model.pt & e176_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999847139956484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 12.2078	Cost: 27.15s
Train Epoch: 177 [20480/90000 (23%)]	Loss: 12.4380	Cost: 12.06s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 12.2372	Cost: 12.15s
Train Epoch: 177 [61440/90000 (68%)]	Loss: 12.2748	Cost: 11.79s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 12.2572	Cost: 11.77s
Train Epoch: 177 	Average Loss: 12.2487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6002

Saving model as e177_model.pt & e177_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999845397980232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 12.4731	Cost: 21.98s
Train Epoch: 178 [20480/90000 (23%)]	Loss: 12.3189	Cost: 6.58s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 12.2271	Cost: 7.88s
Train Epoch: 178 [61440/90000 (68%)]	Loss: 12.3799	Cost: 8.61s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 12.3219	Cost: 13.46s
Train Epoch: 178 	Average Loss: 12.2656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5363

Saving model as e178_model.pt & e178_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999843646134532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 12.2063	Cost: 22.25s
Train Epoch: 179 [20480/90000 (23%)]	Loss: 12.3914	Cost: 6.30s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 12.1427	Cost: 6.57s
Train Epoch: 179 [61440/90000 (68%)]	Loss: 12.2777	Cost: 6.14s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 12.2602	Cost: 6.39s
Train Epoch: 179 	Average Loss: 12.2054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5967

Learning rate: 0.00019999841884419376
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 12.1444	Cost: 22.43s
Train Epoch: 180 [20480/90000 (23%)]	Loss: 12.3821	Cost: 6.71s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 12.1426	Cost: 12.43s
Train Epoch: 180 [61440/90000 (68%)]	Loss: 12.2251	Cost: 11.82s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 12.2493	Cost: 11.91s
Train Epoch: 180 	Average Loss: 12.2030
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6213

Learning rate: 0.00019999840112834775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 12.2377	Cost: 28.35s
Train Epoch: 181 [20480/90000 (23%)]	Loss: 12.2345	Cost: 12.13s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 12.1710	Cost: 12.17s
Train Epoch: 181 [61440/90000 (68%)]	Loss: 12.1300	Cost: 11.79s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 12.2435	Cost: 11.80s
Train Epoch: 181 	Average Loss: 12.1874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5324

Saving model as e181_model.pt & e181_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999838331380727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 12.1540	Cost: 28.66s
Train Epoch: 182 [20480/90000 (23%)]	Loss: 12.2532	Cost: 6.62s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 12.0863	Cost: 13.26s
Train Epoch: 182 [61440/90000 (68%)]	Loss: 12.1831	Cost: 12.24s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 12.1890	Cost: 11.94s
Train Epoch: 182 	Average Loss: 12.1644
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5324

Learning rate: 0.00019999836540057235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 12.3853	Cost: 27.95s
Train Epoch: 183 [20480/90000 (23%)]	Loss: 12.1604	Cost: 11.87s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 12.1749	Cost: 12.04s
Train Epoch: 183 [61440/90000 (68%)]	Loss: 12.0343	Cost: 11.78s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 12.1392	Cost: 8.60s
Train Epoch: 183 	Average Loss: 12.1532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5046

Saving model as e183_model.pt & e183_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199998347388643
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 12.3429	Cost: 25.13s
Train Epoch: 184 [20480/90000 (23%)]	Loss: 12.1286	Cost: 9.08s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 12.1185	Cost: 12.29s
Train Epoch: 184 [61440/90000 (68%)]	Loss: 12.1386	Cost: 12.38s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 12.2497	Cost: 12.09s
Train Epoch: 184 	Average Loss: 12.1568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5296

Learning rate: 0.00019999832927801924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 12.3621	Cost: 32.00s
Train Epoch: 185 [20480/90000 (23%)]	Loss: 11.9638	Cost: 10.56s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 11.9802	Cost: 12.12s
Train Epoch: 185 [61440/90000 (68%)]	Loss: 12.1498	Cost: 11.85s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 12.0363	Cost: 6.24s
Train Epoch: 185 	Average Loss: 12.1051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4542

Saving model as e185_model.pt & e185_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999831106870108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 12.3067	Cost: 24.07s
Train Epoch: 186 [20480/90000 (23%)]	Loss: 12.2430	Cost: 7.02s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 12.1403	Cost: 12.39s
Train Epoch: 186 [61440/90000 (68%)]	Loss: 12.2446	Cost: 12.07s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 12.2391	Cost: 11.84s
Train Epoch: 186 	Average Loss: 12.1348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5262

Learning rate: 0.00019999829276068855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 12.2295	Cost: 50.06s
Train Epoch: 187 [20480/90000 (23%)]	Loss: 12.1251	Cost: 10.12s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 12.0856	Cost: 12.14s
Train Epoch: 187 [61440/90000 (68%)]	Loss: 12.0832	Cost: 11.85s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 12.2248	Cost: 6.88s
Train Epoch: 187 	Average Loss: 12.1202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5334

Learning rate: 0.00019999827435398168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 12.1791	Cost: 28.67s
Train Epoch: 188 [20480/90000 (23%)]	Loss: 12.1441	Cost: 11.88s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 12.1092	Cost: 11.68s
Train Epoch: 188 [61440/90000 (68%)]	Loss: 12.0995	Cost: 5.79s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 12.0717	Cost: 6.27s
Train Epoch: 188 	Average Loss: 12.1055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5240

Learning rate: 0.00019999825584858045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 12.0979	Cost: 38.24s
Train Epoch: 189 [20480/90000 (23%)]	Loss: 12.1121	Cost: 9.37s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 12.2825	Cost: 6.27s
Train Epoch: 189 [61440/90000 (68%)]	Loss: 12.0857	Cost: 6.22s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 12.0764	Cost: 7.86s
Train Epoch: 189 	Average Loss: 12.1081
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5154

Learning rate: 0.00019999823724448486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 12.1276	Cost: 23.56s
Train Epoch: 190 [20480/90000 (23%)]	Loss: 12.0270	Cost: 6.35s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 12.1605	Cost: 6.53s
Train Epoch: 190 [61440/90000 (68%)]	Loss: 12.1276	Cost: 6.54s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 12.1869	Cost: 8.64s
Train Epoch: 190 	Average Loss: 12.0744
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4157

Saving model as e190_model.pt & e190_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.000199998218541695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 12.0902	Cost: 26.64s
Train Epoch: 191 [20480/90000 (23%)]	Loss: 12.0305	Cost: 9.34s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 12.0409	Cost: 6.19s
Train Epoch: 191 [61440/90000 (68%)]	Loss: 12.0480	Cost: 6.65s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 12.0480	Cost: 5.98s
Train Epoch: 191 	Average Loss: 12.0680
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3937

Saving model as e191_model.pt & e191_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999819974021087
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 12.2645	Cost: 27.68s
Train Epoch: 192 [20480/90000 (23%)]	Loss: 12.1340	Cost: 11.89s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 11.9563	Cost: 12.13s
Train Epoch: 192 [61440/90000 (68%)]	Loss: 12.1204	Cost: 11.82s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 12.0793	Cost: 11.78s
Train Epoch: 192 	Average Loss: 12.0734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4251

Learning rate: 0.00019999818084003246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 12.1736	Cost: 26.93s
Train Epoch: 193 [20480/90000 (23%)]	Loss: 12.1062	Cost: 11.94s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 12.0381	Cost: 11.97s
Train Epoch: 193 [61440/90000 (68%)]	Loss: 12.0576	Cost: 11.78s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 12.0244	Cost: 7.38s
Train Epoch: 193 	Average Loss: 12.0462
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4780

Learning rate: 0.00019999816184115978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 12.2063	Cost: 26.59s
Train Epoch: 194 [20480/90000 (23%)]	Loss: 12.1906	Cost: 12.17s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 11.8913	Cost: 8.79s
Train Epoch: 194 [61440/90000 (68%)]	Loss: 12.0694	Cost: 5.82s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 11.9823	Cost: 6.91s
Train Epoch: 194 	Average Loss: 12.0242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4122

Learning rate: 0.00019999814274359288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 12.0290	Cost: 25.81s
Train Epoch: 195 [20480/90000 (23%)]	Loss: 11.9549	Cost: 6.45s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 12.0504	Cost: 6.55s
Train Epoch: 195 [61440/90000 (68%)]	Loss: 12.0440	Cost: 6.50s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 12.0863	Cost: 6.16s
Train Epoch: 195 	Average Loss: 12.0250
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3299

Saving model as e195_model.pt & e195_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999812354733177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 12.0100	Cost: 23.22s
Train Epoch: 196 [20480/90000 (23%)]	Loss: 12.1425	Cost: 6.37s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 11.9354	Cost: 6.32s
Train Epoch: 196 [61440/90000 (68%)]	Loss: 11.9919	Cost: 6.52s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 12.1124	Cost: 6.12s
Train Epoch: 196 	Average Loss: 12.0096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4037

Learning rate: 0.00019999810425237646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 12.0986	Cost: 24.11s
Train Epoch: 197 [20480/90000 (23%)]	Loss: 12.0656	Cost: 6.47s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 11.9816	Cost: 13.69s
Train Epoch: 197 [61440/90000 (68%)]	Loss: 12.0554	Cost: 11.95s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 11.8920	Cost: 11.88s
Train Epoch: 197 	Average Loss: 11.9806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4071

Learning rate: 0.00019999808485872698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 12.2306	Cost: 30.21s
Train Epoch: 198 [20480/90000 (23%)]	Loss: 11.9013	Cost: 11.26s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 11.8669	Cost: 12.06s
Train Epoch: 198 [61440/90000 (68%)]	Loss: 12.0448	Cost: 11.72s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 12.0219	Cost: 5.94s
Train Epoch: 198 	Average Loss: 11.9756
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3126

Saving model as e198_model.pt & e198_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999806536638337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 11.9960	Cost: 28.00s
Train Epoch: 199 [20480/90000 (23%)]	Loss: 12.0613	Cost: 11.87s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 11.9663	Cost: 12.16s
Train Epoch: 199 [61440/90000 (68%)]	Loss: 11.9811	Cost: 12.09s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 12.0259	Cost: 12.10s
Train Epoch: 199 	Average Loss: 11.9860
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3401

Learning rate: 0.00019999804577534562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 12.0653	Cost: 33.68s
Train Epoch: 200 [20480/90000 (23%)]	Loss: 12.0340	Cost: 12.06s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 11.9757	Cost: 12.19s
Train Epoch: 200 [61440/90000 (68%)]	Loss: 11.9379	Cost: 8.04s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 12.0212	Cost: 5.85s
Train Epoch: 200 	Average Loss: 11.9552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3134

Learning rate: 0.00019999802608561374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 11.8587	Cost: 28.89s
Train Epoch: 201 [20480/90000 (23%)]	Loss: 12.0047	Cost: 11.87s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 11.9883	Cost: 6.52s
Train Epoch: 201 [61440/90000 (68%)]	Loss: 12.0214	Cost: 6.04s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 11.7463	Cost: 7.06s
Train Epoch: 201 	Average Loss: 11.9376
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3405

Learning rate: 0.00019999800629718777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 12.0169	Cost: 36.80s
Train Epoch: 202 [20480/90000 (23%)]	Loss: 12.0293	Cost: 12.06s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 11.8858	Cost: 6.46s
Train Epoch: 202 [61440/90000 (68%)]	Loss: 11.8791	Cost: 5.96s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 11.9160	Cost: 6.73s
Train Epoch: 202 	Average Loss: 11.9264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3565

Learning rate: 0.00019999798641006774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 12.0327	Cost: 23.42s
Train Epoch: 203 [20480/90000 (23%)]	Loss: 12.0264	Cost: 6.34s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 11.9040	Cost: 7.46s
Train Epoch: 203 [61440/90000 (68%)]	Loss: 12.1158	Cost: 6.05s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 11.9795	Cost: 6.08s
Train Epoch: 203 	Average Loss: 11.9141
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3022

Saving model as e203_model.pt & e203_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999796642425366
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 12.1972	Cost: 29.87s
Train Epoch: 204 [20480/90000 (23%)]	Loss: 12.0687	Cost: 9.55s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 11.8648	Cost: 12.17s
Train Epoch: 204 [61440/90000 (68%)]	Loss: 11.9640	Cost: 11.82s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 11.9190	Cost: 7.43s
Train Epoch: 204 	Average Loss: 11.9211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2095

Saving model as e204_model.pt & e204_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999794633974552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 11.8996	Cost: 26.27s
Train Epoch: 205 [20480/90000 (23%)]	Loss: 12.0874	Cost: 10.23s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 11.9397	Cost: 12.23s
Train Epoch: 205 [61440/90000 (68%)]	Loss: 11.9383	Cost: 12.00s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 12.1943	Cost: 12.13s
Train Epoch: 205 	Average Loss: 11.9002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2706

Learning rate: 0.00019999792615654335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 11.8768	Cost: 31.69s
Train Epoch: 206 [20480/90000 (23%)]	Loss: 11.9649	Cost: 12.23s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 11.7472	Cost: 11.86s
Train Epoch: 206 [61440/90000 (68%)]	Loss: 11.9655	Cost: 5.90s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 11.8551	Cost: 5.86s
Train Epoch: 206 	Average Loss: 11.8630
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2906

Learning rate: 0.00019999790587464718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 11.7558	Cost: 26.14s
Train Epoch: 207 [20480/90000 (23%)]	Loss: 11.9092	Cost: 8.80s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 12.0264	Cost: 6.20s
Train Epoch: 207 [61440/90000 (68%)]	Loss: 11.8968	Cost: 7.00s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 11.9128	Cost: 6.44s
Train Epoch: 207 	Average Loss: 11.8679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3456

Learning rate: 0.00019999788549405706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 11.9249	Cost: 23.11s
Train Epoch: 208 [20480/90000 (23%)]	Loss: 12.0132	Cost: 6.32s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 11.8779	Cost: 6.46s
Train Epoch: 208 [61440/90000 (68%)]	Loss: 11.8708	Cost: 6.27s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 11.9483	Cost: 6.38s
Train Epoch: 208 	Average Loss: 11.8486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2969

Learning rate: 0.00019999786501477296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 11.8676	Cost: 23.66s
Train Epoch: 209 [20480/90000 (23%)]	Loss: 11.8225	Cost: 6.42s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 11.8506	Cost: 11.71s
Train Epoch: 209 [61440/90000 (68%)]	Loss: 11.7780	Cost: 11.90s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 11.9240	Cost: 11.90s
Train Epoch: 209 	Average Loss: 11.8582
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2617

Learning rate: 0.00019999784443679492
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 11.9098	Cost: 28.71s
Train Epoch: 210 [20480/90000 (23%)]	Loss: 11.8883	Cost: 12.38s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 11.8238	Cost: 12.06s
Train Epoch: 210 [61440/90000 (68%)]	Loss: 11.8863	Cost: 11.99s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 11.7910	Cost: 7.64s
Train Epoch: 210 	Average Loss: 11.8004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2424

Learning rate: 0.000199997823760123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 11.8576	Cost: 25.82s
Train Epoch: 211 [20480/90000 (23%)]	Loss: 11.7999	Cost: 6.06s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 11.7732	Cost: 7.43s
Train Epoch: 211 [61440/90000 (68%)]	Loss: 11.8723	Cost: 6.27s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 12.1326	Cost: 7.17s
Train Epoch: 211 	Average Loss: 11.8454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2742

Learning rate: 0.00019999780298475715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 11.8626	Cost: 28.77s
Train Epoch: 212 [20480/90000 (23%)]	Loss: 11.8906	Cost: 6.55s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 11.8199	Cost: 14.75s
Train Epoch: 212 [61440/90000 (68%)]	Loss: 11.9030	Cost: 12.19s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 11.8887	Cost: 11.95s
Train Epoch: 212 	Average Loss: 11.8517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2812

Learning rate: 0.00019999778211069746
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 11.7277	Cost: 26.70s
Train Epoch: 213 [20480/90000 (23%)]	Loss: 11.9358	Cost: 12.19s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 11.8377	Cost: 12.03s
Train Epoch: 213 [61440/90000 (68%)]	Loss: 11.8093	Cost: 11.80s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 11.9105	Cost: 6.81s
Train Epoch: 213 	Average Loss: 11.7875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1280

Saving model as e213_model.pt & e213_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999977611379439
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 11.8023	Cost: 27.36s
Train Epoch: 214 [20480/90000 (23%)]	Loss: 11.9176	Cost: 12.05s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 11.7461	Cost: 12.18s
Train Epoch: 214 [61440/90000 (68%)]	Loss: 11.7528	Cost: 12.17s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 11.8232	Cost: 10.32s
Train Epoch: 214 	Average Loss: 11.8111
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1628

Learning rate: 0.00019999774006649652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 11.9481	Cost: 27.58s
Train Epoch: 215 [20480/90000 (23%)]	Loss: 11.8240	Cost: 12.09s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 11.8841	Cost: 11.49s
Train Epoch: 215 [61440/90000 (68%)]	Loss: 11.9337	Cost: 6.09s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 11.8895	Cost: 6.05s
Train Epoch: 215 	Average Loss: 11.8051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2432

Learning rate: 0.00019999771889635528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 11.9047	Cost: 27.75s
Train Epoch: 216 [20480/90000 (23%)]	Loss: 11.8618	Cost: 11.38s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 11.7532	Cost: 6.12s
Train Epoch: 216 [61440/90000 (68%)]	Loss: 11.8640	Cost: 5.94s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 11.9934	Cost: 6.86s
Train Epoch: 216 	Average Loss: 11.7829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2089

Learning rate: 0.00019999769762752028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 12.0510	Cost: 24.36s
Train Epoch: 217 [20480/90000 (23%)]	Loss: 11.8203	Cost: 6.13s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 11.7725	Cost: 7.23s
Train Epoch: 217 [61440/90000 (68%)]	Loss: 11.8492	Cost: 7.01s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 11.7511	Cost: 8.82s
Train Epoch: 217 	Average Loss: 11.7521
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1415

Learning rate: 0.00019999767625999152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 11.8421	Cost: 23.23s
Train Epoch: 218 [20480/90000 (23%)]	Loss: 11.8533	Cost: 6.48s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 11.8063	Cost: 6.90s
Train Epoch: 218 [61440/90000 (68%)]	Loss: 11.9711	Cost: 6.80s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 11.7615	Cost: 15.87s
Train Epoch: 218 	Average Loss: 11.7658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1652

Learning rate: 0.00019999765479376897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 11.9705	Cost: 30.71s
Train Epoch: 219 [20480/90000 (23%)]	Loss: 11.9377	Cost: 11.80s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 11.7728	Cost: 12.07s
Train Epoch: 219 [61440/90000 (68%)]	Loss: 11.8466	Cost: 8.75s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 11.8773	Cost: 5.91s
Train Epoch: 219 	Average Loss: 11.7803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1494

Learning rate: 0.00019999763322885272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 11.8059	Cost: 26.61s
Train Epoch: 220 [20480/90000 (23%)]	Loss: 11.7446	Cost: 6.10s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 11.6531	Cost: 10.78s
Train Epoch: 220 [61440/90000 (68%)]	Loss: 11.7613	Cost: 6.66s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 11.6018	Cost: 8.79s
Train Epoch: 220 	Average Loss: 11.7052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1810

Learning rate: 0.00019999761156524275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 11.7765	Cost: 22.06s
Train Epoch: 221 [20480/90000 (23%)]	Loss: 11.9418	Cost: 6.26s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 11.6515	Cost: 6.64s
Train Epoch: 221 [61440/90000 (68%)]	Loss: 11.6922	Cost: 6.59s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 11.7216	Cost: 15.53s
Train Epoch: 221 	Average Loss: 11.7183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1721

Learning rate: 0.0001999975898029391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 11.9184	Cost: 31.16s
Train Epoch: 222 [20480/90000 (23%)]	Loss: 11.7537	Cost: 11.22s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 11.8206	Cost: 12.08s
Train Epoch: 222 [61440/90000 (68%)]	Loss: 11.7720	Cost: 11.75s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 11.6235	Cost: 6.11s
Train Epoch: 222 	Average Loss: 11.7320
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0670

Saving model as e222_model.pt & e222_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999756794194176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 11.7717	Cost: 28.44s
Train Epoch: 223 [20480/90000 (23%)]	Loss: 11.8192	Cost: 12.31s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 11.5769	Cost: 12.07s
Train Epoch: 223 [61440/90000 (68%)]	Loss: 11.7128	Cost: 11.86s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 11.7083	Cost: 9.85s
Train Epoch: 223 	Average Loss: 11.7066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0330

Saving model as e223_model.pt & e223_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999975459822508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 11.8607	Cost: 22.54s
Train Epoch: 224 [20480/90000 (23%)]	Loss: 11.7614	Cost: 6.20s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 11.7681	Cost: 14.89s
Train Epoch: 224 [61440/90000 (68%)]	Loss: 11.8769	Cost: 12.14s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 11.6859	Cost: 11.84s
Train Epoch: 224 	Average Loss: 11.6958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0912

Learning rate: 0.0001999975239238662
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 11.7691	Cost: 31.81s
Train Epoch: 225 [20480/90000 (23%)]	Loss: 11.7038	Cost: 11.47s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 11.7882	Cost: 13.28s
Train Epoch: 225 [61440/90000 (68%)]	Loss: 11.6452	Cost: 12.11s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 11.6454	Cost: 11.76s
Train Epoch: 225 	Average Loss: 11.6645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1181

Learning rate: 0.000199997501766788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 11.7595	Cost: 27.29s
Train Epoch: 226 [20480/90000 (23%)]	Loss: 11.8315	Cost: 8.81s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 11.7053	Cost: 6.36s
Train Epoch: 226 [61440/90000 (68%)]	Loss: 11.7267	Cost: 6.10s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 11.7965	Cost: 7.84s
Train Epoch: 226 	Average Loss: 11.6435
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0956

Learning rate: 0.00019999747951101625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 11.8285	Cost: 23.65s
Train Epoch: 227 [20480/90000 (23%)]	Loss: 11.8315	Cost: 6.26s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 11.7101	Cost: 6.48s
Train Epoch: 227 [61440/90000 (68%)]	Loss: 11.6472	Cost: 6.26s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 11.7051	Cost: 5.97s
Train Epoch: 227 	Average Loss: 11.6815
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0209

Saving model as e227_model.pt & e227_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999974571565509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 11.6585	Cost: 23.01s
Train Epoch: 228 [20480/90000 (23%)]	Loss: 11.6792	Cost: 7.20s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 11.6521	Cost: 6.44s
Train Epoch: 228 [61440/90000 (68%)]	Loss: 11.5668	Cost: 6.13s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 11.6378	Cost: 5.93s
Train Epoch: 228 	Average Loss: 11.6395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0551

Learning rate: 0.00019999743470339206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 12.0169	Cost: 28.45s
Train Epoch: 229 [20480/90000 (23%)]	Loss: 11.6960	Cost: 7.64s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 11.4434	Cost: 11.94s
Train Epoch: 229 [61440/90000 (68%)]	Loss: 11.5828	Cost: 11.81s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 11.5585	Cost: 12.05s
Train Epoch: 229 	Average Loss: 11.6294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0626

Learning rate: 0.0001999974121515397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 11.8496	Cost: 24.28s
Train Epoch: 230 [20480/90000 (23%)]	Loss: 11.8297	Cost: 11.32s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 11.5339	Cost: 12.16s
Train Epoch: 230 [61440/90000 (68%)]	Loss: 11.7137	Cost: 11.81s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 11.5771	Cost: 11.80s
Train Epoch: 230 	Average Loss: 11.6199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1008

Learning rate: 0.00019999738950099387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 11.6995	Cost: 28.08s
Train Epoch: 231 [20480/90000 (23%)]	Loss: 11.7203	Cost: 12.17s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 11.5754	Cost: 12.09s
Train Epoch: 231 [61440/90000 (68%)]	Loss: 11.6739	Cost: 11.80s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 11.6585	Cost: 8.03s
Train Epoch: 231 	Average Loss: 11.6295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0314

Learning rate: 0.00019999736675175452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 11.5473	Cost: 27.03s
Train Epoch: 232 [20480/90000 (23%)]	Loss: 11.8451	Cost: 11.92s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 11.5731	Cost: 12.34s
Train Epoch: 232 [61440/90000 (68%)]	Loss: 11.7380	Cost: 6.38s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 11.7304	Cost: 5.98s
Train Epoch: 232 	Average Loss: 11.6054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9135

Saving model as e232_model.pt & e232_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999734390382178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 11.8105	Cost: 24.95s
Train Epoch: 233 [20480/90000 (23%)]	Loss: 11.7927	Cost: 8.86s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 11.6204	Cost: 12.29s
Train Epoch: 233 [61440/90000 (68%)]	Loss: 11.6278	Cost: 11.93s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 11.8070	Cost: 11.83s
Train Epoch: 233 	Average Loss: 11.6111
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0028

Learning rate: 0.00019999732095719557
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 11.7557	Cost: 31.74s
Train Epoch: 234 [20480/90000 (23%)]	Loss: 11.6439	Cost: 11.24s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 11.5483	Cost: 12.18s
Train Epoch: 234 [61440/90000 (68%)]	Loss: 11.8325	Cost: 11.59s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 11.5117	Cost: 5.81s
Train Epoch: 234 	Average Loss: 11.5849
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9936

Learning rate: 0.00019999729791187596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 11.7102	Cost: 27.22s
Train Epoch: 235 [20480/90000 (23%)]	Loss: 11.5828	Cost: 12.12s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 11.4709	Cost: 7.55s
Train Epoch: 235 [61440/90000 (68%)]	Loss: 11.6231	Cost: 5.82s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 11.7253	Cost: 6.66s
Train Epoch: 235 	Average Loss: 11.6031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0509

Learning rate: 0.000199997274767863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 11.7000	Cost: 23.34s
Train Epoch: 236 [20480/90000 (23%)]	Loss: 11.7874	Cost: 7.25s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 11.6315	Cost: 6.47s
Train Epoch: 236 [61440/90000 (68%)]	Loss: 11.6081	Cost: 6.20s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 11.6640	Cost: 5.93s
Train Epoch: 236 	Average Loss: 11.5961
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0369

Learning rate: 0.0001999972515251567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 11.6253	Cost: 24.91s
Train Epoch: 237 [20480/90000 (23%)]	Loss: 11.5185	Cost: 6.13s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 11.6007	Cost: 7.58s
Train Epoch: 237 [61440/90000 (68%)]	Loss: 11.5878	Cost: 6.19s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 11.7268	Cost: 16.88s
Train Epoch: 237 	Average Loss: 11.5603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9125

Saving model as e237_model.pt & e237_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999722818375706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 11.7010	Cost: 23.81s
Train Epoch: 238 [20480/90000 (23%)]	Loss: 11.6917	Cost: 6.09s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 11.5954	Cost: 7.36s
Train Epoch: 238 [61440/90000 (68%)]	Loss: 11.5908	Cost: 10.09s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 11.6343	Cost: 12.16s
Train Epoch: 238 	Average Loss: 11.5756
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0002

Learning rate: 0.00019999720474366407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 11.8262	Cost: 26.36s
Train Epoch: 239 [20480/90000 (23%)]	Loss: 11.5671	Cost: 12.20s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 11.3526	Cost: 12.13s
Train Epoch: 239 [61440/90000 (68%)]	Loss: 11.3888	Cost: 11.88s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 11.5398	Cost: 11.95s
Train Epoch: 239 	Average Loss: 11.5517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9454

Learning rate: 0.00019999718120487783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 11.4486	Cost: 30.57s
Train Epoch: 240 [20480/90000 (23%)]	Loss: 11.4491	Cost: 12.04s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 11.5152	Cost: 12.23s
Train Epoch: 240 [61440/90000 (68%)]	Loss: 11.6386	Cost: 8.83s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 11.5515	Cost: 6.09s
Train Epoch: 240 	Average Loss: 11.5242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9470

Learning rate: 0.00019999715756739835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 11.6036	Cost: 30.39s
Train Epoch: 241 [20480/90000 (23%)]	Loss: 11.5307	Cost: 11.08s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 11.4274	Cost: 8.20s
Train Epoch: 241 [61440/90000 (68%)]	Loss: 11.5654	Cost: 5.93s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 11.5446	Cost: 6.78s
Train Epoch: 241 	Average Loss: 11.5187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9736

Learning rate: 0.00019999713383122558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 11.7508	Cost: 24.54s
Train Epoch: 242 [20480/90000 (23%)]	Loss: 11.6152	Cost: 6.10s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 11.3459	Cost: 10.70s
Train Epoch: 242 [61440/90000 (68%)]	Loss: 11.5957	Cost: 6.44s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 11.6086	Cost: 9.03s
Train Epoch: 242 	Average Loss: 11.5211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9949

Learning rate: 0.0001999971099963596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 11.7179	Cost: 22.92s
Train Epoch: 243 [20480/90000 (23%)]	Loss: 11.5069	Cost: 6.28s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 11.5139	Cost: 12.75s
Train Epoch: 243 [61440/90000 (68%)]	Loss: 11.6026	Cost: 12.07s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 11.4426	Cost: 11.91s
Train Epoch: 243 	Average Loss: 11.5250
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8851

Saving model as e243_model.pt & e243_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999708606280046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 11.5498	Cost: 25.68s
Train Epoch: 244 [20480/90000 (23%)]	Loss: 11.5761	Cost: 8.10s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 11.3396	Cost: 13.18s
Train Epoch: 244 [61440/90000 (68%)]	Loss: 11.6099	Cost: 12.35s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 11.6727	Cost: 12.18s
Train Epoch: 244 	Average Loss: 11.4936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9380

Learning rate: 0.00019999706203054814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 11.5373	Cost: 28.65s
Train Epoch: 245 [20480/90000 (23%)]	Loss: 11.6245	Cost: 11.32s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 11.5682	Cost: 12.20s
Train Epoch: 245 [61440/90000 (68%)]	Loss: 11.4173	Cost: 11.58s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 11.4342	Cost: 5.92s
Train Epoch: 245 	Average Loss: 11.4904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9315

Learning rate: 0.00019999703789960266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 11.6475	Cost: 34.44s
Train Epoch: 246 [20480/90000 (23%)]	Loss: 11.5746	Cost: 10.57s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 11.5924	Cost: 6.14s
Train Epoch: 246 [61440/90000 (68%)]	Loss: 11.4400	Cost: 6.11s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 11.5192	Cost: 6.66s
Train Epoch: 246 	Average Loss: 11.4970
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9161

Learning rate: 0.00019999701366996408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 11.7829	Cost: 24.70s
Train Epoch: 247 [20480/90000 (23%)]	Loss: 11.5398	Cost: 6.31s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 11.2863	Cost: 7.07s
Train Epoch: 247 [61440/90000 (68%)]	Loss: 11.5430	Cost: 6.14s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 11.3836	Cost: 6.06s
Train Epoch: 247 	Average Loss: 11.4771
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8809

Saving model as e247_model.pt & e247_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999969893416324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 11.7524	Cost: 36.07s
Train Epoch: 248 [20480/90000 (23%)]	Loss: 11.5134	Cost: 11.94s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 11.3738	Cost: 7.02s
Train Epoch: 248 [61440/90000 (68%)]	Loss: 11.5028	Cost: 5.95s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 11.4819	Cost: 6.79s
Train Epoch: 248 	Average Loss: 11.4704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9301

Learning rate: 0.00019999696491460766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 11.5726	Cost: 28.24s
Train Epoch: 249 [20480/90000 (23%)]	Loss: 11.4603	Cost: 11.57s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 11.4016	Cost: 7.57s
Train Epoch: 249 [61440/90000 (68%)]	Loss: 11.4770	Cost: 5.84s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 11.5792	Cost: 6.63s
Train Epoch: 249 	Average Loss: 11.4533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8900

Learning rate: 0.00019999694038888986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 11.5751	Cost: 26.81s
Train Epoch: 250 [20480/90000 (23%)]	Loss: 11.5765	Cost: 8.83s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 11.4006	Cost: 6.22s
Train Epoch: 250 [61440/90000 (68%)]	Loss: 11.5255	Cost: 6.89s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 11.4108	Cost: 6.04s
Train Epoch: 250 	Average Loss: 11.4548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8973

Learning rate: 0.00019999691576447903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 11.3770	Cost: 24.14s
Train Epoch: 251 [20480/90000 (23%)]	Loss: 11.6098	Cost: 6.07s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 11.4561	Cost: 8.21s
Train Epoch: 251 [61440/90000 (68%)]	Loss: 11.3905	Cost: 6.14s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 11.4293	Cost: 6.13s
Train Epoch: 251 	Average Loss: 11.4160
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8149

Saving model as e251_model.pt & e251_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999968910413752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 11.6503	Cost: 28.36s
Train Epoch: 252 [20480/90000 (23%)]	Loss: 11.4903	Cost: 12.43s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 11.5818	Cost: 11.01s
Train Epoch: 252 [61440/90000 (68%)]	Loss: 11.3748	Cost: 5.81s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 11.4495	Cost: 6.20s
Train Epoch: 252 	Average Loss: 11.4204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8694

Learning rate: 0.0001999968662195784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 11.4546	Cost: 31.60s
Train Epoch: 253 [20480/90000 (23%)]	Loss: 11.5141	Cost: 8.52s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 11.4249	Cost: 6.86s
Train Epoch: 253 [61440/90000 (68%)]	Loss: 11.4010	Cost: 6.18s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 11.4199	Cost: 11.06s
Train Epoch: 253 	Average Loss: 11.4176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8879

Learning rate: 0.00019999684129908864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 11.5575	Cost: 23.34s
Train Epoch: 254 [20480/90000 (23%)]	Loss: 11.5549	Cost: 6.24s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 11.4282	Cost: 6.49s
Train Epoch: 254 [61440/90000 (68%)]	Loss: 11.3213	Cost: 6.16s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 11.2884	Cost: 5.94s
Train Epoch: 254 	Average Loss: 11.4244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8429

Learning rate: 0.00019999681627990595
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 11.5772	Cost: 22.80s
Train Epoch: 255 [20480/90000 (23%)]	Loss: 11.5469	Cost: 6.80s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 11.3457	Cost: 7.99s
Train Epoch: 255 [61440/90000 (68%)]	Loss: 11.6466	Cost: 10.08s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 11.4911	Cost: 12.05s
Train Epoch: 255 	Average Loss: 11.4422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8345

Learning rate: 0.00019999679116203034
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 11.5095	Cost: 28.22s
Train Epoch: 256 [20480/90000 (23%)]	Loss: 11.5243	Cost: 12.35s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 11.5169	Cost: 12.15s
Train Epoch: 256 [61440/90000 (68%)]	Loss: 11.4230	Cost: 11.87s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 11.3915	Cost: 10.60s
Train Epoch: 256 	Average Loss: 11.4095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7981

Saving model as e256_model.pt & e256_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999967659454619
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 11.4427	Cost: 32.70s
Train Epoch: 257 [20480/90000 (23%)]	Loss: 11.3189	Cost: 13.02s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 11.3257	Cost: 13.56s
Train Epoch: 257 [61440/90000 (68%)]	Loss: 11.5027	Cost: 11.95s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 11.4558	Cost: 11.95s
Train Epoch: 257 	Average Loss: 11.4060
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8292

Learning rate: 0.00019999674063020056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 11.4361	Cost: 31.43s
Train Epoch: 258 [20480/90000 (23%)]	Loss: 11.4025	Cost: 12.19s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 11.3325	Cost: 11.72s
Train Epoch: 258 [61440/90000 (68%)]	Loss: 11.2971	Cost: 9.18s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 11.2940	Cost: 5.87s
Train Epoch: 258 	Average Loss: 11.3615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7812

Saving model as e258_model.pt & e258_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999671521624642
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 11.4724	Cost: 26.75s
Train Epoch: 259 [20480/90000 (23%)]	Loss: 11.3749	Cost: 10.87s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 11.2531	Cost: 12.03s
Train Epoch: 259 [61440/90000 (68%)]	Loss: 11.3993	Cost: 11.83s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 11.2835	Cost: 11.80s
Train Epoch: 259 	Average Loss: 11.3463
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7172

Saving model as e259_model.pt & e259_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999966897035995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 11.4311	Cost: 22.55s
Train Epoch: 260 [20480/90000 (23%)]	Loss: 11.3739	Cost: 6.20s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 11.2394	Cost: 8.02s
Train Epoch: 260 [61440/90000 (68%)]	Loss: 11.1781	Cost: 7.92s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 11.4154	Cost: 13.85s
Train Epoch: 260 	Average Loss: 11.3350
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8744

Learning rate: 0.00019999666409225978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 11.4498	Cost: 31.39s
Train Epoch: 261 [20480/90000 (23%)]	Loss: 11.4043	Cost: 12.91s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 11.2720	Cost: 12.58s
Train Epoch: 261 [61440/90000 (68%)]	Loss: 11.4477	Cost: 12.13s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 11.3922	Cost: 11.83s
Train Epoch: 261 	Average Loss: 11.3489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7495

Learning rate: 0.00019999663838222732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 11.3245	Cost: 28.20s
Train Epoch: 262 [20480/90000 (23%)]	Loss: 11.4064	Cost: 12.17s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 11.2917	Cost: 8.87s
Train Epoch: 262 [61440/90000 (68%)]	Loss: 11.3775	Cost: 6.10s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 11.3267	Cost: 6.83s
Train Epoch: 262 	Average Loss: 11.3730
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8220

Learning rate: 0.00019999661257350212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 11.3447	Cost: 25.02s
Train Epoch: 263 [20480/90000 (23%)]	Loss: 11.4624	Cost: 6.95s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 11.2562	Cost: 6.48s
Train Epoch: 263 [61440/90000 (68%)]	Loss: 11.2435	Cost: 6.35s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 11.1943	Cost: 7.19s
Train Epoch: 263 	Average Loss: 11.3212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7317

Learning rate: 0.00019999658666608423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 11.5546	Cost: 23.15s
Train Epoch: 264 [20480/90000 (23%)]	Loss: 11.3602	Cost: 6.42s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 11.1821	Cost: 8.28s
Train Epoch: 264 [61440/90000 (68%)]	Loss: 11.3583	Cost: 11.14s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 11.2606	Cost: 12.10s
Train Epoch: 264 	Average Loss: 11.3018
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8162

Learning rate: 0.00019999656065997363
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 11.3460	Cost: 27.85s
Train Epoch: 265 [20480/90000 (23%)]	Loss: 11.5560	Cost: 11.19s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 11.3632	Cost: 12.24s
Train Epoch: 265 [61440/90000 (68%)]	Loss: 11.4299	Cost: 11.88s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 11.3925	Cost: 11.78s
Train Epoch: 265 	Average Loss: 11.3332
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7317

Learning rate: 0.00019999653455517042
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 11.3987	Cost: 39.35s
Train Epoch: 266 [20480/90000 (23%)]	Loss: 11.2848	Cost: 11.23s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 11.3615	Cost: 12.39s
Train Epoch: 266 [61440/90000 (68%)]	Loss: 11.4571	Cost: 11.97s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 11.3432	Cost: 8.06s
Train Epoch: 266 	Average Loss: 11.2988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7111

Saving model as e266_model.pt & e266_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999650835167456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 11.4778	Cost: 22.91s
Train Epoch: 267 [20480/90000 (23%)]	Loss: 11.2716	Cost: 6.43s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 11.3951	Cost: 12.79s
Train Epoch: 267 [61440/90000 (68%)]	Loss: 11.3421	Cost: 12.09s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 11.3524	Cost: 11.85s
Train Epoch: 267 	Average Loss: 11.3182
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7819

Learning rate: 0.00019999648204948613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 11.2114	Cost: 26.83s
Train Epoch: 268 [20480/90000 (23%)]	Loss: 11.3450	Cost: 11.88s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 11.2668	Cost: 12.12s
Train Epoch: 268 [61440/90000 (68%)]	Loss: 11.3638	Cost: 11.78s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 11.3529	Cost: 11.14s
Train Epoch: 268 	Average Loss: 11.2843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6632

Saving model as e268_model.pt & e268_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999964556486051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 11.3514	Cost: 25.48s
Train Epoch: 269 [20480/90000 (23%)]	Loss: 11.3852	Cost: 10.08s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 11.2142	Cost: 12.18s
Train Epoch: 269 [61440/90000 (68%)]	Loss: 11.3219	Cost: 11.86s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 11.4797	Cost: 11.87s
Train Epoch: 269 	Average Loss: 11.2849
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7605

Learning rate: 0.00019999642914903155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 11.3804	Cost: 29.14s
Train Epoch: 270 [20480/90000 (23%)]	Loss: 11.3403	Cost: 12.36s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 11.3205	Cost: 12.24s
Train Epoch: 270 [61440/90000 (68%)]	Loss: 11.5027	Cost: 8.65s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 11.2472	Cost: 5.81s
Train Epoch: 270 	Average Loss: 11.2777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6673

Learning rate: 0.00019999640255076545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 11.0701	Cost: 27.67s
Train Epoch: 271 [20480/90000 (23%)]	Loss: 11.3519	Cost: 12.07s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 11.3872	Cost: 7.16s
Train Epoch: 271 [61440/90000 (68%)]	Loss: 11.3036	Cost: 6.26s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 11.2991	Cost: 6.44s
Train Epoch: 271 	Average Loss: 11.2709
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7402

Learning rate: 0.0001999963758538069
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 11.4382	Cost: 33.40s
Train Epoch: 272 [20480/90000 (23%)]	Loss: 11.2786	Cost: 9.78s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 11.1929	Cost: 10.65s
Train Epoch: 272 [61440/90000 (68%)]	Loss: 11.2976	Cost: 5.85s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 11.3297	Cost: 6.75s
Train Epoch: 272 	Average Loss: 11.2804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6339

Saving model as e272_model.pt & e272_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999634905815583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 11.4781	Cost: 32.18s
Train Epoch: 273 [20480/90000 (23%)]	Loss: 11.4720	Cost: 12.11s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 11.2530	Cost: 11.95s
Train Epoch: 273 [61440/90000 (68%)]	Loss: 11.2456	Cost: 8.75s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 11.3339	Cost: 5.80s
Train Epoch: 273 	Average Loss: 11.2497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6024

Saving model as e273_model.pt & e273_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999632216381234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 11.3866	Cost: 27.43s
Train Epoch: 274 [20480/90000 (23%)]	Loss: 11.4848	Cost: 12.17s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 11.2345	Cost: 12.14s
Train Epoch: 274 [61440/90000 (68%)]	Loss: 11.2221	Cost: 11.80s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 11.2943	Cost: 10.97s
Train Epoch: 274 	Average Loss: 11.2371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7146

Learning rate: 0.00019999629517077644
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 11.1524	Cost: 29.12s
Train Epoch: 275 [20480/90000 (23%)]	Loss: 11.1550	Cost: 10.26s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 11.1924	Cost: 11.97s
Train Epoch: 275 [61440/90000 (68%)]	Loss: 11.2652	Cost: 11.69s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 11.3198	Cost: 6.77s
Train Epoch: 275 	Average Loss: 11.2288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7159

Learning rate: 0.00019999626807904816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 11.2784	Cost: 27.27s
Train Epoch: 276 [20480/90000 (23%)]	Loss: 11.2174	Cost: 10.86s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 11.0935	Cost: 6.10s
Train Epoch: 276 [61440/90000 (68%)]	Loss: 11.3874	Cost: 5.86s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 11.2159	Cost: 6.87s
Train Epoch: 276 	Average Loss: 11.2403
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8147

Learning rate: 0.0001999962408886275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 11.4559	Cost: 24.54s
Train Epoch: 277 [20480/90000 (23%)]	Loss: 11.3510	Cost: 6.47s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 11.1043	Cost: 6.49s
Train Epoch: 277 [61440/90000 (68%)]	Loss: 11.1980	Cost: 6.52s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 11.4061	Cost: 6.51s
Train Epoch: 277 	Average Loss: 11.2311
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6488

Learning rate: 0.00019999621359951451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 11.3617	Cost: 23.86s
Train Epoch: 278 [20480/90000 (23%)]	Loss: 11.2243	Cost: 6.38s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 11.2469	Cost: 13.41s
Train Epoch: 278 [61440/90000 (68%)]	Loss: 11.2850	Cost: 12.09s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 11.3355	Cost: 12.18s
Train Epoch: 278 	Average Loss: 11.2170
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6507

Learning rate: 0.00019999618621170925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 11.3658	Cost: 28.76s
Train Epoch: 279 [20480/90000 (23%)]	Loss: 11.4081	Cost: 12.27s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 11.1660	Cost: 11.85s
Train Epoch: 279 [61440/90000 (68%)]	Loss: 11.2518	Cost: 8.61s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 11.1566	Cost: 5.78s
Train Epoch: 279 	Average Loss: 11.1900
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6670

Learning rate: 0.00019999615872521166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 11.3802	Cost: 29.83s
Train Epoch: 280 [20480/90000 (23%)]	Loss: 11.2599	Cost: 6.08s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 11.2801	Cost: 11.85s
Train Epoch: 280 [61440/90000 (68%)]	Loss: 11.1634	Cost: 6.46s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 11.2423	Cost: 10.52s
Train Epoch: 280 	Average Loss: 11.2011
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5649

Saving model as e280_model.pt & e280_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999613114002183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 11.2996	Cost: 22.30s
Train Epoch: 281 [20480/90000 (23%)]	Loss: 11.2932	Cost: 6.26s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 11.1005	Cost: 6.44s
Train Epoch: 281 [61440/90000 (68%)]	Loss: 11.1480	Cost: 6.18s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 11.3514	Cost: 6.19s
Train Epoch: 281 	Average Loss: 11.1992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6576

Learning rate: 0.0001999961034561398
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 11.2747	Cost: 28.70s
Train Epoch: 282 [20480/90000 (23%)]	Loss: 11.2921	Cost: 13.26s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 11.2115	Cost: 13.94s
Train Epoch: 282 [61440/90000 (68%)]	Loss: 11.2137	Cost: 12.11s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 11.1747	Cost: 11.76s
Train Epoch: 282 	Average Loss: 11.1925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7369

Learning rate: 0.0001999960756735655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 11.2320	Cost: 27.69s
Train Epoch: 283 [20480/90000 (23%)]	Loss: 11.1666	Cost: 12.01s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 10.9068	Cost: 10.53s
Train Epoch: 283 [61440/90000 (68%)]	Loss: 11.1015	Cost: 6.06s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 11.2293	Cost: 6.31s
Train Epoch: 283 	Average Loss: 11.1753
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5573

Saving model as e283_model.pt & e283_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999960477922991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 11.1934	Cost: 26.26s
Train Epoch: 284 [20480/90000 (23%)]	Loss: 11.2849	Cost: 11.86s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 11.1517	Cost: 12.06s
Train Epoch: 284 [61440/90000 (68%)]	Loss: 11.2062	Cost: 11.88s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 11.1931	Cost: 8.24s
Train Epoch: 284 	Average Loss: 11.1566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5848

Learning rate: 0.00019999601981234054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 11.1808	Cost: 27.48s
Train Epoch: 285 [20480/90000 (23%)]	Loss: 11.3497	Cost: 10.85s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 11.2132	Cost: 6.13s
Train Epoch: 285 [61440/90000 (68%)]	Loss: 11.1954	Cost: 5.94s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 11.3381	Cost: 6.83s
Train Epoch: 285 	Average Loss: 11.1424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5692

Learning rate: 0.00019999599173368987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 11.1292	Cost: 25.56s
Train Epoch: 286 [20480/90000 (23%)]	Loss: 11.3845	Cost: 5.94s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 11.0618	Cost: 6.92s
Train Epoch: 286 [61440/90000 (68%)]	Loss: 11.1689	Cost: 6.19s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 11.2309	Cost: 6.12s
Train Epoch: 286 	Average Loss: 11.1386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6374

Learning rate: 0.00019999596355634708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 11.1734	Cost: 22.24s
Train Epoch: 287 [20480/90000 (23%)]	Loss: 11.2364	Cost: 6.36s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 11.0103	Cost: 6.33s
Train Epoch: 287 [61440/90000 (68%)]	Loss: 11.1089	Cost: 6.32s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 11.0956	Cost: 9.47s
Train Epoch: 287 	Average Loss: 11.1384
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5249

Saving model as e287_model.pt & e287_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999593528031228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 11.4144	Cost: 22.87s
Train Epoch: 288 [20480/90000 (23%)]	Loss: 11.3419	Cost: 7.08s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 11.0313	Cost: 6.54s
Train Epoch: 288 [61440/90000 (68%)]	Loss: 11.1300	Cost: 6.17s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 11.4184	Cost: 6.05s
Train Epoch: 288 	Average Loss: 11.1664
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6151

Learning rate: 0.0001999959069055854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 11.3471	Cost: 22.36s
Train Epoch: 289 [20480/90000 (23%)]	Loss: 11.2197	Cost: 6.28s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 11.0439	Cost: 8.02s
Train Epoch: 289 [61440/90000 (68%)]	Loss: 11.3331	Cost: 8.18s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 11.0657	Cost: 14.78s
Train Epoch: 289 	Average Loss: 11.1245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6186

Learning rate: 0.00019999587843216654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 11.1955	Cost: 27.45s
Train Epoch: 290 [20480/90000 (23%)]	Loss: 11.2389	Cost: 11.94s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 11.0988	Cost: 12.23s
Train Epoch: 290 [61440/90000 (68%)]	Loss: 11.1432	Cost: 11.79s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 11.1748	Cost: 11.79s
Train Epoch: 290 	Average Loss: 11.1217
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4796

Saving model as e290_model.pt & e290_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999584986005571
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 11.2926	Cost: 22.88s
Train Epoch: 291 [20480/90000 (23%)]	Loss: 11.3630	Cost: 6.14s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 11.1666	Cost: 11.22s
Train Epoch: 291 [61440/90000 (68%)]	Loss: 11.0592	Cost: 12.13s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 11.1996	Cost: 12.01s
Train Epoch: 291 	Average Loss: 11.1156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5649

Learning rate: 0.00019999582118925292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 11.2295	Cost: 31.65s
Train Epoch: 292 [20480/90000 (23%)]	Loss: 11.1321	Cost: 12.45s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 11.0577	Cost: 12.66s
Train Epoch: 292 [61440/90000 (68%)]	Loss: 11.1608	Cost: 12.17s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 11.0693	Cost: 11.93s
Train Epoch: 292 	Average Loss: 11.1103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4924

Learning rate: 0.00019999579241975824
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 11.0522	Cost: 28.51s
Train Epoch: 293 [20480/90000 (23%)]	Loss: 11.1886	Cost: 11.76s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 11.0241	Cost: 11.98s
Train Epoch: 293 [61440/90000 (68%)]	Loss: 11.2262	Cost: 11.25s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 10.9222	Cost: 6.05s
Train Epoch: 293 	Average Loss: 11.1071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5561

Learning rate: 0.00019999576355157165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 11.2605	Cost: 40.02s
Train Epoch: 294 [20480/90000 (23%)]	Loss: 11.1549	Cost: 11.96s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 11.1077	Cost: 7.87s
Train Epoch: 294 [61440/90000 (68%)]	Loss: 11.2237	Cost: 5.93s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 11.0742	Cost: 6.76s
Train Epoch: 294 	Average Loss: 11.1072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4417

Saving model as e294_model.pt & e294_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999957345846932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 11.2288	Cost: 28.36s
Train Epoch: 295 [20480/90000 (23%)]	Loss: 11.2823	Cost: 11.93s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 11.1301	Cost: 11.93s
Train Epoch: 295 [61440/90000 (68%)]	Loss: 11.0603	Cost: 6.23s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 11.1100	Cost: 6.16s
Train Epoch: 295 	Average Loss: 11.0831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5447

Learning rate: 0.0001999957055191229
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 11.1155	Cost: 27.69s
Train Epoch: 296 [20480/90000 (23%)]	Loss: 11.2063	Cost: 7.70s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 11.1549	Cost: 6.12s
Train Epoch: 296 [61440/90000 (68%)]	Loss: 11.1641	Cost: 6.90s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 11.1774	Cost: 6.01s
Train Epoch: 296 	Average Loss: 11.0941
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5199

Learning rate: 0.0001999956763548608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 11.2076	Cost: 23.63s
Train Epoch: 297 [20480/90000 (23%)]	Loss: 11.3674	Cost: 6.26s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 10.7529	Cost: 6.68s
Train Epoch: 297 [61440/90000 (68%)]	Loss: 11.0539	Cost: 6.18s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 11.1996	Cost: 6.08s
Train Epoch: 297 	Average Loss: 11.0963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5161

Learning rate: 0.00019999564709190693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 11.3682	Cost: 32.53s
Train Epoch: 298 [20480/90000 (23%)]	Loss: 11.1237	Cost: 10.05s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 10.9665	Cost: 12.39s
Train Epoch: 298 [61440/90000 (68%)]	Loss: 11.1407	Cost: 12.10s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 11.2086	Cost: 11.77s
Train Epoch: 298 	Average Loss: 11.0845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5173

Learning rate: 0.00019999561773026132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 11.3837	Cost: 33.00s
Train Epoch: 299 [20480/90000 (23%)]	Loss: 11.1372	Cost: 12.31s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 11.1181	Cost: 10.19s
Train Epoch: 299 [61440/90000 (68%)]	Loss: 11.0992	Cost: 6.18s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 11.1089	Cost: 7.99s
Train Epoch: 299 	Average Loss: 11.0302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4820

Learning rate: 0.00019999558826992397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 11.2454	Cost: 23.96s
Train Epoch: 300 [20480/90000 (23%)]	Loss: 11.1502	Cost: 6.28s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 11.0382	Cost: 7.19s
Train Epoch: 300 [61440/90000 (68%)]	Loss: 11.1865	Cost: 6.42s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 10.9756	Cost: 6.14s
Train Epoch: 300 	Average Loss: 11.0321
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5599

Learning rate: 0.00019999555871089494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 11.1897	Cost: 22.10s
Train Epoch: 301 [20480/90000 (23%)]	Loss: 10.9849	Cost: 6.33s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 10.8839	Cost: 6.51s
Train Epoch: 301 [61440/90000 (68%)]	Loss: 11.1437	Cost: 6.28s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 11.0325	Cost: 6.50s
Train Epoch: 301 	Average Loss: 11.0274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4119

Saving model as e301_model.pt & e301_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999552905317427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 11.2523	Cost: 23.64s
Train Epoch: 302 [20480/90000 (23%)]	Loss: 11.1021	Cost: 6.64s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 10.7207	Cost: 6.42s
Train Epoch: 302 [61440/90000 (68%)]	Loss: 11.0856	Cost: 6.42s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 11.1989	Cost: 6.56s
Train Epoch: 302 	Average Loss: 11.0338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5314

Learning rate: 0.00019999549929676196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 11.2196	Cost: 23.07s
Train Epoch: 303 [20480/90000 (23%)]	Loss: 11.1125	Cost: 6.49s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 10.9170	Cost: 12.55s
Train Epoch: 303 [61440/90000 (68%)]	Loss: 11.0782	Cost: 12.08s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 11.0341	Cost: 11.80s
Train Epoch: 303 	Average Loss: 11.0132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4680

Learning rate: 0.00019999546944165803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 11.1644	Cost: 28.19s
Train Epoch: 304 [20480/90000 (23%)]	Loss: 11.0628	Cost: 12.04s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 11.0131	Cost: 12.11s
Train Epoch: 304 [61440/90000 (68%)]	Loss: 11.0554	Cost: 11.80s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 10.9210	Cost: 11.80s
Train Epoch: 304 	Average Loss: 11.0188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5080

Learning rate: 0.00019999543948786254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 11.0346	Cost: 27.00s
Train Epoch: 305 [20480/90000 (23%)]	Loss: 11.0325	Cost: 10.83s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 10.9084	Cost: 12.04s
Train Epoch: 305 [61440/90000 (68%)]	Loss: 10.9017	Cost: 11.83s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 10.9301	Cost: 6.22s
Train Epoch: 305 	Average Loss: 10.9885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4468

Learning rate: 0.0001999954094353755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 11.2647	Cost: 26.73s
Train Epoch: 306 [20480/90000 (23%)]	Loss: 11.1653	Cost: 11.73s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 10.9839	Cost: 11.09s
Train Epoch: 306 [61440/90000 (68%)]	Loss: 11.0797	Cost: 5.82s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 11.1024	Cost: 6.51s
Train Epoch: 306 	Average Loss: 11.0315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6199

Learning rate: 0.00019999537928419694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 11.0973	Cost: 27.05s
Train Epoch: 307 [20480/90000 (23%)]	Loss: 10.9008	Cost: 10.73s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 11.0839	Cost: 6.05s
Train Epoch: 307 [61440/90000 (68%)]	Loss: 11.2357	Cost: 5.92s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 11.1185	Cost: 6.86s
Train Epoch: 307 	Average Loss: 11.0184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5263

Learning rate: 0.00019999534903432692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 11.2033	Cost: 25.10s
Train Epoch: 308 [20480/90000 (23%)]	Loss: 11.2718	Cost: 6.29s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 10.9420	Cost: 6.91s
Train Epoch: 308 [61440/90000 (68%)]	Loss: 11.1916	Cost: 7.02s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 10.9257	Cost: 6.13s
Train Epoch: 308 	Average Loss: 10.9865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4172

Learning rate: 0.00019999531868576542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 11.0462	Cost: 24.78s
Train Epoch: 309 [20480/90000 (23%)]	Loss: 11.1373	Cost: 6.44s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 10.9086	Cost: 6.56s
Train Epoch: 309 [61440/90000 (68%)]	Loss: 11.1244	Cost: 6.45s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 10.9769	Cost: 6.56s
Train Epoch: 309 	Average Loss: 11.0039
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3770

Saving model as e309_model.pt & e309_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999528823851252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 11.2862	Cost: 23.30s
Train Epoch: 310 [20480/90000 (23%)]	Loss: 10.9759	Cost: 7.04s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 10.7939	Cost: 6.45s
Train Epoch: 310 [61440/90000 (68%)]	Loss: 10.9139	Cost: 6.29s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 10.9375	Cost: 6.15s
Train Epoch: 310 	Average Loss: 10.9845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3689

Saving model as e310_model.pt & e310_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999525769256822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 11.0058	Cost: 27.85s
Train Epoch: 311 [20480/90000 (23%)]	Loss: 11.0019	Cost: 6.18s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 11.0501	Cost: 6.53s
Train Epoch: 311 [61440/90000 (68%)]	Loss: 11.0447	Cost: 6.24s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 10.9286	Cost: 7.02s
Train Epoch: 311 	Average Loss: 10.9505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4869

Learning rate: 0.00019999522704793255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 11.2374	Cost: 23.53s
Train Epoch: 312 [20480/90000 (23%)]	Loss: 11.0108	Cost: 6.34s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 10.7898	Cost: 12.90s
Train Epoch: 312 [61440/90000 (68%)]	Loss: 10.8907	Cost: 12.25s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 10.9095	Cost: 11.92s
Train Epoch: 312 	Average Loss: 10.9675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4555

Learning rate: 0.00019999519630460553
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 11.0913	Cost: 29.84s
Train Epoch: 313 [20480/90000 (23%)]	Loss: 11.0581	Cost: 12.22s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 11.0284	Cost: 12.16s
Train Epoch: 313 [61440/90000 (68%)]	Loss: 10.9766	Cost: 12.07s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 10.9041	Cost: 11.70s
Train Epoch: 313 	Average Loss: 10.9817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4101

Learning rate: 0.00019999516546258725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 10.9981	Cost: 33.89s
Train Epoch: 314 [20480/90000 (23%)]	Loss: 10.9101	Cost: 12.02s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 10.9265	Cost: 12.22s
Train Epoch: 314 [61440/90000 (68%)]	Loss: 11.0648	Cost: 11.81s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 10.9921	Cost: 7.40s
Train Epoch: 314 	Average Loss: 10.9427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4121

Learning rate: 0.00019999513452187764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 11.1407	Cost: 27.31s
Train Epoch: 315 [20480/90000 (23%)]	Loss: 11.0522	Cost: 12.22s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 10.7043	Cost: 10.94s
Train Epoch: 315 [61440/90000 (68%)]	Loss: 10.8868	Cost: 6.07s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 10.9965	Cost: 6.26s
Train Epoch: 315 	Average Loss: 10.9277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4157

Learning rate: 0.0001999951034824768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 10.9717	Cost: 24.05s
Train Epoch: 316 [20480/90000 (23%)]	Loss: 11.0417	Cost: 6.05s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 10.9734	Cost: 7.16s
Train Epoch: 316 [61440/90000 (68%)]	Loss: 10.9414	Cost: 6.32s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 10.8743	Cost: 6.14s
Train Epoch: 316 	Average Loss: 10.9433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4774

Learning rate: 0.00019999507234438478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 11.0752	Cost: 27.63s
Train Epoch: 317 [20480/90000 (23%)]	Loss: 11.0005	Cost: 7.37s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 11.0065	Cost: 11.53s
Train Epoch: 317 [61440/90000 (68%)]	Loss: 10.9264	Cost: 12.19s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 10.8914	Cost: 12.12s
Train Epoch: 317 	Average Loss: 10.9270
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3310

Saving model as e317_model.pt & e317_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999504110760157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 11.0545	Cost: 28.84s
Train Epoch: 318 [20480/90000 (23%)]	Loss: 10.9586	Cost: 6.52s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 10.9416	Cost: 8.58s
Train Epoch: 318 [61440/90000 (68%)]	Loss: 11.0526	Cost: 6.24s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 11.0309	Cost: 16.80s
Train Epoch: 318 	Average Loss: 10.9286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4360

Learning rate: 0.0001999950097721272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 11.0251	Cost: 25.00s
Train Epoch: 319 [20480/90000 (23%)]	Loss: 10.9907	Cost: 8.20s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 10.9730	Cost: 12.23s
Train Epoch: 319 [61440/90000 (68%)]	Loss: 10.7673	Cost: 11.95s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 10.9840	Cost: 11.79s
Train Epoch: 319 	Average Loss: 10.9092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3487

Learning rate: 0.00019999497833796175
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 11.0791	Cost: 26.83s
Train Epoch: 320 [20480/90000 (23%)]	Loss: 10.8992	Cost: 12.16s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 10.8841	Cost: 11.96s
Train Epoch: 320 [61440/90000 (68%)]	Loss: 10.8172	Cost: 11.58s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 10.9418	Cost: 5.82s
Train Epoch: 320 	Average Loss: 10.9067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3407

Learning rate: 0.00019999494680510515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 10.9999	Cost: 25.64s
Train Epoch: 321 [20480/90000 (23%)]	Loss: 11.1223	Cost: 11.92s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 10.7260	Cost: 9.37s
Train Epoch: 321 [61440/90000 (68%)]	Loss: 10.9566	Cost: 5.81s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 11.0957	Cost: 6.79s
Train Epoch: 321 	Average Loss: 10.9119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4202

Learning rate: 0.00019999491517355754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 10.8875	Cost: 26.53s
Train Epoch: 322 [20480/90000 (23%)]	Loss: 10.9564	Cost: 6.00s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 10.9114	Cost: 8.83s
Train Epoch: 322 [61440/90000 (68%)]	Loss: 10.9671	Cost: 6.29s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 10.9109	Cost: 6.69s
Train Epoch: 322 	Average Loss: 10.8917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3094

Saving model as e322_model.pt & e322_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999488344331888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 11.1761	Cost: 34.92s
Train Epoch: 323 [20480/90000 (23%)]	Loss: 10.9575	Cost: 12.43s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 10.7910	Cost: 12.09s
Train Epoch: 323 [61440/90000 (68%)]	Loss: 10.9782	Cost: 6.34s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 10.8947	Cost: 5.92s
Train Epoch: 323 	Average Loss: 10.8727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3130

Learning rate: 0.00019999485161438922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 10.8511	Cost: 28.29s
Train Epoch: 324 [20480/90000 (23%)]	Loss: 10.8222	Cost: 9.17s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 10.7194	Cost: 6.33s
Train Epoch: 324 [61440/90000 (68%)]	Loss: 10.8509	Cost: 6.90s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 10.8485	Cost: 6.48s
Train Epoch: 324 	Average Loss: 10.8948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3503

Learning rate: 0.0001999948196867686
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 10.9660	Cost: 28.14s
Train Epoch: 325 [20480/90000 (23%)]	Loss: 10.9520	Cost: 6.41s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 10.6967	Cost: 6.48s
Train Epoch: 325 [61440/90000 (68%)]	Loss: 10.9368	Cost: 6.34s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 10.8502	Cost: 8.79s
Train Epoch: 325 	Average Loss: 10.8722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3481

Learning rate: 0.00019999478766045706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 10.9692	Cost: 22.44s
Train Epoch: 326 [20480/90000 (23%)]	Loss: 10.9451	Cost: 6.29s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 10.8059	Cost: 8.02s
Train Epoch: 326 [61440/90000 (68%)]	Loss: 10.7316	Cost: 8.33s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 11.0426	Cost: 13.29s
Train Epoch: 326 	Average Loss: 10.8597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3061

Saving model as e326_model.pt & e326_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999475553545462
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 11.0709	Cost: 23.25s
Train Epoch: 327 [20480/90000 (23%)]	Loss: 10.9093	Cost: 6.31s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 10.8996	Cost: 7.03s
Train Epoch: 327 [61440/90000 (68%)]	Loss: 10.9381	Cost: 6.06s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 11.0544	Cost: 8.32s
Train Epoch: 327 	Average Loss: 10.8733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3405

Learning rate: 0.0001999947233117613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 10.9331	Cost: 32.15s
Train Epoch: 328 [20480/90000 (23%)]	Loss: 10.9806	Cost: 7.72s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 10.6784	Cost: 14.07s
Train Epoch: 328 [61440/90000 (68%)]	Loss: 10.7442	Cost: 12.18s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 10.9313	Cost: 12.06s
Train Epoch: 328 	Average Loss: 10.8282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3290

Learning rate: 0.00019999469098937715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 11.2058	Cost: 28.02s
Train Epoch: 329 [20480/90000 (23%)]	Loss: 10.8977	Cost: 12.18s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 10.9065	Cost: 12.16s
Train Epoch: 329 [61440/90000 (68%)]	Loss: 10.8932	Cost: 12.17s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 11.0780	Cost: 8.99s
Train Epoch: 329 	Average Loss: 10.8620
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3538

Learning rate: 0.00019999465856830218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 11.0991	Cost: 36.01s
Train Epoch: 330 [20480/90000 (23%)]	Loss: 10.9006	Cost: 12.26s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 10.9980	Cost: 11.82s
Train Epoch: 330 [61440/90000 (68%)]	Loss: 10.9485	Cost: 10.00s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 10.9107	Cost: 6.07s
Train Epoch: 330 	Average Loss: 10.8862
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3611

Learning rate: 0.00019999462604853647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 10.9774	Cost: 27.55s
Train Epoch: 331 [20480/90000 (23%)]	Loss: 10.9640	Cost: 10.46s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 10.8140	Cost: 8.92s
Train Epoch: 331 [61440/90000 (68%)]	Loss: 11.1000	Cost: 5.89s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 10.9194	Cost: 6.83s
Train Epoch: 331 	Average Loss: 10.8687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2291

Saving model as e331_model.pt & e331_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999459343008003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 10.9767	Cost: 28.97s
Train Epoch: 332 [20480/90000 (23%)]	Loss: 10.9755	Cost: 12.58s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 10.7529	Cost: 12.38s
Train Epoch: 332 [61440/90000 (68%)]	Loss: 10.8575	Cost: 8.42s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 10.8881	Cost: 6.17s
Train Epoch: 332 	Average Loss: 10.8003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3000

Learning rate: 0.00019999456071293284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 10.9861	Cost: 25.23s
Train Epoch: 333 [20480/90000 (23%)]	Loss: 10.9941	Cost: 6.24s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 10.7275	Cost: 8.17s
Train Epoch: 333 [61440/90000 (68%)]	Loss: 10.8693	Cost: 6.27s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 10.9899	Cost: 6.08s
Train Epoch: 333 	Average Loss: 10.8572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3279

Learning rate: 0.00019999452789709498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 10.8963	Cost: 24.11s
Train Epoch: 334 [20480/90000 (23%)]	Loss: 10.7428	Cost: 6.22s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 10.8354	Cost: 6.82s
Train Epoch: 334 [61440/90000 (68%)]	Loss: 10.7643	Cost: 6.13s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 10.9287	Cost: 8.22s
Train Epoch: 334 	Average Loss: 10.8027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3227

Learning rate: 0.0001999944949825665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 11.1707	Cost: 23.47s
Train Epoch: 335 [20480/90000 (23%)]	Loss: 10.9050	Cost: 6.73s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 10.5767	Cost: 9.41s
Train Epoch: 335 [61440/90000 (68%)]	Loss: 10.8334	Cost: 11.07s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 10.7715	Cost: 11.77s
Train Epoch: 335 	Average Loss: 10.7722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3373

Learning rate: 0.0001999944619693474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 10.9380	Cost: 26.39s
Train Epoch: 336 [20480/90000 (23%)]	Loss: 10.9724	Cost: 12.01s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 10.7396	Cost: 12.20s
Train Epoch: 336 [61440/90000 (68%)]	Loss: 10.7482	Cost: 11.96s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 10.8257	Cost: 11.91s
Train Epoch: 336 	Average Loss: 10.7904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2677

Learning rate: 0.00019999442885743776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 10.9798	Cost: 26.92s
Train Epoch: 337 [20480/90000 (23%)]	Loss: 10.7452	Cost: 12.05s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 10.7326	Cost: 12.12s
Train Epoch: 337 [61440/90000 (68%)]	Loss: 10.6969	Cost: 12.13s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 10.8980	Cost: 8.92s
Train Epoch: 337 	Average Loss: 10.7929
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2594

Learning rate: 0.00019999439564683753
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 10.7218	Cost: 38.39s
Train Epoch: 338 [20480/90000 (23%)]	Loss: 10.7663	Cost: 11.73s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 10.6123	Cost: 11.78s
Train Epoch: 338 [61440/90000 (68%)]	Loss: 10.6881	Cost: 6.01s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 10.8774	Cost: 5.98s
Train Epoch: 338 	Average Loss: 10.7827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2896

Learning rate: 0.0001999943623375468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 10.9915	Cost: 26.39s
Train Epoch: 339 [20480/90000 (23%)]	Loss: 10.7370	Cost: 9.40s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 10.7745	Cost: 6.16s
Train Epoch: 339 [61440/90000 (68%)]	Loss: 10.6841	Cost: 6.63s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 10.7614	Cost: 6.38s
Train Epoch: 339 	Average Loss: 10.7848
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2591

Learning rate: 0.0001999943289295656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 10.7852	Cost: 27.30s
Train Epoch: 340 [20480/90000 (23%)]	Loss: 10.7891	Cost: 6.28s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 10.7989	Cost: 7.59s
Train Epoch: 340 [61440/90000 (68%)]	Loss: 10.7847	Cost: 6.40s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 10.8998	Cost: 10.02s
Train Epoch: 340 	Average Loss: 10.7760
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2760

Learning rate: 0.00019999429542289394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 11.0565	Cost: 24.72s
Train Epoch: 341 [20480/90000 (23%)]	Loss: 10.8899	Cost: 6.70s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 10.7227	Cost: 16.43s
Train Epoch: 341 [61440/90000 (68%)]	Loss: 10.8715	Cost: 12.68s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 10.7132	Cost: 12.17s
Train Epoch: 341 	Average Loss: 10.7913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2401

Learning rate: 0.00019999426181753187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 10.8687	Cost: 33.78s
Train Epoch: 342 [20480/90000 (23%)]	Loss: 10.8214	Cost: 10.97s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 10.6131	Cost: 12.30s
Train Epoch: 342 [61440/90000 (68%)]	Loss: 10.8388	Cost: 12.00s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 10.8905	Cost: 6.37s
Train Epoch: 342 	Average Loss: 10.7470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2112

Saving model as e342_model.pt & e342_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999942281134794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 10.9702	Cost: 29.44s
Train Epoch: 343 [20480/90000 (23%)]	Loss: 10.9477	Cost: 12.26s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 10.5974	Cost: 12.24s
Train Epoch: 343 [61440/90000 (68%)]	Loss: 10.6362	Cost: 11.93s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 10.7966	Cost: 11.98s
Train Epoch: 343 	Average Loss: 10.7626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2287

Learning rate: 0.0001999941943107366
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 10.8870	Cost: 30.24s
Train Epoch: 344 [20480/90000 (23%)]	Loss: 10.8245	Cost: 13.06s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 10.5947	Cost: 12.76s
Train Epoch: 344 [61440/90000 (68%)]	Loss: 10.7100	Cost: 10.14s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 10.7749	Cost: 6.20s
Train Epoch: 344 	Average Loss: 10.7467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2204

Learning rate: 0.00019999416040930349
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 11.0756	Cost: 36.18s
Train Epoch: 345 [20480/90000 (23%)]	Loss: 10.8598	Cost: 11.82s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 10.6069	Cost: 12.12s
Train Epoch: 345 [61440/90000 (68%)]	Loss: 10.7603	Cost: 6.36s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 10.8828	Cost: 5.92s
Train Epoch: 345 	Average Loss: 10.7559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2671

Learning rate: 0.0001999941264091801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 10.8770	Cost: 30.37s
Train Epoch: 346 [20480/90000 (23%)]	Loss: 10.8791	Cost: 11.82s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 10.8161	Cost: 6.34s
Train Epoch: 346 [61440/90000 (68%)]	Loss: 10.6842	Cost: 5.95s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 10.9219	Cost: 7.08s
Train Epoch: 346 	Average Loss: 10.7561
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1823

Saving model as e346_model.pt & e346_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999409231036646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 10.9028	Cost: 27.69s
Train Epoch: 347 [20480/90000 (23%)]	Loss: 10.7645	Cost: 12.26s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 10.5450	Cost: 12.04s
Train Epoch: 347 [61440/90000 (68%)]	Loss: 10.7557	Cost: 11.85s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 10.7630	Cost: 10.56s
Train Epoch: 347 	Average Loss: 10.7103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1227

Saving model as e347_model.pt & e347_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999940581128626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 11.0818	Cost: 23.09s
Train Epoch: 348 [20480/90000 (23%)]	Loss: 10.8659	Cost: 6.46s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 10.5984	Cost: 13.53s
Train Epoch: 348 [61440/90000 (68%)]	Loss: 10.8728	Cost: 11.99s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 10.8349	Cost: 11.87s
Train Epoch: 348 	Average Loss: 10.7064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2661

Learning rate: 0.00019999402381666855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 10.7889	Cost: 23.79s
Train Epoch: 349 [20480/90000 (23%)]	Loss: 10.7435	Cost: 11.89s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 10.6405	Cost: 12.15s
Train Epoch: 349 [61440/90000 (68%)]	Loss: 10.7224	Cost: 11.85s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 10.7838	Cost: 11.86s
Train Epoch: 349 	Average Loss: 10.7048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2241

Learning rate: 0.0001999939894217844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 10.7295	Cost: 37.54s
Train Epoch: 350 [20480/90000 (23%)]	Loss: 10.7710	Cost: 13.48s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 10.7536	Cost: 12.20s
Train Epoch: 350 [61440/90000 (68%)]	Loss: 10.7022	Cost: 11.95s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 10.7269	Cost: 11.68s
Train Epoch: 350 	Average Loss: 10.7194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2158

Learning rate: 0.0001999939549282101
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 10.8148	Cost: 25.65s
Train Epoch: 351 [20480/90000 (23%)]	Loss: 10.8184	Cost: 12.09s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 10.8219	Cost: 12.00s
Train Epoch: 351 [61440/90000 (68%)]	Loss: 10.6506	Cost: 11.84s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 10.7668	Cost: 8.51s
Train Epoch: 351 	Average Loss: 10.6961
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1736

Learning rate: 0.00019999392033594573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 10.8310	Cost: 26.64s
Train Epoch: 352 [20480/90000 (23%)]	Loss: 10.6720	Cost: 12.01s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 10.6753	Cost: 11.99s
Train Epoch: 352 [61440/90000 (68%)]	Loss: 10.6797	Cost: 6.22s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 10.6542	Cost: 5.94s
Train Epoch: 352 	Average Loss: 10.6879
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1884

Learning rate: 0.0001999938856449913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 10.9464	Cost: 26.64s
Train Epoch: 353 [20480/90000 (23%)]	Loss: 10.7901	Cost: 10.68s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 10.6164	Cost: 6.29s
Train Epoch: 353 [61440/90000 (68%)]	Loss: 10.6419	Cost: 6.37s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 10.8124	Cost: 6.36s
Train Epoch: 353 	Average Loss: 10.7404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2014

Learning rate: 0.00019999385085534688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 10.6357	Cost: 25.53s
Train Epoch: 354 [20480/90000 (23%)]	Loss: 10.7119	Cost: 6.31s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 10.6639	Cost: 6.24s
Train Epoch: 354 [61440/90000 (68%)]	Loss: 10.7230	Cost: 7.10s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 10.6885	Cost: 6.18s
Train Epoch: 354 	Average Loss: 10.6818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1857

Learning rate: 0.00019999381596701247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 11.0267	Cost: 23.56s
Train Epoch: 355 [20480/90000 (23%)]	Loss: 10.7222	Cost: 6.16s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 10.5986	Cost: 6.80s
Train Epoch: 355 [61440/90000 (68%)]	Loss: 10.4956	Cost: 6.16s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 10.6275	Cost: 5.99s
Train Epoch: 355 	Average Loss: 10.6824
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2027

Learning rate: 0.00019999378097998813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 10.9219	Cost: 22.60s
Train Epoch: 356 [20480/90000 (23%)]	Loss: 10.8324	Cost: 6.74s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 10.6278	Cost: 12.32s
Train Epoch: 356 [61440/90000 (68%)]	Loss: 10.6714	Cost: 12.16s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 10.7882	Cost: 11.86s
Train Epoch: 356 	Average Loss: 10.6606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1386

Learning rate: 0.00019999374589427387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 10.8462	Cost: 31.78s
Train Epoch: 357 [20480/90000 (23%)]	Loss: 10.7686	Cost: 12.31s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 10.4522	Cost: 11.94s
Train Epoch: 357 [61440/90000 (68%)]	Loss: 10.7325	Cost: 8.65s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 10.5697	Cost: 5.82s
Train Epoch: 357 	Average Loss: 10.6752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1643

Learning rate: 0.00019999371070986973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 10.8613	Cost: 26.66s
Train Epoch: 358 [20480/90000 (23%)]	Loss: 10.8269	Cost: 11.93s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 10.5427	Cost: 6.44s
Train Epoch: 358 [61440/90000 (68%)]	Loss: 10.5851	Cost: 5.88s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 10.6452	Cost: 6.83s
Train Epoch: 358 	Average Loss: 10.6842
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1990

Learning rate: 0.00019999367542677577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 10.7437	Cost: 23.03s
Train Epoch: 359 [20480/90000 (23%)]	Loss: 10.7759	Cost: 7.13s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 10.6374	Cost: 6.46s
Train Epoch: 359 [61440/90000 (68%)]	Loss: 10.5273	Cost: 5.96s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 10.8028	Cost: 6.23s
Train Epoch: 359 	Average Loss: 10.6415
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2174

Learning rate: 0.00019999364004499203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 10.7621	Cost: 23.93s
Train Epoch: 360 [20480/90000 (23%)]	Loss: 10.8244	Cost: 6.33s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 10.5155	Cost: 12.77s
Train Epoch: 360 [61440/90000 (68%)]	Loss: 10.5798	Cost: 12.25s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 10.7662	Cost: 11.93s
Train Epoch: 360 	Average Loss: 10.6478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1526

Learning rate: 0.0001999936045645185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 11.0502	Cost: 33.86s
Train Epoch: 361 [20480/90000 (23%)]	Loss: 10.7243	Cost: 13.69s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 10.3954	Cost: 12.16s
Train Epoch: 361 [61440/90000 (68%)]	Loss: 10.5861	Cost: 12.03s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 10.7212	Cost: 7.50s
Train Epoch: 361 	Average Loss: 10.6423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1354

Learning rate: 0.00019999356898535523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 10.9641	Cost: 23.58s
Train Epoch: 362 [20480/90000 (23%)]	Loss: 10.7420	Cost: 6.65s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 10.4435	Cost: 6.57s
Train Epoch: 362 [61440/90000 (68%)]	Loss: 10.7810	Cost: 6.42s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 10.7030	Cost: 8.41s
Train Epoch: 362 	Average Loss: 10.6136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0250

Saving model as e362_model.pt & e362_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999935333075023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 10.8516	Cost: 23.02s
Train Epoch: 363 [20480/90000 (23%)]	Loss: 10.5961	Cost: 6.05s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 10.7410	Cost: 7.38s
Train Epoch: 363 [61440/90000 (68%)]	Loss: 10.5941	Cost: 6.47s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 10.7639	Cost: 9.39s
Train Epoch: 363 	Average Loss: 10.6318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1998

Learning rate: 0.0001999934975309597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 10.6649	Cost: 23.64s
Train Epoch: 364 [20480/90000 (23%)]	Loss: 10.6908	Cost: 6.35s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 10.4888	Cost: 8.24s
Train Epoch: 364 [61440/90000 (68%)]	Loss: 10.6169	Cost: 11.34s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 10.6978	Cost: 12.06s
Train Epoch: 364 	Average Loss: 10.6510
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2279

Learning rate: 0.00019999346165572743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 10.8103	Cost: 36.09s
Train Epoch: 365 [20480/90000 (23%)]	Loss: 10.6787	Cost: 11.82s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 10.6654	Cost: 12.11s
Train Epoch: 365 [61440/90000 (68%)]	Loss: 10.6079	Cost: 7.45s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 10.7776	Cost: 5.82s
Train Epoch: 365 	Average Loss: 10.6319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1902

Learning rate: 0.00019999342568180562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 10.7139	Cost: 24.55s
Train Epoch: 366 [20480/90000 (23%)]	Loss: 10.6592	Cost: 6.11s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 10.6467	Cost: 11.75s
Train Epoch: 366 [61440/90000 (68%)]	Loss: 10.7214	Cost: 6.44s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 10.7879	Cost: 10.48s
Train Epoch: 366 	Average Loss: 10.6131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1073

Learning rate: 0.00019999338960919423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 10.7219	Cost: 23.43s
Train Epoch: 367 [20480/90000 (23%)]	Loss: 10.5990	Cost: 6.21s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 10.5308	Cost: 12.56s
Train Epoch: 367 [61440/90000 (68%)]	Loss: 10.5679	Cost: 12.12s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 10.5713	Cost: 11.84s
Train Epoch: 367 	Average Loss: 10.6069
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2030

Learning rate: 0.0001999933534378933
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 11.0694	Cost: 30.68s
Train Epoch: 368 [20480/90000 (23%)]	Loss: 10.4975	Cost: 12.01s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 10.4774	Cost: 11.97s
Train Epoch: 368 [61440/90000 (68%)]	Loss: 10.6955	Cost: 10.39s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 10.6833	Cost: 5.86s
Train Epoch: 368 	Average Loss: 10.6459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0983

Learning rate: 0.00019999331716790292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 10.8343	Cost: 26.51s
Train Epoch: 369 [20480/90000 (23%)]	Loss: 10.7619	Cost: 8.73s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 10.4163	Cost: 6.22s
Train Epoch: 369 [61440/90000 (68%)]	Loss: 10.6033	Cost: 6.91s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 10.6937	Cost: 5.99s
Train Epoch: 369 	Average Loss: 10.6068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1633

Learning rate: 0.00019999328079922307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 10.7252	Cost: 23.77s
Train Epoch: 370 [20480/90000 (23%)]	Loss: 10.7247	Cost: 6.33s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 10.4846	Cost: 6.81s
Train Epoch: 370 [61440/90000 (68%)]	Loss: 10.6281	Cost: 6.43s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 10.8125	Cost: 6.05s
Train Epoch: 370 	Average Loss: 10.6108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1585

Learning rate: 0.00019999324433185383
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 10.7351	Cost: 26.45s
Train Epoch: 371 [20480/90000 (23%)]	Loss: 10.5950	Cost: 6.20s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 10.5501	Cost: 9.94s
Train Epoch: 371 [61440/90000 (68%)]	Loss: 10.6478	Cost: 10.01s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 10.6096	Cost: 13.42s
Train Epoch: 371 	Average Loss: 10.5928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1139

Learning rate: 0.0001999932077657952
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 10.5513	Cost: 24.34s
Train Epoch: 372 [20480/90000 (23%)]	Loss: 10.6298	Cost: 7.65s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 10.5070	Cost: 12.35s
Train Epoch: 372 [61440/90000 (68%)]	Loss: 10.5903	Cost: 12.00s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 10.7301	Cost: 11.84s
Train Epoch: 372 	Average Loss: 10.5816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0739

Learning rate: 0.00019999317110104724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 10.7014	Cost: 27.71s
Train Epoch: 373 [20480/90000 (23%)]	Loss: 10.4718	Cost: 11.79s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 10.5215	Cost: 12.15s
Train Epoch: 373 [61440/90000 (68%)]	Loss: 10.5840	Cost: 11.80s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 10.5449	Cost: 9.19s
Train Epoch: 373 	Average Loss: 10.5612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1351

Learning rate: 0.00019999313433760997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 10.9322	Cost: 34.22s
Train Epoch: 374 [20480/90000 (23%)]	Loss: 10.7869	Cost: 8.78s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 10.5035	Cost: 7.10s
Train Epoch: 374 [61440/90000 (68%)]	Loss: 10.6372	Cost: 6.13s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 10.6227	Cost: 10.39s
Train Epoch: 374 	Average Loss: 10.5584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0461

Learning rate: 0.00019999309747548342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 10.9925	Cost: 24.44s
Train Epoch: 375 [20480/90000 (23%)]	Loss: 10.6662	Cost: 6.27s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 10.5860	Cost: 6.56s
Train Epoch: 375 [61440/90000 (68%)]	Loss: 10.4913	Cost: 6.24s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 10.5459	Cost: 6.13s
Train Epoch: 375 	Average Loss: 10.5691
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1272

Learning rate: 0.00019999306051466764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 10.8633	Cost: 24.87s
Train Epoch: 376 [20480/90000 (23%)]	Loss: 10.5593	Cost: 6.43s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 10.4786	Cost: 11.41s
Train Epoch: 376 [61440/90000 (68%)]	Loss: 10.4314	Cost: 12.28s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 10.7106	Cost: 12.05s
Train Epoch: 376 	Average Loss: 10.5552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0724

Learning rate: 0.0001999930234551627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 10.7204	Cost: 28.35s
Train Epoch: 377 [20480/90000 (23%)]	Loss: 10.4920	Cost: 12.11s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 10.3580	Cost: 12.07s
Train Epoch: 377 [61440/90000 (68%)]	Loss: 10.4722	Cost: 11.85s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 10.5153	Cost: 7.40s
Train Epoch: 377 	Average Loss: 10.5192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0185

Saving model as e377_model.pt & e377_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999298629696857
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 10.7615	Cost: 37.66s
Train Epoch: 378 [20480/90000 (23%)]	Loss: 10.5191	Cost: 12.54s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 10.5188	Cost: 12.28s
Train Epoch: 378 [61440/90000 (68%)]	Loss: 10.5774	Cost: 12.06s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 10.5628	Cost: 8.70s
Train Epoch: 378 	Average Loss: 10.5266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1251

Learning rate: 0.00019999294904008533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 10.7868	Cost: 50.00s
Train Epoch: 379 [20480/90000 (23%)]	Loss: 10.4870	Cost: 13.35s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 10.4066	Cost: 12.13s
Train Epoch: 379 [61440/90000 (68%)]	Loss: 10.6820	Cost: 13.91s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 10.6076	Cost: 7.06s
Train Epoch: 379 	Average Loss: 10.5482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0680

Learning rate: 0.000199992911684513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 10.9925	Cost: 55.58s
Train Epoch: 380 [20480/90000 (23%)]	Loss: 10.6430	Cost: 7.39s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 10.5303	Cost: 16.14s
Train Epoch: 380 [61440/90000 (68%)]	Loss: 10.6992	Cost: 9.28s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 10.4978	Cost: 19.18s
Train Epoch: 380 	Average Loss: 10.5487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0735

Learning rate: 0.0001999928742302516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 10.8052	Cost: 26.06s
Train Epoch: 381 [20480/90000 (23%)]	Loss: 10.4885	Cost: 12.34s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 10.4008	Cost: 12.15s
Train Epoch: 381 [61440/90000 (68%)]	Loss: 10.6633	Cost: 11.77s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 10.5600	Cost: 11.81s
Train Epoch: 381 	Average Loss: 10.5051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1489

Learning rate: 0.00019999283667730122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 10.7613	Cost: 30.29s
Train Epoch: 382 [20480/90000 (23%)]	Loss: 10.4739	Cost: 11.70s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 10.4648	Cost: 11.77s
Train Epoch: 382 [61440/90000 (68%)]	Loss: 10.5928	Cost: 11.85s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 10.5487	Cost: 6.95s
Train Epoch: 382 	Average Loss: 10.5159
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0452

Learning rate: 0.00019999279902566184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 10.9120	Cost: 60.43s
Train Epoch: 383 [20480/90000 (23%)]	Loss: 10.5061	Cost: 7.44s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 10.4410	Cost: 6.27s
Train Epoch: 383 [61440/90000 (68%)]	Loss: 10.5639	Cost: 10.08s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 10.6547	Cost: 19.33s
Train Epoch: 383 	Average Loss: 10.5207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0555

Learning rate: 0.0001999927612753335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 10.8023	Cost: 85.11s
Train Epoch: 384 [20480/90000 (23%)]	Loss: 10.5404	Cost: 10.90s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 10.5020	Cost: 24.98s
Train Epoch: 384 [61440/90000 (68%)]	Loss: 10.5528	Cost: 14.62s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 10.6490	Cost: 23.18s
Train Epoch: 384 	Average Loss: 10.5122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0467

Learning rate: 0.00019999272342631632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 10.7792	Cost: 34.21s
Train Epoch: 385 [20480/90000 (23%)]	Loss: 10.6223	Cost: 7.11s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 10.4319	Cost: 8.59s
Train Epoch: 385 [61440/90000 (68%)]	Loss: 10.5024	Cost: 6.91s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 10.4952	Cost: 10.75s
Train Epoch: 385 	Average Loss: 10.4655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0789

Learning rate: 0.00019999268547861025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 10.5877	Cost: 29.44s
Train Epoch: 386 [20480/90000 (23%)]	Loss: 10.4511	Cost: 6.51s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 10.4983	Cost: 15.54s
Train Epoch: 386 [61440/90000 (68%)]	Loss: 10.5277	Cost: 11.46s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 10.4649	Cost: 34.23s
Train Epoch: 386 	Average Loss: 10.4973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0867

Learning rate: 0.00019999264743221536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 10.5782	Cost: 46.34s
Train Epoch: 387 [20480/90000 (23%)]	Loss: 10.4756	Cost: 13.92s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 10.5244	Cost: 30.76s
Train Epoch: 387 [61440/90000 (68%)]	Loss: 10.6726	Cost: 23.20s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 10.4972	Cost: 36.96s
Train Epoch: 387 	Average Loss: 10.4484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0892

Learning rate: 0.00019999260928713167
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 10.7406	Cost: 42.35s
Train Epoch: 388 [20480/90000 (23%)]	Loss: 10.5571	Cost: 9.18s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 10.3811	Cost: 12.14s
Train Epoch: 388 [61440/90000 (68%)]	Loss: 10.4596	Cost: 11.38s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 10.6028	Cost: 21.04s
Train Epoch: 388 	Average Loss: 10.5325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0662

Learning rate: 0.00019999257104335924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 10.7086	Cost: 145.62s
Train Epoch: 389 [20480/90000 (23%)]	Loss: 10.3749	Cost: 15.28s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 10.2951	Cost: 20.22s
Train Epoch: 389 [61440/90000 (68%)]	Loss: 10.5208	Cost: 22.84s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 10.6359	Cost: 25.46s
Train Epoch: 389 	Average Loss: 10.4841
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0482

Learning rate: 0.00019999253270089811
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 10.6240	Cost: 48.83s
Train Epoch: 390 [20480/90000 (23%)]	Loss: 10.5652	Cost: 10.52s
Train Epoch: 390 [40960/90000 (45%)]	Loss: 10.2880	Cost: 15.49s
Train Epoch: 390 [61440/90000 (68%)]	Loss: 10.3745	Cost: 9.04s
Train Epoch: 390 [81920/90000 (91%)]	Loss: 10.5137	Cost: 9.42s
Train Epoch: 390 	Average Loss: 10.4666
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9402

Saving model as e390_model.pt & e390_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999924942597483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 10.8729	Cost: 115.18s
Train Epoch: 391 [20480/90000 (23%)]	Loss: 10.6091	Cost: 19.38s
Train Epoch: 391 [40960/90000 (45%)]	Loss: 10.2650	Cost: 26.54s
Train Epoch: 391 [61440/90000 (68%)]	Loss: 10.5379	Cost: 13.16s
Train Epoch: 391 [81920/90000 (91%)]	Loss: 10.5068	Cost: 23.77s
Train Epoch: 391 	Average Loss: 10.4677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0570

Learning rate: 0.00019999245571990988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 10.8634	Cost: 96.09s
Train Epoch: 392 [20480/90000 (23%)]	Loss: 10.5098	Cost: 17.13s
Train Epoch: 392 [40960/90000 (45%)]	Loss: 10.5070	Cost: 26.33s
Train Epoch: 392 [61440/90000 (68%)]	Loss: 10.4672	Cost: 18.97s
Train Epoch: 392 [81920/90000 (91%)]	Loss: 10.4568	Cost: 18.81s
Train Epoch: 392 	Average Loss: 10.4678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9919

Learning rate: 0.00019999241708138285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 10.5715	Cost: 95.60s
Train Epoch: 393 [20480/90000 (23%)]	Loss: 10.5705	Cost: 11.07s
Train Epoch: 393 [40960/90000 (45%)]	Loss: 10.3777	Cost: 22.38s
Train Epoch: 393 [61440/90000 (68%)]	Loss: 10.6526	Cost: 13.83s
Train Epoch: 393 [81920/90000 (91%)]	Loss: 10.5054	Cost: 28.86s
Train Epoch: 393 	Average Loss: 10.4668
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0006

Learning rate: 0.00019999237834416724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 10.5829	Cost: 98.37s
Train Epoch: 394 [20480/90000 (23%)]	Loss: 10.4199	Cost: 16.77s
Train Epoch: 394 [40960/90000 (45%)]	Loss: 10.4578	Cost: 19.99s
Train Epoch: 394 [61440/90000 (68%)]	Loss: 10.4741	Cost: 13.59s
Train Epoch: 394 [81920/90000 (91%)]	Loss: 10.7145	Cost: 21.78s
Train Epoch: 394 	Average Loss: 10.4701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0409

Learning rate: 0.0001999923395082631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 10.8169	Cost: 28.56s
Train Epoch: 395 [20480/90000 (23%)]	Loss: 10.3209	Cost: 11.56s
Train Epoch: 395 [40960/90000 (45%)]	Loss: 10.3357	Cost: 8.82s
Train Epoch: 395 [61440/90000 (68%)]	Loss: 10.5879	Cost: 5.84s
Train Epoch: 395 [81920/90000 (91%)]	Loss: 10.5273	Cost: 6.67s
Train Epoch: 395 	Average Loss: 10.4607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9501

Learning rate: 0.0001999923005736705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 10.5164	Cost: 26.99s
Train Epoch: 396 [20480/90000 (23%)]	Loss: 10.5012	Cost: 9.91s
Train Epoch: 396 [40960/90000 (45%)]	Loss: 10.4689	Cost: 5.99s
Train Epoch: 396 [61440/90000 (68%)]	Loss: 10.4811	Cost: 6.03s
Train Epoch: 396 [81920/90000 (91%)]	Loss: 10.5848	Cost: 6.65s
Train Epoch: 396 	Average Loss: 10.4270
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9554

Learning rate: 0.00019999226154038944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 10.5704	Cost: 26.01s
Train Epoch: 397 [20480/90000 (23%)]	Loss: 10.5727	Cost: 6.06s
Train Epoch: 397 [40960/90000 (45%)]	Loss: 10.1918	Cost: 8.82s
Train Epoch: 397 [61440/90000 (68%)]	Loss: 10.3272	Cost: 6.08s
Train Epoch: 397 [81920/90000 (91%)]	Loss: 10.5041	Cost: 6.04s
Train Epoch: 397 	Average Loss: 10.4104
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1061

Learning rate: 0.00019999222240841996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 10.7740	Cost: 24.12s
Train Epoch: 398 [20480/90000 (23%)]	Loss: 10.3473	Cost: 6.62s
Train Epoch: 398 [40960/90000 (45%)]	Loss: 10.3121	Cost: 6.82s
Train Epoch: 398 [61440/90000 (68%)]	Loss: 10.2922	Cost: 6.31s
Train Epoch: 398 [81920/90000 (91%)]	Loss: 10.4850	Cost: 14.60s
Train Epoch: 398 	Average Loss: 10.4308
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0632

Learning rate: 0.00019999218317776212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 10.4464	Cost: 33.75s
Train Epoch: 399 [20480/90000 (23%)]	Loss: 10.5182	Cost: 12.27s
Train Epoch: 399 [40960/90000 (45%)]	Loss: 10.3896	Cost: 12.24s
Train Epoch: 399 [61440/90000 (68%)]	Loss: 10.4695	Cost: 11.88s
Train Epoch: 399 [81920/90000 (91%)]	Loss: 10.6212	Cost: 11.81s
Train Epoch: 399 	Average Loss: 10.4500
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0821

Learning rate: 0.00019999214384841597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 10.6852	Cost: 28.50s
Train Epoch: 400 [20480/90000 (23%)]	Loss: 10.5063	Cost: 12.19s
Train Epoch: 400 [40960/90000 (45%)]	Loss: 10.3190	Cost: 11.97s
Train Epoch: 400 [61440/90000 (68%)]	Loss: 10.4571	Cost: 9.83s
Train Epoch: 400 [81920/90000 (91%)]	Loss: 10.4646	Cost: 5.83s
Train Epoch: 400 	Average Loss: 10.4129
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9726

Learning rate: 0.00019999210442038154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 401 [0/90000 (0%)]	Loss: 10.7059	Cost: 27.37s
Train Epoch: 401 [20480/90000 (23%)]	Loss: 10.4650	Cost: 7.40s
Train Epoch: 401 [40960/90000 (45%)]	Loss: 10.4059	Cost: 6.25s
Train Epoch: 401 [61440/90000 (68%)]	Loss: 10.4376	Cost: 6.91s
Train Epoch: 401 [81920/90000 (91%)]	Loss: 10.5828	Cost: 6.24s
Train Epoch: 401 	Average Loss: 10.4088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9469

Learning rate: 0.00019999206489365883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 402 [0/90000 (0%)]	Loss: 10.7857	Cost: 23.57s
Train Epoch: 402 [20480/90000 (23%)]	Loss: 10.5019	Cost: 6.56s
Train Epoch: 402 [40960/90000 (45%)]	Loss: 10.5039	Cost: 8.22s
Train Epoch: 402 [61440/90000 (68%)]	Loss: 10.4803	Cost: 6.51s
Train Epoch: 402 [81920/90000 (91%)]	Loss: 10.5100	Cost: 9.31s
Train Epoch: 402 	Average Loss: 10.3962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9582

Learning rate: 0.0001999920252682479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 403 [0/90000 (0%)]	Loss: 10.5498	Cost: 23.85s
Train Epoch: 403 [20480/90000 (23%)]	Loss: 10.5162	Cost: 6.43s
Train Epoch: 403 [40960/90000 (45%)]	Loss: 10.2409	Cost: 10.50s
Train Epoch: 403 [61440/90000 (68%)]	Loss: 10.3103	Cost: 9.80s
Train Epoch: 403 [81920/90000 (91%)]	Loss: 10.4553	Cost: 13.42s
Train Epoch: 403 	Average Loss: 10.3744
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0108

Learning rate: 0.00019999198554414882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 404 [0/90000 (0%)]	Loss: 10.6341	Cost: 38.56s
Train Epoch: 404 [20480/90000 (23%)]	Loss: 10.4672	Cost: 12.66s
Train Epoch: 404 [40960/90000 (45%)]	Loss: 10.2789	Cost: 12.20s
Train Epoch: 404 [61440/90000 (68%)]	Loss: 10.3555	Cost: 11.91s
Train Epoch: 404 [81920/90000 (91%)]	Loss: 10.5000	Cost: 9.90s
Train Epoch: 404 	Average Loss: 10.4192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8633

Saving model as e404_model.pt & e404_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999919457213616
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 405 [0/90000 (0%)]	Loss: 10.6553	Cost: 31.32s
Train Epoch: 405 [20480/90000 (23%)]	Loss: 10.4850	Cost: 8.05s
Train Epoch: 405 [40960/90000 (45%)]	Loss: 10.3008	Cost: 13.62s
Train Epoch: 405 [61440/90000 (68%)]	Loss: 10.4740	Cost: 12.06s
Train Epoch: 405 [81920/90000 (91%)]	Loss: 10.4147	Cost: 11.82s
Train Epoch: 405 	Average Loss: 10.4020
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8938

Learning rate: 0.00019999190579988627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 406 [0/90000 (0%)]	Loss: 10.3200	Cost: 26.83s
Train Epoch: 406 [20480/90000 (23%)]	Loss: 10.4316	Cost: 12.20s
Train Epoch: 406 [40960/90000 (45%)]	Loss: 10.3117	Cost: 11.91s
Train Epoch: 406 [61440/90000 (68%)]	Loss: 10.4228	Cost: 8.61s
Train Epoch: 406 [81920/90000 (91%)]	Loss: 10.4454	Cost: 5.80s
Train Epoch: 406 	Average Loss: 10.3316
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0059

Learning rate: 0.0001999918657797229
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 407 [0/90000 (0%)]	Loss: 10.7020	Cost: 27.52s
Train Epoch: 407 [20480/90000 (23%)]	Loss: 10.5145	Cost: 11.65s
Train Epoch: 407 [40960/90000 (45%)]	Loss: 10.3025	Cost: 7.78s
Train Epoch: 407 [61440/90000 (68%)]	Loss: 10.4727	Cost: 5.87s
Train Epoch: 407 [81920/90000 (91%)]	Loss: 10.6369	Cost: 6.68s
Train Epoch: 407 	Average Loss: 10.3740
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9694

Learning rate: 0.00019999182566087152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 408 [0/90000 (0%)]	Loss: 10.8347	Cost: 29.27s
Train Epoch: 408 [20480/90000 (23%)]	Loss: 10.4462	Cost: 7.28s
Train Epoch: 408 [40960/90000 (45%)]	Loss: 10.2049	Cost: 8.59s
Train Epoch: 408 [61440/90000 (68%)]	Loss: 10.2364	Cost: 6.47s
Train Epoch: 408 [81920/90000 (91%)]	Loss: 10.3884	Cost: 8.26s
Train Epoch: 408 	Average Loss: 10.3799
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9840

Learning rate: 0.00019999178544333215
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 409 [0/90000 (0%)]	Loss: 10.4869	Cost: 22.69s
Train Epoch: 409 [20480/90000 (23%)]	Loss: 10.1453	Cost: 6.35s
Train Epoch: 409 [40960/90000 (45%)]	Loss: 10.4828	Cost: 7.23s
Train Epoch: 409 [61440/90000 (68%)]	Loss: 10.4896	Cost: 6.36s
Train Epoch: 409 [81920/90000 (91%)]	Loss: 10.5246	Cost: 16.00s
Train Epoch: 409 	Average Loss: 10.3677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9558

Learning rate: 0.00019999174512710485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 410 [0/90000 (0%)]	Loss: 10.7650	Cost: 25.47s
Train Epoch: 410 [20480/90000 (23%)]	Loss: 10.4285	Cost: 8.83s
Train Epoch: 410 [40960/90000 (45%)]	Loss: 10.3979	Cost: 12.37s
Train Epoch: 410 [61440/90000 (68%)]	Loss: 10.5589	Cost: 11.93s
Train Epoch: 410 [81920/90000 (91%)]	Loss: 10.3135	Cost: 11.79s
Train Epoch: 410 	Average Loss: 10.3516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9505

Learning rate: 0.00019999170471218965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 411 [0/90000 (0%)]	Loss: 10.5440	Cost: 27.78s
Train Epoch: 411 [20480/90000 (23%)]	Loss: 10.5348	Cost: 11.86s
Train Epoch: 411 [40960/90000 (45%)]	Loss: 10.3293	Cost: 12.11s
Train Epoch: 411 [61440/90000 (68%)]	Loss: 10.2796	Cost: 11.82s
Train Epoch: 411 [81920/90000 (91%)]	Loss: 10.3120	Cost: 9.79s
Train Epoch: 411 	Average Loss: 10.3467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9655

Learning rate: 0.0001999916641985866
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 412 [0/90000 (0%)]	Loss: 10.4089	Cost: 28.00s
Train Epoch: 412 [20480/90000 (23%)]	Loss: 10.3476	Cost: 11.75s
Train Epoch: 412 [40960/90000 (45%)]	Loss: 10.1131	Cost: 11.94s
Train Epoch: 412 [61440/90000 (68%)]	Loss: 10.3023	Cost: 10.95s
Train Epoch: 412 [81920/90000 (91%)]	Loss: 10.4743	Cost: 5.78s
Train Epoch: 412 	Average Loss: 10.3375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9430

Learning rate: 0.00019999162358629572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 413 [0/90000 (0%)]	Loss: 10.4714	Cost: 26.42s
Train Epoch: 413 [20480/90000 (23%)]	Loss: 10.3024	Cost: 10.26s
Train Epoch: 413 [40960/90000 (45%)]	Loss: 10.1308	Cost: 6.19s
Train Epoch: 413 [61440/90000 (68%)]	Loss: 10.2222	Cost: 6.31s
Train Epoch: 413 [81920/90000 (91%)]	Loss: 10.2969	Cost: 6.37s
Train Epoch: 413 	Average Loss: 10.3162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9826

Learning rate: 0.0001999915828753171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 414 [0/90000 (0%)]	Loss: 10.5408	Cost: 24.72s
Train Epoch: 414 [20480/90000 (23%)]	Loss: 10.4181	Cost: 6.97s
Train Epoch: 414 [40960/90000 (45%)]	Loss: 10.2529	Cost: 6.43s
Train Epoch: 414 [61440/90000 (68%)]	Loss: 10.2632	Cost: 6.03s
Train Epoch: 414 [81920/90000 (91%)]	Loss: 10.2262	Cost: 6.03s
Train Epoch: 414 	Average Loss: 10.2876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8993

Learning rate: 0.0001999915420656507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 415 [0/90000 (0%)]	Loss: 10.6732	Cost: 23.09s
Train Epoch: 415 [20480/90000 (23%)]	Loss: 10.5284	Cost: 6.39s
Train Epoch: 415 [40960/90000 (45%)]	Loss: 10.3367	Cost: 11.60s
Train Epoch: 415 [61440/90000 (68%)]	Loss: 10.3017	Cost: 11.92s
Train Epoch: 415 [81920/90000 (91%)]	Loss: 10.3001	Cost: 11.88s
Train Epoch: 415 	Average Loss: 10.3318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9242

Learning rate: 0.0001999915011572966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 416 [0/90000 (0%)]	Loss: 10.6033	Cost: 27.54s
Train Epoch: 416 [20480/90000 (23%)]	Loss: 10.3481	Cost: 12.36s
Train Epoch: 416 [40960/90000 (45%)]	Loss: 10.1070	Cost: 12.22s
Train Epoch: 416 [61440/90000 (68%)]	Loss: 10.4245	Cost: 11.73s
Train Epoch: 416 [81920/90000 (91%)]	Loss: 10.4065	Cost: 11.94s
Train Epoch: 416 	Average Loss: 10.3098
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9499

Learning rate: 0.0001999914601502549
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 417 [0/90000 (0%)]	Loss: 10.6931	Cost: 28.91s
Train Epoch: 417 [20480/90000 (23%)]	Loss: 10.2497	Cost: 12.41s
Train Epoch: 417 [40960/90000 (45%)]	Loss: 10.2450	Cost: 12.00s
Train Epoch: 417 [61440/90000 (68%)]	Loss: 10.4013	Cost: 10.62s
Train Epoch: 417 [81920/90000 (91%)]	Loss: 10.4344	Cost: 5.82s
Train Epoch: 417 	Average Loss: 10.3277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8783

Learning rate: 0.00019999141904452554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 418 [0/90000 (0%)]	Loss: 10.5943	Cost: 27.71s
Train Epoch: 418 [20480/90000 (23%)]	Loss: 10.4155	Cost: 11.53s
Train Epoch: 418 [40960/90000 (45%)]	Loss: 10.2233	Cost: 7.76s
Train Epoch: 418 [61440/90000 (68%)]	Loss: 10.2365	Cost: 5.83s
Train Epoch: 418 [81920/90000 (91%)]	Loss: 10.3111	Cost: 6.65s
Train Epoch: 418 	Average Loss: 10.2806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9421

Learning rate: 0.0001999913778401086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 419 [0/90000 (0%)]	Loss: 10.4270	Cost: 24.02s
Train Epoch: 419 [20480/90000 (23%)]	Loss: 10.3555	Cost: 6.42s
Train Epoch: 419 [40960/90000 (45%)]	Loss: 10.2365	Cost: 6.93s
Train Epoch: 419 [61440/90000 (68%)]	Loss: 10.2854	Cost: 6.55s
Train Epoch: 419 [81920/90000 (91%)]	Loss: 10.2797	Cost: 6.45s
Train Epoch: 419 	Average Loss: 10.2804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8870

Learning rate: 0.00019999133653700416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 420 [0/90000 (0%)]	Loss: 10.3713	Cost: 22.62s
Train Epoch: 420 [20480/90000 (23%)]	Loss: 10.4016	Cost: 6.46s
Train Epoch: 420 [40960/90000 (45%)]	Loss: 10.0365	Cost: 8.11s
Train Epoch: 420 [61440/90000 (68%)]	Loss: 10.3386	Cost: 6.07s
Train Epoch: 420 [81920/90000 (91%)]	Loss: 10.3703	Cost: 15.33s
Train Epoch: 420 	Average Loss: 10.2998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8880

Learning rate: 0.0001999912951352122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 421 [0/90000 (0%)]	Loss: 10.6407	Cost: 22.26s
Train Epoch: 421 [20480/90000 (23%)]	Loss: 10.2158	Cost: 6.16s
Train Epoch: 421 [40960/90000 (45%)]	Loss: 10.2501	Cost: 12.01s
Train Epoch: 421 [61440/90000 (68%)]	Loss: 10.2498	Cost: 11.86s
Train Epoch: 421 [81920/90000 (91%)]	Loss: 10.4478	Cost: 11.93s
Train Epoch: 421 	Average Loss: 10.2977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9219

Learning rate: 0.0001999912536347328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 422 [0/90000 (0%)]	Loss: 10.7146	Cost: 27.24s
Train Epoch: 422 [20480/90000 (23%)]	Loss: 10.4026	Cost: 11.99s
Train Epoch: 422 [40960/90000 (45%)]	Loss: 10.1783	Cost: 12.12s
Train Epoch: 422 [61440/90000 (68%)]	Loss: 10.2249	Cost: 11.79s
Train Epoch: 422 [81920/90000 (91%)]	Loss: 10.4083	Cost: 9.83s
Train Epoch: 422 	Average Loss: 10.2962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9461

Learning rate: 0.00019999121203556597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 423 [0/90000 (0%)]	Loss: 10.4276	Cost: 26.91s
Train Epoch: 423 [20480/90000 (23%)]	Loss: 10.5209	Cost: 11.89s
Train Epoch: 423 [40960/90000 (45%)]	Loss: 10.1933	Cost: 6.48s
Train Epoch: 423 [61440/90000 (68%)]	Loss: 10.2503	Cost: 5.93s
Train Epoch: 423 [81920/90000 (91%)]	Loss: 10.3867	Cost: 6.89s
Train Epoch: 423 	Average Loss: 10.2502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9665

Learning rate: 0.0001999911703377118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 424 [0/90000 (0%)]	Loss: 10.5877	Cost: 26.99s
Train Epoch: 424 [20480/90000 (23%)]	Loss: 10.3379	Cost: 6.89s
Train Epoch: 424 [40960/90000 (45%)]	Loss: 10.2374	Cost: 6.21s
Train Epoch: 424 [61440/90000 (68%)]	Loss: 10.2299	Cost: 6.80s
Train Epoch: 424 [81920/90000 (91%)]	Loss: 10.3929	Cost: 6.07s
Train Epoch: 424 	Average Loss: 10.2531
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8480

Saving model as e424_model.pt & e424_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999112854117028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 425 [0/90000 (0%)]	Loss: 10.5498	Cost: 27.89s
Train Epoch: 425 [20480/90000 (23%)]	Loss: 10.3473	Cost: 12.15s
Train Epoch: 425 [40960/90000 (45%)]	Loss: 10.2335	Cost: 11.92s
Train Epoch: 425 [61440/90000 (68%)]	Loss: 10.4158	Cost: 9.81s
Train Epoch: 425 [81920/90000 (91%)]	Loss: 10.1898	Cost: 5.85s
Train Epoch: 425 	Average Loss: 10.2500
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9484

Learning rate: 0.00019999108664594148
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 426 [0/90000 (0%)]	Loss: 10.5526	Cost: 28.08s
Train Epoch: 426 [20480/90000 (23%)]	Loss: 10.3588	Cost: 10.73s
Train Epoch: 426 [40960/90000 (45%)]	Loss: 10.2977	Cost: 6.60s
Train Epoch: 426 [61440/90000 (68%)]	Loss: 10.2262	Cost: 6.07s
Train Epoch: 426 [81920/90000 (91%)]	Loss: 10.3886	Cost: 6.98s
Train Epoch: 426 	Average Loss: 10.2448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7869

Saving model as e426_model.pt & e426_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999910446520254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 427 [0/90000 (0%)]	Loss: 10.4939	Cost: 26.12s
Train Epoch: 427 [20480/90000 (23%)]	Loss: 10.2055	Cost: 11.88s
Train Epoch: 427 [40960/90000 (45%)]	Loss: 10.2803	Cost: 12.19s
Train Epoch: 427 [61440/90000 (68%)]	Loss: 10.4028	Cost: 11.87s
Train Epoch: 427 [81920/90000 (91%)]	Loss: 10.3095	Cost: 11.79s
Train Epoch: 427 	Average Loss: 10.2384
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8686

Learning rate: 0.00019999100255942216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 428 [0/90000 (0%)]	Loss: 10.4857	Cost: 27.25s
Train Epoch: 428 [20480/90000 (23%)]	Loss: 10.2914	Cost: 11.90s
Train Epoch: 428 [40960/90000 (45%)]	Loss: 10.2522	Cost: 11.90s
Train Epoch: 428 [61440/90000 (68%)]	Loss: 10.1821	Cost: 11.81s
Train Epoch: 428 [81920/90000 (91%)]	Loss: 10.1656	Cost: 6.13s
Train Epoch: 428 	Average Loss: 10.2520
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8279

Learning rate: 0.00019999096036813171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 429 [0/90000 (0%)]	Loss: 10.6048	Cost: 26.98s
Train Epoch: 429 [20480/90000 (23%)]	Loss: 10.3312	Cost: 11.82s
Train Epoch: 429 [40960/90000 (45%)]	Loss: 10.2358	Cost: 10.54s
Train Epoch: 429 [61440/90000 (68%)]	Loss: 10.3846	Cost: 5.75s
Train Epoch: 429 [81920/90000 (91%)]	Loss: 10.2651	Cost: 6.47s
Train Epoch: 429 	Average Loss: 10.2381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8036

Learning rate: 0.0001999909180781542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 430 [0/90000 (0%)]	Loss: 10.6071	Cost: 26.96s
Train Epoch: 430 [20480/90000 (23%)]	Loss: 10.3271	Cost: 10.66s
Train Epoch: 430 [40960/90000 (45%)]	Loss: 10.3125	Cost: 6.14s
Train Epoch: 430 [61440/90000 (68%)]	Loss: 10.3019	Cost: 5.95s
Train Epoch: 430 [81920/90000 (91%)]	Loss: 10.3755	Cost: 6.82s
Train Epoch: 430 	Average Loss: 10.2518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8889

Learning rate: 0.00019999087568948958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 431 [0/90000 (0%)]	Loss: 10.6503	Cost: 28.04s
Train Epoch: 431 [20480/90000 (23%)]	Loss: 10.2785	Cost: 7.99s
Train Epoch: 431 [40960/90000 (45%)]	Loss: 10.2592	Cost: 6.39s
Train Epoch: 431 [61440/90000 (68%)]	Loss: 10.2142	Cost: 6.90s
Train Epoch: 431 [81920/90000 (91%)]	Loss: 10.2423	Cost: 6.14s
Train Epoch: 431 	Average Loss: 10.2542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8523

Learning rate: 0.0001999908332021379
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 432 [0/90000 (0%)]	Loss: 10.4279	Cost: 33.96s
Train Epoch: 432 [20480/90000 (23%)]	Loss: 10.2417	Cost: 6.52s
Train Epoch: 432 [40960/90000 (45%)]	Loss: 10.1306	Cost: 10.18s
Train Epoch: 432 [61440/90000 (68%)]	Loss: 10.2816	Cost: 6.16s
Train Epoch: 432 [81920/90000 (91%)]	Loss: 10.3197	Cost: 7.39s
Train Epoch: 432 	Average Loss: 10.2067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7826

Saving model as e432_model.pt & e432_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019999079061609924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 433 [0/90000 (0%)]	Loss: 10.6500	Cost: 26.81s
Train Epoch: 433 [20480/90000 (23%)]	Loss: 10.4334	Cost: 11.97s
Train Epoch: 433 [40960/90000 (45%)]	Loss: 10.1663	Cost: 10.70s
Train Epoch: 433 [61440/90000 (68%)]	Loss: 10.2721	Cost: 6.00s
Train Epoch: 433 [81920/90000 (91%)]	Loss: 10.2314	Cost: 6.00s
Train Epoch: 433 	Average Loss: 10.2227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8581

Learning rate: 0.00019999074793137364
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 434 [0/90000 (0%)]	Loss: 10.6117	Cost: 27.76s
Train Epoch: 434 [20480/90000 (23%)]	Loss: 10.2581	Cost: 10.17s
Train Epoch: 434 [40960/90000 (45%)]	Loss: 9.9066	Cost: 6.17s
Train Epoch: 434 [61440/90000 (68%)]	Loss: 10.0347	Cost: 5.97s
Train Epoch: 434 [81920/90000 (91%)]	Loss: 10.2378	Cost: 6.91s
Train Epoch: 434 	Average Loss: 10.1989
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8342

Learning rate: 0.00019999070514796111
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 435 [0/90000 (0%)]	Loss: 10.6989	Cost: 25.92s
Train Epoch: 435 [20480/90000 (23%)]	Loss: 10.1096	Cost: 7.66s
Train Epoch: 435 [40960/90000 (45%)]	Loss: 10.1496	Cost: 6.05s
Train Epoch: 435 [61440/90000 (68%)]	Loss: 10.1648	Cost: 6.89s
Train Epoch: 435 [81920/90000 (91%)]	Loss: 10.3264	Cost: 6.16s
Train Epoch: 435 	Average Loss: 10.1859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9060

Learning rate: 0.00019999066226586174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 436 [0/90000 (0%)]	Loss: 10.4117	Cost: 28.75s
Train Epoch: 436 [20480/90000 (23%)]	Loss: 10.2176	Cost: 6.37s
Train Epoch: 436 [40960/90000 (45%)]	Loss: 10.1534	Cost: 7.21s
Train Epoch: 436 [61440/90000 (68%)]	Loss: 10.3620	Cost: 6.31s
Train Epoch: 436 [81920/90000 (91%)]	Loss: 10.1372	Cost: 6.97s
Train Epoch: 436 	Average Loss: 10.2259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8703

Learning rate: 0.00019999061928507552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 437 [0/90000 (0%)]	Loss: 10.4591	Cost: 23.83s
Train Epoch: 437 [20480/90000 (23%)]	Loss: 10.3921	Cost: 6.32s
Train Epoch: 437 [40960/90000 (45%)]	Loss: 10.2439	Cost: 8.05s
Train Epoch: 437 [61440/90000 (68%)]	Loss: 10.2217	Cost: 6.83s
Train Epoch: 437 [81920/90000 (91%)]	Loss: 10.2723	Cost: 15.99s
Train Epoch: 437 	Average Loss: 10.2016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8559

Learning rate: 0.0001999905762056025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 438 [0/90000 (0%)]	Loss: 10.3839	Cost: 24.91s
Train Epoch: 438 [20480/90000 (23%)]	Loss: 10.4236	Cost: 7.92s
Train Epoch: 438 [40960/90000 (45%)]	Loss: 10.0358	Cost: 16.06s
Train Epoch: 438 [61440/90000 (68%)]	Loss: 10.2703	Cost: 12.01s
Train Epoch: 438 [81920/90000 (91%)]	Loss: 10.3561	Cost: 12.13s
Train Epoch: 438 	Average Loss: 10.2025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7925

Learning rate: 0.00019999053302744273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 439 [0/90000 (0%)]	Loss: 10.5893	Cost: 28.09s
Train Epoch: 439 [20480/90000 (23%)]	Loss: 10.1169	Cost: 9.09s
Train Epoch: 439 [40960/90000 (45%)]	Loss: 10.0834	Cost: 9.46s
Train Epoch: 439 [61440/90000 (68%)]	Loss: 10.2089	Cost: 5.98s
Train Epoch: 439 [81920/90000 (91%)]	Loss: 10.3224	Cost: 6.74s
Train Epoch: 439 	Average Loss: 10.1563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8233

Learning rate: 0.00019999048975059627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 440 [0/90000 (0%)]	Loss: 10.3896	Cost: 65.96s
Train Epoch: 440 [20480/90000 (23%)]	Loss: 10.0977	Cost: 6.27s
Train Epoch: 440 [40960/90000 (45%)]	Loss: 10.0371	Cost: 12.07s
Train Epoch: 440 [61440/90000 (68%)]	Loss: 10.1439	Cost: 6.59s
Train Epoch: 440 [81920/90000 (91%)]	Loss: 10.3131	Cost: 11.67s
Train Epoch: 440 	Average Loss: 10.1537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8077

Learning rate: 0.00019999044637506315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 441 [0/90000 (0%)]	Loss: 10.7371	Cost: 30.79s
Train Epoch: 441 [20480/90000 (23%)]	Loss: 10.2578	Cost: 17.57s
Train Epoch: 441 [40960/90000 (45%)]	Loss: 10.1655	Cost: 20.28s
Train Epoch: 441 [61440/90000 (68%)]	Loss: 10.2594	Cost: 21.88s
Train Epoch: 441 [81920/90000 (91%)]	Loss: 10.2127	Cost: 22.38s
Train Epoch: 441 	Average Loss: 10.1973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7413

Saving model as e441_model.pt & e441_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999904029008434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 442 [0/90000 (0%)]	Loss: 10.6249	Cost: 74.11s
Train Epoch: 442 [20480/90000 (23%)]	Loss: 10.2663	Cost: 12.57s
Train Epoch: 442 [40960/90000 (45%)]	Loss: 10.1775	Cost: 26.82s
Train Epoch: 442 [61440/90000 (68%)]	Loss: 10.3480	Cost: 9.75s
Train Epoch: 442 [81920/90000 (91%)]	Loss: 10.1627	Cost: 39.47s
Train Epoch: 442 	Average Loss: 10.1687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7651

Learning rate: 0.0001999903593279371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 443 [0/90000 (0%)]	Loss: 10.6161	Cost: 70.38s
Train Epoch: 443 [20480/90000 (23%)]	Loss: 10.2403	Cost: 6.62s
Train Epoch: 443 [40960/90000 (45%)]	Loss: 9.9956	Cost: 11.35s
Train Epoch: 443 [61440/90000 (68%)]	Loss: 10.2526	Cost: 6.68s
Train Epoch: 443 [81920/90000 (91%)]	Loss: 10.2161	Cost: 17.06s
Train Epoch: 443 	Average Loss: 10.1556
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8851

Learning rate: 0.00019999031565634426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 444 [0/90000 (0%)]	Loss: 10.4122	Cost: 23.03s
Train Epoch: 444 [20480/90000 (23%)]	Loss: 10.2705	Cost: 6.48s
Train Epoch: 444 [40960/90000 (45%)]	Loss: 10.1079	Cost: 13.01s
Train Epoch: 444 [61440/90000 (68%)]	Loss: 10.0259	Cost: 12.06s
Train Epoch: 444 [81920/90000 (91%)]	Loss: 10.3232	Cost: 11.86s
Train Epoch: 444 	Average Loss: 10.1609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7816

Learning rate: 0.00019999027188606495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 445 [0/90000 (0%)]	Loss: 10.3994	Cost: 99.67s
Train Epoch: 445 [20480/90000 (23%)]	Loss: 10.3299	Cost: 13.22s
Train Epoch: 445 [40960/90000 (45%)]	Loss: 10.1115	Cost: 27.19s
Train Epoch: 445 [61440/90000 (68%)]	Loss: 10.1021	Cost: 13.47s
Train Epoch: 445 [81920/90000 (91%)]	Loss: 10.2606	Cost: 32.99s
Train Epoch: 445 	Average Loss: 10.1350
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8324

Learning rate: 0.0001999902280170992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 446 [0/90000 (0%)]	Loss: 10.3941	Cost: 26.43s
Train Epoch: 446 [20480/90000 (23%)]	Loss: 10.2161	Cost: 6.91s
Train Epoch: 446 [40960/90000 (45%)]	Loss: 10.0025	Cost: 18.12s
Train Epoch: 446 [61440/90000 (68%)]	Loss: 10.3024	Cost: 35.68s
Train Epoch: 446 [81920/90000 (91%)]	Loss: 10.1449	Cost: 44.15s
Train Epoch: 446 	Average Loss: 10.1409
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7859

Learning rate: 0.00019999018404944703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 447 [0/90000 (0%)]	Loss: 10.4769	Cost: 34.74s
Train Epoch: 447 [20480/90000 (23%)]	Loss: 10.1161	Cost: 11.18s
Train Epoch: 447 [40960/90000 (45%)]	Loss: 10.1798	Cost: 7.04s
Train Epoch: 447 [61440/90000 (68%)]	Loss: 10.2611	Cost: 6.88s
Train Epoch: 447 [81920/90000 (91%)]	Loss: 10.1220	Cost: 8.54s
Train Epoch: 447 	Average Loss: 10.1226
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7688

Learning rate: 0.0001999901399831085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 448 [0/90000 (0%)]	Loss: 10.3455	Cost: 67.32s
Train Epoch: 448 [20480/90000 (23%)]	Loss: 10.1774	Cost: 6.55s
Train Epoch: 448 [40960/90000 (45%)]	Loss: 9.9304	Cost: 7.31s
Train Epoch: 448 [61440/90000 (68%)]	Loss: 10.2391	Cost: 6.84s
Train Epoch: 448 [81920/90000 (91%)]	Loss: 10.1257	Cost: 17.35s
Train Epoch: 448 	Average Loss: 10.1216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7765

Learning rate: 0.00019999009581808368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 449 [0/90000 (0%)]	Loss: 10.4205	Cost: 35.44s
Train Epoch: 449 [20480/90000 (23%)]	Loss: 10.1900	Cost: 11.79s
Train Epoch: 449 [40960/90000 (45%)]	Loss: 10.0271	Cost: 12.21s
Train Epoch: 449 [61440/90000 (68%)]	Loss: 10.1213	Cost: 11.92s
Train Epoch: 449 [81920/90000 (91%)]	Loss: 10.0981	Cost: 6.26s
Train Epoch: 449 	Average Loss: 10.1094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8955

Learning rate: 0.00019999005155437258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 450 [0/90000 (0%)]	Loss: 10.5248	Cost: 49.22s
Train Epoch: 450 [20480/90000 (23%)]	Loss: 10.1913	Cost: 14.36s
Train Epoch: 450 [40960/90000 (45%)]	Loss: 9.9285	Cost: 16.61s
Train Epoch: 450 [61440/90000 (68%)]	Loss: 10.0747	Cost: 13.57s
Train Epoch: 450 [81920/90000 (91%)]	Loss: 10.3625	Cost: 15.10s
Train Epoch: 450 	Average Loss: 10.1350
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8307

Learning rate: 0.00019999000719197527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 451 [0/90000 (0%)]	Loss: 10.3665	Cost: 83.78s
Train Epoch: 451 [20480/90000 (23%)]	Loss: 10.2562	Cost: 16.21s
Train Epoch: 451 [40960/90000 (45%)]	Loss: 10.0873	Cost: 31.33s
Train Epoch: 451 [61440/90000 (68%)]	Loss: 10.0169	Cost: 12.01s
Train Epoch: 451 [81920/90000 (91%)]	Loss: 10.1342	Cost: 33.64s
Train Epoch: 451 	Average Loss: 10.1432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8945

Learning rate: 0.00019998996273089178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 452 [0/90000 (0%)]	Loss: 10.3777	Cost: 67.54s
Train Epoch: 452 [20480/90000 (23%)]	Loss: 10.1260	Cost: 9.89s
Train Epoch: 452 [40960/90000 (45%)]	Loss: 10.2258	Cost: 20.09s
Train Epoch: 452 [61440/90000 (68%)]	Loss: 9.9577	Cost: 11.06s
Train Epoch: 452 [81920/90000 (91%)]	Loss: 10.1753	Cost: 20.76s
Train Epoch: 452 	Average Loss: 10.1086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7574

Learning rate: 0.00019998991817112214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 453 [0/90000 (0%)]	Loss: 10.5626	Cost: 61.45s
Train Epoch: 453 [20480/90000 (23%)]	Loss: 10.0422	Cost: 11.06s
Train Epoch: 453 [40960/90000 (45%)]	Loss: 10.0816	Cost: 20.56s
Train Epoch: 453 [61440/90000 (68%)]	Loss: 10.0167	Cost: 12.22s
Train Epoch: 453 [81920/90000 (91%)]	Loss: 10.1204	Cost: 24.81s
Train Epoch: 453 	Average Loss: 10.1221
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8147

Learning rate: 0.00019998987351266641
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 454 [0/90000 (0%)]	Loss: 10.3596	Cost: 84.83s
Train Epoch: 454 [20480/90000 (23%)]	Loss: 10.0427	Cost: 10.45s
Train Epoch: 454 [40960/90000 (45%)]	Loss: 9.9918	Cost: 22.97s
Train Epoch: 454 [61440/90000 (68%)]	Loss: 10.0303	Cost: 11.38s
Train Epoch: 454 [81920/90000 (91%)]	Loss: 10.1269	Cost: 23.80s
Train Epoch: 454 	Average Loss: 10.1187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8741

Learning rate: 0.00019998982875552463
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 455 [0/90000 (0%)]	Loss: 10.6914	Cost: 71.16s
Train Epoch: 455 [20480/90000 (23%)]	Loss: 10.2030	Cost: 14.35s
Train Epoch: 455 [40960/90000 (45%)]	Loss: 10.0716	Cost: 16.95s
Train Epoch: 455 [61440/90000 (68%)]	Loss: 10.0430	Cost: 11.64s
Train Epoch: 455 [81920/90000 (91%)]	Loss: 10.1926	Cost: 16.25s
Train Epoch: 455 	Average Loss: 10.1342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8368

Learning rate: 0.00019998978389969684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 456 [0/90000 (0%)]	Loss: 10.4622	Cost: 64.13s
Train Epoch: 456 [20480/90000 (23%)]	Loss: 10.1573	Cost: 10.98s
Train Epoch: 456 [40960/90000 (45%)]	Loss: 10.0517	Cost: 21.78s
Train Epoch: 456 [61440/90000 (68%)]	Loss: 10.0546	Cost: 13.66s
Train Epoch: 456 [81920/90000 (91%)]	Loss: 10.1730	Cost: 21.65s
Train Epoch: 456 	Average Loss: 10.1173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7981

Learning rate: 0.0001999897389451831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 457 [0/90000 (0%)]	Loss: 10.4370	Cost: 86.81s
Train Epoch: 457 [20480/90000 (23%)]	Loss: 10.1461	Cost: 10.28s
Train Epoch: 457 [40960/90000 (45%)]	Loss: 9.8634	Cost: 22.83s
Train Epoch: 457 [61440/90000 (68%)]	Loss: 10.0644	Cost: 11.70s
Train Epoch: 457 [81920/90000 (91%)]	Loss: 10.1158	Cost: 28.87s
Train Epoch: 457 	Average Loss: 10.0963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7668

Learning rate: 0.00019998969389198342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 458 [0/90000 (0%)]	Loss: 10.3559	Cost: 104.62s
Train Epoch: 458 [20480/90000 (23%)]	Loss: 10.1450	Cost: 16.71s
Train Epoch: 458 [40960/90000 (45%)]	Loss: 10.0603	Cost: 23.64s
Train Epoch: 458 [61440/90000 (68%)]	Loss: 10.0907	Cost: 14.96s
Train Epoch: 458 [81920/90000 (91%)]	Loss: 10.1905	Cost: 22.67s
Train Epoch: 458 	Average Loss: 10.0800
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7222

Saving model as e458_model.pt & e458_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998964874009788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 459 [0/90000 (0%)]	Loss: 10.6316	Cost: 99.08s
Train Epoch: 459 [20480/90000 (23%)]	Loss: 10.0618	Cost: 14.65s
Train Epoch: 459 [40960/90000 (45%)]	Loss: 10.1034	Cost: 28.49s
Train Epoch: 459 [61440/90000 (68%)]	Loss: 10.3170	Cost: 17.12s
Train Epoch: 459 [81920/90000 (91%)]	Loss: 10.1979	Cost: 19.23s
Train Epoch: 459 	Average Loss: 10.1305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8515

Learning rate: 0.00019998960348952653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 460 [0/90000 (0%)]	Loss: 10.3326	Cost: 102.18s
Train Epoch: 460 [20480/90000 (23%)]	Loss: 10.0886	Cost: 11.79s
Train Epoch: 460 [40960/90000 (45%)]	Loss: 10.0815	Cost: 22.06s
Train Epoch: 460 [61440/90000 (68%)]	Loss: 10.0526	Cost: 11.63s
Train Epoch: 460 [81920/90000 (91%)]	Loss: 10.0511	Cost: 26.32s
Train Epoch: 460 	Average Loss: 10.1025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7829

Learning rate: 0.00019998955814026938
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 461 [0/90000 (0%)]	Loss: 10.5293	Cost: 112.05s
Train Epoch: 461 [20480/90000 (23%)]	Loss: 10.2373	Cost: 12.14s
Train Epoch: 461 [40960/90000 (45%)]	Loss: 9.8860	Cost: 20.72s
Train Epoch: 461 [61440/90000 (68%)]	Loss: 10.1356	Cost: 10.65s
Train Epoch: 461 [81920/90000 (91%)]	Loss: 10.0480	Cost: 29.21s
Train Epoch: 461 	Average Loss: 10.0731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7640

Learning rate: 0.0001999895126923265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 462 [0/90000 (0%)]	Loss: 10.4147	Cost: 82.82s
Train Epoch: 462 [20480/90000 (23%)]	Loss: 10.1238	Cost: 17.16s
Train Epoch: 462 [40960/90000 (45%)]	Loss: 10.0579	Cost: 16.71s
Train Epoch: 462 [61440/90000 (68%)]	Loss: 10.0791	Cost: 14.14s
Train Epoch: 462 [81920/90000 (91%)]	Loss: 10.0592	Cost: 22.11s
Train Epoch: 462 	Average Loss: 10.0904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8423

Learning rate: 0.00019998946714569794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 463 [0/90000 (0%)]	Loss: 10.4542	Cost: 87.95s
Train Epoch: 463 [20480/90000 (23%)]	Loss: 10.0695	Cost: 14.20s
Train Epoch: 463 [40960/90000 (45%)]	Loss: 10.0278	Cost: 26.22s
Train Epoch: 463 [61440/90000 (68%)]	Loss: 9.9907	Cost: 14.29s
Train Epoch: 463 [81920/90000 (91%)]	Loss: 10.0996	Cost: 21.61s
Train Epoch: 463 	Average Loss: 10.0560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7731

Learning rate: 0.0001999894215003837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 464 [0/90000 (0%)]	Loss: 10.4110	Cost: 85.98s
Train Epoch: 464 [20480/90000 (23%)]	Loss: 9.9954	Cost: 11.25s
Train Epoch: 464 [40960/90000 (45%)]	Loss: 10.1204	Cost: 26.94s
Train Epoch: 464 [61440/90000 (68%)]	Loss: 10.0501	Cost: 16.45s
Train Epoch: 464 [81920/90000 (91%)]	Loss: 10.1469	Cost: 21.02s
Train Epoch: 464 	Average Loss: 10.0458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6747

Saving model as e464_model.pt & e464_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998937575638385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 465 [0/90000 (0%)]	Loss: 10.5672	Cost: 94.01s
Train Epoch: 465 [20480/90000 (23%)]	Loss: 10.1183	Cost: 13.48s
Train Epoch: 465 [40960/90000 (45%)]	Loss: 10.0827	Cost: 20.49s
Train Epoch: 465 [61440/90000 (68%)]	Loss: 10.2438	Cost: 10.76s
Train Epoch: 465 [81920/90000 (91%)]	Loss: 10.1003	Cost: 27.64s
Train Epoch: 465 	Average Loss: 10.0600
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8476

Learning rate: 0.0001999893299136985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 466 [0/90000 (0%)]	Loss: 10.4355	Cost: 100.80s
Train Epoch: 466 [20480/90000 (23%)]	Loss: 9.9412	Cost: 17.48s
Train Epoch: 466 [40960/90000 (45%)]	Loss: 10.0288	Cost: 23.97s
Train Epoch: 466 [61440/90000 (68%)]	Loss: 9.9780	Cost: 13.80s
Train Epoch: 466 [81920/90000 (91%)]	Loss: 9.9786	Cost: 22.43s
Train Epoch: 466 	Average Loss: 10.0263
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7702

Learning rate: 0.00019998928397232759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 467 [0/90000 (0%)]	Loss: 10.3717	Cost: 95.20s
Train Epoch: 467 [20480/90000 (23%)]	Loss: 10.1458	Cost: 11.94s
Train Epoch: 467 [40960/90000 (45%)]	Loss: 9.9343	Cost: 19.02s
Train Epoch: 467 [61440/90000 (68%)]	Loss: 10.1085	Cost: 12.15s
Train Epoch: 467 [81920/90000 (91%)]	Loss: 10.0997	Cost: 19.91s
Train Epoch: 467 	Average Loss: 10.0457
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8046

Learning rate: 0.00019998923793227122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 468 [0/90000 (0%)]	Loss: 10.4707	Cost: 89.00s
Train Epoch: 468 [20480/90000 (23%)]	Loss: 10.1006	Cost: 15.93s
Train Epoch: 468 [40960/90000 (45%)]	Loss: 10.1216	Cost: 25.48s
Train Epoch: 468 [61440/90000 (68%)]	Loss: 10.3307	Cost: 12.70s
Train Epoch: 468 [81920/90000 (91%)]	Loss: 10.0658	Cost: 15.48s
Train Epoch: 468 	Average Loss: 10.0642
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7793

Learning rate: 0.0001999891917935294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 469 [0/90000 (0%)]	Loss: 10.5381	Cost: 98.27s
Train Epoch: 469 [20480/90000 (23%)]	Loss: 10.0083	Cost: 6.51s
Train Epoch: 469 [40960/90000 (45%)]	Loss: 10.0868	Cost: 6.48s
Train Epoch: 469 [61440/90000 (68%)]	Loss: 9.9505	Cost: 6.27s
Train Epoch: 469 [81920/90000 (91%)]	Loss: 10.0170	Cost: 6.19s
Train Epoch: 469 	Average Loss: 10.0102
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7006

Learning rate: 0.00019998914555610225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 470 [0/90000 (0%)]	Loss: 10.5413	Cost: 22.93s
Train Epoch: 470 [20480/90000 (23%)]	Loss: 9.9742	Cost: 6.26s
Train Epoch: 470 [40960/90000 (45%)]	Loss: 9.8451	Cost: 8.61s
Train Epoch: 470 [61440/90000 (68%)]	Loss: 10.0805	Cost: 7.99s
Train Epoch: 470 [81920/90000 (91%)]	Loss: 9.9060	Cost: 14.13s
Train Epoch: 470 	Average Loss: 10.0280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7819

Learning rate: 0.00019998909921998975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 471 [0/90000 (0%)]	Loss: 10.3639	Cost: 28.54s
Train Epoch: 471 [20480/90000 (23%)]	Loss: 10.1394	Cost: 12.35s
Train Epoch: 471 [40960/90000 (45%)]	Loss: 10.0242	Cost: 12.27s
Train Epoch: 471 [61440/90000 (68%)]	Loss: 9.9697	Cost: 11.88s
Train Epoch: 471 [81920/90000 (91%)]	Loss: 10.1700	Cost: 11.84s
Train Epoch: 471 	Average Loss: 10.0373
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8170

Learning rate: 0.00019998905278519196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 472 [0/90000 (0%)]	Loss: 10.4335	Cost: 36.56s
Train Epoch: 472 [20480/90000 (23%)]	Loss: 10.1159	Cost: 11.89s
Train Epoch: 472 [40960/90000 (45%)]	Loss: 10.0767	Cost: 12.08s
Train Epoch: 472 [61440/90000 (68%)]	Loss: 10.0439	Cost: 6.36s
Train Epoch: 472 [81920/90000 (91%)]	Loss: 9.8637	Cost: 5.92s
Train Epoch: 472 	Average Loss: 10.0201
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7159

Learning rate: 0.00019998900625170892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 473 [0/90000 (0%)]	Loss: 10.4244	Cost: 27.67s
Train Epoch: 473 [20480/90000 (23%)]	Loss: 10.2414	Cost: 10.39s
Train Epoch: 473 [40960/90000 (45%)]	Loss: 9.8932	Cost: 6.64s
Train Epoch: 473 [61440/90000 (68%)]	Loss: 9.9006	Cost: 5.89s
Train Epoch: 473 [81920/90000 (91%)]	Loss: 10.1035	Cost: 6.84s
Train Epoch: 473 	Average Loss: 9.9850
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7862

Learning rate: 0.0001999889596195407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 474 [0/90000 (0%)]	Loss: 10.3785	Cost: 24.44s
Train Epoch: 474 [20480/90000 (23%)]	Loss: 10.1313	Cost: 6.25s
Train Epoch: 474 [40960/90000 (45%)]	Loss: 10.0924	Cost: 6.41s
Train Epoch: 474 [61440/90000 (68%)]	Loss: 10.0625	Cost: 6.08s
Train Epoch: 474 [81920/90000 (91%)]	Loss: 10.0578	Cost: 6.11s
Train Epoch: 474 	Average Loss: 10.0418
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6988

Learning rate: 0.00019998891288868732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 475 [0/90000 (0%)]	Loss: 10.2567	Cost: 22.78s
Train Epoch: 475 [20480/90000 (23%)]	Loss: 10.0862	Cost: 6.11s
Train Epoch: 475 [40960/90000 (45%)]	Loss: 9.8763	Cost: 7.19s
Train Epoch: 475 [61440/90000 (68%)]	Loss: 10.2469	Cost: 6.23s
Train Epoch: 475 [81920/90000 (91%)]	Loss: 10.0046	Cost: 15.56s
Train Epoch: 475 	Average Loss: 9.9919
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8674

Learning rate: 0.00019998886605914883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 476 [0/90000 (0%)]	Loss: 10.6502	Cost: 26.51s
Train Epoch: 476 [20480/90000 (23%)]	Loss: 10.0243	Cost: 11.26s
Train Epoch: 476 [40960/90000 (45%)]	Loss: 9.8543	Cost: 12.79s
Train Epoch: 476 [61440/90000 (68%)]	Loss: 9.7731	Cost: 11.71s
Train Epoch: 476 [81920/90000 (91%)]	Loss: 9.9597	Cost: 11.82s
Train Epoch: 476 	Average Loss: 9.9824
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8041

Learning rate: 0.00019998881913092532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 477 [0/90000 (0%)]	Loss: 10.4355	Cost: 41.55s
Train Epoch: 477 [20480/90000 (23%)]	Loss: 10.1658	Cost: 11.78s
Train Epoch: 477 [40960/90000 (45%)]	Loss: 9.9031	Cost: 12.09s
Train Epoch: 477 [61440/90000 (68%)]	Loss: 10.1221	Cost: 6.29s
Train Epoch: 477 [81920/90000 (91%)]	Loss: 10.1246	Cost: 5.88s
Train Epoch: 477 	Average Loss: 10.0177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7734

Learning rate: 0.00019998877210401677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 478 [0/90000 (0%)]	Loss: 10.3717	Cost: 26.85s
Train Epoch: 478 [20480/90000 (23%)]	Loss: 10.2196	Cost: 8.66s
Train Epoch: 478 [40960/90000 (45%)]	Loss: 10.0252	Cost: 6.10s
Train Epoch: 478 [61440/90000 (68%)]	Loss: 10.0383	Cost: 6.79s
Train Epoch: 478 [81920/90000 (91%)]	Loss: 10.0527	Cost: 6.14s
Train Epoch: 478 	Average Loss: 10.0077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7780

Learning rate: 0.00019998872497842328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 479 [0/90000 (0%)]	Loss: 10.3290	Cost: 24.11s
Train Epoch: 479 [20480/90000 (23%)]	Loss: 9.9512	Cost: 6.44s
Train Epoch: 479 [40960/90000 (45%)]	Loss: 9.8582	Cost: 7.26s
Train Epoch: 479 [61440/90000 (68%)]	Loss: 9.9692	Cost: 6.15s
Train Epoch: 479 [81920/90000 (91%)]	Loss: 10.2135	Cost: 7.02s
Train Epoch: 479 	Average Loss: 10.0021
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7369

Learning rate: 0.00019998867775414486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 480 [0/90000 (0%)]	Loss: 10.3659	Cost: 34.36s
Train Epoch: 480 [20480/90000 (23%)]	Loss: 10.0134	Cost: 8.97s
Train Epoch: 480 [40960/90000 (45%)]	Loss: 9.7611	Cost: 13.63s
Train Epoch: 480 [61440/90000 (68%)]	Loss: 9.9236	Cost: 12.06s
Train Epoch: 480 [81920/90000 (91%)]	Loss: 10.0353	Cost: 11.92s
Train Epoch: 480 	Average Loss: 9.9737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7336

Learning rate: 0.00019998863043118158
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 481 [0/90000 (0%)]	Loss: 10.2643	Cost: 26.94s
Train Epoch: 481 [20480/90000 (23%)]	Loss: 9.9088	Cost: 12.26s
Train Epoch: 481 [40960/90000 (45%)]	Loss: 9.9748	Cost: 11.60s
Train Epoch: 481 [61440/90000 (68%)]	Loss: 9.8885	Cost: 10.98s
Train Epoch: 481 [81920/90000 (91%)]	Loss: 9.9805	Cost: 5.83s
Train Epoch: 481 	Average Loss: 9.9616
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6978

Learning rate: 0.00019998858300953348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 482 [0/90000 (0%)]	Loss: 10.3083	Cost: 29.12s
Train Epoch: 482 [20480/90000 (23%)]	Loss: 9.9536	Cost: 9.94s
Train Epoch: 482 [40960/90000 (45%)]	Loss: 9.9932	Cost: 6.32s
Train Epoch: 482 [61440/90000 (68%)]	Loss: 9.8974	Cost: 5.86s
Train Epoch: 482 [81920/90000 (91%)]	Loss: 10.1493	Cost: 6.86s
Train Epoch: 482 	Average Loss: 9.9718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6633

Saving model as e482_model.pt & e482_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999885354892006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 483 [0/90000 (0%)]	Loss: 10.4177	Cost: 38.57s
Train Epoch: 483 [20480/90000 (23%)]	Loss: 9.9342	Cost: 12.62s
Train Epoch: 483 [40960/90000 (45%)]	Loss: 9.7886	Cost: 12.79s
Train Epoch: 483 [61440/90000 (68%)]	Loss: 9.8894	Cost: 11.94s
Train Epoch: 483 [81920/90000 (91%)]	Loss: 10.0728	Cost: 8.15s
Train Epoch: 483 	Average Loss: 9.9193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7135

Learning rate: 0.000199988487870183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 484 [0/90000 (0%)]	Loss: 10.4253	Cost: 27.06s
Train Epoch: 484 [20480/90000 (23%)]	Loss: 9.9827	Cost: 11.22s
Train Epoch: 484 [40960/90000 (45%)]	Loss: 9.8892	Cost: 6.14s
Train Epoch: 484 [61440/90000 (68%)]	Loss: 9.7088	Cost: 5.86s
Train Epoch: 484 [81920/90000 (91%)]	Loss: 9.8112	Cost: 6.83s
Train Epoch: 484 	Average Loss: 9.9435
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7222

Learning rate: 0.00019998844015248072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 485 [0/90000 (0%)]	Loss: 10.3087	Cost: 22.82s
Train Epoch: 485 [20480/90000 (23%)]	Loss: 9.8211	Cost: 6.51s
Train Epoch: 485 [40960/90000 (45%)]	Loss: 9.7807	Cost: 6.46s
Train Epoch: 485 [61440/90000 (68%)]	Loss: 9.9873	Cost: 6.24s
Train Epoch: 485 [81920/90000 (91%)]	Loss: 10.0322	Cost: 6.39s
Train Epoch: 485 	Average Loss: 9.9368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7335

Learning rate: 0.0001999883923360938
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 486 [0/90000 (0%)]	Loss: 10.3960	Cost: 23.53s
Train Epoch: 486 [20480/90000 (23%)]	Loss: 9.9060	Cost: 6.31s
Train Epoch: 486 [40960/90000 (45%)]	Loss: 9.8172	Cost: 15.66s
Train Epoch: 486 [61440/90000 (68%)]	Loss: 9.9121	Cost: 12.36s
Train Epoch: 486 [81920/90000 (91%)]	Loss: 9.8688	Cost: 12.15s
Train Epoch: 486 	Average Loss: 9.9365
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6378

Saving model as e486_model.pt & e486_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998834442102228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 487 [0/90000 (0%)]	Loss: 10.3487	Cost: 22.18s
Train Epoch: 487 [20480/90000 (23%)]	Loss: 9.9940	Cost: 6.56s
Train Epoch: 487 [40960/90000 (45%)]	Loss: 9.8184	Cost: 8.11s
Train Epoch: 487 [61440/90000 (68%)]	Loss: 9.9478	Cost: 10.26s
Train Epoch: 487 [81920/90000 (91%)]	Loss: 9.9868	Cost: 14.20s
Train Epoch: 487 	Average Loss: 9.9328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6529

Learning rate: 0.00019998829640726623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 488 [0/90000 (0%)]	Loss: 10.3329	Cost: 28.73s
Train Epoch: 488 [20480/90000 (23%)]	Loss: 10.0024	Cost: 12.08s
Train Epoch: 488 [40960/90000 (45%)]	Loss: 10.0042	Cost: 12.09s
Train Epoch: 488 [61440/90000 (68%)]	Loss: 9.8653	Cost: 11.81s
Train Epoch: 488 [81920/90000 (91%)]	Loss: 10.1218	Cost: 10.37s
Train Epoch: 488 	Average Loss: 9.9313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6700

Learning rate: 0.00019998824829482568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 489 [0/90000 (0%)]	Loss: 10.4356	Cost: 30.52s
Train Epoch: 489 [20480/90000 (23%)]	Loss: 10.0770	Cost: 9.91s
Train Epoch: 489 [40960/90000 (45%)]	Loss: 9.6884	Cost: 7.49s
Train Epoch: 489 [61440/90000 (68%)]	Loss: 9.9563	Cost: 6.41s
Train Epoch: 489 [81920/90000 (91%)]	Loss: 9.9232	Cost: 11.56s
Train Epoch: 489 	Average Loss: 9.9444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7315

Learning rate: 0.0001999882000837007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 490 [0/90000 (0%)]	Loss: 10.2772	Cost: 23.33s
Train Epoch: 490 [20480/90000 (23%)]	Loss: 10.0651	Cost: 6.30s
Train Epoch: 490 [40960/90000 (45%)]	Loss: 9.8151	Cost: 6.46s
Train Epoch: 490 [61440/90000 (68%)]	Loss: 9.8666	Cost: 6.21s
Train Epoch: 490 [81920/90000 (91%)]	Loss: 10.0499	Cost: 6.05s
Train Epoch: 490 	Average Loss: 9.9386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7484

Learning rate: 0.0001999881517738913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 491 [0/90000 (0%)]	Loss: 10.1873	Cost: 29.22s
Train Epoch: 491 [20480/90000 (23%)]	Loss: 10.1256	Cost: 6.38s
Train Epoch: 491 [40960/90000 (45%)]	Loss: 9.8510	Cost: 17.19s
Train Epoch: 491 [61440/90000 (68%)]	Loss: 9.7172	Cost: 12.15s
Train Epoch: 491 [81920/90000 (91%)]	Loss: 9.9438	Cost: 11.98s
Train Epoch: 491 	Average Loss: 9.8942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6686

Learning rate: 0.00019998810336539752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 492 [0/90000 (0%)]	Loss: 10.3737	Cost: 31.19s
Train Epoch: 492 [20480/90000 (23%)]	Loss: 10.1305	Cost: 12.28s
Train Epoch: 492 [40960/90000 (45%)]	Loss: 9.6816	Cost: 12.00s
Train Epoch: 492 [61440/90000 (68%)]	Loss: 9.8174	Cost: 10.12s
Train Epoch: 492 [81920/90000 (91%)]	Loss: 9.9342	Cost: 5.90s
Train Epoch: 492 	Average Loss: 9.9441
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7529

Learning rate: 0.00019998805485821946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 493 [0/90000 (0%)]	Loss: 10.3414	Cost: 24.06s
Train Epoch: 493 [20480/90000 (23%)]	Loss: 9.9324	Cost: 6.78s
Train Epoch: 493 [40960/90000 (45%)]	Loss: 9.9051	Cost: 6.44s
Train Epoch: 493 [61440/90000 (68%)]	Loss: 9.8624	Cost: 6.26s
Train Epoch: 493 [81920/90000 (91%)]	Loss: 9.8967	Cost: 6.27s
Train Epoch: 493 	Average Loss: 9.9053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6702

Learning rate: 0.00019998800625235718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 494 [0/90000 (0%)]	Loss: 10.3068	Cost: 22.96s
Train Epoch: 494 [20480/90000 (23%)]	Loss: 9.9104	Cost: 6.28s
Train Epoch: 494 [40960/90000 (45%)]	Loss: 9.8237	Cost: 9.40s
Train Epoch: 494 [61440/90000 (68%)]	Loss: 9.9971	Cost: 9.44s
Train Epoch: 494 [81920/90000 (91%)]	Loss: 9.9524	Cost: 14.08s
Train Epoch: 494 	Average Loss: 9.8996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6125

Saving model as e494_model.pt & e494_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998795754781068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 495 [0/90000 (0%)]	Loss: 10.1181	Cost: 26.37s
Train Epoch: 495 [20480/90000 (23%)]	Loss: 10.1180	Cost: 6.17s
Train Epoch: 495 [40960/90000 (45%)]	Loss: 9.8711	Cost: 13.82s
Train Epoch: 495 [61440/90000 (68%)]	Loss: 9.9872	Cost: 12.19s
Train Epoch: 495 [81920/90000 (91%)]	Loss: 9.7810	Cost: 11.90s
Train Epoch: 495 	Average Loss: 9.8971
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7322

Learning rate: 0.00019998790874458001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 496 [0/90000 (0%)]	Loss: 10.2671	Cost: 28.18s
Train Epoch: 496 [20480/90000 (23%)]	Loss: 9.8835	Cost: 11.91s
Train Epoch: 496 [40960/90000 (45%)]	Loss: 9.7832	Cost: 12.01s
Train Epoch: 496 [61440/90000 (68%)]	Loss: 9.9018	Cost: 11.82s
Train Epoch: 496 [81920/90000 (91%)]	Loss: 9.9680	Cost: 7.09s
Train Epoch: 496 	Average Loss: 9.9042
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7120

Learning rate: 0.00019998785984266522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 497 [0/90000 (0%)]	Loss: 10.3531	Cost: 27.08s
Train Epoch: 497 [20480/90000 (23%)]	Loss: 9.8733	Cost: 6.68s
Train Epoch: 497 [40960/90000 (45%)]	Loss: 9.8714	Cost: 6.36s
Train Epoch: 497 [61440/90000 (68%)]	Loss: 10.0482	Cost: 6.86s
Train Epoch: 497 [81920/90000 (91%)]	Loss: 10.0895	Cost: 6.39s
Train Epoch: 497 	Average Loss: 9.9090
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6750

Learning rate: 0.0001999878108420664
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 498 [0/90000 (0%)]	Loss: 10.3917	Cost: 22.04s
Train Epoch: 498 [20480/90000 (23%)]	Loss: 10.0506	Cost: 6.34s
Train Epoch: 498 [40960/90000 (45%)]	Loss: 9.8216	Cost: 6.64s
Train Epoch: 498 [61440/90000 (68%)]	Loss: 9.9154	Cost: 6.22s
Train Epoch: 498 [81920/90000 (91%)]	Loss: 9.9839	Cost: 15.05s
Train Epoch: 498 	Average Loss: 9.9219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6881

Learning rate: 0.0001999877617427835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 499 [0/90000 (0%)]	Loss: 10.2636	Cost: 33.31s
Train Epoch: 499 [20480/90000 (23%)]	Loss: 9.9752	Cost: 10.66s
Train Epoch: 499 [40960/90000 (45%)]	Loss: 9.9075	Cost: 12.12s
Train Epoch: 499 [61440/90000 (68%)]	Loss: 9.9897	Cost: 11.97s
Train Epoch: 499 [81920/90000 (91%)]	Loss: 9.8998	Cost: 11.88s
Train Epoch: 499 	Average Loss: 9.8977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6588

Learning rate: 0.00019998771254481668
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 500 [0/90000 (0%)]	Loss: 10.3284	Cost: 28.29s
Train Epoch: 500 [20480/90000 (23%)]	Loss: 9.8000	Cost: 11.87s
Train Epoch: 500 [40960/90000 (45%)]	Loss: 10.0013	Cost: 11.98s
Train Epoch: 500 [61440/90000 (68%)]	Loss: 9.8977	Cost: 9.39s
Train Epoch: 500 [81920/90000 (91%)]	Loss: 9.7962	Cost: 5.83s
Train Epoch: 500 	Average Loss: 9.8838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7120

Learning rate: 0.00019998766324816594
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 501 [0/90000 (0%)]	Loss: 10.2251	Cost: 26.48s
Train Epoch: 501 [20480/90000 (23%)]	Loss: 9.8680	Cost: 10.61s
Train Epoch: 501 [40960/90000 (45%)]	Loss: 9.7574	Cost: 6.05s
Train Epoch: 501 [61440/90000 (68%)]	Loss: 9.9225	Cost: 6.15s
Train Epoch: 501 [81920/90000 (91%)]	Loss: 9.7695	Cost: 6.68s
Train Epoch: 501 	Average Loss: 9.8678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7418

Learning rate: 0.00019998761385283135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 502 [0/90000 (0%)]	Loss: 10.2128	Cost: 23.07s
Train Epoch: 502 [20480/90000 (23%)]	Loss: 9.9454	Cost: 7.23s
Train Epoch: 502 [40960/90000 (45%)]	Loss: 9.7840	Cost: 8.27s
Train Epoch: 502 [61440/90000 (68%)]	Loss: 9.7816	Cost: 6.50s
Train Epoch: 502 [81920/90000 (91%)]	Loss: 10.0259	Cost: 9.85s
Train Epoch: 502 	Average Loss: 9.8653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5900

Saving model as e502_model.pt & e502_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998756435881293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 503 [0/90000 (0%)]	Loss: 10.4627	Cost: 23.73s
Train Epoch: 503 [20480/90000 (23%)]	Loss: 10.0884	Cost: 6.96s
Train Epoch: 503 [40960/90000 (45%)]	Loss: 9.9754	Cost: 6.50s
Train Epoch: 503 [61440/90000 (68%)]	Loss: 9.8801	Cost: 6.48s
Train Epoch: 503 [81920/90000 (91%)]	Loss: 9.8340	Cost: 6.22s
Train Epoch: 503 	Average Loss: 9.8892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6910

Learning rate: 0.00019998751476611075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 504 [0/90000 (0%)]	Loss: 10.2910	Cost: 24.30s
Train Epoch: 504 [20480/90000 (23%)]	Loss: 9.9045	Cost: 6.61s
Train Epoch: 504 [40960/90000 (45%)]	Loss: 9.8920	Cost: 13.41s
Train Epoch: 504 [61440/90000 (68%)]	Loss: 9.8925	Cost: 12.10s
Train Epoch: 504 [81920/90000 (91%)]	Loss: 9.7456	Cost: 11.89s
Train Epoch: 504 	Average Loss: 9.8882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6902

Learning rate: 0.00019998746507472485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 505 [0/90000 (0%)]	Loss: 10.2351	Cost: 30.40s
Train Epoch: 505 [20480/90000 (23%)]	Loss: 9.7659	Cost: 12.09s
Train Epoch: 505 [40960/90000 (45%)]	Loss: 10.0002	Cost: 12.08s
Train Epoch: 505 [61440/90000 (68%)]	Loss: 9.7684	Cost: 11.80s
Train Epoch: 505 [81920/90000 (91%)]	Loss: 9.9736	Cost: 6.44s
Train Epoch: 505 	Average Loss: 9.8524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6312

Learning rate: 0.00019998741528465526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 506 [0/90000 (0%)]	Loss: 10.4910	Cost: 31.90s
Train Epoch: 506 [20480/90000 (23%)]	Loss: 9.8150	Cost: 7.21s
Train Epoch: 506 [40960/90000 (45%)]	Loss: 9.7603	Cost: 9.51s
Train Epoch: 506 [61440/90000 (68%)]	Loss: 9.9793	Cost: 6.41s
Train Epoch: 506 [81920/90000 (91%)]	Loss: 9.7126	Cost: 9.02s
Train Epoch: 506 	Average Loss: 9.8483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6384

Learning rate: 0.00019998736539590206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 507 [0/90000 (0%)]	Loss: 10.3172	Cost: 22.10s
Train Epoch: 507 [20480/90000 (23%)]	Loss: 10.1331	Cost: 6.36s
Train Epoch: 507 [40960/90000 (45%)]	Loss: 9.8732	Cost: 8.64s
Train Epoch: 507 [61440/90000 (68%)]	Loss: 10.1857	Cost: 10.39s
Train Epoch: 507 [81920/90000 (91%)]	Loss: 9.8210	Cost: 12.88s
Train Epoch: 507 	Average Loss: 9.8826
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7567

Learning rate: 0.00019998731540846526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 508 [0/90000 (0%)]	Loss: 10.4502	Cost: 27.65s
Train Epoch: 508 [20480/90000 (23%)]	Loss: 9.8826	Cost: 12.13s
Train Epoch: 508 [40960/90000 (45%)]	Loss: 9.8507	Cost: 12.14s
Train Epoch: 508 [61440/90000 (68%)]	Loss: 9.7102	Cost: 11.91s
Train Epoch: 508 [81920/90000 (91%)]	Loss: 9.9809	Cost: 10.78s
Train Epoch: 508 	Average Loss: 9.9151
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7098

Learning rate: 0.00019998726532234495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 509 [0/90000 (0%)]	Loss: 10.2013	Cost: 26.51s
Train Epoch: 509 [20480/90000 (23%)]	Loss: 10.0539	Cost: 12.16s
Train Epoch: 509 [40960/90000 (45%)]	Loss: 9.8100	Cost: 11.97s
Train Epoch: 509 [61440/90000 (68%)]	Loss: 9.9496	Cost: 7.38s
Train Epoch: 509 [81920/90000 (91%)]	Loss: 9.7849	Cost: 5.82s
Train Epoch: 509 	Average Loss: 9.8486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6434

Learning rate: 0.00019998721513754116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 510 [0/90000 (0%)]	Loss: 10.4356	Cost: 23.25s
Train Epoch: 510 [20480/90000 (23%)]	Loss: 9.9238	Cost: 6.28s
Train Epoch: 510 [40960/90000 (45%)]	Loss: 9.8991	Cost: 6.49s
Train Epoch: 510 [61440/90000 (68%)]	Loss: 9.9975	Cost: 6.27s
Train Epoch: 510 [81920/90000 (91%)]	Loss: 9.9224	Cost: 6.24s
Train Epoch: 510 	Average Loss: 9.8535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6973

Learning rate: 0.00019998716485405393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 511 [0/90000 (0%)]	Loss: 10.4528	Cost: 23.50s
Train Epoch: 511 [20480/90000 (23%)]	Loss: 9.9405	Cost: 6.30s
Train Epoch: 511 [40960/90000 (45%)]	Loss: 9.9951	Cost: 13.19s
Train Epoch: 511 [61440/90000 (68%)]	Loss: 9.6806	Cost: 12.05s
Train Epoch: 511 [81920/90000 (91%)]	Loss: 9.6716	Cost: 11.86s
Train Epoch: 511 	Average Loss: 9.8256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6404

Learning rate: 0.00019998711447188336
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 512 [0/90000 (0%)]	Loss: 10.1965	Cost: 34.19s
Train Epoch: 512 [20480/90000 (23%)]	Loss: 9.8519	Cost: 11.80s
Train Epoch: 512 [40960/90000 (45%)]	Loss: 9.6372	Cost: 7.88s
Train Epoch: 512 [61440/90000 (68%)]	Loss: 9.8482	Cost: 6.22s
Train Epoch: 512 [81920/90000 (91%)]	Loss: 9.8781	Cost: 6.98s
Train Epoch: 512 	Average Loss: 9.8189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6320

Learning rate: 0.00019998706399102943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 513 [0/90000 (0%)]	Loss: 10.2043	Cost: 23.48s
Train Epoch: 513 [20480/90000 (23%)]	Loss: 9.8562	Cost: 6.34s
Train Epoch: 513 [40960/90000 (45%)]	Loss: 9.7298	Cost: 6.41s
Train Epoch: 513 [61440/90000 (68%)]	Loss: 9.7542	Cost: 6.44s
Train Epoch: 513 [81920/90000 (91%)]	Loss: 9.8562	Cost: 5.83s
Train Epoch: 513 	Average Loss: 9.8001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5901

Learning rate: 0.00019998701341149226
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 514 [0/90000 (0%)]	Loss: 10.2894	Cost: 25.67s
Train Epoch: 514 [20480/90000 (23%)]	Loss: 10.0260	Cost: 7.57s
Train Epoch: 514 [40960/90000 (45%)]	Loss: 9.6755	Cost: 7.70s
Train Epoch: 514 [61440/90000 (68%)]	Loss: 9.7988	Cost: 7.45s
Train Epoch: 514 [81920/90000 (91%)]	Loss: 9.7856	Cost: 7.67s
Train Epoch: 514 	Average Loss: 9.8085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6476

Learning rate: 0.00019998696273327185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 515 [0/90000 (0%)]	Loss: 10.3406	Cost: 30.82s
Train Epoch: 515 [20480/90000 (23%)]	Loss: 9.8151	Cost: 14.16s
Train Epoch: 515 [40960/90000 (45%)]	Loss: 9.7925	Cost: 13.40s
Train Epoch: 515 [61440/90000 (68%)]	Loss: 9.7117	Cost: 12.87s
Train Epoch: 515 [81920/90000 (91%)]	Loss: 10.0071	Cost: 8.39s
Train Epoch: 515 	Average Loss: 9.7764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7169

Learning rate: 0.00019998691195636826
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 516 [0/90000 (0%)]	Loss: 10.3275	Cost: 26.20s
Train Epoch: 516 [20480/90000 (23%)]	Loss: 9.9438	Cost: 7.18s
Train Epoch: 516 [40960/90000 (45%)]	Loss: 9.8762	Cost: 8.57s
Train Epoch: 516 [61440/90000 (68%)]	Loss: 9.7324	Cost: 6.61s
Train Epoch: 516 [81920/90000 (91%)]	Loss: 9.8275	Cost: 6.30s
Train Epoch: 516 	Average Loss: 9.8160
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7481

Learning rate: 0.00019998686108078153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 517 [0/90000 (0%)]	Loss: 10.0196	Cost: 26.24s
Train Epoch: 517 [20480/90000 (23%)]	Loss: 9.9164	Cost: 8.31s
Train Epoch: 517 [40960/90000 (45%)]	Loss: 9.7093	Cost: 13.63s
Train Epoch: 517 [61440/90000 (68%)]	Loss: 9.6905	Cost: 13.42s
Train Epoch: 517 [81920/90000 (91%)]	Loss: 9.6919	Cost: 12.86s
Train Epoch: 517 	Average Loss: 9.7921
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6610

Learning rate: 0.00019998681010651175
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 518 [0/90000 (0%)]	Loss: 10.4221	Cost: 45.06s
Train Epoch: 518 [20480/90000 (23%)]	Loss: 9.7196	Cost: 13.14s
Train Epoch: 518 [40960/90000 (45%)]	Loss: 9.7780	Cost: 10.29s
Train Epoch: 518 [61440/90000 (68%)]	Loss: 9.9334	Cost: 7.23s
Train Epoch: 518 [81920/90000 (91%)]	Loss: 9.7376	Cost: 7.93s
Train Epoch: 518 	Average Loss: 9.7938
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5990

Learning rate: 0.0001999867590335589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 519 [0/90000 (0%)]	Loss: 10.3322	Cost: 24.26s
Train Epoch: 519 [20480/90000 (23%)]	Loss: 9.8025	Cost: 7.65s
Train Epoch: 519 [40960/90000 (45%)]	Loss: 9.7854	Cost: 7.40s
Train Epoch: 519 [61440/90000 (68%)]	Loss: 9.6841	Cost: 6.94s
Train Epoch: 519 [81920/90000 (91%)]	Loss: 9.9549	Cost: 6.99s
Train Epoch: 519 	Average Loss: 9.7746
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7147

Learning rate: 0.00019998670786192314
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 520 [0/90000 (0%)]	Loss: 10.1835	Cost: 36.80s
Train Epoch: 520 [20480/90000 (23%)]	Loss: 9.8527	Cost: 13.42s
Train Epoch: 520 [40960/90000 (45%)]	Loss: 9.6253	Cost: 12.19s
Train Epoch: 520 [61440/90000 (68%)]	Loss: 9.9201	Cost: 11.76s
Train Epoch: 520 [81920/90000 (91%)]	Loss: 9.7140	Cost: 10.35s
Train Epoch: 520 	Average Loss: 9.7587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6226

Learning rate: 0.00019998665659160442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 521 [0/90000 (0%)]	Loss: 10.1964	Cost: 27.40s
Train Epoch: 521 [20480/90000 (23%)]	Loss: 9.9202	Cost: 9.92s
Train Epoch: 521 [40960/90000 (45%)]	Loss: 9.7887	Cost: 6.13s
Train Epoch: 521 [61440/90000 (68%)]	Loss: 9.7513	Cost: 6.41s
Train Epoch: 521 [81920/90000 (91%)]	Loss: 9.7954	Cost: 6.50s
Train Epoch: 521 	Average Loss: 9.7758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5728

Saving model as e521_model.pt & e521_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998660522260283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 522 [0/90000 (0%)]	Loss: 10.2178	Cost: 28.76s
Train Epoch: 522 [20480/90000 (23%)]	Loss: 9.7555	Cost: 11.08s
Train Epoch: 522 [40960/90000 (45%)]	Loss: 9.7525	Cost: 12.19s
Train Epoch: 522 [61440/90000 (68%)]	Loss: 9.8115	Cost: 12.14s
Train Epoch: 522 [81920/90000 (91%)]	Loss: 9.8067	Cost: 7.59s
Train Epoch: 522 	Average Loss: 9.7556
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6298

Learning rate: 0.00019998655375491842
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 523 [0/90000 (0%)]	Loss: 10.4497	Cost: 28.06s
Train Epoch: 523 [20480/90000 (23%)]	Loss: 9.7964	Cost: 9.09s
Train Epoch: 523 [40960/90000 (45%)]	Loss: 9.5911	Cost: 6.04s
Train Epoch: 523 [61440/90000 (68%)]	Loss: 9.6497	Cost: 5.98s
Train Epoch: 523 [81920/90000 (91%)]	Loss: 9.7130	Cost: 6.80s
Train Epoch: 523 	Average Loss: 9.7923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5598

Saving model as e523_model.pt & e523_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.00019998650218855122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 524 [0/90000 (0%)]	Loss: 10.1775	Cost: 27.25s
Train Epoch: 524 [20480/90000 (23%)]	Loss: 9.7619	Cost: 12.12s
Train Epoch: 524 [40960/90000 (45%)]	Loss: 9.6760	Cost: 12.09s
Train Epoch: 524 [61440/90000 (68%)]	Loss: 9.8566	Cost: 11.82s
Train Epoch: 524 [81920/90000 (91%)]	Loss: 9.7715	Cost: 9.18s
Train Epoch: 524 	Average Loss: 9.7702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5850

Learning rate: 0.00019998645052350132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 525 [0/90000 (0%)]	Loss: 10.4826	Cost: 40.87s
Train Epoch: 525 [20480/90000 (23%)]	Loss: 9.8991	Cost: 11.86s
Train Epoch: 525 [40960/90000 (45%)]	Loss: 9.6338	Cost: 11.88s
Train Epoch: 525 [61440/90000 (68%)]	Loss: 9.8515	Cost: 5.79s
Train Epoch: 525 [81920/90000 (91%)]	Loss: 9.7358	Cost: 5.89s
Train Epoch: 525 	Average Loss: 9.7923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6055

Learning rate: 0.00019998639875976873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 526 [0/90000 (0%)]	Loss: 10.2562	Cost: 27.01s
Train Epoch: 526 [20480/90000 (23%)]	Loss: 9.7539	Cost: 11.95s
Train Epoch: 526 [40960/90000 (45%)]	Loss: 9.7504	Cost: 7.02s
Train Epoch: 526 [61440/90000 (68%)]	Loss: 9.5985	Cost: 5.87s
Train Epoch: 526 [81920/90000 (91%)]	Loss: 9.8137	Cost: 6.70s
Train Epoch: 526 	Average Loss: 9.7618
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6596

Learning rate: 0.0001999863468973535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 527 [0/90000 (0%)]	Loss: 10.1924	Cost: 27.55s
Train Epoch: 527 [20480/90000 (23%)]	Loss: 9.7996	Cost: 6.57s
Train Epoch: 527 [40960/90000 (45%)]	Loss: 9.6443	Cost: 6.07s
Train Epoch: 527 [61440/90000 (68%)]	Loss: 9.7011	Cost: 6.98s
Train Epoch: 527 [81920/90000 (91%)]	Loss: 9.7862	Cost: 6.08s
Train Epoch: 527 	Average Loss: 9.7531
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5792

Learning rate: 0.00019998629493625576
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 528 [0/90000 (0%)]	Loss: 10.5085	Cost: 24.01s
Train Epoch: 528 [20480/90000 (23%)]	Loss: 9.7224	Cost: 6.46s
Train Epoch: 528 [40960/90000 (45%)]	Loss: 9.6708	Cost: 6.88s
Train Epoch: 528 [61440/90000 (68%)]	Loss: 9.6638	Cost: 6.50s
Train Epoch: 528 [81920/90000 (91%)]	Loss: 9.8495	Cost: 6.07s
Train Epoch: 528 	Average Loss: 9.7324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6834

Learning rate: 0.00019998624287647545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 529 [0/90000 (0%)]	Loss: 10.3340	Cost: 27.48s
Train Epoch: 529 [20480/90000 (23%)]	Loss: 9.7033	Cost: 7.71s
Train Epoch: 529 [40960/90000 (45%)]	Loss: 9.6431	Cost: 11.62s
Train Epoch: 529 [61440/90000 (68%)]	Loss: 9.7216	Cost: 11.97s
Train Epoch: 529 [81920/90000 (91%)]	Loss: 9.8001	Cost: 12.00s
Train Epoch: 529 	Average Loss: 9.7501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.4751

Saving model as e529_model.pt & e529_waveforms_supplementary.hdf5
Save test samples ...
Learning rate: 0.0001999861907180127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 530 [0/90000 (0%)]	Loss: 10.1706	Cost: 22.24s
Train Epoch: 530 [20480/90000 (23%)]	Loss: 9.8819	Cost: 6.24s
Train Epoch: 530 [40960/90000 (45%)]	Loss: 9.6108	Cost: 7.02s
Train Epoch: 530 [61440/90000 (68%)]	Loss: 9.6477	Cost: 6.12s
Train Epoch: 530 [81920/90000 (91%)]	Loss: 9.6471	Cost: 14.80s
Train Epoch: 530 	Average Loss: 9.7250
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6103

Learning rate: 0.0001999861384608675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 531 [0/90000 (0%)]	Loss: 10.2830	Cost: 23.74s
Train Epoch: 531 [20480/90000 (23%)]	Loss: 9.7395	Cost: 6.20s
Train Epoch: 531 [40960/90000 (45%)]	Loss: 9.5569	Cost: 12.08s
Train Epoch: 531 [61440/90000 (68%)]	Loss: 9.7299	Cost: 12.06s
Train Epoch: 531 [81920/90000 (91%)]	Loss: 9.6105	Cost: 11.95s
Train Epoch: 531 	Average Loss: 9.7053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5998

Learning rate: 0.00019998608610503996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 532 [0/90000 (0%)]	Loss: 10.1351	Cost: 29.25s
Train Epoch: 532 [20480/90000 (23%)]	Loss: 9.7672	Cost: 12.43s
Train Epoch: 532 [40960/90000 (45%)]	Loss: 9.7411	Cost: 12.14s
Train Epoch: 532 [61440/90000 (68%)]	Loss: 9.7108	Cost: 11.79s
Train Epoch: 532 [81920/90000 (91%)]	Loss: 9.7143	Cost: 9.83s
Train Epoch: 532 	Average Loss: 9.6974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6710

Learning rate: 0.00019998603365053012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 533 [0/90000 (0%)]	Loss: 10.2412	Cost: 38.51s
Train Epoch: 533 [20480/90000 (23%)]	Loss: 9.7274	Cost: 11.09s
Train Epoch: 533 [40960/90000 (45%)]	Loss: 9.6503	Cost: 8.39s
Train Epoch: 533 [61440/90000 (68%)]	Loss: 9.7338	Cost: 6.03s
Train Epoch: 533 [81920/90000 (91%)]	Loss: 9.7800	Cost: 6.79s
Train Epoch: 533 	Average Loss: 9.7207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6068

Learning rate: 0.00019998598109733802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 534 [0/90000 (0%)]	Loss: 10.3496	Cost: 24.85s
Train Epoch: 534 [20480/90000 (23%)]	Loss: 9.7960	Cost: 7.02s
Train Epoch: 534 [40960/90000 (45%)]	Loss: 9.4993	Cost: 6.55s
Train Epoch: 534 [61440/90000 (68%)]	Loss: 9.7272	Cost: 6.24s
Train Epoch: 534 [81920/90000 (91%)]	Loss: 9.7842	Cost: 6.13s
Train Epoch: 534 	Average Loss: 9.7064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7041

Learning rate: 0.0001999859284454637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 535 [0/90000 (0%)]	Loss: 10.4328	Cost: 24.46s
Train Epoch: 535 [20480/90000 (23%)]	Loss: 9.5293	Cost: 6.25s
Train Epoch: 535 [40960/90000 (45%)]	Loss: 9.5899	Cost: 8.99s
Train Epoch: 535 [61440/90000 (68%)]	Loss: 9.8084	Cost: 9.51s
Train Epoch: 535 [81920/90000 (91%)]	Loss: 9.7638	Cost: 13.89s
Train Epoch: 535 	Average Loss: 9.7428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5807

Learning rate: 0.00019998587569490723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 536 [0/90000 (0%)]	Loss: 10.1570	Cost: 25.53s
Train Epoch: 536 [20480/90000 (23%)]	Loss: 9.7221	Cost: 9.32s
Train Epoch: 536 [40960/90000 (45%)]	Loss: 9.5002	Cost: 11.86s
Train Epoch: 536 [61440/90000 (68%)]	Loss: 9.5937	Cost: 11.89s
Train Epoch: 536 [81920/90000 (91%)]	Loss: 9.7537	Cost: 11.79s
Train Epoch: 536 	Average Loss: 9.6609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6099

Learning rate: 0.00019998582284566865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 537 [0/90000 (0%)]	Loss: 10.3308	Cost: 30.98s
Train Epoch: 537 [20480/90000 (23%)]	Loss: 9.7943	Cost: 11.73s
Train Epoch: 537 [40960/90000 (45%)]	Loss: 9.5727	Cost: 12.00s
Train Epoch: 537 [61440/90000 (68%)]	Loss: 9.7205	Cost: 10.39s
Train Epoch: 537 [81920/90000 (91%)]	Loss: 9.8080	Cost: 5.84s
Train Epoch: 537 	Average Loss: 9.6549
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5755

Learning rate: 0.00019998576989774803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 538 [0/90000 (0%)]	Loss: 10.4283	Cost: 27.55s
Train Epoch: 538 [20480/90000 (23%)]	Loss: 9.8208	Cost: 10.33s
Train Epoch: 538 [40960/90000 (45%)]	Loss: 9.5230	Cost: 8.93s
Train Epoch: 538 [61440/90000 (68%)]	Loss: 9.7297	Cost: 5.80s
Train Epoch: 538 [81920/90000 (91%)]	Loss: 9.5753	Cost: 6.69s
Train Epoch: 538 	Average Loss: 9.6965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6276

Learning rate: 0.0001999857168511454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 539 [0/90000 (0%)]	Loss: 10.2819	Cost: 27.84s
Train Epoch: 539 [20480/90000 (23%)]	Loss: 9.7383	Cost: 8.70s
Train Epoch: 539 [40960/90000 (45%)]	Loss: 9.5300	Cost: 6.02s
Train Epoch: 539 [61440/90000 (68%)]	Loss: 9.6699	Cost: 6.62s
Train Epoch: 539 [81920/90000 (91%)]	Loss: 9.6238	Cost: 6.22s
Train Epoch: 539 	Average Loss: 9.7130
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5979

Learning rate: 0.00019998566370586085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 540 [0/90000 (0%)]	Loss: 10.1424	Cost: 25.14s
Train Epoch: 540 [20480/90000 (23%)]	Loss: 9.8833	Cost: 7.01s
Train Epoch: 540 [40960/90000 (45%)]	Loss: 9.4014	Cost: 6.42s
Train Epoch: 540 [61440/90000 (68%)]	Loss: 9.4291	Cost: 6.12s
Train Epoch: 540 [81920/90000 (91%)]	Loss: 9.7088	Cost: 6.09s
Train Epoch: 540 	Average Loss: 9.6689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6689

Learning rate: 0.0001999856104618944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 541 [0/90000 (0%)]	Loss: 10.3252	Cost: 25.12s
Train Epoch: 541 [20480/90000 (23%)]	Loss: 9.7946	Cost: 8.30s
Train Epoch: 541 [40960/90000 (45%)]	Loss: 9.6360	Cost: 16.87s
Train Epoch: 541 [61440/90000 (68%)]	Loss: 9.7823	Cost: 12.71s
Train Epoch: 541 [81920/90000 (91%)]	Loss: 9.7557	Cost: 12.12s
Train Epoch: 541 	Average Loss: 9.6974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5607

Learning rate: 0.0001999855571192461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 542 [0/90000 (0%)]	Loss: 10.4237	Cost: 32.85s
Train Epoch: 542 [20480/90000 (23%)]	Loss: 9.5870	Cost: 12.17s
Train Epoch: 542 [40960/90000 (45%)]	Loss: 9.5892	Cost: 12.05s
Train Epoch: 542 [61440/90000 (68%)]	Loss: 9.6520	Cost: 7.41s
Train Epoch: 542 [81920/90000 (91%)]	Loss: 9.8095	Cost: 5.79s
Train Epoch: 542 	Average Loss: 9.6732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5530

Learning rate: 0.00019998550367791602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 543 [0/90000 (0%)]	Loss: 10.1726	Cost: 27.87s
Train Epoch: 543 [20480/90000 (23%)]	Loss: 9.5271	Cost: 10.27s
Train Epoch: 543 [40960/90000 (45%)]	Loss: 9.5505	Cost: 7.63s
Train Epoch: 543 [61440/90000 (68%)]	Loss: 9.7507	Cost: 5.82s
Train Epoch: 543 [81920/90000 (91%)]	Loss: 9.6794	Cost: 6.67s
Train Epoch: 543 	Average Loss: 9.6355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6513

Learning rate: 0.0001999854501379042
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 544 [0/90000 (0%)]	Loss: 10.4039	Cost: 24.25s
Train Epoch: 544 [20480/90000 (23%)]	Loss: 9.5725	Cost: 6.34s
Train Epoch: 544 [40960/90000 (45%)]	Loss: 9.5814	Cost: 7.06s
Train Epoch: 544 [61440/90000 (68%)]	Loss: 9.4951	Cost: 6.71s
Train Epoch: 544 [81920/90000 (91%)]	Loss: 9.7609	Cost: 6.17s
Train Epoch: 544 	Average Loss: 9.6936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6306

Learning rate: 0.00019998539649921068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 545 [0/90000 (0%)]	Loss: 10.1896	Cost: 24.83s
Train Epoch: 545 [20480/90000 (23%)]	Loss: 9.5754	Cost: 6.47s
Train Epoch: 545 [40960/90000 (45%)]	Loss: 9.6056	Cost: 9.17s
Train Epoch: 545 [61440/90000 (68%)]	Loss: 9.6486	Cost: 11.83s
Train Epoch: 545 [81920/90000 (91%)]	Loss: 9.7612	Cost: 12.06s
Train Epoch: 545 	Average Loss: 9.6696
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6904

Learning rate: 0.00019998534276183553
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 546 [0/90000 (0%)]	Loss: 10.1637	Cost: 28.59s
Train Epoch: 546 [20480/90000 (23%)]	Loss: 9.6366	Cost: 14.36s
Train Epoch: 546 [40960/90000 (45%)]	Loss: 9.5788	Cost: 13.99s
Train Epoch: 546 [61440/90000 (68%)]	Loss: 9.6344	Cost: 11.89s
Train Epoch: 546 [81920/90000 (91%)]	Loss: 9.4985	Cost: 9.82s
Train Epoch: 546 	Average Loss: 9.6137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5700

Learning rate: 0.00019998528892577877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 547 [0/90000 (0%)]	Loss: 10.4091	Cost: 31.00s
Train Epoch: 547 [20480/90000 (23%)]	Loss: 9.7739	Cost: 10.61s
Train Epoch: 547 [40960/90000 (45%)]	Loss: 9.5697	Cost: 6.21s
Train Epoch: 547 [61440/90000 (68%)]	Loss: 9.8112	Cost: 6.23s
Train Epoch: 547 [81920/90000 (91%)]	Loss: 9.7588	Cost: 6.52s
Train Epoch: 547 	Average Loss: 9.6938
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5748

Learning rate: 0.00019998523499104056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 548 [0/90000 (0%)]	Loss: 10.3202	Cost: 23.61s
Train Epoch: 548 [20480/90000 (23%)]	Loss: 9.6862	Cost: 6.39s
Train Epoch: 548 [40960/90000 (45%)]	Loss: 9.4531	Cost: 6.65s
Train Epoch: 548 [61440/90000 (68%)]	Loss: 9.6145	Cost: 6.17s
Train Epoch: 548 [81920/90000 (91%)]	Loss: 9.5767	Cost: 6.17s
Train Epoch: 548 	Average Loss: 9.6524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5861

Learning rate: 0.0001999851809576208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 549 [0/90000 (0%)]	Loss: 10.2627	Cost: 22.96s
Train Epoch: 549 [20480/90000 (23%)]	Loss: 9.5381	Cost: 6.19s
Train Epoch: 549 [40960/90000 (45%)]	Loss: 9.4056	Cost: 8.31s
Train Epoch: 549 [61440/90000 (68%)]	Loss: 9.6138	Cost: 11.21s
Train Epoch: 549 [81920/90000 (91%)]	Loss: 9.6851	Cost: 12.16s
Train Epoch: 549 	Average Loss: 9.6165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5602

Learning rate: 0.00019998512682551964
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 550 [0/90000 (0%)]	Loss: 10.4983	Cost: 29.91s
Train Epoch: 550 [20480/90000 (23%)]	Loss: 9.7217	Cost: 11.95s
Train Epoch: 550 [40960/90000 (45%)]	Loss: 9.4930	Cost: 12.12s
Train Epoch: 550 [61440/90000 (68%)]	Loss: 9.6702	Cost: 11.83s
Train Epoch: 550 [81920/90000 (91%)]	Loss: 9.6651	Cost: 6.81s
Train Epoch: 550 	Average Loss: 9.6537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6528

Learning rate: 0.00019998507259473715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 551 [0/90000 (0%)]	Loss: 10.1696	Cost: 26.79s
Train Epoch: 551 [20480/90000 (23%)]	Loss: 9.5889	Cost: 12.07s
Train Epoch: 551 [40960/90000 (45%)]	Loss: 9.5585	Cost: 9.96s
Train Epoch: 551 [61440/90000 (68%)]	Loss: 9.6610	Cost: 5.78s
Train Epoch: 551 [81920/90000 (91%)]	Loss: 9.5624	Cost: 6.67s
Train Epoch: 551 	Average Loss: 9.6277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5828

Learning rate: 0.00019998501826527334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 552 [0/90000 (0%)]	Loss: 10.2541	Cost: 27.31s
Train Epoch: 552 [20480/90000 (23%)]	Loss: 9.8891	Cost: 10.11s
Train Epoch: 552 [40960/90000 (45%)]	Loss: 9.3842	Cost: 5.99s
Train Epoch: 552 [61440/90000 (68%)]	Loss: 9.5286	Cost: 6.30s
Train Epoch: 552 [81920/90000 (91%)]	Loss: 9.5473	Cost: 6.44s
Train Epoch: 552 	Average Loss: 9.6161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6559

Learning rate: 0.00019998496383712825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 553 [0/90000 (0%)]	Loss: 10.2102	Cost: 29.91s
Train Epoch: 553 [20480/90000 (23%)]	Loss: 9.6565	Cost: 7.10s
Train Epoch: 553 [40960/90000 (45%)]	Loss: 9.5632	Cost: 8.42s
Train Epoch: 553 [61440/90000 (68%)]	Loss: 9.4333	Cost: 6.47s
Train Epoch: 553 [81920/90000 (91%)]	Loss: 9.7539	Cost: 8.11s
Train Epoch: 553 	Average Loss: 9.6401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6833

Learning rate: 0.000199984909310302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 554 [0/90000 (0%)]	Loss: 10.4434	Cost: 22.45s
Train Epoch: 554 [20480/90000 (23%)]	Loss: 9.5413	Cost: 6.11s
Train Epoch: 554 [40960/90000 (45%)]	Loss: 9.5480	Cost: 10.54s
Train Epoch: 554 [61440/90000 (68%)]	Loss: 9.3986	Cost: 12.15s
Train Epoch: 554 [81920/90000 (91%)]	Loss: 9.7627	Cost: 11.99s
Train Epoch: 554 	Average Loss: 9.6040
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5726

Learning rate: 0.00019998485468479454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 555 [0/90000 (0%)]	Loss: 10.1703	Cost: 31.47s
Train Epoch: 555 [20480/90000 (23%)]	Loss: 9.6910	Cost: 10.62s
Train Epoch: 555 [40960/90000 (45%)]	Loss: 9.5998	Cost: 12.06s
Train Epoch: 555 [61440/90000 (68%)]	Loss: 9.6982	Cost: 11.88s
Train Epoch: 555 [81920/90000 (91%)]	Loss: 9.6940	Cost: 6.24s
Train Epoch: 555 	Average Loss: 9.6461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5079

Learning rate: 0.000199984799960606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 556 [0/90000 (0%)]	Loss: 10.2447	Cost: 26.98s
Train Epoch: 556 [20480/90000 (23%)]	Loss: 9.6723	Cost: 11.52s
Train Epoch: 556 [40960/90000 (45%)]	Loss: 9.4959	Cost: 7.56s
Train Epoch: 556 [61440/90000 (68%)]	Loss: 9.5197	Cost: 5.80s
Train Epoch: 556 [81920/90000 (91%)]	Loss: 9.5795	Cost: 6.65s
Train Epoch: 556 	Average Loss: 9.5871
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5306

Learning rate: 0.00019998474513773643
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 557 [0/90000 (0%)]	Loss: 10.2493	Cost: 23.48s
Train Epoch: 557 [20480/90000 (23%)]	Loss: 9.7649	Cost: 6.86s
Train Epoch: 557 [40960/90000 (45%)]	Loss: 9.4420	Cost: 6.37s
Train Epoch: 557 [61440/90000 (68%)]	Loss: 9.5879	Cost: 6.18s
Train Epoch: 557 [81920/90000 (91%)]	Loss: 9.5016	Cost: 6.12s
Train Epoch: 557 	Average Loss: 9.5764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6029

Learning rate: 0.00019998469021618588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 558 [0/90000 (0%)]	Loss: 10.2898	Cost: 25.24s
Train Epoch: 558 [20480/90000 (23%)]	Loss: 9.6170	Cost: 6.11s
Train Epoch: 558 [40960/90000 (45%)]	Loss: 9.3481	Cost: 13.06s
Train Epoch: 558 [61440/90000 (68%)]	Loss: 9.5419	Cost: 12.08s
Train Epoch: 558 [81920/90000 (91%)]	Loss: 9.6551	Cost: 11.83s
Train Epoch: 558 	Average Loss: 9.5929
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6411

Learning rate: 0.00019998463519595438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 559 [0/90000 (0%)]	Loss: 10.2316	Cost: 34.82s
Train Epoch: 559 [20480/90000 (23%)]	Loss: 9.6335	Cost: 11.80s
Train Epoch: 559 [40960/90000 (45%)]	Loss: 9.4083	Cost: 11.85s
Train Epoch: 559 [61440/90000 (68%)]	Loss: 9.7142	Cost: 11.89s
Train Epoch: 559 [81920/90000 (91%)]	Loss: 9.7259	Cost: 11.00s
Train Epoch: 559 	Average Loss: 9.6002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.4795

Learning rate: 0.000199984580077042
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 560 [0/90000 (0%)]	Loss: 10.2383	Cost: 28.15s
Train Epoch: 560 [20480/90000 (23%)]	Loss: 9.5871	Cost: 10.36s
Train Epoch: 560 [40960/90000 (45%)]	Loss: 9.6018	Cost: 8.89s
Train Epoch: 560 [61440/90000 (68%)]	Loss: 9.6494	Cost: 5.79s
Train Epoch: 560 [81920/90000 (91%)]	Loss: 9.3736	Cost: 6.65s
Train Epoch: 560 	Average Loss: 9.5645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6210

Learning rate: 0.00019998452485944882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 561 [0/90000 (0%)]	Loss: 10.2465	Cost: 24.56s
Train Epoch: 561 [20480/90000 (23%)]	Loss: 9.4881	Cost: 7.09s
Train Epoch: 561 [40960/90000 (45%)]	Loss: 9.7640	Cost: 6.28s
Train Epoch: 561 [61440/90000 (68%)]	Loss: 9.6430	Cost: 6.77s
Train Epoch: 561 [81920/90000 (91%)]	Loss: 9.5160	Cost: 6.65s
Train Epoch: 561 	Average Loss: 9.6058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6256

Learning rate: 0.00019998446954317485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 562 [0/90000 (0%)]	Loss: 10.2389	Cost: 27.13s
Train Epoch: 562 [20480/90000 (23%)]	Loss: 9.4415	Cost: 7.41s
Train Epoch: 562 [40960/90000 (45%)]	Loss: 9.5866	Cost: 19.87s
Train Epoch: 562 [61440/90000 (68%)]	Loss: 9.7354	Cost: 11.97s
Train Epoch: 562 [81920/90000 (91%)]	Loss: 9.6443	Cost: 11.96s
Train Epoch: 562 	Average Loss: 9.5890
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6035

Learning rate: 0.00019998441412822013
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 563 [0/90000 (0%)]	Loss: 10.4277	Cost: 28.61s
Train Epoch: 563 [20480/90000 (23%)]	Loss: 9.6074	Cost: 11.88s
Train Epoch: 563 [40960/90000 (45%)]	Loss: 9.4212	Cost: 11.94s
Train Epoch: 563 [61440/90000 (68%)]	Loss: 9.3868	Cost: 9.19s
Train Epoch: 563 [81920/90000 (91%)]	Loss: 9.6869	Cost: 5.78s
Train Epoch: 563 	Average Loss: 9.5639
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5583

Learning rate: 0.0001999843586145848
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 564 [0/90000 (0%)]	Loss: 10.2236	Cost: 27.41s
Train Epoch: 564 [20480/90000 (23%)]	Loss: 9.6290	Cost: 11.91s
Train Epoch: 564 [40960/90000 (45%)]	Loss: 9.4754	Cost: 6.10s
Train Epoch: 564 [61440/90000 (68%)]	Loss: 9.5823	Cost: 5.90s
Train Epoch: 564 [81920/90000 (91%)]	Loss: 9.4813	Cost: 6.82s
Train Epoch: 564 	Average Loss: 9.5754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5855

Learning rate: 0.00019998430300226887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 565 [0/90000 (0%)]	Loss: 10.2381	Cost: 26.64s
Train Epoch: 565 [20480/90000 (23%)]	Loss: 9.6906	Cost: 6.15s
Train Epoch: 565 [40960/90000 (45%)]	Loss: 9.4958	Cost: 6.84s
Train Epoch: 565 [61440/90000 (68%)]	Loss: 9.6340	Cost: 6.24s
Train Epoch: 565 [81920/90000 (91%)]	Loss: 9.6453	Cost: 6.10s
Train Epoch: 565 	Average Loss: 9.5748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6043

Learning rate: 0.0001999842472912724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 566 [0/90000 (0%)]	Loss: 10.3302	Cost: 22.59s
Train Epoch: 566 [20480/90000 (23%)]	Loss: 9.7108	Cost: 6.28s
Train Epoch: 566 [40960/90000 (45%)]	Loss: 9.5639	Cost: 6.47s
Train Epoch: 566 [61440/90000 (68%)]	Loss: 9.7161	Cost: 5.98s
Train Epoch: 566 [81920/90000 (91%)]	Loss: 9.5007	Cost: 8.25s
Train Epoch: 566 	Average Loss: 9.6198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5567

Learning rate: 0.0001999841914815954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 567 [0/90000 (0%)]	Loss: 10.3607	Cost: 22.40s
Train Epoch: 567 [20480/90000 (23%)]	Loss: 9.6470	Cost: 6.26s
Train Epoch: 567 [40960/90000 (45%)]	Loss: 9.5414	Cost: 9.57s
Train Epoch: 567 [61440/90000 (68%)]	Loss: 9.6481	Cost: 11.83s
Train Epoch: 567 [81920/90000 (91%)]	Loss: 9.4987	Cost: 12.02s
Train Epoch: 567 	Average Loss: 9.5891
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5900

Learning rate: 0.00019998413557323794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 568 [0/90000 (0%)]	Loss: 10.5007	Cost: 33.72s
Train Epoch: 568 [20480/90000 (23%)]	Loss: 9.5408	Cost: 12.48s
Train Epoch: 568 [40960/90000 (45%)]	Loss: 9.5059	Cost: 12.73s
Train Epoch: 568 [61440/90000 (68%)]	Loss: 9.4458	Cost: 12.23s
Train Epoch: 568 [81920/90000 (91%)]	Loss: 9.5840	Cost: 12.05s
Train Epoch: 568 	Average Loss: 9.5749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5906

Learning rate: 0.00019998407956620012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 569 [0/90000 (0%)]	Loss: 10.4838	Cost: 27.07s
Train Epoch: 569 [20480/90000 (23%)]	Loss: 9.5867	Cost: 11.80s
Train Epoch: 569 [40960/90000 (45%)]	Loss: 9.5023	Cost: 9.94s
Train Epoch: 569 [61440/90000 (68%)]	Loss: 9.5622	Cost: 5.82s
Train Epoch: 569 [81920/90000 (91%)]	Loss: 9.5755	Cost: 6.77s
Train Epoch: 569 	Average Loss: 9.5562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5069

Learning rate: 0.00019998402346048196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 570 [0/90000 (0%)]	Loss: 10.1414	Cost: 25.45s
Train Epoch: 570 [20480/90000 (23%)]	Loss: 9.4075	Cost: 6.25s
Train Epoch: 570 [40960/90000 (45%)]	Loss: 9.4860	Cost: 6.99s
Train Epoch: 570 [61440/90000 (68%)]	Loss: 9.7512	Cost: 6.13s
Train Epoch: 570 [81920/90000 (91%)]	Loss: 9.4626	Cost: 5.95s
Train Epoch: 570 	Average Loss: 9.5265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5715

Learning rate: 0.0001999839672560835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 571 [0/90000 (0%)]	Loss: 10.2158	Cost: 23.08s
Train Epoch: 571 [20480/90000 (23%)]	Loss: 9.7067	Cost: 6.48s
Train Epoch: 571 [40960/90000 (45%)]	Loss: 9.5693	Cost: 11.48s
Train Epoch: 571 [61440/90000 (68%)]	Loss: 9.5122	Cost: 12.20s
Train Epoch: 571 [81920/90000 (91%)]	Loss: 9.5471	Cost: 11.90s
Train Epoch: 571 	Average Loss: 9.5516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6938

Learning rate: 0.00019998391095300483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 572 [0/90000 (0%)]	Loss: 10.2520	Cost: 27.22s
Train Epoch: 572 [20480/90000 (23%)]	Loss: 9.6927	Cost: 11.78s
Train Epoch: 572 [40960/90000 (45%)]	Loss: 9.5078	Cost: 11.97s
Train Epoch: 572 [61440/90000 (68%)]	Loss: 9.3917	Cost: 11.85s
Train Epoch: 572 [81920/90000 (91%)]	Loss: 9.4150	Cost: 9.80s
Train Epoch: 572 	Average Loss: 9.5222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5686

Learning rate: 0.00019998385455124602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 573 [0/90000 (0%)]	Loss: 10.2846	Cost: 27.23s
Train Epoch: 573 [20480/90000 (23%)]	Loss: 9.6752	Cost: 12.14s
Train Epoch: 573 [40960/90000 (45%)]	Loss: 9.2423	Cost: 10.50s
Train Epoch: 573 [61440/90000 (68%)]	Loss: 9.4112	Cost: 5.83s
Train Epoch: 573 [81920/90000 (91%)]	Loss: 9.4240	Cost: 6.75s
Train Epoch: 573 	Average Loss: 9.5310
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5664

Learning rate: 0.00019998379805080712
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 574 [0/90000 (0%)]	Loss: 10.2555	Cost: 29.27s
Train Epoch: 574 [20480/90000 (23%)]	Loss: 9.5336	Cost: 7.29s
Train Epoch: 574 [40960/90000 (45%)]	Loss: 9.5677	Cost: 9.59s
Train Epoch: 574 [61440/90000 (68%)]	Loss: 9.6734	Cost: 6.46s
Train Epoch: 574 [81920/90000 (91%)]	Loss: 9.2805	Cost: 9.62s
Train Epoch: 574 	Average Loss: 9.5128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5683

Learning rate: 0.00019998374145168815
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 575 [0/90000 (0%)]	Loss: 10.2613	Cost: 28.38s
Train Epoch: 575 [20480/90000 (23%)]	Loss: 9.5345	Cost: 12.34s
Train Epoch: 575 [40960/90000 (45%)]	Loss: 9.3819	Cost: 13.78s
Train Epoch: 575 [61440/90000 (68%)]	Loss: 9.4836	Cost: 11.95s
Train Epoch: 575 [81920/90000 (91%)]	Loss: 9.5211	Cost: 12.05s
Train Epoch: 575 	Average Loss: 9.5143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5932

Learning rate: 0.00019998368475388916
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 576 [0/90000 (0%)]	Loss: 10.1530	Cost: 28.17s
Train Epoch: 576 [20480/90000 (23%)]	Loss: 9.5947	Cost: 11.57s
Train Epoch: 576 [40960/90000 (45%)]	Loss: 9.3903	Cost: 6.12s
Train Epoch: 576 [61440/90000 (68%)]	Loss: 9.5068	Cost: 5.88s
Train Epoch: 576 [81920/90000 (91%)]	Loss: 9.6042	Cost: 6.89s
Train Epoch: 576 	Average Loss: 9.5086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6471

Learning rate: 0.00019998362795741026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 577 [0/90000 (0%)]	Loss: 10.1698	Cost: 33.21s
Train Epoch: 577 [20480/90000 (23%)]	Loss: 9.5231	Cost: 6.29s
Train Epoch: 577 [40960/90000 (45%)]	Loss: 9.3710	Cost: 9.31s
Train Epoch: 577 [61440/90000 (68%)]	Loss: 9.4029	Cost: 6.38s
Train Epoch: 577 [81920/90000 (91%)]	Loss: 9.4350	Cost: 6.18s
Train Epoch: 577 	Average Loss: 9.5149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6606

Learning rate: 0.00019998357106225145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 578 [0/90000 (0%)]	Loss: 10.1961	Cost: 23.26s
Train Epoch: 578 [20480/90000 (23%)]	Loss: 9.4470	Cost: 6.45s
Train Epoch: 578 [40960/90000 (45%)]	Loss: 9.3973	Cost: 6.84s
Train Epoch: 578 [61440/90000 (68%)]	Loss: 9.4708	Cost: 6.26s
Train Epoch: 578 [81920/90000 (91%)]	Loss: 9.5909	Cost: 14.93s
Train Epoch: 578 	Average Loss: 9.4940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6477

Learning rate: 0.00019998351406841282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 579 [0/90000 (0%)]	Loss: 10.2206	Cost: 23.14s
Train Epoch: 579 [20480/90000 (23%)]	Loss: 9.3999	Cost: 6.31s
Train Epoch: 579 [40960/90000 (45%)]	Loss: 9.4027	Cost: 12.55s
Train Epoch: 579 [61440/90000 (68%)]	Loss: 9.5867	Cost: 12.10s
Train Epoch: 579 [81920/90000 (91%)]	Loss: 9.5732	Cost: 11.88s
Train Epoch: 579 	Average Loss: 9.4615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5627

Learning rate: 0.0001999834569758944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 580 [0/90000 (0%)]	Loss: 10.1895	Cost: 32.97s
Train Epoch: 580 [20480/90000 (23%)]	Loss: 9.5098	Cost: 12.12s
Train Epoch: 580 [40960/90000 (45%)]	Loss: 9.4135	Cost: 11.95s
Train Epoch: 580 [61440/90000 (68%)]	Loss: 9.4463	Cost: 6.28s
Train Epoch: 580 [81920/90000 (91%)]	Loss: 9.4954	Cost: 6.02s
Train Epoch: 580 	Average Loss: 9.4826
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5969

Learning rate: 0.00019998339978469627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 581 [0/90000 (0%)]	Loss: 10.1889	Cost: 27.06s
Train Epoch: 581 [20480/90000 (23%)]	Loss: 9.5899	Cost: 9.28s
Train Epoch: 581 [40960/90000 (45%)]	Loss: 9.4896	Cost: 5.98s
Train Epoch: 581 [61440/90000 (68%)]	Loss: 9.3101	Cost: 6.02s
Train Epoch: 581 [81920/90000 (91%)]	Loss: 9.4766	Cost: 7.21s
Train Epoch: 581 	Average Loss: 9.4538
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5330

Learning rate: 0.0001999833424948185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 582 [0/90000 (0%)]	Loss: 10.2442	Cost: 25.79s
Train Epoch: 582 [20480/90000 (23%)]	Loss: 9.5118	Cost: 6.41s
Train Epoch: 582 [40960/90000 (45%)]	Loss: 9.2423	Cost: 7.44s
Train Epoch: 582 [61440/90000 (68%)]	Loss: 9.4168	Cost: 6.24s
Train Epoch: 582 [81920/90000 (91%)]	Loss: 9.6481	Cost: 5.77s
Train Epoch: 582 	Average Loss: 9.4602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5228

Learning rate: 0.00019998328510626112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 583 [0/90000 (0%)]	Loss: 10.2046	Cost: 27.73s
Train Epoch: 583 [20480/90000 (23%)]	Loss: 9.4816	Cost: 10.07s
Train Epoch: 583 [40960/90000 (45%)]	Loss: 9.4255	Cost: 12.40s
Train Epoch: 583 [61440/90000 (68%)]	Loss: 9.4464	Cost: 12.02s
Train Epoch: 583 [81920/90000 (91%)]	Loss: 9.3601	Cost: 11.67s
Train Epoch: 583 	Average Loss: 9.4798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5738

Learning rate: 0.0001999832276190242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 584 [0/90000 (0%)]	Loss: 10.1253	Cost: 29.59s
Train Epoch: 584 [20480/90000 (23%)]	Loss: 9.5027	Cost: 10.76s
Train Epoch: 584 [40960/90000 (45%)]	Loss: 9.2723	Cost: 12.12s
Train Epoch: 584 [61440/90000 (68%)]	Loss: 9.4763	Cost: 11.95s
Train Epoch: 584 [81920/90000 (91%)]	Loss: 9.3759	Cost: 6.43s
Train Epoch: 584 	Average Loss: 9.4714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6466

Learning rate: 0.00019998317003310778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 585 [0/90000 (0%)]	Loss: 10.2429	Cost: 35.12s
Train Epoch: 585 [20480/90000 (23%)]	Loss: 9.5420	Cost: 7.38s
Train Epoch: 585 [40960/90000 (45%)]	Loss: 9.4962	Cost: 11.58s
Train Epoch: 585 [61440/90000 (68%)]	Loss: 9.5379	Cost: 6.04s
Train Epoch: 585 [81920/90000 (91%)]	Loss: 9.4774	Cost: 5.88s
Train Epoch: 585 	Average Loss: 9.4702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5672

Learning rate: 0.0001999831123485119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 586 [0/90000 (0%)]	Loss: 10.1959	Cost: 25.69s
Train Epoch: 586 [20480/90000 (23%)]	Loss: 9.4248	Cost: 6.05s
Train Epoch: 586 [40960/90000 (45%)]	Loss: 9.4022	Cost: 7.43s
Train Epoch: 586 [61440/90000 (68%)]	Loss: 9.4637	Cost: 6.27s
Train Epoch: 586 [81920/90000 (91%)]	Loss: 9.5084	Cost: 6.26s
Train Epoch: 586 	Average Loss: 9.4390
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5976

Learning rate: 0.00019998305456523665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 587 [0/90000 (0%)]	Loss: 10.1454	Cost: 23.91s
Train Epoch: 587 [20480/90000 (23%)]	Loss: 9.5318	Cost: 6.28s
Train Epoch: 587 [40960/90000 (45%)]	Loss: 9.4785	Cost: 11.49s
Train Epoch: 587 [61440/90000 (68%)]	Loss: 9.3272	Cost: 12.28s
Train Epoch: 587 [81920/90000 (91%)]	Loss: 9.3646	Cost: 11.97s
Train Epoch: 587 	Average Loss: 9.4633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5833

Learning rate: 0.0001999829966832821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 588 [0/90000 (0%)]	Loss: 10.3218	Cost: 38.98s
Train Epoch: 588 [20480/90000 (23%)]	Loss: 9.4306	Cost: 12.37s
Train Epoch: 588 [40960/90000 (45%)]	Loss: 9.3349	Cost: 12.40s
Train Epoch: 588 [61440/90000 (68%)]	Loss: 9.4950	Cost: 7.78s
Train Epoch: 588 [81920/90000 (91%)]	Loss: 9.5064	Cost: 6.16s
Train Epoch: 588 	Average Loss: 9.4394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6470

Learning rate: 0.00019998293870264827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 589 [0/90000 (0%)]	Loss: 10.3984	Cost: 26.63s
Train Epoch: 589 [20480/90000 (23%)]	Loss: 9.4908	Cost: 6.03s
Train Epoch: 589 [40960/90000 (45%)]	Loss: 9.1622	Cost: 9.61s
Train Epoch: 589 [61440/90000 (68%)]	Loss: 9.4193	Cost: 6.39s
Train Epoch: 589 [81920/90000 (91%)]	Loss: 9.4381	Cost: 6.46s
Train Epoch: 589 	Average Loss: 9.4205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5401

Learning rate: 0.00019998288062333524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 590 [0/90000 (0%)]	Loss: 10.3369	Cost: 21.70s
Train Epoch: 590 [20480/90000 (23%)]	Loss: 9.3704	Cost: 6.30s
Train Epoch: 590 [40960/90000 (45%)]	Loss: 9.3890	Cost: 6.63s
Train Epoch: 590 [61440/90000 (68%)]	Loss: 9.2994	Cost: 6.25s
Train Epoch: 590 [81920/90000 (91%)]	Loss: 9.4673	Cost: 8.68s
Train Epoch: 590 	Average Loss: 9.4404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5940

Learning rate: 0.00019998282244534305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 591 [0/90000 (0%)]	Loss: 10.5400	Cost: 23.96s
Train Epoch: 591 [20480/90000 (23%)]	Loss: 9.6021	Cost: 6.47s
Train Epoch: 591 [40960/90000 (45%)]	Loss: 9.4027	Cost: 8.10s
Train Epoch: 591 [61440/90000 (68%)]	Loss: 9.2808	Cost: 7.84s
Train Epoch: 591 [81920/90000 (91%)]	Loss: 9.3548	Cost: 14.52s
Train Epoch: 591 	Average Loss: 9.4336
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6180

Learning rate: 0.0001999827641686718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 592 [0/90000 (0%)]	Loss: 10.0908	Cost: 26.88s
Train Epoch: 592 [20480/90000 (23%)]	Loss: 9.3969	Cost: 9.78s
Train Epoch: 592 [40960/90000 (45%)]	Loss: 9.2017	Cost: 12.27s
Train Epoch: 592 [61440/90000 (68%)]	Loss: 9.4093	Cost: 11.93s
Train Epoch: 592 [81920/90000 (91%)]	Loss: 9.2669	Cost: 11.81s
Train Epoch: 592 	Average Loss: 9.4155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6257

Learning rate: 0.0001999827057933215
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 593 [0/90000 (0%)]	Loss: 10.0703	Cost: 27.68s
Train Epoch: 593 [20480/90000 (23%)]	Loss: 9.4738	Cost: 11.78s
Train Epoch: 593 [40960/90000 (45%)]	Loss: 9.2433	Cost: 11.94s
Train Epoch: 593 [61440/90000 (68%)]	Loss: 9.4629	Cost: 10.36s
Train Epoch: 593 [81920/90000 (91%)]	Loss: 9.2359	Cost: 5.85s
Train Epoch: 593 	Average Loss: 9.4052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5364

Learning rate: 0.0001999826473192922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 594 [0/90000 (0%)]	Loss: 10.3590	Cost: 27.89s
Train Epoch: 594 [20480/90000 (23%)]	Loss: 9.3995	Cost: 10.18s
Train Epoch: 594 [40960/90000 (45%)]	Loss: 9.2364	Cost: 11.52s
Train Epoch: 594 [61440/90000 (68%)]	Loss: 9.1411	Cost: 5.80s
Train Epoch: 594 [81920/90000 (91%)]	Loss: 9.3835	Cost: 5.90s
Train Epoch: 594 	Average Loss: 9.3938
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5799

Learning rate: 0.00019998258874658403
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 595 [0/90000 (0%)]	Loss: 10.2701	Cost: 29.63s
Train Epoch: 595 [20480/90000 (23%)]	Loss: 9.3917	Cost: 7.17s
Train Epoch: 595 [40960/90000 (45%)]	Loss: 9.2948	Cost: 6.63s
Train Epoch: 595 [61440/90000 (68%)]	Loss: 9.3940	Cost: 6.38s
Train Epoch: 595 [81920/90000 (91%)]	Loss: 9.4091	Cost: 6.45s
Train Epoch: 595 	Average Loss: 9.4185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5721

Learning rate: 0.00019998253007519698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 596 [0/90000 (0%)]	Loss: 10.0740	Cost: 22.67s
Train Epoch: 596 [20480/90000 (23%)]	Loss: 9.3614	Cost: 6.33s
Train Epoch: 596 [40960/90000 (45%)]	Loss: 9.3012	Cost: 12.49s
Train Epoch: 596 [61440/90000 (68%)]	Loss: 9.4342	Cost: 12.08s
Train Epoch: 596 [81920/90000 (91%)]	Loss: 9.2987	Cost: 11.84s
Train Epoch: 596 	Average Loss: 9.3584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5186

Learning rate: 0.00019998247130513115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 597 [0/90000 (0%)]	Loss: 10.2520	Cost: 29.05s
Train Epoch: 597 [20480/90000 (23%)]	Loss: 9.3666	Cost: 10.79s
Train Epoch: 597 [40960/90000 (45%)]	Loss: 9.3078	Cost: 12.10s
Train Epoch: 597 [61440/90000 (68%)]	Loss: 9.3205	Cost: 12.06s
Train Epoch: 597 [81920/90000 (91%)]	Loss: 9.4199	Cost: 8.16s
Train Epoch: 597 	Average Loss: 9.4062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5412

Learning rate: 0.00019998241243638655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 598 [0/90000 (0%)]	Loss: 10.2209	Cost: 34.16s
Train Epoch: 598 [20480/90000 (23%)]	Loss: 9.4218	Cost: 10.95s
Train Epoch: 598 [40960/90000 (45%)]	Loss: 9.2626	Cost: 9.41s
Train Epoch: 598 [61440/90000 (68%)]	Loss: 9.5107	Cost: 6.15s
Train Epoch: 598 [81920/90000 (91%)]	Loss: 9.5120	Cost: 6.69s
Train Epoch: 598 	Average Loss: 9.3998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5778

Learning rate: 0.00019998235346896327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 599 [0/90000 (0%)]	Loss: 10.2585	Cost: 24.69s
Train Epoch: 599 [20480/90000 (23%)]	Loss: 9.3696	Cost: 6.15s
Train Epoch: 599 [40960/90000 (45%)]	Loss: 9.1366	Cost: 10.34s
Train Epoch: 599 [61440/90000 (68%)]	Loss: 9.2986	Cost: 6.43s
Train Epoch: 599 [81920/90000 (91%)]	Loss: 9.4439	Cost: 11.39s
Train Epoch: 599 	Average Loss: 9.3524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5437

Learning rate: 0.0001999822944028614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 600 [0/90000 (0%)]	Loss: 10.2777	Cost: 25.41s
Train Epoch: 600 [20480/90000 (23%)]	Loss: 9.3169	Cost: 6.30s
Train Epoch: 600 [40960/90000 (45%)]	Loss: 9.2773	Cost: 13.20s
Train Epoch: 600 [61440/90000 (68%)]	Loss: 9.4040	Cost: 12.17s
Train Epoch: 600 [81920/90000 (91%)]	Loss: 9.3785	Cost: 11.80s
Train Epoch: 600 	Average Loss: 9.3840
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5047

Learning rate: 0.0001999822352380809
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 601 [0/90000 (0%)]	Loss: 10.3768	Cost: 29.50s
Train Epoch: 601 [20480/90000 (23%)]	Loss: 9.3133	Cost: 12.14s
Train Epoch: 601 [40960/90000 (45%)]	Loss: 9.2755	Cost: 12.33s
Train Epoch: 601 [61440/90000 (68%)]	Loss: 9.4769	Cost: 11.52s
Train Epoch: 601 [81920/90000 (91%)]	Loss: 9.4029	Cost: 7.52s
Train Epoch: 601 	Average Loss: 9.4001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6070

Learning rate: 0.00019998217597462192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 602 [0/90000 (0%)]	Loss: 10.3733	Cost: 26.67s
Train Epoch: 602 [20480/90000 (23%)]	Loss: 9.3237	Cost: 11.86s
Train Epoch: 602 [40960/90000 (45%)]	Loss: 9.1500	Cost: 8.82s
Train Epoch: 602 [61440/90000 (68%)]	Loss: 9.2936	Cost: 5.88s
Train Epoch: 602 [81920/90000 (91%)]	Loss: 9.3775	Cost: 6.71s
Train Epoch: 602 	Average Loss: 9.3472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6331

Learning rate: 0.00019998211661248448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 603 [0/90000 (0%)]	Loss: 10.1703	Cost: 24.72s
Train Epoch: 603 [20480/90000 (23%)]	Loss: 9.4797	Cost: 6.31s
Train Epoch: 603 [40960/90000 (45%)]	Loss: 9.3714	Cost: 6.39s
Train Epoch: 603 [61440/90000 (68%)]	Loss: 9.3539	Cost: 6.19s
Train Epoch: 603 [81920/90000 (91%)]	Loss: 9.3997	Cost: 6.16s
Train Epoch: 603 	Average Loss: 9.3859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5630

Learning rate: 0.00019998205715166862
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 604 [0/90000 (0%)]	Loss: 10.1938	Cost: 22.45s
Train Epoch: 604 [20480/90000 (23%)]	Loss: 9.2625	Cost: 6.26s
Train Epoch: 604 [40960/90000 (45%)]	Loss: 9.2430	Cost: 7.09s
Train Epoch: 604 [61440/90000 (68%)]	Loss: 9.2663	Cost: 6.71s
Train Epoch: 604 [81920/90000 (91%)]	Loss: 9.3139	Cost: 15.51s
Train Epoch: 604 	Average Loss: 9.3628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5806

Learning rate: 0.00019998199759217446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 605 [0/90000 (0%)]	Loss: 10.0688	Cost: 24.91s
Train Epoch: 605 [20480/90000 (23%)]	Loss: 9.3728	Cost: 8.10s
Train Epoch: 605 [40960/90000 (45%)]	Loss: 9.2530	Cost: 11.08s
Train Epoch: 605 [61440/90000 (68%)]	Loss: 9.2108	Cost: 11.98s
Train Epoch: 605 [81920/90000 (91%)]	Loss: 9.4696	Cost: 11.87s
Train Epoch: 605 	Average Loss: 9.3448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5198

Learning rate: 0.000199981937934002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 606 [0/90000 (0%)]	Loss: 10.3438	Cost: 26.29s
Train Epoch: 606 [20480/90000 (23%)]	Loss: 9.3062	Cost: 11.84s
Train Epoch: 606 [40960/90000 (45%)]	Loss: 9.2898	Cost: 12.04s
Train Epoch: 606 [61440/90000 (68%)]	Loss: 9.4208	Cost: 11.73s
Train Epoch: 606 [81920/90000 (91%)]	Loss: 9.2753	Cost: 11.49s
Train Epoch: 606 	Average Loss: 9.3498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5825

Learning rate: 0.00019998187817715134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 607 [0/90000 (0%)]	Loss: 10.0114	Cost: 29.34s
Train Epoch: 607 [20480/90000 (23%)]	Loss: 9.2751	Cost: 12.16s
Train Epoch: 607 [40960/90000 (45%)]	Loss: 9.2439	Cost: 11.75s
Train Epoch: 607 [61440/90000 (68%)]	Loss: 9.3010	Cost: 5.78s
Train Epoch: 607 [81920/90000 (91%)]	Loss: 9.4242	Cost: 6.16s
Train Epoch: 607 	Average Loss: 9.3199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5633

Learning rate: 0.00019998181832162252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 608 [0/90000 (0%)]	Loss: 10.2217	Cost: 26.81s
Train Epoch: 608 [20480/90000 (23%)]	Loss: 9.4027	Cost: 8.42s
Train Epoch: 608 [40960/90000 (45%)]	Loss: 9.3495	Cost: 10.04s
Train Epoch: 608 [61440/90000 (68%)]	Loss: 9.3536	Cost: 5.86s
Train Epoch: 608 [81920/90000 (91%)]	Loss: 9.3747	Cost: 6.73s
Train Epoch: 608 	Average Loss: 9.3408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6243

Learning rate: 0.0001999817583674156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 609 [0/90000 (0%)]	Loss: 10.4319	Cost: 26.35s
Train Epoch: 609 [20480/90000 (23%)]	Loss: 9.3466	Cost: 8.03s
Train Epoch: 609 [40960/90000 (45%)]	Loss: 9.2536	Cost: 6.03s
Train Epoch: 609 [61440/90000 (68%)]	Loss: 9.2609	Cost: 6.87s
Train Epoch: 609 [81920/90000 (91%)]	Loss: 9.2208	Cost: 6.10s
Train Epoch: 609 	Average Loss: 9.3266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5696

Learning rate: 0.00019998169831453064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 610 [0/90000 (0%)]	Loss: 10.0389	Cost: 24.64s
Train Epoch: 610 [20480/90000 (23%)]	Loss: 9.2783	Cost: 6.50s
Train Epoch: 610 [40960/90000 (45%)]	Loss: 9.1215	Cost: 6.78s
Train Epoch: 610 [61440/90000 (68%)]	Loss: 9.1377	Cost: 6.10s
Train Epoch: 610 [81920/90000 (91%)]	Loss: 9.4171	Cost: 6.09s
Train Epoch: 610 	Average Loss: 9.3286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6468

Learning rate: 0.0001999816381629677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 611 [0/90000 (0%)]	Loss: 10.1281	Cost: 23.10s
Train Epoch: 611 [20480/90000 (23%)]	Loss: 9.3467	Cost: 6.16s
Train Epoch: 611 [40960/90000 (45%)]	Loss: 9.0002	Cost: 6.30s
Train Epoch: 611 [61440/90000 (68%)]	Loss: 9.2411	Cost: 6.00s
Train Epoch: 611 [81920/90000 (91%)]	Loss: 9.1843	Cost: 11.69s
Train Epoch: 611 	Average Loss: 9.3207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5969

Learning rate: 0.00019998157791272685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 612 [0/90000 (0%)]	Loss: 10.4623	Cost: 23.97s
Train Epoch: 612 [20480/90000 (23%)]	Loss: 9.1684	Cost: 6.08s
Train Epoch: 612 [40960/90000 (45%)]	Loss: 9.1882	Cost: 11.82s
Train Epoch: 612 [61440/90000 (68%)]	Loss: 9.2738	Cost: 12.07s
Train Epoch: 612 [81920/90000 (91%)]	Loss: 9.2080	Cost: 11.79s
Train Epoch: 612 	Average Loss: 9.3277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6487

Learning rate: 0.00019998151756380812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 613 [0/90000 (0%)]	Loss: 10.2756	Cost: 26.28s
Train Epoch: 613 [20480/90000 (23%)]	Loss: 9.4782	Cost: 12.03s
Train Epoch: 613 [40960/90000 (45%)]	Loss: 9.1879	Cost: 12.45s
Train Epoch: 613 [61440/90000 (68%)]	Loss: 9.2406	Cost: 11.55s
Train Epoch: 613 [81920/90000 (91%)]	Loss: 9.2671	Cost: 11.89s
Train Epoch: 613 	Average Loss: 9.3176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6143

Learning rate: 0.0001999814571162116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 614 [0/90000 (0%)]	Loss: 10.3859	Cost: 28.45s
Train Epoch: 614 [20480/90000 (23%)]	Loss: 9.3313	Cost: 12.18s
Train Epoch: 614 [40960/90000 (45%)]	Loss: 9.4818	Cost: 12.04s
Train Epoch: 614 [61440/90000 (68%)]	Loss: 9.3054	Cost: 7.40s
Train Epoch: 614 [81920/90000 (91%)]	Loss: 9.3787	Cost: 5.85s
Train Epoch: 614 	Average Loss: 9.3156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6581

Learning rate: 0.00019998139656993732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 615 [0/90000 (0%)]	Loss: 10.3035	Cost: 28.02s
Train Epoch: 615 [20480/90000 (23%)]	Loss: 9.3193	Cost: 11.43s
Train Epoch: 615 [40960/90000 (45%)]	Loss: 9.3015	Cost: 7.81s
Train Epoch: 615 [61440/90000 (68%)]	Loss: 9.2531	Cost: 5.87s
Train Epoch: 615 [81920/90000 (91%)]	Loss: 9.1534	Cost: 6.71s
Train Epoch: 615 	Average Loss: 9.2926
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6242

Learning rate: 0.00019998133592498537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 616 [0/90000 (0%)]	Loss: 10.3079	Cost: 26.40s
Train Epoch: 616 [20480/90000 (23%)]	Loss: 9.2186	Cost: 6.53s
Train Epoch: 616 [40960/90000 (45%)]	Loss: 9.1377	Cost: 6.21s
Train Epoch: 616 [61440/90000 (68%)]	Loss: 9.1764	Cost: 6.90s
Train Epoch: 616 [81920/90000 (91%)]	Loss: 9.1895	Cost: 6.07s
Train Epoch: 616 	Average Loss: 9.3079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6015

Learning rate: 0.00019998127518135577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 617 [0/90000 (0%)]	Loss: 10.3972	Cost: 23.44s
Train Epoch: 617 [20480/90000 (23%)]	Loss: 9.3687	Cost: 6.89s
Train Epoch: 617 [40960/90000 (45%)]	Loss: 9.1641	Cost: 6.32s
Train Epoch: 617 [61440/90000 (68%)]	Loss: 9.1247	Cost: 6.01s
Train Epoch: 617 [81920/90000 (91%)]	Loss: 9.2719	Cost: 6.09s
Train Epoch: 617 	Average Loss: 9.3050
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5481

Learning rate: 0.0001999812143390486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 618 [0/90000 (0%)]	Loss: 10.2220	Cost: 23.48s
Train Epoch: 618 [20480/90000 (23%)]	Loss: 9.2312	Cost: 6.35s
Train Epoch: 618 [40960/90000 (45%)]	Loss: 9.3033	Cost: 6.56s
Train Epoch: 618 [61440/90000 (68%)]	Loss: 9.1610	Cost: 6.00s
Train Epoch: 618 [81920/90000 (91%)]	Loss: 9.2177	Cost: 11.22s
Train Epoch: 618 	Average Loss: 9.2760
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5469

Learning rate: 0.00019998115339806398
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 619 [0/90000 (0%)]	Loss: 10.2613	Cost: 25.10s
Train Epoch: 619 [20480/90000 (23%)]	Loss: 9.2315	Cost: 6.05s
Train Epoch: 619 [40960/90000 (45%)]	Loss: 9.2065	Cost: 12.98s
Train Epoch: 619 [61440/90000 (68%)]	Loss: 9.4510	Cost: 12.03s
Train Epoch: 619 [81920/90000 (91%)]	Loss: 9.3560	Cost: 11.79s
Train Epoch: 619 	Average Loss: 9.2921
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5941

Learning rate: 0.00019998109235840191
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 620 [0/90000 (0%)]	Loss: 10.3335	Cost: 26.36s
Train Epoch: 620 [20480/90000 (23%)]	Loss: 9.1484	Cost: 12.26s
Train Epoch: 620 [40960/90000 (45%)]	Loss: 9.3504	Cost: 11.98s
Train Epoch: 620 [61440/90000 (68%)]	Loss: 9.2933	Cost: 11.42s
Train Epoch: 620 [81920/90000 (91%)]	Loss: 9.3091	Cost: 11.65s
Train Epoch: 620 	Average Loss: 9.2865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6026

Learning rate: 0.00019998103122006243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 621 [0/90000 (0%)]	Loss: 10.1367	Cost: 28.15s
Train Epoch: 621 [20480/90000 (23%)]	Loss: 9.2779	Cost: 12.10s
Train Epoch: 621 [40960/90000 (45%)]	Loss: 8.9145	Cost: 12.02s
Train Epoch: 621 [61440/90000 (68%)]	Loss: 9.1035	Cost: 6.15s
Train Epoch: 621 [81920/90000 (91%)]	Loss: 9.3305	Cost: 5.83s
Train Epoch: 621 	Average Loss: 9.2567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5006

Learning rate: 0.00019998096998304565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 622 [0/90000 (0%)]	Loss: 10.2795	Cost: 26.59s
Train Epoch: 622 [20480/90000 (23%)]	Loss: 9.2209	Cost: 8.21s
Train Epoch: 622 [40960/90000 (45%)]	Loss: 9.2119	Cost: 5.99s
Train Epoch: 622 [61440/90000 (68%)]	Loss: 9.1575	Cost: 7.04s
Train Epoch: 622 [81920/90000 (91%)]	Loss: 9.2173	Cost: 5.83s
Train Epoch: 622 	Average Loss: 9.2728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5229

Learning rate: 0.0001999809086473516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 623 [0/90000 (0%)]	Loss: 10.1496	Cost: 24.12s
Train Epoch: 623 [20480/90000 (23%)]	Loss: 9.1599	Cost: 6.04s
Train Epoch: 623 [40960/90000 (45%)]	Loss: 9.2587	Cost: 7.23s
Train Epoch: 623 [61440/90000 (68%)]	Loss: 9.3983	Cost: 6.10s
Train Epoch: 623 [81920/90000 (91%)]	Loss: 9.3659	Cost: 5.96s
Train Epoch: 623 	Average Loss: 9.2533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5769

Learning rate: 0.00019998084721298032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 624 [0/90000 (0%)]	Loss: 10.1148	Cost: 22.72s
Train Epoch: 624 [20480/90000 (23%)]	Loss: 9.2301	Cost: 6.36s
Train Epoch: 624 [40960/90000 (45%)]	Loss: 8.9989	Cost: 6.40s
Train Epoch: 624 [61440/90000 (68%)]	Loss: 9.2758	Cost: 6.00s
Train Epoch: 624 [81920/90000 (91%)]	Loss: 9.5292	Cost: 6.52s
Train Epoch: 624 	Average Loss: 9.2458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6429

Learning rate: 0.00019998078567993191
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 625 [0/90000 (0%)]	Loss: 10.1059	Cost: 23.37s
Train Epoch: 625 [20480/90000 (23%)]	Loss: 9.2047	Cost: 6.17s
Train Epoch: 625 [40960/90000 (45%)]	Loss: 9.1819	Cost: 12.75s
Train Epoch: 625 [61440/90000 (68%)]	Loss: 9.2984	Cost: 12.17s
Train Epoch: 625 [81920/90000 (91%)]	Loss: 9.2260	Cost: 11.83s
Train Epoch: 625 	Average Loss: 9.2459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6174

Learning rate: 0.00019998072404820645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 626 [0/90000 (0%)]	Loss: 10.2307	Cost: 26.11s
Train Epoch: 626 [20480/90000 (23%)]	Loss: 9.2066	Cost: 11.95s
Train Epoch: 626 [40960/90000 (45%)]	Loss: 9.0322	Cost: 12.10s
Train Epoch: 626 [61440/90000 (68%)]	Loss: 9.0883	Cost: 11.71s
Train Epoch: 626 [81920/90000 (91%)]	Loss: 9.1807	Cost: 11.36s
Train Epoch: 626 	Average Loss: 9.2262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6019

Learning rate: 0.00019998066231780395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 627 [0/90000 (0%)]	Loss: 10.0871	Cost: 27.17s
Train Epoch: 627 [20480/90000 (23%)]	Loss: 9.3997	Cost: 12.11s
Train Epoch: 627 [40960/90000 (45%)]	Loss: 9.1920	Cost: 11.98s
Train Epoch: 627 [61440/90000 (68%)]	Loss: 9.4040	Cost: 7.51s
Train Epoch: 627 [81920/90000 (91%)]	Loss: 9.2352	Cost: 5.85s
Train Epoch: 627 	Average Loss: 9.2513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5454

Learning rate: 0.0001999806004887245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 628 [0/90000 (0%)]	Loss: 10.2211	Cost: 27.85s
Train Epoch: 628 [20480/90000 (23%)]	Loss: 9.1496	Cost: 10.91s
Train Epoch: 628 [40960/90000 (45%)]	Loss: 9.0713	Cost: 6.14s
Train Epoch: 628 [61440/90000 (68%)]	Loss: 9.3272	Cost: 5.84s
Train Epoch: 628 [81920/90000 (91%)]	Loss: 9.0957	Cost: 6.87s
Train Epoch: 628 	Average Loss: 9.2059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5659

Learning rate: 0.00019998053856096817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 629 [0/90000 (0%)]	Loss: 10.3982	Cost: 24.96s
Train Epoch: 629 [20480/90000 (23%)]	Loss: 9.2848	Cost: 5.95s
Train Epoch: 629 [40960/90000 (45%)]	Loss: 9.1373	Cost: 7.03s
Train Epoch: 629 [61440/90000 (68%)]	Loss: 9.0914	Cost: 6.13s
Train Epoch: 629 [81920/90000 (91%)]	Loss: 9.1686	Cost: 6.16s
Train Epoch: 629 	Average Loss: 9.2078
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5582

Learning rate: 0.00019998047653453497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 630 [0/90000 (0%)]	Loss: 10.2035	Cost: 22.69s
Train Epoch: 630 [20480/90000 (23%)]	Loss: 9.3281	Cost: 6.32s
Train Epoch: 630 [40960/90000 (45%)]	Loss: 9.1136	Cost: 6.40s
Train Epoch: 630 [61440/90000 (68%)]	Loss: 9.1759	Cost: 6.04s
Train Epoch: 630 [81920/90000 (91%)]	Loss: 9.1481	Cost: 5.99s
Train Epoch: 630 	Average Loss: 9.2569
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6526

Learning rate: 0.000199980414409425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 631 [0/90000 (0%)]	Loss: 10.3601	Cost: 23.10s
Train Epoch: 631 [20480/90000 (23%)]	Loss: 9.0527	Cost: 5.98s
Train Epoch: 631 [40960/90000 (45%)]	Loss: 9.1220	Cost: 9.40s
Train Epoch: 631 [61440/90000 (68%)]	Loss: 9.1843	Cost: 12.29s
Train Epoch: 631 [81920/90000 (91%)]	Loss: 9.1768	Cost: 12.00s
Train Epoch: 631 	Average Loss: 9.2122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5452

Learning rate: 0.0001999803521856383
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 632 [0/90000 (0%)]	Loss: 10.2426	Cost: 26.94s
Train Epoch: 632 [20480/90000 (23%)]	Loss: 9.2731	Cost: 11.22s
Train Epoch: 632 [40960/90000 (45%)]	Loss: 9.3441	Cost: 12.21s
Train Epoch: 632 [61440/90000 (68%)]	Loss: 9.0922	Cost: 11.87s
Train Epoch: 632 [81920/90000 (91%)]	Loss: 9.1341	Cost: 11.89s
Train Epoch: 632 	Average Loss: 9.2117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6333

Learning rate: 0.00019998028986317499
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 633 [0/90000 (0%)]	Loss: 10.2083	Cost: 30.25s
Train Epoch: 633 [20480/90000 (23%)]	Loss: 9.2046	Cost: 10.01s
Train Epoch: 633 [40960/90000 (45%)]	Loss: 9.0957	Cost: 11.96s
Train Epoch: 633 [61440/90000 (68%)]	Loss: 9.0182	Cost: 11.75s
Train Epoch: 633 [81920/90000 (91%)]	Loss: 9.3309	Cost: 7.04s
Train Epoch: 633 	Average Loss: 9.1832
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5546

Learning rate: 0.00019998022744203506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 634 [0/90000 (0%)]	Loss: 10.0919	Cost: 28.25s
Train Epoch: 634 [20480/90000 (23%)]	Loss: 9.0171	Cost: 12.10s
Train Epoch: 634 [40960/90000 (45%)]	Loss: 9.1086	Cost: 10.14s
Train Epoch: 634 [61440/90000 (68%)]	Loss: 9.2345	Cost: 5.87s
Train Epoch: 634 [81920/90000 (91%)]	Loss: 9.3745	Cost: 6.78s
Train Epoch: 634 	Average Loss: 9.1792
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6276

Learning rate: 0.0001999801649222186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 635 [0/90000 (0%)]	Loss: 10.3066	Cost: 26.31s
Train Epoch: 635 [20480/90000 (23%)]	Loss: 9.2581	Cost: 12.08s
Train Epoch: 635 [40960/90000 (45%)]	Loss: 9.0213	Cost: 6.35s
Train Epoch: 635 [61440/90000 (68%)]	Loss: 9.2208	Cost: 5.93s
Train Epoch: 635 [81920/90000 (91%)]	Loss: 8.9696	Cost: 6.89s
Train Epoch: 635 	Average Loss: 9.1836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5774

Learning rate: 0.00019998010230372565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 636 [0/90000 (0%)]	Loss: 10.0974	Cost: 25.01s
Train Epoch: 636 [20480/90000 (23%)]	Loss: 9.1499	Cost: 5.96s
Train Epoch: 636 [40960/90000 (45%)]	Loss: 9.0378	Cost: 7.19s
Train Epoch: 636 [61440/90000 (68%)]	Loss: 9.0971	Cost: 6.52s
Train Epoch: 636 [81920/90000 (91%)]	Loss: 9.0497	Cost: 6.10s
Train Epoch: 636 	Average Loss: 9.1644
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5662

Learning rate: 0.00019998003958655633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 637 [0/90000 (0%)]	Loss: 10.4612	Cost: 24.33s
Train Epoch: 637 [20480/90000 (23%)]	Loss: 9.2007	Cost: 6.19s
Train Epoch: 637 [40960/90000 (45%)]	Loss: 9.0019	Cost: 6.62s
Train Epoch: 637 [61440/90000 (68%)]	Loss: 9.0866	Cost: 5.98s
Train Epoch: 637 [81920/90000 (91%)]	Loss: 9.2195	Cost: 6.29s
Train Epoch: 637 	Average Loss: 9.1703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6046

Learning rate: 0.00019997997677071068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 638 [0/90000 (0%)]	Loss: 10.1301	Cost: 22.16s
Train Epoch: 638 [20480/90000 (23%)]	Loss: 9.2898	Cost: 6.05s
Train Epoch: 638 [40960/90000 (45%)]	Loss: 8.9125	Cost: 8.22s
Train Epoch: 638 [61440/90000 (68%)]	Loss: 9.1985	Cost: 6.32s
Train Epoch: 638 [81920/90000 (91%)]	Loss: 9.0990	Cost: 16.47s
Train Epoch: 638 	Average Loss: 9.1846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5310

Learning rate: 0.00019997991385618872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 639 [0/90000 (0%)]	Loss: 10.4311	Cost: 24.85s
Train Epoch: 639 [20480/90000 (23%)]	Loss: 9.1547	Cost: 8.01s
Train Epoch: 639 [40960/90000 (45%)]	Loss: 9.1459	Cost: 12.28s
Train Epoch: 639 [61440/90000 (68%)]	Loss: 9.2248	Cost: 11.94s
Train Epoch: 639 [81920/90000 (91%)]	Loss: 9.1320	Cost: 11.95s
Train Epoch: 639 	Average Loss: 9.1936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5757

Learning rate: 0.00019997985084299058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 640 [0/90000 (0%)]	Loss: 10.1955	Cost: 26.68s
Train Epoch: 640 [20480/90000 (23%)]	Loss: 9.0215	Cost: 12.16s
Train Epoch: 640 [40960/90000 (45%)]	Loss: 8.9908	Cost: 12.14s
Train Epoch: 640 [61440/90000 (68%)]	Loss: 9.2831	Cost: 11.97s
Train Epoch: 640 [81920/90000 (91%)]	Loss: 9.0677	Cost: 9.14s
Train Epoch: 640 	Average Loss: 9.1779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5278

Learning rate: 0.00019997978773111623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 641 [0/90000 (0%)]	Loss: 10.3779	Cost: 25.40s
Train Epoch: 641 [20480/90000 (23%)]	Loss: 9.2127	Cost: 6.01s
Train Epoch: 641 [40960/90000 (45%)]	Loss: 9.0786	Cost: 7.27s
Train Epoch: 641 [61440/90000 (68%)]	Loss: 9.2383	Cost: 6.75s
Train Epoch: 641 [81920/90000 (91%)]	Loss: 9.2482	Cost: 6.55s
Train Epoch: 641 	Average Loss: 9.1432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5896

Learning rate: 0.00019997972452056583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 642 [0/90000 (0%)]	Loss: 10.4877	Cost: 22.40s
Train Epoch: 642 [20480/90000 (23%)]	Loss: 9.1899	Cost: 6.38s
Train Epoch: 642 [40960/90000 (45%)]	Loss: 9.0332	Cost: 6.20s
Train Epoch: 642 [61440/90000 (68%)]	Loss: 9.1749	Cost: 6.20s
Train Epoch: 642 [81920/90000 (91%)]	Loss: 9.0357	Cost: 14.10s
Train Epoch: 642 	Average Loss: 9.1900
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6290

Learning rate: 0.00019997966121133937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 643 [0/90000 (0%)]	Loss: 10.2287	Cost: 26.03s
Train Epoch: 643 [20480/90000 (23%)]	Loss: 9.0911	Cost: 9.21s
Train Epoch: 643 [40960/90000 (45%)]	Loss: 8.8642	Cost: 12.33s
Train Epoch: 643 [61440/90000 (68%)]	Loss: 8.9309	Cost: 11.84s
Train Epoch: 643 [81920/90000 (91%)]	Loss: 9.1218	Cost: 11.40s
Train Epoch: 643 	Average Loss: 9.1373
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6486

Learning rate: 0.00019997959780343694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 644 [0/90000 (0%)]	Loss: 10.1680	Cost: 26.31s
Train Epoch: 644 [20480/90000 (23%)]	Loss: 9.2601	Cost: 11.91s
Train Epoch: 644 [40960/90000 (45%)]	Loss: 8.9090	Cost: 12.01s
Train Epoch: 644 [61440/90000 (68%)]	Loss: 8.9974	Cost: 11.83s
Train Epoch: 644 [81920/90000 (91%)]	Loss: 9.0507	Cost: 8.06s
Train Epoch: 644 	Average Loss: 9.1280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6103

Learning rate: 0.0001999795342968586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 645 [0/90000 (0%)]	Loss: 10.2242	Cost: 28.18s
Train Epoch: 645 [20480/90000 (23%)]	Loss: 9.1751	Cost: 12.00s
Train Epoch: 645 [40960/90000 (45%)]	Loss: 8.9694	Cost: 11.77s
Train Epoch: 645 [61440/90000 (68%)]	Loss: 9.0733	Cost: 5.85s
Train Epoch: 645 [81920/90000 (91%)]	Loss: 9.0673	Cost: 5.81s
Train Epoch: 645 	Average Loss: 9.0910
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5489

Learning rate: 0.00019997947069160443
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 646 [0/90000 (0%)]	Loss: 10.0979	Cost: 27.18s
Train Epoch: 646 [20480/90000 (23%)]	Loss: 9.1765	Cost: 9.86s
Train Epoch: 646 [40960/90000 (45%)]	Loss: 9.0811	Cost: 6.15s
Train Epoch: 646 [61440/90000 (68%)]	Loss: 9.0077	Cost: 6.15s
Train Epoch: 646 [81920/90000 (91%)]	Loss: 9.0189	Cost: 6.61s
Train Epoch: 646 	Average Loss: 9.1248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6341

Learning rate: 0.00019997940698767447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 647 [0/90000 (0%)]	Loss: 10.4139	Cost: 25.43s
Train Epoch: 647 [20480/90000 (23%)]	Loss: 9.1255	Cost: 5.95s
Train Epoch: 647 [40960/90000 (45%)]	Loss: 9.0405	Cost: 7.21s
Train Epoch: 647 [61440/90000 (68%)]	Loss: 9.0364	Cost: 6.06s
Train Epoch: 647 [81920/90000 (91%)]	Loss: 9.1727	Cost: 6.76s
Train Epoch: 647 	Average Loss: 9.1181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5628

Learning rate: 0.0001999793431850688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 648 [0/90000 (0%)]	Loss: 10.0288	Cost: 22.80s
Train Epoch: 648 [20480/90000 (23%)]	Loss: 8.9281	Cost: 6.33s
Train Epoch: 648 [40960/90000 (45%)]	Loss: 9.0455	Cost: 6.51s
Train Epoch: 648 [61440/90000 (68%)]	Loss: 9.1308	Cost: 5.92s
Train Epoch: 648 [81920/90000 (91%)]	Loss: 9.0635	Cost: 7.59s
Train Epoch: 648 	Average Loss: 9.1360
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6135

Learning rate: 0.00019997927928378745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 649 [0/90000 (0%)]	Loss: 10.1421	Cost: 23.80s
Train Epoch: 649 [20480/90000 (23%)]	Loss: 9.0121	Cost: 6.14s
Train Epoch: 649 [40960/90000 (45%)]	Loss: 8.9283	Cost: 10.13s
Train Epoch: 649 [61440/90000 (68%)]	Loss: 8.9935	Cost: 11.80s
Train Epoch: 649 [81920/90000 (91%)]	Loss: 9.1631	Cost: 11.96s
Train Epoch: 649 	Average Loss: 9.1026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5125

Learning rate: 0.0001999792152838305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 650 [0/90000 (0%)]	Loss: 10.3028	Cost: 31.71s
Train Epoch: 650 [20480/90000 (23%)]	Loss: 9.0848	Cost: 12.18s
Train Epoch: 650 [40960/90000 (45%)]	Loss: 9.0171	Cost: 11.98s
Train Epoch: 650 [61440/90000 (68%)]	Loss: 9.0472	Cost: 9.28s
Train Epoch: 650 [81920/90000 (91%)]	Loss: 9.0338	Cost: 5.94s
Train Epoch: 650 	Average Loss: 9.0992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6269

Learning rate: 0.00019997915118519805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 651 [0/90000 (0%)]	Loss: 10.3438	Cost: 27.71s
Train Epoch: 651 [20480/90000 (23%)]	Loss: 8.9863	Cost: 9.68s
Train Epoch: 651 [40960/90000 (45%)]	Loss: 8.8683	Cost: 5.99s
Train Epoch: 651 [61440/90000 (68%)]	Loss: 8.9850	Cost: 6.40s
Train Epoch: 651 [81920/90000 (91%)]	Loss: 9.0061	Cost: 6.33s
Train Epoch: 651 	Average Loss: 9.0916
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5989

Learning rate: 0.0001999790869878901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 652 [0/90000 (0%)]	Loss: 10.2694	Cost: 25.21s
Train Epoch: 652 [20480/90000 (23%)]	Loss: 9.2850	Cost: 5.94s
Train Epoch: 652 [40960/90000 (45%)]	Loss: 8.9354	Cost: 7.48s
Train Epoch: 652 [61440/90000 (68%)]	Loss: 9.0507	Cost: 6.42s
Train Epoch: 652 [81920/90000 (91%)]	Loss: 9.0946	Cost: 5.98s
Train Epoch: 652 	Average Loss: 9.1010
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7213

Learning rate: 0.00019997902269190676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 653 [0/90000 (0%)]	Loss: 10.3975	Cost: 24.24s
Train Epoch: 653 [20480/90000 (23%)]	Loss: 9.1833	Cost: 6.33s
Train Epoch: 653 [40960/90000 (45%)]	Loss: 8.9848	Cost: 6.40s
Train Epoch: 653 [61440/90000 (68%)]	Loss: 9.1452	Cost: 5.95s
Train Epoch: 653 [81920/90000 (91%)]	Loss: 8.9223	Cost: 5.99s
Train Epoch: 653 	Average Loss: 9.0739
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6417

Learning rate: 0.0001999789582972481
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 654 [0/90000 (0%)]	Loss: 10.2831	Cost: 22.91s
Train Epoch: 654 [20480/90000 (23%)]	Loss: 9.0672	Cost: 6.08s
Train Epoch: 654 [40960/90000 (45%)]	Loss: 8.9916	Cost: 11.77s
Train Epoch: 654 [61440/90000 (68%)]	Loss: 9.0899	Cost: 12.13s
Train Epoch: 654 [81920/90000 (91%)]	Loss: 9.0699	Cost: 11.89s
Train Epoch: 654 	Average Loss: 9.0973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5710

Learning rate: 0.00019997889380391414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 655 [0/90000 (0%)]	Loss: 10.4104	Cost: 25.80s
Train Epoch: 655 [20480/90000 (23%)]	Loss: 9.0673	Cost: 11.85s
Train Epoch: 655 [40960/90000 (45%)]	Loss: 8.9169	Cost: 12.08s
Train Epoch: 655 [61440/90000 (68%)]	Loss: 8.9713	Cost: 11.86s
Train Epoch: 655 [81920/90000 (91%)]	Loss: 9.1175	Cost: 11.85s
Train Epoch: 655 	Average Loss: 9.1016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5828

Learning rate: 0.00019997882921190502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 656 [0/90000 (0%)]	Loss: 10.5048	Cost: 28.61s
Train Epoch: 656 [20480/90000 (23%)]	Loss: 9.2756	Cost: 12.25s
Train Epoch: 656 [40960/90000 (45%)]	Loss: 8.9403	Cost: 12.13s
Train Epoch: 656 [61440/90000 (68%)]	Loss: 8.8512	Cost: 11.78s
Train Epoch: 656 [81920/90000 (91%)]	Loss: 9.0491	Cost: 7.07s
Train Epoch: 656 	Average Loss: 9.0846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6341

Learning rate: 0.00019997876452122068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 657 [0/90000 (0%)]	Loss: 10.3534	Cost: 28.43s
Train Epoch: 657 [20480/90000 (23%)]	Loss: 9.0223	Cost: 11.79s
Train Epoch: 657 [40960/90000 (45%)]	Loss: 8.8250	Cost: 8.74s
Train Epoch: 657 [61440/90000 (68%)]	Loss: 8.9102	Cost: 5.86s
Train Epoch: 657 [81920/90000 (91%)]	Loss: 9.1003	Cost: 6.72s
Train Epoch: 657 	Average Loss: 9.0501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6051

Learning rate: 0.00019997869973186128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 658 [0/90000 (0%)]	Loss: 10.1293	Cost: 25.36s
Train Epoch: 658 [20480/90000 (23%)]	Loss: 8.9690	Cost: 6.00s
Train Epoch: 658 [40960/90000 (45%)]	Loss: 9.0895	Cost: 7.91s
Train Epoch: 658 [61440/90000 (68%)]	Loss: 8.9000	Cost: 6.16s
Train Epoch: 658 [81920/90000 (91%)]	Loss: 8.9365	Cost: 6.15s
Train Epoch: 658 	Average Loss: 9.0685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7480

Learning rate: 0.00019997863484382683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 659 [0/90000 (0%)]	Loss: 10.1962	Cost: 24.02s
Train Epoch: 659 [20480/90000 (23%)]	Loss: 9.1121	Cost: 6.11s
Train Epoch: 659 [40960/90000 (45%)]	Loss: 9.0248	Cost: 6.63s
Train Epoch: 659 [61440/90000 (68%)]	Loss: 9.0673	Cost: 5.94s
Train Epoch: 659 [81920/90000 (91%)]	Loss: 9.0400	Cost: 5.92s
Train Epoch: 659 	Average Loss: 9.0370
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6906

Learning rate: 0.00019997856985711746
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 660 [0/90000 (0%)]	Loss: 10.1952	Cost: 22.84s
Train Epoch: 660 [20480/90000 (23%)]	Loss: 9.0716	Cost: 6.14s
Train Epoch: 660 [40960/90000 (45%)]	Loss: 8.8985	Cost: 7.87s
Train Epoch: 660 [61440/90000 (68%)]	Loss: 9.0267	Cost: 6.59s
Train Epoch: 660 [81920/90000 (91%)]	Loss: 9.0362	Cost: 14.93s
Train Epoch: 660 	Average Loss: 9.0567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6615

Learning rate: 0.0001999785047717332
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 661 [0/90000 (0%)]	Loss: 10.1749	Cost: 25.73s
Train Epoch: 661 [20480/90000 (23%)]	Loss: 8.9702	Cost: 8.75s
Train Epoch: 661 [40960/90000 (45%)]	Loss: 8.8192	Cost: 12.24s
Train Epoch: 661 [61440/90000 (68%)]	Loss: 9.1563	Cost: 11.97s
Train Epoch: 661 [81920/90000 (91%)]	Loss: 8.9305	Cost: 11.79s
Train Epoch: 661 	Average Loss: 9.0172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6097

Learning rate: 0.0001999784395876741
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 662 [0/90000 (0%)]	Loss: 10.2099	Cost: 26.35s
Train Epoch: 662 [20480/90000 (23%)]	Loss: 9.0752	Cost: 12.24s
Train Epoch: 662 [40960/90000 (45%)]	Loss: 8.9044	Cost: 11.98s
Train Epoch: 662 [61440/90000 (68%)]	Loss: 9.0030	Cost: 11.81s
Train Epoch: 662 [81920/90000 (91%)]	Loss: 9.0180	Cost: 9.86s
Train Epoch: 662 	Average Loss: 9.0227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5516

Learning rate: 0.00019997837430494025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 663 [0/90000 (0%)]	Loss: 10.2392	Cost: 28.72s
Train Epoch: 663 [20480/90000 (23%)]	Loss: 9.1534	Cost: 12.13s
Train Epoch: 663 [40960/90000 (45%)]	Loss: 8.8458	Cost: 11.93s
Train Epoch: 663 [61440/90000 (68%)]	Loss: 8.7612	Cost: 5.83s
Train Epoch: 663 [81920/90000 (91%)]	Loss: 9.0116	Cost: 6.04s
Train Epoch: 663 	Average Loss: 9.0293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5393

Learning rate: 0.00019997830892353166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 664 [0/90000 (0%)]	Loss: 10.4012	Cost: 27.14s
Train Epoch: 664 [20480/90000 (23%)]	Loss: 8.9840	Cost: 8.67s
Train Epoch: 664 [40960/90000 (45%)]	Loss: 9.0372	Cost: 6.17s
Train Epoch: 664 [61440/90000 (68%)]	Loss: 8.9034	Cost: 6.70s
Train Epoch: 664 [81920/90000 (91%)]	Loss: 9.0830	Cost: 6.05s
Train Epoch: 664 	Average Loss: 9.0381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7118

Learning rate: 0.0001999782434434485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 665 [0/90000 (0%)]	Loss: 10.2327	Cost: 24.22s
Train Epoch: 665 [20480/90000 (23%)]	Loss: 9.0875	Cost: 5.94s
Train Epoch: 665 [40960/90000 (45%)]	Loss: 8.7385	Cost: 7.34s
Train Epoch: 665 [61440/90000 (68%)]	Loss: 8.8049	Cost: 6.14s
Train Epoch: 665 [81920/90000 (91%)]	Loss: 9.1441	Cost: 6.00s
Train Epoch: 665 	Average Loss: 8.9923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6527

Learning rate: 0.0001999781778646907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 666 [0/90000 (0%)]	Loss: 10.4608	Cost: 24.09s
Train Epoch: 666 [20480/90000 (23%)]	Loss: 9.0001	Cost: 6.37s
Train Epoch: 666 [40960/90000 (45%)]	Loss: 8.9121	Cost: 6.38s
Train Epoch: 666 [61440/90000 (68%)]	Loss: 8.9506	Cost: 6.24s
Train Epoch: 666 [81920/90000 (91%)]	Loss: 9.0326	Cost: 6.12s
Train Epoch: 666 	Average Loss: 9.0102
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6486

Learning rate: 0.00019997811218725844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 667 [0/90000 (0%)]	Loss: 10.4100	Cost: 23.53s
Train Epoch: 667 [20480/90000 (23%)]	Loss: 8.8189	Cost: 6.06s
Train Epoch: 667 [40960/90000 (45%)]	Loss: 8.9337	Cost: 6.86s
Train Epoch: 667 [61440/90000 (68%)]	Loss: 8.8705	Cost: 6.08s
Train Epoch: 667 [81920/90000 (91%)]	Loss: 8.9518	Cost: 15.50s
Train Epoch: 667 	Average Loss: 9.0145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5277

Learning rate: 0.0001999780464111517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 668 [0/90000 (0%)]	Loss: 10.1689	Cost: 26.35s
Train Epoch: 668 [20480/90000 (23%)]	Loss: 9.0466	Cost: 9.99s
Train Epoch: 668 [40960/90000 (45%)]	Loss: 8.8543	Cost: 12.19s
Train Epoch: 668 [61440/90000 (68%)]	Loss: 8.7084	Cost: 11.96s
Train Epoch: 668 [81920/90000 (91%)]	Loss: 8.9296	Cost: 11.95s
Train Epoch: 668 	Average Loss: 9.0041
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6335

Learning rate: 0.00019997798053637063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 669 [0/90000 (0%)]	Loss: 10.5386	Cost: 28.33s
Train Epoch: 669 [20480/90000 (23%)]	Loss: 9.0164	Cost: 12.17s
Train Epoch: 669 [40960/90000 (45%)]	Loss: 8.9725	Cost: 10.06s
Train Epoch: 669 [61440/90000 (68%)]	Loss: 8.8026	Cost: 5.92s
Train Epoch: 669 [81920/90000 (91%)]	Loss: 8.8501	Cost: 6.76s
Train Epoch: 669 	Average Loss: 8.9937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7125

Learning rate: 0.00019997791456291523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 670 [0/90000 (0%)]	Loss: 10.4277	Cost: 27.98s
Train Epoch: 670 [20480/90000 (23%)]	Loss: 9.0543	Cost: 7.14s
Train Epoch: 670 [40960/90000 (45%)]	Loss: 8.7985	Cost: 6.54s
Train Epoch: 670 [61440/90000 (68%)]	Loss: 8.8002	Cost: 6.86s
Train Epoch: 670 [81920/90000 (91%)]	Loss: 8.9571	Cost: 6.19s
Train Epoch: 670 	Average Loss: 8.9772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6437

Learning rate: 0.00019997784849078558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 671 [0/90000 (0%)]	Loss: 10.3144	Cost: 23.55s
Train Epoch: 671 [20480/90000 (23%)]	Loss: 8.7822	Cost: 6.67s
Train Epoch: 671 [40960/90000 (45%)]	Loss: 8.7472	Cost: 7.32s
Train Epoch: 671 [61440/90000 (68%)]	Loss: 8.9590	Cost: 6.97s
Train Epoch: 671 [81920/90000 (91%)]	Loss: 9.0484	Cost: 9.08s
Train Epoch: 671 	Average Loss: 8.9883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6752

Learning rate: 0.00019997778231998174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 672 [0/90000 (0%)]	Loss: 10.4490	Cost: 29.31s
Train Epoch: 672 [20480/90000 (23%)]	Loss: 8.8770	Cost: 10.04s
Train Epoch: 672 [40960/90000 (45%)]	Loss: 8.9361	Cost: 12.12s
Train Epoch: 672 [61440/90000 (68%)]	Loss: 9.0486	Cost: 11.88s
Train Epoch: 672 [81920/90000 (91%)]	Loss: 8.8043	Cost: 7.56s
Train Epoch: 672 	Average Loss: 8.9681
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6397

Learning rate: 0.0001999777160505038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 673 [0/90000 (0%)]	Loss: 10.3025	Cost: 24.36s
Train Epoch: 673 [20480/90000 (23%)]	Loss: 8.9735	Cost: 5.95s
Train Epoch: 673 [40960/90000 (45%)]	Loss: 8.7076	Cost: 7.32s
Train Epoch: 673 [61440/90000 (68%)]	Loss: 9.0047	Cost: 6.18s
Train Epoch: 673 [81920/90000 (91%)]	Loss: 9.0077	Cost: 6.69s
Train Epoch: 673 	Average Loss: 8.9981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6457

Learning rate: 0.0001999776496823518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 674 [0/90000 (0%)]	Loss: 10.1720	Cost: 26.72s
Train Epoch: 674 [20480/90000 (23%)]	Loss: 8.8563	Cost: 8.91s
Train Epoch: 674 [40960/90000 (45%)]	Loss: 8.8097	Cost: 12.34s
Train Epoch: 674 [61440/90000 (68%)]	Loss: 8.7506	Cost: 11.96s
Train Epoch: 674 [81920/90000 (91%)]	Loss: 9.0667	Cost: 12.01s
Train Epoch: 674 	Average Loss: 8.9864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6334

Learning rate: 0.00019997758321552579
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 675 [0/90000 (0%)]	Loss: 10.4118	Cost: 33.45s
Train Epoch: 675 [20480/90000 (23%)]	Loss: 8.9955	Cost: 12.03s
Train Epoch: 675 [40960/90000 (45%)]	Loss: 8.7842	Cost: 12.05s
Train Epoch: 675 [61440/90000 (68%)]	Loss: 8.8510	Cost: 6.31s
Train Epoch: 675 [81920/90000 (91%)]	Loss: 8.9811	Cost: 6.15s
Train Epoch: 675 	Average Loss: 8.9794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7081

Learning rate: 0.00019997751665002588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 676 [0/90000 (0%)]	Loss: 10.5350	Cost: 24.34s
Train Epoch: 676 [20480/90000 (23%)]	Loss: 8.8804	Cost: 6.29s
Train Epoch: 676 [40960/90000 (45%)]	Loss: 8.8326	Cost: 6.61s
Train Epoch: 676 [61440/90000 (68%)]	Loss: 8.9930	Cost: 6.23s
Train Epoch: 676 [81920/90000 (91%)]	Loss: 8.7983	Cost: 6.63s
Train Epoch: 676 	Average Loss: 8.9531
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6554

Learning rate: 0.00019997744998585216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 677 [0/90000 (0%)]	Loss: 10.4208	Cost: 25.10s
Train Epoch: 677 [20480/90000 (23%)]	Loss: 8.9674	Cost: 6.61s
Train Epoch: 677 [40960/90000 (45%)]	Loss: 8.9830	Cost: 13.40s
Train Epoch: 677 [61440/90000 (68%)]	Loss: 8.8882	Cost: 12.01s
Train Epoch: 677 [81920/90000 (91%)]	Loss: 8.9276	Cost: 11.88s
Train Epoch: 677 	Average Loss: 8.9619
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5589

Learning rate: 0.0001999773832230046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 678 [0/90000 (0%)]	Loss: 10.3778	Cost: 27.38s
Train Epoch: 678 [20480/90000 (23%)]	Loss: 9.0416	Cost: 11.83s
Train Epoch: 678 [40960/90000 (45%)]	Loss: 8.7969	Cost: 11.93s
Train Epoch: 678 [61440/90000 (68%)]	Loss: 8.9673	Cost: 11.83s
Train Epoch: 678 [81920/90000 (91%)]	Loss: 9.1057	Cost: 8.08s
Train Epoch: 678 	Average Loss: 8.9804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6501

Learning rate: 0.00019997731636148334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 679 [0/90000 (0%)]	Loss: 10.3117	Cost: 28.33s
Train Epoch: 679 [20480/90000 (23%)]	Loss: 8.8736	Cost: 11.14s
Train Epoch: 679 [40960/90000 (45%)]	Loss: 8.7377	Cost: 8.16s
Train Epoch: 679 [61440/90000 (68%)]	Loss: 8.8183	Cost: 5.87s
Train Epoch: 679 [81920/90000 (91%)]	Loss: 8.8960	Cost: 6.74s
Train Epoch: 679 	Average Loss: 8.9239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5815

Learning rate: 0.00019997724940128839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 680 [0/90000 (0%)]	Loss: 10.4137	Cost: 24.63s
Train Epoch: 680 [20480/90000 (23%)]	Loss: 8.9672	Cost: 5.96s
Train Epoch: 680 [40960/90000 (45%)]	Loss: 8.8306	Cost: 7.55s
Train Epoch: 680 [61440/90000 (68%)]	Loss: 8.9570	Cost: 6.14s
Train Epoch: 680 [81920/90000 (91%)]	Loss: 8.9045	Cost: 6.01s
Train Epoch: 680 	Average Loss: 8.9280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6543

Learning rate: 0.0001999771823424199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 681 [0/90000 (0%)]	Loss: 10.2707	Cost: 24.31s
Train Epoch: 681 [20480/90000 (23%)]	Loss: 8.8705	Cost: 6.34s
Train Epoch: 681 [40960/90000 (45%)]	Loss: 8.6086	Cost: 6.36s
Train Epoch: 681 [61440/90000 (68%)]	Loss: 8.6818	Cost: 5.97s
Train Epoch: 681 [81920/90000 (91%)]	Loss: 8.8274	Cost: 6.02s
Train Epoch: 681 	Average Loss: 8.9077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6291

Learning rate: 0.00019997711518487783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 682 [0/90000 (0%)]	Loss: 10.3030	Cost: 22.57s
Train Epoch: 682 [20480/90000 (23%)]	Loss: 9.0383	Cost: 6.16s
Train Epoch: 682 [40960/90000 (45%)]	Loss: 8.8421	Cost: 11.75s
Train Epoch: 682 [61440/90000 (68%)]	Loss: 8.8462	Cost: 12.23s
Train Epoch: 682 [81920/90000 (91%)]	Loss: 8.9938	Cost: 11.86s
Train Epoch: 682 	Average Loss: 8.9333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6683

Learning rate: 0.00019997704792866234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 683 [0/90000 (0%)]	Loss: 10.3643	Cost: 30.76s
Train Epoch: 683 [20480/90000 (23%)]	Loss: 9.0926	Cost: 11.25s
Train Epoch: 683 [40960/90000 (45%)]	Loss: 8.7487	Cost: 12.00s
Train Epoch: 683 [61440/90000 (68%)]	Loss: 8.8468	Cost: 11.71s
Train Epoch: 683 [81920/90000 (91%)]	Loss: 8.7603	Cost: 5.91s
Train Epoch: 683 	Average Loss: 8.9014
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6159

Learning rate: 0.00019997698057377345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 684 [0/90000 (0%)]	Loss: 10.4744	Cost: 25.62s
Train Epoch: 684 [20480/90000 (23%)]	Loss: 8.9227	Cost: 6.05s
Train Epoch: 684 [40960/90000 (45%)]	Loss: 8.9034	Cost: 6.12s
Train Epoch: 684 [61440/90000 (68%)]	Loss: 8.9270	Cost: 6.83s
Train Epoch: 684 [81920/90000 (91%)]	Loss: 8.9168	Cost: 6.60s
Train Epoch: 684 	Average Loss: 8.9173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7444

Learning rate: 0.0001999769131202112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 685 [0/90000 (0%)]	Loss: 10.4954	Cost: 24.17s
Train Epoch: 685 [20480/90000 (23%)]	Loss: 8.8722	Cost: 6.14s
Train Epoch: 685 [40960/90000 (45%)]	Loss: 8.6424	Cost: 6.70s
Train Epoch: 685 [61440/90000 (68%)]	Loss: 8.8688	Cost: 5.98s
Train Epoch: 685 [81920/90000 (91%)]	Loss: 8.9168	Cost: 6.07s
Train Epoch: 685 	Average Loss: 8.9177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6817

Learning rate: 0.00019997684556797576
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 686 [0/90000 (0%)]	Loss: 10.3780	Cost: 23.14s
Train Epoch: 686 [20480/90000 (23%)]	Loss: 8.7992	Cost: 6.15s
Train Epoch: 686 [40960/90000 (45%)]	Loss: 8.8129	Cost: 8.00s
Train Epoch: 686 [61440/90000 (68%)]	Loss: 8.8203	Cost: 7.40s
Train Epoch: 686 [81920/90000 (91%)]	Loss: 9.0444	Cost: 14.67s
Train Epoch: 686 	Average Loss: 8.8922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5897

Learning rate: 0.0001999767779170671
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 687 [0/90000 (0%)]	Loss: 10.1818	Cost: 25.72s
Train Epoch: 687 [20480/90000 (23%)]	Loss: 9.0011	Cost: 10.00s
Train Epoch: 687 [40960/90000 (45%)]	Loss: 8.4653	Cost: 12.20s
Train Epoch: 687 [61440/90000 (68%)]	Loss: 8.8821	Cost: 11.80s
Train Epoch: 687 [81920/90000 (91%)]	Loss: 8.7295	Cost: 11.44s
Train Epoch: 687 	Average Loss: 8.8786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7511

Learning rate: 0.00019997671016748527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 688 [0/90000 (0%)]	Loss: 10.3336	Cost: 28.13s
Train Epoch: 688 [20480/90000 (23%)]	Loss: 8.9194	Cost: 12.11s
Train Epoch: 688 [40960/90000 (45%)]	Loss: 8.5828	Cost: 11.97s
Train Epoch: 688 [61440/90000 (68%)]	Loss: 8.7325	Cost: 11.91s
Train Epoch: 688 [81920/90000 (91%)]	Loss: 8.9087	Cost: 6.23s
Train Epoch: 688 	Average Loss: 8.8816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6309

Learning rate: 0.00019997664231923042
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 689 [0/90000 (0%)]	Loss: 10.2656	Cost: 28.96s
Train Epoch: 689 [20480/90000 (23%)]	Loss: 8.9197	Cost: 11.72s
Train Epoch: 689 [40960/90000 (45%)]	Loss: 8.5320	Cost: 6.00s
Train Epoch: 689 [61440/90000 (68%)]	Loss: 8.7653	Cost: 5.88s
Train Epoch: 689 [81920/90000 (91%)]	Loss: 8.6735	Cost: 6.88s
Train Epoch: 689 	Average Loss: 8.8754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7106

Learning rate: 0.00019997657437230258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 690 [0/90000 (0%)]	Loss: 10.2523	Cost: 24.85s
Train Epoch: 690 [20480/90000 (23%)]	Loss: 8.8551	Cost: 5.94s
Train Epoch: 690 [40960/90000 (45%)]	Loss: 8.7777	Cost: 7.21s
Train Epoch: 690 [61440/90000 (68%)]	Loss: 8.8214	Cost: 6.15s
Train Epoch: 690 [81920/90000 (91%)]	Loss: 8.9117	Cost: 6.12s
Train Epoch: 690 	Average Loss: 8.8508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7544

Learning rate: 0.00019997650632670182
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 691 [0/90000 (0%)]	Loss: 10.2112	Cost: 23.56s
Train Epoch: 691 [20480/90000 (23%)]	Loss: 8.9336	Cost: 6.29s
Train Epoch: 691 [40960/90000 (45%)]	Loss: 8.6449	Cost: 6.53s
Train Epoch: 691 [61440/90000 (68%)]	Loss: 8.7291	Cost: 6.12s
Train Epoch: 691 [81920/90000 (91%)]	Loss: 8.6919	Cost: 13.92s
Train Epoch: 691 	Average Loss: 8.8542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7771

Learning rate: 0.0001999764381824282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 692 [0/90000 (0%)]	Loss: 10.5448	Cost: 28.32s
Train Epoch: 692 [20480/90000 (23%)]	Loss: 8.7405	Cost: 12.46s
Train Epoch: 692 [40960/90000 (45%)]	Loss: 8.5391	Cost: 12.12s
Train Epoch: 692 [61440/90000 (68%)]	Loss: 8.7765	Cost: 11.87s
Train Epoch: 692 [81920/90000 (91%)]	Loss: 9.0114	Cost: 11.75s
Train Epoch: 692 	Average Loss: 8.8616
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7281

Learning rate: 0.0001999763699394818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 693 [0/90000 (0%)]	Loss: 10.4198	Cost: 27.40s
Train Epoch: 693 [20480/90000 (23%)]	Loss: 8.8922	Cost: 11.77s
Train Epoch: 693 [40960/90000 (45%)]	Loss: 8.5786	Cost: 11.16s
Train Epoch: 693 [61440/90000 (68%)]	Loss: 8.7507	Cost: 5.88s
Train Epoch: 693 [81920/90000 (91%)]	Loss: 8.7892	Cost: 6.64s
Train Epoch: 693 	Average Loss: 8.8727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7061

Learning rate: 0.0001999763015978627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 694 [0/90000 (0%)]	Loss: 10.3607	Cost: 25.42s
Train Epoch: 694 [20480/90000 (23%)]	Loss: 8.8323	Cost: 5.94s
Train Epoch: 694 [40960/90000 (45%)]	Loss: 8.7646	Cost: 7.43s
Train Epoch: 694 [61440/90000 (68%)]	Loss: 8.7703	Cost: 6.14s
Train Epoch: 694 [81920/90000 (91%)]	Loss: 8.6672	Cost: 6.07s
Train Epoch: 694 	Average Loss: 8.8261
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7202

Learning rate: 0.0001999762331575709
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 695 [0/90000 (0%)]	Loss: 10.1655	Cost: 23.34s
Train Epoch: 695 [20480/90000 (23%)]	Loss: 8.7705	Cost: 6.28s
Train Epoch: 695 [40960/90000 (45%)]	Loss: 8.8875	Cost: 6.37s
Train Epoch: 695 [61440/90000 (68%)]	Loss: 8.5862	Cost: 6.14s
Train Epoch: 695 [81920/90000 (91%)]	Loss: 8.6100	Cost: 5.78s
Train Epoch: 695 	Average Loss: 8.8394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7077

Learning rate: 0.00019997616461860652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 696 [0/90000 (0%)]	Loss: 10.2814	Cost: 22.64s
Train Epoch: 696 [20480/90000 (23%)]	Loss: 8.7666	Cost: 6.13s
Train Epoch: 696 [40960/90000 (45%)]	Loss: 8.6071	Cost: 10.68s
Train Epoch: 696 [61440/90000 (68%)]	Loss: 8.7504	Cost: 12.27s
Train Epoch: 696 [81920/90000 (91%)]	Loss: 8.8015	Cost: 11.86s
Train Epoch: 696 	Average Loss: 8.8325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6401

Learning rate: 0.00019997609598096963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 697 [0/90000 (0%)]	Loss: 10.3712	Cost: 27.47s
Train Epoch: 697 [20480/90000 (23%)]	Loss: 8.7760	Cost: 12.24s
Train Epoch: 697 [40960/90000 (45%)]	Loss: 8.8015	Cost: 11.99s
Train Epoch: 697 [61440/90000 (68%)]	Loss: 8.7634	Cost: 11.76s
Train Epoch: 697 [81920/90000 (91%)]	Loss: 8.8640	Cost: 7.63s
Train Epoch: 697 	Average Loss: 8.8367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7052

Learning rate: 0.0001999760272446603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 698 [0/90000 (0%)]	Loss: 10.3179	Cost: 26.17s
Train Epoch: 698 [20480/90000 (23%)]	Loss: 8.9552	Cost: 11.89s
Train Epoch: 698 [40960/90000 (45%)]	Loss: 8.8112	Cost: 9.91s
Train Epoch: 698 [61440/90000 (68%)]	Loss: 8.7051	Cost: 5.85s
Train Epoch: 698 [81920/90000 (91%)]	Loss: 8.8823	Cost: 6.82s
Train Epoch: 698 	Average Loss: 8.8687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6530

Learning rate: 0.00019997595840967857
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 699 [0/90000 (0%)]	Loss: 10.3237	Cost: 23.60s
Train Epoch: 699 [20480/90000 (23%)]	Loss: 8.7777	Cost: 6.29s
Train Epoch: 699 [40960/90000 (45%)]	Loss: 8.6282	Cost: 6.39s
Train Epoch: 699 [61440/90000 (68%)]	Loss: 8.7721	Cost: 6.20s
Train Epoch: 699 [81920/90000 (91%)]	Loss: 8.7509	Cost: 6.17s
Train Epoch: 699 	Average Loss: 8.8203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6763

Learning rate: 0.00019997588947602451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 700 [0/90000 (0%)]	Loss: 10.2029	Cost: 23.03s
Train Epoch: 700 [20480/90000 (23%)]	Loss: 8.8032	Cost: 6.18s
Train Epoch: 700 [40960/90000 (45%)]	Loss: 8.6498	Cost: 9.18s
Train Epoch: 700 [61440/90000 (68%)]	Loss: 8.7327	Cost: 10.58s
Train Epoch: 700 [81920/90000 (91%)]	Loss: 8.7938	Cost: 12.10s
Train Epoch: 700 	Average Loss: 8.8393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6500

Learning rate: 0.00019997582044369825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 701 [0/90000 (0%)]	Loss: 10.2656	Cost: 24.64s
Train Epoch: 701 [20480/90000 (23%)]	Loss: 8.7251	Cost: 9.22s
Train Epoch: 701 [40960/90000 (45%)]	Loss: 8.6049	Cost: 12.31s
Train Epoch: 701 [61440/90000 (68%)]	Loss: 8.7168	Cost: 11.96s
Train Epoch: 701 [81920/90000 (91%)]	Loss: 8.6815	Cost: 11.78s
Train Epoch: 701 	Average Loss: 8.7969
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7082

Learning rate: 0.00019997575131269977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 702 [0/90000 (0%)]	Loss: 10.2930	Cost: 26.80s
Train Epoch: 702 [20480/90000 (23%)]	Loss: 8.7987	Cost: 11.97s
Train Epoch: 702 [40960/90000 (45%)]	Loss: 8.6535	Cost: 12.04s
Train Epoch: 702 [61440/90000 (68%)]	Loss: 8.7432	Cost: 11.76s
Train Epoch: 702 [81920/90000 (91%)]	Loss: 8.9109	Cost: 8.08s
Train Epoch: 702 	Average Loss: 8.8290
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6947

Learning rate: 0.00019997568208302919
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 703 [0/90000 (0%)]	Loss: 10.1312	Cost: 27.13s
Train Epoch: 703 [20480/90000 (23%)]	Loss: 8.7005	Cost: 11.82s
Train Epoch: 703 [40960/90000 (45%)]	Loss: 8.5409	Cost: 8.13s
Train Epoch: 703 [61440/90000 (68%)]	Loss: 8.7500	Cost: 5.86s
Train Epoch: 703 [81920/90000 (91%)]	Loss: 8.5531	Cost: 6.71s
Train Epoch: 703 	Average Loss: 8.7844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6192

Learning rate: 0.00019997561275468656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 704 [0/90000 (0%)]	Loss: 10.2677	Cost: 25.20s
Train Epoch: 704 [20480/90000 (23%)]	Loss: 8.7908	Cost: 5.92s
Train Epoch: 704 [40960/90000 (45%)]	Loss: 8.5344	Cost: 6.69s
Train Epoch: 704 [61440/90000 (68%)]	Loss: 8.6941	Cost: 6.95s
Train Epoch: 704 [81920/90000 (91%)]	Loss: 8.7439	Cost: 6.13s
Train Epoch: 704 	Average Loss: 8.7922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6808

Learning rate: 0.00019997554332767197
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 705 [0/90000 (0%)]	Loss: 10.4141	Cost: 23.66s
Train Epoch: 705 [20480/90000 (23%)]	Loss: 8.7764	Cost: 6.07s
Train Epoch: 705 [40960/90000 (45%)]	Loss: 8.7893	Cost: 7.20s
Train Epoch: 705 [61440/90000 (68%)]	Loss: 8.8744	Cost: 6.07s
Train Epoch: 705 [81920/90000 (91%)]	Loss: 8.7672	Cost: 15.94s
Train Epoch: 705 	Average Loss: 8.7903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6794

Learning rate: 0.0001999754738019855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 706 [0/90000 (0%)]	Loss: 10.1423	Cost: 26.23s
Train Epoch: 706 [20480/90000 (23%)]	Loss: 8.9164	Cost: 8.81s
Train Epoch: 706 [40960/90000 (45%)]	Loss: 8.5950	Cost: 12.41s
Train Epoch: 706 [61440/90000 (68%)]	Loss: 8.7244	Cost: 11.88s
Train Epoch: 706 [81920/90000 (91%)]	Loss: 8.7524	Cost: 11.87s
Train Epoch: 706 	Average Loss: 8.7939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6628

Learning rate: 0.00019997540417762715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 707 [0/90000 (0%)]	Loss: 10.2735	Cost: 28.79s
Train Epoch: 707 [20480/90000 (23%)]	Loss: 8.7052	Cost: 12.21s
Train Epoch: 707 [40960/90000 (45%)]	Loss: 8.5452	Cost: 12.00s
Train Epoch: 707 [61440/90000 (68%)]	Loss: 8.7674	Cost: 11.72s
Train Epoch: 707 [81920/90000 (91%)]	Loss: 8.7519	Cost: 5.80s
Train Epoch: 707 	Average Loss: 8.7616
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7153

Learning rate: 0.00019997533445459704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 708 [0/90000 (0%)]	Loss: 10.3343	Cost: 27.10s
Train Epoch: 708 [20480/90000 (23%)]	Loss: 8.5697	Cost: 11.96s
Train Epoch: 708 [40960/90000 (45%)]	Loss: 8.6971	Cost: 6.33s
Train Epoch: 708 [61440/90000 (68%)]	Loss: 8.9015	Cost: 5.86s
Train Epoch: 708 [81920/90000 (91%)]	Loss: 8.7527	Cost: 6.82s
Train Epoch: 708 	Average Loss: 8.7360
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7417

Learning rate: 0.00019997526463289524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 709 [0/90000 (0%)]	Loss: 10.3993	Cost: 24.74s
Train Epoch: 709 [20480/90000 (23%)]	Loss: 8.8284	Cost: 6.10s
Train Epoch: 709 [40960/90000 (45%)]	Loss: 8.4842	Cost: 6.95s
Train Epoch: 709 [61440/90000 (68%)]	Loss: 8.7572	Cost: 6.16s
Train Epoch: 709 [81920/90000 (91%)]	Loss: 8.6780	Cost: 6.17s
Train Epoch: 709 	Average Loss: 8.7806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6845

Learning rate: 0.0001999751947125218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 710 [0/90000 (0%)]	Loss: 10.2208	Cost: 23.27s
Train Epoch: 710 [20480/90000 (23%)]	Loss: 8.7724	Cost: 6.11s
Train Epoch: 710 [40960/90000 (45%)]	Loss: 8.6573	Cost: 6.51s
Train Epoch: 710 [61440/90000 (68%)]	Loss: 8.5336	Cost: 6.00s
Train Epoch: 710 [81920/90000 (91%)]	Loss: 8.7664	Cost: 7.30s
Train Epoch: 710 	Average Loss: 8.7425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6957

Learning rate: 0.00019997512469347679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 711 [0/90000 (0%)]	Loss: 10.3461	Cost: 22.96s
Train Epoch: 711 [20480/90000 (23%)]	Loss: 8.6187	Cost: 6.10s
Train Epoch: 711 [40960/90000 (45%)]	Loss: 8.3549	Cost: 11.80s
Train Epoch: 711 [61440/90000 (68%)]	Loss: 8.7562	Cost: 12.06s
Train Epoch: 711 [81920/90000 (91%)]	Loss: 8.8223	Cost: 11.80s
Train Epoch: 711 	Average Loss: 8.7416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6958

Learning rate: 0.00019997505457576027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 712 [0/90000 (0%)]	Loss: 10.3941	Cost: 25.16s
Train Epoch: 712 [20480/90000 (23%)]	Loss: 8.7797	Cost: 11.85s
Train Epoch: 712 [40960/90000 (45%)]	Loss: 8.6052	Cost: 12.18s
Train Epoch: 712 [61440/90000 (68%)]	Loss: 8.7561	Cost: 11.84s
Train Epoch: 712 [81920/90000 (91%)]	Loss: 8.4978	Cost: 11.76s
Train Epoch: 712 	Average Loss: 8.7413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5595

Learning rate: 0.00019997498435937237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 713 [0/90000 (0%)]	Loss: 10.4627	Cost: 27.38s
Train Epoch: 713 [20480/90000 (23%)]	Loss: 8.8297	Cost: 11.85s
Train Epoch: 713 [40960/90000 (45%)]	Loss: 8.4921	Cost: 11.96s
Train Epoch: 713 [61440/90000 (68%)]	Loss: 8.6959	Cost: 11.82s
Train Epoch: 713 [81920/90000 (91%)]	Loss: 8.5698	Cost: 6.85s
Train Epoch: 713 	Average Loss: 8.7610
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7828

Learning rate: 0.00019997491404431306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 714 [0/90000 (0%)]	Loss: 10.3408	Cost: 26.68s
Train Epoch: 714 [20480/90000 (23%)]	Loss: 8.6345	Cost: 11.45s
Train Epoch: 714 [40960/90000 (45%)]	Loss: 8.6111	Cost: 8.15s
Train Epoch: 714 [61440/90000 (68%)]	Loss: 8.6629	Cost: 5.84s
Train Epoch: 714 [81920/90000 (91%)]	Loss: 8.4494	Cost: 6.72s
Train Epoch: 714 	Average Loss: 8.7308
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7500

Learning rate: 0.00019997484363058253
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 715 [0/90000 (0%)]	Loss: 10.2259	Cost: 25.20s
Train Epoch: 715 [20480/90000 (23%)]	Loss: 8.7739	Cost: 6.08s
Train Epoch: 715 [40960/90000 (45%)]	Loss: 8.6579	Cost: 8.02s
Train Epoch: 715 [61440/90000 (68%)]	Loss: 8.5161	Cost: 6.15s
Train Epoch: 715 [81920/90000 (91%)]	Loss: 8.6119	Cost: 6.09s
Train Epoch: 715 	Average Loss: 8.6896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7877

Learning rate: 0.00019997477311818073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 716 [0/90000 (0%)]	Loss: 10.4790	Cost: 23.57s
Train Epoch: 716 [20480/90000 (23%)]	Loss: 8.6748	Cost: 6.20s
Train Epoch: 716 [40960/90000 (45%)]	Loss: 8.6940	Cost: 6.48s
Train Epoch: 716 [61440/90000 (68%)]	Loss: 8.7230	Cost: 6.20s
Train Epoch: 716 [81920/90000 (91%)]	Loss: 8.7985	Cost: 5.86s
Train Epoch: 716 	Average Loss: 8.8102
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6834

Learning rate: 0.0001999747025071078
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 717 [0/90000 (0%)]	Loss: 10.1878	Cost: 22.38s
Train Epoch: 717 [20480/90000 (23%)]	Loss: 8.7383	Cost: 6.07s
Train Epoch: 717 [40960/90000 (45%)]	Loss: 8.5631	Cost: 8.19s
Train Epoch: 717 [61440/90000 (68%)]	Loss: 8.6538	Cost: 8.73s
Train Epoch: 717 [81920/90000 (91%)]	Loss: 8.6664	Cost: 14.02s
Train Epoch: 717 	Average Loss: 8.7521
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7352

Learning rate: 0.0001999746317973638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 718 [0/90000 (0%)]	Loss: 10.2250	Cost: 25.29s
Train Epoch: 718 [20480/90000 (23%)]	Loss: 8.6591	Cost: 10.58s
Train Epoch: 718 [40960/90000 (45%)]	Loss: 8.5521	Cost: 12.19s
Train Epoch: 718 [61440/90000 (68%)]	Loss: 8.6458	Cost: 11.85s
Train Epoch: 718 [81920/90000 (91%)]	Loss: 8.4929	Cost: 11.51s
Train Epoch: 718 	Average Loss: 8.6791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7391

Learning rate: 0.00019997456098894882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 719 [0/90000 (0%)]	Loss: 10.4134	Cost: 27.61s
Train Epoch: 719 [20480/90000 (23%)]	Loss: 8.5644	Cost: 12.20s
Train Epoch: 719 [40960/90000 (45%)]	Loss: 8.5690	Cost: 11.99s
Train Epoch: 719 [61440/90000 (68%)]	Loss: 8.7206	Cost: 9.85s
Train Epoch: 719 [81920/90000 (91%)]	Loss: 8.5723	Cost: 5.89s
Train Epoch: 719 	Average Loss: 8.7205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7443

Learning rate: 0.00019997449008186285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 720 [0/90000 (0%)]	Loss: 10.3868	Cost: 26.81s
Train Epoch: 720 [20480/90000 (23%)]	Loss: 8.6545	Cost: 11.54s
Train Epoch: 720 [40960/90000 (45%)]	Loss: 8.5242	Cost: 7.04s
Train Epoch: 720 [61440/90000 (68%)]	Loss: 8.7207	Cost: 5.88s
Train Epoch: 720 [81920/90000 (91%)]	Loss: 8.6237	Cost: 6.68s
Train Epoch: 720 	Average Loss: 8.7150
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7718

Learning rate: 0.00019997441907610605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 721 [0/90000 (0%)]	Loss: 10.2822	Cost: 23.54s
Train Epoch: 721 [20480/90000 (23%)]	Loss: 8.3642	Cost: 6.46s
Train Epoch: 721 [40960/90000 (45%)]	Loss: 8.5688	Cost: 6.30s
Train Epoch: 721 [61440/90000 (68%)]	Loss: 8.7451	Cost: 6.14s
Train Epoch: 721 [81920/90000 (91%)]	Loss: 8.6215	Cost: 6.08s
Train Epoch: 721 	Average Loss: 8.6946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6923

Learning rate: 0.00019997434797167847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 722 [0/90000 (0%)]	Loss: 10.3865	Cost: 22.61s
Train Epoch: 722 [20480/90000 (23%)]	Loss: 8.5925	Cost: 6.25s
Train Epoch: 722 [40960/90000 (45%)]	Loss: 8.5589	Cost: 8.12s
Train Epoch: 722 [61440/90000 (68%)]	Loss: 8.5429	Cost: 8.72s
Train Epoch: 722 [81920/90000 (91%)]	Loss: 8.7083	Cost: 13.30s
Train Epoch: 722 	Average Loss: 8.6564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7643

Learning rate: 0.00019997427676858012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 723 [0/90000 (0%)]	Loss: 10.2575	Cost: 24.85s
Train Epoch: 723 [20480/90000 (23%)]	Loss: 8.7017	Cost: 10.61s
Train Epoch: 723 [40960/90000 (45%)]	Loss: 8.6130	Cost: 12.19s
Train Epoch: 723 [61440/90000 (68%)]	Loss: 8.6734	Cost: 11.90s
Train Epoch: 723 [81920/90000 (91%)]	Loss: 8.7183	Cost: 11.79s
Train Epoch: 723 	Average Loss: 8.6704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8205

Learning rate: 0.00019997420546681116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 724 [0/90000 (0%)]	Loss: 10.3749	Cost: 26.67s
Train Epoch: 724 [20480/90000 (23%)]	Loss: 8.5635	Cost: 12.31s
Train Epoch: 724 [40960/90000 (45%)]	Loss: 8.5616	Cost: 12.01s
Train Epoch: 724 [61440/90000 (68%)]	Loss: 8.6420	Cost: 11.78s
Train Epoch: 724 [81920/90000 (91%)]	Loss: 8.6942	Cost: 6.87s
Train Epoch: 724 	Average Loss: 8.6556
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7478

Learning rate: 0.0001999741340663716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 725 [0/90000 (0%)]	Loss: 10.4440	Cost: 27.44s
Train Epoch: 725 [20480/90000 (23%)]	Loss: 8.7410	Cost: 12.10s
Train Epoch: 725 [40960/90000 (45%)]	Loss: 8.3680	Cost: 6.96s
Train Epoch: 725 [61440/90000 (68%)]	Loss: 8.6218	Cost: 5.91s
Train Epoch: 725 [81920/90000 (91%)]	Loss: 8.6931	Cost: 6.78s
Train Epoch: 725 	Average Loss: 8.6576
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7912

Learning rate: 0.0001999740625672615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 726 [0/90000 (0%)]	Loss: 10.3205	Cost: 24.75s
Train Epoch: 726 [20480/90000 (23%)]	Loss: 8.5752	Cost: 5.93s
Train Epoch: 726 [40960/90000 (45%)]	Loss: 8.4471	Cost: 6.78s
Train Epoch: 726 [61440/90000 (68%)]	Loss: 8.5255	Cost: 6.18s
Train Epoch: 726 [81920/90000 (91%)]	Loss: 8.6623	Cost: 6.18s
Train Epoch: 726 	Average Loss: 8.6715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7669

Learning rate: 0.00019997399096948094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 727 [0/90000 (0%)]	Loss: 10.3561	Cost: 23.56s
Train Epoch: 727 [20480/90000 (23%)]	Loss: 8.5544	Cost: 6.51s
Train Epoch: 727 [40960/90000 (45%)]	Loss: 8.4770	Cost: 6.27s
Train Epoch: 727 [61440/90000 (68%)]	Loss: 8.4457	Cost: 6.11s
Train Epoch: 727 [81920/90000 (91%)]	Loss: 8.4969	Cost: 8.66s
Train Epoch: 727 	Average Loss: 8.6529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7041

Learning rate: 0.00019997391927303003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 728 [0/90000 (0%)]	Loss: 10.4340	Cost: 22.99s
Train Epoch: 728 [20480/90000 (23%)]	Loss: 8.5744	Cost: 6.07s
Train Epoch: 728 [40960/90000 (45%)]	Loss: 8.5061	Cost: 13.28s
Train Epoch: 728 [61440/90000 (68%)]	Loss: 8.5680	Cost: 12.11s
Train Epoch: 728 [81920/90000 (91%)]	Loss: 8.5785	Cost: 11.90s
Train Epoch: 728 	Average Loss: 8.6491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8056

Learning rate: 0.00019997384747790883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 729 [0/90000 (0%)]	Loss: 10.5522	Cost: 26.85s
Train Epoch: 729 [20480/90000 (23%)]	Loss: 8.7241	Cost: 12.24s
Train Epoch: 729 [40960/90000 (45%)]	Loss: 8.5483	Cost: 12.10s
Train Epoch: 729 [61440/90000 (68%)]	Loss: 8.4762	Cost: 11.76s
Train Epoch: 729 [81920/90000 (91%)]	Loss: 8.6765	Cost: 8.22s
Train Epoch: 729 	Average Loss: 8.6636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7629

Learning rate: 0.00019997377558411737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 730 [0/90000 (0%)]	Loss: 10.5095	Cost: 29.02s
Train Epoch: 730 [20480/90000 (23%)]	Loss: 8.5765	Cost: 11.64s
Train Epoch: 730 [40960/90000 (45%)]	Loss: 8.6149	Cost: 7.53s
Train Epoch: 730 [61440/90000 (68%)]	Loss: 8.6437	Cost: 5.86s
Train Epoch: 730 [81920/90000 (91%)]	Loss: 8.4718	Cost: 6.65s
Train Epoch: 730 	Average Loss: 8.6673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8109

Learning rate: 0.00019997370359165574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 731 [0/90000 (0%)]	Loss: 10.7256	Cost: 24.62s
Train Epoch: 731 [20480/90000 (23%)]	Loss: 8.6191	Cost: 5.92s
Train Epoch: 731 [40960/90000 (45%)]	Loss: 8.5673	Cost: 7.96s
Train Epoch: 731 [61440/90000 (68%)]	Loss: 8.6270	Cost: 6.17s
Train Epoch: 731 [81920/90000 (91%)]	Loss: 8.5707	Cost: 6.15s
Train Epoch: 731 	Average Loss: 8.6602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7603

Learning rate: 0.00019997363150052406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 732 [0/90000 (0%)]	Loss: 10.3094	Cost: 22.76s
Train Epoch: 732 [20480/90000 (23%)]	Loss: 8.6817	Cost: 6.19s
Train Epoch: 732 [40960/90000 (45%)]	Loss: 8.3861	Cost: 6.40s
Train Epoch: 732 [61440/90000 (68%)]	Loss: 8.4674	Cost: 6.08s
Train Epoch: 732 [81920/90000 (91%)]	Loss: 8.5682	Cost: 9.23s
Train Epoch: 732 	Average Loss: 8.6309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8092

Learning rate: 0.00019997355931072235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 733 [0/90000 (0%)]	Loss: 10.6451	Cost: 23.08s
Train Epoch: 733 [20480/90000 (23%)]	Loss: 8.6962	Cost: 6.26s
Train Epoch: 733 [40960/90000 (45%)]	Loss: 8.5350	Cost: 12.50s
Train Epoch: 733 [61440/90000 (68%)]	Loss: 8.5488	Cost: 12.14s
Train Epoch: 733 [81920/90000 (91%)]	Loss: 8.4853	Cost: 11.86s
Train Epoch: 733 	Average Loss: 8.6201
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7522

Learning rate: 0.0001999734870222507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 734 [0/90000 (0%)]	Loss: 10.6667	Cost: 26.57s
Train Epoch: 734 [20480/90000 (23%)]	Loss: 8.5608	Cost: 11.95s
Train Epoch: 734 [40960/90000 (45%)]	Loss: 8.4396	Cost: 12.05s
Train Epoch: 734 [61440/90000 (68%)]	Loss: 8.5553	Cost: 12.06s
Train Epoch: 734 [81920/90000 (91%)]	Loss: 8.3365	Cost: 8.59s
Train Epoch: 734 	Average Loss: 8.6369
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7766

Learning rate: 0.00019997341463510914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 735 [0/90000 (0%)]	Loss: 10.4845	Cost: 27.30s
Train Epoch: 735 [20480/90000 (23%)]	Loss: 8.6966	Cost: 10.17s
Train Epoch: 735 [40960/90000 (45%)]	Loss: 8.6697	Cost: 8.78s
Train Epoch: 735 [61440/90000 (68%)]	Loss: 8.4537	Cost: 5.86s
Train Epoch: 735 [81920/90000 (91%)]	Loss: 8.7401	Cost: 6.88s
Train Epoch: 735 	Average Loss: 8.6653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7850

Learning rate: 0.00019997334214929782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 736 [0/90000 (0%)]	Loss: 10.6584	Cost: 24.54s
Train Epoch: 736 [20480/90000 (23%)]	Loss: 8.5683	Cost: 6.14s
Train Epoch: 736 [40960/90000 (45%)]	Loss: 8.4016	Cost: 6.94s
Train Epoch: 736 [61440/90000 (68%)]	Loss: 8.6837	Cost: 6.16s
Train Epoch: 736 [81920/90000 (91%)]	Loss: 8.4184	Cost: 6.10s
Train Epoch: 736 	Average Loss: 8.5877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8285

Learning rate: 0.00019997326956481675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 737 [0/90000 (0%)]	Loss: 10.5647	Cost: 23.79s
Train Epoch: 737 [20480/90000 (23%)]	Loss: 8.8973	Cost: 6.30s
Train Epoch: 737 [40960/90000 (45%)]	Loss: 8.6338	Cost: 6.48s
Train Epoch: 737 [61440/90000 (68%)]	Loss: 8.7033	Cost: 5.96s
Train Epoch: 737 [81920/90000 (91%)]	Loss: 8.6469	Cost: 8.61s
Train Epoch: 737 	Average Loss: 8.7712
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6295

Learning rate: 0.000199973196881666
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 738 [0/90000 (0%)]	Loss: 10.2256	Cost: 22.87s
Train Epoch: 738 [20480/90000 (23%)]	Loss: 8.8799	Cost: 6.11s
Train Epoch: 738 [40960/90000 (45%)]	Loss: 8.3726	Cost: 12.85s
Train Epoch: 738 [61440/90000 (68%)]	Loss: 8.5853	Cost: 12.07s
Train Epoch: 738 [81920/90000 (91%)]	Loss: 8.6731	Cost: 11.88s
Train Epoch: 738 	Average Loss: 8.6829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7741

Learning rate: 0.00019997312409984565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 739 [0/90000 (0%)]	Loss: 10.4547	Cost: 28.64s
Train Epoch: 739 [20480/90000 (23%)]	Loss: 8.6877	Cost: 12.34s
Train Epoch: 739 [40960/90000 (45%)]	Loss: 8.4284	Cost: 12.06s
Train Epoch: 739 [61440/90000 (68%)]	Loss: 8.5176	Cost: 11.94s
Train Epoch: 739 [81920/90000 (91%)]	Loss: 8.6380	Cost: 7.59s
Train Epoch: 739 	Average Loss: 8.6412
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7871

Learning rate: 0.00019997305121935581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 740 [0/90000 (0%)]	Loss: 10.1589	Cost: 28.78s
Train Epoch: 740 [20480/90000 (23%)]	Loss: 8.6120	Cost: 10.32s
Train Epoch: 740 [40960/90000 (45%)]	Loss: 8.3451	Cost: 8.25s
Train Epoch: 740 [61440/90000 (68%)]	Loss: 8.5479	Cost: 5.83s
Train Epoch: 740 [81920/90000 (91%)]	Loss: 8.5961	Cost: 6.75s
Train Epoch: 740 	Average Loss: 8.6226
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7118

Learning rate: 0.00019997297824019653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 741 [0/90000 (0%)]	Loss: 10.4053	Cost: 24.57s
Train Epoch: 741 [20480/90000 (23%)]	Loss: 8.5381	Cost: 6.94s
Train Epoch: 741 [40960/90000 (45%)]	Loss: 8.6540	Cost: 6.23s
Train Epoch: 741 [61440/90000 (68%)]	Loss: 8.5807	Cost: 6.06s
Train Epoch: 741 [81920/90000 (91%)]	Loss: 8.6268	Cost: 6.16s
Train Epoch: 741 	Average Loss: 8.6770
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7319

Learning rate: 0.00019997290516236789
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 742 [0/90000 (0%)]	Loss: 10.4810	Cost: 22.71s
Train Epoch: 742 [20480/90000 (23%)]	Loss: 8.3881	Cost: 6.56s
Train Epoch: 742 [40960/90000 (45%)]	Loss: 8.1879	Cost: 6.17s
Train Epoch: 742 [61440/90000 (68%)]	Loss: 8.4296	Cost: 6.04s
Train Epoch: 742 [81920/90000 (91%)]	Loss: 8.7154	Cost: 15.79s
Train Epoch: 742 	Average Loss: 8.5765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7296

Learning rate: 0.0001999728319858699
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 743 [0/90000 (0%)]	Loss: 10.3032	Cost: 22.38s
Train Epoch: 743 [20480/90000 (23%)]	Loss: 8.6744	Cost: 6.04s
Train Epoch: 743 [40960/90000 (45%)]	Loss: 8.3571	Cost: 12.45s
Train Epoch: 743 [61440/90000 (68%)]	Loss: 8.3028	Cost: 12.07s
Train Epoch: 743 [81920/90000 (91%)]	Loss: 8.5121	Cost: 11.77s
Train Epoch: 743 	Average Loss: 8.5808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8268

Learning rate: 0.00019997275871070266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 744 [0/90000 (0%)]	Loss: 10.2913	Cost: 26.76s
Train Epoch: 744 [20480/90000 (23%)]	Loss: 8.4115	Cost: 12.05s
Train Epoch: 744 [40960/90000 (45%)]	Loss: 8.3187	Cost: 11.92s
Train Epoch: 744 [61440/90000 (68%)]	Loss: 8.4204	Cost: 11.93s
Train Epoch: 744 [81920/90000 (91%)]	Loss: 8.4636	Cost: 9.26s
Train Epoch: 744 	Average Loss: 8.5757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7904

Learning rate: 0.00019997268533686628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 745 [0/90000 (0%)]	Loss: 10.4630	Cost: 27.47s
Train Epoch: 745 [20480/90000 (23%)]	Loss: 8.5907	Cost: 11.85s
Train Epoch: 745 [40960/90000 (45%)]	Loss: 8.3548	Cost: 11.67s
Train Epoch: 745 [61440/90000 (68%)]	Loss: 8.4686	Cost: 5.94s
Train Epoch: 745 [81920/90000 (91%)]	Loss: 8.5825	Cost: 6.41s
Train Epoch: 745 	Average Loss: 8.5623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8064

Learning rate: 0.00019997261186436086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 746 [0/90000 (0%)]	Loss: 10.6424	Cost: 26.96s
Train Epoch: 746 [20480/90000 (23%)]	Loss: 8.5570	Cost: 11.63s
Train Epoch: 746 [40960/90000 (45%)]	Loss: 8.4355	Cost: 7.00s
Train Epoch: 746 [61440/90000 (68%)]	Loss: 8.4626	Cost: 5.86s
Train Epoch: 746 [81920/90000 (91%)]	Loss: 8.5750	Cost: 6.64s
Train Epoch: 746 	Average Loss: 8.5846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8019

Learning rate: 0.0001999725382931864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 747 [0/90000 (0%)]	Loss: 10.3448	Cost: 23.92s
Train Epoch: 747 [20480/90000 (23%)]	Loss: 8.4119	Cost: 6.67s
Train Epoch: 747 [40960/90000 (45%)]	Loss: 8.4190	Cost: 6.51s
Train Epoch: 747 [61440/90000 (68%)]	Loss: 8.4241	Cost: 6.19s
Train Epoch: 747 [81920/90000 (91%)]	Loss: 8.4584	Cost: 6.14s
Train Epoch: 747 	Average Loss: 8.5562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6957

Learning rate: 0.000199972464623343
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 748 [0/90000 (0%)]	Loss: 10.4554	Cost: 23.22s
Train Epoch: 748 [20480/90000 (23%)]	Loss: 8.3699	Cost: 6.53s
Train Epoch: 748 [40960/90000 (45%)]	Loss: 8.4068	Cost: 6.24s
Train Epoch: 748 [61440/90000 (68%)]	Loss: 8.5785	Cost: 6.05s
Train Epoch: 748 [81920/90000 (91%)]	Loss: 8.3966	Cost: 12.88s
Train Epoch: 748 	Average Loss: 8.5275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7535

Learning rate: 0.00019997239085483074
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 749 [0/90000 (0%)]	Loss: 10.3392	Cost: 24.48s
Train Epoch: 749 [20480/90000 (23%)]	Loss: 8.4150	Cost: 6.34s
Train Epoch: 749 [40960/90000 (45%)]	Loss: 8.4243	Cost: 12.14s
Train Epoch: 749 [61440/90000 (68%)]	Loss: 8.3299	Cost: 11.96s
Train Epoch: 749 [81920/90000 (91%)]	Loss: 8.4577	Cost: 11.61s
Train Epoch: 749 	Average Loss: 8.5304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7873

Learning rate: 0.0001999723169876497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 750 [0/90000 (0%)]	Loss: 10.5318	Cost: 27.49s
Train Epoch: 750 [20480/90000 (23%)]	Loss: 8.5488	Cost: 11.99s
Train Epoch: 750 [40960/90000 (45%)]	Loss: 8.3449	Cost: 12.03s
Train Epoch: 750 [61440/90000 (68%)]	Loss: 8.3784	Cost: 11.80s
Train Epoch: 750 [81920/90000 (91%)]	Loss: 8.3935	Cost: 9.92s
Train Epoch: 750 	Average Loss: 8.4938
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7138

Learning rate: 0.0001999722430217999
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 751 [0/90000 (0%)]	Loss: 10.4268	Cost: 26.87s
Train Epoch: 751 [20480/90000 (23%)]	Loss: 8.3712	Cost: 11.81s
Train Epoch: 751 [40960/90000 (45%)]	Loss: 8.2608	Cost: 10.56s
Train Epoch: 751 [61440/90000 (68%)]	Loss: 8.2828	Cost: 5.85s
Train Epoch: 751 [81920/90000 (91%)]	Loss: 8.3725	Cost: 6.59s
Train Epoch: 751 	Average Loss: 8.4858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7632

Learning rate: 0.00019997216895728146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 752 [0/90000 (0%)]	Loss: 10.3088	Cost: 27.03s
Train Epoch: 752 [20480/90000 (23%)]	Loss: 8.4854	Cost: 7.97s
Train Epoch: 752 [40960/90000 (45%)]	Loss: 8.4521	Cost: 5.97s
Train Epoch: 752 [61440/90000 (68%)]	Loss: 8.5464	Cost: 6.88s
Train Epoch: 752 [81920/90000 (91%)]	Loss: 8.3907	Cost: 5.88s
Train Epoch: 752 	Average Loss: 8.5138
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7839

Learning rate: 0.00019997209479409445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 753 [0/90000 (0%)]	Loss: 10.5250	Cost: 23.43s
Train Epoch: 753 [20480/90000 (23%)]	Loss: 8.4398	Cost: 6.90s
Train Epoch: 753 [40960/90000 (45%)]	Loss: 8.2982	Cost: 6.37s
Train Epoch: 753 [61440/90000 (68%)]	Loss: 8.4098	Cost: 6.17s
Train Epoch: 753 [81920/90000 (91%)]	Loss: 8.3820	Cost: 6.19s
Train Epoch: 753 	Average Loss: 8.5161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7410

Learning rate: 0.00019997202053223894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 754 [0/90000 (0%)]	Loss: 10.2995	Cost: 23.56s
Train Epoch: 754 [20480/90000 (23%)]	Loss: 8.3542	Cost: 6.41s
Train Epoch: 754 [40960/90000 (45%)]	Loss: 8.2892	Cost: 6.32s
Train Epoch: 754 [61440/90000 (68%)]	Loss: 8.4166	Cost: 6.07s
Train Epoch: 754 [81920/90000 (91%)]	Loss: 8.3347	Cost: 15.85s
Train Epoch: 754 	Average Loss: 8.4695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7684

Learning rate: 0.00019997194617171497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 755 [0/90000 (0%)]	Loss: 10.2110	Cost: 22.72s
Train Epoch: 755 [20480/90000 (23%)]	Loss: 8.3086	Cost: 6.09s
Train Epoch: 755 [40960/90000 (45%)]	Loss: 8.3419	Cost: 12.04s
Train Epoch: 755 [61440/90000 (68%)]	Loss: 8.4708	Cost: 12.12s
Train Epoch: 755 [81920/90000 (91%)]	Loss: 8.4366	Cost: 11.87s
Train Epoch: 755 	Average Loss: 8.4792
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7596

Learning rate: 0.00019997187171252268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 756 [0/90000 (0%)]	Loss: 10.7918	Cost: 25.62s
Train Epoch: 756 [20480/90000 (23%)]	Loss: 8.4420	Cost: 12.25s
Train Epoch: 756 [40960/90000 (45%)]	Loss: 8.4057	Cost: 12.15s
Train Epoch: 756 [61440/90000 (68%)]	Loss: 8.4585	Cost: 11.78s
Train Epoch: 756 [81920/90000 (91%)]	Loss: 8.3189	Cost: 11.86s
Train Epoch: 756 	Average Loss: 8.5273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8257

Learning rate: 0.0001999717971546621
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 757 [0/90000 (0%)]	Loss: 10.5527	Cost: 26.94s
Train Epoch: 757 [20480/90000 (23%)]	Loss: 8.4282	Cost: 11.82s
Train Epoch: 757 [40960/90000 (45%)]	Loss: 8.6118	Cost: 12.06s
Train Epoch: 757 [61440/90000 (68%)]	Loss: 8.5055	Cost: 11.89s
Train Epoch: 757 [81920/90000 (91%)]	Loss: 8.5784	Cost: 6.80s
Train Epoch: 757 	Average Loss: 8.5703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8341

Learning rate: 0.00019997172249813333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 758 [0/90000 (0%)]	Loss: 10.4519	Cost: 27.51s
Train Epoch: 758 [20480/90000 (23%)]	Loss: 8.4029	Cost: 9.41s
Train Epoch: 758 [40960/90000 (45%)]	Loss: 8.2340	Cost: 9.85s
Train Epoch: 758 [61440/90000 (68%)]	Loss: 8.5241	Cost: 5.88s
Train Epoch: 758 [81920/90000 (91%)]	Loss: 8.4657	Cost: 6.82s
Train Epoch: 758 	Average Loss: 8.5235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7629

Learning rate: 0.0001999716477429364
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 759 [0/90000 (0%)]	Loss: 10.4028	Cost: 22.71s
Train Epoch: 759 [20480/90000 (23%)]	Loss: 8.5350	Cost: 6.18s
Train Epoch: 759 [40960/90000 (45%)]	Loss: 8.4339	Cost: 6.42s
Train Epoch: 759 [61440/90000 (68%)]	Loss: 8.5548	Cost: 6.14s
Train Epoch: 759 [81920/90000 (91%)]	Loss: 8.5329	Cost: 7.25s
Train Epoch: 759 	Average Loss: 8.4821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7998

Learning rate: 0.00019997157288907143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 760 [0/90000 (0%)]	Loss: 10.5374	Cost: 24.82s
Train Epoch: 760 [20480/90000 (23%)]	Loss: 8.3980	Cost: 9.92s
Train Epoch: 760 [40960/90000 (45%)]	Loss: 8.4751	Cost: 12.15s
Train Epoch: 760 [61440/90000 (68%)]	Loss: 8.2879	Cost: 11.73s
Train Epoch: 760 [81920/90000 (91%)]	Loss: 8.3614	Cost: 12.04s
Train Epoch: 760 	Average Loss: 8.4687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7956

Learning rate: 0.00019997149793653845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 761 [0/90000 (0%)]	Loss: 10.4949	Cost: 24.15s
Train Epoch: 761 [20480/90000 (23%)]	Loss: 8.5138	Cost: 11.27s
Train Epoch: 761 [40960/90000 (45%)]	Loss: 8.2105	Cost: 12.24s
Train Epoch: 761 [61440/90000 (68%)]	Loss: 8.2260	Cost: 11.92s
Train Epoch: 761 [81920/90000 (91%)]	Loss: 8.4111	Cost: 11.90s
Train Epoch: 761 	Average Loss: 8.4672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8400

Learning rate: 0.00019997142288533755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 762 [0/90000 (0%)]	Loss: 10.2903	Cost: 24.84s
Train Epoch: 762 [20480/90000 (23%)]	Loss: 8.3592	Cost: 12.25s
Train Epoch: 762 [40960/90000 (45%)]	Loss: 8.3703	Cost: 12.09s
Train Epoch: 762 [61440/90000 (68%)]	Loss: 8.3398	Cost: 11.77s
Train Epoch: 762 [81920/90000 (91%)]	Loss: 8.2804	Cost: 10.73s
Train Epoch: 762 	Average Loss: 8.4352
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8614

Learning rate: 0.00019997134773546882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 763 [0/90000 (0%)]	Loss: 10.6222	Cost: 27.29s
Train Epoch: 763 [20480/90000 (23%)]	Loss: 8.2906	Cost: 12.09s
Train Epoch: 763 [40960/90000 (45%)]	Loss: 8.3315	Cost: 10.53s
Train Epoch: 763 [61440/90000 (68%)]	Loss: 8.4140	Cost: 5.85s
Train Epoch: 763 [81920/90000 (91%)]	Loss: 8.3060	Cost: 6.98s
Train Epoch: 763 	Average Loss: 8.4204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8420

Learning rate: 0.00019997127248693236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 764 [0/90000 (0%)]	Loss: 10.4109	Cost: 26.56s
Train Epoch: 764 [20480/90000 (23%)]	Loss: 8.4049	Cost: 6.27s
Train Epoch: 764 [40960/90000 (45%)]	Loss: 8.1342	Cost: 6.02s
Train Epoch: 764 [61440/90000 (68%)]	Loss: 8.3068	Cost: 6.85s
Train Epoch: 764 [81920/90000 (91%)]	Loss: 8.2289	Cost: 6.07s
Train Epoch: 764 	Average Loss: 8.4203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8283

Learning rate: 0.00019997119713972814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 765 [0/90000 (0%)]	Loss: 10.4680	Cost: 22.98s
Train Epoch: 765 [20480/90000 (23%)]	Loss: 8.4226	Cost: 6.29s
Train Epoch: 765 [40960/90000 (45%)]	Loss: 8.1888	Cost: 6.38s
Train Epoch: 765 [61440/90000 (68%)]	Loss: 8.2462	Cost: 6.06s
Train Epoch: 765 [81920/90000 (91%)]	Loss: 8.2347	Cost: 6.04s
Train Epoch: 765 	Average Loss: 8.4045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7994

Learning rate: 0.00019997112169385637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 766 [0/90000 (0%)]	Loss: 10.3261	Cost: 24.42s
Train Epoch: 766 [20480/90000 (23%)]	Loss: 8.3667	Cost: 6.09s
Train Epoch: 766 [40960/90000 (45%)]	Loss: 8.3222	Cost: 12.39s
Train Epoch: 766 [61440/90000 (68%)]	Loss: 8.2430	Cost: 12.22s
Train Epoch: 766 [81920/90000 (91%)]	Loss: 8.2389	Cost: 11.41s
Train Epoch: 766 	Average Loss: 8.4157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9061

Learning rate: 0.00019997104614931702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 767 [0/90000 (0%)]	Loss: 10.3011	Cost: 25.87s
Train Epoch: 767 [20480/90000 (23%)]	Loss: 8.1745	Cost: 12.19s
Train Epoch: 767 [40960/90000 (45%)]	Loss: 8.3500	Cost: 12.00s
Train Epoch: 767 [61440/90000 (68%)]	Loss: 8.3710	Cost: 11.99s
Train Epoch: 767 [81920/90000 (91%)]	Loss: 8.3660	Cost: 10.34s
Train Epoch: 767 	Average Loss: 8.3959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7946

Learning rate: 0.0001999709705061102
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 768 [0/90000 (0%)]	Loss: 10.4834	Cost: 27.98s
Train Epoch: 768 [20480/90000 (23%)]	Loss: 8.2990	Cost: 12.17s
Train Epoch: 768 [40960/90000 (45%)]	Loss: 8.2808	Cost: 11.21s
Train Epoch: 768 [61440/90000 (68%)]	Loss: 8.3332	Cost: 5.95s
Train Epoch: 768 [81920/90000 (91%)]	Loss: 8.5395	Cost: 6.60s
Train Epoch: 768 	Average Loss: 8.4498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8139

Learning rate: 0.00019997089476423598
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 769 [0/90000 (0%)]	Loss: 10.4589	Cost: 27.14s
Train Epoch: 769 [20480/90000 (23%)]	Loss: 8.2678	Cost: 8.87s
Train Epoch: 769 [40960/90000 (45%)]	Loss: 8.2069	Cost: 6.13s
Train Epoch: 769 [61440/90000 (68%)]	Loss: 8.2082	Cost: 6.62s
Train Epoch: 769 [81920/90000 (91%)]	Loss: 8.4133	Cost: 6.09s
Train Epoch: 769 	Average Loss: 8.3873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8168

Learning rate: 0.00019997081892369448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 770 [0/90000 (0%)]	Loss: 10.5694	Cost: 24.16s
Train Epoch: 770 [20480/90000 (23%)]	Loss: 8.1993	Cost: 5.96s
Train Epoch: 770 [40960/90000 (45%)]	Loss: 8.0508	Cost: 7.19s
Train Epoch: 770 [61440/90000 (68%)]	Loss: 8.3212	Cost: 6.14s
Train Epoch: 770 [81920/90000 (91%)]	Loss: 8.2157	Cost: 6.11s
Train Epoch: 770 	Average Loss: 8.3641
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8118

Learning rate: 0.0001999707429844857
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 771 [0/90000 (0%)]	Loss: 10.2330	Cost: 22.44s
Train Epoch: 771 [20480/90000 (23%)]	Loss: 8.3743	Cost: 6.28s
Train Epoch: 771 [40960/90000 (45%)]	Loss: 8.2422	Cost: 6.16s
Train Epoch: 771 [61440/90000 (68%)]	Loss: 8.1489	Cost: 6.14s
Train Epoch: 771 [81920/90000 (91%)]	Loss: 8.2357	Cost: 11.88s
Train Epoch: 771 	Average Loss: 8.3533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8188

Learning rate: 0.00019997066694660978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 772 [0/90000 (0%)]	Loss: 10.3882	Cost: 24.44s
Train Epoch: 772 [20480/90000 (23%)]	Loss: 8.2376	Cost: 6.07s
Train Epoch: 772 [40960/90000 (45%)]	Loss: 8.2207	Cost: 12.89s
Train Epoch: 772 [61440/90000 (68%)]	Loss: 8.4549	Cost: 12.00s
Train Epoch: 772 [81920/90000 (91%)]	Loss: 8.2727	Cost: 11.86s
Train Epoch: 772 	Average Loss: 8.3517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8280

Learning rate: 0.00019997059081006675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 773 [0/90000 (0%)]	Loss: 10.4028	Cost: 28.14s
Train Epoch: 773 [20480/90000 (23%)]	Loss: 8.1712	Cost: 11.87s
Train Epoch: 773 [40960/90000 (45%)]	Loss: 8.2070	Cost: 8.76s
Train Epoch: 773 [61440/90000 (68%)]	Loss: 8.1009	Cost: 5.87s
Train Epoch: 773 [81920/90000 (91%)]	Loss: 8.1059	Cost: 7.01s
Train Epoch: 773 	Average Loss: 8.3401
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8183

Learning rate: 0.0001999705145748567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 774 [0/90000 (0%)]	Loss: 10.3281	Cost: 22.50s
Train Epoch: 774 [20480/90000 (23%)]	Loss: 8.2222	Cost: 6.32s
Train Epoch: 774 [40960/90000 (45%)]	Loss: 8.1287	Cost: 6.43s
Train Epoch: 774 [61440/90000 (68%)]	Loss: 8.2963	Cost: 6.06s
Train Epoch: 774 [81920/90000 (91%)]	Loss: 8.2076	Cost: 6.04s
Train Epoch: 774 	Average Loss: 8.3771
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7892

Learning rate: 0.0001999704382409797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 775 [0/90000 (0%)]	Loss: 10.3435	Cost: 28.50s
Train Epoch: 775 [20480/90000 (23%)]	Loss: 8.2868	Cost: 11.94s
Train Epoch: 775 [40960/90000 (45%)]	Loss: 8.1918	Cost: 12.19s
Train Epoch: 775 [61440/90000 (68%)]	Loss: 8.2704	Cost: 12.19s
Train Epoch: 775 [81920/90000 (91%)]	Loss: 8.0961	Cost: 11.95s
Train Epoch: 775 	Average Loss: 8.3074
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8040

Learning rate: 0.00019997036180843583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 776 [0/90000 (0%)]	Loss: 10.5774	Cost: 25.64s
Train Epoch: 776 [20480/90000 (23%)]	Loss: 8.5690	Cost: 6.01s
Train Epoch: 776 [40960/90000 (45%)]	Loss: 8.0764	Cost: 8.53s
Train Epoch: 776 [61440/90000 (68%)]	Loss: 8.1233	Cost: 6.14s
Train Epoch: 776 [81920/90000 (91%)]	Loss: 8.1732	Cost: 6.37s
Train Epoch: 776 	Average Loss: 8.3355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8962

Learning rate: 0.00019997028527722518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 777 [0/90000 (0%)]	Loss: 10.3987	Cost: 23.36s
Train Epoch: 777 [20480/90000 (23%)]	Loss: 8.6612	Cost: 6.12s
Train Epoch: 777 [40960/90000 (45%)]	Loss: 8.4278	Cost: 10.24s
Train Epoch: 777 [61440/90000 (68%)]	Loss: 8.4068	Cost: 12.17s
Train Epoch: 777 [81920/90000 (91%)]	Loss: 8.3600	Cost: 12.20s
Train Epoch: 777 	Average Loss: 8.5038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8313

Learning rate: 0.00019997020864734782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 778 [0/90000 (0%)]	Loss: 10.5639	Cost: 29.10s
Train Epoch: 778 [20480/90000 (23%)]	Loss: 8.3199	Cost: 11.97s
Train Epoch: 778 [40960/90000 (45%)]	Loss: 8.4046	Cost: 11.23s
Train Epoch: 778 [61440/90000 (68%)]	Loss: 8.3284	Cost: 5.89s
Train Epoch: 778 [81920/90000 (91%)]	Loss: 8.4283	Cost: 6.71s
Train Epoch: 778 	Average Loss: 8.4254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8388

Learning rate: 0.00019997013191880381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 779 [0/90000 (0%)]	Loss: 10.5640	Cost: 23.64s
Train Epoch: 779 [20480/90000 (23%)]	Loss: 8.4216	Cost: 6.40s
Train Epoch: 779 [40960/90000 (45%)]	Loss: 8.1340	Cost: 6.42s
Train Epoch: 779 [61440/90000 (68%)]	Loss: 8.2626	Cost: 6.30s
Train Epoch: 779 [81920/90000 (91%)]	Loss: 8.1684	Cost: 5.83s
Train Epoch: 779 	Average Loss: 8.3600
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7039

Learning rate: 0.00019997005509159326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 780 [0/90000 (0%)]	Loss: 10.2533	Cost: 22.85s
Train Epoch: 780 [20480/90000 (23%)]	Loss: 8.3603	Cost: 6.17s
Train Epoch: 780 [40960/90000 (45%)]	Loss: 8.1831	Cost: 8.22s
Train Epoch: 780 [61440/90000 (68%)]	Loss: 8.3261	Cost: 6.92s
Train Epoch: 780 [81920/90000 (91%)]	Loss: 8.1731	Cost: 15.21s
Train Epoch: 780 	Average Loss: 8.3559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8304

Learning rate: 0.0001999699781657162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 781 [0/90000 (0%)]	Loss: 10.3574	Cost: 25.37s
Train Epoch: 781 [20480/90000 (23%)]	Loss: 8.3352	Cost: 10.81s
Train Epoch: 781 [40960/90000 (45%)]	Loss: 8.2105	Cost: 12.00s
Train Epoch: 781 [61440/90000 (68%)]	Loss: 8.2942	Cost: 11.77s
Train Epoch: 781 [81920/90000 (91%)]	Loss: 8.0580	Cost: 11.82s
Train Epoch: 781 	Average Loss: 8.3144
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8364

Learning rate: 0.00019996990114117273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 782 [0/90000 (0%)]	Loss: 10.3555	Cost: 28.21s
Train Epoch: 782 [20480/90000 (23%)]	Loss: 8.1951	Cost: 12.03s
Train Epoch: 782 [40960/90000 (45%)]	Loss: 8.1784	Cost: 11.94s
Train Epoch: 782 [61440/90000 (68%)]	Loss: 8.0447	Cost: 11.06s
Train Epoch: 782 [81920/90000 (91%)]	Loss: 8.2281	Cost: 5.85s
Train Epoch: 782 	Average Loss: 8.3009
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8517

Learning rate: 0.0001999698240179629
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 783 [0/90000 (0%)]	Loss: 10.6408	Cost: 27.51s
Train Epoch: 783 [20480/90000 (23%)]	Loss: 8.2142	Cost: 12.09s
Train Epoch: 783 [40960/90000 (45%)]	Loss: 8.1387	Cost: 6.94s
Train Epoch: 783 [61440/90000 (68%)]	Loss: 8.2162	Cost: 5.87s
Train Epoch: 783 [81920/90000 (91%)]	Loss: 8.2255	Cost: 6.74s
Train Epoch: 783 	Average Loss: 8.2819
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8157

Learning rate: 0.00019996974679608684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 784 [0/90000 (0%)]	Loss: 10.4898	Cost: 25.14s
Train Epoch: 784 [20480/90000 (23%)]	Loss: 8.3338	Cost: 6.25s
Train Epoch: 784 [40960/90000 (45%)]	Loss: 8.1303	Cost: 6.86s
Train Epoch: 784 [61440/90000 (68%)]	Loss: 8.1820	Cost: 6.17s
Train Epoch: 784 [81920/90000 (91%)]	Loss: 8.1383	Cost: 6.06s
Train Epoch: 784 	Average Loss: 8.2817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8272

Learning rate: 0.00019996966947554456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 785 [0/90000 (0%)]	Loss: 10.4003	Cost: 23.11s
Train Epoch: 785 [20480/90000 (23%)]	Loss: 7.9938	Cost: 6.20s
Train Epoch: 785 [40960/90000 (45%)]	Loss: 7.9917	Cost: 6.64s
Train Epoch: 785 [61440/90000 (68%)]	Loss: 8.2117	Cost: 6.07s
Train Epoch: 785 [81920/90000 (91%)]	Loss: 8.2489	Cost: 12.06s
Train Epoch: 785 	Average Loss: 8.2537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9185

Learning rate: 0.0001999695920563362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 786 [0/90000 (0%)]	Loss: 10.6523	Cost: 23.18s
Train Epoch: 786 [20480/90000 (23%)]	Loss: 8.1320	Cost: 6.04s
Train Epoch: 786 [40960/90000 (45%)]	Loss: 7.9753	Cost: 12.69s
Train Epoch: 786 [61440/90000 (68%)]	Loss: 8.2519	Cost: 11.99s
Train Epoch: 786 [81920/90000 (91%)]	Loss: 8.3906	Cost: 11.78s
Train Epoch: 786 	Average Loss: 8.2776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8874

Learning rate: 0.0001999695145384618
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 787 [0/90000 (0%)]	Loss: 10.6712	Cost: 26.24s
Train Epoch: 787 [20480/90000 (23%)]	Loss: 8.0553	Cost: 12.03s
Train Epoch: 787 [40960/90000 (45%)]	Loss: 8.1206	Cost: 12.00s
Train Epoch: 787 [61440/90000 (68%)]	Loss: 8.1971	Cost: 11.72s
Train Epoch: 787 [81920/90000 (91%)]	Loss: 8.1274	Cost: 11.48s
Train Epoch: 787 	Average Loss: 8.2937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8903

Learning rate: 0.00019996943692192142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 788 [0/90000 (0%)]	Loss: 10.3532	Cost: 29.00s
Train Epoch: 788 [20480/90000 (23%)]	Loss: 8.1974	Cost: 12.20s
Train Epoch: 788 [40960/90000 (45%)]	Loss: 8.0768	Cost: 11.96s
Train Epoch: 788 [61440/90000 (68%)]	Loss: 8.1537	Cost: 6.28s
Train Epoch: 788 [81920/90000 (91%)]	Loss: 8.1428	Cost: 5.86s
Train Epoch: 788 	Average Loss: 8.2997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9241

Learning rate: 0.0001999693592067152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 789 [0/90000 (0%)]	Loss: 10.3289	Cost: 27.85s
Train Epoch: 789 [20480/90000 (23%)]	Loss: 8.3235	Cost: 11.27s
Train Epoch: 789 [40960/90000 (45%)]	Loss: 8.1310	Cost: 6.00s
Train Epoch: 789 [61440/90000 (68%)]	Loss: 8.1949	Cost: 5.87s
Train Epoch: 789 [81920/90000 (91%)]	Loss: 8.1238	Cost: 6.89s
Train Epoch: 789 	Average Loss: 8.2936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8557

Learning rate: 0.00019996928139284315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 790 [0/90000 (0%)]	Loss: 10.5658	Cost: 24.99s
Train Epoch: 790 [20480/90000 (23%)]	Loss: 8.0595	Cost: 6.76s
Train Epoch: 790 [40960/90000 (45%)]	Loss: 7.9696	Cost: 6.36s
Train Epoch: 790 [61440/90000 (68%)]	Loss: 7.9962	Cost: 6.15s
Train Epoch: 790 [81920/90000 (91%)]	Loss: 8.1161	Cost: 6.08s
Train Epoch: 790 	Average Loss: 8.2264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9216

Learning rate: 0.00019996920348030537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 791 [0/90000 (0%)]	Loss: 10.5999	Cost: 22.86s
Train Epoch: 791 [20480/90000 (23%)]	Loss: 8.0469	Cost: 6.26s
Train Epoch: 791 [40960/90000 (45%)]	Loss: 8.2105	Cost: 6.65s
Train Epoch: 791 [61440/90000 (68%)]	Loss: 8.1404	Cost: 6.06s
Train Epoch: 791 [81920/90000 (91%)]	Loss: 8.1115	Cost: 15.73s
Train Epoch: 791 	Average Loss: 8.2234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8829

Learning rate: 0.00019996912546910197
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 792 [0/90000 (0%)]	Loss: 10.6039	Cost: 24.76s
Train Epoch: 792 [20480/90000 (23%)]	Loss: 8.4023	Cost: 6.73s
Train Epoch: 792 [40960/90000 (45%)]	Loss: 7.8929	Cost: 12.37s
Train Epoch: 792 [61440/90000 (68%)]	Loss: 8.1599	Cost: 12.05s
Train Epoch: 792 [81920/90000 (91%)]	Loss: 8.1848	Cost: 11.92s
Train Epoch: 792 	Average Loss: 8.2905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8367

Learning rate: 0.000199969047359233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 793 [0/90000 (0%)]	Loss: 10.5191	Cost: 25.26s
Train Epoch: 793 [20480/90000 (23%)]	Loss: 8.0455	Cost: 12.24s
Train Epoch: 793 [40960/90000 (45%)]	Loss: 8.0082	Cost: 12.12s
Train Epoch: 793 [61440/90000 (68%)]	Loss: 8.1441	Cost: 11.88s
Train Epoch: 793 [81920/90000 (91%)]	Loss: 8.0434	Cost: 8.69s
Train Epoch: 793 	Average Loss: 8.2559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9005

Learning rate: 0.00019996896915069852
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 794 [0/90000 (0%)]	Loss: 10.3946	Cost: 29.93s
Train Epoch: 794 [20480/90000 (23%)]	Loss: 8.2102	Cost: 9.82s
Train Epoch: 794 [40960/90000 (45%)]	Loss: 8.0037	Cost: 8.75s
Train Epoch: 794 [61440/90000 (68%)]	Loss: 8.2157	Cost: 5.88s
Train Epoch: 794 [81920/90000 (91%)]	Loss: 8.1037	Cost: 6.80s
Train Epoch: 794 	Average Loss: 8.2418
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8598

Learning rate: 0.0001999688908434986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 795 [0/90000 (0%)]	Loss: 10.6899	Cost: 26.66s
Train Epoch: 795 [20480/90000 (23%)]	Loss: 8.2395	Cost: 6.77s
Train Epoch: 795 [40960/90000 (45%)]	Loss: 8.0740	Cost: 5.97s
Train Epoch: 795 [61440/90000 (68%)]	Loss: 8.1702	Cost: 6.79s
Train Epoch: 795 [81920/90000 (91%)]	Loss: 8.0130	Cost: 6.13s
Train Epoch: 795 	Average Loss: 8.2286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8307

Learning rate: 0.00019996881243763336
