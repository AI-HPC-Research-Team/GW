Nestedspace(activation='elu', apply_unconditional_transform=False, base_transform_type='rq-coupling', basis_dir='data/GW150914_sample_prior_basis/', batch_norm=True, batch_size=2048, bw_dstar=None, cuda=True, data_dir='data/GW150914_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, dropout_probability=0.0, epochs=100000, flow_lr=None, hidden_dims=512, kl_annealing=True, lr=0.0002, lr_anneal_method='cosine', lr_annealing=True, mixed_alpha=0.1, mode='train', model_dir='models/GW150914_sample_uniform_100basis_all_mixed_prior_a01/', model_source='new', model_type='nde', nbins=8, nflows=15, nsample=100000, nsamples_target_event=50000, num_transform_blocks=10, output_freq=10, sampling_from='mixed', save=True, save_aux_filename='waveforms_supplementary.hdf5', save_model_name='model.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, tail_bound=1.0, transfer_epochs=0, truncate_basis=100)
Waveform directory data/GW150914_sample_prior_basis/
Model directory models/GW150914_sample_uniform_100basis_all_mixed_prior_a01/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from mixed prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Detectors: ['H1', 'L1']

Constructing model of type nde

Initial learning rate 0.0002
Using cosine LR annealing.

Model hyperparameters:
input_dim 	 15
num_flow_steps 	 15
context_dim 	 400
base_transform_kwargs
	 hidden_dim 	 512
	 num_transform_blocks 	 10
	 activation 	 elu
	 dropout_probability 	 0.0
	 batch_norm 	 True
	 num_bins 	 8
	 tail_bound 	 1.0
	 apply_unconditional_transform 	 False
	 base_transform_type 	 rq-coupling

Training for 100000 epochs
Starting timer
Learning rate: 0.0002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 27.4604	Cost: 22.05s
Train Epoch: 1 [20480/90000 (23%)]	Loss: 22.0418	Cost: 5.99s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 21.5769	Cost: 6.31s
Train Epoch: 1 [61440/90000 (68%)]	Loss: 21.3844	Cost: 6.11s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 21.2236	Cost: 7.85s
Train Epoch: 1 	Average Loss: 21.9078
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.2971

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 0.00019999999995065198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 21.2382	Cost: 24.10s
Train Epoch: 2 [20480/90000 (23%)]	Loss: 21.2175	Cost: 6.06s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 21.1999	Cost: 7.16s
Train Epoch: 2 [61440/90000 (68%)]	Loss: 21.2065	Cost: 5.85s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 21.1173	Cost: 5.90s
Train Epoch: 2 	Average Loss: 21.1633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.1438

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 0.0001999999998026079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 21.0786	Cost: 23.16s
Train Epoch: 3 [20480/90000 (23%)]	Loss: 21.0580	Cost: 6.43s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 21.0528	Cost: 7.69s
Train Epoch: 3 [61440/90000 (68%)]	Loss: 21.0375	Cost: 6.10s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 20.8880	Cost: 6.35s
Train Epoch: 3 	Average Loss: 21.0163
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 21.0030

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 0.0001999999995558678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 20.7968	Cost: 25.32s
Train Epoch: 4 [20480/90000 (23%)]	Loss: 20.9575	Cost: 5.99s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 20.9078	Cost: 7.26s
Train Epoch: 4 [61440/90000 (68%)]	Loss: 20.8551	Cost: 6.20s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 20.9483	Cost: 5.68s
Train Epoch: 4 	Average Loss: 20.8794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.8894

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 0.00019999999921043165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 20.7987	Cost: 27.32s
Train Epoch: 5 [20480/90000 (23%)]	Loss: 20.8184	Cost: 6.22s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 20.7826	Cost: 6.44s
Train Epoch: 5 [61440/90000 (68%)]	Loss: 20.6315	Cost: 6.07s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 20.5521	Cost: 6.17s
Train Epoch: 5 	Average Loss: 20.7044
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.7155

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 0.00019999999876629945
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 20.5451	Cost: 24.16s
Train Epoch: 6 [20480/90000 (23%)]	Loss: 20.5609	Cost: 6.05s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 20.5298	Cost: 8.28s
Train Epoch: 6 [61440/90000 (68%)]	Loss: 20.4431	Cost: 5.88s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 20.3254	Cost: 8.44s
Train Epoch: 6 	Average Loss: 20.4904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4910

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 0.00019999999822347122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 20.3764	Cost: 23.06s
Train Epoch: 7 [20480/90000 (23%)]	Loss: 20.2693	Cost: 6.04s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 20.2476	Cost: 6.37s
Train Epoch: 7 [61440/90000 (68%)]	Loss: 20.3193	Cost: 5.97s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 20.1769	Cost: 8.50s
Train Epoch: 7 	Average Loss: 20.2805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.3320

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 0.00019999999758194695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 20.1288	Cost: 22.75s
Train Epoch: 8 [20480/90000 (23%)]	Loss: 20.1880	Cost: 5.92s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 20.1349	Cost: 7.47s
Train Epoch: 8 [61440/90000 (68%)]	Loss: 20.0164	Cost: 5.70s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 20.0277	Cost: 5.83s
Train Epoch: 8 	Average Loss: 20.1159
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.2051

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 0.00019999999684172664
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 20.1695	Cost: 22.59s
Train Epoch: 9 [20480/90000 (23%)]	Loss: 20.0902	Cost: 5.97s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 19.9366	Cost: 6.97s
Train Epoch: 9 [61440/90000 (68%)]	Loss: 19.8646	Cost: 6.27s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 19.8010	Cost: 5.87s
Train Epoch: 9 	Average Loss: 19.9386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.9693

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 0.00019999999600281025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 19.8159	Cost: 25.57s
Train Epoch: 10 [20480/90000 (23%)]	Loss: 19.9033	Cost: 6.13s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 19.7149	Cost: 7.20s
Train Epoch: 10 [61440/90000 (68%)]	Loss: 19.7439	Cost: 5.91s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 19.6972	Cost: 5.86s
Train Epoch: 10 	Average Loss: 19.7803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.8449

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 0.00019999999506519785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 19.6408	Cost: 24.49s
Train Epoch: 11 [20480/90000 (23%)]	Loss: 19.7721	Cost: 6.00s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 19.6892	Cost: 9.10s
Train Epoch: 11 [61440/90000 (68%)]	Loss: 19.6312	Cost: 5.88s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 19.4482	Cost: 8.40s
Train Epoch: 11 	Average Loss: 19.6008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.6840

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 0.00019999999402888941
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 19.5168	Cost: 22.46s
Train Epoch: 12 [20480/90000 (23%)]	Loss: 19.5064	Cost: 5.98s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 19.4058	Cost: 6.62s
Train Epoch: 12 [61440/90000 (68%)]	Loss: 19.3851	Cost: 5.96s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 19.3503	Cost: 8.21s
Train Epoch: 12 	Average Loss: 19.4028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.4586

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 0.00019999999289388494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 19.2750	Cost: 23.42s
Train Epoch: 13 [20480/90000 (23%)]	Loss: 19.3582	Cost: 5.94s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 19.2358	Cost: 6.41s
Train Epoch: 13 [61440/90000 (68%)]	Loss: 19.1679	Cost: 5.73s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 19.2388	Cost: 5.63s
Train Epoch: 13 	Average Loss: 19.2154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2747

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Learning rate: 0.0001999999916601844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 19.0962	Cost: 22.85s
Train Epoch: 14 [20480/90000 (23%)]	Loss: 19.0482	Cost: 6.04s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 19.0192	Cost: 7.27s
Train Epoch: 14 [61440/90000 (68%)]	Loss: 18.9162	Cost: 5.97s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 18.9859	Cost: 6.32s
Train Epoch: 14 	Average Loss: 19.0320
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0978

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Learning rate: 0.00019999999032778784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 18.9580	Cost: 24.19s
Train Epoch: 15 [20480/90000 (23%)]	Loss: 18.8430	Cost: 6.32s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 18.8236	Cost: 6.47s
Train Epoch: 15 [61440/90000 (68%)]	Loss: 18.8950	Cost: 6.47s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 18.9050	Cost: 5.59s
Train Epoch: 15 	Average Loss: 18.8494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.0055

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Learning rate: 0.00019999998889669524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 18.9124	Cost: 28.33s
Train Epoch: 16 [20480/90000 (23%)]	Loss: 18.7826	Cost: 5.87s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 18.5334	Cost: 6.68s
Train Epoch: 16 [61440/90000 (68%)]	Loss: 18.7119	Cost: 5.94s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 18.5379	Cost: 5.53s
Train Epoch: 16 	Average Loss: 18.7053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.8162

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Learning rate: 0.0001999999873669066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 18.6401	Cost: 23.46s
Train Epoch: 17 [20480/90000 (23%)]	Loss: 18.4965	Cost: 6.06s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 18.4989	Cost: 7.76s
Train Epoch: 17 [61440/90000 (68%)]	Loss: 18.6081	Cost: 5.85s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 18.5394	Cost: 7.43s
Train Epoch: 17 	Average Loss: 18.5532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.7154

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Learning rate: 0.00019999998573842195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 18.5022	Cost: 23.66s
Train Epoch: 18 [20480/90000 (23%)]	Loss: 18.5506	Cost: 6.03s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 18.4106	Cost: 6.38s
Train Epoch: 18 [61440/90000 (68%)]	Loss: 18.4766	Cost: 6.07s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 18.4449	Cost: 8.66s
Train Epoch: 18 	Average Loss: 18.4125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.5660

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Learning rate: 0.00019999998401124124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 18.2786	Cost: 24.38s
Train Epoch: 19 [20480/90000 (23%)]	Loss: 18.2890	Cost: 6.07s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 18.2352	Cost: 6.49s
Train Epoch: 19 [61440/90000 (68%)]	Loss: 18.2618	Cost: 6.03s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 18.1222	Cost: 5.87s
Train Epoch: 19 	Average Loss: 18.2483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3683

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Learning rate: 0.00019999998218536453
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 18.2018	Cost: 22.70s
Train Epoch: 20 [20480/90000 (23%)]	Loss: 18.2232	Cost: 6.00s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 18.1171	Cost: 6.42s
Train Epoch: 20 [61440/90000 (68%)]	Loss: 17.9957	Cost: 5.98s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 18.1521	Cost: 5.89s
Train Epoch: 20 	Average Loss: 18.1188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.2859

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Learning rate: 0.00019999998026079178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 18.0695	Cost: 26.29s
Train Epoch: 21 [20480/90000 (23%)]	Loss: 17.9369	Cost: 5.99s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 18.0095	Cost: 7.44s
Train Epoch: 21 [61440/90000 (68%)]	Loss: 18.0241	Cost: 5.92s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 18.1025	Cost: 5.72s
Train Epoch: 21 	Average Loss: 18.0066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.1703

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Learning rate: 0.000199999978237523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 17.9591	Cost: 29.15s
Train Epoch: 22 [20480/90000 (23%)]	Loss: 17.8211	Cost: 6.02s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 17.8838	Cost: 6.46s
Train Epoch: 22 [61440/90000 (68%)]	Loss: 17.8284	Cost: 6.04s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 17.8096	Cost: 6.55s
Train Epoch: 22 	Average Loss: 17.8608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0258

Saving model as e22_model.pt & e22_waveforms_supplementary.hdf5
Learning rate: 0.00019999997611555822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 17.7981	Cost: 24.76s
Train Epoch: 23 [20480/90000 (23%)]	Loss: 17.8447	Cost: 6.01s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 17.7128	Cost: 7.45s
Train Epoch: 23 [61440/90000 (68%)]	Loss: 17.7369	Cost: 5.91s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 17.7077	Cost: 7.64s
Train Epoch: 23 	Average Loss: 17.7504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.9605

Saving model as e23_model.pt & e23_waveforms_supplementary.hdf5
Learning rate: 0.00019999997389489742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 17.7850	Cost: 23.36s
Train Epoch: 24 [20480/90000 (23%)]	Loss: 17.5580	Cost: 6.00s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 17.6883	Cost: 6.58s
Train Epoch: 24 [61440/90000 (68%)]	Loss: 17.6275	Cost: 6.11s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 17.6141	Cost: 8.73s
Train Epoch: 24 	Average Loss: 17.6617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.8165

Saving model as e24_model.pt & e24_waveforms_supplementary.hdf5
Learning rate: 0.00019999997157554058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 17.5167	Cost: 23.97s
Train Epoch: 25 [20480/90000 (23%)]	Loss: 17.5624	Cost: 6.70s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 17.5037	Cost: 6.32s
Train Epoch: 25 [61440/90000 (68%)]	Loss: 17.4786	Cost: 5.86s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 17.5423	Cost: 5.96s
Train Epoch: 25 	Average Loss: 17.5206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7320

Saving model as e25_model.pt & e25_waveforms_supplementary.hdf5
Learning rate: 0.00019999996915748774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 17.4535	Cost: 22.37s
Train Epoch: 26 [20480/90000 (23%)]	Loss: 17.5130	Cost: 5.99s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 17.4067	Cost: 7.41s
Train Epoch: 26 [61440/90000 (68%)]	Loss: 17.2823	Cost: 5.89s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 17.4050	Cost: 6.86s
Train Epoch: 26 	Average Loss: 17.4224
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6179

Saving model as e26_model.pt & e26_waveforms_supplementary.hdf5
Learning rate: 0.00019999996664073888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 17.3560	Cost: 25.80s
Train Epoch: 27 [20480/90000 (23%)]	Loss: 17.4263	Cost: 5.96s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 17.1808	Cost: 6.75s
Train Epoch: 27 [61440/90000 (68%)]	Loss: 17.2171	Cost: 5.88s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 17.3022	Cost: 5.56s
Train Epoch: 27 	Average Loss: 17.3008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.5475

Saving model as e27_model.pt & e27_waveforms_supplementary.hdf5
Learning rate: 0.00019999996402529402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 17.1914	Cost: 27.10s
Train Epoch: 28 [20480/90000 (23%)]	Loss: 17.2789	Cost: 6.01s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 17.0192	Cost: 6.90s
Train Epoch: 28 [61440/90000 (68%)]	Loss: 17.1676	Cost: 5.96s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 17.1676	Cost: 6.30s
Train Epoch: 28 	Average Loss: 17.1596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3572

Saving model as e28_model.pt & e28_waveforms_supplementary.hdf5
Learning rate: 0.00019999996131115315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 17.2497	Cost: 23.67s
Train Epoch: 29 [20480/90000 (23%)]	Loss: 17.1816	Cost: 6.11s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 16.9963	Cost: 6.92s
Train Epoch: 29 [61440/90000 (68%)]	Loss: 16.9887	Cost: 6.07s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 16.9632	Cost: 8.43s
Train Epoch: 29 	Average Loss: 17.0683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3137

Saving model as e29_model.pt & e29_waveforms_supplementary.hdf5
Learning rate: 0.00019999995849831625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 17.0130	Cost: 24.00s
Train Epoch: 30 [20480/90000 (23%)]	Loss: 16.8676	Cost: 5.98s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 16.9180	Cost: 6.89s
Train Epoch: 30 [61440/90000 (68%)]	Loss: 16.8749	Cost: 5.85s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 16.9677	Cost: 5.85s
Train Epoch: 30 	Average Loss: 16.9411
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2323

Saving model as e30_model.pt & e30_waveforms_supplementary.hdf5
Learning rate: 0.00019999995558678336
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 16.9603	Cost: 22.33s
Train Epoch: 31 [20480/90000 (23%)]	Loss: 16.7311	Cost: 5.97s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 16.7892	Cost: 7.47s
Train Epoch: 31 [61440/90000 (68%)]	Loss: 16.7939	Cost: 5.96s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 16.8518	Cost: 5.77s
Train Epoch: 31 	Average Loss: 16.8392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.0451

Saving model as e31_model.pt & e31_waveforms_supplementary.hdf5
Learning rate: 0.0001999999525765545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 16.9708	Cost: 25.59s
Train Epoch: 32 [20480/90000 (23%)]	Loss: 16.7270	Cost: 6.19s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 16.7637	Cost: 6.86s
Train Epoch: 32 [61440/90000 (68%)]	Loss: 16.7618	Cost: 6.07s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 16.7971	Cost: 5.77s
Train Epoch: 32 	Average Loss: 16.7754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.9624

Saving model as e32_model.pt & e32_waveforms_supplementary.hdf5
Learning rate: 0.0001999999494676296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 16.7582	Cost: 27.36s
Train Epoch: 33 [20480/90000 (23%)]	Loss: 16.6422	Cost: 5.98s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 16.6054	Cost: 6.43s
Train Epoch: 33 [61440/90000 (68%)]	Loss: 16.6806	Cost: 5.94s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 16.6689	Cost: 6.21s
Train Epoch: 33 	Average Loss: 16.6508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8769

Saving model as e33_model.pt & e33_waveforms_supplementary.hdf5
Learning rate: 0.00019999994626000874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 16.5167	Cost: 23.64s
Train Epoch: 34 [20480/90000 (23%)]	Loss: 16.5147	Cost: 6.00s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 16.4126	Cost: 7.79s
Train Epoch: 34 [61440/90000 (68%)]	Loss: 16.4362	Cost: 5.94s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 16.4666	Cost: 8.44s
Train Epoch: 34 	Average Loss: 16.5236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7678

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Learning rate: 0.00019999994295369188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 16.6143	Cost: 23.11s
Train Epoch: 35 [20480/90000 (23%)]	Loss: 16.3509	Cost: 5.96s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 16.3535	Cost: 6.68s
Train Epoch: 35 [61440/90000 (68%)]	Loss: 16.5025	Cost: 5.86s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 16.4371	Cost: 5.95s
Train Epoch: 35 	Average Loss: 16.4541
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7287

Saving model as e35_model.pt & e35_waveforms_supplementary.hdf5
Learning rate: 0.000199999939548679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 16.3608	Cost: 23.70s
Train Epoch: 36 [20480/90000 (23%)]	Loss: 16.3041	Cost: 6.00s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 16.3864	Cost: 7.32s
Train Epoch: 36 [61440/90000 (68%)]	Loss: 16.4182	Cost: 5.83s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 16.1437	Cost: 6.17s
Train Epoch: 36 	Average Loss: 16.3374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6080

Saving model as e36_model.pt & e36_waveforms_supplementary.hdf5
Learning rate: 0.00019999993604497015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 16.2666	Cost: 24.86s
Train Epoch: 37 [20480/90000 (23%)]	Loss: 16.2779	Cost: 5.98s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 16.2281	Cost: 6.07s
Train Epoch: 37 [61440/90000 (68%)]	Loss: 16.2588	Cost: 5.95s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 16.1571	Cost: 5.55s
Train Epoch: 37 	Average Loss: 16.2581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5089

Saving model as e37_model.pt & e37_waveforms_supplementary.hdf5
Learning rate: 0.00019999993244256535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 16.1906	Cost: 28.75s
Train Epoch: 38 [20480/90000 (23%)]	Loss: 16.1166	Cost: 6.02s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 16.0528	Cost: 7.08s
Train Epoch: 38 [61440/90000 (68%)]	Loss: 16.0396	Cost: 6.41s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 16.0734	Cost: 5.80s
Train Epoch: 38 	Average Loss: 16.1715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4487

Saving model as e38_model.pt & e38_waveforms_supplementary.hdf5
Learning rate: 0.00019999992874146456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 16.1599	Cost: 26.33s
Train Epoch: 39 [20480/90000 (23%)]	Loss: 16.1946	Cost: 6.01s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 15.9364	Cost: 7.24s
Train Epoch: 39 [61440/90000 (68%)]	Loss: 15.9159	Cost: 6.03s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 16.0891	Cost: 6.34s
Train Epoch: 39 	Average Loss: 16.0677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4149

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Learning rate: 0.0001999999249416678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 16.1201	Cost: 22.36s
Train Epoch: 40 [20480/90000 (23%)]	Loss: 16.0181	Cost: 5.97s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 15.9986	Cost: 6.57s
Train Epoch: 40 [61440/90000 (68%)]	Loss: 16.0141	Cost: 6.07s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 16.0013	Cost: 8.35s
Train Epoch: 40 	Average Loss: 15.9839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2288

Saving model as e40_model.pt & e40_waveforms_supplementary.hdf5
Learning rate: 0.00019999992104317507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 15.9714	Cost: 23.99s
Train Epoch: 41 [20480/90000 (23%)]	Loss: 15.8993	Cost: 5.97s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 15.8133	Cost: 7.37s
Train Epoch: 41 [61440/90000 (68%)]	Loss: 16.0016	Cost: 6.43s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 15.9417	Cost: 6.33s
Train Epoch: 41 	Average Loss: 15.9388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1664

Saving model as e41_model.pt & e41_waveforms_supplementary.hdf5
Learning rate: 0.00019999991704598637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 15.8550	Cost: 23.82s
Train Epoch: 42 [20480/90000 (23%)]	Loss: 15.7760	Cost: 6.00s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 15.8480	Cost: 6.84s
Train Epoch: 42 [61440/90000 (68%)]	Loss: 15.8654	Cost: 5.88s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 15.6420	Cost: 7.80s
Train Epoch: 42 	Average Loss: 15.8336
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0944

Saving model as e42_model.pt & e42_waveforms_supplementary.hdf5
Learning rate: 0.00019999991295010171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 15.9414	Cost: 25.94s
Train Epoch: 43 [20480/90000 (23%)]	Loss: 15.8383	Cost: 6.08s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 15.7763	Cost: 6.41s
Train Epoch: 43 [61440/90000 (68%)]	Loss: 15.6963	Cost: 6.15s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 15.7831	Cost: 5.73s
Train Epoch: 43 	Average Loss: 15.7716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0634

Saving model as e43_model.pt & e43_waveforms_supplementary.hdf5
Learning rate: 0.00019999990875552108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 15.7011	Cost: 29.30s
Train Epoch: 44 [20480/90000 (23%)]	Loss: 15.7466	Cost: 5.94s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 15.6171	Cost: 6.85s
Train Epoch: 44 [61440/90000 (68%)]	Loss: 15.6190	Cost: 6.43s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 15.7601	Cost: 5.80s
Train Epoch: 44 	Average Loss: 15.7128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9520

Saving model as e44_model.pt & e44_waveforms_supplementary.hdf5
Learning rate: 0.00019999990446224451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 15.6474	Cost: 25.68s
Train Epoch: 45 [20480/90000 (23%)]	Loss: 15.7422	Cost: 6.00s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 15.5259	Cost: 7.59s
Train Epoch: 45 [61440/90000 (68%)]	Loss: 15.5283	Cost: 6.01s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 15.5940	Cost: 6.99s
Train Epoch: 45 	Average Loss: 15.6464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9413

Saving model as e45_model.pt & e45_waveforms_supplementary.hdf5
Learning rate: 0.000199999900070272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 15.7843	Cost: 23.92s
Train Epoch: 46 [20480/90000 (23%)]	Loss: 15.5931	Cost: 6.08s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 15.5026	Cost: 6.28s
Train Epoch: 46 [61440/90000 (68%)]	Loss: 15.5761	Cost: 5.98s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 15.5938	Cost: 8.88s
Train Epoch: 46 	Average Loss: 15.6001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8847

Saving model as e46_model.pt & e46_waveforms_supplementary.hdf5
Learning rate: 0.00019999989557960353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 15.4349	Cost: 23.02s
Train Epoch: 47 [20480/90000 (23%)]	Loss: 15.7048	Cost: 6.04s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 15.5056	Cost: 6.45s
Train Epoch: 47 [61440/90000 (68%)]	Loss: 15.5394	Cost: 5.86s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 15.5022	Cost: 6.09s
Train Epoch: 47 	Average Loss: 15.5376
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7809

Saving model as e47_model.pt & e47_waveforms_supplementary.hdf5
Learning rate: 0.0001999998909902391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 15.5481	Cost: 23.74s
Train Epoch: 48 [20480/90000 (23%)]	Loss: 15.4254	Cost: 6.01s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 15.3216	Cost: 6.41s
Train Epoch: 48 [61440/90000 (68%)]	Loss: 15.4450	Cost: 5.96s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 15.3426	Cost: 5.78s
Train Epoch: 48 	Average Loss: 15.4640
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7151

Saving model as e48_model.pt & e48_waveforms_supplementary.hdf5
Learning rate: 0.00019999988630217875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 15.3230	Cost: 26.17s
Train Epoch: 49 [20480/90000 (23%)]	Loss: 15.4296	Cost: 5.97s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 15.2969	Cost: 7.00s
Train Epoch: 49 [61440/90000 (68%)]	Loss: 15.5439	Cost: 5.87s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 15.4140	Cost: 5.93s
Train Epoch: 49 	Average Loss: 15.4067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7001

Saving model as e49_model.pt & e49_waveforms_supplementary.hdf5
Learning rate: 0.00019999988151542247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 15.3969	Cost: 28.25s
Train Epoch: 50 [20480/90000 (23%)]	Loss: 15.2988	Cost: 6.02s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 15.3183	Cost: 8.36s
Train Epoch: 50 [61440/90000 (68%)]	Loss: 15.2391	Cost: 5.92s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 15.3523	Cost: 7.35s
Train Epoch: 50 	Average Loss: 15.3587
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7283

Learning rate: 0.00019999987662997027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 15.5052	Cost: 22.65s
Train Epoch: 51 [20480/90000 (23%)]	Loss: 15.2922	Cost: 6.00s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 15.3160	Cost: 7.71s
Train Epoch: 51 [61440/90000 (68%)]	Loss: 15.2254	Cost: 5.94s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 15.1992	Cost: 8.76s
Train Epoch: 51 	Average Loss: 15.3169
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5609

Saving model as e51_model.pt & e51_waveforms_supplementary.hdf5
Learning rate: 0.00019999987164582216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 15.2565	Cost: 24.08s
Train Epoch: 52 [20480/90000 (23%)]	Loss: 15.4129	Cost: 6.02s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 15.3035	Cost: 6.33s
Train Epoch: 52 [61440/90000 (68%)]	Loss: 15.2146	Cost: 5.91s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 15.4718	Cost: 5.84s
Train Epoch: 52 	Average Loss: 15.2665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5535

Saving model as e52_model.pt & e52_waveforms_supplementary.hdf5
Learning rate: 0.0001999998665629781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 15.1883	Cost: 24.99s
Train Epoch: 53 [20480/90000 (23%)]	Loss: 15.2243	Cost: 6.08s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 15.1351	Cost: 7.06s
Train Epoch: 53 [61440/90000 (68%)]	Loss: 15.1108	Cost: 5.86s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 15.2453	Cost: 6.23s
Train Epoch: 53 	Average Loss: 15.1994
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4746

Saving model as e53_model.pt & e53_waveforms_supplementary.hdf5
Learning rate: 0.00019999986138143815
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 15.3553	Cost: 24.26s
Train Epoch: 54 [20480/90000 (23%)]	Loss: 15.2146	Cost: 6.28s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 15.0775	Cost: 6.29s
Train Epoch: 54 [61440/90000 (68%)]	Loss: 15.1720	Cost: 6.05s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 15.1938	Cost: 5.73s
Train Epoch: 54 	Average Loss: 15.1772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4683

Saving model as e54_model.pt & e54_waveforms_supplementary.hdf5
Learning rate: 0.00019999985610120227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 15.1662	Cost: 26.12s
Train Epoch: 55 [20480/90000 (23%)]	Loss: 15.0355	Cost: 6.00s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 15.1326	Cost: 7.03s
Train Epoch: 55 [61440/90000 (68%)]	Loss: 15.1709	Cost: 5.86s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 15.2170	Cost: 5.69s
Train Epoch: 55 	Average Loss: 15.1284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4459

Saving model as e55_model.pt & e55_waveforms_supplementary.hdf5
Learning rate: 0.0001999998507222705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 15.0642	Cost: 25.49s
Train Epoch: 56 [20480/90000 (23%)]	Loss: 15.1641	Cost: 5.95s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 15.0057	Cost: 8.83s
Train Epoch: 56 [61440/90000 (68%)]	Loss: 15.0215	Cost: 5.88s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 15.1246	Cost: 8.16s
Train Epoch: 56 	Average Loss: 15.0803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4013

Saving model as e56_model.pt & e56_waveforms_supplementary.hdf5
Learning rate: 0.00019999984524464283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 15.0146	Cost: 22.57s
Train Epoch: 57 [20480/90000 (23%)]	Loss: 15.0339	Cost: 6.10s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 14.9689	Cost: 7.38s
Train Epoch: 57 [61440/90000 (68%)]	Loss: 15.0166	Cost: 5.96s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 15.0550	Cost: 8.54s
Train Epoch: 57 	Average Loss: 15.0146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3643

Saving model as e57_model.pt & e57_waveforms_supplementary.hdf5
Learning rate: 0.0001999998396683193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 15.0455	Cost: 23.89s
Train Epoch: 58 [20480/90000 (23%)]	Loss: 14.9999	Cost: 5.83s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 14.9622	Cost: 6.72s
Train Epoch: 58 [61440/90000 (68%)]	Loss: 14.9571	Cost: 5.70s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 15.0149	Cost: 5.78s
Train Epoch: 58 	Average Loss: 14.9631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3159

Saving model as e58_model.pt & e58_waveforms_supplementary.hdf5
Learning rate: 0.00019999983399329984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 15.0441	Cost: 23.65s
Train Epoch: 59 [20480/90000 (23%)]	Loss: 14.9744	Cost: 5.95s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 14.8485	Cost: 7.28s
Train Epoch: 59 [61440/90000 (68%)]	Loss: 15.1232	Cost: 5.89s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 14.9629	Cost: 6.13s
Train Epoch: 59 	Average Loss: 14.9620
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2647

Saving model as e59_model.pt & e59_waveforms_supplementary.hdf5
Learning rate: 0.00019999982821958452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 14.9351	Cost: 25.65s
Train Epoch: 60 [20480/90000 (23%)]	Loss: 14.8161	Cost: 6.10s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 14.7213	Cost: 7.20s
Train Epoch: 60 [61440/90000 (68%)]	Loss: 14.9692	Cost: 6.10s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 14.7330	Cost: 5.80s
Train Epoch: 60 	Average Loss: 14.9035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2409

Saving model as e60_model.pt & e60_waveforms_supplementary.hdf5
Learning rate: 0.00019999982234717332
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 14.9371	Cost: 29.98s
Train Epoch: 61 [20480/90000 (23%)]	Loss: 14.9041	Cost: 6.00s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 14.7948	Cost: 8.59s
Train Epoch: 61 [61440/90000 (68%)]	Loss: 14.8474	Cost: 5.86s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 14.8178	Cost: 6.82s
Train Epoch: 61 	Average Loss: 14.8739
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2138

Saving model as e61_model.pt & e61_waveforms_supplementary.hdf5
Learning rate: 0.00019999981637606627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 14.7582	Cost: 24.35s
Train Epoch: 62 [20480/90000 (23%)]	Loss: 14.8585	Cost: 5.99s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 14.6851	Cost: 7.81s
Train Epoch: 62 [61440/90000 (68%)]	Loss: 14.7855	Cost: 5.87s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 14.7652	Cost: 7.04s
Train Epoch: 62 	Average Loss: 14.8229
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1862

Saving model as e62_model.pt & e62_waveforms_supplementary.hdf5
Learning rate: 0.00019999981030626333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 14.7530	Cost: 23.42s
Train Epoch: 63 [20480/90000 (23%)]	Loss: 14.8631	Cost: 5.98s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 14.5857	Cost: 6.68s
Train Epoch: 63 [61440/90000 (68%)]	Loss: 14.7449	Cost: 6.03s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 14.7358	Cost: 8.20s
Train Epoch: 63 	Average Loss: 14.7782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0713

Saving model as e63_model.pt & e63_waveforms_supplementary.hdf5
Learning rate: 0.00019999980413776456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 14.8320	Cost: 23.70s
Train Epoch: 64 [20480/90000 (23%)]	Loss: 14.7053	Cost: 6.03s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 14.6110	Cost: 6.92s
Train Epoch: 64 [61440/90000 (68%)]	Loss: 14.6027	Cost: 5.91s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 14.7364	Cost: 5.66s
Train Epoch: 64 	Average Loss: 14.7562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0816

Learning rate: 0.00019999979787056995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 14.8173	Cost: 36.25s
Train Epoch: 65 [20480/90000 (23%)]	Loss: 14.7486	Cost: 6.06s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 14.6122	Cost: 9.17s
Train Epoch: 65 [61440/90000 (68%)]	Loss: 14.6587	Cost: 9.11s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 14.7662	Cost: 16.49s
Train Epoch: 65 	Average Loss: 14.7088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9735

Saving model as e65_model.pt & e65_waveforms_supplementary.hdf5
Learning rate: 0.00019999979150467947
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 14.6719	Cost: 43.72s
Train Epoch: 66 [20480/90000 (23%)]	Loss: 14.6416	Cost: 7.28s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 14.4949	Cost: 8.18s
Train Epoch: 66 [61440/90000 (68%)]	Loss: 14.6100	Cost: 5.90s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 14.6176	Cost: 11.08s
Train Epoch: 66 	Average Loss: 14.6574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9229

Saving model as e66_model.pt & e66_waveforms_supplementary.hdf5
Learning rate: 0.00019999978504009312
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 14.5481	Cost: 45.61s
Train Epoch: 67 [20480/90000 (23%)]	Loss: 14.5636	Cost: 9.48s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 14.5607	Cost: 10.02s
Train Epoch: 67 [61440/90000 (68%)]	Loss: 14.6224	Cost: 6.09s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 14.6041	Cost: 9.60s
Train Epoch: 67 	Average Loss: 14.6194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9649

Learning rate: 0.00019999977847681098
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 14.6198	Cost: 67.15s
Train Epoch: 68 [20480/90000 (23%)]	Loss: 14.6006	Cost: 11.27s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 14.5373	Cost: 16.30s
Train Epoch: 68 [61440/90000 (68%)]	Loss: 14.6062	Cost: 11.54s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 14.5392	Cost: 17.89s
Train Epoch: 68 	Average Loss: 14.5802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.8029

Saving model as e68_model.pt & e68_waveforms_supplementary.hdf5
Learning rate: 0.00019999977181483299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 14.5999	Cost: 23.41s
Train Epoch: 69 [20480/90000 (23%)]	Loss: 14.6562	Cost: 8.37s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 14.4770	Cost: 17.11s
Train Epoch: 69 [61440/90000 (68%)]	Loss: 14.6338	Cost: 9.43s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 14.5919	Cost: 17.49s
Train Epoch: 69 	Average Loss: 14.5546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.8706

Learning rate: 0.0001999997650541592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 14.4367	Cost: 25.56s
Train Epoch: 70 [20480/90000 (23%)]	Loss: 14.4682	Cost: 6.22s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 14.3997	Cost: 7.58s
Train Epoch: 70 [61440/90000 (68%)]	Loss: 14.5238	Cost: 5.97s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 14.6191	Cost: 6.46s
Train Epoch: 70 	Average Loss: 14.4952
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.8111

Learning rate: 0.0001999997581947896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 14.4626	Cost: 30.96s
Train Epoch: 71 [20480/90000 (23%)]	Loss: 14.4355	Cost: 6.09s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 14.4659	Cost: 9.08s
Train Epoch: 71 [61440/90000 (68%)]	Loss: 14.4677	Cost: 6.02s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 14.3557	Cost: 6.00s
Train Epoch: 71 	Average Loss: 14.4579
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7734

Saving model as e71_model.pt & e71_waveforms_supplementary.hdf5
Learning rate: 0.0001999997512367242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 14.4849	Cost: 28.27s
Train Epoch: 72 [20480/90000 (23%)]	Loss: 14.4522	Cost: 6.20s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 14.2308	Cost: 8.75s
Train Epoch: 72 [61440/90000 (68%)]	Loss: 14.3966	Cost: 6.05s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 14.4507	Cost: 8.53s
Train Epoch: 72 	Average Loss: 14.4280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7011

Saving model as e72_model.pt & e72_waveforms_supplementary.hdf5
Learning rate: 0.000199999744179963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 14.4839	Cost: 24.47s
Train Epoch: 73 [20480/90000 (23%)]	Loss: 14.3643	Cost: 6.08s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 14.2886	Cost: 6.62s
Train Epoch: 73 [61440/90000 (68%)]	Loss: 14.3657	Cost: 6.02s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 14.4345	Cost: 8.62s
Train Epoch: 73 	Average Loss: 14.3961
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7765

Learning rate: 0.000199999737024506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 14.3041	Cost: 25.27s
Train Epoch: 74 [20480/90000 (23%)]	Loss: 14.2621	Cost: 6.02s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 14.1756	Cost: 9.12s
Train Epoch: 74 [61440/90000 (68%)]	Loss: 14.2664	Cost: 8.10s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 14.3450	Cost: 20.10s
Train Epoch: 74 	Average Loss: 14.3496
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7382

Learning rate: 0.00019999972977035322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 14.5396	Cost: 69.19s
Train Epoch: 75 [20480/90000 (23%)]	Loss: 14.2422	Cost: 9.58s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 14.1787	Cost: 16.42s
Train Epoch: 75 [61440/90000 (68%)]	Loss: 14.3686	Cost: 8.33s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 14.3154	Cost: 11.17s
Train Epoch: 75 	Average Loss: 14.3343
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6330

Saving model as e75_model.pt & e75_waveforms_supplementary.hdf5
Learning rate: 0.00019999972241750466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 14.4665	Cost: 70.97s
Train Epoch: 76 [20480/90000 (23%)]	Loss: 14.2476	Cost: 10.15s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 14.1370	Cost: 16.68s
Train Epoch: 76 [61440/90000 (68%)]	Loss: 14.2826	Cost: 8.20s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 14.1464	Cost: 12.48s
Train Epoch: 76 	Average Loss: 14.2885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5994

Saving model as e76_model.pt & e76_waveforms_supplementary.hdf5
Learning rate: 0.0001999997149659603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 14.3143	Cost: 68.49s
Train Epoch: 77 [20480/90000 (23%)]	Loss: 14.3295	Cost: 11.34s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 14.1171	Cost: 18.25s
Train Epoch: 77 [61440/90000 (68%)]	Loss: 14.2296	Cost: 8.88s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 14.3034	Cost: 18.97s
Train Epoch: 77 	Average Loss: 14.2451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6064

Learning rate: 0.0001999997074157202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 14.1598	Cost: 67.53s
Train Epoch: 78 [20480/90000 (23%)]	Loss: 14.0655	Cost: 9.88s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 14.1546	Cost: 17.38s
Train Epoch: 78 [61440/90000 (68%)]	Loss: 14.1654	Cost: 8.35s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 14.3680	Cost: 22.03s
Train Epoch: 78 	Average Loss: 14.2074
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5606

Saving model as e78_model.pt & e78_waveforms_supplementary.hdf5
Learning rate: 0.00019999969976678433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 14.2932	Cost: 58.85s
Train Epoch: 79 [20480/90000 (23%)]	Loss: 14.1173	Cost: 8.29s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 14.1715	Cost: 17.19s
Train Epoch: 79 [61440/90000 (68%)]	Loss: 14.2657	Cost: 8.39s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 14.3255	Cost: 7.96s
Train Epoch: 79 	Average Loss: 14.1786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4684

Saving model as e79_model.pt & e79_waveforms_supplementary.hdf5
Learning rate: 0.00019999969201915272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 14.1783	Cost: 64.79s
Train Epoch: 80 [20480/90000 (23%)]	Loss: 14.1139	Cost: 10.13s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 13.9986	Cost: 16.50s
Train Epoch: 80 [61440/90000 (68%)]	Loss: 14.1845	Cost: 8.56s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 14.1253	Cost: 20.87s
Train Epoch: 80 	Average Loss: 14.1461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4837

Learning rate: 0.00019999968417282538
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 14.3164	Cost: 72.96s
Train Epoch: 81 [20480/90000 (23%)]	Loss: 14.0377	Cost: 10.81s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 14.1075	Cost: 15.24s
Train Epoch: 81 [61440/90000 (68%)]	Loss: 14.2065	Cost: 8.13s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 14.0482	Cost: 16.20s
Train Epoch: 81 	Average Loss: 14.1406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4460

Saving model as e81_model.pt & e81_waveforms_supplementary.hdf5
Learning rate: 0.0001999996762278023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 14.1423	Cost: 66.07s
Train Epoch: 82 [20480/90000 (23%)]	Loss: 13.9898	Cost: 10.33s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 13.9386	Cost: 16.08s
Train Epoch: 82 [61440/90000 (68%)]	Loss: 14.1036	Cost: 8.38s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 14.0890	Cost: 20.92s
Train Epoch: 82 	Average Loss: 14.0948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4285

Saving model as e82_model.pt & e82_waveforms_supplementary.hdf5
Learning rate: 0.0001999996681840835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 14.1527	Cost: 63.26s
Train Epoch: 83 [20480/90000 (23%)]	Loss: 14.1181	Cost: 9.79s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 13.9775	Cost: 16.99s
Train Epoch: 83 [61440/90000 (68%)]	Loss: 14.0416	Cost: 8.13s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 13.9635	Cost: 21.50s
Train Epoch: 83 	Average Loss: 14.0411
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4497

Learning rate: 0.00019999966004166902
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 13.9843	Cost: 63.44s
Train Epoch: 84 [20480/90000 (23%)]	Loss: 14.0065	Cost: 9.61s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 13.9437	Cost: 15.16s
Train Epoch: 84 [61440/90000 (68%)]	Loss: 14.0916	Cost: 8.59s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 13.9727	Cost: 18.34s
Train Epoch: 84 	Average Loss: 14.0447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3413

Saving model as e84_model.pt & e84_waveforms_supplementary.hdf5
Learning rate: 0.0001999996518005588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 13.8877	Cost: 67.82s
Train Epoch: 85 [20480/90000 (23%)]	Loss: 14.0524	Cost: 9.66s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 13.8822	Cost: 16.36s
Train Epoch: 85 [61440/90000 (68%)]	Loss: 14.0287	Cost: 8.28s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 14.0397	Cost: 17.61s
Train Epoch: 85 	Average Loss: 13.9914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3167

Saving model as e85_model.pt & e85_waveforms_supplementary.hdf5
Learning rate: 0.00019999964346075288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 13.8733	Cost: 65.00s
Train Epoch: 86 [20480/90000 (23%)]	Loss: 13.9666	Cost: 10.50s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 13.9913	Cost: 15.10s
Train Epoch: 86 [61440/90000 (68%)]	Loss: 13.9270	Cost: 8.17s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 13.7849	Cost: 18.11s
Train Epoch: 86 	Average Loss: 13.9601
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3004

Saving model as e86_model.pt & e86_waveforms_supplementary.hdf5
Learning rate: 0.00019999963502225128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 14.0111	Cost: 66.91s
Train Epoch: 87 [20480/90000 (23%)]	Loss: 14.0322	Cost: 9.26s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 13.8055	Cost: 13.36s
Train Epoch: 87 [61440/90000 (68%)]	Loss: 14.0277	Cost: 8.08s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 13.9915	Cost: 17.70s
Train Epoch: 87 	Average Loss: 13.9579
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.2772

Saving model as e87_model.pt & e87_waveforms_supplementary.hdf5
Learning rate: 0.00019999962648505396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 13.8898	Cost: 63.71s
Train Epoch: 88 [20480/90000 (23%)]	Loss: 13.9624	Cost: 9.59s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 13.6966	Cost: 17.73s
Train Epoch: 88 [61440/90000 (68%)]	Loss: 13.8941	Cost: 8.11s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 13.8499	Cost: 10.76s
Train Epoch: 88 	Average Loss: 13.9076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.2200

Saving model as e88_model.pt & e88_waveforms_supplementary.hdf5
Learning rate: 0.000199999617849161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 13.9094	Cost: 73.62s
Train Epoch: 89 [20480/90000 (23%)]	Loss: 13.9328	Cost: 11.50s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 13.7938	Cost: 15.03s
Train Epoch: 89 [61440/90000 (68%)]	Loss: 13.8766	Cost: 8.14s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 13.8882	Cost: 19.05s
Train Epoch: 89 	Average Loss: 13.8676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.2475

Learning rate: 0.00019999960911457236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 13.9530	Cost: 64.18s
Train Epoch: 90 [20480/90000 (23%)]	Loss: 13.7779	Cost: 11.33s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 13.6042	Cost: 16.46s
Train Epoch: 90 [61440/90000 (68%)]	Loss: 13.9027	Cost: 8.36s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 13.7832	Cost: 17.42s
Train Epoch: 90 	Average Loss: 13.8114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1807

Saving model as e90_model.pt & e90_waveforms_supplementary.hdf5
Learning rate: 0.00019999960028128805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 13.9387	Cost: 70.05s
Train Epoch: 91 [20480/90000 (23%)]	Loss: 13.8682	Cost: 9.95s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 13.6806	Cost: 18.42s
Train Epoch: 91 [61440/90000 (68%)]	Loss: 13.7372	Cost: 10.58s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 13.8045	Cost: 16.02s
Train Epoch: 91 	Average Loss: 13.7862
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1407

Saving model as e91_model.pt & e91_waveforms_supplementary.hdf5
Learning rate: 0.00019999959134930808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 13.9560	Cost: 57.79s
Train Epoch: 92 [20480/90000 (23%)]	Loss: 13.9466	Cost: 10.96s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 13.8118	Cost: 12.84s
Train Epoch: 92 [61440/90000 (68%)]	Loss: 13.6778	Cost: 9.46s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 13.7376	Cost: 16.68s
Train Epoch: 92 	Average Loss: 13.8013
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1275

Saving model as e92_model.pt & e92_waveforms_supplementary.hdf5
Learning rate: 0.0001999995823186325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 13.7950	Cost: 56.23s
Train Epoch: 93 [20480/90000 (23%)]	Loss: 13.7594	Cost: 9.76s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 13.7164	Cost: 17.43s
Train Epoch: 93 [61440/90000 (68%)]	Loss: 13.8385	Cost: 8.26s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 13.7906	Cost: 20.50s
Train Epoch: 93 	Average Loss: 13.7713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0942

Saving model as e93_model.pt & e93_waveforms_supplementary.hdf5
Learning rate: 0.00019999957318926127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 13.7556	Cost: 72.02s
Train Epoch: 94 [20480/90000 (23%)]	Loss: 13.8174	Cost: 9.33s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 13.5958	Cost: 16.74s
Train Epoch: 94 [61440/90000 (68%)]	Loss: 13.7083	Cost: 8.25s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 13.6890	Cost: 19.35s
Train Epoch: 94 	Average Loss: 13.7279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0394

Saving model as e94_model.pt & e94_waveforms_supplementary.hdf5
Learning rate: 0.00019999956396119442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 13.7070	Cost: 72.02s
Train Epoch: 95 [20480/90000 (23%)]	Loss: 13.6392	Cost: 10.66s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 13.6449	Cost: 18.25s
Train Epoch: 95 [61440/90000 (68%)]	Loss: 13.7870	Cost: 8.28s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 13.6244	Cost: 20.53s
Train Epoch: 95 	Average Loss: 13.6793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9662

Saving model as e95_model.pt & e95_waveforms_supplementary.hdf5
Learning rate: 0.00019999955463443194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 13.7667	Cost: 65.22s
Train Epoch: 96 [20480/90000 (23%)]	Loss: 13.7463	Cost: 9.73s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 13.4893	Cost: 17.21s
Train Epoch: 96 [61440/90000 (68%)]	Loss: 13.6829	Cost: 9.79s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 13.6840	Cost: 17.66s
Train Epoch: 96 	Average Loss: 13.6504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9997

Learning rate: 0.00019999954520897388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 13.6623	Cost: 68.51s
Train Epoch: 97 [20480/90000 (23%)]	Loss: 13.5425	Cost: 9.77s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 13.4966	Cost: 15.55s
Train Epoch: 97 [61440/90000 (68%)]	Loss: 13.5468	Cost: 8.00s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 13.7902	Cost: 16.78s
Train Epoch: 97 	Average Loss: 13.6286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9788

Learning rate: 0.00019999953568482025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 13.7438	Cost: 67.71s
Train Epoch: 98 [20480/90000 (23%)]	Loss: 13.6465	Cost: 9.94s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 13.6227	Cost: 17.20s
Train Epoch: 98 [61440/90000 (68%)]	Loss: 13.6175	Cost: 8.26s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 13.6368	Cost: 18.35s
Train Epoch: 98 	Average Loss: 13.6096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9429

Saving model as e98_model.pt & e98_waveforms_supplementary.hdf5
Learning rate: 0.000199999526061971
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 13.5715	Cost: 65.41s
Train Epoch: 99 [20480/90000 (23%)]	Loss: 13.5853	Cost: 10.73s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 13.4980	Cost: 16.06s
Train Epoch: 99 [61440/90000 (68%)]	Loss: 13.6831	Cost: 8.25s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 13.6274	Cost: 13.40s
Train Epoch: 99 	Average Loss: 13.5812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9014

Saving model as e99_model.pt & e99_waveforms_supplementary.hdf5
Learning rate: 0.00019999951634042617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 13.6501	Cost: 65.76s
Train Epoch: 100 [20480/90000 (23%)]	Loss: 13.4120	Cost: 11.11s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 13.4211	Cost: 14.10s
Train Epoch: 100 [61440/90000 (68%)]	Loss: 13.5356	Cost: 7.37s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 13.4879	Cost: 19.55s
Train Epoch: 100 	Average Loss: 13.5285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8586

Saving model as e100_model.pt & e100_waveforms_supplementary.hdf5
Learning rate: 0.00019999950652018581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 13.6159	Cost: 62.27s
Train Epoch: 101 [20480/90000 (23%)]	Loss: 13.4132	Cost: 10.59s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 13.5605	Cost: 16.89s
Train Epoch: 101 [61440/90000 (68%)]	Loss: 13.4985	Cost: 8.75s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 13.5205	Cost: 19.05s
Train Epoch: 101 	Average Loss: 13.5062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8888

Learning rate: 0.00019999949660124986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 13.5949	Cost: 72.41s
Train Epoch: 102 [20480/90000 (23%)]	Loss: 13.5517	Cost: 9.67s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 13.3813	Cost: 18.61s
Train Epoch: 102 [61440/90000 (68%)]	Loss: 13.4630	Cost: 11.06s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 13.5235	Cost: 17.91s
Train Epoch: 102 	Average Loss: 13.4903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8795

Learning rate: 0.00019999948658361836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 13.5714	Cost: 66.49s
Train Epoch: 103 [20480/90000 (23%)]	Loss: 13.4632	Cost: 9.83s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 13.3187	Cost: 16.30s
Train Epoch: 103 [61440/90000 (68%)]	Loss: 13.5669	Cost: 8.83s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 13.4538	Cost: 8.19s
Train Epoch: 103 	Average Loss: 13.4659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8069

Saving model as e103_model.pt & e103_waveforms_supplementary.hdf5
Learning rate: 0.00019999947646729134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 13.3849	Cost: 58.52s
Train Epoch: 104 [20480/90000 (23%)]	Loss: 13.5546	Cost: 9.98s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 13.1971	Cost: 14.15s
Train Epoch: 104 [61440/90000 (68%)]	Loss: 13.3893	Cost: 8.53s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 13.3281	Cost: 18.17s
Train Epoch: 104 	Average Loss: 13.4520
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7832

Saving model as e104_model.pt & e104_waveforms_supplementary.hdf5
Learning rate: 0.00019999946625226878
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 13.3992	Cost: 69.86s
Train Epoch: 105 [20480/90000 (23%)]	Loss: 13.3719	Cost: 9.65s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 13.2998	Cost: 17.82s
Train Epoch: 105 [61440/90000 (68%)]	Loss: 13.4118	Cost: 8.43s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 13.3785	Cost: 19.60s
Train Epoch: 105 	Average Loss: 13.4142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7417

Saving model as e105_model.pt & e105_waveforms_supplementary.hdf5
Learning rate: 0.00019999945593855072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 13.3968	Cost: 68.02s
Train Epoch: 106 [20480/90000 (23%)]	Loss: 13.3463	Cost: 11.21s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 13.3159	Cost: 18.16s
Train Epoch: 106 [61440/90000 (68%)]	Loss: 13.2367	Cost: 8.37s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 13.3219	Cost: 13.97s
Train Epoch: 106 	Average Loss: 13.3859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6980

Saving model as e106_model.pt & e106_waveforms_supplementary.hdf5
Learning rate: 0.00019999944552613714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 13.4204	Cost: 77.04s
Train Epoch: 107 [20480/90000 (23%)]	Loss: 13.3558	Cost: 11.28s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 13.3907	Cost: 19.09s
Train Epoch: 107 [61440/90000 (68%)]	Loss: 13.1587	Cost: 9.11s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 13.4575	Cost: 18.14s
Train Epoch: 107 	Average Loss: 13.3695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7030

Learning rate: 0.00019999943501502806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 13.2775	Cost: 72.52s
Train Epoch: 108 [20480/90000 (23%)]	Loss: 13.2452	Cost: 10.53s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 13.2646	Cost: 14.19s
Train Epoch: 108 [61440/90000 (68%)]	Loss: 13.2108	Cost: 10.66s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 13.3399	Cost: 18.45s
Train Epoch: 108 	Average Loss: 13.3343
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6629

Saving model as e108_model.pt & e108_waveforms_supplementary.hdf5
Learning rate: 0.0001999994244052235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 13.5575	Cost: 68.18s
Train Epoch: 109 [20480/90000 (23%)]	Loss: 13.2737	Cost: 9.59s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 13.3057	Cost: 16.59s
Train Epoch: 109 [61440/90000 (68%)]	Loss: 13.2905	Cost: 8.62s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 13.3717	Cost: 18.16s
Train Epoch: 109 	Average Loss: 13.3131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7211

Learning rate: 0.00019999941369672346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 13.4090	Cost: 67.09s
Train Epoch: 110 [20480/90000 (23%)]	Loss: 13.2164	Cost: 9.77s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 13.2365	Cost: 17.56s
Train Epoch: 110 [61440/90000 (68%)]	Loss: 13.3227	Cost: 8.17s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 13.3610	Cost: 10.76s
Train Epoch: 110 	Average Loss: 13.2851
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6255

Saving model as e110_model.pt & e110_waveforms_supplementary.hdf5
Learning rate: 0.00019999940288952794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 13.2529	Cost: 66.34s
Train Epoch: 111 [20480/90000 (23%)]	Loss: 13.2340	Cost: 10.84s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 13.1503	Cost: 15.28s
Train Epoch: 111 [61440/90000 (68%)]	Loss: 13.3194	Cost: 9.81s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 13.1816	Cost: 17.93s
Train Epoch: 111 	Average Loss: 13.2691
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5472

Saving model as e111_model.pt & e111_waveforms_supplementary.hdf5
Learning rate: 0.000199999391983637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 13.0639	Cost: 70.00s
Train Epoch: 112 [20480/90000 (23%)]	Loss: 13.0991	Cost: 8.67s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 13.2232	Cost: 21.01s
Train Epoch: 112 [61440/90000 (68%)]	Loss: 13.2534	Cost: 9.72s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 13.3846	Cost: 16.36s
Train Epoch: 112 	Average Loss: 13.2560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6296

Learning rate: 0.0001999993809790506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 13.3580	Cost: 55.31s
Train Epoch: 113 [20480/90000 (23%)]	Loss: 13.0976	Cost: 10.44s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 13.1214	Cost: 14.57s
Train Epoch: 113 [61440/90000 (68%)]	Loss: 13.2612	Cost: 7.22s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 13.2364	Cost: 20.42s
Train Epoch: 113 	Average Loss: 13.2201
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6553

Learning rate: 0.00019999936987576873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 13.3845	Cost: 58.23s
Train Epoch: 114 [20480/90000 (23%)]	Loss: 13.0898	Cost: 10.31s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 13.0865	Cost: 16.34s
Train Epoch: 114 [61440/90000 (68%)]	Loss: 13.2689	Cost: 8.54s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 13.1006	Cost: 16.86s
Train Epoch: 114 	Average Loss: 13.1952
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5910

Learning rate: 0.00019999935867379148
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 13.1756	Cost: 71.75s
Train Epoch: 115 [20480/90000 (23%)]	Loss: 13.1459	Cost: 10.04s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 12.9576	Cost: 14.91s
Train Epoch: 115 [61440/90000 (68%)]	Loss: 13.1416	Cost: 8.58s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 13.1506	Cost: 16.96s
Train Epoch: 115 	Average Loss: 13.1732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4675

Saving model as e115_model.pt & e115_waveforms_supplementary.hdf5
Learning rate: 0.00019999934737311882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 13.0837	Cost: 69.81s
Train Epoch: 116 [20480/90000 (23%)]	Loss: 13.1920	Cost: 10.22s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 13.0811	Cost: 15.16s
Train Epoch: 116 [61440/90000 (68%)]	Loss: 13.1324	Cost: 8.30s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 12.9685	Cost: 17.60s
Train Epoch: 116 	Average Loss: 13.1565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5233

Learning rate: 0.00019999933597375074
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 13.2129	Cost: 69.64s
Train Epoch: 117 [20480/90000 (23%)]	Loss: 13.2072	Cost: 10.16s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 13.0564	Cost: 17.48s
Train Epoch: 117 [61440/90000 (68%)]	Loss: 13.0904	Cost: 9.75s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 13.0343	Cost: 18.72s
Train Epoch: 117 	Average Loss: 13.1378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4893

Learning rate: 0.0001999993244756873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 13.1696	Cost: 55.34s
Train Epoch: 118 [20480/90000 (23%)]	Loss: 13.0290	Cost: 9.78s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 13.0950	Cost: 16.36s
Train Epoch: 118 [61440/90000 (68%)]	Loss: 13.1057	Cost: 8.31s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 12.9303	Cost: 10.11s
Train Epoch: 118 	Average Loss: 13.0889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4540

Saving model as e118_model.pt & e118_waveforms_supplementary.hdf5
Learning rate: 0.00019999931287892846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 13.2114	Cost: 72.12s
Train Epoch: 119 [20480/90000 (23%)]	Loss: 12.9804	Cost: 9.06s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 12.8741	Cost: 17.68s
Train Epoch: 119 [61440/90000 (68%)]	Loss: 13.2232	Cost: 8.37s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 12.9691	Cost: 19.40s
Train Epoch: 119 	Average Loss: 13.0577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4101

Saving model as e119_model.pt & e119_waveforms_supplementary.hdf5
Learning rate: 0.00019999930118347426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 13.1230	Cost: 71.34s
Train Epoch: 120 [20480/90000 (23%)]	Loss: 12.9402	Cost: 12.39s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 12.9729	Cost: 15.27s
Train Epoch: 120 [61440/90000 (68%)]	Loss: 12.9628	Cost: 8.46s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 13.0289	Cost: 10.21s
Train Epoch: 120 	Average Loss: 13.0688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3892

Saving model as e120_model.pt & e120_waveforms_supplementary.hdf5
Learning rate: 0.0001999992893893247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 12.9169	Cost: 61.44s
Train Epoch: 121 [20480/90000 (23%)]	Loss: 13.0823	Cost: 11.16s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 12.8229	Cost: 19.99s
Train Epoch: 121 [61440/90000 (68%)]	Loss: 13.2210	Cost: 8.72s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 13.0803	Cost: 18.74s
Train Epoch: 121 	Average Loss: 13.0468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4532

Learning rate: 0.0001999992774964798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 13.2490	Cost: 68.87s
Train Epoch: 122 [20480/90000 (23%)]	Loss: 13.0099	Cost: 10.90s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 12.9449	Cost: 13.61s
Train Epoch: 122 [61440/90000 (68%)]	Loss: 12.8793	Cost: 10.74s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 13.0979	Cost: 16.87s
Train Epoch: 122 	Average Loss: 13.0311
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3920

Learning rate: 0.00019999926550493962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 13.1262	Cost: 68.62s
Train Epoch: 123 [20480/90000 (23%)]	Loss: 12.9716	Cost: 9.03s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 12.8951	Cost: 17.62s
Train Epoch: 123 [61440/90000 (68%)]	Loss: 12.9151	Cost: 8.29s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 13.0455	Cost: 20.25s
Train Epoch: 123 	Average Loss: 13.0189
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3918

Learning rate: 0.00019999925341470404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 12.9912	Cost: 72.00s
Train Epoch: 124 [20480/90000 (23%)]	Loss: 12.9611	Cost: 8.97s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 12.9353	Cost: 19.54s
Train Epoch: 124 [61440/90000 (68%)]	Loss: 12.8529	Cost: 8.68s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 12.9452	Cost: 20.18s
Train Epoch: 124 	Average Loss: 12.9480
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3946

Learning rate: 0.0001999992412257732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 13.0681	Cost: 68.95s
Train Epoch: 125 [20480/90000 (23%)]	Loss: 13.1143	Cost: 8.57s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 12.8536	Cost: 15.68s
Train Epoch: 125 [61440/90000 (68%)]	Loss: 12.7928	Cost: 8.37s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 12.9840	Cost: 16.96s
Train Epoch: 125 	Average Loss: 12.9375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2952

Saving model as e125_model.pt & e125_waveforms_supplementary.hdf5
Learning rate: 0.00019999922893814705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 13.0818	Cost: 68.40s
Train Epoch: 126 [20480/90000 (23%)]	Loss: 12.8384	Cost: 13.80s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 12.9544	Cost: 15.50s
Train Epoch: 126 [61440/90000 (68%)]	Loss: 12.9935	Cost: 9.08s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 12.8669	Cost: 16.40s
Train Epoch: 126 	Average Loss: 12.9166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3038

Learning rate: 0.00019999921655182562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 12.9383	Cost: 62.86s
Train Epoch: 127 [20480/90000 (23%)]	Loss: 12.8574	Cost: 10.22s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 12.8700	Cost: 15.20s
Train Epoch: 127 [61440/90000 (68%)]	Loss: 12.7957	Cost: 10.01s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 12.9166	Cost: 12.61s
Train Epoch: 127 	Average Loss: 12.9288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3222

Learning rate: 0.0001999992040668089
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 12.9591	Cost: 24.35s
Train Epoch: 128 [20480/90000 (23%)]	Loss: 12.9681	Cost: 6.01s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 12.8804	Cost: 6.82s
Train Epoch: 128 [61440/90000 (68%)]	Loss: 12.9145	Cost: 5.75s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 12.9227	Cost: 5.81s
Train Epoch: 128 	Average Loss: 12.8878
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2256

Saving model as e128_model.pt & e128_waveforms_supplementary.hdf5
Learning rate: 0.00019999919148309698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 12.9153	Cost: 24.24s
Train Epoch: 129 [20480/90000 (23%)]	Loss: 12.7766	Cost: 6.05s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 12.8714	Cost: 6.79s
Train Epoch: 129 [61440/90000 (68%)]	Loss: 12.8157	Cost: 5.92s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 12.7724	Cost: 6.33s
Train Epoch: 129 	Average Loss: 12.8631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2320

Learning rate: 0.00019999917880068977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 12.9605	Cost: 24.88s
Train Epoch: 130 [20480/90000 (23%)]	Loss: 12.8009	Cost: 6.04s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 12.7558	Cost: 6.93s
Train Epoch: 130 [61440/90000 (68%)]	Loss: 12.8019	Cost: 6.14s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 12.8087	Cost: 5.80s
Train Epoch: 130 	Average Loss: 12.8580
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1932

Saving model as e130_model.pt & e130_waveforms_supplementary.hdf5
Learning rate: 0.00019999916601958734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 12.8803	Cost: 28.20s
Train Epoch: 131 [20480/90000 (23%)]	Loss: 12.8336	Cost: 6.07s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 12.7924	Cost: 6.84s
Train Epoch: 131 [61440/90000 (68%)]	Loss: 12.8011	Cost: 5.92s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 12.7426	Cost: 5.81s
Train Epoch: 131 	Average Loss: 12.8191
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1283

Saving model as e131_model.pt & e131_waveforms_supplementary.hdf5
Learning rate: 0.00019999915313978966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 12.7672	Cost: 24.99s
Train Epoch: 132 [20480/90000 (23%)]	Loss: 12.8461	Cost: 6.02s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 12.7325	Cost: 8.18s
Train Epoch: 132 [61440/90000 (68%)]	Loss: 12.7438	Cost: 5.90s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 12.8640	Cost: 8.94s
Train Epoch: 132 	Average Loss: 12.8161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1688

Learning rate: 0.00019999914016129682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 12.7587	Cost: 23.73s
Train Epoch: 133 [20480/90000 (23%)]	Loss: 12.8403	Cost: 6.01s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 12.6696	Cost: 6.65s
Train Epoch: 133 [61440/90000 (68%)]	Loss: 12.8348	Cost: 6.05s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 12.8056	Cost: 8.92s
Train Epoch: 133 	Average Loss: 12.7998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1119

Saving model as e133_model.pt & e133_waveforms_supplementary.hdf5
Learning rate: 0.00019999912708410875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 12.7376	Cost: 24.01s
Train Epoch: 134 [20480/90000 (23%)]	Loss: 12.7601	Cost: 6.18s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 12.6575	Cost: 6.89s
Train Epoch: 134 [61440/90000 (68%)]	Loss: 12.7443	Cost: 5.86s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 12.8044	Cost: 5.85s
Train Epoch: 134 	Average Loss: 12.7810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1713

Learning rate: 0.00019999911390822548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 12.8225	Cost: 22.89s
Train Epoch: 135 [20480/90000 (23%)]	Loss: 12.8615	Cost: 6.06s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 12.7502	Cost: 7.38s
Train Epoch: 135 [61440/90000 (68%)]	Loss: 12.8260	Cost: 6.31s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 12.7492	Cost: 6.44s
Train Epoch: 135 	Average Loss: 12.7889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1333

Learning rate: 0.00019999910063364705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 12.6803	Cost: 25.07s
Train Epoch: 136 [20480/90000 (23%)]	Loss: 12.7267	Cost: 6.00s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 12.7005	Cost: 7.02s
Train Epoch: 136 [61440/90000 (68%)]	Loss: 12.9512	Cost: 6.01s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 12.6783	Cost: 6.10s
Train Epoch: 136 	Average Loss: 12.7353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0995

Saving model as e136_model.pt & e136_waveforms_supplementary.hdf5
Learning rate: 0.00019999908726037348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 12.7774	Cost: 28.91s
Train Epoch: 137 [20480/90000 (23%)]	Loss: 12.6978	Cost: 6.10s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 12.7687	Cost: 7.88s
Train Epoch: 137 [61440/90000 (68%)]	Loss: 12.6327	Cost: 5.86s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 12.5761	Cost: 6.42s
Train Epoch: 137 	Average Loss: 12.6998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0624

Saving model as e137_model.pt & e137_waveforms_supplementary.hdf5
Learning rate: 0.00019999907378840477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 12.8534	Cost: 25.71s
Train Epoch: 138 [20480/90000 (23%)]	Loss: 12.6911	Cost: 6.00s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 12.6378	Cost: 8.30s
Train Epoch: 138 [61440/90000 (68%)]	Loss: 12.6899	Cost: 5.93s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 12.6379	Cost: 8.34s
Train Epoch: 138 	Average Loss: 12.7062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0869

Learning rate: 0.00019999906021774094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 12.5934	Cost: 23.91s
Train Epoch: 139 [20480/90000 (23%)]	Loss: 12.8016	Cost: 6.08s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 12.6167	Cost: 6.62s
Train Epoch: 139 [61440/90000 (68%)]	Loss: 12.4921	Cost: 6.06s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 12.5847	Cost: 8.50s
Train Epoch: 139 	Average Loss: 12.6619
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0065

Saving model as e139_model.pt & e139_waveforms_supplementary.hdf5
Learning rate: 0.00019999904654838195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 12.6479	Cost: 24.05s
Train Epoch: 140 [20480/90000 (23%)]	Loss: 12.6572	Cost: 5.88s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 12.5191	Cost: 7.44s
Train Epoch: 140 [61440/90000 (68%)]	Loss: 12.5084	Cost: 5.99s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 12.5568	Cost: 5.71s
Train Epoch: 140 	Average Loss: 12.6501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0330

Learning rate: 0.0001999990327803279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 12.8147	Cost: 22.81s
Train Epoch: 141 [20480/90000 (23%)]	Loss: 12.5927	Cost: 5.98s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 12.4931	Cost: 7.17s
Train Epoch: 141 [61440/90000 (68%)]	Loss: 12.5708	Cost: 6.37s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 12.7573	Cost: 6.22s
Train Epoch: 141 	Average Loss: 12.6463
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9966

Saving model as e141_model.pt & e141_waveforms_supplementary.hdf5
Learning rate: 0.00019999901891357876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 12.6736	Cost: 25.67s
Train Epoch: 142 [20480/90000 (23%)]	Loss: 12.4847	Cost: 5.99s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 12.6259	Cost: 7.19s
Train Epoch: 142 [61440/90000 (68%)]	Loss: 12.5940	Cost: 5.91s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 12.6128	Cost: 6.00s
Train Epoch: 142 	Average Loss: 12.6215
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9596

Saving model as e142_model.pt & e142_waveforms_supplementary.hdf5
Learning rate: 0.0001999990049481345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 12.6740	Cost: 29.13s
Train Epoch: 143 [20480/90000 (23%)]	Loss: 12.5695	Cost: 6.12s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 12.4991	Cost: 6.88s
Train Epoch: 143 [61440/90000 (68%)]	Loss: 12.6009	Cost: 5.93s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 12.5560	Cost: 5.72s
Train Epoch: 143 	Average Loss: 12.6115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9646

Learning rate: 0.00019999899088399522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 12.6481	Cost: 24.72s
Train Epoch: 144 [20480/90000 (23%)]	Loss: 12.4933	Cost: 6.16s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 12.5830	Cost: 8.14s
Train Epoch: 144 [61440/90000 (68%)]	Loss: 12.5663	Cost: 5.90s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 12.7109	Cost: 8.60s
Train Epoch: 144 	Average Loss: 12.5991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0159

Learning rate: 0.0001999989767211609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 12.5033	Cost: 23.40s
Train Epoch: 145 [20480/90000 (23%)]	Loss: 12.5769	Cost: 6.16s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 12.4489	Cost: 6.38s
Train Epoch: 145 [61440/90000 (68%)]	Loss: 12.6181	Cost: 6.12s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 12.5539	Cost: 6.61s
Train Epoch: 145 	Average Loss: 12.5957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9423

Saving model as e145_model.pt & e145_waveforms_supplementary.hdf5
Learning rate: 0.00019999896245963153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 12.8463	Cost: 23.67s
Train Epoch: 146 [20480/90000 (23%)]	Loss: 12.6704	Cost: 6.44s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 12.5563	Cost: 6.54s
Train Epoch: 146 [61440/90000 (68%)]	Loss: 12.4942	Cost: 5.96s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 12.5523	Cost: 5.72s
Train Epoch: 146 	Average Loss: 12.5858
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9896

Learning rate: 0.00019999894809940715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 12.7429	Cost: 23.46s
Train Epoch: 147 [20480/90000 (23%)]	Loss: 12.5666	Cost: 6.22s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 12.4902	Cost: 6.27s
Train Epoch: 147 [61440/90000 (68%)]	Loss: 12.4965	Cost: 6.15s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 12.5558	Cost: 5.72s
Train Epoch: 147 	Average Loss: 12.5625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9450

Learning rate: 0.00019999893364048776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 12.6353	Cost: 28.63s
Train Epoch: 148 [20480/90000 (23%)]	Loss: 12.4945	Cost: 6.00s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 12.6338	Cost: 6.83s
Train Epoch: 148 [61440/90000 (68%)]	Loss: 12.4813	Cost: 5.95s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 12.5097	Cost: 5.75s
Train Epoch: 148 	Average Loss: 12.5281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8866

Saving model as e148_model.pt & e148_waveforms_supplementary.hdf5
Learning rate: 0.00019999891908287334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 12.5410	Cost: 26.15s
Train Epoch: 149 [20480/90000 (23%)]	Loss: 12.6126	Cost: 5.99s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 12.3886	Cost: 8.04s
Train Epoch: 149 [61440/90000 (68%)]	Loss: 12.4268	Cost: 5.87s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 12.4175	Cost: 7.61s
Train Epoch: 149 	Average Loss: 12.4928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8866

Saving model as e149_model.pt & e149_waveforms_supplementary.hdf5
Learning rate: 0.00019999890442656397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 12.5411	Cost: 22.77s
Train Epoch: 150 [20480/90000 (23%)]	Loss: 12.3751	Cost: 5.94s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 12.4816	Cost: 6.56s
Train Epoch: 150 [61440/90000 (68%)]	Loss: 12.4255	Cost: 5.97s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 12.6628	Cost: 8.45s
Train Epoch: 150 	Average Loss: 12.4636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8125

Saving model as e150_model.pt & e150_waveforms_supplementary.hdf5
Learning rate: 0.00019999888967155965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 12.4759	Cost: 24.14s
Train Epoch: 151 [20480/90000 (23%)]	Loss: 12.4941	Cost: 5.85s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 12.3786	Cost: 7.16s
Train Epoch: 151 [61440/90000 (68%)]	Loss: 12.3667	Cost: 5.75s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 12.5977	Cost: 6.02s
Train Epoch: 151 	Average Loss: 12.4919
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8687

Learning rate: 0.00019999887481786036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 12.5666	Cost: 23.80s
Train Epoch: 152 [20480/90000 (23%)]	Loss: 12.3741	Cost: 5.87s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 12.3941	Cost: 7.33s
Train Epoch: 152 [61440/90000 (68%)]	Loss: 12.3518	Cost: 5.76s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 12.4789	Cost: 8.32s
Train Epoch: 152 	Average Loss: 12.4636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8184

Learning rate: 0.00019999885986546616
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 12.3143	Cost: 26.74s
Train Epoch: 153 [20480/90000 (23%)]	Loss: 12.4198	Cost: 5.94s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 12.5108	Cost: 6.38s
Train Epoch: 153 [61440/90000 (68%)]	Loss: 12.6030	Cost: 6.04s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 12.5301	Cost: 6.22s
Train Epoch: 153 	Average Loss: 12.4847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8229

Learning rate: 0.00019999884481437704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 12.5657	Cost: 24.35s
Train Epoch: 154 [20480/90000 (23%)]	Loss: 12.3253	Cost: 6.03s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 12.3774	Cost: 7.89s
Train Epoch: 154 [61440/90000 (68%)]	Loss: 12.2331	Cost: 6.03s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 12.4436	Cost: 7.60s
Train Epoch: 154 	Average Loss: 12.4273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8830

Learning rate: 0.000199998829664593
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 12.5639	Cost: 23.03s
Train Epoch: 155 [20480/90000 (23%)]	Loss: 12.3488	Cost: 6.09s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 12.2925	Cost: 6.39s
Train Epoch: 155 [61440/90000 (68%)]	Loss: 12.4115	Cost: 6.00s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 12.5289	Cost: 9.11s
Train Epoch: 155 	Average Loss: 12.4218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7586

Saving model as e155_model.pt & e155_waveforms_supplementary.hdf5
Learning rate: 0.00019999881441611406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 12.4486	Cost: 24.14s
Train Epoch: 156 [20480/90000 (23%)]	Loss: 12.3654	Cost: 6.15s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 12.3060	Cost: 6.95s
Train Epoch: 156 [61440/90000 (68%)]	Loss: 12.2689	Cost: 5.83s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 12.5639	Cost: 6.27s
Train Epoch: 156 	Average Loss: 12.4038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7994

Learning rate: 0.00019999879906894028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 12.4465	Cost: 24.97s
Train Epoch: 157 [20480/90000 (23%)]	Loss: 12.4594	Cost: 6.29s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 12.3194	Cost: 6.80s
Train Epoch: 157 [61440/90000 (68%)]	Loss: 12.3077	Cost: 6.26s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 12.3356	Cost: 6.00s
Train Epoch: 157 	Average Loss: 12.3821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7966

Learning rate: 0.00019999878362307163
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 12.5014	Cost: 26.90s
Train Epoch: 158 [20480/90000 (23%)]	Loss: 12.2602	Cost: 6.06s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 12.2302	Cost: 6.47s
Train Epoch: 158 [61440/90000 (68%)]	Loss: 12.3239	Cost: 6.21s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 12.4840	Cost: 5.82s
Train Epoch: 158 	Average Loss: 12.3647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7091

Saving model as e158_model.pt & e158_waveforms_supplementary.hdf5
Learning rate: 0.0001999987680785081
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 12.4494	Cost: 23.37s
Train Epoch: 159 [20480/90000 (23%)]	Loss: 12.2346	Cost: 6.01s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 12.1657	Cost: 7.69s
Train Epoch: 159 [61440/90000 (68%)]	Loss: 12.1822	Cost: 6.05s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 12.3764	Cost: 7.04s
Train Epoch: 159 	Average Loss: 12.3650
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7263

Learning rate: 0.00019999875243524977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 12.4069	Cost: 23.15s
Train Epoch: 160 [20480/90000 (23%)]	Loss: 12.2703	Cost: 6.04s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 12.2669	Cost: 6.85s
Train Epoch: 160 [61440/90000 (68%)]	Loss: 12.3190	Cost: 6.09s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 12.3029	Cost: 8.43s
Train Epoch: 160 	Average Loss: 12.3493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7509

Learning rate: 0.00019999873669329665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 12.4827	Cost: 23.66s
Train Epoch: 161 [20480/90000 (23%)]	Loss: 12.2958	Cost: 6.21s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 12.2948	Cost: 6.81s
Train Epoch: 161 [61440/90000 (68%)]	Loss: 12.2820	Cost: 5.98s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 12.3785	Cost: 5.96s
Train Epoch: 161 	Average Loss: 12.3239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6504

Saving model as e161_model.pt & e161_waveforms_supplementary.hdf5
Learning rate: 0.0001999987208526487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 12.2539	Cost: 23.22s
Train Epoch: 162 [20480/90000 (23%)]	Loss: 12.3756	Cost: 6.17s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 12.2179	Cost: 7.44s
Train Epoch: 162 [61440/90000 (68%)]	Loss: 12.2390	Cost: 5.92s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 12.4115	Cost: 6.71s
Train Epoch: 162 	Average Loss: 12.3229
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6924

Learning rate: 0.000199998704913306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 12.3357	Cost: 27.46s
Train Epoch: 163 [20480/90000 (23%)]	Loss: 12.3171	Cost: 6.11s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 12.1857	Cost: 7.49s
Train Epoch: 163 [61440/90000 (68%)]	Loss: 12.2522	Cost: 5.89s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 12.2967	Cost: 5.87s
Train Epoch: 163 	Average Loss: 12.3052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7259

Learning rate: 0.00019999868887526852
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 12.4600	Cost: 29.07s
Train Epoch: 164 [20480/90000 (23%)]	Loss: 12.2326	Cost: 6.23s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 12.0433	Cost: 7.24s
Train Epoch: 164 [61440/90000 (68%)]	Loss: 12.3015	Cost: 6.17s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 12.3067	Cost: 6.60s
Train Epoch: 164 	Average Loss: 12.2414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6799

Learning rate: 0.0001999986727385363
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 12.2819	Cost: 23.03s
Train Epoch: 165 [20480/90000 (23%)]	Loss: 12.3198	Cost: 5.98s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 12.1422	Cost: 6.99s
Train Epoch: 165 [61440/90000 (68%)]	Loss: 12.2617	Cost: 5.98s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 12.1050	Cost: 8.26s
Train Epoch: 165 	Average Loss: 12.2605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6655

Learning rate: 0.0001999986565031093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 12.3735	Cost: 24.07s
Train Epoch: 166 [20480/90000 (23%)]	Loss: 12.2830	Cost: 6.15s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 12.1081	Cost: 6.75s
Train Epoch: 166 [61440/90000 (68%)]	Loss: 12.1243	Cost: 5.92s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 12.3089	Cost: 5.81s
Train Epoch: 166 	Average Loss: 12.2501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7041

Learning rate: 0.00019999864016898762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 12.4495	Cost: 23.75s
Train Epoch: 167 [20480/90000 (23%)]	Loss: 12.2791	Cost: 6.04s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 12.2008	Cost: 7.51s
Train Epoch: 167 [61440/90000 (68%)]	Loss: 12.1580	Cost: 6.14s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 12.0856	Cost: 6.32s
Train Epoch: 167 	Average Loss: 12.2345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7015

Learning rate: 0.00019999862373617122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 12.1951	Cost: 25.48s
Train Epoch: 168 [20480/90000 (23%)]	Loss: 12.2691	Cost: 6.10s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 12.0303	Cost: 6.72s
Train Epoch: 168 [61440/90000 (68%)]	Loss: 12.1227	Cost: 6.15s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 12.1648	Cost: 5.71s
Train Epoch: 168 	Average Loss: 12.2128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6220

Saving model as e168_model.pt & e168_waveforms_supplementary.hdf5
Learning rate: 0.00019999860720466015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 12.2562	Cost: 29.14s
Train Epoch: 169 [20480/90000 (23%)]	Loss: 11.9758	Cost: 6.15s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 12.0093	Cost: 6.84s
Train Epoch: 169 [61440/90000 (68%)]	Loss: 12.1951	Cost: 5.88s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 12.1353	Cost: 6.35s
Train Epoch: 169 	Average Loss: 12.1873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6028

Saving model as e169_model.pt & e169_waveforms_supplementary.hdf5
Learning rate: 0.0001999985905744544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 12.2178	Cost: 27.90s
Train Epoch: 170 [20480/90000 (23%)]	Loss: 12.2152	Cost: 6.14s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 12.1901	Cost: 7.02s
Train Epoch: 170 [61440/90000 (68%)]	Loss: 12.2794	Cost: 5.99s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 12.2059	Cost: 6.73s
Train Epoch: 170 	Average Loss: 12.2100
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6430

Learning rate: 0.000199998573845554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 12.3427	Cost: 23.97s
Train Epoch: 171 [20480/90000 (23%)]	Loss: 12.2408	Cost: 6.10s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 12.0696	Cost: 8.02s
Train Epoch: 171 [61440/90000 (68%)]	Loss: 12.2298	Cost: 5.97s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 12.1581	Cost: 8.57s
Train Epoch: 171 	Average Loss: 12.1555
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5694

Saving model as e171_model.pt & e171_waveforms_supplementary.hdf5
Learning rate: 0.00019999855701795897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 12.1920	Cost: 23.40s
Train Epoch: 172 [20480/90000 (23%)]	Loss: 12.1811	Cost: 5.97s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 12.1876	Cost: 6.61s
Train Epoch: 172 [61440/90000 (68%)]	Loss: 12.1249	Cost: 6.16s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 12.1182	Cost: 6.00s
Train Epoch: 172 	Average Loss: 12.1701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5673

Saving model as e172_model.pt & e172_waveforms_supplementary.hdf5
Learning rate: 0.00019999854009166934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 12.1530	Cost: 24.22s
Train Epoch: 173 [20480/90000 (23%)]	Loss: 12.1079	Cost: 6.04s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 12.0657	Cost: 6.76s
Train Epoch: 173 [61440/90000 (68%)]	Loss: 12.1037	Cost: 6.09s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 12.1067	Cost: 5.72s
Train Epoch: 173 	Average Loss: 12.1618
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5618

Saving model as e173_model.pt & e173_waveforms_supplementary.hdf5
Learning rate: 0.00019999852306668508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 12.2089	Cost: 25.92s
Train Epoch: 174 [20480/90000 (23%)]	Loss: 12.1526	Cost: 5.96s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 12.0375	Cost: 7.40s
Train Epoch: 174 [61440/90000 (68%)]	Loss: 12.1201	Cost: 6.05s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 12.1403	Cost: 7.33s
Train Epoch: 174 	Average Loss: 12.1428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5178

Saving model as e174_model.pt & e174_waveforms_supplementary.hdf5
Learning rate: 0.00019999850594300622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 12.1974	Cost: 27.34s
Train Epoch: 175 [20480/90000 (23%)]	Loss: 12.2494	Cost: 6.15s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 12.0392	Cost: 6.69s
Train Epoch: 175 [61440/90000 (68%)]	Loss: 12.0395	Cost: 5.90s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 12.2014	Cost: 5.76s
Train Epoch: 175 	Average Loss: 12.1626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4772

Saving model as e175_model.pt & e175_waveforms_supplementary.hdf5
Learning rate: 0.00019999848872063282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 12.2152	Cost: 29.47s
Train Epoch: 176 [20480/90000 (23%)]	Loss: 12.1176	Cost: 6.06s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 11.9747	Cost: 9.35s
Train Epoch: 176 [61440/90000 (68%)]	Loss: 11.9594	Cost: 5.93s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 12.2161	Cost: 6.83s
Train Epoch: 176 	Average Loss: 12.1260
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5355

Learning rate: 0.00019999847139956484
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 12.2782	Cost: 22.87s
Train Epoch: 177 [20480/90000 (23%)]	Loss: 12.0632	Cost: 6.00s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 12.0323	Cost: 7.59s
Train Epoch: 177 [61440/90000 (68%)]	Loss: 12.0039	Cost: 5.98s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 12.0874	Cost: 8.34s
Train Epoch: 177 	Average Loss: 12.1179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4910

Learning rate: 0.00019999845397980232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 12.2611	Cost: 23.28s
Train Epoch: 178 [20480/90000 (23%)]	Loss: 12.0845	Cost: 6.00s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 12.0487	Cost: 6.37s
Train Epoch: 178 [61440/90000 (68%)]	Loss: 11.9953	Cost: 6.22s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 12.0735	Cost: 8.11s
Train Epoch: 178 	Average Loss: 12.1294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4653

Saving model as e178_model.pt & e178_waveforms_supplementary.hdf5
Learning rate: 0.00019999843646134532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 12.0408	Cost: 23.00s
Train Epoch: 179 [20480/90000 (23%)]	Loss: 12.1832	Cost: 6.02s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 12.0194	Cost: 6.94s
Train Epoch: 179 [61440/90000 (68%)]	Loss: 11.8123	Cost: 5.83s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 12.1130	Cost: 6.11s
Train Epoch: 179 	Average Loss: 12.0762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4918

Learning rate: 0.00019999841884419376
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 12.1781	Cost: 24.81s
Train Epoch: 180 [20480/90000 (23%)]	Loss: 12.1859	Cost: 5.85s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 12.0197	Cost: 6.82s
Train Epoch: 180 [61440/90000 (68%)]	Loss: 11.8541	Cost: 5.84s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 12.0434	Cost: 6.87s
Train Epoch: 180 	Average Loss: 12.0890
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4927

Learning rate: 0.00019999840112834775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 12.1954	Cost: 28.29s
Train Epoch: 181 [20480/90000 (23%)]	Loss: 11.9408	Cost: 5.94s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 12.0838	Cost: 6.98s
Train Epoch: 181 [61440/90000 (68%)]	Loss: 12.0876	Cost: 6.06s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 12.0134	Cost: 6.23s
Train Epoch: 181 	Average Loss: 12.0745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4527

Saving model as e181_model.pt & e181_waveforms_supplementary.hdf5
Learning rate: 0.00019999838331380727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 12.0012	Cost: 26.51s
Train Epoch: 182 [20480/90000 (23%)]	Loss: 12.0087	Cost: 5.96s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 11.9223	Cost: 7.81s
Train Epoch: 182 [61440/90000 (68%)]	Loss: 11.9620	Cost: 5.87s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 11.9679	Cost: 7.08s
Train Epoch: 182 	Average Loss: 12.0536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4719

Learning rate: 0.00019999836540057235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 12.0697	Cost: 22.62s
Train Epoch: 183 [20480/90000 (23%)]	Loss: 12.0899	Cost: 5.86s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 11.8630	Cost: 6.76s
Train Epoch: 183 [61440/90000 (68%)]	Loss: 12.0303	Cost: 6.00s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 12.0799	Cost: 8.85s
Train Epoch: 183 	Average Loss: 12.0348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3988

Saving model as e183_model.pt & e183_waveforms_supplementary.hdf5
Learning rate: 0.000199998347388643
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 12.0818	Cost: 23.40s
Train Epoch: 184 [20480/90000 (23%)]	Loss: 12.0738	Cost: 6.23s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 11.9351	Cost: 6.83s
Train Epoch: 184 [61440/90000 (68%)]	Loss: 11.9046	Cost: 6.05s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 11.9011	Cost: 5.71s
Train Epoch: 184 	Average Loss: 12.0163
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4973

Learning rate: 0.00019999832927801924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 12.3031	Cost: 22.46s
Train Epoch: 185 [20480/90000 (23%)]	Loss: 11.9994	Cost: 6.02s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 11.9992	Cost: 7.42s
Train Epoch: 185 [61440/90000 (68%)]	Loss: 11.8905	Cost: 5.91s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 11.9544	Cost: 6.67s
Train Epoch: 185 	Average Loss: 11.9990
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4746

Learning rate: 0.00019999831106870108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 12.1471	Cost: 26.68s
Train Epoch: 186 [20480/90000 (23%)]	Loss: 11.9606	Cost: 5.97s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 11.8168	Cost: 6.97s
Train Epoch: 186 [61440/90000 (68%)]	Loss: 11.9439	Cost: 5.89s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 12.0699	Cost: 5.92s
Train Epoch: 186 	Average Loss: 11.9817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3470

Saving model as e186_model.pt & e186_waveforms_supplementary.hdf5
Learning rate: 0.00019999829276068855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 12.0302	Cost: 28.91s
Train Epoch: 187 [20480/90000 (23%)]	Loss: 11.9483	Cost: 6.08s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 11.9070	Cost: 7.20s
Train Epoch: 187 [61440/90000 (68%)]	Loss: 12.0033	Cost: 6.10s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 12.0117	Cost: 6.69s
Train Epoch: 187 	Average Loss: 12.0053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3885

Learning rate: 0.00019999827435398168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 12.0933	Cost: 24.16s
Train Epoch: 188 [20480/90000 (23%)]	Loss: 11.8996	Cost: 6.04s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 11.9095	Cost: 6.49s
Train Epoch: 188 [61440/90000 (68%)]	Loss: 12.0583	Cost: 5.98s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 11.9274	Cost: 8.27s
Train Epoch: 188 	Average Loss: 11.9679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3734

Learning rate: 0.00019999825584858045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 11.9512	Cost: 23.89s
Train Epoch: 189 [20480/90000 (23%)]	Loss: 12.0030	Cost: 6.17s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 11.9199	Cost: 7.24s
Train Epoch: 189 [61440/90000 (68%)]	Loss: 11.9383	Cost: 5.86s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 11.8952	Cost: 5.77s
Train Epoch: 189 	Average Loss: 11.9419
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3482

Learning rate: 0.00019999823724448486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 12.0891	Cost: 23.41s
Train Epoch: 190 [20480/90000 (23%)]	Loss: 11.9414	Cost: 6.33s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 11.8298	Cost: 6.71s
Train Epoch: 190 [61440/90000 (68%)]	Loss: 11.8880	Cost: 6.01s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 11.8746	Cost: 5.75s
Train Epoch: 190 	Average Loss: 11.9559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3340

Saving model as e190_model.pt & e190_waveforms_supplementary.hdf5
Learning rate: 0.000199998218541695
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 12.1904	Cost: 25.07s
Train Epoch: 191 [20480/90000 (23%)]	Loss: 11.9475	Cost: 6.12s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 11.7372	Cost: 6.75s
Train Epoch: 191 [61440/90000 (68%)]	Loss: 11.9767	Cost: 5.98s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 11.9058	Cost: 5.91s
Train Epoch: 191 	Average Loss: 11.9490
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3431

Learning rate: 0.00019999819974021087
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 11.8001	Cost: 27.65s
Train Epoch: 192 [20480/90000 (23%)]	Loss: 11.8084	Cost: 6.11s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 11.7047	Cost: 8.32s
Train Epoch: 192 [61440/90000 (68%)]	Loss: 11.9540	Cost: 5.96s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 11.6849	Cost: 7.26s
Train Epoch: 192 	Average Loss: 11.9204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3789

Learning rate: 0.00019999818084003246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 11.9527	Cost: 24.20s
Train Epoch: 193 [20480/90000 (23%)]	Loss: 11.9010	Cost: 6.02s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 11.8193	Cost: 7.94s
Train Epoch: 193 [61440/90000 (68%)]	Loss: 11.8855	Cost: 5.95s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 11.9811	Cost: 8.67s
Train Epoch: 193 	Average Loss: 11.9232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2869

Saving model as e193_model.pt & e193_waveforms_supplementary.hdf5
Learning rate: 0.00019999816184115978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 12.2448	Cost: 23.39s
Train Epoch: 194 [20480/90000 (23%)]	Loss: 11.7687	Cost: 5.95s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 11.7732	Cost: 6.28s
Train Epoch: 194 [61440/90000 (68%)]	Loss: 11.9042	Cost: 5.79s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 11.7110	Cost: 5.65s
Train Epoch: 194 	Average Loss: 11.9072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3517

Learning rate: 0.00019999814274359288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 12.0170	Cost: 23.01s
Train Epoch: 195 [20480/90000 (23%)]	Loss: 11.6775	Cost: 5.94s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 11.7334	Cost: 7.95s
Train Epoch: 195 [61440/90000 (68%)]	Loss: 11.8509	Cost: 5.94s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 11.9866	Cost: 6.09s
Train Epoch: 195 	Average Loss: 11.8745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3010

Learning rate: 0.00019999812354733177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 12.0978	Cost: 25.94s
Train Epoch: 196 [20480/90000 (23%)]	Loss: 11.7216	Cost: 6.10s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 11.7624	Cost: 7.31s
Train Epoch: 196 [61440/90000 (68%)]	Loss: 11.9106	Cost: 6.09s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 11.9639	Cost: 6.73s
Train Epoch: 196 	Average Loss: 11.8912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3875

Learning rate: 0.00019999810425237646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 12.0157	Cost: 28.49s
Train Epoch: 197 [20480/90000 (23%)]	Loss: 11.8720	Cost: 6.09s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 11.7714	Cost: 8.33s
Train Epoch: 197 [61440/90000 (68%)]	Loss: 11.8749	Cost: 5.99s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 11.9763	Cost: 6.01s
Train Epoch: 197 	Average Loss: 11.8927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3356

Learning rate: 0.00019999808485872698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 12.1683	Cost: 24.59s
Train Epoch: 198 [20480/90000 (23%)]	Loss: 11.8474	Cost: 6.03s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 11.9148	Cost: 7.86s
Train Epoch: 198 [61440/90000 (68%)]	Loss: 11.8257	Cost: 5.87s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 11.8332	Cost: 7.38s
Train Epoch: 198 	Average Loss: 11.8688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3315

Learning rate: 0.00019999806536638337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 12.2593	Cost: 23.58s
Train Epoch: 199 [20480/90000 (23%)]	Loss: 11.7282	Cost: 5.98s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 11.7054	Cost: 6.80s
Train Epoch: 199 [61440/90000 (68%)]	Loss: 11.8557	Cost: 6.14s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 11.8931	Cost: 6.28s
Train Epoch: 199 	Average Loss: 11.8694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2775

Saving model as e199_model.pt & e199_waveforms_supplementary.hdf5
Learning rate: 0.00019999804577534562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 11.7924	Cost: 24.45s
Train Epoch: 200 [20480/90000 (23%)]	Loss: 11.7820	Cost: 6.05s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 11.5410	Cost: 7.25s
Train Epoch: 200 [61440/90000 (68%)]	Loss: 11.7109	Cost: 5.92s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 12.0686	Cost: 6.17s
Train Epoch: 200 	Average Loss: 11.8337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1654

Saving model as e200_model.pt & e200_waveforms_supplementary.hdf5
Learning rate: 0.00019999802608561374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 11.9691	Cost: 22.89s
Train Epoch: 201 [20480/90000 (23%)]	Loss: 11.7576	Cost: 5.94s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 11.5395	Cost: 6.87s
Train Epoch: 201 [61440/90000 (68%)]	Loss: 11.7511	Cost: 6.04s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 11.9038	Cost: 5.98s
Train Epoch: 201 	Average Loss: 11.8463
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2801

Learning rate: 0.00019999800629718777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 11.9072	Cost: 28.73s
Train Epoch: 202 [20480/90000 (23%)]	Loss: 11.8893	Cost: 6.02s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 11.7796	Cost: 7.60s
Train Epoch: 202 [61440/90000 (68%)]	Loss: 11.8417	Cost: 5.77s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 11.7438	Cost: 6.36s
Train Epoch: 202 	Average Loss: 11.8222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1565

Saving model as e202_model.pt & e202_waveforms_supplementary.hdf5
Learning rate: 0.00019999798641006774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 12.0174	Cost: 27.72s
Train Epoch: 203 [20480/90000 (23%)]	Loss: 11.8443	Cost: 5.98s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 11.7739	Cost: 8.66s
Train Epoch: 203 [61440/90000 (68%)]	Loss: 11.8660	Cost: 5.85s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 11.8057	Cost: 7.44s
Train Epoch: 203 	Average Loss: 11.8234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2304

Learning rate: 0.00019999796642425366
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 11.8998	Cost: 23.95s
Train Epoch: 204 [20480/90000 (23%)]	Loss: 11.7819	Cost: 6.05s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 11.7193	Cost: 8.21s
Train Epoch: 204 [61440/90000 (68%)]	Loss: 11.7485	Cost: 5.92s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 11.8259	Cost: 9.16s
Train Epoch: 204 	Average Loss: 11.7896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2125

Learning rate: 0.00019999794633974552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 11.7084	Cost: 23.34s
Train Epoch: 205 [20480/90000 (23%)]	Loss: 11.7332	Cost: 6.08s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 11.5503	Cost: 6.71s
Train Epoch: 205 [61440/90000 (68%)]	Loss: 11.7130	Cost: 5.94s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 11.8726	Cost: 5.89s
Train Epoch: 205 	Average Loss: 11.7701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2431

Learning rate: 0.00019999792615654335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 11.9928	Cost: 23.49s
Train Epoch: 206 [20480/90000 (23%)]	Loss: 11.7390	Cost: 5.99s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 11.6737	Cost: 7.38s
Train Epoch: 206 [61440/90000 (68%)]	Loss: 11.6241	Cost: 5.98s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 11.8753	Cost: 7.25s
Train Epoch: 206 	Average Loss: 11.8140
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2577

Learning rate: 0.00019999790587464718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 11.7690	Cost: 25.48s
Train Epoch: 207 [20480/90000 (23%)]	Loss: 11.6737	Cost: 6.19s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 11.7456	Cost: 7.62s
Train Epoch: 207 [61440/90000 (68%)]	Loss: 11.7481	Cost: 6.17s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 11.7415	Cost: 5.80s
Train Epoch: 207 	Average Loss: 11.7656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2331

Learning rate: 0.00019999788549405706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 11.7654	Cost: 27.52s
Train Epoch: 208 [20480/90000 (23%)]	Loss: 11.8048	Cost: 6.16s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 11.5857	Cost: 6.41s
Train Epoch: 208 [61440/90000 (68%)]	Loss: 11.8426	Cost: 6.06s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 11.6229	Cost: 5.74s
Train Epoch: 208 	Average Loss: 11.7667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1889

Learning rate: 0.00019999786501477296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 11.8611	Cost: 22.52s
Train Epoch: 209 [20480/90000 (23%)]	Loss: 11.6686	Cost: 6.03s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 11.7129	Cost: 7.50s
Train Epoch: 209 [61440/90000 (68%)]	Loss: 11.7526	Cost: 5.95s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 11.8036	Cost: 8.39s
Train Epoch: 209 	Average Loss: 11.7551
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2664

Learning rate: 0.00019999784443679492
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 11.6466	Cost: 23.66s
Train Epoch: 210 [20480/90000 (23%)]	Loss: 11.7034	Cost: 6.05s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 11.7188	Cost: 6.71s
Train Epoch: 210 [61440/90000 (68%)]	Loss: 11.7131	Cost: 5.87s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 11.7874	Cost: 5.75s
Train Epoch: 210 	Average Loss: 11.7478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2466

Learning rate: 0.000199997823760123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 11.6708	Cost: 22.50s
Train Epoch: 211 [20480/90000 (23%)]	Loss: 11.5994	Cost: 6.06s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 11.5567	Cost: 7.23s
Train Epoch: 211 [61440/90000 (68%)]	Loss: 11.7708	Cost: 5.95s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 11.7709	Cost: 6.25s
Train Epoch: 211 	Average Loss: 11.7242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1876

Learning rate: 0.00019999780298475715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 11.7156	Cost: 25.10s
Train Epoch: 212 [20480/90000 (23%)]	Loss: 11.5674	Cost: 6.11s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 11.5227	Cost: 7.24s
Train Epoch: 212 [61440/90000 (68%)]	Loss: 11.5626	Cost: 6.00s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 11.7447	Cost: 5.85s
Train Epoch: 212 	Average Loss: 11.7010
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0995

Saving model as e212_model.pt & e212_waveforms_supplementary.hdf5
Learning rate: 0.00019999778211069746
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 11.8648	Cost: 28.34s
Train Epoch: 213 [20480/90000 (23%)]	Loss: 11.6427	Cost: 6.05s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 11.5686	Cost: 7.08s
Train Epoch: 213 [61440/90000 (68%)]	Loss: 11.6077	Cost: 6.26s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 11.6079	Cost: 6.35s
Train Epoch: 213 	Average Loss: 11.7085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1504

Learning rate: 0.0001999977611379439
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 12.0312	Cost: 24.32s
Train Epoch: 214 [20480/90000 (23%)]	Loss: 11.7781	Cost: 5.99s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 11.6640	Cost: 8.50s
Train Epoch: 214 [61440/90000 (68%)]	Loss: 11.7425	Cost: 5.96s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 11.6442	Cost: 9.05s
Train Epoch: 214 	Average Loss: 11.7032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1289

Learning rate: 0.00019999774006649652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 11.7771	Cost: 24.66s
Train Epoch: 215 [20480/90000 (23%)]	Loss: 11.6876	Cost: 5.99s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 11.4738	Cost: 6.62s
Train Epoch: 215 [61440/90000 (68%)]	Loss: 11.5956	Cost: 6.28s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 11.6914	Cost: 6.11s
Train Epoch: 215 	Average Loss: 11.6707
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0258

Saving model as e215_model.pt & e215_waveforms_supplementary.hdf5
Learning rate: 0.00019999771889635528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 11.7643	Cost: 23.29s
Train Epoch: 216 [20480/90000 (23%)]	Loss: 11.6206	Cost: 6.13s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 11.5845	Cost: 7.47s
Train Epoch: 216 [61440/90000 (68%)]	Loss: 11.5797	Cost: 6.06s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 11.5718	Cost: 6.16s
Train Epoch: 216 	Average Loss: 11.6738
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1710

Learning rate: 0.00019999769762752028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 11.9210	Cost: 25.23s
Train Epoch: 217 [20480/90000 (23%)]	Loss: 11.5490	Cost: 6.14s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 11.5746	Cost: 6.24s
Train Epoch: 217 [61440/90000 (68%)]	Loss: 11.5353	Cost: 6.09s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 11.6183	Cost: 6.66s
Train Epoch: 217 	Average Loss: 11.6626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0499

Learning rate: 0.00019999767625999152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 11.9376	Cost: 27.26s
Train Epoch: 218 [20480/90000 (23%)]	Loss: 11.5169	Cost: 6.03s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 11.4740	Cost: 7.15s
Train Epoch: 218 [61440/90000 (68%)]	Loss: 11.6422	Cost: 6.03s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 11.8062	Cost: 5.94s
Train Epoch: 218 	Average Loss: 11.6348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0834

Learning rate: 0.00019999765479376897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 11.8781	Cost: 25.31s
Train Epoch: 219 [20480/90000 (23%)]	Loss: 11.6128	Cost: 6.06s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 11.5702	Cost: 7.78s
Train Epoch: 219 [61440/90000 (68%)]	Loss: 11.5858	Cost: 6.04s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 11.5930	Cost: 7.05s
Train Epoch: 219 	Average Loss: 11.6532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0762

Learning rate: 0.00019999763322885272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 11.6533	Cost: 22.80s
Train Epoch: 220 [20480/90000 (23%)]	Loss: 11.7416	Cost: 5.85s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 11.4383	Cost: 6.27s
Train Epoch: 220 [61440/90000 (68%)]	Loss: 11.4703	Cost: 5.88s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 11.5867	Cost: 5.95s
Train Epoch: 220 	Average Loss: 11.6304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0379

Learning rate: 0.00019999761156524275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 11.7295	Cost: 24.29s
Train Epoch: 221 [20480/90000 (23%)]	Loss: 11.6320	Cost: 6.16s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 11.5709	Cost: 7.49s
Train Epoch: 221 [61440/90000 (68%)]	Loss: 11.6174	Cost: 5.87s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 11.5093	Cost: 6.18s
Train Epoch: 221 	Average Loss: 11.6266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0674

Learning rate: 0.0001999975898029391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 11.6351	Cost: 23.37s
Train Epoch: 222 [20480/90000 (23%)]	Loss: 11.6570	Cost: 5.95s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 11.4843	Cost: 6.46s
Train Epoch: 222 [61440/90000 (68%)]	Loss: 11.6011	Cost: 5.97s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 11.5386	Cost: 5.71s
Train Epoch: 222 	Average Loss: 11.6203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0489

Learning rate: 0.00019999756794194176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 11.7209	Cost: 28.24s
Train Epoch: 223 [20480/90000 (23%)]	Loss: 11.4721	Cost: 6.05s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 11.4625	Cost: 7.24s
Train Epoch: 223 [61440/90000 (68%)]	Loss: 11.6705	Cost: 6.08s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 11.6361	Cost: 5.94s
Train Epoch: 223 	Average Loss: 11.6081
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0121

Saving model as e223_model.pt & e223_waveforms_supplementary.hdf5
Learning rate: 0.0001999975459822508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 11.5926	Cost: 23.98s
Train Epoch: 224 [20480/90000 (23%)]	Loss: 11.5051	Cost: 5.99s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 11.4195	Cost: 7.81s
Train Epoch: 224 [61440/90000 (68%)]	Loss: 11.4740	Cost: 5.87s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 11.4162	Cost: 7.24s
Train Epoch: 224 	Average Loss: 11.5917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0396

Learning rate: 0.0001999975239238662
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 11.5485	Cost: 22.43s
Train Epoch: 225 [20480/90000 (23%)]	Loss: 11.4770	Cost: 6.00s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 11.3662	Cost: 6.30s
Train Epoch: 225 [61440/90000 (68%)]	Loss: 11.5331	Cost: 6.01s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 11.4546	Cost: 8.91s
Train Epoch: 225 	Average Loss: 11.5614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0321

Learning rate: 0.000199997501766788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 11.9427	Cost: 23.14s
Train Epoch: 226 [20480/90000 (23%)]	Loss: 11.6461	Cost: 6.05s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 11.4290	Cost: 7.58s
Train Epoch: 226 [61440/90000 (68%)]	Loss: 11.5049	Cost: 5.91s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 11.6706	Cost: 6.15s
Train Epoch: 226 	Average Loss: 11.5995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0252

Learning rate: 0.00019999747951101625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 11.6711	Cost: 24.60s
Train Epoch: 227 [20480/90000 (23%)]	Loss: 11.5933	Cost: 6.05s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 11.3148	Cost: 7.56s
Train Epoch: 227 [61440/90000 (68%)]	Loss: 11.4120	Cost: 6.08s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 11.7107	Cost: 5.92s
Train Epoch: 227 	Average Loss: 11.5898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0676

Learning rate: 0.0001999974571565509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 11.6953	Cost: 27.57s
Train Epoch: 228 [20480/90000 (23%)]	Loss: 11.4835	Cost: 6.20s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 11.4508	Cost: 7.41s
Train Epoch: 228 [61440/90000 (68%)]	Loss: 11.5137	Cost: 6.00s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 11.6388	Cost: 6.33s
Train Epoch: 228 	Average Loss: 11.5802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0147

Learning rate: 0.00019999743470339206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 11.6251	Cost: 24.13s
Train Epoch: 229 [20480/90000 (23%)]	Loss: 11.5652	Cost: 5.99s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 11.5412	Cost: 8.04s
Train Epoch: 229 [61440/90000 (68%)]	Loss: 11.5968	Cost: 6.03s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 11.5450	Cost: 8.10s
Train Epoch: 229 	Average Loss: 11.5628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9827

Saving model as e229_model.pt & e229_waveforms_supplementary.hdf5
Learning rate: 0.0001999974121515397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 11.6551	Cost: 22.83s
Train Epoch: 230 [20480/90000 (23%)]	Loss: 11.5790	Cost: 5.99s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 11.3194	Cost: 6.26s
Train Epoch: 230 [61440/90000 (68%)]	Loss: 11.5584	Cost: 6.12s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 11.4688	Cost: 7.70s
Train Epoch: 230 	Average Loss: 11.5678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9888

Learning rate: 0.00019999738950099387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 11.7013	Cost: 23.23s
Train Epoch: 231 [20480/90000 (23%)]	Loss: 11.4923	Cost: 6.02s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 11.3179	Cost: 6.71s
Train Epoch: 231 [61440/90000 (68%)]	Loss: 11.4535	Cost: 5.87s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 11.4810	Cost: 6.00s
Train Epoch: 231 	Average Loss: 11.5339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9397

Saving model as e231_model.pt & e231_waveforms_supplementary.hdf5
Learning rate: 0.00019999736675175452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 11.5299	Cost: 23.83s
Train Epoch: 232 [20480/90000 (23%)]	Loss: 11.5580	Cost: 6.25s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 11.3762	Cost: 7.08s
Train Epoch: 232 [61440/90000 (68%)]	Loss: 11.4605	Cost: 6.18s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 11.3752	Cost: 5.78s
Train Epoch: 232 	Average Loss: 11.5188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9641

Learning rate: 0.00019999734390382178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 11.7703	Cost: 27.06s
Train Epoch: 233 [20480/90000 (23%)]	Loss: 11.4273	Cost: 6.07s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 11.3226	Cost: 6.74s
Train Epoch: 233 [61440/90000 (68%)]	Loss: 11.5193	Cost: 5.86s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 11.4989	Cost: 5.73s
Train Epoch: 233 	Average Loss: 11.5277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9962

Learning rate: 0.00019999732095719557
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 11.7186	Cost: 25.71s
Train Epoch: 234 [20480/90000 (23%)]	Loss: 11.6652	Cost: 5.99s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 11.4674	Cost: 8.59s
Train Epoch: 234 [61440/90000 (68%)]	Loss: 11.4318	Cost: 5.93s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 11.3338	Cost: 9.04s
Train Epoch: 234 	Average Loss: 11.4817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9276

Saving model as e234_model.pt & e234_waveforms_supplementary.hdf5
Learning rate: 0.00019999729791187596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 11.5794	Cost: 24.73s
Train Epoch: 235 [20480/90000 (23%)]	Loss: 11.3657	Cost: 6.01s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 11.3674	Cost: 7.89s
Train Epoch: 235 [61440/90000 (68%)]	Loss: 11.5010	Cost: 5.96s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 11.3658	Cost: 8.63s
Train Epoch: 235 	Average Loss: 11.5331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9515

Learning rate: 0.000199997274767863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 11.7181	Cost: 23.88s
Train Epoch: 236 [20480/90000 (23%)]	Loss: 11.5315	Cost: 6.12s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 11.3258	Cost: 7.11s
Train Epoch: 236 [61440/90000 (68%)]	Loss: 11.3615	Cost: 5.93s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 11.5155	Cost: 5.69s
Train Epoch: 236 	Average Loss: 11.4919
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9102

Saving model as e236_model.pt & e236_waveforms_supplementary.hdf5
Learning rate: 0.0001999972515251567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 11.7147	Cost: 23.97s
Train Epoch: 237 [20480/90000 (23%)]	Loss: 11.4230	Cost: 6.40s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 11.2268	Cost: 6.39s
Train Epoch: 237 [61440/90000 (68%)]	Loss: 11.3879	Cost: 5.96s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 11.5442	Cost: 6.23s
Train Epoch: 237 	Average Loss: 11.4895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9188

Learning rate: 0.00019999722818375706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 11.4928	Cost: 24.65s
Train Epoch: 238 [20480/90000 (23%)]	Loss: 11.5065	Cost: 6.31s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 11.4334	Cost: 6.29s
Train Epoch: 238 [61440/90000 (68%)]	Loss: 11.3993	Cost: 6.05s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 11.5910	Cost: 6.57s
Train Epoch: 238 	Average Loss: 11.4882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9736

Learning rate: 0.00019999720474366407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 11.6252	Cost: 27.51s
Train Epoch: 239 [20480/90000 (23%)]	Loss: 11.4491	Cost: 6.04s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 11.3845	Cost: 6.75s
Train Epoch: 239 [61440/90000 (68%)]	Loss: 11.3396	Cost: 6.01s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 11.5255	Cost: 6.16s
Train Epoch: 239 	Average Loss: 11.4597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8630

Saving model as e239_model.pt & e239_waveforms_supplementary.hdf5
Learning rate: 0.00019999718120487783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 11.6717	Cost: 23.56s
Train Epoch: 240 [20480/90000 (23%)]	Loss: 11.3886	Cost: 6.07s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 11.5300	Cost: 8.02s
Train Epoch: 240 [61440/90000 (68%)]	Loss: 11.2370	Cost: 5.89s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 11.3726	Cost: 7.97s
Train Epoch: 240 	Average Loss: 11.4432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9263

Learning rate: 0.00019999715756739835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 11.4863	Cost: 23.82s
Train Epoch: 241 [20480/90000 (23%)]	Loss: 11.3894	Cost: 6.64s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 11.4191	Cost: 6.26s
Train Epoch: 241 [61440/90000 (68%)]	Loss: 11.4263	Cost: 6.20s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 11.4862	Cost: 6.09s
Train Epoch: 241 	Average Loss: 11.4281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8620

Saving model as e241_model.pt & e241_waveforms_supplementary.hdf5
Learning rate: 0.00019999713383122558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 11.3280	Cost: 24.25s
Train Epoch: 242 [20480/90000 (23%)]	Loss: 11.4258	Cost: 5.97s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 11.2604	Cost: 7.44s
Train Epoch: 242 [61440/90000 (68%)]	Loss: 11.4294	Cost: 5.76s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 11.3173	Cost: 6.50s
Train Epoch: 242 	Average Loss: 11.4367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9606

Learning rate: 0.0001999971099963596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 11.7262	Cost: 23.55s
Train Epoch: 243 [20480/90000 (23%)]	Loss: 11.3566	Cost: 5.99s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 11.3031	Cost: 6.45s
Train Epoch: 243 [61440/90000 (68%)]	Loss: 11.3551	Cost: 5.94s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 11.4400	Cost: 5.55s
Train Epoch: 243 	Average Loss: 11.4195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8844

Learning rate: 0.00019999708606280046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 11.4585	Cost: 28.21s
Train Epoch: 244 [20480/90000 (23%)]	Loss: 11.2569	Cost: 5.99s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 11.3408	Cost: 7.73s
Train Epoch: 244 [61440/90000 (68%)]	Loss: 11.4488	Cost: 5.95s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 11.5295	Cost: 6.02s
Train Epoch: 244 	Average Loss: 11.4057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9073

Learning rate: 0.00019999706203054814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 11.4767	Cost: 24.32s
Train Epoch: 245 [20480/90000 (23%)]	Loss: 11.3331	Cost: 6.01s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 11.3221	Cost: 7.86s
Train Epoch: 245 [61440/90000 (68%)]	Loss: 11.4638	Cost: 6.12s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 11.3701	Cost: 7.48s
Train Epoch: 245 	Average Loss: 11.4224
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8282

Saving model as e245_model.pt & e245_waveforms_supplementary.hdf5
Learning rate: 0.00019999703789960266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 11.4757	Cost: 23.03s
Train Epoch: 246 [20480/90000 (23%)]	Loss: 11.3277	Cost: 6.26s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 11.2827	Cost: 6.64s
Train Epoch: 246 [61440/90000 (68%)]	Loss: 11.3834	Cost: 6.02s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 11.2845	Cost: 8.37s
Train Epoch: 246 	Average Loss: 11.3990
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8609

Learning rate: 0.00019999701366996408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 11.6868	Cost: 23.75s
Train Epoch: 247 [20480/90000 (23%)]	Loss: 11.3729	Cost: 6.04s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 11.2250	Cost: 6.55s
Train Epoch: 247 [61440/90000 (68%)]	Loss: 11.3058	Cost: 5.88s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 11.4801	Cost: 5.57s
Train Epoch: 247 	Average Loss: 11.3919
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8255

Saving model as e247_model.pt & e247_waveforms_supplementary.hdf5
Learning rate: 0.0001999969893416324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 11.4821	Cost: 23.50s
Train Epoch: 248 [20480/90000 (23%)]	Loss: 11.2563	Cost: 5.93s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 11.0286	Cost: 7.24s
Train Epoch: 248 [61440/90000 (68%)]	Loss: 11.4256	Cost: 5.88s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 11.3141	Cost: 5.69s
Train Epoch: 248 	Average Loss: 11.3716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8761

Learning rate: 0.00019999696491460766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 11.4283	Cost: 29.53s
Train Epoch: 249 [20480/90000 (23%)]	Loss: 11.3523	Cost: 6.17s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 11.1683	Cost: 7.84s
Train Epoch: 249 [61440/90000 (68%)]	Loss: 11.1452	Cost: 5.93s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 11.4757	Cost: 5.78s
Train Epoch: 249 	Average Loss: 11.3464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8348

Learning rate: 0.00019999694038888986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 11.4910	Cost: 28.60s
Train Epoch: 250 [20480/90000 (23%)]	Loss: 11.3040	Cost: 5.97s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 11.2967	Cost: 7.18s
Train Epoch: 250 [61440/90000 (68%)]	Loss: 11.3231	Cost: 6.02s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 11.3176	Cost: 7.25s
Train Epoch: 250 	Average Loss: 11.3711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7847

Saving model as e250_model.pt & e250_waveforms_supplementary.hdf5
Learning rate: 0.00019999691576447903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 11.5877	Cost: 24.25s
Train Epoch: 251 [20480/90000 (23%)]	Loss: 11.2752	Cost: 6.05s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 11.1483	Cost: 7.59s
Train Epoch: 251 [61440/90000 (68%)]	Loss: 11.2355	Cost: 5.94s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 11.5247	Cost: 8.17s
Train Epoch: 251 	Average Loss: 11.3502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8084

Learning rate: 0.0001999968910413752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 11.5659	Cost: 23.80s
Train Epoch: 252 [20480/90000 (23%)]	Loss: 11.4208	Cost: 6.21s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 11.2139	Cost: 6.45s
Train Epoch: 252 [61440/90000 (68%)]	Loss: 11.2637	Cost: 5.85s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 11.4692	Cost: 5.94s
Train Epoch: 252 	Average Loss: 11.3437
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8337

Learning rate: 0.0001999968662195784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 11.4767	Cost: 24.22s
Train Epoch: 253 [20480/90000 (23%)]	Loss: 11.4576	Cost: 5.95s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 11.1505	Cost: 7.46s
Train Epoch: 253 [61440/90000 (68%)]	Loss: 11.3508	Cost: 6.21s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 11.3615	Cost: 6.05s
Train Epoch: 253 	Average Loss: 11.3357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7822

Saving model as e253_model.pt & e253_waveforms_supplementary.hdf5
Learning rate: 0.00019999684129908864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 11.5067	Cost: 23.94s
Train Epoch: 254 [20480/90000 (23%)]	Loss: 11.4525	Cost: 6.02s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 11.2242	Cost: 6.67s
Train Epoch: 254 [61440/90000 (68%)]	Loss: 11.2881	Cost: 6.06s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 11.3287	Cost: 5.94s
Train Epoch: 254 	Average Loss: 11.3154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7907

Learning rate: 0.00019999681627990595
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 11.5286	Cost: 26.09s
Train Epoch: 255 [20480/90000 (23%)]	Loss: 11.3732	Cost: 6.02s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 11.1448	Cost: 8.32s
Train Epoch: 255 [61440/90000 (68%)]	Loss: 11.2616	Cost: 5.79s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 11.1886	Cost: 6.71s
Train Epoch: 255 	Average Loss: 11.3261
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7431

Saving model as e255_model.pt & e255_waveforms_supplementary.hdf5
Learning rate: 0.00019999679116203034
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 11.4817	Cost: 24.87s
Train Epoch: 256 [20480/90000 (23%)]	Loss: 11.1714	Cost: 6.01s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 11.1258	Cost: 8.18s
Train Epoch: 256 [61440/90000 (68%)]	Loss: 11.2333	Cost: 6.00s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 11.3208	Cost: 7.53s
Train Epoch: 256 	Average Loss: 11.2825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7270

Saving model as e256_model.pt & e256_waveforms_supplementary.hdf5
Learning rate: 0.0001999967659454619
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 11.5618	Cost: 23.08s
Train Epoch: 257 [20480/90000 (23%)]	Loss: 11.2616	Cost: 6.66s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 11.2276	Cost: 6.36s
Train Epoch: 257 [61440/90000 (68%)]	Loss: 11.2452	Cost: 6.06s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 11.4186	Cost: 7.76s
Train Epoch: 257 	Average Loss: 11.3146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7463

Learning rate: 0.00019999674063020056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 11.4653	Cost: 24.66s
Train Epoch: 258 [20480/90000 (23%)]	Loss: 11.2844	Cost: 6.16s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 11.1074	Cost: 7.43s
Train Epoch: 258 [61440/90000 (68%)]	Loss: 11.2511	Cost: 5.71s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 11.3428	Cost: 5.58s
Train Epoch: 258 	Average Loss: 11.2866
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7790

Learning rate: 0.00019999671521624642
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 11.4671	Cost: 23.54s
Train Epoch: 259 [20480/90000 (23%)]	Loss: 11.3632	Cost: 6.08s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 11.2270	Cost: 7.64s
Train Epoch: 259 [61440/90000 (68%)]	Loss: 11.1771	Cost: 5.91s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 11.4138	Cost: 6.88s
Train Epoch: 259 	Average Loss: 11.2745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8680

Learning rate: 0.0001999966897035995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 11.4008	Cost: 26.31s
Train Epoch: 260 [20480/90000 (23%)]	Loss: 11.2525	Cost: 6.05s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 11.3386	Cost: 7.71s
Train Epoch: 260 [61440/90000 (68%)]	Loss: 11.2534	Cost: 5.90s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 11.2470	Cost: 6.93s
Train Epoch: 260 	Average Loss: 11.2904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6653

Saving model as e260_model.pt & e260_waveforms_supplementary.hdf5
Learning rate: 0.00019999666409225978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 11.3087	Cost: 27.03s
Train Epoch: 261 [20480/90000 (23%)]	Loss: 11.2697	Cost: 6.02s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 11.0281	Cost: 9.48s
Train Epoch: 261 [61440/90000 (68%)]	Loss: 11.1386	Cost: 5.91s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 11.2561	Cost: 7.74s
Train Epoch: 261 	Average Loss: 11.2459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6851

Learning rate: 0.00019999663838222732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 11.5474	Cost: 22.56s
Train Epoch: 262 [20480/90000 (23%)]	Loss: 11.2995	Cost: 5.97s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 11.0572	Cost: 6.24s
Train Epoch: 262 [61440/90000 (68%)]	Loss: 11.2461	Cost: 5.96s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 11.1740	Cost: 8.63s
Train Epoch: 262 	Average Loss: 11.2729
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7248

Learning rate: 0.00019999661257350212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 11.3826	Cost: 23.56s
Train Epoch: 263 [20480/90000 (23%)]	Loss: 11.2465	Cost: 6.04s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 11.2300	Cost: 7.68s
Train Epoch: 263 [61440/90000 (68%)]	Loss: 11.2040	Cost: 5.71s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 11.0770	Cost: 6.00s
Train Epoch: 263 	Average Loss: 11.2403
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7877

Learning rate: 0.00019999658666608423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 11.4916	Cost: 24.10s
Train Epoch: 264 [20480/90000 (23%)]	Loss: 11.1661	Cost: 5.92s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 11.1686	Cost: 6.52s
Train Epoch: 264 [61440/90000 (68%)]	Loss: 11.1258	Cost: 6.05s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 11.0691	Cost: 6.47s
Train Epoch: 264 	Average Loss: 11.2115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7112

Learning rate: 0.00019999656065997363
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 11.3396	Cost: 27.72s
Train Epoch: 265 [20480/90000 (23%)]	Loss: 11.2406	Cost: 6.07s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 11.1690	Cost: 7.03s
Train Epoch: 265 [61440/90000 (68%)]	Loss: 11.1111	Cost: 6.21s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 11.1885	Cost: 6.16s
Train Epoch: 265 	Average Loss: 11.2533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6991

Learning rate: 0.00019999653455517042
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 11.3816	Cost: 24.27s
Train Epoch: 266 [20480/90000 (23%)]	Loss: 11.1768	Cost: 6.28s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 11.0724	Cost: 8.43s
Train Epoch: 266 [61440/90000 (68%)]	Loss: 11.0600	Cost: 6.12s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 11.3822	Cost: 7.95s
Train Epoch: 266 	Average Loss: 11.2496
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7557

Learning rate: 0.00019999650835167456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 11.2890	Cost: 23.34s
Train Epoch: 267 [20480/90000 (23%)]	Loss: 11.2047	Cost: 6.17s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 11.0809	Cost: 6.51s
Train Epoch: 267 [61440/90000 (68%)]	Loss: 11.2620	Cost: 6.20s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 11.2960	Cost: 9.17s
Train Epoch: 267 	Average Loss: 11.2282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7431

Learning rate: 0.00019999648204948613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 11.5590	Cost: 23.41s
Train Epoch: 268 [20480/90000 (23%)]	Loss: 11.1809	Cost: 6.10s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 11.0923	Cost: 7.27s
Train Epoch: 268 [61440/90000 (68%)]	Loss: 11.2275	Cost: 6.28s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 11.2245	Cost: 5.77s
Train Epoch: 268 	Average Loss: 11.1936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6969

Learning rate: 0.0001999964556486051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 11.4069	Cost: 22.83s
Train Epoch: 269 [20480/90000 (23%)]	Loss: 11.1163	Cost: 6.13s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 11.1016	Cost: 8.13s
Train Epoch: 269 [61440/90000 (68%)]	Loss: 11.1437	Cost: 5.98s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 11.0814	Cost: 6.69s
Train Epoch: 269 	Average Loss: 11.1823
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6939

Learning rate: 0.00019999642914903155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 11.2335	Cost: 27.40s
Train Epoch: 270 [20480/90000 (23%)]	Loss: 11.2653	Cost: 6.09s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 11.0877	Cost: 7.54s
Train Epoch: 270 [61440/90000 (68%)]	Loss: 11.2821	Cost: 5.73s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 11.2190	Cost: 5.66s
Train Epoch: 270 	Average Loss: 11.1877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6395

Saving model as e270_model.pt & e270_waveforms_supplementary.hdf5
Learning rate: 0.00019999640255076545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 11.2025	Cost: 28.44s
Train Epoch: 271 [20480/90000 (23%)]	Loss: 11.0489	Cost: 6.05s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 11.0730	Cost: 6.77s
Train Epoch: 271 [61440/90000 (68%)]	Loss: 11.3118	Cost: 6.25s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 11.1797	Cost: 6.23s
Train Epoch: 271 	Average Loss: 11.1994
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6478

Learning rate: 0.0001999963758538069
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 11.3288	Cost: 25.28s
Train Epoch: 272 [20480/90000 (23%)]	Loss: 11.1632	Cost: 6.03s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 11.0488	Cost: 8.16s
Train Epoch: 272 [61440/90000 (68%)]	Loss: 11.2372	Cost: 5.89s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 11.0748	Cost: 8.20s
Train Epoch: 272 	Average Loss: 11.1805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6863

Learning rate: 0.00019999634905815583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 11.3213	Cost: 23.41s
Train Epoch: 273 [20480/90000 (23%)]	Loss: 11.2067	Cost: 6.07s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 11.0818	Cost: 6.65s
Train Epoch: 273 [61440/90000 (68%)]	Loss: 11.0632	Cost: 6.09s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 11.2262	Cost: 8.02s
Train Epoch: 273 	Average Loss: 11.1435
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6810

Learning rate: 0.00019999632216381234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 11.4210	Cost: 23.56s
Train Epoch: 274 [20480/90000 (23%)]	Loss: 11.1172	Cost: 6.26s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 11.0916	Cost: 6.46s
Train Epoch: 274 [61440/90000 (68%)]	Loss: 11.0957	Cost: 5.93s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 11.0256	Cost: 5.75s
Train Epoch: 274 	Average Loss: 11.1732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6606

Learning rate: 0.00019999629517077644
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 11.1117	Cost: 22.83s
Train Epoch: 275 [20480/90000 (23%)]	Loss: 11.2463	Cost: 6.04s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 11.1481	Cost: 8.04s
Train Epoch: 275 [61440/90000 (68%)]	Loss: 11.0569	Cost: 6.56s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 11.0917	Cost: 6.24s
Train Epoch: 275 	Average Loss: 11.1649
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6229

Saving model as e275_model.pt & e275_waveforms_supplementary.hdf5
Learning rate: 0.00019999626807904816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 11.4268	Cost: 26.39s
Train Epoch: 276 [20480/90000 (23%)]	Loss: 10.9513	Cost: 6.09s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 10.9992	Cost: 7.32s
Train Epoch: 276 [61440/90000 (68%)]	Loss: 10.9231	Cost: 5.99s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 11.0260	Cost: 5.90s
Train Epoch: 276 	Average Loss: 11.1311
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6616

Learning rate: 0.0001999962408886275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 11.4332	Cost: 28.53s
Train Epoch: 277 [20480/90000 (23%)]	Loss: 11.2068	Cost: 6.06s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 10.9147	Cost: 6.68s
Train Epoch: 277 [61440/90000 (68%)]	Loss: 11.1392	Cost: 6.13s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 11.1885	Cost: 5.95s
Train Epoch: 277 	Average Loss: 11.1537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7253

Learning rate: 0.00019999621359951451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 11.3090	Cost: 22.76s
Train Epoch: 278 [20480/90000 (23%)]	Loss: 11.1030	Cost: 6.04s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 11.0705	Cost: 6.72s
Train Epoch: 278 [61440/90000 (68%)]	Loss: 11.0015	Cost: 6.03s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 10.9635	Cost: 8.34s
Train Epoch: 278 	Average Loss: 11.1180
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6143

Saving model as e278_model.pt & e278_waveforms_supplementary.hdf5
Learning rate: 0.00019999618621170925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 11.3057	Cost: 23.86s
Train Epoch: 279 [20480/90000 (23%)]	Loss: 11.2229	Cost: 5.97s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 11.0787	Cost: 7.18s
Train Epoch: 279 [61440/90000 (68%)]	Loss: 10.9267	Cost: 6.45s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 11.0193	Cost: 6.19s
Train Epoch: 279 	Average Loss: 11.1168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5472

Saving model as e279_model.pt & e279_waveforms_supplementary.hdf5
Learning rate: 0.00019999615872521166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 11.1875	Cost: 23.45s
Train Epoch: 280 [20480/90000 (23%)]	Loss: 11.1390	Cost: 6.01s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 11.0731	Cost: 8.33s
Train Epoch: 280 [61440/90000 (68%)]	Loss: 11.1117	Cost: 6.55s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 11.0654	Cost: 6.23s
Train Epoch: 280 	Average Loss: 11.1268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6020

Learning rate: 0.00019999613114002183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 11.3905	Cost: 25.45s
Train Epoch: 281 [20480/90000 (23%)]	Loss: 10.9848	Cost: 6.14s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 10.9861	Cost: 6.98s
Train Epoch: 281 [61440/90000 (68%)]	Loss: 11.0517	Cost: 5.92s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 11.0769	Cost: 5.75s
Train Epoch: 281 	Average Loss: 11.0990
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5374

Saving model as e281_model.pt & e281_waveforms_supplementary.hdf5
Learning rate: 0.0001999961034561398
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 11.2348	Cost: 28.48s
Train Epoch: 282 [20480/90000 (23%)]	Loss: 11.0536	Cost: 6.07s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 10.9407	Cost: 6.66s
Train Epoch: 282 [61440/90000 (68%)]	Loss: 10.9851	Cost: 6.31s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 11.0151	Cost: 6.18s
Train Epoch: 282 	Average Loss: 11.1072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6042

Learning rate: 0.0001999960756735655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 11.2886	Cost: 25.44s
Train Epoch: 283 [20480/90000 (23%)]	Loss: 11.0795	Cost: 6.03s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 10.8510	Cost: 8.07s
Train Epoch: 283 [61440/90000 (68%)]	Loss: 10.9787	Cost: 5.94s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 10.9366	Cost: 8.56s
Train Epoch: 283 	Average Loss: 11.1040
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6009

Learning rate: 0.0001999960477922991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 11.3027	Cost: 23.38s
Train Epoch: 284 [20480/90000 (23%)]	Loss: 11.0413	Cost: 6.62s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 11.0034	Cost: 6.41s
Train Epoch: 284 [61440/90000 (68%)]	Loss: 10.9922	Cost: 5.99s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 11.1149	Cost: 6.11s
Train Epoch: 284 	Average Loss: 11.0752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6475

Learning rate: 0.00019999601981234054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 11.3357	Cost: 24.26s
Train Epoch: 285 [20480/90000 (23%)]	Loss: 11.0469	Cost: 6.04s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 10.9160	Cost: 6.90s
Train Epoch: 285 [61440/90000 (68%)]	Loss: 10.9606	Cost: 6.36s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 11.1922	Cost: 6.24s
Train Epoch: 285 	Average Loss: 11.0857
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6271

Learning rate: 0.00019999599173368987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 11.2100	Cost: 24.30s
Train Epoch: 286 [20480/90000 (23%)]	Loss: 11.0046	Cost: 6.15s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 11.0508	Cost: 6.26s
Train Epoch: 286 [61440/90000 (68%)]	Loss: 10.8605	Cost: 6.10s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 11.1341	Cost: 7.07s
Train Epoch: 286 	Average Loss: 11.0829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6476

Learning rate: 0.00019999596355634708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 11.2731	Cost: 29.72s
Train Epoch: 287 [20480/90000 (23%)]	Loss: 11.1929	Cost: 6.08s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 10.9122	Cost: 8.14s
Train Epoch: 287 [61440/90000 (68%)]	Loss: 11.1223	Cost: 6.40s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 11.1234	Cost: 6.54s
Train Epoch: 287 	Average Loss: 11.0923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5323

Saving model as e287_model.pt & e287_waveforms_supplementary.hdf5
Learning rate: 0.00019999593528031228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 11.2443	Cost: 24.72s
Train Epoch: 288 [20480/90000 (23%)]	Loss: 11.0721	Cost: 6.01s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 10.9074	Cost: 8.77s
Train Epoch: 288 [61440/90000 (68%)]	Loss: 11.0902	Cost: 6.15s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 11.0683	Cost: 7.76s
Train Epoch: 288 	Average Loss: 11.0542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5391

Learning rate: 0.0001999959069055854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 11.1036	Cost: 23.96s
Train Epoch: 289 [20480/90000 (23%)]	Loss: 10.9694	Cost: 6.44s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 10.9022	Cost: 6.47s
Train Epoch: 289 [61440/90000 (68%)]	Loss: 10.8744	Cost: 6.02s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 11.0573	Cost: 8.62s
Train Epoch: 289 	Average Loss: 11.0689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6514

Learning rate: 0.00019999587843216654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 11.1611	Cost: 23.70s
Train Epoch: 290 [20480/90000 (23%)]	Loss: 11.0879	Cost: 6.12s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 10.9130	Cost: 7.26s
Train Epoch: 290 [61440/90000 (68%)]	Loss: 11.0960	Cost: 5.92s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 11.0922	Cost: 6.24s
Train Epoch: 290 	Average Loss: 11.0693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5692

Learning rate: 0.00019999584986005571
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 11.2069	Cost: 23.99s
Train Epoch: 291 [20480/90000 (23%)]	Loss: 10.9413	Cost: 6.17s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 11.0251	Cost: 7.91s
Train Epoch: 291 [61440/90000 (68%)]	Loss: 10.8207	Cost: 5.98s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 11.0406	Cost: 6.90s
Train Epoch: 291 	Average Loss: 11.0502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5632

Learning rate: 0.00019999582118925292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 11.3235	Cost: 25.22s
Train Epoch: 292 [20480/90000 (23%)]	Loss: 11.0206	Cost: 6.16s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 11.0375	Cost: 6.99s
Train Epoch: 292 [61440/90000 (68%)]	Loss: 10.9431	Cost: 6.03s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 10.9531	Cost: 5.95s
Train Epoch: 292 	Average Loss: 11.0420
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5518

Learning rate: 0.00019999579241975824
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 11.5489	Cost: 28.60s
Train Epoch: 293 [20480/90000 (23%)]	Loss: 11.0062	Cost: 6.23s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 10.8991	Cost: 6.88s
Train Epoch: 293 [61440/90000 (68%)]	Loss: 10.9124	Cost: 6.45s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 11.1623	Cost: 5.71s
Train Epoch: 293 	Average Loss: 11.0323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5872

Learning rate: 0.00019999576355157165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 11.4627	Cost: 22.68s
Train Epoch: 294 [20480/90000 (23%)]	Loss: 10.9982	Cost: 6.00s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 10.9278	Cost: 7.84s
Train Epoch: 294 [61440/90000 (68%)]	Loss: 10.9075	Cost: 5.94s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 11.0404	Cost: 8.40s
Train Epoch: 294 	Average Loss: 11.0061
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5429

Learning rate: 0.0001999957345846932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 11.1793	Cost: 24.05s
Train Epoch: 295 [20480/90000 (23%)]	Loss: 11.1202	Cost: 6.16s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 10.8735	Cost: 6.36s
Train Epoch: 295 [61440/90000 (68%)]	Loss: 10.8666	Cost: 6.31s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 10.9957	Cost: 7.61s
Train Epoch: 295 	Average Loss: 11.0168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5580

Learning rate: 0.0001999957055191229
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 10.9533	Cost: 23.76s
Train Epoch: 296 [20480/90000 (23%)]	Loss: 11.0406	Cost: 6.13s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 10.9082	Cost: 7.07s
Train Epoch: 296 [61440/90000 (68%)]	Loss: 10.9497	Cost: 6.52s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 10.9130	Cost: 5.87s
Train Epoch: 296 	Average Loss: 11.0040
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5210

Saving model as e296_model.pt & e296_waveforms_supplementary.hdf5
Learning rate: 0.0001999956763548608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 11.3594	Cost: 22.98s
Train Epoch: 297 [20480/90000 (23%)]	Loss: 10.9947	Cost: 6.05s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 10.9101	Cost: 7.48s
Train Epoch: 297 [61440/90000 (68%)]	Loss: 10.9262	Cost: 5.96s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 11.0006	Cost: 6.09s
Train Epoch: 297 	Average Loss: 10.9875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4772

Saving model as e297_model.pt & e297_waveforms_supplementary.hdf5
Learning rate: 0.00019999564709190693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 11.1386	Cost: 25.10s
Train Epoch: 298 [20480/90000 (23%)]	Loss: 10.8996	Cost: 6.00s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 10.8824	Cost: 7.05s
Train Epoch: 298 [61440/90000 (68%)]	Loss: 10.7794	Cost: 5.93s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 11.0498	Cost: 5.92s
Train Epoch: 298 	Average Loss: 10.9661
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5123

Learning rate: 0.00019999561773026132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 11.2288	Cost: 28.96s
Train Epoch: 299 [20480/90000 (23%)]	Loss: 11.0796	Cost: 5.99s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 10.8161	Cost: 7.22s
Train Epoch: 299 [61440/90000 (68%)]	Loss: 10.9320	Cost: 6.05s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 10.9358	Cost: 6.20s
Train Epoch: 299 	Average Loss: 10.9658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4206

Saving model as e299_model.pt & e299_waveforms_supplementary.hdf5
Learning rate: 0.00019999558826992397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 11.3654	Cost: 24.03s
Train Epoch: 300 [20480/90000 (23%)]	Loss: 11.1376	Cost: 6.01s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 10.9335	Cost: 7.95s
Train Epoch: 300 [61440/90000 (68%)]	Loss: 10.9151	Cost: 5.93s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 10.8597	Cost: 7.98s
Train Epoch: 300 	Average Loss: 10.9675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5269

Learning rate: 0.00019999555871089494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 11.2079	Cost: 24.07s
Train Epoch: 301 [20480/90000 (23%)]	Loss: 10.9925	Cost: 6.35s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 10.8193	Cost: 6.34s
Train Epoch: 301 [61440/90000 (68%)]	Loss: 11.0012	Cost: 6.02s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 10.8550	Cost: 6.16s
Train Epoch: 301 	Average Loss: 10.9750
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5879

Learning rate: 0.00019999552905317427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 11.1957	Cost: 23.35s
Train Epoch: 302 [20480/90000 (23%)]	Loss: 10.9892	Cost: 6.21s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 10.8251	Cost: 6.81s
Train Epoch: 302 [61440/90000 (68%)]	Loss: 10.8401	Cost: 6.19s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 10.9684	Cost: 6.22s
Train Epoch: 302 	Average Loss: 10.9515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4337

Learning rate: 0.00019999549929676196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 11.1588	Cost: 24.49s
Train Epoch: 303 [20480/90000 (23%)]	Loss: 10.9186	Cost: 6.20s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 10.7939	Cost: 6.62s
Train Epoch: 303 [61440/90000 (68%)]	Loss: 10.8984	Cost: 6.07s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 11.0471	Cost: 6.29s
Train Epoch: 303 	Average Loss: 10.9551
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4570

Learning rate: 0.00019999546944165803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 11.0169	Cost: 27.83s
Train Epoch: 304 [20480/90000 (23%)]	Loss: 10.8860	Cost: 6.03s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 10.7673	Cost: 6.72s
Train Epoch: 304 [61440/90000 (68%)]	Loss: 10.9029	Cost: 6.08s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 10.9578	Cost: 5.54s
Train Epoch: 304 	Average Loss: 10.9287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5514

Learning rate: 0.00019999543948786254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 10.9868	Cost: 25.38s
Train Epoch: 305 [20480/90000 (23%)]	Loss: 11.1230	Cost: 6.05s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 10.7708	Cost: 7.77s
Train Epoch: 305 [61440/90000 (68%)]	Loss: 10.7370	Cost: 5.91s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 11.1358	Cost: 8.07s
Train Epoch: 305 	Average Loss: 10.9455
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5417

Learning rate: 0.0001999954094353755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 11.0674	Cost: 23.96s
Train Epoch: 306 [20480/90000 (23%)]	Loss: 10.8610	Cost: 5.96s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 10.8253	Cost: 6.68s
Train Epoch: 306 [61440/90000 (68%)]	Loss: 10.8012	Cost: 6.12s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 10.9031	Cost: 5.81s
Train Epoch: 306 	Average Loss: 10.9416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4401

Learning rate: 0.00019999537928419694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 11.2095	Cost: 24.34s
Train Epoch: 307 [20480/90000 (23%)]	Loss: 10.8911	Cost: 6.19s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 10.7952	Cost: 6.38s
Train Epoch: 307 [61440/90000 (68%)]	Loss: 10.7701	Cost: 6.06s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 10.7707	Cost: 6.18s
Train Epoch: 307 	Average Loss: 10.9080
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4393

Learning rate: 0.00019999534903432692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 10.8616	Cost: 25.63s
Train Epoch: 308 [20480/90000 (23%)]	Loss: 10.9213	Cost: 6.10s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 10.8555	Cost: 6.62s
Train Epoch: 308 [61440/90000 (68%)]	Loss: 10.8295	Cost: 6.02s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 10.9922	Cost: 7.14s
Train Epoch: 308 	Average Loss: 10.9382
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4239

Learning rate: 0.00019999531868576542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 11.1973	Cost: 28.04s
Train Epoch: 309 [20480/90000 (23%)]	Loss: 11.0116	Cost: 6.09s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 10.7510	Cost: 8.00s
Train Epoch: 309 [61440/90000 (68%)]	Loss: 10.8557	Cost: 5.97s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 10.9769	Cost: 6.08s
Train Epoch: 309 	Average Loss: 10.9220
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3720

Saving model as e309_model.pt & e309_waveforms_supplementary.hdf5
Learning rate: 0.00019999528823851252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 11.1980	Cost: 27.27s
Train Epoch: 310 [20480/90000 (23%)]	Loss: 10.9225	Cost: 6.09s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 10.7531	Cost: 7.14s
Train Epoch: 310 [61440/90000 (68%)]	Loss: 10.8978	Cost: 6.15s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 10.8330	Cost: 6.84s
Train Epoch: 310 	Average Loss: 10.8916
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4434

Learning rate: 0.00019999525769256822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 11.1723	Cost: 22.16s
Train Epoch: 311 [20480/90000 (23%)]	Loss: 10.8375	Cost: 6.05s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 10.8363	Cost: 7.23s
Train Epoch: 311 [61440/90000 (68%)]	Loss: 10.8263	Cost: 5.98s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 11.0302	Cost: 8.69s
Train Epoch: 311 	Average Loss: 10.8855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4870

Learning rate: 0.00019999522704793255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 11.2514	Cost: 23.61s
Train Epoch: 312 [20480/90000 (23%)]	Loss: 10.8033	Cost: 6.06s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 10.6048	Cost: 7.40s
Train Epoch: 312 [61440/90000 (68%)]	Loss: 10.8624	Cost: 6.02s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 10.7546	Cost: 6.21s
Train Epoch: 312 	Average Loss: 10.8726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4786

Learning rate: 0.00019999519630460553
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 11.1608	Cost: 22.62s
Train Epoch: 313 [20480/90000 (23%)]	Loss: 10.8403	Cost: 6.14s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 10.7237	Cost: 7.08s
Train Epoch: 313 [61440/90000 (68%)]	Loss: 10.6837	Cost: 6.32s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 10.6602	Cost: 6.32s
Train Epoch: 313 	Average Loss: 10.8750
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4595

Learning rate: 0.00019999516546258725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 11.1509	Cost: 26.52s
Train Epoch: 314 [20480/90000 (23%)]	Loss: 10.8983	Cost: 6.00s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 10.7398	Cost: 7.26s
Train Epoch: 314 [61440/90000 (68%)]	Loss: 10.8061	Cost: 6.06s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 10.7573	Cost: 5.93s
Train Epoch: 314 	Average Loss: 10.8735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4536

Learning rate: 0.00019999513452187764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 10.9202	Cost: 28.82s
Train Epoch: 315 [20480/90000 (23%)]	Loss: 10.8690	Cost: 6.20s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 10.6881	Cost: 6.79s
Train Epoch: 315 [61440/90000 (68%)]	Loss: 10.9287	Cost: 6.01s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 10.7420	Cost: 6.55s
Train Epoch: 315 	Average Loss: 10.8593
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4598

Learning rate: 0.0001999951034824768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 11.0654	Cost: 23.34s
Train Epoch: 316 [20480/90000 (23%)]	Loss: 10.6117	Cost: 6.06s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 10.6634	Cost: 8.26s
Train Epoch: 316 [61440/90000 (68%)]	Loss: 10.8339	Cost: 5.89s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 10.8098	Cost: 8.59s
Train Epoch: 316 	Average Loss: 10.8791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3262

Saving model as e316_model.pt & e316_waveforms_supplementary.hdf5
Learning rate: 0.00019999507234438478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 11.2040	Cost: 23.48s
Train Epoch: 317 [20480/90000 (23%)]	Loss: 10.6641	Cost: 6.49s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 10.8756	Cost: 6.31s
Train Epoch: 317 [61440/90000 (68%)]	Loss: 10.9240	Cost: 6.27s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 10.8549	Cost: 6.52s
Train Epoch: 317 	Average Loss: 10.8617
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4466

Learning rate: 0.00019999504110760157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 11.0972	Cost: 24.22s
Train Epoch: 318 [20480/90000 (23%)]	Loss: 10.8680	Cost: 6.10s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 10.7441	Cost: 6.18s
Train Epoch: 318 [61440/90000 (68%)]	Loss: 10.7838	Cost: 5.99s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 10.7478	Cost: 5.72s
Train Epoch: 318 	Average Loss: 10.8608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3984

Learning rate: 0.0001999950097721272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 11.1729	Cost: 23.68s
Train Epoch: 319 [20480/90000 (23%)]	Loss: 11.0532	Cost: 6.09s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 10.7960	Cost: 6.33s
Train Epoch: 319 [61440/90000 (68%)]	Loss: 10.6330	Cost: 6.14s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 10.8599	Cost: 5.89s
Train Epoch: 319 	Average Loss: 10.8196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4220

Learning rate: 0.00019999497833796175
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 11.1068	Cost: 27.89s
Train Epoch: 320 [20480/90000 (23%)]	Loss: 10.7549	Cost: 6.19s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 10.7414	Cost: 6.54s
Train Epoch: 320 [61440/90000 (68%)]	Loss: 10.7519	Cost: 6.42s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 10.8733	Cost: 6.19s
Train Epoch: 320 	Average Loss: 10.8276
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3820

Learning rate: 0.00019999494680510515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 11.0650	Cost: 23.73s
Train Epoch: 321 [20480/90000 (23%)]	Loss: 10.9070	Cost: 6.01s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 10.6772	Cost: 8.23s
Train Epoch: 321 [61440/90000 (68%)]	Loss: 10.8344	Cost: 6.14s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 10.8835	Cost: 7.46s
Train Epoch: 321 	Average Loss: 10.8211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3837

Learning rate: 0.00019999491517355754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 10.9976	Cost: 23.51s
Train Epoch: 322 [20480/90000 (23%)]	Loss: 10.6405	Cost: 6.03s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 10.7494	Cost: 6.24s
Train Epoch: 322 [61440/90000 (68%)]	Loss: 10.6584	Cost: 6.27s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 10.6983	Cost: 7.77s
Train Epoch: 322 	Average Loss: 10.8187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3151

Saving model as e322_model.pt & e322_waveforms_supplementary.hdf5
Learning rate: 0.00019999488344331888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 10.9944	Cost: 24.97s
Train Epoch: 323 [20480/90000 (23%)]	Loss: 10.7989	Cost: 6.18s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 10.6396	Cost: 6.19s
Train Epoch: 323 [61440/90000 (68%)]	Loss: 10.6587	Cost: 5.90s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 10.6730	Cost: 5.78s
Train Epoch: 323 	Average Loss: 10.7941
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3793

Learning rate: 0.00019999485161438922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 11.1710	Cost: 23.41s
Train Epoch: 324 [20480/90000 (23%)]	Loss: 10.7841	Cost: 6.00s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 10.7590	Cost: 6.88s
Train Epoch: 324 [61440/90000 (68%)]	Loss: 10.7463	Cost: 5.93s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 10.8116	Cost: 6.79s
Train Epoch: 324 	Average Loss: 10.8110
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4262

Learning rate: 0.0001999948196867686
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 11.1114	Cost: 30.22s
Train Epoch: 325 [20480/90000 (23%)]	Loss: 10.8580	Cost: 6.03s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 10.6897	Cost: 7.53s
Train Epoch: 325 [61440/90000 (68%)]	Loss: 10.7103	Cost: 5.90s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 10.8049	Cost: 5.53s
Train Epoch: 325 	Average Loss: 10.8113
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3677

Learning rate: 0.00019999478766045706
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 11.0354	Cost: 25.21s
Train Epoch: 326 [20480/90000 (23%)]	Loss: 10.8191	Cost: 6.04s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 10.6728	Cost: 7.70s
Train Epoch: 326 [61440/90000 (68%)]	Loss: 10.7211	Cost: 5.86s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 10.6730	Cost: 7.31s
Train Epoch: 326 	Average Loss: 10.7563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4561

Learning rate: 0.00019999475553545462
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 11.0040	Cost: 23.14s
Train Epoch: 327 [20480/90000 (23%)]	Loss: 10.6972	Cost: 5.97s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 10.6544	Cost: 6.62s
Train Epoch: 327 [61440/90000 (68%)]	Loss: 10.7874	Cost: 6.34s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 10.7259	Cost: 8.05s
Train Epoch: 327 	Average Loss: 10.7805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3720

Learning rate: 0.0001999947233117613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 10.8785	Cost: 23.46s
Train Epoch: 328 [20480/90000 (23%)]	Loss: 10.9123	Cost: 6.22s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 10.6196	Cost: 6.65s
Train Epoch: 328 [61440/90000 (68%)]	Loss: 10.7773	Cost: 5.94s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 10.7447	Cost: 6.47s
Train Epoch: 328 	Average Loss: 10.7783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3413

Learning rate: 0.00019999469098937715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 11.1343	Cost: 23.80s
Train Epoch: 329 [20480/90000 (23%)]	Loss: 10.7164	Cost: 6.16s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 10.6310	Cost: 7.82s
Train Epoch: 329 [61440/90000 (68%)]	Loss: 10.6930	Cost: 5.99s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 10.6593	Cost: 6.59s
Train Epoch: 329 	Average Loss: 10.7440
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4106

Learning rate: 0.00019999465856830218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 11.1935	Cost: 26.46s
Train Epoch: 330 [20480/90000 (23%)]	Loss: 10.7044	Cost: 5.96s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 10.5826	Cost: 7.42s
Train Epoch: 330 [61440/90000 (68%)]	Loss: 10.7513	Cost: 5.82s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 10.7192	Cost: 5.74s
Train Epoch: 330 	Average Loss: 10.7684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3935

Learning rate: 0.00019999462604853647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 11.0646	Cost: 26.87s
Train Epoch: 331 [20480/90000 (23%)]	Loss: 10.5933	Cost: 6.04s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 10.5987	Cost: 7.84s
Train Epoch: 331 [61440/90000 (68%)]	Loss: 10.6626	Cost: 5.92s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 10.7474	Cost: 7.15s
Train Epoch: 331 	Average Loss: 10.7558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3961

Learning rate: 0.00019999459343008003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 10.9802	Cost: 23.05s
Train Epoch: 332 [20480/90000 (23%)]	Loss: 10.9224	Cost: 5.88s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 10.6713	Cost: 6.36s
Train Epoch: 332 [61440/90000 (68%)]	Loss: 10.6693	Cost: 5.95s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 10.7139	Cost: 8.89s
Train Epoch: 332 	Average Loss: 10.7714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3557

Learning rate: 0.00019999456071293284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 10.9856	Cost: 24.00s
Train Epoch: 333 [20480/90000 (23%)]	Loss: 10.7457	Cost: 6.17s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 10.6200	Cost: 6.20s
Train Epoch: 333 [61440/90000 (68%)]	Loss: 10.6995	Cost: 5.87s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 10.8155	Cost: 5.93s
Train Epoch: 333 	Average Loss: 10.7509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3845

Learning rate: 0.00019999452789709498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 11.0491	Cost: 22.94s
Train Epoch: 334 [20480/90000 (23%)]	Loss: 10.7112	Cost: 6.12s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 10.6065	Cost: 6.67s
Train Epoch: 334 [61440/90000 (68%)]	Loss: 10.5868	Cost: 5.95s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 10.7098	Cost: 5.66s
Train Epoch: 334 	Average Loss: 10.7259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2466

Saving model as e334_model.pt & e334_waveforms_supplementary.hdf5
Learning rate: 0.0001999944949825665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 11.1252	Cost: 25.86s
Train Epoch: 335 [20480/90000 (23%)]	Loss: 10.7095	Cost: 6.10s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 10.6093	Cost: 7.05s
Train Epoch: 335 [61440/90000 (68%)]	Loss: 10.6382	Cost: 6.04s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 10.7098	Cost: 5.70s
Train Epoch: 335 	Average Loss: 10.7311
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3294

Learning rate: 0.0001999944619693474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 10.8950	Cost: 26.47s
Train Epoch: 336 [20480/90000 (23%)]	Loss: 10.6183	Cost: 6.02s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 10.4597	Cost: 7.31s
Train Epoch: 336 [61440/90000 (68%)]	Loss: 10.6806	Cost: 5.89s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 10.6817	Cost: 6.87s
Train Epoch: 336 	Average Loss: 10.7016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3323

Learning rate: 0.00019999442885743776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 10.9227	Cost: 24.03s
Train Epoch: 337 [20480/90000 (23%)]	Loss: 10.6208	Cost: 6.12s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 10.5898	Cost: 6.31s
Train Epoch: 337 [61440/90000 (68%)]	Loss: 10.6136	Cost: 6.05s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 10.6592	Cost: 8.82s
Train Epoch: 337 	Average Loss: 10.7013
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3723

Learning rate: 0.00019999439564683753
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 10.9806	Cost: 24.18s
Train Epoch: 338 [20480/90000 (23%)]	Loss: 10.7486	Cost: 5.93s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 10.5419	Cost: 6.26s
Train Epoch: 338 [61440/90000 (68%)]	Loss: 10.5549	Cost: 5.92s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 10.8681	Cost: 5.52s
Train Epoch: 338 	Average Loss: 10.6889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2901

Learning rate: 0.0001999943623375468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 11.1946	Cost: 22.90s
Train Epoch: 339 [20480/90000 (23%)]	Loss: 10.5696	Cost: 6.22s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 10.4420	Cost: 6.99s
Train Epoch: 339 [61440/90000 (68%)]	Loss: 10.6762	Cost: 6.08s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 10.7629	Cost: 5.93s
Train Epoch: 339 	Average Loss: 10.7124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3100

Learning rate: 0.0001999943289295656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 10.9405	Cost: 27.64s
Train Epoch: 340 [20480/90000 (23%)]	Loss: 10.6489	Cost: 6.16s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 10.5979	Cost: 7.32s
Train Epoch: 340 [61440/90000 (68%)]	Loss: 10.6317	Cost: 6.28s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 10.6279	Cost: 5.96s
Train Epoch: 340 	Average Loss: 10.7165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3537

Learning rate: 0.00019999429542289394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 10.8964	Cost: 26.97s
Train Epoch: 341 [20480/90000 (23%)]	Loss: 10.6969	Cost: 5.99s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 10.5217	Cost: 9.66s
Train Epoch: 341 [61440/90000 (68%)]	Loss: 10.4976	Cost: 6.08s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 10.7703	Cost: 8.51s
Train Epoch: 341 	Average Loss: 10.7130
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1833

Saving model as e341_model.pt & e341_waveforms_supplementary.hdf5
Learning rate: 0.00019999426181753187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 10.9232	Cost: 23.14s
Train Epoch: 342 [20480/90000 (23%)]	Loss: 10.6876	Cost: 6.05s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 10.5163	Cost: 7.81s
Train Epoch: 342 [61440/90000 (68%)]	Loss: 10.5545	Cost: 5.96s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 10.5694	Cost: 8.80s
Train Epoch: 342 	Average Loss: 10.6852
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2850

Learning rate: 0.0001999942281134794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 10.7547	Cost: 23.92s
Train Epoch: 343 [20480/90000 (23%)]	Loss: 10.8149	Cost: 5.90s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 10.5798	Cost: 6.51s
Train Epoch: 343 [61440/90000 (68%)]	Loss: 10.6212	Cost: 5.84s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 10.6451	Cost: 5.97s
Train Epoch: 343 	Average Loss: 10.7092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3495

Learning rate: 0.0001999941943107366
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 10.8751	Cost: 23.70s
Train Epoch: 344 [20480/90000 (23%)]	Loss: 10.6496	Cost: 6.24s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 10.6495	Cost: 6.27s
Train Epoch: 344 [61440/90000 (68%)]	Loss: 10.5180	Cost: 5.92s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 10.6296	Cost: 5.74s
Train Epoch: 344 	Average Loss: 10.6797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2956

Learning rate: 0.00019999416040930349
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 11.0543	Cost: 24.30s
Train Epoch: 345 [20480/90000 (23%)]	Loss: 10.6080	Cost: 6.10s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 10.4941	Cost: 6.31s
Train Epoch: 345 [61440/90000 (68%)]	Loss: 10.7406	Cost: 6.11s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 10.5276	Cost: 5.64s
Train Epoch: 345 	Average Loss: 10.6918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3321

Learning rate: 0.0001999941264091801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 11.2400	Cost: 29.35s
Train Epoch: 346 [20480/90000 (23%)]	Loss: 10.5794	Cost: 6.11s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 10.5148	Cost: 6.74s
Train Epoch: 346 [61440/90000 (68%)]	Loss: 10.4784	Cost: 6.03s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 10.6591	Cost: 5.55s
Train Epoch: 346 	Average Loss: 10.6429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3542

Learning rate: 0.00019999409231036646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 11.1446	Cost: 25.40s
Train Epoch: 347 [20480/90000 (23%)]	Loss: 10.6744	Cost: 6.03s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 10.4277	Cost: 8.41s
Train Epoch: 347 [61440/90000 (68%)]	Loss: 10.6433	Cost: 5.89s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 10.6656	Cost: 8.19s
Train Epoch: 347 	Average Loss: 10.6812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3074

Learning rate: 0.0001999940581128626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 10.7732	Cost: 24.25s
Train Epoch: 348 [20480/90000 (23%)]	Loss: 10.5353	Cost: 6.00s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 10.5393	Cost: 6.73s
Train Epoch: 348 [61440/90000 (68%)]	Loss: 10.6130	Cost: 6.11s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 10.7233	Cost: 7.99s
Train Epoch: 348 	Average Loss: 10.6516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3009

Learning rate: 0.00019999402381666855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 11.1509	Cost: 22.78s
Train Epoch: 349 [20480/90000 (23%)]	Loss: 10.6801	Cost: 6.03s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 10.4809	Cost: 7.29s
Train Epoch: 349 [61440/90000 (68%)]	Loss: 10.6397	Cost: 5.97s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 10.7346	Cost: 6.13s
Train Epoch: 349 	Average Loss: 10.6950
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2596

Learning rate: 0.0001999939894217844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 10.8445	Cost: 23.72s
Train Epoch: 350 [20480/90000 (23%)]	Loss: 10.6009	Cost: 5.98s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 10.5327	Cost: 6.66s
Train Epoch: 350 [61440/90000 (68%)]	Loss: 10.6907	Cost: 6.16s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 10.5511	Cost: 5.62s
Train Epoch: 350 	Average Loss: 10.6426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3070

Learning rate: 0.0001999939549282101
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 10.6172	Cost: 28.12s
Train Epoch: 351 [20480/90000 (23%)]	Loss: 10.6986	Cost: 6.08s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 10.5146	Cost: 6.61s
Train Epoch: 351 [61440/90000 (68%)]	Loss: 10.6004	Cost: 6.02s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 10.6389	Cost: 5.54s
Train Epoch: 351 	Average Loss: 10.6347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2287

Learning rate: 0.00019999392033594573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 10.7935	Cost: 24.25s
Train Epoch: 352 [20480/90000 (23%)]	Loss: 10.6706	Cost: 6.02s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 10.3975	Cost: 7.72s
Train Epoch: 352 [61440/90000 (68%)]	Loss: 10.6640	Cost: 5.90s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 10.5667	Cost: 7.79s
Train Epoch: 352 	Average Loss: 10.6455
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1213

Saving model as e352_model.pt & e352_waveforms_supplementary.hdf5
Learning rate: 0.0001999938856449913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 10.9010	Cost: 23.20s
Train Epoch: 353 [20480/90000 (23%)]	Loss: 10.5763	Cost: 6.03s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 10.4457	Cost: 6.34s
Train Epoch: 353 [61440/90000 (68%)]	Loss: 10.5187	Cost: 6.08s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 10.7578	Cost: 7.66s
Train Epoch: 353 	Average Loss: 10.6385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2488

Learning rate: 0.00019999385085534688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 10.8393	Cost: 24.24s
Train Epoch: 354 [20480/90000 (23%)]	Loss: 10.4959	Cost: 6.05s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 10.3989	Cost: 7.24s
Train Epoch: 354 [61440/90000 (68%)]	Loss: 10.5864	Cost: 6.15s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 10.5836	Cost: 5.88s
Train Epoch: 354 	Average Loss: 10.6468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2770

Learning rate: 0.00019999381596701247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 11.0778	Cost: 22.82s
Train Epoch: 355 [20480/90000 (23%)]	Loss: 10.6827	Cost: 5.90s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 10.4331	Cost: 7.57s
Train Epoch: 355 [61440/90000 (68%)]	Loss: 10.5084	Cost: 5.81s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 10.5165	Cost: 6.11s
Train Epoch: 355 	Average Loss: 10.6240
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2933

Learning rate: 0.00019999378097998813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 10.6683	Cost: 29.69s
Train Epoch: 356 [20480/90000 (23%)]	Loss: 10.5582	Cost: 6.02s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 10.5924	Cost: 6.97s
Train Epoch: 356 [61440/90000 (68%)]	Loss: 10.5677	Cost: 5.94s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 10.5918	Cost: 6.09s
Train Epoch: 356 	Average Loss: 10.6285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2577

Learning rate: 0.00019999374589427387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 10.9600	Cost: 25.24s
Train Epoch: 357 [20480/90000 (23%)]	Loss: 10.5987	Cost: 6.08s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 10.6098	Cost: 7.54s
Train Epoch: 357 [61440/90000 (68%)]	Loss: 10.4616	Cost: 5.87s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 10.5609	Cost: 7.65s
Train Epoch: 357 	Average Loss: 10.6113
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1703

Learning rate: 0.00019999371070986973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 10.8819	Cost: 23.15s
Train Epoch: 358 [20480/90000 (23%)]	Loss: 10.4457	Cost: 5.86s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 10.6466	Cost: 6.51s
Train Epoch: 358 [61440/90000 (68%)]	Loss: 10.4603	Cost: 6.42s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 10.4841	Cost: 7.59s
Train Epoch: 358 	Average Loss: 10.5830
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2263

Learning rate: 0.00019999367542677577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 11.1098	Cost: 22.70s
Train Epoch: 359 [20480/90000 (23%)]	Loss: 10.5386	Cost: 6.17s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 10.3622	Cost: 6.65s
Train Epoch: 359 [61440/90000 (68%)]	Loss: 10.4871	Cost: 5.98s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 10.5836	Cost: 6.49s
Train Epoch: 359 	Average Loss: 10.5962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2555

Learning rate: 0.00019999364004499203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 10.7737	Cost: 24.45s
Train Epoch: 360 [20480/90000 (23%)]	Loss: 10.4808	Cost: 5.93s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 10.5575	Cost: 8.05s
Train Epoch: 360 [61440/90000 (68%)]	Loss: 10.5144	Cost: 6.30s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 10.6931	Cost: 6.29s
Train Epoch: 360 	Average Loss: 10.6009
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1319

Learning rate: 0.0001999936045645185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 11.0386	Cost: 26.54s
Train Epoch: 361 [20480/90000 (23%)]	Loss: 10.6385	Cost: 6.09s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 10.4483	Cost: 6.32s
Train Epoch: 361 [61440/90000 (68%)]	Loss: 10.6232	Cost: 5.94s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 10.6153	Cost: 5.57s
Train Epoch: 361 	Average Loss: 10.5861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2522

Learning rate: 0.00019999356898535523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 10.8138	Cost: 26.52s
Train Epoch: 362 [20480/90000 (23%)]	Loss: 10.6144	Cost: 6.01s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 10.4069	Cost: 9.30s
Train Epoch: 362 [61440/90000 (68%)]	Loss: 10.5567	Cost: 6.06s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 10.6617	Cost: 7.65s
Train Epoch: 362 	Average Loss: 10.6043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1997

Learning rate: 0.0001999935333075023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 10.8583	Cost: 22.36s
Train Epoch: 363 [20480/90000 (23%)]	Loss: 10.3968	Cost: 5.89s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 10.3494	Cost: 6.85s
Train Epoch: 363 [61440/90000 (68%)]	Loss: 10.5202	Cost: 5.92s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 10.5221	Cost: 8.93s
Train Epoch: 363 	Average Loss: 10.5782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2818

Learning rate: 0.0001999934975309597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 10.8281	Cost: 23.23s
Train Epoch: 364 [20480/90000 (23%)]	Loss: 10.5442	Cost: 5.90s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 10.4867	Cost: 7.54s
Train Epoch: 364 [61440/90000 (68%)]	Loss: 10.4019	Cost: 6.63s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 10.5475	Cost: 6.18s
Train Epoch: 364 	Average Loss: 10.5759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2418

Learning rate: 0.00019999346165572743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 10.7198	Cost: 23.69s
Train Epoch: 365 [20480/90000 (23%)]	Loss: 10.6235	Cost: 6.23s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 10.5014	Cost: 6.83s
Train Epoch: 365 [61440/90000 (68%)]	Loss: 10.4802	Cost: 6.05s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 10.4928	Cost: 5.98s
Train Epoch: 365 	Average Loss: 10.5457
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1684

Learning rate: 0.00019999342568180562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 10.8550	Cost: 28.22s
Train Epoch: 366 [20480/90000 (23%)]	Loss: 10.4976	Cost: 6.08s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 10.4667	Cost: 6.59s
Train Epoch: 366 [61440/90000 (68%)]	Loss: 10.4136	Cost: 6.18s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 10.4005	Cost: 6.17s
Train Epoch: 366 	Average Loss: 10.5278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2747

Learning rate: 0.00019999338960919423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 10.9809	Cost: 25.34s
Train Epoch: 367 [20480/90000 (23%)]	Loss: 10.4160	Cost: 6.06s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 10.2990	Cost: 7.49s
Train Epoch: 367 [61440/90000 (68%)]	Loss: 10.3842	Cost: 5.96s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 10.5323	Cost: 7.01s
Train Epoch: 367 	Average Loss: 10.5163
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2192

Learning rate: 0.0001999933534378933
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 10.9185	Cost: 23.24s
Train Epoch: 368 [20480/90000 (23%)]	Loss: 10.4397	Cost: 6.06s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 10.4200	Cost: 6.64s
Train Epoch: 368 [61440/90000 (68%)]	Loss: 10.5007	Cost: 6.43s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 10.5685	Cost: 7.49s
Train Epoch: 368 	Average Loss: 10.5621
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2151

Learning rate: 0.00019999331716790292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 10.9273	Cost: 23.12s
Train Epoch: 369 [20480/90000 (23%)]	Loss: 10.5452	Cost: 5.99s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 10.4213	Cost: 6.66s
Train Epoch: 369 [61440/90000 (68%)]	Loss: 10.3802	Cost: 6.06s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 10.5728	Cost: 5.74s
Train Epoch: 369 	Average Loss: 10.5547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2550

Learning rate: 0.00019999328079922307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 10.9108	Cost: 24.51s
Train Epoch: 370 [20480/90000 (23%)]	Loss: 10.5072	Cost: 6.05s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 10.4939	Cost: 6.39s
Train Epoch: 370 [61440/90000 (68%)]	Loss: 10.3984	Cost: 6.42s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 10.3695	Cost: 5.72s
Train Epoch: 370 	Average Loss: 10.5679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2407

Learning rate: 0.00019999324433185383
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 10.8087	Cost: 27.68s
Train Epoch: 371 [20480/90000 (23%)]	Loss: 10.3703	Cost: 6.24s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 10.4743	Cost: 6.54s
Train Epoch: 371 [61440/90000 (68%)]	Loss: 10.4530	Cost: 6.10s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 10.4146	Cost: 6.22s
Train Epoch: 371 	Average Loss: 10.5253
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1842

Learning rate: 0.0001999932077657952
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 10.9115	Cost: 25.70s
Train Epoch: 372 [20480/90000 (23%)]	Loss: 10.6426	Cost: 6.03s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 10.5449	Cost: 8.09s
Train Epoch: 372 [61440/90000 (68%)]	Loss: 10.4074	Cost: 5.87s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 10.4322	Cost: 7.56s
Train Epoch: 372 	Average Loss: 10.5223
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1314

Learning rate: 0.00019999317110104724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 10.6419	Cost: 23.10s
Train Epoch: 373 [20480/90000 (23%)]	Loss: 10.6333	Cost: 5.95s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 10.4742	Cost: 5.98s
Train Epoch: 373 [61440/90000 (68%)]	Loss: 10.4991	Cost: 6.21s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 10.5032	Cost: 7.96s
Train Epoch: 373 	Average Loss: 10.5360
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2972

Learning rate: 0.00019999313433760997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 10.9734	Cost: 23.07s
Train Epoch: 374 [20480/90000 (23%)]	Loss: 10.5980	Cost: 6.03s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 10.3553	Cost: 6.79s
Train Epoch: 374 [61440/90000 (68%)]	Loss: 10.5337	Cost: 5.87s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 10.4936	Cost: 5.71s
Train Epoch: 374 	Average Loss: 10.4967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2082

Learning rate: 0.00019999309747548342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 10.9558	Cost: 23.58s
Train Epoch: 375 [20480/90000 (23%)]	Loss: 10.3361	Cost: 5.99s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 10.3807	Cost: 6.08s
Train Epoch: 375 [61440/90000 (68%)]	Loss: 10.3432	Cost: 5.79s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 10.3421	Cost: 5.50s
Train Epoch: 375 	Average Loss: 10.5178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2076

Learning rate: 0.00019999306051466764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 10.9741	Cost: 27.86s
Train Epoch: 376 [20480/90000 (23%)]	Loss: 10.3316	Cost: 6.02s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 10.3200	Cost: 6.82s
Train Epoch: 376 [61440/90000 (68%)]	Loss: 10.3995	Cost: 6.09s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 10.5186	Cost: 6.18s
Train Epoch: 376 	Average Loss: 10.5113
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1892

Learning rate: 0.0001999930234551627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 10.9847	Cost: 23.92s
Train Epoch: 377 [20480/90000 (23%)]	Loss: 10.3425	Cost: 6.02s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 10.4097	Cost: 8.37s
Train Epoch: 377 [61440/90000 (68%)]	Loss: 10.4253	Cost: 5.91s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 10.4181	Cost: 8.31s
Train Epoch: 377 	Average Loss: 10.5035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1712

Learning rate: 0.00019999298629696857
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 10.6843	Cost: 24.02s
Train Epoch: 378 [20480/90000 (23%)]	Loss: 10.4189	Cost: 6.07s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 10.4726	Cost: 6.65s
Train Epoch: 378 [61440/90000 (68%)]	Loss: 10.3637	Cost: 6.10s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 10.5195	Cost: 8.40s
Train Epoch: 378 	Average Loss: 10.4983
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1960

Learning rate: 0.00019999294904008533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 10.8274	Cost: 24.55s
Train Epoch: 379 [20480/90000 (23%)]	Loss: 10.4054	Cost: 6.17s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 10.3878	Cost: 6.35s
Train Epoch: 379 [61440/90000 (68%)]	Loss: 10.4288	Cost: 5.85s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 10.4277	Cost: 6.47s
Train Epoch: 379 	Average Loss: 10.4535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1694

Learning rate: 0.000199992911684513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 10.7694	Cost: 22.95s
Train Epoch: 380 [20480/90000 (23%)]	Loss: 10.6888	Cost: 6.12s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 10.4448	Cost: 8.03s
Train Epoch: 380 [61440/90000 (68%)]	Loss: 10.4769	Cost: 6.07s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 10.5350	Cost: 6.48s
Train Epoch: 380 	Average Loss: 10.4833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1615

Learning rate: 0.0001999928742302516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 10.8867	Cost: 26.67s
Train Epoch: 381 [20480/90000 (23%)]	Loss: 10.4092	Cost: 6.17s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 10.3251	Cost: 7.09s
Train Epoch: 381 [61440/90000 (68%)]	Loss: 10.4263	Cost: 6.05s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 10.3543	Cost: 7.52s
Train Epoch: 381 	Average Loss: 10.4722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1991

Learning rate: 0.00019999283667730122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 10.7650	Cost: 29.16s
Train Epoch: 382 [20480/90000 (23%)]	Loss: 10.2890	Cost: 6.14s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 10.4469	Cost: 6.88s
Train Epoch: 382 [61440/90000 (68%)]	Loss: 10.2213	Cost: 6.16s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 10.4370	Cost: 5.75s
Train Epoch: 382 	Average Loss: 10.4322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2161

Learning rate: 0.00019999279902566184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 10.9571	Cost: 25.41s
Train Epoch: 383 [20480/90000 (23%)]	Loss: 10.5320	Cost: 6.01s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 10.5202	Cost: 8.38s
Train Epoch: 383 [61440/90000 (68%)]	Loss: 10.3696	Cost: 5.95s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 10.3341	Cost: 7.61s
Train Epoch: 383 	Average Loss: 10.4778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2240

Learning rate: 0.0001999927612753335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 11.0125	Cost: 23.21s
Train Epoch: 384 [20480/90000 (23%)]	Loss: 10.3766	Cost: 6.12s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 10.2633	Cost: 6.69s
Train Epoch: 384 [61440/90000 (68%)]	Loss: 10.3252	Cost: 6.09s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 10.2855	Cost: 8.59s
Train Epoch: 384 	Average Loss: 10.4200
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2002

Learning rate: 0.00019999272342631632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 11.0373	Cost: 24.67s
Train Epoch: 385 [20480/90000 (23%)]	Loss: 10.3095	Cost: 5.98s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 10.4125	Cost: 7.46s
Train Epoch: 385 [61440/90000 (68%)]	Loss: 10.3406	Cost: 5.81s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 10.4971	Cost: 5.70s
Train Epoch: 385 	Average Loss: 10.4534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2274

Learning rate: 0.00019999268547861025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 11.0609	Cost: 23.44s
Train Epoch: 386 [20480/90000 (23%)]	Loss: 10.4249	Cost: 6.13s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 10.4761	Cost: 7.74s
Train Epoch: 386 [61440/90000 (68%)]	Loss: 10.4600	Cost: 5.90s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 10.3777	Cost: 6.13s
Train Epoch: 386 	Average Loss: 10.4703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1794

Learning rate: 0.00019999264743221536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 10.7390	Cost: 26.81s
Train Epoch: 387 [20480/90000 (23%)]	Loss: 10.6094	Cost: 5.95s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 10.3131	Cost: 7.36s
Train Epoch: 387 [61440/90000 (68%)]	Loss: 10.3804	Cost: 5.94s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 10.3515	Cost: 5.98s
Train Epoch: 387 	Average Loss: 10.4658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1517

Learning rate: 0.00019999260928713167
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 10.7289	Cost: 27.38s
Train Epoch: 388 [20480/90000 (23%)]	Loss: 10.4630	Cost: 6.03s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 10.3317	Cost: 6.76s
Train Epoch: 388 [61440/90000 (68%)]	Loss: 10.3163	Cost: 6.07s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 10.3916	Cost: 6.25s
Train Epoch: 388 	Average Loss: 10.4310
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1273

Learning rate: 0.00019999257104335924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 10.8375	Cost: 21.96s
Train Epoch: 389 [20480/90000 (23%)]	Loss: 10.4909	Cost: 6.03s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 10.2820	Cost: 7.08s
Train Epoch: 389 [61440/90000 (68%)]	Loss: 10.3699	Cost: 6.00s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 10.3291	Cost: 8.39s
Train Epoch: 389 	Average Loss: 10.4264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2269

Learning rate: 0.00019999253270089811
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 10.8466	Cost: 24.06s
Train Epoch: 390 [20480/90000 (23%)]	Loss: 10.4064	Cost: 6.01s
Train Epoch: 390 [40960/90000 (45%)]	Loss: 10.1587	Cost: 6.50s
Train Epoch: 390 [61440/90000 (68%)]	Loss: 10.3221	Cost: 5.92s
Train Epoch: 390 [81920/90000 (91%)]	Loss: 10.3577	Cost: 5.75s
Train Epoch: 390 	Average Loss: 10.3946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1969

Learning rate: 0.0001999924942597483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 10.8698	Cost: 23.79s
Train Epoch: 391 [20480/90000 (23%)]	Loss: 10.4580	Cost: 6.15s
Train Epoch: 391 [40960/90000 (45%)]	Loss: 10.2683	Cost: 7.88s
Train Epoch: 391 [61440/90000 (68%)]	Loss: 10.3629	Cost: 6.03s
Train Epoch: 391 [81920/90000 (91%)]	Loss: 10.5074	Cost: 6.11s
Train Epoch: 391 	Average Loss: 10.4134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1437

Learning rate: 0.00019999245571990988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 10.8603	Cost: 25.59s
Train Epoch: 392 [20480/90000 (23%)]	Loss: 10.4313	Cost: 6.14s
Train Epoch: 392 [40960/90000 (45%)]	Loss: 10.2792	Cost: 6.73s
Train Epoch: 392 [61440/90000 (68%)]	Loss: 10.1344	Cost: 6.12s
Train Epoch: 392 [81920/90000 (91%)]	Loss: 10.3982	Cost: 6.39s
Train Epoch: 392 	Average Loss: 10.4389
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2159

Learning rate: 0.00019999241708138285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 10.8893	Cost: 28.23s
Train Epoch: 393 [20480/90000 (23%)]	Loss: 10.4335	Cost: 5.99s
Train Epoch: 393 [40960/90000 (45%)]	Loss: 10.1160	Cost: 8.97s
Train Epoch: 393 [61440/90000 (68%)]	Loss: 10.2536	Cost: 6.12s
Train Epoch: 393 [81920/90000 (91%)]	Loss: 10.3447	Cost: 6.02s
Train Epoch: 393 	Average Loss: 10.4022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1257

Learning rate: 0.00019999237834416724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 10.7321	Cost: 23.01s
Train Epoch: 394 [20480/90000 (23%)]	Loss: 10.3638	Cost: 5.96s
Train Epoch: 394 [40960/90000 (45%)]	Loss: 10.3112	Cost: 8.31s
Train Epoch: 394 [61440/90000 (68%)]	Loss: 10.1315	Cost: 5.90s
Train Epoch: 394 [81920/90000 (91%)]	Loss: 10.2744	Cost: 9.17s
Train Epoch: 394 	Average Loss: 10.3895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0946

Saving model as e394_model.pt & e394_waveforms_supplementary.hdf5
Learning rate: 0.0001999923395082631
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 10.7678	Cost: 24.06s
Train Epoch: 395 [20480/90000 (23%)]	Loss: 10.2818	Cost: 6.08s
Train Epoch: 395 [40960/90000 (45%)]	Loss: 10.1556	Cost: 6.41s
Train Epoch: 395 [61440/90000 (68%)]	Loss: 10.2360	Cost: 6.05s
Train Epoch: 395 [81920/90000 (91%)]	Loss: 10.4046	Cost: 7.16s
Train Epoch: 395 	Average Loss: 10.3645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1543

Learning rate: 0.0001999923005736705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 10.9814	Cost: 23.77s
Train Epoch: 396 [20480/90000 (23%)]	Loss: 10.4703	Cost: 6.10s
Train Epoch: 396 [40960/90000 (45%)]	Loss: 10.2276	Cost: 7.08s
Train Epoch: 396 [61440/90000 (68%)]	Loss: 10.2760	Cost: 6.12s
Train Epoch: 396 [81920/90000 (91%)]	Loss: 10.1991	Cost: 5.73s
Train Epoch: 396 	Average Loss: 10.3864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1160

Learning rate: 0.00019999226154038944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 10.9091	Cost: 26.05s
Train Epoch: 397 [20480/90000 (23%)]	Loss: 10.3568	Cost: 6.15s
Train Epoch: 397 [40960/90000 (45%)]	Loss: 10.1169	Cost: 7.05s
Train Epoch: 397 [61440/90000 (68%)]	Loss: 10.4514	Cost: 5.90s
Train Epoch: 397 [81920/90000 (91%)]	Loss: 10.3674	Cost: 6.18s
Train Epoch: 397 	Average Loss: 10.4001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1156

Learning rate: 0.00019999222240841996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 10.7679	Cost: 28.17s
Train Epoch: 398 [20480/90000 (23%)]	Loss: 10.2519	Cost: 6.02s
Train Epoch: 398 [40960/90000 (45%)]	Loss: 10.2987	Cost: 6.73s
Train Epoch: 398 [61440/90000 (68%)]	Loss: 10.2363	Cost: 6.07s
Train Epoch: 398 [81920/90000 (91%)]	Loss: 10.2403	Cost: 5.66s
Train Epoch: 398 	Average Loss: 10.3486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0118

Saving model as e398_model.pt & e398_waveforms_supplementary.hdf5
Learning rate: 0.00019999218317776212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 10.7360	Cost: 27.51s
Train Epoch: 399 [20480/90000 (23%)]	Loss: 10.3473	Cost: 6.19s
Train Epoch: 399 [40960/90000 (45%)]	Loss: 10.2830	Cost: 7.07s
Train Epoch: 399 [61440/90000 (68%)]	Loss: 10.2856	Cost: 6.15s
Train Epoch: 399 [81920/90000 (91%)]	Loss: 10.1485	Cost: 6.67s
Train Epoch: 399 	Average Loss: 10.3740
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1180

Learning rate: 0.00019999214384841597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 10.7006	Cost: 22.56s
Train Epoch: 400 [20480/90000 (23%)]	Loss: 10.3101	Cost: 6.20s
Train Epoch: 400 [40960/90000 (45%)]	Loss: 10.3292	Cost: 6.76s
Train Epoch: 400 [61440/90000 (68%)]	Loss: 10.4169	Cost: 6.03s
Train Epoch: 400 [81920/90000 (91%)]	Loss: 10.3092	Cost: 8.75s
Train Epoch: 400 	Average Loss: 10.3539
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1214

Learning rate: 0.00019999210442038154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 401 [0/90000 (0%)]	Loss: 10.7306	Cost: 23.23s
Train Epoch: 401 [20480/90000 (23%)]	Loss: 10.2315	Cost: 6.09s
Train Epoch: 401 [40960/90000 (45%)]	Loss: 10.0512	Cost: 7.22s
Train Epoch: 401 [61440/90000 (68%)]	Loss: 10.2473	Cost: 6.14s
Train Epoch: 401 [81920/90000 (91%)]	Loss: 10.2680	Cost: 6.20s
Train Epoch: 401 	Average Loss: 10.3271
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1138

Learning rate: 0.00019999206489365883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 402 [0/90000 (0%)]	Loss: 10.7367	Cost: 23.92s
Train Epoch: 402 [20480/90000 (23%)]	Loss: 10.3701	Cost: 6.11s
Train Epoch: 402 [40960/90000 (45%)]	Loss: 10.0675	Cost: 6.22s
Train Epoch: 402 [61440/90000 (68%)]	Loss: 10.3003	Cost: 6.09s
Train Epoch: 402 [81920/90000 (91%)]	Loss: 10.2832	Cost: 6.23s
Train Epoch: 402 	Average Loss: 10.3732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1056

Learning rate: 0.0001999920252682479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 403 [0/90000 (0%)]	Loss: 10.7368	Cost: 27.20s
Train Epoch: 403 [20480/90000 (23%)]	Loss: 10.1376	Cost: 6.11s
Train Epoch: 403 [40960/90000 (45%)]	Loss: 10.0876	Cost: 7.41s
Train Epoch: 403 [61440/90000 (68%)]	Loss: 10.1396	Cost: 5.98s
Train Epoch: 403 [81920/90000 (91%)]	Loss: 10.2083	Cost: 5.82s
Train Epoch: 403 	Average Loss: 10.3120
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0812

Learning rate: 0.00019999198554414882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 404 [0/90000 (0%)]	Loss: 10.8287	Cost: 28.47s
Train Epoch: 404 [20480/90000 (23%)]	Loss: 10.4310	Cost: 6.00s
Train Epoch: 404 [40960/90000 (45%)]	Loss: 10.2115	Cost: 8.83s
Train Epoch: 404 [61440/90000 (68%)]	Loss: 10.1833	Cost: 5.84s
Train Epoch: 404 [81920/90000 (91%)]	Loss: 10.4003	Cost: 6.01s
Train Epoch: 404 	Average Loss: 10.3732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1140

Learning rate: 0.0001999919457213616
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 405 [0/90000 (0%)]	Loss: 10.6001	Cost: 23.40s
Train Epoch: 405 [20480/90000 (23%)]	Loss: 10.2854	Cost: 6.02s
Train Epoch: 405 [40960/90000 (45%)]	Loss: 10.1407	Cost: 7.99s
Train Epoch: 405 [61440/90000 (68%)]	Loss: 10.2341	Cost: 5.99s
Train Epoch: 405 [81920/90000 (91%)]	Loss: 10.3073	Cost: 8.89s
Train Epoch: 405 	Average Loss: 10.3308
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2258

Learning rate: 0.00019999190579988627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 406 [0/90000 (0%)]	Loss: 10.6943	Cost: 22.94s
Train Epoch: 406 [20480/90000 (23%)]	Loss: 10.2202	Cost: 6.05s
Train Epoch: 406 [40960/90000 (45%)]	Loss: 10.2828	Cost: 6.49s
Train Epoch: 406 [61440/90000 (68%)]	Loss: 10.0918	Cost: 6.25s
Train Epoch: 406 [81920/90000 (91%)]	Loss: 10.2558	Cost: 7.58s
Train Epoch: 406 	Average Loss: 10.3465
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1719

Learning rate: 0.0001999918657797229
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 407 [0/90000 (0%)]	Loss: 10.8129	Cost: 23.45s
Train Epoch: 407 [20480/90000 (23%)]	Loss: 10.2033	Cost: 6.00s
Train Epoch: 407 [40960/90000 (45%)]	Loss: 10.1807	Cost: 7.40s
Train Epoch: 407 [61440/90000 (68%)]	Loss: 10.3148	Cost: 6.00s
Train Epoch: 407 [81920/90000 (91%)]	Loss: 10.3753	Cost: 6.64s
Train Epoch: 407 	Average Loss: 10.3265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1398

Learning rate: 0.00019999182566087152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 408 [0/90000 (0%)]	Loss: 10.9675	Cost: 23.76s
Train Epoch: 408 [20480/90000 (23%)]	Loss: 10.1666	Cost: 6.03s
Train Epoch: 408 [40960/90000 (45%)]	Loss: 10.3066	Cost: 7.69s
Train Epoch: 408 [61440/90000 (68%)]	Loss: 10.2820	Cost: 6.00s
Train Epoch: 408 [81920/90000 (91%)]	Loss: 10.2356	Cost: 5.93s
Train Epoch: 408 	Average Loss: 10.3542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0509

Learning rate: 0.00019999178544333215
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 409 [0/90000 (0%)]	Loss: 10.8365	Cost: 27.43s
Train Epoch: 409 [20480/90000 (23%)]	Loss: 10.2908	Cost: 6.14s
Train Epoch: 409 [40960/90000 (45%)]	Loss: 10.1116	Cost: 7.32s
Train Epoch: 409 [61440/90000 (68%)]	Loss: 10.2973	Cost: 5.85s
Train Epoch: 409 [81920/90000 (91%)]	Loss: 10.4247	Cost: 6.06s
Train Epoch: 409 	Average Loss: 10.3071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1258

Learning rate: 0.00019999174512710485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 410 [0/90000 (0%)]	Loss: 10.7869	Cost: 25.70s
Train Epoch: 410 [20480/90000 (23%)]	Loss: 10.1628	Cost: 6.02s
Train Epoch: 410 [40960/90000 (45%)]	Loss: 10.1362	Cost: 8.73s
Train Epoch: 410 [61440/90000 (68%)]	Loss: 10.1561	Cost: 5.85s
Train Epoch: 410 [81920/90000 (91%)]	Loss: 10.2420	Cost: 9.79s
Train Epoch: 410 	Average Loss: 10.3069
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1125

Learning rate: 0.00019999170471218965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 411 [0/90000 (0%)]	Loss: 10.9583	Cost: 24.23s
Train Epoch: 411 [20480/90000 (23%)]	Loss: 10.2220	Cost: 6.06s
Train Epoch: 411 [40960/90000 (45%)]	Loss: 10.2565	Cost: 6.45s
Train Epoch: 411 [61440/90000 (68%)]	Loss: 10.2215	Cost: 6.11s
Train Epoch: 411 [81920/90000 (91%)]	Loss: 10.3089	Cost: 8.40s
Train Epoch: 411 	Average Loss: 10.2809
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1381

Learning rate: 0.0001999916641985866
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 412 [0/90000 (0%)]	Loss: 10.8636	Cost: 23.81s
Train Epoch: 412 [20480/90000 (23%)]	Loss: 10.1525	Cost: 6.15s
Train Epoch: 412 [40960/90000 (45%)]	Loss: 10.1439	Cost: 7.63s
Train Epoch: 412 [61440/90000 (68%)]	Loss: 10.2148	Cost: 5.90s
Train Epoch: 412 [81920/90000 (91%)]	Loss: 10.2868	Cost: 5.81s
Train Epoch: 412 	Average Loss: 10.2982
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0442

Learning rate: 0.00019999162358629572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 413 [0/90000 (0%)]	Loss: 10.5977	Cost: 24.84s
Train Epoch: 413 [20480/90000 (23%)]	Loss: 10.0500	Cost: 6.31s
Train Epoch: 413 [40960/90000 (45%)]	Loss: 10.1804	Cost: 6.48s
Train Epoch: 413 [61440/90000 (68%)]	Loss: 10.2544	Cost: 5.98s
Train Epoch: 413 [81920/90000 (91%)]	Loss: 10.3462	Cost: 5.75s
Train Epoch: 413 	Average Loss: 10.3131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0118

Learning rate: 0.0001999915828753171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 414 [0/90000 (0%)]	Loss: 10.7683	Cost: 27.76s
Train Epoch: 414 [20480/90000 (23%)]	Loss: 10.2031	Cost: 6.01s
Train Epoch: 414 [40960/90000 (45%)]	Loss: 10.1617	Cost: 6.60s
Train Epoch: 414 [61440/90000 (68%)]	Loss: 10.1868	Cost: 5.97s
Train Epoch: 414 [81920/90000 (91%)]	Loss: 10.2369	Cost: 5.83s
Train Epoch: 414 	Average Loss: 10.2877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1257

Learning rate: 0.0001999915420656507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 415 [0/90000 (0%)]	Loss: 10.7355	Cost: 26.52s
Train Epoch: 415 [20480/90000 (23%)]	Loss: 10.1783	Cost: 6.02s
Train Epoch: 415 [40960/90000 (45%)]	Loss: 10.1272	Cost: 8.93s
Train Epoch: 415 [61440/90000 (68%)]	Loss: 10.2310	Cost: 6.11s
Train Epoch: 415 [81920/90000 (91%)]	Loss: 10.2332	Cost: 7.76s
Train Epoch: 415 	Average Loss: 10.3034
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1346

Learning rate: 0.0001999915011572966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 416 [0/90000 (0%)]	Loss: 10.7136	Cost: 22.65s
Train Epoch: 416 [20480/90000 (23%)]	Loss: 10.2956	Cost: 6.10s
Train Epoch: 416 [40960/90000 (45%)]	Loss: 10.2389	Cost: 6.71s
Train Epoch: 416 [61440/90000 (68%)]	Loss: 10.1860	Cost: 6.11s
Train Epoch: 416 [81920/90000 (91%)]	Loss: 10.2807	Cost: 7.85s
Train Epoch: 416 	Average Loss: 10.2657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1360

Learning rate: 0.0001999914601502549
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 417 [0/90000 (0%)]	Loss: 10.7672	Cost: 23.58s
Train Epoch: 417 [20480/90000 (23%)]	Loss: 10.2768	Cost: 6.14s
Train Epoch: 417 [40960/90000 (45%)]	Loss: 10.1528	Cost: 6.85s
Train Epoch: 417 [61440/90000 (68%)]	Loss: 10.2011	Cost: 5.96s
Train Epoch: 417 [81920/90000 (91%)]	Loss: 10.2248	Cost: 5.92s
Train Epoch: 417 	Average Loss: 10.2977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0763

Learning rate: 0.00019999141904452554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 418 [0/90000 (0%)]	Loss: 10.8670	Cost: 23.75s
Train Epoch: 418 [20480/90000 (23%)]	Loss: 10.4049	Cost: 6.03s
Train Epoch: 418 [40960/90000 (45%)]	Loss: 10.0468	Cost: 6.54s
Train Epoch: 418 [61440/90000 (68%)]	Loss: 10.1321	Cost: 6.45s
Train Epoch: 418 [81920/90000 (91%)]	Loss: 10.2243	Cost: 6.20s
Train Epoch: 418 	Average Loss: 10.2522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1559

Learning rate: 0.0001999913778401086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 419 [0/90000 (0%)]	Loss: 10.8118	Cost: 27.66s
Train Epoch: 419 [20480/90000 (23%)]	Loss: 10.0498	Cost: 6.31s
Train Epoch: 419 [40960/90000 (45%)]	Loss: 10.1494	Cost: 6.93s
Train Epoch: 419 [61440/90000 (68%)]	Loss: 9.8856	Cost: 5.96s
Train Epoch: 419 [81920/90000 (91%)]	Loss: 10.3406	Cost: 6.16s
Train Epoch: 419 	Average Loss: 10.2448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1383

Learning rate: 0.00019999133653700416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 420 [0/90000 (0%)]	Loss: 10.6908	Cost: 27.26s
Train Epoch: 420 [20480/90000 (23%)]	Loss: 10.1162	Cost: 6.20s
Train Epoch: 420 [40960/90000 (45%)]	Loss: 10.1246	Cost: 9.00s
Train Epoch: 420 [61440/90000 (68%)]	Loss: 10.1905	Cost: 6.02s
Train Epoch: 420 [81920/90000 (91%)]	Loss: 10.2767	Cost: 8.13s
Train Epoch: 420 	Average Loss: 10.2382
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0849

Learning rate: 0.0001999912951352122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 421 [0/90000 (0%)]	Loss: 10.4799	Cost: 24.07s
Train Epoch: 421 [20480/90000 (23%)]	Loss: 10.1311	Cost: 6.08s
Train Epoch: 421 [40960/90000 (45%)]	Loss: 10.0174	Cost: 7.46s
Train Epoch: 421 [61440/90000 (68%)]	Loss: 10.0857	Cost: 5.93s
Train Epoch: 421 [81920/90000 (91%)]	Loss: 9.9955	Cost: 8.02s
Train Epoch: 421 	Average Loss: 10.2410
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0771

Learning rate: 0.0001999912536347328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 422 [0/90000 (0%)]	Loss: 10.7842	Cost: 24.18s
Train Epoch: 422 [20480/90000 (23%)]	Loss: 10.2037	Cost: 6.08s
Train Epoch: 422 [40960/90000 (45%)]	Loss: 10.1003	Cost: 6.35s
Train Epoch: 422 [61440/90000 (68%)]	Loss: 9.9611	Cost: 5.74s
Train Epoch: 422 [81920/90000 (91%)]	Loss: 10.0997	Cost: 5.88s
Train Epoch: 422 	Average Loss: 10.2423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1657

Learning rate: 0.00019999121203556597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 423 [0/90000 (0%)]	Loss: 10.7701	Cost: 24.36s
Train Epoch: 423 [20480/90000 (23%)]	Loss: 10.0731	Cost: 6.22s
Train Epoch: 423 [40960/90000 (45%)]	Loss: 9.9941	Cost: 7.46s
Train Epoch: 423 [61440/90000 (68%)]	Loss: 10.1158	Cost: 6.31s
Train Epoch: 423 [81920/90000 (91%)]	Loss: 10.1020	Cost: 6.03s
Train Epoch: 423 	Average Loss: 10.2425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0596

Learning rate: 0.0001999911703377118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 424 [0/90000 (0%)]	Loss: 10.5967	Cost: 25.61s
Train Epoch: 424 [20480/90000 (23%)]	Loss: 10.0772	Cost: 6.03s
Train Epoch: 424 [40960/90000 (45%)]	Loss: 10.1085	Cost: 6.71s
Train Epoch: 424 [61440/90000 (68%)]	Loss: 10.1565	Cost: 6.04s
Train Epoch: 424 [81920/90000 (91%)]	Loss: 10.2227	Cost: 6.53s
Train Epoch: 424 	Average Loss: 10.2796
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0898

Learning rate: 0.00019999112854117028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 425 [0/90000 (0%)]	Loss: 10.9228	Cost: 28.09s
Train Epoch: 425 [20480/90000 (23%)]	Loss: 10.1891	Cost: 6.16s
Train Epoch: 425 [40960/90000 (45%)]	Loss: 9.9882	Cost: 6.47s
Train Epoch: 425 [61440/90000 (68%)]	Loss: 10.2368	Cost: 5.90s
Train Epoch: 425 [81920/90000 (91%)]	Loss: 10.1402	Cost: 5.61s
Train Epoch: 425 	Average Loss: 10.2520
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0922

Learning rate: 0.00019999108664594148
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 426 [0/90000 (0%)]	Loss: 10.6018	Cost: 23.57s
Train Epoch: 426 [20480/90000 (23%)]	Loss: 10.2065	Cost: 6.14s
Train Epoch: 426 [40960/90000 (45%)]	Loss: 10.0364	Cost: 7.63s
Train Epoch: 426 [61440/90000 (68%)]	Loss: 10.1471	Cost: 5.91s
Train Epoch: 426 [81920/90000 (91%)]	Loss: 10.2023	Cost: 7.51s
Train Epoch: 426 	Average Loss: 10.2155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0899

Learning rate: 0.0001999910446520254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 427 [0/90000 (0%)]	Loss: 10.7159	Cost: 23.45s
Train Epoch: 427 [20480/90000 (23%)]	Loss: 10.1857	Cost: 5.96s
Train Epoch: 427 [40960/90000 (45%)]	Loss: 10.1020	Cost: 6.51s
Train Epoch: 427 [61440/90000 (68%)]	Loss: 10.1343	Cost: 6.14s
Train Epoch: 427 [81920/90000 (91%)]	Loss: 10.2367	Cost: 8.53s
Train Epoch: 427 	Average Loss: 10.2227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0832

Learning rate: 0.00019999100255942216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 428 [0/90000 (0%)]	Loss: 10.7725	Cost: 23.33s
Train Epoch: 428 [20480/90000 (23%)]	Loss: 10.1227	Cost: 6.05s
Train Epoch: 428 [40960/90000 (45%)]	Loss: 10.1022	Cost: 6.94s
Train Epoch: 428 [61440/90000 (68%)]	Loss: 10.0609	Cost: 5.88s
Train Epoch: 428 [81920/90000 (91%)]	Loss: 10.0891	Cost: 6.02s
Train Epoch: 428 	Average Loss: 10.1938
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1479

Learning rate: 0.00019999096036813171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 429 [0/90000 (0%)]	Loss: 10.5636	Cost: 24.69s
Train Epoch: 429 [20480/90000 (23%)]	Loss: 10.1747	Cost: 6.05s
Train Epoch: 429 [40960/90000 (45%)]	Loss: 10.1658	Cost: 7.67s
Train Epoch: 429 [61440/90000 (68%)]	Loss: 10.2383	Cost: 6.16s
Train Epoch: 429 [81920/90000 (91%)]	Loss: 10.3065	Cost: 6.03s
Train Epoch: 429 	Average Loss: 10.2198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1149

Learning rate: 0.0001999909180781542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 430 [0/90000 (0%)]	Loss: 10.6746	Cost: 28.53s
Train Epoch: 430 [20480/90000 (23%)]	Loss: 10.0979	Cost: 6.12s
Train Epoch: 430 [40960/90000 (45%)]	Loss: 10.1778	Cost: 7.70s
Train Epoch: 430 [61440/90000 (68%)]	Loss: 10.1811	Cost: 6.00s
Train Epoch: 430 [81920/90000 (91%)]	Loss: 10.0964	Cost: 5.77s
Train Epoch: 430 	Average Loss: 10.2283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0720

Learning rate: 0.00019999087568948958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 431 [0/90000 (0%)]	Loss: 10.7119	Cost: 24.86s
Train Epoch: 431 [20480/90000 (23%)]	Loss: 10.1203	Cost: 6.03s
Train Epoch: 431 [40960/90000 (45%)]	Loss: 10.0018	Cost: 8.71s
Train Epoch: 431 [61440/90000 (68%)]	Loss: 10.1592	Cost: 6.45s
Train Epoch: 431 [81920/90000 (91%)]	Loss: 10.3143	Cost: 8.17s
Train Epoch: 431 	Average Loss: 10.1966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1566

Learning rate: 0.0001999908332021379
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 432 [0/90000 (0%)]	Loss: 10.8155	Cost: 23.01s
Train Epoch: 432 [20480/90000 (23%)]	Loss: 10.0710	Cost: 6.05s
Train Epoch: 432 [40960/90000 (45%)]	Loss: 10.0853	Cost: 6.90s
Train Epoch: 432 [61440/90000 (68%)]	Loss: 10.1542	Cost: 6.08s
Train Epoch: 432 [81920/90000 (91%)]	Loss: 10.3061	Cost: 8.85s
Train Epoch: 432 	Average Loss: 10.1903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1017

Learning rate: 0.00019999079061609924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 433 [0/90000 (0%)]	Loss: 10.7270	Cost: 24.27s
Train Epoch: 433 [20480/90000 (23%)]	Loss: 10.1098	Cost: 5.90s
Train Epoch: 433 [40960/90000 (45%)]	Loss: 10.0154	Cost: 7.37s
Train Epoch: 433 [61440/90000 (68%)]	Loss: 10.0009	Cost: 5.77s
Train Epoch: 433 [81920/90000 (91%)]	Loss: 9.9288	Cost: 5.90s
Train Epoch: 433 	Average Loss: 10.1876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0708

Learning rate: 0.00019999074793137364
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 434 [0/90000 (0%)]	Loss: 10.6750	Cost: 23.02s
Train Epoch: 434 [20480/90000 (23%)]	Loss: 10.2264	Cost: 6.05s
Train Epoch: 434 [40960/90000 (45%)]	Loss: 10.0060	Cost: 6.78s
Train Epoch: 434 [61440/90000 (68%)]	Loss: 10.1430	Cost: 6.31s
Train Epoch: 434 [81920/90000 (91%)]	Loss: 10.2166	Cost: 5.69s
Train Epoch: 434 	Average Loss: 10.1589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0425

Learning rate: 0.00019999070514796111
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 435 [0/90000 (0%)]	Loss: 10.7882	Cost: 27.19s
Train Epoch: 435 [20480/90000 (23%)]	Loss: 10.0886	Cost: 6.02s
Train Epoch: 435 [40960/90000 (45%)]	Loss: 10.0891	Cost: 7.66s
Train Epoch: 435 [61440/90000 (68%)]	Loss: 9.9519	Cost: 5.80s
Train Epoch: 435 [81920/90000 (91%)]	Loss: 10.0467	Cost: 5.77s
Train Epoch: 435 	Average Loss: 10.1701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0395

Learning rate: 0.00019999066226586174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 436 [0/90000 (0%)]	Loss: 10.8963	Cost: 26.71s
Train Epoch: 436 [20480/90000 (23%)]	Loss: 10.2077	Cost: 6.05s
Train Epoch: 436 [40960/90000 (45%)]	Loss: 9.9658	Cost: 7.74s
Train Epoch: 436 [61440/90000 (68%)]	Loss: 10.0628	Cost: 6.06s
Train Epoch: 436 [81920/90000 (91%)]	Loss: 10.0775	Cost: 6.59s
Train Epoch: 436 	Average Loss: 10.1849
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0723

Learning rate: 0.00019999061928507552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 437 [0/90000 (0%)]	Loss: 10.8083	Cost: 22.44s
Train Epoch: 437 [20480/90000 (23%)]	Loss: 10.0521	Cost: 6.08s
Train Epoch: 437 [40960/90000 (45%)]	Loss: 10.1430	Cost: 6.49s
Train Epoch: 437 [61440/90000 (68%)]	Loss: 10.0397	Cost: 6.03s
Train Epoch: 437 [81920/90000 (91%)]	Loss: 10.0260	Cost: 8.74s
Train Epoch: 437 	Average Loss: 10.1698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1000

Learning rate: 0.0001999905762056025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 438 [0/90000 (0%)]	Loss: 10.5299	Cost: 23.72s
Train Epoch: 438 [20480/90000 (23%)]	Loss: 10.0877	Cost: 6.18s
Train Epoch: 438 [40960/90000 (45%)]	Loss: 9.9855	Cost: 7.02s
Train Epoch: 438 [61440/90000 (68%)]	Loss: 10.0929	Cost: 5.88s
Train Epoch: 438 [81920/90000 (91%)]	Loss: 10.2335	Cost: 5.74s
Train Epoch: 438 	Average Loss: 10.1659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0553

Learning rate: 0.00019999053302744273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 439 [0/90000 (0%)]	Loss: 10.4352	Cost: 24.47s
Train Epoch: 439 [20480/90000 (23%)]	Loss: 10.1659	Cost: 6.11s
Train Epoch: 439 [40960/90000 (45%)]	Loss: 9.9673	Cost: 6.26s
Train Epoch: 439 [61440/90000 (68%)]	Loss: 10.0318	Cost: 6.18s
Train Epoch: 439 [81920/90000 (91%)]	Loss: 10.2232	Cost: 5.71s
Train Epoch: 439 	Average Loss: 10.1775
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0588

Learning rate: 0.00019999048975059627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 440 [0/90000 (0%)]	Loss: 10.7805	Cost: 26.88s
Train Epoch: 440 [20480/90000 (23%)]	Loss: 10.1096	Cost: 6.11s
Train Epoch: 440 [40960/90000 (45%)]	Loss: 10.0057	Cost: 6.79s
Train Epoch: 440 [61440/90000 (68%)]	Loss: 10.1137	Cost: 5.96s
Train Epoch: 440 [81920/90000 (91%)]	Loss: 10.1962	Cost: 5.64s
Train Epoch: 440 	Average Loss: 10.1659
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0724

Learning rate: 0.00019999044637506315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 441 [0/90000 (0%)]	Loss: 10.6825	Cost: 27.93s
Train Epoch: 441 [20480/90000 (23%)]	Loss: 9.9662	Cost: 6.14s
Train Epoch: 441 [40960/90000 (45%)]	Loss: 10.0255	Cost: 8.35s
Train Epoch: 441 [61440/90000 (68%)]	Loss: 9.8909	Cost: 6.12s
Train Epoch: 441 [81920/90000 (91%)]	Loss: 10.2555	Cost: 7.64s
Train Epoch: 441 	Average Loss: 10.1665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1263

Learning rate: 0.0001999904029008434
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 442 [0/90000 (0%)]	Loss: 10.7500	Cost: 26.10s
Train Epoch: 442 [20480/90000 (23%)]	Loss: 10.1292	Cost: 6.00s
Train Epoch: 442 [40960/90000 (45%)]	Loss: 9.8246	Cost: 7.77s
Train Epoch: 442 [61440/90000 (68%)]	Loss: 9.9915	Cost: 5.95s
Train Epoch: 442 [81920/90000 (91%)]	Loss: 10.0992	Cost: 7.96s
Train Epoch: 442 	Average Loss: 10.1625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0514

Learning rate: 0.0001999903593279371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 443 [0/90000 (0%)]	Loss: 10.7661	Cost: 24.14s
Train Epoch: 443 [20480/90000 (23%)]	Loss: 9.8877	Cost: 6.05s
Train Epoch: 443 [40960/90000 (45%)]	Loss: 9.8982	Cost: 6.89s
Train Epoch: 443 [61440/90000 (68%)]	Loss: 10.0353	Cost: 6.26s
Train Epoch: 443 [81920/90000 (91%)]	Loss: 10.1125	Cost: 6.21s
Train Epoch: 443 	Average Loss: 10.1207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0290

Learning rate: 0.00019999031565634426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 444 [0/90000 (0%)]	Loss: 10.6744	Cost: 23.95s
Train Epoch: 444 [20480/90000 (23%)]	Loss: 10.0947	Cost: 6.09s
Train Epoch: 444 [40960/90000 (45%)]	Loss: 9.9038	Cost: 8.09s
Train Epoch: 444 [61440/90000 (68%)]	Loss: 9.9250	Cost: 5.69s
Train Epoch: 444 [81920/90000 (91%)]	Loss: 10.1804	Cost: 7.46s
Train Epoch: 444 	Average Loss: 10.1325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9877

Saving model as e444_model.pt & e444_waveforms_supplementary.hdf5
Learning rate: 0.00019999027188606495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 445 [0/90000 (0%)]	Loss: 10.6391	Cost: 23.49s
Train Epoch: 445 [20480/90000 (23%)]	Loss: 10.1502	Cost: 6.01s
Train Epoch: 445 [40960/90000 (45%)]	Loss: 9.9902	Cost: 6.39s
Train Epoch: 445 [61440/90000 (68%)]	Loss: 9.9729	Cost: 6.16s
Train Epoch: 445 [81920/90000 (91%)]	Loss: 10.0436	Cost: 5.73s
Train Epoch: 445 	Average Loss: 10.1288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9358

Saving model as e445_model.pt & e445_waveforms_supplementary.hdf5
Learning rate: 0.0001999902280170992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 446 [0/90000 (0%)]	Loss: 10.8248	Cost: 30.35s
Train Epoch: 446 [20480/90000 (23%)]	Loss: 10.2228	Cost: 6.15s
Train Epoch: 446 [40960/90000 (45%)]	Loss: 9.8166	Cost: 8.01s
Train Epoch: 446 [61440/90000 (68%)]	Loss: 9.8746	Cost: 5.93s
Train Epoch: 446 [81920/90000 (91%)]	Loss: 10.0141	Cost: 5.79s
Train Epoch: 446 	Average Loss: 10.1254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9939

Learning rate: 0.00019999018404944703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 447 [0/90000 (0%)]	Loss: 10.8207	Cost: 27.14s
Train Epoch: 447 [20480/90000 (23%)]	Loss: 10.0590	Cost: 6.24s
Train Epoch: 447 [40960/90000 (45%)]	Loss: 9.9580	Cost: 9.39s
Train Epoch: 447 [61440/90000 (68%)]	Loss: 9.9131	Cost: 5.97s
Train Epoch: 447 [81920/90000 (91%)]	Loss: 9.9893	Cost: 7.95s
Train Epoch: 447 	Average Loss: 10.1196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0905

Learning rate: 0.0001999901399831085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 448 [0/90000 (0%)]	Loss: 10.5753	Cost: 22.38s
Train Epoch: 448 [20480/90000 (23%)]	Loss: 10.1049	Cost: 6.16s
Train Epoch: 448 [40960/90000 (45%)]	Loss: 9.9231	Cost: 6.86s
Train Epoch: 448 [61440/90000 (68%)]	Loss: 10.0106	Cost: 5.97s
Train Epoch: 448 [81920/90000 (91%)]	Loss: 9.8930	Cost: 8.67s
Train Epoch: 448 	Average Loss: 10.1054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1237

Learning rate: 0.00019999009581808368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 449 [0/90000 (0%)]	Loss: 10.7688	Cost: 23.46s
Train Epoch: 449 [20480/90000 (23%)]	Loss: 9.9234	Cost: 6.12s
Train Epoch: 449 [40960/90000 (45%)]	Loss: 9.8776	Cost: 6.43s
Train Epoch: 449 [61440/90000 (68%)]	Loss: 10.0365	Cost: 6.10s
Train Epoch: 449 [81920/90000 (91%)]	Loss: 10.1671	Cost: 5.88s
Train Epoch: 449 	Average Loss: 10.1059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0736

Learning rate: 0.00019999005155437258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 450 [0/90000 (0%)]	Loss: 10.7740	Cost: 23.61s
Train Epoch: 450 [20480/90000 (23%)]	Loss: 9.9981	Cost: 6.07s
Train Epoch: 450 [40960/90000 (45%)]	Loss: 9.9293	Cost: 6.52s
Train Epoch: 450 [61440/90000 (68%)]	Loss: 10.2338	Cost: 6.21s
Train Epoch: 450 [81920/90000 (91%)]	Loss: 9.9411	Cost: 5.78s
Train Epoch: 450 	Average Loss: 10.0864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0421

Learning rate: 0.00019999000719197527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 451 [0/90000 (0%)]	Loss: 10.6462	Cost: 27.45s
Train Epoch: 451 [20480/90000 (23%)]	Loss: 9.8813	Cost: 6.07s
Train Epoch: 451 [40960/90000 (45%)]	Loss: 9.9581	Cost: 7.55s
Train Epoch: 451 [61440/90000 (68%)]	Loss: 9.9509	Cost: 5.95s
Train Epoch: 451 [81920/90000 (91%)]	Loss: 10.0793	Cost: 6.02s
Train Epoch: 451 	Average Loss: 10.0890
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9653

Learning rate: 0.00019998996273089178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 452 [0/90000 (0%)]	Loss: 10.6608	Cost: 27.47s
Train Epoch: 452 [20480/90000 (23%)]	Loss: 9.9663	Cost: 6.13s
Train Epoch: 452 [40960/90000 (45%)]	Loss: 10.1016	Cost: 6.51s
Train Epoch: 452 [61440/90000 (68%)]	Loss: 9.8863	Cost: 6.04s
Train Epoch: 452 [81920/90000 (91%)]	Loss: 10.0114	Cost: 6.09s
Train Epoch: 452 	Average Loss: 10.0960
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9567

Learning rate: 0.00019998991817112214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 453 [0/90000 (0%)]	Loss: 10.7560	Cost: 25.33s
Train Epoch: 453 [20480/90000 (23%)]	Loss: 10.0035	Cost: 6.08s
Train Epoch: 453 [40960/90000 (45%)]	Loss: 9.8596	Cost: 7.87s
Train Epoch: 453 [61440/90000 (68%)]	Loss: 9.8667	Cost: 5.92s
Train Epoch: 453 [81920/90000 (91%)]	Loss: 10.0238	Cost: 8.25s
Train Epoch: 453 	Average Loss: 10.0904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0108

Learning rate: 0.00019998987351266641
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 454 [0/90000 (0%)]	Loss: 10.4432	Cost: 23.49s
Train Epoch: 454 [20480/90000 (23%)]	Loss: 9.9001	Cost: 6.11s
Train Epoch: 454 [40960/90000 (45%)]	Loss: 9.8552	Cost: 6.73s
Train Epoch: 454 [61440/90000 (68%)]	Loss: 10.0806	Cost: 5.89s
Train Epoch: 454 [81920/90000 (91%)]	Loss: 9.9593	Cost: 6.28s
Train Epoch: 454 	Average Loss: 10.0543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9681

Learning rate: 0.00019998982875552463
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 455 [0/90000 (0%)]	Loss: 10.4545	Cost: 22.99s
Train Epoch: 455 [20480/90000 (23%)]	Loss: 9.9845	Cost: 6.13s
Train Epoch: 455 [40960/90000 (45%)]	Loss: 9.9101	Cost: 7.26s
Train Epoch: 455 [61440/90000 (68%)]	Loss: 10.1047	Cost: 5.92s
Train Epoch: 455 [81920/90000 (91%)]	Loss: 9.9642	Cost: 6.82s
Train Epoch: 455 	Average Loss: 10.0579
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0501

Learning rate: 0.00019998978389969684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 456 [0/90000 (0%)]	Loss: 10.5878	Cost: 24.73s
Train Epoch: 456 [20480/90000 (23%)]	Loss: 10.0105	Cost: 6.15s
Train Epoch: 456 [40960/90000 (45%)]	Loss: 10.0153	Cost: 7.18s
Train Epoch: 456 [61440/90000 (68%)]	Loss: 10.0129	Cost: 6.03s
Train Epoch: 456 [81920/90000 (91%)]	Loss: 9.9697	Cost: 7.44s
Train Epoch: 456 	Average Loss: 10.0528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9921

Learning rate: 0.0001999897389451831
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 457 [0/90000 (0%)]	Loss: 10.5081	Cost: 28.54s
Train Epoch: 457 [20480/90000 (23%)]	Loss: 9.9096	Cost: 6.16s
Train Epoch: 457 [40960/90000 (45%)]	Loss: 9.8983	Cost: 6.97s
Train Epoch: 457 [61440/90000 (68%)]	Loss: 9.8834	Cost: 6.07s
Train Epoch: 457 [81920/90000 (91%)]	Loss: 10.0039	Cost: 6.04s
Train Epoch: 457 	Average Loss: 10.0671
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0303

Learning rate: 0.00019998969389198342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 458 [0/90000 (0%)]	Loss: 10.6873	Cost: 23.87s
Train Epoch: 458 [20480/90000 (23%)]	Loss: 10.0074	Cost: 6.04s
Train Epoch: 458 [40960/90000 (45%)]	Loss: 9.9692	Cost: 8.21s
Train Epoch: 458 [61440/90000 (68%)]	Loss: 9.8414	Cost: 5.94s
Train Epoch: 458 [81920/90000 (91%)]	Loss: 10.1517	Cost: 8.70s
Train Epoch: 458 	Average Loss: 10.0563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0317

Learning rate: 0.00019998964874009788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 459 [0/90000 (0%)]	Loss: 10.6659	Cost: 23.48s
Train Epoch: 459 [20480/90000 (23%)]	Loss: 9.9580	Cost: 5.98s
Train Epoch: 459 [40960/90000 (45%)]	Loss: 9.8743	Cost: 6.61s
Train Epoch: 459 [61440/90000 (68%)]	Loss: 9.8079	Cost: 6.34s
Train Epoch: 459 [81920/90000 (91%)]	Loss: 9.8308	Cost: 6.08s
Train Epoch: 459 	Average Loss: 10.0481
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9959

Learning rate: 0.00019998960348952653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 460 [0/90000 (0%)]	Loss: 10.7722	Cost: 23.80s
Train Epoch: 460 [20480/90000 (23%)]	Loss: 9.9564	Cost: 6.00s
Train Epoch: 460 [40960/90000 (45%)]	Loss: 9.9549	Cost: 6.74s
Train Epoch: 460 [61440/90000 (68%)]	Loss: 9.9484	Cost: 6.10s
Train Epoch: 460 [81920/90000 (91%)]	Loss: 9.8571	Cost: 5.72s
Train Epoch: 460 	Average Loss: 10.0435
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0550

Learning rate: 0.00019998955814026938
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 461 [0/90000 (0%)]	Loss: 10.7325	Cost: 25.78s
Train Epoch: 461 [20480/90000 (23%)]	Loss: 9.9156	Cost: 6.14s
Train Epoch: 461 [40960/90000 (45%)]	Loss: 9.7886	Cost: 6.60s
Train Epoch: 461 [61440/90000 (68%)]	Loss: 10.0331	Cost: 6.19s
Train Epoch: 461 [81920/90000 (91%)]	Loss: 9.9552	Cost: 5.77s
Train Epoch: 461 	Average Loss: 10.0292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1082

Learning rate: 0.0001999895126923265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 462 [0/90000 (0%)]	Loss: 10.6908	Cost: 28.50s
Train Epoch: 462 [20480/90000 (23%)]	Loss: 9.8405	Cost: 5.93s
Train Epoch: 462 [40960/90000 (45%)]	Loss: 9.9550	Cost: 7.72s
Train Epoch: 462 [61440/90000 (68%)]	Loss: 10.0120	Cost: 5.96s
Train Epoch: 462 [81920/90000 (91%)]	Loss: 9.9453	Cost: 5.78s
Train Epoch: 462 	Average Loss: 10.0486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0878

Learning rate: 0.00019998946714569794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 463 [0/90000 (0%)]	Loss: 10.6188	Cost: 23.92s
Train Epoch: 463 [20480/90000 (23%)]	Loss: 10.0305	Cost: 6.00s
Train Epoch: 463 [40960/90000 (45%)]	Loss: 9.9098	Cost: 7.91s
Train Epoch: 463 [61440/90000 (68%)]	Loss: 9.9349	Cost: 6.00s
Train Epoch: 463 [81920/90000 (91%)]	Loss: 10.0542	Cost: 8.70s
Train Epoch: 463 	Average Loss: 10.0295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9847

Learning rate: 0.0001999894215003837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 464 [0/90000 (0%)]	Loss: 10.8833	Cost: 23.14s
Train Epoch: 464 [20480/90000 (23%)]	Loss: 10.0081	Cost: 6.06s
Train Epoch: 464 [40960/90000 (45%)]	Loss: 10.0693	Cost: 6.57s
Train Epoch: 464 [61440/90000 (68%)]	Loss: 9.8025	Cost: 6.30s
Train Epoch: 464 [81920/90000 (91%)]	Loss: 10.0061	Cost: 8.96s
Train Epoch: 464 	Average Loss: 10.0570
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9506

Learning rate: 0.00019998937575638385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 465 [0/90000 (0%)]	Loss: 10.7303	Cost: 24.35s
Train Epoch: 465 [20480/90000 (23%)]	Loss: 9.9464	Cost: 6.25s
Train Epoch: 465 [40960/90000 (45%)]	Loss: 9.8445	Cost: 6.78s
Train Epoch: 465 [61440/90000 (68%)]	Loss: 10.0408	Cost: 5.97s
Train Epoch: 465 [81920/90000 (91%)]	Loss: 9.7547	Cost: 6.29s
Train Epoch: 465 	Average Loss: 10.0058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0250

Learning rate: 0.0001999893299136985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 466 [0/90000 (0%)]	Loss: 10.6456	Cost: 23.80s
Train Epoch: 466 [20480/90000 (23%)]	Loss: 10.0200	Cost: 6.12s
Train Epoch: 466 [40960/90000 (45%)]	Loss: 9.8711	Cost: 6.29s
Train Epoch: 466 [61440/90000 (68%)]	Loss: 10.0903	Cost: 6.25s
Train Epoch: 466 [81920/90000 (91%)]	Loss: 9.8806	Cost: 6.41s
Train Epoch: 466 	Average Loss: 10.0267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9518

Learning rate: 0.00019998928397232759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 467 [0/90000 (0%)]	Loss: 10.6690	Cost: 26.21s
Train Epoch: 467 [20480/90000 (23%)]	Loss: 9.8283	Cost: 6.34s
Train Epoch: 467 [40960/90000 (45%)]	Loss: 9.8075	Cost: 6.58s
Train Epoch: 467 [61440/90000 (68%)]	Loss: 9.8597	Cost: 5.92s
Train Epoch: 467 [81920/90000 (91%)]	Loss: 9.7940	Cost: 5.88s
Train Epoch: 467 	Average Loss: 9.9844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9925

Learning rate: 0.00019998923793227122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 468 [0/90000 (0%)]	Loss: 10.6603	Cost: 26.08s
Train Epoch: 468 [20480/90000 (23%)]	Loss: 10.0410	Cost: 6.08s
Train Epoch: 468 [40960/90000 (45%)]	Loss: 9.8099	Cost: 7.37s
Train Epoch: 468 [61440/90000 (68%)]	Loss: 9.8854	Cost: 6.19s
Train Epoch: 468 [81920/90000 (91%)]	Loss: 10.1819	Cost: 7.12s
Train Epoch: 468 	Average Loss: 10.0121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0529

Learning rate: 0.0001999891917935294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 469 [0/90000 (0%)]	Loss: 10.9171	Cost: 23.19s
Train Epoch: 469 [20480/90000 (23%)]	Loss: 9.9006	Cost: 6.10s
Train Epoch: 469 [40960/90000 (45%)]	Loss: 9.8712	Cost: 6.49s
Train Epoch: 469 [61440/90000 (68%)]	Loss: 10.0515	Cost: 6.05s
Train Epoch: 469 [81920/90000 (91%)]	Loss: 9.8557	Cost: 8.26s
Train Epoch: 469 	Average Loss: 10.0277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9968

Learning rate: 0.00019998914555610225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 470 [0/90000 (0%)]	Loss: 10.7680	Cost: 24.10s
Train Epoch: 470 [20480/90000 (23%)]	Loss: 10.0410	Cost: 5.97s
Train Epoch: 470 [40960/90000 (45%)]	Loss: 9.8640	Cost: 7.07s
Train Epoch: 470 [61440/90000 (68%)]	Loss: 10.0331	Cost: 5.89s
Train Epoch: 470 [81920/90000 (91%)]	Loss: 9.9167	Cost: 5.54s
Train Epoch: 470 	Average Loss: 10.0067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0184

Learning rate: 0.00019998909921998975
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 471 [0/90000 (0%)]	Loss: 10.5438	Cost: 23.21s
Train Epoch: 471 [20480/90000 (23%)]	Loss: 9.8237	Cost: 6.16s
Train Epoch: 471 [40960/90000 (45%)]	Loss: 9.7016	Cost: 7.96s
Train Epoch: 471 [61440/90000 (68%)]	Loss: 9.8235	Cost: 6.04s
Train Epoch: 471 [81920/90000 (91%)]	Loss: 9.9079	Cost: 6.68s
Train Epoch: 471 	Average Loss: 9.9993
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9907

Learning rate: 0.00019998905278519196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 472 [0/90000 (0%)]	Loss: 10.7096	Cost: 25.54s
Train Epoch: 472 [20480/90000 (23%)]	Loss: 9.9788	Cost: 6.18s
Train Epoch: 472 [40960/90000 (45%)]	Loss: 9.8635	Cost: 6.88s
Train Epoch: 472 [61440/90000 (68%)]	Loss: 9.8549	Cost: 5.86s
Train Epoch: 472 [81920/90000 (91%)]	Loss: 9.8799	Cost: 5.98s
Train Epoch: 472 	Average Loss: 9.9793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9332

Saving model as e472_model.pt & e472_waveforms_supplementary.hdf5
Learning rate: 0.00019998900625170892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 473 [0/90000 (0%)]	Loss: 10.6279	Cost: 28.36s
Train Epoch: 473 [20480/90000 (23%)]	Loss: 9.7661	Cost: 6.04s
Train Epoch: 473 [40960/90000 (45%)]	Loss: 9.9383	Cost: 6.47s
Train Epoch: 473 [61440/90000 (68%)]	Loss: 9.9782	Cost: 6.12s
Train Epoch: 473 [81920/90000 (91%)]	Loss: 9.9550	Cost: 5.91s
Train Epoch: 473 	Average Loss: 9.9818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9824

Learning rate: 0.0001999889596195407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 474 [0/90000 (0%)]	Loss: 10.9061	Cost: 25.42s
Train Epoch: 474 [20480/90000 (23%)]	Loss: 9.9538	Cost: 6.23s
Train Epoch: 474 [40960/90000 (45%)]	Loss: 9.7205	Cost: 7.39s
Train Epoch: 474 [61440/90000 (68%)]	Loss: 9.9913	Cost: 5.92s
Train Epoch: 474 [81920/90000 (91%)]	Loss: 9.8303	Cost: 8.15s
Train Epoch: 474 	Average Loss: 9.9665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0407

Learning rate: 0.00019998891288868732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 475 [0/90000 (0%)]	Loss: 10.7647	Cost: 23.49s
Train Epoch: 475 [20480/90000 (23%)]	Loss: 9.9558	Cost: 6.22s
Train Epoch: 475 [40960/90000 (45%)]	Loss: 9.8009	Cost: 6.43s
Train Epoch: 475 [61440/90000 (68%)]	Loss: 9.9456	Cost: 5.96s
Train Epoch: 475 [81920/90000 (91%)]	Loss: 9.8556	Cost: 6.13s
Train Epoch: 475 	Average Loss: 10.0381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0617

Learning rate: 0.00019998886605914883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 476 [0/90000 (0%)]	Loss: 10.6470	Cost: 23.80s
Train Epoch: 476 [20480/90000 (23%)]	Loss: 9.8900	Cost: 6.04s
Train Epoch: 476 [40960/90000 (45%)]	Loss: 9.8623	Cost: 7.22s
Train Epoch: 476 [61440/90000 (68%)]	Loss: 9.9203	Cost: 6.08s
Train Epoch: 476 [81920/90000 (91%)]	Loss: 9.7887	Cost: 5.74s
Train Epoch: 476 	Average Loss: 9.9964
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9901

Learning rate: 0.00019998881913092532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 477 [0/90000 (0%)]	Loss: 10.6802	Cost: 25.49s
Train Epoch: 477 [20480/90000 (23%)]	Loss: 9.8293	Cost: 6.00s
Train Epoch: 477 [40960/90000 (45%)]	Loss: 9.8928	Cost: 6.39s
Train Epoch: 477 [61440/90000 (68%)]	Loss: 9.9389	Cost: 6.09s
Train Epoch: 477 [81920/90000 (91%)]	Loss: 9.9298	Cost: 5.75s
Train Epoch: 477 	Average Loss: 9.9755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0887

Learning rate: 0.00019998877210401677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 478 [0/90000 (0%)]	Loss: 10.6289	Cost: 27.93s
Train Epoch: 478 [20480/90000 (23%)]	Loss: 9.9728	Cost: 6.08s
Train Epoch: 478 [40960/90000 (45%)]	Loss: 9.8039	Cost: 8.63s
Train Epoch: 478 [61440/90000 (68%)]	Loss: 9.8546	Cost: 5.96s
Train Epoch: 478 [81920/90000 (91%)]	Loss: 9.7396	Cost: 6.77s
Train Epoch: 478 	Average Loss: 9.9426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0146

Learning rate: 0.00019998872497842328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 479 [0/90000 (0%)]	Loss: 10.6017	Cost: 24.61s
Train Epoch: 479 [20480/90000 (23%)]	Loss: 9.8018	Cost: 6.05s
Train Epoch: 479 [40960/90000 (45%)]	Loss: 9.7516	Cost: 7.81s
Train Epoch: 479 [61440/90000 (68%)]	Loss: 9.7626	Cost: 5.92s
Train Epoch: 479 [81920/90000 (91%)]	Loss: 9.9609	Cost: 7.86s
Train Epoch: 479 	Average Loss: 9.9647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9701

Learning rate: 0.00019998867775414486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 480 [0/90000 (0%)]	Loss: 10.8163	Cost: 23.54s
Train Epoch: 480 [20480/90000 (23%)]	Loss: 9.9035	Cost: 6.61s
Train Epoch: 480 [40960/90000 (45%)]	Loss: 9.7890	Cost: 6.35s
Train Epoch: 480 [61440/90000 (68%)]	Loss: 9.8069	Cost: 5.87s
Train Epoch: 480 [81920/90000 (91%)]	Loss: 10.0726	Cost: 6.26s
Train Epoch: 480 	Average Loss: 9.9597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0505

Learning rate: 0.00019998863043118158
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 481 [0/90000 (0%)]	Loss: 10.5883	Cost: 24.14s
Train Epoch: 481 [20480/90000 (23%)]	Loss: 9.7531	Cost: 6.04s
Train Epoch: 481 [40960/90000 (45%)]	Loss: 9.7588	Cost: 6.87s
Train Epoch: 481 [61440/90000 (68%)]	Loss: 9.9012	Cost: 6.04s
Train Epoch: 481 [81920/90000 (91%)]	Loss: 9.8775	Cost: 5.97s
Train Epoch: 481 	Average Loss: 9.9313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9932

Learning rate: 0.00019998858300953348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 482 [0/90000 (0%)]	Loss: 10.5835	Cost: 23.91s
Train Epoch: 482 [20480/90000 (23%)]	Loss: 9.6292	Cost: 6.15s
Train Epoch: 482 [40960/90000 (45%)]	Loss: 9.7822	Cost: 6.49s
Train Epoch: 482 [61440/90000 (68%)]	Loss: 9.7102	Cost: 6.09s
Train Epoch: 482 [81920/90000 (91%)]	Loss: 9.8299	Cost: 5.85s
Train Epoch: 482 	Average Loss: 9.8931
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0400

Learning rate: 0.0001999885354892006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 483 [0/90000 (0%)]	Loss: 10.6440	Cost: 29.60s
Train Epoch: 483 [20480/90000 (23%)]	Loss: 9.8199	Cost: 6.06s
Train Epoch: 483 [40960/90000 (45%)]	Loss: 9.6093	Cost: 7.85s
Train Epoch: 483 [61440/90000 (68%)]	Loss: 9.8914	Cost: 5.86s
Train Epoch: 483 [81920/90000 (91%)]	Loss: 9.7632	Cost: 6.11s
Train Epoch: 483 	Average Loss: 9.9296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9585

Learning rate: 0.000199988487870183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 484 [0/90000 (0%)]	Loss: 10.4630	Cost: 25.08s
Train Epoch: 484 [20480/90000 (23%)]	Loss: 9.8877	Cost: 6.19s
Train Epoch: 484 [40960/90000 (45%)]	Loss: 9.8755	Cost: 7.48s
Train Epoch: 484 [61440/90000 (68%)]	Loss: 9.7993	Cost: 5.95s
Train Epoch: 484 [81920/90000 (91%)]	Loss: 9.8596	Cost: 8.10s
Train Epoch: 484 	Average Loss: 9.8939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0297

Learning rate: 0.00019998844015248072
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 485 [0/90000 (0%)]	Loss: 10.7099	Cost: 23.72s
Train Epoch: 485 [20480/90000 (23%)]	Loss: 9.9308	Cost: 5.93s
Train Epoch: 485 [40960/90000 (45%)]	Loss: 9.7533	Cost: 6.91s
Train Epoch: 485 [61440/90000 (68%)]	Loss: 9.8414	Cost: 5.99s
Train Epoch: 485 [81920/90000 (91%)]	Loss: 9.8906	Cost: 9.06s
Train Epoch: 485 	Average Loss: 9.9282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0087

Learning rate: 0.0001999883923360938
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 486 [0/90000 (0%)]	Loss: 10.5589	Cost: 23.97s
Train Epoch: 486 [20480/90000 (23%)]	Loss: 9.6162	Cost: 6.27s
Train Epoch: 486 [40960/90000 (45%)]	Loss: 9.4670	Cost: 6.68s
Train Epoch: 486 [61440/90000 (68%)]	Loss: 9.7531	Cost: 5.87s
Train Epoch: 486 [81920/90000 (91%)]	Loss: 9.8689	Cost: 6.40s
Train Epoch: 486 	Average Loss: 9.9277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9693

Learning rate: 0.00019998834442102228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 487 [0/90000 (0%)]	Loss: 10.6179	Cost: 23.99s
Train Epoch: 487 [20480/90000 (23%)]	Loss: 9.7932	Cost: 6.00s
Train Epoch: 487 [40960/90000 (45%)]	Loss: 9.7799	Cost: 7.56s
Train Epoch: 487 [61440/90000 (68%)]	Loss: 9.8349	Cost: 6.01s
Train Epoch: 487 [81920/90000 (91%)]	Loss: 9.6264	Cost: 6.78s
Train Epoch: 487 	Average Loss: 9.9191
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9775

Learning rate: 0.00019998829640726623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 488 [0/90000 (0%)]	Loss: 10.5983	Cost: 26.91s
Train Epoch: 488 [20480/90000 (23%)]	Loss: 9.9111	Cost: 5.96s
Train Epoch: 488 [40960/90000 (45%)]	Loss: 9.9069	Cost: 6.62s
Train Epoch: 488 [61440/90000 (68%)]	Loss: 9.8971	Cost: 5.97s
Train Epoch: 488 [81920/90000 (91%)]	Loss: 9.8214	Cost: 5.87s
Train Epoch: 488 	Average Loss: 9.9381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9836

Learning rate: 0.00019998824829482568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 489 [0/90000 (0%)]	Loss: 10.5210	Cost: 24.94s
Train Epoch: 489 [20480/90000 (23%)]	Loss: 9.9831	Cost: 5.99s
Train Epoch: 489 [40960/90000 (45%)]	Loss: 9.9119	Cost: 7.93s
Train Epoch: 489 [61440/90000 (68%)]	Loss: 9.7875	Cost: 6.11s
Train Epoch: 489 [81920/90000 (91%)]	Loss: 9.8497	Cost: 6.81s
Train Epoch: 489 	Average Loss: 9.9033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0324

Learning rate: 0.0001999882000837007
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 490 [0/90000 (0%)]	Loss: 10.6646	Cost: 23.59s
Train Epoch: 490 [20480/90000 (23%)]	Loss: 9.9375	Cost: 6.13s
Train Epoch: 490 [40960/90000 (45%)]	Loss: 9.6010	Cost: 6.54s
Train Epoch: 490 [61440/90000 (68%)]	Loss: 9.8395	Cost: 6.10s
Train Epoch: 490 [81920/90000 (91%)]	Loss: 9.9077	Cost: 8.44s
Train Epoch: 490 	Average Loss: 9.9201
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1140

Learning rate: 0.0001999881517738913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 491 [0/90000 (0%)]	Loss: 10.7284	Cost: 23.78s
Train Epoch: 491 [20480/90000 (23%)]	Loss: 9.8561	Cost: 6.26s
Train Epoch: 491 [40960/90000 (45%)]	Loss: 9.7247	Cost: 6.33s
Train Epoch: 491 [61440/90000 (68%)]	Loss: 9.8093	Cost: 5.94s
Train Epoch: 491 [81920/90000 (91%)]	Loss: 9.7721	Cost: 6.14s
Train Epoch: 491 	Average Loss: 9.8849
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0356

Learning rate: 0.00019998810336539752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 492 [0/90000 (0%)]	Loss: 10.6269	Cost: 23.64s
Train Epoch: 492 [20480/90000 (23%)]	Loss: 9.8452	Cost: 5.98s
Train Epoch: 492 [40960/90000 (45%)]	Loss: 9.8173	Cost: 6.60s
Train Epoch: 492 [61440/90000 (68%)]	Loss: 9.7287	Cost: 5.97s
Train Epoch: 492 [81920/90000 (91%)]	Loss: 9.8908	Cost: 5.97s
Train Epoch: 492 	Average Loss: 9.8703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0176

Learning rate: 0.00019998805485821946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 493 [0/90000 (0%)]	Loss: 10.7701	Cost: 27.62s
Train Epoch: 493 [20480/90000 (23%)]	Loss: 9.7825	Cost: 5.97s
Train Epoch: 493 [40960/90000 (45%)]	Loss: 9.7219	Cost: 6.85s
Train Epoch: 493 [61440/90000 (68%)]	Loss: 9.7299	Cost: 6.05s
Train Epoch: 493 [81920/90000 (91%)]	Loss: 9.7180	Cost: 5.88s
Train Epoch: 493 	Average Loss: 9.8466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0268

Learning rate: 0.00019998800625235718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 494 [0/90000 (0%)]	Loss: 10.5451	Cost: 27.12s
Train Epoch: 494 [20480/90000 (23%)]	Loss: 9.7500	Cost: 5.99s
Train Epoch: 494 [40960/90000 (45%)]	Loss: 9.6597	Cost: 9.37s
Train Epoch: 494 [61440/90000 (68%)]	Loss: 9.7470	Cost: 6.03s
Train Epoch: 494 [81920/90000 (91%)]	Loss: 9.8214	Cost: 8.47s
Train Epoch: 494 	Average Loss: 9.8573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9401

Learning rate: 0.00019998795754781068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 495 [0/90000 (0%)]	Loss: 10.6194	Cost: 24.96s
Train Epoch: 495 [20480/90000 (23%)]	Loss: 9.6765	Cost: 5.99s
Train Epoch: 495 [40960/90000 (45%)]	Loss: 9.7593	Cost: 7.55s
Train Epoch: 495 [61440/90000 (68%)]	Loss: 9.7365	Cost: 5.96s
Train Epoch: 495 [81920/90000 (91%)]	Loss: 9.8325	Cost: 8.18s
Train Epoch: 495 	Average Loss: 9.8654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0630

Learning rate: 0.00019998790874458001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 496 [0/90000 (0%)]	Loss: 10.6518	Cost: 23.85s
Train Epoch: 496 [20480/90000 (23%)]	Loss: 9.8407	Cost: 6.27s
Train Epoch: 496 [40960/90000 (45%)]	Loss: 9.6351	Cost: 6.54s
Train Epoch: 496 [61440/90000 (68%)]	Loss: 9.7856	Cost: 5.82s
Train Epoch: 496 [81920/90000 (91%)]	Loss: 9.8621	Cost: 6.45s
Train Epoch: 496 	Average Loss: 9.8652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9982

Learning rate: 0.00019998785984266522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 497 [0/90000 (0%)]	Loss: 10.5794	Cost: 23.95s
Train Epoch: 497 [20480/90000 (23%)]	Loss: 9.8491	Cost: 6.02s
Train Epoch: 497 [40960/90000 (45%)]	Loss: 9.6825	Cost: 6.47s
Train Epoch: 497 [61440/90000 (68%)]	Loss: 9.8426	Cost: 6.39s
Train Epoch: 497 [81920/90000 (91%)]	Loss: 9.8164	Cost: 6.21s
Train Epoch: 497 	Average Loss: 9.8639
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0581

Learning rate: 0.0001999878108420664
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 498 [0/90000 (0%)]	Loss: 10.5971	Cost: 23.88s
Train Epoch: 498 [20480/90000 (23%)]	Loss: 9.8176	Cost: 6.04s
Train Epoch: 498 [40960/90000 (45%)]	Loss: 9.6252	Cost: 6.91s
Train Epoch: 498 [61440/90000 (68%)]	Loss: 9.7923	Cost: 6.23s
Train Epoch: 498 [81920/90000 (91%)]	Loss: 9.7871	Cost: 6.63s
Train Epoch: 498 	Average Loss: 9.8581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9907

Learning rate: 0.0001999877617427835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 499 [0/90000 (0%)]	Loss: 10.5967	Cost: 30.07s
Train Epoch: 499 [20480/90000 (23%)]	Loss: 9.8737	Cost: 6.08s
Train Epoch: 499 [40960/90000 (45%)]	Loss: 9.6461	Cost: 6.88s
Train Epoch: 499 [61440/90000 (68%)]	Loss: 9.7253	Cost: 5.87s
Train Epoch: 499 [81920/90000 (91%)]	Loss: 9.8350	Cost: 5.90s
Train Epoch: 499 	Average Loss: 9.8351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0230

Learning rate: 0.00019998771254481668
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 500 [0/90000 (0%)]	Loss: 10.5792	Cost: 24.42s
Train Epoch: 500 [20480/90000 (23%)]	Loss: 9.7455	Cost: 6.06s
Train Epoch: 500 [40960/90000 (45%)]	Loss: 9.4609	Cost: 7.59s
Train Epoch: 500 [61440/90000 (68%)]	Loss: 9.6566	Cost: 6.16s
Train Epoch: 500 [81920/90000 (91%)]	Loss: 9.7150	Cost: 6.74s
Train Epoch: 500 	Average Loss: 9.7872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9734

Learning rate: 0.00019998766324816594
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 501 [0/90000 (0%)]	Loss: 10.3798	Cost: 23.77s
Train Epoch: 501 [20480/90000 (23%)]	Loss: 9.6053	Cost: 6.08s
Train Epoch: 501 [40960/90000 (45%)]	Loss: 9.6065	Cost: 6.53s
Train Epoch: 501 [61440/90000 (68%)]	Loss: 9.6203	Cost: 6.14s
Train Epoch: 501 [81920/90000 (91%)]	Loss: 9.8045	Cost: 9.26s
Train Epoch: 501 	Average Loss: 9.8125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0685

Learning rate: 0.00019998761385283135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 502 [0/90000 (0%)]	Loss: 10.7552	Cost: 23.90s
Train Epoch: 502 [20480/90000 (23%)]	Loss: 9.7270	Cost: 6.13s
Train Epoch: 502 [40960/90000 (45%)]	Loss: 9.6653	Cost: 7.29s
Train Epoch: 502 [61440/90000 (68%)]	Loss: 9.7805	Cost: 5.90s
Train Epoch: 502 [81920/90000 (91%)]	Loss: 9.7929	Cost: 5.96s
Train Epoch: 502 	Average Loss: 9.8245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9783

Learning rate: 0.00019998756435881293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 503 [0/90000 (0%)]	Loss: 10.5773	Cost: 23.71s
Train Epoch: 503 [20480/90000 (23%)]	Loss: 9.6448	Cost: 6.14s
Train Epoch: 503 [40960/90000 (45%)]	Loss: 9.5911	Cost: 7.63s
Train Epoch: 503 [61440/90000 (68%)]	Loss: 9.7842	Cost: 6.03s
Train Epoch: 503 [81920/90000 (91%)]	Loss: 9.7617	Cost: 6.46s
Train Epoch: 503 	Average Loss: 9.7962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0289

Learning rate: 0.00019998751476611075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 504 [0/90000 (0%)]	Loss: 10.7418	Cost: 27.74s
Train Epoch: 504 [20480/90000 (23%)]	Loss: 9.6027	Cost: 6.16s
Train Epoch: 504 [40960/90000 (45%)]	Loss: 9.6598	Cost: 6.48s
Train Epoch: 504 [61440/90000 (68%)]	Loss: 9.8561	Cost: 5.94s
Train Epoch: 504 [81920/90000 (91%)]	Loss: 9.7487	Cost: 5.81s
Train Epoch: 504 	Average Loss: 9.7973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0355

Learning rate: 0.00019998746507472485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 505 [0/90000 (0%)]	Loss: 10.6344	Cost: 26.70s
Train Epoch: 505 [20480/90000 (23%)]	Loss: 9.8673	Cost: 6.09s
Train Epoch: 505 [40960/90000 (45%)]	Loss: 9.8095	Cost: 9.24s
Train Epoch: 505 [61440/90000 (68%)]	Loss: 9.5911	Cost: 6.05s
Train Epoch: 505 [81920/90000 (91%)]	Loss: 9.7317	Cost: 8.40s
Train Epoch: 505 	Average Loss: 9.7921
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0371

Learning rate: 0.00019998741528465526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 506 [0/90000 (0%)]	Loss: 10.7145	Cost: 24.16s
Train Epoch: 506 [20480/90000 (23%)]	Loss: 9.6112	Cost: 6.06s
Train Epoch: 506 [40960/90000 (45%)]	Loss: 9.6669	Cost: 8.01s
Train Epoch: 506 [61440/90000 (68%)]	Loss: 9.7142	Cost: 5.97s
Train Epoch: 506 [81920/90000 (91%)]	Loss: 9.8056	Cost: 8.72s
Train Epoch: 506 	Average Loss: 9.7823
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0080

Learning rate: 0.00019998736539590206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 507 [0/90000 (0%)]	Loss: 10.6565	Cost: 23.89s
Train Epoch: 507 [20480/90000 (23%)]	Loss: 9.6482	Cost: 6.22s
Train Epoch: 507 [40960/90000 (45%)]	Loss: 9.6015	Cost: 7.22s
Train Epoch: 507 [61440/90000 (68%)]	Loss: 9.5732	Cost: 5.85s
Train Epoch: 507 [81920/90000 (91%)]	Loss: 9.6962	Cost: 6.35s
Train Epoch: 507 	Average Loss: 9.7867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0569

Learning rate: 0.00019998731540846526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 508 [0/90000 (0%)]	Loss: 10.5858	Cost: 23.32s
Train Epoch: 508 [20480/90000 (23%)]	Loss: 9.7731	Cost: 6.12s
Train Epoch: 508 [40960/90000 (45%)]	Loss: 9.5113	Cost: 7.02s
Train Epoch: 508 [61440/90000 (68%)]	Loss: 9.6859	Cost: 6.18s
Train Epoch: 508 [81920/90000 (91%)]	Loss: 9.7115	Cost: 6.52s
Train Epoch: 508 	Average Loss: 9.7728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9863

Learning rate: 0.00019998726532234495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 509 [0/90000 (0%)]	Loss: 10.5202	Cost: 24.84s
Train Epoch: 509 [20480/90000 (23%)]	Loss: 9.6401	Cost: 6.10s
Train Epoch: 509 [40960/90000 (45%)]	Loss: 9.6437	Cost: 6.56s
Train Epoch: 509 [61440/90000 (68%)]	Loss: 9.5284	Cost: 6.11s
Train Epoch: 509 [81920/90000 (91%)]	Loss: 9.6643	Cost: 5.91s
Train Epoch: 509 	Average Loss: 9.7590
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0055

Learning rate: 0.00019998721513754116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 510 [0/90000 (0%)]	Loss: 10.5739	Cost: 27.95s
Train Epoch: 510 [20480/90000 (23%)]	Loss: 9.7097	Cost: 6.04s
Train Epoch: 510 [40960/90000 (45%)]	Loss: 9.7664	Cost: 6.74s
Train Epoch: 510 [61440/90000 (68%)]	Loss: 9.5979	Cost: 5.97s
Train Epoch: 510 [81920/90000 (91%)]	Loss: 9.8314	Cost: 5.72s
Train Epoch: 510 	Average Loss: 9.7589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0169

Learning rate: 0.00019998716485405393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 511 [0/90000 (0%)]	Loss: 10.6766	Cost: 23.34s
Train Epoch: 511 [20480/90000 (23%)]	Loss: 9.7268	Cost: 6.14s
Train Epoch: 511 [40960/90000 (45%)]	Loss: 9.6562	Cost: 8.17s
Train Epoch: 511 [61440/90000 (68%)]	Loss: 9.6643	Cost: 5.89s
Train Epoch: 511 [81920/90000 (91%)]	Loss: 9.6355	Cost: 9.07s
Train Epoch: 511 	Average Loss: 9.7767
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0181

Learning rate: 0.00019998711447188336
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 512 [0/90000 (0%)]	Loss: 10.5781	Cost: 23.13s
Train Epoch: 512 [20480/90000 (23%)]	Loss: 9.6666	Cost: 6.29s
Train Epoch: 512 [40960/90000 (45%)]	Loss: 9.6461	Cost: 6.34s
Train Epoch: 512 [61440/90000 (68%)]	Loss: 9.6158	Cost: 5.86s
Train Epoch: 512 [81920/90000 (91%)]	Loss: 9.8255	Cost: 6.23s
Train Epoch: 512 	Average Loss: 9.7755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0384

Learning rate: 0.00019998706399102943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 513 [0/90000 (0%)]	Loss: 10.6366	Cost: 24.82s
Train Epoch: 513 [20480/90000 (23%)]	Loss: 9.6666	Cost: 6.20s
Train Epoch: 513 [40960/90000 (45%)]	Loss: 9.6226	Cost: 7.04s
Train Epoch: 513 [61440/90000 (68%)]	Loss: 9.7019	Cost: 6.60s
Train Epoch: 513 [81920/90000 (91%)]	Loss: 9.6855	Cost: 6.20s
Train Epoch: 513 	Average Loss: 9.7591
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9904

Learning rate: 0.00019998701341149226
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 514 [0/90000 (0%)]	Loss: 10.6418	Cost: 24.34s
Train Epoch: 514 [20480/90000 (23%)]	Loss: 9.5696	Cost: 6.09s
Train Epoch: 514 [40960/90000 (45%)]	Loss: 9.7371	Cost: 6.46s
Train Epoch: 514 [61440/90000 (68%)]	Loss: 9.5564	Cost: 6.22s
Train Epoch: 514 [81920/90000 (91%)]	Loss: 9.7658	Cost: 5.90s
Train Epoch: 514 	Average Loss: 9.7750
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1260

Learning rate: 0.00019998696273327185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 515 [0/90000 (0%)]	Loss: 10.6672	Cost: 28.47s
Train Epoch: 515 [20480/90000 (23%)]	Loss: 9.6556	Cost: 6.11s
Train Epoch: 515 [40960/90000 (45%)]	Loss: 9.5719	Cost: 6.59s
Train Epoch: 515 [61440/90000 (68%)]	Loss: 9.6389	Cost: 6.05s
Train Epoch: 515 [81920/90000 (91%)]	Loss: 9.5331	Cost: 6.85s
Train Epoch: 515 	Average Loss: 9.7664
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0539

Learning rate: 0.00019998691195636826
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 516 [0/90000 (0%)]	Loss: 10.7079	Cost: 25.45s
Train Epoch: 516 [20480/90000 (23%)]	Loss: 9.6413	Cost: 6.03s
Train Epoch: 516 [40960/90000 (45%)]	Loss: 9.3914	Cost: 7.89s
Train Epoch: 516 [61440/90000 (68%)]	Loss: 9.6045	Cost: 6.08s
Train Epoch: 516 [81920/90000 (91%)]	Loss: 9.7042	Cost: 6.89s
Train Epoch: 516 	Average Loss: 9.7252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0290

Learning rate: 0.00019998686108078153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 517 [0/90000 (0%)]	Loss: 10.6099	Cost: 23.94s
Train Epoch: 517 [20480/90000 (23%)]	Loss: 9.6352	Cost: 6.27s
Train Epoch: 517 [40960/90000 (45%)]	Loss: 9.5554	Cost: 6.48s
Train Epoch: 517 [61440/90000 (68%)]	Loss: 9.7981	Cost: 6.44s
Train Epoch: 517 [81920/90000 (91%)]	Loss: 9.8400	Cost: 8.61s
Train Epoch: 517 	Average Loss: 9.7459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0359

Learning rate: 0.00019998681010651175
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 518 [0/90000 (0%)]	Loss: 10.5951	Cost: 24.21s
Train Epoch: 518 [20480/90000 (23%)]	Loss: 9.5822	Cost: 6.17s
Train Epoch: 518 [40960/90000 (45%)]	Loss: 9.6551	Cost: 6.71s
Train Epoch: 518 [61440/90000 (68%)]	Loss: 9.6790	Cost: 5.96s
Train Epoch: 518 [81920/90000 (91%)]	Loss: 9.6849	Cost: 5.81s
Train Epoch: 518 	Average Loss: 9.7257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0830

Learning rate: 0.0001999867590335589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 519 [0/90000 (0%)]	Loss: 10.8290	Cost: 23.90s
Train Epoch: 519 [20480/90000 (23%)]	Loss: 9.7547	Cost: 6.32s
Train Epoch: 519 [40960/90000 (45%)]	Loss: 9.5038	Cost: 6.40s
Train Epoch: 519 [61440/90000 (68%)]	Loss: 9.6602	Cost: 6.31s
Train Epoch: 519 [81920/90000 (91%)]	Loss: 9.6019	Cost: 5.75s
Train Epoch: 519 	Average Loss: 9.7658
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9999

Learning rate: 0.00019998670786192314
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 520 [0/90000 (0%)]	Loss: 10.6165	Cost: 27.32s
Train Epoch: 520 [20480/90000 (23%)]	Loss: 9.5595	Cost: 6.24s
Train Epoch: 520 [40960/90000 (45%)]	Loss: 9.6410	Cost: 6.72s
Train Epoch: 520 [61440/90000 (68%)]	Loss: 9.7466	Cost: 5.94s
Train Epoch: 520 [81920/90000 (91%)]	Loss: 9.6707	Cost: 6.22s
Train Epoch: 520 	Average Loss: 9.7105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9893

Learning rate: 0.00019998665659160442
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 521 [0/90000 (0%)]	Loss: 10.6195	Cost: 25.10s
Train Epoch: 521 [20480/90000 (23%)]	Loss: 9.4754	Cost: 6.04s
Train Epoch: 521 [40960/90000 (45%)]	Loss: 9.5871	Cost: 7.84s
Train Epoch: 521 [61440/90000 (68%)]	Loss: 9.6423	Cost: 5.86s
Train Epoch: 521 [81920/90000 (91%)]	Loss: 9.6265	Cost: 7.91s
Train Epoch: 521 	Average Loss: 9.7190
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0197

Learning rate: 0.00019998660522260283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 522 [0/90000 (0%)]	Loss: 10.7562	Cost: 23.41s
Train Epoch: 522 [20480/90000 (23%)]	Loss: 9.5261	Cost: 5.88s
Train Epoch: 522 [40960/90000 (45%)]	Loss: 9.5392	Cost: 6.21s
Train Epoch: 522 [61440/90000 (68%)]	Loss: 9.4812	Cost: 6.26s
Train Epoch: 522 [81920/90000 (91%)]	Loss: 9.6570	Cost: 7.32s
Train Epoch: 522 	Average Loss: 9.7063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9829

Learning rate: 0.00019998655375491842
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 523 [0/90000 (0%)]	Loss: 10.8533	Cost: 24.52s
Train Epoch: 523 [20480/90000 (23%)]	Loss: 9.6834	Cost: 6.19s
Train Epoch: 523 [40960/90000 (45%)]	Loss: 9.5401	Cost: 7.15s
Train Epoch: 523 [61440/90000 (68%)]	Loss: 9.5489	Cost: 5.89s
Train Epoch: 523 [81920/90000 (91%)]	Loss: 9.6636	Cost: 6.29s
Train Epoch: 523 	Average Loss: 9.7112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9739

Learning rate: 0.00019998650218855122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 524 [0/90000 (0%)]	Loss: 10.7652	Cost: 23.66s
Train Epoch: 524 [20480/90000 (23%)]	Loss: 9.6827	Cost: 6.12s
Train Epoch: 524 [40960/90000 (45%)]	Loss: 9.5413	Cost: 7.42s
Train Epoch: 524 [61440/90000 (68%)]	Loss: 9.7715	Cost: 6.23s
Train Epoch: 524 [81920/90000 (91%)]	Loss: 9.6639	Cost: 6.23s
Train Epoch: 524 	Average Loss: 9.7115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9711

Learning rate: 0.00019998645052350132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 525 [0/90000 (0%)]	Loss: 10.4873	Cost: 26.00s
Train Epoch: 525 [20480/90000 (23%)]	Loss: 9.5501	Cost: 5.93s
Train Epoch: 525 [40960/90000 (45%)]	Loss: 9.4189	Cost: 6.50s
Train Epoch: 525 [61440/90000 (68%)]	Loss: 9.6178	Cost: 5.88s
Train Epoch: 525 [81920/90000 (91%)]	Loss: 9.6767	Cost: 5.63s
Train Epoch: 525 	Average Loss: 9.6943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0893

Learning rate: 0.00019998639875976873
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 526 [0/90000 (0%)]	Loss: 10.7021	Cost: 26.90s
Train Epoch: 526 [20480/90000 (23%)]	Loss: 9.5816	Cost: 6.05s
Train Epoch: 526 [40960/90000 (45%)]	Loss: 9.5716	Cost: 7.25s
Train Epoch: 526 [61440/90000 (68%)]	Loss: 9.6889	Cost: 6.38s
Train Epoch: 526 [81920/90000 (91%)]	Loss: 9.5265	Cost: 6.08s
Train Epoch: 526 	Average Loss: 9.6655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0663

Learning rate: 0.0001999863468973535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 527 [0/90000 (0%)]	Loss: 10.6094	Cost: 22.98s
Train Epoch: 527 [20480/90000 (23%)]	Loss: 9.6392	Cost: 6.00s
Train Epoch: 527 [40960/90000 (45%)]	Loss: 9.3477	Cost: 6.30s
Train Epoch: 527 [61440/90000 (68%)]	Loss: 9.6187	Cost: 6.18s
Train Epoch: 527 [81920/90000 (91%)]	Loss: 9.5726	Cost: 8.13s
Train Epoch: 527 	Average Loss: 9.6841
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9476

Learning rate: 0.00019998629493625576
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 528 [0/90000 (0%)]	Loss: 10.6455	Cost: 23.97s
Train Epoch: 528 [20480/90000 (23%)]	Loss: 9.6113	Cost: 6.12s
Train Epoch: 528 [40960/90000 (45%)]	Loss: 9.7040	Cost: 7.36s
Train Epoch: 528 [61440/90000 (68%)]	Loss: 9.5171	Cost: 5.92s
Train Epoch: 528 [81920/90000 (91%)]	Loss: 9.5304	Cost: 5.61s
Train Epoch: 528 	Average Loss: 9.6781
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9215

Saving model as e528_model.pt & e528_waveforms_supplementary.hdf5
Learning rate: 0.00019998624287647545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 529 [0/90000 (0%)]	Loss: 10.5211	Cost: 23.72s
Train Epoch: 529 [20480/90000 (23%)]	Loss: 9.5486	Cost: 6.28s
Train Epoch: 529 [40960/90000 (45%)]	Loss: 9.4049	Cost: 6.33s
Train Epoch: 529 [61440/90000 (68%)]	Loss: 9.6154	Cost: 6.25s
Train Epoch: 529 [81920/90000 (91%)]	Loss: 9.4567	Cost: 6.25s
Train Epoch: 529 	Average Loss: 9.6622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9677

Learning rate: 0.0001999861907180127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 530 [0/90000 (0%)]	Loss: 10.5914	Cost: 26.04s
Train Epoch: 530 [20480/90000 (23%)]	Loss: 9.5565	Cost: 5.94s
Train Epoch: 530 [40960/90000 (45%)]	Loss: 9.5518	Cost: 6.54s
Train Epoch: 530 [61440/90000 (68%)]	Loss: 9.5364	Cost: 5.88s
Train Epoch: 530 [81920/90000 (91%)]	Loss: 9.4934	Cost: 5.91s
Train Epoch: 530 	Average Loss: 9.6677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0720

Learning rate: 0.0001999861384608675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 531 [0/90000 (0%)]	Loss: 10.5863	Cost: 25.14s
Train Epoch: 531 [20480/90000 (23%)]	Loss: 9.6564	Cost: 6.02s
Train Epoch: 531 [40960/90000 (45%)]	Loss: 9.3779	Cost: 7.97s
Train Epoch: 531 [61440/90000 (68%)]	Loss: 9.6861	Cost: 5.96s
Train Epoch: 531 [81920/90000 (91%)]	Loss: 9.5572	Cost: 7.19s
Train Epoch: 531 	Average Loss: 9.6645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0008

Learning rate: 0.00019998608610503996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 532 [0/90000 (0%)]	Loss: 10.7212	Cost: 23.30s
Train Epoch: 532 [20480/90000 (23%)]	Loss: 9.5924	Cost: 6.03s
Train Epoch: 532 [40960/90000 (45%)]	Loss: 9.6401	Cost: 6.62s
Train Epoch: 532 [61440/90000 (68%)]	Loss: 9.6982	Cost: 6.05s
Train Epoch: 532 [81920/90000 (91%)]	Loss: 9.5493	Cost: 8.51s
Train Epoch: 532 	Average Loss: 9.6672
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0370

Learning rate: 0.00019998603365053012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 533 [0/90000 (0%)]	Loss: 10.6851	Cost: 23.87s
Train Epoch: 533 [20480/90000 (23%)]	Loss: 9.5727	Cost: 6.20s
Train Epoch: 533 [40960/90000 (45%)]	Loss: 9.7255	Cost: 6.49s
Train Epoch: 533 [61440/90000 (68%)]	Loss: 9.6526	Cost: 6.31s
Train Epoch: 533 [81920/90000 (91%)]	Loss: 9.5705	Cost: 5.76s
Train Epoch: 533 	Average Loss: 9.6693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9312

Learning rate: 0.00019998598109733802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 534 [0/90000 (0%)]	Loss: 10.8740	Cost: 23.61s
Train Epoch: 534 [20480/90000 (23%)]	Loss: 9.4140	Cost: 6.14s
Train Epoch: 534 [40960/90000 (45%)]	Loss: 9.3425	Cost: 6.32s
Train Epoch: 534 [61440/90000 (68%)]	Loss: 9.3903	Cost: 6.09s
Train Epoch: 534 [81920/90000 (91%)]	Loss: 9.5226	Cost: 6.48s
Train Epoch: 534 	Average Loss: 9.6301
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1006

Learning rate: 0.0001999859284454637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 535 [0/90000 (0%)]	Loss: 10.6541	Cost: 29.10s
Train Epoch: 535 [20480/90000 (23%)]	Loss: 9.5958	Cost: 6.09s
Train Epoch: 535 [40960/90000 (45%)]	Loss: 9.4462	Cost: 6.70s
Train Epoch: 535 [61440/90000 (68%)]	Loss: 9.4302	Cost: 6.20s
Train Epoch: 535 [81920/90000 (91%)]	Loss: 9.3802	Cost: 6.15s
Train Epoch: 535 	Average Loss: 9.6502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0785

Learning rate: 0.00019998587569490723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 536 [0/90000 (0%)]	Loss: 10.7342	Cost: 26.11s
Train Epoch: 536 [20480/90000 (23%)]	Loss: 9.5001	Cost: 6.15s
Train Epoch: 536 [40960/90000 (45%)]	Loss: 9.5766	Cost: 8.66s
Train Epoch: 536 [61440/90000 (68%)]	Loss: 9.6194	Cost: 6.07s
Train Epoch: 536 [81920/90000 (91%)]	Loss: 9.6688	Cost: 8.27s
Train Epoch: 536 	Average Loss: 9.6551
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0594

Learning rate: 0.00019998582284566865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 537 [0/90000 (0%)]	Loss: 10.6304	Cost: 22.08s
Train Epoch: 537 [20480/90000 (23%)]	Loss: 9.4539	Cost: 5.99s
Train Epoch: 537 [40960/90000 (45%)]	Loss: 9.4468	Cost: 7.95s
Train Epoch: 537 [61440/90000 (68%)]	Loss: 9.5770	Cost: 6.02s
Train Epoch: 537 [81920/90000 (91%)]	Loss: 9.5417	Cost: 8.82s
Train Epoch: 537 	Average Loss: 9.6095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9932

Learning rate: 0.00019998576989774803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 538 [0/90000 (0%)]	Loss: 10.6234	Cost: 23.88s
Train Epoch: 538 [20480/90000 (23%)]	Loss: 9.5016	Cost: 6.01s
Train Epoch: 538 [40960/90000 (45%)]	Loss: 9.6569	Cost: 6.52s
Train Epoch: 538 [61440/90000 (68%)]	Loss: 9.6168	Cost: 6.19s
Train Epoch: 538 [81920/90000 (91%)]	Loss: 9.5706	Cost: 6.20s
Train Epoch: 538 	Average Loss: 9.6172
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0144

Learning rate: 0.0001999857168511454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 539 [0/90000 (0%)]	Loss: 10.5288	Cost: 22.69s
Train Epoch: 539 [20480/90000 (23%)]	Loss: 9.4490	Cost: 6.18s
Train Epoch: 539 [40960/90000 (45%)]	Loss: 9.3188	Cost: 7.05s
Train Epoch: 539 [61440/90000 (68%)]	Loss: 9.4756	Cost: 6.07s
Train Epoch: 539 [81920/90000 (91%)]	Loss: 9.4721	Cost: 6.43s
Train Epoch: 539 	Average Loss: 9.5709
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0164

Learning rate: 0.00019998566370586085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 540 [0/90000 (0%)]	Loss: 10.5447	Cost: 25.14s
Train Epoch: 540 [20480/90000 (23%)]	Loss: 9.4836	Cost: 6.00s
Train Epoch: 540 [40960/90000 (45%)]	Loss: 9.3808	Cost: 6.85s
Train Epoch: 540 [61440/90000 (68%)]	Loss: 9.5011	Cost: 6.13s
Train Epoch: 540 [81920/90000 (91%)]	Loss: 9.4748	Cost: 5.87s
Train Epoch: 540 	Average Loss: 9.5981
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9527

Learning rate: 0.0001999856104618944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 541 [0/90000 (0%)]	Loss: 10.6784	Cost: 28.40s
Train Epoch: 541 [20480/90000 (23%)]	Loss: 9.5452	Cost: 5.97s
Train Epoch: 541 [40960/90000 (45%)]	Loss: 9.3129	Cost: 6.67s
Train Epoch: 541 [61440/90000 (68%)]	Loss: 9.5264	Cost: 6.04s
Train Epoch: 541 [81920/90000 (91%)]	Loss: 9.4122	Cost: 5.74s
Train Epoch: 541 	Average Loss: 9.6077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0287

Learning rate: 0.0001999855571192461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 542 [0/90000 (0%)]	Loss: 10.5683	Cost: 25.20s
Train Epoch: 542 [20480/90000 (23%)]	Loss: 9.5976	Cost: 6.00s
Train Epoch: 542 [40960/90000 (45%)]	Loss: 9.4408	Cost: 7.73s
Train Epoch: 542 [61440/90000 (68%)]	Loss: 9.4111	Cost: 5.88s
Train Epoch: 542 [81920/90000 (91%)]	Loss: 9.4279	Cost: 7.41s
Train Epoch: 542 	Average Loss: 9.6071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9153

Saving model as e542_model.pt & e542_waveforms_supplementary.hdf5
Learning rate: 0.00019998550367791602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 543 [0/90000 (0%)]	Loss: 10.6799	Cost: 24.03s
Train Epoch: 543 [20480/90000 (23%)]	Loss: 9.5013	Cost: 6.11s
Train Epoch: 543 [40960/90000 (45%)]	Loss: 9.4261	Cost: 6.46s
Train Epoch: 543 [61440/90000 (68%)]	Loss: 9.4832	Cost: 6.06s
Train Epoch: 543 [81920/90000 (91%)]	Loss: 9.4995	Cost: 9.16s
Train Epoch: 543 	Average Loss: 9.5846
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0931

Learning rate: 0.0001999854501379042
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 544 [0/90000 (0%)]	Loss: 10.3845	Cost: 23.56s
Train Epoch: 544 [20480/90000 (23%)]	Loss: 9.2749	Cost: 6.16s
Train Epoch: 544 [40960/90000 (45%)]	Loss: 9.4475	Cost: 7.03s
Train Epoch: 544 [61440/90000 (68%)]	Loss: 9.4207	Cost: 5.92s
Train Epoch: 544 [81920/90000 (91%)]	Loss: 9.5560	Cost: 5.80s
Train Epoch: 544 	Average Loss: 9.6079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9844

Learning rate: 0.00019998539649921068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 545 [0/90000 (0%)]	Loss: 10.7680	Cost: 23.10s
Train Epoch: 545 [20480/90000 (23%)]	Loss: 9.3530	Cost: 6.16s
Train Epoch: 545 [40960/90000 (45%)]	Loss: 9.3239	Cost: 7.56s
Train Epoch: 545 [61440/90000 (68%)]	Loss: 9.2729	Cost: 6.26s
Train Epoch: 545 [81920/90000 (91%)]	Loss: 9.5343	Cost: 6.25s
Train Epoch: 545 	Average Loss: 9.5916
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0467

Learning rate: 0.00019998534276183553
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 546 [0/90000 (0%)]	Loss: 10.6097	Cost: 27.60s
Train Epoch: 546 [20480/90000 (23%)]	Loss: 9.4148	Cost: 5.95s
Train Epoch: 546 [40960/90000 (45%)]	Loss: 9.2825	Cost: 7.58s
Train Epoch: 546 [61440/90000 (68%)]	Loss: 9.4484	Cost: 6.38s
Train Epoch: 546 [81920/90000 (91%)]	Loss: 9.6321	Cost: 5.65s
Train Epoch: 546 	Average Loss: 9.5958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0064

Learning rate: 0.00019998528892577877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 547 [0/90000 (0%)]	Loss: 10.7337	Cost: 28.85s
Train Epoch: 547 [20480/90000 (23%)]	Loss: 9.3204	Cost: 6.05s
Train Epoch: 547 [40960/90000 (45%)]	Loss: 9.2825	Cost: 6.88s
Train Epoch: 547 [61440/90000 (68%)]	Loss: 9.4288	Cost: 6.17s
Train Epoch: 547 [81920/90000 (91%)]	Loss: 9.5862	Cost: 6.67s
Train Epoch: 547 	Average Loss: 9.5591
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0056

Learning rate: 0.00019998523499104056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 548 [0/90000 (0%)]	Loss: 10.4699	Cost: 25.21s
Train Epoch: 548 [20480/90000 (23%)]	Loss: 9.4871	Cost: 5.99s
Train Epoch: 548 [40960/90000 (45%)]	Loss: 9.3962	Cost: 7.88s
Train Epoch: 548 [61440/90000 (68%)]	Loss: 9.3993	Cost: 5.95s
Train Epoch: 548 [81920/90000 (91%)]	Loss: 9.5532	Cost: 8.45s
Train Epoch: 548 	Average Loss: 9.5244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0537

Learning rate: 0.0001999851809576208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 549 [0/90000 (0%)]	Loss: 10.8675	Cost: 24.57s
Train Epoch: 549 [20480/90000 (23%)]	Loss: 9.4254	Cost: 6.17s
Train Epoch: 549 [40960/90000 (45%)]	Loss: 9.2578	Cost: 6.83s
Train Epoch: 549 [61440/90000 (68%)]	Loss: 9.7681	Cost: 5.76s
Train Epoch: 549 [81920/90000 (91%)]	Loss: 9.4750	Cost: 6.16s
Train Epoch: 549 	Average Loss: 9.5692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0020

Learning rate: 0.00019998512682551964
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 550 [0/90000 (0%)]	Loss: 10.6224	Cost: 23.06s
Train Epoch: 550 [20480/90000 (23%)]	Loss: 9.4937	Cost: 6.27s
Train Epoch: 550 [40960/90000 (45%)]	Loss: 9.3266	Cost: 6.41s
Train Epoch: 550 [61440/90000 (68%)]	Loss: 9.5788	Cost: 6.28s
Train Epoch: 550 [81920/90000 (91%)]	Loss: 9.4529	Cost: 6.21s
Train Epoch: 550 	Average Loss: 9.5618
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0203

Learning rate: 0.00019998507259473715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 551 [0/90000 (0%)]	Loss: 10.6988	Cost: 25.34s
Train Epoch: 551 [20480/90000 (23%)]	Loss: 9.4334	Cost: 6.02s
Train Epoch: 551 [40960/90000 (45%)]	Loss: 9.3012	Cost: 7.46s
Train Epoch: 551 [61440/90000 (68%)]	Loss: 9.3979	Cost: 6.03s
Train Epoch: 551 [81920/90000 (91%)]	Loss: 9.5258	Cost: 5.93s
Train Epoch: 551 	Average Loss: 9.5406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0667

Learning rate: 0.00019998501826527334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 552 [0/90000 (0%)]	Loss: 10.7768	Cost: 28.65s
Train Epoch: 552 [20480/90000 (23%)]	Loss: 9.4043	Cost: 6.03s
Train Epoch: 552 [40960/90000 (45%)]	Loss: 9.2692	Cost: 6.83s
Train Epoch: 552 [61440/90000 (68%)]	Loss: 9.4089	Cost: 5.95s
Train Epoch: 552 [81920/90000 (91%)]	Loss: 9.5358	Cost: 5.73s
Train Epoch: 552 	Average Loss: 9.5583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0533

Learning rate: 0.00019998496383712825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 553 [0/90000 (0%)]	Loss: 10.7583	Cost: 22.82s
Train Epoch: 553 [20480/90000 (23%)]	Loss: 9.2303	Cost: 6.03s
Train Epoch: 553 [40960/90000 (45%)]	Loss: 9.3836	Cost: 7.50s
Train Epoch: 553 [61440/90000 (68%)]	Loss: 9.4571	Cost: 5.91s
Train Epoch: 553 [81920/90000 (91%)]	Loss: 9.3697	Cost: 7.94s
Train Epoch: 553 	Average Loss: 9.5261
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0655

Learning rate: 0.000199984909310302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 554 [0/90000 (0%)]	Loss: 10.6194	Cost: 23.94s
Train Epoch: 554 [20480/90000 (23%)]	Loss: 9.3846	Cost: 5.86s
Train Epoch: 554 [40960/90000 (45%)]	Loss: 9.2969	Cost: 6.52s
Train Epoch: 554 [61440/90000 (68%)]	Loss: 9.4157	Cost: 6.33s
Train Epoch: 554 [81920/90000 (91%)]	Loss: 9.3479	Cost: 6.01s
Train Epoch: 554 	Average Loss: 9.5265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1326

Learning rate: 0.00019998485468479454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 555 [0/90000 (0%)]	Loss: 10.6122	Cost: 23.32s
Train Epoch: 555 [20480/90000 (23%)]	Loss: 9.2956	Cost: 6.51s
Train Epoch: 555 [40960/90000 (45%)]	Loss: 9.2842	Cost: 7.04s
Train Epoch: 555 [61440/90000 (68%)]	Loss: 9.4565	Cost: 6.43s
Train Epoch: 555 [81920/90000 (91%)]	Loss: 9.3456	Cost: 6.19s
Train Epoch: 555 	Average Loss: 9.5117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0958

Learning rate: 0.000199984799960606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 556 [0/90000 (0%)]	Loss: 10.7371	Cost: 23.91s
Train Epoch: 556 [20480/90000 (23%)]	Loss: 9.4336	Cost: 6.07s
Train Epoch: 556 [40960/90000 (45%)]	Loss: 9.4273	Cost: 6.27s
Train Epoch: 556 [61440/90000 (68%)]	Loss: 9.3482	Cost: 5.99s
Train Epoch: 556 [81920/90000 (91%)]	Loss: 9.4989	Cost: 6.50s
Train Epoch: 556 	Average Loss: 9.5203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0331

Learning rate: 0.00019998474513773643
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 557 [0/90000 (0%)]	Loss: 10.7450	Cost: 30.39s
Train Epoch: 557 [20480/90000 (23%)]	Loss: 9.4259	Cost: 5.98s
Train Epoch: 557 [40960/90000 (45%)]	Loss: 9.2335	Cost: 6.59s
Train Epoch: 557 [61440/90000 (68%)]	Loss: 9.4111	Cost: 5.87s
Train Epoch: 557 [81920/90000 (91%)]	Loss: 9.4405	Cost: 6.29s
Train Epoch: 557 	Average Loss: 9.5248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9715

Learning rate: 0.00019998469021618588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 558 [0/90000 (0%)]	Loss: 10.6544	Cost: 24.53s
Train Epoch: 558 [20480/90000 (23%)]	Loss: 9.3813	Cost: 6.13s
Train Epoch: 558 [40960/90000 (45%)]	Loss: 9.3220	Cost: 7.68s
Train Epoch: 558 [61440/90000 (68%)]	Loss: 9.4562	Cost: 5.87s
Train Epoch: 558 [81920/90000 (91%)]	Loss: 9.5144	Cost: 8.13s
Train Epoch: 558 	Average Loss: 9.5127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0560

Learning rate: 0.00019998463519595438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 559 [0/90000 (0%)]	Loss: 10.8527	Cost: 23.24s
Train Epoch: 559 [20480/90000 (23%)]	Loss: 9.3473	Cost: 6.08s
Train Epoch: 559 [40960/90000 (45%)]	Loss: 9.2905	Cost: 6.35s
Train Epoch: 559 [61440/90000 (68%)]	Loss: 9.3479	Cost: 6.00s
Train Epoch: 559 [81920/90000 (91%)]	Loss: 9.3959	Cost: 6.45s
Train Epoch: 559 	Average Loss: 9.4935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0364

Learning rate: 0.000199984580077042
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 560 [0/90000 (0%)]	Loss: 10.6387	Cost: 23.44s
Train Epoch: 560 [20480/90000 (23%)]	Loss: 9.3929	Cost: 6.12s
Train Epoch: 560 [40960/90000 (45%)]	Loss: 9.3457	Cost: 6.67s
Train Epoch: 560 [61440/90000 (68%)]	Loss: 9.3386	Cost: 5.89s
Train Epoch: 560 [81920/90000 (91%)]	Loss: 9.4307	Cost: 6.07s
Train Epoch: 560 	Average Loss: 9.5217
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0742

Learning rate: 0.00019998452485944882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 561 [0/90000 (0%)]	Loss: 10.6963	Cost: 22.28s
Train Epoch: 561 [20480/90000 (23%)]	Loss: 9.3921	Cost: 6.10s
Train Epoch: 561 [40960/90000 (45%)]	Loss: 9.3563	Cost: 6.63s
Train Epoch: 561 [61440/90000 (68%)]	Loss: 9.2863	Cost: 5.98s
Train Epoch: 561 [81920/90000 (91%)]	Loss: 9.3724	Cost: 6.16s
Train Epoch: 561 	Average Loss: 9.5049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1560

Learning rate: 0.00019998446954317485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 562 [0/90000 (0%)]	Loss: 10.6248	Cost: 23.66s
Train Epoch: 562 [20480/90000 (23%)]	Loss: 9.3152	Cost: 5.96s
Train Epoch: 562 [40960/90000 (45%)]	Loss: 9.2124	Cost: 7.01s
Train Epoch: 562 [61440/90000 (68%)]	Loss: 9.3076	Cost: 5.97s
Train Epoch: 562 [81920/90000 (91%)]	Loss: 9.2955	Cost: 6.27s
Train Epoch: 562 	Average Loss: 9.4703
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0394

Learning rate: 0.00019998441412822013
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 563 [0/90000 (0%)]	Loss: 10.6104	Cost: 23.77s
Train Epoch: 563 [20480/90000 (23%)]	Loss: 9.2635	Cost: 6.25s
Train Epoch: 563 [40960/90000 (45%)]	Loss: 9.3835	Cost: 6.30s
Train Epoch: 563 [61440/90000 (68%)]	Loss: 9.4851	Cost: 5.94s
Train Epoch: 563 [81920/90000 (91%)]	Loss: 9.4440	Cost: 6.58s
Train Epoch: 563 	Average Loss: 9.5031
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0662

Learning rate: 0.0001999843586145848
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 564 [0/90000 (0%)]	Loss: 10.6274	Cost: 23.01s
Train Epoch: 564 [20480/90000 (23%)]	Loss: 9.4164	Cost: 6.04s
Train Epoch: 564 [40960/90000 (45%)]	Loss: 9.3164	Cost: 6.46s
Train Epoch: 564 [61440/90000 (68%)]	Loss: 9.3816	Cost: 5.97s
Train Epoch: 564 [81920/90000 (91%)]	Loss: 9.3804	Cost: 5.75s
Train Epoch: 564 	Average Loss: 9.4688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0489

Learning rate: 0.00019998430300226887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 565 [0/90000 (0%)]	Loss: 10.5071	Cost: 23.41s
Train Epoch: 565 [20480/90000 (23%)]	Loss: 9.3255	Cost: 6.15s
Train Epoch: 565 [40960/90000 (45%)]	Loss: 9.3531	Cost: 6.82s
Train Epoch: 565 [61440/90000 (68%)]	Loss: 9.3650	Cost: 6.17s
Train Epoch: 565 [81920/90000 (91%)]	Loss: 9.2225	Cost: 8.10s
Train Epoch: 565 	Average Loss: 9.4598
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0749

Learning rate: 0.0001999842472912724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 566 [0/90000 (0%)]	Loss: 10.5977	Cost: 23.58s
Train Epoch: 566 [20480/90000 (23%)]	Loss: 9.4075	Cost: 6.18s
Train Epoch: 566 [40960/90000 (45%)]	Loss: 9.3210	Cost: 6.49s
Train Epoch: 566 [61440/90000 (68%)]	Loss: 9.2896	Cost: 6.02s
Train Epoch: 566 [81920/90000 (91%)]	Loss: 9.3756	Cost: 6.18s
Train Epoch: 566 	Average Loss: 9.4733
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0473

Learning rate: 0.0001999841914815954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 567 [0/90000 (0%)]	Loss: 10.5301	Cost: 23.22s
Train Epoch: 567 [20480/90000 (23%)]	Loss: 9.2486	Cost: 6.02s
Train Epoch: 567 [40960/90000 (45%)]	Loss: 9.3348	Cost: 6.85s
Train Epoch: 567 [61440/90000 (68%)]	Loss: 9.3746	Cost: 6.32s
Train Epoch: 567 [81920/90000 (91%)]	Loss: 9.4554	Cost: 6.23s
Train Epoch: 567 	Average Loss: 9.4709
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0328

Learning rate: 0.00019998413557323794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 568 [0/90000 (0%)]	Loss: 10.6514	Cost: 30.51s
Train Epoch: 568 [20480/90000 (23%)]	Loss: 9.2447	Cost: 6.12s
Train Epoch: 568 [40960/90000 (45%)]	Loss: 9.5395	Cost: 7.30s
Train Epoch: 568 [61440/90000 (68%)]	Loss: 9.2239	Cost: 6.35s
Train Epoch: 568 [81920/90000 (91%)]	Loss: 9.3653	Cost: 6.68s
Train Epoch: 568 	Average Loss: 9.4561
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0236

Learning rate: 0.00019998407956620012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 569 [0/90000 (0%)]	Loss: 10.9080	Cost: 23.92s
Train Epoch: 569 [20480/90000 (23%)]	Loss: 9.3239	Cost: 6.03s
Train Epoch: 569 [40960/90000 (45%)]	Loss: 9.3751	Cost: 7.53s
Train Epoch: 569 [61440/90000 (68%)]	Loss: 9.2712	Cost: 6.02s
Train Epoch: 569 [81920/90000 (91%)]	Loss: 9.4004	Cost: 9.18s
Train Epoch: 569 	Average Loss: 9.4693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0971

Learning rate: 0.00019998402346048196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 570 [0/90000 (0%)]	Loss: 10.6552	Cost: 23.04s
Train Epoch: 570 [20480/90000 (23%)]	Loss: 9.3946	Cost: 5.87s
Train Epoch: 570 [40960/90000 (45%)]	Loss: 9.2155	Cost: 6.11s
Train Epoch: 570 [61440/90000 (68%)]	Loss: 9.2566	Cost: 6.42s
Train Epoch: 570 [81920/90000 (91%)]	Loss: 9.2400	Cost: 8.04s
Train Epoch: 570 	Average Loss: 9.4384
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0786

Learning rate: 0.0001999839672560835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 571 [0/90000 (0%)]	Loss: 10.7016	Cost: 23.74s
Train Epoch: 571 [20480/90000 (23%)]	Loss: 9.3690	Cost: 5.88s
Train Epoch: 571 [40960/90000 (45%)]	Loss: 9.3311	Cost: 6.62s
Train Epoch: 571 [61440/90000 (68%)]	Loss: 9.3516	Cost: 5.99s
Train Epoch: 571 [81920/90000 (91%)]	Loss: 9.3065	Cost: 5.90s
Train Epoch: 571 	Average Loss: 9.4533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0451

Learning rate: 0.00019998391095300483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 572 [0/90000 (0%)]	Loss: 10.4204	Cost: 23.98s
Train Epoch: 572 [20480/90000 (23%)]	Loss: 9.2629	Cost: 6.00s
Train Epoch: 572 [40960/90000 (45%)]	Loss: 9.2164	Cost: 6.45s
Train Epoch: 572 [61440/90000 (68%)]	Loss: 9.3117	Cost: 6.41s
Train Epoch: 572 [81920/90000 (91%)]	Loss: 9.2098	Cost: 6.20s
Train Epoch: 572 	Average Loss: 9.4358
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0675

Learning rate: 0.00019998385455124602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 573 [0/90000 (0%)]	Loss: 10.6136	Cost: 28.61s
Train Epoch: 573 [20480/90000 (23%)]	Loss: 9.2594	Cost: 5.98s
Train Epoch: 573 [40960/90000 (45%)]	Loss: 9.4087	Cost: 6.85s
Train Epoch: 573 [61440/90000 (68%)]	Loss: 9.2375	Cost: 6.14s
Train Epoch: 573 [81920/90000 (91%)]	Loss: 9.4422	Cost: 5.75s
Train Epoch: 573 	Average Loss: 9.4289
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0680

Learning rate: 0.00019998379805080712
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 574 [0/90000 (0%)]	Loss: 10.8466	Cost: 24.42s
Train Epoch: 574 [20480/90000 (23%)]	Loss: 9.3937	Cost: 6.23s
Train Epoch: 574 [40960/90000 (45%)]	Loss: 9.3423	Cost: 7.50s
Train Epoch: 574 [61440/90000 (68%)]	Loss: 9.2951	Cost: 5.88s
Train Epoch: 574 [81920/90000 (91%)]	Loss: 9.4231	Cost: 7.55s
Train Epoch: 574 	Average Loss: 9.4068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0323

Learning rate: 0.00019998374145168815
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 575 [0/90000 (0%)]	Loss: 10.5780	Cost: 23.58s
Train Epoch: 575 [20480/90000 (23%)]	Loss: 9.1814	Cost: 6.00s
Train Epoch: 575 [40960/90000 (45%)]	Loss: 9.2689	Cost: 6.44s
Train Epoch: 575 [61440/90000 (68%)]	Loss: 9.2366	Cost: 5.95s
Train Epoch: 575 [81920/90000 (91%)]	Loss: 9.1542	Cost: 7.68s
Train Epoch: 575 	Average Loss: 9.4341
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1065

Learning rate: 0.00019998368475388916
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 576 [0/90000 (0%)]	Loss: 10.5549	Cost: 23.43s
Train Epoch: 576 [20480/90000 (23%)]	Loss: 9.2815	Cost: 6.24s
Train Epoch: 576 [40960/90000 (45%)]	Loss: 9.1721	Cost: 7.48s
Train Epoch: 576 [61440/90000 (68%)]	Loss: 9.1264	Cost: 5.95s
Train Epoch: 576 [81920/90000 (91%)]	Loss: 9.1310	Cost: 5.76s
Train Epoch: 576 	Average Loss: 9.4075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0037

Learning rate: 0.00019998362795741026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 577 [0/90000 (0%)]	Loss: 10.7222	Cost: 25.43s
Train Epoch: 577 [20480/90000 (23%)]	Loss: 9.1405	Cost: 6.17s
Train Epoch: 577 [40960/90000 (45%)]	Loss: 9.2575	Cost: 6.79s
Train Epoch: 577 [61440/90000 (68%)]	Loss: 9.1729	Cost: 6.26s
Train Epoch: 577 [81920/90000 (91%)]	Loss: 9.2925	Cost: 6.53s
Train Epoch: 577 	Average Loss: 9.4123
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0841

Learning rate: 0.00019998357106225145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 578 [0/90000 (0%)]	Loss: 10.8283	Cost: 27.99s
Train Epoch: 578 [20480/90000 (23%)]	Loss: 9.2452	Cost: 6.09s
Train Epoch: 578 [40960/90000 (45%)]	Loss: 9.2194	Cost: 6.91s
Train Epoch: 578 [61440/90000 (68%)]	Loss: 9.1933	Cost: 6.07s
Train Epoch: 578 [81920/90000 (91%)]	Loss: 9.3053	Cost: 6.17s
Train Epoch: 578 	Average Loss: 9.4008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0965

Learning rate: 0.00019998351406841282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 579 [0/90000 (0%)]	Loss: 10.6456	Cost: 24.17s
Train Epoch: 579 [20480/90000 (23%)]	Loss: 9.3369	Cost: 5.98s
Train Epoch: 579 [40960/90000 (45%)]	Loss: 9.1925	Cost: 7.64s
Train Epoch: 579 [61440/90000 (68%)]	Loss: 9.1872	Cost: 5.90s
Train Epoch: 579 [81920/90000 (91%)]	Loss: 9.1833	Cost: 7.23s
Train Epoch: 579 	Average Loss: 9.3827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0707

Learning rate: 0.0001999834569758944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 580 [0/90000 (0%)]	Loss: 10.5745	Cost: 23.69s
Train Epoch: 580 [20480/90000 (23%)]	Loss: 9.0455	Cost: 6.09s
Train Epoch: 580 [40960/90000 (45%)]	Loss: 9.2652	Cost: 6.63s
Train Epoch: 580 [61440/90000 (68%)]	Loss: 9.4412	Cost: 5.94s
Train Epoch: 580 [81920/90000 (91%)]	Loss: 9.1670	Cost: 6.12s
Train Epoch: 580 	Average Loss: 9.3844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0973

Learning rate: 0.00019998339978469627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 581 [0/90000 (0%)]	Loss: 10.6926	Cost: 24.33s
Train Epoch: 581 [20480/90000 (23%)]	Loss: 9.2705	Cost: 6.20s
Train Epoch: 581 [40960/90000 (45%)]	Loss: 9.1443	Cost: 6.32s
Train Epoch: 581 [61440/90000 (68%)]	Loss: 9.3704	Cost: 6.02s
Train Epoch: 581 [81920/90000 (91%)]	Loss: 9.3160	Cost: 6.25s
Train Epoch: 581 	Average Loss: 9.3779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0804

Learning rate: 0.0001999833424948185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 582 [0/90000 (0%)]	Loss: 10.5863	Cost: 23.85s
Train Epoch: 582 [20480/90000 (23%)]	Loss: 9.1537	Cost: 6.10s
Train Epoch: 582 [40960/90000 (45%)]	Loss: 9.2241	Cost: 6.32s
Train Epoch: 582 [61440/90000 (68%)]	Loss: 9.1980	Cost: 6.09s
Train Epoch: 582 [81920/90000 (91%)]	Loss: 9.3490	Cost: 6.39s
Train Epoch: 582 	Average Loss: 9.3652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0291

Learning rate: 0.00019998328510626112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 583 [0/90000 (0%)]	Loss: 10.6833	Cost: 28.31s
Train Epoch: 583 [20480/90000 (23%)]	Loss: 9.3573	Cost: 6.14s
Train Epoch: 583 [40960/90000 (45%)]	Loss: 9.1022	Cost: 6.66s
Train Epoch: 583 [61440/90000 (68%)]	Loss: 9.1679	Cost: 6.15s
Train Epoch: 583 [81920/90000 (91%)]	Loss: 9.1822	Cost: 5.78s
Train Epoch: 583 	Average Loss: 9.3783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0527

Learning rate: 0.0001999832276190242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 584 [0/90000 (0%)]	Loss: 10.5773	Cost: 23.97s
Train Epoch: 584 [20480/90000 (23%)]	Loss: 9.1794	Cost: 5.99s
Train Epoch: 584 [40960/90000 (45%)]	Loss: 9.2552	Cost: 8.16s
Train Epoch: 584 [61440/90000 (68%)]	Loss: 9.3591	Cost: 5.88s
Train Epoch: 584 [81920/90000 (91%)]	Loss: 9.2159	Cost: 8.33s
Train Epoch: 584 	Average Loss: 9.3819
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0745

Learning rate: 0.00019998317003310778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 585 [0/90000 (0%)]	Loss: 10.7943	Cost: 23.12s
Train Epoch: 585 [20480/90000 (23%)]	Loss: 9.1073	Cost: 6.04s
Train Epoch: 585 [40960/90000 (45%)]	Loss: 9.1239	Cost: 6.28s
Train Epoch: 585 [61440/90000 (68%)]	Loss: 9.1652	Cost: 5.99s
Train Epoch: 585 [81920/90000 (91%)]	Loss: 9.3962	Cost: 7.11s
Train Epoch: 585 	Average Loss: 9.3708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0317

Learning rate: 0.0001999831123485119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 586 [0/90000 (0%)]	Loss: 10.5901	Cost: 22.99s
Train Epoch: 586 [20480/90000 (23%)]	Loss: 9.1915	Cost: 5.97s
Train Epoch: 586 [40960/90000 (45%)]	Loss: 9.1198	Cost: 7.19s
Train Epoch: 586 [61440/90000 (68%)]	Loss: 9.2425	Cost: 5.90s
Train Epoch: 586 [81920/90000 (91%)]	Loss: 9.1407	Cost: 5.90s
Train Epoch: 586 	Average Loss: 9.3353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1726

Learning rate: 0.00019998305456523665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 587 [0/90000 (0%)]	Loss: 10.6982	Cost: 23.93s
Train Epoch: 587 [20480/90000 (23%)]	Loss: 9.0584	Cost: 5.99s
Train Epoch: 587 [40960/90000 (45%)]	Loss: 9.1440	Cost: 6.95s
Train Epoch: 587 [61440/90000 (68%)]	Loss: 9.1724	Cost: 6.05s
Train Epoch: 587 [81920/90000 (91%)]	Loss: 9.1162	Cost: 6.40s
Train Epoch: 587 	Average Loss: 9.2999
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1150

Learning rate: 0.0001999829966832821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 588 [0/90000 (0%)]	Loss: 10.7525	Cost: 29.17s
Train Epoch: 588 [20480/90000 (23%)]	Loss: 9.0735	Cost: 6.06s
Train Epoch: 588 [40960/90000 (45%)]	Loss: 9.1956	Cost: 7.04s
Train Epoch: 588 [61440/90000 (68%)]	Loss: 9.1283	Cost: 6.13s
Train Epoch: 588 [81920/90000 (91%)]	Loss: 9.1172	Cost: 6.27s
Train Epoch: 588 	Average Loss: 9.3573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0513

Learning rate: 0.00019998293870264827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 589 [0/90000 (0%)]	Loss: 10.7056	Cost: 25.13s
Train Epoch: 589 [20480/90000 (23%)]	Loss: 9.4338	Cost: 6.06s
Train Epoch: 589 [40960/90000 (45%)]	Loss: 9.0519	Cost: 7.86s
Train Epoch: 589 [61440/90000 (68%)]	Loss: 9.3435	Cost: 6.01s
Train Epoch: 589 [81920/90000 (91%)]	Loss: 9.3512	Cost: 7.34s
Train Epoch: 589 	Average Loss: 9.3543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0677

Learning rate: 0.00019998288062333524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 590 [0/90000 (0%)]	Loss: 10.6656	Cost: 23.53s
Train Epoch: 590 [20480/90000 (23%)]	Loss: 9.2545	Cost: 5.96s
Train Epoch: 590 [40960/90000 (45%)]	Loss: 8.9619	Cost: 6.48s
Train Epoch: 590 [61440/90000 (68%)]	Loss: 9.2450	Cost: 6.06s
Train Epoch: 590 [81920/90000 (91%)]	Loss: 9.3282	Cost: 7.97s
Train Epoch: 590 	Average Loss: 9.3460
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1247

Learning rate: 0.00019998282244534305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 591 [0/90000 (0%)]	Loss: 10.7107	Cost: 24.32s
Train Epoch: 591 [20480/90000 (23%)]	Loss: 9.1736	Cost: 6.06s
Train Epoch: 591 [40960/90000 (45%)]	Loss: 9.3056	Cost: 7.54s
Train Epoch: 591 [61440/90000 (68%)]	Loss: 9.1275	Cost: 5.94s
Train Epoch: 591 [81920/90000 (91%)]	Loss: 9.3997	Cost: 6.16s
Train Epoch: 591 	Average Loss: 9.3526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0453

Learning rate: 0.0001999827641686718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 592 [0/90000 (0%)]	Loss: 10.7370	Cost: 23.49s
Train Epoch: 592 [20480/90000 (23%)]	Loss: 9.1978	Cost: 6.20s
Train Epoch: 592 [40960/90000 (45%)]	Loss: 9.3148	Cost: 6.80s
Train Epoch: 592 [61440/90000 (68%)]	Loss: 9.0362	Cost: 5.93s
Train Epoch: 592 [81920/90000 (91%)]	Loss: 9.1355	Cost: 6.67s
Train Epoch: 592 	Average Loss: 9.3267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1375

Learning rate: 0.0001999827057933215
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 593 [0/90000 (0%)]	Loss: 10.7439	Cost: 28.08s
Train Epoch: 593 [20480/90000 (23%)]	Loss: 9.2351	Cost: 6.04s
Train Epoch: 593 [40960/90000 (45%)]	Loss: 9.2097	Cost: 7.07s
Train Epoch: 593 [61440/90000 (68%)]	Loss: 9.0749	Cost: 6.05s
Train Epoch: 593 [81920/90000 (91%)]	Loss: 9.2432	Cost: 5.57s
Train Epoch: 593 	Average Loss: 9.3176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1493

Learning rate: 0.0001999826473192922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 594 [0/90000 (0%)]	Loss: 10.8189	Cost: 24.76s
Train Epoch: 594 [20480/90000 (23%)]	Loss: 9.2243	Cost: 6.07s
Train Epoch: 594 [40960/90000 (45%)]	Loss: 9.1247	Cost: 8.03s
Train Epoch: 594 [61440/90000 (68%)]	Loss: 9.2110	Cost: 5.86s
Train Epoch: 594 [81920/90000 (91%)]	Loss: 9.2885	Cost: 7.30s
Train Epoch: 594 	Average Loss: 9.3247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0895

Learning rate: 0.00019998258874658403
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 595 [0/90000 (0%)]	Loss: 10.6653	Cost: 23.31s
Train Epoch: 595 [20480/90000 (23%)]	Loss: 9.1517	Cost: 5.99s
Train Epoch: 595 [40960/90000 (45%)]	Loss: 9.0384	Cost: 6.51s
Train Epoch: 595 [61440/90000 (68%)]	Loss: 9.2500	Cost: 6.12s
Train Epoch: 595 [81920/90000 (91%)]	Loss: 9.1642	Cost: 7.69s
Train Epoch: 595 	Average Loss: 9.3479
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1407

Learning rate: 0.00019998253007519698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 596 [0/90000 (0%)]	Loss: 10.7585	Cost: 23.03s
Train Epoch: 596 [20480/90000 (23%)]	Loss: 9.2572	Cost: 5.94s
Train Epoch: 596 [40960/90000 (45%)]	Loss: 9.0435	Cost: 6.86s
Train Epoch: 596 [61440/90000 (68%)]	Loss: 9.2547	Cost: 5.82s
Train Epoch: 596 [81920/90000 (91%)]	Loss: 9.1454	Cost: 5.57s
Train Epoch: 596 	Average Loss: 9.3108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0119

Learning rate: 0.00019998247130513115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 597 [0/90000 (0%)]	Loss: 10.8008	Cost: 25.43s
Train Epoch: 597 [20480/90000 (23%)]	Loss: 9.1420	Cost: 6.05s
Train Epoch: 597 [40960/90000 (45%)]	Loss: 9.0318	Cost: 6.91s
Train Epoch: 597 [61440/90000 (68%)]	Loss: 9.1734	Cost: 6.08s
Train Epoch: 597 [81920/90000 (91%)]	Loss: 9.1126	Cost: 6.26s
Train Epoch: 597 	Average Loss: 9.2790
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0133

Learning rate: 0.00019998241243638655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 598 [0/90000 (0%)]	Loss: 10.6628	Cost: 25.08s
Train Epoch: 598 [20480/90000 (23%)]	Loss: 9.1841	Cost: 6.00s
Train Epoch: 598 [40960/90000 (45%)]	Loss: 9.0610	Cost: 6.91s
Train Epoch: 598 [61440/90000 (68%)]	Loss: 9.1492	Cost: 5.99s
Train Epoch: 598 [81920/90000 (91%)]	Loss: 9.0954	Cost: 5.97s
Train Epoch: 598 	Average Loss: 9.2612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0911

Learning rate: 0.00019998235346896327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 599 [0/90000 (0%)]	Loss: 10.5868	Cost: 22.46s
Train Epoch: 599 [20480/90000 (23%)]	Loss: 9.2068	Cost: 6.00s
Train Epoch: 599 [40960/90000 (45%)]	Loss: 8.9803	Cost: 7.57s
Train Epoch: 599 [61440/90000 (68%)]	Loss: 9.0452	Cost: 5.95s
Train Epoch: 599 [81920/90000 (91%)]	Loss: 9.0758	Cost: 8.40s
Train Epoch: 599 	Average Loss: 9.2472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0708

Learning rate: 0.0001999822944028614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 600 [0/90000 (0%)]	Loss: 10.7870	Cost: 23.42s
Train Epoch: 600 [20480/90000 (23%)]	Loss: 9.1891	Cost: 6.00s
Train Epoch: 600 [40960/90000 (45%)]	Loss: 9.1517	Cost: 7.13s
Train Epoch: 600 [61440/90000 (68%)]	Loss: 9.2893	Cost: 5.94s
Train Epoch: 600 [81920/90000 (91%)]	Loss: 9.0134	Cost: 6.25s
Train Epoch: 600 	Average Loss: 9.2803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0678

Learning rate: 0.0001999822352380809
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 601 [0/90000 (0%)]	Loss: 10.6130	Cost: 23.44s
Train Epoch: 601 [20480/90000 (23%)]	Loss: 9.0586	Cost: 6.02s
Train Epoch: 601 [40960/90000 (45%)]	Loss: 9.1113	Cost: 7.37s
Train Epoch: 601 [61440/90000 (68%)]	Loss: 9.1982	Cost: 5.95s
Train Epoch: 601 [81920/90000 (91%)]	Loss: 9.3549	Cost: 6.57s
Train Epoch: 601 	Average Loss: 9.2791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0994

Learning rate: 0.00019998217597462192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 602 [0/90000 (0%)]	Loss: 10.9532	Cost: 25.42s
Train Epoch: 602 [20480/90000 (23%)]	Loss: 9.2168	Cost: 5.97s
Train Epoch: 602 [40960/90000 (45%)]	Loss: 9.0502	Cost: 7.37s
Train Epoch: 602 [61440/90000 (68%)]	Loss: 9.1814	Cost: 5.91s
Train Epoch: 602 [81920/90000 (91%)]	Loss: 9.0735	Cost: 5.79s
Train Epoch: 602 	Average Loss: 9.2575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1181

Learning rate: 0.00019998211661248448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 603 [0/90000 (0%)]	Loss: 10.7660	Cost: 28.10s
Train Epoch: 603 [20480/90000 (23%)]	Loss: 9.2182	Cost: 6.05s
Train Epoch: 603 [40960/90000 (45%)]	Loss: 9.0647	Cost: 8.55s
Train Epoch: 603 [61440/90000 (68%)]	Loss: 9.2530	Cost: 6.12s
Train Epoch: 603 [81920/90000 (91%)]	Loss: 8.9914	Cost: 6.16s
Train Epoch: 603 	Average Loss: 9.2842
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1719

Learning rate: 0.00019998205715166862
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 604 [0/90000 (0%)]	Loss: 10.4976	Cost: 23.45s
Train Epoch: 604 [20480/90000 (23%)]	Loss: 9.0384	Cost: 6.00s
Train Epoch: 604 [40960/90000 (45%)]	Loss: 8.9403	Cost: 7.80s
Train Epoch: 604 [61440/90000 (68%)]	Loss: 9.0713	Cost: 5.94s
Train Epoch: 604 [81920/90000 (91%)]	Loss: 9.2124	Cost: 8.43s
Train Epoch: 604 	Average Loss: 9.2552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0591

Learning rate: 0.00019998199759217446
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 605 [0/90000 (0%)]	Loss: 10.6506	Cost: 23.02s
Train Epoch: 605 [20480/90000 (23%)]	Loss: 8.9641	Cost: 6.03s
Train Epoch: 605 [40960/90000 (45%)]	Loss: 8.9430	Cost: 6.32s
Train Epoch: 605 [61440/90000 (68%)]	Loss: 8.9035	Cost: 6.13s
Train Epoch: 605 [81920/90000 (91%)]	Loss: 9.0910	Cost: 7.43s
Train Epoch: 605 	Average Loss: 9.2285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0770

Learning rate: 0.000199981937934002
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 606 [0/90000 (0%)]	Loss: 10.5505	Cost: 23.04s
Train Epoch: 606 [20480/90000 (23%)]	Loss: 9.0520	Cost: 6.18s
Train Epoch: 606 [40960/90000 (45%)]	Loss: 9.0639	Cost: 7.25s
Train Epoch: 606 [61440/90000 (68%)]	Loss: 9.0434	Cost: 5.98s
Train Epoch: 606 [81920/90000 (91%)]	Loss: 9.2639	Cost: 5.89s
Train Epoch: 606 	Average Loss: 9.2282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1736

Learning rate: 0.00019998187817715134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 607 [0/90000 (0%)]	Loss: 10.7938	Cost: 24.44s
Train Epoch: 607 [20480/90000 (23%)]	Loss: 9.1962	Cost: 5.93s
Train Epoch: 607 [40960/90000 (45%)]	Loss: 9.0261	Cost: 6.85s
Train Epoch: 607 [61440/90000 (68%)]	Loss: 9.1639	Cost: 6.08s
Train Epoch: 607 [81920/90000 (91%)]	Loss: 9.1830	Cost: 6.67s
Train Epoch: 607 	Average Loss: 9.2242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0838

Learning rate: 0.00019998181832162252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 608 [0/90000 (0%)]	Loss: 10.6859	Cost: 28.74s
Train Epoch: 608 [20480/90000 (23%)]	Loss: 9.0371	Cost: 5.92s
Train Epoch: 608 [40960/90000 (45%)]	Loss: 8.9742	Cost: 7.33s
Train Epoch: 608 [61440/90000 (68%)]	Loss: 9.2057	Cost: 5.98s
Train Epoch: 608 [81920/90000 (91%)]	Loss: 9.1343	Cost: 6.24s
Train Epoch: 608 	Average Loss: 9.2254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0739

Learning rate: 0.0001999817583674156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 609 [0/90000 (0%)]	Loss: 10.6376	Cost: 26.29s
Train Epoch: 609 [20480/90000 (23%)]	Loss: 8.9587	Cost: 5.99s
Train Epoch: 609 [40960/90000 (45%)]	Loss: 9.1014	Cost: 7.42s
Train Epoch: 609 [61440/90000 (68%)]	Loss: 9.1724	Cost: 6.10s
Train Epoch: 609 [81920/90000 (91%)]	Loss: 9.1351	Cost: 6.40s
Train Epoch: 609 	Average Loss: 9.2071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0200

Learning rate: 0.00019998169831453064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 610 [0/90000 (0%)]	Loss: 10.7454	Cost: 23.06s
Train Epoch: 610 [20480/90000 (23%)]	Loss: 9.1093	Cost: 5.93s
Train Epoch: 610 [40960/90000 (45%)]	Loss: 9.1647	Cost: 6.72s
Train Epoch: 610 [61440/90000 (68%)]	Loss: 9.0372	Cost: 5.98s
Train Epoch: 610 [81920/90000 (91%)]	Loss: 8.9924	Cost: 8.58s
Train Epoch: 610 	Average Loss: 9.2091
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0857

Learning rate: 0.0001999816381629677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 611 [0/90000 (0%)]	Loss: 10.7464	Cost: 24.33s
Train Epoch: 611 [20480/90000 (23%)]	Loss: 8.9706	Cost: 5.92s
Train Epoch: 611 [40960/90000 (45%)]	Loss: 8.8800	Cost: 7.28s
Train Epoch: 611 [61440/90000 (68%)]	Loss: 9.1963	Cost: 5.97s
Train Epoch: 611 [81920/90000 (91%)]	Loss: 9.0439	Cost: 5.61s
Train Epoch: 611 	Average Loss: 9.1891
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1285

Learning rate: 0.00019998157791272685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 612 [0/90000 (0%)]	Loss: 10.8061	Cost: 23.84s
Train Epoch: 612 [20480/90000 (23%)]	Loss: 9.2982	Cost: 5.99s
Train Epoch: 612 [40960/90000 (45%)]	Loss: 9.1216	Cost: 7.77s
Train Epoch: 612 [61440/90000 (68%)]	Loss: 8.9953	Cost: 5.99s
Train Epoch: 612 [81920/90000 (91%)]	Loss: 9.1085	Cost: 6.30s
Train Epoch: 612 	Average Loss: 9.2059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1240

Learning rate: 0.00019998151756380812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 613 [0/90000 (0%)]	Loss: 10.7874	Cost: 25.65s
Train Epoch: 613 [20480/90000 (23%)]	Loss: 9.2549	Cost: 6.41s
Train Epoch: 613 [40960/90000 (45%)]	Loss: 9.0153	Cost: 6.72s
Train Epoch: 613 [61440/90000 (68%)]	Loss: 9.0240	Cost: 5.88s
Train Epoch: 613 [81920/90000 (91%)]	Loss: 9.0787	Cost: 5.84s
Train Epoch: 613 	Average Loss: 9.2263
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1093

Learning rate: 0.0001999814571162116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 614 [0/90000 (0%)]	Loss: 10.5539	Cost: 26.90s
Train Epoch: 614 [20480/90000 (23%)]	Loss: 9.0645	Cost: 6.00s
Train Epoch: 614 [40960/90000 (45%)]	Loss: 8.8517	Cost: 7.02s
Train Epoch: 614 [61440/90000 (68%)]	Loss: 9.0226	Cost: 6.16s
Train Epoch: 614 [81920/90000 (91%)]	Loss: 9.1042	Cost: 6.30s
Train Epoch: 614 	Average Loss: 9.1754
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1495

Learning rate: 0.00019998139656993732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 615 [0/90000 (0%)]	Loss: 10.9960	Cost: 22.94s
Train Epoch: 615 [20480/90000 (23%)]	Loss: 9.0591	Cost: 6.06s
Train Epoch: 615 [40960/90000 (45%)]	Loss: 8.8820	Cost: 6.64s
Train Epoch: 615 [61440/90000 (68%)]	Loss: 9.0754	Cost: 6.05s
Train Epoch: 615 [81920/90000 (91%)]	Loss: 8.9639	Cost: 8.12s
Train Epoch: 615 	Average Loss: 9.1596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1083

Learning rate: 0.00019998133592498537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 616 [0/90000 (0%)]	Loss: 10.5664	Cost: 23.49s
Train Epoch: 616 [20480/90000 (23%)]	Loss: 9.0363	Cost: 5.98s
Train Epoch: 616 [40960/90000 (45%)]	Loss: 9.0361	Cost: 7.77s
Train Epoch: 616 [61440/90000 (68%)]	Loss: 8.8399	Cost: 5.91s
Train Epoch: 616 [81920/90000 (91%)]	Loss: 8.9181	Cost: 5.72s
Train Epoch: 616 	Average Loss: 9.1704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1797

Learning rate: 0.00019998127518135577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 617 [0/90000 (0%)]	Loss: 10.6964	Cost: 23.74s
Train Epoch: 617 [20480/90000 (23%)]	Loss: 9.0341	Cost: 5.94s
Train Epoch: 617 [40960/90000 (45%)]	Loss: 9.0173	Cost: 7.09s
Train Epoch: 617 [61440/90000 (68%)]	Loss: 9.1817	Cost: 5.78s
Train Epoch: 617 [81920/90000 (91%)]	Loss: 9.0653	Cost: 7.02s
Train Epoch: 617 	Average Loss: 9.2176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1297

Learning rate: 0.0001999812143390486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 618 [0/90000 (0%)]	Loss: 10.9327	Cost: 26.29s
Train Epoch: 618 [20480/90000 (23%)]	Loss: 8.8564	Cost: 6.00s
Train Epoch: 618 [40960/90000 (45%)]	Loss: 8.8724	Cost: 6.40s
Train Epoch: 618 [61440/90000 (68%)]	Loss: 8.9876	Cost: 6.09s
Train Epoch: 618 [81920/90000 (91%)]	Loss: 9.0863	Cost: 5.53s
Train Epoch: 618 	Average Loss: 9.1439
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2210

Learning rate: 0.00019998115339806398
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 619 [0/90000 (0%)]	Loss: 10.7525	Cost: 24.30s
Train Epoch: 619 [20480/90000 (23%)]	Loss: 9.0285	Cost: 5.98s
Train Epoch: 619 [40960/90000 (45%)]	Loss: 8.8466	Cost: 8.00s
Train Epoch: 619 [61440/90000 (68%)]	Loss: 9.0913	Cost: 6.02s
Train Epoch: 619 [81920/90000 (91%)]	Loss: 9.0802	Cost: 7.39s
Train Epoch: 619 	Average Loss: 9.1391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2216

Learning rate: 0.00019998109235840191
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 620 [0/90000 (0%)]	Loss: 10.8141	Cost: 22.90s
Train Epoch: 620 [20480/90000 (23%)]	Loss: 9.0346	Cost: 6.66s
Train Epoch: 620 [40960/90000 (45%)]	Loss: 8.9824	Cost: 6.41s
Train Epoch: 620 [61440/90000 (68%)]	Loss: 9.1091	Cost: 6.07s
Train Epoch: 620 [81920/90000 (91%)]	Loss: 8.9345	Cost: 7.03s
Train Epoch: 620 	Average Loss: 9.2001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1572

Learning rate: 0.00019998103122006243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 621 [0/90000 (0%)]	Loss: 10.9602	Cost: 24.17s
Train Epoch: 621 [20480/90000 (23%)]	Loss: 8.9576	Cost: 6.19s
Train Epoch: 621 [40960/90000 (45%)]	Loss: 8.8877	Cost: 6.52s
Train Epoch: 621 [61440/90000 (68%)]	Loss: 9.0262	Cost: 5.93s
Train Epoch: 621 [81920/90000 (91%)]	Loss: 9.2448	Cost: 5.72s
Train Epoch: 621 	Average Loss: 9.1467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1243

Learning rate: 0.00019998096998304565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 622 [0/90000 (0%)]	Loss: 10.8552	Cost: 22.84s
Train Epoch: 622 [20480/90000 (23%)]	Loss: 9.0048	Cost: 6.55s
Train Epoch: 622 [40960/90000 (45%)]	Loss: 9.0228	Cost: 7.30s
Train Epoch: 622 [61440/90000 (68%)]	Loss: 8.9902	Cost: 5.99s
Train Epoch: 622 [81920/90000 (91%)]	Loss: 9.2217	Cost: 6.80s
Train Epoch: 622 	Average Loss: 9.1536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1258

Learning rate: 0.0001999809086473516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 623 [0/90000 (0%)]	Loss: 10.9525	Cost: 26.65s
Train Epoch: 623 [20480/90000 (23%)]	Loss: 9.0262	Cost: 6.06s
Train Epoch: 623 [40960/90000 (45%)]	Loss: 8.9472	Cost: 6.57s
Train Epoch: 623 [61440/90000 (68%)]	Loss: 8.8798	Cost: 6.09s
Train Epoch: 623 [81920/90000 (91%)]	Loss: 8.9670	Cost: 6.15s
Train Epoch: 623 	Average Loss: 9.1277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1451

Learning rate: 0.00019998084721298032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 624 [0/90000 (0%)]	Loss: 10.8765	Cost: 27.63s
Train Epoch: 624 [20480/90000 (23%)]	Loss: 8.9511	Cost: 6.07s
Train Epoch: 624 [40960/90000 (45%)]	Loss: 8.8628	Cost: 7.10s
Train Epoch: 624 [61440/90000 (68%)]	Loss: 9.0041	Cost: 6.11s
Train Epoch: 624 [81920/90000 (91%)]	Loss: 9.0974	Cost: 6.95s
Train Epoch: 624 	Average Loss: 9.1314
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1236

Learning rate: 0.00019998078567993191
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 625 [0/90000 (0%)]	Loss: 10.6822	Cost: 22.14s
Train Epoch: 625 [20480/90000 (23%)]	Loss: 8.9047	Cost: 6.14s
Train Epoch: 625 [40960/90000 (45%)]	Loss: 8.9637	Cost: 7.34s
Train Epoch: 625 [61440/90000 (68%)]	Loss: 8.9609	Cost: 6.08s
Train Epoch: 625 [81920/90000 (91%)]	Loss: 8.7919	Cost: 8.54s
Train Epoch: 625 	Average Loss: 9.0971
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1711

Learning rate: 0.00019998072404820645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 626 [0/90000 (0%)]	Loss: 10.6089	Cost: 24.41s
Train Epoch: 626 [20480/90000 (23%)]	Loss: 8.7558	Cost: 6.07s
Train Epoch: 626 [40960/90000 (45%)]	Loss: 8.8077	Cost: 7.45s
Train Epoch: 626 [61440/90000 (68%)]	Loss: 8.8685	Cost: 5.92s
Train Epoch: 626 [81920/90000 (91%)]	Loss: 9.1130	Cost: 6.13s
Train Epoch: 626 	Average Loss: 9.0898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1362

Learning rate: 0.00019998066231780395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 627 [0/90000 (0%)]	Loss: 10.8894	Cost: 23.24s
Train Epoch: 627 [20480/90000 (23%)]	Loss: 8.9777	Cost: 6.15s
Train Epoch: 627 [40960/90000 (45%)]	Loss: 8.7008	Cost: 7.12s
Train Epoch: 627 [61440/90000 (68%)]	Loss: 9.0238	Cost: 5.97s
Train Epoch: 627 [81920/90000 (91%)]	Loss: 9.0003	Cost: 5.85s
Train Epoch: 627 	Average Loss: 9.1022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1897

Learning rate: 0.0001999806004887245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 628 [0/90000 (0%)]	Loss: 10.6382	Cost: 27.08s
Train Epoch: 628 [20480/90000 (23%)]	Loss: 8.8163	Cost: 6.11s
Train Epoch: 628 [40960/90000 (45%)]	Loss: 8.8599	Cost: 7.48s
Train Epoch: 628 [61440/90000 (68%)]	Loss: 8.9672	Cost: 6.53s
Train Epoch: 628 [81920/90000 (91%)]	Loss: 8.9145	Cost: 5.75s
Train Epoch: 628 	Average Loss: 9.0773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2196

Learning rate: 0.00019998053856096817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 629 [0/90000 (0%)]	Loss: 10.6647	Cost: 28.35s
Train Epoch: 629 [20480/90000 (23%)]	Loss: 8.8192	Cost: 6.00s
Train Epoch: 629 [40960/90000 (45%)]	Loss: 8.7503	Cost: 8.89s
Train Epoch: 629 [61440/90000 (68%)]	Loss: 9.0348	Cost: 6.08s
Train Epoch: 629 [81920/90000 (91%)]	Loss: 8.9622	Cost: 6.68s
Train Epoch: 629 	Average Loss: 9.0638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1891

Learning rate: 0.00019998047653453497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 630 [0/90000 (0%)]	Loss: 11.2111	Cost: 22.41s
Train Epoch: 630 [20480/90000 (23%)]	Loss: 8.9682	Cost: 6.04s
Train Epoch: 630 [40960/90000 (45%)]	Loss: 8.8686	Cost: 7.66s
Train Epoch: 630 [61440/90000 (68%)]	Loss: 8.9760	Cost: 5.96s
Train Epoch: 630 [81920/90000 (91%)]	Loss: 8.9298	Cost: 8.51s
Train Epoch: 630 	Average Loss: 9.0934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1475

Learning rate: 0.000199980414409425
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 631 [0/90000 (0%)]	Loss: 10.9781	Cost: 23.96s
Train Epoch: 631 [20480/90000 (23%)]	Loss: 8.9905	Cost: 6.51s
Train Epoch: 631 [40960/90000 (45%)]	Loss: 8.7806	Cost: 6.41s
Train Epoch: 631 [61440/90000 (68%)]	Loss: 8.8766	Cost: 6.40s
Train Epoch: 631 [81920/90000 (91%)]	Loss: 9.0369	Cost: 6.13s
Train Epoch: 631 	Average Loss: 9.0972
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1244

Learning rate: 0.0001999803521856383
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 632 [0/90000 (0%)]	Loss: 10.8137	Cost: 24.33s
Train Epoch: 632 [20480/90000 (23%)]	Loss: 8.8764	Cost: 6.07s
Train Epoch: 632 [40960/90000 (45%)]	Loss: 8.9088	Cost: 6.53s
Train Epoch: 632 [61440/90000 (68%)]	Loss: 9.0777	Cost: 6.11s
Train Epoch: 632 [81920/90000 (91%)]	Loss: 8.9153	Cost: 6.36s
Train Epoch: 632 	Average Loss: 9.0501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9845

Learning rate: 0.00019998028986317499
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 633 [0/90000 (0%)]	Loss: 10.7095	Cost: 25.52s
Train Epoch: 633 [20480/90000 (23%)]	Loss: 8.8701	Cost: 6.19s
Train Epoch: 633 [40960/90000 (45%)]	Loss: 8.6704	Cost: 6.83s
Train Epoch: 633 [61440/90000 (68%)]	Loss: 9.0389	Cost: 6.02s
Train Epoch: 633 [81920/90000 (91%)]	Loss: 8.9839	Cost: 6.82s
Train Epoch: 633 	Average Loss: 9.0468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0944

Learning rate: 0.00019998022744203506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 634 [0/90000 (0%)]	Loss: 10.7337	Cost: 27.73s
Train Epoch: 634 [20480/90000 (23%)]	Loss: 8.7119	Cost: 6.02s
Train Epoch: 634 [40960/90000 (45%)]	Loss: 8.9281	Cost: 6.82s
Train Epoch: 634 [61440/90000 (68%)]	Loss: 8.9833	Cost: 5.93s
Train Epoch: 634 [81920/90000 (91%)]	Loss: 8.8896	Cost: 5.73s
Train Epoch: 634 	Average Loss: 9.0136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1521

Learning rate: 0.0001999801649222186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 635 [0/90000 (0%)]	Loss: 10.6249	Cost: 24.81s
Train Epoch: 635 [20480/90000 (23%)]	Loss: 8.8444	Cost: 6.04s
Train Epoch: 635 [40960/90000 (45%)]	Loss: 8.9192	Cost: 8.08s
Train Epoch: 635 [61440/90000 (68%)]	Loss: 8.9600	Cost: 5.86s
Train Epoch: 635 [81920/90000 (91%)]	Loss: 9.1039	Cost: 7.63s
Train Epoch: 635 	Average Loss: 9.0394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1680

Learning rate: 0.00019998010230372565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 636 [0/90000 (0%)]	Loss: 10.7991	Cost: 23.13s
Train Epoch: 636 [20480/90000 (23%)]	Loss: 8.8431	Cost: 5.97s
Train Epoch: 636 [40960/90000 (45%)]	Loss: 8.6547	Cost: 6.81s
Train Epoch: 636 [61440/90000 (68%)]	Loss: 8.8458	Cost: 6.23s
Train Epoch: 636 [81920/90000 (91%)]	Loss: 8.8668	Cost: 8.53s
Train Epoch: 636 	Average Loss: 9.0254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1260

Learning rate: 0.00019998003958655633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 637 [0/90000 (0%)]	Loss: 10.8773	Cost: 23.25s
Train Epoch: 637 [20480/90000 (23%)]	Loss: 8.8897	Cost: 6.27s
Train Epoch: 637 [40960/90000 (45%)]	Loss: 8.8204	Cost: 7.33s
Train Epoch: 637 [61440/90000 (68%)]	Loss: 8.8554	Cost: 6.02s
Train Epoch: 637 [81920/90000 (91%)]	Loss: 9.0667	Cost: 6.00s
Train Epoch: 637 	Average Loss: 9.0359
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1766

Learning rate: 0.00019997997677071068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 638 [0/90000 (0%)]	Loss: 10.8525	Cost: 25.28s
Train Epoch: 638 [20480/90000 (23%)]	Loss: 8.6953	Cost: 6.04s
Train Epoch: 638 [40960/90000 (45%)]	Loss: 8.7567	Cost: 7.14s
Train Epoch: 638 [61440/90000 (68%)]	Loss: 8.8230	Cost: 5.78s
Train Epoch: 638 [81920/90000 (91%)]	Loss: 8.8762	Cost: 6.84s
Train Epoch: 638 	Average Loss: 9.0116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1885

Learning rate: 0.00019997991385618872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 639 [0/90000 (0%)]	Loss: 10.5558	Cost: 29.81s
Train Epoch: 639 [20480/90000 (23%)]	Loss: 8.9261	Cost: 5.99s
Train Epoch: 639 [40960/90000 (45%)]	Loss: 8.6819	Cost: 7.52s
Train Epoch: 639 [61440/90000 (68%)]	Loss: 8.9414	Cost: 5.76s
Train Epoch: 639 [81920/90000 (91%)]	Loss: 8.7622	Cost: 5.67s
Train Epoch: 639 	Average Loss: 8.9863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1497

Learning rate: 0.00019997985084299058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 640 [0/90000 (0%)]	Loss: 10.5751	Cost: 28.09s
Train Epoch: 640 [20480/90000 (23%)]	Loss: 8.9175	Cost: 5.97s
Train Epoch: 640 [40960/90000 (45%)]	Loss: 8.7747	Cost: 6.97s
Train Epoch: 640 [61440/90000 (68%)]	Loss: 8.8716	Cost: 6.08s
Train Epoch: 640 [81920/90000 (91%)]	Loss: 8.9441	Cost: 6.63s
Train Epoch: 640 	Average Loss: 9.0052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2550

Learning rate: 0.00019997978773111623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 641 [0/90000 (0%)]	Loss: 10.7572	Cost: 23.78s
Train Epoch: 641 [20480/90000 (23%)]	Loss: 8.7768	Cost: 6.17s
Train Epoch: 641 [40960/90000 (45%)]	Loss: 8.7785	Cost: 6.31s
Train Epoch: 641 [61440/90000 (68%)]	Loss: 8.9946	Cost: 6.00s
Train Epoch: 641 [81920/90000 (91%)]	Loss: 8.9406	Cost: 7.93s
Train Epoch: 641 	Average Loss: 9.0071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2271

Learning rate: 0.00019997972452056583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 642 [0/90000 (0%)]	Loss: 11.0247	Cost: 24.44s
Train Epoch: 642 [20480/90000 (23%)]	Loss: 8.9560	Cost: 6.05s
Train Epoch: 642 [40960/90000 (45%)]	Loss: 8.8877	Cost: 7.02s
Train Epoch: 642 [61440/90000 (68%)]	Loss: 8.7422	Cost: 5.84s
Train Epoch: 642 [81920/90000 (91%)]	Loss: 8.8933	Cost: 6.19s
Train Epoch: 642 	Average Loss: 8.9947
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2381

Learning rate: 0.00019997966121133937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 643 [0/90000 (0%)]	Loss: 10.9259	Cost: 22.38s
Train Epoch: 643 [20480/90000 (23%)]	Loss: 8.7348	Cost: 6.01s
Train Epoch: 643 [40960/90000 (45%)]	Loss: 8.5792	Cost: 8.04s
Train Epoch: 643 [61440/90000 (68%)]	Loss: 8.8482	Cost: 6.00s
Train Epoch: 643 [81920/90000 (91%)]	Loss: 8.7872	Cost: 5.88s
Train Epoch: 643 	Average Loss: 8.9491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2204

Learning rate: 0.00019997959780343694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 644 [0/90000 (0%)]	Loss: 10.7547	Cost: 26.76s
Train Epoch: 644 [20480/90000 (23%)]	Loss: 8.6921	Cost: 6.00s
Train Epoch: 644 [40960/90000 (45%)]	Loss: 8.7762	Cost: 7.27s
Train Epoch: 644 [61440/90000 (68%)]	Loss: 8.8626	Cost: 6.17s
Train Epoch: 644 [81920/90000 (91%)]	Loss: 8.8384	Cost: 5.99s
Train Epoch: 644 	Average Loss: 8.9545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1537

Learning rate: 0.0001999795342968586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 645 [0/90000 (0%)]	Loss: 10.7217	Cost: 26.17s
Train Epoch: 645 [20480/90000 (23%)]	Loss: 8.8305	Cost: 6.04s
Train Epoch: 645 [40960/90000 (45%)]	Loss: 8.6407	Cost: 7.47s
Train Epoch: 645 [61440/90000 (68%)]	Loss: 8.7424	Cost: 6.04s
Train Epoch: 645 [81920/90000 (91%)]	Loss: 8.7575	Cost: 6.50s
Train Epoch: 645 	Average Loss: 8.9326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2681

Learning rate: 0.00019997947069160443
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 646 [0/90000 (0%)]	Loss: 10.7228	Cost: 22.59s
Train Epoch: 646 [20480/90000 (23%)]	Loss: 8.5757	Cost: 5.95s
Train Epoch: 646 [40960/90000 (45%)]	Loss: 8.7776	Cost: 6.52s
Train Epoch: 646 [61440/90000 (68%)]	Loss: 8.8872	Cost: 6.20s
Train Epoch: 646 [81920/90000 (91%)]	Loss: 8.8724	Cost: 7.81s
Train Epoch: 646 	Average Loss: 8.9193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1778

Learning rate: 0.00019997940698767447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 647 [0/90000 (0%)]	Loss: 10.8088	Cost: 24.07s
Train Epoch: 647 [20480/90000 (23%)]	Loss: 8.7068	Cost: 5.98s
Train Epoch: 647 [40960/90000 (45%)]	Loss: 8.5522	Cost: 7.23s
Train Epoch: 647 [61440/90000 (68%)]	Loss: 8.8363	Cost: 6.07s
Train Epoch: 647 [81920/90000 (91%)]	Loss: 8.8394	Cost: 6.12s
Train Epoch: 647 	Average Loss: 8.9352
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1796

Learning rate: 0.0001999793431850688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 648 [0/90000 (0%)]	Loss: 10.7404	Cost: 24.13s
Train Epoch: 648 [20480/90000 (23%)]	Loss: 8.7610	Cost: 6.05s
Train Epoch: 648 [40960/90000 (45%)]	Loss: 8.6503	Cost: 6.94s
Train Epoch: 648 [61440/90000 (68%)]	Loss: 8.9549	Cost: 6.24s
Train Epoch: 648 [81920/90000 (91%)]	Loss: 8.8500	Cost: 5.57s
Train Epoch: 648 	Average Loss: 8.9487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2083

Learning rate: 0.00019997927928378745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 649 [0/90000 (0%)]	Loss: 10.8696	Cost: 29.22s
Train Epoch: 649 [20480/90000 (23%)]	Loss: 8.7726	Cost: 5.95s
Train Epoch: 649 [40960/90000 (45%)]	Loss: 8.7094	Cost: 8.66s
Train Epoch: 649 [61440/90000 (68%)]	Loss: 8.7372	Cost: 5.79s
Train Epoch: 649 [81920/90000 (91%)]	Loss: 8.7164	Cost: 5.95s
Train Epoch: 649 	Average Loss: 8.9158
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2473

Learning rate: 0.0001999792152838305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 650 [0/90000 (0%)]	Loss: 10.6710	Cost: 25.88s
Train Epoch: 650 [20480/90000 (23%)]	Loss: 8.9828	Cost: 6.00s
Train Epoch: 650 [40960/90000 (45%)]	Loss: 8.6822	Cost: 8.22s
Train Epoch: 650 [61440/90000 (68%)]	Loss: 8.8508	Cost: 5.86s
Train Epoch: 650 [81920/90000 (91%)]	Loss: 8.7049	Cost: 7.69s
Train Epoch: 650 	Average Loss: 8.9516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2226

Learning rate: 0.00019997915118519805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 651 [0/90000 (0%)]	Loss: 10.6316	Cost: 22.72s
Train Epoch: 651 [20480/90000 (23%)]	Loss: 8.6575	Cost: 6.61s
Train Epoch: 651 [40960/90000 (45%)]	Loss: 8.6392	Cost: 6.62s
Train Epoch: 651 [61440/90000 (68%)]	Loss: 8.8631	Cost: 6.19s
Train Epoch: 651 [81920/90000 (91%)]	Loss: 8.8024	Cost: 7.00s
Train Epoch: 651 	Average Loss: 8.9236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2901

Learning rate: 0.0001999790869878901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 652 [0/90000 (0%)]	Loss: 10.8015	Cost: 23.75s
Train Epoch: 652 [20480/90000 (23%)]	Loss: 8.8637	Cost: 5.91s
Train Epoch: 652 [40960/90000 (45%)]	Loss: 8.6535	Cost: 7.21s
Train Epoch: 652 [61440/90000 (68%)]	Loss: 8.9693	Cost: 6.05s
Train Epoch: 652 [81920/90000 (91%)]	Loss: 8.8385	Cost: 6.82s
Train Epoch: 652 	Average Loss: 8.9517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2081

Learning rate: 0.00019997902269190676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 653 [0/90000 (0%)]	Loss: 10.6908	Cost: 23.59s
Train Epoch: 653 [20480/90000 (23%)]	Loss: 8.6786	Cost: 6.15s
Train Epoch: 653 [40960/90000 (45%)]	Loss: 8.5004	Cost: 6.34s
Train Epoch: 653 [61440/90000 (68%)]	Loss: 8.7005	Cost: 6.04s
Train Epoch: 653 [81920/90000 (91%)]	Loss: 8.8089	Cost: 6.68s
Train Epoch: 653 	Average Loss: 8.9050
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1887

Learning rate: 0.0001999789582972481
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 654 [0/90000 (0%)]	Loss: 10.7348	Cost: 30.18s
Train Epoch: 654 [20480/90000 (23%)]	Loss: 8.6135	Cost: 5.99s
Train Epoch: 654 [40960/90000 (45%)]	Loss: 8.6283	Cost: 7.59s
Train Epoch: 654 [61440/90000 (68%)]	Loss: 8.6784	Cost: 6.06s
Train Epoch: 654 [81920/90000 (91%)]	Loss: 8.7058	Cost: 6.78s
Train Epoch: 654 	Average Loss: 8.8736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2787

Learning rate: 0.00019997889380391414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 655 [0/90000 (0%)]	Loss: 10.6818	Cost: 27.54s
Train Epoch: 655 [20480/90000 (23%)]	Loss: 8.7313	Cost: 6.10s
Train Epoch: 655 [40960/90000 (45%)]	Loss: 8.6397	Cost: 6.95s
Train Epoch: 655 [61440/90000 (68%)]	Loss: 8.7048	Cost: 6.12s
Train Epoch: 655 [81920/90000 (91%)]	Loss: 8.6633	Cost: 6.82s
Train Epoch: 655 	Average Loss: 8.8928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2549

Learning rate: 0.00019997882921190502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 656 [0/90000 (0%)]	Loss: 11.1192	Cost: 23.46s
Train Epoch: 656 [20480/90000 (23%)]	Loss: 8.7191	Cost: 6.17s
Train Epoch: 656 [40960/90000 (45%)]	Loss: 8.5974	Cost: 6.06s
Train Epoch: 656 [61440/90000 (68%)]	Loss: 8.7147	Cost: 6.03s
Train Epoch: 656 [81920/90000 (91%)]	Loss: 8.7370	Cost: 7.71s
Train Epoch: 656 	Average Loss: 8.8728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2195

Learning rate: 0.00019997876452122068
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 657 [0/90000 (0%)]	Loss: 10.9335	Cost: 24.33s
Train Epoch: 657 [20480/90000 (23%)]	Loss: 8.6311	Cost: 6.10s
Train Epoch: 657 [40960/90000 (45%)]	Loss: 8.8386	Cost: 6.33s
Train Epoch: 657 [61440/90000 (68%)]	Loss: 8.6976	Cost: 6.00s
Train Epoch: 657 [81920/90000 (91%)]	Loss: 8.7454	Cost: 5.76s
Train Epoch: 657 	Average Loss: 8.8750
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1419

Learning rate: 0.00019997869973186128
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 658 [0/90000 (0%)]	Loss: 10.8805	Cost: 25.15s
Train Epoch: 658 [20480/90000 (23%)]	Loss: 8.7243	Cost: 6.34s
Train Epoch: 658 [40960/90000 (45%)]	Loss: 8.6028	Cost: 6.76s
Train Epoch: 658 [61440/90000 (68%)]	Loss: 8.6969	Cost: 6.39s
Train Epoch: 658 [81920/90000 (91%)]	Loss: 8.8865	Cost: 6.26s
Train Epoch: 658 	Average Loss: 8.8862
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3158

Learning rate: 0.00019997863484382683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 659 [0/90000 (0%)]	Loss: 10.9245	Cost: 29.73s
Train Epoch: 659 [20480/90000 (23%)]	Loss: 8.7396	Cost: 6.00s
Train Epoch: 659 [40960/90000 (45%)]	Loss: 8.5524	Cost: 7.26s
Train Epoch: 659 [61440/90000 (68%)]	Loss: 8.6735	Cost: 6.06s
Train Epoch: 659 [81920/90000 (91%)]	Loss: 8.9191	Cost: 6.90s
Train Epoch: 659 	Average Loss: 8.8770
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1799

Learning rate: 0.00019997856985711746
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 660 [0/90000 (0%)]	Loss: 10.8382	Cost: 26.18s
Train Epoch: 660 [20480/90000 (23%)]	Loss: 8.6671	Cost: 6.24s
Train Epoch: 660 [40960/90000 (45%)]	Loss: 8.6868	Cost: 7.48s
Train Epoch: 660 [61440/90000 (68%)]	Loss: 8.4880	Cost: 6.16s
Train Epoch: 660 [81920/90000 (91%)]	Loss: 8.7060	Cost: 6.88s
Train Epoch: 660 	Average Loss: 8.8462
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2151

Learning rate: 0.0001999785047717332
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 661 [0/90000 (0%)]	Loss: 10.5501	Cost: 24.13s
Train Epoch: 661 [20480/90000 (23%)]	Loss: 8.5875	Cost: 5.90s
Train Epoch: 661 [40960/90000 (45%)]	Loss: 8.4790	Cost: 6.21s
Train Epoch: 661 [61440/90000 (68%)]	Loss: 8.6672	Cost: 6.10s
Train Epoch: 661 [81920/90000 (91%)]	Loss: 8.6529	Cost: 7.98s
Train Epoch: 661 	Average Loss: 8.8352
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2376

Learning rate: 0.0001999784395876741
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 662 [0/90000 (0%)]	Loss: 10.8594	Cost: 23.99s
Train Epoch: 662 [20480/90000 (23%)]	Loss: 8.6562	Cost: 5.97s
Train Epoch: 662 [40960/90000 (45%)]	Loss: 8.4872	Cost: 6.08s
Train Epoch: 662 [61440/90000 (68%)]	Loss: 8.9112	Cost: 5.93s
Train Epoch: 662 [81920/90000 (91%)]	Loss: 8.8010	Cost: 5.53s
Train Epoch: 662 	Average Loss: 8.8715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2717

Learning rate: 0.00019997837430494025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 663 [0/90000 (0%)]	Loss: 11.0209	Cost: 25.88s
Train Epoch: 663 [20480/90000 (23%)]	Loss: 8.6581	Cost: 6.06s
Train Epoch: 663 [40960/90000 (45%)]	Loss: 8.5509	Cost: 6.33s
Train Epoch: 663 [61440/90000 (68%)]	Loss: 8.5640	Cost: 6.08s
Train Epoch: 663 [81920/90000 (91%)]	Loss: 8.5352	Cost: 6.01s
Train Epoch: 663 	Average Loss: 8.8340
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1266

Learning rate: 0.00019997830892353166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 664 [0/90000 (0%)]	Loss: 10.9117	Cost: 27.01s
Train Epoch: 664 [20480/90000 (23%)]	Loss: 8.6418	Cost: 5.96s
Train Epoch: 664 [40960/90000 (45%)]	Loss: 8.6489	Cost: 8.25s
Train Epoch: 664 [61440/90000 (68%)]	Loss: 8.6398	Cost: 6.39s
Train Epoch: 664 [81920/90000 (91%)]	Loss: 8.6209	Cost: 6.25s
Train Epoch: 664 	Average Loss: 8.8219
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2805

Learning rate: 0.0001999782434434485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 665 [0/90000 (0%)]	Loss: 10.6675	Cost: 24.78s
Train Epoch: 665 [20480/90000 (23%)]	Loss: 8.5176	Cost: 6.02s
Train Epoch: 665 [40960/90000 (45%)]	Loss: 8.5582	Cost: 7.60s
Train Epoch: 665 [61440/90000 (68%)]	Loss: 8.6158	Cost: 5.86s
Train Epoch: 665 [81920/90000 (91%)]	Loss: 8.6599	Cost: 7.66s
Train Epoch: 665 	Average Loss: 8.8247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2417

Learning rate: 0.0001999781778646907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 666 [0/90000 (0%)]	Loss: 10.8140	Cost: 22.74s
Train Epoch: 666 [20480/90000 (23%)]	Loss: 8.5959	Cost: 5.94s
Train Epoch: 666 [40960/90000 (45%)]	Loss: 8.6286	Cost: 6.52s
Train Epoch: 666 [61440/90000 (68%)]	Loss: 8.7359	Cost: 6.05s
Train Epoch: 666 [81920/90000 (91%)]	Loss: 8.6070	Cost: 9.15s
Train Epoch: 666 	Average Loss: 8.8236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2257

Learning rate: 0.00019997811218725844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 667 [0/90000 (0%)]	Loss: 10.8554	Cost: 24.14s
Train Epoch: 667 [20480/90000 (23%)]	Loss: 8.6523	Cost: 6.02s
Train Epoch: 667 [40960/90000 (45%)]	Loss: 8.5542	Cost: 7.36s
Train Epoch: 667 [61440/90000 (68%)]	Loss: 8.8084	Cost: 6.43s
Train Epoch: 667 [81920/90000 (91%)]	Loss: 8.8892	Cost: 5.78s
Train Epoch: 667 	Average Loss: 8.8376
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2483

Learning rate: 0.0001999780464111517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 668 [0/90000 (0%)]	Loss: 10.9359	Cost: 22.95s
Train Epoch: 668 [20480/90000 (23%)]	Loss: 8.5947	Cost: 5.99s
Train Epoch: 668 [40960/90000 (45%)]	Loss: 8.5663	Cost: 7.23s
Train Epoch: 668 [61440/90000 (68%)]	Loss: 8.6375	Cost: 6.13s
Train Epoch: 668 [81920/90000 (91%)]	Loss: 8.6363	Cost: 6.02s
Train Epoch: 668 	Average Loss: 8.8037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2728

Learning rate: 0.00019997798053637063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 669 [0/90000 (0%)]	Loss: 11.0124	Cost: 28.91s
Train Epoch: 669 [20480/90000 (23%)]	Loss: 8.6702	Cost: 6.22s
Train Epoch: 669 [40960/90000 (45%)]	Loss: 8.5398	Cost: 7.71s
Train Epoch: 669 [61440/90000 (68%)]	Loss: 8.6919	Cost: 5.94s
Train Epoch: 669 [81920/90000 (91%)]	Loss: 8.7494	Cost: 7.23s
Train Epoch: 669 	Average Loss: 8.8187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3047

Learning rate: 0.00019997791456291523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 670 [0/90000 (0%)]	Loss: 10.7755	Cost: 25.96s
Train Epoch: 670 [20480/90000 (23%)]	Loss: 8.6941	Cost: 6.02s
Train Epoch: 670 [40960/90000 (45%)]	Loss: 8.5106	Cost: 7.58s
Train Epoch: 670 [61440/90000 (68%)]	Loss: 8.6547	Cost: 6.21s
Train Epoch: 670 [81920/90000 (91%)]	Loss: 8.7019	Cost: 6.73s
Train Epoch: 670 	Average Loss: 8.7580
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2547

Learning rate: 0.00019997784849078558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 671 [0/90000 (0%)]	Loss: 11.0064	Cost: 23.51s
Train Epoch: 671 [20480/90000 (23%)]	Loss: 8.4787	Cost: 6.01s
Train Epoch: 671 [40960/90000 (45%)]	Loss: 8.5428	Cost: 6.50s
Train Epoch: 671 [61440/90000 (68%)]	Loss: 8.4729	Cost: 6.30s
Train Epoch: 671 [81920/90000 (91%)]	Loss: 8.7038	Cost: 5.89s
Train Epoch: 671 	Average Loss: 8.7760
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2484

Learning rate: 0.00019997778231998174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 672 [0/90000 (0%)]	Loss: 10.7478	Cost: 23.67s
Train Epoch: 672 [20480/90000 (23%)]	Loss: 8.6506	Cost: 5.89s
Train Epoch: 672 [40960/90000 (45%)]	Loss: 8.5981	Cost: 7.41s
Train Epoch: 672 [61440/90000 (68%)]	Loss: 8.5101	Cost: 5.85s
Train Epoch: 672 [81920/90000 (91%)]	Loss: 8.6707	Cost: 5.96s
Train Epoch: 672 	Average Loss: 8.7666
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2161

Learning rate: 0.0001999777160505038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 673 [0/90000 (0%)]	Loss: 10.7783	Cost: 25.07s
Train Epoch: 673 [20480/90000 (23%)]	Loss: 8.6567	Cost: 6.39s
Train Epoch: 673 [40960/90000 (45%)]	Loss: 8.4211	Cost: 6.45s
Train Epoch: 673 [61440/90000 (68%)]	Loss: 8.4984	Cost: 6.52s
Train Epoch: 673 [81920/90000 (91%)]	Loss: 8.6289	Cost: 6.19s
Train Epoch: 673 	Average Loss: 8.7502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2844

Learning rate: 0.0001999776496823518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 674 [0/90000 (0%)]	Loss: 10.8616	Cost: 30.07s
Train Epoch: 674 [20480/90000 (23%)]	Loss: 8.5776	Cost: 6.00s
Train Epoch: 674 [40960/90000 (45%)]	Loss: 8.5570	Cost: 8.28s
Train Epoch: 674 [61440/90000 (68%)]	Loss: 8.4883	Cost: 5.81s
Train Epoch: 674 [81920/90000 (91%)]	Loss: 8.7616	Cost: 7.11s
Train Epoch: 674 	Average Loss: 8.7670
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3038

Learning rate: 0.00019997758321552579
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 675 [0/90000 (0%)]	Loss: 11.0580	Cost: 24.89s
Train Epoch: 675 [20480/90000 (23%)]	Loss: 8.5238	Cost: 5.97s
Train Epoch: 675 [40960/90000 (45%)]	Loss: 8.4661	Cost: 7.41s
Train Epoch: 675 [61440/90000 (68%)]	Loss: 8.4948	Cost: 5.83s
Train Epoch: 675 [81920/90000 (91%)]	Loss: 8.3906	Cost: 6.97s
Train Epoch: 675 	Average Loss: 8.7429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2982

Learning rate: 0.00019997751665002588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 676 [0/90000 (0%)]	Loss: 10.9936	Cost: 23.50s
Train Epoch: 676 [20480/90000 (23%)]	Loss: 8.6344	Cost: 6.17s
Train Epoch: 676 [40960/90000 (45%)]	Loss: 8.6816	Cost: 6.26s
Train Epoch: 676 [61440/90000 (68%)]	Loss: 8.6960	Cost: 6.21s
Train Epoch: 676 [81920/90000 (91%)]	Loss: 8.5052	Cost: 7.20s
Train Epoch: 676 	Average Loss: 8.7394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2300

Learning rate: 0.00019997744998585216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 677 [0/90000 (0%)]	Loss: 10.6766	Cost: 23.17s
Train Epoch: 677 [20480/90000 (23%)]	Loss: 8.4815	Cost: 6.15s
Train Epoch: 677 [40960/90000 (45%)]	Loss: 8.4900	Cost: 6.71s
Train Epoch: 677 [61440/90000 (68%)]	Loss: 8.5026	Cost: 5.92s
Train Epoch: 677 [81920/90000 (91%)]	Loss: 8.5642	Cost: 6.33s
Train Epoch: 677 	Average Loss: 8.6999
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2617

Learning rate: 0.0001999773832230046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 678 [0/90000 (0%)]	Loss: 11.0485	Cost: 24.05s
Train Epoch: 678 [20480/90000 (23%)]	Loss: 8.5846	Cost: 6.17s
Train Epoch: 678 [40960/90000 (45%)]	Loss: 8.5697	Cost: 6.41s
Train Epoch: 678 [61440/90000 (68%)]	Loss: 8.3975	Cost: 6.14s
Train Epoch: 678 [81920/90000 (91%)]	Loss: 8.6873	Cost: 6.07s
Train Epoch: 678 	Average Loss: 8.7339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2733

Learning rate: 0.00019997731636148334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 679 [0/90000 (0%)]	Loss: 11.1118	Cost: 28.60s
Train Epoch: 679 [20480/90000 (23%)]	Loss: 8.6422	Cost: 6.07s
Train Epoch: 679 [40960/90000 (45%)]	Loss: 8.4164	Cost: 6.81s
Train Epoch: 679 [61440/90000 (68%)]	Loss: 8.7039	Cost: 6.11s
Train Epoch: 679 [81920/90000 (91%)]	Loss: 8.5206	Cost: 5.74s
Train Epoch: 679 	Average Loss: 8.7209
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2896

Learning rate: 0.00019997724940128839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 680 [0/90000 (0%)]	Loss: 10.7093	Cost: 24.79s
Train Epoch: 680 [20480/90000 (23%)]	Loss: 8.4912	Cost: 6.00s
Train Epoch: 680 [40960/90000 (45%)]	Loss: 8.4629	Cost: 8.01s
Train Epoch: 680 [61440/90000 (68%)]	Loss: 8.5875	Cost: 5.87s
Train Epoch: 680 [81920/90000 (91%)]	Loss: 8.5119	Cost: 7.71s
Train Epoch: 680 	Average Loss: 8.7124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2781

Learning rate: 0.0001999771823424199
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 681 [0/90000 (0%)]	Loss: 10.8750	Cost: 22.97s
Train Epoch: 681 [20480/90000 (23%)]	Loss: 8.4967	Cost: 6.00s
Train Epoch: 681 [40960/90000 (45%)]	Loss: 8.3342	Cost: 6.80s
Train Epoch: 681 [61440/90000 (68%)]	Loss: 8.5857	Cost: 6.31s
Train Epoch: 681 [81920/90000 (91%)]	Loss: 8.7302	Cost: 6.32s
Train Epoch: 681 	Average Loss: 8.7328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3352

Learning rate: 0.00019997711518487783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 682 [0/90000 (0%)]	Loss: 10.7006	Cost: 25.17s
Train Epoch: 682 [20480/90000 (23%)]	Loss: 8.5206	Cost: 6.04s
Train Epoch: 682 [40960/90000 (45%)]	Loss: 8.6349	Cost: 7.45s
Train Epoch: 682 [61440/90000 (68%)]	Loss: 8.4608	Cost: 6.38s
Train Epoch: 682 [81920/90000 (91%)]	Loss: 8.4711	Cost: 6.22s
Train Epoch: 682 	Average Loss: 8.6968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2273

Learning rate: 0.00019997704792866234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 683 [0/90000 (0%)]	Loss: 10.7695	Cost: 23.97s
Train Epoch: 683 [20480/90000 (23%)]	Loss: 8.5195	Cost: 6.15s
Train Epoch: 683 [40960/90000 (45%)]	Loss: 8.5312	Cost: 6.42s
Train Epoch: 683 [61440/90000 (68%)]	Loss: 8.5896	Cost: 6.22s
Train Epoch: 683 [81920/90000 (91%)]	Loss: 8.6569	Cost: 6.27s
Train Epoch: 683 	Average Loss: 8.7183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2197

Learning rate: 0.00019997698057377345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 684 [0/90000 (0%)]	Loss: 10.9704	Cost: 26.65s
Train Epoch: 684 [20480/90000 (23%)]	Loss: 8.4086	Cost: 6.09s
Train Epoch: 684 [40960/90000 (45%)]	Loss: 8.3761	Cost: 6.92s
Train Epoch: 684 [61440/90000 (68%)]	Loss: 8.5328	Cost: 6.43s
Train Epoch: 684 [81920/90000 (91%)]	Loss: 8.5570	Cost: 7.50s
Train Epoch: 684 	Average Loss: 8.7024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2389

Learning rate: 0.0001999769131202112
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 685 [0/90000 (0%)]	Loss: 10.7793	Cost: 26.37s
Train Epoch: 685 [20480/90000 (23%)]	Loss: 8.6492	Cost: 6.03s
Train Epoch: 685 [40960/90000 (45%)]	Loss: 8.5592	Cost: 8.18s
Train Epoch: 685 [61440/90000 (68%)]	Loss: 8.3752	Cost: 5.97s
Train Epoch: 685 [81920/90000 (91%)]	Loss: 8.4716	Cost: 8.63s
Train Epoch: 685 	Average Loss: 8.7337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2432

Learning rate: 0.00019997684556797576
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 686 [0/90000 (0%)]	Loss: 11.1551	Cost: 22.35s
Train Epoch: 686 [20480/90000 (23%)]	Loss: 8.4056	Cost: 6.13s
Train Epoch: 686 [40960/90000 (45%)]	Loss: 8.3859	Cost: 6.32s
Train Epoch: 686 [61440/90000 (68%)]	Loss: 8.4645	Cost: 6.03s
Train Epoch: 686 [81920/90000 (91%)]	Loss: 8.5526	Cost: 8.82s
Train Epoch: 686 	Average Loss: 8.6833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2786

Learning rate: 0.0001999767779170671
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 687 [0/90000 (0%)]	Loss: 10.7101	Cost: 23.73s
Train Epoch: 687 [20480/90000 (23%)]	Loss: 8.5447	Cost: 5.88s
Train Epoch: 687 [40960/90000 (45%)]	Loss: 8.3591	Cost: 7.35s
Train Epoch: 687 [61440/90000 (68%)]	Loss: 8.4745	Cost: 5.95s
Train Epoch: 687 [81920/90000 (91%)]	Loss: 8.5281	Cost: 5.73s
Train Epoch: 687 	Average Loss: 8.6447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2590

Learning rate: 0.00019997671016748527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 688 [0/90000 (0%)]	Loss: 10.7291	Cost: 23.78s
Train Epoch: 688 [20480/90000 (23%)]	Loss: 8.3885	Cost: 6.02s
Train Epoch: 688 [40960/90000 (45%)]	Loss: 8.4431	Cost: 7.39s
Train Epoch: 688 [61440/90000 (68%)]	Loss: 8.5094	Cost: 5.77s
Train Epoch: 688 [81920/90000 (91%)]	Loss: 8.5545	Cost: 6.72s
Train Epoch: 688 	Average Loss: 8.6779
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2696

Learning rate: 0.00019997664231923042
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 689 [0/90000 (0%)]	Loss: 10.8371	Cost: 26.82s
Train Epoch: 689 [20480/90000 (23%)]	Loss: 8.5370	Cost: 5.98s
Train Epoch: 689 [40960/90000 (45%)]	Loss: 8.3438	Cost: 7.20s
Train Epoch: 689 [61440/90000 (68%)]	Loss: 8.5340	Cost: 5.84s
Train Epoch: 689 [81920/90000 (91%)]	Loss: 8.6345	Cost: 6.01s
Train Epoch: 689 	Average Loss: 8.6641
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2626

Learning rate: 0.00019997657437230258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 690 [0/90000 (0%)]	Loss: 10.7614	Cost: 25.26s
Train Epoch: 690 [20480/90000 (23%)]	Loss: 8.3926	Cost: 6.02s
Train Epoch: 690 [40960/90000 (45%)]	Loss: 8.5373	Cost: 7.70s
Train Epoch: 690 [61440/90000 (68%)]	Loss: 8.5609	Cost: 5.87s
Train Epoch: 690 [81920/90000 (91%)]	Loss: 8.4789	Cost: 7.50s
Train Epoch: 690 	Average Loss: 8.6554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4753

Learning rate: 0.00019997650632670182
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 691 [0/90000 (0%)]	Loss: 10.7219	Cost: 23.20s
Train Epoch: 691 [20480/90000 (23%)]	Loss: 8.4773	Cost: 5.95s
Train Epoch: 691 [40960/90000 (45%)]	Loss: 8.5472	Cost: 6.87s
Train Epoch: 691 [61440/90000 (68%)]	Loss: 8.4030	Cost: 6.14s
Train Epoch: 691 [81920/90000 (91%)]	Loss: 8.4630	Cost: 7.04s
Train Epoch: 691 	Average Loss: 8.6424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3454

Learning rate: 0.0001999764381824282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 692 [0/90000 (0%)]	Loss: 10.8361	Cost: 24.66s
Train Epoch: 692 [20480/90000 (23%)]	Loss: 8.4213	Cost: 6.11s
Train Epoch: 692 [40960/90000 (45%)]	Loss: 8.4657	Cost: 6.10s
Train Epoch: 692 [61440/90000 (68%)]	Loss: 8.5041	Cost: 5.98s
Train Epoch: 692 [81920/90000 (91%)]	Loss: 8.4658	Cost: 5.56s
Train Epoch: 692 	Average Loss: 8.6485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3088

Learning rate: 0.0001999763699394818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 693 [0/90000 (0%)]	Loss: 10.6853	Cost: 23.64s
Train Epoch: 693 [20480/90000 (23%)]	Loss: 8.4119	Cost: 6.09s
Train Epoch: 693 [40960/90000 (45%)]	Loss: 8.4939	Cost: 6.58s
Train Epoch: 693 [61440/90000 (68%)]	Loss: 8.4339	Cost: 6.07s
Train Epoch: 693 [81920/90000 (91%)]	Loss: 8.4156	Cost: 5.75s
Train Epoch: 693 	Average Loss: 8.6280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3522

Learning rate: 0.0001999763015978627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 694 [0/90000 (0%)]	Loss: 10.8581	Cost: 26.29s
Train Epoch: 694 [20480/90000 (23%)]	Loss: 8.4831	Cost: 6.12s
Train Epoch: 694 [40960/90000 (45%)]	Loss: 8.3342	Cost: 6.69s
Train Epoch: 694 [61440/90000 (68%)]	Loss: 8.3733	Cost: 5.96s
Train Epoch: 694 [81920/90000 (91%)]	Loss: 8.2742	Cost: 5.57s
Train Epoch: 694 	Average Loss: 8.5953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3847

Learning rate: 0.0001999762331575709
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 695 [0/90000 (0%)]	Loss: 10.9986	Cost: 23.05s
Train Epoch: 695 [20480/90000 (23%)]	Loss: 8.6061	Cost: 6.05s
Train Epoch: 695 [40960/90000 (45%)]	Loss: 8.3959	Cost: 8.02s
Train Epoch: 695 [61440/90000 (68%)]	Loss: 8.3395	Cost: 5.93s
Train Epoch: 695 [81920/90000 (91%)]	Loss: 8.2607	Cost: 8.48s
Train Epoch: 695 	Average Loss: 8.6299
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3099

Learning rate: 0.00019997616461860652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 696 [0/90000 (0%)]	Loss: 11.0558	Cost: 23.62s
Train Epoch: 696 [20480/90000 (23%)]	Loss: 8.3793	Cost: 5.96s
Train Epoch: 696 [40960/90000 (45%)]	Loss: 8.3952	Cost: 6.86s
Train Epoch: 696 [61440/90000 (68%)]	Loss: 8.3587	Cost: 5.85s
Train Epoch: 696 [81920/90000 (91%)]	Loss: 8.2907	Cost: 6.72s
Train Epoch: 696 	Average Loss: 8.5916
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3230

Learning rate: 0.00019997609598096963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 697 [0/90000 (0%)]	Loss: 11.0452	Cost: 23.49s
Train Epoch: 697 [20480/90000 (23%)]	Loss: 8.5293	Cost: 6.20s
Train Epoch: 697 [40960/90000 (45%)]	Loss: 8.3507	Cost: 7.33s
Train Epoch: 697 [61440/90000 (68%)]	Loss: 8.2793	Cost: 5.98s
Train Epoch: 697 [81920/90000 (91%)]	Loss: 8.2834	Cost: 6.32s
Train Epoch: 697 	Average Loss: 8.6006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3754

Learning rate: 0.0001999760272446603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 698 [0/90000 (0%)]	Loss: 10.9969	Cost: 24.31s
Train Epoch: 698 [20480/90000 (23%)]	Loss: 8.2969	Cost: 6.07s
Train Epoch: 698 [40960/90000 (45%)]	Loss: 8.1699	Cost: 6.45s
Train Epoch: 698 [61440/90000 (68%)]	Loss: 8.4226	Cost: 6.13s
Train Epoch: 698 [81920/90000 (91%)]	Loss: 8.3235	Cost: 5.92s
Train Epoch: 698 	Average Loss: 8.5800
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3677

Learning rate: 0.00019997595840967857
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 699 [0/90000 (0%)]	Loss: 11.2598	Cost: 28.63s
Train Epoch: 699 [20480/90000 (23%)]	Loss: 8.3756	Cost: 6.10s
Train Epoch: 699 [40960/90000 (45%)]	Loss: 8.4840	Cost: 8.62s
Train Epoch: 699 [61440/90000 (68%)]	Loss: 8.5192	Cost: 5.91s
Train Epoch: 699 [81920/90000 (91%)]	Loss: 8.3472	Cost: 6.21s
Train Epoch: 699 	Average Loss: 8.6033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2979

Learning rate: 0.00019997588947602451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 700 [0/90000 (0%)]	Loss: 11.0804	Cost: 23.70s
Train Epoch: 700 [20480/90000 (23%)]	Loss: 8.3121	Cost: 6.04s
Train Epoch: 700 [40960/90000 (45%)]	Loss: 8.3241	Cost: 7.94s
Train Epoch: 700 [61440/90000 (68%)]	Loss: 8.4250	Cost: 6.09s
Train Epoch: 700 [81920/90000 (91%)]	Loss: 8.3863	Cost: 8.19s
Train Epoch: 700 	Average Loss: 8.6258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3752

Learning rate: 0.00019997582044369825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 701 [0/90000 (0%)]	Loss: 10.7754	Cost: 23.39s
Train Epoch: 701 [20480/90000 (23%)]	Loss: 8.5125	Cost: 5.87s
Train Epoch: 701 [40960/90000 (45%)]	Loss: 8.3403	Cost: 6.93s
Train Epoch: 701 [61440/90000 (68%)]	Loss: 8.4641	Cost: 6.00s
Train Epoch: 701 [81920/90000 (91%)]	Loss: 8.4012	Cost: 5.90s
Train Epoch: 701 	Average Loss: 8.6024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4246

Learning rate: 0.00019997575131269977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 702 [0/90000 (0%)]	Loss: 11.0007	Cost: 23.83s
Train Epoch: 702 [20480/90000 (23%)]	Loss: 8.3043	Cost: 5.97s
Train Epoch: 702 [40960/90000 (45%)]	Loss: 8.2302	Cost: 6.61s
Train Epoch: 702 [61440/90000 (68%)]	Loss: 8.4252	Cost: 5.77s
Train Epoch: 702 [81920/90000 (91%)]	Loss: 8.4419	Cost: 6.36s
Train Epoch: 702 	Average Loss: 8.5743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3619

Learning rate: 0.00019997568208302919
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 703 [0/90000 (0%)]	Loss: 10.8190	Cost: 24.36s
Train Epoch: 703 [20480/90000 (23%)]	Loss: 8.2341	Cost: 5.98s
Train Epoch: 703 [40960/90000 (45%)]	Loss: 8.1798	Cost: 6.67s
Train Epoch: 703 [61440/90000 (68%)]	Loss: 8.3551	Cost: 6.09s
Train Epoch: 703 [81920/90000 (91%)]	Loss: 8.2986	Cost: 6.29s
Train Epoch: 703 	Average Loss: 8.5178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3937

Learning rate: 0.00019997561275468656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 704 [0/90000 (0%)]	Loss: 10.9567	Cost: 28.21s
Train Epoch: 704 [20480/90000 (23%)]	Loss: 8.1973	Cost: 6.14s
Train Epoch: 704 [40960/90000 (45%)]	Loss: 8.1032	Cost: 6.56s
Train Epoch: 704 [61440/90000 (68%)]	Loss: 8.4240	Cost: 6.12s
Train Epoch: 704 [81920/90000 (91%)]	Loss: 8.3768	Cost: 5.83s
Train Epoch: 704 	Average Loss: 8.5239
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3681

Learning rate: 0.00019997554332767197
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 705 [0/90000 (0%)]	Loss: 10.9485	Cost: 25.11s
Train Epoch: 705 [20480/90000 (23%)]	Loss: 8.2834	Cost: 6.02s
Train Epoch: 705 [40960/90000 (45%)]	Loss: 8.2558	Cost: 7.58s
Train Epoch: 705 [61440/90000 (68%)]	Loss: 8.3702	Cost: 5.90s
Train Epoch: 705 [81920/90000 (91%)]	Loss: 8.3303	Cost: 7.24s
Train Epoch: 705 	Average Loss: 8.5269
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3687

Learning rate: 0.0001999754738019855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 706 [0/90000 (0%)]	Loss: 11.2999	Cost: 23.18s
Train Epoch: 706 [20480/90000 (23%)]	Loss: 8.3120	Cost: 5.93s
Train Epoch: 706 [40960/90000 (45%)]	Loss: 8.3218	Cost: 6.40s
Train Epoch: 706 [61440/90000 (68%)]	Loss: 8.2834	Cost: 5.82s
Train Epoch: 706 [81920/90000 (91%)]	Loss: 8.3349	Cost: 5.96s
Train Epoch: 706 	Average Loss: 8.5538
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3820

Learning rate: 0.00019997540417762715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 707 [0/90000 (0%)]	Loss: 10.8979	Cost: 23.96s
Train Epoch: 707 [20480/90000 (23%)]	Loss: 8.1136	Cost: 6.26s
Train Epoch: 707 [40960/90000 (45%)]	Loss: 8.4014	Cost: 6.19s
Train Epoch: 707 [61440/90000 (68%)]	Loss: 8.2158	Cost: 5.95s
Train Epoch: 707 [81920/90000 (91%)]	Loss: 8.4615	Cost: 6.11s
Train Epoch: 707 	Average Loss: 8.5386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3697

Learning rate: 0.00019997533445459704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 708 [0/90000 (0%)]	Loss: 10.9260	Cost: 25.33s
Train Epoch: 708 [20480/90000 (23%)]	Loss: 8.4049	Cost: 6.21s
Train Epoch: 708 [40960/90000 (45%)]	Loss: 8.2587	Cost: 6.50s
Train Epoch: 708 [61440/90000 (68%)]	Loss: 8.4800	Cost: 6.10s
Train Epoch: 708 [81920/90000 (91%)]	Loss: 8.2739	Cost: 6.03s
Train Epoch: 708 	Average Loss: 8.6467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3874

Learning rate: 0.00019997526463289524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 709 [0/90000 (0%)]	Loss: 10.8395	Cost: 28.74s
Train Epoch: 709 [20480/90000 (23%)]	Loss: 8.2862	Cost: 5.98s
Train Epoch: 709 [40960/90000 (45%)]	Loss: 8.3346	Cost: 7.26s
Train Epoch: 709 [61440/90000 (68%)]	Loss: 8.2638	Cost: 5.85s
Train Epoch: 709 [81920/90000 (91%)]	Loss: 8.4526	Cost: 6.08s
Train Epoch: 709 	Average Loss: 8.5749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4442

Learning rate: 0.0001999751947125218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 710 [0/90000 (0%)]	Loss: 10.8018	Cost: 25.86s
Train Epoch: 710 [20480/90000 (23%)]	Loss: 8.3543	Cost: 6.06s
Train Epoch: 710 [40960/90000 (45%)]	Loss: 8.1196	Cost: 7.70s
Train Epoch: 710 [61440/90000 (68%)]	Loss: 8.2402	Cost: 6.02s
Train Epoch: 710 [81920/90000 (91%)]	Loss: 8.2510	Cost: 6.73s
Train Epoch: 710 	Average Loss: 8.4988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4142

Learning rate: 0.00019997512469347679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 711 [0/90000 (0%)]	Loss: 11.0196	Cost: 23.12s
Train Epoch: 711 [20480/90000 (23%)]	Loss: 8.3459	Cost: 6.09s
Train Epoch: 711 [40960/90000 (45%)]	Loss: 8.1649	Cost: 6.29s
Train Epoch: 711 [61440/90000 (68%)]	Loss: 8.3749	Cost: 6.19s
Train Epoch: 711 [81920/90000 (91%)]	Loss: 8.4440	Cost: 8.59s
Train Epoch: 711 	Average Loss: 8.5075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4338

Learning rate: 0.00019997505457576027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 712 [0/90000 (0%)]	Loss: 11.0287	Cost: 25.56s
Train Epoch: 712 [20480/90000 (23%)]	Loss: 8.2461	Cost: 6.01s
Train Epoch: 712 [40960/90000 (45%)]	Loss: 8.0645	Cost: 7.77s
Train Epoch: 712 [61440/90000 (68%)]	Loss: 8.3092	Cost: 5.88s
Train Epoch: 712 [81920/90000 (91%)]	Loss: 8.3450	Cost: 6.02s
Train Epoch: 712 	Average Loss: 8.4725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4044

Learning rate: 0.00019997498435937237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 713 [0/90000 (0%)]	Loss: 11.0773	Cost: 23.09s
Train Epoch: 713 [20480/90000 (23%)]	Loss: 8.1106	Cost: 6.00s
Train Epoch: 713 [40960/90000 (45%)]	Loss: 8.2685	Cost: 6.95s
Train Epoch: 713 [61440/90000 (68%)]	Loss: 8.1576	Cost: 5.93s
Train Epoch: 713 [81920/90000 (91%)]	Loss: 8.3278	Cost: 6.02s
Train Epoch: 713 	Average Loss: 8.4604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4327

Learning rate: 0.00019997491404431306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 714 [0/90000 (0%)]	Loss: 10.9085	Cost: 29.52s
Train Epoch: 714 [20480/90000 (23%)]	Loss: 8.1704	Cost: 6.14s
Train Epoch: 714 [40960/90000 (45%)]	Loss: 8.1781	Cost: 7.01s
Train Epoch: 714 [61440/90000 (68%)]	Loss: 8.1730	Cost: 6.00s
Train Epoch: 714 [81920/90000 (91%)]	Loss: 8.5323	Cost: 6.17s
Train Epoch: 714 	Average Loss: 8.4501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3332

Learning rate: 0.00019997484363058253
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 715 [0/90000 (0%)]	Loss: 11.1440	Cost: 25.28s
Train Epoch: 715 [20480/90000 (23%)]	Loss: 8.2128	Cost: 6.08s
Train Epoch: 715 [40960/90000 (45%)]	Loss: 8.1753	Cost: 9.08s
Train Epoch: 715 [61440/90000 (68%)]	Loss: 8.1065	Cost: 5.98s
Train Epoch: 715 [81920/90000 (91%)]	Loss: 8.2830	Cost: 8.99s
Train Epoch: 715 	Average Loss: 8.4534
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4695

Learning rate: 0.00019997477311818073
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 716 [0/90000 (0%)]	Loss: 11.1087	Cost: 23.41s
Train Epoch: 716 [20480/90000 (23%)]	Loss: 8.3466	Cost: 5.99s
Train Epoch: 716 [40960/90000 (45%)]	Loss: 8.2903	Cost: 6.32s
Train Epoch: 716 [61440/90000 (68%)]	Loss: 8.2583	Cost: 6.06s
Train Epoch: 716 [81920/90000 (91%)]	Loss: 8.2170	Cost: 8.54s
Train Epoch: 716 	Average Loss: 8.4710
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4038

Learning rate: 0.0001999747025071078
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 717 [0/90000 (0%)]	Loss: 11.0832	Cost: 24.09s
Train Epoch: 717 [20480/90000 (23%)]	Loss: 8.1333	Cost: 6.14s
Train Epoch: 717 [40960/90000 (45%)]	Loss: 8.1197	Cost: 7.48s
Train Epoch: 717 [61440/90000 (68%)]	Loss: 8.2412	Cost: 5.92s
Train Epoch: 717 [81920/90000 (91%)]	Loss: 8.1921	Cost: 5.80s
Train Epoch: 717 	Average Loss: 8.4359
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4157

Learning rate: 0.0001999746317973638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 718 [0/90000 (0%)]	Loss: 10.8526	Cost: 24.98s
Train Epoch: 718 [20480/90000 (23%)]	Loss: 8.3700	Cost: 6.00s
Train Epoch: 718 [40960/90000 (45%)]	Loss: 8.1987	Cost: 6.28s
Train Epoch: 718 [61440/90000 (68%)]	Loss: 8.2671	Cost: 6.06s
Train Epoch: 718 [81920/90000 (91%)]	Loss: 8.4516	Cost: 5.74s
Train Epoch: 718 	Average Loss: 8.5722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4033

Learning rate: 0.00019997456098894882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 719 [0/90000 (0%)]	Loss: 10.7455	Cost: 29.60s
Train Epoch: 719 [20480/90000 (23%)]	Loss: 8.3261	Cost: 6.06s
Train Epoch: 719 [40960/90000 (45%)]	Loss: 8.0287	Cost: 7.53s
Train Epoch: 719 [61440/90000 (68%)]	Loss: 8.3534	Cost: 5.77s
Train Epoch: 719 [81920/90000 (91%)]	Loss: 8.3053	Cost: 6.68s
Train Epoch: 719 	Average Loss: 8.4640
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4224

Learning rate: 0.00019997449008186285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 720 [0/90000 (0%)]	Loss: 11.1678	Cost: 25.72s
Train Epoch: 720 [20480/90000 (23%)]	Loss: 8.1719	Cost: 5.98s
Train Epoch: 720 [40960/90000 (45%)]	Loss: 8.1000	Cost: 8.43s
Train Epoch: 720 [61440/90000 (68%)]	Loss: 8.2269	Cost: 6.02s
Train Epoch: 720 [81920/90000 (91%)]	Loss: 8.2948	Cost: 7.29s
Train Epoch: 720 	Average Loss: 8.4388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4493

Learning rate: 0.00019997441907610605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 721 [0/90000 (0%)]	Loss: 10.9106	Cost: 22.74s
Train Epoch: 721 [20480/90000 (23%)]	Loss: 8.1654	Cost: 6.06s
Train Epoch: 721 [40960/90000 (45%)]	Loss: 8.1862	Cost: 6.85s
Train Epoch: 721 [61440/90000 (68%)]	Loss: 8.3858	Cost: 6.17s
Train Epoch: 721 [81920/90000 (91%)]	Loss: 8.2202	Cost: 9.20s
Train Epoch: 721 	Average Loss: 8.4485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3561

Learning rate: 0.00019997434797167847
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 722 [0/90000 (0%)]	Loss: 10.9539	Cost: 24.74s
Train Epoch: 722 [20480/90000 (23%)]	Loss: 8.1435	Cost: 6.07s
Train Epoch: 722 [40960/90000 (45%)]	Loss: 8.2130	Cost: 7.24s
Train Epoch: 722 [61440/90000 (68%)]	Loss: 8.3855	Cost: 5.95s
Train Epoch: 722 [81920/90000 (91%)]	Loss: 8.0530	Cost: 6.28s
Train Epoch: 722 	Average Loss: 8.4091
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3478

Learning rate: 0.00019997427676858012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 723 [0/90000 (0%)]	Loss: 11.0230	Cost: 24.32s
Train Epoch: 723 [20480/90000 (23%)]	Loss: 8.3785	Cost: 6.21s
Train Epoch: 723 [40960/90000 (45%)]	Loss: 8.0777	Cost: 6.23s
Train Epoch: 723 [61440/90000 (68%)]	Loss: 8.2769	Cost: 6.08s
Train Epoch: 723 [81920/90000 (91%)]	Loss: 8.1361	Cost: 6.22s
Train Epoch: 723 	Average Loss: 8.4353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3842

Learning rate: 0.00019997420546681116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 724 [0/90000 (0%)]	Loss: 11.0386	Cost: 25.48s
Train Epoch: 724 [20480/90000 (23%)]	Loss: 7.9617	Cost: 6.24s
Train Epoch: 724 [40960/90000 (45%)]	Loss: 8.0557	Cost: 6.90s
Train Epoch: 724 [61440/90000 (68%)]	Loss: 8.1106	Cost: 5.97s
Train Epoch: 724 [81920/90000 (91%)]	Loss: 8.0987	Cost: 5.77s
Train Epoch: 724 	Average Loss: 8.3687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5034

Learning rate: 0.0001999741340663716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 725 [0/90000 (0%)]	Loss: 10.9533	Cost: 28.60s
Train Epoch: 725 [20480/90000 (23%)]	Loss: 8.1483	Cost: 6.02s
Train Epoch: 725 [40960/90000 (45%)]	Loss: 8.1453	Cost: 7.15s
Train Epoch: 725 [61440/90000 (68%)]	Loss: 8.1657	Cost: 6.09s
Train Epoch: 725 [81920/90000 (91%)]	Loss: 8.2197	Cost: 5.68s
Train Epoch: 725 	Average Loss: 8.3997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4107

Learning rate: 0.0001999740625672615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 726 [0/90000 (0%)]	Loss: 11.0901	Cost: 22.50s
Train Epoch: 726 [20480/90000 (23%)]	Loss: 8.0839	Cost: 5.99s
Train Epoch: 726 [40960/90000 (45%)]	Loss: 8.0549	Cost: 7.70s
Train Epoch: 726 [61440/90000 (68%)]	Loss: 8.0162	Cost: 6.01s
Train Epoch: 726 [81920/90000 (91%)]	Loss: 8.1729	Cost: 8.76s
Train Epoch: 726 	Average Loss: 8.3924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4830

Learning rate: 0.00019997399096948094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 727 [0/90000 (0%)]	Loss: 10.9762	Cost: 23.29s
Train Epoch: 727 [20480/90000 (23%)]	Loss: 8.1043	Cost: 5.99s
Train Epoch: 727 [40960/90000 (45%)]	Loss: 7.8950	Cost: 6.47s
Train Epoch: 727 [61440/90000 (68%)]	Loss: 8.2339	Cost: 5.86s
Train Epoch: 727 [81920/90000 (91%)]	Loss: 8.3249	Cost: 5.87s
Train Epoch: 727 	Average Loss: 8.3557
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5134

Learning rate: 0.00019997391927303003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 728 [0/90000 (0%)]	Loss: 11.0298	Cost: 24.11s
Train Epoch: 728 [20480/90000 (23%)]	Loss: 8.0591	Cost: 6.03s
Train Epoch: 728 [40960/90000 (45%)]	Loss: 7.9803	Cost: 7.10s
Train Epoch: 728 [61440/90000 (68%)]	Loss: 8.1540	Cost: 6.20s
Train Epoch: 728 [81920/90000 (91%)]	Loss: 8.1569	Cost: 6.24s
Train Epoch: 728 	Average Loss: 8.3626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4939

Learning rate: 0.00019997384747790883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 729 [0/90000 (0%)]	Loss: 11.3092	Cost: 24.97s
Train Epoch: 729 [20480/90000 (23%)]	Loss: 8.0758	Cost: 5.98s
Train Epoch: 729 [40960/90000 (45%)]	Loss: 8.1574	Cost: 6.55s
Train Epoch: 729 [61440/90000 (68%)]	Loss: 8.2742	Cost: 5.99s
Train Epoch: 729 [81920/90000 (91%)]	Loss: 8.1767	Cost: 5.79s
Train Epoch: 729 	Average Loss: 8.3423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5930

Learning rate: 0.00019997377558411737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 730 [0/90000 (0%)]	Loss: 10.9838	Cost: 27.47s
Train Epoch: 730 [20480/90000 (23%)]	Loss: 8.0927	Cost: 6.02s
Train Epoch: 730 [40960/90000 (45%)]	Loss: 8.0987	Cost: 6.43s
Train Epoch: 730 [61440/90000 (68%)]	Loss: 8.0694	Cost: 5.99s
Train Epoch: 730 [81920/90000 (91%)]	Loss: 8.2610	Cost: 6.61s
Train Epoch: 730 	Average Loss: 8.3647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4682

Learning rate: 0.00019997370359165574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 731 [0/90000 (0%)]	Loss: 10.9930	Cost: 23.07s
Train Epoch: 731 [20480/90000 (23%)]	Loss: 8.2476	Cost: 6.06s
Train Epoch: 731 [40960/90000 (45%)]	Loss: 8.0552	Cost: 7.84s
Train Epoch: 731 [61440/90000 (68%)]	Loss: 8.0905	Cost: 5.99s
Train Epoch: 731 [81920/90000 (91%)]	Loss: 8.1733	Cost: 8.93s
Train Epoch: 731 	Average Loss: 8.3267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5246

Learning rate: 0.00019997363150052406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 732 [0/90000 (0%)]	Loss: 11.0664	Cost: 23.38s
Train Epoch: 732 [20480/90000 (23%)]	Loss: 8.1288	Cost: 6.07s
Train Epoch: 732 [40960/90000 (45%)]	Loss: 7.9085	Cost: 6.82s
Train Epoch: 732 [61440/90000 (68%)]	Loss: 8.0883	Cost: 6.53s
Train Epoch: 732 [81920/90000 (91%)]	Loss: 8.1192	Cost: 6.16s
Train Epoch: 732 	Average Loss: 8.3268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3300

Learning rate: 0.00019997355931072235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 733 [0/90000 (0%)]	Loss: 10.8381	Cost: 24.30s
Train Epoch: 733 [20480/90000 (23%)]	Loss: 8.0002	Cost: 6.02s
Train Epoch: 733 [40960/90000 (45%)]	Loss: 7.9517	Cost: 6.66s
Train Epoch: 733 [61440/90000 (68%)]	Loss: 8.0284	Cost: 6.12s
Train Epoch: 733 [81920/90000 (91%)]	Loss: 8.1106	Cost: 6.20s
Train Epoch: 733 	Average Loss: 8.3501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4903

Learning rate: 0.0001999734870222507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 734 [0/90000 (0%)]	Loss: 10.9746	Cost: 25.45s
Train Epoch: 734 [20480/90000 (23%)]	Loss: 8.0402	Cost: 6.03s
Train Epoch: 734 [40960/90000 (45%)]	Loss: 7.9822	Cost: 6.98s
Train Epoch: 734 [61440/90000 (68%)]	Loss: 8.0247	Cost: 5.89s
Train Epoch: 734 [81920/90000 (91%)]	Loss: 8.2072	Cost: 6.34s
Train Epoch: 734 	Average Loss: 8.2792
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4828

Learning rate: 0.00019997341463510914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 735 [0/90000 (0%)]	Loss: 11.0353	Cost: 28.47s
Train Epoch: 735 [20480/90000 (23%)]	Loss: 8.2394	Cost: 6.24s
Train Epoch: 735 [40960/90000 (45%)]	Loss: 7.9957	Cost: 6.86s
Train Epoch: 735 [61440/90000 (68%)]	Loss: 8.2178	Cost: 6.03s
Train Epoch: 735 [81920/90000 (91%)]	Loss: 8.1268	Cost: 5.68s
Train Epoch: 735 	Average Loss: 8.3277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5773

Learning rate: 0.00019997334214929782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 736 [0/90000 (0%)]	Loss: 10.7306	Cost: 24.88s
Train Epoch: 736 [20480/90000 (23%)]	Loss: 8.2759	Cost: 6.00s
Train Epoch: 736 [40960/90000 (45%)]	Loss: 7.9945	Cost: 7.92s
Train Epoch: 736 [61440/90000 (68%)]	Loss: 8.0889	Cost: 6.06s
Train Epoch: 736 [81920/90000 (91%)]	Loss: 8.1529	Cost: 7.68s
Train Epoch: 736 	Average Loss: 8.3262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4680

Learning rate: 0.00019997326956481675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 737 [0/90000 (0%)]	Loss: 10.9992	Cost: 24.19s
Train Epoch: 737 [20480/90000 (23%)]	Loss: 7.9981	Cost: 6.25s
Train Epoch: 737 [40960/90000 (45%)]	Loss: 7.7120	Cost: 6.42s
Train Epoch: 737 [61440/90000 (68%)]	Loss: 8.1401	Cost: 6.11s
Train Epoch: 737 [81920/90000 (91%)]	Loss: 8.1788	Cost: 7.50s
Train Epoch: 737 	Average Loss: 8.2856
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4492

Learning rate: 0.000199973196881666
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 738 [0/90000 (0%)]	Loss: 11.2757	Cost: 23.38s
Train Epoch: 738 [20480/90000 (23%)]	Loss: 7.9816	Cost: 5.97s
Train Epoch: 738 [40960/90000 (45%)]	Loss: 7.9082	Cost: 7.87s
Train Epoch: 738 [61440/90000 (68%)]	Loss: 7.7751	Cost: 5.93s
Train Epoch: 738 [81920/90000 (91%)]	Loss: 8.1067	Cost: 5.99s
Train Epoch: 738 	Average Loss: 8.2430
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5319

Learning rate: 0.00019997312409984565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 739 [0/90000 (0%)]	Loss: 11.0081	Cost: 23.39s
Train Epoch: 739 [20480/90000 (23%)]	Loss: 8.1202	Cost: 6.09s
Train Epoch: 739 [40960/90000 (45%)]	Loss: 7.9672	Cost: 6.52s
Train Epoch: 739 [61440/90000 (68%)]	Loss: 8.1118	Cost: 6.04s
Train Epoch: 739 [81920/90000 (91%)]	Loss: 8.1648	Cost: 5.89s
Train Epoch: 739 	Average Loss: 8.2845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5568

Learning rate: 0.00019997305121935581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 740 [0/90000 (0%)]	Loss: 11.3000	Cost: 28.49s
Train Epoch: 740 [20480/90000 (23%)]	Loss: 7.9699	Cost: 6.12s
Train Epoch: 740 [40960/90000 (45%)]	Loss: 7.9498	Cost: 7.48s
Train Epoch: 740 [61440/90000 (68%)]	Loss: 8.0197	Cost: 6.31s
Train Epoch: 740 [81920/90000 (91%)]	Loss: 7.9159	Cost: 6.06s
Train Epoch: 740 	Average Loss: 8.2368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5437

Learning rate: 0.00019997297824019653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 741 [0/90000 (0%)]	Loss: 11.2644	Cost: 25.50s
Train Epoch: 741 [20480/90000 (23%)]	Loss: 8.0106	Cost: 6.07s
Train Epoch: 741 [40960/90000 (45%)]	Loss: 7.9839	Cost: 7.83s
Train Epoch: 741 [61440/90000 (68%)]	Loss: 8.0462	Cost: 5.93s
Train Epoch: 741 [81920/90000 (91%)]	Loss: 7.8838	Cost: 7.16s
Train Epoch: 741 	Average Loss: 8.2372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5093

Learning rate: 0.00019997290516236789
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 742 [0/90000 (0%)]	Loss: 10.8516	Cost: 22.85s
Train Epoch: 742 [20480/90000 (23%)]	Loss: 7.9725	Cost: 6.04s
Train Epoch: 742 [40960/90000 (45%)]	Loss: 7.7262	Cost: 6.44s
Train Epoch: 742 [61440/90000 (68%)]	Loss: 7.7082	Cost: 6.14s
Train Epoch: 742 [81920/90000 (91%)]	Loss: 7.9757	Cost: 9.10s
Train Epoch: 742 	Average Loss: 8.2269
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4648

Learning rate: 0.0001999728319858699
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 743 [0/90000 (0%)]	Loss: 11.2388	Cost: 23.96s
Train Epoch: 743 [20480/90000 (23%)]	Loss: 7.7851	Cost: 6.18s
Train Epoch: 743 [40960/90000 (45%)]	Loss: 7.8537	Cost: 6.84s
Train Epoch: 743 [61440/90000 (68%)]	Loss: 8.1077	Cost: 5.90s
Train Epoch: 743 [81920/90000 (91%)]	Loss: 7.9779	Cost: 6.51s
Train Epoch: 743 	Average Loss: 8.2197
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5488

Learning rate: 0.00019997275871070266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 744 [0/90000 (0%)]	Loss: 11.1800	Cost: 24.34s
Train Epoch: 744 [20480/90000 (23%)]	Loss: 8.0860	Cost: 5.98s
Train Epoch: 744 [40960/90000 (45%)]	Loss: 7.8802	Cost: 6.84s
Train Epoch: 744 [61440/90000 (68%)]	Loss: 8.1079	Cost: 6.36s
Train Epoch: 744 [81920/90000 (91%)]	Loss: 8.0827	Cost: 6.20s
Train Epoch: 744 	Average Loss: 8.2293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5262

Learning rate: 0.00019997268533686628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 745 [0/90000 (0%)]	Loss: 11.1220	Cost: 28.89s
Train Epoch: 745 [20480/90000 (23%)]	Loss: 8.1249	Cost: 6.05s
Train Epoch: 745 [40960/90000 (45%)]	Loss: 7.8919	Cost: 6.99s
Train Epoch: 745 [61440/90000 (68%)]	Loss: 7.9462	Cost: 5.99s
Train Epoch: 745 [81920/90000 (91%)]	Loss: 8.2631	Cost: 5.90s
Train Epoch: 745 	Average Loss: 8.2164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6185

Learning rate: 0.00019997261186436086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 746 [0/90000 (0%)]	Loss: 11.2381	Cost: 23.52s
Train Epoch: 746 [20480/90000 (23%)]	Loss: 8.0301	Cost: 6.03s
Train Epoch: 746 [40960/90000 (45%)]	Loss: 7.9002	Cost: 7.85s
Train Epoch: 746 [61440/90000 (68%)]	Loss: 7.9393	Cost: 5.98s
Train Epoch: 746 [81920/90000 (91%)]	Loss: 8.1591	Cost: 8.06s
Train Epoch: 746 	Average Loss: 8.2027
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6650

Learning rate: 0.0001999725382931864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 747 [0/90000 (0%)]	Loss: 11.1942	Cost: 23.93s
Train Epoch: 747 [20480/90000 (23%)]	Loss: 7.9435	Cost: 5.88s
Train Epoch: 747 [40960/90000 (45%)]	Loss: 7.7066	Cost: 6.79s
Train Epoch: 747 [61440/90000 (68%)]	Loss: 7.8738	Cost: 6.03s
Train Epoch: 747 [81920/90000 (91%)]	Loss: 8.1338	Cost: 5.86s
Train Epoch: 747 	Average Loss: 8.1950
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5692

Learning rate: 0.000199972464623343
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 748 [0/90000 (0%)]	Loss: 11.1398	Cost: 23.26s
Train Epoch: 748 [20480/90000 (23%)]	Loss: 7.9383	Cost: 5.91s
Train Epoch: 748 [40960/90000 (45%)]	Loss: 7.8326	Cost: 7.09s
Train Epoch: 748 [61440/90000 (68%)]	Loss: 8.0449	Cost: 6.06s
Train Epoch: 748 [81920/90000 (91%)]	Loss: 8.0158	Cost: 5.77s
Train Epoch: 748 	Average Loss: 8.2229
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5036

Learning rate: 0.00019997239085483074
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 749 [0/90000 (0%)]	Loss: 11.1444	Cost: 25.52s
Train Epoch: 749 [20480/90000 (23%)]	Loss: 7.8659	Cost: 6.02s
Train Epoch: 749 [40960/90000 (45%)]	Loss: 7.8163	Cost: 6.64s
Train Epoch: 749 [61440/90000 (68%)]	Loss: 7.9863	Cost: 6.07s
Train Epoch: 749 [81920/90000 (91%)]	Loss: 7.7752	Cost: 5.88s
Train Epoch: 749 	Average Loss: 8.1532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6232

Learning rate: 0.0001999723169876497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 750 [0/90000 (0%)]	Loss: 11.1761	Cost: 28.76s
Train Epoch: 750 [20480/90000 (23%)]	Loss: 7.8407	Cost: 5.96s
Train Epoch: 750 [40960/90000 (45%)]	Loss: 7.7892	Cost: 6.83s
Train Epoch: 750 [61440/90000 (68%)]	Loss: 8.0792	Cost: 5.98s
Train Epoch: 750 [81920/90000 (91%)]	Loss: 7.9841	Cost: 6.61s
Train Epoch: 750 	Average Loss: 8.2024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6308

Learning rate: 0.0001999722430217999
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 751 [0/90000 (0%)]	Loss: 11.4163	Cost: 24.39s
Train Epoch: 751 [20480/90000 (23%)]	Loss: 7.8729	Cost: 6.02s
Train Epoch: 751 [40960/90000 (45%)]	Loss: 7.8832	Cost: 7.63s
Train Epoch: 751 [61440/90000 (68%)]	Loss: 7.9606	Cost: 5.96s
Train Epoch: 751 [81920/90000 (91%)]	Loss: 7.9135	Cost: 8.28s
Train Epoch: 751 	Average Loss: 8.1748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6824

Learning rate: 0.00019997216895728146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 752 [0/90000 (0%)]	Loss: 11.2743	Cost: 24.42s
Train Epoch: 752 [20480/90000 (23%)]	Loss: 7.8490	Cost: 5.92s
Train Epoch: 752 [40960/90000 (45%)]	Loss: 8.0072	Cost: 6.84s
Train Epoch: 752 [61440/90000 (68%)]	Loss: 7.8529	Cost: 5.93s
Train Epoch: 752 [81920/90000 (91%)]	Loss: 7.9426	Cost: 6.12s
Train Epoch: 752 	Average Loss: 8.1741
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5266

Learning rate: 0.00019997209479409445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 753 [0/90000 (0%)]	Loss: 11.2209	Cost: 23.32s
Train Epoch: 753 [20480/90000 (23%)]	Loss: 7.7876	Cost: 6.09s
Train Epoch: 753 [40960/90000 (45%)]	Loss: 7.8867	Cost: 6.23s
Train Epoch: 753 [61440/90000 (68%)]	Loss: 7.9555	Cost: 6.24s
Train Epoch: 753 [81920/90000 (91%)]	Loss: 7.9726	Cost: 6.26s
Train Epoch: 753 	Average Loss: 8.1752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5937

Learning rate: 0.00019997202053223894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 754 [0/90000 (0%)]	Loss: 11.1054	Cost: 26.41s
Train Epoch: 754 [20480/90000 (23%)]	Loss: 7.9105	Cost: 6.10s
Train Epoch: 754 [40960/90000 (45%)]	Loss: 7.8894	Cost: 7.22s
Train Epoch: 754 [61440/90000 (68%)]	Loss: 7.9427	Cost: 6.04s
Train Epoch: 754 [81920/90000 (91%)]	Loss: 7.9735	Cost: 5.84s
Train Epoch: 754 	Average Loss: 8.1573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5082

Learning rate: 0.00019997194617171497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 755 [0/90000 (0%)]	Loss: 11.1534	Cost: 28.19s
Train Epoch: 755 [20480/90000 (23%)]	Loss: 7.9107	Cost: 6.26s
Train Epoch: 755 [40960/90000 (45%)]	Loss: 7.9080	Cost: 6.85s
Train Epoch: 755 [61440/90000 (68%)]	Loss: 7.7436	Cost: 6.09s
Train Epoch: 755 [81920/90000 (91%)]	Loss: 7.8752	Cost: 6.44s
Train Epoch: 755 	Average Loss: 8.0970
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5656

Learning rate: 0.00019997187171252268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 756 [0/90000 (0%)]	Loss: 11.1926	Cost: 22.45s
Train Epoch: 756 [20480/90000 (23%)]	Loss: 8.0283	Cost: 5.95s
Train Epoch: 756 [40960/90000 (45%)]	Loss: 7.8989	Cost: 7.76s
Train Epoch: 756 [61440/90000 (68%)]	Loss: 7.8347	Cost: 5.95s
Train Epoch: 756 [81920/90000 (91%)]	Loss: 7.8862	Cost: 9.48s
Train Epoch: 756 	Average Loss: 8.1598
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5894

Learning rate: 0.0001999717971546621
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 757 [0/90000 (0%)]	Loss: 11.1843	Cost: 24.20s
Train Epoch: 757 [20480/90000 (23%)]	Loss: 7.9726	Cost: 6.04s
Train Epoch: 757 [40960/90000 (45%)]	Loss: 7.7443	Cost: 6.91s
Train Epoch: 757 [61440/90000 (68%)]	Loss: 7.8836	Cost: 5.84s
Train Epoch: 757 [81920/90000 (91%)]	Loss: 8.0864	Cost: 5.66s
Train Epoch: 757 	Average Loss: 8.1468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5288

Learning rate: 0.00019997172249813333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 758 [0/90000 (0%)]	Loss: 11.2042	Cost: 24.18s
Train Epoch: 758 [20480/90000 (23%)]	Loss: 7.9687	Cost: 6.09s
Train Epoch: 758 [40960/90000 (45%)]	Loss: 7.7007	Cost: 6.62s
Train Epoch: 758 [61440/90000 (68%)]	Loss: 7.8720	Cost: 6.36s
Train Epoch: 758 [81920/90000 (91%)]	Loss: 7.9759	Cost: 6.22s
Train Epoch: 758 	Average Loss: 8.1655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6981

Learning rate: 0.0001999716477429364
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 759 [0/90000 (0%)]	Loss: 11.2737	Cost: 26.23s
Train Epoch: 759 [20480/90000 (23%)]	Loss: 7.9116	Cost: 6.12s
Train Epoch: 759 [40960/90000 (45%)]	Loss: 7.8526	Cost: 7.41s
Train Epoch: 759 [61440/90000 (68%)]	Loss: 7.9432	Cost: 5.95s
Train Epoch: 759 [81920/90000 (91%)]	Loss: 7.8718	Cost: 5.71s
Train Epoch: 759 	Average Loss: 8.1676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6842

Learning rate: 0.00019997157288907143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 760 [0/90000 (0%)]	Loss: 11.2279	Cost: 27.90s
Train Epoch: 760 [20480/90000 (23%)]	Loss: 7.8941	Cost: 6.02s
Train Epoch: 760 [40960/90000 (45%)]	Loss: 7.7546	Cost: 9.09s
Train Epoch: 760 [61440/90000 (68%)]	Loss: 7.9532	Cost: 6.01s
Train Epoch: 760 [81920/90000 (91%)]	Loss: 8.0664	Cost: 6.17s
Train Epoch: 760 	Average Loss: 8.1075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5691

Learning rate: 0.00019997149793653845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 761 [0/90000 (0%)]	Loss: 11.2356	Cost: 22.46s
Train Epoch: 761 [20480/90000 (23%)]	Loss: 7.9045	Cost: 6.16s
Train Epoch: 761 [40960/90000 (45%)]	Loss: 7.7991	Cost: 7.09s
Train Epoch: 761 [61440/90000 (68%)]	Loss: 7.8352	Cost: 6.07s
Train Epoch: 761 [81920/90000 (91%)]	Loss: 7.9375	Cost: 8.68s
Train Epoch: 761 	Average Loss: 8.1037
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6328

Learning rate: 0.00019997142288533755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 762 [0/90000 (0%)]	Loss: 11.1502	Cost: 24.59s
Train Epoch: 762 [20480/90000 (23%)]	Loss: 7.8439	Cost: 6.17s
Train Epoch: 762 [40960/90000 (45%)]	Loss: 7.6670	Cost: 7.22s
Train Epoch: 762 [61440/90000 (68%)]	Loss: 7.8511	Cost: 5.93s
Train Epoch: 762 [81920/90000 (91%)]	Loss: 7.9094	Cost: 5.78s
Train Epoch: 762 	Average Loss: 8.0742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6269

Learning rate: 0.00019997134773546882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 763 [0/90000 (0%)]	Loss: 11.1652	Cost: 24.59s
Train Epoch: 763 [20480/90000 (23%)]	Loss: 7.6946	Cost: 6.03s
Train Epoch: 763 [40960/90000 (45%)]	Loss: 7.6322	Cost: 7.20s
Train Epoch: 763 [61440/90000 (68%)]	Loss: 7.7023	Cost: 6.07s
Train Epoch: 763 [81920/90000 (91%)]	Loss: 8.0501	Cost: 6.35s
Train Epoch: 763 	Average Loss: 8.0704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7317

Learning rate: 0.00019997127248693236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 764 [0/90000 (0%)]	Loss: 11.0937	Cost: 27.77s
Train Epoch: 764 [20480/90000 (23%)]	Loss: 7.8084	Cost: 6.04s
Train Epoch: 764 [40960/90000 (45%)]	Loss: 7.7655	Cost: 7.19s
Train Epoch: 764 [61440/90000 (68%)]	Loss: 7.6139	Cost: 6.33s
Train Epoch: 764 [81920/90000 (91%)]	Loss: 7.8689	Cost: 5.79s
Train Epoch: 764 	Average Loss: 8.0608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5504

Learning rate: 0.00019997119713972814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 765 [0/90000 (0%)]	Loss: 11.1472	Cost: 23.58s
Train Epoch: 765 [20480/90000 (23%)]	Loss: 7.9340	Cost: 6.00s
Train Epoch: 765 [40960/90000 (45%)]	Loss: 7.6506	Cost: 8.11s
Train Epoch: 765 [61440/90000 (68%)]	Loss: 7.9046	Cost: 5.87s
Train Epoch: 765 [81920/90000 (91%)]	Loss: 7.7330	Cost: 8.06s
Train Epoch: 765 	Average Loss: 8.0413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6348

Learning rate: 0.00019997112169385637
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 766 [0/90000 (0%)]	Loss: 11.2582	Cost: 23.94s
Train Epoch: 766 [20480/90000 (23%)]	Loss: 7.6797	Cost: 6.24s
Train Epoch: 766 [40960/90000 (45%)]	Loss: 7.7920	Cost: 6.36s
Train Epoch: 766 [61440/90000 (68%)]	Loss: 7.8684	Cost: 5.96s
Train Epoch: 766 [81920/90000 (91%)]	Loss: 8.0357	Cost: 5.79s
Train Epoch: 766 	Average Loss: 8.0958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7311

Learning rate: 0.00019997104614931702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 767 [0/90000 (0%)]	Loss: 11.1822	Cost: 23.62s
Train Epoch: 767 [20480/90000 (23%)]	Loss: 7.8086	Cost: 6.19s
Train Epoch: 767 [40960/90000 (45%)]	Loss: 7.7125	Cost: 7.25s
Train Epoch: 767 [61440/90000 (68%)]	Loss: 7.8731	Cost: 6.02s
Train Epoch: 767 [81920/90000 (91%)]	Loss: 7.6547	Cost: 6.60s
Train Epoch: 767 	Average Loss: 8.0335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7113

Learning rate: 0.0001999709705061102
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 768 [0/90000 (0%)]	Loss: 11.3970	Cost: 25.03s
Train Epoch: 768 [20480/90000 (23%)]	Loss: 7.6960	Cost: 6.06s
Train Epoch: 768 [40960/90000 (45%)]	Loss: 7.8731	Cost: 6.87s
Train Epoch: 768 [61440/90000 (68%)]	Loss: 7.8426	Cost: 5.99s
Train Epoch: 768 [81920/90000 (91%)]	Loss: 7.8983	Cost: 6.74s
Train Epoch: 768 	Average Loss: 8.0859
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7009

Learning rate: 0.00019997089476423598
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 769 [0/90000 (0%)]	Loss: 11.3281	Cost: 28.28s
Train Epoch: 769 [20480/90000 (23%)]	Loss: 7.9819	Cost: 6.07s
Train Epoch: 769 [40960/90000 (45%)]	Loss: 7.7646	Cost: 6.88s
Train Epoch: 769 [61440/90000 (68%)]	Loss: 7.9389	Cost: 6.08s
Train Epoch: 769 [81920/90000 (91%)]	Loss: 7.9083	Cost: 5.70s
Train Epoch: 769 	Average Loss: 8.1115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6685

Learning rate: 0.00019997081892369448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 770 [0/90000 (0%)]	Loss: 11.1572	Cost: 24.41s
Train Epoch: 770 [20480/90000 (23%)]	Loss: 7.6672	Cost: 5.98s
Train Epoch: 770 [40960/90000 (45%)]	Loss: 7.6104	Cost: 8.22s
Train Epoch: 770 [61440/90000 (68%)]	Loss: 7.6089	Cost: 5.88s
Train Epoch: 770 [81920/90000 (91%)]	Loss: 7.9326	Cost: 7.86s
Train Epoch: 770 	Average Loss: 8.0233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6605

Learning rate: 0.0001999707429844857
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 771 [0/90000 (0%)]	Loss: 11.2207	Cost: 24.01s
Train Epoch: 771 [20480/90000 (23%)]	Loss: 7.8423	Cost: 6.02s
Train Epoch: 771 [40960/90000 (45%)]	Loss: 7.6774	Cost: 6.43s
Train Epoch: 771 [61440/90000 (68%)]	Loss: 7.7465	Cost: 6.22s
Train Epoch: 771 [81920/90000 (91%)]	Loss: 7.8229	Cost: 8.56s
Train Epoch: 771 	Average Loss: 7.9928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6176

Learning rate: 0.00019997066694660978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 772 [0/90000 (0%)]	Loss: 11.3605	Cost: 24.55s
Train Epoch: 772 [20480/90000 (23%)]	Loss: 7.6560	Cost: 6.21s
Train Epoch: 772 [40960/90000 (45%)]	Loss: 7.5467	Cost: 7.27s
Train Epoch: 772 [61440/90000 (68%)]	Loss: 7.7502	Cost: 6.03s
Train Epoch: 772 [81920/90000 (91%)]	Loss: 7.7456	Cost: 6.43s
Train Epoch: 772 	Average Loss: 8.0152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7128

Learning rate: 0.00019997059081006675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 773 [0/90000 (0%)]	Loss: 11.2134	Cost: 24.11s
Train Epoch: 773 [20480/90000 (23%)]	Loss: 7.6133	Cost: 6.18s
Train Epoch: 773 [40960/90000 (45%)]	Loss: 7.5960	Cost: 7.31s
Train Epoch: 773 [61440/90000 (68%)]	Loss: 7.7210	Cost: 6.21s
Train Epoch: 773 [81920/90000 (91%)]	Loss: 7.7169	Cost: 6.35s
Train Epoch: 773 	Average Loss: 7.9863
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7570

Learning rate: 0.0001999705145748567
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 774 [0/90000 (0%)]	Loss: 11.1050	Cost: 28.26s
Train Epoch: 774 [20480/90000 (23%)]	Loss: 7.5495	Cost: 5.98s
Train Epoch: 774 [40960/90000 (45%)]	Loss: 7.5243	Cost: 7.74s
Train Epoch: 774 [61440/90000 (68%)]	Loss: 7.7557	Cost: 6.35s
Train Epoch: 774 [81920/90000 (91%)]	Loss: 7.8165	Cost: 6.33s
Train Epoch: 774 	Average Loss: 7.9850
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6692

Learning rate: 0.0001999704382409797
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 775 [0/90000 (0%)]	Loss: 11.1520	Cost: 23.13s
Train Epoch: 775 [20480/90000 (23%)]	Loss: 7.6177	Cost: 6.06s
Train Epoch: 775 [40960/90000 (45%)]	Loss: 7.6084	Cost: 7.92s
Train Epoch: 775 [61440/90000 (68%)]	Loss: 7.5421	Cost: 6.03s
Train Epoch: 775 [81920/90000 (91%)]	Loss: 7.7440	Cost: 6.68s
Train Epoch: 775 	Average Loss: 7.9765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7062

Learning rate: 0.00019997036180843583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 776 [0/90000 (0%)]	Loss: 11.3588	Cost: 23.44s
Train Epoch: 776 [20480/90000 (23%)]	Loss: 7.6256	Cost: 6.60s
Train Epoch: 776 [40960/90000 (45%)]	Loss: 7.6506	Cost: 6.17s
Train Epoch: 776 [61440/90000 (68%)]	Loss: 7.8287	Cost: 5.99s
Train Epoch: 776 [81920/90000 (91%)]	Loss: 7.7275	Cost: 7.23s
Train Epoch: 776 	Average Loss: 7.9845
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7169

Learning rate: 0.00019997028527722518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 777 [0/90000 (0%)]	Loss: 11.2179	Cost: 23.42s
Train Epoch: 777 [20480/90000 (23%)]	Loss: 7.6917	Cost: 6.17s
Train Epoch: 777 [40960/90000 (45%)]	Loss: 7.7179	Cost: 6.49s
Train Epoch: 777 [61440/90000 (68%)]	Loss: 7.6934	Cost: 6.01s
Train Epoch: 777 [81920/90000 (91%)]	Loss: 7.6328	Cost: 6.22s
Train Epoch: 777 	Average Loss: 7.9644
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7346

Learning rate: 0.00019997020864734782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 778 [0/90000 (0%)]	Loss: 11.2771	Cost: 24.96s
Train Epoch: 778 [20480/90000 (23%)]	Loss: 7.6874	Cost: 6.12s
Train Epoch: 778 [40960/90000 (45%)]	Loss: 7.7107	Cost: 6.79s
Train Epoch: 778 [61440/90000 (68%)]	Loss: 7.6698	Cost: 6.08s
Train Epoch: 778 [81920/90000 (91%)]	Loss: 7.6610	Cost: 6.86s
Train Epoch: 778 	Average Loss: 7.9843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7182

Learning rate: 0.00019997013191880381
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 779 [0/90000 (0%)]	Loss: 11.1654	Cost: 29.79s
Train Epoch: 779 [20480/90000 (23%)]	Loss: 7.6861	Cost: 6.13s
Train Epoch: 779 [40960/90000 (45%)]	Loss: 7.5866	Cost: 6.84s
Train Epoch: 779 [61440/90000 (68%)]	Loss: 7.4252	Cost: 6.01s
Train Epoch: 779 [81920/90000 (91%)]	Loss: 7.6347	Cost: 5.75s
Train Epoch: 779 	Average Loss: 7.9377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7882

Learning rate: 0.00019997005509159326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 780 [0/90000 (0%)]	Loss: 11.3417	Cost: 24.87s
Train Epoch: 780 [20480/90000 (23%)]	Loss: 7.8388	Cost: 6.00s
Train Epoch: 780 [40960/90000 (45%)]	Loss: 7.6325	Cost: 7.66s
Train Epoch: 780 [61440/90000 (68%)]	Loss: 7.5773	Cost: 6.05s
Train Epoch: 780 [81920/90000 (91%)]	Loss: 7.6197	Cost: 7.31s
Train Epoch: 780 	Average Loss: 7.9544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7336

Learning rate: 0.0001999699781657162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 781 [0/90000 (0%)]	Loss: 11.1892	Cost: 23.90s
Train Epoch: 781 [20480/90000 (23%)]	Loss: 7.4769	Cost: 6.10s
Train Epoch: 781 [40960/90000 (45%)]	Loss: 7.5104	Cost: 6.66s
Train Epoch: 781 [61440/90000 (68%)]	Loss: 7.7860	Cost: 5.97s
Train Epoch: 781 [81920/90000 (91%)]	Loss: 7.6284	Cost: 6.09s
Train Epoch: 781 	Average Loss: 7.9744
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6192

Learning rate: 0.00019996990114117273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 782 [0/90000 (0%)]	Loss: 11.4470	Cost: 23.85s
Train Epoch: 782 [20480/90000 (23%)]	Loss: 7.7099	Cost: 6.19s
Train Epoch: 782 [40960/90000 (45%)]	Loss: 7.5211	Cost: 6.87s
Train Epoch: 782 [61440/90000 (68%)]	Loss: 7.6360	Cost: 6.03s
Train Epoch: 782 [81920/90000 (91%)]	Loss: 7.6297	Cost: 6.71s
Train Epoch: 782 	Average Loss: 7.9615
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7747

Learning rate: 0.0001999698240179629
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 783 [0/90000 (0%)]	Loss: 11.2640	Cost: 25.00s
Train Epoch: 783 [20480/90000 (23%)]	Loss: 7.6477	Cost: 6.10s
Train Epoch: 783 [40960/90000 (45%)]	Loss: 7.6383	Cost: 6.19s
Train Epoch: 783 [61440/90000 (68%)]	Loss: 7.7978	Cost: 6.09s
Train Epoch: 783 [81920/90000 (91%)]	Loss: 7.8173	Cost: 5.95s
Train Epoch: 783 	Average Loss: 7.9618
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7045

Learning rate: 0.00019996974679608684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 784 [0/90000 (0%)]	Loss: 11.3729	Cost: 29.55s
Train Epoch: 784 [20480/90000 (23%)]	Loss: 7.6674	Cost: 6.05s
Train Epoch: 784 [40960/90000 (45%)]	Loss: 7.5402	Cost: 6.96s
Train Epoch: 784 [61440/90000 (68%)]	Loss: 7.7089	Cost: 6.51s
Train Epoch: 784 [81920/90000 (91%)]	Loss: 7.7190	Cost: 7.00s
Train Epoch: 784 	Average Loss: 7.9708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8035

Learning rate: 0.00019996966947554456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 785 [0/90000 (0%)]	Loss: 11.2051	Cost: 25.09s
Train Epoch: 785 [20480/90000 (23%)]	Loss: 7.6646	Cost: 5.98s
Train Epoch: 785 [40960/90000 (45%)]	Loss: 7.4964	Cost: 8.12s
Train Epoch: 785 [61440/90000 (68%)]	Loss: 7.5900	Cost: 6.02s
Train Epoch: 785 [81920/90000 (91%)]	Loss: 7.4167	Cost: 7.26s
Train Epoch: 785 	Average Loss: 7.9084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7583

Learning rate: 0.0001999695920563362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 786 [0/90000 (0%)]	Loss: 11.4967	Cost: 23.88s
Train Epoch: 786 [20480/90000 (23%)]	Loss: 7.7554	Cost: 6.08s
Train Epoch: 786 [40960/90000 (45%)]	Loss: 7.2307	Cost: 6.84s
Train Epoch: 786 [61440/90000 (68%)]	Loss: 7.5118	Cost: 6.03s
Train Epoch: 786 [81920/90000 (91%)]	Loss: 7.5740	Cost: 8.02s
Train Epoch: 786 	Average Loss: 7.9099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6554

Learning rate: 0.0001999695145384618
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 787 [0/90000 (0%)]	Loss: 11.1461	Cost: 24.07s
Train Epoch: 787 [20480/90000 (23%)]	Loss: 7.4288	Cost: 6.03s
Train Epoch: 787 [40960/90000 (45%)]	Loss: 7.6468	Cost: 7.62s
Train Epoch: 787 [61440/90000 (68%)]	Loss: 7.7654	Cost: 5.94s
Train Epoch: 787 [81920/90000 (91%)]	Loss: 7.5695	Cost: 6.56s
Train Epoch: 787 	Average Loss: 7.8834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7891

Learning rate: 0.00019996943692192142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 788 [0/90000 (0%)]	Loss: 11.2388	Cost: 22.87s
Train Epoch: 788 [20480/90000 (23%)]	Loss: 7.6426	Cost: 6.01s
Train Epoch: 788 [40960/90000 (45%)]	Loss: 7.6812	Cost: 6.59s
Train Epoch: 788 [61440/90000 (68%)]	Loss: 7.6410	Cost: 6.05s
Train Epoch: 788 [81920/90000 (91%)]	Loss: 7.5786	Cost: 5.59s
Train Epoch: 788 	Average Loss: 7.8759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7944

Learning rate: 0.0001999693592067152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 789 [0/90000 (0%)]	Loss: 11.0758	Cost: 28.53s
Train Epoch: 789 [20480/90000 (23%)]	Loss: 7.6087	Cost: 5.96s
Train Epoch: 789 [40960/90000 (45%)]	Loss: 7.5434	Cost: 8.06s
Train Epoch: 789 [61440/90000 (68%)]	Loss: 7.6853	Cost: 5.95s
Train Epoch: 789 [81920/90000 (91%)]	Loss: 7.6164	Cost: 6.02s
Train Epoch: 789 	Average Loss: 7.8332
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7399

Learning rate: 0.00019996928139284315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 790 [0/90000 (0%)]	Loss: 11.2659	Cost: 25.58s
Train Epoch: 790 [20480/90000 (23%)]	Loss: 7.6402	Cost: 6.02s
Train Epoch: 790 [40960/90000 (45%)]	Loss: 7.4851	Cost: 7.67s
Train Epoch: 790 [61440/90000 (68%)]	Loss: 7.4096	Cost: 6.10s
Train Epoch: 790 [81920/90000 (91%)]	Loss: 7.6165	Cost: 6.26s
Train Epoch: 790 	Average Loss: 7.8573
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6921

Learning rate: 0.00019996920348030537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 791 [0/90000 (0%)]	Loss: 11.1796	Cost: 22.85s
Train Epoch: 791 [20480/90000 (23%)]	Loss: 7.4296	Cost: 5.96s
Train Epoch: 791 [40960/90000 (45%)]	Loss: 7.4219	Cost: 6.34s
Train Epoch: 791 [61440/90000 (68%)]	Loss: 7.5221	Cost: 6.02s
Train Epoch: 791 [81920/90000 (91%)]	Loss: 7.7353	Cost: 8.31s
Train Epoch: 791 	Average Loss: 7.8649
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7820

Learning rate: 0.00019996912546910197
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 792 [0/90000 (0%)]	Loss: 11.5388	Cost: 23.92s
Train Epoch: 792 [20480/90000 (23%)]	Loss: 7.6746	Cost: 6.05s
Train Epoch: 792 [40960/90000 (45%)]	Loss: 7.4993	Cost: 6.11s
Train Epoch: 792 [61440/90000 (68%)]	Loss: 7.5866	Cost: 5.87s
Train Epoch: 792 [81920/90000 (91%)]	Loss: 7.5514	Cost: 5.75s
Train Epoch: 792 	Average Loss: 7.8889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7946

Learning rate: 0.000199969047359233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 793 [0/90000 (0%)]	Loss: 11.4145	Cost: 23.48s
Train Epoch: 793 [20480/90000 (23%)]	Loss: 7.5158	Cost: 6.31s
Train Epoch: 793 [40960/90000 (45%)]	Loss: 7.5308	Cost: 6.45s
Train Epoch: 793 [61440/90000 (68%)]	Loss: 7.4371	Cost: 6.16s
Train Epoch: 793 [81920/90000 (91%)]	Loss: 7.6441	Cost: 5.96s
Train Epoch: 793 	Average Loss: 7.8462
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7348

Learning rate: 0.00019996896915069852
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 794 [0/90000 (0%)]	Loss: 11.2376	Cost: 28.64s
Train Epoch: 794 [20480/90000 (23%)]	Loss: 7.4040	Cost: 6.23s
Train Epoch: 794 [40960/90000 (45%)]	Loss: 7.5573	Cost: 7.39s
Train Epoch: 794 [61440/90000 (68%)]	Loss: 7.7102	Cost: 5.91s
Train Epoch: 794 [81920/90000 (91%)]	Loss: 7.5207	Cost: 5.72s
Train Epoch: 794 	Average Loss: 7.8468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7150

Learning rate: 0.0001999688908434986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 795 [0/90000 (0%)]	Loss: 11.1509	Cost: 24.62s
Train Epoch: 795 [20480/90000 (23%)]	Loss: 7.6168	Cost: 6.05s
Train Epoch: 795 [40960/90000 (45%)]	Loss: 7.5460	Cost: 7.95s
Train Epoch: 795 [61440/90000 (68%)]	Loss: 7.6480	Cost: 6.04s
Train Epoch: 795 [81920/90000 (91%)]	Loss: 7.5836	Cost: 6.94s
Train Epoch: 795 	Average Loss: 7.8290
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8112

Learning rate: 0.00019996881243763336
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 796 [0/90000 (0%)]	Loss: 11.4072	Cost: 23.30s
Train Epoch: 796 [20480/90000 (23%)]	Loss: 7.6319	Cost: 5.93s
Train Epoch: 796 [40960/90000 (45%)]	Loss: 7.4090	Cost: 6.25s
Train Epoch: 796 [61440/90000 (68%)]	Loss: 7.3971	Cost: 6.10s
Train Epoch: 796 [81920/90000 (91%)]	Loss: 7.4845	Cost: 8.12s
Train Epoch: 796 	Average Loss: 7.8094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8852

Learning rate: 0.00019996873393310284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 797 [0/90000 (0%)]	Loss: 11.4980	Cost: 24.01s
Train Epoch: 797 [20480/90000 (23%)]	Loss: 7.5034	Cost: 6.19s
Train Epoch: 797 [40960/90000 (45%)]	Loss: 7.5350	Cost: 6.69s
Train Epoch: 797 [61440/90000 (68%)]	Loss: 7.5110	Cost: 6.10s
Train Epoch: 797 [81920/90000 (91%)]	Loss: 7.4710	Cost: 6.19s
Train Epoch: 797 	Average Loss: 7.8310
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6737

Learning rate: 0.00019996865532990714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 798 [0/90000 (0%)]	Loss: 11.5034	Cost: 25.31s
Train Epoch: 798 [20480/90000 (23%)]	Loss: 7.5321	Cost: 6.13s
Train Epoch: 798 [40960/90000 (45%)]	Loss: 7.3391	Cost: 6.61s
Train Epoch: 798 [61440/90000 (68%)]	Loss: 7.5019	Cost: 6.08s
Train Epoch: 798 [81920/90000 (91%)]	Loss: 7.3718	Cost: 5.79s
Train Epoch: 798 	Average Loss: 7.8489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8227

Learning rate: 0.00019996857662804636
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 799 [0/90000 (0%)]	Loss: 11.4068	Cost: 29.38s
Train Epoch: 799 [20480/90000 (23%)]	Loss: 7.6190	Cost: 5.98s
Train Epoch: 799 [40960/90000 (45%)]	Loss: 7.3945	Cost: 8.91s
Train Epoch: 799 [61440/90000 (68%)]	Loss: 7.5397	Cost: 6.15s
Train Epoch: 799 [81920/90000 (91%)]	Loss: 7.6198	Cost: 7.73s
Train Epoch: 799 	Average Loss: 7.8256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8033

Learning rate: 0.00019996849782752052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 800 [0/90000 (0%)]	Loss: 11.2823	Cost: 26.16s
Train Epoch: 800 [20480/90000 (23%)]	Loss: 7.5791	Cost: 6.06s
Train Epoch: 800 [40960/90000 (45%)]	Loss: 7.5430	Cost: 9.22s
Train Epoch: 800 [61440/90000 (68%)]	Loss: 7.3995	Cost: 5.90s
Train Epoch: 800 [81920/90000 (91%)]	Loss: 7.5070	Cost: 7.52s
Train Epoch: 800 	Average Loss: 7.7906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7537

Learning rate: 0.00019996841892832974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 801 [0/90000 (0%)]	Loss: 11.2251	Cost: 22.29s
Train Epoch: 801 [20480/90000 (23%)]	Loss: 7.4430	Cost: 5.94s
Train Epoch: 801 [40960/90000 (45%)]	Loss: 7.3317	Cost: 7.37s
Train Epoch: 801 [61440/90000 (68%)]	Loss: 7.7602	Cost: 6.04s
Train Epoch: 801 [81920/90000 (91%)]	Loss: 7.5837	Cost: 9.58s
Train Epoch: 801 	Average Loss: 7.7802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8862

Learning rate: 0.00019996833993047412
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 802 [0/90000 (0%)]	Loss: 11.5929	Cost: 24.74s
Train Epoch: 802 [20480/90000 (23%)]	Loss: 7.2343	Cost: 6.04s
Train Epoch: 802 [40960/90000 (45%)]	Loss: 7.4130	Cost: 6.32s
Train Epoch: 802 [61440/90000 (68%)]	Loss: 7.6619	Cost: 6.16s
Train Epoch: 802 [81920/90000 (91%)]	Loss: 7.6414	Cost: 5.72s
Train Epoch: 802 	Average Loss: 7.8109
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7413

Learning rate: 0.00019996826083395366
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 803 [0/90000 (0%)]	Loss: 11.3556	Cost: 22.06s
Train Epoch: 803 [20480/90000 (23%)]	Loss: 7.4263	Cost: 6.01s
Train Epoch: 803 [40960/90000 (45%)]	Loss: 7.4966	Cost: 7.94s
Train Epoch: 803 [61440/90000 (68%)]	Loss: 7.5692	Cost: 6.01s
Train Epoch: 803 [81920/90000 (91%)]	Loss: 7.5026	Cost: 5.78s
Train Epoch: 803 	Average Loss: 7.7839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8567

Learning rate: 0.0001999681816387685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 804 [0/90000 (0%)]	Loss: 11.5684	Cost: 25.59s
Train Epoch: 804 [20480/90000 (23%)]	Loss: 7.3881	Cost: 6.15s
Train Epoch: 804 [40960/90000 (45%)]	Loss: 7.3351	Cost: 7.23s
Train Epoch: 804 [61440/90000 (68%)]	Loss: 7.4086	Cost: 5.97s
Train Epoch: 804 [81920/90000 (91%)]	Loss: 7.6538	Cost: 6.06s
Train Epoch: 804 	Average Loss: 7.7849
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6915

Learning rate: 0.00019996810234491867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 805 [0/90000 (0%)]	Loss: 11.4708	Cost: 26.20s
Train Epoch: 805 [20480/90000 (23%)]	Loss: 7.3463	Cost: 6.16s
Train Epoch: 805 [40960/90000 (45%)]	Loss: 7.4211	Cost: 9.15s
Train Epoch: 805 [61440/90000 (68%)]	Loss: 7.2675	Cost: 6.01s
Train Epoch: 805 [81920/90000 (91%)]	Loss: 7.5418	Cost: 7.58s
Train Epoch: 805 	Average Loss: 7.7729
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9222

Learning rate: 0.0001999680229524043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 806 [0/90000 (0%)]	Loss: 11.2352	Cost: 22.31s
Train Epoch: 806 [20480/90000 (23%)]	Loss: 7.9820	Cost: 6.01s
Train Epoch: 806 [40960/90000 (45%)]	Loss: 7.8211	Cost: 6.84s
Train Epoch: 806 [61440/90000 (68%)]	Loss: 7.7951	Cost: 6.05s
Train Epoch: 806 [81920/90000 (91%)]	Loss: 7.8545	Cost: 8.42s
Train Epoch: 806 	Average Loss: 8.1360
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7949

Learning rate: 0.00019996794346122544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 807 [0/90000 (0%)]	Loss: 11.3042	Cost: 24.20s
Train Epoch: 807 [20480/90000 (23%)]	Loss: 7.5642	Cost: 6.16s
Train Epoch: 807 [40960/90000 (45%)]	Loss: 7.5374	Cost: 7.05s
Train Epoch: 807 [61440/90000 (68%)]	Loss: 7.6532	Cost: 5.91s
Train Epoch: 807 [81920/90000 (91%)]	Loss: 7.4884	Cost: 6.31s
Train Epoch: 807 	Average Loss: 7.9365
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7123

Learning rate: 0.00019996786387138218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 808 [0/90000 (0%)]	Loss: 11.3078	Cost: 23.37s
Train Epoch: 808 [20480/90000 (23%)]	Loss: 7.7015	Cost: 6.66s
Train Epoch: 808 [40960/90000 (45%)]	Loss: 7.2612	Cost: 6.35s
Train Epoch: 808 [61440/90000 (68%)]	Loss: 7.5538	Cost: 5.97s
Train Epoch: 808 [81920/90000 (91%)]	Loss: 7.3654	Cost: 5.53s
Train Epoch: 808 	Average Loss: 7.8197
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8587

Learning rate: 0.00019996778418287457
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 809 [0/90000 (0%)]	Loss: 11.0826	Cost: 28.28s
Train Epoch: 809 [20480/90000 (23%)]	Loss: 7.5475	Cost: 6.10s
Train Epoch: 809 [40960/90000 (45%)]	Loss: 7.3514	Cost: 7.35s
Train Epoch: 809 [61440/90000 (68%)]	Loss: 7.6011	Cost: 6.35s
Train Epoch: 809 [81920/90000 (91%)]	Loss: 7.6169	Cost: 5.88s
Train Epoch: 809 	Average Loss: 7.7499
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8208

Learning rate: 0.00019996770439570274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 810 [0/90000 (0%)]	Loss: 11.3933	Cost: 29.04s
Train Epoch: 810 [20480/90000 (23%)]	Loss: 7.5513	Cost: 5.98s
Train Epoch: 810 [40960/90000 (45%)]	Loss: 7.3078	Cost: 6.95s
Train Epoch: 810 [61440/90000 (68%)]	Loss: 7.4601	Cost: 6.08s
Train Epoch: 810 [81920/90000 (91%)]	Loss: 7.3573	Cost: 6.22s
Train Epoch: 810 	Average Loss: 7.7409
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7433

Learning rate: 0.00019996762450986673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 811 [0/90000 (0%)]	Loss: 11.4372	Cost: 23.27s
Train Epoch: 811 [20480/90000 (23%)]	Loss: 7.3342	Cost: 6.07s
Train Epoch: 811 [40960/90000 (45%)]	Loss: 7.2712	Cost: 6.85s
Train Epoch: 811 [61440/90000 (68%)]	Loss: 7.4460	Cost: 5.98s
Train Epoch: 811 [81920/90000 (91%)]	Loss: 7.3974	Cost: 8.24s
Train Epoch: 811 	Average Loss: 7.7564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8483

Learning rate: 0.00019996754452536662
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 812 [0/90000 (0%)]	Loss: 11.4297	Cost: 25.66s
Train Epoch: 812 [20480/90000 (23%)]	Loss: 7.3395	Cost: 6.01s
Train Epoch: 812 [40960/90000 (45%)]	Loss: 7.3242	Cost: 6.58s
Train Epoch: 812 [61440/90000 (68%)]	Loss: 7.6541	Cost: 5.90s
Train Epoch: 812 [81920/90000 (91%)]	Loss: 7.3530	Cost: 6.21s
Train Epoch: 812 	Average Loss: 7.7353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8891

Learning rate: 0.0001999674644422025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 813 [0/90000 (0%)]	Loss: 11.6172	Cost: 23.38s
Train Epoch: 813 [20480/90000 (23%)]	Loss: 7.3603	Cost: 6.16s
Train Epoch: 813 [40960/90000 (45%)]	Loss: 7.1992	Cost: 7.27s
Train Epoch: 813 [61440/90000 (68%)]	Loss: 7.4190	Cost: 6.25s
Train Epoch: 813 [81920/90000 (91%)]	Loss: 7.6026	Cost: 6.08s
Train Epoch: 813 	Average Loss: 7.7543
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9393

Learning rate: 0.00019996738426037447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 814 [0/90000 (0%)]	Loss: 11.4083	Cost: 28.03s
Train Epoch: 814 [20480/90000 (23%)]	Loss: 7.2065	Cost: 5.96s
Train Epoch: 814 [40960/90000 (45%)]	Loss: 7.3175	Cost: 7.81s
Train Epoch: 814 [61440/90000 (68%)]	Loss: 7.3629	Cost: 5.87s
Train Epoch: 814 [81920/90000 (91%)]	Loss: 7.5336	Cost: 6.14s
Train Epoch: 814 	Average Loss: 7.6914
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8834

Learning rate: 0.00019996730397988258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 815 [0/90000 (0%)]	Loss: 11.4272	Cost: 27.45s
Train Epoch: 815 [20480/90000 (23%)]	Loss: 7.3652	Cost: 6.06s
Train Epoch: 815 [40960/90000 (45%)]	Loss: 7.4626	Cost: 9.33s
Train Epoch: 815 [61440/90000 (68%)]	Loss: 7.5887	Cost: 6.01s
Train Epoch: 815 [81920/90000 (91%)]	Loss: 7.4985	Cost: 8.45s
Train Epoch: 815 	Average Loss: 7.6956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8210

Learning rate: 0.00019996722360072691
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 816 [0/90000 (0%)]	Loss: 11.2531	Cost: 23.87s
Train Epoch: 816 [20480/90000 (23%)]	Loss: 7.3108	Cost: 6.09s
Train Epoch: 816 [40960/90000 (45%)]	Loss: 7.2339	Cost: 6.55s
Train Epoch: 816 [61440/90000 (68%)]	Loss: 7.3546	Cost: 6.03s
Train Epoch: 816 [81920/90000 (91%)]	Loss: 7.3314	Cost: 8.19s
Train Epoch: 816 	Average Loss: 7.6654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8808

Learning rate: 0.00019996714312290757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 817 [0/90000 (0%)]	Loss: 11.4149	Cost: 24.34s
Train Epoch: 817 [20480/90000 (23%)]	Loss: 7.3736	Cost: 6.08s
Train Epoch: 817 [40960/90000 (45%)]	Loss: 7.1851	Cost: 7.07s
Train Epoch: 817 [61440/90000 (68%)]	Loss: 7.3461	Cost: 5.91s
Train Epoch: 817 [81920/90000 (91%)]	Loss: 7.3635	Cost: 5.94s
Train Epoch: 817 	Average Loss: 7.6452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9291

Learning rate: 0.0001999670625464246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 818 [0/90000 (0%)]	Loss: 11.5555	Cost: 23.25s
Train Epoch: 818 [20480/90000 (23%)]	Loss: 7.2799	Cost: 6.21s
Train Epoch: 818 [40960/90000 (45%)]	Loss: 7.3110	Cost: 6.60s
Train Epoch: 818 [61440/90000 (68%)]	Loss: 7.3760	Cost: 6.06s
Train Epoch: 818 [81920/90000 (91%)]	Loss: 7.3495	Cost: 6.09s
Train Epoch: 818 	Average Loss: 7.6397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8396

Learning rate: 0.00019996698187127807
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 819 [0/90000 (0%)]	Loss: 11.2149	Cost: 25.83s
Train Epoch: 819 [20480/90000 (23%)]	Loss: 7.2371	Cost: 6.00s
Train Epoch: 819 [40960/90000 (45%)]	Loss: 7.5117	Cost: 6.41s
Train Epoch: 819 [61440/90000 (68%)]	Loss: 7.2660	Cost: 6.10s
Train Epoch: 819 [81920/90000 (91%)]	Loss: 7.2672	Cost: 6.14s
Train Epoch: 819 	Average Loss: 7.6290
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0788

Learning rate: 0.00019996690109746812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 820 [0/90000 (0%)]	Loss: 11.4976	Cost: 24.14s
Train Epoch: 820 [20480/90000 (23%)]	Loss: 7.3340	Cost: 6.00s
Train Epoch: 820 [40960/90000 (45%)]	Loss: 7.5596	Cost: 7.59s
Train Epoch: 820 [61440/90000 (68%)]	Loss: 7.6822	Cost: 6.06s
Train Epoch: 820 [81920/90000 (91%)]	Loss: 7.6328	Cost: 6.76s
Train Epoch: 820 	Average Loss: 7.7493
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9442

Learning rate: 0.00019996682022499477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 821 [0/90000 (0%)]	Loss: 11.3309	Cost: 23.04s
Train Epoch: 821 [20480/90000 (23%)]	Loss: 7.5126	Cost: 6.49s
Train Epoch: 821 [40960/90000 (45%)]	Loss: 7.2442	Cost: 6.36s
Train Epoch: 821 [61440/90000 (68%)]	Loss: 7.2649	Cost: 6.17s
Train Epoch: 821 [81920/90000 (91%)]	Loss: 7.3556	Cost: 8.05s
Train Epoch: 821 	Average Loss: 7.7107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9162

Learning rate: 0.00019996673925385812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 822 [0/90000 (0%)]	Loss: 11.5047	Cost: 24.93s
Train Epoch: 822 [20480/90000 (23%)]	Loss: 7.4086	Cost: 6.38s
Train Epoch: 822 [40960/90000 (45%)]	Loss: 7.3493	Cost: 6.26s
Train Epoch: 822 [61440/90000 (68%)]	Loss: 7.3233	Cost: 5.95s
Train Epoch: 822 [81920/90000 (91%)]	Loss: 7.2717	Cost: 6.16s
Train Epoch: 822 	Average Loss: 7.6849
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8918

Learning rate: 0.00019996665818405824
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 823 [0/90000 (0%)]	Loss: 11.3592	Cost: 24.69s
Train Epoch: 823 [20480/90000 (23%)]	Loss: 7.3227	Cost: 6.11s
Train Epoch: 823 [40960/90000 (45%)]	Loss: 7.4230	Cost: 6.62s
Train Epoch: 823 [61440/90000 (68%)]	Loss: 7.4695	Cost: 6.02s
Train Epoch: 823 [81920/90000 (91%)]	Loss: 7.5084	Cost: 6.68s
Train Epoch: 823 	Average Loss: 7.7102
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9345

Learning rate: 0.00019996657701559526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 824 [0/90000 (0%)]	Loss: 11.2927	Cost: 29.09s
Train Epoch: 824 [20480/90000 (23%)]	Loss: 7.2366	Cost: 6.34s
Train Epoch: 824 [40960/90000 (45%)]	Loss: 7.1574	Cost: 6.75s
Train Epoch: 824 [61440/90000 (68%)]	Loss: 7.3771	Cost: 6.06s
Train Epoch: 824 [81920/90000 (91%)]	Loss: 7.3379	Cost: 6.20s
Train Epoch: 824 	Average Loss: 7.6530
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9029

Learning rate: 0.0001999664957484692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 825 [0/90000 (0%)]	Loss: 11.2699	Cost: 24.35s
Train Epoch: 825 [20480/90000 (23%)]	Loss: 7.1601	Cost: 6.06s
Train Epoch: 825 [40960/90000 (45%)]	Loss: 7.0864	Cost: 8.04s
Train Epoch: 825 [61440/90000 (68%)]	Loss: 7.5208	Cost: 5.86s
Train Epoch: 825 [81920/90000 (91%)]	Loss: 7.4398	Cost: 9.03s
Train Epoch: 825 	Average Loss: 7.6285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9130

Learning rate: 0.00019996641438268018
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 826 [0/90000 (0%)]	Loss: 11.4481	Cost: 23.13s
Train Epoch: 826 [20480/90000 (23%)]	Loss: 7.3703	Cost: 6.01s
Train Epoch: 826 [40960/90000 (45%)]	Loss: 7.2433	Cost: 6.82s
Train Epoch: 826 [61440/90000 (68%)]	Loss: 7.3213	Cost: 6.27s
Train Epoch: 826 [81920/90000 (91%)]	Loss: 7.3574	Cost: 7.87s
Train Epoch: 826 	Average Loss: 7.5804
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0083

Learning rate: 0.00019996633291822824
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 827 [0/90000 (0%)]	Loss: 11.7094	Cost: 24.76s
Train Epoch: 827 [20480/90000 (23%)]	Loss: 7.2881	Cost: 6.11s
Train Epoch: 827 [40960/90000 (45%)]	Loss: 7.1279	Cost: 7.06s
Train Epoch: 827 [61440/90000 (68%)]	Loss: 7.2396	Cost: 5.97s
Train Epoch: 827 [81920/90000 (91%)]	Loss: 7.4125	Cost: 6.42s
Train Epoch: 827 	Average Loss: 7.6008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8799

Learning rate: 0.00019996625135511347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 828 [0/90000 (0%)]	Loss: 11.3782	Cost: 24.21s
Train Epoch: 828 [20480/90000 (23%)]	Loss: 7.2964	Cost: 5.95s
Train Epoch: 828 [40960/90000 (45%)]	Loss: 7.2312	Cost: 7.09s
Train Epoch: 828 [61440/90000 (68%)]	Loss: 7.1778	Cost: 6.08s
Train Epoch: 828 [81920/90000 (91%)]	Loss: 7.4190	Cost: 6.13s
Train Epoch: 828 	Average Loss: 7.5836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8159

Learning rate: 0.000199966169693336
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 829 [0/90000 (0%)]	Loss: 11.3174	Cost: 26.99s
Train Epoch: 829 [20480/90000 (23%)]	Loss: 7.1573	Cost: 6.09s
Train Epoch: 829 [40960/90000 (45%)]	Loss: 7.1599	Cost: 6.39s
Train Epoch: 829 [61440/90000 (68%)]	Loss: 7.1409	Cost: 6.39s
Train Epoch: 829 [81920/90000 (91%)]	Loss: 7.1320	Cost: 5.77s
Train Epoch: 829 	Average Loss: 7.5899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9247

Learning rate: 0.00019996608793289584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 830 [0/90000 (0%)]	Loss: 11.5965	Cost: 23.89s
Train Epoch: 830 [20480/90000 (23%)]	Loss: 7.3928	Cost: 6.00s
Train Epoch: 830 [40960/90000 (45%)]	Loss: 7.2340	Cost: 7.60s
Train Epoch: 830 [61440/90000 (68%)]	Loss: 7.4990	Cost: 5.87s
Train Epoch: 830 [81920/90000 (91%)]	Loss: 7.4255	Cost: 7.53s
Train Epoch: 830 	Average Loss: 7.6221
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9981

Learning rate: 0.00019996600607379315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 831 [0/90000 (0%)]	Loss: 11.4463	Cost: 23.31s
Train Epoch: 831 [20480/90000 (23%)]	Loss: 7.3218	Cost: 6.12s
Train Epoch: 831 [40960/90000 (45%)]	Loss: 7.2686	Cost: 6.29s
Train Epoch: 831 [61440/90000 (68%)]	Loss: 7.3323	Cost: 6.03s
Train Epoch: 831 [81920/90000 (91%)]	Loss: 7.3279	Cost: 6.70s
Train Epoch: 831 	Average Loss: 7.5861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8728

Learning rate: 0.00019996592411602795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 832 [0/90000 (0%)]	Loss: 11.6059	Cost: 24.13s
Train Epoch: 832 [20480/90000 (23%)]	Loss: 7.1524	Cost: 6.25s
Train Epoch: 832 [40960/90000 (45%)]	Loss: 7.0565	Cost: 6.29s
Train Epoch: 832 [61440/90000 (68%)]	Loss: 7.3421	Cost: 6.16s
Train Epoch: 832 [81920/90000 (91%)]	Loss: 7.2293	Cost: 6.36s
Train Epoch: 832 	Average Loss: 7.5761
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0475

Learning rate: 0.00019996584205960035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 833 [0/90000 (0%)]	Loss: 11.5171	Cost: 23.75s
Train Epoch: 833 [20480/90000 (23%)]	Loss: 7.1839	Cost: 5.95s
Train Epoch: 833 [40960/90000 (45%)]	Loss: 7.1147	Cost: 6.61s
Train Epoch: 833 [61440/90000 (68%)]	Loss: 7.1261	Cost: 6.06s
Train Epoch: 833 [81920/90000 (91%)]	Loss: 7.2230	Cost: 5.74s
Train Epoch: 833 	Average Loss: 7.5203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9597

Learning rate: 0.00019996575990451038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 834 [0/90000 (0%)]	Loss: 11.6503	Cost: 27.67s
Train Epoch: 834 [20480/90000 (23%)]	Loss: 7.0685	Cost: 5.99s
Train Epoch: 834 [40960/90000 (45%)]	Loss: 7.1623	Cost: 6.61s
Train Epoch: 834 [61440/90000 (68%)]	Loss: 7.3207	Cost: 5.94s
Train Epoch: 834 [81920/90000 (91%)]	Loss: 7.1915	Cost: 5.81s
Train Epoch: 834 	Average Loss: 7.5227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9660

Learning rate: 0.00019996567765075823
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 835 [0/90000 (0%)]	Loss: 11.4341	Cost: 25.32s
Train Epoch: 835 [20480/90000 (23%)]	Loss: 7.1434	Cost: 6.05s
Train Epoch: 835 [40960/90000 (45%)]	Loss: 6.9299	Cost: 7.61s
Train Epoch: 835 [61440/90000 (68%)]	Loss: 7.3372	Cost: 5.88s
Train Epoch: 835 [81920/90000 (91%)]	Loss: 7.2147	Cost: 8.93s
Train Epoch: 835 	Average Loss: 7.4964
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8938

Learning rate: 0.00019996559529834385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 836 [0/90000 (0%)]	Loss: 11.3773	Cost: 23.46s
Train Epoch: 836 [20480/90000 (23%)]	Loss: 7.2061	Cost: 6.03s
Train Epoch: 836 [40960/90000 (45%)]	Loss: 7.0737	Cost: 6.50s
Train Epoch: 836 [61440/90000 (68%)]	Loss: 6.9968	Cost: 6.28s
Train Epoch: 836 [81920/90000 (91%)]	Loss: 7.1120	Cost: 8.06s
Train Epoch: 836 	Average Loss: 7.4976
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9118

Learning rate: 0.0001999655128472674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 837 [0/90000 (0%)]	Loss: 11.4182	Cost: 24.08s
Train Epoch: 837 [20480/90000 (23%)]	Loss: 7.2843	Cost: 6.19s
Train Epoch: 837 [40960/90000 (45%)]	Loss: 6.9618	Cost: 7.23s
Train Epoch: 837 [61440/90000 (68%)]	Loss: 7.1093	Cost: 5.99s
Train Epoch: 837 [81920/90000 (91%)]	Loss: 7.3127	Cost: 6.58s
Train Epoch: 837 	Average Loss: 7.4828
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9331

Learning rate: 0.00019996543029752892
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 838 [0/90000 (0%)]	Loss: 11.3744	Cost: 23.71s
Train Epoch: 838 [20480/90000 (23%)]	Loss: 7.1505	Cost: 5.94s
Train Epoch: 838 [40960/90000 (45%)]	Loss: 7.1466	Cost: 6.21s
Train Epoch: 838 [61440/90000 (68%)]	Loss: 7.2126	Cost: 6.22s
Train Epoch: 838 [81920/90000 (91%)]	Loss: 7.0476	Cost: 7.14s
Train Epoch: 838 	Average Loss: 7.4742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0549

Learning rate: 0.00019996534764912853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 839 [0/90000 (0%)]	Loss: 11.6712	Cost: 29.44s
Train Epoch: 839 [20480/90000 (23%)]	Loss: 7.1996	Cost: 6.07s
Train Epoch: 839 [40960/90000 (45%)]	Loss: 7.0786	Cost: 6.93s
Train Epoch: 839 [61440/90000 (68%)]	Loss: 7.1810	Cost: 6.17s
Train Epoch: 839 [81920/90000 (91%)]	Loss: 7.2874	Cost: 6.24s
Train Epoch: 839 	Average Loss: 7.5241
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9379

Learning rate: 0.00019996526490206627
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 840 [0/90000 (0%)]	Loss: 11.5809	Cost: 23.40s
Train Epoch: 840 [20480/90000 (23%)]	Loss: 7.1812	Cost: 6.11s
Train Epoch: 840 [40960/90000 (45%)]	Loss: 7.1831	Cost: 7.67s
Train Epoch: 840 [61440/90000 (68%)]	Loss: 7.1808	Cost: 5.89s
Train Epoch: 840 [81920/90000 (91%)]	Loss: 7.2588	Cost: 7.65s
Train Epoch: 840 	Average Loss: 7.4770
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9714

Learning rate: 0.00019996518205634228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 841 [0/90000 (0%)]	Loss: 11.4284	Cost: 23.84s
Train Epoch: 841 [20480/90000 (23%)]	Loss: 7.2134	Cost: 6.11s
Train Epoch: 841 [40960/90000 (45%)]	Loss: 7.0596	Cost: 6.75s
Train Epoch: 841 [61440/90000 (68%)]	Loss: 7.1453	Cost: 6.26s
Train Epoch: 841 [81920/90000 (91%)]	Loss: 7.1943	Cost: 6.10s
Train Epoch: 841 	Average Loss: 7.4843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9329

Learning rate: 0.00019996509911195663
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 842 [0/90000 (0%)]	Loss: 11.6474	Cost: 23.20s
Train Epoch: 842 [20480/90000 (23%)]	Loss: 7.3270	Cost: 6.14s
Train Epoch: 842 [40960/90000 (45%)]	Loss: 7.2107	Cost: 6.45s
Train Epoch: 842 [61440/90000 (68%)]	Loss: 7.1038	Cost: 6.00s
Train Epoch: 842 [81920/90000 (91%)]	Loss: 6.9641	Cost: 5.99s
Train Epoch: 842 	Average Loss: 7.5016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0459

Learning rate: 0.00019996501606890936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 843 [0/90000 (0%)]	Loss: 11.4869	Cost: 24.22s
Train Epoch: 843 [20480/90000 (23%)]	Loss: 7.0805	Cost: 5.98s
Train Epoch: 843 [40960/90000 (45%)]	Loss: 6.9520	Cost: 7.08s
Train Epoch: 843 [61440/90000 (68%)]	Loss: 7.4565	Cost: 6.05s
Train Epoch: 843 [81920/90000 (91%)]	Loss: 7.1806	Cost: 7.01s
Train Epoch: 843 	Average Loss: 7.4675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9812

Learning rate: 0.0001999649329272006
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 844 [0/90000 (0%)]	Loss: 11.6916	Cost: 29.74s
Train Epoch: 844 [20480/90000 (23%)]	Loss: 7.3138	Cost: 6.11s
Train Epoch: 844 [40960/90000 (45%)]	Loss: 7.1935	Cost: 7.81s
Train Epoch: 844 [61440/90000 (68%)]	Loss: 7.3418	Cost: 5.95s
Train Epoch: 844 [81920/90000 (91%)]	Loss: 7.3196	Cost: 6.42s
Train Epoch: 844 	Average Loss: 7.5417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9939

Learning rate: 0.00019996484968683035
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 845 [0/90000 (0%)]	Loss: 11.5402	Cost: 26.93s
Train Epoch: 845 [20480/90000 (23%)]	Loss: 7.1544	Cost: 6.04s
Train Epoch: 845 [40960/90000 (45%)]	Loss: 6.9129	Cost: 7.42s
Train Epoch: 845 [61440/90000 (68%)]	Loss: 7.3881	Cost: 5.94s
Train Epoch: 845 [81920/90000 (91%)]	Loss: 7.3405	Cost: 7.17s
Train Epoch: 845 	Average Loss: 7.4667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0517

Learning rate: 0.0001999647663477988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 846 [0/90000 (0%)]	Loss: 11.6215	Cost: 22.85s
Train Epoch: 846 [20480/90000 (23%)]	Loss: 7.1679	Cost: 5.99s
Train Epoch: 846 [40960/90000 (45%)]	Loss: 7.1104	Cost: 6.68s
Train Epoch: 846 [61440/90000 (68%)]	Loss: 7.0571	Cost: 6.08s
Train Epoch: 846 [81920/90000 (91%)]	Loss: 7.4114	Cost: 8.93s
Train Epoch: 846 	Average Loss: 7.4793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9751

Learning rate: 0.00019996468291010595
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 847 [0/90000 (0%)]	Loss: 11.6952	Cost: 23.36s
Train Epoch: 847 [20480/90000 (23%)]	Loss: 7.1889	Cost: 6.08s
Train Epoch: 847 [40960/90000 (45%)]	Loss: 7.0362	Cost: 6.69s
Train Epoch: 847 [61440/90000 (68%)]	Loss: 6.9700	Cost: 6.37s
Train Epoch: 847 [81920/90000 (91%)]	Loss: 7.1417	Cost: 5.73s
Train Epoch: 847 	Average Loss: 7.4338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0245

Learning rate: 0.00019996459937375192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 848 [0/90000 (0%)]	Loss: 11.5439	Cost: 23.79s
Train Epoch: 848 [20480/90000 (23%)]	Loss: 6.9804	Cost: 6.02s
Train Epoch: 848 [40960/90000 (45%)]	Loss: 6.9287	Cost: 7.21s
Train Epoch: 848 [61440/90000 (68%)]	Loss: 7.1659	Cost: 6.00s
Train Epoch: 848 [81920/90000 (91%)]	Loss: 7.2161	Cost: 5.87s
Train Epoch: 848 	Average Loss: 7.4298
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9726

Learning rate: 0.00019996451573873678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 849 [0/90000 (0%)]	Loss: 11.7409	Cost: 27.52s
Train Epoch: 849 [20480/90000 (23%)]	Loss: 7.0358	Cost: 6.08s
Train Epoch: 849 [40960/90000 (45%)]	Loss: 7.1130	Cost: 7.50s
Train Epoch: 849 [61440/90000 (68%)]	Loss: 7.3182	Cost: 5.85s
Train Epoch: 849 [81920/90000 (91%)]	Loss: 7.0671	Cost: 6.24s
Train Epoch: 849 	Average Loss: 7.4188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1105

Learning rate: 0.00019996443200506062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 850 [0/90000 (0%)]	Loss: 11.7076	Cost: 26.04s
Train Epoch: 850 [20480/90000 (23%)]	Loss: 7.3184	Cost: 6.04s
Train Epoch: 850 [40960/90000 (45%)]	Loss: 6.8844	Cost: 7.35s
Train Epoch: 850 [61440/90000 (68%)]	Loss: 7.0402	Cost: 6.11s
Train Epoch: 850 [81920/90000 (91%)]	Loss: 7.0583	Cost: 6.81s
Train Epoch: 850 	Average Loss: 7.4178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0226

Learning rate: 0.00019996434817272352
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 851 [0/90000 (0%)]	Loss: 11.3741	Cost: 22.42s
Train Epoch: 851 [20480/90000 (23%)]	Loss: 6.8803	Cost: 6.16s
Train Epoch: 851 [40960/90000 (45%)]	Loss: 7.0002	Cost: 6.73s
Train Epoch: 851 [61440/90000 (68%)]	Loss: 7.0371	Cost: 6.08s
Train Epoch: 851 [81920/90000 (91%)]	Loss: 6.8815	Cost: 8.33s
Train Epoch: 851 	Average Loss: 7.3355
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1004

Learning rate: 0.00019996426424172557
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 852 [0/90000 (0%)]	Loss: 11.4898	Cost: 24.35s
Train Epoch: 852 [20480/90000 (23%)]	Loss: 7.0307	Cost: 6.22s
Train Epoch: 852 [40960/90000 (45%)]	Loss: 6.8924	Cost: 6.68s
Train Epoch: 852 [61440/90000 (68%)]	Loss: 6.9754	Cost: 6.33s
Train Epoch: 852 [81920/90000 (91%)]	Loss: 7.2040	Cost: 5.85s
Train Epoch: 852 	Average Loss: 7.3436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0221

Learning rate: 0.00019996418021206683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 853 [0/90000 (0%)]	Loss: 11.3107	Cost: 24.27s
Train Epoch: 853 [20480/90000 (23%)]	Loss: 7.0811	Cost: 6.14s
Train Epoch: 853 [40960/90000 (45%)]	Loss: 7.2553	Cost: 7.52s
Train Epoch: 853 [61440/90000 (68%)]	Loss: 7.3645	Cost: 6.36s
Train Epoch: 853 [81920/90000 (91%)]	Loss: 7.1920	Cost: 6.25s
Train Epoch: 853 	Average Loss: 7.4786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0168

Learning rate: 0.00019996409608374742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 854 [0/90000 (0%)]	Loss: 11.6183	Cost: 26.30s
Train Epoch: 854 [20480/90000 (23%)]	Loss: 7.1628	Cost: 6.01s
Train Epoch: 854 [40960/90000 (45%)]	Loss: 6.8892	Cost: 7.67s
Train Epoch: 854 [61440/90000 (68%)]	Loss: 7.1278	Cost: 5.87s
Train Epoch: 854 [81920/90000 (91%)]	Loss: 6.9590	Cost: 5.98s
Train Epoch: 854 	Average Loss: 7.4458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1106

Learning rate: 0.0001999640118567674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 855 [0/90000 (0%)]	Loss: 11.6338	Cost: 27.82s
Train Epoch: 855 [20480/90000 (23%)]	Loss: 7.1053	Cost: 6.02s
Train Epoch: 855 [40960/90000 (45%)]	Loss: 7.0548	Cost: 6.53s
Train Epoch: 855 [61440/90000 (68%)]	Loss: 7.0581	Cost: 6.30s
Train Epoch: 855 [81920/90000 (91%)]	Loss: 7.1377	Cost: 6.41s
Train Epoch: 855 	Average Loss: 7.3810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0572

Learning rate: 0.00019996392753112682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 856 [0/90000 (0%)]	Loss: 11.4560	Cost: 23.79s
Train Epoch: 856 [20480/90000 (23%)]	Loss: 7.1004	Cost: 6.03s
Train Epoch: 856 [40960/90000 (45%)]	Loss: 6.8365	Cost: 8.40s
Train Epoch: 856 [61440/90000 (68%)]	Loss: 6.8844	Cost: 6.12s
Train Epoch: 856 [81920/90000 (91%)]	Loss: 7.0300	Cost: 9.02s
Train Epoch: 856 	Average Loss: 7.3212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0634

Learning rate: 0.00019996384310682583
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 857 [0/90000 (0%)]	Loss: 11.5872	Cost: 24.12s
Train Epoch: 857 [20480/90000 (23%)]	Loss: 6.9729	Cost: 6.19s
Train Epoch: 857 [40960/90000 (45%)]	Loss: 6.9489	Cost: 6.51s
Train Epoch: 857 [61440/90000 (68%)]	Loss: 6.9452	Cost: 5.90s
Train Epoch: 857 [81920/90000 (91%)]	Loss: 7.0949	Cost: 6.01s
Train Epoch: 857 	Average Loss: 7.3262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1715

Learning rate: 0.00019996375858386448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 858 [0/90000 (0%)]	Loss: 11.6484	Cost: 23.91s
Train Epoch: 858 [20480/90000 (23%)]	Loss: 6.9380	Cost: 6.08s
Train Epoch: 858 [40960/90000 (45%)]	Loss: 6.9872	Cost: 7.75s
Train Epoch: 858 [61440/90000 (68%)]	Loss: 6.9681	Cost: 5.93s
Train Epoch: 858 [81920/90000 (91%)]	Loss: 7.0126	Cost: 6.50s
Train Epoch: 858 	Average Loss: 7.2956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1666

Learning rate: 0.00019996367396224286
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 859 [0/90000 (0%)]	Loss: 11.5500	Cost: 25.52s
Train Epoch: 859 [20480/90000 (23%)]	Loss: 7.0456	Cost: 6.23s
Train Epoch: 859 [40960/90000 (45%)]	Loss: 6.9777	Cost: 6.35s
Train Epoch: 859 [61440/90000 (68%)]	Loss: 7.0182	Cost: 6.06s
Train Epoch: 859 [81920/90000 (91%)]	Loss: 7.2374	Cost: 6.70s
Train Epoch: 859 	Average Loss: 7.3353
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1181

Learning rate: 0.00019996358924196105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 860 [0/90000 (0%)]	Loss: 11.5742	Cost: 30.61s
Train Epoch: 860 [20480/90000 (23%)]	Loss: 7.0519	Cost: 6.05s
Train Epoch: 860 [40960/90000 (45%)]	Loss: 6.8122	Cost: 7.54s
Train Epoch: 860 [61440/90000 (68%)]	Loss: 6.9077	Cost: 6.01s
Train Epoch: 860 [81920/90000 (91%)]	Loss: 7.0511	Cost: 6.95s
Train Epoch: 860 	Average Loss: 7.2632
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0827

Learning rate: 0.0001999635044230191
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 861 [0/90000 (0%)]	Loss: 11.6206	Cost: 24.98s
Train Epoch: 861 [20480/90000 (23%)]	Loss: 6.8396	Cost: 6.01s
Train Epoch: 861 [40960/90000 (45%)]	Loss: 6.8859	Cost: 7.84s
Train Epoch: 861 [61440/90000 (68%)]	Loss: 7.0712	Cost: 5.88s
Train Epoch: 861 [81920/90000 (91%)]	Loss: 6.9472	Cost: 7.28s
Train Epoch: 861 	Average Loss: 7.2982
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1361

Learning rate: 0.00019996341950541716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 862 [0/90000 (0%)]	Loss: 11.8359	Cost: 23.24s
Train Epoch: 862 [20480/90000 (23%)]	Loss: 6.9698	Cost: 5.91s
Train Epoch: 862 [40960/90000 (45%)]	Loss: 6.8221	Cost: 6.57s
Train Epoch: 862 [61440/90000 (68%)]	Loss: 6.8097	Cost: 6.11s
Train Epoch: 862 [81920/90000 (91%)]	Loss: 6.9121	Cost: 8.67s
Train Epoch: 862 	Average Loss: 7.2829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1404

Learning rate: 0.00019996333448915526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 863 [0/90000 (0%)]	Loss: 11.6693	Cost: 24.01s
Train Epoch: 863 [20480/90000 (23%)]	Loss: 6.8747	Cost: 6.04s
Train Epoch: 863 [40960/90000 (45%)]	Loss: 6.8192	Cost: 7.42s
Train Epoch: 863 [61440/90000 (68%)]	Loss: 6.8375	Cost: 6.18s
Train Epoch: 863 [81920/90000 (91%)]	Loss: 6.8695	Cost: 5.76s
Train Epoch: 863 	Average Loss: 7.2510
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1068

Learning rate: 0.0001999632493742335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 864 [0/90000 (0%)]	Loss: 11.7119	Cost: 23.23s
Train Epoch: 864 [20480/90000 (23%)]	Loss: 6.9393	Cost: 5.94s
Train Epoch: 864 [40960/90000 (45%)]	Loss: 6.8316	Cost: 6.58s
Train Epoch: 864 [61440/90000 (68%)]	Loss: 6.9167	Cost: 6.17s
Train Epoch: 864 [81920/90000 (91%)]	Loss: 6.9400	Cost: 5.75s
Train Epoch: 864 	Average Loss: 7.2376
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1201

Learning rate: 0.00019996316416065197
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 865 [0/90000 (0%)]	Loss: 11.5539	Cost: 29.31s
Train Epoch: 865 [20480/90000 (23%)]	Loss: 6.8788	Cost: 5.97s
Train Epoch: 865 [40960/90000 (45%)]	Loss: 6.9435	Cost: 7.00s
Train Epoch: 865 [61440/90000 (68%)]	Loss: 6.9006	Cost: 5.68s
Train Epoch: 865 [81920/90000 (91%)]	Loss: 6.7252	Cost: 6.91s
Train Epoch: 865 	Average Loss: 7.2693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1050

Learning rate: 0.00019996307884841076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 866 [0/90000 (0%)]	Loss: 11.7921	Cost: 27.45s
Train Epoch: 866 [20480/90000 (23%)]	Loss: 7.0262	Cost: 5.98s
Train Epoch: 866 [40960/90000 (45%)]	Loss: 6.7996	Cost: 8.12s
Train Epoch: 866 [61440/90000 (68%)]	Loss: 6.7622	Cost: 5.87s
Train Epoch: 866 [81920/90000 (91%)]	Loss: 6.8923	Cost: 7.89s
Train Epoch: 866 	Average Loss: 7.2829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1597

Learning rate: 0.00019996299343750997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 867 [0/90000 (0%)]	Loss: 11.7605	Cost: 23.26s
Train Epoch: 867 [20480/90000 (23%)]	Loss: 7.1007	Cost: 6.00s
Train Epoch: 867 [40960/90000 (45%)]	Loss: 6.9658	Cost: 7.18s
Train Epoch: 867 [61440/90000 (68%)]	Loss: 6.8235	Cost: 5.97s
Train Epoch: 867 [81920/90000 (91%)]	Loss: 6.9748	Cost: 8.66s
Train Epoch: 867 	Average Loss: 7.2862
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2093

Learning rate: 0.00019996290792794963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 868 [0/90000 (0%)]	Loss: 11.5093	Cost: 24.33s
Train Epoch: 868 [20480/90000 (23%)]	Loss: 7.1243	Cost: 6.08s
Train Epoch: 868 [40960/90000 (45%)]	Loss: 6.8359	Cost: 6.36s
Train Epoch: 868 [61440/90000 (68%)]	Loss: 6.9691	Cost: 5.93s
Train Epoch: 868 [81920/90000 (91%)]	Loss: 6.8386	Cost: 5.71s
Train Epoch: 868 	Average Loss: 7.2592
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1456

Learning rate: 0.00019996282231972984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 869 [0/90000 (0%)]	Loss: 11.7214	Cost: 23.56s
Train Epoch: 869 [20480/90000 (23%)]	Loss: 6.8700	Cost: 6.16s
Train Epoch: 869 [40960/90000 (45%)]	Loss: 6.8564	Cost: 8.40s
Train Epoch: 869 [61440/90000 (68%)]	Loss: 6.9474	Cost: 6.12s
Train Epoch: 869 [81920/90000 (91%)]	Loss: 7.0182	Cost: 6.16s
Train Epoch: 869 	Average Loss: 7.2503
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1483

Learning rate: 0.00019996273661285075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 870 [0/90000 (0%)]	Loss: 11.7302	Cost: 27.34s
Train Epoch: 870 [20480/90000 (23%)]	Loss: 6.9888	Cost: 6.01s
Train Epoch: 870 [40960/90000 (45%)]	Loss: 6.8192	Cost: 7.11s
Train Epoch: 870 [61440/90000 (68%)]	Loss: 7.0521	Cost: 5.97s
Train Epoch: 870 [81920/90000 (91%)]	Loss: 6.7025	Cost: 5.63s
Train Epoch: 870 	Average Loss: 7.2191
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1369

Learning rate: 0.00019996265080731235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 871 [0/90000 (0%)]	Loss: 11.6986	Cost: 26.48s
Train Epoch: 871 [20480/90000 (23%)]	Loss: 6.8261	Cost: 6.05s
Train Epoch: 871 [40960/90000 (45%)]	Loss: 6.6492	Cost: 9.33s
Train Epoch: 871 [61440/90000 (68%)]	Loss: 6.6103	Cost: 6.15s
Train Epoch: 871 [81920/90000 (91%)]	Loss: 6.9275	Cost: 7.77s
Train Epoch: 871 	Average Loss: 7.1623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1052

Learning rate: 0.00019996256490311477
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 872 [0/90000 (0%)]	Loss: 11.8545	Cost: 23.16s
Train Epoch: 872 [20480/90000 (23%)]	Loss: 6.7803	Cost: 6.68s
Train Epoch: 872 [40960/90000 (45%)]	Loss: 6.5881	Cost: 6.58s
Train Epoch: 872 [61440/90000 (68%)]	Loss: 6.9688	Cost: 6.03s
Train Epoch: 872 [81920/90000 (91%)]	Loss: 6.9175	Cost: 6.70s
Train Epoch: 872 	Average Loss: 7.1731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2191

Learning rate: 0.00019996247890025813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 873 [0/90000 (0%)]	Loss: 11.6605	Cost: 23.37s
Train Epoch: 873 [20480/90000 (23%)]	Loss: 6.8116	Cost: 5.99s
Train Epoch: 873 [40960/90000 (45%)]	Loss: 6.7718	Cost: 7.52s
Train Epoch: 873 [61440/90000 (68%)]	Loss: 6.8535	Cost: 6.39s
Train Epoch: 873 [81920/90000 (91%)]	Loss: 6.7844	Cost: 6.39s
Train Epoch: 873 	Average Loss: 7.1851
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1873

Learning rate: 0.00019996239279874246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 874 [0/90000 (0%)]	Loss: 11.6779	Cost: 24.06s
Train Epoch: 874 [20480/90000 (23%)]	Loss: 6.8761	Cost: 6.02s
Train Epoch: 874 [40960/90000 (45%)]	Loss: 6.6456	Cost: 7.11s
Train Epoch: 874 [61440/90000 (68%)]	Loss: 6.8348	Cost: 6.04s
Train Epoch: 874 [81920/90000 (91%)]	Loss: 6.8343	Cost: 6.20s
Train Epoch: 874 	Average Loss: 7.1985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2520

Learning rate: 0.00019996230659856786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 875 [0/90000 (0%)]	Loss: 11.8584	Cost: 27.23s
Train Epoch: 875 [20480/90000 (23%)]	Loss: 6.8207	Cost: 6.25s
Train Epoch: 875 [40960/90000 (45%)]	Loss: 6.8522	Cost: 6.56s
Train Epoch: 875 [61440/90000 (68%)]	Loss: 6.8564	Cost: 5.96s
Train Epoch: 875 [81920/90000 (91%)]	Loss: 6.6665	Cost: 5.92s
Train Epoch: 875 	Average Loss: 7.1469
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2277

Learning rate: 0.0001999622202997344
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 876 [0/90000 (0%)]	Loss: 11.7536	Cost: 24.74s
Train Epoch: 876 [20480/90000 (23%)]	Loss: 6.7789	Cost: 6.06s
Train Epoch: 876 [40960/90000 (45%)]	Loss: 6.8228	Cost: 7.91s
Train Epoch: 876 [61440/90000 (68%)]	Loss: 6.8637	Cost: 6.13s
Train Epoch: 876 [81920/90000 (91%)]	Loss: 6.6848	Cost: 7.52s
Train Epoch: 876 	Average Loss: 7.1502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2015

Learning rate: 0.0001999621339022422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 877 [0/90000 (0%)]	Loss: 11.9390	Cost: 23.63s
Train Epoch: 877 [20480/90000 (23%)]	Loss: 6.6793	Cost: 6.09s
Train Epoch: 877 [40960/90000 (45%)]	Loss: 6.8101	Cost: 6.23s
Train Epoch: 877 [61440/90000 (68%)]	Loss: 6.7322	Cost: 6.17s
Train Epoch: 877 [81920/90000 (91%)]	Loss: 6.8454	Cost: 7.20s
Train Epoch: 877 	Average Loss: 7.1646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1804

Learning rate: 0.00019996204740609135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 878 [0/90000 (0%)]	Loss: 11.8323	Cost: 23.56s
Train Epoch: 878 [20480/90000 (23%)]	Loss: 6.9348	Cost: 6.16s
Train Epoch: 878 [40960/90000 (45%)]	Loss: 6.7487	Cost: 6.59s
Train Epoch: 878 [61440/90000 (68%)]	Loss: 6.6443	Cost: 5.94s
Train Epoch: 878 [81920/90000 (91%)]	Loss: 6.8696	Cost: 6.06s
Train Epoch: 878 	Average Loss: 7.1647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2438

Learning rate: 0.0001999619608112819
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 879 [0/90000 (0%)]	Loss: 11.7063	Cost: 24.10s
Train Epoch: 879 [20480/90000 (23%)]	Loss: 6.7955	Cost: 6.21s
Train Epoch: 879 [40960/90000 (45%)]	Loss: 6.7558	Cost: 6.37s
Train Epoch: 879 [61440/90000 (68%)]	Loss: 6.8779	Cost: 6.06s
Train Epoch: 879 [81920/90000 (91%)]	Loss: 6.8536	Cost: 6.31s
Train Epoch: 879 	Average Loss: 7.1408
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1739

Learning rate: 0.00019996187411781396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 880 [0/90000 (0%)]	Loss: 11.8837	Cost: 28.92s
Train Epoch: 880 [20480/90000 (23%)]	Loss: 6.9226	Cost: 6.08s
Train Epoch: 880 [40960/90000 (45%)]	Loss: 6.8282	Cost: 7.80s
Train Epoch: 880 [61440/90000 (68%)]	Loss: 6.7392	Cost: 6.05s
Train Epoch: 880 [81920/90000 (91%)]	Loss: 6.8873	Cost: 6.03s
Train Epoch: 880 	Average Loss: 7.1713
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2639

Learning rate: 0.00019996178732568757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 881 [0/90000 (0%)]	Loss: 11.8200	Cost: 24.92s
Train Epoch: 881 [20480/90000 (23%)]	Loss: 6.6880	Cost: 6.00s
Train Epoch: 881 [40960/90000 (45%)]	Loss: 6.6672	Cost: 8.29s
Train Epoch: 881 [61440/90000 (68%)]	Loss: 6.6469	Cost: 5.88s
Train Epoch: 881 [81920/90000 (91%)]	Loss: 6.7977	Cost: 8.19s
Train Epoch: 881 	Average Loss: 7.1063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2745

Learning rate: 0.00019996170043490283
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 882 [0/90000 (0%)]	Loss: 11.7551	Cost: 24.72s
Train Epoch: 882 [20480/90000 (23%)]	Loss: 6.6319	Cost: 5.98s
Train Epoch: 882 [40960/90000 (45%)]	Loss: 6.7001	Cost: 6.42s
Train Epoch: 882 [61440/90000 (68%)]	Loss: 6.5123	Cost: 5.86s
Train Epoch: 882 [81920/90000 (91%)]	Loss: 6.6785	Cost: 6.00s
Train Epoch: 882 	Average Loss: 7.0769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1926

Learning rate: 0.00019996161344545987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 883 [0/90000 (0%)]	Loss: 11.7742	Cost: 23.79s
Train Epoch: 883 [20480/90000 (23%)]	Loss: 6.8298	Cost: 6.06s
Train Epoch: 883 [40960/90000 (45%)]	Loss: 6.7398	Cost: 7.13s
Train Epoch: 883 [61440/90000 (68%)]	Loss: 6.7574	Cost: 6.07s
Train Epoch: 883 [81920/90000 (91%)]	Loss: 6.6200	Cost: 6.79s
Train Epoch: 883 	Average Loss: 7.0806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2497

Learning rate: 0.0001999615263573588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 884 [0/90000 (0%)]	Loss: 11.8233	Cost: 24.61s
Train Epoch: 884 [20480/90000 (23%)]	Loss: 6.8071	Cost: 6.28s
Train Epoch: 884 [40960/90000 (45%)]	Loss: 6.6644	Cost: 6.79s
Train Epoch: 884 [61440/90000 (68%)]	Loss: 6.6741	Cost: 6.04s
Train Epoch: 884 [81920/90000 (91%)]	Loss: 6.6932	Cost: 5.95s
Train Epoch: 884 	Average Loss: 7.1048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2656

Learning rate: 0.0001999614391705996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 885 [0/90000 (0%)]	Loss: 11.6359	Cost: 29.31s
Train Epoch: 885 [20480/90000 (23%)]	Loss: 6.7815	Cost: 5.98s
Train Epoch: 885 [40960/90000 (45%)]	Loss: 6.6954	Cost: 7.27s
Train Epoch: 885 [61440/90000 (68%)]	Loss: 6.6752	Cost: 6.09s
Train Epoch: 885 [81920/90000 (91%)]	Loss: 6.6544	Cost: 6.21s
Train Epoch: 885 	Average Loss: 7.0668
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1853

Learning rate: 0.00019996135188518242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 886 [0/90000 (0%)]	Loss: 11.4507	Cost: 24.99s
Train Epoch: 886 [20480/90000 (23%)]	Loss: 6.6646	Cost: 6.01s
Train Epoch: 886 [40960/90000 (45%)]	Loss: 6.7096	Cost: 8.88s
Train Epoch: 886 [61440/90000 (68%)]	Loss: 6.7718	Cost: 6.07s
Train Epoch: 886 [81920/90000 (91%)]	Loss: 6.7215	Cost: 8.33s
Train Epoch: 886 	Average Loss: 7.0792
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2649

Learning rate: 0.00019996126450110731
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 887 [0/90000 (0%)]	Loss: 11.7993	Cost: 23.79s
Train Epoch: 887 [20480/90000 (23%)]	Loss: 6.6315	Cost: 6.19s
Train Epoch: 887 [40960/90000 (45%)]	Loss: 6.5060	Cost: 6.46s
Train Epoch: 887 [61440/90000 (68%)]	Loss: 6.6105	Cost: 6.05s
Train Epoch: 887 [81920/90000 (91%)]	Loss: 6.5506	Cost: 6.40s
Train Epoch: 887 	Average Loss: 7.0741
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1850

Learning rate: 0.00019996117701837445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 888 [0/90000 (0%)]	Loss: 12.0593	Cost: 24.10s
Train Epoch: 888 [20480/90000 (23%)]	Loss: 6.7960	Cost: 6.06s
Train Epoch: 888 [40960/90000 (45%)]	Loss: 6.7295	Cost: 6.58s
Train Epoch: 888 [61440/90000 (68%)]	Loss: 6.6932	Cost: 5.92s
Train Epoch: 888 [81920/90000 (91%)]	Loss: 6.7540	Cost: 5.93s
Train Epoch: 888 	Average Loss: 7.0690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3627

Learning rate: 0.00019996108943698385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 889 [0/90000 (0%)]	Loss: 11.9354	Cost: 24.69s
Train Epoch: 889 [20480/90000 (23%)]	Loss: 6.6445	Cost: 6.14s
Train Epoch: 889 [40960/90000 (45%)]	Loss: 6.7178	Cost: 6.50s
Train Epoch: 889 [61440/90000 (68%)]	Loss: 6.6252	Cost: 6.05s
Train Epoch: 889 [81920/90000 (91%)]	Loss: 6.8381	Cost: 5.93s
Train Epoch: 889 	Average Loss: 7.0609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2323

Learning rate: 0.0001999610017569356
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 890 [0/90000 (0%)]	Loss: 11.9303	Cost: 30.41s
Train Epoch: 890 [20480/90000 (23%)]	Loss: 6.8386	Cost: 6.19s
Train Epoch: 890 [40960/90000 (45%)]	Loss: 6.6831	Cost: 8.19s
Train Epoch: 890 [61440/90000 (68%)]	Loss: 6.6429	Cost: 6.26s
Train Epoch: 890 [81920/90000 (91%)]	Loss: 6.6143	Cost: 6.06s
Train Epoch: 890 	Average Loss: 7.0647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3108

Learning rate: 0.0001999609139782298
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 891 [0/90000 (0%)]	Loss: 11.9288	Cost: 24.30s
Train Epoch: 891 [20480/90000 (23%)]	Loss: 6.4798	Cost: 6.01s
Train Epoch: 891 [40960/90000 (45%)]	Loss: 6.5729	Cost: 8.30s
Train Epoch: 891 [61440/90000 (68%)]	Loss: 6.6685	Cost: 5.89s
Train Epoch: 891 [81920/90000 (91%)]	Loss: 6.6957	Cost: 8.13s
Train Epoch: 891 	Average Loss: 7.0043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2576

Learning rate: 0.0001999608261008665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 892 [0/90000 (0%)]	Loss: 11.9469	Cost: 24.20s
Train Epoch: 892 [20480/90000 (23%)]	Loss: 6.7702	Cost: 5.98s
Train Epoch: 892 [40960/90000 (45%)]	Loss: 6.5267	Cost: 6.39s
Train Epoch: 892 [61440/90000 (68%)]	Loss: 6.6170	Cost: 6.01s
Train Epoch: 892 [81920/90000 (91%)]	Loss: 6.6133	Cost: 5.87s
Train Epoch: 892 	Average Loss: 7.0337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3741

Learning rate: 0.00019996073812484586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 893 [0/90000 (0%)]	Loss: 11.7095	Cost: 22.98s
Train Epoch: 893 [20480/90000 (23%)]	Loss: 6.8334	Cost: 6.49s
Train Epoch: 893 [40960/90000 (45%)]	Loss: 6.7083	Cost: 6.44s
Train Epoch: 893 [61440/90000 (68%)]	Loss: 6.5200	Cost: 6.42s
Train Epoch: 893 [81920/90000 (91%)]	Loss: 6.6524	Cost: 6.26s
Train Epoch: 893 	Average Loss: 7.0693
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3625

Learning rate: 0.0001999606500501679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 894 [0/90000 (0%)]	Loss: 11.7932	Cost: 25.38s
Train Epoch: 894 [20480/90000 (23%)]	Loss: 6.6809	Cost: 6.12s
Train Epoch: 894 [40960/90000 (45%)]	Loss: 6.6436	Cost: 7.04s
Train Epoch: 894 [61440/90000 (68%)]	Loss: 6.5567	Cost: 6.06s
Train Epoch: 894 [81920/90000 (91%)]	Loss: 6.7530	Cost: 6.59s
Train Epoch: 894 	Average Loss: 7.0411
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2537

Learning rate: 0.00019996056187683277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 895 [0/90000 (0%)]	Loss: 11.7843	Cost: 28.62s
Train Epoch: 895 [20480/90000 (23%)]	Loss: 6.6969	Cost: 5.99s
Train Epoch: 895 [40960/90000 (45%)]	Loss: 6.5980	Cost: 6.87s
Train Epoch: 895 [61440/90000 (68%)]	Loss: 6.5718	Cost: 6.13s
Train Epoch: 895 [81920/90000 (91%)]	Loss: 6.6501	Cost: 5.75s
Train Epoch: 895 	Average Loss: 7.0156
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2811

Learning rate: 0.0001999604736048405
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 896 [0/90000 (0%)]	Loss: 11.6104	Cost: 23.77s
Train Epoch: 896 [20480/90000 (23%)]	Loss: 6.5837	Cost: 6.04s
Train Epoch: 896 [40960/90000 (45%)]	Loss: 6.4130	Cost: 7.66s
Train Epoch: 896 [61440/90000 (68%)]	Loss: 6.3848	Cost: 5.88s
Train Epoch: 896 [81920/90000 (91%)]	Loss: 6.7514	Cost: 7.47s
Train Epoch: 896 	Average Loss: 6.9987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2674

Learning rate: 0.00019996038523419118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 897 [0/90000 (0%)]	Loss: 11.9700	Cost: 23.69s
Train Epoch: 897 [20480/90000 (23%)]	Loss: 6.7225	Cost: 6.62s
Train Epoch: 897 [40960/90000 (45%)]	Loss: 6.4801	Cost: 6.44s
Train Epoch: 897 [61440/90000 (68%)]	Loss: 6.7262	Cost: 6.04s
Train Epoch: 897 [81920/90000 (91%)]	Loss: 6.6649	Cost: 8.45s
Train Epoch: 897 	Average Loss: 7.0551
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2051

Learning rate: 0.0001999602967648849
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 898 [0/90000 (0%)]	Loss: 11.7306	Cost: 23.38s
Train Epoch: 898 [20480/90000 (23%)]	Loss: 6.6249	Cost: 6.20s
Train Epoch: 898 [40960/90000 (45%)]	Loss: 6.5637	Cost: 6.81s
Train Epoch: 898 [61440/90000 (68%)]	Loss: 6.4064	Cost: 5.96s
Train Epoch: 898 [81920/90000 (91%)]	Loss: 6.4927	Cost: 5.90s
Train Epoch: 898 	Average Loss: 6.9799
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3406

Learning rate: 0.0001999602081969218
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 899 [0/90000 (0%)]	Loss: 11.7473	Cost: 24.92s
Train Epoch: 899 [20480/90000 (23%)]	Loss: 6.4615	Cost: 6.16s
Train Epoch: 899 [40960/90000 (45%)]	Loss: 6.5306	Cost: 6.93s
Train Epoch: 899 [61440/90000 (68%)]	Loss: 6.5244	Cost: 6.04s
Train Epoch: 899 [81920/90000 (91%)]	Loss: 6.5830	Cost: 6.14s
Train Epoch: 899 	Average Loss: 6.9966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2844

Learning rate: 0.00019996011953030192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 900 [0/90000 (0%)]	Loss: 11.9555	Cost: 30.66s
Train Epoch: 900 [20480/90000 (23%)]	Loss: 6.7070	Cost: 5.98s
Train Epoch: 900 [40960/90000 (45%)]	Loss: 6.5422	Cost: 7.77s
Train Epoch: 900 [61440/90000 (68%)]	Loss: 6.8025	Cost: 5.93s
Train Epoch: 900 [81920/90000 (91%)]	Loss: 6.7427	Cost: 6.56s
Train Epoch: 900 	Average Loss: 7.0201
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2566

Learning rate: 0.00019996003076502535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 901 [0/90000 (0%)]	Loss: 11.7813	Cost: 26.81s
Train Epoch: 901 [20480/90000 (23%)]	Loss: 6.5353	Cost: 6.06s
Train Epoch: 901 [40960/90000 (45%)]	Loss: 6.5929	Cost: 7.73s
Train Epoch: 901 [61440/90000 (68%)]	Loss: 6.6569	Cost: 6.16s
Train Epoch: 901 [81920/90000 (91%)]	Loss: 6.5827	Cost: 6.87s
Train Epoch: 901 	Average Loss: 6.9821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3295

Learning rate: 0.0001999599419010922
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 902 [0/90000 (0%)]	Loss: 11.7457	Cost: 23.51s
Train Epoch: 902 [20480/90000 (23%)]	Loss: 6.5861	Cost: 6.13s
Train Epoch: 902 [40960/90000 (45%)]	Loss: 6.4455	Cost: 6.46s
Train Epoch: 902 [61440/90000 (68%)]	Loss: 6.3512	Cost: 6.25s
Train Epoch: 902 [81920/90000 (91%)]	Loss: 6.5944	Cost: 7.89s
Train Epoch: 902 	Average Loss: 6.9209
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2229

Learning rate: 0.00019995985293850256
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 903 [0/90000 (0%)]	Loss: 11.8704	Cost: 24.04s
Train Epoch: 903 [20480/90000 (23%)]	Loss: 6.7074	Cost: 6.06s
Train Epoch: 903 [40960/90000 (45%)]	Loss: 6.4670	Cost: 6.48s
Train Epoch: 903 [61440/90000 (68%)]	Loss: 6.5231	Cost: 5.97s
Train Epoch: 903 [81920/90000 (91%)]	Loss: 6.3681	Cost: 6.36s
Train Epoch: 903 	Average Loss: 6.9331
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3286

Learning rate: 0.00019995976387725647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 904 [0/90000 (0%)]	Loss: 11.7918	Cost: 24.32s
Train Epoch: 904 [20480/90000 (23%)]	Loss: 6.8393	Cost: 6.07s
Train Epoch: 904 [40960/90000 (45%)]	Loss: 6.4510	Cost: 8.41s
Train Epoch: 904 [61440/90000 (68%)]	Loss: 6.6295	Cost: 6.33s
Train Epoch: 904 [81920/90000 (91%)]	Loss: 6.5013	Cost: 6.22s
Train Epoch: 904 	Average Loss: 6.9466
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3226

Learning rate: 0.00019995967471735402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 905 [0/90000 (0%)]	Loss: 12.0930	Cost: 27.34s
Train Epoch: 905 [20480/90000 (23%)]	Loss: 6.6191	Cost: 6.00s
Train Epoch: 905 [40960/90000 (45%)]	Loss: 6.4579	Cost: 7.10s
Train Epoch: 905 [61440/90000 (68%)]	Loss: 6.4003	Cost: 6.30s
Train Epoch: 905 [81920/90000 (91%)]	Loss: 6.5811	Cost: 6.36s
Train Epoch: 905 	Average Loss: 6.9327
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2822

Learning rate: 0.00019995958545879536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 906 [0/90000 (0%)]	Loss: 11.9603	Cost: 27.60s
Train Epoch: 906 [20480/90000 (23%)]	Loss: 6.6475	Cost: 6.02s
Train Epoch: 906 [40960/90000 (45%)]	Loss: 6.5313	Cost: 7.29s
Train Epoch: 906 [61440/90000 (68%)]	Loss: 6.7051	Cost: 6.22s
Train Epoch: 906 [81920/90000 (91%)]	Loss: 6.4353	Cost: 6.35s
Train Epoch: 906 	Average Loss: 6.9838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3834

Learning rate: 0.00019995949610158054
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 907 [0/90000 (0%)]	Loss: 11.7916	Cost: 22.41s
Train Epoch: 907 [20480/90000 (23%)]	Loss: 6.8304	Cost: 6.49s
Train Epoch: 907 [40960/90000 (45%)]	Loss: 6.5788	Cost: 6.10s
Train Epoch: 907 [61440/90000 (68%)]	Loss: 6.9775	Cost: 6.01s
Train Epoch: 907 [81920/90000 (91%)]	Loss: 6.7272	Cost: 8.19s
Train Epoch: 907 	Average Loss: 7.1210
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3720

Learning rate: 0.00019995940664570966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 908 [0/90000 (0%)]	Loss: 11.8824	Cost: 24.00s
Train Epoch: 908 [20480/90000 (23%)]	Loss: 6.6196	Cost: 5.92s
Train Epoch: 908 [40960/90000 (45%)]	Loss: 6.4442	Cost: 6.93s
Train Epoch: 908 [61440/90000 (68%)]	Loss: 6.6284	Cost: 5.85s
Train Epoch: 908 [81920/90000 (91%)]	Loss: 6.7978	Cost: 6.10s
Train Epoch: 908 	Average Loss: 7.0788
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2308

Learning rate: 0.00019995931709118278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 909 [0/90000 (0%)]	Loss: 11.9187	Cost: 23.62s
Train Epoch: 909 [20480/90000 (23%)]	Loss: 6.6152	Cost: 5.98s
Train Epoch: 909 [40960/90000 (45%)]	Loss: 6.4591	Cost: 6.86s
Train Epoch: 909 [61440/90000 (68%)]	Loss: 6.6044	Cost: 6.09s
Train Epoch: 909 [81920/90000 (91%)]	Loss: 6.7338	Cost: 6.40s
Train Epoch: 909 	Average Loss: 6.9874
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3409

Learning rate: 0.00019995922743800003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 910 [0/90000 (0%)]	Loss: 11.9465	Cost: 27.41s
Train Epoch: 910 [20480/90000 (23%)]	Loss: 6.5311	Cost: 6.04s
Train Epoch: 910 [40960/90000 (45%)]	Loss: 6.3622	Cost: 7.13s
Train Epoch: 910 [61440/90000 (68%)]	Loss: 6.5195	Cost: 5.95s
Train Epoch: 910 [81920/90000 (91%)]	Loss: 6.6167	Cost: 5.74s
Train Epoch: 910 	Average Loss: 6.9458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3439

Learning rate: 0.00019995913768616145
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 911 [0/90000 (0%)]	Loss: 11.7054	Cost: 24.57s
Train Epoch: 911 [20480/90000 (23%)]	Loss: 6.4908	Cost: 6.04s
Train Epoch: 911 [40960/90000 (45%)]	Loss: 6.4107	Cost: 8.36s
Train Epoch: 911 [61440/90000 (68%)]	Loss: 6.5046	Cost: 5.88s
Train Epoch: 911 [81920/90000 (91%)]	Loss: 6.5043	Cost: 8.02s
Train Epoch: 911 	Average Loss: 6.9078
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4568

Learning rate: 0.00019995904783566716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 912 [0/90000 (0%)]	Loss: 11.7063	Cost: 24.11s
Train Epoch: 912 [20480/90000 (23%)]	Loss: 6.4389	Cost: 6.04s
Train Epoch: 912 [40960/90000 (45%)]	Loss: 6.3826	Cost: 6.25s
Train Epoch: 912 [61440/90000 (68%)]	Loss: 6.4690	Cost: 6.32s
Train Epoch: 912 [81920/90000 (91%)]	Loss: 6.5273	Cost: 8.54s
Train Epoch: 912 	Average Loss: 6.8692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3780

Learning rate: 0.00019995895788651726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 913 [0/90000 (0%)]	Loss: 11.8438	Cost: 23.49s
Train Epoch: 913 [20480/90000 (23%)]	Loss: 6.5323	Cost: 6.10s
Train Epoch: 913 [40960/90000 (45%)]	Loss: 6.4277	Cost: 7.67s
Train Epoch: 913 [61440/90000 (68%)]	Loss: 6.5233	Cost: 5.98s
Train Epoch: 913 [81920/90000 (91%)]	Loss: 6.5778	Cost: 6.03s
Train Epoch: 913 	Average Loss: 6.8990
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3832

Learning rate: 0.00019995886783871183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 914 [0/90000 (0%)]	Loss: 11.8900	Cost: 24.77s
Train Epoch: 914 [20480/90000 (23%)]	Loss: 6.5351	Cost: 6.00s
Train Epoch: 914 [40960/90000 (45%)]	Loss: 6.6148	Cost: 6.95s
Train Epoch: 914 [61440/90000 (68%)]	Loss: 6.5334	Cost: 6.09s
Train Epoch: 914 [81920/90000 (91%)]	Loss: 6.4647	Cost: 5.79s
Train Epoch: 914 	Average Loss: 6.9194
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3933

Learning rate: 0.00019995877769225096
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 915 [0/90000 (0%)]	Loss: 11.9264	Cost: 29.72s
Train Epoch: 915 [20480/90000 (23%)]	Loss: 6.5273	Cost: 6.08s
Train Epoch: 915 [40960/90000 (45%)]	Loss: 6.6286	Cost: 7.13s
Train Epoch: 915 [61440/90000 (68%)]	Loss: 6.4468	Cost: 6.34s
Train Epoch: 915 [81920/90000 (91%)]	Loss: 6.4615	Cost: 6.21s
Train Epoch: 915 	Average Loss: 6.8953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2854

Learning rate: 0.0001999586874471347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 916 [0/90000 (0%)]	Loss: 11.9813	Cost: 26.15s
Train Epoch: 916 [20480/90000 (23%)]	Loss: 6.4667	Cost: 6.01s
Train Epoch: 916 [40960/90000 (45%)]	Loss: 6.3491	Cost: 7.98s
Train Epoch: 916 [61440/90000 (68%)]	Loss: 6.3403	Cost: 6.14s
Train Epoch: 916 [81920/90000 (91%)]	Loss: 6.5455	Cost: 7.25s
Train Epoch: 916 	Average Loss: 6.8700
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3831

Learning rate: 0.00019995859710336317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 917 [0/90000 (0%)]	Loss: 11.9133	Cost: 24.10s
Train Epoch: 917 [20480/90000 (23%)]	Loss: 6.7226	Cost: 6.03s
Train Epoch: 917 [40960/90000 (45%)]	Loss: 6.6759	Cost: 6.31s
Train Epoch: 917 [61440/90000 (68%)]	Loss: 6.6453	Cost: 6.18s
Train Epoch: 917 [81920/90000 (91%)]	Loss: 6.6987	Cost: 7.60s
Train Epoch: 917 	Average Loss: 7.1069
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3839

Learning rate: 0.00019995850666093646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 918 [0/90000 (0%)]	Loss: 11.8201	Cost: 24.26s
Train Epoch: 918 [20480/90000 (23%)]	Loss: 6.6404	Cost: 6.04s
Train Epoch: 918 [40960/90000 (45%)]	Loss: 6.6303	Cost: 6.66s
Train Epoch: 918 [61440/90000 (68%)]	Loss: 6.5455	Cost: 6.01s
Train Epoch: 918 [81920/90000 (91%)]	Loss: 6.4992	Cost: 6.74s
Train Epoch: 918 	Average Loss: 6.9354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3668

Learning rate: 0.0001999584161198547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 919 [0/90000 (0%)]	Loss: 11.8208	Cost: 23.07s
Train Epoch: 919 [20480/90000 (23%)]	Loss: 6.4495	Cost: 5.96s
Train Epoch: 919 [40960/90000 (45%)]	Loss: 6.5365	Cost: 6.43s
Train Epoch: 919 [61440/90000 (68%)]	Loss: 6.7963	Cost: 5.94s
Train Epoch: 919 [81920/90000 (91%)]	Loss: 6.6119	Cost: 5.60s
Train Epoch: 919 	Average Loss: 7.0198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3478

Learning rate: 0.0001999583254801179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 920 [0/90000 (0%)]	Loss: 11.6671	Cost: 26.90s
Train Epoch: 920 [20480/90000 (23%)]	Loss: 6.6002	Cost: 6.05s
Train Epoch: 920 [40960/90000 (45%)]	Loss: 6.5317	Cost: 6.84s
Train Epoch: 920 [61440/90000 (68%)]	Loss: 6.5139	Cost: 6.04s
Train Epoch: 920 [81920/90000 (91%)]	Loss: 6.3127	Cost: 6.07s
Train Epoch: 920 	Average Loss: 6.9000
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2964

Learning rate: 0.0001999582347417262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 921 [0/90000 (0%)]	Loss: 11.7845	Cost: 24.36s
Train Epoch: 921 [20480/90000 (23%)]	Loss: 6.5585	Cost: 6.02s
Train Epoch: 921 [40960/90000 (45%)]	Loss: 6.3902	Cost: 8.08s
Train Epoch: 921 [61440/90000 (68%)]	Loss: 6.3293	Cost: 5.95s
Train Epoch: 921 [81920/90000 (91%)]	Loss: 6.4901	Cost: 7.58s
Train Epoch: 921 	Average Loss: 6.8426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3877

Learning rate: 0.00019995814390467965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 922 [0/90000 (0%)]	Loss: 11.9896	Cost: 23.06s
Train Epoch: 922 [20480/90000 (23%)]	Loss: 6.3873	Cost: 5.95s
Train Epoch: 922 [40960/90000 (45%)]	Loss: 6.4011	Cost: 6.39s
Train Epoch: 922 [61440/90000 (68%)]	Loss: 6.4017	Cost: 6.32s
Train Epoch: 922 [81920/90000 (91%)]	Loss: 6.2900	Cost: 8.52s
Train Epoch: 922 	Average Loss: 6.7972
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3121

Learning rate: 0.00019995805296897838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 923 [0/90000 (0%)]	Loss: 11.8414	Cost: 24.49s
Train Epoch: 923 [20480/90000 (23%)]	Loss: 6.4593	Cost: 5.99s
Train Epoch: 923 [40960/90000 (45%)]	Loss: 6.3462	Cost: 6.30s
Train Epoch: 923 [61440/90000 (68%)]	Loss: 6.4916	Cost: 5.99s
Train Epoch: 923 [81920/90000 (91%)]	Loss: 6.3067	Cost: 5.78s
Train Epoch: 923 	Average Loss: 6.7735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3878

Learning rate: 0.00019995796193462246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 924 [0/90000 (0%)]	Loss: 11.7795	Cost: 23.50s
Train Epoch: 924 [20480/90000 (23%)]	Loss: 6.2611	Cost: 6.02s
Train Epoch: 924 [40960/90000 (45%)]	Loss: 6.3532	Cost: 6.37s
Train Epoch: 924 [61440/90000 (68%)]	Loss: 6.3152	Cost: 6.11s
Train Epoch: 924 [81920/90000 (91%)]	Loss: 6.3939	Cost: 5.88s
Train Epoch: 924 	Average Loss: 6.7414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4242

Learning rate: 0.000199957870801612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 925 [0/90000 (0%)]	Loss: 11.7732	Cost: 27.88s
Train Epoch: 925 [20480/90000 (23%)]	Loss: 6.5439	Cost: 6.06s
Train Epoch: 925 [40960/90000 (45%)]	Loss: 6.5284	Cost: 6.60s
Train Epoch: 925 [61440/90000 (68%)]	Loss: 6.6004	Cost: 6.01s
Train Epoch: 925 [81920/90000 (91%)]	Loss: 6.5595	Cost: 5.73s
Train Epoch: 925 	Average Loss: 6.8778
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7599

Learning rate: 0.00019995777956994707
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 926 [0/90000 (0%)]	Loss: 12.2787	Cost: 25.98s
Train Epoch: 926 [20480/90000 (23%)]	Loss: 7.0519	Cost: 6.06s
Train Epoch: 926 [40960/90000 (45%)]	Loss: 6.7886	Cost: 9.37s
Train Epoch: 926 [61440/90000 (68%)]	Loss: 6.6573	Cost: 5.87s
Train Epoch: 926 [81920/90000 (91%)]	Loss: 6.5280	Cost: 7.50s
Train Epoch: 926 	Average Loss: 7.1653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5462

Learning rate: 0.0001999576882396278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 927 [0/90000 (0%)]	Loss: 11.8793	Cost: 23.81s
Train Epoch: 927 [20480/90000 (23%)]	Loss: 6.7186	Cost: 5.98s
Train Epoch: 927 [40960/90000 (45%)]	Loss: 6.5191	Cost: 6.66s
Train Epoch: 927 [61440/90000 (68%)]	Loss: 6.2618	Cost: 6.00s
Train Epoch: 927 [81920/90000 (91%)]	Loss: 6.4548	Cost: 9.10s
Train Epoch: 927 	Average Loss: 6.8791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4379

Learning rate: 0.00019995759681065418
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 928 [0/90000 (0%)]	Loss: 12.0116	Cost: 23.82s
Train Epoch: 928 [20480/90000 (23%)]	Loss: 6.2222	Cost: 5.92s
Train Epoch: 928 [40960/90000 (45%)]	Loss: 6.2962	Cost: 7.92s
Train Epoch: 928 [61440/90000 (68%)]	Loss: 6.2290	Cost: 5.88s
Train Epoch: 928 [81920/90000 (91%)]	Loss: 6.3042	Cost: 6.31s
Train Epoch: 928 	Average Loss: 6.7554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4760

Learning rate: 0.0001999575052830264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 929 [0/90000 (0%)]	Loss: 11.9357	Cost: 23.56s
Train Epoch: 929 [20480/90000 (23%)]	Loss: 6.3418	Cost: 6.15s
Train Epoch: 929 [40960/90000 (45%)]	Loss: 6.4887	Cost: 7.60s
Train Epoch: 929 [61440/90000 (68%)]	Loss: 6.3179	Cost: 6.03s
Train Epoch: 929 [81920/90000 (91%)]	Loss: 6.2885	Cost: 7.57s
Train Epoch: 929 	Average Loss: 6.7839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3885

Learning rate: 0.0001999574136567445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 930 [0/90000 (0%)]	Loss: 12.1740	Cost: 25.56s
Train Epoch: 930 [20480/90000 (23%)]	Loss: 6.4351	Cost: 6.11s
Train Epoch: 930 [40960/90000 (45%)]	Loss: 6.3329	Cost: 6.57s
Train Epoch: 930 [61440/90000 (68%)]	Loss: 6.3033	Cost: 6.03s
Train Epoch: 930 [81920/90000 (91%)]	Loss: 6.3454	Cost: 5.93s
Train Epoch: 930 	Average Loss: 6.7097
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4030

Learning rate: 0.00019995732193180861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 931 [0/90000 (0%)]	Loss: 11.7217	Cost: 26.83s
Train Epoch: 931 [20480/90000 (23%)]	Loss: 6.4221	Cost: 6.01s
Train Epoch: 931 [40960/90000 (45%)]	Loss: 6.2475	Cost: 8.47s
Train Epoch: 931 [61440/90000 (68%)]	Loss: 6.2044	Cost: 6.14s
Train Epoch: 931 [81920/90000 (91%)]	Loss: 6.4829	Cost: 7.25s
Train Epoch: 931 	Average Loss: 6.6879
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4753

Learning rate: 0.00019995723010821879
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 932 [0/90000 (0%)]	Loss: 12.0448	Cost: 22.86s
Train Epoch: 932 [20480/90000 (23%)]	Loss: 6.4813	Cost: 6.06s
Train Epoch: 932 [40960/90000 (45%)]	Loss: 6.4070	Cost: 6.77s
Train Epoch: 932 [61440/90000 (68%)]	Loss: 6.2794	Cost: 6.02s
Train Epoch: 932 [81920/90000 (91%)]	Loss: 6.4869	Cost: 8.92s
Train Epoch: 932 	Average Loss: 6.7720
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4672

Learning rate: 0.00019995713818597515
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 933 [0/90000 (0%)]	Loss: 11.8791	Cost: 25.05s
Train Epoch: 933 [20480/90000 (23%)]	Loss: 6.4948	Cost: 6.05s
Train Epoch: 933 [40960/90000 (45%)]	Loss: 6.2745	Cost: 7.35s
Train Epoch: 933 [61440/90000 (68%)]	Loss: 6.3003	Cost: 5.83s
Train Epoch: 933 [81920/90000 (91%)]	Loss: 6.2509	Cost: 5.99s
Train Epoch: 933 	Average Loss: 6.6868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4469

Learning rate: 0.00019995704616507777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 934 [0/90000 (0%)]	Loss: 11.9874	Cost: 23.87s
Train Epoch: 934 [20480/90000 (23%)]	Loss: 6.4572	Cost: 6.15s
Train Epoch: 934 [40960/90000 (45%)]	Loss: 6.3013	Cost: 6.83s
Train Epoch: 934 [61440/90000 (68%)]	Loss: 6.3136	Cost: 6.12s
Train Epoch: 934 [81920/90000 (91%)]	Loss: 6.1909	Cost: 5.79s
Train Epoch: 934 	Average Loss: 6.7066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4220

Learning rate: 0.0001999569540455267
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 935 [0/90000 (0%)]	Loss: 11.9453	Cost: 26.12s
Train Epoch: 935 [20480/90000 (23%)]	Loss: 6.3128	Cost: 6.07s
Train Epoch: 935 [40960/90000 (45%)]	Loss: 6.3478	Cost: 6.77s
Train Epoch: 935 [61440/90000 (68%)]	Loss: 6.3524	Cost: 5.86s
Train Epoch: 935 [81920/90000 (91%)]	Loss: 6.3591	Cost: 5.99s
Train Epoch: 935 	Average Loss: 6.7238
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4107

Learning rate: 0.0001999568618273221
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 936 [0/90000 (0%)]	Loss: 11.6407	Cost: 29.34s
Train Epoch: 936 [20480/90000 (23%)]	Loss: 6.3948	Cost: 6.00s
Train Epoch: 936 [40960/90000 (45%)]	Loss: 6.1570	Cost: 8.90s
Train Epoch: 936 [61440/90000 (68%)]	Loss: 6.0912	Cost: 5.91s
Train Epoch: 936 [81920/90000 (91%)]	Loss: 6.2361	Cost: 6.71s
Train Epoch: 936 	Average Loss: 6.6758
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4740

Learning rate: 0.00019995676951046402
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 937 [0/90000 (0%)]	Loss: 11.9750	Cost: 24.32s
Train Epoch: 937 [20480/90000 (23%)]	Loss: 6.3139	Cost: 6.04s
Train Epoch: 937 [40960/90000 (45%)]	Loss: 6.1460	Cost: 7.68s
Train Epoch: 937 [61440/90000 (68%)]	Loss: 6.2219	Cost: 5.91s
Train Epoch: 937 [81920/90000 (91%)]	Loss: 6.1294	Cost: 7.93s
Train Epoch: 937 	Average Loss: 6.6674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4894

Learning rate: 0.00019995667709495258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 938 [0/90000 (0%)]	Loss: 11.9469	Cost: 23.75s
Train Epoch: 938 [20480/90000 (23%)]	Loss: 6.1109	Cost: 6.01s
Train Epoch: 938 [40960/90000 (45%)]	Loss: 6.1923	Cost: 6.27s
Train Epoch: 938 [61440/90000 (68%)]	Loss: 6.3220	Cost: 5.98s
Train Epoch: 938 [81920/90000 (91%)]	Loss: 6.4635	Cost: 6.13s
Train Epoch: 938 	Average Loss: 6.6795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4665

Learning rate: 0.00019995658458078785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 939 [0/90000 (0%)]	Loss: 11.9838	Cost: 23.93s
Train Epoch: 939 [20480/90000 (23%)]	Loss: 6.4983	Cost: 6.10s
Train Epoch: 939 [40960/90000 (45%)]	Loss: 6.4088	Cost: 7.19s
Train Epoch: 939 [61440/90000 (68%)]	Loss: 6.2164	Cost: 5.96s
Train Epoch: 939 [81920/90000 (91%)]	Loss: 6.2209	Cost: 6.17s
Train Epoch: 939 	Average Loss: 6.7490
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4249

Learning rate: 0.0001999564919679699
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 940 [0/90000 (0%)]	Loss: 12.0415	Cost: 25.28s
Train Epoch: 940 [20480/90000 (23%)]	Loss: 6.3164	Cost: 6.10s
Train Epoch: 940 [40960/90000 (45%)]	Loss: 6.3580	Cost: 6.50s
Train Epoch: 940 [61440/90000 (68%)]	Loss: 6.0654	Cost: 6.38s
Train Epoch: 940 [81920/90000 (91%)]	Loss: 6.2641	Cost: 6.03s
Train Epoch: 940 	Average Loss: 6.6879
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3920

Learning rate: 0.00019995639925649887
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 941 [0/90000 (0%)]	Loss: 12.0448	Cost: 27.90s
Train Epoch: 941 [20480/90000 (23%)]	Loss: 6.2284	Cost: 6.03s
Train Epoch: 941 [40960/90000 (45%)]	Loss: 6.1725	Cost: 6.76s
Train Epoch: 941 [61440/90000 (68%)]	Loss: 6.2340	Cost: 6.16s
Train Epoch: 941 [81920/90000 (91%)]	Loss: 6.2734	Cost: 6.26s
Train Epoch: 941 	Average Loss: 6.6468
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4117

Learning rate: 0.00019995630644637483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 942 [0/90000 (0%)]	Loss: 12.0487	Cost: 24.83s
Train Epoch: 942 [20480/90000 (23%)]	Loss: 6.3072	Cost: 6.06s
Train Epoch: 942 [40960/90000 (45%)]	Loss: 6.0511	Cost: 7.90s
Train Epoch: 942 [61440/90000 (68%)]	Loss: 6.0055	Cost: 5.88s
Train Epoch: 942 [81920/90000 (91%)]	Loss: 6.1696	Cost: 7.51s
Train Epoch: 942 	Average Loss: 6.6422
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5326

Learning rate: 0.0001999562135375979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 943 [0/90000 (0%)]	Loss: 12.0793	Cost: 23.37s
Train Epoch: 943 [20480/90000 (23%)]	Loss: 6.2736	Cost: 6.18s
Train Epoch: 943 [40960/90000 (45%)]	Loss: 6.1056	Cost: 6.27s
Train Epoch: 943 [61440/90000 (68%)]	Loss: 6.3497	Cost: 6.22s
Train Epoch: 943 [81920/90000 (91%)]	Loss: 6.1957	Cost: 7.40s
Train Epoch: 943 	Average Loss: 6.6105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4606

Learning rate: 0.00019995612053016812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 944 [0/90000 (0%)]	Loss: 11.9455	Cost: 23.89s
Train Epoch: 944 [20480/90000 (23%)]	Loss: 6.1029	Cost: 6.26s
Train Epoch: 944 [40960/90000 (45%)]	Loss: 6.0498	Cost: 7.25s
Train Epoch: 944 [61440/90000 (68%)]	Loss: 5.9673	Cost: 5.98s
Train Epoch: 944 [81920/90000 (91%)]	Loss: 6.2683	Cost: 6.39s
Train Epoch: 944 	Average Loss: 6.5650
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5892

Learning rate: 0.0001999560274240856
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 945 [0/90000 (0%)]	Loss: 11.9886	Cost: 23.47s
Train Epoch: 945 [20480/90000 (23%)]	Loss: 6.2036	Cost: 6.19s
Train Epoch: 945 [40960/90000 (45%)]	Loss: 6.0550	Cost: 7.78s
Train Epoch: 945 [61440/90000 (68%)]	Loss: 6.1322	Cost: 5.92s
Train Epoch: 945 [81920/90000 (91%)]	Loss: 6.1385	Cost: 6.43s
Train Epoch: 945 	Average Loss: 6.5923
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5326

Learning rate: 0.00019995593421935043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 946 [0/90000 (0%)]	Loss: 12.3345	Cost: 27.08s
Train Epoch: 946 [20480/90000 (23%)]	Loss: 6.3365	Cost: 6.26s
Train Epoch: 946 [40960/90000 (45%)]	Loss: 6.3386	Cost: 6.94s
Train Epoch: 946 [61440/90000 (68%)]	Loss: 6.2789	Cost: 5.96s
Train Epoch: 946 [81920/90000 (91%)]	Loss: 6.0308	Cost: 6.13s
Train Epoch: 946 	Average Loss: 6.6893
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5458

Learning rate: 0.00019995584091596268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 947 [0/90000 (0%)]	Loss: 12.0759	Cost: 27.36s
Train Epoch: 947 [20480/90000 (23%)]	Loss: 6.0891	Cost: 6.03s
Train Epoch: 947 [40960/90000 (45%)]	Loss: 6.1137	Cost: 7.30s
Train Epoch: 947 [61440/90000 (68%)]	Loss: 6.1063	Cost: 6.08s
Train Epoch: 947 [81920/90000 (91%)]	Loss: 6.2431	Cost: 6.53s
Train Epoch: 947 	Average Loss: 6.6085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5425

Learning rate: 0.00019995574751392248
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 948 [0/90000 (0%)]	Loss: 12.2209	Cost: 22.71s
Train Epoch: 948 [20480/90000 (23%)]	Loss: 6.0384	Cost: 6.15s
Train Epoch: 948 [40960/90000 (45%)]	Loss: 6.1227	Cost: 7.08s
Train Epoch: 948 [61440/90000 (68%)]	Loss: 6.0333	Cost: 6.37s
Train Epoch: 948 [81920/90000 (91%)]	Loss: 6.0875	Cost: 8.26s
Train Epoch: 948 	Average Loss: 6.5810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4859

Learning rate: 0.00019995565401322992
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 949 [0/90000 (0%)]	Loss: 12.1879	Cost: 24.49s
Train Epoch: 949 [20480/90000 (23%)]	Loss: 6.3052	Cost: 6.52s
Train Epoch: 949 [40960/90000 (45%)]	Loss: 6.0445	Cost: 6.36s
Train Epoch: 949 [61440/90000 (68%)]	Loss: 6.1137	Cost: 6.13s
Train Epoch: 949 [81920/90000 (91%)]	Loss: 6.1660	Cost: 5.90s
Train Epoch: 949 	Average Loss: 6.5626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5585

Learning rate: 0.00019995556041388512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 950 [0/90000 (0%)]	Loss: 12.1758	Cost: 24.50s
Train Epoch: 950 [20480/90000 (23%)]	Loss: 6.1680	Cost: 6.18s
Train Epoch: 950 [40960/90000 (45%)]	Loss: 6.0548	Cost: 6.60s
Train Epoch: 950 [61440/90000 (68%)]	Loss: 6.2776	Cost: 6.25s
Train Epoch: 950 [81920/90000 (91%)]	Loss: 6.2211	Cost: 5.96s
Train Epoch: 950 	Average Loss: 6.6288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5834

Learning rate: 0.0001999554667158881
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 951 [0/90000 (0%)]	Loss: 12.3169	Cost: 27.28s
Train Epoch: 951 [20480/90000 (23%)]	Loss: 6.3492	Cost: 6.19s
Train Epoch: 951 [40960/90000 (45%)]	Loss: 6.6554	Cost: 7.22s
Train Epoch: 951 [61440/90000 (68%)]	Loss: 6.4294	Cost: 5.96s
Train Epoch: 951 [81920/90000 (91%)]	Loss: 6.4004	Cost: 6.06s
Train Epoch: 951 	Average Loss: 6.8548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5377

Learning rate: 0.00019995537291923898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 952 [0/90000 (0%)]	Loss: 12.0712	Cost: 28.53s
Train Epoch: 952 [20480/90000 (23%)]	Loss: 6.2587	Cost: 6.14s
Train Epoch: 952 [40960/90000 (45%)]	Loss: 6.3294	Cost: 7.20s
Train Epoch: 952 [61440/90000 (68%)]	Loss: 6.4319	Cost: 6.27s
Train Epoch: 952 [81920/90000 (91%)]	Loss: 6.6044	Cost: 6.24s
Train Epoch: 952 	Average Loss: 6.7884
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5106

Learning rate: 0.00019995527902393789
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 953 [0/90000 (0%)]	Loss: 11.9084	Cost: 24.81s
Train Epoch: 953 [20480/90000 (23%)]	Loss: 6.0646	Cost: 6.08s
Train Epoch: 953 [40960/90000 (45%)]	Loss: 6.1905	Cost: 7.76s
Train Epoch: 953 [61440/90000 (68%)]	Loss: 5.9895	Cost: 5.89s
Train Epoch: 953 [81920/90000 (91%)]	Loss: 6.0906	Cost: 7.83s
Train Epoch: 953 	Average Loss: 6.6243
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4233

Learning rate: 0.00019995518502998488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 954 [0/90000 (0%)]	Loss: 12.0715	Cost: 23.59s
Train Epoch: 954 [20480/90000 (23%)]	Loss: 6.1847	Cost: 6.19s
Train Epoch: 954 [40960/90000 (45%)]	Loss: 6.0053	Cost: 6.29s
Train Epoch: 954 [61440/90000 (68%)]	Loss: 6.0244	Cost: 6.02s
Train Epoch: 954 [81920/90000 (91%)]	Loss: 6.0324	Cost: 6.38s
Train Epoch: 954 	Average Loss: 6.4909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5517

Learning rate: 0.00019995509093738005
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 955 [0/90000 (0%)]	Loss: 12.2213	Cost: 23.86s
Train Epoch: 955 [20480/90000 (23%)]	Loss: 5.9104	Cost: 6.20s
Train Epoch: 955 [40960/90000 (45%)]	Loss: 5.9717	Cost: 6.77s
Train Epoch: 955 [61440/90000 (68%)]	Loss: 6.0398	Cost: 6.05s
Train Epoch: 955 [81920/90000 (91%)]	Loss: 6.2413	Cost: 7.08s
Train Epoch: 955 	Average Loss: 6.5307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5348

Learning rate: 0.00019995499674612354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 956 [0/90000 (0%)]	Loss: 11.8523	Cost: 25.10s
Train Epoch: 956 [20480/90000 (23%)]	Loss: 6.1622	Cost: 6.11s
Train Epoch: 956 [40960/90000 (45%)]	Loss: 5.9865	Cost: 6.41s
Train Epoch: 956 [61440/90000 (68%)]	Loss: 6.0659	Cost: 5.98s
Train Epoch: 956 [81920/90000 (91%)]	Loss: 5.9911	Cost: 6.88s
Train Epoch: 956 	Average Loss: 6.5710
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6466

Learning rate: 0.00019995490245621535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 957 [0/90000 (0%)]	Loss: 12.1224	Cost: 30.11s
Train Epoch: 957 [20480/90000 (23%)]	Loss: 6.1470	Cost: 6.07s
Train Epoch: 957 [40960/90000 (45%)]	Loss: 5.9431	Cost: 8.92s
Train Epoch: 957 [61440/90000 (68%)]	Loss: 5.9706	Cost: 5.84s
Train Epoch: 957 [81920/90000 (91%)]	Loss: 6.0073	Cost: 5.78s
Train Epoch: 957 	Average Loss: 6.4642
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5900

Learning rate: 0.00019995480806765564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 958 [0/90000 (0%)]	Loss: 12.2412	Cost: 26.12s
Train Epoch: 958 [20480/90000 (23%)]	Loss: 5.9511	Cost: 6.01s
Train Epoch: 958 [40960/90000 (45%)]	Loss: 5.9653	Cost: 8.83s
Train Epoch: 958 [61440/90000 (68%)]	Loss: 5.8168	Cost: 5.90s
Train Epoch: 958 [81920/90000 (91%)]	Loss: 5.9345	Cost: 7.90s
Train Epoch: 958 	Average Loss: 6.4319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6586

Learning rate: 0.0001999547135804445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 959 [0/90000 (0%)]	Loss: 11.9321	Cost: 22.88s
Train Epoch: 959 [20480/90000 (23%)]	Loss: 5.9251	Cost: 5.91s
Train Epoch: 959 [40960/90000 (45%)]	Loss: 5.9192	Cost: 7.06s
Train Epoch: 959 [61440/90000 (68%)]	Loss: 5.7977	Cost: 5.94s
Train Epoch: 959 [81920/90000 (91%)]	Loss: 6.1158	Cost: 8.65s
Train Epoch: 959 	Average Loss: 6.3460
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5868

Learning rate: 0.000199954618994582
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 960 [0/90000 (0%)]	Loss: 12.0927	Cost: 24.97s
Train Epoch: 960 [20480/90000 (23%)]	Loss: 5.7449	Cost: 6.14s
Train Epoch: 960 [40960/90000 (45%)]	Loss: 6.0456	Cost: 6.29s
Train Epoch: 960 [61440/90000 (68%)]	Loss: 5.8524	Cost: 5.91s
Train Epoch: 960 [81920/90000 (91%)]	Loss: 6.0460	Cost: 6.17s
Train Epoch: 960 	Average Loss: 6.4090
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7480

Learning rate: 0.00019995452431006823
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 961 [0/90000 (0%)]	Loss: 12.3779	Cost: 23.11s
Train Epoch: 961 [20480/90000 (23%)]	Loss: 5.8293	Cost: 6.07s
Train Epoch: 961 [40960/90000 (45%)]	Loss: 5.9032	Cost: 7.51s
Train Epoch: 961 [61440/90000 (68%)]	Loss: 6.5776	Cost: 5.88s
Train Epoch: 961 [81920/90000 (91%)]	Loss: 6.3694	Cost: 6.30s
Train Epoch: 961 	Average Loss: 6.5598
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7074

Learning rate: 0.0001999544295269033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 962 [0/90000 (0%)]	Loss: 12.2548	Cost: 27.06s
Train Epoch: 962 [20480/90000 (23%)]	Loss: 6.0393	Cost: 6.01s
Train Epoch: 962 [40960/90000 (45%)]	Loss: 6.1350	Cost: 7.35s
Train Epoch: 962 [61440/90000 (68%)]	Loss: 5.9971	Cost: 5.96s
Train Epoch: 962 [81920/90000 (91%)]	Loss: 5.8980	Cost: 6.00s
Train Epoch: 962 	Average Loss: 6.5150
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6449

Learning rate: 0.00019995433464508735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 963 [0/90000 (0%)]	Loss: 12.2298	Cost: 26.40s
Train Epoch: 963 [20480/90000 (23%)]	Loss: 6.0028	Cost: 6.02s
Train Epoch: 963 [40960/90000 (45%)]	Loss: 5.9740	Cost: 8.59s
Train Epoch: 963 [61440/90000 (68%)]	Loss: 5.8817	Cost: 5.95s
Train Epoch: 963 [81920/90000 (91%)]	Loss: 5.9319	Cost: 7.47s
Train Epoch: 963 	Average Loss: 6.4051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6766

Learning rate: 0.0001999542396646204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 964 [0/90000 (0%)]	Loss: 12.3135	Cost: 22.03s
Train Epoch: 964 [20480/90000 (23%)]	Loss: 6.0216	Cost: 6.00s
Train Epoch: 964 [40960/90000 (45%)]	Loss: 5.9404	Cost: 7.82s
Train Epoch: 964 [61440/90000 (68%)]	Loss: 5.9640	Cost: 6.03s
Train Epoch: 964 [81920/90000 (91%)]	Loss: 5.9447	Cost: 8.99s
Train Epoch: 964 	Average Loss: 6.4296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6708

Learning rate: 0.00019995414458550255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 965 [0/90000 (0%)]	Loss: 12.3386	Cost: 23.47s
Train Epoch: 965 [20480/90000 (23%)]	Loss: 6.1607	Cost: 6.70s
Train Epoch: 965 [40960/90000 (45%)]	Loss: 5.9265	Cost: 6.43s
Train Epoch: 965 [61440/90000 (68%)]	Loss: 5.8735	Cost: 5.93s
Train Epoch: 965 [81920/90000 (91%)]	Loss: 6.0950	Cost: 5.77s
Train Epoch: 965 	Average Loss: 6.4292
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6716

Learning rate: 0.00019995404940773392
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 966 [0/90000 (0%)]	Loss: 12.1944	Cost: 24.26s
Train Epoch: 966 [20480/90000 (23%)]	Loss: 5.9634	Cost: 6.01s
Train Epoch: 966 [40960/90000 (45%)]	Loss: 5.7992	Cost: 6.12s
Train Epoch: 966 [61440/90000 (68%)]	Loss: 5.6328	Cost: 6.00s
Train Epoch: 966 [81920/90000 (91%)]	Loss: 6.2279	Cost: 5.55s
Train Epoch: 966 	Average Loss: 6.3572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7448

Learning rate: 0.00019995395413131462
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 967 [0/90000 (0%)]	Loss: 12.1655	Cost: 26.05s
Train Epoch: 967 [20480/90000 (23%)]	Loss: 5.7278	Cost: 6.02s
Train Epoch: 967 [40960/90000 (45%)]	Loss: 6.0164	Cost: 7.17s
Train Epoch: 967 [61440/90000 (68%)]	Loss: 5.8644	Cost: 5.99s
Train Epoch: 967 [81920/90000 (91%)]	Loss: 6.0989	Cost: 5.71s
Train Epoch: 967 	Average Loss: 6.3270
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6722

Learning rate: 0.00019995385875624472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 968 [0/90000 (0%)]	Loss: 11.9452	Cost: 27.47s
Train Epoch: 968 [20480/90000 (23%)]	Loss: 5.9811	Cost: 6.04s
Train Epoch: 968 [40960/90000 (45%)]	Loss: 5.9629	Cost: 6.55s
Train Epoch: 968 [61440/90000 (68%)]	Loss: 6.0976	Cost: 6.27s
Train Epoch: 968 [81920/90000 (91%)]	Loss: 5.7280	Cost: 6.09s
Train Epoch: 968 	Average Loss: 6.3701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6391

Learning rate: 0.00019995376328252426
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 969 [0/90000 (0%)]	Loss: 11.9961	Cost: 23.74s
Train Epoch: 969 [20480/90000 (23%)]	Loss: 6.0540	Cost: 6.05s
Train Epoch: 969 [40960/90000 (45%)]	Loss: 5.9342	Cost: 6.55s
Train Epoch: 969 [61440/90000 (68%)]	Loss: 5.8598	Cost: 6.03s
Train Epoch: 969 [81920/90000 (91%)]	Loss: 5.9570	Cost: 8.07s
Train Epoch: 969 	Average Loss: 6.4150
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7061

Learning rate: 0.00019995366771015345
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 970 [0/90000 (0%)]	Loss: 12.1927	Cost: 24.09s
Train Epoch: 970 [20480/90000 (23%)]	Loss: 5.8873	Cost: 5.96s
Train Epoch: 970 [40960/90000 (45%)]	Loss: 5.9443	Cost: 7.39s
Train Epoch: 970 [61440/90000 (68%)]	Loss: 5.8389	Cost: 5.76s
Train Epoch: 970 [81920/90000 (91%)]	Loss: 5.8725	Cost: 5.58s
Train Epoch: 970 	Average Loss: 6.3095
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7301

Learning rate: 0.0001999535720391323
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 971 [0/90000 (0%)]	Loss: 12.1663	Cost: 22.77s
Train Epoch: 971 [20480/90000 (23%)]	Loss: 5.9004	Cost: 6.03s
Train Epoch: 971 [40960/90000 (45%)]	Loss: 5.9424	Cost: 7.78s
Train Epoch: 971 [61440/90000 (68%)]	Loss: 6.0347	Cost: 5.97s
Train Epoch: 971 [81920/90000 (91%)]	Loss: 6.0592	Cost: 6.18s
Train Epoch: 971 	Average Loss: 6.3719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7093

Learning rate: 0.00019995347626946094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 972 [0/90000 (0%)]	Loss: 12.1512	Cost: 26.66s
Train Epoch: 972 [20480/90000 (23%)]	Loss: 5.9955	Cost: 6.18s
Train Epoch: 972 [40960/90000 (45%)]	Loss: 5.8357	Cost: 6.42s
Train Epoch: 972 [61440/90000 (68%)]	Loss: 5.8488	Cost: 6.12s
Train Epoch: 972 [81920/90000 (91%)]	Loss: 5.7991	Cost: 6.23s
Train Epoch: 972 	Average Loss: 6.3947
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6700

Learning rate: 0.00019995338040113944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 973 [0/90000 (0%)]	Loss: 12.3465	Cost: 24.27s
Train Epoch: 973 [20480/90000 (23%)]	Loss: 5.8471	Cost: 6.00s
Train Epoch: 973 [40960/90000 (45%)]	Loss: 5.6582	Cost: 7.58s
Train Epoch: 973 [61440/90000 (68%)]	Loss: 5.6379	Cost: 6.03s
Train Epoch: 973 [81920/90000 (91%)]	Loss: 5.6988	Cost: 6.61s
Train Epoch: 973 	Average Loss: 6.2805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7470

Learning rate: 0.0001999532844341679
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 974 [0/90000 (0%)]	Loss: 12.3501	Cost: 23.80s
Train Epoch: 974 [20480/90000 (23%)]	Loss: 6.0111	Cost: 6.18s
Train Epoch: 974 [40960/90000 (45%)]	Loss: 5.7510	Cost: 6.79s
Train Epoch: 974 [61440/90000 (68%)]	Loss: 5.6542	Cost: 6.17s
Train Epoch: 974 [81920/90000 (91%)]	Loss: 6.0022	Cost: 8.28s
Train Epoch: 974 	Average Loss: 6.3178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7037

Learning rate: 0.00019995318836854643
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 975 [0/90000 (0%)]	Loss: 12.1431	Cost: 25.77s
Train Epoch: 975 [20480/90000 (23%)]	Loss: 5.8142	Cost: 6.21s
Train Epoch: 975 [40960/90000 (45%)]	Loss: 5.7664	Cost: 7.14s
Train Epoch: 975 [61440/90000 (68%)]	Loss: 5.6721	Cost: 5.90s
Train Epoch: 975 [81920/90000 (91%)]	Loss: 5.8271	Cost: 5.60s
Train Epoch: 975 	Average Loss: 6.2440
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6855

Learning rate: 0.00019995309220427514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 976 [0/90000 (0%)]	Loss: 12.0415	Cost: 22.74s
Train Epoch: 976 [20480/90000 (23%)]	Loss: 5.5550	Cost: 6.15s
Train Epoch: 976 [40960/90000 (45%)]	Loss: 5.7470	Cost: 6.77s
Train Epoch: 976 [61440/90000 (68%)]	Loss: 5.5745	Cost: 6.07s
Train Epoch: 976 [81920/90000 (91%)]	Loss: 5.6010	Cost: 5.90s
Train Epoch: 976 	Average Loss: 6.1869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7460

Learning rate: 0.00019995299594135409
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 977 [0/90000 (0%)]	Loss: 12.0605	Cost: 26.38s
Train Epoch: 977 [20480/90000 (23%)]	Loss: 5.8150	Cost: 5.98s
Train Epoch: 977 [40960/90000 (45%)]	Loss: 5.7660	Cost: 6.68s
Train Epoch: 977 [61440/90000 (68%)]	Loss: 5.7070	Cost: 5.88s
Train Epoch: 977 [81920/90000 (91%)]	Loss: 5.7801	Cost: 5.74s
Train Epoch: 977 	Average Loss: 6.2564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7745

Learning rate: 0.00019995289957978334
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 978 [0/90000 (0%)]	Loss: 12.4465	Cost: 25.55s
Train Epoch: 978 [20480/90000 (23%)]	Loss: 5.9222	Cost: 5.99s
Train Epoch: 978 [40960/90000 (45%)]	Loss: 5.7581	Cost: 7.86s
Train Epoch: 978 [61440/90000 (68%)]	Loss: 5.6846	Cost: 6.12s
Train Epoch: 978 [81920/90000 (91%)]	Loss: 5.7755	Cost: 6.92s
Train Epoch: 978 	Average Loss: 6.2868
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7901

Learning rate: 0.00019995280311956308
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 979 [0/90000 (0%)]	Loss: 12.0251	Cost: 23.12s
Train Epoch: 979 [20480/90000 (23%)]	Loss: 5.8694	Cost: 5.97s
Train Epoch: 979 [40960/90000 (45%)]	Loss: 5.5496	Cost: 6.83s
Train Epoch: 979 [61440/90000 (68%)]	Loss: 5.8100	Cost: 6.09s
Train Epoch: 979 [81920/90000 (91%)]	Loss: 5.7362	Cost: 9.03s
Train Epoch: 979 	Average Loss: 6.2853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8029

Learning rate: 0.00019995270656069335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 980 [0/90000 (0%)]	Loss: 12.1996	Cost: 24.12s
Train Epoch: 980 [20480/90000 (23%)]	Loss: 5.8847	Cost: 6.13s
Train Epoch: 980 [40960/90000 (45%)]	Loss: 5.9278	Cost: 6.89s
Train Epoch: 980 [61440/90000 (68%)]	Loss: 5.6571	Cost: 6.05s
Train Epoch: 980 [81920/90000 (91%)]	Loss: 5.7192	Cost: 5.80s
Train Epoch: 980 	Average Loss: 6.2509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7029

Learning rate: 0.00019995260990317428
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 981 [0/90000 (0%)]	Loss: 12.4545	Cost: 22.83s
Train Epoch: 981 [20480/90000 (23%)]	Loss: 5.8579	Cost: 5.94s
Train Epoch: 981 [40960/90000 (45%)]	Loss: 5.7453	Cost: 6.19s
Train Epoch: 981 [61440/90000 (68%)]	Loss: 5.4915	Cost: 5.84s
Train Epoch: 981 [81920/90000 (91%)]	Loss: 5.7645	Cost: 5.55s
Train Epoch: 981 	Average Loss: 6.2586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9080

Learning rate: 0.0001999525131470059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 982 [0/90000 (0%)]	Loss: 12.2260	Cost: 27.04s
Train Epoch: 982 [20480/90000 (23%)]	Loss: 5.7711	Cost: 5.95s
Train Epoch: 982 [40960/90000 (45%)]	Loss: 5.6408	Cost: 7.45s
Train Epoch: 982 [61440/90000 (68%)]	Loss: 5.5357	Cost: 5.86s
Train Epoch: 982 [81920/90000 (91%)]	Loss: 5.6634	Cost: 5.71s
Train Epoch: 982 	Average Loss: 6.2003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7648

Learning rate: 0.00019995241629218837
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 983 [0/90000 (0%)]	Loss: 12.0662	Cost: 26.60s
Train Epoch: 983 [20480/90000 (23%)]	Loss: 5.6887	Cost: 6.04s
Train Epoch: 983 [40960/90000 (45%)]	Loss: 5.5997	Cost: 7.08s
Train Epoch: 983 [61440/90000 (68%)]	Loss: 5.4796	Cost: 6.02s
Train Epoch: 983 [81920/90000 (91%)]	Loss: 5.5099	Cost: 6.41s
Train Epoch: 983 	Average Loss: 6.1377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6727

Learning rate: 0.00019995231933872174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 984 [0/90000 (0%)]	Loss: 12.2430	Cost: 22.79s
Train Epoch: 984 [20480/90000 (23%)]	Loss: 5.4463	Cost: 6.16s
Train Epoch: 984 [40960/90000 (45%)]	Loss: 5.5364	Cost: 6.58s
Train Epoch: 984 [61440/90000 (68%)]	Loss: 5.5535	Cost: 6.10s
Train Epoch: 984 [81920/90000 (91%)]	Loss: 5.7184	Cost: 7.96s
Train Epoch: 984 	Average Loss: 6.1216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8036

Learning rate: 0.00019995222228660613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 985 [0/90000 (0%)]	Loss: 12.4323	Cost: 23.86s
Train Epoch: 985 [20480/90000 (23%)]	Loss: 5.7264	Cost: 6.01s
Train Epoch: 985 [40960/90000 (45%)]	Loss: 5.6896	Cost: 7.04s
Train Epoch: 985 [61440/90000 (68%)]	Loss: 5.5486	Cost: 5.86s
Train Epoch: 985 [81920/90000 (91%)]	Loss: 5.6776	Cost: 6.20s
Train Epoch: 985 	Average Loss: 6.2039
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8566

Learning rate: 0.00019995212513584164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 986 [0/90000 (0%)]	Loss: 12.5539	Cost: 22.95s
Train Epoch: 986 [20480/90000 (23%)]	Loss: 5.7132	Cost: 6.14s
Train Epoch: 986 [40960/90000 (45%)]	Loss: 5.6751	Cost: 7.79s
Train Epoch: 986 [61440/90000 (68%)]	Loss: 5.5793	Cost: 6.12s
Train Epoch: 986 [81920/90000 (91%)]	Loss: 5.6524	Cost: 6.02s
Train Epoch: 986 	Average Loss: 6.1770
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7714

Learning rate: 0.00019995202788642834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 987 [0/90000 (0%)]	Loss: 12.3011	Cost: 27.56s
Train Epoch: 987 [20480/90000 (23%)]	Loss: 5.6718	Cost: 5.96s
Train Epoch: 987 [40960/90000 (45%)]	Loss: 5.8064	Cost: 7.80s
Train Epoch: 987 [61440/90000 (68%)]	Loss: 5.6187	Cost: 5.85s
Train Epoch: 987 [81920/90000 (91%)]	Loss: 5.7885	Cost: 5.87s
Train Epoch: 987 	Average Loss: 6.2181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7886

Learning rate: 0.00019995193053836638
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 988 [0/90000 (0%)]	Loss: 12.4814	Cost: 26.16s
Train Epoch: 988 [20480/90000 (23%)]	Loss: 5.9135	Cost: 6.00s
Train Epoch: 988 [40960/90000 (45%)]	Loss: 5.7228	Cost: 8.98s
Train Epoch: 988 [61440/90000 (68%)]	Loss: 5.6846	Cost: 5.86s
Train Epoch: 988 [81920/90000 (91%)]	Loss: 5.5663	Cost: 8.87s
Train Epoch: 988 	Average Loss: 6.2560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7291

Learning rate: 0.0001999518330916558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 989 [0/90000 (0%)]	Loss: 12.3937	Cost: 23.16s
Train Epoch: 989 [20480/90000 (23%)]	Loss: 5.7401	Cost: 6.18s
Train Epoch: 989 [40960/90000 (45%)]	Loss: 5.6542	Cost: 6.55s
Train Epoch: 989 [61440/90000 (68%)]	Loss: 5.7637	Cost: 5.98s
Train Epoch: 989 [81920/90000 (91%)]	Loss: 5.8918	Cost: 8.81s
Train Epoch: 989 	Average Loss: 6.1876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8796

Learning rate: 0.0001999517355462967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 990 [0/90000 (0%)]	Loss: 12.3101	Cost: 23.32s
Train Epoch: 990 [20480/90000 (23%)]	Loss: 5.8166	Cost: 5.94s
Train Epoch: 990 [40960/90000 (45%)]	Loss: 5.7011	Cost: 7.00s
Train Epoch: 990 [61440/90000 (68%)]	Loss: 5.6698	Cost: 5.71s
Train Epoch: 990 [81920/90000 (91%)]	Loss: 5.6760	Cost: 5.79s
Train Epoch: 990 	Average Loss: 6.2211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8090

Learning rate: 0.00019995163790228918
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 991 [0/90000 (0%)]	Loss: 12.1857	Cost: 24.63s
Train Epoch: 991 [20480/90000 (23%)]	Loss: 5.7544	Cost: 6.00s
Train Epoch: 991 [40960/90000 (45%)]	Loss: 5.7302	Cost: 6.75s
Train Epoch: 991 [61440/90000 (68%)]	Loss: 5.8061	Cost: 5.94s
Train Epoch: 991 [81920/90000 (91%)]	Loss: 5.8496	Cost: 5.80s
Train Epoch: 991 	Average Loss: 6.2150
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7502

Learning rate: 0.00019995154015963335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 992 [0/90000 (0%)]	Loss: 12.2765	Cost: 30.31s
Train Epoch: 992 [20480/90000 (23%)]	Loss: 5.6656	Cost: 6.18s
Train Epoch: 992 [40960/90000 (45%)]	Loss: 5.8526	Cost: 8.55s
Train Epoch: 992 [61440/90000 (68%)]	Loss: 5.6367	Cost: 5.91s
Train Epoch: 992 [81920/90000 (91%)]	Loss: 5.7797	Cost: 5.71s
Train Epoch: 992 	Average Loss: 6.1867
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9388

Learning rate: 0.0001999514423183293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 993 [0/90000 (0%)]	Loss: 12.3225	Cost: 23.36s
Train Epoch: 993 [20480/90000 (23%)]	Loss: 6.4296	Cost: 6.10s
Train Epoch: 993 [40960/90000 (45%)]	Loss: 6.2989	Cost: 7.69s
Train Epoch: 993 [61440/90000 (68%)]	Loss: 6.2285	Cost: 6.15s
Train Epoch: 993 [81920/90000 (91%)]	Loss: 5.8245	Cost: 7.05s
Train Epoch: 993 	Average Loss: 6.6901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8170

Learning rate: 0.00019995134437837716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 994 [0/90000 (0%)]	Loss: 12.1974	Cost: 23.84s
Train Epoch: 994 [20480/90000 (23%)]	Loss: 6.0147	Cost: 6.00s
Train Epoch: 994 [40960/90000 (45%)]	Loss: 5.8176	Cost: 6.35s
Train Epoch: 994 [61440/90000 (68%)]	Loss: 5.9027	Cost: 6.21s
Train Epoch: 994 [81920/90000 (91%)]	Loss: 5.7683	Cost: 7.59s
Train Epoch: 994 	Average Loss: 6.3560
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7719

Learning rate: 0.000199951246339777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 995 [0/90000 (0%)]	Loss: 12.3670	Cost: 23.93s
Train Epoch: 995 [20480/90000 (23%)]	Loss: 5.6360	Cost: 6.17s
Train Epoch: 995 [40960/90000 (45%)]	Loss: 5.8446	Cost: 7.27s
Train Epoch: 995 [61440/90000 (68%)]	Loss: 5.5037	Cost: 5.83s
Train Epoch: 995 [81920/90000 (91%)]	Loss: 5.4724	Cost: 5.83s
Train Epoch: 995 	Average Loss: 6.2040
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7238

Learning rate: 0.00019995114820252889
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 996 [0/90000 (0%)]	Loss: 12.4424	Cost: 23.68s
Train Epoch: 996 [20480/90000 (23%)]	Loss: 5.6572	Cost: 6.00s
Train Epoch: 996 [40960/90000 (45%)]	Loss: 5.7275	Cost: 6.50s
Train Epoch: 996 [61440/90000 (68%)]	Loss: 5.5460	Cost: 6.14s
Train Epoch: 996 [81920/90000 (91%)]	Loss: 5.6783	Cost: 6.34s
Train Epoch: 996 	Average Loss: 6.1029
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9528

Learning rate: 0.00019995104996663296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 997 [0/90000 (0%)]	Loss: 12.5321	Cost: 28.80s
Train Epoch: 997 [20480/90000 (23%)]	Loss: 5.5934	Cost: 6.00s
Train Epoch: 997 [40960/90000 (45%)]	Loss: 5.6349	Cost: 7.34s
Train Epoch: 997 [61440/90000 (68%)]	Loss: 5.6704	Cost: 5.88s
Train Epoch: 997 [81920/90000 (91%)]	Loss: 5.5621	Cost: 5.91s
Train Epoch: 997 	Average Loss: 6.1164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8177

Learning rate: 0.00019995095163208927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 998 [0/90000 (0%)]	Loss: 12.3876	Cost: 26.16s
Train Epoch: 998 [20480/90000 (23%)]	Loss: 5.4456	Cost: 5.97s
Train Epoch: 998 [40960/90000 (45%)]	Loss: 5.6479	Cost: 7.23s
Train Epoch: 998 [61440/90000 (68%)]	Loss: 5.6382	Cost: 5.92s
Train Epoch: 998 [81920/90000 (91%)]	Loss: 5.5627	Cost: 6.89s
Train Epoch: 998 	Average Loss: 6.0623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7629

Learning rate: 0.000199950853198898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 999 [0/90000 (0%)]	Loss: 12.1412	Cost: 24.37s
Train Epoch: 999 [20480/90000 (23%)]	Loss: 5.6048	Cost: 6.07s
Train Epoch: 999 [40960/90000 (45%)]	Loss: 5.7129	Cost: 6.62s
Train Epoch: 999 [61440/90000 (68%)]	Loss: 5.5751	Cost: 6.13s
Train Epoch: 999 [81920/90000 (91%)]	Loss: 5.6648	Cost: 8.41s
Train Epoch: 999 	Average Loss: 6.1298
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8386

Learning rate: 0.00019995075466705913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1000 [0/90000 (0%)]	Loss: 12.3573	Cost: 23.80s
Train Epoch: 1000 [20480/90000 (23%)]	Loss: 5.7116	Cost: 6.16s
Train Epoch: 1000 [40960/90000 (45%)]	Loss: 5.3298	Cost: 7.28s
Train Epoch: 1000 [61440/90000 (68%)]	Loss: 5.5413	Cost: 5.94s
Train Epoch: 1000 [81920/90000 (91%)]	Loss: 5.4961	Cost: 6.36s
Train Epoch: 1000 	Average Loss: 6.0802
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7717

Learning rate: 0.00019995065603657287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1001 [0/90000 (0%)]	Loss: 12.4521	Cost: 25.50s
Train Epoch: 1001 [20480/90000 (23%)]	Loss: 5.5434	Cost: 5.98s
Train Epoch: 1001 [40960/90000 (45%)]	Loss: 5.5255	Cost: 7.30s
Train Epoch: 1001 [61440/90000 (68%)]	Loss: 5.6347	Cost: 5.98s
Train Epoch: 1001 [81920/90000 (91%)]	Loss: 5.4470	Cost: 6.05s
Train Epoch: 1001 	Average Loss: 6.0825
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8575

Learning rate: 0.00019995055730743925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1002 [0/90000 (0%)]	Loss: 12.4901	Cost: 26.74s
Train Epoch: 1002 [20480/90000 (23%)]	Loss: 5.5569	Cost: 6.15s
Train Epoch: 1002 [40960/90000 (45%)]	Loss: 5.5199	Cost: 6.63s
Train Epoch: 1002 [61440/90000 (68%)]	Loss: 5.5928	Cost: 6.05s
Train Epoch: 1002 [81920/90000 (91%)]	Loss: 5.4165	Cost: 5.73s
Train Epoch: 1002 	Average Loss: 6.0634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9466

Learning rate: 0.00019995045847965838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1003 [0/90000 (0%)]	Loss: 12.3018	Cost: 24.39s
Train Epoch: 1003 [20480/90000 (23%)]	Loss: 5.4592	Cost: 6.02s
Train Epoch: 1003 [40960/90000 (45%)]	Loss: 5.4710	Cost: 8.37s
Train Epoch: 1003 [61440/90000 (68%)]	Loss: 5.3576	Cost: 5.86s
Train Epoch: 1003 [81920/90000 (91%)]	Loss: 5.6386	Cost: 7.97s
Train Epoch: 1003 	Average Loss: 5.9954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9139

Learning rate: 0.00019995035955323038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1004 [0/90000 (0%)]	Loss: 12.4914	Cost: 23.43s
Train Epoch: 1004 [20480/90000 (23%)]	Loss: 5.5650	Cost: 5.95s
Train Epoch: 1004 [40960/90000 (45%)]	Loss: 5.4874	Cost: 6.37s
Train Epoch: 1004 [61440/90000 (68%)]	Loss: 5.3023	Cost: 6.48s
Train Epoch: 1004 [81920/90000 (91%)]	Loss: 5.6264	Cost: 6.17s
Train Epoch: 1004 	Average Loss: 6.0048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9090

Learning rate: 0.00019995026052815532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1005 [0/90000 (0%)]	Loss: 12.3069	Cost: 24.10s
Train Epoch: 1005 [20480/90000 (23%)]	Loss: 5.4278	Cost: 5.99s
Train Epoch: 1005 [40960/90000 (45%)]	Loss: 5.4281	Cost: 7.58s
Train Epoch: 1005 [61440/90000 (68%)]	Loss: 5.5330	Cost: 5.97s
Train Epoch: 1005 [81920/90000 (91%)]	Loss: 5.5503	Cost: 6.12s
Train Epoch: 1005 	Average Loss: 5.9979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8984

Learning rate: 0.00019995016140443328
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1006 [0/90000 (0%)]	Loss: 12.2290	Cost: 25.33s
Train Epoch: 1006 [20480/90000 (23%)]	Loss: 5.5076	Cost: 6.05s
Train Epoch: 1006 [40960/90000 (45%)]	Loss: 5.5505	Cost: 6.81s
Train Epoch: 1006 [61440/90000 (68%)]	Loss: 5.3986	Cost: 5.97s
Train Epoch: 1006 [81920/90000 (91%)]	Loss: 5.7194	Cost: 9.21s
Train Epoch: 1006 	Average Loss: 6.0476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0143

Learning rate: 0.0001999500621820644
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1007 [0/90000 (0%)]	Loss: 12.3475	Cost: 27.43s
Train Epoch: 1007 [20480/90000 (23%)]	Loss: 5.7291	Cost: 6.05s
Train Epoch: 1007 [40960/90000 (45%)]	Loss: 5.7145	Cost: 7.00s
Train Epoch: 1007 [61440/90000 (68%)]	Loss: 5.7422	Cost: 6.11s
Train Epoch: 1007 [81920/90000 (91%)]	Loss: 5.8487	Cost: 5.75s
Train Epoch: 1007 	Average Loss: 6.1780
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8866

Learning rate: 0.00019994996286104878
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1008 [0/90000 (0%)]	Loss: 12.3315	Cost: 23.60s
Train Epoch: 1008 [20480/90000 (23%)]	Loss: 5.9337	Cost: 6.01s
Train Epoch: 1008 [40960/90000 (45%)]	Loss: 5.5660	Cost: 7.53s
Train Epoch: 1008 [61440/90000 (68%)]	Loss: 5.5058	Cost: 6.16s
Train Epoch: 1008 [81920/90000 (91%)]	Loss: 5.5237	Cost: 7.69s
Train Epoch: 1008 	Average Loss: 6.1163
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8908

Learning rate: 0.0001999498634413865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1009 [0/90000 (0%)]	Loss: 12.5672	Cost: 23.99s
Train Epoch: 1009 [20480/90000 (23%)]	Loss: 5.3708	Cost: 6.09s
Train Epoch: 1009 [40960/90000 (45%)]	Loss: 5.5021	Cost: 6.77s
Train Epoch: 1009 [61440/90000 (68%)]	Loss: 5.3898	Cost: 6.10s
Train Epoch: 1009 [81920/90000 (91%)]	Loss: 5.5455	Cost: 8.76s
Train Epoch: 1009 	Average Loss: 5.9786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8974

Learning rate: 0.00019994976392307765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1010 [0/90000 (0%)]	Loss: 12.5295	Cost: 24.08s
Train Epoch: 1010 [20480/90000 (23%)]	Loss: 5.5213	Cost: 6.18s
Train Epoch: 1010 [40960/90000 (45%)]	Loss: 5.5576	Cost: 6.97s
Train Epoch: 1010 [61440/90000 (68%)]	Loss: 5.3454	Cost: 5.85s
Train Epoch: 1010 [81920/90000 (91%)]	Loss: 5.6640	Cost: 6.10s
Train Epoch: 1010 	Average Loss: 5.9749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9045

Learning rate: 0.00019994966430612234
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1011 [0/90000 (0%)]	Loss: 12.4507	Cost: 23.05s
Train Epoch: 1011 [20480/90000 (23%)]	Loss: 5.4874	Cost: 6.27s
Train Epoch: 1011 [40960/90000 (45%)]	Loss: 5.4881	Cost: 6.36s
Train Epoch: 1011 [61440/90000 (68%)]	Loss: 5.4238	Cost: 6.47s
Train Epoch: 1011 [81920/90000 (91%)]	Loss: 5.4100	Cost: 5.58s
Train Epoch: 1011 	Average Loss: 5.9613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9578

Learning rate: 0.00019994956459052065
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1012 [0/90000 (0%)]	Loss: 12.3980	Cost: 30.37s
Train Epoch: 1012 [20480/90000 (23%)]	Loss: 5.4940	Cost: 6.15s
Train Epoch: 1012 [40960/90000 (45%)]	Loss: 5.5317	Cost: 7.43s
Train Epoch: 1012 [61440/90000 (68%)]	Loss: 5.5249	Cost: 5.96s
Train Epoch: 1012 [81920/90000 (91%)]	Loss: 5.5058	Cost: 5.55s
Train Epoch: 1012 	Average Loss: 5.9499
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0266

Learning rate: 0.00019994946477627272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1013 [0/90000 (0%)]	Loss: 12.6941	Cost: 25.84s
Train Epoch: 1013 [20480/90000 (23%)]	Loss: 5.6873	Cost: 6.05s
Train Epoch: 1013 [40960/90000 (45%)]	Loss: 5.5273	Cost: 7.64s
Train Epoch: 1013 [61440/90000 (68%)]	Loss: 5.4177	Cost: 6.03s
Train Epoch: 1013 [81920/90000 (91%)]	Loss: 5.4865	Cost: 7.15s
Train Epoch: 1013 	Average Loss: 5.9919
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9189

Learning rate: 0.0001999493648633786
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1014 [0/90000 (0%)]	Loss: 12.3641	Cost: 23.04s
Train Epoch: 1014 [20480/90000 (23%)]	Loss: 5.4135	Cost: 6.07s
Train Epoch: 1014 [40960/90000 (45%)]	Loss: 5.3242	Cost: 6.87s
Train Epoch: 1014 [61440/90000 (68%)]	Loss: 5.4515	Cost: 6.13s
Train Epoch: 1014 [81920/90000 (91%)]	Loss: 5.3541	Cost: 8.55s
Train Epoch: 1014 	Average Loss: 5.9252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0042

Learning rate: 0.00019994926485183842
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1015 [0/90000 (0%)]	Loss: 12.3457	Cost: 23.42s
Train Epoch: 1015 [20480/90000 (23%)]	Loss: 5.5635	Cost: 6.06s
Train Epoch: 1015 [40960/90000 (45%)]	Loss: 5.4047	Cost: 7.31s
Train Epoch: 1015 [61440/90000 (68%)]	Loss: 5.3282	Cost: 5.96s
Train Epoch: 1015 [81920/90000 (91%)]	Loss: 5.5077	Cost: 6.60s
Train Epoch: 1015 	Average Loss: 5.9550
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9844

Learning rate: 0.00019994916474165228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1016 [0/90000 (0%)]	Loss: 12.2260	Cost: 23.71s
Train Epoch: 1016 [20480/90000 (23%)]	Loss: 5.3034	Cost: 5.98s
Train Epoch: 1016 [40960/90000 (45%)]	Loss: 5.4800	Cost: 6.34s
Train Epoch: 1016 [61440/90000 (68%)]	Loss: 5.4498	Cost: 6.08s
Train Epoch: 1016 [81920/90000 (91%)]	Loss: 5.4837	Cost: 6.51s
Train Epoch: 1016 	Average Loss: 5.9488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8773

Learning rate: 0.00019994906453282024
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1017 [0/90000 (0%)]	Loss: 12.4161	Cost: 29.05s
Train Epoch: 1017 [20480/90000 (23%)]	Loss: 5.4259	Cost: 6.08s
Train Epoch: 1017 [40960/90000 (45%)]	Loss: 5.3618	Cost: 7.95s
Train Epoch: 1017 [61440/90000 (68%)]	Loss: 5.3380	Cost: 5.98s
Train Epoch: 1017 [81920/90000 (91%)]	Loss: 5.3906	Cost: 7.17s
Train Epoch: 1017 	Average Loss: 5.9341
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9354

Learning rate: 0.00019994896422534245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1018 [0/90000 (0%)]	Loss: 12.7755	Cost: 24.32s
Train Epoch: 1018 [20480/90000 (23%)]	Loss: 5.3057	Cost: 6.05s
Train Epoch: 1018 [40960/90000 (45%)]	Loss: 5.4076	Cost: 8.12s
Train Epoch: 1018 [61440/90000 (68%)]	Loss: 5.4368	Cost: 5.88s
Train Epoch: 1018 [81920/90000 (91%)]	Loss: 5.3494	Cost: 8.97s
Train Epoch: 1018 	Average Loss: 5.9052
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9311

Learning rate: 0.00019994886381921899
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1019 [0/90000 (0%)]	Loss: 12.2609	Cost: 23.26s
Train Epoch: 1019 [20480/90000 (23%)]	Loss: 5.5137	Cost: 5.90s
Train Epoch: 1019 [40960/90000 (45%)]	Loss: 5.4658	Cost: 6.57s
Train Epoch: 1019 [61440/90000 (68%)]	Loss: 5.4871	Cost: 6.13s
Train Epoch: 1019 [81920/90000 (91%)]	Loss: 5.3119	Cost: 8.38s
Train Epoch: 1019 	Average Loss: 5.9421
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9231

Learning rate: 0.00019994876331444993
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1020 [0/90000 (0%)]	Loss: 12.5724	Cost: 24.20s
Train Epoch: 1020 [20480/90000 (23%)]	Loss: 5.4118	Cost: 5.96s
Train Epoch: 1020 [40960/90000 (45%)]	Loss: 5.2349	Cost: 7.38s
Train Epoch: 1020 [61440/90000 (68%)]	Loss: 5.2771	Cost: 6.08s
Train Epoch: 1020 [81920/90000 (91%)]	Loss: 5.3391	Cost: 6.14s
Train Epoch: 1020 	Average Loss: 5.9021
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9854

Learning rate: 0.0001999486627110354
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1021 [0/90000 (0%)]	Loss: 12.5415	Cost: 23.94s
Train Epoch: 1021 [20480/90000 (23%)]	Loss: 5.3940	Cost: 6.34s
Train Epoch: 1021 [40960/90000 (45%)]	Loss: 5.3278	Cost: 6.36s
Train Epoch: 1021 [61440/90000 (68%)]	Loss: 5.2188	Cost: 6.28s
Train Epoch: 1021 [81920/90000 (91%)]	Loss: 5.2777	Cost: 5.77s
Train Epoch: 1021 	Average Loss: 5.8406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9968

Learning rate: 0.00019994856200897552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1022 [0/90000 (0%)]	Loss: 12.4315	Cost: 28.25s
Train Epoch: 1022 [20480/90000 (23%)]	Loss: 5.5552	Cost: 6.20s
Train Epoch: 1022 [40960/90000 (45%)]	Loss: 5.3894	Cost: 7.11s
Train Epoch: 1022 [61440/90000 (68%)]	Loss: 5.3420	Cost: 5.82s
Train Epoch: 1022 [81920/90000 (91%)]	Loss: 5.4314	Cost: 6.99s
Train Epoch: 1022 	Average Loss: 5.9216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9518

Learning rate: 0.00019994846120827034
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1023 [0/90000 (0%)]	Loss: 12.3923	Cost: 26.72s
Train Epoch: 1023 [20480/90000 (23%)]	Loss: 5.1900	Cost: 6.08s
Train Epoch: 1023 [40960/90000 (45%)]	Loss: 5.2985	Cost: 7.62s
Train Epoch: 1023 [61440/90000 (68%)]	Loss: 5.2106	Cost: 6.62s
Train Epoch: 1023 [81920/90000 (91%)]	Loss: 5.4449	Cost: 5.95s
Train Epoch: 1023 	Average Loss: 5.8470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0584

Learning rate: 0.00019994836030891997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1024 [0/90000 (0%)]	Loss: 12.2551	Cost: 22.18s
Train Epoch: 1024 [20480/90000 (23%)]	Loss: 5.5264	Cost: 5.99s
Train Epoch: 1024 [40960/90000 (45%)]	Loss: 5.5211	Cost: 6.51s
Train Epoch: 1024 [61440/90000 (68%)]	Loss: 5.2614	Cost: 6.13s
Train Epoch: 1024 [81920/90000 (91%)]	Loss: 5.4175	Cost: 8.56s
Train Epoch: 1024 	Average Loss: 5.9228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0916

Learning rate: 0.00019994825931092452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1025 [0/90000 (0%)]	Loss: 12.4211	Cost: 23.71s
Train Epoch: 1025 [20480/90000 (23%)]	Loss: 5.4702	Cost: 5.89s
Train Epoch: 1025 [40960/90000 (45%)]	Loss: 5.6425	Cost: 7.66s
Train Epoch: 1025 [61440/90000 (68%)]	Loss: 5.6376	Cost: 5.98s
Train Epoch: 1025 [81920/90000 (91%)]	Loss: 5.4677	Cost: 5.99s
Train Epoch: 1025 	Average Loss: 6.0445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9201

Learning rate: 0.00019994815821428413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1026 [0/90000 (0%)]	Loss: 12.3842	Cost: 24.89s
Train Epoch: 1026 [20480/90000 (23%)]	Loss: 5.4358	Cost: 6.07s
Train Epoch: 1026 [40960/90000 (45%)]	Loss: 5.3057	Cost: 7.28s
Train Epoch: 1026 [61440/90000 (68%)]	Loss: 5.1414	Cost: 6.50s
Train Epoch: 1026 [81920/90000 (91%)]	Loss: 5.1121	Cost: 6.25s
Train Epoch: 1026 	Average Loss: 5.8404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9742

Learning rate: 0.00019994805701899885
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1027 [0/90000 (0%)]	Loss: 12.5945	Cost: 30.24s
Train Epoch: 1027 [20480/90000 (23%)]	Loss: 5.3863	Cost: 6.05s
Train Epoch: 1027 [40960/90000 (45%)]	Loss: 5.6472	Cost: 7.54s
Train Epoch: 1027 [61440/90000 (68%)]	Loss: 5.3450	Cost: 5.92s
Train Epoch: 1027 [81920/90000 (91%)]	Loss: 5.3476	Cost: 5.78s
Train Epoch: 1027 	Average Loss: 5.8296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9545

Learning rate: 0.0001999479557250688
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1028 [0/90000 (0%)]	Loss: 12.5649	Cost: 25.18s
Train Epoch: 1028 [20480/90000 (23%)]	Loss: 5.2831	Cost: 6.02s
Train Epoch: 1028 [40960/90000 (45%)]	Loss: 5.4212	Cost: 9.08s
Train Epoch: 1028 [61440/90000 (68%)]	Loss: 5.1805	Cost: 5.97s
Train Epoch: 1028 [81920/90000 (91%)]	Loss: 5.2828	Cost: 8.36s
Train Epoch: 1028 	Average Loss: 5.8011
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0365

Learning rate: 0.00019994785433249406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1029 [0/90000 (0%)]	Loss: 12.1041	Cost: 24.47s
Train Epoch: 1029 [20480/90000 (23%)]	Loss: 5.2940	Cost: 5.95s
Train Epoch: 1029 [40960/90000 (45%)]	Loss: 5.2143	Cost: 6.40s
Train Epoch: 1029 [61440/90000 (68%)]	Loss: 5.3674	Cost: 6.01s
Train Epoch: 1029 [81920/90000 (91%)]	Loss: 5.2561	Cost: 8.53s
Train Epoch: 1029 	Average Loss: 5.7498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0843

Learning rate: 0.00019994775284127474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1030 [0/90000 (0%)]	Loss: 12.6393	Cost: 24.58s
Train Epoch: 1030 [20480/90000 (23%)]	Loss: 5.2250	Cost: 6.08s
Train Epoch: 1030 [40960/90000 (45%)]	Loss: 5.1548	Cost: 7.17s
Train Epoch: 1030 [61440/90000 (68%)]	Loss: 5.1047	Cost: 5.94s
Train Epoch: 1030 [81920/90000 (91%)]	Loss: 5.4683	Cost: 5.89s
Train Epoch: 1030 	Average Loss: 5.8126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0082

Learning rate: 0.00019994765125141094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1031 [0/90000 (0%)]	Loss: 12.6146	Cost: 23.18s
Train Epoch: 1031 [20480/90000 (23%)]	Loss: 5.5438	Cost: 6.19s
Train Epoch: 1031 [40960/90000 (45%)]	Loss: 5.4278	Cost: 8.03s
Train Epoch: 1031 [61440/90000 (68%)]	Loss: 5.2807	Cost: 6.06s
Train Epoch: 1031 [81920/90000 (91%)]	Loss: 5.2724	Cost: 6.45s
Train Epoch: 1031 	Average Loss: 5.9375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0164

Learning rate: 0.00019994754956290274
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1032 [0/90000 (0%)]	Loss: 12.6789	Cost: 28.62s
Train Epoch: 1032 [20480/90000 (23%)]	Loss: 5.4139	Cost: 6.19s
Train Epoch: 1032 [40960/90000 (45%)]	Loss: 5.3580	Cost: 7.10s
Train Epoch: 1032 [61440/90000 (68%)]	Loss: 5.2976	Cost: 5.94s
Train Epoch: 1032 [81920/90000 (91%)]	Loss: 5.2119	Cost: 6.20s
Train Epoch: 1032 	Average Loss: 5.8673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0264

Learning rate: 0.0001999474477757503
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1033 [0/90000 (0%)]	Loss: 12.3833	Cost: 24.46s
Train Epoch: 1033 [20480/90000 (23%)]	Loss: 5.0875	Cost: 6.21s
Train Epoch: 1033 [40960/90000 (45%)]	Loss: 5.3128	Cost: 7.90s
Train Epoch: 1033 [61440/90000 (68%)]	Loss: 5.2937	Cost: 6.17s
Train Epoch: 1033 [81920/90000 (91%)]	Loss: 5.1730	Cost: 8.05s
Train Epoch: 1033 	Average Loss: 5.7793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0247

Learning rate: 0.00019994734588995366
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1034 [0/90000 (0%)]	Loss: 12.2831	Cost: 22.74s
Train Epoch: 1034 [20480/90000 (23%)]	Loss: 5.2806	Cost: 6.10s
Train Epoch: 1034 [40960/90000 (45%)]	Loss: 5.3399	Cost: 6.58s
Train Epoch: 1034 [61440/90000 (68%)]	Loss: 5.3459	Cost: 6.35s
Train Epoch: 1034 [81920/90000 (91%)]	Loss: 5.4492	Cost: 6.84s
Train Epoch: 1034 	Average Loss: 5.7771
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0793

Learning rate: 0.00019994724390551296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1035 [0/90000 (0%)]	Loss: 12.6526	Cost: 24.03s
Train Epoch: 1035 [20480/90000 (23%)]	Loss: 5.1096	Cost: 6.10s
Train Epoch: 1035 [40960/90000 (45%)]	Loss: 5.2500	Cost: 6.23s
Train Epoch: 1035 [61440/90000 (68%)]	Loss: 5.1565	Cost: 6.16s
Train Epoch: 1035 [81920/90000 (91%)]	Loss: 5.2651	Cost: 6.22s
Train Epoch: 1035 	Average Loss: 5.8010
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0282

Learning rate: 0.00019994714182242827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1036 [0/90000 (0%)]	Loss: 12.6389	Cost: 23.37s
Train Epoch: 1036 [20480/90000 (23%)]	Loss: 5.3485	Cost: 6.06s
Train Epoch: 1036 [40960/90000 (45%)]	Loss: 5.4203	Cost: 6.76s
Train Epoch: 1036 [61440/90000 (68%)]	Loss: 5.0676	Cost: 6.05s
Train Epoch: 1036 [81920/90000 (91%)]	Loss: 5.1985	Cost: 6.39s
Train Epoch: 1036 	Average Loss: 5.7675
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0769

Learning rate: 0.0001999470396406997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1037 [0/90000 (0%)]	Loss: 12.4918	Cost: 29.62s
Train Epoch: 1037 [20480/90000 (23%)]	Loss: 5.1231	Cost: 6.22s
Train Epoch: 1037 [40960/90000 (45%)]	Loss: 5.1144	Cost: 7.91s
Train Epoch: 1037 [61440/90000 (68%)]	Loss: 5.1718	Cost: 6.46s
Train Epoch: 1037 [81920/90000 (91%)]	Loss: 5.2270	Cost: 6.16s
Train Epoch: 1037 	Average Loss: 5.7225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0442

Learning rate: 0.00019994693736032738
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1038 [0/90000 (0%)]	Loss: 12.9111	Cost: 23.89s
Train Epoch: 1038 [20480/90000 (23%)]	Loss: 5.0748	Cost: 5.98s
Train Epoch: 1038 [40960/90000 (45%)]	Loss: 5.2996	Cost: 8.14s
Train Epoch: 1038 [61440/90000 (68%)]	Loss: 5.1240	Cost: 5.84s
Train Epoch: 1038 [81920/90000 (91%)]	Loss: 5.2381	Cost: 9.05s
Train Epoch: 1038 	Average Loss: 5.7293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0221

Learning rate: 0.00019994683498131136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1039 [0/90000 (0%)]	Loss: 12.6048	Cost: 23.69s
Train Epoch: 1039 [20480/90000 (23%)]	Loss: 5.1996	Cost: 5.95s
Train Epoch: 1039 [40960/90000 (45%)]	Loss: 5.4263	Cost: 6.46s
Train Epoch: 1039 [61440/90000 (68%)]	Loss: 5.1777	Cost: 6.22s
Train Epoch: 1039 [81920/90000 (91%)]	Loss: 5.1113	Cost: 7.68s
Train Epoch: 1039 	Average Loss: 5.7743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1629

Learning rate: 0.0001999467325036518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1040 [0/90000 (0%)]	Loss: 12.4211	Cost: 23.25s
Train Epoch: 1040 [20480/90000 (23%)]	Loss: 5.2691	Cost: 6.18s
Train Epoch: 1040 [40960/90000 (45%)]	Loss: 5.2175	Cost: 7.27s
Train Epoch: 1040 [61440/90000 (68%)]	Loss: 5.2638	Cost: 6.17s
Train Epoch: 1040 [81920/90000 (91%)]	Loss: 5.0769	Cost: 6.15s
Train Epoch: 1040 	Average Loss: 5.6834
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0777

Learning rate: 0.00019994662992734875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1041 [0/90000 (0%)]	Loss: 12.5981	Cost: 25.29s
Train Epoch: 1041 [20480/90000 (23%)]	Loss: 5.2928	Cost: 6.00s
Train Epoch: 1041 [40960/90000 (45%)]	Loss: 5.2268	Cost: 7.85s
Train Epoch: 1041 [61440/90000 (68%)]	Loss: 5.2292	Cost: 5.92s
Train Epoch: 1041 [81920/90000 (91%)]	Loss: 5.2264	Cost: 7.29s
Train Epoch: 1041 	Average Loss: 5.7179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1459

Learning rate: 0.00019994652725240233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1042 [0/90000 (0%)]	Loss: 12.5340	Cost: 29.38s
Train Epoch: 1042 [20480/90000 (23%)]	Loss: 5.1828	Cost: 6.01s
Train Epoch: 1042 [40960/90000 (45%)]	Loss: 5.2283	Cost: 7.62s
Train Epoch: 1042 [61440/90000 (68%)]	Loss: 5.0477	Cost: 5.91s
Train Epoch: 1042 [81920/90000 (91%)]	Loss: 5.1491	Cost: 6.75s
Train Epoch: 1042 	Average Loss: 5.7200
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1871

Learning rate: 0.00019994642447881264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1043 [0/90000 (0%)]	Loss: 12.4661	Cost: 23.42s
Train Epoch: 1043 [20480/90000 (23%)]	Loss: 5.2335	Cost: 6.05s
Train Epoch: 1043 [40960/90000 (45%)]	Loss: 5.3179	Cost: 7.69s
Train Epoch: 1043 [61440/90000 (68%)]	Loss: 5.2041	Cost: 6.07s
Train Epoch: 1043 [81920/90000 (91%)]	Loss: 5.2595	Cost: 7.06s
Train Epoch: 1043 	Average Loss: 5.7293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1834

Learning rate: 0.00019994632160657977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1044 [0/90000 (0%)]	Loss: 12.4053	Cost: 23.28s
Train Epoch: 1044 [20480/90000 (23%)]	Loss: 5.3842	Cost: 5.89s
Train Epoch: 1044 [40960/90000 (45%)]	Loss: 5.7154	Cost: 6.71s
Train Epoch: 1044 [61440/90000 (68%)]	Loss: 5.4413	Cost: 6.07s
Train Epoch: 1044 [81920/90000 (91%)]	Loss: 5.3304	Cost: 8.91s
Train Epoch: 1044 	Average Loss: 5.8818
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0288

Learning rate: 0.00019994621863570386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1045 [0/90000 (0%)]	Loss: 12.5120	Cost: 24.94s
Train Epoch: 1045 [20480/90000 (23%)]	Loss: 5.2905	Cost: 6.19s
Train Epoch: 1045 [40960/90000 (45%)]	Loss: 5.2251	Cost: 7.01s
Train Epoch: 1045 [61440/90000 (68%)]	Loss: 5.2610	Cost: 5.88s
Train Epoch: 1045 [81920/90000 (91%)]	Loss: 5.1694	Cost: 6.22s
Train Epoch: 1045 	Average Loss: 5.7879
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0680

Learning rate: 0.00019994611556618498
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1046 [0/90000 (0%)]	Loss: 12.4109	Cost: 23.55s
Train Epoch: 1046 [20480/90000 (23%)]	Loss: 5.0754	Cost: 6.18s
Train Epoch: 1046 [40960/90000 (45%)]	Loss: 5.2657	Cost: 7.15s
Train Epoch: 1046 [61440/90000 (68%)]	Loss: 5.2625	Cost: 6.00s
Train Epoch: 1046 [81920/90000 (91%)]	Loss: 5.1889	Cost: 6.85s
Train Epoch: 1046 	Average Loss: 5.7511
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0261

Learning rate: 0.00019994601239802325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1047 [0/90000 (0%)]	Loss: 12.4340	Cost: 26.39s
Train Epoch: 1047 [20480/90000 (23%)]	Loss: 5.1371	Cost: 6.11s
Train Epoch: 1047 [40960/90000 (45%)]	Loss: 5.1695	Cost: 7.24s
Train Epoch: 1047 [61440/90000 (68%)]	Loss: 5.1318	Cost: 6.05s
Train Epoch: 1047 [81920/90000 (91%)]	Loss: 4.9976	Cost: 5.81s
Train Epoch: 1047 	Average Loss: 5.7146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0963

Learning rate: 0.00019994590913121875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1048 [0/90000 (0%)]	Loss: 12.4246	Cost: 28.61s
Train Epoch: 1048 [20480/90000 (23%)]	Loss: 5.3141	Cost: 6.13s
Train Epoch: 1048 [40960/90000 (45%)]	Loss: 5.0906	Cost: 6.52s
Train Epoch: 1048 [61440/90000 (68%)]	Loss: 5.0374	Cost: 6.06s
Train Epoch: 1048 [81920/90000 (91%)]	Loss: 5.1809	Cost: 5.72s
Train Epoch: 1048 	Average Loss: 5.6752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1743

Learning rate: 0.0001999458057657716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1049 [0/90000 (0%)]	Loss: 12.5777	Cost: 23.77s
Train Epoch: 1049 [20480/90000 (23%)]	Loss: 5.1600	Cost: 6.29s
Train Epoch: 1049 [40960/90000 (45%)]	Loss: 5.0082	Cost: 7.68s
Train Epoch: 1049 [61440/90000 (68%)]	Loss: 4.9985	Cost: 6.04s
Train Epoch: 1049 [81920/90000 (91%)]	Loss: 5.1069	Cost: 8.01s
Train Epoch: 1049 	Average Loss: 5.6459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1541

Learning rate: 0.00019994570230168185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1050 [0/90000 (0%)]	Loss: 12.7769	Cost: 24.18s
Train Epoch: 1050 [20480/90000 (23%)]	Loss: 5.2804	Cost: 6.05s
Train Epoch: 1050 [40960/90000 (45%)]	Loss: 5.1206	Cost: 6.37s
Train Epoch: 1050 [61440/90000 (68%)]	Loss: 5.0653	Cost: 5.93s
Train Epoch: 1050 [81920/90000 (91%)]	Loss: 4.9640	Cost: 6.14s
Train Epoch: 1050 	Average Loss: 5.6563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1369

Learning rate: 0.00019994559873894968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1051 [0/90000 (0%)]	Loss: 12.9391	Cost: 22.42s
Train Epoch: 1051 [20480/90000 (23%)]	Loss: 5.0960	Cost: 6.13s
Train Epoch: 1051 [40960/90000 (45%)]	Loss: 5.0641	Cost: 7.65s
Train Epoch: 1051 [61440/90000 (68%)]	Loss: 5.1209	Cost: 5.87s
Train Epoch: 1051 [81920/90000 (91%)]	Loss: 5.0975	Cost: 6.44s
Train Epoch: 1051 	Average Loss: 5.6749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1649

Learning rate: 0.00019994549507757517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1052 [0/90000 (0%)]	Loss: 12.4777	Cost: 27.93s
Train Epoch: 1052 [20480/90000 (23%)]	Loss: 5.0426	Cost: 6.19s
Train Epoch: 1052 [40960/90000 (45%)]	Loss: 5.0123	Cost: 6.82s
Train Epoch: 1052 [61440/90000 (68%)]	Loss: 4.9832	Cost: 5.91s
Train Epoch: 1052 [81920/90000 (91%)]	Loss: 5.0763	Cost: 6.02s
Train Epoch: 1052 	Average Loss: 5.6175
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1040

Learning rate: 0.0001999453913175584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1053 [0/90000 (0%)]	Loss: 12.5267	Cost: 27.51s
Train Epoch: 1053 [20480/90000 (23%)]	Loss: 4.8572	Cost: 6.08s
Train Epoch: 1053 [40960/90000 (45%)]	Loss: 4.8628	Cost: 7.67s
Train Epoch: 1053 [61440/90000 (68%)]	Loss: 5.0789	Cost: 6.15s
Train Epoch: 1053 [81920/90000 (91%)]	Loss: 5.0308	Cost: 7.08s
Train Epoch: 1053 	Average Loss: 5.6012
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2291

Learning rate: 0.00019994528745889947
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1054 [0/90000 (0%)]	Loss: 12.6133	Cost: 23.36s
Train Epoch: 1054 [20480/90000 (23%)]	Loss: 4.9138	Cost: 6.07s
Train Epoch: 1054 [40960/90000 (45%)]	Loss: 5.0292	Cost: 6.47s
Train Epoch: 1054 [61440/90000 (68%)]	Loss: 5.0846	Cost: 6.11s
Train Epoch: 1054 [81920/90000 (91%)]	Loss: 5.1406	Cost: 8.19s
Train Epoch: 1054 	Average Loss: 5.6396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2581

Learning rate: 0.0001999451835015985
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1055 [0/90000 (0%)]	Loss: 12.6381	Cost: 23.54s
Train Epoch: 1055 [20480/90000 (23%)]	Loss: 5.2321	Cost: 6.00s
Train Epoch: 1055 [40960/90000 (45%)]	Loss: 5.1827	Cost: 7.63s
Train Epoch: 1055 [61440/90000 (68%)]	Loss: 5.0212	Cost: 6.09s
Train Epoch: 1055 [81920/90000 (91%)]	Loss: 5.0977	Cost: 6.22s
Train Epoch: 1055 	Average Loss: 5.6777
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1106

Learning rate: 0.0001999450794456556
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1056 [0/90000 (0%)]	Loss: 12.5063	Cost: 23.03s
Train Epoch: 1056 [20480/90000 (23%)]	Loss: 4.9576	Cost: 6.02s
Train Epoch: 1056 [40960/90000 (45%)]	Loss: 4.8860	Cost: 7.85s
Train Epoch: 1056 [61440/90000 (68%)]	Loss: 5.0636	Cost: 5.87s
Train Epoch: 1056 [81920/90000 (91%)]	Loss: 5.0059	Cost: 6.91s
Train Epoch: 1056 	Average Loss: 5.5729
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1550

Learning rate: 0.00019994497529107083
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1057 [0/90000 (0%)]	Loss: 12.2723	Cost: 28.23s
Train Epoch: 1057 [20480/90000 (23%)]	Loss: 5.1547	Cost: 6.02s
Train Epoch: 1057 [40960/90000 (45%)]	Loss: 5.0066	Cost: 7.44s
Train Epoch: 1057 [61440/90000 (68%)]	Loss: 5.1060	Cost: 5.93s
Train Epoch: 1057 [81920/90000 (91%)]	Loss: 5.1214	Cost: 5.74s
Train Epoch: 1057 	Average Loss: 5.6359
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1619

Learning rate: 0.00019994487103784436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1058 [0/90000 (0%)]	Loss: 12.7655	Cost: 26.32s
Train Epoch: 1058 [20480/90000 (23%)]	Loss: 5.1081	Cost: 6.24s
Train Epoch: 1058 [40960/90000 (45%)]	Loss: 4.9496	Cost: 8.25s
Train Epoch: 1058 [61440/90000 (68%)]	Loss: 4.9619	Cost: 6.12s
Train Epoch: 1058 [81920/90000 (91%)]	Loss: 5.0315	Cost: 8.26s
Train Epoch: 1058 	Average Loss: 5.6039
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1582

Learning rate: 0.00019994476668597623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1059 [0/90000 (0%)]	Loss: 12.7028	Cost: 22.21s
Train Epoch: 1059 [20480/90000 (23%)]	Loss: 5.0672	Cost: 5.97s
Train Epoch: 1059 [40960/90000 (45%)]	Loss: 4.7679	Cost: 8.28s
Train Epoch: 1059 [61440/90000 (68%)]	Loss: 5.0070	Cost: 5.92s
Train Epoch: 1059 [81920/90000 (91%)]	Loss: 5.0121	Cost: 9.58s
Train Epoch: 1059 	Average Loss: 5.5697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2722

Learning rate: 0.00019994466223546657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1060 [0/90000 (0%)]	Loss: 12.6027	Cost: 23.80s
Train Epoch: 1060 [20480/90000 (23%)]	Loss: 5.0200	Cost: 6.03s
Train Epoch: 1060 [40960/90000 (45%)]	Loss: 5.0827	Cost: 7.04s
Train Epoch: 1060 [61440/90000 (68%)]	Loss: 5.0924	Cost: 6.49s
Train Epoch: 1060 [81920/90000 (91%)]	Loss: 5.1458	Cost: 6.18s
Train Epoch: 1060 	Average Loss: 5.6366
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2494

Learning rate: 0.0001999445576863155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1061 [0/90000 (0%)]	Loss: 12.5182	Cost: 23.28s
Train Epoch: 1061 [20480/90000 (23%)]	Loss: 5.0345	Cost: 6.10s
Train Epoch: 1061 [40960/90000 (45%)]	Loss: 4.9002	Cost: 7.40s
Train Epoch: 1061 [61440/90000 (68%)]	Loss: 5.1708	Cost: 5.91s
Train Epoch: 1061 [81920/90000 (91%)]	Loss: 5.1395	Cost: 6.25s
Train Epoch: 1061 	Average Loss: 5.6424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2421

Learning rate: 0.0001999444530385231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1062 [0/90000 (0%)]	Loss: 12.6873	Cost: 25.24s
Train Epoch: 1062 [20480/90000 (23%)]	Loss: 5.1645	Cost: 6.10s
Train Epoch: 1062 [40960/90000 (45%)]	Loss: 5.1412	Cost: 7.06s
Train Epoch: 1062 [61440/90000 (68%)]	Loss: 5.0496	Cost: 6.01s
Train Epoch: 1062 [81920/90000 (91%)]	Loss: 4.9715	Cost: 6.09s
Train Epoch: 1062 	Average Loss: 5.6432
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2026

Learning rate: 0.00019994434829208945
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1063 [0/90000 (0%)]	Loss: 12.7401	Cost: 29.08s
Train Epoch: 1063 [20480/90000 (23%)]	Loss: 5.1699	Cost: 6.02s
Train Epoch: 1063 [40960/90000 (45%)]	Loss: 5.0111	Cost: 6.49s
Train Epoch: 1063 [61440/90000 (68%)]	Loss: 5.1469	Cost: 5.94s
Train Epoch: 1063 [81920/90000 (91%)]	Loss: 4.9549	Cost: 5.76s
Train Epoch: 1063 	Average Loss: 5.6106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2279

Learning rate: 0.0001999442434470147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1064 [0/90000 (0%)]	Loss: 12.8099	Cost: 24.84s
Train Epoch: 1064 [20480/90000 (23%)]	Loss: 5.0568	Cost: 6.02s
Train Epoch: 1064 [40960/90000 (45%)]	Loss: 4.8664	Cost: 8.03s
Train Epoch: 1064 [61440/90000 (68%)]	Loss: 4.6684	Cost: 6.03s
Train Epoch: 1064 [81920/90000 (91%)]	Loss: 5.2704	Cost: 8.24s
Train Epoch: 1064 	Average Loss: 5.5596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2335

Learning rate: 0.00019994413850329894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1065 [0/90000 (0%)]	Loss: 12.8139	Cost: 22.59s
Train Epoch: 1065 [20480/90000 (23%)]	Loss: 4.9618	Cost: 6.10s
Train Epoch: 1065 [40960/90000 (45%)]	Loss: 5.0042	Cost: 6.37s
Train Epoch: 1065 [61440/90000 (68%)]	Loss: 5.0157	Cost: 6.15s
Train Epoch: 1065 [81920/90000 (91%)]	Loss: 4.9873	Cost: 8.10s
Train Epoch: 1065 	Average Loss: 5.6134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2559

Learning rate: 0.0001999440334609423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1066 [0/90000 (0%)]	Loss: 12.4452	Cost: 24.38s
Train Epoch: 1066 [20480/90000 (23%)]	Loss: 5.1595	Cost: 6.18s
Train Epoch: 1066 [40960/90000 (45%)]	Loss: 4.8739	Cost: 6.69s
Train Epoch: 1066 [61440/90000 (68%)]	Loss: 4.9026	Cost: 5.91s
Train Epoch: 1066 [81920/90000 (91%)]	Loss: 5.0946	Cost: 5.87s
Train Epoch: 1066 	Average Loss: 5.4752
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2403

Learning rate: 0.0001999439283199448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1067 [0/90000 (0%)]	Loss: 12.6539	Cost: 23.91s
Train Epoch: 1067 [20480/90000 (23%)]	Loss: 5.0254	Cost: 6.10s
Train Epoch: 1067 [40960/90000 (45%)]	Loss: 4.8315	Cost: 7.86s
Train Epoch: 1067 [61440/90000 (68%)]	Loss: 4.9529	Cost: 6.02s
Train Epoch: 1067 [81920/90000 (91%)]	Loss: 4.9708	Cost: 5.97s
Train Epoch: 1067 	Average Loss: 5.4609
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1747

Learning rate: 0.0001999438230803066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1068 [0/90000 (0%)]	Loss: 12.7171	Cost: 28.57s
Train Epoch: 1068 [20480/90000 (23%)]	Loss: 5.0359	Cost: 5.95s
Train Epoch: 1068 [40960/90000 (45%)]	Loss: 4.8622	Cost: 7.59s
Train Epoch: 1068 [61440/90000 (68%)]	Loss: 4.8943	Cost: 6.04s
Train Epoch: 1068 [81920/90000 (91%)]	Loss: 4.9144	Cost: 5.90s
Train Epoch: 1068 	Average Loss: 5.4836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2387

Learning rate: 0.00019994371774202785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1069 [0/90000 (0%)]	Loss: 12.8931	Cost: 24.07s
Train Epoch: 1069 [20480/90000 (23%)]	Loss: 4.9420	Cost: 6.03s
Train Epoch: 1069 [40960/90000 (45%)]	Loss: 4.8347	Cost: 7.51s
Train Epoch: 1069 [61440/90000 (68%)]	Loss: 4.8252	Cost: 6.08s
Train Epoch: 1069 [81920/90000 (91%)]	Loss: 4.8965	Cost: 6.74s
Train Epoch: 1069 	Average Loss: 5.4416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2343

Learning rate: 0.00019994361230510856
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1070 [0/90000 (0%)]	Loss: 12.6973	Cost: 22.85s
Train Epoch: 1070 [20480/90000 (23%)]	Loss: 5.0096	Cost: 6.16s
Train Epoch: 1070 [40960/90000 (45%)]	Loss: 4.9269	Cost: 6.65s
Train Epoch: 1070 [61440/90000 (68%)]	Loss: 4.8906	Cost: 6.12s
Train Epoch: 1070 [81920/90000 (91%)]	Loss: 4.9359	Cost: 8.82s
Train Epoch: 1070 	Average Loss: 5.5232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3086

Learning rate: 0.00019994350676954888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1071 [0/90000 (0%)]	Loss: 12.6036	Cost: 23.90s
Train Epoch: 1071 [20480/90000 (23%)]	Loss: 5.1661	Cost: 6.33s
Train Epoch: 1071 [40960/90000 (45%)]	Loss: 4.7429	Cost: 6.56s
Train Epoch: 1071 [61440/90000 (68%)]	Loss: 4.7632	Cost: 5.85s
Train Epoch: 1071 [81920/90000 (91%)]	Loss: 5.1244	Cost: 5.99s
Train Epoch: 1071 	Average Loss: 5.5264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3308

Learning rate: 0.0001999434011353489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1072 [0/90000 (0%)]	Loss: 12.5885	Cost: 24.21s
Train Epoch: 1072 [20480/90000 (23%)]	Loss: 5.2167	Cost: 6.17s
Train Epoch: 1072 [40960/90000 (45%)]	Loss: 4.9269	Cost: 7.08s
Train Epoch: 1072 [61440/90000 (68%)]	Loss: 4.8905	Cost: 5.93s
Train Epoch: 1072 [81920/90000 (91%)]	Loss: 4.9672	Cost: 5.59s
Train Epoch: 1072 	Average Loss: 5.5882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2604

Learning rate: 0.00019994329540250878
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1073 [0/90000 (0%)]	Loss: 12.6426	Cost: 28.06s
Train Epoch: 1073 [20480/90000 (23%)]	Loss: 4.9573	Cost: 6.05s
Train Epoch: 1073 [40960/90000 (45%)]	Loss: 4.9956	Cost: 7.78s
Train Epoch: 1073 [61440/90000 (68%)]	Loss: 4.7543	Cost: 6.02s
Train Epoch: 1073 [81920/90000 (91%)]	Loss: 4.9959	Cost: 5.87s
Train Epoch: 1073 	Average Loss: 5.4308
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1901

Learning rate: 0.00019994318957102856
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1074 [0/90000 (0%)]	Loss: 12.8166	Cost: 29.10s
Train Epoch: 1074 [20480/90000 (23%)]	Loss: 5.0148	Cost: 6.07s
Train Epoch: 1074 [40960/90000 (45%)]	Loss: 5.0214	Cost: 6.81s
Train Epoch: 1074 [61440/90000 (68%)]	Loss: 4.7746	Cost: 6.02s
Train Epoch: 1074 [81920/90000 (91%)]	Loss: 4.6899	Cost: 6.14s
Train Epoch: 1074 	Average Loss: 5.4202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2849

Learning rate: 0.00019994308364090836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1075 [0/90000 (0%)]	Loss: 12.7498	Cost: 22.76s
Train Epoch: 1075 [20480/90000 (23%)]	Loss: 4.8046	Cost: 6.08s
Train Epoch: 1075 [40960/90000 (45%)]	Loss: 4.7353	Cost: 6.26s
Train Epoch: 1075 [61440/90000 (68%)]	Loss: 4.8748	Cost: 6.05s
Train Epoch: 1075 [81920/90000 (91%)]	Loss: 4.7327	Cost: 8.11s
Train Epoch: 1075 	Average Loss: 5.3680
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3575

Learning rate: 0.0001999429776121483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1076 [0/90000 (0%)]	Loss: 12.6934	Cost: 23.78s
Train Epoch: 1076 [20480/90000 (23%)]	Loss: 4.8475	Cost: 6.25s
Train Epoch: 1076 [40960/90000 (45%)]	Loss: 4.7915	Cost: 6.34s
Train Epoch: 1076 [61440/90000 (68%)]	Loss: 4.6299	Cost: 5.95s
Train Epoch: 1076 [81920/90000 (91%)]	Loss: 4.7368	Cost: 6.47s
Train Epoch: 1076 	Average Loss: 5.3519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3017

Learning rate: 0.0001999428714847485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1077 [0/90000 (0%)]	Loss: 12.7928	Cost: 23.91s
Train Epoch: 1077 [20480/90000 (23%)]	Loss: 4.7887	Cost: 6.21s
Train Epoch: 1077 [40960/90000 (45%)]	Loss: 4.7191	Cost: 6.29s
Train Epoch: 1077 [61440/90000 (68%)]	Loss: 4.6068	Cost: 6.28s
Train Epoch: 1077 [81920/90000 (91%)]	Loss: 4.9539	Cost: 6.20s
Train Epoch: 1077 	Average Loss: 5.3850
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2473

Learning rate: 0.000199942765258709
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1078 [0/90000 (0%)]	Loss: 12.7957	Cost: 26.85s
Train Epoch: 1078 [20480/90000 (23%)]	Loss: 5.0554	Cost: 6.02s
Train Epoch: 1078 [40960/90000 (45%)]	Loss: 4.7533	Cost: 6.78s
Train Epoch: 1078 [61440/90000 (68%)]	Loss: 4.8455	Cost: 6.05s
Train Epoch: 1078 [81920/90000 (91%)]	Loss: 4.6723	Cost: 6.17s
Train Epoch: 1078 	Average Loss: 5.4448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2639

Learning rate: 0.00019994265893402997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1079 [0/90000 (0%)]	Loss: 12.6149	Cost: 25.77s
Train Epoch: 1079 [20480/90000 (23%)]	Loss: 4.7983	Cost: 6.12s
Train Epoch: 1079 [40960/90000 (45%)]	Loss: 4.6780	Cost: 8.36s
Train Epoch: 1079 [61440/90000 (68%)]	Loss: 4.7563	Cost: 5.99s
Train Epoch: 1079 [81920/90000 (91%)]	Loss: 4.7548	Cost: 8.28s
Train Epoch: 1079 	Average Loss: 5.3680
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2399

Learning rate: 0.00019994255251071146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1080 [0/90000 (0%)]	Loss: 12.8112	Cost: 21.70s
Train Epoch: 1080 [20480/90000 (23%)]	Loss: 4.8967	Cost: 6.13s
Train Epoch: 1080 [40960/90000 (45%)]	Loss: 4.7487	Cost: 6.71s
Train Epoch: 1080 [61440/90000 (68%)]	Loss: 4.6508	Cost: 6.04s
Train Epoch: 1080 [81920/90000 (91%)]	Loss: 4.6553	Cost: 8.24s
Train Epoch: 1080 	Average Loss: 5.3530
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2673

Learning rate: 0.00019994244598875362
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1081 [0/90000 (0%)]	Loss: 12.8980	Cost: 23.79s
Train Epoch: 1081 [20480/90000 (23%)]	Loss: 4.9844	Cost: 6.10s
Train Epoch: 1081 [40960/90000 (45%)]	Loss: 4.8301	Cost: 6.90s
Train Epoch: 1081 [61440/90000 (68%)]	Loss: 4.7614	Cost: 5.90s
Train Epoch: 1081 [81920/90000 (91%)]	Loss: 4.7616	Cost: 6.14s
Train Epoch: 1081 	Average Loss: 5.4001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3133

Learning rate: 0.00019994233936815656
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1082 [0/90000 (0%)]	Loss: 12.8340	Cost: 22.97s
Train Epoch: 1082 [20480/90000 (23%)]	Loss: 4.8860	Cost: 6.06s
Train Epoch: 1082 [40960/90000 (45%)]	Loss: 4.5561	Cost: 7.20s
Train Epoch: 1082 [61440/90000 (68%)]	Loss: 4.7155	Cost: 6.26s
Train Epoch: 1082 [81920/90000 (91%)]	Loss: 4.6590	Cost: 5.78s
Train Epoch: 1082 	Average Loss: 5.3448
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3950

Learning rate: 0.00019994223264892036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1083 [0/90000 (0%)]	Loss: 13.1012	Cost: 28.62s
Train Epoch: 1083 [20480/90000 (23%)]	Loss: 4.7590	Cost: 6.05s
Train Epoch: 1083 [40960/90000 (45%)]	Loss: 4.6772	Cost: 7.33s
Train Epoch: 1083 [61440/90000 (68%)]	Loss: 4.6802	Cost: 6.35s
Train Epoch: 1083 [81920/90000 (91%)]	Loss: 4.8283	Cost: 6.22s
Train Epoch: 1083 	Average Loss: 5.4382
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3156

Learning rate: 0.0001999421258310451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1084 [0/90000 (0%)]	Loss: 12.8350	Cost: 24.45s
Train Epoch: 1084 [20480/90000 (23%)]	Loss: 4.9608	Cost: 6.00s
Train Epoch: 1084 [40960/90000 (45%)]	Loss: 5.2734	Cost: 7.72s
Train Epoch: 1084 [61440/90000 (68%)]	Loss: 4.8387	Cost: 6.06s
Train Epoch: 1084 [81920/90000 (91%)]	Loss: 4.8532	Cost: 6.90s
Train Epoch: 1084 	Average Loss: 5.5421
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2322

Learning rate: 0.00019994201891453093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1085 [0/90000 (0%)]	Loss: 12.7973	Cost: 24.13s
Train Epoch: 1085 [20480/90000 (23%)]	Loss: 4.6751	Cost: 5.97s
Train Epoch: 1085 [40960/90000 (45%)]	Loss: 4.6828	Cost: 6.35s
Train Epoch: 1085 [61440/90000 (68%)]	Loss: 4.8605	Cost: 6.02s
Train Epoch: 1085 [81920/90000 (91%)]	Loss: 4.5398	Cost: 8.68s
Train Epoch: 1085 	Average Loss: 5.3380
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2418

Learning rate: 0.00019994191189937795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1086 [0/90000 (0%)]	Loss: 12.7447	Cost: 24.43s
Train Epoch: 1086 [20480/90000 (23%)]	Loss: 4.8151	Cost: 6.21s
Train Epoch: 1086 [40960/90000 (45%)]	Loss: 4.6536	Cost: 6.25s
Train Epoch: 1086 [61440/90000 (68%)]	Loss: 4.6549	Cost: 5.91s
Train Epoch: 1086 [81920/90000 (91%)]	Loss: 4.6048	Cost: 6.10s
Train Epoch: 1086 	Average Loss: 5.3318
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3305

Learning rate: 0.00019994180478558626
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1087 [0/90000 (0%)]	Loss: 12.7271	Cost: 23.28s
Train Epoch: 1087 [20480/90000 (23%)]	Loss: 4.6682	Cost: 6.17s
Train Epoch: 1087 [40960/90000 (45%)]	Loss: 4.4825	Cost: 7.50s
Train Epoch: 1087 [61440/90000 (68%)]	Loss: 4.5388	Cost: 6.54s
Train Epoch: 1087 [81920/90000 (91%)]	Loss: 4.6720	Cost: 6.24s
Train Epoch: 1087 	Average Loss: 5.2282
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2598

Learning rate: 0.00019994169757315598
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1088 [0/90000 (0%)]	Loss: 12.7196	Cost: 26.71s
Train Epoch: 1088 [20480/90000 (23%)]	Loss: 4.6558	Cost: 6.11s
Train Epoch: 1088 [40960/90000 (45%)]	Loss: 4.6858	Cost: 6.53s
Train Epoch: 1088 [61440/90000 (68%)]	Loss: 4.5251	Cost: 5.81s
Train Epoch: 1088 [81920/90000 (91%)]	Loss: 4.5570	Cost: 6.09s
Train Epoch: 1088 	Average Loss: 5.2556
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3908

Learning rate: 0.00019994159026208715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1089 [0/90000 (0%)]	Loss: 12.8154	Cost: 26.95s
Train Epoch: 1089 [20480/90000 (23%)]	Loss: 4.6125	Cost: 6.06s
Train Epoch: 1089 [40960/90000 (45%)]	Loss: 4.6639	Cost: 9.40s
Train Epoch: 1089 [61440/90000 (68%)]	Loss: 4.5928	Cost: 5.94s
Train Epoch: 1089 [81920/90000 (91%)]	Loss: 4.6783	Cost: 7.24s
Train Epoch: 1089 	Average Loss: 5.2670
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4480

Learning rate: 0.00019994148285237993
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1090 [0/90000 (0%)]	Loss: 12.5568	Cost: 22.36s
Train Epoch: 1090 [20480/90000 (23%)]	Loss: 4.8757	Cost: 6.25s
Train Epoch: 1090 [40960/90000 (45%)]	Loss: 4.8479	Cost: 6.49s
Train Epoch: 1090 [61440/90000 (68%)]	Loss: 4.5405	Cost: 6.00s
Train Epoch: 1090 [81920/90000 (91%)]	Loss: 4.7577	Cost: 8.73s
Train Epoch: 1090 	Average Loss: 5.3719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3248

Learning rate: 0.00019994137534403445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1091 [0/90000 (0%)]	Loss: 12.9711	Cost: 23.77s
Train Epoch: 1091 [20480/90000 (23%)]	Loss: 4.5620	Cost: 6.05s
Train Epoch: 1091 [40960/90000 (45%)]	Loss: 4.6841	Cost: 6.76s
Train Epoch: 1091 [61440/90000 (68%)]	Loss: 4.5889	Cost: 5.97s
Train Epoch: 1091 [81920/90000 (91%)]	Loss: 4.4654	Cost: 5.72s
Train Epoch: 1091 	Average Loss: 5.2582
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3981

Learning rate: 0.00019994126773705077
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1092 [0/90000 (0%)]	Loss: 12.9073	Cost: 23.73s
Train Epoch: 1092 [20480/90000 (23%)]	Loss: 4.4022	Cost: 6.22s
Train Epoch: 1092 [40960/90000 (45%)]	Loss: 4.6483	Cost: 7.77s
Train Epoch: 1092 [61440/90000 (68%)]	Loss: 4.5901	Cost: 6.26s
Train Epoch: 1092 [81920/90000 (91%)]	Loss: 4.5040	Cost: 6.24s
Train Epoch: 1092 	Average Loss: 5.2447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4045

Learning rate: 0.000199941160031429
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1093 [0/90000 (0%)]	Loss: 13.1559	Cost: 25.58s
Train Epoch: 1093 [20480/90000 (23%)]	Loss: 4.7765	Cost: 6.02s
Train Epoch: 1093 [40960/90000 (45%)]	Loss: 4.7717	Cost: 6.33s
Train Epoch: 1093 [61440/90000 (68%)]	Loss: 4.6361	Cost: 6.03s
Train Epoch: 1093 [81920/90000 (91%)]	Loss: 4.6187	Cost: 6.08s
Train Epoch: 1093 	Average Loss: 5.2844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4871

Learning rate: 0.00019994105222716926
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1094 [0/90000 (0%)]	Loss: 13.0095	Cost: 26.96s
Train Epoch: 1094 [20480/90000 (23%)]	Loss: 4.5573	Cost: 6.12s
Train Epoch: 1094 [40960/90000 (45%)]	Loss: 4.5640	Cost: 7.64s
Train Epoch: 1094 [61440/90000 (68%)]	Loss: 4.6362	Cost: 6.09s
Train Epoch: 1094 [81920/90000 (91%)]	Loss: 4.5202	Cost: 7.40s
Train Epoch: 1094 	Average Loss: 5.2491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4633

Learning rate: 0.00019994094432427168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1095 [0/90000 (0%)]	Loss: 12.8127	Cost: 23.74s
Train Epoch: 1095 [20480/90000 (23%)]	Loss: 4.7778	Cost: 6.02s
Train Epoch: 1095 [40960/90000 (45%)]	Loss: 4.7868	Cost: 6.74s
Train Epoch: 1095 [61440/90000 (68%)]	Loss: 4.6312	Cost: 6.16s
Train Epoch: 1095 [81920/90000 (91%)]	Loss: 4.5998	Cost: 9.22s
Train Epoch: 1095 	Average Loss: 5.2722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3872

Learning rate: 0.00019994083632273634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1096 [0/90000 (0%)]	Loss: 12.9580	Cost: 23.49s
Train Epoch: 1096 [20480/90000 (23%)]	Loss: 4.6133	Cost: 6.11s
Train Epoch: 1096 [40960/90000 (45%)]	Loss: 4.7101	Cost: 6.98s
Train Epoch: 1096 [61440/90000 (68%)]	Loss: 4.4170	Cost: 5.82s
Train Epoch: 1096 [81920/90000 (91%)]	Loss: 4.3846	Cost: 5.91s
Train Epoch: 1096 	Average Loss: 5.1455
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4803

Learning rate: 0.00019994072822256335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1097 [0/90000 (0%)]	Loss: 12.7990	Cost: 24.19s
Train Epoch: 1097 [20480/90000 (23%)]	Loss: 4.3846	Cost: 6.21s
Train Epoch: 1097 [40960/90000 (45%)]	Loss: 4.6125	Cost: 7.78s
Train Epoch: 1097 [61440/90000 (68%)]	Loss: 4.4351	Cost: 6.30s
Train Epoch: 1097 [81920/90000 (91%)]	Loss: 4.5783	Cost: 6.58s
Train Epoch: 1097 	Average Loss: 5.1215
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3794

Learning rate: 0.0001999406200237528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1098 [0/90000 (0%)]	Loss: 13.0195	Cost: 25.58s
Train Epoch: 1098 [20480/90000 (23%)]	Loss: 4.5903	Cost: 6.14s
Train Epoch: 1098 [40960/90000 (45%)]	Loss: 4.6599	Cost: 6.85s
Train Epoch: 1098 [61440/90000 (68%)]	Loss: 4.4467	Cost: 6.02s
Train Epoch: 1098 [81920/90000 (91%)]	Loss: 4.2408	Cost: 6.05s
Train Epoch: 1098 	Average Loss: 5.1423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4850

Learning rate: 0.00019994051172630482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1099 [0/90000 (0%)]	Loss: 12.6914	Cost: 27.83s
Train Epoch: 1099 [20480/90000 (23%)]	Loss: 4.5433	Cost: 6.16s
Train Epoch: 1099 [40960/90000 (45%)]	Loss: 4.4674	Cost: 6.29s
Train Epoch: 1099 [61440/90000 (68%)]	Loss: 4.3038	Cost: 6.02s
Train Epoch: 1099 [81920/90000 (91%)]	Loss: 4.4454	Cost: 5.56s
Train Epoch: 1099 	Average Loss: 5.0727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4010

Learning rate: 0.0001999404033302195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1100 [0/90000 (0%)]	Loss: 12.8832	Cost: 23.70s
Train Epoch: 1100 [20480/90000 (23%)]	Loss: 4.6979	Cost: 5.99s
Train Epoch: 1100 [40960/90000 (45%)]	Loss: 4.6233	Cost: 7.75s
Train Epoch: 1100 [61440/90000 (68%)]	Loss: 4.4051	Cost: 5.94s
Train Epoch: 1100 [81920/90000 (91%)]	Loss: 4.2431	Cost: 8.31s
Train Epoch: 1100 	Average Loss: 5.0715
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3769

Learning rate: 0.00019994029483549696
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1101 [0/90000 (0%)]	Loss: 13.0854	Cost: 23.50s
Train Epoch: 1101 [20480/90000 (23%)]	Loss: 4.4339	Cost: 6.03s
Train Epoch: 1101 [40960/90000 (45%)]	Loss: 4.4394	Cost: 6.43s
Train Epoch: 1101 [61440/90000 (68%)]	Loss: 4.6096	Cost: 5.90s
Train Epoch: 1101 [81920/90000 (91%)]	Loss: 4.5091	Cost: 5.71s
Train Epoch: 1101 	Average Loss: 5.1633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4655

Learning rate: 0.0001999401862421373
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1102 [0/90000 (0%)]	Loss: 12.9993	Cost: 24.34s
Train Epoch: 1102 [20480/90000 (23%)]	Loss: 4.5373	Cost: 6.22s
Train Epoch: 1102 [40960/90000 (45%)]	Loss: 4.7721	Cost: 7.14s
Train Epoch: 1102 [61440/90000 (68%)]	Loss: 4.3793	Cost: 5.95s
Train Epoch: 1102 [81920/90000 (91%)]	Loss: 4.3748	Cost: 6.22s
Train Epoch: 1102 	Average Loss: 5.1801
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5591

Learning rate: 0.00019994007755014064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1103 [0/90000 (0%)]	Loss: 12.9337	Cost: 24.60s
Train Epoch: 1103 [20480/90000 (23%)]	Loss: 4.4799	Cost: 5.98s
Train Epoch: 1103 [40960/90000 (45%)]	Loss: 4.5616	Cost: 7.13s
Train Epoch: 1103 [61440/90000 (68%)]	Loss: 4.4679	Cost: 5.82s
Train Epoch: 1103 [81920/90000 (91%)]	Loss: 4.4591	Cost: 6.19s
Train Epoch: 1103 	Average Loss: 5.0803
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4825

Learning rate: 0.00019993996875950707
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1104 [0/90000 (0%)]	Loss: 12.8495	Cost: 28.55s
Train Epoch: 1104 [20480/90000 (23%)]	Loss: 4.4628	Cost: 6.11s
Train Epoch: 1104 [40960/90000 (45%)]	Loss: 4.3504	Cost: 6.97s
Train Epoch: 1104 [61440/90000 (68%)]	Loss: 4.4492	Cost: 6.11s
Train Epoch: 1104 [81920/90000 (91%)]	Loss: 4.4748	Cost: 5.80s
Train Epoch: 1104 	Average Loss: 5.0941
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5555

Learning rate: 0.0001999398598702367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1105 [0/90000 (0%)]	Loss: 13.0160	Cost: 24.92s
Train Epoch: 1105 [20480/90000 (23%)]	Loss: 4.4978	Cost: 6.05s
Train Epoch: 1105 [40960/90000 (45%)]	Loss: 4.4700	Cost: 8.19s
Train Epoch: 1105 [61440/90000 (68%)]	Loss: 4.6113	Cost: 5.91s
Train Epoch: 1105 [81920/90000 (91%)]	Loss: 4.3938	Cost: 8.19s
Train Epoch: 1105 	Average Loss: 5.1242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5464

Learning rate: 0.00019993975088232965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1106 [0/90000 (0%)]	Loss: 12.9673	Cost: 23.67s
Train Epoch: 1106 [20480/90000 (23%)]	Loss: 4.3835	Cost: 5.91s
Train Epoch: 1106 [40960/90000 (45%)]	Loss: 4.4791	Cost: 6.69s
Train Epoch: 1106 [61440/90000 (68%)]	Loss: 4.6738	Cost: 6.09s
Train Epoch: 1106 [81920/90000 (91%)]	Loss: 4.6184	Cost: 7.56s
Train Epoch: 1106 	Average Loss: 5.1470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4908

Learning rate: 0.00019993964179578603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1107 [0/90000 (0%)]	Loss: 12.9568	Cost: 25.02s
Train Epoch: 1107 [20480/90000 (23%)]	Loss: 4.6454	Cost: 6.09s
Train Epoch: 1107 [40960/90000 (45%)]	Loss: 4.5211	Cost: 7.37s
Train Epoch: 1107 [61440/90000 (68%)]	Loss: 4.5632	Cost: 5.84s
Train Epoch: 1107 [81920/90000 (91%)]	Loss: 4.4236	Cost: 5.58s
Train Epoch: 1107 	Average Loss: 5.1963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4734

Learning rate: 0.0001999395326106059
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1108 [0/90000 (0%)]	Loss: 12.8967	Cost: 23.04s
Train Epoch: 1108 [20480/90000 (23%)]	Loss: 4.5376	Cost: 6.15s
Train Epoch: 1108 [40960/90000 (45%)]	Loss: 4.5320	Cost: 7.65s
Train Epoch: 1108 [61440/90000 (68%)]	Loss: 4.3781	Cost: 6.02s
Train Epoch: 1108 [81920/90000 (91%)]	Loss: 4.3202	Cost: 5.75s
Train Epoch: 1108 	Average Loss: 5.1206
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4518

Learning rate: 0.00019993942332678945
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1109 [0/90000 (0%)]	Loss: 13.0704	Cost: 26.41s
Train Epoch: 1109 [20480/90000 (23%)]	Loss: 4.5464	Cost: 6.26s
Train Epoch: 1109 [40960/90000 (45%)]	Loss: 4.5605	Cost: 6.91s
Train Epoch: 1109 [61440/90000 (68%)]	Loss: 4.5539	Cost: 5.93s
Train Epoch: 1109 [81920/90000 (91%)]	Loss: 4.3635	Cost: 5.84s
Train Epoch: 1109 	Average Loss: 5.1698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3874

Learning rate: 0.00019993931394433673
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1110 [0/90000 (0%)]	Loss: 12.8911	Cost: 25.18s
Train Epoch: 1110 [20480/90000 (23%)]	Loss: 4.6237	Cost: 6.09s
Train Epoch: 1110 [40960/90000 (45%)]	Loss: 4.4807	Cost: 9.38s
Train Epoch: 1110 [61440/90000 (68%)]	Loss: 4.4735	Cost: 5.96s
Train Epoch: 1110 [81920/90000 (91%)]	Loss: 4.3366	Cost: 7.90s
Train Epoch: 1110 	Average Loss: 5.0870
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5475

Learning rate: 0.00019993920446324782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1111 [0/90000 (0%)]	Loss: 12.9366	Cost: 23.01s
Train Epoch: 1111 [20480/90000 (23%)]	Loss: 4.5232	Cost: 6.53s
Train Epoch: 1111 [40960/90000 (45%)]	Loss: 4.3161	Cost: 6.87s
Train Epoch: 1111 [61440/90000 (68%)]	Loss: 4.7708	Cost: 6.08s
Train Epoch: 1111 [81920/90000 (91%)]	Loss: 4.5502	Cost: 7.52s
Train Epoch: 1111 	Average Loss: 5.1827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5343

Learning rate: 0.0001999390948835229
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1112 [0/90000 (0%)]	Loss: 12.8555	Cost: 24.06s
Train Epoch: 1112 [20480/90000 (23%)]	Loss: 4.7727	Cost: 6.06s
Train Epoch: 1112 [40960/90000 (45%)]	Loss: 4.6768	Cost: 7.05s
Train Epoch: 1112 [61440/90000 (68%)]	Loss: 4.6129	Cost: 6.12s
Train Epoch: 1112 [81920/90000 (91%)]	Loss: 4.6130	Cost: 6.21s
Train Epoch: 1112 	Average Loss: 5.2230
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5649

Learning rate: 0.00019993898520516204
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1113 [0/90000 (0%)]	Loss: 13.1039	Cost: 23.40s
Train Epoch: 1113 [20480/90000 (23%)]	Loss: 4.5649	Cost: 6.03s
Train Epoch: 1113 [40960/90000 (45%)]	Loss: 4.3499	Cost: 7.97s
Train Epoch: 1113 [61440/90000 (68%)]	Loss: 4.3752	Cost: 6.00s
Train Epoch: 1113 [81920/90000 (91%)]	Loss: 4.2180	Cost: 6.52s
Train Epoch: 1113 	Average Loss: 5.0423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5160

Learning rate: 0.00019993887542816538
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1114 [0/90000 (0%)]	Loss: 12.9078	Cost: 26.70s
Train Epoch: 1114 [20480/90000 (23%)]	Loss: 4.4109	Cost: 6.03s
Train Epoch: 1114 [40960/90000 (45%)]	Loss: 4.4500	Cost: 7.21s
Train Epoch: 1114 [61440/90000 (68%)]	Loss: 4.4538	Cost: 5.75s
Train Epoch: 1114 [81920/90000 (91%)]	Loss: 4.2404	Cost: 5.74s
Train Epoch: 1114 	Average Loss: 5.0169
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5180

Learning rate: 0.000199938765552533
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1115 [0/90000 (0%)]	Loss: 12.9378	Cost: 27.49s
Train Epoch: 1115 [20480/90000 (23%)]	Loss: 4.5313	Cost: 6.03s
Train Epoch: 1115 [40960/90000 (45%)]	Loss: 4.3179	Cost: 8.77s
Train Epoch: 1115 [61440/90000 (68%)]	Loss: 4.5645	Cost: 5.96s
Train Epoch: 1115 [81920/90000 (91%)]	Loss: 4.3737	Cost: 8.00s
Train Epoch: 1115 	Average Loss: 5.0997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5908

Learning rate: 0.00019993865557826497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1116 [0/90000 (0%)]	Loss: 12.8673	Cost: 24.10s
Train Epoch: 1116 [20480/90000 (23%)]	Loss: 4.6247	Cost: 5.97s
Train Epoch: 1116 [40960/90000 (45%)]	Loss: 4.4685	Cost: 7.61s
Train Epoch: 1116 [61440/90000 (68%)]	Loss: 4.4526	Cost: 5.99s
Train Epoch: 1116 [81920/90000 (91%)]	Loss: 4.2837	Cost: 8.41s
Train Epoch: 1116 	Average Loss: 5.0813
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5760

Learning rate: 0.00019993854550536149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1117 [0/90000 (0%)]	Loss: 13.0442	Cost: 23.56s
Train Epoch: 1117 [20480/90000 (23%)]	Loss: 4.5341	Cost: 5.93s
Train Epoch: 1117 [40960/90000 (45%)]	Loss: 4.7323	Cost: 7.22s
Train Epoch: 1117 [61440/90000 (68%)]	Loss: 4.6009	Cost: 5.86s
Train Epoch: 1117 [81920/90000 (91%)]	Loss: 4.4242	Cost: 5.57s
Train Epoch: 1117 	Average Loss: 5.2306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5438

Learning rate: 0.00019993843533382257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1118 [0/90000 (0%)]	Loss: 13.1096	Cost: 24.21s
Train Epoch: 1118 [20480/90000 (23%)]	Loss: 4.7295	Cost: 6.14s
Train Epoch: 1118 [40960/90000 (45%)]	Loss: 4.6151	Cost: 6.18s
Train Epoch: 1118 [61440/90000 (68%)]	Loss: 4.3749	Cost: 6.26s
Train Epoch: 1118 [81920/90000 (91%)]	Loss: 4.2744	Cost: 5.73s
Train Epoch: 1118 	Average Loss: 5.2099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5449

Learning rate: 0.00019993832506364843
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1119 [0/90000 (0%)]	Loss: 12.9218	Cost: 26.58s
Train Epoch: 1119 [20480/90000 (23%)]	Loss: 4.7170	Cost: 6.05s
Train Epoch: 1119 [40960/90000 (45%)]	Loss: 4.7507	Cost: 7.30s
Train Epoch: 1119 [61440/90000 (68%)]	Loss: 4.5103	Cost: 5.89s
Train Epoch: 1119 [81920/90000 (91%)]	Loss: 4.4267	Cost: 6.25s
Train Epoch: 1119 	Average Loss: 5.2575
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4206

Learning rate: 0.00019993821469483904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1120 [0/90000 (0%)]	Loss: 13.0812	Cost: 25.69s
Train Epoch: 1120 [20480/90000 (23%)]	Loss: 4.6208	Cost: 6.00s
Train Epoch: 1120 [40960/90000 (45%)]	Loss: 4.4842	Cost: 7.99s
Train Epoch: 1120 [61440/90000 (68%)]	Loss: 4.4963	Cost: 5.97s
Train Epoch: 1120 [81920/90000 (91%)]	Loss: 3.9952	Cost: 7.66s
Train Epoch: 1120 	Average Loss: 5.0829
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5600

Learning rate: 0.00019993810422739465
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1121 [0/90000 (0%)]	Loss: 13.1687	Cost: 22.48s
Train Epoch: 1121 [20480/90000 (23%)]	Loss: 4.6017	Cost: 5.99s
Train Epoch: 1121 [40960/90000 (45%)]	Loss: 4.1758	Cost: 6.38s
Train Epoch: 1121 [61440/90000 (68%)]	Loss: 4.3884	Cost: 6.12s
Train Epoch: 1121 [81920/90000 (91%)]	Loss: 4.3505	Cost: 8.26s
Train Epoch: 1121 	Average Loss: 5.0302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5403

Learning rate: 0.00019993799366131528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1122 [0/90000 (0%)]	Loss: 12.7991	Cost: 24.21s
Train Epoch: 1122 [20480/90000 (23%)]	Loss: 4.3753	Cost: 6.14s
Train Epoch: 1122 [40960/90000 (45%)]	Loss: 4.3502	Cost: 6.50s
Train Epoch: 1122 [61440/90000 (68%)]	Loss: 4.2953	Cost: 5.92s
Train Epoch: 1122 [81920/90000 (91%)]	Loss: 4.2203	Cost: 6.17s
Train Epoch: 1122 	Average Loss: 4.9759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5894

Learning rate: 0.00019993788299660107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1123 [0/90000 (0%)]	Loss: 13.1277	Cost: 23.99s
Train Epoch: 1123 [20480/90000 (23%)]	Loss: 4.3780	Cost: 6.16s
Train Epoch: 1123 [40960/90000 (45%)]	Loss: 4.3726	Cost: 6.86s
Train Epoch: 1123 [61440/90000 (68%)]	Loss: 4.3394	Cost: 6.03s
Train Epoch: 1123 [81920/90000 (91%)]	Loss: 4.3616	Cost: 5.84s
Train Epoch: 1123 	Average Loss: 4.9748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6042

Learning rate: 0.00019993777223325214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1124 [0/90000 (0%)]	Loss: 13.1149	Cost: 27.60s
Train Epoch: 1124 [20480/90000 (23%)]	Loss: 4.3088	Cost: 5.96s
Train Epoch: 1124 [40960/90000 (45%)]	Loss: 4.4159	Cost: 7.50s
Train Epoch: 1124 [61440/90000 (68%)]	Loss: 4.2521	Cost: 5.93s
Train Epoch: 1124 [81920/90000 (91%)]	Loss: 4.3818	Cost: 5.87s
Train Epoch: 1124 	Average Loss: 4.9643
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6278

Learning rate: 0.00019993766137126854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1125 [0/90000 (0%)]	Loss: 13.3260	Cost: 27.67s
Train Epoch: 1125 [20480/90000 (23%)]	Loss: 4.3750	Cost: 6.05s
Train Epoch: 1125 [40960/90000 (45%)]	Loss: 4.3044	Cost: 7.71s
Train Epoch: 1125 [61440/90000 (68%)]	Loss: 4.1415	Cost: 5.96s
Train Epoch: 1125 [81920/90000 (91%)]	Loss: 4.4211	Cost: 6.78s
Train Epoch: 1125 	Average Loss: 4.9612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6224

Learning rate: 0.00019993755041065043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1126 [0/90000 (0%)]	Loss: 13.0677	Cost: 21.94s
Train Epoch: 1126 [20480/90000 (23%)]	Loss: 4.6145	Cost: 6.12s
Train Epoch: 1126 [40960/90000 (45%)]	Loss: 4.1686	Cost: 6.96s
Train Epoch: 1126 [61440/90000 (68%)]	Loss: 4.2715	Cost: 6.08s
Train Epoch: 1126 [81920/90000 (91%)]	Loss: 3.9973	Cost: 8.56s
Train Epoch: 1126 	Average Loss: 4.9670
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5980

Learning rate: 0.00019993743935139792
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1127 [0/90000 (0%)]	Loss: 13.1209	Cost: 24.80s
Train Epoch: 1127 [20480/90000 (23%)]	Loss: 4.4390	Cost: 6.19s
Train Epoch: 1127 [40960/90000 (45%)]	Loss: 4.2405	Cost: 7.28s
Train Epoch: 1127 [61440/90000 (68%)]	Loss: 4.1796	Cost: 5.97s
Train Epoch: 1127 [81920/90000 (91%)]	Loss: 4.1659	Cost: 6.22s
Train Epoch: 1127 	Average Loss: 4.9216
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6335

Learning rate: 0.00019993732819351113
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1128 [0/90000 (0%)]	Loss: 13.0857	Cost: 24.00s
Train Epoch: 1128 [20480/90000 (23%)]	Loss: 4.2921	Cost: 6.25s
Train Epoch: 1128 [40960/90000 (45%)]	Loss: 4.3531	Cost: 7.48s
Train Epoch: 1128 [61440/90000 (68%)]	Loss: 4.2834	Cost: 6.33s
Train Epoch: 1128 [81920/90000 (91%)]	Loss: 4.2641	Cost: 6.18s
Train Epoch: 1128 	Average Loss: 4.9171
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5524

Learning rate: 0.00019993721693699015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1129 [0/90000 (0%)]	Loss: 13.2345	Cost: 26.28s
Train Epoch: 1129 [20480/90000 (23%)]	Loss: 4.4832	Cost: 5.96s
Train Epoch: 1129 [40960/90000 (45%)]	Loss: 4.2436	Cost: 7.17s
Train Epoch: 1129 [61440/90000 (68%)]	Loss: 4.1642	Cost: 5.84s
Train Epoch: 1129 [81920/90000 (91%)]	Loss: 4.1639	Cost: 5.73s
Train Epoch: 1129 	Average Loss: 4.8904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5636

Learning rate: 0.00019993710558183504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1130 [0/90000 (0%)]	Loss: 13.0513	Cost: 28.29s
Train Epoch: 1130 [20480/90000 (23%)]	Loss: 4.2347	Cost: 6.11s
Train Epoch: 1130 [40960/90000 (45%)]	Loss: 4.1248	Cost: 7.40s
Train Epoch: 1130 [61440/90000 (68%)]	Loss: 4.2627	Cost: 6.05s
Train Epoch: 1130 [81920/90000 (91%)]	Loss: 3.9712	Cost: 5.97s
Train Epoch: 1130 	Average Loss: 4.8474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6552

Learning rate: 0.000199936994128046
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1131 [0/90000 (0%)]	Loss: 12.9957	Cost: 23.60s
Train Epoch: 1131 [20480/90000 (23%)]	Loss: 4.3339	Cost: 6.10s
Train Epoch: 1131 [40960/90000 (45%)]	Loss: 4.2166	Cost: 7.81s
Train Epoch: 1131 [61440/90000 (68%)]	Loss: 4.1067	Cost: 5.91s
Train Epoch: 1131 [81920/90000 (91%)]	Loss: 4.0950	Cost: 7.74s
Train Epoch: 1131 	Average Loss: 4.8099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6598

Learning rate: 0.0001999368825756231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1132 [0/90000 (0%)]	Loss: 13.1336	Cost: 23.38s
Train Epoch: 1132 [20480/90000 (23%)]	Loss: 4.3117	Cost: 6.00s
Train Epoch: 1132 [40960/90000 (45%)]	Loss: 4.2069	Cost: 6.23s
Train Epoch: 1132 [61440/90000 (68%)]	Loss: 4.1073	Cost: 6.13s
Train Epoch: 1132 [81920/90000 (91%)]	Loss: 4.0571	Cost: 7.94s
Train Epoch: 1132 	Average Loss: 4.8135
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6749

Learning rate: 0.00019993677092456643
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1133 [0/90000 (0%)]	Loss: 12.9099	Cost: 23.90s
Train Epoch: 1133 [20480/90000 (23%)]	Loss: 4.2653	Cost: 6.34s
Train Epoch: 1133 [40960/90000 (45%)]	Loss: 4.3278	Cost: 7.35s
Train Epoch: 1133 [61440/90000 (68%)]	Loss: 4.0827	Cost: 6.49s
Train Epoch: 1133 [81920/90000 (91%)]	Loss: 4.3058	Cost: 5.80s
Train Epoch: 1133 	Average Loss: 4.8690
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7329

Learning rate: 0.00019993665917487612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1134 [0/90000 (0%)]	Loss: 13.0205	Cost: 23.69s
Train Epoch: 1134 [20480/90000 (23%)]	Loss: 4.3094	Cost: 6.17s
Train Epoch: 1134 [40960/90000 (45%)]	Loss: 4.2568	Cost: 6.63s
Train Epoch: 1134 [61440/90000 (68%)]	Loss: 4.1042	Cost: 6.18s
Train Epoch: 1134 [81920/90000 (91%)]	Loss: 3.9956	Cost: 6.26s
Train Epoch: 1134 	Average Loss: 4.9245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6586

Learning rate: 0.0001999365473265523
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1135 [0/90000 (0%)]	Loss: 13.2246	Cost: 29.62s
Train Epoch: 1135 [20480/90000 (23%)]	Loss: 4.1920	Cost: 6.03s
Train Epoch: 1135 [40960/90000 (45%)]	Loss: 4.1095	Cost: 7.49s
Train Epoch: 1135 [61440/90000 (68%)]	Loss: 4.1160	Cost: 6.14s
Train Epoch: 1135 [81920/90000 (91%)]	Loss: 4.1275	Cost: 5.71s
Train Epoch: 1135 	Average Loss: 4.8783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7815

Learning rate: 0.00019993643537959504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1136 [0/90000 (0%)]	Loss: 13.2339	Cost: 26.98s
Train Epoch: 1136 [20480/90000 (23%)]	Loss: 4.3708	Cost: 6.04s
Train Epoch: 1136 [40960/90000 (45%)]	Loss: 4.1986	Cost: 7.87s
Train Epoch: 1136 [61440/90000 (68%)]	Loss: 4.1006	Cost: 6.14s
Train Epoch: 1136 [81920/90000 (91%)]	Loss: 3.9886	Cost: 6.43s
Train Epoch: 1136 	Average Loss: 4.8339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6143

Learning rate: 0.0001999363233340045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1137 [0/90000 (0%)]	Loss: 13.1352	Cost: 22.98s
Train Epoch: 1137 [20480/90000 (23%)]	Loss: 4.3174	Cost: 6.00s
Train Epoch: 1137 [40960/90000 (45%)]	Loss: 4.1062	Cost: 6.97s
Train Epoch: 1137 [61440/90000 (68%)]	Loss: 4.0799	Cost: 5.97s
Train Epoch: 1137 [81920/90000 (91%)]	Loss: 4.2907	Cost: 8.43s
Train Epoch: 1137 	Average Loss: 4.8079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6468

Learning rate: 0.00019993621118978076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1138 [0/90000 (0%)]	Loss: 12.9396	Cost: 24.32s
Train Epoch: 1138 [20480/90000 (23%)]	Loss: 4.3325	Cost: 5.98s
Train Epoch: 1138 [40960/90000 (45%)]	Loss: 4.4632	Cost: 7.37s
Train Epoch: 1138 [61440/90000 (68%)]	Loss: 4.2603	Cost: 5.89s
Train Epoch: 1138 [81920/90000 (91%)]	Loss: 4.2356	Cost: 5.60s
Train Epoch: 1138 	Average Loss: 5.0222
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6504

Learning rate: 0.00019993609894692393
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1139 [0/90000 (0%)]	Loss: 12.9759	Cost: 23.30s
Train Epoch: 1139 [20480/90000 (23%)]	Loss: 4.4992	Cost: 6.20s
Train Epoch: 1139 [40960/90000 (45%)]	Loss: 4.2631	Cost: 7.43s
Train Epoch: 1139 [61440/90000 (68%)]	Loss: 4.3878	Cost: 6.42s
Train Epoch: 1139 [81920/90000 (91%)]	Loss: 4.1045	Cost: 6.25s
Train Epoch: 1139 	Average Loss: 4.9439
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6380

Learning rate: 0.0001999359866054341
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1140 [0/90000 (0%)]	Loss: 13.1740	Cost: 25.56s
Train Epoch: 1140 [20480/90000 (23%)]	Loss: 4.1826	Cost: 6.23s
Train Epoch: 1140 [40960/90000 (45%)]	Loss: 4.2379	Cost: 7.26s
Train Epoch: 1140 [61440/90000 (68%)]	Loss: 4.0846	Cost: 6.05s
Train Epoch: 1140 [81920/90000 (91%)]	Loss: 4.1740	Cost: 5.79s
Train Epoch: 1140 	Average Loss: 4.8685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6450

Learning rate: 0.00019993587416531144
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1141 [0/90000 (0%)]	Loss: 13.1878	Cost: 26.47s
Train Epoch: 1141 [20480/90000 (23%)]	Loss: 4.1179	Cost: 6.09s
Train Epoch: 1141 [40960/90000 (45%)]	Loss: 4.0761	Cost: 7.21s
Train Epoch: 1141 [61440/90000 (68%)]	Loss: 4.0398	Cost: 6.08s
Train Epoch: 1141 [81920/90000 (91%)]	Loss: 4.0193	Cost: 5.81s
Train Epoch: 1141 	Average Loss: 4.7595
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8029

Learning rate: 0.00019993576162655603
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1142 [0/90000 (0%)]	Loss: 13.2976	Cost: 22.87s
Train Epoch: 1142 [20480/90000 (23%)]	Loss: 4.0593	Cost: 5.98s
Train Epoch: 1142 [40960/90000 (45%)]	Loss: 4.0809	Cost: 7.78s
Train Epoch: 1142 [61440/90000 (68%)]	Loss: 3.8906	Cost: 5.96s
Train Epoch: 1142 [81920/90000 (91%)]	Loss: 4.0605	Cost: 8.39s
Train Epoch: 1142 	Average Loss: 4.7305
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6746

Learning rate: 0.00019993564898916795
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1143 [0/90000 (0%)]	Loss: 13.0786	Cost: 23.46s
Train Epoch: 1143 [20480/90000 (23%)]	Loss: 3.9386	Cost: 6.44s
Train Epoch: 1143 [40960/90000 (45%)]	Loss: 4.0230	Cost: 6.51s
Train Epoch: 1143 [61440/90000 (68%)]	Loss: 3.8950	Cost: 5.95s
Train Epoch: 1143 [81920/90000 (91%)]	Loss: 4.0343	Cost: 5.76s
Train Epoch: 1143 	Average Loss: 4.6384
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7891

Learning rate: 0.00019993553625314737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1144 [0/90000 (0%)]	Loss: 12.9698	Cost: 23.64s
Train Epoch: 1144 [20480/90000 (23%)]	Loss: 3.8860	Cost: 6.03s
Train Epoch: 1144 [40960/90000 (45%)]	Loss: 4.1536	Cost: 7.32s
Train Epoch: 1144 [61440/90000 (68%)]	Loss: 4.2773	Cost: 6.07s
Train Epoch: 1144 [81920/90000 (91%)]	Loss: 4.3425	Cost: 6.12s
Train Epoch: 1144 	Average Loss: 4.7785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7659

Learning rate: 0.00019993542341849435
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1145 [0/90000 (0%)]	Loss: 13.2530	Cost: 25.32s
Train Epoch: 1145 [20480/90000 (23%)]	Loss: 4.3392	Cost: 6.16s
Train Epoch: 1145 [40960/90000 (45%)]	Loss: 4.2882	Cost: 7.09s
Train Epoch: 1145 [61440/90000 (68%)]	Loss: 4.1302	Cost: 5.99s
Train Epoch: 1145 [81920/90000 (91%)]	Loss: 4.2789	Cost: 5.80s
Train Epoch: 1145 	Average Loss: 4.8811
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6346

Learning rate: 0.000199935310485209
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1146 [0/90000 (0%)]	Loss: 13.2767	Cost: 28.16s
Train Epoch: 1146 [20480/90000 (23%)]	Loss: 4.1648	Cost: 6.63s
Train Epoch: 1146 [40960/90000 (45%)]	Loss: 4.1292	Cost: 7.94s
Train Epoch: 1146 [61440/90000 (68%)]	Loss: 4.0641	Cost: 5.87s
Train Epoch: 1146 [81920/90000 (91%)]	Loss: 4.0604	Cost: 7.05s
Train Epoch: 1146 	Average Loss: 4.7853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7285

Learning rate: 0.00019993519745329147
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1147 [0/90000 (0%)]	Loss: 13.2063	Cost: 24.36s
Train Epoch: 1147 [20480/90000 (23%)]	Loss: 4.3072	Cost: 6.00s
Train Epoch: 1147 [40960/90000 (45%)]	Loss: 4.1097	Cost: 7.73s
Train Epoch: 1147 [61440/90000 (68%)]	Loss: 4.0672	Cost: 5.93s
Train Epoch: 1147 [81920/90000 (91%)]	Loss: 4.0809	Cost: 8.12s
Train Epoch: 1147 	Average Loss: 4.8413
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7450

Learning rate: 0.00019993508432274184
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1148 [0/90000 (0%)]	Loss: 13.1737	Cost: 23.82s
Train Epoch: 1148 [20480/90000 (23%)]	Loss: 4.0665	Cost: 5.95s
Train Epoch: 1148 [40960/90000 (45%)]	Loss: 3.9148	Cost: 6.59s
Train Epoch: 1148 [61440/90000 (68%)]	Loss: 3.9286	Cost: 6.10s
Train Epoch: 1148 [81920/90000 (91%)]	Loss: 3.6275	Cost: 5.89s
Train Epoch: 1148 	Average Loss: 4.6548
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8693

Learning rate: 0.00019993497109356025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1149 [0/90000 (0%)]	Loss: 13.2582	Cost: 24.79s
Train Epoch: 1149 [20480/90000 (23%)]	Loss: 3.9773	Cost: 6.15s
Train Epoch: 1149 [40960/90000 (45%)]	Loss: 4.1098	Cost: 6.55s
Train Epoch: 1149 [61440/90000 (68%)]	Loss: 3.7551	Cost: 6.03s
Train Epoch: 1149 [81920/90000 (91%)]	Loss: 3.8300	Cost: 6.18s
Train Epoch: 1149 	Average Loss: 4.6400
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7481

Learning rate: 0.00019993485776574678
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1150 [0/90000 (0%)]	Loss: 13.1330	Cost: 25.73s
Train Epoch: 1150 [20480/90000 (23%)]	Loss: 3.9923	Cost: 6.15s
Train Epoch: 1150 [40960/90000 (45%)]	Loss: 4.0457	Cost: 6.45s
Train Epoch: 1150 [61440/90000 (68%)]	Loss: 3.8808	Cost: 6.03s
Train Epoch: 1150 [81920/90000 (91%)]	Loss: 4.1279	Cost: 6.53s
Train Epoch: 1150 	Average Loss: 4.6817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7886

Learning rate: 0.00019993474433930157
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1151 [0/90000 (0%)]	Loss: 13.2743	Cost: 29.97s
Train Epoch: 1151 [20480/90000 (23%)]	Loss: 3.9965	Cost: 6.10s
Train Epoch: 1151 [40960/90000 (45%)]	Loss: 4.2222	Cost: 7.35s
Train Epoch: 1151 [61440/90000 (68%)]	Loss: 4.0841	Cost: 6.26s
Train Epoch: 1151 [81920/90000 (91%)]	Loss: 4.1414	Cost: 6.22s
Train Epoch: 1151 	Average Loss: 4.7670
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7452

Learning rate: 0.00019993463081422472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1152 [0/90000 (0%)]	Loss: 13.3028	Cost: 27.19s
Train Epoch: 1152 [20480/90000 (23%)]	Loss: 4.1479	Cost: 6.03s
Train Epoch: 1152 [40960/90000 (45%)]	Loss: 4.0056	Cost: 9.19s
Train Epoch: 1152 [61440/90000 (68%)]	Loss: 3.8347	Cost: 5.93s
Train Epoch: 1152 [81920/90000 (91%)]	Loss: 3.8192	Cost: 7.87s
Train Epoch: 1152 	Average Loss: 4.7205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7963

Learning rate: 0.00019993451719051635
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1153 [0/90000 (0%)]	Loss: 13.2172	Cost: 22.91s
Train Epoch: 1153 [20480/90000 (23%)]	Loss: 3.9748	Cost: 5.98s
Train Epoch: 1153 [40960/90000 (45%)]	Loss: 4.0460	Cost: 7.14s
Train Epoch: 1153 [61440/90000 (68%)]	Loss: 3.8523	Cost: 6.23s
Train Epoch: 1153 [81920/90000 (91%)]	Loss: 3.8938	Cost: 8.33s
Train Epoch: 1153 	Average Loss: 4.6101
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7707

Learning rate: 0.00019993440346817654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1154 [0/90000 (0%)]	Loss: 13.2955	Cost: 24.04s
Train Epoch: 1154 [20480/90000 (23%)]	Loss: 4.0786	Cost: 6.12s
Train Epoch: 1154 [40960/90000 (45%)]	Loss: 4.0199	Cost: 6.78s
Train Epoch: 1154 [61440/90000 (68%)]	Loss: 3.9879	Cost: 5.82s
Train Epoch: 1154 [81920/90000 (91%)]	Loss: 3.9017	Cost: 5.77s
Train Epoch: 1154 	Average Loss: 4.6529
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7632

Learning rate: 0.00019993428964720544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1155 [0/90000 (0%)]	Loss: 13.3731	Cost: 24.86s
Train Epoch: 1155 [20480/90000 (23%)]	Loss: 3.8982	Cost: 6.10s
Train Epoch: 1155 [40960/90000 (45%)]	Loss: 3.9671	Cost: 7.95s
Train Epoch: 1155 [61440/90000 (68%)]	Loss: 3.8285	Cost: 6.19s
Train Epoch: 1155 [81920/90000 (91%)]	Loss: 3.9517	Cost: 6.29s
Train Epoch: 1155 	Average Loss: 4.6293
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7811

Learning rate: 0.00019993417572760315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1156 [0/90000 (0%)]	Loss: 13.3954	Cost: 24.38s
Train Epoch: 1156 [20480/90000 (23%)]	Loss: 4.0488	Cost: 6.29s
Train Epoch: 1156 [40960/90000 (45%)]	Loss: 3.8699	Cost: 6.49s
Train Epoch: 1156 [61440/90000 (68%)]	Loss: 4.0846	Cost: 5.99s
Train Epoch: 1156 [81920/90000 (91%)]	Loss: 4.0021	Cost: 6.71s
Train Epoch: 1156 	Average Loss: 4.6475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7410

Learning rate: 0.0001999340617093698
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1157 [0/90000 (0%)]	Loss: 13.1551	Cost: 28.22s
Train Epoch: 1157 [20480/90000 (23%)]	Loss: 4.0600	Cost: 6.25s
Train Epoch: 1157 [40960/90000 (45%)]	Loss: 3.9691	Cost: 6.75s
Train Epoch: 1157 [61440/90000 (68%)]	Loss: 3.7791	Cost: 6.31s
Train Epoch: 1157 [81920/90000 (91%)]	Loss: 4.0384	Cost: 5.78s
Train Epoch: 1157 	Average Loss: 4.6561
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8072

Learning rate: 0.00019993394759250545
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1158 [0/90000 (0%)]	Loss: 13.4841	Cost: 25.38s
Train Epoch: 1158 [20480/90000 (23%)]	Loss: 4.2841	Cost: 6.02s
Train Epoch: 1158 [40960/90000 (45%)]	Loss: 4.2562	Cost: 8.18s
Train Epoch: 1158 [61440/90000 (68%)]	Loss: 4.0675	Cost: 5.83s
Train Epoch: 1158 [81920/90000 (91%)]	Loss: 4.0861	Cost: 8.31s
Train Epoch: 1158 	Average Loss: 4.8082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8044

Learning rate: 0.0001999338333770103
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1159 [0/90000 (0%)]	Loss: 13.3690	Cost: 24.02s
Train Epoch: 1159 [20480/90000 (23%)]	Loss: 4.0949	Cost: 6.11s
Train Epoch: 1159 [40960/90000 (45%)]	Loss: 4.1357	Cost: 6.63s
Train Epoch: 1159 [61440/90000 (68%)]	Loss: 3.8408	Cost: 6.35s
Train Epoch: 1159 [81920/90000 (91%)]	Loss: 3.9178	Cost: 6.70s
Train Epoch: 1159 	Average Loss: 4.6729
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7258

Learning rate: 0.00019993371906288436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1160 [0/90000 (0%)]	Loss: 13.2207	Cost: 23.93s
Train Epoch: 1160 [20480/90000 (23%)]	Loss: 3.9959	Cost: 6.12s
Train Epoch: 1160 [40960/90000 (45%)]	Loss: 3.7235	Cost: 7.04s
Train Epoch: 1160 [61440/90000 (68%)]	Loss: 4.1251	Cost: 6.02s
Train Epoch: 1160 [81920/90000 (91%)]	Loss: 4.0939	Cost: 6.23s
Train Epoch: 1160 	Average Loss: 4.7107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8268

Learning rate: 0.0001999336046501278
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1161 [0/90000 (0%)]	Loss: 13.4477	Cost: 24.25s
Train Epoch: 1161 [20480/90000 (23%)]	Loss: 3.8472	Cost: 5.96s
Train Epoch: 1161 [40960/90000 (45%)]	Loss: 4.1339	Cost: 7.35s
Train Epoch: 1161 [61440/90000 (68%)]	Loss: 4.1948	Cost: 6.31s
Train Epoch: 1161 [81920/90000 (91%)]	Loss: 4.2824	Cost: 6.03s
Train Epoch: 1161 	Average Loss: 4.7610
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8318

Learning rate: 0.00019993349013874075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1162 [0/90000 (0%)]	Loss: 13.2023	Cost: 30.43s
Train Epoch: 1162 [20480/90000 (23%)]	Loss: 4.0282	Cost: 6.11s
Train Epoch: 1162 [40960/90000 (45%)]	Loss: 4.0602	Cost: 7.24s
Train Epoch: 1162 [61440/90000 (68%)]	Loss: 4.0595	Cost: 6.00s
Train Epoch: 1162 [81920/90000 (91%)]	Loss: 3.7708	Cost: 6.13s
Train Epoch: 1162 	Average Loss: 4.7121
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7267

Learning rate: 0.00019993337552872326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1163 [0/90000 (0%)]	Loss: 13.0055	Cost: 25.21s
Train Epoch: 1163 [20480/90000 (23%)]	Loss: 4.0988	Cost: 6.02s
Train Epoch: 1163 [40960/90000 (45%)]	Loss: 3.8518	Cost: 8.63s
Train Epoch: 1163 [61440/90000 (68%)]	Loss: 4.0143	Cost: 6.83s
Train Epoch: 1163 [81920/90000 (91%)]	Loss: 3.9415	Cost: 7.52s
Train Epoch: 1163 	Average Loss: 4.6081
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8056

Learning rate: 0.0001999332608200755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1164 [0/90000 (0%)]	Loss: 13.3127	Cost: 23.66s
Train Epoch: 1164 [20480/90000 (23%)]	Loss: 4.0283	Cost: 6.13s
Train Epoch: 1164 [40960/90000 (45%)]	Loss: 4.0452	Cost: 6.31s
Train Epoch: 1164 [61440/90000 (68%)]	Loss: 4.0662	Cost: 6.25s
Train Epoch: 1164 [81920/90000 (91%)]	Loss: 3.9267	Cost: 8.51s
Train Epoch: 1164 	Average Loss: 4.6876
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7355

Learning rate: 0.00019993314601279757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1165 [0/90000 (0%)]	Loss: 13.1082	Cost: 24.03s
Train Epoch: 1165 [20480/90000 (23%)]	Loss: 3.9641	Cost: 6.11s
Train Epoch: 1165 [40960/90000 (45%)]	Loss: 3.9629	Cost: 7.16s
Train Epoch: 1165 [61440/90000 (68%)]	Loss: 3.9481	Cost: 6.12s
Train Epoch: 1165 [81920/90000 (91%)]	Loss: 3.7085	Cost: 5.74s
Train Epoch: 1165 	Average Loss: 4.6060
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7447

Learning rate: 0.00019993303110688956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1166 [0/90000 (0%)]	Loss: 13.2230	Cost: 23.24s
Train Epoch: 1166 [20480/90000 (23%)]	Loss: 3.9222	Cost: 5.92s
Train Epoch: 1166 [40960/90000 (45%)]	Loss: 3.8539	Cost: 7.39s
Train Epoch: 1166 [61440/90000 (68%)]	Loss: 4.0212	Cost: 6.09s
Train Epoch: 1166 [81920/90000 (91%)]	Loss: 3.9107	Cost: 6.45s
Train Epoch: 1166 	Average Loss: 4.5798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7948

Learning rate: 0.0001999329161023516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1167 [0/90000 (0%)]	Loss: 13.0788	Cost: 27.44s
Train Epoch: 1167 [20480/90000 (23%)]	Loss: 4.0316	Cost: 5.98s
Train Epoch: 1167 [40960/90000 (45%)]	Loss: 4.0200	Cost: 7.24s
Train Epoch: 1167 [61440/90000 (68%)]	Loss: 4.1075	Cost: 6.20s
Train Epoch: 1167 [81920/90000 (91%)]	Loss: 4.0632	Cost: 6.26s
Train Epoch: 1167 	Average Loss: 4.6424
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9085

Learning rate: 0.00019993280099918386
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1168 [0/90000 (0%)]	Loss: 13.2925	Cost: 23.36s
Train Epoch: 1168 [20480/90000 (23%)]	Loss: 3.8888	Cost: 6.04s
Train Epoch: 1168 [40960/90000 (45%)]	Loss: 4.1456	Cost: 7.90s
Train Epoch: 1168 [61440/90000 (68%)]	Loss: 3.9412	Cost: 6.01s
Train Epoch: 1168 [81920/90000 (91%)]	Loss: 4.1874	Cost: 7.83s
Train Epoch: 1168 	Average Loss: 4.6684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8220

Learning rate: 0.00019993268579738635
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1169 [0/90000 (0%)]	Loss: 13.3945	Cost: 23.03s
Train Epoch: 1169 [20480/90000 (23%)]	Loss: 3.9354	Cost: 6.08s
Train Epoch: 1169 [40960/90000 (45%)]	Loss: 4.0330	Cost: 6.20s
Train Epoch: 1169 [61440/90000 (68%)]	Loss: 3.8652	Cost: 6.50s
Train Epoch: 1169 [81920/90000 (91%)]	Loss: 3.9523	Cost: 7.54s
Train Epoch: 1169 	Average Loss: 4.6322
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8600

Learning rate: 0.00019993257049695927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1170 [0/90000 (0%)]	Loss: 13.1652	Cost: 24.01s
Train Epoch: 1170 [20480/90000 (23%)]	Loss: 3.7168	Cost: 6.17s
Train Epoch: 1170 [40960/90000 (45%)]	Loss: 3.8260	Cost: 6.51s
Train Epoch: 1170 [61440/90000 (68%)]	Loss: 3.9078	Cost: 5.96s
Train Epoch: 1170 [81920/90000 (91%)]	Loss: 3.9675	Cost: 5.77s
Train Epoch: 1170 	Average Loss: 4.5284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7917

Learning rate: 0.00019993245509790266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1171 [0/90000 (0%)]	Loss: 13.5539	Cost: 24.30s
Train Epoch: 1171 [20480/90000 (23%)]	Loss: 3.7294	Cost: 5.90s
Train Epoch: 1171 [40960/90000 (45%)]	Loss: 3.7385	Cost: 7.28s
Train Epoch: 1171 [61440/90000 (68%)]	Loss: 3.9529	Cost: 6.10s
Train Epoch: 1171 [81920/90000 (91%)]	Loss: 4.0129	Cost: 5.74s
Train Epoch: 1171 	Average Loss: 4.5635
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7975

Learning rate: 0.00019993233960021668
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1172 [0/90000 (0%)]	Loss: 13.4511	Cost: 27.47s
Train Epoch: 1172 [20480/90000 (23%)]	Loss: 4.0841	Cost: 5.96s
Train Epoch: 1172 [40960/90000 (45%)]	Loss: 3.9578	Cost: 7.59s
Train Epoch: 1172 [61440/90000 (68%)]	Loss: 4.0783	Cost: 5.81s
Train Epoch: 1172 [81920/90000 (91%)]	Loss: 4.1458	Cost: 6.54s
Train Epoch: 1172 	Average Loss: 4.6774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8004

Learning rate: 0.00019993222400390142
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1173 [0/90000 (0%)]	Loss: 13.1912	Cost: 28.80s
Train Epoch: 1173 [20480/90000 (23%)]	Loss: 4.0361	Cost: 5.99s
Train Epoch: 1173 [40960/90000 (45%)]	Loss: 4.2819	Cost: 9.03s
Train Epoch: 1173 [61440/90000 (68%)]	Loss: 4.0574	Cost: 6.07s
Train Epoch: 1173 [81920/90000 (91%)]	Loss: 3.8777	Cost: 7.55s
Train Epoch: 1173 	Average Loss: 4.7336
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8478

Learning rate: 0.00019993210830895701
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1174 [0/90000 (0%)]	Loss: 13.1834	Cost: 24.81s
Train Epoch: 1174 [20480/90000 (23%)]	Loss: 4.0416	Cost: 5.98s
Train Epoch: 1174 [40960/90000 (45%)]	Loss: 3.9753	Cost: 7.72s
Train Epoch: 1174 [61440/90000 (68%)]	Loss: 3.7646	Cost: 5.93s
Train Epoch: 1174 [81920/90000 (91%)]	Loss: 3.7688	Cost: 8.23s
Train Epoch: 1174 	Average Loss: 4.5815
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8089

Learning rate: 0.00019993199251538358
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1175 [0/90000 (0%)]	Loss: 13.2265	Cost: 23.31s
Train Epoch: 1175 [20480/90000 (23%)]	Loss: 3.6890	Cost: 5.97s
Train Epoch: 1175 [40960/90000 (45%)]	Loss: 3.7567	Cost: 6.90s
Train Epoch: 1175 [61440/90000 (68%)]	Loss: 3.9308	Cost: 6.20s
Train Epoch: 1175 [81920/90000 (91%)]	Loss: 3.8630	Cost: 6.19s
Train Epoch: 1175 	Average Loss: 4.4902
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7504

Learning rate: 0.00019993187662318122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1176 [0/90000 (0%)]	Loss: 13.5023	Cost: 24.09s
Train Epoch: 1176 [20480/90000 (23%)]	Loss: 4.1329	Cost: 6.13s
Train Epoch: 1176 [40960/90000 (45%)]	Loss: 3.9176	Cost: 7.47s
Train Epoch: 1176 [61440/90000 (68%)]	Loss: 3.7173	Cost: 6.02s
Train Epoch: 1176 [81920/90000 (91%)]	Loss: 3.7520	Cost: 5.97s
Train Epoch: 1176 	Average Loss: 4.6702
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7987

Learning rate: 0.00019993176063235005
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1177 [0/90000 (0%)]	Loss: 13.5916	Cost: 23.84s
Train Epoch: 1177 [20480/90000 (23%)]	Loss: 3.9191	Cost: 6.07s
Train Epoch: 1177 [40960/90000 (45%)]	Loss: 3.8954	Cost: 7.45s
Train Epoch: 1177 [61440/90000 (68%)]	Loss: 3.8240	Cost: 6.31s
Train Epoch: 1177 [81920/90000 (91%)]	Loss: 3.6978	Cost: 6.69s
Train Epoch: 1177 	Average Loss: 4.5853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8086

Learning rate: 0.00019993164454289018
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1178 [0/90000 (0%)]	Loss: 13.2252	Cost: 29.71s
Train Epoch: 1178 [20480/90000 (23%)]	Loss: 3.9177	Cost: 6.44s
Train Epoch: 1178 [40960/90000 (45%)]	Loss: 3.9643	Cost: 7.45s
Train Epoch: 1178 [61440/90000 (68%)]	Loss: 3.8046	Cost: 5.88s
Train Epoch: 1178 [81920/90000 (91%)]	Loss: 4.0023	Cost: 5.84s
Train Epoch: 1178 	Average Loss: 4.5619
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8678

Learning rate: 0.00019993152835480173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1179 [0/90000 (0%)]	Loss: 13.2729	Cost: 26.88s
Train Epoch: 1179 [20480/90000 (23%)]	Loss: 3.6465	Cost: 6.12s
Train Epoch: 1179 [40960/90000 (45%)]	Loss: 3.5642	Cost: 7.64s
Train Epoch: 1179 [61440/90000 (68%)]	Loss: 3.6142	Cost: 6.29s
Train Epoch: 1179 [81920/90000 (91%)]	Loss: 3.9451	Cost: 6.88s
Train Epoch: 1179 	Average Loss: 4.4959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8477

Learning rate: 0.00019993141206808485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1180 [0/90000 (0%)]	Loss: 13.2019	Cost: 22.84s
Train Epoch: 1180 [20480/90000 (23%)]	Loss: 3.8949	Cost: 6.04s
Train Epoch: 1180 [40960/90000 (45%)]	Loss: 3.7547	Cost: 7.99s
Train Epoch: 1180 [61440/90000 (68%)]	Loss: 3.7636	Cost: 5.98s
Train Epoch: 1180 [81920/90000 (91%)]	Loss: 3.7539	Cost: 9.37s
Train Epoch: 1180 	Average Loss: 4.5582
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8295

Learning rate: 0.0001999312956827396
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1181 [0/90000 (0%)]	Loss: 13.3889	Cost: 24.20s
Train Epoch: 1181 [20480/90000 (23%)]	Loss: 3.8627	Cost: 6.14s
Train Epoch: 1181 [40960/90000 (45%)]	Loss: 3.7227	Cost: 6.29s
Train Epoch: 1181 [61440/90000 (68%)]	Loss: 3.6798	Cost: 6.29s
Train Epoch: 1181 [81920/90000 (91%)]	Loss: 3.7325	Cost: 5.82s
Train Epoch: 1181 	Average Loss: 4.5163
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8745

Learning rate: 0.00019993117919876613
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1182 [0/90000 (0%)]	Loss: 13.3313	Cost: 24.60s
Train Epoch: 1182 [20480/90000 (23%)]	Loss: 4.0299	Cost: 6.22s
Train Epoch: 1182 [40960/90000 (45%)]	Loss: 3.8350	Cost: 7.33s
Train Epoch: 1182 [61440/90000 (68%)]	Loss: 4.0624	Cost: 5.98s
Train Epoch: 1182 [81920/90000 (91%)]	Loss: 3.9544	Cost: 6.08s
Train Epoch: 1182 	Average Loss: 4.6288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8723

Learning rate: 0.0001999310626161645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1183 [0/90000 (0%)]	Loss: 13.4026	Cost: 24.45s
Train Epoch: 1183 [20480/90000 (23%)]	Loss: 3.7380	Cost: 6.24s
Train Epoch: 1183 [40960/90000 (45%)]	Loss: 3.8485	Cost: 6.77s
Train Epoch: 1183 [61440/90000 (68%)]	Loss: 3.7310	Cost: 6.23s
Train Epoch: 1183 [81920/90000 (91%)]	Loss: 3.7465	Cost: 6.12s
Train Epoch: 1183 	Average Loss: 4.5309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8915

Learning rate: 0.00019993094593493492
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1184 [0/90000 (0%)]	Loss: 13.3865	Cost: 29.55s
Train Epoch: 1184 [20480/90000 (23%)]	Loss: 3.9186	Cost: 6.06s
Train Epoch: 1184 [40960/90000 (45%)]	Loss: 3.8974	Cost: 7.71s
Train Epoch: 1184 [61440/90000 (68%)]	Loss: 3.6522	Cost: 6.14s
Train Epoch: 1184 [81920/90000 (91%)]	Loss: 3.7675	Cost: 6.15s
Train Epoch: 1184 	Average Loss: 4.5177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9609

Learning rate: 0.0001999308291550774
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1185 [0/90000 (0%)]	Loss: 13.2383	Cost: 25.63s
Train Epoch: 1185 [20480/90000 (23%)]	Loss: 3.7539	Cost: 6.03s
Train Epoch: 1185 [40960/90000 (45%)]	Loss: 3.7246	Cost: 7.68s
Train Epoch: 1185 [61440/90000 (68%)]	Loss: 3.6414	Cost: 6.03s
Train Epoch: 1185 [81920/90000 (91%)]	Loss: 3.6561	Cost: 6.81s
Train Epoch: 1185 	Average Loss: 4.4138
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9395

Learning rate: 0.00019993071227659214
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1186 [0/90000 (0%)]	Loss: 13.2920	Cost: 23.11s
Train Epoch: 1186 [20480/90000 (23%)]	Loss: 3.7215	Cost: 6.14s
Train Epoch: 1186 [40960/90000 (45%)]	Loss: 3.4737	Cost: 6.41s
Train Epoch: 1186 [61440/90000 (68%)]	Loss: 3.6177	Cost: 6.06s
Train Epoch: 1186 [81920/90000 (91%)]	Loss: 3.6061	Cost: 8.91s
Train Epoch: 1186 	Average Loss: 4.3143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9123

Learning rate: 0.0001999305952994792
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1187 [0/90000 (0%)]	Loss: 13.3808	Cost: 23.84s
Train Epoch: 1187 [20480/90000 (23%)]	Loss: 3.6878	Cost: 6.13s
Train Epoch: 1187 [40960/90000 (45%)]	Loss: 3.4887	Cost: 6.93s
Train Epoch: 1187 [61440/90000 (68%)]	Loss: 3.6057	Cost: 6.24s
Train Epoch: 1187 [81920/90000 (91%)]	Loss: 3.5675	Cost: 5.74s
Train Epoch: 1187 	Average Loss: 4.3581
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9655

Learning rate: 0.0001999304782237387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1188 [0/90000 (0%)]	Loss: 13.3125	Cost: 22.29s
Train Epoch: 1188 [20480/90000 (23%)]	Loss: 3.9613	Cost: 6.07s
Train Epoch: 1188 [40960/90000 (45%)]	Loss: 3.7288	Cost: 6.56s
Train Epoch: 1188 [61440/90000 (68%)]	Loss: 3.7491	Cost: 5.95s
Train Epoch: 1188 [81920/90000 (91%)]	Loss: 3.4744	Cost: 5.82s
Train Epoch: 1188 	Average Loss: 4.3714
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9808

Learning rate: 0.0001999303610493708
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1189 [0/90000 (0%)]	Loss: 13.3410	Cost: 23.04s
Train Epoch: 1189 [20480/90000 (23%)]	Loss: 3.8436	Cost: 6.14s
Train Epoch: 1189 [40960/90000 (45%)]	Loss: 3.6520	Cost: 6.69s
Train Epoch: 1189 [61440/90000 (68%)]	Loss: 3.5093	Cost: 6.24s
Train Epoch: 1189 [81920/90000 (91%)]	Loss: 3.7044	Cost: 6.16s
Train Epoch: 1189 	Average Loss: 4.3481
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9311

Learning rate: 0.0001999302437763756
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1190 [0/90000 (0%)]	Loss: 13.6117	Cost: 22.75s
Train Epoch: 1190 [20480/90000 (23%)]	Loss: 3.6197	Cost: 6.15s
Train Epoch: 1190 [40960/90000 (45%)]	Loss: 3.5206	Cost: 6.71s
Train Epoch: 1190 [61440/90000 (68%)]	Loss: 3.6893	Cost: 6.05s
Train Epoch: 1190 [81920/90000 (91%)]	Loss: 3.4796	Cost: 6.22s
Train Epoch: 1190 	Average Loss: 4.3297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0241

Learning rate: 0.00019993012640475317
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1191 [0/90000 (0%)]	Loss: 13.3534	Cost: 23.53s
Train Epoch: 1191 [20480/90000 (23%)]	Loss: 3.8860	Cost: 6.25s
Train Epoch: 1191 [40960/90000 (45%)]	Loss: 3.5673	Cost: 6.59s
Train Epoch: 1191 [61440/90000 (68%)]	Loss: 3.5733	Cost: 6.23s
Train Epoch: 1191 [81920/90000 (91%)]	Loss: 3.6452	Cost: 5.84s
Train Epoch: 1191 	Average Loss: 4.3757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9944

Learning rate: 0.00019993000893450363
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1192 [0/90000 (0%)]	Loss: 13.2279	Cost: 22.56s
Train Epoch: 1192 [20480/90000 (23%)]	Loss: 3.4544	Cost: 6.10s
Train Epoch: 1192 [40960/90000 (45%)]	Loss: 3.8008	Cost: 6.79s
Train Epoch: 1192 [61440/90000 (68%)]	Loss: 3.6740	Cost: 6.03s
Train Epoch: 1192 [81920/90000 (91%)]	Loss: 3.4373	Cost: 6.21s
Train Epoch: 1192 	Average Loss: 4.2937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9565

Learning rate: 0.00019992989136562717
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1193 [0/90000 (0%)]	Loss: 13.0390	Cost: 23.82s
Train Epoch: 1193 [20480/90000 (23%)]	Loss: 3.7213	Cost: 6.07s
Train Epoch: 1193 [40960/90000 (45%)]	Loss: 3.6464	Cost: 6.70s
Train Epoch: 1193 [61440/90000 (68%)]	Loss: 3.6435	Cost: 6.17s
Train Epoch: 1193 [81920/90000 (91%)]	Loss: 3.7138	Cost: 6.09s
Train Epoch: 1193 	Average Loss: 4.3074
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9814

Learning rate: 0.00019992977369812385
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1194 [0/90000 (0%)]	Loss: 13.5344	Cost: 26.93s
Train Epoch: 1194 [20480/90000 (23%)]	Loss: 3.5056	Cost: 6.14s
Train Epoch: 1194 [40960/90000 (45%)]	Loss: 3.3554	Cost: 7.60s
Train Epoch: 1194 [61440/90000 (68%)]	Loss: 3.6104	Cost: 6.07s
Train Epoch: 1194 [81920/90000 (91%)]	Loss: 3.3593	Cost: 5.92s
Train Epoch: 1194 	Average Loss: 4.2935
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0497

Learning rate: 0.00019992965593199378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1195 [0/90000 (0%)]	Loss: 13.3762	Cost: 28.78s
Train Epoch: 1195 [20480/90000 (23%)]	Loss: 3.6649	Cost: 6.20s
Train Epoch: 1195 [40960/90000 (45%)]	Loss: 3.5607	Cost: 6.87s
Train Epoch: 1195 [61440/90000 (68%)]	Loss: 3.5355	Cost: 6.32s
Train Epoch: 1195 [81920/90000 (91%)]	Loss: 3.6135	Cost: 6.24s
Train Epoch: 1195 	Average Loss: 4.3257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0513

Learning rate: 0.00019992953806723712
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1196 [0/90000 (0%)]	Loss: 13.2302	Cost: 24.60s
Train Epoch: 1196 [20480/90000 (23%)]	Loss: 3.5869	Cost: 5.99s
Train Epoch: 1196 [40960/90000 (45%)]	Loss: 3.3832	Cost: 7.75s
Train Epoch: 1196 [61440/90000 (68%)]	Loss: 3.8935	Cost: 5.87s
Train Epoch: 1196 [81920/90000 (91%)]	Loss: 3.7533	Cost: 7.23s
Train Epoch: 1196 	Average Loss: 4.3510
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9768

Learning rate: 0.00019992942010385397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1197 [0/90000 (0%)]	Loss: 13.2682	Cost: 24.24s
Train Epoch: 1197 [20480/90000 (23%)]	Loss: 3.8645	Cost: 6.15s
Train Epoch: 1197 [40960/90000 (45%)]	Loss: 3.7813	Cost: 6.65s
Train Epoch: 1197 [61440/90000 (68%)]	Loss: 3.8228	Cost: 5.97s
Train Epoch: 1197 [81920/90000 (91%)]	Loss: 3.8629	Cost: 5.70s
Train Epoch: 1197 	Average Loss: 4.4492
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9766

Learning rate: 0.0001999293020418444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1198 [0/90000 (0%)]	Loss: 13.1823	Cost: 23.94s
Train Epoch: 1198 [20480/90000 (23%)]	Loss: 3.6846	Cost: 6.22s
Train Epoch: 1198 [40960/90000 (45%)]	Loss: 4.2997	Cost: 7.61s
Train Epoch: 1198 [61440/90000 (68%)]	Loss: 3.9662	Cost: 6.21s
Train Epoch: 1198 [81920/90000 (91%)]	Loss: 4.0225	Cost: 6.59s
Train Epoch: 1198 	Average Loss: 4.6685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9852

Learning rate: 0.00019992918388120855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1199 [0/90000 (0%)]	Loss: 13.5268	Cost: 24.54s
Train Epoch: 1199 [20480/90000 (23%)]	Loss: 3.9378	Cost: 6.00s
Train Epoch: 1199 [40960/90000 (45%)]	Loss: 3.5705	Cost: 6.87s
Train Epoch: 1199 [61440/90000 (68%)]	Loss: 3.7391	Cost: 6.19s
Train Epoch: 1199 [81920/90000 (91%)]	Loss: 3.7531	Cost: 7.35s
Train Epoch: 1199 	Average Loss: 4.4943
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8430

Learning rate: 0.00019992906562194657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1200 [0/90000 (0%)]	Loss: 13.2899	Cost: 29.91s
Train Epoch: 1200 [20480/90000 (23%)]	Loss: 3.6099	Cost: 6.13s
Train Epoch: 1200 [40960/90000 (45%)]	Loss: 3.7004	Cost: 7.30s
Train Epoch: 1200 [61440/90000 (68%)]	Loss: 3.4818	Cost: 6.04s
Train Epoch: 1200 [81920/90000 (91%)]	Loss: 3.8142	Cost: 6.48s
Train Epoch: 1200 	Average Loss: 4.3844
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9405

Learning rate: 0.00019992894726405855
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1201 [0/90000 (0%)]	Loss: 13.2821	Cost: 25.17s
Train Epoch: 1201 [20480/90000 (23%)]	Loss: 3.5780	Cost: 6.08s
Train Epoch: 1201 [40960/90000 (45%)]	Loss: 3.4334	Cost: 7.98s
Train Epoch: 1201 [61440/90000 (68%)]	Loss: 3.7185	Cost: 6.12s
Train Epoch: 1201 [81920/90000 (91%)]	Loss: 3.8262	Cost: 7.39s
Train Epoch: 1201 	Average Loss: 4.3625
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0149

Learning rate: 0.00019992882880754464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1202 [0/90000 (0%)]	Loss: 13.2478	Cost: 22.55s
Train Epoch: 1202 [20480/90000 (23%)]	Loss: 3.7148	Cost: 6.01s
Train Epoch: 1202 [40960/90000 (45%)]	Loss: 3.6142	Cost: 6.51s
Train Epoch: 1202 [61440/90000 (68%)]	Loss: 3.6934	Cost: 6.04s
Train Epoch: 1202 [81920/90000 (91%)]	Loss: 3.6456	Cost: 8.22s
Train Epoch: 1202 	Average Loss: 4.3864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9537

Learning rate: 0.0001999287102524049
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1203 [0/90000 (0%)]	Loss: 13.0722	Cost: 24.21s
Train Epoch: 1203 [20480/90000 (23%)]	Loss: 3.4895	Cost: 6.10s
Train Epoch: 1203 [40960/90000 (45%)]	Loss: 3.6348	Cost: 7.51s
Train Epoch: 1203 [61440/90000 (68%)]	Loss: 3.7902	Cost: 6.04s
Train Epoch: 1203 [81920/90000 (91%)]	Loss: 3.8202	Cost: 6.61s
Train Epoch: 1203 	Average Loss: 4.3745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9755

Learning rate: 0.0001999285915986395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1204 [0/90000 (0%)]	Loss: 13.4666	Cost: 24.04s
Train Epoch: 1204 [20480/90000 (23%)]	Loss: 3.7161	Cost: 5.99s
Train Epoch: 1204 [40960/90000 (45%)]	Loss: 3.4949	Cost: 6.78s
Train Epoch: 1204 [61440/90000 (68%)]	Loss: 3.4586	Cost: 6.09s
Train Epoch: 1204 [81920/90000 (91%)]	Loss: 3.6491	Cost: 5.57s
Train Epoch: 1204 	Average Loss: 4.3047
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0153

Learning rate: 0.00019992847284624853
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1205 [0/90000 (0%)]	Loss: 13.4303	Cost: 30.26s
Train Epoch: 1205 [20480/90000 (23%)]	Loss: 3.5336	Cost: 6.11s
Train Epoch: 1205 [40960/90000 (45%)]	Loss: 3.6690	Cost: 7.73s
Train Epoch: 1205 [61440/90000 (68%)]	Loss: 3.6101	Cost: 6.10s
Train Epoch: 1205 [81920/90000 (91%)]	Loss: 3.6962	Cost: 6.18s
Train Epoch: 1205 	Average Loss: 4.2896
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9696

Learning rate: 0.00019992835399523207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1206 [0/90000 (0%)]	Loss: 13.7394	Cost: 27.52s
Train Epoch: 1206 [20480/90000 (23%)]	Loss: 3.5687	Cost: 6.13s
Train Epoch: 1206 [40960/90000 (45%)]	Loss: 3.5344	Cost: 8.45s
Train Epoch: 1206 [61440/90000 (68%)]	Loss: 3.5434	Cost: 5.98s
Train Epoch: 1206 [81920/90000 (91%)]	Loss: 3.5415	Cost: 7.45s
Train Epoch: 1206 	Average Loss: 4.2082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0999

Learning rate: 0.00019992823504559032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1207 [0/90000 (0%)]	Loss: 13.3597	Cost: 22.18s
Train Epoch: 1207 [20480/90000 (23%)]	Loss: 3.5742	Cost: 6.10s
Train Epoch: 1207 [40960/90000 (45%)]	Loss: 3.4304	Cost: 7.71s
Train Epoch: 1207 [61440/90000 (68%)]	Loss: 3.3935	Cost: 6.21s
Train Epoch: 1207 [81920/90000 (91%)]	Loss: 3.3558	Cost: 8.50s
Train Epoch: 1207 	Average Loss: 4.2139
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0845

Learning rate: 0.00019992811599732333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1208 [0/90000 (0%)]	Loss: 13.2910	Cost: 23.81s
Train Epoch: 1208 [20480/90000 (23%)]	Loss: 3.3876	Cost: 6.17s
Train Epoch: 1208 [40960/90000 (45%)]	Loss: 3.3787	Cost: 6.57s
Train Epoch: 1208 [61440/90000 (68%)]	Loss: 3.6133	Cost: 5.84s
Train Epoch: 1208 [81920/90000 (91%)]	Loss: 3.4641	Cost: 6.15s
Train Epoch: 1208 	Average Loss: 4.2161
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0811

Learning rate: 0.00019992799685043125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1209 [0/90000 (0%)]	Loss: 13.1995	Cost: 23.90s
Train Epoch: 1209 [20480/90000 (23%)]	Loss: 3.4650	Cost: 6.17s
Train Epoch: 1209 [40960/90000 (45%)]	Loss: 3.5104	Cost: 6.35s
Train Epoch: 1209 [61440/90000 (68%)]	Loss: 3.5846	Cost: 6.14s
Train Epoch: 1209 [81920/90000 (91%)]	Loss: 3.5206	Cost: 5.58s
Train Epoch: 1209 	Average Loss: 4.2335
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9993

Learning rate: 0.00019992787760491417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1210 [0/90000 (0%)]	Loss: 13.2571	Cost: 25.76s
Train Epoch: 1210 [20480/90000 (23%)]	Loss: 3.6651	Cost: 6.20s
Train Epoch: 1210 [40960/90000 (45%)]	Loss: 3.3655	Cost: 6.78s
Train Epoch: 1210 [61440/90000 (68%)]	Loss: 3.3387	Cost: 6.04s
Train Epoch: 1210 [81920/90000 (91%)]	Loss: 3.2504	Cost: 6.33s
Train Epoch: 1210 	Average Loss: 4.1676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9904

Learning rate: 0.00019992775826077226
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1211 [0/90000 (0%)]	Loss: 13.6775	Cost: 29.31s
Train Epoch: 1211 [20480/90000 (23%)]	Loss: 3.1497	Cost: 6.10s
Train Epoch: 1211 [40960/90000 (45%)]	Loss: 3.2486	Cost: 8.49s
Train Epoch: 1211 [61440/90000 (68%)]	Loss: 3.4731	Cost: 6.04s
Train Epoch: 1211 [81920/90000 (91%)]	Loss: 3.7734	Cost: 5.70s
Train Epoch: 1211 	Average Loss: 4.1486
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1130

Learning rate: 0.0001999276388180056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1212 [0/90000 (0%)]	Loss: 13.5014	Cost: 22.48s
Train Epoch: 1212 [20480/90000 (23%)]	Loss: 3.8079	Cost: 6.02s
Train Epoch: 1212 [40960/90000 (45%)]	Loss: 3.6905	Cost: 7.94s
Train Epoch: 1212 [61440/90000 (68%)]	Loss: 3.6162	Cost: 5.92s
Train Epoch: 1212 [81920/90000 (91%)]	Loss: 3.5795	Cost: 8.60s
Train Epoch: 1212 	Average Loss: 4.3264
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1529

Learning rate: 0.00019992751927661433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1213 [0/90000 (0%)]	Loss: 13.4878	Cost: 24.00s
Train Epoch: 1213 [20480/90000 (23%)]	Loss: 3.6224	Cost: 6.17s
Train Epoch: 1213 [40960/90000 (45%)]	Loss: 3.5744	Cost: 6.34s
Train Epoch: 1213 [61440/90000 (68%)]	Loss: 3.4052	Cost: 6.17s
Train Epoch: 1213 [81920/90000 (91%)]	Loss: 3.3831	Cost: 7.80s
Train Epoch: 1213 	Average Loss: 4.2105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1342

Learning rate: 0.00019992739963659852
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1214 [0/90000 (0%)]	Loss: 13.6571	Cost: 23.17s
Train Epoch: 1214 [20480/90000 (23%)]	Loss: 3.5985	Cost: 6.11s
Train Epoch: 1214 [40960/90000 (45%)]	Loss: 3.6128	Cost: 7.27s
Train Epoch: 1214 [61440/90000 (68%)]	Loss: 3.4453	Cost: 6.00s
Train Epoch: 1214 [81920/90000 (91%)]	Loss: 3.6051	Cost: 6.68s
Train Epoch: 1214 	Average Loss: 4.3137
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0524

Learning rate: 0.00019992727989795832
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1215 [0/90000 (0%)]	Loss: 13.3838	Cost: 23.66s
Train Epoch: 1215 [20480/90000 (23%)]	Loss: 3.4250	Cost: 6.20s
Train Epoch: 1215 [40960/90000 (45%)]	Loss: 3.6319	Cost: 6.97s
Train Epoch: 1215 [61440/90000 (68%)]	Loss: 3.5238	Cost: 6.33s
Train Epoch: 1215 [81920/90000 (91%)]	Loss: 3.4169	Cost: 6.04s
Train Epoch: 1215 	Average Loss: 4.2225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0648

Learning rate: 0.0001999271600606939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1216 [0/90000 (0%)]	Loss: 13.7126	Cost: 29.52s
Train Epoch: 1216 [20480/90000 (23%)]	Loss: 3.5403	Cost: 6.13s
Train Epoch: 1216 [40960/90000 (45%)]	Loss: 3.7554	Cost: 7.60s
Train Epoch: 1216 [61440/90000 (68%)]	Loss: 3.5939	Cost: 5.88s
Train Epoch: 1216 [81920/90000 (91%)]	Loss: 3.3132	Cost: 6.85s
Train Epoch: 1216 	Average Loss: 4.2249
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0234

Learning rate: 0.00019992704012480525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1217 [0/90000 (0%)]	Loss: 13.6016	Cost: 26.18s
Train Epoch: 1217 [20480/90000 (23%)]	Loss: 3.3665	Cost: 5.98s
Train Epoch: 1217 [40960/90000 (45%)]	Loss: 3.3325	Cost: 7.93s
Train Epoch: 1217 [61440/90000 (68%)]	Loss: 3.3122	Cost: 6.28s
Train Epoch: 1217 [81920/90000 (91%)]	Loss: 3.2680	Cost: 6.55s
Train Epoch: 1217 	Average Loss: 4.0612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1047

Learning rate: 0.00019992692009029262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1218 [0/90000 (0%)]	Loss: 13.5317	Cost: 22.87s
Train Epoch: 1218 [20480/90000 (23%)]	Loss: 3.5154	Cost: 6.02s
Train Epoch: 1218 [40960/90000 (45%)]	Loss: 3.3251	Cost: 6.91s
Train Epoch: 1218 [61440/90000 (68%)]	Loss: 3.1623	Cost: 6.17s
Train Epoch: 1218 [81920/90000 (91%)]	Loss: 3.2696	Cost: 8.41s
Train Epoch: 1218 	Average Loss: 4.0623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0956

Learning rate: 0.00019992679995715608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1219 [0/90000 (0%)]	Loss: 13.5553	Cost: 24.00s
Train Epoch: 1219 [20480/90000 (23%)]	Loss: 3.4931	Cost: 5.99s
Train Epoch: 1219 [40960/90000 (45%)]	Loss: 3.4764	Cost: 7.19s
Train Epoch: 1219 [61440/90000 (68%)]	Loss: 3.4881	Cost: 6.26s
Train Epoch: 1219 [81920/90000 (91%)]	Loss: 3.5225	Cost: 6.19s
Train Epoch: 1219 	Average Loss: 4.1348
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0654

Learning rate: 0.00019992667972539572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1220 [0/90000 (0%)]	Loss: 13.2883	Cost: 22.75s
Train Epoch: 1220 [20480/90000 (23%)]	Loss: 3.4262	Cost: 5.97s
Train Epoch: 1220 [40960/90000 (45%)]	Loss: 3.2790	Cost: 6.29s
Train Epoch: 1220 [61440/90000 (68%)]	Loss: 3.2564	Cost: 5.96s
Train Epoch: 1220 [81920/90000 (91%)]	Loss: 3.2666	Cost: 5.53s
Train Epoch: 1220 	Average Loss: 4.0864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0621

Learning rate: 0.00019992655939501169
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1221 [0/90000 (0%)]	Loss: 13.5781	Cost: 26.98s
Train Epoch: 1221 [20480/90000 (23%)]	Loss: 3.2891	Cost: 6.04s
Train Epoch: 1221 [40960/90000 (45%)]	Loss: 3.3614	Cost: 7.85s
Train Epoch: 1221 [61440/90000 (68%)]	Loss: 3.4102	Cost: 6.49s
Train Epoch: 1221 [81920/90000 (91%)]	Loss: 3.3869	Cost: 5.98s
Train Epoch: 1221 	Average Loss: 4.0962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0867

Learning rate: 0.0001999264389660041
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1222 [0/90000 (0%)]	Loss: 13.5315	Cost: 26.69s
Train Epoch: 1222 [20480/90000 (23%)]	Loss: 3.3643	Cost: 6.03s
Train Epoch: 1222 [40960/90000 (45%)]	Loss: 3.3547	Cost: 8.88s
Train Epoch: 1222 [61440/90000 (68%)]	Loss: 3.2590	Cost: 6.02s
Train Epoch: 1222 [81920/90000 (91%)]	Loss: 3.6519	Cost: 6.72s
Train Epoch: 1222 	Average Loss: 4.0765
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1211

Learning rate: 0.00019992631843837304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1223 [0/90000 (0%)]	Loss: 13.5537	Cost: 23.82s
Train Epoch: 1223 [20480/90000 (23%)]	Loss: 3.6342	Cost: 6.12s
Train Epoch: 1223 [40960/90000 (45%)]	Loss: 3.8803	Cost: 7.07s
Train Epoch: 1223 [61440/90000 (68%)]	Loss: 3.8933	Cost: 6.23s
Train Epoch: 1223 [81920/90000 (91%)]	Loss: 3.9480	Cost: 8.62s
Train Epoch: 1223 	Average Loss: 4.5237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1430

Learning rate: 0.00019992619781211864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1224 [0/90000 (0%)]	Loss: 13.6601	Cost: 24.49s
Train Epoch: 1224 [20480/90000 (23%)]	Loss: 4.2215	Cost: 6.10s
Train Epoch: 1224 [40960/90000 (45%)]	Loss: 3.8128	Cost: 7.20s
Train Epoch: 1224 [61440/90000 (68%)]	Loss: 3.8878	Cost: 5.94s
Train Epoch: 1224 [81920/90000 (91%)]	Loss: 3.7124	Cost: 6.25s
Train Epoch: 1224 	Average Loss: 4.6277
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0733

Learning rate: 0.0001999260770872411
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1225 [0/90000 (0%)]	Loss: 13.5023	Cost: 23.87s
Train Epoch: 1225 [20480/90000 (23%)]	Loss: 3.6591	Cost: 5.95s
Train Epoch: 1225 [40960/90000 (45%)]	Loss: 3.6680	Cost: 6.82s
Train Epoch: 1225 [61440/90000 (68%)]	Loss: 3.6766	Cost: 6.30s
Train Epoch: 1225 [81920/90000 (91%)]	Loss: 3.5745	Cost: 5.77s
Train Epoch: 1225 	Average Loss: 4.3735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0577

Learning rate: 0.00019992595626374044
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1226 [0/90000 (0%)]	Loss: 13.5566	Cost: 29.28s
Train Epoch: 1226 [20480/90000 (23%)]	Loss: 3.8271	Cost: 6.03s
Train Epoch: 1226 [40960/90000 (45%)]	Loss: 3.6981	Cost: 7.59s
Train Epoch: 1226 [61440/90000 (68%)]	Loss: 3.8053	Cost: 6.06s
Train Epoch: 1226 [81920/90000 (91%)]	Loss: 3.7243	Cost: 5.73s
Train Epoch: 1226 	Average Loss: 4.4833
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1179

Learning rate: 0.00019992583534161684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1227 [0/90000 (0%)]	Loss: 13.5228	Cost: 28.96s
Train Epoch: 1227 [20480/90000 (23%)]	Loss: 3.5116	Cost: 6.03s
Train Epoch: 1227 [40960/90000 (45%)]	Loss: 3.4638	Cost: 8.42s
Train Epoch: 1227 [61440/90000 (68%)]	Loss: 3.4311	Cost: 6.09s
Train Epoch: 1227 [81920/90000 (91%)]	Loss: 3.4987	Cost: 6.17s
Train Epoch: 1227 	Average Loss: 4.2597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1738

Learning rate: 0.00019992571432087038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1228 [0/90000 (0%)]	Loss: 13.6627	Cost: 23.49s
Train Epoch: 1228 [20480/90000 (23%)]	Loss: 3.4501	Cost: 5.98s
Train Epoch: 1228 [40960/90000 (45%)]	Loss: 3.2299	Cost: 7.81s
Train Epoch: 1228 [61440/90000 (68%)]	Loss: 3.3554	Cost: 6.04s
Train Epoch: 1228 [81920/90000 (91%)]	Loss: 3.2607	Cost: 8.97s
Train Epoch: 1228 	Average Loss: 4.0566
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1410

Learning rate: 0.00019992559320150118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1229 [0/90000 (0%)]	Loss: 13.5950	Cost: 24.25s
Train Epoch: 1229 [20480/90000 (23%)]	Loss: 3.3216	Cost: 6.06s
Train Epoch: 1229 [40960/90000 (45%)]	Loss: 3.5790	Cost: 7.20s
Train Epoch: 1229 [61440/90000 (68%)]	Loss: 3.4702	Cost: 5.95s
Train Epoch: 1229 [81920/90000 (91%)]	Loss: 3.4397	Cost: 5.90s
Train Epoch: 1229 	Average Loss: 4.1304
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0831

Learning rate: 0.00019992547198350937
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1230 [0/90000 (0%)]	Loss: 13.6579	Cost: 23.04s
Train Epoch: 1230 [20480/90000 (23%)]	Loss: 3.2858	Cost: 6.17s
Train Epoch: 1230 [40960/90000 (45%)]	Loss: 3.4238	Cost: 7.09s
Train Epoch: 1230 [61440/90000 (68%)]	Loss: 3.5291	Cost: 5.91s
Train Epoch: 1230 [81920/90000 (91%)]	Loss: 3.6278	Cost: 6.45s
Train Epoch: 1230 	Average Loss: 4.1956
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0819

Learning rate: 0.00019992535066689507
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1231 [0/90000 (0%)]	Loss: 13.6315	Cost: 25.72s
Train Epoch: 1231 [20480/90000 (23%)]	Loss: 3.4905	Cost: 6.20s
Train Epoch: 1231 [40960/90000 (45%)]	Loss: 3.4885	Cost: 7.22s
Train Epoch: 1231 [61440/90000 (68%)]	Loss: 3.5356	Cost: 6.21s
Train Epoch: 1231 [81920/90000 (91%)]	Loss: 3.4273	Cost: 6.02s
Train Epoch: 1231 	Average Loss: 4.2302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1316

Learning rate: 0.0001999252292516584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1232 [0/90000 (0%)]	Loss: 13.5382	Cost: 28.60s
Train Epoch: 1232 [20480/90000 (23%)]	Loss: 3.5792	Cost: 6.10s
Train Epoch: 1232 [40960/90000 (45%)]	Loss: 3.4524	Cost: 6.62s
Train Epoch: 1232 [61440/90000 (68%)]	Loss: 3.2568	Cost: 5.96s
Train Epoch: 1232 [81920/90000 (91%)]	Loss: 3.3455	Cost: 5.71s
Train Epoch: 1232 	Average Loss: 4.2099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0817

Learning rate: 0.0001999251077377995
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1233 [0/90000 (0%)]	Loss: 13.3554	Cost: 23.23s
Train Epoch: 1233 [20480/90000 (23%)]	Loss: 3.4038	Cost: 6.02s
Train Epoch: 1233 [40960/90000 (45%)]	Loss: 3.1066	Cost: 8.31s
Train Epoch: 1233 [61440/90000 (68%)]	Loss: 3.3412	Cost: 6.08s
Train Epoch: 1233 [81920/90000 (91%)]	Loss: 3.1917	Cost: 8.10s
Train Epoch: 1233 	Average Loss: 4.1155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1655

Learning rate: 0.00019992498612531848
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1234 [0/90000 (0%)]	Loss: 13.5997	Cost: 23.97s
Train Epoch: 1234 [20480/90000 (23%)]	Loss: 3.3600	Cost: 6.33s
Train Epoch: 1234 [40960/90000 (45%)]	Loss: 3.1351	Cost: 6.27s
Train Epoch: 1234 [61440/90000 (68%)]	Loss: 3.2738	Cost: 6.20s
Train Epoch: 1234 [81920/90000 (91%)]	Loss: 3.5494	Cost: 6.97s
Train Epoch: 1234 	Average Loss: 4.0287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.2056

Learning rate: 0.00019992486441421542
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1235 [0/90000 (0%)]	Loss: 13.3878	Cost: 25.34s
Train Epoch: 1235 [20480/90000 (23%)]	Loss: 3.3079	Cost: 6.11s
Train Epoch: 1235 [40960/90000 (45%)]	Loss: 3.1957	Cost: 7.32s
Train Epoch: 1235 [61440/90000 (68%)]	Loss: 3.1190	Cost: 6.12s
Train Epoch: 1235 [81920/90000 (91%)]	Loss: 3.2870	Cost: 5.73s
Train Epoch: 1235 	Average Loss: 3.9749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1455

Learning rate: 0.0001999247426044905
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1236 [0/90000 (0%)]	Loss: 13.5807	Cost: 23.32s
Train Epoch: 1236 [20480/90000 (23%)]	Loss: 3.2027	Cost: 6.00s
Train Epoch: 1236 [40960/90000 (45%)]	Loss: 3.2315	Cost: 7.71s
Train Epoch: 1236 [61440/90000 (68%)]	Loss: 3.1563	Cost: 6.12s
Train Epoch: 1236 [81920/90000 (91%)]	Loss: 3.3718	Cost: 6.40s
Train Epoch: 1236 	Average Loss: 4.0041
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0808

Learning rate: 0.0001999246206961438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1237 [0/90000 (0%)]	Loss: 13.8380	Cost: 26.39s
Train Epoch: 1237 [20480/90000 (23%)]	Loss: 3.1906	Cost: 5.96s
Train Epoch: 1237 [40960/90000 (45%)]	Loss: 3.1120	Cost: 6.72s
Train Epoch: 1237 [61440/90000 (68%)]	Loss: 3.0475	Cost: 6.11s
Train Epoch: 1237 [81920/90000 (91%)]	Loss: 3.1703	Cost: 5.72s
Train Epoch: 1237 	Average Loss: 3.9768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1776

Learning rate: 0.00019992449868917544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1238 [0/90000 (0%)]	Loss: 13.6474	Cost: 26.47s
Train Epoch: 1238 [20480/90000 (23%)]	Loss: 3.2157	Cost: 5.98s
Train Epoch: 1238 [40960/90000 (45%)]	Loss: 3.0967	Cost: 9.56s
Train Epoch: 1238 [61440/90000 (68%)]	Loss: 3.0316	Cost: 5.84s
Train Epoch: 1238 [81920/90000 (91%)]	Loss: 3.5092	Cost: 9.52s
Train Epoch: 1238 	Average Loss: 3.9527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1743

Learning rate: 0.00019992437658358558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1239 [0/90000 (0%)]	Loss: 13.5255	Cost: 24.67s
Train Epoch: 1239 [20480/90000 (23%)]	Loss: 3.5300	Cost: 5.94s
Train Epoch: 1239 [40960/90000 (45%)]	Loss: 3.3005	Cost: 7.20s
Train Epoch: 1239 [61440/90000 (68%)]	Loss: 3.5350	Cost: 6.02s
Train Epoch: 1239 [81920/90000 (91%)]	Loss: 3.5403	Cost: 8.80s
Train Epoch: 1239 	Average Loss: 4.1275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1752

Learning rate: 0.0001999242543793743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1240 [0/90000 (0%)]	Loss: 13.3604	Cost: 23.61s
Train Epoch: 1240 [20480/90000 (23%)]	Loss: 3.4607	Cost: 5.98s
Train Epoch: 1240 [40960/90000 (45%)]	Loss: 3.1577	Cost: 6.77s
Train Epoch: 1240 [61440/90000 (68%)]	Loss: 3.2995	Cost: 6.06s
Train Epoch: 1240 [81920/90000 (91%)]	Loss: 3.0745	Cost: 5.72s
Train Epoch: 1240 	Average Loss: 4.0231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1270

Learning rate: 0.0001999241320765417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1241 [0/90000 (0%)]	Loss: 13.5376	Cost: 24.46s
Train Epoch: 1241 [20480/90000 (23%)]	Loss: 3.3144	Cost: 6.15s
Train Epoch: 1241 [40960/90000 (45%)]	Loss: 3.2153	Cost: 6.72s
Train Epoch: 1241 [61440/90000 (68%)]	Loss: 3.4099	Cost: 6.13s
Train Epoch: 1241 [81920/90000 (91%)]	Loss: 3.5563	Cost: 5.93s
Train Epoch: 1241 	Average Loss: 4.1203
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1981

Learning rate: 0.000199924009675088
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1242 [0/90000 (0%)]	Loss: 13.5659	Cost: 24.48s
Train Epoch: 1242 [20480/90000 (23%)]	Loss: 3.3795	Cost: 6.04s
Train Epoch: 1242 [40960/90000 (45%)]	Loss: 3.3179	Cost: 6.90s
Train Epoch: 1242 [61440/90000 (68%)]	Loss: 2.9866	Cost: 6.43s
Train Epoch: 1242 [81920/90000 (91%)]	Loss: 3.1370	Cost: 5.83s
Train Epoch: 1242 	Average Loss: 3.9909
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.2367

Learning rate: 0.0001999238871750132
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1243 [0/90000 (0%)]	Loss: 13.9936	Cost: 27.03s
Train Epoch: 1243 [20480/90000 (23%)]	Loss: 3.1989	Cost: 6.05s
Train Epoch: 1243 [40960/90000 (45%)]	Loss: 3.0192	Cost: 7.36s
Train Epoch: 1243 [61440/90000 (68%)]	Loss: 3.1429	Cost: 6.10s
Train Epoch: 1243 [81920/90000 (91%)]	Loss: 2.9594	Cost: 6.45s
Train Epoch: 1243 	Average Loss: 3.8535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.2138

Learning rate: 0.0001999237645763175
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1244 [0/90000 (0%)]	Loss: 13.8636	Cost: 21.84s
Train Epoch: 1244 [20480/90000 (23%)]	Loss: 3.2772	Cost: 6.41s
Train Epoch: 1244 [40960/90000 (45%)]	Loss: 3.0781	Cost: 6.79s
Train Epoch: 1244 [61440/90000 (68%)]	Loss: 2.9592	Cost: 6.04s
Train Epoch: 1244 [81920/90000 (91%)]	Loss: 3.1955	Cost: 8.52s
Train Epoch: 1244 	Average Loss: 3.8768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1785

Learning rate: 0.000199923641879001
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1245 [0/90000 (0%)]	Loss: 13.8324	Cost: 23.79s
Train Epoch: 1245 [20480/90000 (23%)]	Loss: 3.0536	Cost: 5.99s
Train Epoch: 1245 [40960/90000 (45%)]	Loss: 3.0623	Cost: 7.93s
Train Epoch: 1245 [61440/90000 (68%)]	Loss: 3.0618	Cost: 5.91s
Train Epoch: 1245 [81920/90000 (91%)]	Loss: 2.8725	Cost: 6.04s
Train Epoch: 1245 	Average Loss: 3.8179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.2424

Learning rate: 0.00019992351908306382
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1246 [0/90000 (0%)]	Loss: 13.6705	Cost: 24.67s
Train Epoch: 1246 [20480/90000 (23%)]	Loss: 3.0195	Cost: 6.18s
Train Epoch: 1246 [40960/90000 (45%)]	Loss: 3.0256	Cost: 6.51s
Train Epoch: 1246 [61440/90000 (68%)]	Loss: 2.8742	Cost: 5.99s
Train Epoch: 1246 [81920/90000 (91%)]	Loss: 2.8875	Cost: 5.75s
Train Epoch: 1246 	Average Loss: 3.7819
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1779

Learning rate: 0.00019992339618850606
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1247 [0/90000 (0%)]	Loss: 13.6006	Cost: 26.44s
Train Epoch: 1247 [20480/90000 (23%)]	Loss: 3.2980	Cost: 6.16s
Train Epoch: 1247 [40960/90000 (45%)]	Loss: 3.0163	Cost: 7.31s
Train Epoch: 1247 [61440/90000 (68%)]	Loss: 2.9375	Cost: 6.01s
Train Epoch: 1247 [81920/90000 (91%)]	Loss: 3.2534	Cost: 6.01s
Train Epoch: 1247 	Average Loss: 3.8114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3216

Learning rate: 0.00019992327319532787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1248 [0/90000 (0%)]	Loss: 13.6791	Cost: 28.72s
Train Epoch: 1248 [20480/90000 (23%)]	Loss: 3.0328	Cost: 6.03s
Train Epoch: 1248 [40960/90000 (45%)]	Loss: 3.2432	Cost: 7.27s
Train Epoch: 1248 [61440/90000 (68%)]	Loss: 2.9224	Cost: 6.55s
Train Epoch: 1248 [81920/90000 (91%)]	Loss: 3.1714	Cost: 6.23s
Train Epoch: 1248 	Average Loss: 3.7906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.2156

Learning rate: 0.0001999231501035294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1249 [0/90000 (0%)]	Loss: 13.8177	Cost: 25.27s
Train Epoch: 1249 [20480/90000 (23%)]	Loss: 2.9856	Cost: 6.10s
Train Epoch: 1249 [40960/90000 (45%)]	Loss: 2.9132	Cost: 8.13s
Train Epoch: 1249 [61440/90000 (68%)]	Loss: 2.9054	Cost: 5.95s
Train Epoch: 1249 [81920/90000 (91%)]	Loss: 3.0598	Cost: 7.41s
Train Epoch: 1249 	Average Loss: 3.7470
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.2874

Learning rate: 0.00019992302691311067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1250 [0/90000 (0%)]	Loss: 13.7112	Cost: 23.66s
Train Epoch: 1250 [20480/90000 (23%)]	Loss: 3.1758	Cost: 6.21s
Train Epoch: 1250 [40960/90000 (45%)]	Loss: 2.8696	Cost: 6.36s
Train Epoch: 1250 [61440/90000 (68%)]	Loss: 2.9072	Cost: 6.18s
Train Epoch: 1250 [81920/90000 (91%)]	Loss: 2.9361	Cost: 6.45s
Train Epoch: 1250 	Average Loss: 3.7936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.2670

Learning rate: 0.00019992290362407192
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1251 [0/90000 (0%)]	Loss: 13.8355	Cost: 24.12s
Train Epoch: 1251 [20480/90000 (23%)]	Loss: 3.1496	Cost: 6.20s
Train Epoch: 1251 [40960/90000 (45%)]	Loss: 2.9384	Cost: 6.44s
Train Epoch: 1251 [61440/90000 (68%)]	Loss: 2.9573	Cost: 6.04s
Train Epoch: 1251 [81920/90000 (91%)]	Loss: 3.0526	Cost: 5.89s
Train Epoch: 1251 	Average Loss: 3.8552
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3366

Learning rate: 0.00019992278023641319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1252 [0/90000 (0%)]	Loss: 13.6957	Cost: 24.11s
Train Epoch: 1252 [20480/90000 (23%)]	Loss: 3.0334	Cost: 6.08s
Train Epoch: 1252 [40960/90000 (45%)]	Loss: 3.0796	Cost: 6.29s
Train Epoch: 1252 [61440/90000 (68%)]	Loss: 2.8983	Cost: 6.25s
Train Epoch: 1252 [81920/90000 (91%)]	Loss: 2.9982	Cost: 6.27s
Train Epoch: 1252 	Average Loss: 3.7648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3185

Learning rate: 0.00019992265675013464
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1253 [0/90000 (0%)]	Loss: 13.4337	Cost: 29.25s
Train Epoch: 1253 [20480/90000 (23%)]	Loss: 3.1909	Cost: 6.04s
Train Epoch: 1253 [40960/90000 (45%)]	Loss: 3.2372	Cost: 7.74s
Train Epoch: 1253 [61440/90000 (68%)]	Loss: 3.1060	Cost: 6.02s
Train Epoch: 1253 [81920/90000 (91%)]	Loss: 3.0864	Cost: 6.68s
Train Epoch: 1253 	Average Loss: 3.9508
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3066

Learning rate: 0.00019992253316523635
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1254 [0/90000 (0%)]	Loss: 13.7166	Cost: 23.82s
Train Epoch: 1254 [20480/90000 (23%)]	Loss: 2.9797	Cost: 6.04s
Train Epoch: 1254 [40960/90000 (45%)]	Loss: 3.0457	Cost: 7.84s
Train Epoch: 1254 [61440/90000 (68%)]	Loss: 2.8960	Cost: 6.01s
Train Epoch: 1254 [81920/90000 (91%)]	Loss: 2.9847	Cost: 7.08s
Train Epoch: 1254 	Average Loss: 3.7770
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4631

Learning rate: 0.0001999224094817185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1255 [0/90000 (0%)]	Loss: 13.7853	Cost: 23.51s
Train Epoch: 1255 [20480/90000 (23%)]	Loss: 2.9548	Cost: 6.11s
Train Epoch: 1255 [40960/90000 (45%)]	Loss: 2.9264	Cost: 6.50s
Train Epoch: 1255 [61440/90000 (68%)]	Loss: 2.9463	Cost: 6.05s
Train Epoch: 1255 [81920/90000 (91%)]	Loss: 2.8847	Cost: 6.58s
Train Epoch: 1255 	Average Loss: 3.7562
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3791

Learning rate: 0.00019992228569958118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1256 [0/90000 (0%)]	Loss: 13.5152	Cost: 25.16s
Train Epoch: 1256 [20480/90000 (23%)]	Loss: 2.8852	Cost: 6.23s
Train Epoch: 1256 [40960/90000 (45%)]	Loss: 3.0215	Cost: 7.27s
Train Epoch: 1256 [61440/90000 (68%)]	Loss: 3.0760	Cost: 5.96s
Train Epoch: 1256 [81920/90000 (91%)]	Loss: 2.9604	Cost: 5.89s
Train Epoch: 1256 	Average Loss: 3.7399
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4112

Learning rate: 0.0001999221618188245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1257 [0/90000 (0%)]	Loss: 13.7843	Cost: 23.67s
Train Epoch: 1257 [20480/90000 (23%)]	Loss: 3.0069	Cost: 5.96s
Train Epoch: 1257 [40960/90000 (45%)]	Loss: 2.9967	Cost: 7.49s
Train Epoch: 1257 [61440/90000 (68%)]	Loss: 2.8846	Cost: 6.36s
Train Epoch: 1257 [81920/90000 (91%)]	Loss: 2.7622	Cost: 6.16s
Train Epoch: 1257 	Average Loss: 3.7003
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3790

Learning rate: 0.00019992203783944864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1258 [0/90000 (0%)]	Loss: 13.6618	Cost: 28.48s
Train Epoch: 1258 [20480/90000 (23%)]	Loss: 2.9165	Cost: 5.99s
Train Epoch: 1258 [40960/90000 (45%)]	Loss: 2.9482	Cost: 7.75s
Train Epoch: 1258 [61440/90000 (68%)]	Loss: 2.7768	Cost: 5.96s
Train Epoch: 1258 [81920/90000 (91%)]	Loss: 2.9423	Cost: 6.11s
Train Epoch: 1258 	Average Loss: 3.6410
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3189

Learning rate: 0.00019992191376145364
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1259 [0/90000 (0%)]	Loss: 13.6223	Cost: 28.47s
Train Epoch: 1259 [20480/90000 (23%)]	Loss: 2.9009	Cost: 6.16s
Train Epoch: 1259 [40960/90000 (45%)]	Loss: 3.0594	Cost: 7.09s
Train Epoch: 1259 [61440/90000 (68%)]	Loss: 3.1408	Cost: 6.31s
Train Epoch: 1259 [81920/90000 (91%)]	Loss: 3.1245	Cost: 6.11s
Train Epoch: 1259 	Average Loss: 3.7840
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.2707

Learning rate: 0.0001999217895848397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1260 [0/90000 (0%)]	Loss: 13.7741	Cost: 22.11s
Train Epoch: 1260 [20480/90000 (23%)]	Loss: 2.9153	Cost: 6.05s
Train Epoch: 1260 [40960/90000 (45%)]	Loss: 3.0342	Cost: 6.98s
Train Epoch: 1260 [61440/90000 (68%)]	Loss: 3.1063	Cost: 6.12s
Train Epoch: 1260 [81920/90000 (91%)]	Loss: 3.3109	Cost: 8.61s
Train Epoch: 1260 	Average Loss: 3.9022
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.2732

Learning rate: 0.0001999216653096069
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1261 [0/90000 (0%)]	Loss: 13.6769	Cost: 24.15s
Train Epoch: 1261 [20480/90000 (23%)]	Loss: 3.0776	Cost: 5.94s
Train Epoch: 1261 [40960/90000 (45%)]	Loss: 2.9225	Cost: 6.94s
Train Epoch: 1261 [61440/90000 (68%)]	Loss: 2.9515	Cost: 6.18s
Train Epoch: 1261 [81920/90000 (91%)]	Loss: 3.0950	Cost: 5.90s
Train Epoch: 1261 	Average Loss: 3.8709
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.2561

Learning rate: 0.00019992154093575535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1262 [0/90000 (0%)]	Loss: 13.7191	Cost: 24.78s
Train Epoch: 1262 [20480/90000 (23%)]	Loss: 3.2662	Cost: 6.24s
Train Epoch: 1262 [40960/90000 (45%)]	Loss: 2.7792	Cost: 6.64s
Train Epoch: 1262 [61440/90000 (68%)]	Loss: 2.9204	Cost: 6.25s
Train Epoch: 1262 [81920/90000 (91%)]	Loss: 3.0096	Cost: 6.20s
Train Epoch: 1262 	Average Loss: 3.7926
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3376

Learning rate: 0.0001999214164632852
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1263 [0/90000 (0%)]	Loss: 13.8736	Cost: 26.87s
Train Epoch: 1263 [20480/90000 (23%)]	Loss: 3.2403	Cost: 6.06s
Train Epoch: 1263 [40960/90000 (45%)]	Loss: 3.1160	Cost: 7.61s
Train Epoch: 1263 [61440/90000 (68%)]	Loss: 3.0730	Cost: 5.85s
Train Epoch: 1263 [81920/90000 (91%)]	Loss: 3.1023	Cost: 6.46s
Train Epoch: 1263 	Average Loss: 3.8772
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3841

Learning rate: 0.00019992129189219657
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1264 [0/90000 (0%)]	Loss: 13.8026	Cost: 28.37s
Train Epoch: 1264 [20480/90000 (23%)]	Loss: 2.9264	Cost: 6.02s
Train Epoch: 1264 [40960/90000 (45%)]	Loss: 2.8797	Cost: 8.49s
Train Epoch: 1264 [61440/90000 (68%)]	Loss: 2.9438	Cost: 5.98s
Train Epoch: 1264 [81920/90000 (91%)]	Loss: 2.9362	Cost: 6.56s
Train Epoch: 1264 	Average Loss: 3.7736
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3698

Learning rate: 0.00019992116722248958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1265 [0/90000 (0%)]	Loss: 13.7110	Cost: 24.83s
Train Epoch: 1265 [20480/90000 (23%)]	Loss: 2.9452	Cost: 5.99s
Train Epoch: 1265 [40960/90000 (45%)]	Loss: 2.8054	Cost: 7.92s
Train Epoch: 1265 [61440/90000 (68%)]	Loss: 2.9882	Cost: 5.88s
Train Epoch: 1265 [81920/90000 (91%)]	Loss: 2.8437	Cost: 7.45s
Train Epoch: 1265 	Average Loss: 3.6403
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3680

Learning rate: 0.00019992104245416436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1266 [0/90000 (0%)]	Loss: 13.7531	Cost: 23.82s
Train Epoch: 1266 [20480/90000 (23%)]	Loss: 3.0923	Cost: 6.03s
Train Epoch: 1266 [40960/90000 (45%)]	Loss: 3.1953	Cost: 6.33s
Train Epoch: 1266 [61440/90000 (68%)]	Loss: 3.2419	Cost: 5.99s
Train Epoch: 1266 [81920/90000 (91%)]	Loss: 3.2284	Cost: 5.98s
Train Epoch: 1266 	Average Loss: 3.9208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3792

Learning rate: 0.000199920917587221
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1267 [0/90000 (0%)]	Loss: 13.7888	Cost: 24.09s
Train Epoch: 1267 [20480/90000 (23%)]	Loss: 3.1800	Cost: 6.24s
Train Epoch: 1267 [40960/90000 (45%)]	Loss: 3.2146	Cost: 7.56s
Train Epoch: 1267 [61440/90000 (68%)]	Loss: 3.0967	Cost: 5.96s
Train Epoch: 1267 [81920/90000 (91%)]	Loss: 3.1886	Cost: 6.92s
Train Epoch: 1267 	Average Loss: 3.9212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3361

Learning rate: 0.00019992079262165963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1268 [0/90000 (0%)]	Loss: 13.7011	Cost: 24.73s
Train Epoch: 1268 [20480/90000 (23%)]	Loss: 3.1307	Cost: 6.73s
Train Epoch: 1268 [40960/90000 (45%)]	Loss: 3.4050	Cost: 6.97s
Train Epoch: 1268 [61440/90000 (68%)]	Loss: 3.3823	Cost: 6.59s
Train Epoch: 1268 [81920/90000 (91%)]	Loss: 3.3317	Cost: 6.24s
Train Epoch: 1268 	Average Loss: 4.0589
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3402

Learning rate: 0.00019992066755748043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1269 [0/90000 (0%)]	Loss: 13.5461	Cost: 27.08s
Train Epoch: 1269 [20480/90000 (23%)]	Loss: 3.3509	Cost: 6.00s
Train Epoch: 1269 [40960/90000 (45%)]	Loss: 3.1233	Cost: 7.72s
Train Epoch: 1269 [61440/90000 (68%)]	Loss: 2.7675	Cost: 5.77s
Train Epoch: 1269 [81920/90000 (91%)]	Loss: 2.8697	Cost: 6.28s
Train Epoch: 1269 	Average Loss: 3.8555
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3644

Learning rate: 0.00019992054239468347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1270 [0/90000 (0%)]	Loss: 13.7019	Cost: 25.55s
Train Epoch: 1270 [20480/90000 (23%)]	Loss: 2.9501	Cost: 6.02s
Train Epoch: 1270 [40960/90000 (45%)]	Loss: 2.8624	Cost: 8.98s
Train Epoch: 1270 [61440/90000 (68%)]	Loss: 2.9625	Cost: 5.85s
Train Epoch: 1270 [81920/90000 (91%)]	Loss: 2.9770	Cost: 8.93s
Train Epoch: 1270 	Average Loss: 3.6974
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4077

Learning rate: 0.0001999204171332689
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1271 [0/90000 (0%)]	Loss: 13.7208	Cost: 23.78s
Train Epoch: 1271 [20480/90000 (23%)]	Loss: 2.9560	Cost: 5.94s
Train Epoch: 1271 [40960/90000 (45%)]	Loss: 3.0552	Cost: 6.97s
Train Epoch: 1271 [61440/90000 (68%)]	Loss: 2.9379	Cost: 6.04s
Train Epoch: 1271 [81920/90000 (91%)]	Loss: 2.9618	Cost: 9.16s
Train Epoch: 1271 	Average Loss: 3.7164
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3147

Learning rate: 0.0001999202917732368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1272 [0/90000 (0%)]	Loss: 13.6396	Cost: 24.14s
Train Epoch: 1272 [20480/90000 (23%)]	Loss: 3.0072	Cost: 6.14s
Train Epoch: 1272 [40960/90000 (45%)]	Loss: 2.8483	Cost: 7.04s
Train Epoch: 1272 [61440/90000 (68%)]	Loss: 2.8845	Cost: 5.87s
Train Epoch: 1272 [81920/90000 (91%)]	Loss: 2.9824	Cost: 6.17s
Train Epoch: 1272 	Average Loss: 3.6883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4378

Learning rate: 0.00019992016631458734
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1273 [0/90000 (0%)]	Loss: 13.6508	Cost: 23.61s
Train Epoch: 1273 [20480/90000 (23%)]	Loss: 2.8992	Cost: 6.11s
Train Epoch: 1273 [40960/90000 (45%)]	Loss: 2.9358	Cost: 7.56s
Train Epoch: 1273 [61440/90000 (68%)]	Loss: 2.8725	Cost: 6.22s
Train Epoch: 1273 [81920/90000 (91%)]	Loss: 3.0170	Cost: 6.40s
Train Epoch: 1273 	Average Loss: 3.7259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3956

Learning rate: 0.00019992004075732064
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1274 [0/90000 (0%)]	Loss: 13.6384	Cost: 25.86s
Train Epoch: 1274 [20480/90000 (23%)]	Loss: 2.7412	Cost: 6.14s
Train Epoch: 1274 [40960/90000 (45%)]	Loss: 2.9114	Cost: 7.10s
Train Epoch: 1274 [61440/90000 (68%)]	Loss: 2.8807	Cost: 5.94s
Train Epoch: 1274 [81920/90000 (91%)]	Loss: 2.7380	Cost: 5.71s
Train Epoch: 1274 	Average Loss: 3.6082
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3525

Learning rate: 0.0001999199151014368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1275 [0/90000 (0%)]	Loss: 13.6774	Cost: 28.09s
Train Epoch: 1275 [20480/90000 (23%)]	Loss: 2.7881	Cost: 6.08s
Train Epoch: 1275 [40960/90000 (45%)]	Loss: 2.8783	Cost: 7.13s
Train Epoch: 1275 [61440/90000 (68%)]	Loss: 2.5943	Cost: 6.12s
Train Epoch: 1275 [81920/90000 (91%)]	Loss: 2.9242	Cost: 5.90s
Train Epoch: 1275 	Average Loss: 3.5864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4306

Learning rate: 0.00019991978934693597
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1276 [0/90000 (0%)]	Loss: 13.9335	Cost: 24.42s
Train Epoch: 1276 [20480/90000 (23%)]	Loss: 2.8996	Cost: 6.01s
Train Epoch: 1276 [40960/90000 (45%)]	Loss: 2.7537	Cost: 7.61s
Train Epoch: 1276 [61440/90000 (68%)]	Loss: 2.6154	Cost: 5.95s
Train Epoch: 1276 [81920/90000 (91%)]	Loss: 2.7156	Cost: 7.96s
Train Epoch: 1276 	Average Loss: 3.5840
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3684

Learning rate: 0.00019991966349381824
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1277 [0/90000 (0%)]	Loss: 13.9608	Cost: 23.29s
Train Epoch: 1277 [20480/90000 (23%)]	Loss: 2.7708	Cost: 6.01s
Train Epoch: 1277 [40960/90000 (45%)]	Loss: 2.9931	Cost: 6.93s
Train Epoch: 1277 [61440/90000 (68%)]	Loss: 2.9539	Cost: 6.15s
Train Epoch: 1277 [81920/90000 (91%)]	Loss: 3.2179	Cost: 9.06s
Train Epoch: 1277 	Average Loss: 3.8229
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3610

Learning rate: 0.00019991953754208377
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1278 [0/90000 (0%)]	Loss: 13.7403	Cost: 23.78s
Train Epoch: 1278 [20480/90000 (23%)]	Loss: 3.0497	Cost: 5.96s
Train Epoch: 1278 [40960/90000 (45%)]	Loss: 3.1052	Cost: 6.37s
Train Epoch: 1278 [61440/90000 (68%)]	Loss: 3.1620	Cost: 5.93s
Train Epoch: 1278 [81920/90000 (91%)]	Loss: 2.9551	Cost: 6.15s
Train Epoch: 1278 	Average Loss: 3.7967
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3577

Learning rate: 0.00019991941149173268
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1279 [0/90000 (0%)]	Loss: 13.8562	Cost: 24.63s
Train Epoch: 1279 [20480/90000 (23%)]	Loss: 2.5953	Cost: 6.23s
Train Epoch: 1279 [40960/90000 (45%)]	Loss: 2.9793	Cost: 7.60s
Train Epoch: 1279 [61440/90000 (68%)]	Loss: 2.9962	Cost: 6.14s
Train Epoch: 1279 [81920/90000 (91%)]	Loss: 3.0272	Cost: 6.37s
Train Epoch: 1279 	Average Loss: 3.7919
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3367

Learning rate: 0.00019991928534276505
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1280 [0/90000 (0%)]	Loss: 13.6724	Cost: 26.77s
Train Epoch: 1280 [20480/90000 (23%)]	Loss: 3.0826	Cost: 6.21s
Train Epoch: 1280 [40960/90000 (45%)]	Loss: 2.8921	Cost: 7.47s
Train Epoch: 1280 [61440/90000 (68%)]	Loss: 2.9300	Cost: 5.84s
Train Epoch: 1280 [81920/90000 (91%)]	Loss: 2.7049	Cost: 5.99s
Train Epoch: 1280 	Average Loss: 3.6771
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4230

Learning rate: 0.00019991915909518107
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1281 [0/90000 (0%)]	Loss: 13.4814	Cost: 27.49s
Train Epoch: 1281 [20480/90000 (23%)]	Loss: 2.8390	Cost: 5.97s
Train Epoch: 1281 [40960/90000 (45%)]	Loss: 2.9287	Cost: 9.19s
Train Epoch: 1281 [61440/90000 (68%)]	Loss: 2.6790	Cost: 5.96s
Train Epoch: 1281 [81920/90000 (91%)]	Loss: 2.8410	Cost: 7.65s
Train Epoch: 1281 	Average Loss: 3.6066
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4519

Learning rate: 0.00019991903274898084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1282 [0/90000 (0%)]	Loss: 13.9269	Cost: 24.29s
Train Epoch: 1282 [20480/90000 (23%)]	Loss: 2.8343	Cost: 6.00s
Train Epoch: 1282 [40960/90000 (45%)]	Loss: 2.7241	Cost: 8.48s
Train Epoch: 1282 [61440/90000 (68%)]	Loss: 2.6561	Cost: 5.88s
Train Epoch: 1282 [81920/90000 (91%)]	Loss: 2.6881	Cost: 8.51s
Train Epoch: 1282 	Average Loss: 3.5546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5351

Learning rate: 0.00019991890630416447
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1283 [0/90000 (0%)]	Loss: 13.9312	Cost: 23.67s
Train Epoch: 1283 [20480/90000 (23%)]	Loss: 2.7061	Cost: 6.13s
Train Epoch: 1283 [40960/90000 (45%)]	Loss: 2.7087	Cost: 6.52s
Train Epoch: 1283 [61440/90000 (68%)]	Loss: 2.6002	Cost: 6.31s
Train Epoch: 1283 [81920/90000 (91%)]	Loss: 2.7131	Cost: 8.29s
Train Epoch: 1283 	Average Loss: 3.4990
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4456

Learning rate: 0.00019991877976073208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1284 [0/90000 (0%)]	Loss: 14.0181	Cost: 24.45s
Train Epoch: 1284 [20480/90000 (23%)]	Loss: 2.6381	Cost: 6.08s
Train Epoch: 1284 [40960/90000 (45%)]	Loss: 2.7126	Cost: 7.67s
Train Epoch: 1284 [61440/90000 (68%)]	Loss: 2.8552	Cost: 5.94s
Train Epoch: 1284 [81920/90000 (91%)]	Loss: 2.7570	Cost: 5.95s
Train Epoch: 1284 	Average Loss: 3.4964
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5012

Learning rate: 0.0001999186531186838
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1285 [0/90000 (0%)]	Loss: 13.7689	Cost: 24.09s
Train Epoch: 1285 [20480/90000 (23%)]	Loss: 2.6967	Cost: 6.16s
Train Epoch: 1285 [40960/90000 (45%)]	Loss: 2.6150	Cost: 6.50s
Train Epoch: 1285 [61440/90000 (68%)]	Loss: 2.7112	Cost: 6.23s
Train Epoch: 1285 [81920/90000 (91%)]	Loss: 2.6449	Cost: 6.17s
Train Epoch: 1285 	Average Loss: 3.5131
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4597

Learning rate: 0.00019991852637801978
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1286 [0/90000 (0%)]	Loss: 13.6004	Cost: 26.80s
Train Epoch: 1286 [20480/90000 (23%)]	Loss: 2.6999	Cost: 6.06s
Train Epoch: 1286 [40960/90000 (45%)]	Loss: 2.8703	Cost: 7.57s
Train Epoch: 1286 [61440/90000 (68%)]	Loss: 2.5559	Cost: 6.23s
Train Epoch: 1286 [81920/90000 (91%)]	Loss: 2.6599	Cost: 6.23s
Train Epoch: 1286 	Average Loss: 3.5663
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5116

Learning rate: 0.00019991839953874008
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1287 [0/90000 (0%)]	Loss: 13.9359	Cost: 26.16s
Train Epoch: 1287 [20480/90000 (23%)]	Loss: 2.7378	Cost: 6.00s
Train Epoch: 1287 [40960/90000 (45%)]	Loss: 2.8305	Cost: 8.63s
Train Epoch: 1287 [61440/90000 (68%)]	Loss: 2.7885	Cost: 6.06s
Train Epoch: 1287 [81920/90000 (91%)]	Loss: 2.8063	Cost: 6.67s
Train Epoch: 1287 	Average Loss: 3.6341
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4925

Learning rate: 0.0001999182726008449
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1288 [0/90000 (0%)]	Loss: 14.0871	Cost: 23.36s
Train Epoch: 1288 [20480/90000 (23%)]	Loss: 2.8301	Cost: 5.97s
Train Epoch: 1288 [40960/90000 (45%)]	Loss: 2.8468	Cost: 6.28s
Train Epoch: 1288 [61440/90000 (68%)]	Loss: 2.7890	Cost: 6.14s
Train Epoch: 1288 [81920/90000 (91%)]	Loss: 2.8652	Cost: 8.64s
Train Epoch: 1288 	Average Loss: 3.6272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4561

Learning rate: 0.0001999181455643344
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1289 [0/90000 (0%)]	Loss: 13.8428	Cost: 23.34s
Train Epoch: 1289 [20480/90000 (23%)]	Loss: 2.8826	Cost: 6.13s
Train Epoch: 1289 [40960/90000 (45%)]	Loss: 2.8386	Cost: 6.57s
Train Epoch: 1289 [61440/90000 (68%)]	Loss: 2.9419	Cost: 6.16s
Train Epoch: 1289 [81920/90000 (91%)]	Loss: 2.6948	Cost: 6.36s
Train Epoch: 1289 	Average Loss: 3.6622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5002

Learning rate: 0.00019991801842920856
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1290 [0/90000 (0%)]	Loss: 13.9239	Cost: 23.11s
Train Epoch: 1290 [20480/90000 (23%)]	Loss: 2.8119	Cost: 5.99s
Train Epoch: 1290 [40960/90000 (45%)]	Loss: 2.8479	Cost: 6.51s
Train Epoch: 1290 [61440/90000 (68%)]	Loss: 2.9153	Cost: 5.94s
Train Epoch: 1290 [81920/90000 (91%)]	Loss: 2.9022	Cost: 5.74s
Train Epoch: 1290 	Average Loss: 3.6653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4764

Learning rate: 0.00019991789119546766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1291 [0/90000 (0%)]	Loss: 13.8142	Cost: 28.41s
Train Epoch: 1291 [20480/90000 (23%)]	Loss: 3.0548	Cost: 6.07s
Train Epoch: 1291 [40960/90000 (45%)]	Loss: 2.6916	Cost: 7.88s
Train Epoch: 1291 [61440/90000 (68%)]	Loss: 2.5438	Cost: 5.95s
Train Epoch: 1291 [81920/90000 (91%)]	Loss: 2.8641	Cost: 6.32s
Train Epoch: 1291 	Average Loss: 3.6057
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4739

Learning rate: 0.0001999177638631117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1292 [0/90000 (0%)]	Loss: 13.9231	Cost: 28.08s
Train Epoch: 1292 [20480/90000 (23%)]	Loss: 2.7138	Cost: 6.10s
Train Epoch: 1292 [40960/90000 (45%)]	Loss: 2.7599	Cost: 8.64s
Train Epoch: 1292 [61440/90000 (68%)]	Loss: 2.4404	Cost: 6.00s
Train Epoch: 1292 [81920/90000 (91%)]	Loss: 2.8156	Cost: 7.94s
Train Epoch: 1292 	Average Loss: 3.4912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4993

Learning rate: 0.00019991763643214085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1293 [0/90000 (0%)]	Loss: 13.9695	Cost: 23.79s
Train Epoch: 1293 [20480/90000 (23%)]	Loss: 2.7003	Cost: 6.00s
Train Epoch: 1293 [40960/90000 (45%)]	Loss: 2.4681	Cost: 8.26s
Train Epoch: 1293 [61440/90000 (68%)]	Loss: 2.5567	Cost: 5.98s
Train Epoch: 1293 [81920/90000 (91%)]	Loss: 2.5961	Cost: 8.69s
Train Epoch: 1293 	Average Loss: 3.4549
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5518

Learning rate: 0.00019991750890255527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1294 [0/90000 (0%)]	Loss: 14.0245	Cost: 24.18s
Train Epoch: 1294 [20480/90000 (23%)]	Loss: 2.6235	Cost: 6.07s
Train Epoch: 1294 [40960/90000 (45%)]	Loss: 2.6698	Cost: 6.35s
Train Epoch: 1294 [61440/90000 (68%)]	Loss: 2.5934	Cost: 5.98s
Train Epoch: 1294 [81920/90000 (91%)]	Loss: 2.8223	Cost: 6.00s
Train Epoch: 1294 	Average Loss: 3.4431
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5996

Learning rate: 0.00019991738127435506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1295 [0/90000 (0%)]	Loss: 13.9650	Cost: 24.54s
Train Epoch: 1295 [20480/90000 (23%)]	Loss: 2.3570	Cost: 6.28s
Train Epoch: 1295 [40960/90000 (45%)]	Loss: 2.5709	Cost: 7.89s
Train Epoch: 1295 [61440/90000 (68%)]	Loss: 2.4588	Cost: 5.90s
Train Epoch: 1295 [81920/90000 (91%)]	Loss: 2.7938	Cost: 6.18s
Train Epoch: 1295 	Average Loss: 3.4143
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5245

Learning rate: 0.00019991725354754033
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1296 [0/90000 (0%)]	Loss: 13.9233	Cost: 24.50s
Train Epoch: 1296 [20480/90000 (23%)]	Loss: 2.7946	Cost: 6.07s
Train Epoch: 1296 [40960/90000 (45%)]	Loss: 2.7755	Cost: 6.31s
Train Epoch: 1296 [61440/90000 (68%)]	Loss: 2.4257	Cost: 6.12s
Train Epoch: 1296 [81920/90000 (91%)]	Loss: 2.8914	Cost: 5.80s
Train Epoch: 1296 	Average Loss: 3.4749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5777

Learning rate: 0.00019991712572211125
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1297 [0/90000 (0%)]	Loss: 13.9531	Cost: 29.35s
Train Epoch: 1297 [20480/90000 (23%)]	Loss: 2.6550	Cost: 6.12s
Train Epoch: 1297 [40960/90000 (45%)]	Loss: 2.6823	Cost: 7.24s
Train Epoch: 1297 [61440/90000 (68%)]	Loss: 2.6624	Cost: 5.99s
Train Epoch: 1297 [81920/90000 (91%)]	Loss: 2.7421	Cost: 6.74s
Train Epoch: 1297 	Average Loss: 3.4491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6082

Learning rate: 0.00019991699779806793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1298 [0/90000 (0%)]	Loss: 14.1634	Cost: 25.39s
Train Epoch: 1298 [20480/90000 (23%)]	Loss: 2.6551	Cost: 6.02s
Train Epoch: 1298 [40960/90000 (45%)]	Loss: 2.5018	Cost: 7.68s
Train Epoch: 1298 [61440/90000 (68%)]	Loss: 2.5837	Cost: 5.87s
Train Epoch: 1298 [81920/90000 (91%)]	Loss: 2.4461	Cost: 7.43s
Train Epoch: 1298 	Average Loss: 3.3811
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5287

Learning rate: 0.00019991686977541043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1299 [0/90000 (0%)]	Loss: 13.8926	Cost: 23.26s
Train Epoch: 1299 [20480/90000 (23%)]	Loss: 2.4076	Cost: 6.61s
Train Epoch: 1299 [40960/90000 (45%)]	Loss: 2.3021	Cost: 6.59s
Train Epoch: 1299 [61440/90000 (68%)]	Loss: 2.1865	Cost: 5.99s
Train Epoch: 1299 [81920/90000 (91%)]	Loss: 2.6066	Cost: 8.70s
Train Epoch: 1299 	Average Loss: 3.3378
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5327

Learning rate: 0.00019991674165413894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1300 [0/90000 (0%)]	Loss: 13.8970	Cost: 24.40s
Train Epoch: 1300 [20480/90000 (23%)]	Loss: 2.9439	Cost: 6.07s
Train Epoch: 1300 [40960/90000 (45%)]	Loss: 3.0152	Cost: 6.69s
Train Epoch: 1300 [61440/90000 (68%)]	Loss: 2.3725	Cost: 6.52s
Train Epoch: 1300 [81920/90000 (91%)]	Loss: 2.7973	Cost: 6.19s
Train Epoch: 1300 	Average Loss: 3.5115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6322

Learning rate: 0.0001999166134342536
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1301 [0/90000 (0%)]	Loss: 14.0803	Cost: 23.86s
Train Epoch: 1301 [20480/90000 (23%)]	Loss: 2.7235	Cost: 6.11s
Train Epoch: 1301 [40960/90000 (45%)]	Loss: 2.6374	Cost: 6.25s
Train Epoch: 1301 [61440/90000 (68%)]	Loss: 2.5078	Cost: 6.31s
Train Epoch: 1301 [81920/90000 (91%)]	Loss: 2.6710	Cost: 5.73s
Train Epoch: 1301 	Average Loss: 3.5114
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6320

Learning rate: 0.00019991648511575452
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1302 [0/90000 (0%)]	Loss: 13.9416	Cost: 25.81s
Train Epoch: 1302 [20480/90000 (23%)]	Loss: 2.4506	Cost: 6.00s
Train Epoch: 1302 [40960/90000 (45%)]	Loss: 2.4394	Cost: 6.90s
Train Epoch: 1302 [61440/90000 (68%)]	Loss: 2.4895	Cost: 5.88s
Train Epoch: 1302 [81920/90000 (91%)]	Loss: 2.7233	Cost: 6.16s
Train Epoch: 1302 	Average Loss: 3.3417
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6443

Learning rate: 0.00019991635669864183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1303 [0/90000 (0%)]	Loss: 13.9621	Cost: 28.00s
Train Epoch: 1303 [20480/90000 (23%)]	Loss: 2.5503	Cost: 5.98s
Train Epoch: 1303 [40960/90000 (45%)]	Loss: 2.4138	Cost: 8.61s
Train Epoch: 1303 [61440/90000 (68%)]	Loss: 2.3539	Cost: 5.90s
Train Epoch: 1303 [81920/90000 (91%)]	Loss: 2.5816	Cost: 6.99s
Train Epoch: 1303 	Average Loss: 3.3295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6463

Learning rate: 0.00019991622818291564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1304 [0/90000 (0%)]	Loss: 14.3162	Cost: 23.72s
Train Epoch: 1304 [20480/90000 (23%)]	Loss: 2.5874	Cost: 6.05s
Train Epoch: 1304 [40960/90000 (45%)]	Loss: 2.6081	Cost: 7.98s
Train Epoch: 1304 [61440/90000 (68%)]	Loss: 2.6054	Cost: 5.95s
Train Epoch: 1304 [81920/90000 (91%)]	Loss: 2.7085	Cost: 8.68s
Train Epoch: 1304 	Average Loss: 3.4759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6878

Learning rate: 0.00019991609956857608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1305 [0/90000 (0%)]	Loss: 14.0129	Cost: 24.21s
Train Epoch: 1305 [20480/90000 (23%)]	Loss: 2.6330	Cost: 6.02s
Train Epoch: 1305 [40960/90000 (45%)]	Loss: 2.6287	Cost: 7.22s
Train Epoch: 1305 [61440/90000 (68%)]	Loss: 2.4950	Cost: 5.84s
Train Epoch: 1305 [81920/90000 (91%)]	Loss: 2.6246	Cost: 6.18s
Train Epoch: 1305 	Average Loss: 3.4900
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6711

Learning rate: 0.0001999159708556233
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1306 [0/90000 (0%)]	Loss: 13.7380	Cost: 23.26s
Train Epoch: 1306 [20480/90000 (23%)]	Loss: 2.6958	Cost: 6.12s
Train Epoch: 1306 [40960/90000 (45%)]	Loss: 2.4890	Cost: 6.74s
Train Epoch: 1306 [61440/90000 (68%)]	Loss: 2.5871	Cost: 5.89s
Train Epoch: 1306 [81920/90000 (91%)]	Loss: 2.7571	Cost: 6.18s
Train Epoch: 1306 	Average Loss: 3.4063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5969

Learning rate: 0.0001999158420440574
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1307 [0/90000 (0%)]	Loss: 14.1720	Cost: 24.04s
Train Epoch: 1307 [20480/90000 (23%)]	Loss: 2.6319	Cost: 6.12s
Train Epoch: 1307 [40960/90000 (45%)]	Loss: 2.4739	Cost: 7.02s
Train Epoch: 1307 [61440/90000 (68%)]	Loss: 2.4421	Cost: 6.03s
Train Epoch: 1307 [81920/90000 (91%)]	Loss: 2.5158	Cost: 5.74s
Train Epoch: 1307 	Average Loss: 3.3313
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5858

Learning rate: 0.0001999157131338785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1308 [0/90000 (0%)]	Loss: 14.1921	Cost: 29.11s
Train Epoch: 1308 [20480/90000 (23%)]	Loss: 2.4399	Cost: 5.99s
Train Epoch: 1308 [40960/90000 (45%)]	Loss: 2.4947	Cost: 7.91s
Train Epoch: 1308 [61440/90000 (68%)]	Loss: 2.5015	Cost: 5.97s
Train Epoch: 1308 [81920/90000 (91%)]	Loss: 2.5935	Cost: 5.78s
Train Epoch: 1308 	Average Loss: 3.3357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5555

Learning rate: 0.00019991558412508676
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1309 [0/90000 (0%)]	Loss: 14.1349	Cost: 24.62s
Train Epoch: 1309 [20480/90000 (23%)]	Loss: 2.8105	Cost: 6.00s
Train Epoch: 1309 [40960/90000 (45%)]	Loss: 2.7204	Cost: 8.02s
Train Epoch: 1309 [61440/90000 (68%)]	Loss: 2.4485	Cost: 6.16s
Train Epoch: 1309 [81920/90000 (91%)]	Loss: 2.5640	Cost: 7.06s
Train Epoch: 1309 	Average Loss: 3.5291
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5141

Learning rate: 0.00019991545501768228
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1310 [0/90000 (0%)]	Loss: 14.0028	Cost: 23.77s
Train Epoch: 1310 [20480/90000 (23%)]	Loss: 2.8659	Cost: 6.17s
Train Epoch: 1310 [40960/90000 (45%)]	Loss: 2.9446	Cost: 6.13s
Train Epoch: 1310 [61440/90000 (68%)]	Loss: 2.6553	Cost: 6.24s
Train Epoch: 1310 [81920/90000 (91%)]	Loss: 2.5798	Cost: 7.43s
Train Epoch: 1310 	Average Loss: 3.5406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5799

Learning rate: 0.00019991532581166522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1311 [0/90000 (0%)]	Loss: 14.1065	Cost: 23.40s
Train Epoch: 1311 [20480/90000 (23%)]	Loss: 2.6778	Cost: 6.21s
Train Epoch: 1311 [40960/90000 (45%)]	Loss: 2.6354	Cost: 7.54s
Train Epoch: 1311 [61440/90000 (68%)]	Loss: 2.5238	Cost: 5.86s
Train Epoch: 1311 [81920/90000 (91%)]	Loss: 2.4995	Cost: 6.37s
Train Epoch: 1311 	Average Loss: 3.3883
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5242

Learning rate: 0.00019991519650703569
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1312 [0/90000 (0%)]	Loss: 13.8503	Cost: 24.52s
Train Epoch: 1312 [20480/90000 (23%)]	Loss: 2.5816	Cost: 6.00s
Train Epoch: 1312 [40960/90000 (45%)]	Loss: 2.4153	Cost: 6.34s
Train Epoch: 1312 [61440/90000 (68%)]	Loss: 2.2596	Cost: 6.29s
Train Epoch: 1312 [81920/90000 (91%)]	Loss: 2.3687	Cost: 5.75s
Train Epoch: 1312 	Average Loss: 3.2388
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6162

Learning rate: 0.0001999150671037938
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1313 [0/90000 (0%)]	Loss: 14.0774	Cost: 27.53s
Train Epoch: 1313 [20480/90000 (23%)]	Loss: 2.4139	Cost: 6.12s
Train Epoch: 1313 [40960/90000 (45%)]	Loss: 2.4606	Cost: 7.46s
Train Epoch: 1313 [61440/90000 (68%)]	Loss: 2.3429	Cost: 5.84s
Train Epoch: 1313 [81920/90000 (91%)]	Loss: 2.3629	Cost: 6.99s
Train Epoch: 1313 	Average Loss: 3.1886
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7413

Learning rate: 0.00019991493760193965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1314 [0/90000 (0%)]	Loss: 14.2607	Cost: 27.10s
Train Epoch: 1314 [20480/90000 (23%)]	Loss: 2.4365	Cost: 6.10s
Train Epoch: 1314 [40960/90000 (45%)]	Loss: 2.6117	Cost: 7.30s
Train Epoch: 1314 [61440/90000 (68%)]	Loss: 2.5158	Cost: 5.93s
Train Epoch: 1314 [81920/90000 (91%)]	Loss: 2.4726	Cost: 6.55s
Train Epoch: 1314 	Average Loss: 3.2375
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6082

Learning rate: 0.00019991480800147347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1315 [0/90000 (0%)]	Loss: 14.1577	Cost: 22.71s
Train Epoch: 1315 [20480/90000 (23%)]	Loss: 2.5334	Cost: 6.23s
Train Epoch: 1315 [40960/90000 (45%)]	Loss: 2.6412	Cost: 6.52s
Train Epoch: 1315 [61440/90000 (68%)]	Loss: 2.7017	Cost: 6.02s
Train Epoch: 1315 [81920/90000 (91%)]	Loss: 2.8876	Cost: 8.92s
Train Epoch: 1315 	Average Loss: 3.4598
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7181

Learning rate: 0.00019991467830239527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1316 [0/90000 (0%)]	Loss: 14.1799	Cost: 24.36s
Train Epoch: 1316 [20480/90000 (23%)]	Loss: 2.8074	Cost: 6.08s
Train Epoch: 1316 [40960/90000 (45%)]	Loss: 2.6940	Cost: 6.27s
Train Epoch: 1316 [61440/90000 (68%)]	Loss: 2.7223	Cost: 5.94s
Train Epoch: 1316 [81920/90000 (91%)]	Loss: 2.4099	Cost: 6.58s
Train Epoch: 1316 	Average Loss: 3.5423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5540

Learning rate: 0.00019991454850470532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1317 [0/90000 (0%)]	Loss: 13.9574	Cost: 23.57s
Train Epoch: 1317 [20480/90000 (23%)]	Loss: 2.5173	Cost: 6.05s
Train Epoch: 1317 [40960/90000 (45%)]	Loss: 2.7740	Cost: 8.39s
Train Epoch: 1317 [61440/90000 (68%)]	Loss: 2.6975	Cost: 5.81s
Train Epoch: 1317 [81920/90000 (91%)]	Loss: 2.8044	Cost: 6.70s
Train Epoch: 1317 	Average Loss: 3.4783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6003

Learning rate: 0.0001999144186084036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1318 [0/90000 (0%)]	Loss: 14.0417	Cost: 26.56s
Train Epoch: 1318 [20480/90000 (23%)]	Loss: 2.7066	Cost: 6.12s
Train Epoch: 1318 [40960/90000 (45%)]	Loss: 2.6833	Cost: 7.22s
Train Epoch: 1318 [61440/90000 (68%)]	Loss: 2.4046	Cost: 5.89s
Train Epoch: 1318 [81920/90000 (91%)]	Loss: 2.4614	Cost: 5.91s
Train Epoch: 1318 	Average Loss: 3.3681
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6977

Learning rate: 0.0001999142886134903
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1319 [0/90000 (0%)]	Loss: 13.9060	Cost: 26.76s
Train Epoch: 1319 [20480/90000 (23%)]	Loss: 2.6051	Cost: 6.03s
Train Epoch: 1319 [40960/90000 (45%)]	Loss: 2.4649	Cost: 6.86s
Train Epoch: 1319 [61440/90000 (68%)]	Loss: 2.3440	Cost: 6.13s
Train Epoch: 1319 [81920/90000 (91%)]	Loss: 2.3047	Cost: 6.46s
Train Epoch: 1319 	Average Loss: 3.2490
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6973

Learning rate: 0.00019991415851996556
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1320 [0/90000 (0%)]	Loss: 14.0950	Cost: 24.29s
Train Epoch: 1320 [20480/90000 (23%)]	Loss: 2.5055	Cost: 6.24s
Train Epoch: 1320 [40960/90000 (45%)]	Loss: 2.1459	Cost: 6.74s
Train Epoch: 1320 [61440/90000 (68%)]	Loss: 2.4842	Cost: 6.15s
Train Epoch: 1320 [81920/90000 (91%)]	Loss: 2.3646	Cost: 8.33s
Train Epoch: 1320 	Average Loss: 3.1751
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5810

Learning rate: 0.0001999140283278295
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1321 [0/90000 (0%)]	Loss: 14.0786	Cost: 24.75s
Train Epoch: 1321 [20480/90000 (23%)]	Loss: 2.3535	Cost: 6.02s
Train Epoch: 1321 [40960/90000 (45%)]	Loss: 2.4705	Cost: 6.94s
Train Epoch: 1321 [61440/90000 (68%)]	Loss: 2.5046	Cost: 5.96s
Train Epoch: 1321 [81920/90000 (91%)]	Loss: 2.4110	Cost: 6.46s
Train Epoch: 1321 	Average Loss: 3.2315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6452

Learning rate: 0.00019991389803708227
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1322 [0/90000 (0%)]	Loss: 14.0147	Cost: 23.18s
Train Epoch: 1322 [20480/90000 (23%)]	Loss: 2.4727	Cost: 6.00s
Train Epoch: 1322 [40960/90000 (45%)]	Loss: 2.4181	Cost: 8.00s
Train Epoch: 1322 [61440/90000 (68%)]	Loss: 2.3341	Cost: 5.92s
Train Epoch: 1322 [81920/90000 (91%)]	Loss: 2.2285	Cost: 6.43s
Train Epoch: 1322 	Average Loss: 3.1988
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6284

Learning rate: 0.00019991376764772397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1323 [0/90000 (0%)]	Loss: 14.0622	Cost: 24.41s
Train Epoch: 1323 [20480/90000 (23%)]	Loss: 2.3893	Cost: 6.23s
Train Epoch: 1323 [40960/90000 (45%)]	Loss: 2.4948	Cost: 6.95s
Train Epoch: 1323 [61440/90000 (68%)]	Loss: 2.2722	Cost: 6.05s
Train Epoch: 1323 [81920/90000 (91%)]	Loss: 2.4165	Cost: 6.49s
Train Epoch: 1323 	Average Loss: 3.1739
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6789

Learning rate: 0.00019991363715975472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1324 [0/90000 (0%)]	Loss: 14.0898	Cost: 30.38s
Train Epoch: 1324 [20480/90000 (23%)]	Loss: 2.5998	Cost: 6.25s
Train Epoch: 1324 [40960/90000 (45%)]	Loss: 2.4016	Cost: 7.53s
Train Epoch: 1324 [61440/90000 (68%)]	Loss: 2.2104	Cost: 6.00s
Train Epoch: 1324 [81920/90000 (91%)]	Loss: 2.2779	Cost: 6.15s
Train Epoch: 1324 	Average Loss: 3.1942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7036

Learning rate: 0.00019991350657317465
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1325 [0/90000 (0%)]	Loss: 14.0400	Cost: 27.06s
Train Epoch: 1325 [20480/90000 (23%)]	Loss: 2.4897	Cost: 6.07s
Train Epoch: 1325 [40960/90000 (45%)]	Loss: 2.3506	Cost: 7.35s
Train Epoch: 1325 [61440/90000 (68%)]	Loss: 2.2705	Cost: 6.14s
Train Epoch: 1325 [81920/90000 (91%)]	Loss: 2.4351	Cost: 6.62s
Train Epoch: 1325 	Average Loss: 3.1729
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6718

Learning rate: 0.0001999133758879839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1326 [0/90000 (0%)]	Loss: 14.1507	Cost: 22.85s
Train Epoch: 1326 [20480/90000 (23%)]	Loss: 2.5099	Cost: 6.01s
Train Epoch: 1326 [40960/90000 (45%)]	Loss: 2.2634	Cost: 6.96s
Train Epoch: 1326 [61440/90000 (68%)]	Loss: 2.2305	Cost: 6.17s
Train Epoch: 1326 [81920/90000 (91%)]	Loss: 2.2701	Cost: 9.01s
Train Epoch: 1326 	Average Loss: 3.1387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6626

Learning rate: 0.00019991324510418263
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1327 [0/90000 (0%)]	Loss: 13.9626	Cost: 23.64s
Train Epoch: 1327 [20480/90000 (23%)]	Loss: 2.2407	Cost: 5.92s
Train Epoch: 1327 [40960/90000 (45%)]	Loss: 2.3136	Cost: 7.20s
Train Epoch: 1327 [61440/90000 (68%)]	Loss: 2.2880	Cost: 5.88s
Train Epoch: 1327 [81920/90000 (91%)]	Loss: 2.1891	Cost: 6.09s
Train Epoch: 1327 	Average Loss: 3.0718
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.8310

Learning rate: 0.00019991311422177093
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1328 [0/90000 (0%)]	Loss: 14.2359	Cost: 23.49s
Train Epoch: 1328 [20480/90000 (23%)]	Loss: 2.1084	Cost: 6.20s
Train Epoch: 1328 [40960/90000 (45%)]	Loss: 2.3549	Cost: 7.67s
Train Epoch: 1328 [61440/90000 (68%)]	Loss: 2.1940	Cost: 5.93s
Train Epoch: 1328 [81920/90000 (91%)]	Loss: 2.4407	Cost: 6.50s
Train Epoch: 1328 	Average Loss: 3.1806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7212

Learning rate: 0.00019991298324074894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1329 [0/90000 (0%)]	Loss: 14.1771	Cost: 26.80s
Train Epoch: 1329 [20480/90000 (23%)]	Loss: 2.4031	Cost: 6.03s
Train Epoch: 1329 [40960/90000 (45%)]	Loss: 2.3394	Cost: 6.93s
Train Epoch: 1329 [61440/90000 (68%)]	Loss: 2.1886	Cost: 5.89s
Train Epoch: 1329 [81920/90000 (91%)]	Loss: 2.5810	Cost: 6.09s
Train Epoch: 1329 	Average Loss: 3.1297
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7947

Learning rate: 0.00019991285216111677
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1330 [0/90000 (0%)]	Loss: 13.9790	Cost: 25.26s
Train Epoch: 1330 [20480/90000 (23%)]	Loss: 2.3156	Cost: 6.14s
Train Epoch: 1330 [40960/90000 (45%)]	Loss: 3.1016	Cost: 8.83s
Train Epoch: 1330 [61440/90000 (68%)]	Loss: 2.9669	Cost: 5.99s
Train Epoch: 1330 [81920/90000 (91%)]	Loss: 2.7242	Cost: 9.25s
Train Epoch: 1330 	Average Loss: 3.4639
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7015

Learning rate: 0.0001999127209828746
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1331 [0/90000 (0%)]	Loss: 14.2147	Cost: 23.69s
Train Epoch: 1331 [20480/90000 (23%)]	Loss: 2.5413	Cost: 6.15s
Train Epoch: 1331 [40960/90000 (45%)]	Loss: 2.5258	Cost: 6.40s
Train Epoch: 1331 [61440/90000 (68%)]	Loss: 2.4693	Cost: 6.07s
Train Epoch: 1331 [81920/90000 (91%)]	Loss: 2.5273	Cost: 8.78s
Train Epoch: 1331 	Average Loss: 3.3932
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6375

Learning rate: 0.0001999125897060225
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1332 [0/90000 (0%)]	Loss: 14.2847	Cost: 25.50s
Train Epoch: 1332 [20480/90000 (23%)]	Loss: 2.3309	Cost: 6.22s
Train Epoch: 1332 [40960/90000 (45%)]	Loss: 2.3053	Cost: 7.11s
Train Epoch: 1332 [61440/90000 (68%)]	Loss: 2.1491	Cost: 6.12s
Train Epoch: 1332 [81920/90000 (91%)]	Loss: 2.2364	Cost: 5.76s
Train Epoch: 1332 	Average Loss: 3.2081
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6983

Learning rate: 0.00019991245833056063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1333 [0/90000 (0%)]	Loss: 14.3757	Cost: 24.09s
Train Epoch: 1333 [20480/90000 (23%)]	Loss: 2.2540	Cost: 6.24s
Train Epoch: 1333 [40960/90000 (45%)]	Loss: 2.0895	Cost: 6.70s
Train Epoch: 1333 [61440/90000 (68%)]	Loss: 2.3082	Cost: 6.08s
Train Epoch: 1333 [81920/90000 (91%)]	Loss: 2.4234	Cost: 5.93s
Train Epoch: 1333 	Average Loss: 3.1185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7690

Learning rate: 0.00019991232685648912
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1334 [0/90000 (0%)]	Loss: 14.0671	Cost: 26.03s
Train Epoch: 1334 [20480/90000 (23%)]	Loss: 2.4401	Cost: 5.99s
Train Epoch: 1334 [40960/90000 (45%)]	Loss: 2.3330	Cost: 7.50s
Train Epoch: 1334 [61440/90000 (68%)]	Loss: 2.4035	Cost: 5.89s
Train Epoch: 1334 [81920/90000 (91%)]	Loss: 2.3634	Cost: 5.91s
Train Epoch: 1334 	Average Loss: 3.1639
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6981

Learning rate: 0.00019991219528380812
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1335 [0/90000 (0%)]	Loss: 14.0489	Cost: 28.42s
Train Epoch: 1335 [20480/90000 (23%)]	Loss: 2.4538	Cost: 6.06s
Train Epoch: 1335 [40960/90000 (45%)]	Loss: 2.4063	Cost: 9.02s
Train Epoch: 1335 [61440/90000 (68%)]	Loss: 2.5364	Cost: 5.87s
Train Epoch: 1335 [81920/90000 (91%)]	Loss: 2.6856	Cost: 6.07s
Train Epoch: 1335 	Average Loss: 3.3116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7043

Learning rate: 0.0001999120636125177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1336 [0/90000 (0%)]	Loss: 14.0221	Cost: 24.72s
Train Epoch: 1336 [20480/90000 (23%)]	Loss: 2.7329	Cost: 6.04s
Train Epoch: 1336 [40960/90000 (45%)]	Loss: 2.4239	Cost: 8.12s
Train Epoch: 1336 [61440/90000 (68%)]	Loss: 2.3671	Cost: 5.96s
Train Epoch: 1336 [81920/90000 (91%)]	Loss: 2.2906	Cost: 8.27s
Train Epoch: 1336 	Average Loss: 3.3074
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6297

Learning rate: 0.00019991193184261806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1337 [0/90000 (0%)]	Loss: 14.0462	Cost: 23.65s
Train Epoch: 1337 [20480/90000 (23%)]	Loss: 2.2031	Cost: 5.96s
Train Epoch: 1337 [40960/90000 (45%)]	Loss: 2.0693	Cost: 6.94s
Train Epoch: 1337 [61440/90000 (68%)]	Loss: 2.1061	Cost: 6.02s
Train Epoch: 1337 [81920/90000 (91%)]	Loss: 2.1871	Cost: 6.77s
Train Epoch: 1337 	Average Loss: 3.0183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7565

Learning rate: 0.00019991179997410924
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1338 [0/90000 (0%)]	Loss: 14.3335	Cost: 23.51s
Train Epoch: 1338 [20480/90000 (23%)]	Loss: 2.1460	Cost: 6.22s
Train Epoch: 1338 [40960/90000 (45%)]	Loss: 2.0604	Cost: 6.83s
Train Epoch: 1338 [61440/90000 (68%)]	Loss: 1.9489	Cost: 6.00s
Train Epoch: 1338 [81920/90000 (91%)]	Loss: 2.1830	Cost: 6.78s
Train Epoch: 1338 	Average Loss: 2.9732
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.8667

Learning rate: 0.00019991166800699146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1339 [0/90000 (0%)]	Loss: 13.9251	Cost: 25.65s
Train Epoch: 1339 [20480/90000 (23%)]	Loss: 2.2035	Cost: 5.95s
Train Epoch: 1339 [40960/90000 (45%)]	Loss: 2.2419	Cost: 8.14s
Train Epoch: 1339 [61440/90000 (68%)]	Loss: 2.1698	Cost: 6.04s
Train Epoch: 1339 [81920/90000 (91%)]	Loss: 2.1409	Cost: 7.09s
Train Epoch: 1339 	Average Loss: 3.0062
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.8486

Learning rate: 0.00019991153594126483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1340 [0/90000 (0%)]	Loss: 14.1623	Cost: 26.63s
Train Epoch: 1340 [20480/90000 (23%)]	Loss: 2.1301	Cost: 6.11s
Train Epoch: 1340 [40960/90000 (45%)]	Loss: 2.1548	Cost: 7.48s
Train Epoch: 1340 [61440/90000 (68%)]	Loss: 2.0792	Cost: 5.82s
Train Epoch: 1340 [81920/90000 (91%)]	Loss: 2.2815	Cost: 6.13s
Train Epoch: 1340 	Average Loss: 3.0212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7536

Learning rate: 0.00019991140377692944
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1341 [0/90000 (0%)]	Loss: 14.1038	Cost: 28.09s
Train Epoch: 1341 [20480/90000 (23%)]	Loss: 2.3236	Cost: 6.03s
Train Epoch: 1341 [40960/90000 (45%)]	Loss: 2.0994	Cost: 6.75s
Train Epoch: 1341 [61440/90000 (68%)]	Loss: 2.0617	Cost: 5.90s
Train Epoch: 1341 [81920/90000 (91%)]	Loss: 2.0131	Cost: 6.13s
Train Epoch: 1341 	Average Loss: 3.0207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7799

Learning rate: 0.00019991127151398547
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1342 [0/90000 (0%)]	Loss: 14.2886	Cost: 22.12s
Train Epoch: 1342 [20480/90000 (23%)]	Loss: 2.1327	Cost: 5.98s
Train Epoch: 1342 [40960/90000 (45%)]	Loss: 1.9674	Cost: 7.52s
Train Epoch: 1342 [61440/90000 (68%)]	Loss: 1.8362	Cost: 5.97s
Train Epoch: 1342 [81920/90000 (91%)]	Loss: 2.0869	Cost: 8.70s
Train Epoch: 1342 	Average Loss: 2.9127
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7848

Learning rate: 0.00019991113915243298
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1343 [0/90000 (0%)]	Loss: 14.1272	Cost: 23.64s
Train Epoch: 1343 [20480/90000 (23%)]	Loss: 2.4330	Cost: 6.05s
Train Epoch: 1343 [40960/90000 (45%)]	Loss: 2.1887	Cost: 7.73s
Train Epoch: 1343 [61440/90000 (68%)]	Loss: 2.1872	Cost: 6.48s
Train Epoch: 1343 [81920/90000 (91%)]	Loss: 2.0715	Cost: 6.40s
Train Epoch: 1343 	Average Loss: 3.0436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.8555

Learning rate: 0.0001999110066922722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1344 [0/90000 (0%)]	Loss: 14.1997	Cost: 23.55s
Train Epoch: 1344 [20480/90000 (23%)]	Loss: 2.2297	Cost: 6.16s
Train Epoch: 1344 [40960/90000 (45%)]	Loss: 2.1692	Cost: 7.55s
Train Epoch: 1344 [61440/90000 (68%)]	Loss: 2.2992	Cost: 6.05s
Train Epoch: 1344 [81920/90000 (91%)]	Loss: 2.1821	Cost: 6.97s
Train Epoch: 1344 	Average Loss: 3.0011
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7732

Learning rate: 0.0001999108741335032
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1345 [0/90000 (0%)]	Loss: 13.9393	Cost: 25.53s
Train Epoch: 1345 [20480/90000 (23%)]	Loss: 2.0964	Cost: 6.03s
Train Epoch: 1345 [40960/90000 (45%)]	Loss: 2.2113	Cost: 6.97s
Train Epoch: 1345 [61440/90000 (68%)]	Loss: 2.1537	Cost: 5.97s
Train Epoch: 1345 [81920/90000 (91%)]	Loss: 2.1340	Cost: 6.42s
Train Epoch: 1345 	Average Loss: 2.9891
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.8602

Learning rate: 0.00019991074147612608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1346 [0/90000 (0%)]	Loss: 14.4299	Cost: 28.59s
Train Epoch: 1346 [20480/90000 (23%)]	Loss: 2.0163	Cost: 5.97s
Train Epoch: 1346 [40960/90000 (45%)]	Loss: 2.1320	Cost: 7.08s
Train Epoch: 1346 [61440/90000 (68%)]	Loss: 2.0600	Cost: 5.96s
Train Epoch: 1346 [81920/90000 (91%)]	Loss: 2.1578	Cost: 5.62s
Train Epoch: 1346 	Average Loss: 2.9629
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.8594

Learning rate: 0.00019991060872014105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1347 [0/90000 (0%)]	Loss: 14.2099	Cost: 24.95s
Train Epoch: 1347 [20480/90000 (23%)]	Loss: 2.0098	Cost: 6.03s
Train Epoch: 1347 [40960/90000 (45%)]	Loss: 1.9209	Cost: 7.99s
Train Epoch: 1347 [61440/90000 (68%)]	Loss: 1.9465	Cost: 5.90s
Train Epoch: 1347 [81920/90000 (91%)]	Loss: 1.8991	Cost: 8.04s
Train Epoch: 1347 	Average Loss: 2.8806
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.8388

Learning rate: 0.0001999104758655482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1348 [0/90000 (0%)]	Loss: 14.4786	Cost: 23.63s
Train Epoch: 1348 [20480/90000 (23%)]	Loss: 2.0603	Cost: 6.11s
Train Epoch: 1348 [40960/90000 (45%)]	Loss: 2.0989	Cost: 6.55s
Train Epoch: 1348 [61440/90000 (68%)]	Loss: 1.8915	Cost: 6.06s
Train Epoch: 1348 [81920/90000 (91%)]	Loss: 2.0870	Cost: 7.38s
Train Epoch: 1348 	Average Loss: 2.8578
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9516

Learning rate: 0.00019991034291234763
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1349 [0/90000 (0%)]	Loss: 14.2772	Cost: 23.92s
Train Epoch: 1349 [20480/90000 (23%)]	Loss: 2.0599	Cost: 5.97s
Train Epoch: 1349 [40960/90000 (45%)]	Loss: 1.8714	Cost: 7.85s
Train Epoch: 1349 [61440/90000 (68%)]	Loss: 2.1742	Cost: 5.90s
Train Epoch: 1349 [81920/90000 (91%)]	Loss: 2.1677	Cost: 6.20s
Train Epoch: 1349 	Average Loss: 2.9177
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9035

Learning rate: 0.00019991020986053954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1350 [0/90000 (0%)]	Loss: 13.8739	Cost: 23.95s
Train Epoch: 1350 [20480/90000 (23%)]	Loss: 2.0641	Cost: 6.01s
Train Epoch: 1350 [40960/90000 (45%)]	Loss: 2.0634	Cost: 6.59s
Train Epoch: 1350 [61440/90000 (68%)]	Loss: 2.0858	Cost: 6.14s
Train Epoch: 1350 [81920/90000 (91%)]	Loss: 1.9877	Cost: 5.92s
Train Epoch: 1350 	Average Loss: 2.9697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.8274

Learning rate: 0.000199910076710124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1351 [0/90000 (0%)]	Loss: 14.0489	Cost: 29.07s
Train Epoch: 1351 [20480/90000 (23%)]	Loss: 2.2648	Cost: 6.05s
Train Epoch: 1351 [40960/90000 (45%)]	Loss: 2.0363	Cost: 8.01s
Train Epoch: 1351 [61440/90000 (68%)]	Loss: 2.0448	Cost: 5.92s
Train Epoch: 1351 [81920/90000 (91%)]	Loss: 2.2113	Cost: 6.74s
Train Epoch: 1351 	Average Loss: 2.8957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9745

Learning rate: 0.00019990994346110117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1352 [0/90000 (0%)]	Loss: 14.1244	Cost: 27.21s
Train Epoch: 1352 [20480/90000 (23%)]	Loss: 1.8893	Cost: 5.96s
Train Epoch: 1352 [40960/90000 (45%)]	Loss: 2.1713	Cost: 9.18s
Train Epoch: 1352 [61440/90000 (68%)]	Loss: 1.9987	Cost: 5.92s
Train Epoch: 1352 [81920/90000 (91%)]	Loss: 2.2422	Cost: 7.78s
Train Epoch: 1352 	Average Loss: 2.8759
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0031

Learning rate: 0.00019990981011347122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1353 [0/90000 (0%)]	Loss: 14.2585	Cost: 21.92s
Train Epoch: 1353 [20480/90000 (23%)]	Loss: 2.1940	Cost: 6.10s
Train Epoch: 1353 [40960/90000 (45%)]	Loss: 2.0900	Cost: 6.75s
Train Epoch: 1353 [61440/90000 (68%)]	Loss: 2.0407	Cost: 6.00s
Train Epoch: 1353 [81920/90000 (91%)]	Loss: 2.1476	Cost: 8.60s
Train Epoch: 1353 	Average Loss: 2.9025
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9262

Learning rate: 0.0001999096766672342
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1354 [0/90000 (0%)]	Loss: 14.3359	Cost: 23.28s
Train Epoch: 1354 [20480/90000 (23%)]	Loss: 1.9640	Cost: 5.98s
Train Epoch: 1354 [40960/90000 (45%)]	Loss: 2.0442	Cost: 7.04s
Train Epoch: 1354 [61440/90000 (68%)]	Loss: 2.0804	Cost: 5.78s
Train Epoch: 1354 [81920/90000 (91%)]	Loss: 1.9687	Cost: 5.93s
Train Epoch: 1354 	Average Loss: 2.9213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.8437

Learning rate: 0.00019990954312239028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1355 [0/90000 (0%)]	Loss: 14.0824	Cost: 22.99s
Train Epoch: 1355 [20480/90000 (23%)]	Loss: 2.0740	Cost: 5.99s
Train Epoch: 1355 [40960/90000 (45%)]	Loss: 2.0940	Cost: 8.90s
Train Epoch: 1355 [61440/90000 (68%)]	Loss: 2.0495	Cost: 6.01s
Train Epoch: 1355 [81920/90000 (91%)]	Loss: 2.0218	Cost: 5.93s
Train Epoch: 1355 	Average Loss: 2.9472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9164

Learning rate: 0.00019990940947893962
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1356 [0/90000 (0%)]	Loss: 14.2522	Cost: 26.33s
Train Epoch: 1356 [20480/90000 (23%)]	Loss: 1.9189	Cost: 6.25s
Train Epoch: 1356 [40960/90000 (45%)]	Loss: 1.8574	Cost: 6.95s
Train Epoch: 1356 [61440/90000 (68%)]	Loss: 1.7782	Cost: 5.92s
Train Epoch: 1356 [81920/90000 (91%)]	Loss: 1.9855	Cost: 5.90s
Train Epoch: 1356 	Average Loss: 2.8269
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9299

Learning rate: 0.00019990927573688231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1357 [0/90000 (0%)]	Loss: 14.1764	Cost: 28.29s
Train Epoch: 1357 [20480/90000 (23%)]	Loss: 1.8574	Cost: 6.42s
Train Epoch: 1357 [40960/90000 (45%)]	Loss: 1.8238	Cost: 6.54s
Train Epoch: 1357 [61440/90000 (68%)]	Loss: 1.7860	Cost: 6.16s
Train Epoch: 1357 [81920/90000 (91%)]	Loss: 1.8870	Cost: 5.77s
Train Epoch: 1357 	Average Loss: 2.7383
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9503

Learning rate: 0.0001999091418962185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1358 [0/90000 (0%)]	Loss: 13.9505	Cost: 24.69s
Train Epoch: 1358 [20480/90000 (23%)]	Loss: 2.0186	Cost: 6.03s
Train Epoch: 1358 [40960/90000 (45%)]	Loss: 2.0786	Cost: 7.94s
Train Epoch: 1358 [61440/90000 (68%)]	Loss: 1.8000	Cost: 5.86s
Train Epoch: 1358 [81920/90000 (91%)]	Loss: 1.8730	Cost: 7.81s
Train Epoch: 1358 	Average Loss: 2.8211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9514

Learning rate: 0.00019990900795694832
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1359 [0/90000 (0%)]	Loss: 14.3207	Cost: 23.41s
Train Epoch: 1359 [20480/90000 (23%)]	Loss: 1.9990	Cost: 6.02s
Train Epoch: 1359 [40960/90000 (45%)]	Loss: 1.8717	Cost: 6.31s
Train Epoch: 1359 [61440/90000 (68%)]	Loss: 1.7941	Cost: 6.20s
Train Epoch: 1359 [81920/90000 (91%)]	Loss: 1.8106	Cost: 7.28s
Train Epoch: 1359 	Average Loss: 2.7674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9427

Learning rate: 0.0001999088739190719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1360 [0/90000 (0%)]	Loss: 14.2232	Cost: 23.76s
Train Epoch: 1360 [20480/90000 (23%)]	Loss: 1.8930	Cost: 6.30s
Train Epoch: 1360 [40960/90000 (45%)]	Loss: 1.9646	Cost: 7.30s
Train Epoch: 1360 [61440/90000 (68%)]	Loss: 1.8859	Cost: 5.92s
Train Epoch: 1360 [81920/90000 (91%)]	Loss: 1.8506	Cost: 6.52s
Train Epoch: 1360 	Average Loss: 2.7561
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0034

Learning rate: 0.00019990873978258938
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1361 [0/90000 (0%)]	Loss: 14.4015	Cost: 23.44s
Train Epoch: 1361 [20480/90000 (23%)]	Loss: 1.8335	Cost: 5.95s
Train Epoch: 1361 [40960/90000 (45%)]	Loss: 1.9276	Cost: 6.81s
Train Epoch: 1361 [61440/90000 (68%)]	Loss: 1.6093	Cost: 6.27s
Train Epoch: 1361 [81920/90000 (91%)]	Loss: 1.7986	Cost: 6.34s
Train Epoch: 1361 	Average Loss: 2.7296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9360

Learning rate: 0.00019990860554750087
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1362 [0/90000 (0%)]	Loss: 14.2103	Cost: 26.16s
Train Epoch: 1362 [20480/90000 (23%)]	Loss: 1.9563	Cost: 6.22s
Train Epoch: 1362 [40960/90000 (45%)]	Loss: 1.9989	Cost: 7.28s
Train Epoch: 1362 [61440/90000 (68%)]	Loss: 1.8329	Cost: 6.46s
Train Epoch: 1362 [81920/90000 (91%)]	Loss: 1.9398	Cost: 6.09s
Train Epoch: 1362 	Average Loss: 2.7390
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0135

Learning rate: 0.00019990847121380652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1363 [0/90000 (0%)]	Loss: 14.4592	Cost: 27.55s
Train Epoch: 1363 [20480/90000 (23%)]	Loss: 1.8446	Cost: 6.03s
Train Epoch: 1363 [40960/90000 (45%)]	Loss: 1.9396	Cost: 8.16s
Train Epoch: 1363 [61440/90000 (68%)]	Loss: 1.6781	Cost: 6.25s
Train Epoch: 1363 [81920/90000 (91%)]	Loss: 1.8358	Cost: 7.02s
Train Epoch: 1363 	Average Loss: 2.7153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0823

Learning rate: 0.00019990833678150646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1364 [0/90000 (0%)]	Loss: 14.5892	Cost: 22.74s
Train Epoch: 1364 [20480/90000 (23%)]	Loss: 1.8885	Cost: 6.15s
Train Epoch: 1364 [40960/90000 (45%)]	Loss: 1.7853	Cost: 7.30s
Train Epoch: 1364 [61440/90000 (68%)]	Loss: 1.9568	Cost: 6.12s
Train Epoch: 1364 [81920/90000 (91%)]	Loss: 2.0195	Cost: 8.70s
Train Epoch: 1364 	Average Loss: 2.7368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0530

Learning rate: 0.00019990820225060084
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1365 [0/90000 (0%)]	Loss: 14.5080	Cost: 24.20s
Train Epoch: 1365 [20480/90000 (23%)]	Loss: 1.9198	Cost: 5.97s
Train Epoch: 1365 [40960/90000 (45%)]	Loss: 1.9655	Cost: 7.35s
Train Epoch: 1365 [61440/90000 (68%)]	Loss: 2.0224	Cost: 5.90s
Train Epoch: 1365 [81920/90000 (91%)]	Loss: 2.1663	Cost: 5.88s
Train Epoch: 1365 	Average Loss: 2.8596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9722

Learning rate: 0.00019990806762108977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1366 [0/90000 (0%)]	Loss: 14.3501	Cost: 23.76s
Train Epoch: 1366 [20480/90000 (23%)]	Loss: 1.8978	Cost: 6.22s
Train Epoch: 1366 [40960/90000 (45%)]	Loss: 1.9257	Cost: 6.35s
Train Epoch: 1366 [61440/90000 (68%)]	Loss: 2.0625	Cost: 6.03s
Train Epoch: 1366 [81920/90000 (91%)]	Loss: 1.9263	Cost: 5.80s
Train Epoch: 1366 	Average Loss: 2.8118
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9486

Learning rate: 0.00019990793289297338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1367 [0/90000 (0%)]	Loss: 14.3852	Cost: 25.72s
Train Epoch: 1367 [20480/90000 (23%)]	Loss: 2.0943	Cost: 6.02s
Train Epoch: 1367 [40960/90000 (45%)]	Loss: 1.8005	Cost: 7.86s
Train Epoch: 1367 [61440/90000 (68%)]	Loss: 1.6005	Cost: 5.77s
Train Epoch: 1367 [81920/90000 (91%)]	Loss: 2.1275	Cost: 5.93s
Train Epoch: 1367 	Average Loss: 2.7619
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0608

Learning rate: 0.00019990779806625182
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1368 [0/90000 (0%)]	Loss: 14.6464	Cost: 27.96s
Train Epoch: 1368 [20480/90000 (23%)]	Loss: 2.1072	Cost: 6.11s
Train Epoch: 1368 [40960/90000 (45%)]	Loss: 1.8700	Cost: 8.77s
Train Epoch: 1368 [61440/90000 (68%)]	Loss: 1.6299	Cost: 5.97s
Train Epoch: 1368 [81920/90000 (91%)]	Loss: 1.8523	Cost: 6.94s
Train Epoch: 1368 	Average Loss: 2.7241
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9761

Learning rate: 0.0001999076631409252
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1369 [0/90000 (0%)]	Loss: 14.6161	Cost: 23.72s
Train Epoch: 1369 [20480/90000 (23%)]	Loss: 1.9831	Cost: 6.00s
Train Epoch: 1369 [40960/90000 (45%)]	Loss: 1.9349	Cost: 8.55s
Train Epoch: 1369 [61440/90000 (68%)]	Loss: 2.0490	Cost: 5.90s
Train Epoch: 1369 [81920/90000 (91%)]	Loss: 2.0882	Cost: 9.13s
Train Epoch: 1369 	Average Loss: 2.8111
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9804

Learning rate: 0.00019990752811699372
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1370 [0/90000 (0%)]	Loss: 14.4035	Cost: 23.39s
Train Epoch: 1370 [20480/90000 (23%)]	Loss: 2.0628	Cost: 6.18s
Train Epoch: 1370 [40960/90000 (45%)]	Loss: 1.8696	Cost: 6.29s
Train Epoch: 1370 [61440/90000 (68%)]	Loss: 1.7409	Cost: 6.10s
Train Epoch: 1370 [81920/90000 (91%)]	Loss: 1.6762	Cost: 6.17s
Train Epoch: 1370 	Average Loss: 2.7633
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0198

Learning rate: 0.00019990739299445743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1371 [0/90000 (0%)]	Loss: 14.5000	Cost: 24.23s
Train Epoch: 1371 [20480/90000 (23%)]	Loss: 1.9276	Cost: 6.04s
Train Epoch: 1371 [40960/90000 (45%)]	Loss: 1.8126	Cost: 7.52s
Train Epoch: 1371 [61440/90000 (68%)]	Loss: 1.9909	Cost: 6.08s
Train Epoch: 1371 [81920/90000 (91%)]	Loss: 1.9194	Cost: 6.29s
Train Epoch: 1371 	Average Loss: 2.7798
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9868

Learning rate: 0.0001999072577733165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1372 [0/90000 (0%)]	Loss: 14.4544	Cost: 25.31s
Train Epoch: 1372 [20480/90000 (23%)]	Loss: 2.1262	Cost: 6.15s
Train Epoch: 1372 [40960/90000 (45%)]	Loss: 2.2070	Cost: 6.23s
Train Epoch: 1372 [61440/90000 (68%)]	Loss: 2.1601	Cost: 6.06s
Train Epoch: 1372 [81920/90000 (91%)]	Loss: 1.9432	Cost: 5.75s
Train Epoch: 1372 	Average Loss: 2.9212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0651

Learning rate: 0.00019990712245357106
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1373 [0/90000 (0%)]	Loss: 14.4036	Cost: 28.03s
Train Epoch: 1373 [20480/90000 (23%)]	Loss: 1.8292	Cost: 6.08s
Train Epoch: 1373 [40960/90000 (45%)]	Loss: 1.9864	Cost: 6.91s
Train Epoch: 1373 [61440/90000 (68%)]	Loss: 1.7261	Cost: 6.04s
Train Epoch: 1373 [81920/90000 (91%)]	Loss: 1.7632	Cost: 6.19s
Train Epoch: 1373 	Average Loss: 2.7791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9927

Learning rate: 0.00019990698703522124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1374 [0/90000 (0%)]	Loss: 14.1931	Cost: 25.63s
Train Epoch: 1374 [20480/90000 (23%)]	Loss: 1.9884	Cost: 6.00s
Train Epoch: 1374 [40960/90000 (45%)]	Loss: 1.7418	Cost: 9.05s
Train Epoch: 1374 [61440/90000 (68%)]	Loss: 1.8692	Cost: 5.96s
Train Epoch: 1374 [81920/90000 (91%)]	Loss: 1.7533	Cost: 9.48s
Train Epoch: 1374 	Average Loss: 2.6648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0190

Learning rate: 0.00019990685151826719
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1375 [0/90000 (0%)]	Loss: 14.4008	Cost: 22.13s
Train Epoch: 1375 [20480/90000 (23%)]	Loss: 1.7198	Cost: 6.01s
Train Epoch: 1375 [40960/90000 (45%)]	Loss: 1.6477	Cost: 7.73s
Train Epoch: 1375 [61440/90000 (68%)]	Loss: 1.7894	Cost: 5.96s
Train Epoch: 1375 [81920/90000 (91%)]	Loss: 1.6352	Cost: 8.69s
Train Epoch: 1375 	Average Loss: 2.6504
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0159

Learning rate: 0.00019990671590270901
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1376 [0/90000 (0%)]	Loss: 14.3294	Cost: 24.15s
Train Epoch: 1376 [20480/90000 (23%)]	Loss: 1.6301	Cost: 5.92s
Train Epoch: 1376 [40960/90000 (45%)]	Loss: 1.6982	Cost: 6.97s
Train Epoch: 1376 [61440/90000 (68%)]	Loss: 1.6335	Cost: 6.06s
Train Epoch: 1376 [81920/90000 (91%)]	Loss: 1.6947	Cost: 5.90s
Train Epoch: 1376 	Average Loss: 2.6231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1126

Learning rate: 0.00019990658018854686
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1377 [0/90000 (0%)]	Loss: 14.5124	Cost: 24.45s
Train Epoch: 1377 [20480/90000 (23%)]	Loss: 1.6922	Cost: 6.11s
Train Epoch: 1377 [40960/90000 (45%)]	Loss: 1.7178	Cost: 7.40s
Train Epoch: 1377 [61440/90000 (68%)]	Loss: 1.7724	Cost: 6.60s
Train Epoch: 1377 [81920/90000 (91%)]	Loss: 2.0162	Cost: 6.28s
Train Epoch: 1377 	Average Loss: 2.6951
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9068

Learning rate: 0.00019990644437578085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1378 [0/90000 (0%)]	Loss: 14.5282	Cost: 24.86s
Train Epoch: 1378 [20480/90000 (23%)]	Loss: 1.8482	Cost: 6.28s
Train Epoch: 1378 [40960/90000 (45%)]	Loss: 1.6313	Cost: 6.56s
Train Epoch: 1378 [61440/90000 (68%)]	Loss: 1.8014	Cost: 6.03s
Train Epoch: 1378 [81920/90000 (91%)]	Loss: 1.8360	Cost: 5.95s
Train Epoch: 1378 	Average Loss: 2.7265
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0235

Learning rate: 0.00019990630846441115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1379 [0/90000 (0%)]	Loss: 14.2776	Cost: 27.84s
Train Epoch: 1379 [20480/90000 (23%)]	Loss: 1.6395	Cost: 6.10s
Train Epoch: 1379 [40960/90000 (45%)]	Loss: 1.6080	Cost: 7.58s
Train Epoch: 1379 [61440/90000 (68%)]	Loss: 1.5905	Cost: 5.98s
Train Epoch: 1379 [81920/90000 (91%)]	Loss: 1.8844	Cost: 6.21s
Train Epoch: 1379 	Average Loss: 2.6309
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9924

Learning rate: 0.00019990617245443785
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1380 [0/90000 (0%)]	Loss: 14.2436	Cost: 26.19s
Train Epoch: 1380 [20480/90000 (23%)]	Loss: 1.7328	Cost: 6.11s
Train Epoch: 1380 [40960/90000 (45%)]	Loss: 1.5884	Cost: 9.40s
Train Epoch: 1380 [61440/90000 (68%)]	Loss: 1.4364	Cost: 5.95s
Train Epoch: 1380 [81920/90000 (91%)]	Loss: 1.7426	Cost: 9.11s
Train Epoch: 1380 	Average Loss: 2.5810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0980

Learning rate: 0.00019990603634586116
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1381 [0/90000 (0%)]	Loss: 14.4495	Cost: 22.86s
Train Epoch: 1381 [20480/90000 (23%)]	Loss: 1.6406	Cost: 6.11s
Train Epoch: 1381 [40960/90000 (45%)]	Loss: 1.7038	Cost: 6.97s
Train Epoch: 1381 [61440/90000 (68%)]	Loss: 1.7173	Cost: 6.02s
Train Epoch: 1381 [81920/90000 (91%)]	Loss: 1.7325	Cost: 8.31s
Train Epoch: 1381 	Average Loss: 2.6541
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1516

Learning rate: 0.00019990590013868113
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1382 [0/90000 (0%)]	Loss: 14.3374	Cost: 24.22s
Train Epoch: 1382 [20480/90000 (23%)]	Loss: 1.8486	Cost: 6.21s
Train Epoch: 1382 [40960/90000 (45%)]	Loss: 1.6574	Cost: 6.76s
Train Epoch: 1382 [61440/90000 (68%)]	Loss: 1.6468	Cost: 5.83s
Train Epoch: 1382 [81920/90000 (91%)]	Loss: 2.0357	Cost: 5.84s
Train Epoch: 1382 	Average Loss: 2.6287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0361

Learning rate: 0.0001999057638328979
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1383 [0/90000 (0%)]	Loss: 14.5343	Cost: 23.23s
Train Epoch: 1383 [20480/90000 (23%)]	Loss: 1.8403	Cost: 6.16s
Train Epoch: 1383 [40960/90000 (45%)]	Loss: 1.5789	Cost: 7.38s
Train Epoch: 1383 [61440/90000 (68%)]	Loss: 1.7161	Cost: 5.84s
Train Epoch: 1383 [81920/90000 (91%)]	Loss: 1.9257	Cost: 6.33s
Train Epoch: 1383 	Average Loss: 2.6564
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0174

Learning rate: 0.00019990562742851166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1384 [0/90000 (0%)]	Loss: 14.0737	Cost: 26.50s
Train Epoch: 1384 [20480/90000 (23%)]	Loss: 1.9239	Cost: 6.04s
Train Epoch: 1384 [40960/90000 (45%)]	Loss: 1.7986	Cost: 6.75s
Train Epoch: 1384 [61440/90000 (68%)]	Loss: 1.7311	Cost: 5.97s
Train Epoch: 1384 [81920/90000 (91%)]	Loss: 1.8417	Cost: 5.89s
Train Epoch: 1384 	Average Loss: 2.7149
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1516

Learning rate: 0.00019990549092552251
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1385 [0/90000 (0%)]	Loss: 14.2189	Cost: 28.63s
Train Epoch: 1385 [20480/90000 (23%)]	Loss: 1.8107	Cost: 6.07s
Train Epoch: 1385 [40960/90000 (45%)]	Loss: 1.9640	Cost: 6.64s
Train Epoch: 1385 [61440/90000 (68%)]	Loss: 1.7652	Cost: 6.43s
Train Epoch: 1385 [81920/90000 (91%)]	Loss: 1.8826	Cost: 6.22s
Train Epoch: 1385 	Average Loss: 2.7555
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0481

Learning rate: 0.00019990535432393063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1386 [0/90000 (0%)]	Loss: 14.2617	Cost: 22.56s
Train Epoch: 1386 [20480/90000 (23%)]	Loss: 1.7097	Cost: 5.99s
Train Epoch: 1386 [40960/90000 (45%)]	Loss: 1.6707	Cost: 8.01s
Train Epoch: 1386 [61440/90000 (68%)]	Loss: 1.6007	Cost: 5.99s
Train Epoch: 1386 [81920/90000 (91%)]	Loss: 1.6406	Cost: 8.67s
Train Epoch: 1386 	Average Loss: 2.6387
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9908

Learning rate: 0.0001999052176237361
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1387 [0/90000 (0%)]	Loss: 14.3181	Cost: 24.71s
Train Epoch: 1387 [20480/90000 (23%)]	Loss: 1.7503	Cost: 6.00s
Train Epoch: 1387 [40960/90000 (45%)]	Loss: 1.9605	Cost: 7.18s
Train Epoch: 1387 [61440/90000 (68%)]	Loss: 1.8622	Cost: 5.89s
Train Epoch: 1387 [81920/90000 (91%)]	Loss: 1.9762	Cost: 5.89s
Train Epoch: 1387 	Average Loss: 2.7371
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0734

Learning rate: 0.00019990508082493906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1388 [0/90000 (0%)]	Loss: 14.5240	Cost: 23.39s
Train Epoch: 1388 [20480/90000 (23%)]	Loss: 1.5851	Cost: 6.50s
Train Epoch: 1388 [40960/90000 (45%)]	Loss: 1.8566	Cost: 6.40s
Train Epoch: 1388 [61440/90000 (68%)]	Loss: 1.7223	Cost: 6.05s
Train Epoch: 1388 [81920/90000 (91%)]	Loss: 1.7862	Cost: 6.15s
Train Epoch: 1388 	Average Loss: 2.6458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1469

Learning rate: 0.0001999049439275397
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1389 [0/90000 (0%)]	Loss: 14.5272	Cost: 25.09s
Train Epoch: 1389 [20480/90000 (23%)]	Loss: 1.7844	Cost: 6.18s
Train Epoch: 1389 [40960/90000 (45%)]	Loss: 1.5353	Cost: 6.91s
Train Epoch: 1389 [61440/90000 (68%)]	Loss: 1.4729	Cost: 6.02s
Train Epoch: 1389 [81920/90000 (91%)]	Loss: 1.5855	Cost: 6.35s
Train Epoch: 1389 	Average Loss: 2.4768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0914

Learning rate: 0.00019990480693153807
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1390 [0/90000 (0%)]	Loss: 14.5764	Cost: 30.06s
Train Epoch: 1390 [20480/90000 (23%)]	Loss: 1.6092	Cost: 6.06s
Train Epoch: 1390 [40960/90000 (45%)]	Loss: 1.8021	Cost: 6.57s
Train Epoch: 1390 [61440/90000 (68%)]	Loss: 1.9452	Cost: 5.90s
Train Epoch: 1390 [81920/90000 (91%)]	Loss: 2.0444	Cost: 7.64s
Train Epoch: 1390 	Average Loss: 2.7459
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1092

Learning rate: 0.00019990466983693436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1391 [0/90000 (0%)]	Loss: 14.4843	Cost: 24.88s
Train Epoch: 1391 [20480/90000 (23%)]	Loss: 2.2028	Cost: 6.00s
Train Epoch: 1391 [40960/90000 (45%)]	Loss: 2.1924	Cost: 7.55s
Train Epoch: 1391 [61440/90000 (68%)]	Loss: 2.2830	Cost: 5.99s
Train Epoch: 1391 [81920/90000 (91%)]	Loss: 2.1333	Cost: 6.85s
Train Epoch: 1391 	Average Loss: 3.0728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9379

Learning rate: 0.0001999045326437287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1392 [0/90000 (0%)]	Loss: 14.3154	Cost: 23.50s
Train Epoch: 1392 [20480/90000 (23%)]	Loss: 1.9526	Cost: 6.10s
Train Epoch: 1392 [40960/90000 (45%)]	Loss: 1.8303	Cost: 6.34s
Train Epoch: 1392 [61440/90000 (68%)]	Loss: 1.7990	Cost: 6.16s
Train Epoch: 1392 [81920/90000 (91%)]	Loss: 1.7970	Cost: 8.01s
Train Epoch: 1392 	Average Loss: 2.7600
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0782

Learning rate: 0.0001999043953519212
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1393 [0/90000 (0%)]	Loss: 14.3757	Cost: 23.10s
Train Epoch: 1393 [20480/90000 (23%)]	Loss: 1.7194	Cost: 6.03s
Train Epoch: 1393 [40960/90000 (45%)]	Loss: 1.4068	Cost: 7.63s
Train Epoch: 1393 [61440/90000 (68%)]	Loss: 1.6840	Cost: 5.94s
Train Epoch: 1393 [81920/90000 (91%)]	Loss: 1.7942	Cost: 6.17s
Train Epoch: 1393 	Average Loss: 2.5514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0512

Learning rate: 0.000199904257961512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1394 [0/90000 (0%)]	Loss: 14.2644	Cost: 23.97s
Train Epoch: 1394 [20480/90000 (23%)]	Loss: 1.7054	Cost: 6.12s
Train Epoch: 1394 [40960/90000 (45%)]	Loss: 1.5483	Cost: 7.45s
Train Epoch: 1394 [61440/90000 (68%)]	Loss: 1.8631	Cost: 6.09s
Train Epoch: 1394 [81920/90000 (91%)]	Loss: 1.8440	Cost: 6.28s
Train Epoch: 1394 	Average Loss: 2.6940
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0371

Learning rate: 0.0001999041204725013
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1395 [0/90000 (0%)]	Loss: 14.7701	Cost: 26.48s
Train Epoch: 1395 [20480/90000 (23%)]	Loss: 2.2517	Cost: 6.56s
Train Epoch: 1395 [40960/90000 (45%)]	Loss: 2.2850	Cost: 7.10s
Train Epoch: 1395 [61440/90000 (68%)]	Loss: 2.0403	Cost: 5.97s
Train Epoch: 1395 [81920/90000 (91%)]	Loss: 2.1704	Cost: 5.91s
Train Epoch: 1395 	Average Loss: 3.1178
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0666

Learning rate: 0.00019990398288488915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1396 [0/90000 (0%)]	Loss: 14.3711	Cost: 28.38s
Train Epoch: 1396 [20480/90000 (23%)]	Loss: 1.9900	Cost: 6.04s
Train Epoch: 1396 [40960/90000 (45%)]	Loss: 1.9524	Cost: 6.93s
Train Epoch: 1396 [61440/90000 (68%)]	Loss: 1.7759	Cost: 6.21s
Train Epoch: 1396 [81920/90000 (91%)]	Loss: 1.7841	Cost: 5.73s
Train Epoch: 1396 	Average Loss: 2.7850
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1043

Learning rate: 0.00019990384519867572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1397 [0/90000 (0%)]	Loss: 14.4162	Cost: 24.69s
Train Epoch: 1397 [20480/90000 (23%)]	Loss: 1.8806	Cost: 6.07s
Train Epoch: 1397 [40960/90000 (45%)]	Loss: 1.4150	Cost: 7.49s
Train Epoch: 1397 [61440/90000 (68%)]	Loss: 1.5565	Cost: 5.91s
Train Epoch: 1397 [81920/90000 (91%)]	Loss: 1.7212	Cost: 7.86s
Train Epoch: 1397 	Average Loss: 2.5494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9979

Learning rate: 0.00019990370741386113
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1398 [0/90000 (0%)]	Loss: 14.4550	Cost: 24.11s
Train Epoch: 1398 [20480/90000 (23%)]	Loss: 1.9558	Cost: 6.09s
Train Epoch: 1398 [40960/90000 (45%)]	Loss: 1.7433	Cost: 6.37s
Train Epoch: 1398 [61440/90000 (68%)]	Loss: 1.3656	Cost: 6.00s
Train Epoch: 1398 [81920/90000 (91%)]	Loss: 1.8040	Cost: 6.13s
Train Epoch: 1398 	Average Loss: 2.5246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1198

Learning rate: 0.00019990356953044556
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1399 [0/90000 (0%)]	Loss: 14.2913	Cost: 23.37s
Train Epoch: 1399 [20480/90000 (23%)]	Loss: 1.6343	Cost: 6.20s
Train Epoch: 1399 [40960/90000 (45%)]	Loss: 1.4824	Cost: 6.55s
Train Epoch: 1399 [61440/90000 (68%)]	Loss: 1.4354	Cost: 6.01s
Train Epoch: 1399 [81920/90000 (91%)]	Loss: 1.5632	Cost: 6.05s
Train Epoch: 1399 	Average Loss: 2.4185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1061

Learning rate: 0.00019990343154842913
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1400 [0/90000 (0%)]	Loss: 14.4979	Cost: 24.48s
Train Epoch: 1400 [20480/90000 (23%)]	Loss: 1.6983	Cost: 6.05s
Train Epoch: 1400 [40960/90000 (45%)]	Loss: 1.4658	Cost: 6.54s
Train Epoch: 1400 [61440/90000 (68%)]	Loss: 1.3887	Cost: 6.13s
Train Epoch: 1400 [81920/90000 (91%)]	Loss: 1.5002	Cost: 5.91s
Train Epoch: 1400 	Average Loss: 2.4056
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2566

Learning rate: 0.00019990329346781198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1401 [0/90000 (0%)]	Loss: 14.5048	Cost: 29.22s
Train Epoch: 1401 [20480/90000 (23%)]	Loss: 1.6962	Cost: 5.93s
Train Epoch: 1401 [40960/90000 (45%)]	Loss: 1.4020	Cost: 7.17s
Train Epoch: 1401 [61440/90000 (68%)]	Loss: 1.4686	Cost: 6.09s
Train Epoch: 1401 [81920/90000 (91%)]	Loss: 1.8173	Cost: 6.79s
Train Epoch: 1401 	Average Loss: 2.5163
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0704

Learning rate: 0.00019990315528859419
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1402 [0/90000 (0%)]	Loss: 14.4811	Cost: 24.08s
Train Epoch: 1402 [20480/90000 (23%)]	Loss: 1.7028	Cost: 6.02s
Train Epoch: 1402 [40960/90000 (45%)]	Loss: 1.7065	Cost: 7.53s
Train Epoch: 1402 [61440/90000 (68%)]	Loss: 1.3986	Cost: 5.99s
Train Epoch: 1402 [81920/90000 (91%)]	Loss: 1.5147	Cost: 6.75s
Train Epoch: 1402 	Average Loss: 2.5302
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1662

Learning rate: 0.00019990301701077598
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1403 [0/90000 (0%)]	Loss: 14.6490	Cost: 23.20s
Train Epoch: 1403 [20480/90000 (23%)]	Loss: 1.6557	Cost: 6.06s
Train Epoch: 1403 [40960/90000 (45%)]	Loss: 1.5312	Cost: 6.55s
Train Epoch: 1403 [61440/90000 (68%)]	Loss: 1.2864	Cost: 6.09s
Train Epoch: 1403 [81920/90000 (91%)]	Loss: 1.3369	Cost: 8.41s
Train Epoch: 1403 	Average Loss: 2.4175
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1006

Learning rate: 0.00019990287863435742
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1404 [0/90000 (0%)]	Loss: 14.2238	Cost: 23.34s
Train Epoch: 1404 [20480/90000 (23%)]	Loss: 1.6816	Cost: 6.08s
Train Epoch: 1404 [40960/90000 (45%)]	Loss: 1.3400	Cost: 6.98s
Train Epoch: 1404 [61440/90000 (68%)]	Loss: 1.2517	Cost: 5.84s
Train Epoch: 1404 [81920/90000 (91%)]	Loss: 1.3121	Cost: 6.34s
Train Epoch: 1404 	Average Loss: 2.3261
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2037

Learning rate: 0.00019990274015933864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1405 [0/90000 (0%)]	Loss: 14.6160	Cost: 24.58s
Train Epoch: 1405 [20480/90000 (23%)]	Loss: 1.5214	Cost: 6.14s
Train Epoch: 1405 [40960/90000 (45%)]	Loss: 1.7574	Cost: 6.51s
Train Epoch: 1405 [61440/90000 (68%)]	Loss: 1.3650	Cost: 6.06s
Train Epoch: 1405 [81920/90000 (91%)]	Loss: 1.9000	Cost: 5.85s
Train Epoch: 1405 	Average Loss: 2.5616
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0895

Learning rate: 0.00019990260158571984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1406 [0/90000 (0%)]	Loss: 14.5375	Cost: 27.18s
Train Epoch: 1406 [20480/90000 (23%)]	Loss: 1.9672	Cost: 6.04s
Train Epoch: 1406 [40960/90000 (45%)]	Loss: 1.7586	Cost: 6.88s
Train Epoch: 1406 [61440/90000 (68%)]	Loss: 1.5426	Cost: 5.90s
Train Epoch: 1406 [81920/90000 (91%)]	Loss: 1.7810	Cost: 5.90s
Train Epoch: 1406 	Average Loss: 2.7423
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1342

Learning rate: 0.0001999024629135011
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1407 [0/90000 (0%)]	Loss: 14.2156	Cost: 28.87s
Train Epoch: 1407 [20480/90000 (23%)]	Loss: 1.9266	Cost: 6.06s
Train Epoch: 1407 [40960/90000 (45%)]	Loss: 1.9269	Cost: 9.04s
Train Epoch: 1407 [61440/90000 (68%)]	Loss: 1.8954	Cost: 5.95s
Train Epoch: 1407 [81920/90000 (91%)]	Loss: 1.9196	Cost: 6.85s
Train Epoch: 1407 	Average Loss: 2.7500
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1786

Learning rate: 0.00019990232414268262
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1408 [0/90000 (0%)]	Loss: 14.6449	Cost: 25.34s
Train Epoch: 1408 [20480/90000 (23%)]	Loss: 1.8761	Cost: 6.07s
Train Epoch: 1408 [40960/90000 (45%)]	Loss: 1.5620	Cost: 7.80s
Train Epoch: 1408 [61440/90000 (68%)]	Loss: 1.5471	Cost: 5.96s
Train Epoch: 1408 [81920/90000 (91%)]	Loss: 1.5195	Cost: 7.40s
Train Epoch: 1408 	Average Loss: 2.5588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1371

Learning rate: 0.0001999021852732645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1409 [0/90000 (0%)]	Loss: 14.6516	Cost: 23.46s
Train Epoch: 1409 [20480/90000 (23%)]	Loss: 1.6022	Cost: 6.15s
Train Epoch: 1409 [40960/90000 (45%)]	Loss: 1.4373	Cost: 6.44s
Train Epoch: 1409 [61440/90000 (68%)]	Loss: 1.4660	Cost: 6.47s
Train Epoch: 1409 [81920/90000 (91%)]	Loss: 1.6141	Cost: 6.05s
Train Epoch: 1409 	Average Loss: 2.3760
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1725

Learning rate: 0.00019990204630524684
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1410 [0/90000 (0%)]	Loss: 14.7699	Cost: 23.49s
Train Epoch: 1410 [20480/90000 (23%)]	Loss: 1.4230	Cost: 6.17s
Train Epoch: 1410 [40960/90000 (45%)]	Loss: 1.4721	Cost: 7.42s
Train Epoch: 1410 [61440/90000 (68%)]	Loss: 1.2108	Cost: 5.91s
Train Epoch: 1410 [81920/90000 (91%)]	Loss: 1.2073	Cost: 6.10s
Train Epoch: 1410 	Average Loss: 2.2836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3133

Learning rate: 0.00019990190723862984
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1411 [0/90000 (0%)]	Loss: 14.6144	Cost: 25.01s
Train Epoch: 1411 [20480/90000 (23%)]	Loss: 1.6283	Cost: 5.94s
Train Epoch: 1411 [40960/90000 (45%)]	Loss: 1.4728	Cost: 6.89s
Train Epoch: 1411 [61440/90000 (68%)]	Loss: 1.5292	Cost: 5.94s
Train Epoch: 1411 [81920/90000 (91%)]	Loss: 1.5054	Cost: 6.28s
Train Epoch: 1411 	Average Loss: 2.4528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1955

Learning rate: 0.00019990176807341357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1412 [0/90000 (0%)]	Loss: 14.8898	Cost: 29.43s
Train Epoch: 1412 [20480/90000 (23%)]	Loss: 2.0491	Cost: 6.02s
Train Epoch: 1412 [40960/90000 (45%)]	Loss: 1.9347	Cost: 8.10s
Train Epoch: 1412 [61440/90000 (68%)]	Loss: 1.6958	Cost: 5.98s
Train Epoch: 1412 [81920/90000 (91%)]	Loss: 1.7140	Cost: 5.80s
Train Epoch: 1412 	Average Loss: 2.7053
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1857

Learning rate: 0.00019990162880959822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1413 [0/90000 (0%)]	Loss: 14.0338	Cost: 24.48s
Train Epoch: 1413 [20480/90000 (23%)]	Loss: 1.6550	Cost: 6.05s
Train Epoch: 1413 [40960/90000 (45%)]	Loss: 1.5175	Cost: 7.64s
Train Epoch: 1413 [61440/90000 (68%)]	Loss: 1.5829	Cost: 6.14s
Train Epoch: 1413 [81920/90000 (91%)]	Loss: 1.5501	Cost: 7.85s
Train Epoch: 1413 	Average Loss: 2.5117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1128

Learning rate: 0.00019990148944718395
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1414 [0/90000 (0%)]	Loss: 14.3014	Cost: 23.15s
Train Epoch: 1414 [20480/90000 (23%)]	Loss: 1.6340	Cost: 6.03s
Train Epoch: 1414 [40960/90000 (45%)]	Loss: 1.5235	Cost: 6.29s
Train Epoch: 1414 [61440/90000 (68%)]	Loss: 1.2986	Cost: 6.31s
Train Epoch: 1414 [81920/90000 (91%)]	Loss: 1.4411	Cost: 8.71s
Train Epoch: 1414 	Average Loss: 2.3766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2050

Learning rate: 0.00019990134998617085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1415 [0/90000 (0%)]	Loss: 14.4885	Cost: 23.43s
Train Epoch: 1415 [20480/90000 (23%)]	Loss: 1.3700	Cost: 6.05s
Train Epoch: 1415 [40960/90000 (45%)]	Loss: 1.4456	Cost: 6.73s
Train Epoch: 1415 [61440/90000 (68%)]	Loss: 1.1503	Cost: 5.95s
Train Epoch: 1415 [81920/90000 (91%)]	Loss: 1.4218	Cost: 5.73s
Train Epoch: 1415 	Average Loss: 2.2571
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1487

Learning rate: 0.00019990121042655904
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1416 [0/90000 (0%)]	Loss: 14.3273	Cost: 24.39s
Train Epoch: 1416 [20480/90000 (23%)]	Loss: 1.5468	Cost: 6.19s
Train Epoch: 1416 [40960/90000 (45%)]	Loss: 1.3662	Cost: 6.54s
Train Epoch: 1416 [61440/90000 (68%)]	Loss: 1.2283	Cost: 6.17s
Train Epoch: 1416 [81920/90000 (91%)]	Loss: 1.4507	Cost: 5.74s
Train Epoch: 1416 	Average Loss: 2.3308
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2428

Learning rate: 0.0001999010707683487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1417 [0/90000 (0%)]	Loss: 14.7471	Cost: 28.28s
Train Epoch: 1417 [20480/90000 (23%)]	Loss: 1.2641	Cost: 6.33s
Train Epoch: 1417 [40960/90000 (45%)]	Loss: 1.4949	Cost: 7.44s
Train Epoch: 1417 [61440/90000 (68%)]	Loss: 1.3761	Cost: 6.04s
Train Epoch: 1417 [81920/90000 (91%)]	Loss: 1.2926	Cost: 6.25s
Train Epoch: 1417 	Average Loss: 2.3071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2444

Learning rate: 0.00019990093101153998
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1418 [0/90000 (0%)]	Loss: 14.8130	Cost: 26.12s
Train Epoch: 1418 [20480/90000 (23%)]	Loss: 1.3759	Cost: 6.16s
Train Epoch: 1418 [40960/90000 (45%)]	Loss: 1.2890	Cost: 7.69s
Train Epoch: 1418 [61440/90000 (68%)]	Loss: 1.2725	Cost: 5.97s
Train Epoch: 1418 [81920/90000 (91%)]	Loss: 1.4124	Cost: 7.02s
Train Epoch: 1418 	Average Loss: 2.2694
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3020

Learning rate: 0.00019990079115613296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1419 [0/90000 (0%)]	Loss: 14.7649	Cost: 22.77s
Train Epoch: 1419 [20480/90000 (23%)]	Loss: 1.6148	Cost: 6.16s
Train Epoch: 1419 [40960/90000 (45%)]	Loss: 1.4183	Cost: 6.53s
Train Epoch: 1419 [61440/90000 (68%)]	Loss: 1.2106	Cost: 6.22s
Train Epoch: 1419 [81920/90000 (91%)]	Loss: 1.3570	Cost: 8.49s
Train Epoch: 1419 	Average Loss: 2.2910
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3437

Learning rate: 0.00019990065120212782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1420 [0/90000 (0%)]	Loss: 14.8483	Cost: 23.47s
Train Epoch: 1420 [20480/90000 (23%)]	Loss: 1.1098	Cost: 6.20s
Train Epoch: 1420 [40960/90000 (45%)]	Loss: 1.2294	Cost: 6.60s
Train Epoch: 1420 [61440/90000 (68%)]	Loss: 1.3666	Cost: 5.91s
Train Epoch: 1420 [81920/90000 (91%)]	Loss: 1.2992	Cost: 6.47s
Train Epoch: 1420 	Average Loss: 2.2099
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3074

Learning rate: 0.0001999005111495247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1421 [0/90000 (0%)]	Loss: 14.7453	Cost: 23.72s
Train Epoch: 1421 [20480/90000 (23%)]	Loss: 1.5255	Cost: 6.20s
Train Epoch: 1421 [40960/90000 (45%)]	Loss: 1.4059	Cost: 7.46s
Train Epoch: 1421 [61440/90000 (68%)]	Loss: 1.4052	Cost: 6.09s
Train Epoch: 1421 [81920/90000 (91%)]	Loss: 1.3895	Cost: 6.00s
Train Epoch: 1421 	Average Loss: 2.3671
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2862

Learning rate: 0.00019990037099832373
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1422 [0/90000 (0%)]	Loss: 14.7122	Cost: 25.86s
Train Epoch: 1422 [20480/90000 (23%)]	Loss: 1.6483	Cost: 6.67s
Train Epoch: 1422 [40960/90000 (45%)]	Loss: 1.5948	Cost: 6.41s
Train Epoch: 1422 [61440/90000 (68%)]	Loss: 1.2814	Cost: 6.02s
Train Epoch: 1422 [81920/90000 (91%)]	Loss: 1.5280	Cost: 5.87s
Train Epoch: 1422 	Average Loss: 2.3977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2879

Learning rate: 0.00019990023074852506
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1423 [0/90000 (0%)]	Loss: 14.6459	Cost: 28.34s
Train Epoch: 1423 [20480/90000 (23%)]	Loss: 1.4724	Cost: 6.11s
Train Epoch: 1423 [40960/90000 (45%)]	Loss: 1.8740	Cost: 8.23s
Train Epoch: 1423 [61440/90000 (68%)]	Loss: 1.6655	Cost: 5.96s
Train Epoch: 1423 [81920/90000 (91%)]	Loss: 1.5479	Cost: 6.01s
Train Epoch: 1423 	Average Loss: 2.5110
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2401

Learning rate: 0.00019990009040012877
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1424 [0/90000 (0%)]	Loss: 14.4965	Cost: 24.69s
Train Epoch: 1424 [20480/90000 (23%)]	Loss: 1.7967	Cost: 6.02s
Train Epoch: 1424 [40960/90000 (45%)]	Loss: 1.8328	Cost: 7.60s
Train Epoch: 1424 [61440/90000 (68%)]	Loss: 1.9116	Cost: 5.92s
Train Epoch: 1424 [81920/90000 (91%)]	Loss: 1.9535	Cost: 7.28s
Train Epoch: 1424 	Average Loss: 2.6600
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1960

Learning rate: 0.0001998999499531351
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1425 [0/90000 (0%)]	Loss: 14.4908	Cost: 22.97s
Train Epoch: 1425 [20480/90000 (23%)]	Loss: 1.7854	Cost: 6.18s
Train Epoch: 1425 [40960/90000 (45%)]	Loss: 1.7629	Cost: 6.26s
Train Epoch: 1425 [61440/90000 (68%)]	Loss: 1.7057	Cost: 5.99s
Train Epoch: 1425 [81920/90000 (91%)]	Loss: 1.9564	Cost: 6.66s
Train Epoch: 1425 	Average Loss: 2.6596
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1731

Learning rate: 0.00019989980940754407
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1426 [0/90000 (0%)]	Loss: 14.3616	Cost: 23.75s
Train Epoch: 1426 [20480/90000 (23%)]	Loss: 1.7146	Cost: 6.21s
Train Epoch: 1426 [40960/90000 (45%)]	Loss: 1.5726	Cost: 6.37s
Train Epoch: 1426 [61440/90000 (68%)]	Loss: 1.2487	Cost: 6.02s
Train Epoch: 1426 [81920/90000 (91%)]	Loss: 1.7408	Cost: 6.19s
Train Epoch: 1426 	Average Loss: 2.4997
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2096

Learning rate: 0.0001998996687633559
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1427 [0/90000 (0%)]	Loss: 14.4728	Cost: 24.36s
Train Epoch: 1427 [20480/90000 (23%)]	Loss: 1.4162	Cost: 5.98s
Train Epoch: 1427 [40960/90000 (45%)]	Loss: 1.5142	Cost: 6.69s
Train Epoch: 1427 [61440/90000 (68%)]	Loss: 1.3952	Cost: 6.14s
Train Epoch: 1427 [81920/90000 (91%)]	Loss: 1.3985	Cost: 5.74s
Train Epoch: 1427 	Average Loss: 2.3441
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2350

Learning rate: 0.00019989952802057075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1428 [0/90000 (0%)]	Loss: 14.6125	Cost: 29.61s
Train Epoch: 1428 [20480/90000 (23%)]	Loss: 1.5395	Cost: 5.97s
Train Epoch: 1428 [40960/90000 (45%)]	Loss: 1.4893	Cost: 7.72s
Train Epoch: 1428 [61440/90000 (68%)]	Loss: 1.1894	Cost: 5.97s
Train Epoch: 1428 [81920/90000 (91%)]	Loss: 1.3260	Cost: 5.74s
Train Epoch: 1428 	Average Loss: 2.2728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2157

Learning rate: 0.00019989938717918869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1429 [0/90000 (0%)]	Loss: 14.8118	Cost: 25.42s
Train Epoch: 1429 [20480/90000 (23%)]	Loss: 1.3151	Cost: 6.04s
Train Epoch: 1429 [40960/90000 (45%)]	Loss: 1.5523	Cost: 8.20s
Train Epoch: 1429 [61440/90000 (68%)]	Loss: 1.1799	Cost: 5.99s
Train Epoch: 1429 [81920/90000 (91%)]	Loss: 1.4870	Cost: 7.67s
Train Epoch: 1429 	Average Loss: 2.2527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1656

Learning rate: 0.00019989924623920987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1430 [0/90000 (0%)]	Loss: 14.7263	Cost: 24.40s
Train Epoch: 1430 [20480/90000 (23%)]	Loss: 1.2828	Cost: 6.32s
Train Epoch: 1430 [40960/90000 (45%)]	Loss: 1.1957	Cost: 6.15s
Train Epoch: 1430 [61440/90000 (68%)]	Loss: 1.1714	Cost: 6.00s
Train Epoch: 1430 [81920/90000 (91%)]	Loss: 1.3491	Cost: 7.85s
Train Epoch: 1430 	Average Loss: 2.2221
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2959

Learning rate: 0.00019989910520063444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1431 [0/90000 (0%)]	Loss: 14.8330	Cost: 24.63s
Train Epoch: 1431 [20480/90000 (23%)]	Loss: 1.1553	Cost: 6.04s
Train Epoch: 1431 [40960/90000 (45%)]	Loss: 1.3087	Cost: 6.84s
Train Epoch: 1431 [61440/90000 (68%)]	Loss: 1.1070	Cost: 5.84s
Train Epoch: 1431 [81920/90000 (91%)]	Loss: 1.3699	Cost: 6.11s
Train Epoch: 1431 	Average Loss: 2.1623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3427

Learning rate: 0.00019989896406346258
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1432 [0/90000 (0%)]	Loss: 14.7158	Cost: 22.69s
Train Epoch: 1432 [20480/90000 (23%)]	Loss: 1.4613	Cost: 5.98s
Train Epoch: 1432 [40960/90000 (45%)]	Loss: 1.5209	Cost: 6.50s
Train Epoch: 1432 [61440/90000 (68%)]	Loss: 1.2996	Cost: 6.07s
Train Epoch: 1432 [81920/90000 (91%)]	Loss: 1.4459	Cost: 6.53s
Train Epoch: 1432 	Average Loss: 2.3639
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1849

Learning rate: 0.00019989882282769438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1433 [0/90000 (0%)]	Loss: 14.5650	Cost: 25.48s
Train Epoch: 1433 [20480/90000 (23%)]	Loss: 1.3014	Cost: 6.17s
Train Epoch: 1433 [40960/90000 (45%)]	Loss: 1.3868	Cost: 6.69s
Train Epoch: 1433 [61440/90000 (68%)]	Loss: 1.6327	Cost: 6.10s
Train Epoch: 1433 [81920/90000 (91%)]	Loss: 1.7224	Cost: 6.42s
Train Epoch: 1433 	Average Loss: 2.4643
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2097

Learning rate: 0.00019989868149333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1434 [0/90000 (0%)]	Loss: 14.7623	Cost: 30.45s
Train Epoch: 1434 [20480/90000 (23%)]	Loss: 1.4907	Cost: 6.14s
Train Epoch: 1434 [40960/90000 (45%)]	Loss: 1.4847	Cost: 7.80s
Train Epoch: 1434 [61440/90000 (68%)]	Loss: 1.3623	Cost: 6.00s
Train Epoch: 1434 [81920/90000 (91%)]	Loss: 1.7481	Cost: 5.99s
Train Epoch: 1434 	Average Loss: 2.5004
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2992

Learning rate: 0.00019989854006036958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1435 [0/90000 (0%)]	Loss: 14.9339	Cost: 26.58s
Train Epoch: 1435 [20480/90000 (23%)]	Loss: 1.8489	Cost: 6.16s
Train Epoch: 1435 [40960/90000 (45%)]	Loss: 1.5128	Cost: 8.33s
Train Epoch: 1435 [61440/90000 (68%)]	Loss: 1.4963	Cost: 5.89s
Train Epoch: 1435 [81920/90000 (91%)]	Loss: 1.5235	Cost: 8.38s
Train Epoch: 1435 	Average Loss: 2.5527
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2528

Learning rate: 0.00019989839852881325
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1436 [0/90000 (0%)]	Loss: 14.3857	Cost: 23.74s
Train Epoch: 1436 [20480/90000 (23%)]	Loss: 1.4414	Cost: 6.54s
Train Epoch: 1436 [40960/90000 (45%)]	Loss: 1.2453	Cost: 6.07s
Train Epoch: 1436 [61440/90000 (68%)]	Loss: 0.9047	Cost: 6.02s
Train Epoch: 1436 [81920/90000 (91%)]	Loss: 1.3599	Cost: 7.69s
Train Epoch: 1436 	Average Loss: 2.2682
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2555

Learning rate: 0.00019989825689866115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1437 [0/90000 (0%)]	Loss: 14.4825	Cost: 23.23s
Train Epoch: 1437 [20480/90000 (23%)]	Loss: 1.6194	Cost: 6.01s
Train Epoch: 1437 [40960/90000 (45%)]	Loss: 1.6364	Cost: 6.72s
Train Epoch: 1437 [61440/90000 (68%)]	Loss: 1.3860	Cost: 5.86s
Train Epoch: 1437 [81920/90000 (91%)]	Loss: 1.5263	Cost: 5.73s
Train Epoch: 1437 	Average Loss: 2.3764
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3553

Learning rate: 0.00019989811516991338
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1438 [0/90000 (0%)]	Loss: 14.5702	Cost: 23.64s
Train Epoch: 1438 [20480/90000 (23%)]	Loss: 1.3955	Cost: 6.08s
Train Epoch: 1438 [40960/90000 (45%)]	Loss: 1.3825	Cost: 6.57s
Train Epoch: 1438 [61440/90000 (68%)]	Loss: 1.3105	Cost: 5.98s
Train Epoch: 1438 [81920/90000 (91%)]	Loss: 1.2336	Cost: 6.51s
Train Epoch: 1438 	Average Loss: 2.2202
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2826

Learning rate: 0.00019989797334257016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1439 [0/90000 (0%)]	Loss: 14.6653	Cost: 29.33s
Train Epoch: 1439 [20480/90000 (23%)]	Loss: 1.4341	Cost: 5.97s
Train Epoch: 1439 [40960/90000 (45%)]	Loss: 1.2947	Cost: 6.88s
Train Epoch: 1439 [61440/90000 (68%)]	Loss: 1.1645	Cost: 6.21s
Train Epoch: 1439 [81920/90000 (91%)]	Loss: 1.4801	Cost: 5.73s
Train Epoch: 1439 	Average Loss: 2.2518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2712

Learning rate: 0.00019989783141663155
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1440 [0/90000 (0%)]	Loss: 14.7419	Cost: 24.53s
Train Epoch: 1440 [20480/90000 (23%)]	Loss: 1.6891	Cost: 6.04s
Train Epoch: 1440 [40960/90000 (45%)]	Loss: 1.6405	Cost: 8.07s
Train Epoch: 1440 [61440/90000 (68%)]	Loss: 1.5414	Cost: 6.05s
Train Epoch: 1440 [81920/90000 (91%)]	Loss: 1.5058	Cost: 8.74s
Train Epoch: 1440 	Average Loss: 2.3898
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2715

Learning rate: 0.00019989768939209776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1441 [0/90000 (0%)]	Loss: 14.5272	Cost: 23.12s
Train Epoch: 1441 [20480/90000 (23%)]	Loss: 1.2725	Cost: 6.04s
Train Epoch: 1441 [40960/90000 (45%)]	Loss: 1.2674	Cost: 6.54s
Train Epoch: 1441 [61440/90000 (68%)]	Loss: 1.0261	Cost: 6.21s
Train Epoch: 1441 [81920/90000 (91%)]	Loss: 1.1807	Cost: 8.25s
Train Epoch: 1441 	Average Loss: 2.1683
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3180

Learning rate: 0.00019989754726896893
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1442 [0/90000 (0%)]	Loss: 14.5864	Cost: 24.64s
Train Epoch: 1442 [20480/90000 (23%)]	Loss: 1.1868	Cost: 6.10s
Train Epoch: 1442 [40960/90000 (45%)]	Loss: 1.2374	Cost: 7.62s
Train Epoch: 1442 [61440/90000 (68%)]	Loss: 1.0924	Cost: 5.89s
Train Epoch: 1442 [81920/90000 (91%)]	Loss: 1.2475	Cost: 5.90s
Train Epoch: 1442 	Average Loss: 2.1644
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4326

Learning rate: 0.00019989740504724516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1443 [0/90000 (0%)]	Loss: 14.5545	Cost: 23.43s
Train Epoch: 1443 [20480/90000 (23%)]	Loss: 1.2937	Cost: 6.20s
Train Epoch: 1443 [40960/90000 (45%)]	Loss: 1.3558	Cost: 7.20s
Train Epoch: 1443 [61440/90000 (68%)]	Loss: 0.9958	Cost: 6.07s
Train Epoch: 1443 [81920/90000 (91%)]	Loss: 1.2783	Cost: 6.53s
Train Epoch: 1443 	Average Loss: 2.2246
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2717

Learning rate: 0.0001998972627269266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1444 [0/90000 (0%)]	Loss: 14.7510	Cost: 26.21s
Train Epoch: 1444 [20480/90000 (23%)]	Loss: 1.1538	Cost: 6.06s
Train Epoch: 1444 [40960/90000 (45%)]	Loss: 1.1838	Cost: 7.40s
Train Epoch: 1444 [61440/90000 (68%)]	Loss: 1.0401	Cost: 5.84s
Train Epoch: 1444 [81920/90000 (91%)]	Loss: 0.9405	Cost: 6.00s
Train Epoch: 1444 	Average Loss: 2.0458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4937

Learning rate: 0.0001998971203080134
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1445 [0/90000 (0%)]	Loss: 14.9266	Cost: 28.93s
Train Epoch: 1445 [20480/90000 (23%)]	Loss: 0.9785	Cost: 6.10s
Train Epoch: 1445 [40960/90000 (45%)]	Loss: 1.0403	Cost: 6.93s
Train Epoch: 1445 [61440/90000 (68%)]	Loss: 0.9963	Cost: 6.07s
Train Epoch: 1445 [81920/90000 (91%)]	Loss: 0.9817	Cost: 5.86s
Train Epoch: 1445 	Average Loss: 2.0213
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3679

Learning rate: 0.00019989697779050568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1446 [0/90000 (0%)]	Loss: 14.6935	Cost: 25.30s
Train Epoch: 1446 [20480/90000 (23%)]	Loss: 0.7540	Cost: 6.05s
Train Epoch: 1446 [40960/90000 (45%)]	Loss: 1.1374	Cost: 7.88s
Train Epoch: 1446 [61440/90000 (68%)]	Loss: 1.2453	Cost: 5.94s
Train Epoch: 1446 [81920/90000 (91%)]	Loss: 1.5720	Cost: 8.30s
Train Epoch: 1446 	Average Loss: 2.1259
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3061

Learning rate: 0.0001998968351744036
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1447 [0/90000 (0%)]	Loss: 14.7476	Cost: 23.82s
Train Epoch: 1447 [20480/90000 (23%)]	Loss: 1.3021	Cost: 6.22s
Train Epoch: 1447 [40960/90000 (45%)]	Loss: 1.1742	Cost: 6.18s
Train Epoch: 1447 [61440/90000 (68%)]	Loss: 1.1444	Cost: 6.30s
Train Epoch: 1447 [81920/90000 (91%)]	Loss: 1.1752	Cost: 7.92s
Train Epoch: 1447 	Average Loss: 2.1630
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3954

Learning rate: 0.00019989669245970728
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1448 [0/90000 (0%)]	Loss: 14.6817	Cost: 23.67s
Train Epoch: 1448 [20480/90000 (23%)]	Loss: 1.2634	Cost: 6.32s
Train Epoch: 1448 [40960/90000 (45%)]	Loss: 1.2122	Cost: 6.25s
Train Epoch: 1448 [61440/90000 (68%)]	Loss: 1.2097	Cost: 6.09s
Train Epoch: 1448 [81920/90000 (91%)]	Loss: 1.2094	Cost: 6.22s
Train Epoch: 1448 	Average Loss: 2.1925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4091

Learning rate: 0.00019989654964641687
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1449 [0/90000 (0%)]	Loss: 14.6616	Cost: 24.21s
Train Epoch: 1449 [20480/90000 (23%)]	Loss: 1.1570	Cost: 6.18s
Train Epoch: 1449 [40960/90000 (45%)]	Loss: 1.0987	Cost: 6.20s
Train Epoch: 1449 [61440/90000 (68%)]	Loss: 1.2061	Cost: 6.11s
Train Epoch: 1449 [81920/90000 (91%)]	Loss: 0.9923	Cost: 5.92s
Train Epoch: 1449 	Average Loss: 2.0590
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3991

Learning rate: 0.00019989640673453253
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1450 [0/90000 (0%)]	Loss: 14.9101	Cost: 27.50s
Train Epoch: 1450 [20480/90000 (23%)]	Loss: 1.0985	Cost: 6.02s
Train Epoch: 1450 [40960/90000 (45%)]	Loss: 1.2154	Cost: 6.63s
Train Epoch: 1450 [61440/90000 (68%)]	Loss: 0.7822	Cost: 6.37s
Train Epoch: 1450 [81920/90000 (91%)]	Loss: 0.9862	Cost: 5.79s
Train Epoch: 1450 	Average Loss: 2.0915
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4332

Learning rate: 0.0001998962637240544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1451 [0/90000 (0%)]	Loss: 14.8705	Cost: 24.09s
Train Epoch: 1451 [20480/90000 (23%)]	Loss: 0.9001	Cost: 5.98s
Train Epoch: 1451 [40960/90000 (45%)]	Loss: 1.1200	Cost: 7.82s
Train Epoch: 1451 [61440/90000 (68%)]	Loss: 0.9986	Cost: 5.88s
Train Epoch: 1451 [81920/90000 (91%)]	Loss: 0.9073	Cost: 7.78s
Train Epoch: 1451 	Average Loss: 1.9789
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4445

Learning rate: 0.0001998961206149826
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1452 [0/90000 (0%)]	Loss: 14.8762	Cost: 23.52s
Train Epoch: 1452 [20480/90000 (23%)]	Loss: 1.0548	Cost: 6.08s
Train Epoch: 1452 [40960/90000 (45%)]	Loss: 1.2935	Cost: 6.98s
Train Epoch: 1452 [61440/90000 (68%)]	Loss: 1.0644	Cost: 5.81s
Train Epoch: 1452 [81920/90000 (91%)]	Loss: 1.0706	Cost: 6.07s
Train Epoch: 1452 	Average Loss: 2.1079
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4719

Learning rate: 0.0001998959774073173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1453 [0/90000 (0%)]	Loss: 14.7568	Cost: 22.96s
Train Epoch: 1453 [20480/90000 (23%)]	Loss: 0.9931	Cost: 6.00s
Train Epoch: 1453 [40960/90000 (45%)]	Loss: 1.0209	Cost: 7.76s
Train Epoch: 1453 [61440/90000 (68%)]	Loss: 1.1537	Cost: 5.78s
Train Epoch: 1453 [81920/90000 (91%)]	Loss: 0.9206	Cost: 6.55s
Train Epoch: 1453 	Average Loss: 1.9793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4658

Learning rate: 0.0001998958341010586
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1454 [0/90000 (0%)]	Loss: 14.6958	Cost: 23.79s
Train Epoch: 1454 [20480/90000 (23%)]	Loss: 0.9134	Cost: 6.11s
Train Epoch: 1454 [40960/90000 (45%)]	Loss: 0.9109	Cost: 6.66s
Train Epoch: 1454 [61440/90000 (68%)]	Loss: 0.9417	Cost: 6.67s
Train Epoch: 1454 [81920/90000 (91%)]	Loss: 1.1050	Cost: 6.22s
Train Epoch: 1454 	Average Loss: 1.9969
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4643

Learning rate: 0.00019989569069620667
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1455 [0/90000 (0%)]	Loss: 14.6870	Cost: 29.23s
Train Epoch: 1455 [20480/90000 (23%)]	Loss: 0.9027	Cost: 6.17s
Train Epoch: 1455 [40960/90000 (45%)]	Loss: 0.8800	Cost: 7.65s
Train Epoch: 1455 [61440/90000 (68%)]	Loss: 1.0853	Cost: 5.81s
Train Epoch: 1455 [81920/90000 (91%)]	Loss: 1.1338	Cost: 6.35s
Train Epoch: 1455 	Average Loss: 2.0329
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4731

Learning rate: 0.00019989554719276168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1456 [0/90000 (0%)]	Loss: 14.7822	Cost: 26.67s
Train Epoch: 1456 [20480/90000 (23%)]	Loss: 1.3212	Cost: 6.01s
Train Epoch: 1456 [40960/90000 (45%)]	Loss: 1.2841	Cost: 8.79s
Train Epoch: 1456 [61440/90000 (68%)]	Loss: 1.2714	Cost: 5.92s
Train Epoch: 1456 [81920/90000 (91%)]	Loss: 1.2572	Cost: 8.90s
Train Epoch: 1456 	Average Loss: 2.1857
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3882

Learning rate: 0.0001998954035907237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1457 [0/90000 (0%)]	Loss: 14.5494	Cost: 22.31s
Train Epoch: 1457 [20480/90000 (23%)]	Loss: 1.4088	Cost: 5.98s
Train Epoch: 1457 [40960/90000 (45%)]	Loss: 1.1743	Cost: 6.91s
Train Epoch: 1457 [61440/90000 (68%)]	Loss: 1.3226	Cost: 5.99s
Train Epoch: 1457 [81920/90000 (91%)]	Loss: 1.2708	Cost: 8.64s
Train Epoch: 1457 	Average Loss: 2.1748
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3590

Learning rate: 0.00019989525989009294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1458 [0/90000 (0%)]	Loss: 14.5245	Cost: 23.89s
Train Epoch: 1458 [20480/90000 (23%)]	Loss: 1.2939	Cost: 5.88s
Train Epoch: 1458 [40960/90000 (45%)]	Loss: 1.2801	Cost: 6.88s
Train Epoch: 1458 [61440/90000 (68%)]	Loss: 1.0552	Cost: 6.16s
Train Epoch: 1458 [81920/90000 (91%)]	Loss: 1.2869	Cost: 5.74s
Train Epoch: 1458 	Average Loss: 2.2153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4607

Learning rate: 0.00019989511609086946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1459 [0/90000 (0%)]	Loss: 14.7437	Cost: 22.19s
Train Epoch: 1459 [20480/90000 (23%)]	Loss: 1.1442	Cost: 6.19s
Train Epoch: 1459 [40960/90000 (45%)]	Loss: 1.1633	Cost: 7.52s
Train Epoch: 1459 [61440/90000 (68%)]	Loss: 1.1125	Cost: 5.96s
Train Epoch: 1459 [81920/90000 (91%)]	Loss: 1.1668	Cost: 6.02s
Train Epoch: 1459 	Average Loss: 2.1236
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4794

Learning rate: 0.00019989497219305346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1460 [0/90000 (0%)]	Loss: 15.1296	Cost: 26.29s
Train Epoch: 1460 [20480/90000 (23%)]	Loss: 1.3425	Cost: 6.21s
Train Epoch: 1460 [40960/90000 (45%)]	Loss: 1.2211	Cost: 6.81s
Train Epoch: 1460 [61440/90000 (68%)]	Loss: 1.2684	Cost: 5.97s
Train Epoch: 1460 [81920/90000 (91%)]	Loss: 1.2935	Cost: 5.78s
Train Epoch: 1460 	Average Loss: 2.1794
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4140

Learning rate: 0.0001998948281966451
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1461 [0/90000 (0%)]	Loss: 14.8308	Cost: 27.43s
Train Epoch: 1461 [20480/90000 (23%)]	Loss: 1.1475	Cost: 6.02s
Train Epoch: 1461 [40960/90000 (45%)]	Loss: 1.0451	Cost: 6.42s
Train Epoch: 1461 [61440/90000 (68%)]	Loss: 1.2773	Cost: 6.07s
Train Epoch: 1461 [81920/90000 (91%)]	Loss: 1.2430	Cost: 5.59s
Train Epoch: 1461 	Average Loss: 2.1319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4214

Learning rate: 0.0001998946841016445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1462 [0/90000 (0%)]	Loss: 14.8382	Cost: 24.63s
Train Epoch: 1462 [20480/90000 (23%)]	Loss: 1.2207	Cost: 6.01s
Train Epoch: 1462 [40960/90000 (45%)]	Loss: 1.4399	Cost: 8.09s
Train Epoch: 1462 [61440/90000 (68%)]	Loss: 2.1028	Cost: 5.93s
Train Epoch: 1462 [81920/90000 (91%)]	Loss: 2.5558	Cost: 8.37s
Train Epoch: 1462 	Average Loss: 2.6074
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3140

Learning rate: 0.0001998945399080518
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1463 [0/90000 (0%)]	Loss: 14.5914	Cost: 23.88s
Train Epoch: 1463 [20480/90000 (23%)]	Loss: 2.3782	Cost: 6.13s
Train Epoch: 1463 [40960/90000 (45%)]	Loss: 2.2392	Cost: 6.73s
Train Epoch: 1463 [61440/90000 (68%)]	Loss: 1.9518	Cost: 6.47s
Train Epoch: 1463 [81920/90000 (91%)]	Loss: 1.7450	Cost: 6.10s
Train Epoch: 1463 	Average Loss: 2.9210
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2835

Learning rate: 0.0001998943956158671
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1464 [0/90000 (0%)]	Loss: 14.6675	Cost: 24.13s
Train Epoch: 1464 [20480/90000 (23%)]	Loss: 1.5766	Cost: 6.38s
Train Epoch: 1464 [40960/90000 (45%)]	Loss: 1.5373	Cost: 7.29s
Train Epoch: 1464 [61440/90000 (68%)]	Loss: 1.4993	Cost: 5.92s
Train Epoch: 1464 [81920/90000 (91%)]	Loss: 1.3214	Cost: 6.31s
Train Epoch: 1464 	Average Loss: 2.3686
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3194

Learning rate: 0.0001998942512250906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1465 [0/90000 (0%)]	Loss: 14.5286	Cost: 23.25s
Train Epoch: 1465 [20480/90000 (23%)]	Loss: 1.2843	Cost: 6.49s
Train Epoch: 1465 [40960/90000 (45%)]	Loss: 1.0130	Cost: 6.27s
Train Epoch: 1465 [61440/90000 (68%)]	Loss: 1.1983	Cost: 6.01s
Train Epoch: 1465 [81920/90000 (91%)]	Loss: 1.3129	Cost: 5.54s
Train Epoch: 1465 	Average Loss: 2.1359
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3420

Learning rate: 0.00019989410673572247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1466 [0/90000 (0%)]	Loss: 14.6569	Cost: 26.81s
Train Epoch: 1466 [20480/90000 (23%)]	Loss: 1.1947	Cost: 6.14s
Train Epoch: 1466 [40960/90000 (45%)]	Loss: 1.5098	Cost: 7.14s
Train Epoch: 1466 [61440/90000 (68%)]	Loss: 1.1831	Cost: 6.01s
Train Epoch: 1466 [81920/90000 (91%)]	Loss: 1.4610	Cost: 5.93s
Train Epoch: 1466 	Average Loss: 2.2471
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3190

Learning rate: 0.00019989396214776275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1467 [0/90000 (0%)]	Loss: 14.9182	Cost: 27.33s
Train Epoch: 1467 [20480/90000 (23%)]	Loss: 1.2920	Cost: 6.09s
Train Epoch: 1467 [40960/90000 (45%)]	Loss: 1.1089	Cost: 8.41s
Train Epoch: 1467 [61440/90000 (68%)]	Loss: 1.1769	Cost: 6.03s
Train Epoch: 1467 [81920/90000 (91%)]	Loss: 1.0996	Cost: 9.19s
Train Epoch: 1467 	Average Loss: 2.1285
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3993

Learning rate: 0.00019989381746121168
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1468 [0/90000 (0%)]	Loss: 14.7089	Cost: 24.46s
Train Epoch: 1468 [20480/90000 (23%)]	Loss: 1.1823	Cost: 6.08s
Train Epoch: 1468 [40960/90000 (45%)]	Loss: 1.0373	Cost: 7.45s
Train Epoch: 1468 [61440/90000 (68%)]	Loss: 1.0749	Cost: 5.94s
Train Epoch: 1468 [81920/90000 (91%)]	Loss: 1.1216	Cost: 7.98s
Train Epoch: 1468 	Average Loss: 2.0280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4244

Learning rate: 0.00019989367267606934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1469 [0/90000 (0%)]	Loss: 14.7810	Cost: 23.95s
Train Epoch: 1469 [20480/90000 (23%)]	Loss: 0.8801	Cost: 6.00s
Train Epoch: 1469 [40960/90000 (45%)]	Loss: 0.9961	Cost: 6.36s
Train Epoch: 1469 [61440/90000 (68%)]	Loss: 0.8372	Cost: 6.13s
Train Epoch: 1469 [81920/90000 (91%)]	Loss: 1.0157	Cost: 7.26s
Train Epoch: 1469 	Average Loss: 1.8463
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5232

Learning rate: 0.00019989352779233594
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1470 [0/90000 (0%)]	Loss: 14.6092	Cost: 24.97s
Train Epoch: 1470 [20480/90000 (23%)]	Loss: 0.8140	Cost: 6.14s
Train Epoch: 1470 [40960/90000 (45%)]	Loss: 0.7476	Cost: 6.44s
Train Epoch: 1470 [61440/90000 (68%)]	Loss: 0.6692	Cost: 5.92s
Train Epoch: 1470 [81920/90000 (91%)]	Loss: 0.8789	Cost: 5.96s
Train Epoch: 1470 	Average Loss: 1.7711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5720

Learning rate: 0.00019989338281001153
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1471 [0/90000 (0%)]	Loss: 14.7954	Cost: 23.55s
Train Epoch: 1471 [20480/90000 (23%)]	Loss: 0.9717	Cost: 5.95s
Train Epoch: 1471 [40960/90000 (45%)]	Loss: 1.0085	Cost: 6.70s
Train Epoch: 1471 [61440/90000 (68%)]	Loss: 0.8493	Cost: 5.98s
Train Epoch: 1471 [81920/90000 (91%)]	Loss: 0.8532	Cost: 5.58s
Train Epoch: 1471 	Average Loss: 1.9724
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5238

Learning rate: 0.00019989323772909634
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1472 [0/90000 (0%)]	Loss: 14.6885	Cost: 27.76s
Train Epoch: 1472 [20480/90000 (23%)]	Loss: 0.8413	Cost: 6.10s
Train Epoch: 1472 [40960/90000 (45%)]	Loss: 0.8602	Cost: 6.66s
Train Epoch: 1472 [61440/90000 (68%)]	Loss: 0.8403	Cost: 6.16s
Train Epoch: 1472 [81920/90000 (91%)]	Loss: 0.9139	Cost: 6.05s
Train Epoch: 1472 	Average Loss: 1.8358
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4043

Learning rate: 0.00019989309254959045
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1473 [0/90000 (0%)]	Loss: 14.8328	Cost: 23.83s
Train Epoch: 1473 [20480/90000 (23%)]	Loss: 0.8378	Cost: 6.11s
Train Epoch: 1473 [40960/90000 (45%)]	Loss: 0.7939	Cost: 8.90s
Train Epoch: 1473 [61440/90000 (68%)]	Loss: 0.5960	Cost: 5.91s
Train Epoch: 1473 [81920/90000 (91%)]	Loss: 1.0174	Cost: 7.83s
Train Epoch: 1473 	Average Loss: 1.7655
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4713

Learning rate: 0.000199892947271494
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1474 [0/90000 (0%)]	Loss: 14.8274	Cost: 22.87s
Train Epoch: 1474 [20480/90000 (23%)]	Loss: 0.8365	Cost: 6.17s
Train Epoch: 1474 [40960/90000 (45%)]	Loss: 1.1724	Cost: 6.39s
Train Epoch: 1474 [61440/90000 (68%)]	Loss: 0.9475	Cost: 6.20s
Train Epoch: 1474 [81920/90000 (91%)]	Loss: 0.8341	Cost: 8.69s
Train Epoch: 1474 	Average Loss: 1.8865
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5234

Learning rate: 0.00019989280189480722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1475 [0/90000 (0%)]	Loss: 14.8962	Cost: 24.42s
Train Epoch: 1475 [20480/90000 (23%)]	Loss: 0.9552	Cost: 6.02s
Train Epoch: 1475 [40960/90000 (45%)]	Loss: 0.7169	Cost: 7.29s
Train Epoch: 1475 [61440/90000 (68%)]	Loss: 0.5859	Cost: 5.96s
Train Epoch: 1475 [81920/90000 (91%)]	Loss: 0.9952	Cost: 5.99s
Train Epoch: 1475 	Average Loss: 1.7911
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6040

Learning rate: 0.00019989265641953016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1476 [0/90000 (0%)]	Loss: 14.6662	Cost: 22.45s
Train Epoch: 1476 [20480/90000 (23%)]	Loss: 1.1509	Cost: 5.99s
Train Epoch: 1476 [40960/90000 (45%)]	Loss: 1.0587	Cost: 7.04s
Train Epoch: 1476 [61440/90000 (68%)]	Loss: 1.0665	Cost: 6.09s
Train Epoch: 1476 [81920/90000 (91%)]	Loss: 1.2170	Cost: 6.03s
Train Epoch: 1476 	Average Loss: 2.0635
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5134

Learning rate: 0.000199892510845663
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1477 [0/90000 (0%)]	Loss: 14.7387	Cost: 27.62s
Train Epoch: 1477 [20480/90000 (23%)]	Loss: 1.3680	Cost: 6.16s
Train Epoch: 1477 [40960/90000 (45%)]	Loss: 1.2345	Cost: 7.24s
Train Epoch: 1477 [61440/90000 (68%)]	Loss: 0.8579	Cost: 6.03s
Train Epoch: 1477 [81920/90000 (91%)]	Loss: 1.0249	Cost: 5.93s
Train Epoch: 1477 	Average Loss: 2.0750
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4034

Learning rate: 0.00019989236517320593
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1478 [0/90000 (0%)]	Loss: 15.0416	Cost: 28.54s
Train Epoch: 1478 [20480/90000 (23%)]	Loss: 0.8999	Cost: 5.98s
Train Epoch: 1478 [40960/90000 (45%)]	Loss: 1.0814	Cost: 8.79s
Train Epoch: 1478 [61440/90000 (68%)]	Loss: 0.7463	Cost: 5.97s
Train Epoch: 1478 [81920/90000 (91%)]	Loss: 1.0240	Cost: 7.66s
Train Epoch: 1478 	Average Loss: 1.9409
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7099

Learning rate: 0.000199892219402159
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1479 [0/90000 (0%)]	Loss: 15.0490	Cost: 24.62s
Train Epoch: 1479 [20480/90000 (23%)]	Loss: 1.9430	Cost: 6.02s
Train Epoch: 1479 [40960/90000 (45%)]	Loss: 1.7788	Cost: 8.14s
Train Epoch: 1479 [61440/90000 (68%)]	Loss: 1.6423	Cost: 5.91s
Train Epoch: 1479 [81920/90000 (91%)]	Loss: 1.5814	Cost: 8.39s
Train Epoch: 1479 	Average Loss: 2.6205
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3939

Learning rate: 0.0001998920735325224
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1480 [0/90000 (0%)]	Loss: 14.9760	Cost: 23.75s
Train Epoch: 1480 [20480/90000 (23%)]	Loss: 1.4964	Cost: 6.02s
Train Epoch: 1480 [40960/90000 (45%)]	Loss: 1.3413	Cost: 6.49s
Train Epoch: 1480 [61440/90000 (68%)]	Loss: 1.1102	Cost: 6.16s
Train Epoch: 1480 [81920/90000 (91%)]	Loss: 1.1545	Cost: 7.29s
Train Epoch: 1480 	Average Loss: 2.2487
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4319

Learning rate: 0.0001998919275642963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1481 [0/90000 (0%)]	Loss: 14.8904	Cost: 23.44s
Train Epoch: 1481 [20480/90000 (23%)]	Loss: 1.0852	Cost: 6.12s
Train Epoch: 1481 [40960/90000 (45%)]	Loss: 0.9496	Cost: 7.22s
Train Epoch: 1481 [61440/90000 (68%)]	Loss: 1.0946	Cost: 6.12s
Train Epoch: 1481 [81920/90000 (91%)]	Loss: 1.1836	Cost: 6.46s
Train Epoch: 1481 	Average Loss: 2.0612
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4914

Learning rate: 0.0001998917814974808
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1482 [0/90000 (0%)]	Loss: 14.8375	Cost: 24.30s
Train Epoch: 1482 [20480/90000 (23%)]	Loss: 0.9277	Cost: 6.22s
Train Epoch: 1482 [40960/90000 (45%)]	Loss: 0.9251	Cost: 6.31s
Train Epoch: 1482 [61440/90000 (68%)]	Loss: 0.8220	Cost: 6.21s
Train Epoch: 1482 [81920/90000 (91%)]	Loss: 0.9405	Cost: 5.77s
Train Epoch: 1482 	Average Loss: 1.8949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5237

Learning rate: 0.00019989163533207604
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1483 [0/90000 (0%)]	Loss: 14.9467	Cost: 26.22s
Train Epoch: 1483 [20480/90000 (23%)]	Loss: 0.9343	Cost: 6.08s
Train Epoch: 1483 [40960/90000 (45%)]	Loss: 0.8816	Cost: 6.94s
Train Epoch: 1483 [61440/90000 (68%)]	Loss: 1.2285	Cost: 6.38s
Train Epoch: 1483 [81920/90000 (91%)]	Loss: 1.2591	Cost: 5.97s
Train Epoch: 1483 	Average Loss: 1.9705
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4710

Learning rate: 0.00019989148906808223
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1484 [0/90000 (0%)]	Loss: 14.7845	Cost: 28.62s
Train Epoch: 1484 [20480/90000 (23%)]	Loss: 1.1896	Cost: 6.21s
Train Epoch: 1484 [40960/90000 (45%)]	Loss: 1.0243	Cost: 9.21s
Train Epoch: 1484 [61440/90000 (68%)]	Loss: 0.8884	Cost: 6.02s
Train Epoch: 1484 [81920/90000 (91%)]	Loss: 0.9754	Cost: 6.43s
Train Epoch: 1484 	Average Loss: 2.0412
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5661

Learning rate: 0.00019989134270549948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1485 [0/90000 (0%)]	Loss: 14.9445	Cost: 24.67s
Train Epoch: 1485 [20480/90000 (23%)]	Loss: 1.0602	Cost: 6.05s
Train Epoch: 1485 [40960/90000 (45%)]	Loss: 1.0667	Cost: 7.65s
Train Epoch: 1485 [61440/90000 (68%)]	Loss: 0.7236	Cost: 6.02s
Train Epoch: 1485 [81920/90000 (91%)]	Loss: 0.9663	Cost: 8.02s
Train Epoch: 1485 	Average Loss: 1.9051
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5336

Learning rate: 0.0001998911962443279
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1486 [0/90000 (0%)]	Loss: 14.9682	Cost: 23.45s
Train Epoch: 1486 [20480/90000 (23%)]	Loss: 0.9407	Cost: 6.04s
Train Epoch: 1486 [40960/90000 (45%)]	Loss: 0.9307	Cost: 6.53s
Train Epoch: 1486 [61440/90000 (68%)]	Loss: 0.7752	Cost: 5.95s
Train Epoch: 1486 [81920/90000 (91%)]	Loss: 0.8667	Cost: 6.22s
Train Epoch: 1486 	Average Loss: 1.8490
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5774

Learning rate: 0.00019989104968456769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1487 [0/90000 (0%)]	Loss: 15.1712	Cost: 23.24s
Train Epoch: 1487 [20480/90000 (23%)]	Loss: 0.8764	Cost: 6.23s
Train Epoch: 1487 [40960/90000 (45%)]	Loss: 0.7623	Cost: 7.02s
Train Epoch: 1487 [61440/90000 (68%)]	Loss: 0.5641	Cost: 6.16s
Train Epoch: 1487 [81920/90000 (91%)]	Loss: 0.8083	Cost: 6.38s
Train Epoch: 1487 	Average Loss: 1.7510
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5119

Learning rate: 0.00019989090302621897
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1488 [0/90000 (0%)]	Loss: 14.8082	Cost: 24.86s
Train Epoch: 1488 [20480/90000 (23%)]	Loss: 0.6997	Cost: 6.09s
Train Epoch: 1488 [40960/90000 (45%)]	Loss: 0.5354	Cost: 7.18s
Train Epoch: 1488 [61440/90000 (68%)]	Loss: 0.5063	Cost: 6.43s
Train Epoch: 1488 [81920/90000 (91%)]	Loss: 0.8030	Cost: 5.77s
Train Epoch: 1488 	Average Loss: 1.7071
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5130

Learning rate: 0.00019989075626928183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1489 [0/90000 (0%)]	Loss: 14.7796	Cost: 27.75s
Train Epoch: 1489 [20480/90000 (23%)]	Loss: 1.0916	Cost: 6.04s
Train Epoch: 1489 [40960/90000 (45%)]	Loss: 0.8612	Cost: 7.01s
Train Epoch: 1489 [61440/90000 (68%)]	Loss: 0.8043	Cost: 6.03s
Train Epoch: 1489 [81920/90000 (91%)]	Loss: 0.6281	Cost: 6.30s
Train Epoch: 1489 	Average Loss: 1.8815
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5288

Learning rate: 0.00019989060941375648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1490 [0/90000 (0%)]	Loss: 14.5999	Cost: 26.21s
Train Epoch: 1490 [20480/90000 (23%)]	Loss: 0.9951	Cost: 5.99s
Train Epoch: 1490 [40960/90000 (45%)]	Loss: 0.7166	Cost: 7.04s
Train Epoch: 1490 [61440/90000 (68%)]	Loss: 0.5591	Cost: 5.89s
Train Epoch: 1490 [81920/90000 (91%)]	Loss: 0.6514	Cost: 7.10s
Train Epoch: 1490 	Average Loss: 1.7522
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6575

Learning rate: 0.00019989046245964308
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1491 [0/90000 (0%)]	Loss: 14.9489	Cost: 22.58s
Train Epoch: 1491 [20480/90000 (23%)]	Loss: 0.7456	Cost: 6.01s
Train Epoch: 1491 [40960/90000 (45%)]	Loss: 0.6574	Cost: 6.40s
Train Epoch: 1491 [61440/90000 (68%)]	Loss: 0.7572	Cost: 6.11s
Train Epoch: 1491 [81920/90000 (91%)]	Loss: 0.9513	Cost: 8.12s
Train Epoch: 1491 	Average Loss: 1.7610
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5848

Learning rate: 0.00019989031540694173
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1492 [0/90000 (0%)]	Loss: 14.7159	Cost: 23.47s
Train Epoch: 1492 [20480/90000 (23%)]	Loss: 0.9009	Cost: 6.19s
Train Epoch: 1492 [40960/90000 (45%)]	Loss: 0.8197	Cost: 7.29s
Train Epoch: 1492 [61440/90000 (68%)]	Loss: 0.8698	Cost: 5.72s
Train Epoch: 1492 [81920/90000 (91%)]	Loss: 0.8006	Cost: 5.61s
Train Epoch: 1492 	Average Loss: 1.8230
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5295

Learning rate: 0.0001998901682556526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1493 [0/90000 (0%)]	Loss: 15.0085	Cost: 22.79s
Train Epoch: 1493 [20480/90000 (23%)]	Loss: 1.0771	Cost: 6.10s
Train Epoch: 1493 [40960/90000 (45%)]	Loss: 0.6731	Cost: 7.54s
Train Epoch: 1493 [61440/90000 (68%)]	Loss: 0.7501	Cost: 6.12s
Train Epoch: 1493 [81920/90000 (91%)]	Loss: 0.6838	Cost: 6.00s
Train Epoch: 1493 	Average Loss: 1.7503
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5785

Learning rate: 0.00019989002100577577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1494 [0/90000 (0%)]	Loss: 14.5959	Cost: 26.27s
Train Epoch: 1494 [20480/90000 (23%)]	Loss: 0.7144	Cost: 6.12s
Train Epoch: 1494 [40960/90000 (45%)]	Loss: 0.6116	Cost: 7.33s
Train Epoch: 1494 [61440/90000 (68%)]	Loss: 0.5952	Cost: 5.79s
Train Epoch: 1494 [81920/90000 (91%)]	Loss: 0.7743	Cost: 5.92s
Train Epoch: 1494 	Average Loss: 1.6141
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6699

Learning rate: 0.0001998898736573115
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1495 [0/90000 (0%)]	Loss: 14.7043	Cost: 26.09s
Train Epoch: 1495 [20480/90000 (23%)]	Loss: 1.1138	Cost: 6.05s
Train Epoch: 1495 [40960/90000 (45%)]	Loss: 0.8954	Cost: 7.39s
Train Epoch: 1495 [61440/90000 (68%)]	Loss: 0.5673	Cost: 5.94s
Train Epoch: 1495 [81920/90000 (91%)]	Loss: 1.1751	Cost: 7.09s
Train Epoch: 1495 	Average Loss: 1.8535
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5762

Learning rate: 0.00019988972621025987
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1496 [0/90000 (0%)]	Loss: 14.6755	Cost: 21.71s
Train Epoch: 1496 [20480/90000 (23%)]	Loss: 0.9517	Cost: 6.05s
Train Epoch: 1496 [40960/90000 (45%)]	Loss: 0.6684	Cost: 6.82s
Train Epoch: 1496 [61440/90000 (68%)]	Loss: 0.8096	Cost: 5.93s
Train Epoch: 1496 [81920/90000 (91%)]	Loss: 0.7492	Cost: 8.96s
Train Epoch: 1496 	Average Loss: 1.8195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6204

Learning rate: 0.00019988957866462102
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1497 [0/90000 (0%)]	Loss: 14.9277	Cost: 25.34s
Train Epoch: 1497 [20480/90000 (23%)]	Loss: 0.8084	Cost: 6.20s
Train Epoch: 1497 [40960/90000 (45%)]	Loss: 0.6693	Cost: 6.79s
Train Epoch: 1497 [61440/90000 (68%)]	Loss: 0.5845	Cost: 5.85s
Train Epoch: 1497 [81920/90000 (91%)]	Loss: 0.6086	Cost: 5.84s
Train Epoch: 1497 	Average Loss: 1.6384
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6083

Learning rate: 0.00019988943102039513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1498 [0/90000 (0%)]	Loss: 14.8316	Cost: 23.18s
Train Epoch: 1498 [20480/90000 (23%)]	Loss: 0.8093	Cost: 6.18s
Train Epoch: 1498 [40960/90000 (45%)]	Loss: 0.5820	Cost: 6.75s
Train Epoch: 1498 [61440/90000 (68%)]	Loss: 0.5517	Cost: 6.24s
Train Epoch: 1498 [81920/90000 (91%)]	Loss: 0.7752	Cost: 5.76s
Train Epoch: 1498 	Average Loss: 1.6255
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7800

Learning rate: 0.0001998892832775823
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1499 [0/90000 (0%)]	Loss: 14.8498	Cost: 25.50s
Train Epoch: 1499 [20480/90000 (23%)]	Loss: 0.9462	Cost: 6.05s
Train Epoch: 1499 [40960/90000 (45%)]	Loss: 0.8198	Cost: 6.84s
Train Epoch: 1499 [61440/90000 (68%)]	Loss: 0.8771	Cost: 6.02s
Train Epoch: 1499 [81920/90000 (91%)]	Loss: 0.8373	Cost: 5.76s
Train Epoch: 1499 	Average Loss: 1.7766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5755

Learning rate: 0.0001998891354361827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1500 [0/90000 (0%)]	Loss: 15.1331	Cost: 29.31s
Train Epoch: 1500 [20480/90000 (23%)]	Loss: 1.0510	Cost: 6.16s
Train Epoch: 1500 [40960/90000 (45%)]	Loss: 0.7107	Cost: 7.77s
Train Epoch: 1500 [61440/90000 (68%)]	Loss: 0.4904	Cost: 6.08s
Train Epoch: 1500 [81920/90000 (91%)]	Loss: 0.7311	Cost: 6.97s
Train Epoch: 1500 	Average Loss: 1.7288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6377

Learning rate: 0.00019988898749619648
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1501 [0/90000 (0%)]	Loss: 14.7678	Cost: 23.40s
Train Epoch: 1501 [20480/90000 (23%)]	Loss: 0.6431	Cost: 6.05s
Train Epoch: 1501 [40960/90000 (45%)]	Loss: 0.5224	Cost: 8.13s
Train Epoch: 1501 [61440/90000 (68%)]	Loss: 0.6123	Cost: 6.00s
Train Epoch: 1501 [81920/90000 (91%)]	Loss: 0.9614	Cost: 8.87s
Train Epoch: 1501 	Average Loss: 1.5866
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6446

Learning rate: 0.00019988883945762376
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1502 [0/90000 (0%)]	Loss: 15.1372	Cost: 23.20s
Train Epoch: 1502 [20480/90000 (23%)]	Loss: 1.0750	Cost: 5.89s
Train Epoch: 1502 [40960/90000 (45%)]	Loss: 0.6707	Cost: 6.75s
Train Epoch: 1502 [61440/90000 (68%)]	Loss: 0.6450	Cost: 6.08s
Train Epoch: 1502 [81920/90000 (91%)]	Loss: 0.9730	Cost: 5.76s
Train Epoch: 1502 	Average Loss: 1.7640
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5497

Learning rate: 0.00019988869132046472
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1503 [0/90000 (0%)]	Loss: 14.9263	Cost: 23.40s
Train Epoch: 1503 [20480/90000 (23%)]	Loss: 1.0452	Cost: 6.15s
Train Epoch: 1503 [40960/90000 (45%)]	Loss: 0.6852	Cost: 6.72s
Train Epoch: 1503 [61440/90000 (68%)]	Loss: 0.5653	Cost: 6.07s
Train Epoch: 1503 [81920/90000 (91%)]	Loss: 0.6256	Cost: 6.71s
Train Epoch: 1503 	Average Loss: 1.7253
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6960

Learning rate: 0.0001998885430847195
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1504 [0/90000 (0%)]	Loss: 15.0652	Cost: 26.42s
Train Epoch: 1504 [20480/90000 (23%)]	Loss: 0.9013	Cost: 5.97s
Train Epoch: 1504 [40960/90000 (45%)]	Loss: 0.6876	Cost: 7.06s
Train Epoch: 1504 [61440/90000 (68%)]	Loss: 0.5584	Cost: 5.91s
Train Epoch: 1504 [81920/90000 (91%)]	Loss: 0.8665	Cost: 6.25s
Train Epoch: 1504 	Average Loss: 1.6454
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6910

Learning rate: 0.00019988839475038826
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1505 [0/90000 (0%)]	Loss: 15.1365	Cost: 28.26s
Train Epoch: 1505 [20480/90000 (23%)]	Loss: 0.8779	Cost: 5.96s
Train Epoch: 1505 [40960/90000 (45%)]	Loss: 0.8131	Cost: 6.84s
Train Epoch: 1505 [61440/90000 (68%)]	Loss: 0.4635	Cost: 5.96s
Train Epoch: 1505 [81920/90000 (91%)]	Loss: 0.7638	Cost: 5.53s
Train Epoch: 1505 	Average Loss: 1.7176
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6550

Learning rate: 0.0001998882463174711
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1506 [0/90000 (0%)]	Loss: 15.0915	Cost: 23.06s
Train Epoch: 1506 [20480/90000 (23%)]	Loss: 0.5439	Cost: 5.99s
Train Epoch: 1506 [40960/90000 (45%)]	Loss: 0.7655	Cost: 7.91s
Train Epoch: 1506 [61440/90000 (68%)]	Loss: 0.5616	Cost: 5.94s
Train Epoch: 1506 [81920/90000 (91%)]	Loss: 0.6764	Cost: 8.37s
Train Epoch: 1506 	Average Loss: 1.6784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6353

Learning rate: 0.00019988809778596821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1507 [0/90000 (0%)]	Loss: 15.0904	Cost: 23.86s
Train Epoch: 1507 [20480/90000 (23%)]	Loss: 0.7678	Cost: 6.15s
Train Epoch: 1507 [40960/90000 (45%)]	Loss: 0.6239	Cost: 6.26s
Train Epoch: 1507 [61440/90000 (68%)]	Loss: 0.3874	Cost: 6.28s
Train Epoch: 1507 [81920/90000 (91%)]	Loss: 0.4512	Cost: 7.14s
Train Epoch: 1507 	Average Loss: 1.5857
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6841

Learning rate: 0.00019988794915587973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1508 [0/90000 (0%)]	Loss: 14.9617	Cost: 24.24s
Train Epoch: 1508 [20480/90000 (23%)]	Loss: 0.4550	Cost: 6.14s
Train Epoch: 1508 [40960/90000 (45%)]	Loss: 0.5399	Cost: 7.73s
Train Epoch: 1508 [61440/90000 (68%)]	Loss: 0.7237	Cost: 6.37s
Train Epoch: 1508 [81920/90000 (91%)]	Loss: 0.7255	Cost: 6.26s
Train Epoch: 1508 	Average Loss: 1.5769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5532

Learning rate: 0.00019988780042720576
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1509 [0/90000 (0%)]	Loss: 14.8806	Cost: 23.50s
Train Epoch: 1509 [20480/90000 (23%)]	Loss: 0.9480	Cost: 6.41s
Train Epoch: 1509 [40960/90000 (45%)]	Loss: 0.9771	Cost: 6.42s
Train Epoch: 1509 [61440/90000 (68%)]	Loss: 0.7005	Cost: 6.23s
Train Epoch: 1509 [81920/90000 (91%)]	Loss: 0.7387	Cost: 6.21s
Train Epoch: 1509 	Average Loss: 1.7805
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6389

Learning rate: 0.0001998876515999465
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1510 [0/90000 (0%)]	Loss: 15.0618	Cost: 25.96s
Train Epoch: 1510 [20480/90000 (23%)]	Loss: 0.8427	Cost: 6.07s
Train Epoch: 1510 [40960/90000 (45%)]	Loss: 1.0038	Cost: 6.52s
Train Epoch: 1510 [61440/90000 (68%)]	Loss: 0.6573	Cost: 6.08s
Train Epoch: 1510 [81920/90000 (91%)]	Loss: 1.0791	Cost: 5.95s
Train Epoch: 1510 	Average Loss: 1.8020
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5414

Learning rate: 0.00019988750267410207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1511 [0/90000 (0%)]	Loss: 15.1621	Cost: 26.67s
Train Epoch: 1511 [20480/90000 (23%)]	Loss: 1.1687	Cost: 6.01s
Train Epoch: 1511 [40960/90000 (45%)]	Loss: 0.8606	Cost: 7.71s
Train Epoch: 1511 [61440/90000 (68%)]	Loss: 0.8726	Cost: 6.00s
Train Epoch: 1511 [81920/90000 (91%)]	Loss: 1.1583	Cost: 6.32s
Train Epoch: 1511 	Average Loss: 1.9773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5904

Learning rate: 0.0001998873536496726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1512 [0/90000 (0%)]	Loss: 14.9164	Cost: 22.76s
Train Epoch: 1512 [20480/90000 (23%)]	Loss: 1.2843	Cost: 5.92s
Train Epoch: 1512 [40960/90000 (45%)]	Loss: 1.0216	Cost: 6.70s
Train Epoch: 1512 [61440/90000 (68%)]	Loss: 0.7071	Cost: 6.22s
Train Epoch: 1512 [81920/90000 (91%)]	Loss: 0.9332	Cost: 8.79s
Train Epoch: 1512 	Average Loss: 1.9647
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6132

Learning rate: 0.00019988720452665832
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1513 [0/90000 (0%)]	Loss: 15.1135	Cost: 23.57s
Train Epoch: 1513 [20480/90000 (23%)]	Loss: 0.8541	Cost: 6.12s
Train Epoch: 1513 [40960/90000 (45%)]	Loss: 0.6199	Cost: 7.42s
Train Epoch: 1513 [61440/90000 (68%)]	Loss: 0.5944	Cost: 5.99s
Train Epoch: 1513 [81920/90000 (91%)]	Loss: 0.7403	Cost: 6.23s
Train Epoch: 1513 	Average Loss: 1.7034
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6368

Learning rate: 0.0001998870553050593
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1514 [0/90000 (0%)]	Loss: 14.8162	Cost: 22.77s
Train Epoch: 1514 [20480/90000 (23%)]	Loss: 1.0562	Cost: 6.07s
Train Epoch: 1514 [40960/90000 (45%)]	Loss: 0.8943	Cost: 6.33s
Train Epoch: 1514 [61440/90000 (68%)]	Loss: 0.9210	Cost: 6.05s
Train Epoch: 1514 [81920/90000 (91%)]	Loss: 0.8298	Cost: 5.75s
Train Epoch: 1514 	Average Loss: 1.8958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6929

Learning rate: 0.0001998869059848757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1515 [0/90000 (0%)]	Loss: 14.8916	Cost: 27.41s
Train Epoch: 1515 [20480/90000 (23%)]	Loss: 0.7571	Cost: 6.16s
Train Epoch: 1515 [40960/90000 (45%)]	Loss: 0.6812	Cost: 6.66s
Train Epoch: 1515 [61440/90000 (68%)]	Loss: 0.8391	Cost: 6.11s
Train Epoch: 1515 [81920/90000 (91%)]	Loss: 0.7126	Cost: 6.16s
Train Epoch: 1515 	Average Loss: 1.6481
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6685

Learning rate: 0.00019988675656610767
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1516 [0/90000 (0%)]	Loss: 14.8267	Cost: 25.77s
Train Epoch: 1516 [20480/90000 (23%)]	Loss: 0.6397	Cost: 6.01s
Train Epoch: 1516 [40960/90000 (45%)]	Loss: 0.6035	Cost: 7.66s
Train Epoch: 1516 [61440/90000 (68%)]	Loss: 0.4752	Cost: 6.04s
Train Epoch: 1516 [81920/90000 (91%)]	Loss: 0.7401	Cost: 7.21s
Train Epoch: 1516 	Average Loss: 1.5646
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7479

Learning rate: 0.00019988660704875537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1517 [0/90000 (0%)]	Loss: 15.0695	Cost: 23.23s
Train Epoch: 1517 [20480/90000 (23%)]	Loss: 0.4657	Cost: 6.09s
Train Epoch: 1517 [40960/90000 (45%)]	Loss: 0.4037	Cost: 6.25s
Train Epoch: 1517 [61440/90000 (68%)]	Loss: 0.5329	Cost: 6.29s
Train Epoch: 1517 [81920/90000 (91%)]	Loss: 0.7206	Cost: 7.64s
Train Epoch: 1517 	Average Loss: 1.4768
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6469

Learning rate: 0.00019988645743281895
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1518 [0/90000 (0%)]	Loss: 15.1729	Cost: 24.06s
Train Epoch: 1518 [20480/90000 (23%)]	Loss: 0.5997	Cost: 6.13s
Train Epoch: 1518 [40960/90000 (45%)]	Loss: 0.4158	Cost: 6.46s
Train Epoch: 1518 [61440/90000 (68%)]	Loss: 0.3810	Cost: 5.94s
Train Epoch: 1518 [81920/90000 (91%)]	Loss: 0.6873	Cost: 5.95s
Train Epoch: 1518 	Average Loss: 1.5800
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8508

Learning rate: 0.00019988630771829852
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1519 [0/90000 (0%)]	Loss: 15.1406	Cost: 22.73s
Train Epoch: 1519 [20480/90000 (23%)]	Loss: 0.5907	Cost: 6.06s
Train Epoch: 1519 [40960/90000 (45%)]	Loss: 0.6865	Cost: 7.09s
Train Epoch: 1519 [61440/90000 (68%)]	Loss: 0.4445	Cost: 6.12s
Train Epoch: 1519 [81920/90000 (91%)]	Loss: 0.5365	Cost: 6.15s
Train Epoch: 1519 	Average Loss: 1.5406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7192

Learning rate: 0.00019988615790519427
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1520 [0/90000 (0%)]	Loss: 14.9578	Cost: 26.90s
Train Epoch: 1520 [20480/90000 (23%)]	Loss: 0.5845	Cost: 6.12s
Train Epoch: 1520 [40960/90000 (45%)]	Loss: 0.2920	Cost: 7.55s
Train Epoch: 1520 [61440/90000 (68%)]	Loss: 0.5124	Cost: 6.47s
Train Epoch: 1520 [81920/90000 (91%)]	Loss: 0.7055	Cost: 6.31s
Train Epoch: 1520 	Average Loss: 1.4953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7829

Learning rate: 0.0001998860079935063
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1521 [0/90000 (0%)]	Loss: 15.0353	Cost: 27.46s
Train Epoch: 1521 [20480/90000 (23%)]	Loss: 0.5341	Cost: 6.00s
Train Epoch: 1521 [40960/90000 (45%)]	Loss: 0.5507	Cost: 6.39s
Train Epoch: 1521 [61440/90000 (68%)]	Loss: 0.2968	Cost: 6.01s
Train Epoch: 1521 [81920/90000 (91%)]	Loss: 0.5286	Cost: 5.57s
Train Epoch: 1521 	Average Loss: 1.5060
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6648

Learning rate: 0.00019988585798323488
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1522 [0/90000 (0%)]	Loss: 14.7433	Cost: 22.43s
Train Epoch: 1522 [20480/90000 (23%)]	Loss: 0.3730	Cost: 6.11s
Train Epoch: 1522 [40960/90000 (45%)]	Loss: 0.4138	Cost: 7.52s
Train Epoch: 1522 [61440/90000 (68%)]	Loss: 0.2513	Cost: 5.96s
Train Epoch: 1522 [81920/90000 (91%)]	Loss: 0.5534	Cost: 9.03s
Train Epoch: 1522 	Average Loss: 1.4162
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8353

Learning rate: 0.00019988570787438
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1523 [0/90000 (0%)]	Loss: 15.2183	Cost: 23.62s
Train Epoch: 1523 [20480/90000 (23%)]	Loss: 0.4044	Cost: 5.92s
Train Epoch: 1523 [40960/90000 (45%)]	Loss: 0.4147	Cost: 7.25s
Train Epoch: 1523 [61440/90000 (68%)]	Loss: 0.1752	Cost: 6.29s
Train Epoch: 1523 [81920/90000 (91%)]	Loss: 0.5298	Cost: 6.16s
Train Epoch: 1523 	Average Loss: 1.4223
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7838

Learning rate: 0.00019988555766694188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1524 [0/90000 (0%)]	Loss: 14.8347	Cost: 24.48s
Train Epoch: 1524 [20480/90000 (23%)]	Loss: 0.2920	Cost: 6.16s
Train Epoch: 1524 [40960/90000 (45%)]	Loss: 0.2780	Cost: 6.17s
Train Epoch: 1524 [61440/90000 (68%)]	Loss: 0.0905	Cost: 6.13s
Train Epoch: 1524 [81920/90000 (91%)]	Loss: 0.3208	Cost: 6.27s
Train Epoch: 1524 	Average Loss: 1.3341
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7730

Learning rate: 0.00019988540736092067
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1525 [0/90000 (0%)]	Loss: 15.0991	Cost: 25.76s
Train Epoch: 1525 [20480/90000 (23%)]	Loss: 0.5022	Cost: 6.16s
Train Epoch: 1525 [40960/90000 (45%)]	Loss: 0.4138	Cost: 7.22s
Train Epoch: 1525 [61440/90000 (68%)]	Loss: 0.2190	Cost: 6.26s
Train Epoch: 1525 [81920/90000 (91%)]	Loss: 0.4936	Cost: 5.98s
Train Epoch: 1525 	Average Loss: 1.4352
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8784

Learning rate: 0.0001998852569563165
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1526 [0/90000 (0%)]	Loss: 15.1323	Cost: 30.30s
Train Epoch: 1526 [20480/90000 (23%)]	Loss: 0.6335	Cost: 6.14s
Train Epoch: 1526 [40960/90000 (45%)]	Loss: 3.3858	Cost: 7.57s
Train Epoch: 1526 [61440/90000 (68%)]	Loss: 3.5205	Cost: 5.90s
Train Epoch: 1526 [81920/90000 (91%)]	Loss: 3.2558	Cost: 5.94s
Train Epoch: 1526 	Average Loss: 3.3250
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6104

Learning rate: 0.00019988510645312958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1527 [0/90000 (0%)]	Loss: 14.8809	Cost: 23.63s
Train Epoch: 1527 [20480/90000 (23%)]	Loss: 2.5723	Cost: 6.10s
Train Epoch: 1527 [40960/90000 (45%)]	Loss: 2.1344	Cost: 7.99s
Train Epoch: 1527 [61440/90000 (68%)]	Loss: 1.9062	Cost: 5.91s
Train Epoch: 1527 [81920/90000 (91%)]	Loss: 1.6890	Cost: 8.10s
Train Epoch: 1527 	Average Loss: 3.0991
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.4350

Learning rate: 0.00019988495585136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1528 [0/90000 (0%)]	Loss: 14.6773	Cost: 23.29s
Train Epoch: 1528 [20480/90000 (23%)]	Loss: 1.3275	Cost: 6.16s
Train Epoch: 1528 [40960/90000 (45%)]	Loss: 1.1231	Cost: 6.47s
Train Epoch: 1528 [61440/90000 (68%)]	Loss: 1.0126	Cost: 5.91s
Train Epoch: 1528 [81920/90000 (91%)]	Loss: 1.1072	Cost: 5.96s
Train Epoch: 1528 	Average Loss: 2.1094
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6438

Learning rate: 0.00019988480515100793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1529 [0/90000 (0%)]	Loss: 15.0506	Cost: 23.17s
Train Epoch: 1529 [20480/90000 (23%)]	Loss: 0.9835	Cost: 6.07s
Train Epoch: 1529 [40960/90000 (45%)]	Loss: 0.9223	Cost: 6.63s
Train Epoch: 1529 [61440/90000 (68%)]	Loss: 0.6169	Cost: 5.99s
Train Epoch: 1529 [81920/90000 (91%)]	Loss: 0.6575	Cost: 5.75s
Train Epoch: 1529 	Average Loss: 1.7864
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7128

Learning rate: 0.0001998846543520735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1530 [0/90000 (0%)]	Loss: 14.7250	Cost: 24.00s
Train Epoch: 1530 [20480/90000 (23%)]	Loss: 0.7326	Cost: 6.10s
Train Epoch: 1530 [40960/90000 (45%)]	Loss: 0.6474	Cost: 6.82s
Train Epoch: 1530 [61440/90000 (68%)]	Loss: 0.6004	Cost: 5.95s
Train Epoch: 1530 [81920/90000 (91%)]	Loss: 0.7404	Cost: 6.58s
Train Epoch: 1530 	Average Loss: 1.6584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6627

Learning rate: 0.00019988450345455685
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1531 [0/90000 (0%)]	Loss: 14.9091	Cost: 27.73s
Train Epoch: 1531 [20480/90000 (23%)]	Loss: 0.6422	Cost: 6.13s
Train Epoch: 1531 [40960/90000 (45%)]	Loss: 0.2934	Cost: 6.66s
Train Epoch: 1531 [61440/90000 (68%)]	Loss: 0.3592	Cost: 6.07s
Train Epoch: 1531 [81920/90000 (91%)]	Loss: 0.5018	Cost: 6.22s
Train Epoch: 1531 	Average Loss: 1.5038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7796

Learning rate: 0.00019988435245845814
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1532 [0/90000 (0%)]	Loss: 14.9866	Cost: 24.66s
Train Epoch: 1532 [20480/90000 (23%)]	Loss: 0.5184	Cost: 6.02s
Train Epoch: 1532 [40960/90000 (45%)]	Loss: 0.3116	Cost: 7.82s
Train Epoch: 1532 [61440/90000 (68%)]	Loss: 0.1422	Cost: 5.88s
Train Epoch: 1532 [81920/90000 (91%)]	Loss: 0.2829	Cost: 7.20s
Train Epoch: 1532 	Average Loss: 1.3359
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6690

Learning rate: 0.00019988420136377757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1533 [0/90000 (0%)]	Loss: 15.0048	Cost: 23.65s
Train Epoch: 1533 [20480/90000 (23%)]	Loss: 0.3567	Cost: 6.10s
Train Epoch: 1533 [40960/90000 (45%)]	Loss: 0.0172	Cost: 6.20s
Train Epoch: 1533 [61440/90000 (68%)]	Loss: 0.1531	Cost: 6.29s
Train Epoch: 1533 [81920/90000 (91%)]	Loss: 0.1459	Cost: 7.09s
Train Epoch: 1533 	Average Loss: 1.2607
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6806

Learning rate: 0.0001998840501705152
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1534 [0/90000 (0%)]	Loss: 15.1677	Cost: 24.02s
Train Epoch: 1534 [20480/90000 (23%)]	Loss: 0.4784	Cost: 6.18s
Train Epoch: 1534 [40960/90000 (45%)]	Loss: 0.4120	Cost: 6.40s
Train Epoch: 1534 [61440/90000 (68%)]	Loss: 0.1158	Cost: 5.97s
Train Epoch: 1534 [81920/90000 (91%)]	Loss: 0.3668	Cost: 6.05s
Train Epoch: 1534 	Average Loss: 1.2747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7730

Learning rate: 0.00019988389887867124
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1535 [0/90000 (0%)]	Loss: 15.0084	Cost: 24.10s
Train Epoch: 1535 [20480/90000 (23%)]	Loss: 0.4283	Cost: 5.96s
Train Epoch: 1535 [40960/90000 (45%)]	Loss: 0.2368	Cost: 7.60s
Train Epoch: 1535 [61440/90000 (68%)]	Loss: 0.2188	Cost: 5.98s
Train Epoch: 1535 [81920/90000 (91%)]	Loss: 0.4798	Cost: 7.47s
Train Epoch: 1535 	Average Loss: 1.3745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7950

Learning rate: 0.00019988374748824582
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1536 [0/90000 (0%)]	Loss: 15.1289	Cost: 28.20s
Train Epoch: 1536 [20480/90000 (23%)]	Loss: 0.5904	Cost: 6.05s
Train Epoch: 1536 [40960/90000 (45%)]	Loss: 0.4700	Cost: 7.43s
Train Epoch: 1536 [61440/90000 (68%)]	Loss: 0.3179	Cost: 5.90s
Train Epoch: 1536 [81920/90000 (91%)]	Loss: 0.3624	Cost: 6.25s
Train Epoch: 1536 	Average Loss: 1.4461
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8334

Learning rate: 0.0001998835959992391
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1537 [0/90000 (0%)]	Loss: 15.3456	Cost: 26.93s
Train Epoch: 1537 [20480/90000 (23%)]	Loss: 0.3277	Cost: 6.09s
Train Epoch: 1537 [40960/90000 (45%)]	Loss: 0.3666	Cost: 7.09s
Train Epoch: 1537 [61440/90000 (68%)]	Loss: 0.2409	Cost: 6.19s
Train Epoch: 1537 [81920/90000 (91%)]	Loss: 0.3181	Cost: 6.39s
Train Epoch: 1537 	Average Loss: 1.3771
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8015

Learning rate: 0.0001998834444116512
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1538 [0/90000 (0%)]	Loss: 14.8628	Cost: 23.86s
Train Epoch: 1538 [20480/90000 (23%)]	Loss: 0.3447	Cost: 6.12s
Train Epoch: 1538 [40960/90000 (45%)]	Loss: 0.3194	Cost: 6.44s
Train Epoch: 1538 [61440/90000 (68%)]	Loss: 0.1095	Cost: 6.21s
Train Epoch: 1538 [81920/90000 (91%)]	Loss: 0.1582	Cost: 8.14s
Train Epoch: 1538 	Average Loss: 1.3332
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7822

Learning rate: 0.00019988329272548232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1539 [0/90000 (0%)]	Loss: 14.9457	Cost: 24.54s
Train Epoch: 1539 [20480/90000 (23%)]	Loss: 0.4225	Cost: 6.26s
Train Epoch: 1539 [40960/90000 (45%)]	Loss: 0.2200	Cost: 6.28s
Train Epoch: 1539 [61440/90000 (68%)]	Loss: 0.2125	Cost: 5.88s
Train Epoch: 1539 [81920/90000 (91%)]	Loss: 0.3167	Cost: 5.67s
Train Epoch: 1539 	Average Loss: 1.2827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8073

Learning rate: 0.00019988314094073257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1540 [0/90000 (0%)]	Loss: 15.0500	Cost: 23.45s
Train Epoch: 1540 [20480/90000 (23%)]	Loss: 0.3215	Cost: 6.01s
Train Epoch: 1540 [40960/90000 (45%)]	Loss: 0.2430	Cost: 7.07s
Train Epoch: 1540 [61440/90000 (68%)]	Loss: -0.0712	Cost: 6.01s
Train Epoch: 1540 [81920/90000 (91%)]	Loss: 0.3217	Cost: 5.75s
Train Epoch: 1540 	Average Loss: 1.2489
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9064

Learning rate: 0.0001998829890574021
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1541 [0/90000 (0%)]	Loss: 15.1162	Cost: 26.29s
Train Epoch: 1541 [20480/90000 (23%)]	Loss: 0.1274	Cost: 5.99s
Train Epoch: 1541 [40960/90000 (45%)]	Loss: -0.0373	Cost: 6.71s
Train Epoch: 1541 [61440/90000 (68%)]	Loss: 0.1334	Cost: 6.00s
Train Epoch: 1541 [81920/90000 (91%)]	Loss: 0.2353	Cost: 5.53s
Train Epoch: 1541 	Average Loss: 1.2138
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9077

Learning rate: 0.00019988283707549108
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1542 [0/90000 (0%)]	Loss: 15.4088	Cost: 23.55s
Train Epoch: 1542 [20480/90000 (23%)]	Loss: 0.2433	Cost: 5.99s
Train Epoch: 1542 [40960/90000 (45%)]	Loss: 0.1967	Cost: 7.97s
Train Epoch: 1542 [61440/90000 (68%)]	Loss: 0.0408	Cost: 5.83s
Train Epoch: 1542 [81920/90000 (91%)]	Loss: -0.1104	Cost: 7.25s
Train Epoch: 1542 	Average Loss: 1.1755
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8007

Learning rate: 0.00019988268499499965
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1543 [0/90000 (0%)]	Loss: 14.9178	Cost: 23.73s
Train Epoch: 1543 [20480/90000 (23%)]	Loss: 0.2454	Cost: 6.12s
Train Epoch: 1543 [40960/90000 (45%)]	Loss: 0.2865	Cost: 6.66s
Train Epoch: 1543 [61440/90000 (68%)]	Loss: 0.2577	Cost: 5.73s
Train Epoch: 1543 [81920/90000 (91%)]	Loss: 0.3422	Cost: 6.74s
Train Epoch: 1543 	Average Loss: 1.3026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9259

Learning rate: 0.00019988253281592796
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1544 [0/90000 (0%)]	Loss: 15.0664	Cost: 23.72s
Train Epoch: 1544 [20480/90000 (23%)]	Loss: 0.2411	Cost: 5.98s
Train Epoch: 1544 [40960/90000 (45%)]	Loss: 0.4111	Cost: 6.94s
Train Epoch: 1544 [61440/90000 (68%)]	Loss: 0.2107	Cost: 5.89s
Train Epoch: 1544 [81920/90000 (91%)]	Loss: 0.2869	Cost: 5.75s
Train Epoch: 1544 	Average Loss: 1.3608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9577

Learning rate: 0.00019988238053827618
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1545 [0/90000 (0%)]	Loss: 15.2315	Cost: 24.80s
Train Epoch: 1545 [20480/90000 (23%)]	Loss: 0.2346	Cost: 6.06s
Train Epoch: 1545 [40960/90000 (45%)]	Loss: 0.1135	Cost: 6.52s
Train Epoch: 1545 [61440/90000 (68%)]	Loss: 0.2029	Cost: 6.11s
Train Epoch: 1545 [81920/90000 (91%)]	Loss: 0.3357	Cost: 6.72s
Train Epoch: 1545 	Average Loss: 1.3019
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8465

Learning rate: 0.0001998822281620444
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1546 [0/90000 (0%)]	Loss: 15.0788	Cost: 30.50s
Train Epoch: 1546 [20480/90000 (23%)]	Loss: 0.4918	Cost: 6.00s
Train Epoch: 1546 [40960/90000 (45%)]	Loss: 0.2373	Cost: 8.86s
Train Epoch: 1546 [61440/90000 (68%)]	Loss: 0.2256	Cost: 5.90s
Train Epoch: 1546 [81920/90000 (91%)]	Loss: 0.6137	Cost: 5.96s
Train Epoch: 1546 	Average Loss: 1.3570
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9342

Learning rate: 0.00019988207568723284
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1547 [0/90000 (0%)]	Loss: 15.1635	Cost: 25.03s
Train Epoch: 1547 [20480/90000 (23%)]	Loss: 0.4686	Cost: 5.99s
Train Epoch: 1547 [40960/90000 (45%)]	Loss: 0.2466	Cost: 7.82s
Train Epoch: 1547 [61440/90000 (68%)]	Loss: 0.1230	Cost: 5.86s
Train Epoch: 1547 [81920/90000 (91%)]	Loss: 0.3116	Cost: 7.83s
Train Epoch: 1547 	Average Loss: 1.3725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9447

Learning rate: 0.0001998819231138416
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1548 [0/90000 (0%)]	Loss: 15.2038	Cost: 23.52s
Train Epoch: 1548 [20480/90000 (23%)]	Loss: 0.7012	Cost: 6.01s
Train Epoch: 1548 [40960/90000 (45%)]	Loss: 0.5674	Cost: 6.43s
Train Epoch: 1548 [61440/90000 (68%)]	Loss: 0.2082	Cost: 5.99s
Train Epoch: 1548 [81920/90000 (91%)]	Loss: 0.6581	Cost: 5.95s
Train Epoch: 1548 	Average Loss: 1.5565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9463

Learning rate: 0.00019988177044187092
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1549 [0/90000 (0%)]	Loss: 15.2647	Cost: 23.16s
Train Epoch: 1549 [20480/90000 (23%)]	Loss: 0.7518	Cost: 6.05s
Train Epoch: 1549 [40960/90000 (45%)]	Loss: 0.4493	Cost: 6.83s
Train Epoch: 1549 [61440/90000 (68%)]	Loss: 0.0862	Cost: 5.93s
Train Epoch: 1549 [81920/90000 (91%)]	Loss: 0.4018	Cost: 5.79s
Train Epoch: 1549 	Average Loss: 1.4253
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8106

Learning rate: 0.00019988161767132086
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1550 [0/90000 (0%)]	Loss: 15.0299	Cost: 24.44s
Train Epoch: 1550 [20480/90000 (23%)]	Loss: 0.3132	Cost: 6.16s
Train Epoch: 1550 [40960/90000 (45%)]	Loss: 0.1958	Cost: 6.97s
Train Epoch: 1550 [61440/90000 (68%)]	Loss: -0.0022	Cost: 6.00s
Train Epoch: 1550 [81920/90000 (91%)]	Loss: 0.0085	Cost: 5.83s
Train Epoch: 1550 	Average Loss: 1.1696
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8795

Learning rate: 0.0001998814648021916
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1551 [0/90000 (0%)]	Loss: 15.0938	Cost: 27.90s
Train Epoch: 1551 [20480/90000 (23%)]	Loss: 0.0473	Cost: 6.03s
Train Epoch: 1551 [40960/90000 (45%)]	Loss: 0.0662	Cost: 7.46s
Train Epoch: 1551 [61440/90000 (68%)]	Loss: 0.1907	Cost: 5.93s
Train Epoch: 1551 [81920/90000 (91%)]	Loss: 0.1853	Cost: 6.25s
Train Epoch: 1551 	Average Loss: 1.1824
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9458

Learning rate: 0.00019988131183448324
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1552 [0/90000 (0%)]	Loss: 15.3381	Cost: 28.14s
Train Epoch: 1552 [20480/90000 (23%)]	Loss: 0.2905	Cost: 6.02s
Train Epoch: 1552 [40960/90000 (45%)]	Loss: 0.2070	Cost: 9.56s
Train Epoch: 1552 [61440/90000 (68%)]	Loss: 0.1303	Cost: 5.95s
Train Epoch: 1552 [81920/90000 (91%)]	Loss: 0.3561	Cost: 7.55s
Train Epoch: 1552 	Average Loss: 1.3208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8257

Learning rate: 0.000199881158768196
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1553 [0/90000 (0%)]	Loss: 15.4241	Cost: 23.64s
Train Epoch: 1553 [20480/90000 (23%)]	Loss: 0.2452	Cost: 6.04s
Train Epoch: 1553 [40960/90000 (45%)]	Loss: -0.0991	Cost: 8.14s
Train Epoch: 1553 [61440/90000 (68%)]	Loss: -0.2078	Cost: 5.96s
Train Epoch: 1553 [81920/90000 (91%)]	Loss: 0.0760	Cost: 8.55s
Train Epoch: 1553 	Average Loss: 1.1704
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9140

Learning rate: 0.00019988100560333
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1554 [0/90000 (0%)]	Loss: 15.3062	Cost: 23.77s
Train Epoch: 1554 [20480/90000 (23%)]	Loss: -0.1301	Cost: 5.99s
Train Epoch: 1554 [40960/90000 (45%)]	Loss: 0.1865	Cost: 6.76s
Train Epoch: 1554 [61440/90000 (68%)]	Loss: 0.6480	Cost: 5.82s
Train Epoch: 1554 [81920/90000 (91%)]	Loss: 0.5047	Cost: 6.03s
Train Epoch: 1554 	Average Loss: 1.2951
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9007

Learning rate: 0.0001998808523398854
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1555 [0/90000 (0%)]	Loss: 14.9821	Cost: 23.68s
Train Epoch: 1555 [20480/90000 (23%)]	Loss: 0.4191	Cost: 6.03s
Train Epoch: 1555 [40960/90000 (45%)]	Loss: 0.8722	Cost: 6.77s
Train Epoch: 1555 [61440/90000 (68%)]	Loss: 0.3408	Cost: 6.00s
Train Epoch: 1555 [81920/90000 (91%)]	Loss: 0.5356	Cost: 6.33s
Train Epoch: 1555 	Average Loss: 1.6179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8534

Learning rate: 0.00019988069897786237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1556 [0/90000 (0%)]	Loss: 15.4644	Cost: 24.31s
Train Epoch: 1556 [20480/90000 (23%)]	Loss: 1.3163	Cost: 6.00s
Train Epoch: 1556 [40960/90000 (45%)]	Loss: 1.2727	Cost: 6.42s
Train Epoch: 1556 [61440/90000 (68%)]	Loss: 0.9755	Cost: 5.95s
Train Epoch: 1556 [81920/90000 (91%)]	Loss: 0.8502	Cost: 5.58s
Train Epoch: 1556 	Average Loss: 2.1456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.7758

Learning rate: 0.00019988054551726105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1557 [0/90000 (0%)]	Loss: 14.8203	Cost: 28.16s
Train Epoch: 1557 [20480/90000 (23%)]	Loss: 0.6050	Cost: 6.06s
Train Epoch: 1557 [40960/90000 (45%)]	Loss: 0.6404	Cost: 8.19s
Train Epoch: 1557 [61440/90000 (68%)]	Loss: 0.3865	Cost: 5.99s
Train Epoch: 1557 [81920/90000 (91%)]	Loss: 0.2880	Cost: 7.23s
Train Epoch: 1557 	Average Loss: 1.5836
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8133

Learning rate: 0.00019988039195808154
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1558 [0/90000 (0%)]	Loss: 14.9975	Cost: 23.58s
Train Epoch: 1558 [20480/90000 (23%)]	Loss: 0.5375	Cost: 6.04s
Train Epoch: 1558 [40960/90000 (45%)]	Loss: 0.4791	Cost: 7.47s
Train Epoch: 1558 [61440/90000 (68%)]	Loss: 0.1812	Cost: 6.25s
Train Epoch: 1558 [81920/90000 (91%)]	Loss: 0.9278	Cost: 6.47s
Train Epoch: 1558 	Average Loss: 1.4519
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8076

Learning rate: 0.00019988023830032404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1559 [0/90000 (0%)]	Loss: 15.3662	Cost: 23.09s
Train Epoch: 1559 [20480/90000 (23%)]	Loss: 0.6632	Cost: 6.14s
Train Epoch: 1559 [40960/90000 (45%)]	Loss: 0.7069	Cost: 6.45s
Train Epoch: 1559 [61440/90000 (68%)]	Loss: 0.5027	Cost: 6.25s
Train Epoch: 1559 [81920/90000 (91%)]	Loss: 0.4505	Cost: 6.71s
Train Epoch: 1559 	Average Loss: 1.6517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8758

Learning rate: 0.00019988008454398872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1560 [0/90000 (0%)]	Loss: 14.8817	Cost: 23.44s
Train Epoch: 1560 [20480/90000 (23%)]	Loss: 0.4639	Cost: 6.05s
Train Epoch: 1560 [40960/90000 (45%)]	Loss: 0.3853	Cost: 6.77s
Train Epoch: 1560 [61440/90000 (68%)]	Loss: 0.3563	Cost: 5.97s
Train Epoch: 1560 [81920/90000 (91%)]	Loss: 0.2994	Cost: 6.06s
Train Epoch: 1560 	Average Loss: 1.4456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8972

Learning rate: 0.0001998799306890757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1561 [0/90000 (0%)]	Loss: 15.2490	Cost: 24.66s
Train Epoch: 1561 [20480/90000 (23%)]	Loss: 0.0702	Cost: 6.06s
Train Epoch: 1561 [40960/90000 (45%)]	Loss: 0.0909	Cost: 7.52s
Train Epoch: 1561 [61440/90000 (68%)]	Loss: 0.0438	Cost: 6.40s
Train Epoch: 1561 [81920/90000 (91%)]	Loss: 0.2800	Cost: 6.24s
Train Epoch: 1561 	Average Loss: 1.2275
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8795

Learning rate: 0.0001998797767355851
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1562 [0/90000 (0%)]	Loss: 15.4160	Cost: 26.65s
Train Epoch: 1562 [20480/90000 (23%)]	Loss: 0.0544	Cost: 6.12s
Train Epoch: 1562 [40960/90000 (45%)]	Loss: 0.0211	Cost: 7.26s
Train Epoch: 1562 [61440/90000 (68%)]	Loss: 0.0086	Cost: 5.90s
Train Epoch: 1562 [81920/90000 (91%)]	Loss: 0.1667	Cost: 6.19s
Train Epoch: 1562 	Average Loss: 1.1540
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0015

Learning rate: 0.00019987962268351716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1563 [0/90000 (0%)]	Loss: 15.1735	Cost: 26.88s
Train Epoch: 1563 [20480/90000 (23%)]	Loss: 0.1527	Cost: 6.12s
Train Epoch: 1563 [40960/90000 (45%)]	Loss: 0.2460	Cost: 6.94s
Train Epoch: 1563 [61440/90000 (68%)]	Loss: 0.1332	Cost: 6.20s
Train Epoch: 1563 [81920/90000 (91%)]	Loss: -0.1496	Cost: 6.61s
Train Epoch: 1563 	Average Loss: 1.1827
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9292

Learning rate: 0.00019987946853287198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1564 [0/90000 (0%)]	Loss: 15.1231	Cost: 23.09s
Train Epoch: 1564 [20480/90000 (23%)]	Loss: -0.0861	Cost: 6.31s
Train Epoch: 1564 [40960/90000 (45%)]	Loss: -0.1446	Cost: 6.84s
Train Epoch: 1564 [61440/90000 (68%)]	Loss: -0.1599	Cost: 6.08s
Train Epoch: 1564 [81920/90000 (91%)]	Loss: 0.1106	Cost: 8.55s
Train Epoch: 1564 	Average Loss: 1.0242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9703

Learning rate: 0.0001998793142836497
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1565 [0/90000 (0%)]	Loss: 15.3917	Cost: 24.47s
Train Epoch: 1565 [20480/90000 (23%)]	Loss: -0.1993	Cost: 6.20s
Train Epoch: 1565 [40960/90000 (45%)]	Loss: -0.1220	Cost: 6.96s
Train Epoch: 1565 [61440/90000 (68%)]	Loss: -0.0488	Cost: 5.87s
Train Epoch: 1565 [81920/90000 (91%)]	Loss: 0.0975	Cost: 5.93s
Train Epoch: 1565 	Average Loss: 1.0211
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0465

Learning rate: 0.00019987915993585048
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1566 [0/90000 (0%)]	Loss: 15.4536	Cost: 23.05s
Train Epoch: 1566 [20480/90000 (23%)]	Loss: 0.3083	Cost: 6.18s
Train Epoch: 1566 [40960/90000 (45%)]	Loss: 0.2799	Cost: 6.35s
Train Epoch: 1566 [61440/90000 (68%)]	Loss: -0.0843	Cost: 6.14s
Train Epoch: 1566 [81920/90000 (91%)]	Loss: 0.1852	Cost: 5.77s
Train Epoch: 1566 	Average Loss: 1.2525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9718

Learning rate: 0.0001998790054894745
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1567 [0/90000 (0%)]	Loss: 15.0789	Cost: 26.89s
Train Epoch: 1567 [20480/90000 (23%)]	Loss: 0.3351	Cost: 6.08s
Train Epoch: 1567 [40960/90000 (45%)]	Loss: 0.2508	Cost: 7.10s
Train Epoch: 1567 [61440/90000 (68%)]	Loss: 0.3215	Cost: 5.87s
Train Epoch: 1567 [81920/90000 (91%)]	Loss: 0.3781	Cost: 5.75s
Train Epoch: 1567 	Average Loss: 1.4081
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9135

Learning rate: 0.00019987885094452186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1568 [0/90000 (0%)]	Loss: 15.5688	Cost: 27.56s
Train Epoch: 1568 [20480/90000 (23%)]	Loss: 0.4184	Cost: 6.11s
Train Epoch: 1568 [40960/90000 (45%)]	Loss: 0.2906	Cost: 6.59s
Train Epoch: 1568 [61440/90000 (68%)]	Loss: 0.0509	Cost: 6.15s
Train Epoch: 1568 [81920/90000 (91%)]	Loss: 0.2199	Cost: 6.03s
Train Epoch: 1568 	Average Loss: 1.3029
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9373

Learning rate: 0.0001998786963009928
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1569 [0/90000 (0%)]	Loss: 15.4160	Cost: 23.98s
Train Epoch: 1569 [20480/90000 (23%)]	Loss: 0.1895	Cost: 6.06s
Train Epoch: 1569 [40960/90000 (45%)]	Loss: 0.0870	Cost: 8.24s
Train Epoch: 1569 [61440/90000 (68%)]	Loss: -0.0741	Cost: 5.94s
Train Epoch: 1569 [81920/90000 (91%)]	Loss: 0.2289	Cost: 8.21s
Train Epoch: 1569 	Average Loss: 1.1872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9411

Learning rate: 0.00019987854155888737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1570 [0/90000 (0%)]	Loss: 15.2364	Cost: 23.14s
Train Epoch: 1570 [20480/90000 (23%)]	Loss: 0.4120	Cost: 6.13s
Train Epoch: 1570 [40960/90000 (45%)]	Loss: 0.1763	Cost: 6.22s
Train Epoch: 1570 [61440/90000 (68%)]	Loss: 0.1692	Cost: 6.00s
Train Epoch: 1570 [81920/90000 (91%)]	Loss: 0.1863	Cost: 6.08s
Train Epoch: 1570 	Average Loss: 1.2280
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0005

Learning rate: 0.0001998783867182058
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1571 [0/90000 (0%)]	Loss: 15.3842	Cost: 22.89s
Train Epoch: 1571 [20480/90000 (23%)]	Loss: 0.2153	Cost: 6.49s
Train Epoch: 1571 [40960/90000 (45%)]	Loss: 0.0290	Cost: 7.18s
Train Epoch: 1571 [61440/90000 (68%)]	Loss: -0.1468	Cost: 5.91s
Train Epoch: 1571 [81920/90000 (91%)]	Loss: 0.2007	Cost: 6.67s
Train Epoch: 1571 	Average Loss: 1.1514
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8325

Learning rate: 0.0001998782317789482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1572 [0/90000 (0%)]	Loss: 15.1428	Cost: 24.33s
Train Epoch: 1572 [20480/90000 (23%)]	Loss: 0.2254	Cost: 5.96s
Train Epoch: 1572 [40960/90000 (45%)]	Loss: -0.1690	Cost: 6.28s
Train Epoch: 1572 [61440/90000 (68%)]	Loss: -0.1994	Cost: 6.10s
Train Epoch: 1572 [81920/90000 (91%)]	Loss: -0.0891	Cost: 5.57s
Train Epoch: 1572 	Average Loss: 1.0198
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0355

Learning rate: 0.00019987807674111475
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1573 [0/90000 (0%)]	Loss: 15.4823	Cost: 29.52s
Train Epoch: 1573 [20480/90000 (23%)]	Loss: -0.0565	Cost: 6.04s
Train Epoch: 1573 [40960/90000 (45%)]	Loss: -0.0843	Cost: 7.80s
Train Epoch: 1573 [61440/90000 (68%)]	Loss: -0.3851	Cost: 6.10s
Train Epoch: 1573 [81920/90000 (91%)]	Loss: -0.2125	Cost: 5.74s
Train Epoch: 1573 	Average Loss: 0.9281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0403

Learning rate: 0.00019987792160470558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1574 [0/90000 (0%)]	Loss: 15.0557	Cost: 25.19s
Train Epoch: 1574 [20480/90000 (23%)]	Loss: -0.1214	Cost: 6.11s
Train Epoch: 1574 [40960/90000 (45%)]	Loss: 0.0951	Cost: 7.42s
Train Epoch: 1574 [61440/90000 (68%)]	Loss: -0.0737	Cost: 6.26s
Train Epoch: 1574 [81920/90000 (91%)]	Loss: -0.0180	Cost: 6.62s
Train Epoch: 1574 	Average Loss: 0.9482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0632

Learning rate: 0.00019987776636972085
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1575 [0/90000 (0%)]	Loss: 15.3864	Cost: 22.63s
Train Epoch: 1575 [20480/90000 (23%)]	Loss: -0.0010	Cost: 5.96s
Train Epoch: 1575 [40960/90000 (45%)]	Loss: -0.0261	Cost: 6.50s
Train Epoch: 1575 [61440/90000 (68%)]	Loss: -0.0422	Cost: 5.99s
Train Epoch: 1575 [81920/90000 (91%)]	Loss: -0.0036	Cost: 8.22s
Train Epoch: 1575 	Average Loss: 1.0780
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9959

Learning rate: 0.00019987761103616069
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1576 [0/90000 (0%)]	Loss: 15.3866	Cost: 23.97s
Train Epoch: 1576 [20480/90000 (23%)]	Loss: -0.0844	Cost: 6.20s
Train Epoch: 1576 [40960/90000 (45%)]	Loss: -0.1581	Cost: 6.61s
Train Epoch: 1576 [61440/90000 (68%)]	Loss: -0.3542	Cost: 5.95s
Train Epoch: 1576 [81920/90000 (91%)]	Loss: -0.1083	Cost: 5.73s
Train Epoch: 1576 	Average Loss: 0.9326
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1122

Learning rate: 0.0001998774556040253
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1577 [0/90000 (0%)]	Loss: 15.4368	Cost: 23.05s
Train Epoch: 1577 [20480/90000 (23%)]	Loss: -0.1936	Cost: 5.99s
Train Epoch: 1577 [40960/90000 (45%)]	Loss: -0.0635	Cost: 7.49s
Train Epoch: 1577 [61440/90000 (68%)]	Loss: -0.2856	Cost: 6.07s
Train Epoch: 1577 [81920/90000 (91%)]	Loss: -0.0873	Cost: 6.29s
Train Epoch: 1577 	Average Loss: 0.8757
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0720

Learning rate: 0.00019987730007331483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1578 [0/90000 (0%)]	Loss: 15.2562	Cost: 28.28s
Train Epoch: 1578 [20480/90000 (23%)]	Loss: 0.2094	Cost: 6.09s
Train Epoch: 1578 [40960/90000 (45%)]	Loss: -0.0567	Cost: 7.21s
Train Epoch: 1578 [61440/90000 (68%)]	Loss: -0.1629	Cost: 5.94s
Train Epoch: 1578 [81920/90000 (91%)]	Loss: -0.2369	Cost: 6.18s
Train Epoch: 1578 	Average Loss: 1.0440
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0322

Learning rate: 0.0001998771444440294
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1579 [0/90000 (0%)]	Loss: 15.7639	Cost: 27.79s
Train Epoch: 1579 [20480/90000 (23%)]	Loss: -0.1859	Cost: 6.10s
Train Epoch: 1579 [40960/90000 (45%)]	Loss: -0.1150	Cost: 9.01s
Train Epoch: 1579 [61440/90000 (68%)]	Loss: -0.4519	Cost: 5.98s
Train Epoch: 1579 [81920/90000 (91%)]	Loss: -0.2862	Cost: 7.01s
Train Epoch: 1579 	Average Loss: 0.8861
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0635

Learning rate: 0.0001998769887161692
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1580 [0/90000 (0%)]	Loss: 15.3757	Cost: 23.13s
Train Epoch: 1580 [20480/90000 (23%)]	Loss: 0.0845	Cost: 6.01s
Train Epoch: 1580 [40960/90000 (45%)]	Loss: 0.1225	Cost: 7.96s
Train Epoch: 1580 [61440/90000 (68%)]	Loss: -0.0430	Cost: 5.97s
Train Epoch: 1580 [81920/90000 (91%)]	Loss: 0.0083	Cost: 9.36s
Train Epoch: 1580 	Average Loss: 1.1287
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9885

Learning rate: 0.00019987683288973435
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1581 [0/90000 (0%)]	Loss: 15.4707	Cost: 24.55s
Train Epoch: 1581 [20480/90000 (23%)]	Loss: -0.0233	Cost: 6.01s
Train Epoch: 1581 [40960/90000 (45%)]	Loss: -0.0044	Cost: 7.03s
Train Epoch: 1581 [61440/90000 (68%)]	Loss: -0.2044	Cost: 6.47s
Train Epoch: 1581 [81920/90000 (91%)]	Loss: -0.1190	Cost: 6.20s
Train Epoch: 1581 	Average Loss: 0.9936
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0513

Learning rate: 0.000199876676964725
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1582 [0/90000 (0%)]	Loss: 15.4279	Cost: 23.69s
Train Epoch: 1582 [20480/90000 (23%)]	Loss: -0.1813	Cost: 6.04s
Train Epoch: 1582 [40960/90000 (45%)]	Loss: -0.0609	Cost: 7.07s
Train Epoch: 1582 [61440/90000 (68%)]	Loss: 0.1566	Cost: 6.03s
Train Epoch: 1582 [81920/90000 (91%)]	Loss: -0.0462	Cost: 6.02s
Train Epoch: 1582 	Average Loss: 1.0210
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0917

Learning rate: 0.00019987652094114133
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1583 [0/90000 (0%)]	Loss: 15.3887	Cost: 25.94s
Train Epoch: 1583 [20480/90000 (23%)]	Loss: -0.1757	Cost: 6.05s
Train Epoch: 1583 [40960/90000 (45%)]	Loss: 0.1557	Cost: 6.50s
Train Epoch: 1583 [61440/90000 (68%)]	Loss: -0.3023	Cost: 5.91s
Train Epoch: 1583 [81920/90000 (91%)]	Loss: 0.2232	Cost: 5.68s
Train Epoch: 1583 	Average Loss: 0.9921
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0087

Learning rate: 0.0001998763648189835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1584 [0/90000 (0%)]	Loss: 15.3925	Cost: 29.74s
Train Epoch: 1584 [20480/90000 (23%)]	Loss: 0.3730	Cost: 6.12s
Train Epoch: 1584 [40960/90000 (45%)]	Loss: 0.3142	Cost: 7.63s
Train Epoch: 1584 [61440/90000 (68%)]	Loss: 0.0510	Cost: 5.88s
Train Epoch: 1584 [81920/90000 (91%)]	Loss: -0.0981	Cost: 5.75s
Train Epoch: 1584 	Average Loss: 1.2306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0562

Learning rate: 0.0001998762085982516
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1585 [0/90000 (0%)]	Loss: 15.3461	Cost: 24.65s
Train Epoch: 1585 [20480/90000 (23%)]	Loss: -0.1597	Cost: 6.01s
Train Epoch: 1585 [40960/90000 (45%)]	Loss: -0.2971	Cost: 8.50s
Train Epoch: 1585 [61440/90000 (68%)]	Loss: -0.3732	Cost: 5.88s
Train Epoch: 1585 [81920/90000 (91%)]	Loss: -0.2558	Cost: 8.97s
Train Epoch: 1585 	Average Loss: 0.8839
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0430

Learning rate: 0.00019987605227894588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1586 [0/90000 (0%)]	Loss: 15.0957	Cost: 22.83s
Train Epoch: 1586 [20480/90000 (23%)]	Loss: -0.0683	Cost: 6.68s
Train Epoch: 1586 [40960/90000 (45%)]	Loss: -0.2315	Cost: 6.65s
Train Epoch: 1586 [61440/90000 (68%)]	Loss: -0.1740	Cost: 6.07s
Train Epoch: 1586 [81920/90000 (91%)]	Loss: -0.3706	Cost: 8.13s
Train Epoch: 1586 	Average Loss: 0.8404
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1030

Learning rate: 0.00019987589586106645
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1587 [0/90000 (0%)]	Loss: 14.9780	Cost: 23.54s
Train Epoch: 1587 [20480/90000 (23%)]	Loss: -0.3804	Cost: 6.06s
Train Epoch: 1587 [40960/90000 (45%)]	Loss: -0.2527	Cost: 7.27s
Train Epoch: 1587 [61440/90000 (68%)]	Loss: -0.3669	Cost: 6.32s
Train Epoch: 1587 [81920/90000 (91%)]	Loss: -0.5086	Cost: 5.77s
Train Epoch: 1587 	Average Loss: 0.7034
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2773

Learning rate: 0.00019987573934461347
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1588 [0/90000 (0%)]	Loss: 15.3848	Cost: 23.94s
Train Epoch: 1588 [20480/90000 (23%)]	Loss: -0.4784	Cost: 6.04s
Train Epoch: 1588 [40960/90000 (45%)]	Loss: -0.3177	Cost: 7.20s
Train Epoch: 1588 [61440/90000 (68%)]	Loss: -0.5983	Cost: 6.03s
Train Epoch: 1588 [81920/90000 (91%)]	Loss: -0.3572	Cost: 6.51s
Train Epoch: 1588 	Average Loss: 0.6570
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1527

Learning rate: 0.00019987558272958707
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1589 [0/90000 (0%)]	Loss: 15.4612	Cost: 28.56s
Train Epoch: 1589 [20480/90000 (23%)]	Loss: -0.0384	Cost: 6.04s
Train Epoch: 1589 [40960/90000 (45%)]	Loss: 0.1882	Cost: 7.42s
Train Epoch: 1589 [61440/90000 (68%)]	Loss: -0.0540	Cost: 6.17s
Train Epoch: 1589 [81920/90000 (91%)]	Loss: -0.0326	Cost: 5.81s
Train Epoch: 1589 	Average Loss: 1.0174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1420

Learning rate: 0.00019987542601598743
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1590 [0/90000 (0%)]	Loss: 15.2309	Cost: 26.75s
Train Epoch: 1590 [20480/90000 (23%)]	Loss: -0.0130	Cost: 6.06s
Train Epoch: 1590 [40960/90000 (45%)]	Loss: -0.0051	Cost: 7.08s
Train Epoch: 1590 [61440/90000 (68%)]	Loss: -0.3044	Cost: 6.13s
Train Epoch: 1590 [81920/90000 (91%)]	Loss: -0.0960	Cost: 6.74s
Train Epoch: 1590 	Average Loss: 0.9773
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0854

Learning rate: 0.00019987526920381467
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1591 [0/90000 (0%)]	Loss: 15.4546	Cost: 22.53s
Train Epoch: 1591 [20480/90000 (23%)]	Loss: -0.0537	Cost: 5.96s
Train Epoch: 1591 [40960/90000 (45%)]	Loss: -0.0892	Cost: 7.74s
Train Epoch: 1591 [61440/90000 (68%)]	Loss: -0.3640	Cost: 5.99s
Train Epoch: 1591 [81920/90000 (91%)]	Loss: -0.1869	Cost: 9.42s
Train Epoch: 1591 	Average Loss: 0.8973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2335

Learning rate: 0.000199875112293069
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1592 [0/90000 (0%)]	Loss: 15.6250	Cost: 23.85s
Train Epoch: 1592 [20480/90000 (23%)]	Loss: -0.2519	Cost: 6.01s
Train Epoch: 1592 [40960/90000 (45%)]	Loss: -0.3402	Cost: 6.72s
Train Epoch: 1592 [61440/90000 (68%)]	Loss: -0.2998	Cost: 6.15s
Train Epoch: 1592 [81920/90000 (91%)]	Loss: -0.1572	Cost: 6.17s
Train Epoch: 1592 	Average Loss: 0.8144
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2536

Learning rate: 0.00019987495528375055
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1593 [0/90000 (0%)]	Loss: 15.3988	Cost: 22.76s
Train Epoch: 1593 [20480/90000 (23%)]	Loss: -0.5122	Cost: 6.12s
Train Epoch: 1593 [40960/90000 (45%)]	Loss: -0.3386	Cost: 6.89s
Train Epoch: 1593 [61440/90000 (68%)]	Loss: -0.3763	Cost: 6.11s
Train Epoch: 1593 [81920/90000 (91%)]	Loss: -0.1326	Cost: 6.32s
Train Epoch: 1593 	Average Loss: 0.7614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1811

Learning rate: 0.00019987479817585945
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1594 [0/90000 (0%)]	Loss: 15.0758	Cost: 25.00s
Train Epoch: 1594 [20480/90000 (23%)]	Loss: -0.0373	Cost: 5.97s
Train Epoch: 1594 [40960/90000 (45%)]	Loss: -0.0649	Cost: 6.80s
Train Epoch: 1594 [61440/90000 (68%)]	Loss: -0.6048	Cost: 6.11s
Train Epoch: 1594 [81920/90000 (91%)]	Loss: -0.2658	Cost: 6.29s
Train Epoch: 1594 	Average Loss: 0.8939
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1429

Learning rate: 0.0001998746409693959
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1595 [0/90000 (0%)]	Loss: 15.3305	Cost: 29.64s
Train Epoch: 1595 [20480/90000 (23%)]	Loss: -0.4431	Cost: 6.02s
Train Epoch: 1595 [40960/90000 (45%)]	Loss: -0.3197	Cost: 7.28s
Train Epoch: 1595 [61440/90000 (68%)]	Loss: -0.1914	Cost: 5.93s
Train Epoch: 1595 [81920/90000 (91%)]	Loss: -0.1228	Cost: 5.74s
Train Epoch: 1595 	Average Loss: 0.8421
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1420

Learning rate: 0.00019987448366436
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1596 [0/90000 (0%)]	Loss: 15.2587	Cost: 25.56s
Train Epoch: 1596 [20480/90000 (23%)]	Loss: -0.2823	Cost: 6.01s
Train Epoch: 1596 [40960/90000 (45%)]	Loss: -0.4881	Cost: 7.78s
Train Epoch: 1596 [61440/90000 (68%)]	Loss: -0.5872	Cost: 5.80s
Train Epoch: 1596 [81920/90000 (91%)]	Loss: -0.2705	Cost: 5.58s
Train Epoch: 1596 	Average Loss: 0.7565
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1577

Learning rate: 0.00019987432626075193
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1597 [0/90000 (0%)]	Loss: 15.4801	Cost: 22.87s
Train Epoch: 1597 [20480/90000 (23%)]	Loss: -0.5211	Cost: 6.16s
Train Epoch: 1597 [40960/90000 (45%)]	Loss: -0.3117	Cost: 6.42s
Train Epoch: 1597 [61440/90000 (68%)]	Loss: -0.4450	Cost: 6.20s
Train Epoch: 1597 [81920/90000 (91%)]	Loss: -0.2116	Cost: 7.88s
Train Epoch: 1597 	Average Loss: 0.6784
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1959

Learning rate: 0.00019987416875857185
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1598 [0/90000 (0%)]	Loss: 15.5104	Cost: 24.82s
Train Epoch: 1598 [20480/90000 (23%)]	Loss: -0.5960	Cost: 6.11s
Train Epoch: 1598 [40960/90000 (45%)]	Loss: -0.2412	Cost: 6.75s
Train Epoch: 1598 [61440/90000 (68%)]	Loss: -0.4654	Cost: 5.94s
Train Epoch: 1598 [81920/90000 (91%)]	Loss: 0.0742	Cost: 5.56s
Train Epoch: 1598 	Average Loss: 0.7491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1665

Learning rate: 0.00019987401115781993
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1599 [0/90000 (0%)]	Loss: 15.6180	Cost: 23.22s
Train Epoch: 1599 [20480/90000 (23%)]	Loss: -0.1184	Cost: 6.05s
Train Epoch: 1599 [40960/90000 (45%)]	Loss: -0.1545	Cost: 7.65s
Train Epoch: 1599 [61440/90000 (68%)]	Loss: -0.3652	Cost: 6.05s
Train Epoch: 1599 [81920/90000 (91%)]	Loss: -0.2865	Cost: 6.24s
Train Epoch: 1599 	Average Loss: 0.9710
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2889

Learning rate: 0.0001998738534584963
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1600 [0/90000 (0%)]	Loss: 15.4063	Cost: 28.23s
Train Epoch: 1600 [20480/90000 (23%)]	Loss: -0.0090	Cost: 6.01s
Train Epoch: 1600 [40960/90000 (45%)]	Loss: -0.3745	Cost: 7.83s
Train Epoch: 1600 [61440/90000 (68%)]	Loss: -0.1638	Cost: 5.95s
Train Epoch: 1600 [81920/90000 (91%)]	Loss: -0.1589	Cost: 5.73s
Train Epoch: 1600 	Average Loss: 0.9414
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3193

Learning rate: 0.00019987369566060113
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1601 [0/90000 (0%)]	Loss: 15.2060	Cost: 26.84s
Train Epoch: 1601 [20480/90000 (23%)]	Loss: -0.1960	Cost: 6.01s
Train Epoch: 1601 [40960/90000 (45%)]	Loss: -0.1229	Cost: 8.88s
Train Epoch: 1601 [61440/90000 (68%)]	Loss: -0.1963	Cost: 6.07s
Train Epoch: 1601 [81920/90000 (91%)]	Loss: -0.1568	Cost: 8.26s
Train Epoch: 1601 	Average Loss: 0.9374
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1499

Learning rate: 0.00019987353776413456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1602 [0/90000 (0%)]	Loss: 15.3952	Cost: 22.82s
Train Epoch: 1602 [20480/90000 (23%)]	Loss: -0.3800	Cost: 6.05s
Train Epoch: 1602 [40960/90000 (45%)]	Loss: 0.0254	Cost: 7.65s
Train Epoch: 1602 [61440/90000 (68%)]	Loss: -0.3177	Cost: 6.02s
Train Epoch: 1602 [81920/90000 (91%)]	Loss: -0.2117	Cost: 8.26s
Train Epoch: 1602 	Average Loss: 0.9010
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1671

Learning rate: 0.0001998733797690968
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1603 [0/90000 (0%)]	Loss: 15.4729	Cost: 24.05s
Train Epoch: 1603 [20480/90000 (23%)]	Loss: -0.2763	Cost: 6.14s
Train Epoch: 1603 [40960/90000 (45%)]	Loss: -0.6130	Cost: 6.93s
Train Epoch: 1603 [61440/90000 (68%)]	Loss: -0.4880	Cost: 5.94s
Train Epoch: 1603 [81920/90000 (91%)]	Loss: -0.1209	Cost: 5.90s
Train Epoch: 1603 	Average Loss: 0.7611
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1795

Learning rate: 0.00019987322167548793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1604 [0/90000 (0%)]	Loss: 15.3292	Cost: 23.10s
Train Epoch: 1604 [20480/90000 (23%)]	Loss: -0.4266	Cost: 6.02s
Train Epoch: 1604 [40960/90000 (45%)]	Loss: -0.3319	Cost: 6.54s
Train Epoch: 1604 [61440/90000 (68%)]	Loss: -0.5379	Cost: 6.32s
Train Epoch: 1604 [81920/90000 (91%)]	Loss: -0.3676	Cost: 6.21s
Train Epoch: 1604 	Average Loss: 0.7946
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1131

Learning rate: 0.00019987306348330817
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1605 [0/90000 (0%)]	Loss: 15.7110	Cost: 25.13s
Train Epoch: 1605 [20480/90000 (23%)]	Loss: 0.0946	Cost: 6.24s
Train Epoch: 1605 [40960/90000 (45%)]	Loss: 0.1057	Cost: 6.86s
Train Epoch: 1605 [61440/90000 (68%)]	Loss: -0.1227	Cost: 6.22s
Train Epoch: 1605 [81920/90000 (91%)]	Loss: 0.0526	Cost: 5.93s
Train Epoch: 1605 	Average Loss: 1.0783
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1760

Learning rate: 0.00019987290519255766
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1606 [0/90000 (0%)]	Loss: 15.5370	Cost: 29.14s
Train Epoch: 1606 [20480/90000 (23%)]	Loss: -0.0471	Cost: 5.99s
Train Epoch: 1606 [40960/90000 (45%)]	Loss: 0.0112	Cost: 8.84s
Train Epoch: 1606 [61440/90000 (68%)]	Loss: -0.1686	Cost: 5.77s
Train Epoch: 1606 [81920/90000 (91%)]	Loss: -0.1711	Cost: 6.01s
Train Epoch: 1606 	Average Loss: 1.0126
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1198

Learning rate: 0.00019987274680323652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1607 [0/90000 (0%)]	Loss: 15.4327	Cost: 24.57s
Train Epoch: 1607 [20480/90000 (23%)]	Loss: -0.3023	Cost: 5.99s
Train Epoch: 1607 [40960/90000 (45%)]	Loss: -0.2229	Cost: 8.15s
Train Epoch: 1607 [61440/90000 (68%)]	Loss: -0.2896	Cost: 5.87s
Train Epoch: 1607 [81920/90000 (91%)]	Loss: -0.3067	Cost: 8.35s
Train Epoch: 1607 	Average Loss: 0.8273
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1541

Learning rate: 0.00019987258831534495
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1608 [0/90000 (0%)]	Loss: 15.5448	Cost: 23.87s
Train Epoch: 1608 [20480/90000 (23%)]	Loss: -0.4721	Cost: 6.63s
Train Epoch: 1608 [40960/90000 (45%)]	Loss: -0.2582	Cost: 6.39s
Train Epoch: 1608 [61440/90000 (68%)]	Loss: -0.3941	Cost: 6.09s
Train Epoch: 1608 [81920/90000 (91%)]	Loss: -0.1447	Cost: 8.28s
Train Epoch: 1608 	Average Loss: 0.7364
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2280

Learning rate: 0.00019987242972888307
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1609 [0/90000 (0%)]	Loss: 15.7441	Cost: 24.74s
Train Epoch: 1609 [20480/90000 (23%)]	Loss: -0.2863	Cost: 6.12s
Train Epoch: 1609 [40960/90000 (45%)]	Loss: -0.4383	Cost: 7.17s
Train Epoch: 1609 [61440/90000 (68%)]	Loss: -0.4405	Cost: 5.93s
Train Epoch: 1609 [81920/90000 (91%)]	Loss: -0.4303	Cost: 5.76s
Train Epoch: 1609 	Average Loss: 0.7483
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1991

Learning rate: 0.00019987227104385105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1610 [0/90000 (0%)]	Loss: 15.6870	Cost: 23.76s
Train Epoch: 1610 [20480/90000 (23%)]	Loss: -0.2515	Cost: 6.17s
Train Epoch: 1610 [40960/90000 (45%)]	Loss: -0.5228	Cost: 6.89s
Train Epoch: 1610 [61440/90000 (68%)]	Loss: -0.3840	Cost: 6.06s
Train Epoch: 1610 [81920/90000 (91%)]	Loss: -0.3270	Cost: 6.25s
Train Epoch: 1610 	Average Loss: 0.7174
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2074

Learning rate: 0.00019987211226024906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1611 [0/90000 (0%)]	Loss: 15.5985	Cost: 24.70s
Train Epoch: 1611 [20480/90000 (23%)]	Loss: -0.6059	Cost: 6.17s
Train Epoch: 1611 [40960/90000 (45%)]	Loss: -0.3899	Cost: 6.26s
Train Epoch: 1611 [61440/90000 (68%)]	Loss: -0.4470	Cost: 5.99s
Train Epoch: 1611 [81920/90000 (91%)]	Loss: -0.4456	Cost: 5.65s
Train Epoch: 1611 	Average Loss: 0.7584
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3299

Learning rate: 0.00019987195337807723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1612 [0/90000 (0%)]	Loss: 15.5258	Cost: 27.43s
Train Epoch: 1612 [20480/90000 (23%)]	Loss: -0.0953	Cost: 6.12s
Train Epoch: 1612 [40960/90000 (45%)]	Loss: -0.0455	Cost: 6.40s
Train Epoch: 1612 [61440/90000 (68%)]	Loss: -0.1878	Cost: 6.07s
Train Epoch: 1612 [81920/90000 (91%)]	Loss: -0.2583	Cost: 5.73s
Train Epoch: 1612 	Average Loss: 0.9674
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2290

Learning rate: 0.0001998717943973357
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1613 [0/90000 (0%)]	Loss: 15.5255	Cost: 23.90s
Train Epoch: 1613 [20480/90000 (23%)]	Loss: -0.2577	Cost: 6.01s
Train Epoch: 1613 [40960/90000 (45%)]	Loss: -0.4730	Cost: 7.77s
Train Epoch: 1613 [61440/90000 (68%)]	Loss: -0.5576	Cost: 5.87s
Train Epoch: 1613 [81920/90000 (91%)]	Loss: -0.3396	Cost: 7.51s
Train Epoch: 1613 	Average Loss: 0.7170
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2176

Learning rate: 0.0001998716353180247
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1614 [0/90000 (0%)]	Loss: 15.4258	Cost: 23.88s
Train Epoch: 1614 [20480/90000 (23%)]	Loss: -0.2268	Cost: 6.11s
Train Epoch: 1614 [40960/90000 (45%)]	Loss: -0.1678	Cost: 6.27s
Train Epoch: 1614 [61440/90000 (68%)]	Loss: -0.1826	Cost: 6.29s
Train Epoch: 1614 [81920/90000 (91%)]	Loss: -0.3725	Cost: 5.99s
Train Epoch: 1614 	Average Loss: 0.8476
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1752

Learning rate: 0.00019987147614014433
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1615 [0/90000 (0%)]	Loss: 15.6451	Cost: 24.17s
Train Epoch: 1615 [20480/90000 (23%)]	Loss: -0.5662	Cost: 6.11s
Train Epoch: 1615 [40960/90000 (45%)]	Loss: -0.3671	Cost: 7.68s
Train Epoch: 1615 [61440/90000 (68%)]	Loss: -0.4156	Cost: 5.96s
Train Epoch: 1615 [81920/90000 (91%)]	Loss: -0.2728	Cost: 6.83s
Train Epoch: 1615 	Average Loss: 0.7441
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1391

Learning rate: 0.0001998713168636948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1616 [0/90000 (0%)]	Loss: 15.5815	Cost: 24.51s
Train Epoch: 1616 [20480/90000 (23%)]	Loss: -0.4741	Cost: 5.96s
Train Epoch: 1616 [40960/90000 (45%)]	Loss: -0.3743	Cost: 7.95s
Train Epoch: 1616 [61440/90000 (68%)]	Loss: -0.4470	Cost: 6.02s
Train Epoch: 1616 [81920/90000 (91%)]	Loss: -0.4067	Cost: 6.34s
Train Epoch: 1616 	Average Loss: 0.6296
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1870

Learning rate: 0.00019987115748867622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1617 [0/90000 (0%)]	Loss: 15.6267	Cost: 26.42s
Train Epoch: 1617 [20480/90000 (23%)]	Loss: -0.4816	Cost: 6.06s
Train Epoch: 1617 [40960/90000 (45%)]	Loss: -0.2354	Cost: 6.91s
Train Epoch: 1617 [61440/90000 (68%)]	Loss: -0.4237	Cost: 6.02s
Train Epoch: 1617 [81920/90000 (91%)]	Loss: -0.2438	Cost: 6.23s
Train Epoch: 1617 	Average Loss: 0.6996
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3557

Learning rate: 0.00019987099801508875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1618 [0/90000 (0%)]	Loss: 15.5602	Cost: 26.44s
Train Epoch: 1618 [20480/90000 (23%)]	Loss: -0.2498	Cost: 6.13s
Train Epoch: 1618 [40960/90000 (45%)]	Loss: -0.3361	Cost: 7.07s
Train Epoch: 1618 [61440/90000 (68%)]	Loss: 1.7972	Cost: 6.15s
Train Epoch: 1618 [81920/90000 (91%)]	Loss: 1.8273	Cost: 6.87s
Train Epoch: 1618 	Average Loss: 1.6180
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2305

Learning rate: 0.00019987083844293254
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1619 [0/90000 (0%)]	Loss: 15.5860	Cost: 24.04s
Train Epoch: 1619 [20480/90000 (23%)]	Loss: 1.1613	Cost: 6.13s
Train Epoch: 1619 [40960/90000 (45%)]	Loss: 0.5940	Cost: 7.11s
Train Epoch: 1619 [61440/90000 (68%)]	Loss: 0.4993	Cost: 6.10s
Train Epoch: 1619 [81920/90000 (91%)]	Loss: 0.7331	Cost: 8.67s
Train Epoch: 1619 	Average Loss: 1.9015
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0326

Learning rate: 0.00019987067877220776
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1620 [0/90000 (0%)]	Loss: 15.4937	Cost: 25.62s
Train Epoch: 1620 [20480/90000 (23%)]	Loss: 0.0456	Cost: 6.06s
Train Epoch: 1620 [40960/90000 (45%)]	Loss: -0.0338	Cost: 6.71s
Train Epoch: 1620 [61440/90000 (68%)]	Loss: -0.1065	Cost: 5.93s
Train Epoch: 1620 [81920/90000 (91%)]	Loss: 0.0303	Cost: 6.33s
Train Epoch: 1620 	Average Loss: 1.1622
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.0826

Learning rate: 0.0001998705190029146
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1621 [0/90000 (0%)]	Loss: 15.3108	Cost: 24.15s
Train Epoch: 1621 [20480/90000 (23%)]	Loss: -0.1855	Cost: 6.17s
Train Epoch: 1621 [40960/90000 (45%)]	Loss: -0.2482	Cost: 6.29s
Train Epoch: 1621 [61440/90000 (68%)]	Loss: -0.1060	Cost: 6.11s
Train Epoch: 1621 [81920/90000 (91%)]	Loss: -0.1671	Cost: 6.15s
Train Epoch: 1621 	Average Loss: 0.9346
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1448

Learning rate: 0.0001998703591350532
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1622 [0/90000 (0%)]	Loss: 15.2489	Cost: 26.96s
Train Epoch: 1622 [20480/90000 (23%)]	Loss: -0.0770	Cost: 6.19s
Train Epoch: 1622 [40960/90000 (45%)]	Loss: -0.0883	Cost: 7.08s
Train Epoch: 1622 [61440/90000 (68%)]	Loss: -0.2613	Cost: 6.11s
Train Epoch: 1622 [81920/90000 (91%)]	Loss: -0.2126	Cost: 5.81s
Train Epoch: 1622 	Average Loss: 0.8787
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1995

Learning rate: 0.0001998701991686237
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1623 [0/90000 (0%)]	Loss: 15.5476	Cost: 27.54s
Train Epoch: 1623 [20480/90000 (23%)]	Loss: -0.3320	Cost: 5.99s
Train Epoch: 1623 [40960/90000 (45%)]	Loss: -0.5335	Cost: 6.76s
Train Epoch: 1623 [61440/90000 (68%)]	Loss: 0.1063	Cost: 6.21s
Train Epoch: 1623 [81920/90000 (91%)]	Loss: 0.1280	Cost: 6.25s
Train Epoch: 1623 	Average Loss: 0.8821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1189

Learning rate: 0.00019987003910362623
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1624 [0/90000 (0%)]	Loss: 15.5112	Cost: 22.94s
Train Epoch: 1624 [20480/90000 (23%)]	Loss: -0.0939	Cost: 6.03s
Train Epoch: 1624 [40960/90000 (45%)]	Loss: -0.0554	Cost: 7.92s
Train Epoch: 1624 [61440/90000 (68%)]	Loss: -0.1700	Cost: 5.95s
Train Epoch: 1624 [81920/90000 (91%)]	Loss: -0.3723	Cost: 8.43s
Train Epoch: 1624 	Average Loss: 0.9799
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1491

Learning rate: 0.000199869878940061
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1625 [0/90000 (0%)]	Loss: 15.4262	Cost: 24.15s
Train Epoch: 1625 [20480/90000 (23%)]	Loss: -0.3668	Cost: 6.44s
Train Epoch: 1625 [40960/90000 (45%)]	Loss: -0.4195	Cost: 6.40s
Train Epoch: 1625 [61440/90000 (68%)]	Loss: -0.3085	Cost: 6.00s
Train Epoch: 1625 [81920/90000 (91%)]	Loss: -0.4246	Cost: 6.14s
Train Epoch: 1625 	Average Loss: 0.7528
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1798

Learning rate: 0.00019986971867792816
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1626 [0/90000 (0%)]	Loss: 15.6158	Cost: 24.49s
Train Epoch: 1626 [20480/90000 (23%)]	Loss: -0.2676	Cost: 5.97s
Train Epoch: 1626 [40960/90000 (45%)]	Loss: -0.3804	Cost: 6.86s
Train Epoch: 1626 [61440/90000 (68%)]	Loss: -0.3384	Cost: 5.94s
Train Epoch: 1626 [81920/90000 (91%)]	Loss: -0.2369	Cost: 5.54s
Train Epoch: 1626 	Average Loss: 0.7577
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1908

Learning rate: 0.00019986955831722782
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1627 [0/90000 (0%)]	Loss: 15.6728	Cost: 24.72s
Train Epoch: 1627 [20480/90000 (23%)]	Loss: -0.2553	Cost: 6.15s
Train Epoch: 1627 [40960/90000 (45%)]	Loss: -0.1655	Cost: 6.87s
Train Epoch: 1627 [61440/90000 (68%)]	Loss: -0.1397	Cost: 6.10s
Train Epoch: 1627 [81920/90000 (91%)]	Loss: 0.1730	Cost: 5.74s
Train Epoch: 1627 	Average Loss: 0.8953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1877

Learning rate: 0.0001998693978579602
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1628 [0/90000 (0%)]	Loss: 15.2649	Cost: 29.88s
Train Epoch: 1628 [20480/90000 (23%)]	Loss: -0.4413	Cost: 6.01s
Train Epoch: 1628 [40960/90000 (45%)]	Loss: -0.4457	Cost: 7.59s
Train Epoch: 1628 [61440/90000 (68%)]	Loss: -0.6634	Cost: 6.55s
Train Epoch: 1628 [81920/90000 (91%)]	Loss: -0.5313	Cost: 6.20s
Train Epoch: 1628 	Average Loss: 0.6953
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3087

Learning rate: 0.00019986923730012544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1629 [0/90000 (0%)]	Loss: 15.6237	Cost: 24.86s
Train Epoch: 1629 [20480/90000 (23%)]	Loss: -0.7527	Cost: 5.99s
Train Epoch: 1629 [40960/90000 (45%)]	Loss: -0.7070	Cost: 7.95s
Train Epoch: 1629 [61440/90000 (68%)]	Loss: -0.8459	Cost: 6.10s
Train Epoch: 1629 [81920/90000 (91%)]	Loss: -0.4633	Cost: 7.43s
Train Epoch: 1629 	Average Loss: 0.4969
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2390

Learning rate: 0.00019986907664372368
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1630 [0/90000 (0%)]	Loss: 15.4402	Cost: 23.75s
Train Epoch: 1630 [20480/90000 (23%)]	Loss: -0.6324	Cost: 6.05s
Train Epoch: 1630 [40960/90000 (45%)]	Loss: -0.7286	Cost: 6.69s
Train Epoch: 1630 [61440/90000 (68%)]	Loss: -0.7392	Cost: 6.08s
Train Epoch: 1630 [81920/90000 (91%)]	Loss: -0.6610	Cost: 8.61s
Train Epoch: 1630 	Average Loss: 0.5179
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2449

Learning rate: 0.0001998689158887551
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1631 [0/90000 (0%)]	Loss: 15.4803	Cost: 24.19s
Train Epoch: 1631 [20480/90000 (23%)]	Loss: -0.7768	Cost: 6.15s
Train Epoch: 1631 [40960/90000 (45%)]	Loss: -0.5798	Cost: 7.32s
Train Epoch: 1631 [61440/90000 (68%)]	Loss: -0.7356	Cost: 5.94s
Train Epoch: 1631 [81920/90000 (91%)]	Loss: -0.4948	Cost: 5.68s
Train Epoch: 1631 	Average Loss: 0.4238
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3637

Learning rate: 0.00019986875503521986
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1632 [0/90000 (0%)]	Loss: 15.4802	Cost: 22.69s
Train Epoch: 1632 [20480/90000 (23%)]	Loss: -0.8547	Cost: 5.95s
Train Epoch: 1632 [40960/90000 (45%)]	Loss: -0.8499	Cost: 7.76s
Train Epoch: 1632 [61440/90000 (68%)]	Loss: -0.9676	Cost: 6.05s
Train Epoch: 1632 [81920/90000 (91%)]	Loss: -0.8274	Cost: 6.63s
Train Epoch: 1632 	Average Loss: 0.3769
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3934

Learning rate: 0.0001998685940831181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1633 [0/90000 (0%)]	Loss: 15.6316	Cost: 27.18s
Train Epoch: 1633 [20480/90000 (23%)]	Loss: -0.8705	Cost: 6.09s
Train Epoch: 1633 [40960/90000 (45%)]	Loss: -0.7242	Cost: 7.29s
Train Epoch: 1633 [61440/90000 (68%)]	Loss: -0.6253	Cost: 5.99s
Train Epoch: 1633 [81920/90000 (91%)]	Loss: -0.5146	Cost: 5.89s
Train Epoch: 1633 	Average Loss: 0.4727
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5096

Learning rate: 0.00019986843303245
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1634 [0/90000 (0%)]	Loss: 15.8728	Cost: 27.41s
Train Epoch: 1634 [20480/90000 (23%)]	Loss: -0.6748	Cost: 6.14s
Train Epoch: 1634 [40960/90000 (45%)]	Loss: -0.3202	Cost: 7.11s
Train Epoch: 1634 [61440/90000 (68%)]	Loss: -0.7223	Cost: 6.10s
Train Epoch: 1634 [81920/90000 (91%)]	Loss: -0.3332	Cost: 5.78s
Train Epoch: 1634 	Average Loss: 0.5722
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4123

Learning rate: 0.00019986827188321572
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1635 [0/90000 (0%)]	Loss: 15.7217	Cost: 22.73s
Train Epoch: 1635 [20480/90000 (23%)]	Loss: -0.5314	Cost: 6.09s
Train Epoch: 1635 [40960/90000 (45%)]	Loss: -0.5359	Cost: 6.53s
Train Epoch: 1635 [61440/90000 (68%)]	Loss: -0.8586	Cost: 6.13s
Train Epoch: 1635 [81920/90000 (91%)]	Loss: -0.4108	Cost: 9.21s
Train Epoch: 1635 	Average Loss: 0.6016
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3663

Learning rate: 0.00019986811063541537
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1636 [0/90000 (0%)]	Loss: 15.4291	Cost: 25.08s
Train Epoch: 1636 [20480/90000 (23%)]	Loss: -0.6861	Cost: 6.00s
Train Epoch: 1636 [40960/90000 (45%)]	Loss: -0.8070	Cost: 7.15s
Train Epoch: 1636 [61440/90000 (68%)]	Loss: -0.8424	Cost: 5.90s
Train Epoch: 1636 [81920/90000 (91%)]	Loss: -0.6358	Cost: 5.82s
Train Epoch: 1636 	Average Loss: 0.5180
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4173

Learning rate: 0.00019986794928904917
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1637 [0/90000 (0%)]	Loss: 15.4637	Cost: 22.69s
Train Epoch: 1637 [20480/90000 (23%)]	Loss: -0.7790	Cost: 6.02s
Train Epoch: 1637 [40960/90000 (45%)]	Loss: -0.9926	Cost: 6.71s
Train Epoch: 1637 [61440/90000 (68%)]	Loss: -0.9349	Cost: 6.21s
Train Epoch: 1637 [81920/90000 (91%)]	Loss: -0.6668	Cost: 6.22s
Train Epoch: 1637 	Average Loss: 0.3618
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3800

Learning rate: 0.00019986778784411726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1638 [0/90000 (0%)]	Loss: 15.6648	Cost: 26.14s
Train Epoch: 1638 [20480/90000 (23%)]	Loss: -0.7296	Cost: 6.09s
Train Epoch: 1638 [40960/90000 (45%)]	Loss: -0.6669	Cost: 7.26s
Train Epoch: 1638 [61440/90000 (68%)]	Loss: -0.5254	Cost: 5.89s
Train Epoch: 1638 [81920/90000 (91%)]	Loss: 0.1168	Cost: 5.86s
Train Epoch: 1638 	Average Loss: 0.6927
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3506

Learning rate: 0.00019986762630061977
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1639 [0/90000 (0%)]	Loss: 15.8841	Cost: 29.21s
Train Epoch: 1639 [20480/90000 (23%)]	Loss: 0.0921	Cost: 6.17s
Train Epoch: 1639 [40960/90000 (45%)]	Loss: -0.0815	Cost: 6.86s
Train Epoch: 1639 [61440/90000 (68%)]	Loss: -0.5511	Cost: 6.09s
Train Epoch: 1639 [81920/90000 (91%)]	Loss: -0.4807	Cost: 5.93s
Train Epoch: 1639 	Average Loss: 0.9281
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2038

Learning rate: 0.0001998674646585569
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1640 [0/90000 (0%)]	Loss: 15.5606	Cost: 23.12s
Train Epoch: 1640 [20480/90000 (23%)]	Loss: -0.5438	Cost: 6.09s
Train Epoch: 1640 [40960/90000 (45%)]	Loss: -0.5404	Cost: 7.88s
Train Epoch: 1640 [61440/90000 (68%)]	Loss: -0.4643	Cost: 5.94s
Train Epoch: 1640 [81920/90000 (91%)]	Loss: -0.3564	Cost: 8.27s
Train Epoch: 1640 	Average Loss: 0.6680
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4299

Learning rate: 0.00019986730291792875
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1641 [0/90000 (0%)]	Loss: 15.8560	Cost: 23.74s
Train Epoch: 1641 [20480/90000 (23%)]	Loss: -0.4848	Cost: 6.02s
Train Epoch: 1641 [40960/90000 (45%)]	Loss: -0.6459	Cost: 6.63s
Train Epoch: 1641 [61440/90000 (68%)]	Loss: -0.7371	Cost: 6.12s
Train Epoch: 1641 [81920/90000 (91%)]	Loss: -0.5607	Cost: 6.53s
Train Epoch: 1641 	Average Loss: 0.5869
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3687

Learning rate: 0.00019986714107873558
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1642 [0/90000 (0%)]	Loss: 15.5029	Cost: 23.67s
Train Epoch: 1642 [20480/90000 (23%)]	Loss: -0.5161	Cost: 6.19s
Train Epoch: 1642 [40960/90000 (45%)]	Loss: -0.6421	Cost: 7.18s
Train Epoch: 1642 [61440/90000 (68%)]	Loss: -0.7848	Cost: 6.01s
Train Epoch: 1642 [81920/90000 (91%)]	Loss: -0.4597	Cost: 6.01s
Train Epoch: 1642 	Average Loss: 0.5485
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3984

Learning rate: 0.00019986697914097749
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1643 [0/90000 (0%)]	Loss: 15.6261	Cost: 25.72s
Train Epoch: 1643 [20480/90000 (23%)]	Loss: -0.6476	Cost: 6.11s
Train Epoch: 1643 [40960/90000 (45%)]	Loss: -0.5424	Cost: 6.30s
Train Epoch: 1643 [61440/90000 (68%)]	Loss: -0.7938	Cost: 6.18s
Train Epoch: 1643 [81920/90000 (91%)]	Loss: -0.4456	Cost: 5.54s
Train Epoch: 1643 	Average Loss: 0.5762
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4253

Learning rate: 0.0001998668171046546
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1644 [0/90000 (0%)]	Loss: 15.9229	Cost: 28.30s
Train Epoch: 1644 [20480/90000 (23%)]	Loss: -0.8780	Cost: 6.04s
Train Epoch: 1644 [40960/90000 (45%)]	Loss: -0.7315	Cost: 6.93s
Train Epoch: 1644 [61440/90000 (68%)]	Loss: -0.9564	Cost: 6.13s
Train Epoch: 1644 [81920/90000 (91%)]	Loss: -0.4147	Cost: 5.76s
Train Epoch: 1644 	Average Loss: 0.4339
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3855

Learning rate: 0.00019986665496976716
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1645 [0/90000 (0%)]	Loss: 15.6825	Cost: 25.82s
Train Epoch: 1645 [20480/90000 (23%)]	Loss: -0.3440	Cost: 6.08s
Train Epoch: 1645 [40960/90000 (45%)]	Loss: -0.6092	Cost: 7.64s
Train Epoch: 1645 [61440/90000 (68%)]	Loss: -0.7109	Cost: 5.89s
Train Epoch: 1645 [81920/90000 (91%)]	Loss: -0.5678	Cost: 7.58s
Train Epoch: 1645 	Average Loss: 0.5594
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4597

Learning rate: 0.00019986649273631525
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1646 [0/90000 (0%)]	Loss: 15.7937	Cost: 23.44s
Train Epoch: 1646 [20480/90000 (23%)]	Loss: -0.5689	Cost: 6.12s
Train Epoch: 1646 [40960/90000 (45%)]	Loss: -0.7851	Cost: 6.26s
Train Epoch: 1646 [61440/90000 (68%)]	Loss: -0.8735	Cost: 6.12s
Train Epoch: 1646 [81920/90000 (91%)]	Loss: -0.6950	Cost: 8.20s
Train Epoch: 1646 	Average Loss: 0.4412
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4288

Learning rate: 0.00019986633040429907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1647 [0/90000 (0%)]	Loss: 15.5689	Cost: 23.88s
Train Epoch: 1647 [20480/90000 (23%)]	Loss: -0.7518	Cost: 6.23s
Train Epoch: 1647 [40960/90000 (45%)]	Loss: -0.6373	Cost: 6.86s
Train Epoch: 1647 [61440/90000 (68%)]	Loss: -0.6177	Cost: 5.89s
Train Epoch: 1647 [81920/90000 (91%)]	Loss: -0.6971	Cost: 5.84s
Train Epoch: 1647 	Average Loss: 0.4445
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4102

Learning rate: 0.0001998661679737188
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1648 [0/90000 (0%)]	Loss: 15.5491	Cost: 23.82s
Train Epoch: 1648 [20480/90000 (23%)]	Loss: -0.3080	Cost: 5.90s
Train Epoch: 1648 [40960/90000 (45%)]	Loss: -0.4667	Cost: 6.67s
Train Epoch: 1648 [61440/90000 (68%)]	Loss: -0.6608	Cost: 6.11s
Train Epoch: 1648 [81920/90000 (91%)]	Loss: -0.5285	Cost: 5.55s
Train Epoch: 1648 	Average Loss: 0.6122
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3950

Learning rate: 0.00019986600544457455
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1649 [0/90000 (0%)]	Loss: 15.5209	Cost: 29.53s
Train Epoch: 1649 [20480/90000 (23%)]	Loss: -0.6659	Cost: 6.09s
Train Epoch: 1649 [40960/90000 (45%)]	Loss: -0.7521	Cost: 7.51s
Train Epoch: 1649 [61440/90000 (68%)]	Loss: -0.8660	Cost: 5.90s
Train Epoch: 1649 [81920/90000 (91%)]	Loss: -0.7486	Cost: 6.31s
Train Epoch: 1649 	Average Loss: 0.4568
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3255

Learning rate: 0.0001998658428168665
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1650 [0/90000 (0%)]	Loss: 15.8366	Cost: 24.52s
Train Epoch: 1650 [20480/90000 (23%)]	Loss: -0.6942	Cost: 6.03s
Train Epoch: 1650 [40960/90000 (45%)]	Loss: -0.7213	Cost: 7.63s
Train Epoch: 1650 [61440/90000 (68%)]	Loss: -0.9557	Cost: 6.04s
Train Epoch: 1650 [81920/90000 (91%)]	Loss: -0.7037	Cost: 6.84s
Train Epoch: 1650 	Average Loss: 0.3501
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4233

Learning rate: 0.00019986568009059481
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1651 [0/90000 (0%)]	Loss: 15.7250	Cost: 24.43s
Train Epoch: 1651 [20480/90000 (23%)]	Loss: -1.0638	Cost: 6.38s
Train Epoch: 1651 [40960/90000 (45%)]	Loss: -0.6104	Cost: 6.29s
Train Epoch: 1651 [61440/90000 (68%)]	Loss: -0.5560	Cost: 6.17s
Train Epoch: 1651 [81920/90000 (91%)]	Loss: -0.3930	Cost: 8.40s
Train Epoch: 1651 	Average Loss: 0.4242
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3987

Learning rate: 0.00019986551726575966
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1652 [0/90000 (0%)]	Loss: 15.6324	Cost: 23.58s
Train Epoch: 1652 [20480/90000 (23%)]	Loss: -0.6643	Cost: 6.19s
Train Epoch: 1652 [40960/90000 (45%)]	Loss: -0.5946	Cost: 6.92s
Train Epoch: 1652 [61440/90000 (68%)]	Loss: -0.8235	Cost: 5.98s
Train Epoch: 1652 [81920/90000 (91%)]	Loss: -0.6989	Cost: 5.85s
Train Epoch: 1652 	Average Loss: 0.4810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4969

Learning rate: 0.00019986535434236117
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1653 [0/90000 (0%)]	Loss: 15.5186	Cost: 23.13s
Train Epoch: 1653 [20480/90000 (23%)]	Loss: -0.7650	Cost: 6.10s
Train Epoch: 1653 [40960/90000 (45%)]	Loss: -0.7950	Cost: 7.32s
Train Epoch: 1653 [61440/90000 (68%)]	Loss: -1.0002	Cost: 6.29s
Train Epoch: 1653 [81920/90000 (91%)]	Loss: -0.8782	Cost: 6.10s
Train Epoch: 1653 	Average Loss: 0.3181
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5490

Learning rate: 0.00019986519132039954
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1654 [0/90000 (0%)]	Loss: 15.8193	Cost: 26.35s
Train Epoch: 1654 [20480/90000 (23%)]	Loss: -0.9342	Cost: 6.10s
Train Epoch: 1654 [40960/90000 (45%)]	Loss: -0.8485	Cost: 6.89s
Train Epoch: 1654 [61440/90000 (68%)]	Loss: -0.4530	Cost: 5.92s
Train Epoch: 1654 [81920/90000 (91%)]	Loss: -0.3117	Cost: 6.07s
Train Epoch: 1654 	Average Loss: 0.4835
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3820

Learning rate: 0.00019986502819987491
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1655 [0/90000 (0%)]	Loss: 15.6768	Cost: 27.00s
Train Epoch: 1655 [20480/90000 (23%)]	Loss: -0.7172	Cost: 6.08s
Train Epoch: 1655 [40960/90000 (45%)]	Loss: -0.7043	Cost: 8.18s
Train Epoch: 1655 [61440/90000 (68%)]	Loss: -1.0779	Cost: 6.09s
Train Epoch: 1655 [81920/90000 (91%)]	Loss: -0.6816	Cost: 7.16s
Train Epoch: 1655 	Average Loss: 0.4654
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4435

Learning rate: 0.00019986486498078747
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1656 [0/90000 (0%)]	Loss: 15.8692	Cost: 22.81s
Train Epoch: 1656 [20480/90000 (23%)]	Loss: -0.8851	Cost: 6.13s
Train Epoch: 1656 [40960/90000 (45%)]	Loss: -0.9230	Cost: 6.76s
Train Epoch: 1656 [61440/90000 (68%)]	Loss: -1.1528	Cost: 6.01s
Train Epoch: 1656 [81920/90000 (91%)]	Loss: -0.9523	Cost: 8.58s
Train Epoch: 1656 	Average Loss: 0.2509
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5283

Learning rate: 0.00019986470166313735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1657 [0/90000 (0%)]	Loss: 15.7803	Cost: 24.47s
Train Epoch: 1657 [20480/90000 (23%)]	Loss: -0.6521	Cost: 6.18s
Train Epoch: 1657 [40960/90000 (45%)]	Loss: -0.7682	Cost: 6.64s
Train Epoch: 1657 [61440/90000 (68%)]	Loss: -0.9510	Cost: 5.90s
Train Epoch: 1657 [81920/90000 (91%)]	Loss: -0.7388	Cost: 5.88s
Train Epoch: 1657 	Average Loss: 0.3520
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5018

Learning rate: 0.00019986453824692474
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1658 [0/90000 (0%)]	Loss: 15.5774	Cost: 23.41s
Train Epoch: 1658 [20480/90000 (23%)]	Loss: -0.6425	Cost: 6.12s
Train Epoch: 1658 [40960/90000 (45%)]	Loss: -0.5645	Cost: 6.32s
Train Epoch: 1658 [61440/90000 (68%)]	Loss: -0.6753	Cost: 6.21s
Train Epoch: 1658 [81920/90000 (91%)]	Loss: -0.7319	Cost: 6.22s
Train Epoch: 1658 	Average Loss: 0.4723
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5197

Learning rate: 0.00019986437473214973
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1659 [0/90000 (0%)]	Loss: 15.8396	Cost: 26.35s
Train Epoch: 1659 [20480/90000 (23%)]	Loss: -0.5508	Cost: 5.99s
Train Epoch: 1659 [40960/90000 (45%)]	Loss: -0.5979	Cost: 7.30s
Train Epoch: 1659 [61440/90000 (68%)]	Loss: -0.7467	Cost: 6.01s
Train Epoch: 1659 [81920/90000 (91%)]	Loss: -0.5023	Cost: 5.77s
Train Epoch: 1659 	Average Loss: 0.5697
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4472

Learning rate: 0.00019986421111881257
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1660 [0/90000 (0%)]	Loss: 15.6017	Cost: 28.98s
Train Epoch: 1660 [20480/90000 (23%)]	Loss: -0.4004	Cost: 6.11s
Train Epoch: 1660 [40960/90000 (45%)]	Loss: -0.6671	Cost: 6.72s
Train Epoch: 1660 [61440/90000 (68%)]	Loss: -0.8615	Cost: 6.48s
Train Epoch: 1660 [81920/90000 (91%)]	Loss: -0.4931	Cost: 6.19s
Train Epoch: 1660 	Average Loss: 0.5076
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3332

Learning rate: 0.00019986404740691337
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1661 [0/90000 (0%)]	Loss: 15.3089	Cost: 25.44s
Train Epoch: 1661 [20480/90000 (23%)]	Loss: -0.4985	Cost: 6.03s
Train Epoch: 1661 [40960/90000 (45%)]	Loss: -0.6702	Cost: 8.15s
Train Epoch: 1661 [61440/90000 (68%)]	Loss: -0.9348	Cost: 5.89s
Train Epoch: 1661 [81920/90000 (91%)]	Loss: -0.9235	Cost: 7.78s
Train Epoch: 1661 	Average Loss: 0.4591
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4200

Learning rate: 0.00019986388359645232
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1662 [0/90000 (0%)]	Loss: 15.6350	Cost: 22.82s
Train Epoch: 1662 [20480/90000 (23%)]	Loss: -0.7850	Cost: 6.10s
Train Epoch: 1662 [40960/90000 (45%)]	Loss: -0.9749	Cost: 6.18s
Train Epoch: 1662 [61440/90000 (68%)]	Loss: -0.9612	Cost: 6.16s
Train Epoch: 1662 [81920/90000 (91%)]	Loss: -0.7691	Cost: 7.57s
Train Epoch: 1662 	Average Loss: 0.2737
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4712

Learning rate: 0.00019986371968742957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1663 [0/90000 (0%)]	Loss: 15.5291	Cost: 24.53s
Train Epoch: 1663 [20480/90000 (23%)]	Loss: -0.9642	Cost: 6.16s
Train Epoch: 1663 [40960/90000 (45%)]	Loss: -0.5029	Cost: 6.95s
Train Epoch: 1663 [61440/90000 (68%)]	Loss: -0.6419	Cost: 5.85s
Train Epoch: 1663 [81920/90000 (91%)]	Loss: -0.4815	Cost: 6.16s
Train Epoch: 1663 	Average Loss: 0.4653
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4310

Learning rate: 0.00019986355567984526
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1664 [0/90000 (0%)]	Loss: 15.5817	Cost: 23.72s
Train Epoch: 1664 [20480/90000 (23%)]	Loss: -0.4360	Cost: 5.90s
Train Epoch: 1664 [40960/90000 (45%)]	Loss: -0.5900	Cost: 7.53s
Train Epoch: 1664 [61440/90000 (68%)]	Loss: -0.8334	Cost: 6.08s
Train Epoch: 1664 [81920/90000 (91%)]	Loss: -0.7700	Cost: 5.89s
Train Epoch: 1664 	Average Loss: 0.5109
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3428

Learning rate: 0.00019986339157369957
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1665 [0/90000 (0%)]	Loss: 15.6730	Cost: 27.36s
Train Epoch: 1665 [20480/90000 (23%)]	Loss: -0.8585	Cost: 6.00s
Train Epoch: 1665 [40960/90000 (45%)]	Loss: -0.7939	Cost: 6.98s
Train Epoch: 1665 [61440/90000 (68%)]	Loss: -1.0455	Cost: 6.02s
Train Epoch: 1665 [81920/90000 (91%)]	Loss: -0.6969	Cost: 5.81s
Train Epoch: 1665 	Average Loss: 0.3136
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4672

Learning rate: 0.00019986322736899266
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1666 [0/90000 (0%)]	Loss: 15.9299	Cost: 27.94s
Train Epoch: 1666 [20480/90000 (23%)]	Loss: -1.0055	Cost: 6.08s
Train Epoch: 1666 [40960/90000 (45%)]	Loss: -0.8517	Cost: 7.42s
Train Epoch: 1666 [61440/90000 (68%)]	Loss: -0.9805	Cost: 6.07s
Train Epoch: 1666 [81920/90000 (91%)]	Loss: -0.7645	Cost: 6.88s
Train Epoch: 1666 	Average Loss: 0.3186
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4237

Learning rate: 0.00019986306306572473
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1667 [0/90000 (0%)]	Loss: 15.6769	Cost: 23.06s
Train Epoch: 1667 [20480/90000 (23%)]	Loss: -0.8751	Cost: 6.08s
Train Epoch: 1667 [40960/90000 (45%)]	Loss: -0.8592	Cost: 7.41s
Train Epoch: 1667 [61440/90000 (68%)]	Loss: -1.2080	Cost: 6.01s
Train Epoch: 1667 [81920/90000 (91%)]	Loss: -1.0924	Cost: 8.34s
Train Epoch: 1667 	Average Loss: 0.2544
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4918

Learning rate: 0.00019986289866389585
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1668 [0/90000 (0%)]	Loss: 15.5659	Cost: 23.20s
Train Epoch: 1668 [20480/90000 (23%)]	Loss: -1.0648	Cost: 6.15s
Train Epoch: 1668 [40960/90000 (45%)]	Loss: -1.1475	Cost: 6.81s
Train Epoch: 1668 [61440/90000 (68%)]	Loss: -1.1919	Cost: 6.03s
Train Epoch: 1668 [81920/90000 (91%)]	Loss: -0.9351	Cost: 5.79s
Train Epoch: 1668 	Average Loss: 0.1524
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5774

Learning rate: 0.00019986273416350628
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1669 [0/90000 (0%)]	Loss: 15.4855	Cost: 23.22s
Train Epoch: 1669 [20480/90000 (23%)]	Loss: -1.0564	Cost: 6.11s
Train Epoch: 1669 [40960/90000 (45%)]	Loss: -0.7827	Cost: 6.93s
Train Epoch: 1669 [61440/90000 (68%)]	Loss: -1.0023	Cost: 6.02s
Train Epoch: 1669 [81920/90000 (91%)]	Loss: -0.7643	Cost: 7.06s
Train Epoch: 1669 	Average Loss: 0.2948
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4502

Learning rate: 0.00019986256956455614
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1670 [0/90000 (0%)]	Loss: 15.6385	Cost: 25.86s
Train Epoch: 1670 [20480/90000 (23%)]	Loss: -0.9415	Cost: 6.07s
Train Epoch: 1670 [40960/90000 (45%)]	Loss: -0.9758	Cost: 6.93s
Train Epoch: 1670 [61440/90000 (68%)]	Loss: -1.0020	Cost: 5.93s
Train Epoch: 1670 [81920/90000 (91%)]	Loss: -1.2060	Cost: 5.79s
Train Epoch: 1670 	Average Loss: 0.1882
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3924

Learning rate: 0.0001998624048670456
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1671 [0/90000 (0%)]	Loss: 15.9307	Cost: 28.38s
Train Epoch: 1671 [20480/90000 (23%)]	Loss: -1.0764	Cost: 6.17s
Train Epoch: 1671 [40960/90000 (45%)]	Loss: -1.0575	Cost: 6.84s
Train Epoch: 1671 [61440/90000 (68%)]	Loss: -1.2241	Cost: 5.95s
Train Epoch: 1671 [81920/90000 (91%)]	Loss: -1.0891	Cost: 5.75s
Train Epoch: 1671 	Average Loss: 0.1649
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6059

Learning rate: 0.00019986224007097482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1672 [0/90000 (0%)]	Loss: 15.9308	Cost: 24.66s
Train Epoch: 1672 [20480/90000 (23%)]	Loss: -0.9040	Cost: 6.07s
Train Epoch: 1672 [40960/90000 (45%)]	Loss: -0.7908	Cost: 7.68s
Train Epoch: 1672 [61440/90000 (68%)]	Loss: -0.9781	Cost: 5.91s
Train Epoch: 1672 [81920/90000 (91%)]	Loss: -0.8944	Cost: 7.89s
Train Epoch: 1672 	Average Loss: 0.2894
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6146

Learning rate: 0.00019986207517634394
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1673 [0/90000 (0%)]	Loss: 15.6105	Cost: 24.12s
Train Epoch: 1673 [20480/90000 (23%)]	Loss: -1.0570	Cost: 5.87s
Train Epoch: 1673 [40960/90000 (45%)]	Loss: -1.2059	Cost: 6.30s
Train Epoch: 1673 [61440/90000 (68%)]	Loss: -1.2361	Cost: 5.98s
Train Epoch: 1673 [81920/90000 (91%)]	Loss: -0.9653	Cost: 6.00s
Train Epoch: 1673 	Average Loss: 0.1588
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5302

Learning rate: 0.00019986191018315315
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1674 [0/90000 (0%)]	Loss: 15.8484	Cost: 24.45s
Train Epoch: 1674 [20480/90000 (23%)]	Loss: -0.8821	Cost: 6.13s
Train Epoch: 1674 [40960/90000 (45%)]	Loss: -1.1028	Cost: 7.31s
Train Epoch: 1674 [61440/90000 (68%)]	Loss: -1.2162	Cost: 5.88s
Train Epoch: 1674 [81920/90000 (91%)]	Loss: -1.1681	Cost: 6.50s
Train Epoch: 1674 	Average Loss: 0.0796
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6132

Learning rate: 0.0001998617450914026
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1675 [0/90000 (0%)]	Loss: 15.5322	Cost: 24.84s
Train Epoch: 1675 [20480/90000 (23%)]	Loss: -1.2055	Cost: 6.19s
Train Epoch: 1675 [40960/90000 (45%)]	Loss: -0.9898	Cost: 6.29s
Train Epoch: 1675 [61440/90000 (68%)]	Loss: -1.2736	Cost: 6.12s
Train Epoch: 1675 [81920/90000 (91%)]	Loss: -1.3029	Cost: 5.73s
Train Epoch: 1675 	Average Loss: 0.0191
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6334

Learning rate: 0.00019986157990109244
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1676 [0/90000 (0%)]	Loss: 15.6346	Cost: 29.57s
Train Epoch: 1676 [20480/90000 (23%)]	Loss: -1.0287	Cost: 6.15s
Train Epoch: 1676 [40960/90000 (45%)]	Loss: -1.1952	Cost: 8.59s
Train Epoch: 1676 [61440/90000 (68%)]	Loss: -1.1605	Cost: 5.79s
Train Epoch: 1676 [81920/90000 (91%)]	Loss: -1.2774	Cost: 7.15s
Train Epoch: 1676 	Average Loss: 0.0231
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6269

Learning rate: 0.00019986141461222288
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1677 [0/90000 (0%)]	Loss: 15.7614	Cost: 24.53s
Train Epoch: 1677 [20480/90000 (23%)]	Loss: -1.2320	Cost: 6.03s
Train Epoch: 1677 [40960/90000 (45%)]	Loss: -1.2161	Cost: 8.04s
Train Epoch: 1677 [61440/90000 (68%)]	Loss: -1.2290	Cost: 5.96s
Train Epoch: 1677 [81920/90000 (91%)]	Loss: -1.1026	Cost: 7.49s
Train Epoch: 1677 	Average Loss: 0.0235
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6545

Learning rate: 0.00019986124922479406
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1678 [0/90000 (0%)]	Loss: 15.9445	Cost: 23.47s
Train Epoch: 1678 [20480/90000 (23%)]	Loss: -0.9469	Cost: 6.17s
Train Epoch: 1678 [40960/90000 (45%)]	Loss: -1.0844	Cost: 6.42s
Train Epoch: 1678 [61440/90000 (68%)]	Loss: -1.2538	Cost: 6.18s
Train Epoch: 1678 [81920/90000 (91%)]	Loss: -1.1561	Cost: 7.47s
Train Epoch: 1678 	Average Loss: 0.1517
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5449

Learning rate: 0.0001998610837388061
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1679 [0/90000 (0%)]	Loss: 16.0423	Cost: 23.78s
Train Epoch: 1679 [20480/90000 (23%)]	Loss: -1.3410	Cost: 6.04s
Train Epoch: 1679 [40960/90000 (45%)]	Loss: -1.2091	Cost: 6.54s
Train Epoch: 1679 [61440/90000 (68%)]	Loss: -1.2826	Cost: 6.10s
Train Epoch: 1679 [81920/90000 (91%)]	Loss: -1.0926	Cost: 5.83s
Train Epoch: 1679 	Average Loss: 0.0263
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6403

Learning rate: 0.00019986091815425925
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1680 [0/90000 (0%)]	Loss: 15.1851	Cost: 24.68s
Train Epoch: 1680 [20480/90000 (23%)]	Loss: -1.0133	Cost: 6.04s
Train Epoch: 1680 [40960/90000 (45%)]	Loss: -0.9420	Cost: 6.64s
Train Epoch: 1680 [61440/90000 (68%)]	Loss: -1.1618	Cost: 6.05s
Train Epoch: 1680 [81920/90000 (91%)]	Loss: -1.0453	Cost: 7.09s
Train Epoch: 1680 	Average Loss: 0.1958
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6031

Learning rate: 0.00019986075247115358
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1681 [0/90000 (0%)]	Loss: 15.6674	Cost: 29.30s
Train Epoch: 1681 [20480/90000 (23%)]	Loss: -1.1700	Cost: 6.13s
Train Epoch: 1681 [40960/90000 (45%)]	Loss: -0.9975	Cost: 7.03s
Train Epoch: 1681 [61440/90000 (68%)]	Loss: -1.2222	Cost: 5.97s
Train Epoch: 1681 [81920/90000 (91%)]	Loss: -1.1707	Cost: 6.29s
Train Epoch: 1681 	Average Loss: 0.1074
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5760

Learning rate: 0.00019986058668948934
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1682 [0/90000 (0%)]	Loss: 15.8728	Cost: 25.01s
Train Epoch: 1682 [20480/90000 (23%)]	Loss: -1.1664	Cost: 6.09s
Train Epoch: 1682 [40960/90000 (45%)]	Loss: -0.9304	Cost: 9.22s
Train Epoch: 1682 [61440/90000 (68%)]	Loss: -1.0130	Cost: 5.87s
Train Epoch: 1682 [81920/90000 (91%)]	Loss: -0.8118	Cost: 7.81s
Train Epoch: 1682 	Average Loss: 0.2028
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4855

Learning rate: 0.00019986042080926664
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1683 [0/90000 (0%)]	Loss: 15.8325	Cost: 21.86s
Train Epoch: 1683 [20480/90000 (23%)]	Loss: -1.0557	Cost: 6.04s
Train Epoch: 1683 [40960/90000 (45%)]	Loss: -0.8571	Cost: 6.78s
Train Epoch: 1683 [61440/90000 (68%)]	Loss: -0.7556	Cost: 6.00s
Train Epoch: 1683 [81920/90000 (91%)]	Loss: -0.8516	Cost: 8.86s
Train Epoch: 1683 	Average Loss: 0.2821
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5703

Learning rate: 0.00019986025483048563
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1684 [0/90000 (0%)]	Loss: 15.9502	Cost: 24.17s
Train Epoch: 1684 [20480/90000 (23%)]	Loss: -0.7921	Cost: 6.10s
Train Epoch: 1684 [40960/90000 (45%)]	Loss: -0.8131	Cost: 6.31s
Train Epoch: 1684 [61440/90000 (68%)]	Loss: -1.0145	Cost: 5.88s
Train Epoch: 1684 [81920/90000 (91%)]	Loss: -0.9986	Cost: 5.73s
Train Epoch: 1684 	Average Loss: 0.2823
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6375

Learning rate: 0.00019986008875314652
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1685 [0/90000 (0%)]	Loss: 15.8456	Cost: 23.99s
Train Epoch: 1685 [20480/90000 (23%)]	Loss: -1.2143	Cost: 6.31s
Train Epoch: 1685 [40960/90000 (45%)]	Loss: -1.1228	Cost: 7.34s
Train Epoch: 1685 [61440/90000 (68%)]	Loss: -1.1251	Cost: 6.10s
Train Epoch: 1685 [81920/90000 (91%)]	Loss: -1.1244	Cost: 6.61s
Train Epoch: 1685 	Average Loss: 0.1140
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6764

Learning rate: 0.00019985992257724942
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1686 [0/90000 (0%)]	Loss: 16.0861	Cost: 26.33s
Train Epoch: 1686 [20480/90000 (23%)]	Loss: -1.2133	Cost: 6.05s
Train Epoch: 1686 [40960/90000 (45%)]	Loss: -0.7170	Cost: 7.41s
Train Epoch: 1686 [61440/90000 (68%)]	Loss: -0.9394	Cost: 5.85s
Train Epoch: 1686 [81920/90000 (91%)]	Loss: -0.9881	Cost: 6.47s
Train Epoch: 1686 	Average Loss: 0.1726
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5791

Learning rate: 0.00019985975630279455
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1687 [0/90000 (0%)]	Loss: 16.1305	Cost: 24.58s
Train Epoch: 1687 [20480/90000 (23%)]	Loss: -0.7224	Cost: 6.10s
Train Epoch: 1687 [40960/90000 (45%)]	Loss: -0.4385	Cost: 7.67s
Train Epoch: 1687 [61440/90000 (68%)]	Loss: -0.6877	Cost: 5.99s
Train Epoch: 1687 [81920/90000 (91%)]	Loss: -0.5550	Cost: 6.49s
Train Epoch: 1687 	Average Loss: 0.4891
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5244

Learning rate: 0.00019985958992978207
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1688 [0/90000 (0%)]	Loss: 15.8578	Cost: 23.01s
Train Epoch: 1688 [20480/90000 (23%)]	Loss: -0.6068	Cost: 5.92s
Train Epoch: 1688 [40960/90000 (45%)]	Loss: -0.6760	Cost: 6.59s
Train Epoch: 1688 [61440/90000 (68%)]	Loss: -0.8372	Cost: 6.06s
Train Epoch: 1688 [81920/90000 (91%)]	Loss: -1.1779	Cost: 8.11s
Train Epoch: 1688 	Average Loss: 0.4949
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6526

Learning rate: 0.00019985942345821208
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1689 [0/90000 (0%)]	Loss: 15.7216	Cost: 24.11s
Train Epoch: 1689 [20480/90000 (23%)]	Loss: -1.0090	Cost: 6.17s
Train Epoch: 1689 [40960/90000 (45%)]	Loss: -0.3294	Cost: 6.88s
Train Epoch: 1689 [61440/90000 (68%)]	Loss: -0.6924	Cost: 5.97s
Train Epoch: 1689 [81920/90000 (91%)]	Loss: -0.4888	Cost: 6.11s
Train Epoch: 1689 	Average Loss: 0.5300
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4730

Learning rate: 0.00019985925688808482
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1690 [0/90000 (0%)]	Loss: 15.5682	Cost: 22.77s
Train Epoch: 1690 [20480/90000 (23%)]	Loss: -0.5662	Cost: 6.00s
Train Epoch: 1690 [40960/90000 (45%)]	Loss: -1.0224	Cost: 8.60s
Train Epoch: 1690 [61440/90000 (68%)]	Loss: -0.7790	Cost: 5.95s
Train Epoch: 1690 [81920/90000 (91%)]	Loss: -1.0117	Cost: 6.58s
Train Epoch: 1690 	Average Loss: 0.3826
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.4374

Learning rate: 0.00019985909021940043
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1691 [0/90000 (0%)]	Loss: 15.8531	Cost: 27.25s
Train Epoch: 1691 [20480/90000 (23%)]	Loss: -0.9447	Cost: 6.06s
Train Epoch: 1691 [40960/90000 (45%)]	Loss: -0.8464	Cost: 7.33s
Train Epoch: 1691 [61440/90000 (68%)]	Loss: -1.1339	Cost: 5.87s
Train Epoch: 1691 [81920/90000 (91%)]	Loss: -0.8705	Cost: 5.82s
Train Epoch: 1691 	Average Loss: 0.2513
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6883

Learning rate: 0.00019985892345215906
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1692 [0/90000 (0%)]	Loss: 16.1186	Cost: 29.21s
Train Epoch: 1692 [20480/90000 (23%)]	Loss: -0.8283	Cost: 6.08s
Train Epoch: 1692 [40960/90000 (45%)]	Loss: -1.0364	Cost: 6.98s
Train Epoch: 1692 [61440/90000 (68%)]	Loss: -1.0863	Cost: 6.13s
Train Epoch: 1692 [81920/90000 (91%)]	Loss: -0.7651	Cost: 6.26s
Train Epoch: 1692 	Average Loss: 0.2669
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5846

Learning rate: 0.00019985875658636091
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1693 [0/90000 (0%)]	Loss: 15.8541	Cost: 23.85s
Train Epoch: 1693 [20480/90000 (23%)]	Loss: -0.8732	Cost: 5.99s
Train Epoch: 1693 [40960/90000 (45%)]	Loss: -1.1295	Cost: 8.16s
Train Epoch: 1693 [61440/90000 (68%)]	Loss: -1.2631	Cost: 5.90s
Train Epoch: 1693 [81920/90000 (91%)]	Loss: -1.2652	Cost: 8.57s
Train Epoch: 1693 	Average Loss: 0.1306
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6517

Learning rate: 0.00019985858962200608
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1694 [0/90000 (0%)]	Loss: 15.8046	Cost: 24.23s
Train Epoch: 1694 [20480/90000 (23%)]	Loss: -1.1551	Cost: 6.12s
Train Epoch: 1694 [40960/90000 (45%)]	Loss: -1.2291	Cost: 6.46s
Train Epoch: 1694 [61440/90000 (68%)]	Loss: -1.3721	Cost: 5.89s
Train Epoch: 1694 [81920/90000 (91%)]	Loss: -0.9078	Cost: 6.35s
Train Epoch: 1694 	Average Loss: 0.0119
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6193

Learning rate: 0.00019985842255909478
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1695 [0/90000 (0%)]	Loss: 15.9601	Cost: 24.41s
Train Epoch: 1695 [20480/90000 (23%)]	Loss: -1.3279	Cost: 6.20s
Train Epoch: 1695 [40960/90000 (45%)]	Loss: -1.0866	Cost: 7.65s
Train Epoch: 1695 [61440/90000 (68%)]	Loss: -1.2739	Cost: 5.98s
Train Epoch: 1695 [81920/90000 (91%)]	Loss: -1.0763	Cost: 5.85s
Train Epoch: 1695 	Average Loss: 0.0376
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6272

Learning rate: 0.0001998582553976272
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1696 [0/90000 (0%)]	Loss: 15.8966	Cost: 24.55s
Train Epoch: 1696 [20480/90000 (23%)]	Loss: -1.4182	Cost: 5.96s
Train Epoch: 1696 [40960/90000 (45%)]	Loss: -1.1669	Cost: 6.99s
Train Epoch: 1696 [61440/90000 (68%)]	Loss: -1.1479	Cost: 6.00s
Train Epoch: 1696 [81920/90000 (91%)]	Loss: -0.8642	Cost: 6.74s
Train Epoch: 1696 	Average Loss: 0.0982
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6937

Learning rate: 0.0001998580881376034
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1697 [0/90000 (0%)]	Loss: 15.8017	Cost: 30.28s
Train Epoch: 1697 [20480/90000 (23%)]	Loss: -1.2356	Cost: 6.06s
Train Epoch: 1697 [40960/90000 (45%)]	Loss: -1.2429	Cost: 8.38s
Train Epoch: 1697 [61440/90000 (68%)]	Loss: -1.4766	Cost: 5.95s
Train Epoch: 1697 [81920/90000 (91%)]	Loss: -0.9997	Cost: 6.02s
Train Epoch: 1697 	Average Loss: 0.0065
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6609

Learning rate: 0.00019985792077902367
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1698 [0/90000 (0%)]	Loss: 15.7373	Cost: 26.24s
Train Epoch: 1698 [20480/90000 (23%)]	Loss: -1.2169	Cost: 6.14s
Train Epoch: 1698 [40960/90000 (45%)]	Loss: -0.8911	Cost: 7.62s
Train Epoch: 1698 [61440/90000 (68%)]	Loss: -1.0072	Cost: 5.97s
Train Epoch: 1698 [81920/90000 (91%)]	Loss: -0.8887	Cost: 7.00s
Train Epoch: 1698 	Average Loss: 0.1319
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6069

Learning rate: 0.00019985775332188809
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1699 [0/90000 (0%)]	Loss: 15.5502	Cost: 24.28s
Train Epoch: 1699 [20480/90000 (23%)]	Loss: -1.1682	Cost: 6.03s
Train Epoch: 1699 [40960/90000 (45%)]	Loss: -1.2584	Cost: 6.31s
Train Epoch: 1699 [61440/90000 (68%)]	Loss: -1.2882	Cost: 6.18s
Train Epoch: 1699 [81920/90000 (91%)]	Loss: -1.1288	Cost: 8.14s
Train Epoch: 1699 	Average Loss: 0.0810
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6857

Learning rate: 0.0001998575857661969
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1700 [0/90000 (0%)]	Loss: 15.9095	Cost: 23.54s
Train Epoch: 1700 [20480/90000 (23%)]	Loss: -1.2964	Cost: 6.15s
Train Epoch: 1700 [40960/90000 (45%)]	Loss: -1.1567	Cost: 6.85s
Train Epoch: 1700 [61440/90000 (68%)]	Loss: -1.3402	Cost: 6.04s
Train Epoch: 1700 [81920/90000 (91%)]	Loss: -1.0183	Cost: 6.40s
Train Epoch: 1700 	Average Loss: 0.0166
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6307

Learning rate: 0.0001998574181119502
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1701 [0/90000 (0%)]	Loss: 15.8582	Cost: 24.41s
Train Epoch: 1701 [20480/90000 (23%)]	Loss: -1.1575	Cost: 6.07s
Train Epoch: 1701 [40960/90000 (45%)]	Loss: -1.2929	Cost: 6.74s
Train Epoch: 1701 [61440/90000 (68%)]	Loss: -1.4779	Cost: 6.03s
Train Epoch: 1701 [81920/90000 (91%)]	Loss: -1.1425	Cost: 5.55s
Train Epoch: 1701 	Average Loss: -0.0075
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6865

Learning rate: 0.00019985725035914822
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1702 [0/90000 (0%)]	Loss: 15.9201	Cost: 27.74s
Train Epoch: 1702 [20480/90000 (23%)]	Loss: -1.3891	Cost: 6.07s
Train Epoch: 1702 [40960/90000 (45%)]	Loss: -1.4074	Cost: 7.43s
Train Epoch: 1702 [61440/90000 (68%)]	Loss: -1.3502	Cost: 6.01s
Train Epoch: 1702 [81920/90000 (91%)]	Loss: -1.5125	Cost: 6.65s
Train Epoch: 1702 	Average Loss: -0.1399
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7744

Learning rate: 0.00019985708250779105
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1703 [0/90000 (0%)]	Loss: 15.7882	Cost: 25.58s
Train Epoch: 1703 [20480/90000 (23%)]	Loss: -1.4674	Cost: 6.04s
Train Epoch: 1703 [40960/90000 (45%)]	Loss: -1.4062	Cost: 7.46s
Train Epoch: 1703 [61440/90000 (68%)]	Loss: -1.5679	Cost: 6.04s
Train Epoch: 1703 [81920/90000 (91%)]	Loss: -1.2905	Cost: 6.57s
Train Epoch: 1703 	Average Loss: -0.1554
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.8508

Learning rate: 0.00019985691455787888
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1704 [0/90000 (0%)]	Loss: 16.1237	Cost: 22.84s
Train Epoch: 1704 [20480/90000 (23%)]	Loss: -1.0535	Cost: 5.99s
Train Epoch: 1704 [40960/90000 (45%)]	Loss: -1.0873	Cost: 6.60s
Train Epoch: 1704 [61440/90000 (68%)]	Loss: -1.1827	Cost: 6.21s
Train Epoch: 1704 [81920/90000 (91%)]	Loss: -1.2956	Cost: 8.74s
Train Epoch: 1704 	Average Loss: 0.0856
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6805

Learning rate: 0.00019985674650941187
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1705 [0/90000 (0%)]	Loss: 15.5891	Cost: 24.71s
Train Epoch: 1705 [20480/90000 (23%)]	Loss: -1.1374	Cost: 6.14s
Train Epoch: 1705 [40960/90000 (45%)]	Loss: -1.3853	Cost: 6.99s
Train Epoch: 1705 [61440/90000 (68%)]	Loss: -1.2854	Cost: 5.98s
Train Epoch: 1705 [81920/90000 (91%)]	Loss: -1.2148	Cost: 6.26s
Train Epoch: 1705 	Average Loss: -0.0807
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7530

Learning rate: 0.00019985657836239023
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1706 [0/90000 (0%)]	Loss: 15.9801	Cost: 24.72s
Train Epoch: 1706 [20480/90000 (23%)]	Loss: -1.0861	Cost: 6.02s
Train Epoch: 1706 [40960/90000 (45%)]	Loss: -0.9088	Cost: 6.53s
Train Epoch: 1706 [61440/90000 (68%)]	Loss: -1.1402	Cost: 6.28s
Train Epoch: 1706 [81920/90000 (91%)]	Loss: -0.5922	Cost: 6.23s
Train Epoch: 1706 	Average Loss: 0.1735
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6435

Learning rate: 0.0001998564101168141
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1707 [0/90000 (0%)]	Loss: 15.9081	Cost: 27.09s
Train Epoch: 1707 [20480/90000 (23%)]	Loss: -0.8990	Cost: 6.05s
Train Epoch: 1707 [40960/90000 (45%)]	Loss: -0.8944	Cost: 6.52s
Train Epoch: 1707 [61440/90000 (68%)]	Loss: -0.9044	Cost: 6.19s
Train Epoch: 1707 [81920/90000 (91%)]	Loss: -0.8487	Cost: 5.92s
Train Epoch: 1707 	Average Loss: 0.3458
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5755

Learning rate: 0.00019985624177268363
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1708 [0/90000 (0%)]	Loss: 15.8541	Cost: 29.06s
Train Epoch: 1708 [20480/90000 (23%)]	Loss: -0.9292	Cost: 6.15s
Train Epoch: 1708 [40960/90000 (45%)]	Loss: -0.9947	Cost: 6.70s
Train Epoch: 1708 [61440/90000 (68%)]	Loss: -1.2275	Cost: 6.18s
Train Epoch: 1708 [81920/90000 (91%)]	Loss: -1.1919	Cost: 5.77s
Train Epoch: 1708 	Average Loss: 0.0907
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6645

Learning rate: 0.00019985607332999902
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1709 [0/90000 (0%)]	Loss: 15.9725	Cost: 23.84s
Train Epoch: 1709 [20480/90000 (23%)]	Loss: -1.1590	Cost: 6.06s
Train Epoch: 1709 [40960/90000 (45%)]	Loss: -1.2790	Cost: 8.13s
Train Epoch: 1709 [61440/90000 (68%)]	Loss: -1.7347	Cost: 5.94s
Train Epoch: 1709 [81920/90000 (91%)]	Loss: -1.3982	Cost: 8.71s
Train Epoch: 1709 	Average Loss: -0.1380
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6558

Learning rate: 0.00019985590478876038
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1710 [0/90000 (0%)]	Loss: 15.2378	Cost: 23.92s
Train Epoch: 1710 [20480/90000 (23%)]	Loss: -1.3222	Cost: 6.10s
Train Epoch: 1710 [40960/90000 (45%)]	Loss: -1.4161	Cost: 6.44s
Train Epoch: 1710 [61440/90000 (68%)]	Loss: -1.4346	Cost: 6.20s
Train Epoch: 1710 [81920/90000 (91%)]	Loss: -1.2391	Cost: 6.03s
Train Epoch: 1710 	Average Loss: -0.0791
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5973

Learning rate: 0.00019985573614896793
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1711 [0/90000 (0%)]	Loss: 16.0776	Cost: 23.53s
Train Epoch: 1711 [20480/90000 (23%)]	Loss: -1.2608	Cost: 6.19s
Train Epoch: 1711 [40960/90000 (45%)]	Loss: -1.2100	Cost: 7.02s
Train Epoch: 1711 [61440/90000 (68%)]	Loss: -1.3691	Cost: 5.94s
Train Epoch: 1711 [81920/90000 (91%)]	Loss: -1.3910	Cost: 6.21s
Train Epoch: 1711 	Average Loss: -0.0605
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6501

Learning rate: 0.00019985556741062183
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1712 [0/90000 (0%)]	Loss: 16.1393	Cost: 25.54s
Train Epoch: 1712 [20480/90000 (23%)]	Loss: -1.2299	Cost: 5.94s
Train Epoch: 1712 [40960/90000 (45%)]	Loss: -1.1646	Cost: 7.24s
Train Epoch: 1712 [61440/90000 (68%)]	Loss: -1.2109	Cost: 5.98s
Train Epoch: 1712 [81920/90000 (91%)]	Loss: -1.0880	Cost: 5.92s
Train Epoch: 1712 	Average Loss: 0.0872
Re-generating waveforms for mixed prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7267

Stopping timer.
Training time (including validation): 160395.54345321655 seconds
Saving model
