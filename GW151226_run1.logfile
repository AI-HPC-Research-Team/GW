Nestedspace(activation='elu', apply_unconditional_transform=False, base_transform_type='rq-coupling', basis_dir='data/GW151012_sample_prior_basis/', batch_norm=True, batch_size=2048, bw_dstar=None, cuda=True, data_dir='data/GW151012_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, dropout_probability=0.0, epochs=10000, flow_lr=None, hidden_dims=1024, kl_annealing=True, lr=0.0002, lr_anneal_method='cosine', lr_annealing=True, mode='train', model_dir='models/GW151012_sample_uniform_100basis_all_posterior_prior/', model_source='new', model_type='nde', nbins=8, nflows=15, nsample=100000, nsamples_target_event=2000, num_transform_blocks=10, output_freq=10, sampling_from='posterior', save=True, save_aux_filename='waveforms_supplementary.hdf5', save_model_name='model.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, tail_bound=1.0, truncate_basis=100)
Waveform directory data/GW151012_sample_prior_basis/
Model directory models/GW151012_sample_uniform_100basis_all_posterior_prior/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from posterior prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Detectors: ['H1', 'L1']

Constructing model of type nde

Initial learning rate 0.0002
Using cosine LR annealing.

Model hyperparameters:
input_dim 	 15
num_flow_steps 	 15
context_dim 	 400
base_transform_kwargs
	 hidden_dim 	 1024
	 num_transform_blocks 	 10
	 activation 	 elu
	 dropout_probability 	 0.0
	 batch_norm 	 True
	 num_bins 	 8
	 tail_bound 	 1.0
	 apply_unconditional_transform 	 False
	 base_transform_type 	 rq-coupling

Training for 10000 epochs
Starting timer
Learning rate: 0.0002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 27.3824	Cost: 23.36s
Train Epoch: 1 [20480/90000 (23%)]	Loss: 21.6209	Cost: 9.17s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 20.6301	Cost: 9.26s
Train Epoch: 1 [61440/90000 (68%)]	Loss: 19.9046	Cost: 8.99s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 19.1901	Cost: 8.69s
Train Epoch: 1 	Average Loss: 20.8277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2615

Learning rate: 0.00019999999506519785
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 18.8487	Cost: 25.80s
Train Epoch: 2 [20480/90000 (23%)]	Loss: 18.1806	Cost: 9.11s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 17.7161	Cost: 9.04s
Train Epoch: 2 [61440/90000 (68%)]	Loss: 17.2690	Cost: 9.01s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 17.1402	Cost: 8.65s
Train Epoch: 2 	Average Loss: 17.7860
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.1351

Learning rate: 0.00019999998026079186
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 16.9663	Cost: 24.02s
Train Epoch: 3 [20480/90000 (23%)]	Loss: 16.8069	Cost: 9.15s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 16.4865	Cost: 9.20s
Train Epoch: 3 [61440/90000 (68%)]	Loss: 16.2770	Cost: 9.04s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 16.1167	Cost: 8.79s
Train Epoch: 3 	Average Loss: 16.5161
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.2358

Learning rate: 0.00019999995558678347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 16.0791	Cost: 22.72s
Train Epoch: 4 [20480/90000 (23%)]	Loss: 15.7971	Cost: 9.21s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 15.7177	Cost: 9.07s
Train Epoch: 4 [61440/90000 (68%)]	Loss: 15.6138	Cost: 9.10s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 15.5314	Cost: 9.04s
Train Epoch: 4 	Average Loss: 15.7762
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6924

Learning rate: 0.0001999999210431752
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 15.4499	Cost: 22.81s
Train Epoch: 5 [20480/90000 (23%)]	Loss: 15.3223	Cost: 9.05s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 15.1522	Cost: 9.20s
Train Epoch: 5 [61440/90000 (68%)]	Loss: 15.1201	Cost: 9.07s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 15.1177	Cost: 9.01s
Train Epoch: 5 	Average Loss: 15.2224
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1855

Learning rate: 0.00019999987662997035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 15.1039	Cost: 22.29s
Train Epoch: 6 [20480/90000 (23%)]	Loss: 14.8320	Cost: 9.18s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 14.9618	Cost: 9.77s
Train Epoch: 6 [61440/90000 (68%)]	Loss: 14.7702	Cost: 8.95s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 14.6198	Cost: 8.95s
Train Epoch: 6 	Average Loss: 14.7784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7167

Learning rate: 0.00019999982234717337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 14.5248	Cost: 23.06s
Train Epoch: 7 [20480/90000 (23%)]	Loss: 14.3617	Cost: 9.18s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 14.2945	Cost: 9.07s
Train Epoch: 7 [61440/90000 (68%)]	Loss: 14.2577	Cost: 8.88s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 14.2219	Cost: 9.07s
Train Epoch: 7 	Average Loss: 14.3726
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.2889

Learning rate: 0.0001999997581947896
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 14.2659	Cost: 22.87s
Train Epoch: 8 [20480/90000 (23%)]	Loss: 14.0448	Cost: 9.35s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 13.9911	Cost: 9.47s
Train Epoch: 8 [61440/90000 (68%)]	Loss: 13.7900	Cost: 9.06s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 13.8004	Cost: 8.85s
Train Epoch: 8 	Average Loss: 13.9864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8053

Learning rate: 0.0001999996841728254
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 13.7860	Cost: 23.61s
Train Epoch: 9 [20480/90000 (23%)]	Loss: 13.7081	Cost: 9.34s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 13.5840	Cost: 9.22s
Train Epoch: 9 [61440/90000 (68%)]	Loss: 13.5197	Cost: 9.15s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 13.5638	Cost: 8.84s
Train Epoch: 9 	Average Loss: 13.6179
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4963

Learning rate: 0.00019999960028128805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 13.4895	Cost: 24.76s
Train Epoch: 10 [20480/90000 (23%)]	Loss: 13.5732	Cost: 9.29s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 13.2999	Cost: 9.27s
Train Epoch: 10 [61440/90000 (68%)]	Loss: 13.1755	Cost: 9.25s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 13.3085	Cost: 8.70s
Train Epoch: 10 	Average Loss: 13.3023
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0575

Learning rate: 0.00019999950652018584
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 12.8893	Cost: 23.79s
Train Epoch: 11 [20480/90000 (23%)]	Loss: 12.9930	Cost: 9.33s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 12.9675	Cost: 9.31s
Train Epoch: 11 [61440/90000 (68%)]	Loss: 12.7341	Cost: 9.02s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 13.0491	Cost: 8.80s
Train Epoch: 11 	Average Loss: 12.9735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8235

Learning rate: 0.00019999940288952797
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 12.8364	Cost: 26.29s
Train Epoch: 12 [20480/90000 (23%)]	Loss: 12.7354	Cost: 9.28s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 12.6657	Cost: 9.30s
Train Epoch: 12 [61440/90000 (68%)]	Loss: 12.6813	Cost: 9.25s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 12.7949	Cost: 8.75s
Train Epoch: 12 	Average Loss: 12.7086
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8070

Learning rate: 0.00019999928938932473
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 12.6799	Cost: 24.47s
Train Epoch: 13 [20480/90000 (23%)]	Loss: 12.5326	Cost: 9.33s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 12.3659	Cost: 9.30s
Train Epoch: 13 [61440/90000 (68%)]	Loss: 12.2808	Cost: 9.20s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 12.3690	Cost: 8.80s
Train Epoch: 13 	Average Loss: 12.4112
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3260

Learning rate: 0.0001999991660195873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 12.3266	Cost: 23.85s
Train Epoch: 14 [20480/90000 (23%)]	Loss: 12.2933	Cost: 9.35s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 12.2236	Cost: 9.35s
Train Epoch: 14 [61440/90000 (68%)]	Loss: 12.0130	Cost: 9.12s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 12.1168	Cost: 9.07s
Train Epoch: 14 	Average Loss: 12.1882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1830

Learning rate: 0.0001999990327803279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 11.9919	Cost: 24.06s
Train Epoch: 15 [20480/90000 (23%)]	Loss: 12.0580	Cost: 9.39s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 11.9892	Cost: 9.32s
Train Epoch: 15 [61440/90000 (68%)]	Loss: 11.9039	Cost: 9.06s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 11.9880	Cost: 8.90s
Train Epoch: 15 	Average Loss: 12.0360
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0957

Learning rate: 0.00019999888967155963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 11.8946	Cost: 24.25s
Train Epoch: 16 [20480/90000 (23%)]	Loss: 12.0148	Cost: 9.40s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 11.6883	Cost: 9.26s
Train Epoch: 16 [61440/90000 (68%)]	Loss: 11.7769	Cost: 9.13s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 11.7677	Cost: 9.09s
Train Epoch: 16 	Average Loss: 11.8814
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6786

Learning rate: 0.0001999987366932966
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 11.7143	Cost: 24.40s
Train Epoch: 17 [20480/90000 (23%)]	Loss: 11.8375	Cost: 9.59s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 11.5282	Cost: 9.29s
Train Epoch: 17 [61440/90000 (68%)]	Loss: 11.5047	Cost: 9.20s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 11.4858	Cost: 9.06s
Train Epoch: 17 	Average Loss: 11.6460
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6281

Learning rate: 0.00019999857384555393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 11.5838	Cost: 24.11s
Train Epoch: 18 [20480/90000 (23%)]	Loss: 11.5333	Cost: 9.48s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 11.4375	Cost: 9.21s
Train Epoch: 18 [61440/90000 (68%)]	Loss: 11.3809	Cost: 9.36s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 11.3221	Cost: 8.96s
Train Epoch: 18 	Average Loss: 11.5165
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4671

Learning rate: 0.0001999984011283477
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 11.5173	Cost: 25.65s
Train Epoch: 19 [20480/90000 (23%)]	Loss: 11.5137	Cost: 9.43s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 11.3601	Cost: 9.45s
Train Epoch: 19 [61440/90000 (68%)]	Loss: 11.3947	Cost: 9.29s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 11.3776	Cost: 9.28s
Train Epoch: 19 	Average Loss: 11.4242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3606

Learning rate: 0.00019999821854169497
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 11.3387	Cost: 24.23s
Train Epoch: 20 [20480/90000 (23%)]	Loss: 11.3841	Cost: 9.61s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 11.1872	Cost: 9.40s
Train Epoch: 20 [61440/90000 (68%)]	Loss: 11.1640	Cost: 9.43s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 11.1184	Cost: 8.90s
Train Epoch: 20 	Average Loss: 11.2613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0950

Learning rate: 0.00019999802608561374
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 11.1802	Cost: 23.69s
Train Epoch: 21 [20480/90000 (23%)]	Loss: 11.1677	Cost: 9.35s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 11.0157	Cost: 9.28s
Train Epoch: 21 [61440/90000 (68%)]	Loss: 10.9810	Cost: 9.09s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 11.0462	Cost: 9.06s
Train Epoch: 21 	Average Loss: 11.0886
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0991

Learning rate: 0.000199997823760123
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 11.1751	Cost: 23.97s
Train Epoch: 22 [20480/90000 (23%)]	Loss: 11.2068	Cost: 9.49s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 10.9600	Cost: 9.34s
Train Epoch: 22 [61440/90000 (68%)]	Loss: 10.9247	Cost: 9.13s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 11.0130	Cost: 8.99s
Train Epoch: 22 	Average Loss: 11.0729
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0506

Learning rate: 0.00019999761156524272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 11.0071	Cost: 23.69s
Train Epoch: 23 [20480/90000 (23%)]	Loss: 11.0294	Cost: 9.50s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 10.8022	Cost: 9.30s
Train Epoch: 23 [61440/90000 (68%)]	Loss: 10.9846	Cost: 9.13s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 11.0906	Cost: 9.14s
Train Epoch: 23 	Average Loss: 10.9815
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0430

Learning rate: 0.00019999738950099387
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 10.8894	Cost: 23.73s
Train Epoch: 24 [20480/90000 (23%)]	Loss: 10.8552	Cost: 9.47s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 10.9936	Cost: 9.24s
Train Epoch: 24 [61440/90000 (68%)]	Loss: 10.7785	Cost: 9.01s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 10.7159	Cost: 9.04s
Train Epoch: 24 	Average Loss: 10.8625
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6911

Learning rate: 0.00019999715756739833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 10.6803	Cost: 24.09s
Train Epoch: 25 [20480/90000 (23%)]	Loss: 10.7715	Cost: 9.55s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 10.8269	Cost: 9.87s
Train Epoch: 25 [61440/90000 (68%)]	Loss: 10.6363	Cost: 8.97s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 10.4754	Cost: 8.99s
Train Epoch: 25 	Average Loss: 10.6890
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6315

Learning rate: 0.000199996915764479
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 10.4917	Cost: 24.61s
Train Epoch: 26 [20480/90000 (23%)]	Loss: 10.6205	Cost: 9.47s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 10.4272	Cost: 9.30s
Train Epoch: 26 [61440/90000 (68%)]	Loss: 10.4992	Cost: 9.09s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 10.5796	Cost: 8.69s
Train Epoch: 26 	Average Loss: 10.6029
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7710

Learning rate: 0.00019999666409225975
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 10.7795	Cost: 23.74s
Train Epoch: 27 [20480/90000 (23%)]	Loss: 10.6957	Cost: 9.10s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 10.5724	Cost: 9.09s
Train Epoch: 27 [61440/90000 (68%)]	Loss: 10.4799	Cost: 9.05s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 10.5980	Cost: 8.89s
Train Epoch: 27 	Average Loss: 10.5626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5098

Learning rate: 0.00019999640255076543
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 10.7438	Cost: 24.59s
Train Epoch: 28 [20480/90000 (23%)]	Loss: 10.6423	Cost: 9.14s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 10.3879	Cost: 9.27s
Train Epoch: 28 [61440/90000 (68%)]	Loss: 10.4528	Cost: 9.07s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 10.3832	Cost: 8.84s
Train Epoch: 28 	Average Loss: 10.4598
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3588

Learning rate: 0.00019999613114002186
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 10.3136	Cost: 22.31s
Train Epoch: 29 [20480/90000 (23%)]	Loss: 10.3577	Cost: 9.00s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 10.2868	Cost: 9.16s
Train Epoch: 29 [61440/90000 (68%)]	Loss: 10.3216	Cost: 9.12s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 10.1917	Cost: 9.60s
Train Epoch: 29 	Average Loss: 10.3384
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3476

Learning rate: 0.0001999958498600558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 10.4580	Cost: 23.56s
Train Epoch: 30 [20480/90000 (23%)]	Loss: 10.4105	Cost: 9.26s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 10.2400	Cost: 9.08s
Train Epoch: 30 [61440/90000 (68%)]	Loss: 10.2915	Cost: 9.12s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 10.2236	Cost: 9.22s
Train Epoch: 30 	Average Loss: 10.3274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2840

Learning rate: 0.000199995558710895
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 10.4165	Cost: 23.29s
Train Epoch: 31 [20480/90000 (23%)]	Loss: 10.3863	Cost: 9.34s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 10.0446	Cost: 9.69s
Train Epoch: 31 [61440/90000 (68%)]	Loss: 10.1624	Cost: 9.26s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 10.1665	Cost: 9.01s
Train Epoch: 31 	Average Loss: 10.2130
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1982

Learning rate: 0.00019999525769256825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 10.2108	Cost: 23.34s
Train Epoch: 32 [20480/90000 (23%)]	Loss: 9.9704	Cost: 9.37s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 10.0779	Cost: 9.38s
Train Epoch: 32 [61440/90000 (68%)]	Loss: 10.1783	Cost: 9.21s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 10.2663	Cost: 8.98s
Train Epoch: 32 	Average Loss: 10.1308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1964

Learning rate: 0.00019999494680510518
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 10.1871	Cost: 22.59s
Train Epoch: 33 [20480/90000 (23%)]	Loss: 10.0537	Cost: 9.17s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 9.9396	Cost: 9.23s
Train Epoch: 33 [61440/90000 (68%)]	Loss: 10.1170	Cost: 9.16s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 10.2648	Cost: 9.00s
Train Epoch: 33 	Average Loss: 10.0996
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0473

Learning rate: 0.00019999462604853658
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 10.1223	Cost: 22.29s
Train Epoch: 34 [20480/90000 (23%)]	Loss: 9.9955	Cost: 9.25s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 10.0214	Cost: 9.03s
Train Epoch: 34 [61440/90000 (68%)]	Loss: 10.0848	Cost: 9.01s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 9.9657	Cost: 9.01s
Train Epoch: 34 	Average Loss: 10.0038
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9269

Learning rate: 0.00019999429542289402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 9.8682	Cost: 23.22s
Train Epoch: 35 [20480/90000 (23%)]	Loss: 10.0092	Cost: 9.16s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 9.8994	Cost: 9.10s
Train Epoch: 35 [61440/90000 (68%)]	Loss: 9.8396	Cost: 8.88s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 9.8871	Cost: 8.87s
Train Epoch: 35 	Average Loss: 9.9418
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8838

Learning rate: 0.00019999395492821016
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 9.9129	Cost: 24.16s
Train Epoch: 36 [20480/90000 (23%)]	Loss: 10.0907	Cost: 9.49s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 9.8231	Cost: 9.11s
Train Epoch: 36 [61440/90000 (68%)]	Loss: 9.7805	Cost: 8.91s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 9.7483	Cost: 8.78s
Train Epoch: 36 	Average Loss: 9.8613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7812

Learning rate: 0.0001999936045645186
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 9.6678	Cost: 24.18s
Train Epoch: 37 [20480/90000 (23%)]	Loss: 9.8979	Cost: 9.32s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 9.7755	Cost: 9.30s
Train Epoch: 37 [61440/90000 (68%)]	Loss: 9.7006	Cost: 9.07s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 9.8315	Cost: 8.85s
Train Epoch: 37 	Average Loss: 9.7839
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6788

Learning rate: 0.00019999324433185394
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 9.7260	Cost: 24.26s
Train Epoch: 38 [20480/90000 (23%)]	Loss: 9.6742	Cost: 9.38s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 9.7091	Cost: 9.24s
Train Epoch: 38 [61440/90000 (68%)]	Loss: 9.8933	Cost: 9.25s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 9.8287	Cost: 8.73s
Train Epoch: 38 	Average Loss: 9.7460
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9079

Learning rate: 0.0001999928742302517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 9.8404	Cost: 23.37s
Train Epoch: 39 [20480/90000 (23%)]	Loss: 9.7330	Cost: 9.23s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 9.6820	Cost: 9.59s
Train Epoch: 39 [61440/90000 (68%)]	Loss: 9.5008	Cost: 9.22s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 9.6946	Cost: 8.71s
Train Epoch: 39 	Average Loss: 9.6534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5470

Learning rate: 0.00019999249425974844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 9.7328	Cost: 24.04s
Train Epoch: 40 [20480/90000 (23%)]	Loss: 9.7062	Cost: 9.38s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 9.6283	Cost: 9.23s
Train Epoch: 40 [61440/90000 (68%)]	Loss: 9.5121	Cost: 9.11s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 9.5931	Cost: 8.78s
Train Epoch: 40 	Average Loss: 9.6241
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5971

Learning rate: 0.00019999210442038165
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 9.7719	Cost: 24.03s
Train Epoch: 41 [20480/90000 (23%)]	Loss: 9.5632	Cost: 9.35s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 9.4999	Cost: 9.29s
Train Epoch: 41 [61440/90000 (68%)]	Loss: 9.4071	Cost: 9.23s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 9.5507	Cost: 8.79s
Train Epoch: 41 	Average Loss: 9.5542
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5886

Learning rate: 0.00019999170471218976
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 9.6340	Cost: 24.69s
Train Epoch: 42 [20480/90000 (23%)]	Loss: 9.5094	Cost: 9.32s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 9.3739	Cost: 9.34s
Train Epoch: 42 [61440/90000 (68%)]	Loss: 9.4122	Cost: 9.17s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 9.5287	Cost: 8.87s
Train Epoch: 42 	Average Loss: 9.5118
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4421

Learning rate: 0.0001999912951352123
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 9.4356	Cost: 26.15s
Train Epoch: 43 [20480/90000 (23%)]	Loss: 9.4216	Cost: 9.31s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 9.4549	Cost: 9.36s
Train Epoch: 43 [61440/90000 (68%)]	Loss: 9.4718	Cost: 9.07s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 9.4573	Cost: 8.79s
Train Epoch: 43 	Average Loss: 9.4447
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4221

Learning rate: 0.00019999087568948966
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 9.4248	Cost: 24.13s
Train Epoch: 44 [20480/90000 (23%)]	Loss: 9.3980	Cost: 9.39s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 9.5675	Cost: 9.22s
Train Epoch: 44 [61440/90000 (68%)]	Loss: 9.3875	Cost: 9.22s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 9.3450	Cost: 8.88s
Train Epoch: 44 	Average Loss: 9.4266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3814

Learning rate: 0.0001999904463750632
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 9.5773	Cost: 25.14s
Train Epoch: 45 [20480/90000 (23%)]	Loss: 9.2833	Cost: 9.39s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 9.3071	Cost: 9.35s
Train Epoch: 45 [61440/90000 (68%)]	Loss: 9.4878	Cost: 9.37s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 9.3440	Cost: 8.86s
Train Epoch: 45 	Average Loss: 9.3630
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3773

Learning rate: 0.00019999000719197536
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 9.3664	Cost: 25.67s
Train Epoch: 46 [20480/90000 (23%)]	Loss: 9.1821	Cost: 9.40s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 9.3006	Cost: 9.30s
Train Epoch: 46 [61440/90000 (68%)]	Loss: 9.2963	Cost: 9.16s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 9.2205	Cost: 8.79s
Train Epoch: 46 	Average Loss: 9.3128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3193

Learning rate: 0.00019998955814026943
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 9.4911	Cost: 24.70s
Train Epoch: 47 [20480/90000 (23%)]	Loss: 9.4069	Cost: 9.42s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 9.3161	Cost: 9.51s
Train Epoch: 47 [61440/90000 (68%)]	Loss: 9.1774	Cost: 8.97s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 9.2518	Cost: 8.83s
Train Epoch: 47 	Average Loss: 9.2779
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2866

Learning rate: 0.00019998909921998973
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 9.1685	Cost: 23.22s
Train Epoch: 48 [20480/90000 (23%)]	Loss: 9.1813	Cost: 9.44s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 9.2743	Cost: 9.32s
Train Epoch: 48 [61440/90000 (68%)]	Loss: 9.3465	Cost: 9.08s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 9.3043	Cost: 8.91s
Train Epoch: 48 	Average Loss: 9.2031
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1744

Learning rate: 0.0001999886304311816
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 9.0544	Cost: 24.56s
Train Epoch: 49 [20480/90000 (23%)]	Loss: 9.1232	Cost: 9.43s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 9.0290	Cost: 9.29s
Train Epoch: 49 [61440/90000 (68%)]	Loss: 9.3428	Cost: 9.34s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 9.1175	Cost: 8.86s
Train Epoch: 49 	Average Loss: 9.1349
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1380

Learning rate: 0.00019998815177389132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 9.2205	Cost: 23.95s
Train Epoch: 50 [20480/90000 (23%)]	Loss: 9.3386	Cost: 9.42s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 9.0670	Cost: 9.26s
Train Epoch: 50 [61440/90000 (68%)]	Loss: 9.1382	Cost: 9.07s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 9.0422	Cost: 9.11s
Train Epoch: 50 	Average Loss: 9.1599
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0659

Saving model as model.pt_e50 & waveforms_supplementary.hdf5_e50
Learning rate: 0.00019998766324816605
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 9.4589	Cost: 25.55s
Train Epoch: 51 [20480/90000 (23%)]	Loss: 9.0586	Cost: 9.30s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 9.0414	Cost: 9.29s
Train Epoch: 51 [61440/90000 (68%)]	Loss: 9.0768	Cost: 9.09s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 8.9655	Cost: 8.78s
Train Epoch: 51 	Average Loss: 9.0687
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1395

Learning rate: 0.00019998716485405404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 9.0495	Cost: 26.21s
Train Epoch: 52 [20480/90000 (23%)]	Loss: 9.0296	Cost: 9.34s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 9.0965	Cost: 9.22s
Train Epoch: 52 [61440/90000 (68%)]	Loss: 9.0588	Cost: 9.09s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 9.0756	Cost: 8.85s
Train Epoch: 52 	Average Loss: 9.0548
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0356

Learning rate: 0.0001999866565916045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 8.9784	Cost: 24.62s
Train Epoch: 53 [20480/90000 (23%)]	Loss: 9.0766	Cost: 9.38s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 8.9106	Cost: 9.32s
Train Epoch: 53 [61440/90000 (68%)]	Loss: 8.8968	Cost: 9.19s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 9.1404	Cost: 8.86s
Train Epoch: 53 	Average Loss: 9.0112
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0036

Learning rate: 0.0001999861384608676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 8.9396	Cost: 24.84s
Train Epoch: 54 [20480/90000 (23%)]	Loss: 8.9575	Cost: 9.36s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 9.0382	Cost: 9.20s
Train Epoch: 54 [61440/90000 (68%)]	Loss: 8.9977	Cost: 9.18s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 8.9208	Cost: 8.88s
Train Epoch: 54 	Average Loss: 8.9616
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9736

Learning rate: 0.00019998561046189446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 8.8605	Cost: 25.51s
Train Epoch: 55 [20480/90000 (23%)]	Loss: 9.0004	Cost: 9.30s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 8.9104	Cost: 9.44s
Train Epoch: 55 [61440/90000 (68%)]	Loss: 9.0368	Cost: 9.15s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 9.0606	Cost: 8.91s
Train Epoch: 55 	Average Loss: 8.9291
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1244

Learning rate: 0.00019998507259473718
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 9.1291	Cost: 24.45s
Train Epoch: 56 [20480/90000 (23%)]	Loss: 8.8920	Cost: 9.19s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 9.1576	Cost: 9.18s
Train Epoch: 56 [61440/90000 (68%)]	Loss: 9.0828	Cost: 8.96s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 8.8747	Cost: 8.66s
Train Epoch: 56 	Average Loss: 8.9272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9040

Learning rate: 0.00019998452485944885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 8.9592	Cost: 24.06s
Train Epoch: 57 [20480/90000 (23%)]	Loss: 8.8043	Cost: 9.05s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 8.7452	Cost: 9.47s
Train Epoch: 57 [61440/90000 (68%)]	Loss: 8.7882	Cost: 9.16s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 8.9140	Cost: 8.68s
Train Epoch: 57 	Average Loss: 8.8555
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8725

Learning rate: 0.00019998396725608354
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 9.1385	Cost: 22.78s
Train Epoch: 58 [20480/90000 (23%)]	Loss: 8.9278	Cost: 9.12s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 8.8055	Cost: 9.28s
Train Epoch: 58 [61440/90000 (68%)]	Loss: 8.8523	Cost: 9.06s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 8.8050	Cost: 9.31s
Train Epoch: 58 	Average Loss: 8.8559
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7874

Learning rate: 0.00019998339978469627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 8.8579	Cost: 22.36s
Train Epoch: 59 [20480/90000 (23%)]	Loss: 8.8787	Cost: 9.09s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 8.8253	Cost: 9.17s
Train Epoch: 59 [61440/90000 (68%)]	Loss: 8.9321	Cost: 9.14s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 8.7455	Cost: 9.58s
Train Epoch: 59 	Average Loss: 8.8064
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8006

Learning rate: 0.00019998282244534305
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 8.8624	Cost: 23.64s
Train Epoch: 60 [20480/90000 (23%)]	Loss: 8.7601	Cost: 9.30s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 8.6181	Cost: 9.18s
Train Epoch: 60 [61440/90000 (68%)]	Loss: 8.7057	Cost: 9.04s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 8.8618	Cost: 9.05s
Train Epoch: 60 	Average Loss: 8.7414
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8416

Learning rate: 0.00019998223523808088
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 8.8091	Cost: 22.13s
Train Epoch: 61 [20480/90000 (23%)]	Loss: 8.7780	Cost: 9.14s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 8.7410	Cost: 9.72s
Train Epoch: 61 [61440/90000 (68%)]	Loss: 8.8122	Cost: 9.47s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 8.6528	Cost: 9.34s
Train Epoch: 61 	Average Loss: 8.7235
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7854

Learning rate: 0.0001999816381629677
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 8.6977	Cost: 22.06s
Train Epoch: 62 [20480/90000 (23%)]	Loss: 8.6928	Cost: 9.39s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 8.6523	Cost: 9.46s
Train Epoch: 62 [61440/90000 (68%)]	Loss: 8.6651	Cost: 9.26s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 8.7035	Cost: 9.20s
Train Epoch: 62 	Average Loss: 8.6882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7524

Learning rate: 0.00019998103122006246
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 8.4781	Cost: 22.20s
Train Epoch: 63 [20480/90000 (23%)]	Loss: 8.7639	Cost: 9.70s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 8.5937	Cost: 9.36s
Train Epoch: 63 [61440/90000 (68%)]	Loss: 8.6420	Cost: 9.07s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 8.4424	Cost: 9.48s
Train Epoch: 63 	Average Loss: 8.6335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6047

Learning rate: 0.00019998041440942506
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 8.5245	Cost: 22.69s
Train Epoch: 64 [20480/90000 (23%)]	Loss: 8.5442	Cost: 9.38s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 8.7354	Cost: 9.27s
Train Epoch: 64 [61440/90000 (68%)]	Loss: 8.5719	Cost: 9.03s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 8.4801	Cost: 9.12s
Train Epoch: 64 	Average Loss: 8.5936
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5552

Learning rate: 0.00019997978773111632
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 8.6136	Cost: 23.42s
Train Epoch: 65 [20480/90000 (23%)]	Loss: 8.7440	Cost: 9.26s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 8.5648	Cost: 9.09s
Train Epoch: 65 [61440/90000 (68%)]	Loss: 8.6586	Cost: 8.91s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 8.6012	Cost: 9.06s
Train Epoch: 65 	Average Loss: 8.5998
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6225

Learning rate: 0.00019997915118519813
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 8.6254	Cost: 23.29s
Train Epoch: 66 [20480/90000 (23%)]	Loss: 8.4916	Cost: 9.24s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 8.5673	Cost: 9.06s
Train Epoch: 66 [61440/90000 (68%)]	Loss: 8.4877	Cost: 8.95s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 8.5351	Cost: 8.80s
Train Epoch: 66 	Average Loss: 8.5393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6400

Learning rate: 0.0001999785047717333
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 8.7530	Cost: 23.78s
Train Epoch: 67 [20480/90000 (23%)]	Loss: 8.4835	Cost: 9.36s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 8.5770	Cost: 9.29s
Train Epoch: 67 [61440/90000 (68%)]	Loss: 8.4749	Cost: 9.02s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 8.5174	Cost: 8.84s
Train Epoch: 67 	Average Loss: 8.5092
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4526

Learning rate: 0.00019997784849078566
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 8.4175	Cost: 25.05s
Train Epoch: 68 [20480/90000 (23%)]	Loss: 8.5450	Cost: 9.30s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 8.6002	Cost: 9.34s
Train Epoch: 68 [61440/90000 (68%)]	Loss: 8.5434	Cost: 9.08s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 8.5314	Cost: 8.76s
Train Epoch: 68 	Average Loss: 8.4929
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4956

Learning rate: 0.00019997718234242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 8.6971	Cost: 23.94s
Train Epoch: 69 [20480/90000 (23%)]	Loss: 8.6193	Cost: 9.33s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 8.6339	Cost: 9.39s
Train Epoch: 69 [61440/90000 (68%)]	Loss: 8.5488	Cost: 9.20s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 8.3952	Cost: 9.00s
Train Epoch: 69 	Average Loss: 8.4596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4894

Learning rate: 0.00019997650632670199
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 8.5343	Cost: 24.10s
Train Epoch: 70 [20480/90000 (23%)]	Loss: 8.4733	Cost: 9.31s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 8.4746	Cost: 9.29s
Train Epoch: 70 [61440/90000 (68%)]	Loss: 8.4108	Cost: 9.34s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 8.5091	Cost: 8.71s
Train Epoch: 70 	Average Loss: 8.3963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4905

Learning rate: 0.0001999758204436984
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 8.4700	Cost: 24.85s
Train Epoch: 71 [20480/90000 (23%)]	Loss: 8.3496	Cost: 9.49s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 8.4311	Cost: 9.26s
Train Epoch: 71 [61440/90000 (68%)]	Loss: 8.3429	Cost: 9.31s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 8.4574	Cost: 8.72s
Train Epoch: 71 	Average Loss: 8.3676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5449

Learning rate: 0.00019997512469347695
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 8.4898	Cost: 25.91s
Train Epoch: 72 [20480/90000 (23%)]	Loss: 8.3552	Cost: 9.27s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 8.3443	Cost: 9.31s
Train Epoch: 72 [61440/90000 (68%)]	Loss: 8.4436	Cost: 9.12s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 8.3927	Cost: 8.79s
Train Epoch: 72 	Average Loss: 8.3524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3130

Learning rate: 0.00019997441907610624
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 8.3539	Cost: 23.77s
Train Epoch: 73 [20480/90000 (23%)]	Loss: 8.7049	Cost: 9.41s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 8.4698	Cost: 9.26s
Train Epoch: 73 [61440/90000 (68%)]	Loss: 8.2645	Cost: 9.34s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 8.3702	Cost: 8.78s
Train Epoch: 73 	Average Loss: 8.3339
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3995

Learning rate: 0.00019997370359165596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 8.3347	Cost: 26.34s
Train Epoch: 74 [20480/90000 (23%)]	Loss: 8.3428	Cost: 9.33s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 8.2133	Cost: 9.21s
Train Epoch: 74 [61440/90000 (68%)]	Loss: 8.3036	Cost: 9.21s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 8.2045	Cost: 8.88s
Train Epoch: 74 	Average Loss: 8.2853
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2996

Learning rate: 0.0001999729782401967
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 8.3431	Cost: 24.57s
Train Epoch: 75 [20480/90000 (23%)]	Loss: 8.3315	Cost: 9.38s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 8.3218	Cost: 9.20s
Train Epoch: 75 [61440/90000 (68%)]	Loss: 8.2302	Cost: 9.28s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 8.3754	Cost: 8.96s
Train Epoch: 75 	Average Loss: 8.2572
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2723

Learning rate: 0.00019997224302180006
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 8.2106	Cost: 24.57s
Train Epoch: 76 [20480/90000 (23%)]	Loss: 8.6024	Cost: 9.33s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 8.1946	Cost: 9.37s
Train Epoch: 76 [61440/90000 (68%)]	Loss: 8.3405	Cost: 9.10s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 8.2057	Cost: 8.85s
Train Epoch: 76 	Average Loss: 8.1980
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2909

Learning rate: 0.00019997149793653861
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 8.2885	Cost: 23.85s
Train Epoch: 77 [20480/90000 (23%)]	Loss: 8.2233	Cost: 9.35s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 8.1639	Cost: 9.23s
Train Epoch: 77 [61440/90000 (68%)]	Loss: 8.1196	Cost: 9.33s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 8.1248	Cost: 8.89s
Train Epoch: 77 	Average Loss: 8.1962
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2088

Learning rate: 0.00019997074298448586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 8.3113	Cost: 23.85s
Train Epoch: 78 [20480/90000 (23%)]	Loss: 8.0540	Cost: 9.36s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 8.0706	Cost: 9.27s
Train Epoch: 78 [61440/90000 (68%)]	Loss: 8.1909	Cost: 9.27s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 8.1256	Cost: 9.09s
Train Epoch: 78 	Average Loss: 8.1405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1987

Learning rate: 0.00019996997816571638
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 8.1222	Cost: 24.04s
Train Epoch: 79 [20480/90000 (23%)]	Loss: 8.0735	Cost: 9.42s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 8.1141	Cost: 9.29s
Train Epoch: 79 [61440/90000 (68%)]	Loss: 8.1803	Cost: 9.34s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 8.0464	Cost: 9.00s
Train Epoch: 79 	Average Loss: 8.1425
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1161

Learning rate: 0.00019996920348030559
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 8.2084	Cost: 23.94s
Train Epoch: 80 [20480/90000 (23%)]	Loss: 8.0659	Cost: 9.70s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 8.1961	Cost: 9.28s
Train Epoch: 80 [61440/90000 (68%)]	Loss: 8.1434	Cost: 9.13s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 8.1466	Cost: 9.05s
Train Epoch: 80 	Average Loss: 8.1839
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1246

Learning rate: 0.00019996841892832998
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 8.0933	Cost: 24.76s
Train Epoch: 81 [20480/90000 (23%)]	Loss: 8.1783	Cost: 9.62s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 8.1979	Cost: 9.28s
Train Epoch: 81 [61440/90000 (68%)]	Loss: 8.2220	Cost: 9.22s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 8.0629	Cost: 8.96s
Train Epoch: 81 	Average Loss: 8.1010
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0652

Learning rate: 0.00019996762450986697
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 8.3082	Cost: 23.87s
Train Epoch: 82 [20480/90000 (23%)]	Loss: 7.9902	Cost: 9.47s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 8.1286	Cost: 9.33s
Train Epoch: 82 [61440/90000 (68%)]	Loss: 8.1489	Cost: 9.02s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 8.1805	Cost: 9.08s
Train Epoch: 82 	Average Loss: 8.0627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1591

Learning rate: 0.00019996682022499498
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 8.2116	Cost: 24.53s
Train Epoch: 83 [20480/90000 (23%)]	Loss: 8.1809	Cost: 9.53s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 8.0908	Cost: 9.30s
Train Epoch: 83 [61440/90000 (68%)]	Loss: 7.9354	Cost: 9.24s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 7.9898	Cost: 8.76s
Train Epoch: 83 	Average Loss: 8.0428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0718

Learning rate: 0.0001999660060737934
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 8.2417	Cost: 24.18s
Train Epoch: 84 [20480/90000 (23%)]	Loss: 8.0264	Cost: 9.11s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 7.9722	Cost: 9.04s
Train Epoch: 84 [61440/90000 (68%)]	Loss: 8.0176	Cost: 8.93s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 8.0362	Cost: 8.64s
Train Epoch: 84 	Average Loss: 8.0022
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0191

Learning rate: 0.00019996518205634255
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 8.0411	Cost: 23.83s
Train Epoch: 85 [20480/90000 (23%)]	Loss: 8.1034	Cost: 9.10s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 8.0983	Cost: 9.56s
Train Epoch: 85 [61440/90000 (68%)]	Loss: 8.0595	Cost: 8.99s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 8.0557	Cost: 9.16s
Train Epoch: 85 	Average Loss: 8.0159
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0011

Learning rate: 0.0001999643481727238
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 8.0164	Cost: 23.11s
Train Epoch: 86 [20480/90000 (23%)]	Loss: 8.0553	Cost: 9.05s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 7.9013	Cost: 9.13s
Train Epoch: 86 [61440/90000 (68%)]	Loss: 8.0113	Cost: 9.11s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 7.9765	Cost: 9.69s
Train Epoch: 86 	Average Loss: 7.9514
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0551

Learning rate: 0.0001999635044230194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 8.3175	Cost: 23.96s
Train Epoch: 87 [20480/90000 (23%)]	Loss: 8.1094	Cost: 9.20s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 8.1607	Cost: 9.08s
Train Epoch: 87 [61440/90000 (68%)]	Loss: 7.9426	Cost: 9.07s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 8.0292	Cost: 9.81s
Train Epoch: 87 	Average Loss: 7.9946
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9883

Learning rate: 0.00019996265080731267
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 7.9768	Cost: 23.77s
Train Epoch: 88 [20480/90000 (23%)]	Loss: 8.0522	Cost: 9.30s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 8.0481	Cost: 9.19s
Train Epoch: 88 [61440/90000 (68%)]	Loss: 7.8501	Cost: 9.07s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 8.0095	Cost: 9.00s
Train Epoch: 88 	Average Loss: 7.9017
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0061

Learning rate: 0.00019996178732568782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 8.0083	Cost: 23.43s
Train Epoch: 89 [20480/90000 (23%)]	Loss: 7.9078	Cost: 9.02s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 7.8589	Cost: 9.59s
Train Epoch: 89 [61440/90000 (68%)]	Loss: 7.8461	Cost: 9.29s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 7.8987	Cost: 9.00s
Train Epoch: 89 	Average Loss: 7.8591
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0792

Learning rate: 0.00019996091397823007
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 8.0929	Cost: 22.60s
Train Epoch: 90 [20480/90000 (23%)]	Loss: 7.8736	Cost: 9.28s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 7.8013	Cost: 9.29s
Train Epoch: 90 [61440/90000 (68%)]	Loss: 7.8316	Cost: 9.20s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 7.9008	Cost: 9.18s
Train Epoch: 90 	Average Loss: 7.8607
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9675

Learning rate: 0.00019996003076502562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 7.8907	Cost: 22.82s
Train Epoch: 91 [20480/90000 (23%)]	Loss: 7.9002	Cost: 9.27s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 7.8128	Cost: 9.25s
Train Epoch: 91 [61440/90000 (68%)]	Loss: 7.6449	Cost: 9.13s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 7.8408	Cost: 9.26s
Train Epoch: 91 	Average Loss: 7.8221
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7739

Learning rate: 0.0001999591376861617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 7.8670	Cost: 23.13s
Train Epoch: 92 [20480/90000 (23%)]	Loss: 7.8620	Cost: 9.28s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 7.8702	Cost: 9.33s
Train Epoch: 92 [61440/90000 (68%)]	Loss: 7.8366	Cost: 9.10s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 7.7635	Cost: 9.11s
Train Epoch: 92 	Average Loss: 7.8246
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9399

Learning rate: 0.0001999582347417264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 7.8488	Cost: 22.60s
Train Epoch: 93 [20480/90000 (23%)]	Loss: 7.7394	Cost: 9.31s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 7.7971	Cost: 9.46s
Train Epoch: 93 [61440/90000 (68%)]	Loss: 7.7382	Cost: 9.37s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 7.8138	Cost: 8.96s
Train Epoch: 93 	Average Loss: 7.7749
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8663

Learning rate: 0.00019995732193180883
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 7.8476	Cost: 24.52s
Train Epoch: 94 [20480/90000 (23%)]	Loss: 7.7275	Cost: 9.54s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 7.8408	Cost: 9.91s
Train Epoch: 94 [61440/90000 (68%)]	Loss: 7.9345	Cost: 9.06s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 7.7869	Cost: 9.00s
Train Epoch: 94 	Average Loss: 7.7571
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8755

Learning rate: 0.00019995639925649909
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 7.9247	Cost: 23.59s
Train Epoch: 95 [20480/90000 (23%)]	Loss: 7.6971	Cost: 9.35s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 7.8449	Cost: 9.20s
Train Epoch: 95 [61440/90000 (68%)]	Loss: 7.7307	Cost: 9.02s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 7.7003	Cost: 8.90s
Train Epoch: 95 	Average Loss: 7.7413
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6864

Learning rate: 0.00019995546671588827
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 7.7568	Cost: 24.66s
Train Epoch: 96 [20480/90000 (23%)]	Loss: 7.6952	Cost: 9.36s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 7.6565	Cost: 9.45s
Train Epoch: 96 [61440/90000 (68%)]	Loss: 7.8227	Cost: 8.94s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 7.6249	Cost: 8.92s
Train Epoch: 96 	Average Loss: 7.7139
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7625

Learning rate: 0.0001999545243100684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 7.7706	Cost: 23.60s
Train Epoch: 97 [20480/90000 (23%)]	Loss: 7.7046	Cost: 9.51s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 7.7387	Cost: 9.42s
Train Epoch: 97 [61440/90000 (68%)]	Loss: 7.6277	Cost: 9.16s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 7.7144	Cost: 8.81s
Train Epoch: 97 	Average Loss: 7.6909
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7857

Learning rate: 0.00019995357203913245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 7.8441	Cost: 24.14s
Train Epoch: 98 [20480/90000 (23%)]	Loss: 7.9127	Cost: 9.45s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 7.6056	Cost: 9.28s
Train Epoch: 98 [61440/90000 (68%)]	Loss: 7.7131	Cost: 9.31s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 7.7362	Cost: 8.87s
Train Epoch: 98 	Average Loss: 7.6846
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6910

Learning rate: 0.00019995260990317447
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 7.7160	Cost: 25.12s
Train Epoch: 99 [20480/90000 (23%)]	Loss: 7.7190	Cost: 9.27s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 7.6874	Cost: 9.36s
Train Epoch: 99 [61440/90000 (68%)]	Loss: 7.6025	Cost: 9.23s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 7.6578	Cost: 9.13s
Train Epoch: 99 	Average Loss: 7.6817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7516

Learning rate: 0.00019995163790228936
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 7.7970	Cost: 25.05s
Train Epoch: 100 [20480/90000 (23%)]	Loss: 7.8036	Cost: 9.24s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 7.6858	Cost: 9.25s
Train Epoch: 100 [61440/90000 (68%)]	Loss: 7.8198	Cost: 9.16s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 7.5335	Cost: 8.81s
Train Epoch: 100 	Average Loss: 7.6299
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7835

Saving model as model.pt_e100 & waveforms_supplementary.hdf5_e100
Learning rate: 0.0001999506560365731
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 7.7144	Cost: 24.39s
Train Epoch: 101 [20480/90000 (23%)]	Loss: 7.5859	Cost: 9.14s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 7.6350	Cost: 9.29s
Train Epoch: 101 [61440/90000 (68%)]	Loss: 7.6070	Cost: 8.92s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 7.5780	Cost: 8.81s
Train Epoch: 101 	Average Loss: 7.5746
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7035

Learning rate: 0.00019994966430612258
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 7.7776	Cost: 23.84s
Train Epoch: 102 [20480/90000 (23%)]	Loss: 7.5301	Cost: 9.34s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 7.5546	Cost: 9.13s
Train Epoch: 102 [61440/90000 (68%)]	Loss: 7.6968	Cost: 8.98s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 7.6931	Cost: 8.77s
Train Epoch: 102 	Average Loss: 7.5780
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7347

Learning rate: 0.00019994866271103568
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 7.8237	Cost: 23.58s
Train Epoch: 103 [20480/90000 (23%)]	Loss: 7.5219	Cost: 9.43s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 7.6788	Cost: 9.28s
Train Epoch: 103 [61440/90000 (68%)]	Loss: 7.6731	Cost: 9.08s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 7.5222	Cost: 8.70s
Train Epoch: 103 	Average Loss: 7.5704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6156

Learning rate: 0.0001999476512514112
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 7.6007	Cost: 25.10s
Train Epoch: 104 [20480/90000 (23%)]	Loss: 7.4861	Cost: 9.32s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 7.6546	Cost: 9.30s
Train Epoch: 104 [61440/90000 (68%)]	Loss: 7.5527	Cost: 9.18s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 7.4912	Cost: 8.71s
Train Epoch: 104 	Average Loss: 7.4984
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6377

Learning rate: 0.00019994662992734905
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 7.8376	Cost: 24.51s
Train Epoch: 105 [20480/90000 (23%)]	Loss: 7.5186	Cost: 9.38s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 7.4874	Cost: 9.59s
Train Epoch: 105 [61440/90000 (68%)]	Loss: 7.4335	Cost: 9.24s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 7.3829	Cost: 8.73s
Train Epoch: 105 	Average Loss: 7.4939
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5345

Learning rate: 0.00019994559873894998
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 7.5363	Cost: 23.37s
Train Epoch: 106 [20480/90000 (23%)]	Loss: 7.5040	Cost: 9.29s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 7.4996	Cost: 9.31s
Train Epoch: 106 [61440/90000 (68%)]	Loss: 7.7841	Cost: 9.15s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 7.5143	Cost: 8.80s
Train Epoch: 106 	Average Loss: 7.5109
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7390

Learning rate: 0.00019994455768631577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 7.5801	Cost: 24.08s
Train Epoch: 107 [20480/90000 (23%)]	Loss: 7.3454	Cost: 9.34s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 7.4328	Cost: 9.27s
Train Epoch: 107 [61440/90000 (68%)]	Loss: 7.5705	Cost: 9.14s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 7.4951	Cost: 8.80s
Train Epoch: 107 	Average Loss: 7.4512
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4701

Learning rate: 0.00019994350676954918
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 7.6416	Cost: 24.12s
Train Epoch: 108 [20480/90000 (23%)]	Loss: 7.4578	Cost: 9.30s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 7.3725	Cost: 9.12s
Train Epoch: 108 [61440/90000 (68%)]	Loss: 7.3184	Cost: 9.23s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 7.3120	Cost: 8.63s
Train Epoch: 108 	Average Loss: 7.4310
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5689

Learning rate: 0.00019994244598875392
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 7.6120	Cost: 23.93s
Train Epoch: 109 [20480/90000 (23%)]	Loss: 7.3583	Cost: 9.06s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 7.4529	Cost: 9.23s
Train Epoch: 109 [61440/90000 (68%)]	Loss: 7.3792	Cost: 9.09s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 7.4896	Cost: 8.78s
Train Epoch: 109 	Average Loss: 7.3971
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4674

Learning rate: 0.00019994137534403472
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 7.4516	Cost: 23.30s
Train Epoch: 110 [20480/90000 (23%)]	Loss: 7.4291	Cost: 9.08s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 7.4350	Cost: 9.26s
Train Epoch: 110 [61440/90000 (68%)]	Loss: 7.5346	Cost: 9.06s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 7.3513	Cost: 8.95s
Train Epoch: 110 	Average Loss: 7.3990
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5128

Learning rate: 0.00019994029483549723
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 7.4721	Cost: 22.20s
Train Epoch: 111 [20480/90000 (23%)]	Loss: 7.3581	Cost: 9.12s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 7.4117	Cost: 9.06s
Train Epoch: 111 [61440/90000 (68%)]	Loss: 7.3629	Cost: 9.07s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 7.3385	Cost: 9.13s
Train Epoch: 111 	Average Loss: 7.3372
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4422

Learning rate: 0.00019993920446324803
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 7.5488	Cost: 24.40s
Train Epoch: 112 [20480/90000 (23%)]	Loss: 7.2919	Cost: 9.42s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 7.4018	Cost: 9.11s
Train Epoch: 112 [61440/90000 (68%)]	Loss: 7.3693	Cost: 9.07s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 7.3082	Cost: 9.10s
Train Epoch: 112 	Average Loss: 7.3446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4499

Learning rate: 0.00019993810422739487
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 7.4469	Cost: 23.60s
Train Epoch: 113 [20480/90000 (23%)]	Loss: 7.2309	Cost: 9.25s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 7.4347	Cost: 9.25s
Train Epoch: 113 [61440/90000 (68%)]	Loss: 7.2455	Cost: 9.02s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 7.2400	Cost: 9.00s
Train Epoch: 113 	Average Loss: 7.3085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4751

Learning rate: 0.00019993699412804622
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 7.3789	Cost: 22.93s
Train Epoch: 114 [20480/90000 (23%)]	Loss: 7.4382	Cost: 9.30s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 7.3115	Cost: 9.36s
Train Epoch: 114 [61440/90000 (68%)]	Loss: 7.3746	Cost: 9.28s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 7.3870	Cost: 9.15s
Train Epoch: 114 	Average Loss: 7.3094
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3953

Learning rate: 0.00019993587416531166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 7.2563	Cost: 22.52s
Train Epoch: 115 [20480/90000 (23%)]	Loss: 7.1345	Cost: 9.27s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 7.4219	Cost: 9.22s
Train Epoch: 115 [61440/90000 (68%)]	Loss: 7.2956	Cost: 9.25s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 7.2636	Cost: 9.15s
Train Epoch: 115 	Average Loss: 7.2375
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4493

Learning rate: 0.00019993474433930176
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 7.4484	Cost: 22.50s
Train Epoch: 116 [20480/90000 (23%)]	Loss: 7.2401	Cost: 9.29s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 7.2830	Cost: 9.26s
Train Epoch: 116 [61440/90000 (68%)]	Loss: 7.2835	Cost: 9.07s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 7.2247	Cost: 9.08s
Train Epoch: 116 	Average Loss: 7.2364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4057

Learning rate: 0.000199933604650128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 7.4849	Cost: 23.77s
Train Epoch: 117 [20480/90000 (23%)]	Loss: 7.0592	Cost: 9.31s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 7.3714	Cost: 9.29s
Train Epoch: 117 [61440/90000 (68%)]	Loss: 7.2764	Cost: 9.01s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 7.3222	Cost: 9.16s
Train Epoch: 117 	Average Loss: 7.2071
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3629

Learning rate: 0.0001999324550979029
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 7.3771	Cost: 23.59s
Train Epoch: 118 [20480/90000 (23%)]	Loss: 7.1715	Cost: 9.39s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 7.1913	Cost: 9.31s
Train Epoch: 118 [61440/90000 (68%)]	Loss: 7.2517	Cost: 9.03s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 7.1667	Cost: 8.99s
Train Epoch: 118 	Average Loss: 7.2095
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3529

Learning rate: 0.00019993129568273988
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 7.4181	Cost: 23.31s
Train Epoch: 119 [20480/90000 (23%)]	Loss: 7.0090	Cost: 9.41s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 7.5569	Cost: 9.18s
Train Epoch: 119 [61440/90000 (68%)]	Loss: 7.1961	Cost: 8.95s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 7.0833	Cost: 8.81s
Train Epoch: 119 	Average Loss: 7.2234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3328

Learning rate: 0.0001999301264047534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 7.4385	Cost: 24.27s
Train Epoch: 120 [20480/90000 (23%)]	Loss: 7.2166	Cost: 9.27s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 7.0420	Cost: 9.34s
Train Epoch: 120 [61440/90000 (68%)]	Loss: 7.2359	Cost: 9.11s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 7.0668	Cost: 8.72s
Train Epoch: 120 	Average Loss: 7.1800
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3423

Learning rate: 0.00019992894726405882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 7.2277	Cost: 25.33s
Train Epoch: 121 [20480/90000 (23%)]	Loss: 7.1150	Cost: 9.30s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 7.0344	Cost: 9.14s
Train Epoch: 121 [61440/90000 (68%)]	Loss: 7.0922	Cost: 8.95s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 7.1053	Cost: 8.69s
Train Epoch: 121 	Average Loss: 7.1193
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2289

Learning rate: 0.00019992775826077256
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 7.2162	Cost: 24.61s
Train Epoch: 122 [20480/90000 (23%)]	Loss: 7.0766	Cost: 9.42s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 7.0074	Cost: 9.28s
Train Epoch: 122 [61440/90000 (68%)]	Loss: 7.0753	Cost: 9.09s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 6.9447	Cost: 8.83s
Train Epoch: 122 	Average Loss: 7.0564
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3213

Learning rate: 0.00019992655939501196
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 7.2953	Cost: 24.87s
Train Epoch: 123 [20480/90000 (23%)]	Loss: 7.1070	Cost: 9.31s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 6.9886	Cost: 9.21s
Train Epoch: 123 [61440/90000 (68%)]	Loss: 7.2544	Cost: 9.12s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 6.9688	Cost: 8.78s
Train Epoch: 123 	Average Loss: 7.0632
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2914

Learning rate: 0.00019992535066689534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 7.2514	Cost: 24.44s
Train Epoch: 124 [20480/90000 (23%)]	Loss: 7.0993	Cost: 9.36s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 7.0166	Cost: 9.35s
Train Epoch: 124 [61440/90000 (68%)]	Loss: 6.9951	Cost: 9.21s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 7.1019	Cost: 8.87s
Train Epoch: 124 	Average Loss: 7.0406
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2072

Learning rate: 0.00019992413207654198
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 7.3538	Cost: 23.62s
Train Epoch: 125 [20480/90000 (23%)]	Loss: 6.8643	Cost: 9.65s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 7.0589	Cost: 9.28s
Train Epoch: 125 [61440/90000 (68%)]	Loss: 7.0280	Cost: 9.19s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 6.9785	Cost: 9.04s
Train Epoch: 125 	Average Loss: 6.9948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1935

Learning rate: 0.0001999229036240722
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 7.3006	Cost: 23.72s
Train Epoch: 126 [20480/90000 (23%)]	Loss: 6.9078	Cost: 9.33s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 6.9686	Cost: 9.35s
Train Epoch: 126 [61440/90000 (68%)]	Loss: 7.0080	Cost: 9.11s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 7.0205	Cost: 9.02s
Train Epoch: 126 	Average Loss: 6.9862
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2253

Learning rate: 0.0001999216653096072
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 7.3648	Cost: 24.42s
Train Epoch: 127 [20480/90000 (23%)]	Loss: 6.9815	Cost: 9.37s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 6.9204	Cost: 9.28s
Train Epoch: 127 [61440/90000 (68%)]	Loss: 6.9995	Cost: 8.89s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 6.9814	Cost: 8.97s
Train Epoch: 127 	Average Loss: 6.9641
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2211

Learning rate: 0.00019992041713326917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 7.1129	Cost: 23.70s
Train Epoch: 128 [20480/90000 (23%)]	Loss: 6.8709	Cost: 9.46s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 6.9721	Cost: 9.26s
Train Epoch: 128 [61440/90000 (68%)]	Loss: 6.9993	Cost: 9.06s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 7.0203	Cost: 8.79s
Train Epoch: 128 	Average Loss: 6.9401
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2290

Learning rate: 0.00019991915909518135
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 7.1330	Cost: 23.94s
Train Epoch: 129 [20480/90000 (23%)]	Loss: 6.8770	Cost: 9.43s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 6.8868	Cost: 9.18s
Train Epoch: 129 [61440/90000 (68%)]	Loss: 6.9197	Cost: 9.03s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 6.9139	Cost: 8.69s
Train Epoch: 129 	Average Loss: 6.8855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1884

Learning rate: 0.0001999178911954679
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 7.1631	Cost: 23.86s
Train Epoch: 130 [20480/90000 (23%)]	Loss: 6.6679	Cost: 9.08s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 6.7331	Cost: 9.02s
Train Epoch: 130 [61440/90000 (68%)]	Loss: 6.7140	Cost: 8.92s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 6.8909	Cost: 8.65s
Train Epoch: 130 	Average Loss: 6.8333
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2346

Learning rate: 0.0001999166134342539
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 7.1636	Cost: 23.69s
Train Epoch: 131 [20480/90000 (23%)]	Loss: 6.7018	Cost: 9.12s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 6.8118	Cost: 9.36s
Train Epoch: 131 [61440/90000 (68%)]	Loss: 6.7741	Cost: 9.06s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 6.9125	Cost: 8.85s
Train Epoch: 131 	Average Loss: 6.8083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0768

Learning rate: 0.00019991532581166554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 7.0445	Cost: 22.49s
Train Epoch: 132 [20480/90000 (23%)]	Loss: 6.7891	Cost: 9.10s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 6.7577	Cost: 9.15s
Train Epoch: 132 [61440/90000 (68%)]	Loss: 6.8000	Cost: 9.12s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 6.8003	Cost: 9.44s
Train Epoch: 132 	Average Loss: 6.8005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0748

Learning rate: 0.00019991402832782987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 6.8993	Cost: 22.13s
Train Epoch: 133 [20480/90000 (23%)]	Loss: 6.7521	Cost: 9.25s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 6.6728	Cost: 9.12s
Train Epoch: 133 [61440/90000 (68%)]	Loss: 6.7171	Cost: 9.11s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 6.6889	Cost: 9.06s
Train Epoch: 133 	Average Loss: 6.7266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0355

Learning rate: 0.00019991272098287494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 6.9912	Cost: 23.67s
Train Epoch: 134 [20480/90000 (23%)]	Loss: 6.6625	Cost: 9.17s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 6.7537	Cost: 9.40s
Train Epoch: 134 [61440/90000 (68%)]	Loss: 6.7630	Cost: 9.05s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 6.7747	Cost: 8.98s
Train Epoch: 134 	Average Loss: 6.7536
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0855

Learning rate: 0.00019991140377692977
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 6.9948	Cost: 22.85s
Train Epoch: 135 [20480/90000 (23%)]	Loss: 6.6728	Cost: 9.30s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 6.9094	Cost: 9.22s
Train Epoch: 135 [61440/90000 (68%)]	Loss: 6.7596	Cost: 9.31s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 6.6910	Cost: 9.14s
Train Epoch: 135 	Average Loss: 6.7129
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0475

Learning rate: 0.0001999100767101244
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 7.0564	Cost: 22.43s
Train Epoch: 136 [20480/90000 (23%)]	Loss: 6.6845	Cost: 9.32s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 6.6473	Cost: 9.38s
Train Epoch: 136 [61440/90000 (68%)]	Loss: 6.6479	Cost: 9.07s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 6.5788	Cost: 9.10s
Train Epoch: 136 	Average Loss: 6.6728
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9795

Learning rate: 0.00019990873978258976
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 6.9295	Cost: 22.65s
Train Epoch: 137 [20480/90000 (23%)]	Loss: 6.5503	Cost: 9.58s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 6.6609	Cost: 9.37s
Train Epoch: 137 [61440/90000 (68%)]	Loss: 6.6630	Cost: 9.04s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 6.5252	Cost: 9.23s
Train Epoch: 137 	Average Loss: 6.6278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9429

Learning rate: 0.0001999073929944578
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 6.9957	Cost: 23.79s
Train Epoch: 138 [20480/90000 (23%)]	Loss: 6.5329	Cost: 9.75s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 6.6407	Cost: 9.21s
Train Epoch: 138 [61440/90000 (68%)]	Loss: 6.6921	Cost: 8.97s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 6.6006	Cost: 9.12s
Train Epoch: 138 	Average Loss: 6.6425
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9384

Learning rate: 0.00019990603634586154
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 7.0819	Cost: 23.54s
Train Epoch: 139 [20480/90000 (23%)]	Loss: 6.5332	Cost: 9.36s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 6.5845	Cost: 9.26s
Train Epoch: 139 [61440/90000 (68%)]	Loss: 6.4658	Cost: 9.05s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 6.5473	Cost: 9.04s
Train Epoch: 139 	Average Loss: 6.5828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9303

Learning rate: 0.00019990466983693474
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 6.8819	Cost: 24.91s
Train Epoch: 140 [20480/90000 (23%)]	Loss: 6.4927	Cost: 9.33s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 6.7044	Cost: 9.54s
Train Epoch: 140 [61440/90000 (68%)]	Loss: 6.5959	Cost: 8.92s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 6.4476	Cost: 8.96s
Train Epoch: 140 	Average Loss: 6.5750
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8860

Learning rate: 0.00019990329346781236
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 6.9478	Cost: 23.63s
Train Epoch: 141 [20480/90000 (23%)]	Loss: 6.5486	Cost: 9.35s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 6.6472	Cost: 9.34s
Train Epoch: 141 [61440/90000 (68%)]	Loss: 6.4625	Cost: 9.08s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 6.4951	Cost: 8.83s
Train Epoch: 141 	Average Loss: 6.5154
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8527

Learning rate: 0.00019990190723863022
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 6.9074	Cost: 23.12s
Train Epoch: 142 [20480/90000 (23%)]	Loss: 6.4156	Cost: 9.37s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 6.5576	Cost: 9.44s
Train Epoch: 142 [61440/90000 (68%)]	Loss: 6.5983	Cost: 9.09s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 6.4626	Cost: 8.77s
Train Epoch: 142 	Average Loss: 6.4939
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8438

Learning rate: 0.00019990051114952508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 6.9219	Cost: 25.40s
Train Epoch: 143 [20480/90000 (23%)]	Loss: 6.3907	Cost: 9.34s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 6.4309	Cost: 9.28s
Train Epoch: 143 [61440/90000 (68%)]	Loss: 6.5053	Cost: 9.08s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 6.4825	Cost: 8.76s
Train Epoch: 143 	Average Loss: 6.4475
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8112

Learning rate: 0.0001998991052006348
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 6.7245	Cost: 24.06s
Train Epoch: 144 [20480/90000 (23%)]	Loss: 6.3025	Cost: 9.38s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 6.5374	Cost: 9.31s
Train Epoch: 144 [61440/90000 (68%)]	Loss: 6.3807	Cost: 9.45s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 6.4425	Cost: 8.72s
Train Epoch: 144 	Average Loss: 6.4298
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7553

Learning rate: 0.0001998976893920981
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 6.9747	Cost: 24.56s
Train Epoch: 145 [20480/90000 (23%)]	Loss: 6.2861	Cost: 9.38s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 6.3281	Cost: 9.26s
Train Epoch: 145 [61440/90000 (68%)]	Loss: 6.4164	Cost: 9.14s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 6.5548	Cost: 8.70s
Train Epoch: 145 	Average Loss: 6.3963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7881

Learning rate: 0.00019989626372405477
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 6.6881	Cost: 24.77s
Train Epoch: 146 [20480/90000 (23%)]	Loss: 6.4219	Cost: 9.26s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 6.3595	Cost: 9.36s
Train Epoch: 146 [61440/90000 (68%)]	Loss: 6.2527	Cost: 9.34s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 6.3440	Cost: 8.79s
Train Epoch: 146 	Average Loss: 6.3581
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7592

Learning rate: 0.00019989482819664545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 6.6551	Cost: 24.16s
Train Epoch: 147 [20480/90000 (23%)]	Loss: 6.2477	Cost: 9.29s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 6.3724	Cost: 9.30s
Train Epoch: 147 [61440/90000 (68%)]	Loss: 6.2895	Cost: 9.13s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 6.3071	Cost: 8.79s
Train Epoch: 147 	Average Loss: 6.2984
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6381

Learning rate: 0.00019989338281001189
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 6.5725	Cost: 25.92s
Train Epoch: 148 [20480/90000 (23%)]	Loss: 6.1816	Cost: 9.48s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 6.2552	Cost: 9.36s
Train Epoch: 148 [61440/90000 (68%)]	Loss: 6.2885	Cost: 9.29s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 6.3466	Cost: 8.64s
Train Epoch: 148 	Average Loss: 6.2525
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6700

Learning rate: 0.00019989192756429667
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 6.6034	Cost: 24.40s
Train Epoch: 149 [20480/90000 (23%)]	Loss: 6.4092	Cost: 9.35s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 6.1897	Cost: 9.24s
Train Epoch: 149 [61440/90000 (68%)]	Loss: 6.1605	Cost: 9.10s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 6.1275	Cost: 9.00s
Train Epoch: 149 	Average Loss: 6.2263
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6605

Learning rate: 0.00019989046245964345
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 6.9508	Cost: 24.79s
Train Epoch: 150 [20480/90000 (23%)]	Loss: 6.1340	Cost: 9.37s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 6.1668	Cost: 9.23s
Train Epoch: 150 [61440/90000 (68%)]	Loss: 6.2643	Cost: 9.37s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 6.2341	Cost: 8.74s
Train Epoch: 150 	Average Loss: 6.2095
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6561

Saving model as model.pt_e150 & waveforms_supplementary.hdf5_e150
Learning rate: 0.00019988898749619688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 6.6265	Cost: 24.45s
Train Epoch: 151 [20480/90000 (23%)]	Loss: 6.2740	Cost: 9.35s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 6.1678	Cost: 9.22s
Train Epoch: 151 [61440/90000 (68%)]	Loss: 6.0565	Cost: 9.10s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 6.2943	Cost: 8.93s
Train Epoch: 151 	Average Loss: 6.1760
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6864

Learning rate: 0.00019988750267410245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 6.6355	Cost: 25.69s
Train Epoch: 152 [20480/90000 (23%)]	Loss: 6.0935	Cost: 9.31s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 6.1951	Cost: 9.35s
Train Epoch: 152 [61440/90000 (68%)]	Loss: 6.1310	Cost: 8.97s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 5.9462	Cost: 8.88s
Train Epoch: 152 	Average Loss: 6.1350
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5745

Learning rate: 0.0001998860079935067
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 6.5954	Cost: 24.45s
Train Epoch: 153 [20480/90000 (23%)]	Loss: 6.2914	Cost: 9.35s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 6.0531	Cost: 9.31s
Train Epoch: 153 [61440/90000 (68%)]	Loss: 6.0926	Cost: 9.29s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 6.1125	Cost: 8.77s
Train Epoch: 153 	Average Loss: 6.1234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5731

Learning rate: 0.00019988450345455726
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 6.5849	Cost: 25.29s
Train Epoch: 154 [20480/90000 (23%)]	Loss: 5.8610	Cost: 9.27s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 6.0673	Cost: 9.28s
Train Epoch: 154 [61440/90000 (68%)]	Loss: 6.1144	Cost: 9.08s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 6.0857	Cost: 8.80s
Train Epoch: 154 	Average Loss: 6.0817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6252

Learning rate: 0.00019988298905740252
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 6.6391	Cost: 24.23s
Train Epoch: 155 [20480/90000 (23%)]	Loss: 5.9372	Cost: 9.37s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 6.0621	Cost: 9.34s
Train Epoch: 155 [61440/90000 (68%)]	Loss: 6.0657	Cost: 9.17s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 5.9970	Cost: 8.66s
Train Epoch: 155 	Average Loss: 6.0354
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5177

Learning rate: 0.000199881464802192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 6.5511	Cost: 23.67s
Train Epoch: 156 [20480/90000 (23%)]	Loss: 6.0043	Cost: 9.34s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 6.0207	Cost: 9.34s
Train Epoch: 156 [61440/90000 (68%)]	Loss: 5.9567	Cost: 9.24s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 5.8714	Cost: 8.70s
Train Epoch: 156 	Average Loss: 5.9821
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4864

Learning rate: 0.0001998799306890761
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 6.4850	Cost: 24.29s
Train Epoch: 157 [20480/90000 (23%)]	Loss: 5.9146	Cost: 9.37s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 5.8565	Cost: 9.23s
Train Epoch: 157 [61440/90000 (68%)]	Loss: 5.9427	Cost: 9.16s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 6.0061	Cost: 8.83s
Train Epoch: 157 	Average Loss: 5.9591
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6329

Learning rate: 0.00019987838671820622
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 6.6921	Cost: 26.88s
Train Epoch: 158 [20480/90000 (23%)]	Loss: 5.8186	Cost: 9.34s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 6.0212	Cost: 9.29s
Train Epoch: 158 [61440/90000 (68%)]	Loss: 5.9584	Cost: 9.20s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 5.9908	Cost: 8.69s
Train Epoch: 158 	Average Loss: 5.9547
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4262

Learning rate: 0.00019987683288973478
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 6.7225	Cost: 24.00s
Train Epoch: 159 [20480/90000 (23%)]	Loss: 5.8508	Cost: 9.32s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 5.8705	Cost: 9.30s
Train Epoch: 159 [61440/90000 (68%)]	Loss: 6.0087	Cost: 9.17s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 5.9266	Cost: 8.73s
Train Epoch: 159 	Average Loss: 5.9027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4607

Learning rate: 0.00019987526920381513
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 6.4378	Cost: 23.85s
Train Epoch: 160 [20480/90000 (23%)]	Loss: 5.7544	Cost: 9.27s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 5.7563	Cost: 9.07s
Train Epoch: 160 [61440/90000 (68%)]	Loss: 5.8635	Cost: 9.02s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 5.8259	Cost: 8.68s
Train Epoch: 160 	Average Loss: 5.8526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3968

Learning rate: 0.00019987369566060162
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 6.2534	Cost: 24.21s
Train Epoch: 161 [20480/90000 (23%)]	Loss: 5.6903	Cost: 9.03s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 5.8388	Cost: 9.03s
Train Epoch: 161 [61440/90000 (68%)]	Loss: 5.7920	Cost: 8.96s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 5.7801	Cost: 8.63s
Train Epoch: 161 	Average Loss: 5.8311
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4202

Learning rate: 0.0001998721122602495
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 6.3102	Cost: 23.48s
Train Epoch: 162 [20480/90000 (23%)]	Loss: 5.6831	Cost: 9.12s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 5.7823	Cost: 9.38s
Train Epoch: 162 [61440/90000 (68%)]	Loss: 5.8651	Cost: 9.06s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 5.7485	Cost: 9.49s
Train Epoch: 162 	Average Loss: 5.7743
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3608

Learning rate: 0.00019987051900291508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 6.3939	Cost: 22.37s
Train Epoch: 163 [20480/90000 (23%)]	Loss: 5.6192	Cost: 9.17s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 5.7130	Cost: 9.08s
Train Epoch: 163 [61440/90000 (68%)]	Loss: 5.8515	Cost: 9.19s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 5.7734	Cost: 9.37s
Train Epoch: 163 	Average Loss: 5.7494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3935

Learning rate: 0.00019986891588875562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 6.2930	Cost: 23.37s
Train Epoch: 164 [20480/90000 (23%)]	Loss: 5.5678	Cost: 9.09s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 5.6805	Cost: 9.51s
Train Epoch: 164 [61440/90000 (68%)]	Loss: 5.6631	Cost: 9.06s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 5.6526	Cost: 9.70s
Train Epoch: 164 	Average Loss: 5.6899
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2984

Learning rate: 0.0001998673029179293
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 6.2748	Cost: 23.62s
Train Epoch: 165 [20480/90000 (23%)]	Loss: 5.6150	Cost: 9.18s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 5.6613	Cost: 9.17s
Train Epoch: 165 [61440/90000 (68%)]	Loss: 5.6213	Cost: 9.05s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 5.6128	Cost: 9.10s
Train Epoch: 165 	Average Loss: 5.6875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2674

Learning rate: 0.00019986568009059536
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 6.5008	Cost: 22.85s
Train Epoch: 166 [20480/90000 (23%)]	Loss: 5.5876	Cost: 9.16s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 5.5854	Cost: 9.28s
Train Epoch: 166 [61440/90000 (68%)]	Loss: 5.6879	Cost: 9.14s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 5.6021	Cost: 9.02s
Train Epoch: 166 	Average Loss: 5.6560
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3023

Learning rate: 0.00019986404740691393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 6.1912	Cost: 22.03s
Train Epoch: 167 [20480/90000 (23%)]	Loss: 5.4847	Cost: 9.77s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 5.5108	Cost: 9.63s
Train Epoch: 167 [61440/90000 (68%)]	Loss: 5.6083	Cost: 9.10s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 5.6460	Cost: 9.07s
Train Epoch: 167 	Average Loss: 5.5738
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2973

Learning rate: 0.00019986240486704617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 6.2900	Cost: 22.75s
Train Epoch: 168 [20480/90000 (23%)]	Loss: 5.5803	Cost: 9.57s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 5.6489	Cost: 9.70s
Train Epoch: 168 [61440/90000 (68%)]	Loss: 5.5515	Cost: 8.93s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 5.6612	Cost: 9.16s
Train Epoch: 168 	Average Loss: 5.6029
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2235

Learning rate: 0.00019986075247115415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 6.1024	Cost: 22.43s
Train Epoch: 169 [20480/90000 (23%)]	Loss: 5.5256	Cost: 9.32s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 5.6430	Cost: 9.39s
Train Epoch: 169 [61440/90000 (68%)]	Loss: 5.5496	Cost: 9.05s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 5.4524	Cost: 8.97s
Train Epoch: 169 	Average Loss: 5.5485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2899

Learning rate: 0.00019985909021940103
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 6.1141	Cost: 23.83s
Train Epoch: 170 [20480/90000 (23%)]	Loss: 5.4480	Cost: 9.36s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 5.5124	Cost: 9.36s
Train Epoch: 170 [61440/90000 (68%)]	Loss: 5.4986	Cost: 9.00s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 5.5673	Cost: 8.86s
Train Epoch: 170 	Average Loss: 5.5106
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2140

Learning rate: 0.0001998574181119508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 6.3110	Cost: 24.51s
Train Epoch: 171 [20480/90000 (23%)]	Loss: 5.2681	Cost: 9.28s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 5.4433	Cost: 9.18s
Train Epoch: 171 [61440/90000 (68%)]	Loss: 5.5186	Cost: 8.89s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 5.7189	Cost: 8.74s
Train Epoch: 171 	Average Loss: 5.4951
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2098

Learning rate: 0.00019985573614896853
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 6.3598	Cost: 24.28s
Train Epoch: 172 [20480/90000 (23%)]	Loss: 5.3982	Cost: 9.31s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 5.6468	Cost: 9.26s
Train Epoch: 172 [61440/90000 (68%)]	Loss: 5.5099	Cost: 9.21s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 5.4446	Cost: 8.76s
Train Epoch: 172 	Average Loss: 5.5104
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1523

Learning rate: 0.00019985404433062024
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 6.0366	Cost: 23.90s
Train Epoch: 173 [20480/90000 (23%)]	Loss: 5.2713	Cost: 9.36s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 5.4878	Cost: 9.31s
Train Epoch: 173 [61440/90000 (68%)]	Loss: 5.3802	Cost: 9.09s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 5.4055	Cost: 8.75s
Train Epoch: 173 	Average Loss: 5.4531
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1061

Learning rate: 0.00019985234265707287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 6.2025	Cost: 24.63s
Train Epoch: 174 [20480/90000 (23%)]	Loss: 5.3585	Cost: 9.41s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 5.3238	Cost: 9.46s
Train Epoch: 174 [61440/90000 (68%)]	Loss: 5.2513	Cost: 9.13s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 5.2531	Cost: 8.78s
Train Epoch: 174 	Average Loss: 5.3250
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0117

Learning rate: 0.00019985063112849436
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 6.0602	Cost: 24.32s
Train Epoch: 175 [20480/90000 (23%)]	Loss: 5.1955	Cost: 9.41s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 5.3896	Cost: 9.32s
Train Epoch: 175 [61440/90000 (68%)]	Loss: 5.1548	Cost: 8.99s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 5.3635	Cost: 8.78s
Train Epoch: 175 	Average Loss: 5.3116
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1751

Learning rate: 0.00019984890974505368
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 6.1546	Cost: 25.50s
Train Epoch: 176 [20480/90000 (23%)]	Loss: 5.3553	Cost: 9.34s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 5.3601	Cost: 9.32s
Train Epoch: 176 [61440/90000 (68%)]	Loss: 5.3261	Cost: 9.15s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 5.2507	Cost: 8.73s
Train Epoch: 176 	Average Loss: 5.3571
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0069

Learning rate: 0.00019984717850692066
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 6.1253	Cost: 24.53s
Train Epoch: 177 [20480/90000 (23%)]	Loss: 5.1318	Cost: 9.37s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 5.2652	Cost: 9.30s
Train Epoch: 177 [61440/90000 (68%)]	Loss: 5.2992	Cost: 9.18s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 5.2911	Cost: 8.90s
Train Epoch: 177 	Average Loss: 5.2697
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0151

Learning rate: 0.00019984543741426617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 6.1526	Cost: 24.53s
Train Epoch: 178 [20480/90000 (23%)]	Loss: 5.2087	Cost: 9.41s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 5.1503	Cost: 9.25s
Train Epoch: 178 [61440/90000 (68%)]	Loss: 5.2947	Cost: 9.25s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 5.2403	Cost: 8.80s
Train Epoch: 178 	Average Loss: 5.1726
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9417

Learning rate: 0.0001998436864672621
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 5.9279	Cost: 26.91s
Train Epoch: 179 [20480/90000 (23%)]	Loss: 5.1071	Cost: 9.39s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 5.1714	Cost: 9.25s
Train Epoch: 179 [61440/90000 (68%)]	Loss: 5.1072	Cost: 9.11s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 5.1110	Cost: 8.80s
Train Epoch: 179 	Average Loss: 5.1385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9525

Learning rate: 0.00019984192566608125
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 5.7891	Cost: 26.65s
Train Epoch: 180 [20480/90000 (23%)]	Loss: 5.0268	Cost: 9.21s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 5.0552	Cost: 9.26s
Train Epoch: 180 [61440/90000 (68%)]	Loss: 5.2497	Cost: 9.61s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 5.1285	Cost: 8.80s
Train Epoch: 180 	Average Loss: 5.1705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1195

Learning rate: 0.00019984015501089739
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 6.0293	Cost: 24.45s
Train Epoch: 181 [20480/90000 (23%)]	Loss: 5.0600	Cost: 9.42s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 5.1011	Cost: 9.29s
Train Epoch: 181 [61440/90000 (68%)]	Loss: 5.1179	Cost: 9.15s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 5.0969	Cost: 8.86s
Train Epoch: 181 	Average Loss: 5.1174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8442

Learning rate: 0.00019983837450188524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 5.8770	Cost: 24.16s
Train Epoch: 182 [20480/90000 (23%)]	Loss: 4.8817	Cost: 9.40s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 5.0320	Cost: 9.29s
Train Epoch: 182 [61440/90000 (68%)]	Loss: 5.0197	Cost: 9.48s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 5.0811	Cost: 8.84s
Train Epoch: 182 	Average Loss: 5.0405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8320

Learning rate: 0.0001998365841392206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 5.7853	Cost: 24.38s
Train Epoch: 183 [20480/90000 (23%)]	Loss: 4.8851	Cost: 9.53s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 5.0122	Cost: 9.22s
Train Epoch: 183 [61440/90000 (68%)]	Loss: 5.0215	Cost: 9.15s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 5.1184	Cost: 8.94s
Train Epoch: 183 	Average Loss: 5.0217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8174

Learning rate: 0.00019983478392308012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 5.8253	Cost: 24.02s
Train Epoch: 184 [20480/90000 (23%)]	Loss: 4.9353	Cost: 9.33s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 5.0253	Cost: 9.32s
Train Epoch: 184 [61440/90000 (68%)]	Loss: 4.9779	Cost: 9.25s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 4.9055	Cost: 9.18s
Train Epoch: 184 	Average Loss: 4.9640
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8439

Learning rate: 0.0001998329738536415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 5.7974	Cost: 24.65s
Train Epoch: 185 [20480/90000 (23%)]	Loss: 4.8383	Cost: 9.36s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 4.8617	Cost: 9.29s
Train Epoch: 185 [61440/90000 (68%)]	Loss: 5.0135	Cost: 9.26s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 4.7919	Cost: 9.13s
Train Epoch: 185 	Average Loss: 4.9600
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7079

Learning rate: 0.00019983115393108338
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 5.6889	Cost: 24.08s
Train Epoch: 186 [20480/90000 (23%)]	Loss: 4.6553	Cost: 9.42s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 4.8608	Cost: 9.19s
Train Epoch: 186 [61440/90000 (68%)]	Loss: 4.9068	Cost: 9.19s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 4.8650	Cost: 8.97s
Train Epoch: 186 	Average Loss: 4.8665
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8020

Learning rate: 0.0001998293241555854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 5.8877	Cost: 24.57s
Train Epoch: 187 [20480/90000 (23%)]	Loss: 4.8297	Cost: 9.39s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 4.8444	Cost: 9.33s
Train Epoch: 187 [61440/90000 (68%)]	Loss: 4.9832	Cost: 9.09s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 4.7884	Cost: 9.03s
Train Epoch: 187 	Average Loss: 4.8564
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7961

Learning rate: 0.0001998274845273281
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 5.7324	Cost: 24.30s
Train Epoch: 188 [20480/90000 (23%)]	Loss: 4.6280	Cost: 9.56s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 4.8032	Cost: 9.25s
Train Epoch: 188 [61440/90000 (68%)]	Loss: 4.7717	Cost: 9.12s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 4.7615	Cost: 9.07s
Train Epoch: 188 	Average Loss: 4.8226
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7191

Learning rate: 0.00019982563504649309
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 5.6624	Cost: 24.03s
Train Epoch: 189 [20480/90000 (23%)]	Loss: 4.6424	Cost: 9.80s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 4.8857	Cost: 9.34s
Train Epoch: 189 [61440/90000 (68%)]	Loss: 4.8015	Cost: 9.45s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 4.8093	Cost: 8.96s
Train Epoch: 189 	Average Loss: 4.7812
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6942

Learning rate: 0.00019982377571326284
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 5.7768	Cost: 23.84s
Train Epoch: 190 [20480/90000 (23%)]	Loss: 4.6394	Cost: 9.84s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 4.7245	Cost: 9.14s
Train Epoch: 190 [61440/90000 (68%)]	Loss: 4.7256	Cost: 8.99s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 4.7274	Cost: 8.92s
Train Epoch: 190 	Average Loss: 4.7610
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6778

Learning rate: 0.00019982190652782097
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 5.6535	Cost: 24.03s
Train Epoch: 191 [20480/90000 (23%)]	Loss: 4.8045	Cost: 9.30s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 4.8477	Cost: 9.15s
Train Epoch: 191 [61440/90000 (68%)]	Loss: 4.7090	Cost: 9.02s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 4.6858	Cost: 8.71s
Train Epoch: 191 	Average Loss: 4.7328
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6735

Learning rate: 0.0001998200274903519
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 5.6531	Cost: 23.96s
Train Epoch: 192 [20480/90000 (23%)]	Loss: 4.5829	Cost: 9.12s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 4.6865	Cost: 9.05s
Train Epoch: 192 [61440/90000 (68%)]	Loss: 4.4497	Cost: 9.01s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 4.7526	Cost: 8.68s
Train Epoch: 192 	Average Loss: 4.6469
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6543

Learning rate: 0.00019981813860104106
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 5.6250	Cost: 24.00s
Train Epoch: 193 [20480/90000 (23%)]	Loss: 4.4700	Cost: 9.09s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 4.5383	Cost: 9.51s
Train Epoch: 193 [61440/90000 (68%)]	Loss: 4.5420	Cost: 9.05s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 4.5336	Cost: 8.97s
Train Epoch: 193 	Average Loss: 4.5881
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5922

Learning rate: 0.0001998162398600749
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 5.3329	Cost: 22.34s
Train Epoch: 194 [20480/90000 (23%)]	Loss: 4.3837	Cost: 8.99s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 4.7080	Cost: 9.12s
Train Epoch: 194 [61440/90000 (68%)]	Loss: 4.7449	Cost: 9.06s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 4.5833	Cost: 9.49s
Train Epoch: 194 	Average Loss: 4.6291
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5740

Learning rate: 0.00019981433126764085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 5.5752	Cost: 23.59s
Train Epoch: 195 [20480/90000 (23%)]	Loss: 4.4605	Cost: 9.22s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 4.5825	Cost: 9.09s
Train Epoch: 195 [61440/90000 (68%)]	Loss: 4.4809	Cost: 9.04s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 4.5046	Cost: 9.58s
Train Epoch: 195 	Average Loss: 4.5308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4790

Learning rate: 0.00019981241282392723
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 5.3379	Cost: 22.51s
Train Epoch: 196 [20480/90000 (23%)]	Loss: 4.4482	Cost: 9.44s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 4.4136	Cost: 9.28s
Train Epoch: 196 [61440/90000 (68%)]	Loss: 4.3580	Cost: 9.13s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 4.4977	Cost: 8.99s
Train Epoch: 196 	Average Loss: 4.5002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5391

Learning rate: 0.0001998104845291234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 5.5802	Cost: 22.98s
Train Epoch: 197 [20480/90000 (23%)]	Loss: 4.3933	Cost: 8.99s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 4.4430	Cost: 9.31s
Train Epoch: 197 [61440/90000 (68%)]	Loss: 4.4102	Cost: 9.08s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 4.5008	Cost: 9.80s
Train Epoch: 197 	Average Loss: 4.4690
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4926

Learning rate: 0.00019980854638341968
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 5.5212	Cost: 21.99s
Train Epoch: 198 [20480/90000 (23%)]	Loss: 4.6171	Cost: 9.03s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 4.5018	Cost: 9.72s
Train Epoch: 198 [61440/90000 (68%)]	Loss: 4.4433	Cost: 8.88s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 4.5482	Cost: 8.97s
Train Epoch: 198 	Average Loss: 4.5572
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5112

Learning rate: 0.00019980659838700736
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 5.5153	Cost: 22.97s
Train Epoch: 199 [20480/90000 (23%)]	Loss: 4.2662	Cost: 9.06s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 4.3809	Cost: 9.12s
Train Epoch: 199 [61440/90000 (68%)]	Loss: 4.4082	Cost: 8.86s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 4.4103	Cost: 8.97s
Train Epoch: 199 	Average Loss: 4.4097
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3973

Learning rate: 0.0001998046405400787
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 5.2170	Cost: 23.32s
Train Epoch: 200 [20480/90000 (23%)]	Loss: 4.2012	Cost: 9.42s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 4.4120	Cost: 9.23s
Train Epoch: 200 [61440/90000 (68%)]	Loss: 4.3187	Cost: 9.16s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 4.4760	Cost: 9.01s
Train Epoch: 200 	Average Loss: 4.3951
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4159

Saving model as model.pt_e200 & waveforms_supplementary.hdf5_e200
Learning rate: 0.00019980267284282693
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 5.4563	Cost: 22.17s
Train Epoch: 201 [20480/90000 (23%)]	Loss: 4.4155	Cost: 9.33s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 4.4889	Cost: 9.31s
Train Epoch: 201 [61440/90000 (68%)]	Loss: 4.4522	Cost: 9.36s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 4.3081	Cost: 9.10s
Train Epoch: 201 	Average Loss: 4.4676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3719

Learning rate: 0.00019980069529544622
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 5.3321	Cost: 23.92s
Train Epoch: 202 [20480/90000 (23%)]	Loss: 4.2284	Cost: 9.27s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 4.2812	Cost: 9.15s
Train Epoch: 202 [61440/90000 (68%)]	Loss: 4.2925	Cost: 8.86s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 4.2213	Cost: 8.93s
Train Epoch: 202 	Average Loss: 4.2809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3986

Learning rate: 0.0001997987078981318
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 5.2922	Cost: 23.30s
Train Epoch: 203 [20480/90000 (23%)]	Loss: 4.1617	Cost: 9.33s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 4.2475	Cost: 10.04s
Train Epoch: 203 [61440/90000 (68%)]	Loss: 4.3477	Cost: 9.17s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 4.2587	Cost: 8.88s
Train Epoch: 203 	Average Loss: 4.2337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2759

Learning rate: 0.00019979671065107978
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 5.2893	Cost: 23.62s
Train Epoch: 204 [20480/90000 (23%)]	Loss: 3.9826	Cost: 9.35s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 4.3107	Cost: 9.27s
Train Epoch: 204 [61440/90000 (68%)]	Loss: 4.1853	Cost: 9.10s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 4.2681	Cost: 8.89s
Train Epoch: 204 	Average Loss: 4.1772
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3496

Learning rate: 0.0001997947035544873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 5.3837	Cost: 24.87s
Train Epoch: 205 [20480/90000 (23%)]	Loss: 4.0307	Cost: 9.41s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 4.1993	Cost: 9.51s
Train Epoch: 205 [61440/90000 (68%)]	Loss: 4.0524	Cost: 8.93s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 4.1216	Cost: 8.76s
Train Epoch: 205 	Average Loss: 4.1650
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2786

Learning rate: 0.00019979268660855247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 5.2719	Cost: 24.61s
Train Epoch: 206 [20480/90000 (23%)]	Loss: 3.9899	Cost: 9.36s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 4.2794	Cost: 9.25s
Train Epoch: 206 [61440/90000 (68%)]	Loss: 4.0962	Cost: 9.06s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 4.1897	Cost: 8.79s
Train Epoch: 206 	Average Loss: 4.1386
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2140

Learning rate: 0.00019979065981347432
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 5.3432	Cost: 24.98s
Train Epoch: 207 [20480/90000 (23%)]	Loss: 3.9258	Cost: 9.32s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 4.1119	Cost: 9.19s
Train Epoch: 207 [61440/90000 (68%)]	Loss: 4.0136	Cost: 9.26s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 4.1119	Cost: 8.70s
Train Epoch: 207 	Average Loss: 4.1109
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2864

Learning rate: 0.0001997886231694529
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 5.2183	Cost: 25.22s
Train Epoch: 208 [20480/90000 (23%)]	Loss: 3.8505	Cost: 9.29s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 4.0340	Cost: 9.29s
Train Epoch: 208 [61440/90000 (68%)]	Loss: 3.9338	Cost: 9.10s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 3.9262	Cost: 8.77s
Train Epoch: 208 	Average Loss: 4.0316
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1757

Learning rate: 0.0001997865766766892
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 5.2440	Cost: 25.65s
Train Epoch: 209 [20480/90000 (23%)]	Loss: 3.8248	Cost: 9.33s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 4.0896	Cost: 9.28s
Train Epoch: 209 [61440/90000 (68%)]	Loss: 4.0883	Cost: 9.07s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 3.9342	Cost: 8.93s
Train Epoch: 209 	Average Loss: 3.9923
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2107

Learning rate: 0.00019978452033538524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 4.9913	Cost: 25.00s
Train Epoch: 210 [20480/90000 (23%)]	Loss: 3.8122	Cost: 9.32s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 3.9514	Cost: 9.49s
Train Epoch: 210 [61440/90000 (68%)]	Loss: 3.9328	Cost: 9.10s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 4.0103	Cost: 8.68s
Train Epoch: 210 	Average Loss: 3.9933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1242

Learning rate: 0.00019978245414574395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 5.2352	Cost: 25.92s
Train Epoch: 211 [20480/90000 (23%)]	Loss: 3.6781	Cost: 9.31s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 3.9270	Cost: 9.28s
Train Epoch: 211 [61440/90000 (68%)]	Loss: 3.8894	Cost: 9.13s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 3.8780	Cost: 8.70s
Train Epoch: 211 	Average Loss: 3.9141
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1418

Learning rate: 0.00019978037810796924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 5.0460	Cost: 24.18s
Train Epoch: 212 [20480/90000 (23%)]	Loss: 3.9943	Cost: 9.47s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 3.9213	Cost: 9.19s
Train Epoch: 212 [61440/90000 (68%)]	Loss: 4.0257	Cost: 9.02s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 3.9175	Cost: 8.85s
Train Epoch: 212 	Average Loss: 3.9586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0547

Learning rate: 0.000199778292222266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 4.8836	Cost: 23.98s
Train Epoch: 213 [20480/90000 (23%)]	Loss: 3.8589	Cost: 9.08s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 3.8426	Cost: 9.06s
Train Epoch: 213 [61440/90000 (68%)]	Loss: 3.8652	Cost: 8.93s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 4.0817	Cost: 8.64s
Train Epoch: 213 	Average Loss: 3.9111
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2292

Learning rate: 0.00019977619648884015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 5.1175	Cost: 24.03s
Train Epoch: 214 [20480/90000 (23%)]	Loss: 3.6590	Cost: 9.09s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 3.8848	Cost: 9.28s
Train Epoch: 214 [61440/90000 (68%)]	Loss: 3.8744	Cost: 9.01s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 3.7861	Cost: 8.72s
Train Epoch: 214 	Average Loss: 3.8684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0674

Learning rate: 0.0001997740909078985
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 4.9921	Cost: 22.53s
Train Epoch: 215 [20480/90000 (23%)]	Loss: 3.6171	Cost: 9.08s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 3.8841	Cost: 9.38s
Train Epoch: 215 [61440/90000 (68%)]	Loss: 3.8249	Cost: 9.11s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 3.8079	Cost: 9.38s
Train Epoch: 215 	Average Loss: 3.8080
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2233

Learning rate: 0.0001997719754796489
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 4.9748	Cost: 22.67s
Train Epoch: 216 [20480/90000 (23%)]	Loss: 3.6491	Cost: 9.11s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 3.7853	Cost: 9.23s
Train Epoch: 216 [61440/90000 (68%)]	Loss: 3.7116	Cost: 9.13s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 3.7078	Cost: 9.64s
Train Epoch: 216 	Average Loss: 3.7899
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9525

Learning rate: 0.00019976985020430003
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 4.8077	Cost: 24.35s
Train Epoch: 217 [20480/90000 (23%)]	Loss: 3.5414	Cost: 9.16s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 3.6098	Cost: 9.11s
Train Epoch: 217 [61440/90000 (68%)]	Loss: 3.5975	Cost: 9.08s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 3.5637	Cost: 9.63s
Train Epoch: 217 	Average Loss: 3.7129
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9685

Learning rate: 0.00019976771508206176
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 4.8901	Cost: 22.48s
Train Epoch: 218 [20480/90000 (23%)]	Loss: 3.5024	Cost: 9.23s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 3.6900	Cost: 9.35s
Train Epoch: 218 [61440/90000 (68%)]	Loss: 3.7232	Cost: 9.24s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 3.6505	Cost: 9.18s
Train Epoch: 218 	Average Loss: 3.7027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9950

Learning rate: 0.00019976557011314476
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 4.6770	Cost: 21.49s
Train Epoch: 219 [20480/90000 (23%)]	Loss: 3.5961	Cost: 9.41s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 3.7358	Cost: 9.29s
Train Epoch: 219 [61440/90000 (68%)]	Loss: 3.6110	Cost: 9.18s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 3.5760	Cost: 9.19s
Train Epoch: 219 	Average Loss: 3.6546
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9066

Learning rate: 0.00019976341529776072
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 4.8176	Cost: 23.13s
Train Epoch: 220 [20480/90000 (23%)]	Loss: 3.5130	Cost: 9.38s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 3.5446	Cost: 9.52s
Train Epoch: 220 [61440/90000 (68%)]	Loss: 3.6034	Cost: 9.00s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 3.5734	Cost: 9.17s
Train Epoch: 220 	Average Loss: 3.5782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0573

Learning rate: 0.00019976125063612233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 4.7964	Cost: 23.47s
Train Epoch: 221 [20480/90000 (23%)]	Loss: 3.5373	Cost: 9.34s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 3.7452	Cost: 9.34s
Train Epoch: 221 [61440/90000 (68%)]	Loss: 3.6548	Cost: 9.05s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 3.6058	Cost: 9.23s
Train Epoch: 221 	Average Loss: 3.6382
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8792

Learning rate: 0.00019975907612844327
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 4.6287	Cost: 22.41s
Train Epoch: 222 [20480/90000 (23%)]	Loss: 3.3932	Cost: 9.37s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 3.5488	Cost: 9.09s
Train Epoch: 222 [61440/90000 (68%)]	Loss: 3.5218	Cost: 9.07s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 3.4289	Cost: 8.78s
Train Epoch: 222 	Average Loss: 3.5187
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7414

Learning rate: 0.00019975689177493812
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 4.7100	Cost: 23.37s
Train Epoch: 223 [20480/90000 (23%)]	Loss: 3.3601	Cost: 9.77s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 3.5578	Cost: 9.27s
Train Epoch: 223 [61440/90000 (68%)]	Loss: 3.3499	Cost: 8.91s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 3.3506	Cost: 8.65s
Train Epoch: 223 	Average Loss: 3.4995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7324

Learning rate: 0.00019975469757582245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 4.6784	Cost: 24.18s
Train Epoch: 224 [20480/90000 (23%)]	Loss: 3.3941	Cost: 9.31s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 3.4575	Cost: 9.56s
Train Epoch: 224 [61440/90000 (68%)]	Loss: 3.3916	Cost: 9.26s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 3.2822	Cost: 8.86s
Train Epoch: 224 	Average Loss: 3.4189
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8438

Learning rate: 0.00019975249353131286
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 4.7655	Cost: 23.93s
Train Epoch: 225 [20480/90000 (23%)]	Loss: 3.3798	Cost: 9.31s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 3.3638	Cost: 9.32s
Train Epoch: 225 [61440/90000 (68%)]	Loss: 3.4007	Cost: 9.15s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 3.2164	Cost: 8.76s
Train Epoch: 225 	Average Loss: 3.4114
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8003

Learning rate: 0.00019975027964162683
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 4.8960	Cost: 26.21s
Train Epoch: 226 [20480/90000 (23%)]	Loss: 3.2598	Cost: 9.30s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 3.4154	Cost: 9.35s
Train Epoch: 226 [61440/90000 (68%)]	Loss: 3.3801	Cost: 9.16s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 3.3388	Cost: 8.80s
Train Epoch: 226 	Average Loss: 3.3876
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6855

Learning rate: 0.0001997480559069829
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 4.6268	Cost: 24.23s
Train Epoch: 227 [20480/90000 (23%)]	Loss: 3.1735	Cost: 9.30s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 3.4512	Cost: 9.40s
Train Epoch: 227 [61440/90000 (68%)]	Loss: 3.7206	Cost: 9.14s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 3.5823	Cost: 8.83s
Train Epoch: 227 	Average Loss: 3.4766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8298

Learning rate: 0.00019974582232760058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 4.8395	Cost: 24.29s
Train Epoch: 228 [20480/90000 (23%)]	Loss: 3.2850	Cost: 9.33s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 3.4078	Cost: 9.30s
Train Epoch: 228 [61440/90000 (68%)]	Loss: 3.3582	Cost: 9.12s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 3.2946	Cost: 8.93s
Train Epoch: 228 	Average Loss: 3.4325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7218

Learning rate: 0.0001997435789037002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 4.6230	Cost: 23.83s
Train Epoch: 229 [20480/90000 (23%)]	Loss: 3.1053	Cost: 9.35s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 3.2292	Cost: 9.35s
Train Epoch: 229 [61440/90000 (68%)]	Loss: 3.2043	Cost: 9.14s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 3.2472	Cost: 9.05s
Train Epoch: 229 	Average Loss: 3.2914
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6153

Learning rate: 0.0001997413256355033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 4.3022	Cost: 23.57s
Train Epoch: 230 [20480/90000 (23%)]	Loss: 3.1084	Cost: 9.19s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 3.2550	Cost: 9.35s
Train Epoch: 230 [61440/90000 (68%)]	Loss: 3.1312	Cost: 9.07s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 3.4838	Cost: 8.94s
Train Epoch: 230 	Average Loss: 3.2557
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7088

Learning rate: 0.0001997390625232322
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 4.6565	Cost: 24.35s
Train Epoch: 231 [20480/90000 (23%)]	Loss: 3.3031	Cost: 9.46s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 3.1108	Cost: 9.29s
Train Epoch: 231 [61440/90000 (68%)]	Loss: 3.2856	Cost: 8.94s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 3.2126	Cost: 9.03s
Train Epoch: 231 	Average Loss: 3.2884
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6897

Learning rate: 0.00019973678956711026
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 4.6241	Cost: 24.15s
Train Epoch: 232 [20480/90000 (23%)]	Loss: 3.0463	Cost: 9.43s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 3.3625	Cost: 9.20s
Train Epoch: 232 [61440/90000 (68%)]	Loss: 3.2123	Cost: 9.01s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 3.0983	Cost: 8.78s
Train Epoch: 232 	Average Loss: 3.2609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7228

Learning rate: 0.00019973450676736185
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 4.5815	Cost: 24.48s
Train Epoch: 233 [20480/90000 (23%)]	Loss: 2.9796	Cost: 9.06s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 3.2559	Cost: 9.04s
Train Epoch: 233 [61440/90000 (68%)]	Loss: 3.0748	Cost: 8.90s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 3.1218	Cost: 8.62s
Train Epoch: 233 	Average Loss: 3.1578
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5509

Learning rate: 0.00019973221412421225
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 4.4160	Cost: 23.93s
Train Epoch: 234 [20480/90000 (23%)]	Loss: 2.9962	Cost: 9.09s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 3.0528	Cost: 9.28s
Train Epoch: 234 [61440/90000 (68%)]	Loss: 2.9247	Cost: 9.01s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 2.9819	Cost: 9.59s
Train Epoch: 234 	Average Loss: 3.0324
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4874

Learning rate: 0.0001997299116378877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 4.2975	Cost: 23.62s
Train Epoch: 235 [20480/90000 (23%)]	Loss: 2.8511	Cost: 9.18s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 2.9898	Cost: 9.53s
Train Epoch: 235 [61440/90000 (68%)]	Loss: 2.9340	Cost: 9.14s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 3.0471	Cost: 9.45s
Train Epoch: 235 	Average Loss: 3.0255
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4577

Learning rate: 0.0001997275993086155
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 4.2993	Cost: 22.74s
Train Epoch: 236 [20480/90000 (23%)]	Loss: 2.9476	Cost: 9.12s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 3.0240	Cost: 9.06s
Train Epoch: 236 [61440/90000 (68%)]	Loss: 2.9002	Cost: 9.10s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 3.0484	Cost: 9.22s
Train Epoch: 236 	Average Loss: 2.9985
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5214

Learning rate: 0.0001997252771366239
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 4.4202	Cost: 24.20s
Train Epoch: 237 [20480/90000 (23%)]	Loss: 2.7186	Cost: 9.33s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 3.1095	Cost: 9.08s
Train Epoch: 237 [61440/90000 (68%)]	Loss: 2.9540	Cost: 9.23s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 2.9803	Cost: 9.06s
Train Epoch: 237 	Average Loss: 2.9718
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4623

Learning rate: 0.000199722945122142
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 4.5759	Cost: 23.03s
Train Epoch: 238 [20480/90000 (23%)]	Loss: 3.0057	Cost: 9.18s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 3.0831	Cost: 9.35s
Train Epoch: 238 [61440/90000 (68%)]	Loss: 2.9534	Cost: 9.16s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 3.0753	Cost: 9.04s
Train Epoch: 238 	Average Loss: 3.0025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4554

Learning rate: 0.0001997206032654
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 4.4246	Cost: 23.05s
Train Epoch: 239 [20480/90000 (23%)]	Loss: 2.7401	Cost: 9.34s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 2.9631	Cost: 9.44s
Train Epoch: 239 [61440/90000 (68%)]	Loss: 2.8247	Cost: 9.27s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 2.8075	Cost: 9.31s
Train Epoch: 239 	Average Loss: 2.9200
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3293

Learning rate: 0.00019971825156662903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 4.2086	Cost: 22.14s
Train Epoch: 240 [20480/90000 (23%)]	Loss: 2.6934	Cost: 9.40s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 2.8688	Cost: 9.24s
Train Epoch: 240 [61440/90000 (68%)]	Loss: 2.8012	Cost: 9.27s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 2.6935	Cost: 9.20s
Train Epoch: 240 	Average Loss: 2.8346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3783

Learning rate: 0.00019971589002606117
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 4.5156	Cost: 22.97s
Train Epoch: 241 [20480/90000 (23%)]	Loss: 2.5914	Cost: 9.79s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 2.8560	Cost: 9.04s
Train Epoch: 241 [61440/90000 (68%)]	Loss: 2.7415	Cost: 8.87s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 2.7081	Cost: 8.97s
Train Epoch: 241 	Average Loss: 2.8514
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3542

Learning rate: 0.00019971351864392958
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 4.2697	Cost: 23.99s
Train Epoch: 242 [20480/90000 (23%)]	Loss: 2.6315	Cost: 9.26s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 2.9324	Cost: 9.09s
Train Epoch: 242 [61440/90000 (68%)]	Loss: 2.8033	Cost: 8.90s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 2.6423	Cost: 8.96s
Train Epoch: 242 	Average Loss: 2.8211
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3028

Learning rate: 0.00019971113742046817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 4.2291	Cost: 23.54s
Train Epoch: 243 [20480/90000 (23%)]	Loss: 2.5539	Cost: 9.41s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 2.6819	Cost: 9.13s
Train Epoch: 243 [61440/90000 (68%)]	Loss: 2.6406	Cost: 8.90s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 2.8413	Cost: 8.75s
Train Epoch: 243 	Average Loss: 2.7784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5299

Learning rate: 0.00019970874635591207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 4.4043	Cost: 24.52s
Train Epoch: 244 [20480/90000 (23%)]	Loss: 2.6941	Cost: 9.29s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 2.7973	Cost: 9.24s
Train Epoch: 244 [61440/90000 (68%)]	Loss: 2.7615	Cost: 8.98s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 2.7296	Cost: 8.64s
Train Epoch: 244 	Average Loss: 2.8241
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3339

Learning rate: 0.00019970634545049727
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 4.1292	Cost: 23.90s
Train Epoch: 245 [20480/90000 (23%)]	Loss: 2.5428	Cost: 9.34s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 2.8125	Cost: 9.30s
Train Epoch: 245 [61440/90000 (68%)]	Loss: 2.6913	Cost: 9.16s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 2.7069	Cost: 8.80s
Train Epoch: 245 	Average Loss: 2.7550
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4035

Learning rate: 0.0001997039347044607
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 4.4037	Cost: 26.67s
Train Epoch: 246 [20480/90000 (23%)]	Loss: 2.6252	Cost: 9.28s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 2.8981	Cost: 9.28s
Train Epoch: 246 [61440/90000 (68%)]	Loss: 2.9531	Cost: 9.36s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 2.7918	Cost: 8.94s
Train Epoch: 246 	Average Loss: 2.8297
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3156

Learning rate: 0.00019970151411804023
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 4.3277	Cost: 23.90s
Train Epoch: 247 [20480/90000 (23%)]	Loss: 2.6392	Cost: 9.42s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 2.7386	Cost: 9.31s
Train Epoch: 247 [61440/90000 (68%)]	Loss: 2.6043	Cost: 9.16s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 2.6074	Cost: 8.90s
Train Epoch: 247 	Average Loss: 2.6833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2313

Learning rate: 0.00019969908369147485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 4.1184	Cost: 26.82s
Train Epoch: 248 [20480/90000 (23%)]	Loss: 2.3505	Cost: 9.30s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 2.7066	Cost: 9.27s
Train Epoch: 248 [61440/90000 (68%)]	Loss: 2.7585	Cost: 9.13s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 2.6081	Cost: 8.73s
Train Epoch: 248 	Average Loss: 2.6397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2371

Learning rate: 0.00019969664342500438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 4.1999	Cost: 26.07s
Train Epoch: 249 [20480/90000 (23%)]	Loss: 2.4842	Cost: 9.51s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 2.6367	Cost: 9.28s
Train Epoch: 249 [61440/90000 (68%)]	Loss: 2.4930	Cost: 9.22s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 2.4574	Cost: 8.78s
Train Epoch: 249 	Average Loss: 2.5734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1786

Learning rate: 0.00019969419331886966
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 4.0566	Cost: 26.57s
Train Epoch: 250 [20480/90000 (23%)]	Loss: 2.4356	Cost: 9.28s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 2.6278	Cost: 9.28s
Train Epoch: 250 [61440/90000 (68%)]	Loss: 2.6085	Cost: 9.06s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 2.6189	Cost: 8.69s
Train Epoch: 250 	Average Loss: 2.5594
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2008

Saving model as model.pt_e250 & waveforms_supplementary.hdf5_e250
Learning rate: 0.0001996917333733126
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 3.9824	Cost: 23.70s
Train Epoch: 251 [20480/90000 (23%)]	Loss: 2.3102	Cost: 9.32s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 2.4224	Cost: 9.27s
Train Epoch: 251 [61440/90000 (68%)]	Loss: 2.3580	Cost: 9.03s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 2.4862	Cost: 8.80s
Train Epoch: 251 	Average Loss: 2.4707
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0600

Learning rate: 0.00019968926358857587
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 4.0657	Cost: 24.35s
Train Epoch: 252 [20480/90000 (23%)]	Loss: 2.3547	Cost: 9.30s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 2.5111	Cost: 9.31s
Train Epoch: 252 [61440/90000 (68%)]	Loss: 2.3353	Cost: 9.18s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 2.5266	Cost: 8.68s
Train Epoch: 252 	Average Loss: 2.4743
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1378

Learning rate: 0.00019968678396490325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 4.1719	Cost: 26.07s
Train Epoch: 253 [20480/90000 (23%)]	Loss: 2.2891	Cost: 9.54s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 2.6852	Cost: 9.21s
Train Epoch: 253 [61440/90000 (68%)]	Loss: 2.5017	Cost: 9.16s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 2.5414	Cost: 8.66s
Train Epoch: 253 	Average Loss: 2.5209
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0912

Learning rate: 0.00019968429450253954
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 4.2093	Cost: 23.90s
Train Epoch: 254 [20480/90000 (23%)]	Loss: 2.3307	Cost: 9.38s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 2.4868	Cost: 9.53s
Train Epoch: 254 [61440/90000 (68%)]	Loss: 2.3582	Cost: 9.46s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 2.2732	Cost: 8.74s
Train Epoch: 254 	Average Loss: 2.4014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0109

Learning rate: 0.0001996817952017304
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 4.0275	Cost: 26.46s
Train Epoch: 255 [20480/90000 (23%)]	Loss: 2.2074	Cost: 9.33s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 2.4318	Cost: 9.19s
Train Epoch: 255 [61440/90000 (68%)]	Loss: 2.4128	Cost: 9.27s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 2.4395	Cost: 8.70s
Train Epoch: 255 	Average Loss: 2.3783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1827

Learning rate: 0.00019967928606272244
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 4.1411	Cost: 24.35s
Train Epoch: 256 [20480/90000 (23%)]	Loss: 2.3129	Cost: 9.47s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 2.5103	Cost: 9.24s
Train Epoch: 256 [61440/90000 (68%)]	Loss: 2.2409	Cost: 9.10s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 2.4086	Cost: 8.90s
Train Epoch: 256 	Average Loss: 2.4295
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0811

Learning rate: 0.0001996767670857634
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 4.2020	Cost: 24.13s
Train Epoch: 257 [20480/90000 (23%)]	Loss: 2.2587	Cost: 9.45s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 2.4889	Cost: 9.27s
Train Epoch: 257 [61440/90000 (68%)]	Loss: 2.1936	Cost: 9.27s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 2.2818	Cost: 8.87s
Train Epoch: 257 	Average Loss: 2.3933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0000

Learning rate: 0.00019967423827110182
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 3.9940	Cost: 25.23s
Train Epoch: 258 [20480/90000 (23%)]	Loss: 2.2193	Cost: 9.40s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 2.2525	Cost: 9.31s
Train Epoch: 258 [61440/90000 (68%)]	Loss: 2.0755	Cost: 9.04s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 2.3015	Cost: 8.94s
Train Epoch: 258 	Average Loss: 2.2276
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9670

Learning rate: 0.00019967169961898734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 3.7552	Cost: 23.78s
Train Epoch: 259 [20480/90000 (23%)]	Loss: 2.0614	Cost: 9.36s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 2.1942	Cost: 9.39s
Train Epoch: 259 [61440/90000 (68%)]	Loss: 2.0608	Cost: 9.10s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 2.2520	Cost: 9.19s
Train Epoch: 259 	Average Loss: 2.2083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9352

Learning rate: 0.00019966915112967047
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 4.1320	Cost: 23.78s
Train Epoch: 260 [20480/90000 (23%)]	Loss: 2.1316	Cost: 9.34s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 2.3190	Cost: 9.40s
Train Epoch: 260 [61440/90000 (68%)]	Loss: 2.3001	Cost: 8.99s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 2.3481	Cost: 8.99s
Train Epoch: 260 	Average Loss: 2.3429
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9195

Learning rate: 0.00019966659280340273
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 3.6143	Cost: 24.30s
Train Epoch: 261 [20480/90000 (23%)]	Loss: 2.0845	Cost: 9.56s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 2.1616	Cost: 9.25s
Train Epoch: 261 [61440/90000 (68%)]	Loss: 2.1180	Cost: 8.98s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 2.2245	Cost: 9.26s
Train Epoch: 261 	Average Loss: 2.2353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8974

Learning rate: 0.00019966402464043667
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 3.7185	Cost: 23.91s
Train Epoch: 262 [20480/90000 (23%)]	Loss: 2.0226	Cost: 9.85s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 2.2729	Cost: 9.29s
Train Epoch: 262 [61440/90000 (68%)]	Loss: 2.0390	Cost: 8.99s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 2.2822	Cost: 8.93s
Train Epoch: 262 	Average Loss: 2.1404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8177

Learning rate: 0.00019966144664102572
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 3.7808	Cost: 24.40s
Train Epoch: 263 [20480/90000 (23%)]	Loss: 1.9892	Cost: 9.19s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 2.2836	Cost: 9.11s
Train Epoch: 263 [61440/90000 (68%)]	Loss: 1.9331	Cost: 8.92s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 1.9662	Cost: 8.78s
Train Epoch: 263 	Average Loss: 2.0677
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7200

Learning rate: 0.00019965885880542434
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 3.7656	Cost: 22.62s
Train Epoch: 264 [20480/90000 (23%)]	Loss: 1.8447	Cost: 9.17s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 2.0939	Cost: 9.11s
Train Epoch: 264 [61440/90000 (68%)]	Loss: 2.0645	Cost: 9.08s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 1.9817	Cost: 9.28s
Train Epoch: 264 	Average Loss: 1.9968
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8376

Learning rate: 0.00019965626113388794
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 3.4670	Cost: 22.58s
Train Epoch: 265 [20480/90000 (23%)]	Loss: 1.6735	Cost: 9.48s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 1.9081	Cost: 9.09s
Train Epoch: 265 [61440/90000 (68%)]	Loss: 1.7910	Cost: 9.09s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 1.9095	Cost: 9.26s
Train Epoch: 265 	Average Loss: 1.9768
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7220

Learning rate: 0.00019965365362667288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 3.5610	Cost: 23.20s
Train Epoch: 266 [20480/90000 (23%)]	Loss: 1.6896	Cost: 9.29s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 1.9897	Cost: 9.37s
Train Epoch: 266 [61440/90000 (68%)]	Loss: 1.8816	Cost: 9.24s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 1.8268	Cost: 9.07s
Train Epoch: 266 	Average Loss: 1.8750
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6445

Learning rate: 0.0001996510362840365
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 3.5421	Cost: 22.17s
Train Epoch: 267 [20480/90000 (23%)]	Loss: 1.6604	Cost: 9.28s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 1.9202	Cost: 9.35s
Train Epoch: 267 [61440/90000 (68%)]	Loss: 1.8919	Cost: 9.13s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 1.9325	Cost: 9.24s
Train Epoch: 267 	Average Loss: 1.9544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7911

Learning rate: 0.00019964840910623716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 3.5469	Cost: 22.89s
Train Epoch: 268 [20480/90000 (23%)]	Loss: 1.9230	Cost: 9.31s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 2.0663	Cost: 9.25s
Train Epoch: 268 [61440/90000 (68%)]	Loss: 1.8536	Cost: 9.27s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 1.7862	Cost: 9.16s
Train Epoch: 268 	Average Loss: 1.9445
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7407

Learning rate: 0.00019964577209353413
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 3.7708	Cost: 22.94s
Train Epoch: 269 [20480/90000 (23%)]	Loss: 1.8048	Cost: 9.37s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 1.9665	Cost: 9.31s
Train Epoch: 269 [61440/90000 (68%)]	Loss: 1.8448	Cost: 9.03s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 2.0428	Cost: 9.09s
Train Epoch: 269 	Average Loss: 1.9797
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7222

Learning rate: 0.00019964312524618766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 3.7495	Cost: 23.12s
Train Epoch: 270 [20480/90000 (23%)]	Loss: 1.8445	Cost: 9.38s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 1.8153	Cost: 9.23s
Train Epoch: 270 [61440/90000 (68%)]	Loss: 1.7731	Cost: 9.18s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 1.9139	Cost: 9.32s
Train Epoch: 270 	Average Loss: 1.9592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6742

Learning rate: 0.000199640468564459
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 3.3982	Cost: 24.21s
Train Epoch: 271 [20480/90000 (23%)]	Loss: 1.7712	Cost: 9.27s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 1.7975	Cost: 9.24s
Train Epoch: 271 [61440/90000 (68%)]	Loss: 1.7005	Cost: 9.14s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 1.7231	Cost: 8.81s
Train Epoch: 271 	Average Loss: 1.8097
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5454

Learning rate: 0.00019963780204861037
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 3.5182	Cost: 23.96s
Train Epoch: 272 [20480/90000 (23%)]	Loss: 1.6563	Cost: 9.37s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 1.7630	Cost: 9.31s
Train Epoch: 272 [61440/90000 (68%)]	Loss: 1.7282	Cost: 9.17s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 1.7947	Cost: 8.80s
Train Epoch: 272 	Average Loss: 1.7945
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6523

Learning rate: 0.0001996351256989049
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 3.4827	Cost: 25.85s
Train Epoch: 273 [20480/90000 (23%)]	Loss: 1.6740	Cost: 9.36s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 1.7987	Cost: 9.28s
Train Epoch: 273 [61440/90000 (68%)]	Loss: 1.6996	Cost: 9.17s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 1.7003	Cost: 8.80s
Train Epoch: 273 	Average Loss: 1.7530
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6199

Learning rate: 0.0001996324395156068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 3.4908	Cost: 25.60s
Train Epoch: 274 [20480/90000 (23%)]	Loss: 1.5459	Cost: 9.33s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 1.6800	Cost: 9.53s
Train Epoch: 274 [61440/90000 (68%)]	Loss: 1.4866	Cost: 9.12s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 1.6463	Cost: 8.73s
Train Epoch: 274 	Average Loss: 1.6561
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4845

Learning rate: 0.00019962974349898107
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 3.4407	Cost: 26.75s
Train Epoch: 275 [20480/90000 (23%)]	Loss: 1.4853	Cost: 9.30s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 1.5570	Cost: 9.32s
Train Epoch: 275 [61440/90000 (68%)]	Loss: 1.5474	Cost: 9.17s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 1.6686	Cost: 8.83s
Train Epoch: 275 	Average Loss: 1.6021
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4843

Learning rate: 0.0001996270376492939
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 3.4182	Cost: 24.38s
Train Epoch: 276 [20480/90000 (23%)]	Loss: 1.4241	Cost: 9.39s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 1.5740	Cost: 9.35s
Train Epoch: 276 [61440/90000 (68%)]	Loss: 1.3237	Cost: 9.21s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 1.4537	Cost: 8.87s
Train Epoch: 276 	Average Loss: 1.5317
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4879

Learning rate: 0.00019962432196681234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 3.2764	Cost: 23.91s
Train Epoch: 277 [20480/90000 (23%)]	Loss: 1.5542	Cost: 9.42s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 1.6893	Cost: 9.26s
Train Epoch: 277 [61440/90000 (68%)]	Loss: 1.6718	Cost: 9.21s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 1.5363	Cost: 8.98s
Train Epoch: 277 	Average Loss: 1.7103
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5289

Learning rate: 0.00019962159645180437
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 3.4533	Cost: 24.00s
Train Epoch: 278 [20480/90000 (23%)]	Loss: 1.3083	Cost: 9.33s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 1.4199	Cost: 9.29s
Train Epoch: 278 [61440/90000 (68%)]	Loss: 1.5458	Cost: 9.14s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 1.6071	Cost: 9.35s
Train Epoch: 278 	Average Loss: 1.5416
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4411

Learning rate: 0.00019961886110453903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 3.3299	Cost: 23.99s
Train Epoch: 279 [20480/90000 (23%)]	Loss: 1.4565	Cost: 9.36s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 1.6156	Cost: 9.23s
Train Epoch: 279 [61440/90000 (68%)]	Loss: 1.6144	Cost: 9.28s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 1.5745	Cost: 8.92s
Train Epoch: 279 	Average Loss: 1.5632
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4091

Learning rate: 0.00019961611592528625
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 3.4053	Cost: 23.87s
Train Epoch: 280 [20480/90000 (23%)]	Loss: 1.3636	Cost: 9.48s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 1.4307	Cost: 9.27s
Train Epoch: 280 [61440/90000 (68%)]	Loss: 1.5060	Cost: 9.15s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 1.5352	Cost: 8.98s
Train Epoch: 280 	Average Loss: 1.5380
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4355

Learning rate: 0.000199613360914317
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 3.1260	Cost: 24.56s
Train Epoch: 281 [20480/90000 (23%)]	Loss: 1.1842	Cost: 9.34s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 1.2870	Cost: 9.31s
Train Epoch: 281 [61440/90000 (68%)]	Loss: 1.2929	Cost: 9.15s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 1.2670	Cost: 9.10s
Train Epoch: 281 	Average Loss: 1.4006
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2519

Learning rate: 0.00019961059607190318
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 3.1380	Cost: 23.58s
Train Epoch: 282 [20480/90000 (23%)]	Loss: 1.0753	Cost: 9.41s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 1.3064	Cost: 9.44s
Train Epoch: 282 [61440/90000 (68%)]	Loss: 1.2595	Cost: 9.17s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 1.3647	Cost: 9.03s
Train Epoch: 282 	Average Loss: 1.3652
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3178

Learning rate: 0.00019960782139831766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 3.3365	Cost: 26.80s
Train Epoch: 283 [20480/90000 (23%)]	Loss: 1.0977	Cost: 9.41s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 1.4843	Cost: 9.22s
Train Epoch: 283 [61440/90000 (68%)]	Loss: 1.4011	Cost: 9.07s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 1.5000	Cost: 8.99s
Train Epoch: 283 	Average Loss: 1.4160
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2801

Learning rate: 0.00019960503689383428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 3.2183	Cost: 24.13s
Train Epoch: 284 [20480/90000 (23%)]	Loss: 1.1218	Cost: 9.34s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 1.3830	Cost: 9.29s
Train Epoch: 284 [61440/90000 (68%)]	Loss: 1.2408	Cost: 8.96s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 1.3356	Cost: 9.05s
Train Epoch: 284 	Average Loss: 1.3232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1601

Learning rate: 0.0001996022425587279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 3.1052	Cost: 24.50s
Train Epoch: 285 [20480/90000 (23%)]	Loss: 1.0616	Cost: 9.35s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 1.3763	Cost: 9.21s
Train Epoch: 285 [61440/90000 (68%)]	Loss: 1.1748	Cost: 9.02s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 1.0715	Cost: 8.87s
Train Epoch: 285 	Average Loss: 1.2668
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1786

Learning rate: 0.0001995994383932743
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 3.1589	Cost: 24.72s
Train Epoch: 286 [20480/90000 (23%)]	Loss: 0.9807	Cost: 9.53s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 1.3005	Cost: 9.19s
Train Epoch: 286 [61440/90000 (68%)]	Loss: 1.2934	Cost: 9.08s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 1.2892	Cost: 8.74s
Train Epoch: 286 	Average Loss: 1.2888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2017

Learning rate: 0.0001995966243977502
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 3.3332	Cost: 23.92s
Train Epoch: 287 [20480/90000 (23%)]	Loss: 1.0148	Cost: 9.07s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 1.2609	Cost: 9.30s
Train Epoch: 287 [61440/90000 (68%)]	Loss: 1.1615	Cost: 8.89s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 1.3581	Cost: 8.63s
Train Epoch: 287 	Average Loss: 1.2977
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2487

Learning rate: 0.0001995938005724334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 3.3303	Cost: 24.04s
Train Epoch: 288 [20480/90000 (23%)]	Loss: 0.9964	Cost: 9.12s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 1.2781	Cost: 9.45s
Train Epoch: 288 [61440/90000 (68%)]	Loss: 1.0142	Cost: 9.00s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 1.1833	Cost: 9.16s
Train Epoch: 288 	Average Loss: 1.2019
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1553

Learning rate: 0.00019959096691760252
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 3.1630	Cost: 23.02s
Train Epoch: 289 [20480/90000 (23%)]	Loss: 1.0217	Cost: 9.12s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 1.0735	Cost: 9.40s
Train Epoch: 289 [61440/90000 (68%)]	Loss: 1.2335	Cost: 9.03s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 1.3053	Cost: 9.81s
Train Epoch: 289 	Average Loss: 1.1758
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2680

Learning rate: 0.00019958812343353726
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 3.3104	Cost: 23.69s
Train Epoch: 290 [20480/90000 (23%)]	Loss: 0.7559	Cost: 9.11s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 1.1276	Cost: 9.05s
Train Epoch: 290 [61440/90000 (68%)]	Loss: 1.2114	Cost: 9.06s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 1.1739	Cost: 9.50s
Train Epoch: 290 	Average Loss: 1.1739
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1526

Learning rate: 0.0001995852701205183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 3.0506	Cost: 24.12s
Train Epoch: 291 [20480/90000 (23%)]	Loss: 0.9996	Cost: 9.29s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 1.1442	Cost: 9.16s
Train Epoch: 291 [61440/90000 (68%)]	Loss: 1.0375	Cost: 9.03s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 1.0368	Cost: 9.46s
Train Epoch: 291 	Average Loss: 1.1433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0007

Learning rate: 0.0001995824069788272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 2.9230	Cost: 22.72s
Train Epoch: 292 [20480/90000 (23%)]	Loss: 0.9361	Cost: 9.18s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 1.0609	Cost: 9.41s
Train Epoch: 292 [61440/90000 (68%)]	Loss: 0.9857	Cost: 9.10s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 1.1116	Cost: 9.05s
Train Epoch: 292 	Average Loss: 1.0559
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3726

Learning rate: 0.00019957953400874656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 3.5256	Cost: 22.28s
Train Epoch: 293 [20480/90000 (23%)]	Loss: 1.0913	Cost: 9.26s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 1.3710	Cost: 9.58s
Train Epoch: 293 [61440/90000 (68%)]	Loss: 1.3208	Cost: 9.53s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 1.2732	Cost: 9.09s
Train Epoch: 293 	Average Loss: 1.3681
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2085

Learning rate: 0.00019957665121055995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 2.9525	Cost: 22.53s
Train Epoch: 294 [20480/90000 (23%)]	Loss: 1.2196	Cost: 9.13s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 1.2048	Cost: 9.09s
Train Epoch: 294 [61440/90000 (68%)]	Loss: 1.1114	Cost: 9.05s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 1.0794	Cost: 8.99s
Train Epoch: 294 	Average Loss: 1.2897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1430

Learning rate: 0.00019957375858455185
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 3.0398	Cost: 22.98s
Train Epoch: 295 [20480/90000 (23%)]	Loss: 0.8494	Cost: 9.36s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 1.1030	Cost: 9.25s
Train Epoch: 295 [61440/90000 (68%)]	Loss: 1.0138	Cost: 9.05s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 1.1832	Cost: 9.10s
Train Epoch: 295 	Average Loss: 1.0772
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0708

Learning rate: 0.00019957085613100776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 3.0442	Cost: 24.78s
Train Epoch: 296 [20480/90000 (23%)]	Loss: 0.7282	Cost: 9.39s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 0.9444	Cost: 9.27s
Train Epoch: 296 [61440/90000 (68%)]	Loss: 0.8204	Cost: 9.02s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 1.0263	Cost: 8.96s
Train Epoch: 296 	Average Loss: 0.9384
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0749

Learning rate: 0.00019956794385021415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 2.8484	Cost: 24.43s
Train Epoch: 297 [20480/90000 (23%)]	Loss: 0.8135	Cost: 9.37s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 1.0054	Cost: 9.95s
Train Epoch: 297 [61440/90000 (68%)]	Loss: 0.8423	Cost: 9.21s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 1.0182	Cost: 8.92s
Train Epoch: 297 	Average Loss: 1.0159
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0422

Learning rate: 0.00019956502174245846
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 3.0683	Cost: 23.38s
Train Epoch: 298 [20480/90000 (23%)]	Loss: 0.8518	Cost: 9.34s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 1.0681	Cost: 9.41s
Train Epoch: 298 [61440/90000 (68%)]	Loss: 0.8297	Cost: 9.13s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 1.0180	Cost: 8.84s
Train Epoch: 298 	Average Loss: 0.9865
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1339

Learning rate: 0.0001995620898080291
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 2.8377	Cost: 24.01s
Train Epoch: 299 [20480/90000 (23%)]	Loss: 0.7426	Cost: 9.33s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 1.0322	Cost: 9.30s
Train Epoch: 299 [61440/90000 (68%)]	Loss: 0.7948	Cost: 9.03s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 0.8749	Cost: 8.65s
Train Epoch: 299 	Average Loss: 0.9125
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9811

Learning rate: 0.00019955914804721542
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 3.2762	Cost: 24.40s
Train Epoch: 300 [20480/90000 (23%)]	Loss: 0.6394	Cost: 9.34s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 0.8303	Cost: 9.29s
Train Epoch: 300 [61440/90000 (68%)]	Loss: 0.7551	Cost: 9.10s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 0.8954	Cost: 8.75s
Train Epoch: 300 	Average Loss: 0.8989
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9502

Saving model as model.pt_e300 & waveforms_supplementary.hdf5_e300
Learning rate: 0.00019955619646030775
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 2.9032	Cost: 24.32s
Train Epoch: 301 [20480/90000 (23%)]	Loss: 0.5224	Cost: 9.29s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 0.6016	Cost: 9.06s
Train Epoch: 301 [61440/90000 (68%)]	Loss: 0.6513	Cost: 8.83s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 0.6018	Cost: 8.85s
Train Epoch: 301 	Average Loss: 0.7126
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7871

Learning rate: 0.0001995532350475974
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 2.7037	Cost: 23.55s
Train Epoch: 302 [20480/90000 (23%)]	Loss: 0.3659	Cost: 9.27s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 0.8142	Cost: 9.16s
Train Epoch: 302 [61440/90000 (68%)]	Loss: 0.6824	Cost: 8.94s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 0.9064	Cost: 8.68s
Train Epoch: 302 	Average Loss: 0.7349
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8375

Learning rate: 0.00019955026380937669
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 2.6317	Cost: 24.33s
Train Epoch: 303 [20480/90000 (23%)]	Loss: 0.5506	Cost: 9.67s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 0.7378	Cost: 9.26s
Train Epoch: 303 [61440/90000 (68%)]	Loss: 0.7481	Cost: 9.14s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 0.7075	Cost: 8.65s
Train Epoch: 303 	Average Loss: 0.7480
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8199

Learning rate: 0.00019954728274593884
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 2.5409	Cost: 25.47s
Train Epoch: 304 [20480/90000 (23%)]	Loss: 0.5096	Cost: 9.25s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 0.8101	Cost: 9.26s
Train Epoch: 304 [61440/90000 (68%)]	Loss: 0.6590	Cost: 9.23s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 0.6129	Cost: 8.77s
Train Epoch: 304 	Average Loss: 0.7600
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8103

Learning rate: 0.00019954429185757805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 2.9478	Cost: 26.16s
Train Epoch: 305 [20480/90000 (23%)]	Loss: 0.4106	Cost: 9.30s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 0.5623	Cost: 9.55s
Train Epoch: 305 [61440/90000 (68%)]	Loss: 0.6792	Cost: 8.98s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 0.6644	Cost: 8.68s
Train Epoch: 305 	Average Loss: 0.6702
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7810

Learning rate: 0.00019954129114458955
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 2.8386	Cost: 24.00s
Train Epoch: 306 [20480/90000 (23%)]	Loss: 0.4911	Cost: 9.35s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 0.6641	Cost: 9.24s
Train Epoch: 306 [61440/90000 (68%)]	Loss: 0.5715	Cost: 9.12s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 0.8784	Cost: 8.77s
Train Epoch: 306 	Average Loss: 0.7143
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8702

Learning rate: 0.00019953828060726943
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 2.7421	Cost: 24.82s
Train Epoch: 307 [20480/90000 (23%)]	Loss: 0.5485	Cost: 9.35s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 0.5228	Cost: 9.29s
Train Epoch: 307 [61440/90000 (68%)]	Loss: 0.6420	Cost: 9.33s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 0.6061	Cost: 8.82s
Train Epoch: 307 	Average Loss: 0.6659
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8497

Learning rate: 0.00019953526024591494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 2.5796	Cost: 24.02s
Train Epoch: 308 [20480/90000 (23%)]	Loss: 0.3023	Cost: 9.40s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 0.4835	Cost: 9.31s
Train Epoch: 308 [61440/90000 (68%)]	Loss: 0.3824	Cost: 9.07s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 0.4083	Cost: 8.95s
Train Epoch: 308 	Average Loss: 0.5031
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6131

Learning rate: 0.00019953223006082406
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 2.4918	Cost: 24.11s
Train Epoch: 309 [20480/90000 (23%)]	Loss: 0.2629	Cost: 9.34s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 0.4861	Cost: 9.28s
Train Epoch: 309 [61440/90000 (68%)]	Loss: 0.2693	Cost: 9.32s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 0.7080	Cost: 9.00s
Train Epoch: 309 	Average Loss: 0.5198
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8140

Learning rate: 0.00019952919005229592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 2.6972	Cost: 23.96s
Train Epoch: 310 [20480/90000 (23%)]	Loss: 0.4184	Cost: 9.40s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 0.6159	Cost: 9.36s
Train Epoch: 310 [61440/90000 (68%)]	Loss: 0.3638	Cost: 9.11s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 0.5530	Cost: 9.06s
Train Epoch: 310 	Average Loss: 0.5532
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6787

Learning rate: 0.00019952614022063054
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 2.2852	Cost: 24.33s
Train Epoch: 311 [20480/90000 (23%)]	Loss: 0.2595	Cost: 9.44s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 0.7919	Cost: 9.26s
Train Epoch: 311 [61440/90000 (68%)]	Loss: 0.6271	Cost: 9.21s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 0.7843	Cost: 9.04s
Train Epoch: 311 	Average Loss: 0.6395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7347

Learning rate: 0.00019952308056612892
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 2.4851	Cost: 23.72s
Train Epoch: 312 [20480/90000 (23%)]	Loss: 0.2936	Cost: 9.43s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 0.5726	Cost: 9.42s
Train Epoch: 312 [61440/90000 (68%)]	Loss: 0.5656	Cost: 9.03s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 0.5700	Cost: 8.93s
Train Epoch: 312 	Average Loss: 0.5924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7280

Learning rate: 0.00019952001108909304
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 2.8429	Cost: 24.08s
Train Epoch: 313 [20480/90000 (23%)]	Loss: 0.4549	Cost: 9.49s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 0.9207	Cost: 9.84s
Train Epoch: 313 [61440/90000 (68%)]	Loss: 0.9055	Cost: 9.30s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 0.8151	Cost: 8.68s
Train Epoch: 313 	Average Loss: 0.8115
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6970

Learning rate: 0.00019951693178982586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 2.7072	Cost: 23.78s
Train Epoch: 314 [20480/90000 (23%)]	Loss: 0.3431	Cost: 9.12s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 0.4560	Cost: 9.03s
Train Epoch: 314 [61440/90000 (68%)]	Loss: 0.2596	Cost: 8.95s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 0.4533	Cost: 8.63s
Train Epoch: 314 	Average Loss: 0.5083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5449

Learning rate: 0.00019951384266863126
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 2.7600	Cost: 24.32s
Train Epoch: 315 [20480/90000 (23%)]	Loss: 0.2357	Cost: 9.06s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 0.4140	Cost: 9.75s
Train Epoch: 315 [61440/90000 (68%)]	Loss: 0.3998	Cost: 9.20s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 0.9001	Cost: 9.40s
Train Epoch: 315 	Average Loss: 0.4936
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9322

Learning rate: 0.00019951074372581416
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 2.9971	Cost: 21.58s
Train Epoch: 316 [20480/90000 (23%)]	Loss: 0.5460	Cost: 9.03s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 0.6005	Cost: 9.08s
Train Epoch: 316 [61440/90000 (68%)]	Loss: 0.5250	Cost: 9.07s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 0.5810	Cost: 9.05s
Train Epoch: 316 	Average Loss: 0.6597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5666

Learning rate: 0.00019950763496168037
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 2.4480	Cost: 23.01s
Train Epoch: 317 [20480/90000 (23%)]	Loss: 0.3205	Cost: 9.14s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 0.6091	Cost: 9.43s
Train Epoch: 317 [61440/90000 (68%)]	Loss: 0.5111	Cost: 9.38s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 0.5691	Cost: 9.37s
Train Epoch: 317 	Average Loss: 0.5430
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6255

Learning rate: 0.00019950451637653678
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 2.4776	Cost: 22.10s
Train Epoch: 318 [20480/90000 (23%)]	Loss: 0.1733	Cost: 9.38s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 0.4275	Cost: 9.23s
Train Epoch: 318 [61440/90000 (68%)]	Loss: 0.3772	Cost: 9.12s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 0.3650	Cost: 9.10s
Train Epoch: 318 	Average Loss: 0.3828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5408

Learning rate: 0.00019950138797069118
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 2.3296	Cost: 23.01s
Train Epoch: 319 [20480/90000 (23%)]	Loss: 0.2027	Cost: 9.37s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 0.1471	Cost: 9.85s
Train Epoch: 319 [61440/90000 (68%)]	Loss: 0.2884	Cost: 9.20s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 0.4019	Cost: 9.14s
Train Epoch: 319 	Average Loss: 0.3479
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4907

Learning rate: 0.00019949824974445222
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 2.3830	Cost: 23.36s
Train Epoch: 320 [20480/90000 (23%)]	Loss: 0.1606	Cost: 9.34s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 0.5857	Cost: 9.27s
Train Epoch: 320 [61440/90000 (68%)]	Loss: 0.4010	Cost: 9.03s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 0.6669	Cost: 9.11s
Train Epoch: 320 	Average Loss: 0.5031
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7587

Learning rate: 0.00019949510169812976
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 2.5972	Cost: 23.20s
Train Epoch: 321 [20480/90000 (23%)]	Loss: 0.3516	Cost: 9.43s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 0.2790	Cost: 9.24s
Train Epoch: 321 [61440/90000 (68%)]	Loss: 0.1590	Cost: 9.00s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 0.1321	Cost: 9.22s
Train Epoch: 321 	Average Loss: 0.3804
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4401

Learning rate: 0.00019949194383203438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 2.4723	Cost: 23.72s
Train Epoch: 322 [20480/90000 (23%)]	Loss: -0.0430	Cost: 9.35s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 0.2952	Cost: 9.28s
Train Epoch: 322 [61440/90000 (68%)]	Loss: 0.2029	Cost: 9.06s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 0.2890	Cost: 8.94s
Train Epoch: 322 	Average Loss: 0.2576
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3565

Learning rate: 0.00019948877614647787
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 2.2964	Cost: 23.97s
Train Epoch: 323 [20480/90000 (23%)]	Loss: -0.0728	Cost: 9.40s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 0.0044	Cost: 9.28s
Train Epoch: 323 [61440/90000 (68%)]	Loss: 0.0464	Cost: 9.08s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 0.0070	Cost: 8.96s
Train Epoch: 323 	Average Loss: 0.1139
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2640

Learning rate: 0.0001994855986417728
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 2.2023	Cost: 23.97s
Train Epoch: 324 [20480/90000 (23%)]	Loss: -0.1576	Cost: 9.33s
Train Epoch: 324 [40960/90000 (45%)]	Loss: -0.0208	Cost: 9.28s
Train Epoch: 324 [61440/90000 (68%)]	Loss: 0.0556	Cost: 9.26s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 0.0207	Cost: 8.91s
Train Epoch: 324 	Average Loss: 0.0531
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3003

Learning rate: 0.0001994824113182328
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 2.4145	Cost: 23.80s
Train Epoch: 325 [20480/90000 (23%)]	Loss: -0.1462	Cost: 9.38s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 0.0382	Cost: 9.32s
Train Epoch: 325 [61440/90000 (68%)]	Loss: 0.0096	Cost: 9.10s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 0.1283	Cost: 9.03s
Train Epoch: 325 	Average Loss: 0.1149
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2725

Learning rate: 0.00019947921417617242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 2.2591	Cost: 24.25s
Train Epoch: 326 [20480/90000 (23%)]	Loss: -0.1537	Cost: 9.44s
Train Epoch: 326 [40960/90000 (45%)]	Loss: -0.0657	Cost: 9.23s
Train Epoch: 326 [61440/90000 (68%)]	Loss: -0.0816	Cost: 9.27s
Train Epoch: 326 [81920/90000 (91%)]	Loss: -0.0563	Cost: 8.78s
Train Epoch: 326 	Average Loss: 0.0025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2281

Learning rate: 0.0001994760072159072
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 2.1624	Cost: 25.02s
Train Epoch: 327 [20480/90000 (23%)]	Loss: -0.3176	Cost: 9.31s
Train Epoch: 327 [40960/90000 (45%)]	Loss: -0.2364	Cost: 9.27s
Train Epoch: 327 [61440/90000 (68%)]	Loss: -0.1566	Cost: 9.24s
Train Epoch: 327 [81920/90000 (91%)]	Loss: -0.0404	Cost: 8.91s
Train Epoch: 327 	Average Loss: -0.0619
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0932

Learning rate: 0.00019947279043775368
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 2.2584	Cost: 23.88s
Train Epoch: 328 [20480/90000 (23%)]	Loss: -0.3784	Cost: 9.40s
Train Epoch: 328 [40960/90000 (45%)]	Loss: -0.3413	Cost: 9.33s
Train Epoch: 328 [61440/90000 (68%)]	Loss: -0.2069	Cost: 9.13s
Train Epoch: 328 [81920/90000 (91%)]	Loss: -0.1343	Cost: 8.86s
Train Epoch: 328 	Average Loss: -0.1261
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1536

Learning rate: 0.00019946956384202932
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 2.3051	Cost: 24.16s
Train Epoch: 329 [20480/90000 (23%)]	Loss: -0.2690	Cost: 9.41s
Train Epoch: 329 [40960/90000 (45%)]	Loss: -0.0987	Cost: 9.22s
Train Epoch: 329 [61440/90000 (68%)]	Loss: -0.0053	Cost: 9.17s
Train Epoch: 329 [81920/90000 (91%)]	Loss: -0.1097	Cost: 9.26s
Train Epoch: 329 	Average Loss: -0.0287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1815

Learning rate: 0.00019946632742905265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 2.2203	Cost: 23.80s
Train Epoch: 330 [20480/90000 (23%)]	Loss: -0.2540	Cost: 9.34s
Train Epoch: 330 [40960/90000 (45%)]	Loss: -0.2240	Cost: 9.31s
Train Epoch: 330 [61440/90000 (68%)]	Loss: -0.3329	Cost: 9.09s
Train Epoch: 330 [81920/90000 (91%)]	Loss: -0.1406	Cost: 8.94s
Train Epoch: 330 	Average Loss: -0.1350
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2211

Learning rate: 0.000199463081199143
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 2.1704	Cost: 24.14s
Train Epoch: 331 [20480/90000 (23%)]	Loss: -0.2133	Cost: 9.44s
Train Epoch: 331 [40960/90000 (45%)]	Loss: -0.2550	Cost: 9.33s
Train Epoch: 331 [61440/90000 (68%)]	Loss: -0.1029	Cost: 9.09s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 0.1115	Cost: 9.21s
Train Epoch: 331 	Average Loss: -0.0101
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2629

Learning rate: 0.0001994598251526208
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 2.1483	Cost: 23.96s
Train Epoch: 332 [20480/90000 (23%)]	Loss: -0.2407	Cost: 9.41s
Train Epoch: 332 [40960/90000 (45%)]	Loss: -0.0429	Cost: 9.30s
Train Epoch: 332 [61440/90000 (68%)]	Loss: -0.3480	Cost: 8.98s
Train Epoch: 332 [81920/90000 (91%)]	Loss: -0.1618	Cost: 9.04s
Train Epoch: 332 	Average Loss: -0.0874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1544

Learning rate: 0.00019945655928980737
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 1.8725	Cost: 24.03s
Train Epoch: 333 [20480/90000 (23%)]	Loss: -0.4061	Cost: 9.39s
Train Epoch: 333 [40960/90000 (45%)]	Loss: -0.1695	Cost: 9.95s
Train Epoch: 333 [61440/90000 (68%)]	Loss: -0.3195	Cost: 8.98s
Train Epoch: 333 [81920/90000 (91%)]	Loss: -0.0620	Cost: 8.92s
Train Epoch: 333 	Average Loss: -0.2166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1156

Learning rate: 0.0001994532836110251
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 2.0601	Cost: 23.94s
Train Epoch: 334 [20480/90000 (23%)]	Loss: -0.3084	Cost: 9.08s
Train Epoch: 334 [40960/90000 (45%)]	Loss: -0.0861	Cost: 9.04s
Train Epoch: 334 [61440/90000 (68%)]	Loss: 0.0097	Cost: 8.94s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 0.1184	Cost: 8.62s
Train Epoch: 334 	Average Loss: -0.0421
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3093

Learning rate: 0.00019944999811659725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 2.1126	Cost: 23.99s
Train Epoch: 335 [20480/90000 (23%)]	Loss: -0.2179	Cost: 9.08s
Train Epoch: 335 [40960/90000 (45%)]	Loss: -0.0672	Cost: 9.52s
Train Epoch: 335 [61440/90000 (68%)]	Loss: -0.2308	Cost: 9.14s
Train Epoch: 335 [81920/90000 (91%)]	Loss: -0.0188	Cost: 8.84s
Train Epoch: 335 	Average Loss: -0.0795
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1275

Learning rate: 0.00019944670280684805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 1.8571	Cost: 22.70s
Train Epoch: 336 [20480/90000 (23%)]	Loss: -0.6025	Cost: 9.11s
Train Epoch: 336 [40960/90000 (45%)]	Loss: -0.2528	Cost: 9.15s
Train Epoch: 336 [61440/90000 (68%)]	Loss: -0.1219	Cost: 9.14s
Train Epoch: 336 [81920/90000 (91%)]	Loss: -0.1103	Cost: 9.37s
Train Epoch: 336 	Average Loss: -0.2087
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1348

Learning rate: 0.00019944339768210285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 1.8936	Cost: 23.50s
Train Epoch: 337 [20480/90000 (23%)]	Loss: -0.4919	Cost: 9.12s
Train Epoch: 337 [40960/90000 (45%)]	Loss: -0.4832	Cost: 9.28s
Train Epoch: 337 [61440/90000 (68%)]	Loss: -0.5448	Cost: 9.09s
Train Epoch: 337 [81920/90000 (91%)]	Loss: -0.5042	Cost: 10.33s
Train Epoch: 337 	Average Loss: -0.3546
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9266

Learning rate: 0.0001994400827426877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 1.7428	Cost: 22.37s
Train Epoch: 338 [20480/90000 (23%)]	Loss: -0.5273	Cost: 9.26s
Train Epoch: 338 [40960/90000 (45%)]	Loss: -0.3060	Cost: 9.36s
Train Epoch: 338 [61440/90000 (68%)]	Loss: -0.5521	Cost: 9.06s
Train Epoch: 338 [81920/90000 (91%)]	Loss: -0.3382	Cost: 9.01s
Train Epoch: 338 	Average Loss: -0.3445
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0575

Learning rate: 0.0001994367579889299
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 1.8446	Cost: 22.71s
Train Epoch: 339 [20480/90000 (23%)]	Loss: -0.6197	Cost: 9.02s
Train Epoch: 339 [40960/90000 (45%)]	Loss: -0.0722	Cost: 9.03s
Train Epoch: 339 [61440/90000 (68%)]	Loss: -0.0524	Cost: 9.05s
Train Epoch: 339 [81920/90000 (91%)]	Loss: -0.1307	Cost: 9.14s
Train Epoch: 339 	Average Loss: -0.1820
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2381

Learning rate: 0.0001994334234211575
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 2.2116	Cost: 21.93s
Train Epoch: 340 [20480/90000 (23%)]	Loss: -0.4567	Cost: 9.07s
Train Epoch: 340 [40960/90000 (45%)]	Loss: -0.4411	Cost: 9.27s
Train Epoch: 340 [61440/90000 (68%)]	Loss: -0.3297	Cost: 9.11s
Train Epoch: 340 [81920/90000 (91%)]	Loss: -0.2645	Cost: 9.06s
Train Epoch: 340 	Average Loss: -0.2990
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9954

Learning rate: 0.00019943007903969968
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 1.9282	Cost: 23.77s
Train Epoch: 341 [20480/90000 (23%)]	Loss: -0.6821	Cost: 9.33s
Train Epoch: 341 [40960/90000 (45%)]	Loss: -0.2467	Cost: 9.31s
Train Epoch: 341 [61440/90000 (68%)]	Loss: -0.2412	Cost: 9.32s
Train Epoch: 341 [81920/90000 (91%)]	Loss: -0.3505	Cost: 9.55s
Train Epoch: 341 	Average Loss: -0.2817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0786

Learning rate: 0.00019942672484488645
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 1.8681	Cost: 23.49s
Train Epoch: 342 [20480/90000 (23%)]	Loss: -0.4919	Cost: 9.32s
Train Epoch: 342 [40960/90000 (45%)]	Loss: -0.4307	Cost: 9.30s
Train Epoch: 342 [61440/90000 (68%)]	Loss: -0.5226	Cost: 9.04s
Train Epoch: 342 [81920/90000 (91%)]	Loss: -0.3840	Cost: 9.09s
Train Epoch: 342 	Average Loss: -0.3455
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9088

Learning rate: 0.0001994233608370489
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 1.8457	Cost: 23.89s
Train Epoch: 343 [20480/90000 (23%)]	Loss: -0.7686	Cost: 9.42s
Train Epoch: 343 [40960/90000 (45%)]	Loss: -0.5752	Cost: 9.25s
Train Epoch: 343 [61440/90000 (68%)]	Loss: -0.4055	Cost: 9.12s
Train Epoch: 343 [81920/90000 (91%)]	Loss: -0.1063	Cost: 9.12s
Train Epoch: 343 	Average Loss: -0.3799
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1278

Learning rate: 0.00019941998701651908
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 2.0772	Cost: 23.24s
Train Epoch: 344 [20480/90000 (23%)]	Loss: -0.6543	Cost: 9.32s
Train Epoch: 344 [40960/90000 (45%)]	Loss: -0.4315	Cost: 9.29s
Train Epoch: 344 [61440/90000 (68%)]	Loss: -0.6134	Cost: 9.16s
Train Epoch: 344 [81920/90000 (91%)]	Loss: -0.6337	Cost: 8.88s
Train Epoch: 344 	Average Loss: -0.4701
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0148

Learning rate: 0.00019941660338362987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 2.0566	Cost: 23.63s
Train Epoch: 345 [20480/90000 (23%)]	Loss: -0.8037	Cost: 9.37s
Train Epoch: 345 [40960/90000 (45%)]	Loss: -0.5193	Cost: 9.22s
Train Epoch: 345 [61440/90000 (68%)]	Loss: -0.7242	Cost: 9.22s
Train Epoch: 345 [81920/90000 (91%)]	Loss: -0.3985	Cost: 8.88s
Train Epoch: 345 	Average Loss: -0.5484
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8787

Learning rate: 0.0001994132099387153
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 1.7229	Cost: 23.88s
Train Epoch: 346 [20480/90000 (23%)]	Loss: -0.8479	Cost: 9.41s
Train Epoch: 346 [40960/90000 (45%)]	Loss: -0.5303	Cost: 9.27s
Train Epoch: 346 [61440/90000 (68%)]	Loss: -0.6814	Cost: 9.24s
Train Epoch: 346 [81920/90000 (91%)]	Loss: -0.3508	Cost: 8.91s
Train Epoch: 346 	Average Loss: -0.5281
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0918

Learning rate: 0.00019940980668211027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 2.1985	Cost: 24.64s
Train Epoch: 347 [20480/90000 (23%)]	Loss: -0.6427	Cost: 9.35s
Train Epoch: 347 [40960/90000 (45%)]	Loss: -0.5802	Cost: 9.32s
Train Epoch: 347 [61440/90000 (68%)]	Loss: -0.4677	Cost: 9.29s
Train Epoch: 347 [81920/90000 (91%)]	Loss: -0.6424	Cost: 9.13s
Train Epoch: 347 	Average Loss: -0.4590
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9341

Learning rate: 0.00019940639361415064
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 1.7590	Cost: 24.19s
Train Epoch: 348 [20480/90000 (23%)]	Loss: -0.8699	Cost: 9.35s
Train Epoch: 348 [40960/90000 (45%)]	Loss: -0.7175	Cost: 9.32s
Train Epoch: 348 [61440/90000 (68%)]	Loss: -0.6551	Cost: 9.15s
Train Epoch: 348 [81920/90000 (91%)]	Loss: -0.5967	Cost: 8.92s
Train Epoch: 348 	Average Loss: -0.6217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8114

Learning rate: 0.00019940297073517331
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 1.6417	Cost: 26.62s
Train Epoch: 349 [20480/90000 (23%)]	Loss: -0.8587	Cost: 9.33s
Train Epoch: 349 [40960/90000 (45%)]	Loss: -0.6600	Cost: 9.36s
Train Epoch: 349 [61440/90000 (68%)]	Loss: -0.6084	Cost: 9.07s
Train Epoch: 349 [81920/90000 (91%)]	Loss: -0.5966	Cost: 9.03s
Train Epoch: 349 	Average Loss: -0.6208
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7347

Learning rate: 0.00019939953804551608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 1.5773	Cost: 24.39s
Train Epoch: 350 [20480/90000 (23%)]	Loss: -1.0171	Cost: 9.32s
Train Epoch: 350 [40960/90000 (45%)]	Loss: -0.8193	Cost: 9.33s
Train Epoch: 350 [61440/90000 (68%)]	Loss: -0.9925	Cost: 9.13s
Train Epoch: 350 [81920/90000 (91%)]	Loss: -0.7604	Cost: 9.07s
Train Epoch: 350 	Average Loss: -0.7746
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6225

Saving model as model.pt_e350 & waveforms_supplementary.hdf5_e350
Learning rate: 0.00019939609554551777
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 1.3632	Cost: 25.46s
Train Epoch: 351 [20480/90000 (23%)]	Loss: -1.1680	Cost: 9.26s
Train Epoch: 351 [40960/90000 (45%)]	Loss: -0.7586	Cost: 9.30s
Train Epoch: 351 [61440/90000 (68%)]	Loss: -0.7898	Cost: 9.01s
Train Epoch: 351 [81920/90000 (91%)]	Loss: -0.5617	Cost: 8.78s
Train Epoch: 351 	Average Loss: -0.7562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6777

Learning rate: 0.0001993926432355181
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 1.5385	Cost: 25.07s
Train Epoch: 352 [20480/90000 (23%)]	Loss: -0.9740	Cost: 9.24s
Train Epoch: 352 [40960/90000 (45%)]	Loss: -0.8818	Cost: 9.14s
Train Epoch: 352 [61440/90000 (68%)]	Loss: -0.0301	Cost: 8.97s
Train Epoch: 352 [81920/90000 (91%)]	Loss: -0.0485	Cost: 8.69s
Train Epoch: 352 	Average Loss: -0.4184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2047

Learning rate: 0.00019938918111585784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 2.0729	Cost: 26.81s
Train Epoch: 353 [20480/90000 (23%)]	Loss: -0.3871	Cost: 9.15s
Train Epoch: 353 [40960/90000 (45%)]	Loss: -0.3222	Cost: 9.08s
Train Epoch: 353 [61440/90000 (68%)]	Loss: -0.4955	Cost: 8.93s
Train Epoch: 353 [81920/90000 (91%)]	Loss: -0.6912	Cost: 8.71s
Train Epoch: 353 	Average Loss: -0.3777
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7690

Learning rate: 0.00019938570918687863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 1.7520	Cost: 25.23s
Train Epoch: 354 [20480/90000 (23%)]	Loss: -1.1709	Cost: 9.28s
Train Epoch: 354 [40960/90000 (45%)]	Loss: -0.8467	Cost: 9.36s
Train Epoch: 354 [61440/90000 (68%)]	Loss: -0.8491	Cost: 9.10s
Train Epoch: 354 [81920/90000 (91%)]	Loss: -0.6288	Cost: 8.67s
Train Epoch: 354 	Average Loss: -0.7881
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8024

Learning rate: 0.0001993822274489232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 1.3904	Cost: 24.28s
Train Epoch: 355 [20480/90000 (23%)]	Loss: -1.0654	Cost: 9.34s
Train Epoch: 355 [40960/90000 (45%)]	Loss: -0.8391	Cost: 9.46s
Train Epoch: 355 [61440/90000 (68%)]	Loss: -0.9068	Cost: 9.02s
Train Epoch: 355 [81920/90000 (91%)]	Loss: -0.8724	Cost: 8.65s
Train Epoch: 355 	Average Loss: -0.8074
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6687

Learning rate: 0.00019937873590233516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 1.5023	Cost: 25.16s
Train Epoch: 356 [20480/90000 (23%)]	Loss: -1.0729	Cost: 9.25s
Train Epoch: 356 [40960/90000 (45%)]	Loss: -0.9337	Cost: 9.29s
Train Epoch: 356 [61440/90000 (68%)]	Loss: -1.0322	Cost: 9.08s
Train Epoch: 356 [81920/90000 (91%)]	Loss: -0.6815	Cost: 8.72s
Train Epoch: 356 	Average Loss: -0.8151
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8867

Learning rate: 0.0001993752345474591
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 1.8775	Cost: 24.20s
Train Epoch: 357 [20480/90000 (23%)]	Loss: -0.8512	Cost: 9.37s
Train Epoch: 357 [40960/90000 (45%)]	Loss: -0.8762	Cost: 9.49s
Train Epoch: 357 [61440/90000 (68%)]	Loss: -0.7578	Cost: 9.16s
Train Epoch: 357 [81920/90000 (91%)]	Loss: -0.7158	Cost: 8.80s
Train Epoch: 357 	Average Loss: -0.7380
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7534

Learning rate: 0.0001993717233846406
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 1.7241	Cost: 24.53s
Train Epoch: 358 [20480/90000 (23%)]	Loss: -1.1034	Cost: 9.37s
Train Epoch: 358 [40960/90000 (45%)]	Loss: -0.8161	Cost: 9.30s
Train Epoch: 358 [61440/90000 (68%)]	Loss: -0.8789	Cost: 9.14s
Train Epoch: 358 [81920/90000 (91%)]	Loss: -0.6748	Cost: 9.19s
Train Epoch: 358 	Average Loss: -0.8100
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6172

Learning rate: 0.0001993682024142262
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 1.5865	Cost: 24.14s
Train Epoch: 359 [20480/90000 (23%)]	Loss: -1.1809	Cost: 9.35s
Train Epoch: 359 [40960/90000 (45%)]	Loss: -0.9811	Cost: 9.26s
Train Epoch: 359 [61440/90000 (68%)]	Loss: -1.1712	Cost: 9.40s
Train Epoch: 359 [81920/90000 (91%)]	Loss: -0.9245	Cost: 8.81s
Train Epoch: 359 	Average Loss: -0.9622
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5451

Learning rate: 0.00019936467163656337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 1.2292	Cost: 26.27s
Train Epoch: 360 [20480/90000 (23%)]	Loss: -1.1702	Cost: 9.35s
Train Epoch: 360 [40960/90000 (45%)]	Loss: -1.1154	Cost: 9.30s
Train Epoch: 360 [61440/90000 (68%)]	Loss: -1.1346	Cost: 9.07s
Train Epoch: 360 [81920/90000 (91%)]	Loss: -0.8420	Cost: 8.79s
Train Epoch: 360 	Average Loss: -0.9950
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5723

Learning rate: 0.00019936113105200064
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 1.1945	Cost: 24.46s
Train Epoch: 361 [20480/90000 (23%)]	Loss: -1.3792	Cost: 9.31s
Train Epoch: 361 [40960/90000 (45%)]	Loss: -1.1044	Cost: 9.32s
Train Epoch: 361 [61440/90000 (68%)]	Loss: -0.9428	Cost: 9.28s
Train Epoch: 361 [81920/90000 (91%)]	Loss: -0.7123	Cost: 8.86s
Train Epoch: 361 	Average Loss: -0.9304
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7648

Learning rate: 0.00019935758066088742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 1.7653	Cost: 24.71s
Train Epoch: 362 [20480/90000 (23%)]	Loss: -1.1512	Cost: 9.41s
Train Epoch: 362 [40960/90000 (45%)]	Loss: -0.9291	Cost: 9.25s
Train Epoch: 362 [61440/90000 (68%)]	Loss: -1.2202	Cost: 9.17s
Train Epoch: 362 [81920/90000 (91%)]	Loss: -1.1431	Cost: 8.95s
Train Epoch: 362 	Average Loss: -1.0172
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4227

Learning rate: 0.00019935402046357414
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 1.5080	Cost: 24.17s
Train Epoch: 363 [20480/90000 (23%)]	Loss: -1.1919	Cost: 9.41s
Train Epoch: 363 [40960/90000 (45%)]	Loss: -1.2384	Cost: 9.34s
Train Epoch: 363 [61440/90000 (68%)]	Loss: -1.1015	Cost: 9.34s
Train Epoch: 363 [81920/90000 (91%)]	Loss: -1.1395	Cost: 8.96s
Train Epoch: 363 	Average Loss: -1.0877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4701

Learning rate: 0.00019935045046041218
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 1.3536	Cost: 25.14s
Train Epoch: 364 [20480/90000 (23%)]	Loss: -0.7280	Cost: 9.35s
Train Epoch: 364 [40960/90000 (45%)]	Loss: -0.4598	Cost: 9.33s
Train Epoch: 364 [61440/90000 (68%)]	Loss: -0.7943	Cost: 9.25s
Train Epoch: 364 [81920/90000 (91%)]	Loss: -0.8351	Cost: 8.85s
Train Epoch: 364 	Average Loss: -0.6698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5418

Learning rate: 0.00019934687065175386
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 1.6729	Cost: 24.30s
Train Epoch: 365 [20480/90000 (23%)]	Loss: -1.2021	Cost: 9.45s
Train Epoch: 365 [40960/90000 (45%)]	Loss: -0.8488	Cost: 9.29s
Train Epoch: 365 [61440/90000 (68%)]	Loss: -0.8308	Cost: 9.19s
Train Epoch: 365 [81920/90000 (91%)]	Loss: -0.6873	Cost: 8.91s
Train Epoch: 365 	Average Loss: -0.8372
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6997

Learning rate: 0.00019934328103795248
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 1.4113	Cost: 25.39s
Train Epoch: 366 [20480/90000 (23%)]	Loss: -0.8070	Cost: 9.23s
Train Epoch: 366 [40960/90000 (45%)]	Loss: -0.7166	Cost: 9.28s
Train Epoch: 366 [61440/90000 (68%)]	Loss: -0.6558	Cost: 9.13s
Train Epoch: 366 [81920/90000 (91%)]	Loss: -0.6736	Cost: 9.06s
Train Epoch: 366 	Average Loss: -0.6511
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6962

Learning rate: 0.00019933968161936236
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 1.6955	Cost: 23.80s
Train Epoch: 367 [20480/90000 (23%)]	Loss: -0.8232	Cost: 9.40s
Train Epoch: 367 [40960/90000 (45%)]	Loss: -0.9549	Cost: 9.20s
Train Epoch: 367 [61440/90000 (68%)]	Loss: -0.9843	Cost: 9.30s
Train Epoch: 367 [81920/90000 (91%)]	Loss: -0.8623	Cost: 8.98s
Train Epoch: 367 	Average Loss: -0.8574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5551

Learning rate: 0.00019933607239633875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 1.6394	Cost: 23.89s
Train Epoch: 368 [20480/90000 (23%)]	Loss: -1.3297	Cost: 9.15s
Train Epoch: 368 [40960/90000 (45%)]	Loss: -1.3810	Cost: 9.11s
Train Epoch: 368 [61440/90000 (68%)]	Loss: -1.3916	Cost: 9.06s
Train Epoch: 368 [81920/90000 (91%)]	Loss: -1.1111	Cost: 8.66s
Train Epoch: 368 	Average Loss: -1.1261
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5641

Learning rate: 0.00019933245336923783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 1.3860	Cost: 22.67s
Train Epoch: 369 [20480/90000 (23%)]	Loss: -1.5037	Cost: 9.00s
Train Epoch: 369 [40960/90000 (45%)]	Loss: -1.3133	Cost: 9.07s
Train Epoch: 369 [61440/90000 (68%)]	Loss: -1.0555	Cost: 9.20s
Train Epoch: 369 [81920/90000 (91%)]	Loss: -1.0608	Cost: 9.31s
Train Epoch: 369 	Average Loss: -1.1684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4273

Learning rate: 0.0001993288245384168
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 1.2925	Cost: 22.79s
Train Epoch: 370 [20480/90000 (23%)]	Loss: -1.3969	Cost: 9.05s
Train Epoch: 370 [40960/90000 (45%)]	Loss: -1.2224	Cost: 9.02s
Train Epoch: 370 [61440/90000 (68%)]	Loss: -1.1655	Cost: 9.11s
Train Epoch: 370 [81920/90000 (91%)]	Loss: -1.2049	Cost: 9.43s
Train Epoch: 370 	Average Loss: -1.1293
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4741

Learning rate: 0.00019932518590423377
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 1.3822	Cost: 22.88s
Train Epoch: 371 [20480/90000 (23%)]	Loss: -1.5792	Cost: 9.22s
Train Epoch: 371 [40960/90000 (45%)]	Loss: -1.1239	Cost: 9.28s
Train Epoch: 371 [61440/90000 (68%)]	Loss: -1.1105	Cost: 9.28s
Train Epoch: 371 [81920/90000 (91%)]	Loss: -1.1257	Cost: 9.37s
Train Epoch: 371 	Average Loss: -1.1303
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3773

Learning rate: 0.00019932153746704794
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 1.4112	Cost: 22.97s
Train Epoch: 372 [20480/90000 (23%)]	Loss: -1.2638	Cost: 9.17s
Train Epoch: 372 [40960/90000 (45%)]	Loss: -1.3793	Cost: 9.42s
Train Epoch: 372 [61440/90000 (68%)]	Loss: -1.2980	Cost: 9.19s
Train Epoch: 372 [81920/90000 (91%)]	Loss: -1.3538	Cost: 9.04s
Train Epoch: 372 	Average Loss: -1.2706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2960

Learning rate: 0.00019931787922721937
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 1.2140	Cost: 22.00s
Train Epoch: 373 [20480/90000 (23%)]	Loss: -1.3876	Cost: 9.42s
Train Epoch: 373 [40960/90000 (45%)]	Loss: -0.9955	Cost: 9.28s
Train Epoch: 373 [61440/90000 (68%)]	Loss: -1.2588	Cost: 9.24s
Train Epoch: 373 [81920/90000 (91%)]	Loss: -1.0191	Cost: 9.11s
Train Epoch: 373 	Average Loss: -1.1454
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4434

Learning rate: 0.00019931421118510906
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 1.4170	Cost: 22.67s
Train Epoch: 374 [20480/90000 (23%)]	Loss: -1.3486	Cost: 9.25s
Train Epoch: 374 [40960/90000 (45%)]	Loss: -1.1545	Cost: 9.25s
Train Epoch: 374 [61440/90000 (68%)]	Loss: -1.3510	Cost: 9.06s
Train Epoch: 374 [81920/90000 (91%)]	Loss: -1.2186	Cost: 9.21s
Train Epoch: 374 	Average Loss: -1.1640
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3302

Learning rate: 0.0001993105333410791
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 1.4986	Cost: 23.97s
Train Epoch: 375 [20480/90000 (23%)]	Loss: -1.2063	Cost: 9.32s
Train Epoch: 375 [40960/90000 (45%)]	Loss: -1.1245	Cost: 9.23s
Train Epoch: 375 [61440/90000 (68%)]	Loss: -1.1913	Cost: 9.30s
Train Epoch: 375 [81920/90000 (91%)]	Loss: -1.0153	Cost: 9.15s
Train Epoch: 375 	Average Loss: -1.0777
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4998

Learning rate: 0.00019930684569549248
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 1.6667	Cost: 24.70s
Train Epoch: 376 [20480/90000 (23%)]	Loss: -1.5889	Cost: 9.35s
Train Epoch: 376 [40960/90000 (45%)]	Loss: -1.4658	Cost: 9.26s
Train Epoch: 376 [61440/90000 (68%)]	Loss: -1.4203	Cost: 9.11s
Train Epoch: 376 [81920/90000 (91%)]	Loss: -1.2964	Cost: 8.92s
Train Epoch: 376 	Average Loss: -1.2860
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4142

Learning rate: 0.0001993031482487131
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 1.3836	Cost: 24.01s
Train Epoch: 377 [20480/90000 (23%)]	Loss: -1.6235	Cost: 9.32s
Train Epoch: 377 [40960/90000 (45%)]	Loss: -1.5209	Cost: 9.20s
Train Epoch: 377 [61440/90000 (68%)]	Loss: -1.6558	Cost: 9.09s
Train Epoch: 377 [81920/90000 (91%)]	Loss: -1.3803	Cost: 8.76s
Train Epoch: 377 	Average Loss: -1.3995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2585

Learning rate: 0.0001992994410011059
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 1.1281	Cost: 25.27s
Train Epoch: 378 [20480/90000 (23%)]	Loss: -1.7641	Cost: 9.20s
Train Epoch: 378 [40960/90000 (45%)]	Loss: -1.6284	Cost: 9.33s
Train Epoch: 378 [61440/90000 (68%)]	Loss: -1.6334	Cost: 9.10s
Train Epoch: 378 [81920/90000 (91%)]	Loss: -1.4118	Cost: 8.69s
Train Epoch: 378 	Average Loss: -1.4484
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1212

Learning rate: 0.00019929572395303678
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 1.3776	Cost: 23.44s
Train Epoch: 379 [20480/90000 (23%)]	Loss: -1.6835	Cost: 9.47s
Train Epoch: 379 [40960/90000 (45%)]	Loss: -1.6312	Cost: 9.33s
Train Epoch: 379 [61440/90000 (68%)]	Loss: -1.5494	Cost: 9.30s
Train Epoch: 379 [81920/90000 (91%)]	Loss: -1.4782	Cost: 8.92s
Train Epoch: 379 	Average Loss: -1.4819
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1698

Learning rate: 0.0001992919971048726
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 1.2761	Cost: 23.92s
Train Epoch: 380 [20480/90000 (23%)]	Loss: -1.6109	Cost: 9.32s
Train Epoch: 380 [40960/90000 (45%)]	Loss: -1.6994	Cost: 9.35s
Train Epoch: 380 [61440/90000 (68%)]	Loss: -1.7291	Cost: 9.12s
Train Epoch: 380 [81920/90000 (91%)]	Loss: -1.4982	Cost: 8.80s
Train Epoch: 380 	Average Loss: -1.5214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0895

Learning rate: 0.0001992882604569812
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 1.1688	Cost: 24.44s
Train Epoch: 381 [20480/90000 (23%)]	Loss: -1.5622	Cost: 9.16s
Train Epoch: 381 [40960/90000 (45%)]	Loss: -1.8096	Cost: 9.28s
Train Epoch: 381 [61440/90000 (68%)]	Loss: -1.7820	Cost: 9.30s
Train Epoch: 381 [81920/90000 (91%)]	Loss: -1.5222	Cost: 8.82s
Train Epoch: 381 	Average Loss: -1.5581
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9900

Learning rate: 0.00019928451400973133
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 1.1674	Cost: 24.28s
Train Epoch: 382 [20480/90000 (23%)]	Loss: -1.6770	Cost: 9.33s
Train Epoch: 382 [40960/90000 (45%)]	Loss: -1.4708	Cost: 9.34s
Train Epoch: 382 [61440/90000 (68%)]	Loss: -1.5592	Cost: 9.15s
Train Epoch: 382 [81920/90000 (91%)]	Loss: -1.2603	Cost: 8.89s
Train Epoch: 382 	Average Loss: -1.3824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2217

Learning rate: 0.0001992807577634928
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 1.0386	Cost: 24.79s
Train Epoch: 383 [20480/90000 (23%)]	Loss: -1.6874	Cost: 9.36s
Train Epoch: 383 [40960/90000 (45%)]	Loss: -1.6441	Cost: 9.30s
Train Epoch: 383 [61440/90000 (68%)]	Loss: -1.6704	Cost: 9.34s
Train Epoch: 383 [81920/90000 (91%)]	Loss: -1.3895	Cost: 8.93s
Train Epoch: 383 	Average Loss: -1.4730
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0402

Learning rate: 0.00019927699171863632
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 0.9507	Cost: 25.93s
Train Epoch: 384 [20480/90000 (23%)]	Loss: -1.8507	Cost: 9.40s
Train Epoch: 384 [40960/90000 (45%)]	Loss: -1.8826	Cost: 9.24s
Train Epoch: 384 [61440/90000 (68%)]	Loss: -1.5654	Cost: 9.24s
Train Epoch: 384 [81920/90000 (91%)]	Loss: -1.0346	Cost: 8.94s
Train Epoch: 384 	Average Loss: -1.4314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6543

Learning rate: 0.00019927321587553357
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 2.0695	Cost: 24.19s
Train Epoch: 385 [20480/90000 (23%)]	Loss: -1.3017	Cost: 9.43s
Train Epoch: 385 [40960/90000 (45%)]	Loss: -1.0099	Cost: 9.84s
Train Epoch: 385 [61440/90000 (68%)]	Loss: -1.0745	Cost: 9.42s
Train Epoch: 385 [81920/90000 (91%)]	Loss: -0.6071	Cost: 9.00s
Train Epoch: 385 	Average Loss: -0.9246
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5573

Learning rate: 0.00019926943023455717
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 1.4627	Cost: 24.10s
Train Epoch: 386 [20480/90000 (23%)]	Loss: -1.4168	Cost: 9.29s
Train Epoch: 386 [40960/90000 (45%)]	Loss: -1.4148	Cost: 9.22s
Train Epoch: 386 [61440/90000 (68%)]	Loss: -1.5415	Cost: 9.12s
Train Epoch: 386 [81920/90000 (91%)]	Loss: -1.4944	Cost: 9.10s
Train Epoch: 386 	Average Loss: -1.2900
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1956

Learning rate: 0.00019926563479608086
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 1.0301	Cost: 24.08s
Train Epoch: 387 [20480/90000 (23%)]	Loss: -1.8995	Cost: 9.44s
Train Epoch: 387 [40960/90000 (45%)]	Loss: -1.6077	Cost: 9.29s
Train Epoch: 387 [61440/90000 (68%)]	Loss: -1.8185	Cost: 9.14s
Train Epoch: 387 [81920/90000 (91%)]	Loss: -1.7662	Cost: 9.01s
Train Epoch: 387 	Average Loss: -1.7116
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9099

Learning rate: 0.00019926182956047912
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 0.7665	Cost: 24.24s
Train Epoch: 388 [20480/90000 (23%)]	Loss: -2.0225	Cost: 9.38s
Train Epoch: 388 [40960/90000 (45%)]	Loss: -1.7507	Cost: 9.27s
Train Epoch: 388 [61440/90000 (68%)]	Loss: -1.7641	Cost: 9.06s
Train Epoch: 388 [81920/90000 (91%)]	Loss: -1.5741	Cost: 8.87s
Train Epoch: 388 	Average Loss: -1.6830
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0647

Learning rate: 0.00019925801452812757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 1.0164	Cost: 24.46s
Train Epoch: 389 [20480/90000 (23%)]	Loss: -1.9440	Cost: 9.30s
Train Epoch: 389 [40960/90000 (45%)]	Loss: -1.8305	Cost: 9.07s
Train Epoch: 389 [61440/90000 (68%)]	Loss: -1.9847	Cost: 9.06s
Train Epoch: 389 [81920/90000 (91%)]	Loss: -1.7935	Cost: 8.64s
Train Epoch: 389 	Average Loss: -1.7341
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9595

Learning rate: 0.00019925418969940278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 0.6228	Cost: 24.11s
Train Epoch: 390 [20480/90000 (23%)]	Loss: -2.1110	Cost: 9.09s
Train Epoch: 390 [40960/90000 (45%)]	Loss: -1.9571	Cost: 9.36s
Train Epoch: 390 [61440/90000 (68%)]	Loss: -2.0279	Cost: 9.06s
Train Epoch: 390 [81920/90000 (91%)]	Loss: -1.7667	Cost: 8.88s
Train Epoch: 390 	Average Loss: -1.8576
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7622

Learning rate: 0.00019925035507468219
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 0.5582	Cost: 23.33s
Train Epoch: 391 [20480/90000 (23%)]	Loss: -1.9539	Cost: 9.08s
Train Epoch: 391 [40960/90000 (45%)]	Loss: -1.7671	Cost: 9.53s
Train Epoch: 391 [61440/90000 (68%)]	Loss: -1.7818	Cost: 9.10s
Train Epoch: 391 [81920/90000 (91%)]	Loss: -1.6737	Cost: 10.07s
Train Epoch: 391 	Average Loss: -1.7615
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0323

Learning rate: 0.00019924651065434423
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 1.2441	Cost: 22.73s
Train Epoch: 392 [20480/90000 (23%)]	Loss: -1.9527	Cost: 9.11s
Train Epoch: 392 [40960/90000 (45%)]	Loss: -1.7949	Cost: 9.08s
Train Epoch: 392 [61440/90000 (68%)]	Loss: -2.0019	Cost: 9.17s
Train Epoch: 392 [81920/90000 (91%)]	Loss: -1.8557	Cost: 9.40s
Train Epoch: 392 	Average Loss: -1.7444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8902

Learning rate: 0.0001992426564387684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 0.5708	Cost: 23.95s
Train Epoch: 393 [20480/90000 (23%)]	Loss: -2.1290	Cost: 9.60s
Train Epoch: 393 [40960/90000 (45%)]	Loss: -1.9281	Cost: 9.16s
Train Epoch: 393 [61440/90000 (68%)]	Loss: -2.0640	Cost: 9.37s
Train Epoch: 393 [81920/90000 (91%)]	Loss: -1.7936	Cost: 9.09s
Train Epoch: 393 	Average Loss: -1.9195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8300

Learning rate: 0.00019923879242833502
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 1.0781	Cost: 22.67s
Train Epoch: 394 [20480/90000 (23%)]	Loss: -2.2165	Cost: 9.36s
Train Epoch: 394 [40960/90000 (45%)]	Loss: -2.0639	Cost: 9.26s
Train Epoch: 394 [61440/90000 (68%)]	Loss: -1.9767	Cost: 9.13s
Train Epoch: 394 [81920/90000 (91%)]	Loss: -2.0157	Cost: 9.06s
Train Epoch: 394 	Average Loss: -1.9573
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7676

Learning rate: 0.00019923491862342552
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 0.9650	Cost: 21.99s
Train Epoch: 395 [20480/90000 (23%)]	Loss: -1.9903	Cost: 9.44s
Train Epoch: 395 [40960/90000 (45%)]	Loss: -1.9966	Cost: 9.25s
Train Epoch: 395 [61440/90000 (68%)]	Loss: -1.8937	Cost: 9.63s
Train Epoch: 395 [81920/90000 (91%)]	Loss: -1.8371	Cost: 9.05s
Train Epoch: 395 	Average Loss: -1.8175
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7208

Learning rate: 0.0001992310350244222
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 0.7087	Cost: 21.50s
Train Epoch: 396 [20480/90000 (23%)]	Loss: -2.1473	Cost: 9.39s
Train Epoch: 396 [40960/90000 (45%)]	Loss: -2.0201	Cost: 9.35s
Train Epoch: 396 [61440/90000 (68%)]	Loss: -2.0751	Cost: 9.45s
Train Epoch: 396 [81920/90000 (91%)]	Loss: -1.9355	Cost: 9.21s
Train Epoch: 396 	Average Loss: -2.0103
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8152

Learning rate: 0.0001992271416317084
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 0.9091	Cost: 22.62s
Train Epoch: 397 [20480/90000 (23%)]	Loss: -2.0958	Cost: 9.35s
Train Epoch: 397 [40960/90000 (45%)]	Loss: -2.0189	Cost: 9.30s
Train Epoch: 397 [61440/90000 (68%)]	Loss: -1.8334	Cost: 9.26s
Train Epoch: 397 [81920/90000 (91%)]	Loss: -1.6503	Cost: 9.14s
Train Epoch: 397 	Average Loss: -1.7795
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9787

Learning rate: 0.0001992232384456683
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 0.9743	Cost: 23.65s
Train Epoch: 398 [20480/90000 (23%)]	Loss: -2.1374	Cost: 9.34s
Train Epoch: 398 [40960/90000 (45%)]	Loss: -1.8770	Cost: 9.27s
Train Epoch: 398 [61440/90000 (68%)]	Loss: -1.7346	Cost: 9.01s
Train Epoch: 398 [81920/90000 (91%)]	Loss: -1.8169	Cost: 9.09s
Train Epoch: 398 	Average Loss: -1.7642
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9176

Learning rate: 0.00019921932546668718
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 0.7396	Cost: 23.08s
Train Epoch: 399 [20480/90000 (23%)]	Loss: -2.1166	Cost: 9.33s
Train Epoch: 399 [40960/90000 (45%)]	Loss: -1.9889	Cost: 9.23s
Train Epoch: 399 [61440/90000 (68%)]	Loss: -1.8388	Cost: 9.20s
Train Epoch: 399 [81920/90000 (91%)]	Loss: -1.8295	Cost: 8.90s
Train Epoch: 399 	Average Loss: -1.8278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7826

Learning rate: 0.00019921540269515121
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 0.7021	Cost: 24.63s
Train Epoch: 400 [20480/90000 (23%)]	Loss: -2.2173	Cost: 9.35s
Train Epoch: 400 [40960/90000 (45%)]	Loss: -2.2092	Cost: 9.29s
Train Epoch: 400 [61440/90000 (68%)]	Loss: -2.0452	Cost: 9.08s
Train Epoch: 400 [81920/90000 (91%)]	Loss: -2.0860	Cost: 8.82s
Train Epoch: 400 	Average Loss: -1.9894
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7571

Saving model as model.pt_e400 & waveforms_supplementary.hdf5_e400
Learning rate: 0.0001992114701314476
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 401 [0/90000 (0%)]	Loss: 0.7649	Cost: 26.04s
Train Epoch: 401 [20480/90000 (23%)]	Loss: -2.0454	Cost: 9.43s
Train Epoch: 401 [40960/90000 (45%)]	Loss: -1.8847	Cost: 9.48s
Train Epoch: 401 [61440/90000 (68%)]	Loss: -2.0960	Cost: 9.01s
Train Epoch: 401 [81920/90000 (91%)]	Loss: -2.1190	Cost: 9.10s
Train Epoch: 401 	Average Loss: -1.8747
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7310

Learning rate: 0.00019920752777596444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 402 [0/90000 (0%)]	Loss: 0.8140	Cost: 23.43s
Train Epoch: 402 [20480/90000 (23%)]	Loss: -2.3066	Cost: 9.33s
Train Epoch: 402 [40960/90000 (45%)]	Loss: -2.2647	Cost: 9.29s
Train Epoch: 402 [61440/90000 (68%)]	Loss: -2.2558	Cost: 9.06s
Train Epoch: 402 [81920/90000 (91%)]	Loss: -2.1609	Cost: 9.09s
Train Epoch: 402 	Average Loss: -2.0872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5718

Learning rate: 0.00019920357562909082
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 403 [0/90000 (0%)]	Loss: 0.8642	Cost: 25.15s
Train Epoch: 403 [20480/90000 (23%)]	Loss: -2.3138	Cost: 9.26s
Train Epoch: 403 [40960/90000 (45%)]	Loss: -2.3405	Cost: 9.32s
Train Epoch: 403 [61440/90000 (68%)]	Loss: -2.2908	Cost: 8.91s
Train Epoch: 403 [81920/90000 (91%)]	Loss: -2.1294	Cost: 8.96s
Train Epoch: 403 	Average Loss: -2.1920
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5002

Learning rate: 0.00019919961369121682
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 404 [0/90000 (0%)]	Loss: 0.3151	Cost: 24.06s
Train Epoch: 404 [20480/90000 (23%)]	Loss: -2.5553	Cost: 9.31s
Train Epoch: 404 [40960/90000 (45%)]	Loss: -2.4465	Cost: 9.32s
Train Epoch: 404 [61440/90000 (68%)]	Loss: -2.2324	Cost: 9.06s
Train Epoch: 404 [81920/90000 (91%)]	Loss: -2.1145	Cost: 8.77s
Train Epoch: 404 	Average Loss: -2.2241
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6157

Learning rate: 0.00019919564196273348
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 405 [0/90000 (0%)]	Loss: 0.5245	Cost: 24.48s
Train Epoch: 405 [20480/90000 (23%)]	Loss: -2.3751	Cost: 9.52s
Train Epoch: 405 [40960/90000 (45%)]	Loss: -2.3367	Cost: 9.20s
Train Epoch: 405 [61440/90000 (68%)]	Loss: -2.1774	Cost: 9.15s
Train Epoch: 405 [81920/90000 (91%)]	Loss: -2.0281	Cost: 8.72s
Train Epoch: 405 	Average Loss: -2.1146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6150

Learning rate: 0.00019919166044403278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 406 [0/90000 (0%)]	Loss: 0.9678	Cost: 26.24s
Train Epoch: 406 [20480/90000 (23%)]	Loss: -2.4254	Cost: 9.32s
Train Epoch: 406 [40960/90000 (45%)]	Loss: -2.3002	Cost: 9.27s
Train Epoch: 406 [61440/90000 (68%)]	Loss: -2.2389	Cost: 9.07s
Train Epoch: 406 [81920/90000 (91%)]	Loss: -2.0835	Cost: 8.71s
Train Epoch: 406 	Average Loss: -2.1645
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5181

Learning rate: 0.00019918766913550764
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 407 [0/90000 (0%)]	Loss: 0.6518	Cost: 23.65s
Train Epoch: 407 [20480/90000 (23%)]	Loss: -2.6873	Cost: 9.32s
Train Epoch: 407 [40960/90000 (45%)]	Loss: -2.4491	Cost: 9.46s
Train Epoch: 407 [61440/90000 (68%)]	Loss: -2.3815	Cost: 9.08s
Train Epoch: 407 [81920/90000 (91%)]	Loss: -2.2746	Cost: 8.73s
Train Epoch: 407 	Average Loss: -2.2996
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4194

Learning rate: 0.00019918366803755205
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 408 [0/90000 (0%)]	Loss: 0.2898	Cost: 26.18s
Train Epoch: 408 [20480/90000 (23%)]	Loss: -2.6441	Cost: 9.32s
Train Epoch: 408 [40960/90000 (45%)]	Loss: -2.2342	Cost: 9.32s
Train Epoch: 408 [61440/90000 (68%)]	Loss: -2.3444	Cost: 9.09s
Train Epoch: 408 [81920/90000 (91%)]	Loss: -2.2538	Cost: 8.75s
Train Epoch: 408 	Average Loss: -2.3034
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4824

Learning rate: 0.00019917965715056087
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 409 [0/90000 (0%)]	Loss: 0.4479	Cost: 24.39s
Train Epoch: 409 [20480/90000 (23%)]	Loss: -2.6137	Cost: 9.38s
Train Epoch: 409 [40960/90000 (45%)]	Loss: -2.3351	Cost: 9.57s
Train Epoch: 409 [61440/90000 (68%)]	Loss: -2.4323	Cost: 9.04s
Train Epoch: 409 [81920/90000 (91%)]	Loss: -2.3109	Cost: 8.81s
Train Epoch: 409 	Average Loss: -2.3146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3899

Learning rate: 0.00019917563647492995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 410 [0/90000 (0%)]	Loss: 0.5451	Cost: 24.48s
Train Epoch: 410 [20480/90000 (23%)]	Loss: -2.6837	Cost: 9.46s
Train Epoch: 410 [40960/90000 (45%)]	Loss: -2.3372	Cost: 9.25s
Train Epoch: 410 [61440/90000 (68%)]	Loss: -2.4644	Cost: 9.17s
Train Epoch: 410 [81920/90000 (91%)]	Loss: -2.3840	Cost: 8.83s
Train Epoch: 410 	Average Loss: -2.3508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4974

Learning rate: 0.00019917160601105614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 411 [0/90000 (0%)]	Loss: 0.3272	Cost: 24.04s
Train Epoch: 411 [20480/90000 (23%)]	Loss: -2.5896	Cost: 9.30s
Train Epoch: 411 [40960/90000 (45%)]	Loss: -2.4953	Cost: 9.38s
Train Epoch: 411 [61440/90000 (68%)]	Loss: -2.2283	Cost: 9.34s
Train Epoch: 411 [81920/90000 (91%)]	Loss: -1.8729	Cost: 8.89s
Train Epoch: 411 	Average Loss: -2.1591
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7285

Learning rate: 0.0001991675657593372
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 412 [0/90000 (0%)]	Loss: 0.7726	Cost: 24.27s
Train Epoch: 412 [20480/90000 (23%)]	Loss: -2.3339	Cost: 9.38s
Train Epoch: 412 [40960/90000 (45%)]	Loss: -2.3036	Cost: 9.31s
Train Epoch: 412 [61440/90000 (68%)]	Loss: -2.2685	Cost: 9.24s
Train Epoch: 412 [81920/90000 (91%)]	Loss: -2.1900	Cost: 9.00s
Train Epoch: 412 	Average Loss: -2.1455
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3358

Learning rate: 0.00019916351572017192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 413 [0/90000 (0%)]	Loss: 0.3298	Cost: 24.39s
Train Epoch: 413 [20480/90000 (23%)]	Loss: -2.5357	Cost: 9.61s
Train Epoch: 413 [40960/90000 (45%)]	Loss: -2.3167	Cost: 9.24s
Train Epoch: 413 [61440/90000 (68%)]	Loss: -2.4806	Cost: 9.12s
Train Epoch: 413 [81920/90000 (91%)]	Loss: -2.3922	Cost: 9.14s
Train Epoch: 413 	Average Loss: -2.3406
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3954

Learning rate: 0.00019915945589396003
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 414 [0/90000 (0%)]	Loss: 0.4322	Cost: 24.06s
Train Epoch: 414 [20480/90000 (23%)]	Loss: -2.6016	Cost: 9.39s
Train Epoch: 414 [40960/90000 (45%)]	Loss: -2.6101	Cost: 9.23s
Train Epoch: 414 [61440/90000 (68%)]	Loss: -2.5745	Cost: 9.05s
Train Epoch: 414 [81920/90000 (91%)]	Loss: -2.3285	Cost: 9.03s
Train Epoch: 414 	Average Loss: -2.4225
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3603

Learning rate: 0.00019915538628110217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 415 [0/90000 (0%)]	Loss: 0.1980	Cost: 24.48s
Train Epoch: 415 [20480/90000 (23%)]	Loss: -2.7360	Cost: 9.38s
Train Epoch: 415 [40960/90000 (45%)]	Loss: -2.5438	Cost: 9.35s
Train Epoch: 415 [61440/90000 (68%)]	Loss: -2.4450	Cost: 8.98s
Train Epoch: 415 [81920/90000 (91%)]	Loss: -2.4963	Cost: 9.09s
Train Epoch: 415 	Average Loss: -2.4346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3277

Learning rate: 0.00019915130688200001
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 416 [0/90000 (0%)]	Loss: 0.4680	Cost: 24.27s
Train Epoch: 416 [20480/90000 (23%)]	Loss: -2.8174	Cost: 9.46s
Train Epoch: 416 [40960/90000 (45%)]	Loss: -2.7233	Cost: 9.67s
Train Epoch: 416 [61440/90000 (68%)]	Loss: -2.6863	Cost: 9.01s
Train Epoch: 416 [81920/90000 (91%)]	Loss: -2.1125	Cost: 8.82s
Train Epoch: 416 	Average Loss: -2.5248
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6709

Learning rate: 0.0001991472176970562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 417 [0/90000 (0%)]	Loss: 0.3244	Cost: 24.64s
Train Epoch: 417 [20480/90000 (23%)]	Loss: -2.5399	Cost: 9.32s
Train Epoch: 417 [40960/90000 (45%)]	Loss: -2.2935	Cost: 9.07s
Train Epoch: 417 [61440/90000 (68%)]	Loss: -2.2795	Cost: 9.07s
Train Epoch: 417 [81920/90000 (91%)]	Loss: -2.4487	Cost: 8.66s
Train Epoch: 417 	Average Loss: -2.2655
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3362

Learning rate: 0.00019914311872667434
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 418 [0/90000 (0%)]	Loss: 0.4291	Cost: 24.47s
Train Epoch: 418 [20480/90000 (23%)]	Loss: -2.8408	Cost: 9.07s
Train Epoch: 418 [40960/90000 (45%)]	Loss: -2.6509	Cost: 9.17s
Train Epoch: 418 [61440/90000 (68%)]	Loss: -2.3998	Cost: 8.94s
Train Epoch: 418 [81920/90000 (91%)]	Loss: -2.3604	Cost: 8.67s
Train Epoch: 418 	Average Loss: -2.4892
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3822

Learning rate: 0.0001991390099712589
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 419 [0/90000 (0%)]	Loss: 0.2761	Cost: 24.00s
Train Epoch: 419 [20480/90000 (23%)]	Loss: -2.8731	Cost: 9.12s
Train Epoch: 419 [40960/90000 (45%)]	Loss: -2.7455	Cost: 9.39s
Train Epoch: 419 [61440/90000 (68%)]	Loss: -2.7696	Cost: 9.06s
Train Epoch: 419 [81920/90000 (91%)]	Loss: -2.3590	Cost: 9.04s
Train Epoch: 419 	Average Loss: -2.5363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3460

Learning rate: 0.00019913489143121547
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 420 [0/90000 (0%)]	Loss: -0.0342	Cost: 22.86s
Train Epoch: 420 [20480/90000 (23%)]	Loss: -2.7692	Cost: 9.09s
Train Epoch: 420 [40960/90000 (45%)]	Loss: -2.5241	Cost: 9.06s
Train Epoch: 420 [61440/90000 (68%)]	Loss: -2.5408	Cost: 9.05s
Train Epoch: 420 [81920/90000 (91%)]	Loss: -2.1244	Cost: 9.05s
Train Epoch: 420 	Average Loss: -2.4459
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4711

Learning rate: 0.0001991307631069505
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 421 [0/90000 (0%)]	Loss: 0.1833	Cost: 22.37s
Train Epoch: 421 [20480/90000 (23%)]	Loss: -2.7453	Cost: 9.24s
Train Epoch: 421 [40960/90000 (45%)]	Loss: -2.2961	Cost: 9.41s
Train Epoch: 421 [61440/90000 (68%)]	Loss: -2.5728	Cost: 9.20s
Train Epoch: 421 [81920/90000 (91%)]	Loss: -2.2311	Cost: 9.06s
Train Epoch: 421 	Average Loss: -2.3194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4458

Learning rate: 0.0001991266249988715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 422 [0/90000 (0%)]	Loss: 0.4092	Cost: 22.39s
Train Epoch: 422 [20480/90000 (23%)]	Loss: -2.5486	Cost: 9.39s
Train Epoch: 422 [40960/90000 (45%)]	Loss: -2.5741	Cost: 9.27s
Train Epoch: 422 [61440/90000 (68%)]	Loss: -2.7159	Cost: 9.13s
Train Epoch: 422 [81920/90000 (91%)]	Loss: -2.6823	Cost: 9.09s
Train Epoch: 422 	Average Loss: -2.5176
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2785

Learning rate: 0.00019912247710738676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 423 [0/90000 (0%)]	Loss: 0.3269	Cost: 22.69s
Train Epoch: 423 [20480/90000 (23%)]	Loss: -2.7807	Cost: 9.48s
Train Epoch: 423 [40960/90000 (45%)]	Loss: -2.6862	Cost: 9.23s
Train Epoch: 423 [61440/90000 (68%)]	Loss: -2.6349	Cost: 9.10s
Train Epoch: 423 [81920/90000 (91%)]	Loss: -2.6717	Cost: 9.16s
Train Epoch: 423 	Average Loss: -2.6495
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2316

Learning rate: 0.0001991183194329058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 424 [0/90000 (0%)]	Loss: 0.1305	Cost: 23.78s
Train Epoch: 424 [20480/90000 (23%)]	Loss: -2.8495	Cost: 9.33s
Train Epoch: 424 [40960/90000 (45%)]	Loss: -2.6193	Cost: 9.43s
Train Epoch: 424 [61440/90000 (68%)]	Loss: -2.8543	Cost: 8.99s
Train Epoch: 424 [81920/90000 (91%)]	Loss: -2.6411	Cost: 9.05s
Train Epoch: 424 	Average Loss: -2.6277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2329

Learning rate: 0.00019911415197583891
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 425 [0/90000 (0%)]	Loss: 0.1756	Cost: 23.37s
Train Epoch: 425 [20480/90000 (23%)]	Loss: -3.1896	Cost: 9.32s
Train Epoch: 425 [40960/90000 (45%)]	Loss: -2.8418	Cost: 9.28s
Train Epoch: 425 [61440/90000 (68%)]	Loss: -2.8870	Cost: 9.06s
Train Epoch: 425 [81920/90000 (91%)]	Loss: -2.8053	Cost: 8.98s
Train Epoch: 425 	Average Loss: -2.7855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1041

Learning rate: 0.00019910997473659734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 426 [0/90000 (0%)]	Loss: 0.1684	Cost: 25.23s
Train Epoch: 426 [20480/90000 (23%)]	Loss: -3.0295	Cost: 9.30s
Train Epoch: 426 [40960/90000 (45%)]	Loss: -2.9660	Cost: 9.38s
Train Epoch: 426 [61440/90000 (68%)]	Loss: -2.8668	Cost: 9.16s
Train Epoch: 426 [81920/90000 (91%)]	Loss: -2.7732	Cost: 8.94s
Train Epoch: 426 	Average Loss: -2.7890
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1431

Learning rate: 0.00019910578771559345
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 427 [0/90000 (0%)]	Loss: 0.1826	Cost: 24.35s
Train Epoch: 427 [20480/90000 (23%)]	Loss: -2.9386	Cost: 9.32s
Train Epoch: 427 [40960/90000 (45%)]	Loss: -2.7013	Cost: 9.22s
Train Epoch: 427 [61440/90000 (68%)]	Loss: -2.6260	Cost: 8.98s
Train Epoch: 427 [81920/90000 (91%)]	Loss: -2.6463	Cost: 8.78s
Train Epoch: 427 	Average Loss: -2.6649
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1580

Learning rate: 0.00019910159091324043
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 428 [0/90000 (0%)]	Loss: 0.3438	Cost: 24.58s
Train Epoch: 428 [20480/90000 (23%)]	Loss: -2.7608	Cost: 9.21s
Train Epoch: 428 [40960/90000 (45%)]	Loss: -2.4435	Cost: 9.09s
Train Epoch: 428 [61440/90000 (68%)]	Loss: -2.6950	Cost: 8.97s
Train Epoch: 428 [81920/90000 (91%)]	Loss: -2.6538	Cost: 8.63s
Train Epoch: 428 	Average Loss: -2.5096
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1794

Learning rate: 0.00019909738432995254
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 429 [0/90000 (0%)]	Loss: 0.1229	Cost: 25.82s
Train Epoch: 429 [20480/90000 (23%)]	Loss: -2.9529	Cost: 9.27s
Train Epoch: 429 [40960/90000 (45%)]	Loss: -2.9275	Cost: 9.19s
Train Epoch: 429 [61440/90000 (68%)]	Loss: -2.9813	Cost: 8.97s
Train Epoch: 429 [81920/90000 (91%)]	Loss: -2.6891	Cost: 8.86s
Train Epoch: 429 	Average Loss: -2.7518
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1099

Learning rate: 0.00019909316796614494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 430 [0/90000 (0%)]	Loss: -0.0807	Cost: 23.99s
Train Epoch: 430 [20480/90000 (23%)]	Loss: -3.1162	Cost: 9.30s
Train Epoch: 430 [40960/90000 (45%)]	Loss: -3.0009	Cost: 9.31s
Train Epoch: 430 [61440/90000 (68%)]	Loss: -2.8187	Cost: 9.10s
Train Epoch: 430 [81920/90000 (91%)]	Loss: -2.8896	Cost: 8.75s
Train Epoch: 430 	Average Loss: -2.8469
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0857

Learning rate: 0.00019908894182223372
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 431 [0/90000 (0%)]	Loss: 0.1232	Cost: 26.69s
Train Epoch: 431 [20480/90000 (23%)]	Loss: -3.4004	Cost: 9.25s
Train Epoch: 431 [40960/90000 (45%)]	Loss: -2.9209	Cost: 9.24s
Train Epoch: 431 [61440/90000 (68%)]	Loss: -3.1796	Cost: 9.05s
Train Epoch: 431 [81920/90000 (91%)]	Loss: -3.0240	Cost: 8.71s
Train Epoch: 431 	Average Loss: -2.9674
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1390

Learning rate: 0.00019908470589863605
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 432 [0/90000 (0%)]	Loss: -0.3265	Cost: 24.56s
Train Epoch: 432 [20480/90000 (23%)]	Loss: -3.3266	Cost: 9.27s
Train Epoch: 432 [40960/90000 (45%)]	Loss: -3.2698	Cost: 9.19s
Train Epoch: 432 [61440/90000 (68%)]	Loss: -3.2097	Cost: 9.15s
Train Epoch: 432 [81920/90000 (91%)]	Loss: -2.9244	Cost: 8.89s
Train Epoch: 432 	Average Loss: -3.0311
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1334

Learning rate: 0.00019908046019576994
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 433 [0/90000 (0%)]	Loss: 0.1341	Cost: 23.99s
Train Epoch: 433 [20480/90000 (23%)]	Loss: -3.3380	Cost: 9.34s
Train Epoch: 433 [40960/90000 (45%)]	Loss: -3.0289	Cost: 9.28s
Train Epoch: 433 [61440/90000 (68%)]	Loss: -1.8014	Cost: 9.13s
Train Epoch: 433 [81920/90000 (91%)]	Loss: -1.8311	Cost: 8.85s
Train Epoch: 433 	Average Loss: -2.3727
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7527

Learning rate: 0.00019907620471405445
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 434 [0/90000 (0%)]	Loss: 0.7090	Cost: 24.51s
Train Epoch: 434 [20480/90000 (23%)]	Loss: -2.2615	Cost: 9.36s
Train Epoch: 434 [40960/90000 (45%)]	Loss: -2.2291	Cost: 9.32s
Train Epoch: 434 [61440/90000 (68%)]	Loss: -2.3293	Cost: 9.08s
Train Epoch: 434 [81920/90000 (91%)]	Loss: -2.3628	Cost: 8.90s
Train Epoch: 434 	Average Loss: -2.1978
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2385

Learning rate: 0.0001990719394539096
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 435 [0/90000 (0%)]	Loss: 0.1991	Cost: 27.95s
Train Epoch: 435 [20480/90000 (23%)]	Loss: -2.8995	Cost: 9.39s
Train Epoch: 435 [40960/90000 (45%)]	Loss: -2.8189	Cost: 9.53s
Train Epoch: 435 [61440/90000 (68%)]	Loss: -2.9965	Cost: 9.00s
Train Epoch: 435 [81920/90000 (91%)]	Loss: -2.2390	Cost: 8.79s
Train Epoch: 435 	Average Loss: -2.7009
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5078

Learning rate: 0.0001990676644157563
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 436 [0/90000 (0%)]	Loss: 0.5612	Cost: 24.13s
Train Epoch: 436 [20480/90000 (23%)]	Loss: -2.7618	Cost: 9.35s
Train Epoch: 436 [40960/90000 (45%)]	Loss: -2.6025	Cost: 9.26s
Train Epoch: 436 [61440/90000 (68%)]	Loss: -2.7746	Cost: 9.12s
Train Epoch: 436 [81920/90000 (91%)]	Loss: -2.7319	Cost: 9.06s
Train Epoch: 436 	Average Loss: -2.5643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2174

Learning rate: 0.00019906337960001657
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 437 [0/90000 (0%)]	Loss: -0.0661	Cost: 24.23s
Train Epoch: 437 [20480/90000 (23%)]	Loss: -3.0318	Cost: 9.38s
Train Epoch: 437 [40960/90000 (45%)]	Loss: -2.8723	Cost: 9.41s
Train Epoch: 437 [61440/90000 (68%)]	Loss: -2.5965	Cost: 9.14s
Train Epoch: 437 [81920/90000 (91%)]	Loss: -2.6816	Cost: 9.05s
Train Epoch: 437 	Average Loss: -2.6976
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1356

Learning rate: 0.0001990590850071132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 438 [0/90000 (0%)]	Loss: -0.1902	Cost: 24.37s
Train Epoch: 438 [20480/90000 (23%)]	Loss: -3.0630	Cost: 9.32s
Train Epoch: 438 [40960/90000 (45%)]	Loss: -3.0817	Cost: 9.32s
Train Epoch: 438 [61440/90000 (68%)]	Loss: -3.0375	Cost: 9.16s
Train Epoch: 438 [81920/90000 (91%)]	Loss: -2.8557	Cost: 8.93s
Train Epoch: 438 	Average Loss: -2.9268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0296

Learning rate: 0.0001990547806374701
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 439 [0/90000 (0%)]	Loss: 0.2032	Cost: 23.96s
Train Epoch: 439 [20480/90000 (23%)]	Loss: -3.1427	Cost: 9.45s
Train Epoch: 439 [40960/90000 (45%)]	Loss: -3.0692	Cost: 9.24s
Train Epoch: 439 [61440/90000 (68%)]	Loss: -3.1278	Cost: 9.34s
Train Epoch: 439 [81920/90000 (91%)]	Loss: -3.0652	Cost: 9.19s
Train Epoch: 439 	Average Loss: -2.9724
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0458

Learning rate: 0.00019905046649151213
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 440 [0/90000 (0%)]	Loss: 0.1780	Cost: 26.40s
Train Epoch: 440 [20480/90000 (23%)]	Loss: -3.3715	Cost: 9.36s
Train Epoch: 440 [40960/90000 (45%)]	Loss: -3.0581	Cost: 9.33s
Train Epoch: 440 [61440/90000 (68%)]	Loss: -3.0471	Cost: 9.14s
Train Epoch: 440 [81920/90000 (91%)]	Loss: -3.0995	Cost: 9.01s
Train Epoch: 440 	Average Loss: -3.0224
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0606

Learning rate: 0.00019904614256966498
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 441 [0/90000 (0%)]	Loss: -0.3267	Cost: 23.81s
Train Epoch: 441 [20480/90000 (23%)]	Loss: -3.4968	Cost: 9.48s
Train Epoch: 441 [40960/90000 (45%)]	Loss: -3.2729	Cost: 9.23s
Train Epoch: 441 [61440/90000 (68%)]	Loss: -3.2072	Cost: 9.13s
Train Epoch: 441 [81920/90000 (91%)]	Loss: -2.9774	Cost: 9.03s
Train Epoch: 441 	Average Loss: -3.1018
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0357

Learning rate: 0.00019904180887235552
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 442 [0/90000 (0%)]	Loss: -0.2963	Cost: 23.77s
Train Epoch: 442 [20480/90000 (23%)]	Loss: -3.4156	Cost: 9.30s
Train Epoch: 442 [40960/90000 (45%)]	Loss: -3.3700	Cost: 9.32s
Train Epoch: 442 [61440/90000 (68%)]	Loss: -3.3751	Cost: 9.05s
Train Epoch: 442 [81920/90000 (91%)]	Loss: -3.1600	Cost: 8.97s
Train Epoch: 442 	Average Loss: -3.1467
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1841

Learning rate: 0.0001990374654000114
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 443 [0/90000 (0%)]	Loss: -0.4213	Cost: 24.47s
Train Epoch: 443 [20480/90000 (23%)]	Loss: -3.5415	Cost: 9.33s
Train Epoch: 443 [40960/90000 (45%)]	Loss: -3.4731	Cost: 9.31s
Train Epoch: 443 [61440/90000 (68%)]	Loss: -3.3573	Cost: 8.96s
Train Epoch: 443 [81920/90000 (91%)]	Loss: -3.2599	Cost: 8.98s
Train Epoch: 443 	Average Loss: -3.3083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3587

Learning rate: 0.0001990331121530613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 444 [0/90000 (0%)]	Loss: -0.2113	Cost: 24.63s
Train Epoch: 444 [20480/90000 (23%)]	Loss: -3.6384	Cost: 9.40s
Train Epoch: 444 [40960/90000 (45%)]	Loss: -3.3947	Cost: 9.33s
Train Epoch: 444 [61440/90000 (68%)]	Loss: -3.3766	Cost: 9.02s
Train Epoch: 444 [81920/90000 (91%)]	Loss: -3.3335	Cost: 8.78s
Train Epoch: 444 	Average Loss: -3.2946
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2945

Learning rate: 0.0001990287491319349
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 445 [0/90000 (0%)]	Loss: -0.3798	Cost: 24.18s
Train Epoch: 445 [20480/90000 (23%)]	Loss: -3.5622	Cost: 9.09s
Train Epoch: 445 [40960/90000 (45%)]	Loss: -3.3103	Cost: 9.05s
Train Epoch: 445 [61440/90000 (68%)]	Loss: -3.4087	Cost: 8.91s
Train Epoch: 445 [81920/90000 (91%)]	Loss: -3.3145	Cost: 8.62s
Train Epoch: 445 	Average Loss: -3.3009
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2087

Learning rate: 0.00019902437633706276
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 446 [0/90000 (0%)]	Loss: -0.0989	Cost: 23.79s
Train Epoch: 446 [20480/90000 (23%)]	Loss: -3.4087	Cost: 9.07s
Train Epoch: 446 [40960/90000 (45%)]	Loss: -3.3565	Cost: 9.14s
Train Epoch: 446 [61440/90000 (68%)]	Loss: -3.4757	Cost: 9.03s
Train Epoch: 446 [81920/90000 (91%)]	Loss: -3.2171	Cost: 8.80s
Train Epoch: 446 	Average Loss: -3.2901
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3266

Learning rate: 0.0001990199937688765
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 447 [0/90000 (0%)]	Loss: -0.2872	Cost: 22.82s
Train Epoch: 447 [20480/90000 (23%)]	Loss: -3.6292	Cost: 9.12s
Train Epoch: 447 [40960/90000 (45%)]	Loss: -3.4215	Cost: 9.19s
Train Epoch: 447 [61440/90000 (68%)]	Loss: -3.5842	Cost: 9.12s
Train Epoch: 447 [81920/90000 (91%)]	Loss: -3.5177	Cost: 9.59s
Train Epoch: 447 	Average Loss: -3.3775
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5145

Learning rate: 0.00019901560142780868
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 448 [0/90000 (0%)]	Loss: -0.2913	Cost: 22.81s
Train Epoch: 448 [20480/90000 (23%)]	Loss: -3.7674	Cost: 9.29s
Train Epoch: 448 [40960/90000 (45%)]	Loss: -3.3899	Cost: 9.09s
Train Epoch: 448 [61440/90000 (68%)]	Loss: -3.3637	Cost: 9.07s
Train Epoch: 448 [81920/90000 (91%)]	Loss: -3.1564	Cost: 9.05s
Train Epoch: 448 	Average Loss: -3.2932
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2212

Learning rate: 0.0001990111993142928
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 449 [0/90000 (0%)]	Loss: -0.0129	Cost: 23.88s
Train Epoch: 449 [20480/90000 (23%)]	Loss: -3.6797	Cost: 9.10s
Train Epoch: 449 [40960/90000 (45%)]	Loss: -3.3933	Cost: 9.11s
Train Epoch: 449 [61440/90000 (68%)]	Loss: -3.3162	Cost: 9.07s
Train Epoch: 449 [81920/90000 (91%)]	Loss: -2.8956	Cost: 9.01s
Train Epoch: 449 	Average Loss: -3.1554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0879

Learning rate: 0.0001990067874287633
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 450 [0/90000 (0%)]	Loss: -0.1647	Cost: 22.82s
Train Epoch: 450 [20480/90000 (23%)]	Loss: -3.5251	Cost: 9.27s
Train Epoch: 450 [40960/90000 (45%)]	Loss: -3.4183	Cost: 9.61s
Train Epoch: 450 [61440/90000 (68%)]	Loss: -3.5041	Cost: 9.26s
Train Epoch: 450 [81920/90000 (91%)]	Loss: -3.1165	Cost: 9.06s
Train Epoch: 450 	Average Loss: -3.2159
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2798

Saving model as model.pt_e450 & waveforms_supplementary.hdf5_e450
Learning rate: 0.00019900236577165563
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 451 [0/90000 (0%)]	Loss: 0.0545	Cost: 23.17s
Train Epoch: 451 [20480/90000 (23%)]	Loss: -3.5509	Cost: 9.25s
Train Epoch: 451 [40960/90000 (45%)]	Loss: -3.5839	Cost: 9.25s
Train Epoch: 451 [61440/90000 (68%)]	Loss: -3.1890	Cost: 9.31s
Train Epoch: 451 [81920/90000 (91%)]	Loss: -3.2476	Cost: 9.08s
Train Epoch: 451 	Average Loss: -3.3173
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3380

Learning rate: 0.00019899793434340619
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 452 [0/90000 (0%)]	Loss: -0.7621	Cost: 22.33s
Train Epoch: 452 [20480/90000 (23%)]	Loss: -3.4849	Cost: 9.37s
Train Epoch: 452 [40960/90000 (45%)]	Loss: -3.6122	Cost: 9.45s
Train Epoch: 452 [61440/90000 (68%)]	Loss: -3.4325	Cost: 9.15s
Train Epoch: 452 [81920/90000 (91%)]	Loss: -2.7346	Cost: 9.12s
Train Epoch: 452 	Average Loss: -3.1862
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0165

Learning rate: 0.00019899349314445237
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 453 [0/90000 (0%)]	Loss: -0.1295	Cost: 23.02s
Train Epoch: 453 [20480/90000 (23%)]	Loss: -3.1338	Cost: 9.28s
Train Epoch: 453 [40960/90000 (45%)]	Loss: -3.3098	Cost: 9.32s
Train Epoch: 453 [61440/90000 (68%)]	Loss: -3.1977	Cost: 9.09s
Train Epoch: 453 [81920/90000 (91%)]	Loss: -3.2483	Cost: 9.18s
Train Epoch: 453 	Average Loss: -3.0911
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4292

Learning rate: 0.00019898904217523244
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 454 [0/90000 (0%)]	Loss: -0.2460	Cost: 24.16s
Train Epoch: 454 [20480/90000 (23%)]	Loss: -3.7090	Cost: 9.27s
Train Epoch: 454 [40960/90000 (45%)]	Loss: -3.5584	Cost: 9.36s
Train Epoch: 454 [61440/90000 (68%)]	Loss: -3.5280	Cost: 9.07s
Train Epoch: 454 [81920/90000 (91%)]	Loss: -3.3821	Cost: 9.14s
Train Epoch: 454 	Average Loss: -3.4837
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2622

Learning rate: 0.00019898458143618574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 455 [0/90000 (0%)]	Loss: -0.4974	Cost: 23.11s
Train Epoch: 455 [20480/90000 (23%)]	Loss: -3.7128	Cost: 9.40s
Train Epoch: 455 [40960/90000 (45%)]	Loss: -3.3162	Cost: 9.40s
Train Epoch: 455 [61440/90000 (68%)]	Loss: -3.1962	Cost: 9.07s
Train Epoch: 455 [81920/90000 (91%)]	Loss: -3.2268	Cost: 9.22s
Train Epoch: 455 	Average Loss: -3.3218
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3678

Learning rate: 0.0001989801109277525
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 456 [0/90000 (0%)]	Loss: -0.3596	Cost: 24.13s
Train Epoch: 456 [20480/90000 (23%)]	Loss: -3.6097	Cost: 9.45s
Train Epoch: 456 [40960/90000 (45%)]	Loss: -3.5950	Cost: 9.44s
Train Epoch: 456 [61440/90000 (68%)]	Loss: -3.4373	Cost: 9.09s
Train Epoch: 456 [81920/90000 (91%)]	Loss: -3.2164	Cost: 9.03s
Train Epoch: 456 	Average Loss: -3.3712
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1839

Learning rate: 0.000198975630650374
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 457 [0/90000 (0%)]	Loss: -0.1223	Cost: 23.71s
Train Epoch: 457 [20480/90000 (23%)]	Loss: -3.7057	Cost: 9.37s
Train Epoch: 457 [40960/90000 (45%)]	Loss: -3.6018	Cost: 9.28s
Train Epoch: 457 [61440/90000 (68%)]	Loss: -3.5129	Cost: 9.06s
Train Epoch: 457 [81920/90000 (91%)]	Loss: -3.3001	Cost: 8.86s
Train Epoch: 457 	Average Loss: -3.3921
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1051

Learning rate: 0.0001989711406044923
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 458 [0/90000 (0%)]	Loss: -0.0516	Cost: 24.21s
Train Epoch: 458 [20480/90000 (23%)]	Loss: -3.4105	Cost: 9.35s
Train Epoch: 458 [40960/90000 (45%)]	Loss: -3.3563	Cost: 9.24s
Train Epoch: 458 [61440/90000 (68%)]	Loss: -3.4866	Cost: 9.26s
Train Epoch: 458 [81920/90000 (91%)]	Loss: -3.4747	Cost: 8.82s
Train Epoch: 458 	Average Loss: -3.2969
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3634

Learning rate: 0.0001989666407905507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 459 [0/90000 (0%)]	Loss: -0.6251	Cost: 23.44s
Train Epoch: 459 [20480/90000 (23%)]	Loss: -3.9497	Cost: 9.40s
Train Epoch: 459 [40960/90000 (45%)]	Loss: -3.6528	Cost: 9.19s
Train Epoch: 459 [61440/90000 (68%)]	Loss: -3.9205	Cost: 9.17s
Train Epoch: 459 [81920/90000 (91%)]	Loss: -3.6802	Cost: 8.67s
Train Epoch: 459 	Average Loss: -3.6797
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6230

Learning rate: 0.00019896213120899325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 460 [0/90000 (0%)]	Loss: -0.6071	Cost: 23.81s
Train Epoch: 460 [20480/90000 (23%)]	Loss: -3.9650	Cost: 9.34s
Train Epoch: 460 [40960/90000 (45%)]	Loss: -3.5343	Cost: 9.34s
Train Epoch: 460 [61440/90000 (68%)]	Loss: -3.6725	Cost: 9.11s
Train Epoch: 460 [81920/90000 (91%)]	Loss: -3.5426	Cost: 8.81s
Train Epoch: 460 	Average Loss: -3.6803
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5023

Learning rate: 0.00019895761186026497
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 461 [0/90000 (0%)]	Loss: -0.5800	Cost: 26.26s
Train Epoch: 461 [20480/90000 (23%)]	Loss: -3.9969	Cost: 9.31s
Train Epoch: 461 [40960/90000 (45%)]	Loss: -3.5563	Cost: 9.31s
Train Epoch: 461 [61440/90000 (68%)]	Loss: -3.7154	Cost: 9.11s
Train Epoch: 461 [81920/90000 (91%)]	Loss: -3.5945	Cost: 8.84s
Train Epoch: 461 	Average Loss: -3.6169
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5789

Learning rate: 0.000198953082744812
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 462 [0/90000 (0%)]	Loss: -0.0554	Cost: 24.41s
Train Epoch: 462 [20480/90000 (23%)]	Loss: -4.1267	Cost: 9.58s
Train Epoch: 462 [40960/90000 (45%)]	Loss: -3.8791	Cost: 9.41s
Train Epoch: 462 [61440/90000 (68%)]	Loss: -3.7679	Cost: 9.12s
Train Epoch: 462 [81920/90000 (91%)]	Loss: -3.6796	Cost: 8.85s
Train Epoch: 462 	Average Loss: -3.6919
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7072

Learning rate: 0.0001989485438630813
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 463 [0/90000 (0%)]	Loss: -0.4465	Cost: 24.34s
Train Epoch: 463 [20480/90000 (23%)]	Loss: -4.0584	Cost: 9.32s
Train Epoch: 463 [40960/90000 (45%)]	Loss: -3.8904	Cost: 9.32s
Train Epoch: 463 [61440/90000 (68%)]	Loss: -3.9086	Cost: 9.05s
Train Epoch: 463 [81920/90000 (91%)]	Loss: -3.5067	Cost: 8.93s
Train Epoch: 463 	Average Loss: -3.7204
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3554

Learning rate: 0.00019894399521552084
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 464 [0/90000 (0%)]	Loss: -0.5532	Cost: 24.16s
Train Epoch: 464 [20480/90000 (23%)]	Loss: -3.6710	Cost: 9.30s
Train Epoch: 464 [40960/90000 (45%)]	Loss: -3.7523	Cost: 9.25s
Train Epoch: 464 [61440/90000 (68%)]	Loss: -3.4744	Cost: 9.04s
Train Epoch: 464 [81920/90000 (91%)]	Loss: -3.2807	Cost: 8.96s
Train Epoch: 464 	Average Loss: -3.4178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2914

Learning rate: 0.0001989394368025795
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 465 [0/90000 (0%)]	Loss: -0.1734	Cost: 24.44s
Train Epoch: 465 [20480/90000 (23%)]	Loss: -3.5690	Cost: 9.48s
Train Epoch: 465 [40960/90000 (45%)]	Loss: -3.5395	Cost: 9.31s
Train Epoch: 465 [61440/90000 (68%)]	Loss: -3.4263	Cost: 9.00s
Train Epoch: 465 [81920/90000 (91%)]	Loss: -3.6832	Cost: 8.96s
Train Epoch: 465 	Average Loss: -3.3704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5624

Learning rate: 0.0001989348686247073
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 466 [0/90000 (0%)]	Loss: -0.2898	Cost: 24.10s
Train Epoch: 466 [20480/90000 (23%)]	Loss: -3.9296	Cost: 9.34s
Train Epoch: 466 [40960/90000 (45%)]	Loss: -3.7520	Cost: 9.14s
Train Epoch: 466 [61440/90000 (68%)]	Loss: -3.4176	Cost: 8.94s
Train Epoch: 466 [81920/90000 (91%)]	Loss: -3.1296	Cost: 8.73s
Train Epoch: 466 	Average Loss: -3.4738
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2036

Learning rate: 0.000198930290682355
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 467 [0/90000 (0%)]	Loss: -0.2441	Cost: 24.09s
Train Epoch: 467 [20480/90000 (23%)]	Loss: -3.7305	Cost: 9.12s
Train Epoch: 467 [40960/90000 (45%)]	Loss: -3.7213	Cost: 9.21s
Train Epoch: 467 [61440/90000 (68%)]	Loss: -3.6299	Cost: 8.92s
Train Epoch: 467 [81920/90000 (91%)]	Loss: -3.6048	Cost: 8.65s
Train Epoch: 467 	Average Loss: -3.5316
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5800

Learning rate: 0.00019892570297597447
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 468 [0/90000 (0%)]	Loss: -0.5043	Cost: 23.93s
Train Epoch: 468 [20480/90000 (23%)]	Loss: -3.9401	Cost: 9.10s
Train Epoch: 468 [40960/90000 (45%)]	Loss: -3.4450	Cost: 9.47s
Train Epoch: 468 [61440/90000 (68%)]	Loss: -3.6713	Cost: 9.04s
Train Epoch: 468 [81920/90000 (91%)]	Loss: -3.8024	Cost: 9.11s
Train Epoch: 468 	Average Loss: -3.5729
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7177

Learning rate: 0.00019892110550601846
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 469 [0/90000 (0%)]	Loss: -0.6950	Cost: 22.87s
Train Epoch: 469 [20480/90000 (23%)]	Loss: -3.9484	Cost: 8.99s
Train Epoch: 469 [40960/90000 (45%)]	Loss: -3.8583	Cost: 9.73s
Train Epoch: 469 [61440/90000 (68%)]	Loss: -3.8660	Cost: 9.22s
Train Epoch: 469 [81920/90000 (91%)]	Loss: -3.7849	Cost: 9.69s
Train Epoch: 469 	Average Loss: -3.7981
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8217

Learning rate: 0.00019891649827294077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 470 [0/90000 (0%)]	Loss: -0.7014	Cost: 23.32s
Train Epoch: 470 [20480/90000 (23%)]	Loss: -4.3603	Cost: 9.35s
Train Epoch: 470 [40960/90000 (45%)]	Loss: -3.0960	Cost: 9.08s
Train Epoch: 470 [61440/90000 (68%)]	Loss: -3.4190	Cost: 9.04s
Train Epoch: 470 [81920/90000 (91%)]	Loss: -3.4081	Cost: 9.64s
Train Epoch: 470 	Average Loss: -3.4399
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3833

Learning rate: 0.00019891188127719607
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 471 [0/90000 (0%)]	Loss: -0.5653	Cost: 24.37s
Train Epoch: 471 [20480/90000 (23%)]	Loss: -3.8561	Cost: 9.31s
Train Epoch: 471 [40960/90000 (45%)]	Loss: -3.9258	Cost: 9.34s
Train Epoch: 471 [61440/90000 (68%)]	Loss: -4.0017	Cost: 9.15s
Train Epoch: 471 [81920/90000 (91%)]	Loss: -3.5795	Cost: 9.17s
Train Epoch: 471 	Average Loss: -3.6599
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5723

Learning rate: 0.00019890725451924011
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 472 [0/90000 (0%)]	Loss: -0.5646	Cost: 22.82s
Train Epoch: 472 [20480/90000 (23%)]	Loss: -3.9921	Cost: 9.05s
Train Epoch: 472 [40960/90000 (45%)]	Loss: -4.0670	Cost: 9.30s
Train Epoch: 472 [61440/90000 (68%)]	Loss: -3.9462	Cost: 8.90s
Train Epoch: 472 [81920/90000 (91%)]	Loss: -3.7358	Cost: 8.99s
Train Epoch: 472 	Average Loss: -3.7942
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7696

Learning rate: 0.00019890261799952944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 473 [0/90000 (0%)]	Loss: -0.4918	Cost: 22.99s
Train Epoch: 473 [20480/90000 (23%)]	Loss: -4.2616	Cost: 9.10s
Train Epoch: 473 [40960/90000 (45%)]	Loss: -4.1733	Cost: 9.20s
Train Epoch: 473 [61440/90000 (68%)]	Loss: -3.9647	Cost: 8.88s
Train Epoch: 473 [81920/90000 (91%)]	Loss: -3.9169	Cost: 8.95s
Train Epoch: 473 	Average Loss: -3.8968
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7526

Learning rate: 0.00019889797171852172
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 474 [0/90000 (0%)]	Loss: -0.8683	Cost: 23.86s
Train Epoch: 474 [20480/90000 (23%)]	Loss: -3.9877	Cost: 9.10s
Train Epoch: 474 [40960/90000 (45%)]	Loss: -4.1222	Cost: 9.01s
Train Epoch: 474 [61440/90000 (68%)]	Loss: -4.0434	Cost: 8.90s
Train Epoch: 474 [81920/90000 (91%)]	Loss: -3.7981	Cost: 8.80s
Train Epoch: 474 	Average Loss: -3.8571
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6943

Learning rate: 0.0001988933156766755
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 475 [0/90000 (0%)]	Loss: -0.7435	Cost: 25.51s
Train Epoch: 475 [20480/90000 (23%)]	Loss: -4.0925	Cost: 9.33s
Train Epoch: 475 [40960/90000 (45%)]	Loss: -4.1252	Cost: 9.25s
Train Epoch: 475 [61440/90000 (68%)]	Loss: -4.0693	Cost: 9.02s
Train Epoch: 475 [81920/90000 (91%)]	Loss: -3.9565	Cost: 8.71s
Train Epoch: 475 	Average Loss: -3.9982
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9739

Learning rate: 0.00019888864987445035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 476 [0/90000 (0%)]	Loss: -1.2508	Cost: 23.25s
Train Epoch: 476 [20480/90000 (23%)]	Loss: -4.6038	Cost: 9.37s
Train Epoch: 476 [40960/90000 (45%)]	Loss: -4.0432	Cost: 9.30s
Train Epoch: 476 [61440/90000 (68%)]	Loss: -3.9852	Cost: 9.09s
Train Epoch: 476 [81920/90000 (91%)]	Loss: -4.1007	Cost: 8.69s
Train Epoch: 476 	Average Loss: -4.0453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9553

Learning rate: 0.00019888397431230674
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 477 [0/90000 (0%)]	Loss: -0.7665	Cost: 24.53s
Train Epoch: 477 [20480/90000 (23%)]	Loss: -4.5481	Cost: 9.65s
Train Epoch: 477 [40960/90000 (45%)]	Loss: -4.3525	Cost: 9.39s
Train Epoch: 477 [61440/90000 (68%)]	Loss: -4.2696	Cost: 9.41s
Train Epoch: 477 [81920/90000 (91%)]	Loss: -4.1916	Cost: 8.78s
Train Epoch: 477 	Average Loss: -4.1412
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0593

Learning rate: 0.00019887928899070613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 478 [0/90000 (0%)]	Loss: -0.7556	Cost: 24.04s
Train Epoch: 478 [20480/90000 (23%)]	Loss: -4.4461	Cost: 9.39s
Train Epoch: 478 [40960/90000 (45%)]	Loss: -4.3953	Cost: 9.30s
Train Epoch: 478 [61440/90000 (68%)]	Loss: -4.2376	Cost: 9.21s
Train Epoch: 478 [81920/90000 (91%)]	Loss: -4.2850	Cost: 8.74s
Train Epoch: 478 	Average Loss: -4.2023
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9074

Learning rate: 0.00019887459391011093
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 479 [0/90000 (0%)]	Loss: -0.7484	Cost: 24.47s
Train Epoch: 479 [20480/90000 (23%)]	Loss: -4.3572	Cost: 9.36s
Train Epoch: 479 [40960/90000 (45%)]	Loss: -4.2503	Cost: 9.28s
Train Epoch: 479 [61440/90000 (68%)]	Loss: -4.3512	Cost: 9.22s
Train Epoch: 479 [81920/90000 (91%)]	Loss: -4.2044	Cost: 8.84s
Train Epoch: 479 	Average Loss: -4.1366
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0633

Learning rate: 0.0001988698890709845
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 480 [0/90000 (0%)]	Loss: -0.9673	Cost: 25.96s
Train Epoch: 480 [20480/90000 (23%)]	Loss: -4.7663	Cost: 9.35s
Train Epoch: 480 [40960/90000 (45%)]	Loss: -4.3688	Cost: 9.31s
Train Epoch: 480 [61440/90000 (68%)]	Loss: -4.3301	Cost: 9.16s
Train Epoch: 480 [81920/90000 (91%)]	Loss: -4.0898	Cost: 8.92s
Train Epoch: 480 	Average Loss: -4.2057
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8920

Learning rate: 0.0001988651744737913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 481 [0/90000 (0%)]	Loss: -0.9140	Cost: 24.85s
Train Epoch: 481 [20480/90000 (23%)]	Loss: -4.6000	Cost: 9.32s
Train Epoch: 481 [40960/90000 (45%)]	Loss: -4.3612	Cost: 9.23s
Train Epoch: 481 [61440/90000 (68%)]	Loss: -4.3890	Cost: 9.13s
Train Epoch: 481 [81920/90000 (91%)]	Loss: -4.2304	Cost: 8.83s
Train Epoch: 481 	Average Loss: -4.2564
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1351

Learning rate: 0.00019886045011899655
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 482 [0/90000 (0%)]	Loss: -1.1559	Cost: 24.16s
Train Epoch: 482 [20480/90000 (23%)]	Loss: -4.7580	Cost: 9.39s
Train Epoch: 482 [40960/90000 (45%)]	Loss: -4.6054	Cost: 9.53s
Train Epoch: 482 [61440/90000 (68%)]	Loss: -4.6927	Cost: 9.18s
Train Epoch: 482 [81920/90000 (91%)]	Loss: -4.3934	Cost: 8.97s
Train Epoch: 482 	Average Loss: -4.4005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1604

Learning rate: 0.00019885571600706652
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 483 [0/90000 (0%)]	Loss: -0.8085	Cost: 25.10s
Train Epoch: 483 [20480/90000 (23%)]	Loss: -4.6271	Cost: 9.40s
Train Epoch: 483 [40960/90000 (45%)]	Loss: -4.2217	Cost: 9.25s
Train Epoch: 483 [61440/90000 (68%)]	Loss: -4.3775	Cost: 9.14s
Train Epoch: 483 [81920/90000 (91%)]	Loss: -4.4001	Cost: 9.03s
Train Epoch: 483 	Average Loss: -4.1868
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1598

Learning rate: 0.00019885097213846847
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 484 [0/90000 (0%)]	Loss: -1.3655	Cost: 24.30s
Train Epoch: 484 [20480/90000 (23%)]	Loss: -4.4970	Cost: 9.36s
Train Epoch: 484 [40960/90000 (45%)]	Loss: -3.9445	Cost: 9.19s
Train Epoch: 484 [61440/90000 (68%)]	Loss: -4.1856	Cost: 9.35s
Train Epoch: 484 [81920/90000 (91%)]	Loss: -4.1272	Cost: 8.86s
Train Epoch: 484 	Average Loss: -4.1377
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8951

Learning rate: 0.00019884621851367065
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 485 [0/90000 (0%)]	Loss: -0.7097	Cost: 24.15s
Train Epoch: 485 [20480/90000 (23%)]	Loss: -4.5180	Cost: 9.46s
Train Epoch: 485 [40960/90000 (45%)]	Loss: -4.2605	Cost: 9.32s
Train Epoch: 485 [61440/90000 (68%)]	Loss: -4.1769	Cost: 9.10s
Train Epoch: 485 [81920/90000 (91%)]	Loss: -3.9573	Cost: 9.02s
Train Epoch: 485 	Average Loss: -4.1234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8822

Learning rate: 0.00019884145513314214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 486 [0/90000 (0%)]	Loss: -1.2548	Cost: 24.30s
Train Epoch: 486 [20480/90000 (23%)]	Loss: -4.3667	Cost: 9.44s
Train Epoch: 486 [40960/90000 (45%)]	Loss: -4.1483	Cost: 9.32s
Train Epoch: 486 [61440/90000 (68%)]	Loss: -4.1467	Cost: 9.07s
Train Epoch: 486 [81920/90000 (91%)]	Loss: -4.3401	Cost: 9.24s
Train Epoch: 486 	Average Loss: -4.0851
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1993

Learning rate: 0.00019883668199735307
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 487 [0/90000 (0%)]	Loss: -1.3784	Cost: 24.05s
Train Epoch: 487 [20480/90000 (23%)]	Loss: -4.8065	Cost: 9.48s
Train Epoch: 487 [40960/90000 (45%)]	Loss: -4.2298	Cost: 9.24s
Train Epoch: 487 [61440/90000 (68%)]	Loss: -4.1649	Cost: 9.03s
Train Epoch: 487 [81920/90000 (91%)]	Loss: -4.2334	Cost: 9.10s
Train Epoch: 487 	Average Loss: -4.2402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9669

Learning rate: 0.00019883189910677464
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 488 [0/90000 (0%)]	Loss: -0.9509	Cost: 23.93s
Train Epoch: 488 [20480/90000 (23%)]	Loss: -4.8191	Cost: 10.07s
Train Epoch: 488 [40960/90000 (45%)]	Loss: -4.4865	Cost: 9.34s
Train Epoch: 488 [61440/90000 (68%)]	Loss: -4.4714	Cost: 8.95s
Train Epoch: 488 [81920/90000 (91%)]	Loss: -4.5580	Cost: 9.06s
Train Epoch: 488 	Average Loss: -4.3907
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2365

Learning rate: 0.00019882710646187875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 489 [0/90000 (0%)]	Loss: -1.2321	Cost: 24.09s
Train Epoch: 489 [20480/90000 (23%)]	Loss: -4.8500	Cost: 9.32s
Train Epoch: 489 [40960/90000 (45%)]	Loss: -4.4876	Cost: 9.18s
Train Epoch: 489 [61440/90000 (68%)]	Loss: -4.5203	Cost: 9.09s
Train Epoch: 489 [81920/90000 (91%)]	Loss: -4.6144	Cost: 8.72s
Train Epoch: 489 	Average Loss: -4.4982
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2405

Learning rate: 0.00019882230406313855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 490 [0/90000 (0%)]	Loss: -1.2306	Cost: 23.97s
Train Epoch: 490 [20480/90000 (23%)]	Loss: -4.8354	Cost: 9.08s
Train Epoch: 490 [40960/90000 (45%)]	Loss: -4.5981	Cost: 9.03s
Train Epoch: 490 [61440/90000 (68%)]	Loss: -4.4550	Cost: 8.93s
Train Epoch: 490 [81920/90000 (91%)]	Loss: -4.2418	Cost: 8.63s
Train Epoch: 490 	Average Loss: -4.4174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1559

Learning rate: 0.00019881749191102795
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 491 [0/90000 (0%)]	Loss: -1.3608	Cost: 23.79s
Train Epoch: 491 [20480/90000 (23%)]	Loss: -4.7157	Cost: 9.05s
Train Epoch: 491 [40960/90000 (45%)]	Loss: -4.3806	Cost: 9.49s
Train Epoch: 491 [61440/90000 (68%)]	Loss: -2.5902	Cost: 9.07s
Train Epoch: 491 [81920/90000 (91%)]	Loss: -3.0073	Cost: 8.95s
Train Epoch: 491 	Average Loss: -3.6505
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2467

Learning rate: 0.00019881267000602186
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 492 [0/90000 (0%)]	Loss: -0.1945	Cost: 22.40s
Train Epoch: 492 [20480/90000 (23%)]	Loss: -3.9844	Cost: 9.14s
Train Epoch: 492 [40960/90000 (45%)]	Loss: -4.1411	Cost: 9.10s
Train Epoch: 492 [61440/90000 (68%)]	Loss: -4.3707	Cost: 9.15s
Train Epoch: 492 [81920/90000 (91%)]	Loss: -4.3265	Cost: 9.71s
Train Epoch: 492 	Average Loss: -3.9283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1263

Learning rate: 0.00019880783834859626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 493 [0/90000 (0%)]	Loss: -1.2935	Cost: 23.67s
Train Epoch: 493 [20480/90000 (23%)]	Loss: -4.5152	Cost: 9.17s
Train Epoch: 493 [40960/90000 (45%)]	Loss: -4.4370	Cost: 9.09s
Train Epoch: 493 [61440/90000 (68%)]	Loss: -4.5121	Cost: 9.05s
Train Epoch: 493 [81920/90000 (91%)]	Loss: -4.4070	Cost: 9.83s
Train Epoch: 493 	Average Loss: -4.3791
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2615

Learning rate: 0.000198802996939228
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 494 [0/90000 (0%)]	Loss: -1.3430	Cost: 24.00s
Train Epoch: 494 [20480/90000 (23%)]	Loss: -4.8770	Cost: 9.30s
Train Epoch: 494 [40960/90000 (45%)]	Loss: -4.6345	Cost: 9.27s
Train Epoch: 494 [61440/90000 (68%)]	Loss: -4.7145	Cost: 9.17s
Train Epoch: 494 [81920/90000 (91%)]	Loss: -4.3405	Cost: 9.18s
Train Epoch: 494 	Average Loss: -4.4928
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1691

Learning rate: 0.0001987981457783948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 495 [0/90000 (0%)]	Loss: -1.4458	Cost: 23.36s
Train Epoch: 495 [20480/90000 (23%)]	Loss: -4.8446	Cost: 9.29s
Train Epoch: 495 [40960/90000 (45%)]	Loss: -4.7609	Cost: 9.67s
Train Epoch: 495 [61440/90000 (68%)]	Loss: -4.7796	Cost: 9.30s
Train Epoch: 495 [81920/90000 (91%)]	Loss: -4.6361	Cost: 9.17s
Train Epoch: 495 	Average Loss: -4.5213
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2864

Learning rate: 0.00019879328486657562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 496 [0/90000 (0%)]	Loss: -1.0271	Cost: 21.90s
Train Epoch: 496 [20480/90000 (23%)]	Loss: -4.9224	Cost: 9.46s
Train Epoch: 496 [40960/90000 (45%)]	Loss: -4.5687	Cost: 9.25s
Train Epoch: 496 [61440/90000 (68%)]	Loss: -4.6798	Cost: 9.36s
Train Epoch: 496 [81920/90000 (91%)]	Loss: -4.5854	Cost: 9.10s
Train Epoch: 496 	Average Loss: -4.5351
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3101

Learning rate: 0.0001987884142042501
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 497 [0/90000 (0%)]	Loss: -1.0843	Cost: 22.60s
Train Epoch: 497 [20480/90000 (23%)]	Loss: -5.0382	Cost: 9.27s
Train Epoch: 497 [40960/90000 (45%)]	Loss: -4.6996	Cost: 9.33s
Train Epoch: 497 [61440/90000 (68%)]	Loss: -4.9156	Cost: 9.09s
Train Epoch: 497 [81920/90000 (91%)]	Loss: -4.7144	Cost: 9.03s
Train Epoch: 497 	Average Loss: -4.6663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4100

Learning rate: 0.00019878353379189899
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 498 [0/90000 (0%)]	Loss: -1.3843	Cost: 23.47s
Train Epoch: 498 [20480/90000 (23%)]	Loss: -5.1375	Cost: 9.31s
Train Epoch: 498 [40960/90000 (45%)]	Loss: -4.7618	Cost: 9.24s
Train Epoch: 498 [61440/90000 (68%)]	Loss: -4.8493	Cost: 9.06s
Train Epoch: 498 [81920/90000 (91%)]	Loss: -4.7696	Cost: 9.12s
Train Epoch: 498 	Average Loss: -4.7142
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3294

Learning rate: 0.00019877864363000396
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 499 [0/90000 (0%)]	Loss: -1.4816	Cost: 24.20s
Train Epoch: 499 [20480/90000 (23%)]	Loss: -5.1021	Cost: 9.27s
Train Epoch: 499 [40960/90000 (45%)]	Loss: -4.8460	Cost: 9.30s
Train Epoch: 499 [61440/90000 (68%)]	Loss: -4.9486	Cost: 9.10s
Train Epoch: 499 [81920/90000 (91%)]	Loss: -4.8143	Cost: 8.98s
Train Epoch: 499 	Average Loss: -4.7390
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4414

Learning rate: 0.00019877374371904765
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 500 [0/90000 (0%)]	Loss: -1.8267	Cost: 23.85s
Train Epoch: 500 [20480/90000 (23%)]	Loss: -5.1865	Cost: 9.39s
Train Epoch: 500 [40960/90000 (45%)]	Loss: -4.7915	Cost: 9.18s
Train Epoch: 500 [61440/90000 (68%)]	Loss: -4.9193	Cost: 8.95s
Train Epoch: 500 [81920/90000 (91%)]	Loss: -4.8540	Cost: 8.74s
Train Epoch: 500 	Average Loss: -4.7709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4831

Saving model as model.pt_e500 & waveforms_supplementary.hdf5_e500
Learning rate: 0.00019876883405951367
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 501 [0/90000 (0%)]	Loss: -1.6087	Cost: 24.22s
Train Epoch: 501 [20480/90000 (23%)]	Loss: -5.2521	Cost: 9.21s
Train Epoch: 501 [40960/90000 (45%)]	Loss: -4.8654	Cost: 9.35s
Train Epoch: 501 [61440/90000 (68%)]	Loss: -4.9206	Cost: 9.05s
Train Epoch: 501 [81920/90000 (91%)]	Loss: -4.6741	Cost: 8.98s
Train Epoch: 501 	Average Loss: -4.7451
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4909

Learning rate: 0.00019876391465188656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 502 [0/90000 (0%)]	Loss: -1.4952	Cost: 24.88s
Train Epoch: 502 [20480/90000 (23%)]	Loss: -4.7758	Cost: 9.30s
Train Epoch: 502 [40960/90000 (45%)]	Loss: -4.4423	Cost: 9.31s
Train Epoch: 502 [61440/90000 (68%)]	Loss: -4.6636	Cost: 9.04s
Train Epoch: 502 [81920/90000 (91%)]	Loss: -4.6488	Cost: 8.99s
Train Epoch: 502 	Average Loss: -4.5156
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3815

Learning rate: 0.00019875898549665186
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 503 [0/90000 (0%)]	Loss: -1.6636	Cost: 24.73s
Train Epoch: 503 [20480/90000 (23%)]	Loss: -5.0630	Cost: 9.33s
Train Epoch: 503 [40960/90000 (45%)]	Loss: -4.8340	Cost: 9.28s
Train Epoch: 503 [61440/90000 (68%)]	Loss: -4.8938	Cost: 9.29s
Train Epoch: 503 [81920/90000 (91%)]	Loss: -4.7773	Cost: 8.96s
Train Epoch: 503 	Average Loss: -4.7593
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4552

Learning rate: 0.0001987540465942961
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 504 [0/90000 (0%)]	Loss: -1.2331	Cost: 23.58s
Train Epoch: 504 [20480/90000 (23%)]	Loss: -5.2802	Cost: 9.37s
Train Epoch: 504 [40960/90000 (45%)]	Loss: -4.9729	Cost: 9.63s
Train Epoch: 504 [61440/90000 (68%)]	Loss: -4.7550	Cost: 9.09s
Train Epoch: 504 [81920/90000 (91%)]	Loss: -4.7665	Cost: 8.84s
Train Epoch: 504 	Average Loss: -4.7201
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3834

Learning rate: 0.00019874909794530664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 505 [0/90000 (0%)]	Loss: -1.3832	Cost: 24.61s
Train Epoch: 505 [20480/90000 (23%)]	Loss: -4.9578	Cost: 9.32s
Train Epoch: 505 [40960/90000 (45%)]	Loss: -4.6618	Cost: 9.36s
Train Epoch: 505 [61440/90000 (68%)]	Loss: -4.7996	Cost: 9.07s
Train Epoch: 505 [81920/90000 (91%)]	Loss: -4.6287	Cost: 8.67s
Train Epoch: 505 	Average Loss: -4.6682
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4616

Learning rate: 0.00019874413955017195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 506 [0/90000 (0%)]	Loss: -1.4922	Cost: 24.25s
Train Epoch: 506 [20480/90000 (23%)]	Loss: -5.2492	Cost: 9.34s
Train Epoch: 506 [40960/90000 (45%)]	Loss: -4.9174	Cost: 9.31s
Train Epoch: 506 [61440/90000 (68%)]	Loss: -4.9386	Cost: 9.37s
Train Epoch: 506 [81920/90000 (91%)]	Loss: -4.7737	Cost: 8.75s
Train Epoch: 506 	Average Loss: -4.8402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5104

Learning rate: 0.00019873917140938142
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 507 [0/90000 (0%)]	Loss: -1.2271	Cost: 26.26s
Train Epoch: 507 [20480/90000 (23%)]	Loss: -5.2246	Cost: 9.32s
Train Epoch: 507 [40960/90000 (45%)]	Loss: -4.8397	Cost: 9.37s
Train Epoch: 507 [61440/90000 (68%)]	Loss: -4.8490	Cost: 9.15s
Train Epoch: 507 [81920/90000 (91%)]	Loss: -4.7555	Cost: 8.89s
Train Epoch: 507 	Average Loss: -4.7836
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5785

Learning rate: 0.00019873419352342536
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 508 [0/90000 (0%)]	Loss: -1.5533	Cost: 25.33s
Train Epoch: 508 [20480/90000 (23%)]	Loss: -5.3701	Cost: 9.31s
Train Epoch: 508 [40960/90000 (45%)]	Loss: -5.1539	Cost: 9.32s
Train Epoch: 508 [61440/90000 (68%)]	Loss: -5.0691	Cost: 8.99s
Train Epoch: 508 [81920/90000 (91%)]	Loss: -5.0209	Cost: 8.85s
Train Epoch: 508 	Average Loss: -4.9737
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5461

Learning rate: 0.00019872920589279508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 509 [0/90000 (0%)]	Loss: -1.4203	Cost: 25.40s
Train Epoch: 509 [20480/90000 (23%)]	Loss: -5.0952	Cost: 9.30s
Train Epoch: 509 [40960/90000 (45%)]	Loss: -4.9133	Cost: 9.34s
Train Epoch: 509 [61440/90000 (68%)]	Loss: -4.9676	Cost: 9.01s
Train Epoch: 509 [81920/90000 (91%)]	Loss: -4.8700	Cost: 8.67s
Train Epoch: 509 	Average Loss: -4.8285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5640

Learning rate: 0.0001987242085179828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 510 [0/90000 (0%)]	Loss: -1.7146	Cost: 25.43s
Train Epoch: 510 [20480/90000 (23%)]	Loss: -5.1392	Cost: 9.22s
Train Epoch: 510 [40960/90000 (45%)]	Loss: -4.6672	Cost: 9.29s
Train Epoch: 510 [61440/90000 (68%)]	Loss: -4.6932	Cost: 9.09s
Train Epoch: 510 [81920/90000 (91%)]	Loss: -4.7409	Cost: 8.71s
Train Epoch: 510 	Average Loss: -4.7203
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5057

Learning rate: 0.00019871920139948181
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 511 [0/90000 (0%)]	Loss: -1.3169	Cost: 24.17s
Train Epoch: 511 [20480/90000 (23%)]	Loss: -5.2127	Cost: 9.44s
Train Epoch: 511 [40960/90000 (45%)]	Loss: -4.9957	Cost: 9.24s
Train Epoch: 511 [61440/90000 (68%)]	Loss: -5.1120	Cost: 9.17s
Train Epoch: 511 [81920/90000 (91%)]	Loss: -4.8841	Cost: 8.81s
Train Epoch: 511 	Average Loss: -4.8846
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6038

Learning rate: 0.00019871418453778627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 512 [0/90000 (0%)]	Loss: -1.9134	Cost: 24.68s
Train Epoch: 512 [20480/90000 (23%)]	Loss: -5.1196	Cost: 9.28s
Train Epoch: 512 [40960/90000 (45%)]	Loss: -4.8232	Cost: 9.26s
Train Epoch: 512 [61440/90000 (68%)]	Loss: -5.0513	Cost: 9.14s
Train Epoch: 512 [81920/90000 (91%)]	Loss: -4.8550	Cost: 8.75s
Train Epoch: 512 	Average Loss: -4.7629
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5605

Learning rate: 0.00019870915793339126
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 513 [0/90000 (0%)]	Loss: -1.8770	Cost: 24.49s
Train Epoch: 513 [20480/90000 (23%)]	Loss: -5.2411	Cost: 9.44s
Train Epoch: 513 [40960/90000 (45%)]	Loss: -5.1509	Cost: 9.28s
Train Epoch: 513 [61440/90000 (68%)]	Loss: -5.1402	Cost: 9.29s
Train Epoch: 513 [81920/90000 (91%)]	Loss: -5.0891	Cost: 8.88s
Train Epoch: 513 	Average Loss: -4.9386
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6581

Learning rate: 0.00019870412158679292
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 514 [0/90000 (0%)]	Loss: -1.5556	Cost: 24.75s
Train Epoch: 514 [20480/90000 (23%)]	Loss: -5.4622	Cost: 9.46s
Train Epoch: 514 [40960/90000 (45%)]	Loss: -5.1605	Cost: 9.30s
Train Epoch: 514 [61440/90000 (68%)]	Loss: -5.1652	Cost: 9.17s
Train Epoch: 514 [81920/90000 (91%)]	Loss: -5.0766	Cost: 8.94s
Train Epoch: 514 	Average Loss: -5.0592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7418

Learning rate: 0.00019869907549848836
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 515 [0/90000 (0%)]	Loss: -1.9247	Cost: 23.87s
Train Epoch: 515 [20480/90000 (23%)]	Loss: -5.5591	Cost: 9.27s
Train Epoch: 515 [40960/90000 (45%)]	Loss: -4.8819	Cost: 9.29s
Train Epoch: 515 [61440/90000 (68%)]	Loss: -5.0691	Cost: 9.09s
Train Epoch: 515 [81920/90000 (91%)]	Loss: -5.0361	Cost: 8.95s
Train Epoch: 515 	Average Loss: -5.0410
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7643

Learning rate: 0.0001986940196689756
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 516 [0/90000 (0%)]	Loss: -1.8782	Cost: 24.27s
Train Epoch: 516 [20480/90000 (23%)]	Loss: -5.6737	Cost: 9.37s
Train Epoch: 516 [40960/90000 (45%)]	Loss: -5.3463	Cost: 9.36s
Train Epoch: 516 [61440/90000 (68%)]	Loss: -5.4621	Cost: 9.02s
Train Epoch: 516 [81920/90000 (91%)]	Loss: -5.1655	Cost: 8.96s
Train Epoch: 516 	Average Loss: -5.2264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8778

Learning rate: 0.00019868895409875357
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 517 [0/90000 (0%)]	Loss: -2.0329	Cost: 24.37s
Train Epoch: 517 [20480/90000 (23%)]	Loss: -5.3587	Cost: 9.47s
Train Epoch: 517 [40960/90000 (45%)]	Loss: -5.2428	Cost: 9.17s
Train Epoch: 517 [61440/90000 (68%)]	Loss: -5.3051	Cost: 8.97s
Train Epoch: 517 [81920/90000 (91%)]	Loss: -5.0696	Cost: 8.99s
Train Epoch: 517 	Average Loss: -5.1091
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6105

Learning rate: 0.00019868387878832229
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 518 [0/90000 (0%)]	Loss: -1.3451	Cost: 24.45s
Train Epoch: 518 [20480/90000 (23%)]	Loss: -4.4746	Cost: 9.22s
Train Epoch: 518 [40960/90000 (45%)]	Loss: -4.6269	Cost: 9.19s
Train Epoch: 518 [61440/90000 (68%)]	Loss: -5.0312	Cost: 9.14s
Train Epoch: 518 [81920/90000 (91%)]	Loss: -4.8270	Cost: 8.68s
Train Epoch: 518 	Average Loss: -4.5505
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4917

Learning rate: 0.00019867879373818264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 519 [0/90000 (0%)]	Loss: -1.9102	Cost: 24.52s
Train Epoch: 519 [20480/90000 (23%)]	Loss: -5.1032	Cost: 9.11s
Train Epoch: 519 [40960/90000 (45%)]	Loss: -5.0990	Cost: 9.10s
Train Epoch: 519 [61440/90000 (68%)]	Loss: -5.2965	Cost: 9.03s
Train Epoch: 519 [81920/90000 (91%)]	Loss: -5.2765	Cost: 8.65s
Train Epoch: 519 	Average Loss: -5.0181
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7906

Learning rate: 0.00019867369894883648
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 520 [0/90000 (0%)]	Loss: -1.7537	Cost: 23.84s
Train Epoch: 520 [20480/90000 (23%)]	Loss: -5.4209	Cost: 9.08s
Train Epoch: 520 [40960/90000 (45%)]	Loss: -5.0794	Cost: 9.37s
Train Epoch: 520 [61440/90000 (68%)]	Loss: -5.0260	Cost: 9.09s
Train Epoch: 520 [81920/90000 (91%)]	Loss: -5.0585	Cost: 9.81s
Train Epoch: 520 	Average Loss: -5.0145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7742

Learning rate: 0.0001986685944207867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 521 [0/90000 (0%)]	Loss: -1.9946	Cost: 22.78s
Train Epoch: 521 [20480/90000 (23%)]	Loss: -5.6520	Cost: 9.12s
Train Epoch: 521 [40960/90000 (45%)]	Loss: -5.3540	Cost: 9.30s
Train Epoch: 521 [61440/90000 (68%)]	Loss: -5.4507	Cost: 9.14s
Train Epoch: 521 [81920/90000 (91%)]	Loss: -5.2587	Cost: 9.84s
Train Epoch: 521 	Average Loss: -5.2496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8493

Learning rate: 0.00019866348015453705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 522 [0/90000 (0%)]	Loss: -1.7544	Cost: 22.56s
Train Epoch: 522 [20480/90000 (23%)]	Loss: -5.6615	Cost: 9.31s
Train Epoch: 522 [40960/90000 (45%)]	Loss: -5.0403	Cost: 9.15s
Train Epoch: 522 [61440/90000 (68%)]	Loss: -5.0899	Cost: 9.16s
Train Epoch: 522 [81920/90000 (91%)]	Loss: -4.3480	Cost: 9.17s
Train Epoch: 522 	Average Loss: -4.9933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4896

Learning rate: 0.0001986583561505923
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 523 [0/90000 (0%)]	Loss: -1.2053	Cost: 22.22s
Train Epoch: 523 [20480/90000 (23%)]	Loss: -5.1914	Cost: 9.32s
Train Epoch: 523 [40960/90000 (45%)]	Loss: -4.8957	Cost: 9.37s
Train Epoch: 523 [61440/90000 (68%)]	Loss: -4.9482	Cost: 9.15s
Train Epoch: 523 [81920/90000 (91%)]	Loss: -4.9424	Cost: 9.00s
Train Epoch: 523 	Average Loss: -4.8612
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6749

Learning rate: 0.0001986532224094582
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 524 [0/90000 (0%)]	Loss: -1.8592	Cost: 22.75s
Train Epoch: 524 [20480/90000 (23%)]	Loss: -5.4192	Cost: 9.30s
Train Epoch: 524 [40960/90000 (45%)]	Loss: -5.2994	Cost: 9.36s
Train Epoch: 524 [61440/90000 (68%)]	Loss: -5.1823	Cost: 8.91s
Train Epoch: 524 [81920/90000 (91%)]	Loss: -5.3637	Cost: 9.10s
Train Epoch: 524 	Average Loss: -5.2089
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9012

Learning rate: 0.00019864807893164133
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 525 [0/90000 (0%)]	Loss: -2.0035	Cost: 23.77s
Train Epoch: 525 [20480/90000 (23%)]	Loss: -5.7604	Cost: 9.13s
Train Epoch: 525 [40960/90000 (45%)]	Loss: -5.5483	Cost: 9.31s
Train Epoch: 525 [61440/90000 (68%)]	Loss: -5.5086	Cost: 9.01s
Train Epoch: 525 [81920/90000 (91%)]	Loss: -5.3669	Cost: 9.09s
Train Epoch: 525 	Average Loss: -5.4589
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9710

Learning rate: 0.00019864292571764947
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 526 [0/90000 (0%)]	Loss: -2.0333	Cost: 23.97s
Train Epoch: 526 [20480/90000 (23%)]	Loss: -5.7323	Cost: 9.18s
Train Epoch: 526 [40960/90000 (45%)]	Loss: -4.7672	Cost: 9.38s
Train Epoch: 526 [61440/90000 (68%)]	Loss: -5.2675	Cost: 9.04s
Train Epoch: 526 [81920/90000 (91%)]	Loss: -5.1912	Cost: 9.18s
Train Epoch: 526 	Average Loss: -5.1629
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7861

Learning rate: 0.00019863776276799112
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 527 [0/90000 (0%)]	Loss: -1.6614	Cost: 23.35s
Train Epoch: 527 [20480/90000 (23%)]	Loss: -5.5883	Cost: 9.27s
Train Epoch: 527 [40960/90000 (45%)]	Loss: -5.3340	Cost: 9.27s
Train Epoch: 527 [61440/90000 (68%)]	Loss: -5.5275	Cost: 9.02s
Train Epoch: 527 [81920/90000 (91%)]	Loss: -5.4126	Cost: 8.97s
Train Epoch: 527 	Average Loss: -5.2245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9912

Learning rate: 0.00019863259008317586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 528 [0/90000 (0%)]	Loss: -2.2882	Cost: 23.88s
Train Epoch: 528 [20480/90000 (23%)]	Loss: -5.9683	Cost: 9.30s
Train Epoch: 528 [40960/90000 (45%)]	Loss: -5.5823	Cost: 9.45s
Train Epoch: 528 [61440/90000 (68%)]	Loss: -5.7439	Cost: 9.15s
Train Epoch: 528 [81920/90000 (91%)]	Loss: -5.3648	Cost: 8.89s
Train Epoch: 528 	Average Loss: -5.4943
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8126

Learning rate: 0.00019862740766371425
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 529 [0/90000 (0%)]	Loss: -1.8470	Cost: 23.87s
Train Epoch: 529 [20480/90000 (23%)]	Loss: -5.6949	Cost: 9.41s
Train Epoch: 529 [40960/90000 (45%)]	Loss: -5.2942	Cost: 9.27s
Train Epoch: 529 [61440/90000 (68%)]	Loss: -5.3183	Cost: 9.14s
Train Epoch: 529 [81920/90000 (91%)]	Loss: -5.5028	Cost: 8.86s
Train Epoch: 529 	Average Loss: -5.2702
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7048

Learning rate: 0.00019862221551011772
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 530 [0/90000 (0%)]	Loss: -1.9893	Cost: 25.05s
Train Epoch: 530 [20480/90000 (23%)]	Loss: -5.5954	Cost: 9.28s
Train Epoch: 530 [40960/90000 (45%)]	Loss: -5.5991	Cost: 9.15s
Train Epoch: 530 [61440/90000 (68%)]	Loss: -5.3985	Cost: 8.95s
Train Epoch: 530 [81920/90000 (91%)]	Loss: -5.4902	Cost: 8.67s
Train Epoch: 530 	Average Loss: -5.3561
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0692

Learning rate: 0.0001986170136228988
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 531 [0/90000 (0%)]	Loss: -2.2511	Cost: 23.44s
Train Epoch: 531 [20480/90000 (23%)]	Loss: -6.1410	Cost: 9.30s
Train Epoch: 531 [40960/90000 (45%)]	Loss: -5.5723	Cost: 9.32s
Train Epoch: 531 [61440/90000 (68%)]	Loss: -5.6933	Cost: 9.20s
Train Epoch: 531 [81920/90000 (91%)]	Loss: -5.4645	Cost: 8.79s
Train Epoch: 531 	Average Loss: -5.5031
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8953

Learning rate: 0.00019861180200257079
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 532 [0/90000 (0%)]	Loss: -1.9881	Cost: 24.21s
Train Epoch: 532 [20480/90000 (23%)]	Loss: -5.8574	Cost: 9.36s
Train Epoch: 532 [40960/90000 (45%)]	Loss: -5.5448	Cost: 9.24s
Train Epoch: 532 [61440/90000 (68%)]	Loss: -5.6126	Cost: 9.14s
Train Epoch: 532 [81920/90000 (91%)]	Loss: -5.2290	Cost: 8.74s
Train Epoch: 532 	Average Loss: -5.4502
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9899

Learning rate: 0.00019860658064964812
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 533 [0/90000 (0%)]	Loss: -1.6339	Cost: 26.02s
Train Epoch: 533 [20480/90000 (23%)]	Loss: -6.0655	Cost: 9.30s
Train Epoch: 533 [40960/90000 (45%)]	Loss: -5.9664	Cost: 9.36s
Train Epoch: 533 [61440/90000 (68%)]	Loss: -5.7920	Cost: 9.10s
Train Epoch: 533 [81920/90000 (91%)]	Loss: -5.7080	Cost: 8.73s
Train Epoch: 533 	Average Loss: -5.6450
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1465

Learning rate: 0.0001986013495646461
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 534 [0/90000 (0%)]	Loss: -2.8835	Cost: 25.55s
Train Epoch: 534 [20480/90000 (23%)]	Loss: -6.1869	Cost: 9.33s
Train Epoch: 534 [40960/90000 (45%)]	Loss: -5.6626	Cost: 9.24s
Train Epoch: 534 [61440/90000 (68%)]	Loss: -5.5521	Cost: 9.07s
Train Epoch: 534 [81920/90000 (91%)]	Loss: -5.6786	Cost: 8.82s
Train Epoch: 534 	Average Loss: -5.5649
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1036

Learning rate: 0.00019859610874808106
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 535 [0/90000 (0%)]	Loss: -1.8127	Cost: 26.18s
Train Epoch: 535 [20480/90000 (23%)]	Loss: -5.9936	Cost: 9.31s
Train Epoch: 535 [40960/90000 (45%)]	Loss: -5.6787	Cost: 9.35s
Train Epoch: 535 [61440/90000 (68%)]	Loss: -5.6791	Cost: 9.06s
Train Epoch: 535 [81920/90000 (91%)]	Loss: -5.4461	Cost: 8.77s
Train Epoch: 535 	Average Loss: -5.5396
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0697

Learning rate: 0.0001985908582004702
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 536 [0/90000 (0%)]	Loss: -1.8019	Cost: 24.28s
Train Epoch: 536 [20480/90000 (23%)]	Loss: -5.8708	Cost: 9.29s
Train Epoch: 536 [40960/90000 (45%)]	Loss: -5.8224	Cost: 9.36s
Train Epoch: 536 [61440/90000 (68%)]	Loss: -5.6212	Cost: 9.08s
Train Epoch: 536 [81920/90000 (91%)]	Loss: -5.5781	Cost: 8.87s
Train Epoch: 536 	Average Loss: -5.5474
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0934

Learning rate: 0.00019858559792233175
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 537 [0/90000 (0%)]	Loss: -1.9185	Cost: 25.94s
Train Epoch: 537 [20480/90000 (23%)]	Loss: -5.5429	Cost: 9.31s
Train Epoch: 537 [40960/90000 (45%)]	Loss: -5.3011	Cost: 9.27s
Train Epoch: 537 [61440/90000 (68%)]	Loss: -5.3333	Cost: 9.10s
Train Epoch: 537 [81920/90000 (91%)]	Loss: -5.2642	Cost: 8.91s
Train Epoch: 537 	Average Loss: -5.2209
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9781

Learning rate: 0.00019858032791418486
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 538 [0/90000 (0%)]	Loss: -1.7400	Cost: 24.16s
Train Epoch: 538 [20480/90000 (23%)]	Loss: -5.9382	Cost: 9.44s
Train Epoch: 538 [40960/90000 (45%)]	Loss: -5.8597	Cost: 9.45s
Train Epoch: 538 [61440/90000 (68%)]	Loss: -5.9096	Cost: 9.19s
Train Epoch: 538 [81920/90000 (91%)]	Loss: -5.7886	Cost: 8.98s
Train Epoch: 538 	Average Loss: -5.6173
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1486

Learning rate: 0.00019857504817654965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 539 [0/90000 (0%)]	Loss: -2.4443	Cost: 24.03s
Train Epoch: 539 [20480/90000 (23%)]	Loss: -6.0972	Cost: 9.38s
Train Epoch: 539 [40960/90000 (45%)]	Loss: -6.0573	Cost: 9.29s
Train Epoch: 539 [61440/90000 (68%)]	Loss: -5.6031	Cost: 9.15s
Train Epoch: 539 [81920/90000 (91%)]	Loss: -5.5416	Cost: 9.04s
Train Epoch: 539 	Average Loss: -5.6300
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9839

Learning rate: 0.00019856975870994725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 540 [0/90000 (0%)]	Loss: -1.6851	Cost: 24.78s
Train Epoch: 540 [20480/90000 (23%)]	Loss: -5.8829	Cost: 9.34s
Train Epoch: 540 [40960/90000 (45%)]	Loss: -5.7485	Cost: 9.30s
Train Epoch: 540 [61440/90000 (68%)]	Loss: -5.8843	Cost: 9.08s
Train Epoch: 540 [81920/90000 (91%)]	Loss: -5.5492	Cost: 8.95s
Train Epoch: 540 	Average Loss: -5.6136
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2194

Learning rate: 0.0001985644595148997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 541 [0/90000 (0%)]	Loss: -1.8419	Cost: 24.08s
Train Epoch: 541 [20480/90000 (23%)]	Loss: -6.1535	Cost: 9.57s
Train Epoch: 541 [40960/90000 (45%)]	Loss: -6.0791	Cost: 9.26s
Train Epoch: 541 [61440/90000 (68%)]	Loss: -5.9883	Cost: 9.12s
Train Epoch: 541 [81920/90000 (91%)]	Loss: -5.6668	Cost: 9.02s
Train Epoch: 541 	Average Loss: -5.7993
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2334

Learning rate: 0.00019855915059192997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 542 [0/90000 (0%)]	Loss: -2.2362	Cost: 24.19s
Train Epoch: 542 [20480/90000 (23%)]	Loss: -6.0398	Cost: 9.47s
Train Epoch: 542 [40960/90000 (45%)]	Loss: -5.7593	Cost: 9.24s
Train Epoch: 542 [61440/90000 (68%)]	Loss: -5.9117	Cost: 9.14s
Train Epoch: 542 [81920/90000 (91%)]	Loss: -5.5057	Cost: 9.05s
Train Epoch: 542 	Average Loss: -5.6558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9134

Learning rate: 0.00019855383194156202
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 543 [0/90000 (0%)]	Loss: -1.9462	Cost: 23.86s
Train Epoch: 543 [20480/90000 (23%)]	Loss: -5.7942	Cost: 9.38s
Train Epoch: 543 [40960/90000 (45%)]	Loss: -5.6185	Cost: 9.34s
Train Epoch: 543 [61440/90000 (68%)]	Loss: -5.6063	Cost: 9.09s
Train Epoch: 543 [81920/90000 (91%)]	Loss: -5.6781	Cost: 9.08s
Train Epoch: 543 	Average Loss: -5.5198
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2559

Learning rate: 0.00019854850356432085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 544 [0/90000 (0%)]	Loss: -2.1122	Cost: 25.32s
Train Epoch: 544 [20480/90000 (23%)]	Loss: -5.9039	Cost: 9.35s
Train Epoch: 544 [40960/90000 (45%)]	Loss: -6.0447	Cost: 10.11s
Train Epoch: 544 [61440/90000 (68%)]	Loss: -6.0383	Cost: 8.96s
Train Epoch: 544 [81920/90000 (91%)]	Loss: -5.3882	Cost: 8.97s
Train Epoch: 544 	Average Loss: -5.6580
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1189

Learning rate: 0.00019854316546073235
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 545 [0/90000 (0%)]	Loss: -2.0694	Cost: 24.44s
Train Epoch: 545 [20480/90000 (23%)]	Loss: -6.1919	Cost: 9.25s
Train Epoch: 545 [40960/90000 (45%)]	Loss: -5.9437	Cost: 9.18s
Train Epoch: 545 [61440/90000 (68%)]	Loss: -6.0079	Cost: 9.04s
Train Epoch: 545 [81920/90000 (91%)]	Loss: -5.8663	Cost: 8.85s
Train Epoch: 545 	Average Loss: -5.7446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2405

Learning rate: 0.0001985378176313233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 546 [0/90000 (0%)]	Loss: -2.2012	Cost: 24.07s
Train Epoch: 546 [20480/90000 (23%)]	Loss: -6.1501	Cost: 9.39s
Train Epoch: 546 [40960/90000 (45%)]	Loss: -5.9701	Cost: 9.18s
Train Epoch: 546 [61440/90000 (68%)]	Loss: -5.9568	Cost: 8.98s
Train Epoch: 546 [81920/90000 (91%)]	Loss: -5.7153	Cost: 8.70s
Train Epoch: 546 	Average Loss: -5.8141
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3567

Learning rate: 0.00019853246007662156
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 547 [0/90000 (0%)]	Loss: -2.0611	Cost: 24.52s
Train Epoch: 547 [20480/90000 (23%)]	Loss: -6.1698	Cost: 9.06s
Train Epoch: 547 [40960/90000 (45%)]	Loss: -5.9557	Cost: 9.02s
Train Epoch: 547 [61440/90000 (68%)]	Loss: -5.8073	Cost: 8.97s
Train Epoch: 547 [81920/90000 (91%)]	Loss: -5.6578	Cost: 8.62s
Train Epoch: 547 	Average Loss: -5.6787
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2445

Learning rate: 0.0001985270927971559
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 548 [0/90000 (0%)]	Loss: -2.5439	Cost: 24.11s
Train Epoch: 548 [20480/90000 (23%)]	Loss: -6.2018	Cost: 9.05s
Train Epoch: 548 [40960/90000 (45%)]	Loss: -6.1071	Cost: 9.53s
Train Epoch: 548 [61440/90000 (68%)]	Loss: -6.1104	Cost: 9.01s
Train Epoch: 548 [81920/90000 (91%)]	Loss: -5.9457	Cost: 9.09s
Train Epoch: 548 	Average Loss: -5.9307
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3713

Learning rate: 0.00019852171579345603
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 549 [0/90000 (0%)]	Loss: -2.3781	Cost: 22.38s
Train Epoch: 549 [20480/90000 (23%)]	Loss: -6.3997	Cost: 9.08s
Train Epoch: 549 [40960/90000 (45%)]	Loss: -6.2077	Cost: 9.17s
Train Epoch: 549 [61440/90000 (68%)]	Loss: -6.1272	Cost: 9.12s
Train Epoch: 549 [81920/90000 (91%)]	Loss: -5.7079	Cost: 9.17s
Train Epoch: 549 	Average Loss: -5.9167
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0661

Learning rate: 0.0001985163290660526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 550 [0/90000 (0%)]	Loss: -2.0265	Cost: 23.60s
Train Epoch: 550 [20480/90000 (23%)]	Loss: -5.9342	Cost: 9.18s
Train Epoch: 550 [40960/90000 (45%)]	Loss: -5.8947	Cost: 9.11s
Train Epoch: 550 [61440/90000 (68%)]	Loss: -5.7435	Cost: 9.07s
Train Epoch: 550 [81920/90000 (91%)]	Loss: -5.5799	Cost: 9.91s
Train Epoch: 550 	Average Loss: -5.5953
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1055

Saving model as model.pt_e550 & waveforms_supplementary.hdf5_e550
Learning rate: 0.0001985109326154773
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 551 [0/90000 (0%)]	Loss: -2.4380	Cost: 23.85s
Train Epoch: 551 [20480/90000 (23%)]	Loss: -6.1303	Cost: 9.56s
Train Epoch: 551 [40960/90000 (45%)]	Loss: -5.9453	Cost: 9.36s
Train Epoch: 551 [61440/90000 (68%)]	Loss: -6.1790	Cost: 9.08s
Train Epoch: 551 [81920/90000 (91%)]	Loss: -5.9658	Cost: 9.69s
Train Epoch: 551 	Average Loss: -5.8739
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4111

Learning rate: 0.00019850552644226275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 552 [0/90000 (0%)]	Loss: -2.5796	Cost: 22.95s
Train Epoch: 552 [20480/90000 (23%)]	Loss: -6.3087	Cost: 9.34s
Train Epoch: 552 [40960/90000 (45%)]	Loss: -6.3804	Cost: 9.42s
Train Epoch: 552 [61440/90000 (68%)]	Loss: -6.2171	Cost: 9.19s
Train Epoch: 552 [81920/90000 (91%)]	Loss: -6.0821	Cost: 9.07s
Train Epoch: 552 	Average Loss: -6.0799
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5334

Learning rate: 0.0001985001105469425
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 553 [0/90000 (0%)]	Loss: -2.1470	Cost: 23.05s
Train Epoch: 553 [20480/90000 (23%)]	Loss: -6.4733	Cost: 9.32s
Train Epoch: 553 [40960/90000 (45%)]	Loss: -6.2686	Cost: 9.29s
Train Epoch: 553 [61440/90000 (68%)]	Loss: -6.1091	Cost: 9.18s
Train Epoch: 553 [81920/90000 (91%)]	Loss: -6.1614	Cost: 9.42s
Train Epoch: 553 	Average Loss: -6.0173
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2860

Learning rate: 0.00019849468493005109
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 554 [0/90000 (0%)]	Loss: -2.5541	Cost: 22.78s
Train Epoch: 554 [20480/90000 (23%)]	Loss: -6.3014	Cost: 9.42s
Train Epoch: 554 [40960/90000 (45%)]	Loss: -5.9436	Cost: 9.40s
Train Epoch: 554 [61440/90000 (68%)]	Loss: -6.0900	Cost: 9.18s
Train Epoch: 554 [81920/90000 (91%)]	Loss: -6.0314	Cost: 9.11s
Train Epoch: 554 	Average Loss: -5.9274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4438

Learning rate: 0.000198489249592124
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 555 [0/90000 (0%)]	Loss: -2.4725	Cost: 22.50s
Train Epoch: 555 [20480/90000 (23%)]	Loss: -6.5362	Cost: 9.34s
Train Epoch: 555 [40960/90000 (45%)]	Loss: -6.2600	Cost: 9.32s
Train Epoch: 555 [61440/90000 (68%)]	Loss: -6.4484	Cost: 9.06s
Train Epoch: 555 [81920/90000 (91%)]	Loss: -6.0931	Cost: 9.28s
Train Epoch: 555 	Average Loss: -6.1533
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4606

Learning rate: 0.00019848380453369767
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 556 [0/90000 (0%)]	Loss: -2.5392	Cost: 22.88s
Train Epoch: 556 [20480/90000 (23%)]	Loss: -6.3883	Cost: 9.34s
Train Epoch: 556 [40960/90000 (45%)]	Loss: -6.1014	Cost: 9.28s
Train Epoch: 556 [61440/90000 (68%)]	Loss: -6.2943	Cost: 9.28s
Train Epoch: 556 [81920/90000 (91%)]	Loss: -5.8522	Cost: 8.98s
Train Epoch: 556 	Average Loss: -5.9890
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5083

Learning rate: 0.00019847834975530955
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 557 [0/90000 (0%)]	Loss: -2.5310	Cost: 24.50s
Train Epoch: 557 [20480/90000 (23%)]	Loss: -6.4541	Cost: 9.59s
Train Epoch: 557 [40960/90000 (45%)]	Loss: -6.0476	Cost: 9.38s
Train Epoch: 557 [61440/90000 (68%)]	Loss: -6.1820	Cost: 8.95s
Train Epoch: 557 [81920/90000 (91%)]	Loss: -6.0504	Cost: 8.91s
Train Epoch: 557 	Average Loss: -5.9900
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5261

Learning rate: 0.00019847288525749797
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 558 [0/90000 (0%)]	Loss: -2.6499	Cost: 25.14s
Train Epoch: 558 [20480/90000 (23%)]	Loss: -6.6791	Cost: 9.31s
Train Epoch: 558 [40960/90000 (45%)]	Loss: -6.3182	Cost: 9.78s
Train Epoch: 558 [61440/90000 (68%)]	Loss: -6.3451	Cost: 8.92s
Train Epoch: 558 [81920/90000 (91%)]	Loss: -6.3933	Cost: 9.04s
Train Epoch: 558 	Average Loss: -6.1842
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7345

Learning rate: 0.0001984674110408022
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 559 [0/90000 (0%)]	Loss: -2.3314	Cost: 24.69s
Train Epoch: 559 [20480/90000 (23%)]	Loss: -6.8805	Cost: 9.31s
Train Epoch: 559 [40960/90000 (45%)]	Loss: -6.1851	Cost: 9.37s
Train Epoch: 559 [61440/90000 (68%)]	Loss: -6.3208	Cost: 9.07s
Train Epoch: 559 [81920/90000 (91%)]	Loss: -6.0234	Cost: 8.80s
Train Epoch: 559 	Average Loss: -6.2105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5922

Learning rate: 0.0001984619271057626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 560 [0/90000 (0%)]	Loss: -2.4126	Cost: 24.64s
Train Epoch: 560 [20480/90000 (23%)]	Loss: -6.5328	Cost: 9.25s
Train Epoch: 560 [40960/90000 (45%)]	Loss: -6.4898	Cost: 9.18s
Train Epoch: 560 [61440/90000 (68%)]	Loss: -6.6666	Cost: 8.94s
Train Epoch: 560 [81920/90000 (91%)]	Loss: -6.2570	Cost: 8.76s
Train Epoch: 560 	Average Loss: -6.3548
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6683

Learning rate: 0.0001984564334529204
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 561 [0/90000 (0%)]	Loss: -2.6975	Cost: 25.24s
Train Epoch: 561 [20480/90000 (23%)]	Loss: -6.6556	Cost: 9.30s
Train Epoch: 561 [40960/90000 (45%)]	Loss: -6.3259	Cost: 9.27s
Train Epoch: 561 [61440/90000 (68%)]	Loss: -6.3973	Cost: 9.19s
Train Epoch: 561 [81920/90000 (91%)]	Loss: -6.1637	Cost: 8.79s
Train Epoch: 561 	Average Loss: -6.2555
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6073

Learning rate: 0.0001984509300828178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 562 [0/90000 (0%)]	Loss: -2.3857	Cost: 24.39s
Train Epoch: 562 [20480/90000 (23%)]	Loss: -6.7714	Cost: 9.30s
Train Epoch: 562 [40960/90000 (45%)]	Loss: -6.4110	Cost: 9.33s
Train Epoch: 562 [61440/90000 (68%)]	Loss: -6.6440	Cost: 9.20s
Train Epoch: 562 [81920/90000 (91%)]	Loss: -6.1987	Cost: 8.80s
Train Epoch: 562 	Average Loss: -6.2927
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5318

Learning rate: 0.00019844541699599793
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 563 [0/90000 (0%)]	Loss: -2.4971	Cost: 26.20s
Train Epoch: 563 [20480/90000 (23%)]	Loss: -6.6473	Cost: 9.31s
Train Epoch: 563 [40960/90000 (45%)]	Loss: -6.3496	Cost: 9.29s
Train Epoch: 563 [61440/90000 (68%)]	Loss: -6.4185	Cost: 9.14s
Train Epoch: 563 [81920/90000 (91%)]	Loss: -6.3257	Cost: 8.70s
Train Epoch: 563 	Average Loss: -6.2246
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6367

Learning rate: 0.00019843989419300492
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 564 [0/90000 (0%)]	Loss: -2.3508	Cost: 24.85s
Train Epoch: 564 [20480/90000 (23%)]	Loss: -6.6656	Cost: 9.40s
Train Epoch: 564 [40960/90000 (45%)]	Loss: -6.5452	Cost: 9.27s
Train Epoch: 564 [61440/90000 (68%)]	Loss: -6.4831	Cost: 9.17s
Train Epoch: 564 [81920/90000 (91%)]	Loss: -6.1709	Cost: 8.70s
Train Epoch: 564 	Average Loss: -6.2853
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7239

Learning rate: 0.00019843436167438387
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 565 [0/90000 (0%)]	Loss: -2.7566	Cost: 24.14s
Train Epoch: 565 [20480/90000 (23%)]	Loss: -6.8514	Cost: 9.40s
Train Epoch: 565 [40960/90000 (45%)]	Loss: -6.3793	Cost: 9.27s
Train Epoch: 565 [61440/90000 (68%)]	Loss: -6.3567	Cost: 9.19s
Train Epoch: 565 [81920/90000 (91%)]	Loss: -6.1237	Cost: 8.88s
Train Epoch: 565 	Average Loss: -6.2473
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6004

Learning rate: 0.00019842881944068082
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 566 [0/90000 (0%)]	Loss: -2.5896	Cost: 24.47s
Train Epoch: 566 [20480/90000 (23%)]	Loss: -6.0389	Cost: 9.32s
Train Epoch: 566 [40960/90000 (45%)]	Loss: -6.1513	Cost: 9.31s
Train Epoch: 566 [61440/90000 (68%)]	Loss: -5.8360	Cost: 9.12s
Train Epoch: 566 [81920/90000 (91%)]	Loss: -5.8638	Cost: 8.88s
Train Epoch: 566 	Average Loss: -5.8950
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4438

Learning rate: 0.00019842326749244275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 567 [0/90000 (0%)]	Loss: -2.5028	Cost: 27.09s
Train Epoch: 567 [20480/90000 (23%)]	Loss: -6.3890	Cost: 9.43s
Train Epoch: 567 [40960/90000 (45%)]	Loss: -5.6903	Cost: 9.69s
Train Epoch: 567 [61440/90000 (68%)]	Loss: -5.8188	Cost: 9.09s
Train Epoch: 567 [81920/90000 (91%)]	Loss: -5.9815	Cost: 8.97s
Train Epoch: 567 	Average Loss: -5.8361
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5312

Learning rate: 0.00019841770583021762
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 568 [0/90000 (0%)]	Loss: -2.4617	Cost: 24.83s
Train Epoch: 568 [20480/90000 (23%)]	Loss: -6.7144	Cost: 9.36s
Train Epoch: 568 [40960/90000 (45%)]	Loss: -6.6796	Cost: 9.27s
Train Epoch: 568 [61440/90000 (68%)]	Loss: -6.4214	Cost: 9.11s
Train Epoch: 568 [81920/90000 (91%)]	Loss: -6.5194	Cost: 8.89s
Train Epoch: 568 	Average Loss: -6.3666
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8578

Learning rate: 0.00019841213445455434
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 569 [0/90000 (0%)]	Loss: -2.9198	Cost: 24.80s
Train Epoch: 569 [20480/90000 (23%)]	Loss: -6.9507	Cost: 9.30s
Train Epoch: 569 [40960/90000 (45%)]	Loss: -6.7252	Cost: 9.33s
Train Epoch: 569 [61440/90000 (68%)]	Loss: -6.6187	Cost: 9.44s
Train Epoch: 569 [81920/90000 (91%)]	Loss: -6.3041	Cost: 8.86s
Train Epoch: 569 	Average Loss: -6.4858
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7007

Learning rate: 0.00019840655336600282
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 570 [0/90000 (0%)]	Loss: -2.4008	Cost: 23.72s
Train Epoch: 570 [20480/90000 (23%)]	Loss: -6.8380	Cost: 9.37s
Train Epoch: 570 [40960/90000 (45%)]	Loss: -6.5564	Cost: 9.27s
Train Epoch: 570 [61440/90000 (68%)]	Loss: -6.9176	Cost: 9.10s
Train Epoch: 570 [81920/90000 (91%)]	Loss: -6.6240	Cost: 8.91s
Train Epoch: 570 	Average Loss: -6.4968
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9027

Learning rate: 0.00019840096256511382
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 571 [0/90000 (0%)]	Loss: -2.8323	Cost: 24.08s
Train Epoch: 571 [20480/90000 (23%)]	Loss: -6.9297	Cost: 9.47s
Train Epoch: 571 [40960/90000 (45%)]	Loss: -6.6194	Cost: 9.30s
Train Epoch: 571 [61440/90000 (68%)]	Loss: -6.5238	Cost: 9.05s
Train Epoch: 571 [81920/90000 (91%)]	Loss: -6.5359	Cost: 9.25s
Train Epoch: 571 	Average Loss: -6.4942
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6933

Learning rate: 0.0001983953620524392
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 572 [0/90000 (0%)]	Loss: -2.8933	Cost: 23.97s
Train Epoch: 572 [20480/90000 (23%)]	Loss: -6.9257	Cost: 9.21s
Train Epoch: 572 [40960/90000 (45%)]	Loss: -6.7168	Cost: 9.34s
Train Epoch: 572 [61440/90000 (68%)]	Loss: -6.2405	Cost: 8.99s
Train Epoch: 572 [81920/90000 (91%)]	Loss: -5.9049	Cost: 8.86s
Train Epoch: 572 	Average Loss: -6.3351
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4047

Learning rate: 0.00019838975182853166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 573 [0/90000 (0%)]	Loss: -2.0594	Cost: 23.91s
Train Epoch: 573 [20480/90000 (23%)]	Loss: -6.3647	Cost: 9.42s
Train Epoch: 573 [40960/90000 (45%)]	Loss: -6.1758	Cost: 9.20s
Train Epoch: 573 [61440/90000 (68%)]	Loss: -6.2202	Cost: 9.52s
Train Epoch: 573 [81920/90000 (91%)]	Loss: -6.0065	Cost: 8.78s
Train Epoch: 573 	Average Loss: -6.0338
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5181

Learning rate: 0.0001983841318939449
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 574 [0/90000 (0%)]	Loss: -2.4660	Cost: 23.91s
Train Epoch: 574 [20480/90000 (23%)]	Loss: -6.6138	Cost: 9.09s
Train Epoch: 574 [40960/90000 (45%)]	Loss: -6.5694	Cost: 9.09s
Train Epoch: 574 [61440/90000 (68%)]	Loss: -6.6097	Cost: 8.89s
Train Epoch: 574 [81920/90000 (91%)]	Loss: -6.5041	Cost: 8.63s
Train Epoch: 574 	Average Loss: -6.4160
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8843

Learning rate: 0.00019837850224923363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 575 [0/90000 (0%)]	Loss: -3.2799	Cost: 24.31s
Train Epoch: 575 [20480/90000 (23%)]	Loss: -6.8259	Cost: 9.10s
Train Epoch: 575 [40960/90000 (45%)]	Loss: -6.7248	Cost: 9.36s
Train Epoch: 575 [61440/90000 (68%)]	Loss: -6.6089	Cost: 8.98s
Train Epoch: 575 [81920/90000 (91%)]	Loss: -6.7552	Cost: 9.03s
Train Epoch: 575 	Average Loss: -6.5873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9878

Learning rate: 0.00019837286289495345
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 576 [0/90000 (0%)]	Loss: -2.9670	Cost: 22.23s
Train Epoch: 576 [20480/90000 (23%)]	Loss: -6.8300	Cost: 9.06s
Train Epoch: 576 [40960/90000 (45%)]	Loss: -6.7166	Cost: 9.16s
Train Epoch: 576 [61440/90000 (68%)]	Loss: -6.7599	Cost: 9.06s
Train Epoch: 576 [81920/90000 (91%)]	Loss: -6.7820	Cost: 9.58s
Train Epoch: 576 	Average Loss: -6.6211
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9757

Learning rate: 0.00019836721383166095
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 577 [0/90000 (0%)]	Loss: -2.6850	Cost: 22.40s
Train Epoch: 577 [20480/90000 (23%)]	Loss: -6.7724	Cost: 9.32s
Train Epoch: 577 [40960/90000 (45%)]	Loss: -6.6851	Cost: 9.17s
Train Epoch: 577 [61440/90000 (68%)]	Loss: -6.8880	Cost: 9.09s
Train Epoch: 577 [81920/90000 (91%)]	Loss: -6.7938	Cost: 9.11s
Train Epoch: 577 	Average Loss: -6.6201
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0603

Learning rate: 0.00019836155505991362
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 578 [0/90000 (0%)]	Loss: -3.0835	Cost: 22.50s
Train Epoch: 578 [20480/90000 (23%)]	Loss: -7.1540	Cost: 9.17s
Train Epoch: 578 [40960/90000 (45%)]	Loss: -6.9727	Cost: 9.26s
Train Epoch: 578 [61440/90000 (68%)]	Loss: -6.7849	Cost: 9.07s
Train Epoch: 578 [81920/90000 (91%)]	Loss: -6.6271	Cost: 8.99s
Train Epoch: 578 	Average Loss: -6.6385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9617

Learning rate: 0.00019835588658027008
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 579 [0/90000 (0%)]	Loss: -2.9865	Cost: 22.45s
Train Epoch: 579 [20480/90000 (23%)]	Loss: -7.1152	Cost: 9.66s
Train Epoch: 579 [40960/90000 (45%)]	Loss: -7.0453	Cost: 9.31s
Train Epoch: 579 [61440/90000 (68%)]	Loss: -7.0529	Cost: 9.30s
Train Epoch: 579 [81920/90000 (91%)]	Loss: -6.7262	Cost: 9.16s
Train Epoch: 579 	Average Loss: -6.7938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0036

Learning rate: 0.00019835020839328965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 580 [0/90000 (0%)]	Loss: -2.6221	Cost: 22.73s
Train Epoch: 580 [20480/90000 (23%)]	Loss: -7.1425	Cost: 9.38s
Train Epoch: 580 [40960/90000 (45%)]	Loss: -6.9390	Cost: 9.43s
Train Epoch: 580 [61440/90000 (68%)]	Loss: -6.9498	Cost: 9.04s
Train Epoch: 580 [81920/90000 (91%)]	Loss: -6.6261	Cost: 9.28s
Train Epoch: 580 	Average Loss: -6.7552
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0360

Learning rate: 0.0001983445204995328
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 581 [0/90000 (0%)]	Loss: -2.7117	Cost: 23.08s
Train Epoch: 581 [20480/90000 (23%)]	Loss: -7.2654	Cost: 9.31s
Train Epoch: 581 [40960/90000 (45%)]	Loss: -6.9168	Cost: 9.30s
Train Epoch: 581 [61440/90000 (68%)]	Loss: -7.0901	Cost: 9.11s
Train Epoch: 581 [81920/90000 (91%)]	Loss: -6.7474	Cost: 8.94s
Train Epoch: 581 	Average Loss: -6.7888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1650

Learning rate: 0.00019833882289956094
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 582 [0/90000 (0%)]	Loss: -2.7217	Cost: 23.72s
Train Epoch: 582 [20480/90000 (23%)]	Loss: -7.2903	Cost: 9.10s
Train Epoch: 582 [40960/90000 (45%)]	Loss: -6.9779	Cost: 8.98s
Train Epoch: 582 [61440/90000 (68%)]	Loss: -6.9153	Cost: 8.88s
Train Epoch: 582 [81920/90000 (91%)]	Loss: -6.8614	Cost: 8.85s
Train Epoch: 582 	Average Loss: -6.8285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2160

Learning rate: 0.00019833311559393636
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 583 [0/90000 (0%)]	Loss: -3.3534	Cost: 24.79s
Train Epoch: 583 [20480/90000 (23%)]	Loss: -7.2924	Cost: 9.23s
Train Epoch: 583 [40960/90000 (45%)]	Loss: -6.9334	Cost: 9.14s
Train Epoch: 583 [61440/90000 (68%)]	Loss: -7.0865	Cost: 8.99s
Train Epoch: 583 [81920/90000 (91%)]	Loss: -6.7973	Cost: 8.72s
Train Epoch: 583 	Average Loss: -6.8708
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1109

Learning rate: 0.00019832739858322235
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 584 [0/90000 (0%)]	Loss: -2.9985	Cost: 25.06s
Train Epoch: 584 [20480/90000 (23%)]	Loss: -7.3802	Cost: 9.26s
Train Epoch: 584 [40960/90000 (45%)]	Loss: -7.0090	Cost: 9.22s
Train Epoch: 584 [61440/90000 (68%)]	Loss: -7.1649	Cost: 9.09s
Train Epoch: 584 [81920/90000 (91%)]	Loss: -6.5738	Cost: 8.68s
Train Epoch: 584 	Average Loss: -6.7788
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9007

Learning rate: 0.00019832167186798315
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 585 [0/90000 (0%)]	Loss: -2.8743	Cost: 23.58s
Train Epoch: 585 [20480/90000 (23%)]	Loss: -7.0891	Cost: 9.44s
Train Epoch: 585 [40960/90000 (45%)]	Loss: -7.0531	Cost: 9.22s
Train Epoch: 585 [61440/90000 (68%)]	Loss: -7.0134	Cost: 9.10s
Train Epoch: 585 [81920/90000 (91%)]	Loss: -6.9186	Cost: 8.73s
Train Epoch: 585 	Average Loss: -6.8063
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1643

Learning rate: 0.000198315935448784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 586 [0/90000 (0%)]	Loss: -2.7430	Cost: 24.41s
Train Epoch: 586 [20480/90000 (23%)]	Loss: -7.4597	Cost: 9.36s
Train Epoch: 586 [40960/90000 (45%)]	Loss: -7.1584	Cost: 9.53s
Train Epoch: 586 [61440/90000 (68%)]	Loss: -7.2403	Cost: 9.13s
Train Epoch: 586 [81920/90000 (91%)]	Loss: -7.0221	Cost: 8.81s
Train Epoch: 586 	Average Loss: -6.9859
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3097

Learning rate: 0.00019831018932619103
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 587 [0/90000 (0%)]	Loss: -3.1235	Cost: 26.16s
Train Epoch: 587 [20480/90000 (23%)]	Loss: -7.4548	Cost: 9.34s
Train Epoch: 587 [40960/90000 (45%)]	Loss: -7.3399	Cost: 9.35s
Train Epoch: 587 [61440/90000 (68%)]	Loss: -7.3629	Cost: 9.21s
Train Epoch: 587 [81920/90000 (91%)]	Loss: -6.9433	Cost: 8.81s
Train Epoch: 587 	Average Loss: -7.0621
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2761

Learning rate: 0.00019830443350077136
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 588 [0/90000 (0%)]	Loss: -3.2296	Cost: 26.33s
Train Epoch: 588 [20480/90000 (23%)]	Loss: -7.4675	Cost: 9.30s
Train Epoch: 588 [40960/90000 (45%)]	Loss: -7.2377	Cost: 9.31s
Train Epoch: 588 [61440/90000 (68%)]	Loss: -7.1360	Cost: 8.95s
Train Epoch: 588 [81920/90000 (91%)]	Loss: -6.9931	Cost: 8.84s
Train Epoch: 588 	Average Loss: -7.0566
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2875

Learning rate: 0.0001982986679730931
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 589 [0/90000 (0%)]	Loss: -2.8911	Cost: 26.98s
Train Epoch: 589 [20480/90000 (23%)]	Loss: -7.5101	Cost: 9.16s
Train Epoch: 589 [40960/90000 (45%)]	Loss: -7.1973	Cost: 9.29s
Train Epoch: 589 [61440/90000 (68%)]	Loss: -7.2910	Cost: 9.03s
Train Epoch: 589 [81920/90000 (91%)]	Loss: -7.0261	Cost: 8.77s
Train Epoch: 589 	Average Loss: -7.0682
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1737

Learning rate: 0.00019829289274372522
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 590 [0/90000 (0%)]	Loss: -3.0465	Cost: 24.00s
Train Epoch: 590 [20480/90000 (23%)]	Loss: -7.4744	Cost: 9.47s
Train Epoch: 590 [40960/90000 (45%)]	Loss: -7.1285	Cost: 9.44s
Train Epoch: 590 [61440/90000 (68%)]	Loss: -7.1139	Cost: 9.35s
Train Epoch: 590 [81920/90000 (91%)]	Loss: -7.1141	Cost: 8.86s
Train Epoch: 590 	Average Loss: -7.0007
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2193

Learning rate: 0.00019828710781323776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 591 [0/90000 (0%)]	Loss: -2.6745	Cost: 27.39s
Train Epoch: 591 [20480/90000 (23%)]	Loss: -7.1998	Cost: 9.30s
Train Epoch: 591 [40960/90000 (45%)]	Loss: -7.0697	Cost: 9.35s
Train Epoch: 591 [61440/90000 (68%)]	Loss: -7.1919	Cost: 9.01s
Train Epoch: 591 [81920/90000 (91%)]	Loss: -6.9769	Cost: 8.70s
Train Epoch: 591 	Average Loss: -6.8785
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3476

Learning rate: 0.00019828131318220168
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 592 [0/90000 (0%)]	Loss: -3.2376	Cost: 24.96s
Train Epoch: 592 [20480/90000 (23%)]	Loss: -7.3229	Cost: 9.34s
Train Epoch: 592 [40960/90000 (45%)]	Loss: -7.1363	Cost: 9.22s
Train Epoch: 592 [61440/90000 (68%)]	Loss: -7.3266	Cost: 9.13s
Train Epoch: 592 [81920/90000 (91%)]	Loss: -7.1780	Cost: 8.87s
Train Epoch: 592 	Average Loss: -7.0395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3804

Learning rate: 0.00019827550885118884
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 593 [0/90000 (0%)]	Loss: -3.3669	Cost: 26.45s
Train Epoch: 593 [20480/90000 (23%)]	Loss: -7.5956	Cost: 9.36s
Train Epoch: 593 [40960/90000 (45%)]	Loss: -7.3572	Cost: 9.26s
Train Epoch: 593 [61440/90000 (68%)]	Loss: -7.5746	Cost: 9.13s
Train Epoch: 593 [81920/90000 (91%)]	Loss: -7.1501	Cost: 8.79s
Train Epoch: 593 	Average Loss: -7.1552
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2810

Learning rate: 0.00019826969482077218
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 594 [0/90000 (0%)]	Loss: -3.3711	Cost: 24.07s
Train Epoch: 594 [20480/90000 (23%)]	Loss: -7.5686	Cost: 9.39s
Train Epoch: 594 [40960/90000 (45%)]	Loss: -6.9812	Cost: 9.23s
Train Epoch: 594 [61440/90000 (68%)]	Loss: -7.2372	Cost: 9.14s
Train Epoch: 594 [81920/90000 (91%)]	Loss: -7.0297	Cost: 8.85s
Train Epoch: 594 	Average Loss: -7.0924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3289

Learning rate: 0.00019826387109152545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 595 [0/90000 (0%)]	Loss: -2.9143	Cost: 24.61s
Train Epoch: 595 [20480/90000 (23%)]	Loss: -7.5335	Cost: 9.21s
Train Epoch: 595 [40960/90000 (45%)]	Loss: -7.5194	Cost: 9.29s
Train Epoch: 595 [61440/90000 (68%)]	Loss: -7.3567	Cost: 9.05s
Train Epoch: 595 [81920/90000 (91%)]	Loss: -7.1833	Cost: 8.81s
Train Epoch: 595 	Average Loss: -7.1820
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4372

Learning rate: 0.00019825803766402344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 596 [0/90000 (0%)]	Loss: -3.3988	Cost: 24.01s
Train Epoch: 596 [20480/90000 (23%)]	Loss: -7.6335	Cost: 9.29s
Train Epoch: 596 [40960/90000 (45%)]	Loss: -7.2967	Cost: 9.32s
Train Epoch: 596 [61440/90000 (68%)]	Loss: -7.4049	Cost: 9.00s
Train Epoch: 596 [81920/90000 (91%)]	Loss: -7.1457	Cost: 8.88s
Train Epoch: 596 	Average Loss: -7.1706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4618

Learning rate: 0.00019825219453884193
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 597 [0/90000 (0%)]	Loss: -3.1818	Cost: 23.77s
Train Epoch: 597 [20480/90000 (23%)]	Loss: -7.5302	Cost: 9.40s
Train Epoch: 597 [40960/90000 (45%)]	Loss: -6.2604	Cost: 9.30s
Train Epoch: 597 [61440/90000 (68%)]	Loss: -6.5615	Cost: 9.10s
Train Epoch: 597 [81920/90000 (91%)]	Loss: -6.6412	Cost: 9.03s
Train Epoch: 597 	Average Loss: -6.5992
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0553

Learning rate: 0.00019824634171655754
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 598 [0/90000 (0%)]	Loss: -2.7033	Cost: 23.94s
Train Epoch: 598 [20480/90000 (23%)]	Loss: -7.1471	Cost: 9.53s
Train Epoch: 598 [40960/90000 (45%)]	Loss: -7.0592	Cost: 9.27s
Train Epoch: 598 [61440/90000 (68%)]	Loss: -7.2034	Cost: 9.16s
Train Epoch: 598 [81920/90000 (91%)]	Loss: -7.0296	Cost: 9.01s
Train Epoch: 598 	Average Loss: -6.9275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4136

Learning rate: 0.000198240479197748
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 599 [0/90000 (0%)]	Loss: -3.4280	Cost: 23.98s
Train Epoch: 599 [20480/90000 (23%)]	Loss: -7.7453	Cost: 9.35s
Train Epoch: 599 [40960/90000 (45%)]	Loss: -7.3655	Cost: 9.34s
Train Epoch: 599 [61440/90000 (68%)]	Loss: -7.2074	Cost: 9.07s
Train Epoch: 599 [81920/90000 (91%)]	Loss: -7.1494	Cost: 9.11s
Train Epoch: 599 	Average Loss: -7.1828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3188

Learning rate: 0.00019823460698299188
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 600 [0/90000 (0%)]	Loss: -3.1969	Cost: 23.80s
Train Epoch: 600 [20480/90000 (23%)]	Loss: -7.6170	Cost: 9.40s
Train Epoch: 600 [40960/90000 (45%)]	Loss: -7.4055	Cost: 9.28s
Train Epoch: 600 [61440/90000 (68%)]	Loss: -7.6656	Cost: 9.10s
Train Epoch: 600 [81920/90000 (91%)]	Loss: -7.0103	Cost: 9.12s
Train Epoch: 600 	Average Loss: -7.1546
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1169

Saving model as model.pt_e600 & waveforms_supplementary.hdf5_e600
Learning rate: 0.00019822872507286872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 601 [0/90000 (0%)]	Loss: -3.4018	Cost: 27.15s
Train Epoch: 601 [20480/90000 (23%)]	Loss: -7.5194	Cost: 9.32s
Train Epoch: 601 [40960/90000 (45%)]	Loss: -7.2430	Cost: 9.27s
Train Epoch: 601 [61440/90000 (68%)]	Loss: -7.3738	Cost: 9.08s
Train Epoch: 601 [81920/90000 (91%)]	Loss: -6.8496	Cost: 8.83s
Train Epoch: 601 	Average Loss: -7.0954
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7219

Learning rate: 0.00019822283346795905
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 602 [0/90000 (0%)]	Loss: -2.7295	Cost: 24.93s
Train Epoch: 602 [20480/90000 (23%)]	Loss: -6.8731	Cost: 9.30s
Train Epoch: 602 [40960/90000 (45%)]	Loss: -6.5295	Cost: 9.31s
Train Epoch: 602 [61440/90000 (68%)]	Loss: -6.4801	Cost: 9.15s
Train Epoch: 602 [81920/90000 (91%)]	Loss: -6.8285	Cost: 9.02s
Train Epoch: 602 	Average Loss: -6.6287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1049

Learning rate: 0.0001982169321688444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 603 [0/90000 (0%)]	Loss: -2.5007	Cost: 24.58s
Train Epoch: 603 [20480/90000 (23%)]	Loss: -7.4076	Cost: 9.67s
Train Epoch: 603 [40960/90000 (45%)]	Loss: -7.3081	Cost: 9.26s
Train Epoch: 603 [61440/90000 (68%)]	Loss: -7.3911	Cost: 9.21s
Train Epoch: 603 [81920/90000 (91%)]	Loss: -7.2140	Cost: 8.91s
Train Epoch: 603 	Average Loss: -7.0877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3405

Learning rate: 0.00019821102117610715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 604 [0/90000 (0%)]	Loss: -2.9590	Cost: 24.48s
Train Epoch: 604 [20480/90000 (23%)]	Loss: -7.6374	Cost: 9.43s
Train Epoch: 604 [40960/90000 (45%)]	Loss: -7.2709	Cost: 9.31s
Train Epoch: 604 [61440/90000 (68%)]	Loss: -7.4775	Cost: 9.13s
Train Epoch: 604 [81920/90000 (91%)]	Loss: -7.2493	Cost: 9.31s
Train Epoch: 604 	Average Loss: -7.2472
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4261

Learning rate: 0.00019820510049033073
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 605 [0/90000 (0%)]	Loss: -3.3686	Cost: 24.18s
Train Epoch: 605 [20480/90000 (23%)]	Loss: -7.6346	Cost: 9.35s
Train Epoch: 605 [40960/90000 (45%)]	Loss: -7.6650	Cost: 9.46s
Train Epoch: 605 [61440/90000 (68%)]	Loss: -7.6617	Cost: 9.10s
Train Epoch: 605 [81920/90000 (91%)]	Loss: -7.3121	Cost: 9.01s
Train Epoch: 605 	Average Loss: -7.3804
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5372

Learning rate: 0.0001981991701120995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 606 [0/90000 (0%)]	Loss: -3.0735	Cost: 24.53s
Train Epoch: 606 [20480/90000 (23%)]	Loss: -7.6299	Cost: 9.41s
Train Epoch: 606 [40960/90000 (45%)]	Loss: -6.6722	Cost: 9.35s
Train Epoch: 606 [61440/90000 (68%)]	Loss: -6.7184	Cost: 9.07s
Train Epoch: 606 [81920/90000 (91%)]	Loss: -7.0004	Cost: 9.05s
Train Epoch: 606 	Average Loss: -6.8544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2259

Learning rate: 0.00019819323004199868
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 607 [0/90000 (0%)]	Loss: -3.3348	Cost: 24.81s
Train Epoch: 607 [20480/90000 (23%)]	Loss: -7.5424	Cost: 9.48s
Train Epoch: 607 [40960/90000 (45%)]	Loss: -7.3834	Cost: 9.25s
Train Epoch: 607 [61440/90000 (68%)]	Loss: -7.4649	Cost: 9.22s
Train Epoch: 607 [81920/90000 (91%)]	Loss: -7.2220	Cost: 9.01s
Train Epoch: 607 	Average Loss: -7.2340
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5311

Learning rate: 0.0001981872802806146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 608 [0/90000 (0%)]	Loss: -3.7251	Cost: 23.92s
Train Epoch: 608 [20480/90000 (23%)]	Loss: -7.6802	Cost: 9.43s
Train Epoch: 608 [40960/90000 (45%)]	Loss: -7.4797	Cost: 9.24s
Train Epoch: 608 [61440/90000 (68%)]	Loss: -7.5756	Cost: 8.94s
Train Epoch: 608 [81920/90000 (91%)]	Loss: -7.3939	Cost: 9.08s
Train Epoch: 608 	Average Loss: -7.3725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6502

Learning rate: 0.0001981813208285345
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 609 [0/90000 (0%)]	Loss: -3.6072	Cost: 24.37s
Train Epoch: 609 [20480/90000 (23%)]	Loss: -7.9023	Cost: 9.39s
Train Epoch: 609 [40960/90000 (45%)]	Loss: -7.3420	Cost: 9.30s
Train Epoch: 609 [61440/90000 (68%)]	Loss: -7.0157	Cost: 9.07s
Train Epoch: 609 [81920/90000 (91%)]	Loss: -6.0510	Cost: 8.94s
Train Epoch: 609 	Average Loss: -7.0078
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6095

Learning rate: 0.00019817535168634647
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 610 [0/90000 (0%)]	Loss: -2.1661	Cost: 23.85s
Train Epoch: 610 [20480/90000 (23%)]	Loss: -7.0039	Cost: 9.12s
Train Epoch: 610 [40960/90000 (45%)]	Loss: -6.9848	Cost: 9.05s
Train Epoch: 610 [61440/90000 (68%)]	Loss: -7.1261	Cost: 8.92s
Train Epoch: 610 [81920/90000 (91%)]	Loss: -7.0514	Cost: 8.65s
Train Epoch: 610 	Average Loss: -6.8036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3813

Learning rate: 0.0001981693728546397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 611 [0/90000 (0%)]	Loss: -3.2004	Cost: 24.51s
Train Epoch: 611 [20480/90000 (23%)]	Loss: -7.4821	Cost: 9.07s
Train Epoch: 611 [40960/90000 (45%)]	Loss: -7.3916	Cost: 9.73s
Train Epoch: 611 [61440/90000 (68%)]	Loss: -7.4367	Cost: 9.00s
Train Epoch: 611 [81920/90000 (91%)]	Loss: -7.2995	Cost: 9.23s
Train Epoch: 611 	Average Loss: -7.2226
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5564

Learning rate: 0.00019816338433400427
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 612 [0/90000 (0%)]	Loss: -3.4185	Cost: 23.22s
Train Epoch: 612 [20480/90000 (23%)]	Loss: -7.7397	Cost: 9.10s
Train Epoch: 612 [40960/90000 (45%)]	Loss: -7.3823	Cost: 9.15s
Train Epoch: 612 [61440/90000 (68%)]	Loss: -7.2507	Cost: 9.09s
Train Epoch: 612 [81920/90000 (91%)]	Loss: -7.2442	Cost: 9.69s
Train Epoch: 612 	Average Loss: -7.2871
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1842

Learning rate: 0.00019815738612503125
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 613 [0/90000 (0%)]	Loss: -3.3638	Cost: 22.53s
Train Epoch: 613 [20480/90000 (23%)]	Loss: -7.3869	Cost: 9.20s
Train Epoch: 613 [40960/90000 (45%)]	Loss: -7.2718	Cost: 9.05s
Train Epoch: 613 [61440/90000 (68%)]	Loss: -7.3972	Cost: 9.03s
Train Epoch: 613 [81920/90000 (91%)]	Loss: -7.1841	Cost: 9.81s
Train Epoch: 613 	Average Loss: -7.0792
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3987

Learning rate: 0.00019815137822831258
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 614 [0/90000 (0%)]	Loss: -3.0359	Cost: 23.75s
Train Epoch: 614 [20480/90000 (23%)]	Loss: -7.4230	Cost: 9.29s
Train Epoch: 614 [40960/90000 (45%)]	Loss: -7.3130	Cost: 9.20s
Train Epoch: 614 [61440/90000 (68%)]	Loss: -7.5588	Cost: 9.15s
Train Epoch: 614 [81920/90000 (91%)]	Loss: -7.4472	Cost: 9.24s
Train Epoch: 614 	Average Loss: -7.2593
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6383

Learning rate: 0.00019814536064444125
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 615 [0/90000 (0%)]	Loss: -3.4302	Cost: 22.11s
Train Epoch: 615 [20480/90000 (23%)]	Loss: -8.0500	Cost: 9.36s
Train Epoch: 615 [40960/90000 (45%)]	Loss: -7.8563	Cost: 9.33s
Train Epoch: 615 [61440/90000 (68%)]	Loss: -7.6719	Cost: 9.41s
Train Epoch: 615 [81920/90000 (91%)]	Loss: -7.4520	Cost: 9.22s
Train Epoch: 615 	Average Loss: -7.5468
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5329

Learning rate: 0.00019813933337401116
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 616 [0/90000 (0%)]	Loss: -3.8195	Cost: 22.50s
Train Epoch: 616 [20480/90000 (23%)]	Loss: -7.8356	Cost: 9.41s
Train Epoch: 616 [40960/90000 (45%)]	Loss: -7.8346	Cost: 9.25s
Train Epoch: 616 [61440/90000 (68%)]	Loss: -7.8445	Cost: 9.24s
Train Epoch: 616 [81920/90000 (91%)]	Loss: -7.6546	Cost: 9.08s
Train Epoch: 616 	Average Loss: -7.5692
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7525

Learning rate: 0.0001981332964176172
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 617 [0/90000 (0%)]	Loss: -3.8664	Cost: 22.61s
Train Epoch: 617 [20480/90000 (23%)]	Loss: -8.1253	Cost: 9.37s
Train Epoch: 617 [40960/90000 (45%)]	Loss: -7.8637	Cost: 9.24s
Train Epoch: 617 [61440/90000 (68%)]	Loss: -7.6299	Cost: 9.06s
Train Epoch: 617 [81920/90000 (91%)]	Loss: -7.3328	Cost: 9.44s
Train Epoch: 617 	Average Loss: -7.5903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5741

Learning rate: 0.00019812724977585515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 618 [0/90000 (0%)]	Loss: -3.4089	Cost: 23.51s
Train Epoch: 618 [20480/90000 (23%)]	Loss: -8.0441	Cost: 9.41s
Train Epoch: 618 [40960/90000 (45%)]	Loss: -7.8998	Cost: 9.49s
Train Epoch: 618 [61440/90000 (68%)]	Loss: -7.8384	Cost: 9.28s
Train Epoch: 618 [81920/90000 (91%)]	Loss: -7.7189	Cost: 9.24s
Train Epoch: 618 	Average Loss: -7.5831
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8043

Learning rate: 0.00019812119344932182
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 619 [0/90000 (0%)]	Loss: -3.8868	Cost: 25.06s
Train Epoch: 619 [20480/90000 (23%)]	Loss: -8.0802	Cost: 9.27s
Train Epoch: 619 [40960/90000 (45%)]	Loss: -7.6773	Cost: 9.26s
Train Epoch: 619 [61440/90000 (68%)]	Loss: -7.8617	Cost: 9.19s
Train Epoch: 619 [81920/90000 (91%)]	Loss: -7.5508	Cost: 9.44s
Train Epoch: 619 	Average Loss: -7.5957
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6063

Learning rate: 0.00019811512743861495
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 620 [0/90000 (0%)]	Loss: -3.4481	Cost: 24.02s
Train Epoch: 620 [20480/90000 (23%)]	Loss: -8.0385	Cost: 9.35s
Train Epoch: 620 [40960/90000 (45%)]	Loss: -7.4310	Cost: 9.32s
Train Epoch: 620 [61440/90000 (68%)]	Loss: -7.5414	Cost: 9.03s
Train Epoch: 620 [81920/90000 (91%)]	Loss: -7.5473	Cost: 9.02s
Train Epoch: 620 	Average Loss: -7.4417
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6969

Learning rate: 0.00019810905174433323
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 621 [0/90000 (0%)]	Loss: -3.7685	Cost: 24.73s
Train Epoch: 621 [20480/90000 (23%)]	Loss: -7.9417	Cost: 9.40s
Train Epoch: 621 [40960/90000 (45%)]	Loss: -7.4932	Cost: 9.26s
Train Epoch: 621 [61440/90000 (68%)]	Loss: -7.6293	Cost: 9.18s
Train Epoch: 621 [81920/90000 (91%)]	Loss: -7.4610	Cost: 9.17s
Train Epoch: 621 	Average Loss: -7.4570
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6535

Learning rate: 0.0001981029663670763
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 622 [0/90000 (0%)]	Loss: -3.2588	Cost: 24.08s
Train Epoch: 622 [20480/90000 (23%)]	Loss: -8.0836	Cost: 9.31s
Train Epoch: 622 [40960/90000 (45%)]	Loss: -7.6934	Cost: 9.33s
Train Epoch: 622 [61440/90000 (68%)]	Loss: -7.8148	Cost: 9.26s
Train Epoch: 622 [81920/90000 (91%)]	Loss: -7.5475	Cost: 9.09s
Train Epoch: 622 	Average Loss: -7.6621
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8039

Learning rate: 0.00019809687130744477
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 623 [0/90000 (0%)]	Loss: -3.9103	Cost: 24.00s
Train Epoch: 623 [20480/90000 (23%)]	Loss: -8.1203	Cost: 9.38s
Train Epoch: 623 [40960/90000 (45%)]	Loss: -7.9640	Cost: 9.26s
Train Epoch: 623 [61440/90000 (68%)]	Loss: -8.2490	Cost: 9.09s
Train Epoch: 623 [81920/90000 (91%)]	Loss: -7.9576	Cost: 9.03s
Train Epoch: 623 	Average Loss: -7.8554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9041

Learning rate: 0.00019809076656604016
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 624 [0/90000 (0%)]	Loss: -3.4890	Cost: 23.28s
Train Epoch: 624 [20480/90000 (23%)]	Loss: -8.3192	Cost: 9.34s
Train Epoch: 624 [40960/90000 (45%)]	Loss: -8.1477	Cost: 9.26s
Train Epoch: 624 [61440/90000 (68%)]	Loss: -8.0924	Cost: 9.03s
Train Epoch: 624 [81920/90000 (91%)]	Loss: -7.8140	Cost: 8.68s
Train Epoch: 624 	Average Loss: -7.8464
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8873

Learning rate: 0.00019808465214346508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 625 [0/90000 (0%)]	Loss: -4.0157	Cost: 25.19s
Train Epoch: 625 [20480/90000 (23%)]	Loss: -8.3553	Cost: 9.33s
Train Epoch: 625 [40960/90000 (45%)]	Loss: -7.7422	Cost: 9.34s
Train Epoch: 625 [61440/90000 (68%)]	Loss: -7.6490	Cost: 9.11s
Train Epoch: 625 [81920/90000 (91%)]	Loss: -7.4366	Cost: 8.98s
Train Epoch: 625 	Average Loss: -7.6027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3851

Learning rate: 0.00019807852804032286
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 626 [0/90000 (0%)]	Loss: -3.2598	Cost: 24.26s
Train Epoch: 626 [20480/90000 (23%)]	Loss: -8.0882	Cost: 9.34s
Train Epoch: 626 [40960/90000 (45%)]	Loss: -7.7721	Cost: 9.34s
Train Epoch: 626 [61440/90000 (68%)]	Loss: -8.0095	Cost: 9.08s
Train Epoch: 626 [81920/90000 (91%)]	Loss: -7.9669	Cost: 8.79s
Train Epoch: 626 	Average Loss: -7.7526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9389

Learning rate: 0.00019807239425721806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 627 [0/90000 (0%)]	Loss: -3.9662	Cost: 26.40s
Train Epoch: 627 [20480/90000 (23%)]	Loss: -8.1561	Cost: 9.28s
Train Epoch: 627 [40960/90000 (45%)]	Loss: -7.8529	Cost: 9.34s
Train Epoch: 627 [61440/90000 (68%)]	Loss: -7.9510	Cost: 9.16s
Train Epoch: 627 [81920/90000 (91%)]	Loss: -7.7644	Cost: 8.91s
Train Epoch: 627 	Average Loss: -7.8247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8801

Learning rate: 0.00019806625079475595
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 628 [0/90000 (0%)]	Loss: -3.9608	Cost: 24.02s
Train Epoch: 628 [20480/90000 (23%)]	Loss: -8.3035	Cost: 9.41s
Train Epoch: 628 [40960/90000 (45%)]	Loss: -7.9309	Cost: 9.32s
Train Epoch: 628 [61440/90000 (68%)]	Loss: -7.7122	Cost: 9.11s
Train Epoch: 628 [81920/90000 (91%)]	Loss: -6.8363	Cost: 9.04s
Train Epoch: 628 	Average Loss: -7.6506
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0976

Learning rate: 0.00019806009765354292
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 629 [0/90000 (0%)]	Loss: -2.6833	Cost: 33.07s
Train Epoch: 629 [20480/90000 (23%)]	Loss: -7.5367	Cost: 10.68s
Train Epoch: 629 [40960/90000 (45%)]	Loss: -7.4669	Cost: 9.60s
Train Epoch: 629 [61440/90000 (68%)]	Loss: -7.7089	Cost: 9.15s
Train Epoch: 629 [81920/90000 (91%)]	Loss: -7.8788	Cost: 9.32s
Train Epoch: 629 	Average Loss: -7.3298
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7875

Learning rate: 0.00019805393483418628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 630 [0/90000 (0%)]	Loss: -3.5686	Cost: 44.09s
Train Epoch: 630 [20480/90000 (23%)]	Loss: -8.4069	Cost: 9.24s
Train Epoch: 630 [40960/90000 (45%)]	Loss: -8.3336	Cost: 9.15s
Train Epoch: 630 [61440/90000 (68%)]	Loss: -8.2999	Cost: 9.25s
Train Epoch: 630 [81920/90000 (91%)]	Loss: -7.8630	Cost: 8.84s
Train Epoch: 630 	Average Loss: -8.0003
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0083

Learning rate: 0.00019804776233729425
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 631 [0/90000 (0%)]	Loss: -4.2909	Cost: 24.12s
Train Epoch: 631 [20480/90000 (23%)]	Loss: -8.4347	Cost: 9.32s
Train Epoch: 631 [40960/90000 (45%)]	Loss: -8.0362	Cost: 9.33s
Train Epoch: 631 [61440/90000 (68%)]	Loss: -7.9529	Cost: 9.23s
Train Epoch: 631 [81920/90000 (91%)]	Loss: -7.9481	Cost: 9.07s
Train Epoch: 631 	Average Loss: -7.9913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8853

Learning rate: 0.00019804158016347603
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 632 [0/90000 (0%)]	Loss: -4.2659	Cost: 23.70s
Train Epoch: 632 [20480/90000 (23%)]	Loss: -8.4467	Cost: 9.59s
Train Epoch: 632 [40960/90000 (45%)]	Loss: -8.2923	Cost: 9.31s
Train Epoch: 632 [61440/90000 (68%)]	Loss: -8.2629	Cost: 9.15s
Train Epoch: 632 [81920/90000 (91%)]	Loss: -7.9666	Cost: 8.99s
Train Epoch: 632 	Average Loss: -8.0511
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1513

Learning rate: 0.0001980353883133418
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 633 [0/90000 (0%)]	Loss: -3.8787	Cost: 23.84s
Train Epoch: 633 [20480/90000 (23%)]	Loss: -8.4992	Cost: 9.46s
Train Epoch: 633 [40960/90000 (45%)]	Loss: -8.3882	Cost: 9.27s
Train Epoch: 633 [61440/90000 (68%)]	Loss: -8.3436	Cost: 9.19s
Train Epoch: 633 [81920/90000 (91%)]	Loss: -7.9203	Cost: 9.11s
Train Epoch: 633 	Average Loss: -8.0827
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0371

Learning rate: 0.0001980291867875026
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 634 [0/90000 (0%)]	Loss: -3.7787	Cost: 23.83s
Train Epoch: 634 [20480/90000 (23%)]	Loss: -8.7203	Cost: 9.47s
Train Epoch: 634 [40960/90000 (45%)]	Loss: -8.2558	Cost: 9.22s
Train Epoch: 634 [61440/90000 (68%)]	Loss: -8.3732	Cost: 9.14s
Train Epoch: 634 [81920/90000 (91%)]	Loss: -8.1124	Cost: 9.01s
Train Epoch: 634 	Average Loss: -8.1173
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1150

Learning rate: 0.00019802297558657058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 635 [0/90000 (0%)]	Loss: -3.8310	Cost: 25.65s
Train Epoch: 635 [20480/90000 (23%)]	Loss: -8.6967	Cost: 9.45s
Train Epoch: 635 [40960/90000 (45%)]	Loss: -8.3867	Cost: 9.40s
Train Epoch: 635 [61440/90000 (68%)]	Loss: -8.3459	Cost: 9.56s
Train Epoch: 635 [81920/90000 (91%)]	Loss: -8.1602	Cost: 9.27s
Train Epoch: 635 	Average Loss: -8.2236
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1118

Learning rate: 0.00019801675471115872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 636 [0/90000 (0%)]	Loss: -3.8586	Cost: 24.84s
Train Epoch: 636 [20480/90000 (23%)]	Loss: -8.4738	Cost: 9.35s
Train Epoch: 636 [40960/90000 (45%)]	Loss: -8.0817	Cost: 9.42s
Train Epoch: 636 [61440/90000 (68%)]	Loss: -8.2539	Cost: 8.98s
Train Epoch: 636 [81920/90000 (91%)]	Loss: -8.1617	Cost: 8.95s
Train Epoch: 636 	Average Loss: -8.0779
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0444

Learning rate: 0.000198010524161881
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 637 [0/90000 (0%)]	Loss: -4.0425	Cost: 23.96s
Train Epoch: 637 [20480/90000 (23%)]	Loss: -8.5557	Cost: 9.61s
Train Epoch: 637 [40960/90000 (45%)]	Loss: -8.2616	Cost: 9.34s
Train Epoch: 637 [61440/90000 (68%)]	Loss: -7.7626	Cost: 8.98s
Train Epoch: 637 [81920/90000 (91%)]	Loss: -7.6078	Cost: 9.06s
Train Epoch: 637 	Average Loss: -7.8634
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8753

Learning rate: 0.00019800428393935233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 638 [0/90000 (0%)]	Loss: -3.3644	Cost: 23.67s
Train Epoch: 638 [20480/90000 (23%)]	Loss: -8.1623	Cost: 9.31s
Train Epoch: 638 [40960/90000 (45%)]	Loss: -7.9964	Cost: 9.14s
Train Epoch: 638 [61440/90000 (68%)]	Loss: -7.8902	Cost: 8.90s
Train Epoch: 638 [81920/90000 (91%)]	Loss: -7.7963	Cost: 8.63s
Train Epoch: 638 	Average Loss: -7.8019
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8989

Learning rate: 0.00019799803404418868
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 639 [0/90000 (0%)]	Loss: -3.6699	Cost: 23.90s
Train Epoch: 639 [20480/90000 (23%)]	Loss: -8.2020	Cost: 9.07s
Train Epoch: 639 [40960/90000 (45%)]	Loss: -8.1323	Cost: 9.07s
Train Epoch: 639 [61440/90000 (68%)]	Loss: -8.2412	Cost: 8.96s
Train Epoch: 639 [81920/90000 (91%)]	Loss: -8.1299	Cost: 8.64s
Train Epoch: 639 	Average Loss: -8.0606
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1487

Learning rate: 0.00019799177447700676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 640 [0/90000 (0%)]	Loss: -3.9128	Cost: 23.67s
Train Epoch: 640 [20480/90000 (23%)]	Loss: -8.6090	Cost: 9.02s
Train Epoch: 640 [40960/90000 (45%)]	Loss: -8.1905	Cost: 9.36s
Train Epoch: 640 [61440/90000 (68%)]	Loss: -8.2682	Cost: 9.02s
Train Epoch: 640 [81920/90000 (91%)]	Loss: -8.2301	Cost: 9.10s
Train Epoch: 640 	Average Loss: -8.0860
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1353

Learning rate: 0.00019798550523842447
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 641 [0/90000 (0%)]	Loss: -4.1428	Cost: 22.70s
Train Epoch: 641 [20480/90000 (23%)]	Loss: -8.6270	Cost: 9.10s
Train Epoch: 641 [40960/90000 (45%)]	Loss: -8.4531	Cost: 9.39s
Train Epoch: 641 [61440/90000 (68%)]	Loss: -8.4938	Cost: 9.13s
Train Epoch: 641 [81920/90000 (91%)]	Loss: -8.4970	Cost: 9.83s
Train Epoch: 641 	Average Loss: -8.4135
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3656

Learning rate: 0.0001979792263290605
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 642 [0/90000 (0%)]	Loss: -4.4319	Cost: 22.91s
Train Epoch: 642 [20480/90000 (23%)]	Loss: -8.7143	Cost: 9.28s
Train Epoch: 642 [40960/90000 (45%)]	Loss: -8.5042	Cost: 9.06s
Train Epoch: 642 [61440/90000 (68%)]	Loss: -8.5845	Cost: 9.03s
Train Epoch: 642 [81920/90000 (91%)]	Loss: -8.2356	Cost: 9.13s
Train Epoch: 642 	Average Loss: -8.3272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1888

Learning rate: 0.00019797293774953458
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 643 [0/90000 (0%)]	Loss: -4.2595	Cost: 23.72s
Train Epoch: 643 [20480/90000 (23%)]	Loss: -8.8725	Cost: 9.14s
Train Epoch: 643 [40960/90000 (45%)]	Loss: -8.7418	Cost: 9.04s
Train Epoch: 643 [61440/90000 (68%)]	Loss: -8.4174	Cost: 9.08s
Train Epoch: 643 [81920/90000 (91%)]	Loss: -8.2212	Cost: 9.75s
Train Epoch: 643 	Average Loss: -8.3494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2117

Learning rate: 0.00019796663950046741
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 644 [0/90000 (0%)]	Loss: -3.9270	Cost: 21.76s
Train Epoch: 644 [20480/90000 (23%)]	Loss: -8.5826	Cost: 9.23s
Train Epoch: 644 [40960/90000 (45%)]	Loss: -8.1827	Cost: 9.42s
Train Epoch: 644 [61440/90000 (68%)]	Loss: -8.0042	Cost: 9.18s
Train Epoch: 644 [81920/90000 (91%)]	Loss: -7.9779	Cost: 9.05s
Train Epoch: 644 	Average Loss: -8.0818
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1109

Learning rate: 0.0001979603315824805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 645 [0/90000 (0%)]	Loss: -4.2007	Cost: 22.82s
Train Epoch: 645 [20480/90000 (23%)]	Loss: -8.6258	Cost: 9.37s
Train Epoch: 645 [40960/90000 (45%)]	Loss: -8.4193	Cost: 9.34s
Train Epoch: 645 [61440/90000 (68%)]	Loss: -8.4497	Cost: 8.99s
Train Epoch: 645 [81920/90000 (91%)]	Loss: -8.3048	Cost: 9.09s
Train Epoch: 645 	Average Loss: -8.2433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2961

Learning rate: 0.0001979540139961965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 646 [0/90000 (0%)]	Loss: -4.4835	Cost: 23.10s
Train Epoch: 646 [20480/90000 (23%)]	Loss: -9.0485	Cost: 9.58s
Train Epoch: 646 [40960/90000 (45%)]	Loss: -8.6657	Cost: 9.32s
Train Epoch: 646 [61440/90000 (68%)]	Loss: -8.6009	Cost: 9.21s
Train Epoch: 646 [81920/90000 (91%)]	Loss: -8.2935	Cost: 9.14s
Train Epoch: 646 	Average Loss: -8.3950
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3757

Learning rate: 0.0001979476867422389
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 647 [0/90000 (0%)]	Loss: -4.0330	Cost: 24.10s
Train Epoch: 647 [20480/90000 (23%)]	Loss: -8.4547	Cost: 9.40s
Train Epoch: 647 [40960/90000 (45%)]	Loss: -8.1185	Cost: 9.30s
Train Epoch: 647 [61440/90000 (68%)]	Loss: -8.4579	Cost: 9.10s
Train Epoch: 647 [81920/90000 (91%)]	Loss: -8.1149	Cost: 8.94s
Train Epoch: 647 	Average Loss: -8.1888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1809

Learning rate: 0.00019794134982123216
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 648 [0/90000 (0%)]	Loss: -3.8299	Cost: 24.63s
Train Epoch: 648 [20480/90000 (23%)]	Loss: -8.6129	Cost: 9.33s
Train Epoch: 648 [40960/90000 (45%)]	Loss: -8.3112	Cost: 9.32s
Train Epoch: 648 [61440/90000 (68%)]	Loss: -8.4756	Cost: 9.31s
Train Epoch: 648 [81920/90000 (91%)]	Loss: -8.4971	Cost: 9.03s
Train Epoch: 648 	Average Loss: -8.2593
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4415

Learning rate: 0.00019793500323380173
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 649 [0/90000 (0%)]	Loss: -4.2874	Cost: 24.08s
Train Epoch: 649 [20480/90000 (23%)]	Loss: -8.8838	Cost: 9.35s
Train Epoch: 649 [40960/90000 (45%)]	Loss: -8.6664	Cost: 9.25s
Train Epoch: 649 [61440/90000 (68%)]	Loss: -8.7653	Cost: 9.15s
Train Epoch: 649 [81920/90000 (91%)]	Loss: -8.4768	Cost: 8.96s
Train Epoch: 649 	Average Loss: -8.5140
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4213

Learning rate: 0.000197928646980574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 650 [0/90000 (0%)]	Loss: -4.0072	Cost: 25.03s
Train Epoch: 650 [20480/90000 (23%)]	Loss: -9.0755	Cost: 9.26s
Train Epoch: 650 [40960/90000 (45%)]	Loss: -8.6344	Cost: 9.71s
Train Epoch: 650 [61440/90000 (68%)]	Loss: -8.7078	Cost: 9.01s
Train Epoch: 650 [81920/90000 (91%)]	Loss: -8.6156	Cost: 8.78s
Train Epoch: 650 	Average Loss: -8.5047
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4568

Saving model as model.pt_e650 & waveforms_supplementary.hdf5_e650
Learning rate: 0.00019792228106217628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 651 [0/90000 (0%)]	Loss: -3.9784	Cost: 23.18s
Train Epoch: 651 [20480/90000 (23%)]	Loss: -8.9912	Cost: 9.48s
Train Epoch: 651 [40960/90000 (45%)]	Loss: -7.2763	Cost: 9.29s
Train Epoch: 651 [61440/90000 (68%)]	Loss: -7.7249	Cost: 8.94s
Train Epoch: 651 [81920/90000 (91%)]	Loss: -7.5788	Cost: 9.07s
Train Epoch: 651 	Average Loss: -7.7455
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7198

Learning rate: 0.00019791590547923692
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 652 [0/90000 (0%)]	Loss: -3.8781	Cost: 23.47s
Train Epoch: 652 [20480/90000 (23%)]	Loss: -8.4448	Cost: 9.33s
Train Epoch: 652 [40960/90000 (45%)]	Loss: -8.3440	Cost: 9.86s
Train Epoch: 652 [61440/90000 (68%)]	Loss: -8.5293	Cost: 9.08s
Train Epoch: 652 [81920/90000 (91%)]	Loss: -8.0744	Cost: 8.98s
Train Epoch: 652 	Average Loss: -8.1328
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1769

Learning rate: 0.00019790952023238508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 653 [0/90000 (0%)]	Loss: -3.9454	Cost: 24.51s
Train Epoch: 653 [20480/90000 (23%)]	Loss: -8.7782	Cost: 9.33s
Train Epoch: 653 [40960/90000 (45%)]	Loss: -8.4768	Cost: 9.28s
Train Epoch: 653 [61440/90000 (68%)]	Loss: -8.7322	Cost: 9.40s
Train Epoch: 653 [81920/90000 (91%)]	Loss: -8.4595	Cost: 8.91s
Train Epoch: 653 	Average Loss: -8.4109
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4291

Learning rate: 0.000197903125322251
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 654 [0/90000 (0%)]	Loss: -4.0851	Cost: 23.81s
Train Epoch: 654 [20480/90000 (23%)]	Loss: -8.9958	Cost: 9.41s
Train Epoch: 654 [40960/90000 (45%)]	Loss: -8.7937	Cost: 9.21s
Train Epoch: 654 [61440/90000 (68%)]	Loss: -8.5831	Cost: 9.11s
Train Epoch: 654 [81920/90000 (91%)]	Loss: -8.5825	Cost: 8.83s
Train Epoch: 654 	Average Loss: -8.5245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1746

Learning rate: 0.00019789672074946586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 655 [0/90000 (0%)]	Loss: -4.2327	Cost: 24.64s
Train Epoch: 655 [20480/90000 (23%)]	Loss: -8.7060	Cost: 9.35s
Train Epoch: 655 [40960/90000 (45%)]	Loss: -8.5150	Cost: 9.25s
Train Epoch: 655 [61440/90000 (68%)]	Loss: -8.7408	Cost: 9.14s
Train Epoch: 655 [81920/90000 (91%)]	Loss: -8.5206	Cost: 8.90s
Train Epoch: 655 	Average Loss: -8.4233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4723

Learning rate: 0.00019789030651466173
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 656 [0/90000 (0%)]	Loss: -4.0848	Cost: 23.89s
Train Epoch: 656 [20480/90000 (23%)]	Loss: -9.1824	Cost: 9.37s
Train Epoch: 656 [40960/90000 (45%)]	Loss: -8.8354	Cost: 9.32s
Train Epoch: 656 [61440/90000 (68%)]	Loss: -8.8606	Cost: 9.12s
Train Epoch: 656 [81920/90000 (91%)]	Loss: -8.7072	Cost: 8.89s
Train Epoch: 656 	Average Loss: -8.6000
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5984

Learning rate: 0.0001978838826184717
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 657 [0/90000 (0%)]	Loss: -4.4718	Cost: 23.62s
Train Epoch: 657 [20480/90000 (23%)]	Loss: -9.1132	Cost: 9.38s
Train Epoch: 657 [40960/90000 (45%)]	Loss: -8.8979	Cost: 9.23s
Train Epoch: 657 [61440/90000 (68%)]	Loss: -8.8760	Cost: 9.15s
Train Epoch: 657 [81920/90000 (91%)]	Loss: -8.7208	Cost: 9.14s
Train Epoch: 657 	Average Loss: -8.6712
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6265

Learning rate: 0.00019787744906152977
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 658 [0/90000 (0%)]	Loss: -4.2079	Cost: 25.12s
Train Epoch: 658 [20480/90000 (23%)]	Loss: -8.8910	Cost: 9.29s
Train Epoch: 658 [40960/90000 (45%)]	Loss: -8.6944	Cost: 9.32s
Train Epoch: 658 [61440/90000 (68%)]	Loss: -8.7376	Cost: 9.08s
Train Epoch: 658 [81920/90000 (91%)]	Loss: -8.5395	Cost: 8.90s
Train Epoch: 658 	Average Loss: -8.4885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2163

Learning rate: 0.00019787100584447087
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 659 [0/90000 (0%)]	Loss: -3.6131	Cost: 24.08s
Train Epoch: 659 [20480/90000 (23%)]	Loss: -8.9825	Cost: 9.32s
Train Epoch: 659 [40960/90000 (45%)]	Loss: -8.7158	Cost: 9.30s
Train Epoch: 659 [61440/90000 (68%)]	Loss: -9.0251	Cost: 9.20s
Train Epoch: 659 [81920/90000 (91%)]	Loss: -8.7015	Cost: 9.08s
Train Epoch: 659 	Average Loss: -8.5605
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7061

Learning rate: 0.00019786455296793095
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 660 [0/90000 (0%)]	Loss: -4.6768	Cost: 24.58s
Train Epoch: 660 [20480/90000 (23%)]	Loss: -9.3792	Cost: 9.32s
Train Epoch: 660 [40960/90000 (45%)]	Loss: -8.8559	Cost: 9.39s
Train Epoch: 660 [61440/90000 (68%)]	Loss: -8.9999	Cost: 9.08s
Train Epoch: 660 [81920/90000 (91%)]	Loss: -8.7512	Cost: 8.99s
Train Epoch: 660 	Average Loss: -8.7855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6307

Learning rate: 0.0001978580904325469
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 661 [0/90000 (0%)]	Loss: -4.9061	Cost: 24.53s
Train Epoch: 661 [20480/90000 (23%)]	Loss: -9.2210	Cost: 9.42s
Train Epoch: 661 [40960/90000 (45%)]	Loss: -9.0865	Cost: 9.30s
Train Epoch: 661 [61440/90000 (68%)]	Loss: -8.8807	Cost: 9.16s
Train Epoch: 661 [81920/90000 (91%)]	Loss: -9.0556	Cost: 9.39s
Train Epoch: 661 	Average Loss: -8.8323
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7191

Learning rate: 0.00019785161823895653
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 662 [0/90000 (0%)]	Loss: -4.6786	Cost: 23.77s
Train Epoch: 662 [20480/90000 (23%)]	Loss: -9.2405	Cost: 9.37s
Train Epoch: 662 [40960/90000 (45%)]	Loss: -9.0727	Cost: 9.28s
Train Epoch: 662 [61440/90000 (68%)]	Loss: -9.1977	Cost: 9.05s
Train Epoch: 662 [81920/90000 (91%)]	Loss: -8.8708	Cost: 9.06s
Train Epoch: 662 	Average Loss: -8.8529
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7298

Learning rate: 0.00019784513638779864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 663 [0/90000 (0%)]	Loss: -4.6809	Cost: 24.11s
Train Epoch: 663 [20480/90000 (23%)]	Loss: -9.4002	Cost: 9.87s
Train Epoch: 663 [40960/90000 (45%)]	Loss: -8.1742	Cost: 9.27s
Train Epoch: 663 [61440/90000 (68%)]	Loss: -8.0329	Cost: 8.98s
Train Epoch: 663 [81920/90000 (91%)]	Loss: -8.0855	Cost: 9.21s
Train Epoch: 663 	Average Loss: -8.2604
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1349

Learning rate: 0.0001978386448797129
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 664 [0/90000 (0%)]	Loss: -4.3643	Cost: 25.13s
Train Epoch: 664 [20480/90000 (23%)]	Loss: -8.9316	Cost: 9.84s
Train Epoch: 664 [40960/90000 (45%)]	Loss: -8.6256	Cost: 9.17s
Train Epoch: 664 [61440/90000 (68%)]	Loss: -8.8383	Cost: 9.12s
Train Epoch: 664 [81920/90000 (91%)]	Loss: -8.7700	Cost: 8.70s
Train Epoch: 664 	Average Loss: -8.5478
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5396

Learning rate: 0.00019783214371534008
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 665 [0/90000 (0%)]	Loss: -4.7545	Cost: 24.41s
Train Epoch: 665 [20480/90000 (23%)]	Loss: -9.1408	Cost: 9.04s
Train Epoch: 665 [40960/90000 (45%)]	Loss: -8.7825	Cost: 9.04s
Train Epoch: 665 [61440/90000 (68%)]	Loss: -8.7250	Cost: 9.04s
Train Epoch: 665 [81920/90000 (91%)]	Loss: -8.7521	Cost: 8.81s
Train Epoch: 665 	Average Loss: -8.6845
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4767

Learning rate: 0.00019782563289532173
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 666 [0/90000 (0%)]	Loss: -4.3649	Cost: 23.95s
Train Epoch: 666 [20480/90000 (23%)]	Loss: -9.2823	Cost: 8.99s
Train Epoch: 666 [40960/90000 (45%)]	Loss: -9.0889	Cost: 9.49s
Train Epoch: 666 [61440/90000 (68%)]	Loss: -8.9026	Cost: 8.97s
Train Epoch: 666 [81920/90000 (91%)]	Loss: -8.3996	Cost: 9.01s
Train Epoch: 666 	Average Loss: -8.7163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0505

Learning rate: 0.0001978191124203005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 667 [0/90000 (0%)]	Loss: -4.0015	Cost: 23.04s
Train Epoch: 667 [20480/90000 (23%)]	Loss: -8.7075	Cost: 9.12s
Train Epoch: 667 [40960/90000 (45%)]	Loss: -8.5108	Cost: 9.43s
Train Epoch: 667 [61440/90000 (68%)]	Loss: -8.6123	Cost: 9.09s
Train Epoch: 667 [81920/90000 (91%)]	Loss: -8.3419	Cost: 9.77s
Train Epoch: 667 	Average Loss: -8.2878
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3653

Learning rate: 0.00019781258229091995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 668 [0/90000 (0%)]	Loss: -4.4379	Cost: 23.41s
Train Epoch: 668 [20480/90000 (23%)]	Loss: -9.1543	Cost: 9.08s
Train Epoch: 668 [40960/90000 (45%)]	Loss: -8.9975	Cost: 9.32s
Train Epoch: 668 [61440/90000 (68%)]	Loss: -8.9441	Cost: 9.10s
Train Epoch: 668 [81920/90000 (91%)]	Loss: -8.9734	Cost: 9.64s
Train Epoch: 668 	Average Loss: -8.7653
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7279

Learning rate: 0.00019780604250782451
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 669 [0/90000 (0%)]	Loss: -4.9098	Cost: 24.12s
Train Epoch: 669 [20480/90000 (23%)]	Loss: -9.1873	Cost: 9.19s
Train Epoch: 669 [40960/90000 (45%)]	Loss: -8.9603	Cost: 9.10s
Train Epoch: 669 [61440/90000 (68%)]	Loss: -8.9248	Cost: 9.09s
Train Epoch: 669 [81920/90000 (91%)]	Loss: -8.7515	Cost: 9.61s
Train Epoch: 669 	Average Loss: -8.8304
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6446

Learning rate: 0.00019779949307165972
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 670 [0/90000 (0%)]	Loss: -4.4673	Cost: 23.55s
Train Epoch: 670 [20480/90000 (23%)]	Loss: -9.4080	Cost: 9.18s
Train Epoch: 670 [40960/90000 (45%)]	Loss: -9.3219	Cost: 9.35s
Train Epoch: 670 [61440/90000 (68%)]	Loss: -9.0847	Cost: 9.09s
Train Epoch: 670 [81920/90000 (91%)]	Loss: -8.8532	Cost: 9.04s
Train Epoch: 670 	Average Loss: -8.9591
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6022

Learning rate: 0.00019779293398307192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 671 [0/90000 (0%)]	Loss: -4.5187	Cost: 22.05s
Train Epoch: 671 [20480/90000 (23%)]	Loss: -9.5325	Cost: 9.44s
Train Epoch: 671 [40960/90000 (45%)]	Loss: -9.3840	Cost: 9.27s
Train Epoch: 671 [61440/90000 (68%)]	Loss: -9.3544	Cost: 9.47s
Train Epoch: 671 [81920/90000 (91%)]	Loss: -8.9409	Cost: 9.09s
Train Epoch: 671 	Average Loss: -9.0438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8233

Learning rate: 0.00019778636524270848
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 672 [0/90000 (0%)]	Loss: -4.7908	Cost: 22.67s
Train Epoch: 672 [20480/90000 (23%)]	Loss: -9.4830	Cost: 9.31s
Train Epoch: 672 [40960/90000 (45%)]	Loss: -9.2436	Cost: 9.37s
Train Epoch: 672 [61440/90000 (68%)]	Loss: -9.1541	Cost: 9.19s
Train Epoch: 672 [81920/90000 (91%)]	Loss: -8.7313	Cost: 9.41s
Train Epoch: 672 	Average Loss: -8.9347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6010

Learning rate: 0.0001977797868512177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 673 [0/90000 (0%)]	Loss: -4.0101	Cost: 23.12s
Train Epoch: 673 [20480/90000 (23%)]	Loss: -9.1695	Cost: 9.27s
Train Epoch: 673 [40960/90000 (45%)]	Loss: -9.0247	Cost: 9.23s
Train Epoch: 673 [61440/90000 (68%)]	Loss: -8.9906	Cost: 9.28s
Train Epoch: 673 [81920/90000 (91%)]	Loss: -8.9048	Cost: 9.07s
Train Epoch: 673 	Average Loss: -8.8490
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8717

Learning rate: 0.00019777319880924887
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 674 [0/90000 (0%)]	Loss: -5.0599	Cost: 23.93s
Train Epoch: 674 [20480/90000 (23%)]	Loss: -9.5762	Cost: 9.33s
Train Epoch: 674 [40960/90000 (45%)]	Loss: -9.1921	Cost: 9.35s
Train Epoch: 674 [61440/90000 (68%)]	Loss: -9.0598	Cost: 9.04s
Train Epoch: 674 [81920/90000 (91%)]	Loss: -8.9170	Cost: 9.14s
Train Epoch: 674 	Average Loss: -8.9855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5609

Learning rate: 0.0001977666011174522
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 675 [0/90000 (0%)]	Loss: -4.7347	Cost: 23.87s
Train Epoch: 675 [20480/90000 (23%)]	Loss: -9.1754	Cost: 9.37s
Train Epoch: 675 [40960/90000 (45%)]	Loss: -8.7771	Cost: 9.15s
Train Epoch: 675 [61440/90000 (68%)]	Loss: -9.1177	Cost: 9.24s
Train Epoch: 675 [81920/90000 (91%)]	Loss: -9.0190	Cost: 8.91s
Train Epoch: 675 	Average Loss: -8.8941
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5617

Learning rate: 0.00019775999377647882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 676 [0/90000 (0%)]	Loss: -4.4169	Cost: 24.02s
Train Epoch: 676 [20480/90000 (23%)]	Loss: -9.2354	Cost: 9.42s
Train Epoch: 676 [40960/90000 (45%)]	Loss: -8.7970	Cost: 9.25s
Train Epoch: 676 [61440/90000 (68%)]	Loss: -9.1738	Cost: 9.16s
Train Epoch: 676 [81920/90000 (91%)]	Loss: -8.8982	Cost: 8.74s
Train Epoch: 676 	Average Loss: -8.7533
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6554

Learning rate: 0.00019775337678698088
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 677 [0/90000 (0%)]	Loss: -4.5765	Cost: 24.89s
Train Epoch: 677 [20480/90000 (23%)]	Loss: -9.4486	Cost: 9.42s
Train Epoch: 677 [40960/90000 (45%)]	Loss: -9.0716	Cost: 9.29s
Train Epoch: 677 [61440/90000 (68%)]	Loss: -9.3264	Cost: 9.30s
Train Epoch: 677 [81920/90000 (91%)]	Loss: -9.1383	Cost: 8.75s
Train Epoch: 677 	Average Loss: -9.0266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8771

Learning rate: 0.00019774675014961146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 678 [0/90000 (0%)]	Loss: -4.3654	Cost: 24.09s
Train Epoch: 678 [20480/90000 (23%)]	Loss: -9.5265	Cost: 9.39s
Train Epoch: 678 [40960/90000 (45%)]	Loss: -9.2033	Cost: 9.25s
Train Epoch: 678 [61440/90000 (68%)]	Loss: -9.5109	Cost: 9.13s
Train Epoch: 678 [81920/90000 (91%)]	Loss: -9.0630	Cost: 8.92s
Train Epoch: 678 	Average Loss: -9.1291
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8329

Learning rate: 0.00019774011386502452
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 679 [0/90000 (0%)]	Loss: -4.8935	Cost: 24.56s
Train Epoch: 679 [20480/90000 (23%)]	Loss: -9.3770	Cost: 9.44s
Train Epoch: 679 [40960/90000 (45%)]	Loss: -9.3572	Cost: 9.27s
Train Epoch: 679 [61440/90000 (68%)]	Loss: -9.3618	Cost: 9.30s
Train Epoch: 679 [81920/90000 (91%)]	Loss: -9.1903	Cost: 8.79s
Train Epoch: 679 	Average Loss: -9.0394
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7795

Learning rate: 0.0001977334679338751
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 680 [0/90000 (0%)]	Loss: -4.5242	Cost: 25.98s
Train Epoch: 680 [20480/90000 (23%)]	Loss: -9.4582	Cost: 9.54s
Train Epoch: 680 [40960/90000 (45%)]	Loss: -9.4117	Cost: 9.44s
Train Epoch: 680 [61440/90000 (68%)]	Loss: -9.2561	Cost: 9.21s
Train Epoch: 680 [81920/90000 (91%)]	Loss: -8.8539	Cost: 8.93s
Train Epoch: 680 	Average Loss: -9.0356
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6675

Learning rate: 0.0001977268123568191
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 681 [0/90000 (0%)]	Loss: -4.9074	Cost: 24.05s
Train Epoch: 681 [20480/90000 (23%)]	Loss: -9.3576	Cost: 9.54s
Train Epoch: 681 [40960/90000 (45%)]	Loss: -9.1935	Cost: 9.23s
Train Epoch: 681 [61440/90000 (68%)]	Loss: -8.9270	Cost: 9.29s
Train Epoch: 681 [81920/90000 (91%)]	Loss: -8.6205	Cost: 9.01s
Train Epoch: 681 	Average Loss: -8.8302
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5370

Learning rate: 0.00019772014713451342
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 682 [0/90000 (0%)]	Loss: -4.4986	Cost: 24.56s
Train Epoch: 682 [20480/90000 (23%)]	Loss: -9.2687	Cost: 9.40s
Train Epoch: 682 [40960/90000 (45%)]	Loss: -9.1022	Cost: 9.27s
Train Epoch: 682 [61440/90000 (68%)]	Loss: -9.2683	Cost: 8.95s
Train Epoch: 682 [81920/90000 (91%)]	Loss: -9.0560	Cost: 9.08s
Train Epoch: 682 	Average Loss: -8.9371
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8029

Learning rate: 0.00019771347226761588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 683 [0/90000 (0%)]	Loss: -5.0983	Cost: 24.76s
Train Epoch: 683 [20480/90000 (23%)]	Loss: -9.5705	Cost: 9.38s
Train Epoch: 683 [40960/90000 (45%)]	Loss: -9.4153	Cost: 9.34s
Train Epoch: 683 [61440/90000 (68%)]	Loss: -9.3438	Cost: 9.36s
Train Epoch: 683 [81920/90000 (91%)]	Loss: -9.1666	Cost: 8.85s
Train Epoch: 683 	Average Loss: -9.0668
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7432

Learning rate: 0.00019770678775678525
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 684 [0/90000 (0%)]	Loss: -4.8013	Cost: 23.95s
Train Epoch: 684 [20480/90000 (23%)]	Loss: -9.4958	Cost: 9.14s
Train Epoch: 684 [40960/90000 (45%)]	Loss: -9.4728	Cost: 9.22s
Train Epoch: 684 [61440/90000 (68%)]	Loss: -9.4874	Cost: 9.10s
Train Epoch: 684 [81920/90000 (91%)]	Loss: -9.0378	Cost: 8.68s
Train Epoch: 684 	Average Loss: -9.1334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7930

Learning rate: 0.00019770009360268128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 685 [0/90000 (0%)]	Loss: -4.5400	Cost: 24.77s
Train Epoch: 685 [20480/90000 (23%)]	Loss: -9.5244	Cost: 9.09s
Train Epoch: 685 [40960/90000 (45%)]	Loss: -9.3386	Cost: 9.31s
Train Epoch: 685 [61440/90000 (68%)]	Loss: -9.3900	Cost: 9.14s
Train Epoch: 685 [81920/90000 (91%)]	Loss: -9.1868	Cost: 8.65s
Train Epoch: 685 	Average Loss: -9.1383
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9458

Learning rate: 0.00019769338980596464
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 686 [0/90000 (0%)]	Loss: -5.0226	Cost: 23.09s
Train Epoch: 686 [20480/90000 (23%)]	Loss: -9.9079	Cost: 9.08s
Train Epoch: 686 [40960/90000 (45%)]	Loss: -9.5404	Cost: 9.45s
Train Epoch: 686 [61440/90000 (68%)]	Loss: -9.4585	Cost: 9.11s
Train Epoch: 686 [81920/90000 (91%)]	Loss: -9.1713	Cost: 9.47s
Train Epoch: 686 	Average Loss: -9.2707
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8224

Learning rate: 0.00019768667636729697
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 687 [0/90000 (0%)]	Loss: -4.6988	Cost: 23.10s
Train Epoch: 687 [20480/90000 (23%)]	Loss: -9.6834	Cost: 9.05s
Train Epoch: 687 [40960/90000 (45%)]	Loss: -9.3138	Cost: 9.43s
Train Epoch: 687 [61440/90000 (68%)]	Loss: -9.5351	Cost: 9.24s
Train Epoch: 687 [81920/90000 (91%)]	Loss: -9.1734	Cost: 9.47s
Train Epoch: 687 	Average Loss: -9.2472
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9731

Learning rate: 0.0001976799532873409
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 688 [0/90000 (0%)]	Loss: -4.3939	Cost: 24.44s
Train Epoch: 688 [20480/90000 (23%)]	Loss: -9.9937	Cost: 9.31s
Train Epoch: 688 [40960/90000 (45%)]	Loss: -9.5883	Cost: 9.09s
Train Epoch: 688 [61440/90000 (68%)]	Loss: -9.5002	Cost: 9.07s
Train Epoch: 688 [81920/90000 (91%)]	Loss: -9.2556	Cost: 9.80s
Train Epoch: 688 	Average Loss: -9.2496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7932

Learning rate: 0.00019767322056675991
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 689 [0/90000 (0%)]	Loss: -4.3814	Cost: 24.03s
Train Epoch: 689 [20480/90000 (23%)]	Loss: -9.6885	Cost: 9.32s
Train Epoch: 689 [40960/90000 (45%)]	Loss: -9.1346	Cost: 9.45s
Train Epoch: 689 [61440/90000 (68%)]	Loss: -9.1327	Cost: 9.32s
Train Epoch: 689 [81920/90000 (91%)]	Loss: -8.6004	Cost: 9.15s
Train Epoch: 689 	Average Loss: -8.9033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7039

Learning rate: 0.00019766647820621853
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 690 [0/90000 (0%)]	Loss: -4.1811	Cost: 23.27s
Train Epoch: 690 [20480/90000 (23%)]	Loss: -9.8326	Cost: 9.52s
Train Epoch: 690 [40960/90000 (45%)]	Loss: -9.5353	Cost: 9.54s
Train Epoch: 690 [61440/90000 (68%)]	Loss: -9.4837	Cost: 9.23s
Train Epoch: 690 [81920/90000 (91%)]	Loss: -9.4523	Cost: 9.13s
Train Epoch: 690 	Average Loss: -9.2174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0683

Learning rate: 0.0001976597262063822
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 691 [0/90000 (0%)]	Loss: -5.1733	Cost: 22.85s
Train Epoch: 691 [20480/90000 (23%)]	Loss: -9.9986	Cost: 9.32s
Train Epoch: 691 [40960/90000 (45%)]	Loss: -9.6537	Cost: 9.27s
Train Epoch: 691 [61440/90000 (68%)]	Loss: -9.4175	Cost: 9.43s
Train Epoch: 691 [81920/90000 (91%)]	Loss: -9.3795	Cost: 9.16s
Train Epoch: 691 	Average Loss: -9.3842
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9111

Learning rate: 0.00019765296456791733
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 692 [0/90000 (0%)]	Loss: -4.7204	Cost: 22.72s
Train Epoch: 692 [20480/90000 (23%)]	Loss: -9.7212	Cost: 9.36s
Train Epoch: 692 [40960/90000 (45%)]	Loss: -9.4495	Cost: 9.75s
Train Epoch: 692 [61440/90000 (68%)]	Loss: -9.6452	Cost: 9.14s
Train Epoch: 692 [81920/90000 (91%)]	Loss: -9.4240	Cost: 9.22s
Train Epoch: 692 	Average Loss: -9.3483
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1725

Learning rate: 0.00019764619329149126
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 693 [0/90000 (0%)]	Loss: -4.8542	Cost: 22.72s
Train Epoch: 693 [20480/90000 (23%)]	Loss: -9.8894	Cost: 9.39s
Train Epoch: 693 [40960/90000 (45%)]	Loss: -9.5376	Cost: 9.27s
Train Epoch: 693 [61440/90000 (68%)]	Loss: -9.0200	Cost: 9.22s
Train Epoch: 693 [81920/90000 (91%)]	Loss: -8.9684	Cost: 9.08s
Train Epoch: 693 	Average Loss: -9.1027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8307

Learning rate: 0.00019763941237777225
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 694 [0/90000 (0%)]	Loss: -4.4904	Cost: 23.84s
Train Epoch: 694 [20480/90000 (23%)]	Loss: -9.8744	Cost: 9.37s
Train Epoch: 694 [40960/90000 (45%)]	Loss: -9.6499	Cost: 9.32s
Train Epoch: 694 [61440/90000 (68%)]	Loss: -9.5994	Cost: 9.03s
Train Epoch: 694 [81920/90000 (91%)]	Loss: -9.3428	Cost: 8.99s
Train Epoch: 694 	Average Loss: -9.3275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0619

Learning rate: 0.0001976326218274296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 695 [0/90000 (0%)]	Loss: -4.8523	Cost: 23.49s
Train Epoch: 695 [20480/90000 (23%)]	Loss: -9.8492	Cost: 9.43s
Train Epoch: 695 [40960/90000 (45%)]	Loss: -9.6918	Cost: 9.30s
Train Epoch: 695 [61440/90000 (68%)]	Loss: -9.7583	Cost: 9.30s
Train Epoch: 695 [81920/90000 (91%)]	Loss: -9.0968	Cost: 8.92s
Train Epoch: 695 	Average Loss: -9.3892
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8758

Learning rate: 0.00019762582164113346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 696 [0/90000 (0%)]	Loss: -4.6395	Cost: 23.86s
Train Epoch: 696 [20480/90000 (23%)]	Loss: -9.7643	Cost: 9.34s
Train Epoch: 696 [40960/90000 (45%)]	Loss: -9.4888	Cost: 9.23s
Train Epoch: 696 [61440/90000 (68%)]	Loss: -9.5107	Cost: 9.10s
Train Epoch: 696 [81920/90000 (91%)]	Loss: -9.4190	Cost: 8.76s
Train Epoch: 696 	Average Loss: -9.3018
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1138

Learning rate: 0.00019761901181955505
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 697 [0/90000 (0%)]	Loss: -5.4912	Cost: 25.52s
Train Epoch: 697 [20480/90000 (23%)]	Loss: -9.8077	Cost: 9.26s
Train Epoch: 697 [40960/90000 (45%)]	Loss: -9.6848	Cost: 9.55s
Train Epoch: 697 [61440/90000 (68%)]	Loss: -9.7548	Cost: 9.45s
Train Epoch: 697 [81920/90000 (91%)]	Loss: -9.6238	Cost: 8.75s
Train Epoch: 697 	Average Loss: -9.4797
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1907

Learning rate: 0.0001976121923633664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 698 [0/90000 (0%)]	Loss: -5.5058	Cost: 23.43s
Train Epoch: 698 [20480/90000 (23%)]	Loss: -9.8312	Cost: 9.34s
Train Epoch: 698 [40960/90000 (45%)]	Loss: -9.7016	Cost: 9.48s
Train Epoch: 698 [61440/90000 (68%)]	Loss: -9.7224	Cost: 9.51s
Train Epoch: 698 [81920/90000 (91%)]	Loss: -9.3418	Cost: 8.87s
Train Epoch: 698 	Average Loss: -9.4489
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1635

Learning rate: 0.0001976053632732406
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 699 [0/90000 (0%)]	Loss: -5.0034	Cost: 26.01s
Train Epoch: 699 [20480/90000 (23%)]	Loss: -10.0289	Cost: 9.30s
Train Epoch: 699 [40960/90000 (45%)]	Loss: -9.7325	Cost: 9.26s
Train Epoch: 699 [61440/90000 (68%)]	Loss: -9.5614	Cost: 9.27s
Train Epoch: 699 [81920/90000 (91%)]	Loss: -9.4932	Cost: 8.81s
Train Epoch: 699 	Average Loss: -9.4766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1374

Learning rate: 0.00019759852454985166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 700 [0/90000 (0%)]	Loss: -5.5399	Cost: 24.27s
Train Epoch: 700 [20480/90000 (23%)]	Loss: -10.1517	Cost: 9.32s
Train Epoch: 700 [40960/90000 (45%)]	Loss: -9.8515	Cost: 9.34s
Train Epoch: 700 [61440/90000 (68%)]	Loss: -9.9679	Cost: 9.13s
Train Epoch: 700 [81920/90000 (91%)]	Loss: -9.5896	Cost: 8.79s
Train Epoch: 700 	Average Loss: -9.6471
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3441

Saving model as model.pt_e700 & waveforms_supplementary.hdf5_e700
Learning rate: 0.0001975916761938745
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 701 [0/90000 (0%)]	Loss: -5.4988	Cost: 24.34s
Train Epoch: 701 [20480/90000 (23%)]	Loss: -10.0831	Cost: 9.26s
Train Epoch: 701 [40960/90000 (45%)]	Loss: -9.5816	Cost: 9.25s
Train Epoch: 701 [61440/90000 (68%)]	Loss: -9.6705	Cost: 9.02s
Train Epoch: 701 [81920/90000 (91%)]	Loss: -9.3966	Cost: 8.72s
Train Epoch: 701 	Average Loss: -9.5379
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0818

Learning rate: 0.00019758481820598506
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 702 [0/90000 (0%)]	Loss: -4.5459	Cost: 23.85s
Train Epoch: 702 [20480/90000 (23%)]	Loss: -9.9780	Cost: 9.34s
Train Epoch: 702 [40960/90000 (45%)]	Loss: -9.7370	Cost: 9.43s
Train Epoch: 702 [61440/90000 (68%)]	Loss: -9.6751	Cost: 9.38s
Train Epoch: 702 [81920/90000 (91%)]	Loss: -9.4338	Cost: 8.65s
Train Epoch: 702 	Average Loss: -9.4557
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0567

Learning rate: 0.0001975779505868602
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 703 [0/90000 (0%)]	Loss: -5.2271	Cost: 24.33s
Train Epoch: 703 [20480/90000 (23%)]	Loss: -10.0860	Cost: 9.35s
Train Epoch: 703 [40960/90000 (45%)]	Loss: -9.6674	Cost: 9.28s
Train Epoch: 703 [61440/90000 (68%)]	Loss: -9.9413	Cost: 9.14s
Train Epoch: 703 [81920/90000 (91%)]	Loss: -9.4415	Cost: 8.78s
Train Epoch: 703 	Average Loss: -9.5469
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2049

Learning rate: 0.0001975710733371777
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 704 [0/90000 (0%)]	Loss: -5.6364	Cost: 24.35s
Train Epoch: 704 [20480/90000 (23%)]	Loss: -9.9719	Cost: 9.35s
Train Epoch: 704 [40960/90000 (45%)]	Loss: -9.9854	Cost: 9.32s
Train Epoch: 704 [61440/90000 (68%)]	Loss: -10.0766	Cost: 9.21s
Train Epoch: 704 [81920/90000 (91%)]	Loss: -9.5963	Cost: 9.02s
Train Epoch: 704 	Average Loss: -9.6504
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2805

Learning rate: 0.00019756418645761634
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 705 [0/90000 (0%)]	Loss: -4.9131	Cost: 25.18s
Train Epoch: 705 [20480/90000 (23%)]	Loss: -10.0626	Cost: 9.62s
Train Epoch: 705 [40960/90000 (45%)]	Loss: -9.6114	Cost: 9.22s
Train Epoch: 705 [61440/90000 (68%)]	Loss: -9.7661	Cost: 9.12s
Train Epoch: 705 [81920/90000 (91%)]	Loss: -9.2923	Cost: 9.02s
Train Epoch: 705 	Average Loss: -9.4809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9855

Learning rate: 0.0001975572899488558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 706 [0/90000 (0%)]	Loss: -4.8489	Cost: 25.87s
Train Epoch: 706 [20480/90000 (23%)]	Loss: -10.0316	Cost: 9.35s
Train Epoch: 706 [40960/90000 (45%)]	Loss: -9.9077	Cost: 9.36s
Train Epoch: 706 [61440/90000 (68%)]	Loss: -9.9424	Cost: 9.16s
Train Epoch: 706 [81920/90000 (91%)]	Loss: -9.6095	Cost: 8.92s
Train Epoch: 706 	Average Loss: -9.5865
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2830

Learning rate: 0.0001975503838115768
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 707 [0/90000 (0%)]	Loss: -5.1120	Cost: 26.92s
Train Epoch: 707 [20480/90000 (23%)]	Loss: -10.2439	Cost: 9.34s
Train Epoch: 707 [40960/90000 (45%)]	Loss: -10.0713	Cost: 9.85s
Train Epoch: 707 [61440/90000 (68%)]	Loss: -10.1342	Cost: 9.12s
Train Epoch: 707 [81920/90000 (91%)]	Loss: -9.9395	Cost: 8.70s
Train Epoch: 707 	Average Loss: -9.7909
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4408

Learning rate: 0.00019754346804646088
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 708 [0/90000 (0%)]	Loss: -5.2136	Cost: 25.87s
Train Epoch: 708 [20480/90000 (23%)]	Loss: -10.2811	Cost: 9.36s
Train Epoch: 708 [40960/90000 (45%)]	Loss: -9.9812	Cost: 9.26s
Train Epoch: 708 [61440/90000 (68%)]	Loss: -9.9026	Cost: 9.17s
Train Epoch: 708 [81920/90000 (91%)]	Loss: -9.7765	Cost: 8.72s
Train Epoch: 708 	Average Loss: -9.8212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2369

Learning rate: 0.00019753654265419063
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 709 [0/90000 (0%)]	Loss: -4.9939	Cost: 24.64s
Train Epoch: 709 [20480/90000 (23%)]	Loss: -10.4311	Cost: 9.38s
Train Epoch: 709 [40960/90000 (45%)]	Loss: -9.9041	Cost: 9.44s
Train Epoch: 709 [61440/90000 (68%)]	Loss: -9.9632	Cost: 9.07s
Train Epoch: 709 [81920/90000 (91%)]	Loss: -9.8133	Cost: 8.88s
Train Epoch: 709 	Average Loss: -9.7836
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5825

Learning rate: 0.00019752960763544955
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 710 [0/90000 (0%)]	Loss: -5.4916	Cost: 24.24s
Train Epoch: 710 [20480/90000 (23%)]	Loss: -10.4675	Cost: 9.35s
Train Epoch: 710 [40960/90000 (45%)]	Loss: -10.0584	Cost: 9.25s
Train Epoch: 710 [61440/90000 (68%)]	Loss: -10.1600	Cost: 9.25s
Train Epoch: 710 [81920/90000 (91%)]	Loss: -9.7596	Cost: 8.86s
Train Epoch: 710 	Average Loss: -9.9018
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3700

Learning rate: 0.0001975226629909221
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 711 [0/90000 (0%)]	Loss: -5.4930	Cost: 24.70s
Train Epoch: 711 [20480/90000 (23%)]	Loss: -10.1528	Cost: 9.39s
Train Epoch: 711 [40960/90000 (45%)]	Loss: -9.1822	Cost: 9.35s
Train Epoch: 711 [61440/90000 (68%)]	Loss: -9.3255	Cost: 9.25s
Train Epoch: 711 [81920/90000 (91%)]	Loss: -9.5516	Cost: 8.79s
Train Epoch: 711 	Average Loss: -9.4158
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0868

Learning rate: 0.00019751570872129367
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 712 [0/90000 (0%)]	Loss: -5.4061	Cost: 26.29s
Train Epoch: 712 [20480/90000 (23%)]	Loss: -10.0278	Cost: 9.34s
Train Epoch: 712 [40960/90000 (45%)]	Loss: -9.8893	Cost: 9.36s
Train Epoch: 712 [61440/90000 (68%)]	Loss: -9.9960	Cost: 9.16s
Train Epoch: 712 [81920/90000 (91%)]	Loss: -9.7534	Cost: 8.78s
Train Epoch: 712 	Average Loss: -9.7339
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3662

Learning rate: 0.00019750874482725065
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 713 [0/90000 (0%)]	Loss: -5.3685	Cost: 24.38s
Train Epoch: 713 [20480/90000 (23%)]	Loss: -10.2533	Cost: 9.40s
Train Epoch: 713 [40960/90000 (45%)]	Loss: -10.2753	Cost: 9.36s
Train Epoch: 713 [61440/90000 (68%)]	Loss: -10.1235	Cost: 9.33s
Train Epoch: 713 [81920/90000 (91%)]	Loss: -9.7280	Cost: 8.94s
Train Epoch: 713 	Average Loss: -9.8159
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2703

Learning rate: 0.00019750177130948036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 714 [0/90000 (0%)]	Loss: -5.1225	Cost: 24.14s
Train Epoch: 714 [20480/90000 (23%)]	Loss: -10.2312	Cost: 9.31s
Train Epoch: 714 [40960/90000 (45%)]	Loss: -10.0029	Cost: 9.38s
Train Epoch: 714 [61440/90000 (68%)]	Loss: -10.1870	Cost: 9.25s
Train Epoch: 714 [81920/90000 (91%)]	Loss: -10.0526	Cost: 9.03s
Train Epoch: 714 	Average Loss: -9.8400
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4385

Learning rate: 0.00019749478816867102
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 715 [0/90000 (0%)]	Loss: -5.7618	Cost: 26.32s
Train Epoch: 715 [20480/90000 (23%)]	Loss: -10.5888	Cost: 9.30s
Train Epoch: 715 [40960/90000 (45%)]	Loss: -10.2262	Cost: 9.43s
Train Epoch: 715 [61440/90000 (68%)]	Loss: -10.1253	Cost: 9.60s
Train Epoch: 715 [81920/90000 (91%)]	Loss: -9.8826	Cost: 8.88s
Train Epoch: 715 	Average Loss: -9.9499
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5508

Learning rate: 0.0001974877954055119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 716 [0/90000 (0%)]	Loss: -5.3177	Cost: 23.92s
Train Epoch: 716 [20480/90000 (23%)]	Loss: -10.5406	Cost: 9.37s
Train Epoch: 716 [40960/90000 (45%)]	Loss: -10.4354	Cost: 9.29s
Train Epoch: 716 [61440/90000 (68%)]	Loss: -10.4746	Cost: 9.15s
Train Epoch: 716 [81920/90000 (91%)]	Loss: -10.0539	Cost: 8.92s
Train Epoch: 716 	Average Loss: -10.1010
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5699

Learning rate: 0.00019748079302069307
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 717 [0/90000 (0%)]	Loss: -5.4146	Cost: 24.00s
Train Epoch: 717 [20480/90000 (23%)]	Loss: -10.7735	Cost: 9.40s
Train Epoch: 717 [40960/90000 (45%)]	Loss: -10.3044	Cost: 9.24s
Train Epoch: 717 [61440/90000 (68%)]	Loss: -10.3166	Cost: 9.39s
Train Epoch: 717 [81920/90000 (91%)]	Loss: -9.7562	Cost: 8.95s
Train Epoch: 717 	Average Loss: -10.0822
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4113

Learning rate: 0.00019747378101490567
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 718 [0/90000 (0%)]	Loss: -4.9666	Cost: 24.18s
Train Epoch: 718 [20480/90000 (23%)]	Loss: -10.5920	Cost: 9.40s
Train Epoch: 718 [40960/90000 (45%)]	Loss: -10.3215	Cost: 9.20s
Train Epoch: 718 [61440/90000 (68%)]	Loss: -10.2734	Cost: 9.11s
Train Epoch: 718 [81920/90000 (91%)]	Loss: -9.9848	Cost: 9.07s
Train Epoch: 718 	Average Loss: -9.9918
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5270

Learning rate: 0.00019746675938884178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 719 [0/90000 (0%)]	Loss: -5.5724	Cost: 23.98s
Train Epoch: 719 [20480/90000 (23%)]	Loss: -10.3357	Cost: 9.51s
Train Epoch: 719 [40960/90000 (45%)]	Loss: -10.3388	Cost: 9.25s
Train Epoch: 719 [61440/90000 (68%)]	Loss: -10.3918	Cost: 9.26s
Train Epoch: 719 [81920/90000 (91%)]	Loss: -10.0899	Cost: 8.99s
Train Epoch: 719 	Average Loss: -10.0281
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4675

Learning rate: 0.0001974597281431944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 720 [0/90000 (0%)]	Loss: -5.0523	Cost: 24.02s
Train Epoch: 720 [20480/90000 (23%)]	Loss: -10.6826	Cost: 9.37s
Train Epoch: 720 [40960/90000 (45%)]	Loss: -10.3272	Cost: 9.25s
Train Epoch: 720 [61440/90000 (68%)]	Loss: -10.2016	Cost: 9.00s
Train Epoch: 720 [81920/90000 (91%)]	Loss: -10.0782	Cost: 9.08s
Train Epoch: 720 	Average Loss: -10.1219
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5678

Learning rate: 0.0001974526872786575
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 721 [0/90000 (0%)]	Loss: -5.6687	Cost: 24.22s
Train Epoch: 721 [20480/90000 (23%)]	Loss: -10.6584	Cost: 9.40s
Train Epoch: 721 [40960/90000 (45%)]	Loss: -10.1116	Cost: 9.37s
Train Epoch: 721 [61440/90000 (68%)]	Loss: -9.6876	Cost: 9.01s
Train Epoch: 721 [81920/90000 (91%)]	Loss: -9.5005	Cost: 8.93s
Train Epoch: 721 	Average Loss: -9.7975
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0847

Learning rate: 0.00019744563679592594
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 722 [0/90000 (0%)]	Loss: -4.8856	Cost: 24.20s
Train Epoch: 722 [20480/90000 (23%)]	Loss: -10.1256	Cost: 9.07s
Train Epoch: 722 [40960/90000 (45%)]	Loss: -10.0925	Cost: 9.24s
Train Epoch: 722 [61440/90000 (68%)]	Loss: -10.0393	Cost: 9.02s
Train Epoch: 722 [81920/90000 (91%)]	Loss: -9.8184	Cost: 8.82s
Train Epoch: 722 	Average Loss: -9.7454
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3946

Learning rate: 0.0001974385766956956
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 723 [0/90000 (0%)]	Loss: -5.2325	Cost: 24.08s
Train Epoch: 723 [20480/90000 (23%)]	Loss: -10.2784	Cost: 9.04s
Train Epoch: 723 [40960/90000 (45%)]	Loss: -10.2957	Cost: 9.28s
Train Epoch: 723 [61440/90000 (68%)]	Loss: -10.3379	Cost: 9.07s
Train Epoch: 723 [81920/90000 (91%)]	Loss: -9.9506	Cost: 9.58s
Train Epoch: 723 	Average Loss: -9.9737
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6368

Learning rate: 0.0001974315069786633
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 724 [0/90000 (0%)]	Loss: -5.4698	Cost: 24.29s
Train Epoch: 724 [20480/90000 (23%)]	Loss: -10.4815	Cost: 9.05s
Train Epoch: 724 [40960/90000 (45%)]	Loss: -10.3675	Cost: 9.53s
Train Epoch: 724 [61440/90000 (68%)]	Loss: -10.2151	Cost: 9.17s
Train Epoch: 724 [81920/90000 (91%)]	Loss: -9.8979	Cost: 9.76s
Train Epoch: 724 	Average Loss: -9.9790
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5870

Learning rate: 0.00019742442764552676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 725 [0/90000 (0%)]	Loss: -5.6563	Cost: 24.45s
Train Epoch: 725 [20480/90000 (23%)]	Loss: -10.4969	Cost: 9.07s
Train Epoch: 725 [40960/90000 (45%)]	Loss: -10.2446	Cost: 9.24s
Train Epoch: 725 [61440/90000 (68%)]	Loss: -10.3619	Cost: 9.26s
Train Epoch: 725 [81920/90000 (91%)]	Loss: -10.2176	Cost: 9.54s
Train Epoch: 725 	Average Loss: -10.0915
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6328

Learning rate: 0.0001974173386969847
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 726 [0/90000 (0%)]	Loss: -5.5876	Cost: 24.19s
Train Epoch: 726 [20480/90000 (23%)]	Loss: -10.7220	Cost: 9.31s
Train Epoch: 726 [40960/90000 (45%)]	Loss: -10.5955	Cost: 9.15s
Train Epoch: 726 [61440/90000 (68%)]	Loss: -10.5293	Cost: 9.05s
Train Epoch: 726 [81920/90000 (91%)]	Loss: -10.1491	Cost: 9.42s
Train Epoch: 726 	Average Loss: -10.2186
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6269

Learning rate: 0.00019741024013373678
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 727 [0/90000 (0%)]	Loss: -5.2243	Cost: 21.84s
Train Epoch: 727 [20480/90000 (23%)]	Loss: -10.6563	Cost: 9.32s
Train Epoch: 727 [40960/90000 (45%)]	Loss: -10.2932	Cost: 9.40s
Train Epoch: 727 [61440/90000 (68%)]	Loss: -10.4989	Cost: 9.25s
Train Epoch: 727 [81920/90000 (91%)]	Loss: -10.1434	Cost: 8.97s
Train Epoch: 727 	Average Loss: -10.1699
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5555

Learning rate: 0.00019740313195648358
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 728 [0/90000 (0%)]	Loss: -5.4447	Cost: 22.44s
Train Epoch: 728 [20480/90000 (23%)]	Loss: -10.6094	Cost: 9.35s
Train Epoch: 728 [40960/90000 (45%)]	Loss: -10.5045	Cost: 9.31s
Train Epoch: 728 [61440/90000 (68%)]	Loss: -10.3633	Cost: 9.29s
Train Epoch: 728 [81920/90000 (91%)]	Loss: -10.0127	Cost: 9.12s
Train Epoch: 728 	Average Loss: -10.1407
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6794

Learning rate: 0.00019739601416592667
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 729 [0/90000 (0%)]	Loss: -5.0233	Cost: 22.35s
Train Epoch: 729 [20480/90000 (23%)]	Loss: -10.7384	Cost: 9.37s
Train Epoch: 729 [40960/90000 (45%)]	Loss: -10.3101	Cost: 9.26s
Train Epoch: 729 [61440/90000 (68%)]	Loss: -10.4115	Cost: 9.17s
Train Epoch: 729 [81920/90000 (91%)]	Loss: -10.2719	Cost: 9.15s
Train Epoch: 729 	Average Loss: -10.1351
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8187

Learning rate: 0.00019738888676276855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 730 [0/90000 (0%)]	Loss: -5.3672	Cost: 23.13s
Train Epoch: 730 [20480/90000 (23%)]	Loss: -10.7499	Cost: 9.38s
Train Epoch: 730 [40960/90000 (45%)]	Loss: -10.5338	Cost: 9.27s
Train Epoch: 730 [61440/90000 (68%)]	Loss: -10.5090	Cost: 9.01s
Train Epoch: 730 [81920/90000 (91%)]	Loss: -10.1750	Cost: 8.92s
Train Epoch: 730 	Average Loss: -10.2466
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6959

Learning rate: 0.00019738174974771262
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 731 [0/90000 (0%)]	Loss: -5.4749	Cost: 24.15s
Train Epoch: 731 [20480/90000 (23%)]	Loss: -10.4772	Cost: 9.36s
Train Epoch: 731 [40960/90000 (45%)]	Loss: -10.4416	Cost: 9.31s
Train Epoch: 731 [61440/90000 (68%)]	Loss: -9.9248	Cost: 9.25s
Train Epoch: 731 [81920/90000 (91%)]	Loss: -9.3603	Cost: 8.75s
Train Epoch: 731 	Average Loss: -9.8725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0666

Learning rate: 0.00019737460312146333
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 732 [0/90000 (0%)]	Loss: -4.8818	Cost: 25.27s
Train Epoch: 732 [20480/90000 (23%)]	Loss: -10.2701	Cost: 9.30s
Train Epoch: 732 [40960/90000 (45%)]	Loss: -10.1476	Cost: 9.34s
Train Epoch: 732 [61440/90000 (68%)]	Loss: -9.6152	Cost: 9.12s
Train Epoch: 732 [81920/90000 (91%)]	Loss: -9.6273	Cost: 8.67s
Train Epoch: 732 	Average Loss: -9.6808
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2285

Learning rate: 0.000197367446884726
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 733 [0/90000 (0%)]	Loss: -4.6258	Cost: 24.11s
Train Epoch: 733 [20480/90000 (23%)]	Loss: -10.2850	Cost: 9.36s
Train Epoch: 733 [40960/90000 (45%)]	Loss: -10.2349	Cost: 9.32s
Train Epoch: 733 [61440/90000 (68%)]	Loss: -10.4572	Cost: 9.44s
Train Epoch: 733 [81920/90000 (91%)]	Loss: -9.9902	Cost: 8.72s
Train Epoch: 733 	Average Loss: -9.9319
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5027

Learning rate: 0.00019736028103820694
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 734 [0/90000 (0%)]	Loss: -5.5173	Cost: 24.63s
Train Epoch: 734 [20480/90000 (23%)]	Loss: -10.6531	Cost: 9.43s
Train Epoch: 734 [40960/90000 (45%)]	Loss: -10.2435	Cost: 9.30s
Train Epoch: 734 [61440/90000 (68%)]	Loss: -10.2666	Cost: 9.52s
Train Epoch: 734 [81920/90000 (91%)]	Loss: -10.2357	Cost: 8.91s
Train Epoch: 734 	Average Loss: -10.0541
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5546

Learning rate: 0.0001973531055826134
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 735 [0/90000 (0%)]	Loss: -5.4801	Cost: 26.70s
Train Epoch: 735 [20480/90000 (23%)]	Loss: -10.0393	Cost: 9.31s
Train Epoch: 735 [40960/90000 (45%)]	Loss: -10.0927	Cost: 9.22s
Train Epoch: 735 [61440/90000 (68%)]	Loss: -10.2212	Cost: 9.36s
Train Epoch: 735 [81920/90000 (91%)]	Loss: -9.9764	Cost: 8.88s
Train Epoch: 735 	Average Loss: -9.7577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7515

Learning rate: 0.0001973459205186535
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 736 [0/90000 (0%)]	Loss: -5.7797	Cost: 24.47s
Train Epoch: 736 [20480/90000 (23%)]	Loss: -10.8263	Cost: 9.38s
Train Epoch: 736 [40960/90000 (45%)]	Loss: -10.6256	Cost: 9.26s
Train Epoch: 736 [61440/90000 (68%)]	Loss: -10.7114	Cost: 9.16s
Train Epoch: 736 [81920/90000 (91%)]	Loss: -10.4407	Cost: 8.95s
Train Epoch: 736 	Average Loss: -10.3518
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9108

Learning rate: 0.00019733872584703645
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 737 [0/90000 (0%)]	Loss: -5.7403	Cost: 27.20s
Train Epoch: 737 [20480/90000 (23%)]	Loss: -10.9873	Cost: 9.34s
Train Epoch: 737 [40960/90000 (45%)]	Loss: -10.5113	Cost: 9.32s
Train Epoch: 737 [61440/90000 (68%)]	Loss: -10.7320	Cost: 9.27s
Train Epoch: 737 [81920/90000 (91%)]	Loss: -10.3188	Cost: 8.81s
Train Epoch: 737 	Average Loss: -10.3871
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7546

Learning rate: 0.0001973315215684723
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 738 [0/90000 (0%)]	Loss: -5.7204	Cost: 24.16s
Train Epoch: 738 [20480/90000 (23%)]	Loss: -10.7954	Cost: 9.31s
Train Epoch: 738 [40960/90000 (45%)]	Loss: -10.6712	Cost: 9.31s
Train Epoch: 738 [61440/90000 (68%)]	Loss: -10.4580	Cost: 9.10s
Train Epoch: 738 [81920/90000 (91%)]	Loss: -10.2775	Cost: 8.87s
Train Epoch: 738 	Average Loss: -10.2757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6276

Learning rate: 0.00019732430768367213
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 739 [0/90000 (0%)]	Loss: -5.3081	Cost: 24.26s
Train Epoch: 739 [20480/90000 (23%)]	Loss: -10.6558	Cost: 9.36s
Train Epoch: 739 [40960/90000 (45%)]	Loss: -10.4072	Cost: 9.26s
Train Epoch: 739 [61440/90000 (68%)]	Loss: -10.6293	Cost: 9.25s
Train Epoch: 739 [81920/90000 (91%)]	Loss: -10.3313	Cost: 9.01s
Train Epoch: 739 	Average Loss: -10.2945
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9635

Learning rate: 0.00019731708419334784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 740 [0/90000 (0%)]	Loss: -5.8739	Cost: 24.00s
Train Epoch: 740 [20480/90000 (23%)]	Loss: -11.0459	Cost: 9.50s
Train Epoch: 740 [40960/90000 (45%)]	Loss: -10.8359	Cost: 9.20s
Train Epoch: 740 [61440/90000 (68%)]	Loss: -10.3199	Cost: 9.26s
Train Epoch: 740 [81920/90000 (91%)]	Loss: -10.1950	Cost: 9.06s
Train Epoch: 740 	Average Loss: -10.2796
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7702

Learning rate: 0.00019730985109821242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 741 [0/90000 (0%)]	Loss: -5.5409	Cost: 24.71s
Train Epoch: 741 [20480/90000 (23%)]	Loss: -10.8121	Cost: 9.79s
Train Epoch: 741 [40960/90000 (45%)]	Loss: -10.7145	Cost: 9.28s
Train Epoch: 741 [61440/90000 (68%)]	Loss: -10.6874	Cost: 9.12s
Train Epoch: 741 [81920/90000 (91%)]	Loss: -10.4499	Cost: 9.03s
Train Epoch: 741 	Average Loss: -10.3460
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7689

Learning rate: 0.0001973026083989797
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 742 [0/90000 (0%)]	Loss: -5.8581	Cost: 24.23s
Train Epoch: 742 [20480/90000 (23%)]	Loss: -10.9507	Cost: 9.47s
Train Epoch: 742 [40960/90000 (45%)]	Loss: -10.7651	Cost: 9.36s
Train Epoch: 742 [61440/90000 (68%)]	Loss: -10.4748	Cost: 8.99s
Train Epoch: 742 [81920/90000 (91%)]	Loss: -10.3389	Cost: 9.07s
Train Epoch: 742 	Average Loss: -10.3935
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8309

Learning rate: 0.00019729535609636458
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 743 [0/90000 (0%)]	Loss: -5.6127	Cost: 24.82s
Train Epoch: 743 [20480/90000 (23%)]	Loss: -10.8420	Cost: 9.32s
Train Epoch: 743 [40960/90000 (45%)]	Loss: -10.6063	Cost: 9.11s
Train Epoch: 743 [61440/90000 (68%)]	Loss: -10.5539	Cost: 9.18s
Train Epoch: 743 [81920/90000 (91%)]	Loss: -10.5183	Cost: 8.70s
Train Epoch: 743 	Average Loss: -10.4419
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9532

Learning rate: 0.00019728809419108275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 744 [0/90000 (0%)]	Loss: -5.2987	Cost: 24.56s
Train Epoch: 744 [20480/90000 (23%)]	Loss: -10.8391	Cost: 9.05s
Train Epoch: 744 [40960/90000 (45%)]	Loss: -10.6210	Cost: 9.20s
Train Epoch: 744 [61440/90000 (68%)]	Loss: -10.7056	Cost: 9.07s
Train Epoch: 744 [81920/90000 (91%)]	Loss: -10.5185	Cost: 8.63s
Train Epoch: 744 	Average Loss: -10.4373
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1489

Learning rate: 0.00019728082268385098
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 745 [0/90000 (0%)]	Loss: -5.6242	Cost: 23.91s
Train Epoch: 745 [20480/90000 (23%)]	Loss: -11.2828	Cost: 9.12s
Train Epoch: 745 [40960/90000 (45%)]	Loss: -10.9524	Cost: 9.54s
Train Epoch: 745 [61440/90000 (68%)]	Loss: -10.9404	Cost: 9.28s
Train Epoch: 745 [81920/90000 (91%)]	Loss: -10.7201	Cost: 9.27s
Train Epoch: 745 	Average Loss: -10.6760
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1239

Learning rate: 0.00019727354157538695
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 746 [0/90000 (0%)]	Loss: -6.0020	Cost: 23.64s
Train Epoch: 746 [20480/90000 (23%)]	Loss: -11.2713	Cost: 9.14s
Train Epoch: 746 [40960/90000 (45%)]	Loss: -10.8600	Cost: 9.45s
Train Epoch: 746 [61440/90000 (68%)]	Loss: -10.8836	Cost: 9.20s
Train Epoch: 746 [81920/90000 (91%)]	Loss: -10.7937	Cost: 9.55s
Train Epoch: 746 	Average Loss: -10.7188
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0443

Learning rate: 0.00019726625086640925
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 747 [0/90000 (0%)]	Loss: -5.8024	Cost: 23.18s
Train Epoch: 747 [20480/90000 (23%)]	Loss: -11.1180	Cost: 9.32s
Train Epoch: 747 [40960/90000 (45%)]	Loss: -10.8313	Cost: 9.15s
Train Epoch: 747 [61440/90000 (68%)]	Loss: -10.9586	Cost: 9.33s
Train Epoch: 747 [81920/90000 (91%)]	Loss: -10.6749	Cost: 9.09s
Train Epoch: 747 	Average Loss: -10.5919
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0762

Learning rate: 0.00019725895055763745
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 748 [0/90000 (0%)]	Loss: -6.4529	Cost: 24.02s
Train Epoch: 748 [20480/90000 (23%)]	Loss: -10.8244	Cost: 9.28s
Train Epoch: 748 [40960/90000 (45%)]	Loss: -10.5034	Cost: 9.41s
Train Epoch: 748 [61440/90000 (68%)]	Loss: -10.4856	Cost: 9.06s
Train Epoch: 748 [81920/90000 (91%)]	Loss: -10.5842	Cost: 9.03s
Train Epoch: 748 	Average Loss: -10.3954
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9597

Learning rate: 0.00019725164064979207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 749 [0/90000 (0%)]	Loss: -5.7532	Cost: 22.33s
Train Epoch: 749 [20480/90000 (23%)]	Loss: -11.0088	Cost: 9.27s
Train Epoch: 749 [40960/90000 (45%)]	Loss: -10.9652	Cost: 9.30s
Train Epoch: 749 [61440/90000 (68%)]	Loss: -10.9050	Cost: 9.35s
Train Epoch: 749 [81920/90000 (91%)]	Loss: -10.7026	Cost: 9.03s
Train Epoch: 749 	Average Loss: -10.6600
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1857

Learning rate: 0.00019724432114359458
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 750 [0/90000 (0%)]	Loss: -6.3011	Cost: 21.74s
Train Epoch: 750 [20480/90000 (23%)]	Loss: -11.3009	Cost: 9.53s
Train Epoch: 750 [40960/90000 (45%)]	Loss: -10.8715	Cost: 9.30s
Train Epoch: 750 [61440/90000 (68%)]	Loss: -11.0168	Cost: 9.11s
Train Epoch: 750 [81920/90000 (91%)]	Loss: -11.0268	Cost: 9.15s
Train Epoch: 750 	Average Loss: -10.8140
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3066

Saving model as model.pt_e750 & waveforms_supplementary.hdf5_e750
Learning rate: 0.00019723699203976736
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 751 [0/90000 (0%)]	Loss: -5.6598	Cost: 22.62s
Train Epoch: 751 [20480/90000 (23%)]	Loss: -11.1615	Cost: 9.32s
Train Epoch: 751 [40960/90000 (45%)]	Loss: -10.7853	Cost: 9.50s
Train Epoch: 751 [61440/90000 (68%)]	Loss: -10.6935	Cost: 9.19s
Train Epoch: 751 [81920/90000 (91%)]	Loss: -10.4275	Cost: 9.14s
Train Epoch: 751 	Average Loss: -10.5783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0123

Learning rate: 0.0001972296533390338
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 752 [0/90000 (0%)]	Loss: -6.0039	Cost: 22.88s
Train Epoch: 752 [20480/90000 (23%)]	Loss: -11.0708	Cost: 9.35s
Train Epoch: 752 [40960/90000 (45%)]	Loss: -10.8854	Cost: 9.30s
Train Epoch: 752 [61440/90000 (68%)]	Loss: -10.8480	Cost: 9.05s
Train Epoch: 752 [81920/90000 (91%)]	Loss: -10.5889	Cost: 9.27s
Train Epoch: 752 	Average Loss: -10.6235
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0660

Learning rate: 0.00019722230504211813
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 753 [0/90000 (0%)]	Loss: -6.2742	Cost: 23.99s
Train Epoch: 753 [20480/90000 (23%)]	Loss: -11.1068	Cost: 9.40s
Train Epoch: 753 [40960/90000 (45%)]	Loss: -10.8610	Cost: 9.21s
Train Epoch: 753 [61440/90000 (68%)]	Loss: -10.8468	Cost: 8.97s
Train Epoch: 753 [81920/90000 (91%)]	Loss: -10.8297	Cost: 9.05s
Train Epoch: 753 	Average Loss: -10.7133
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3682

Learning rate: 0.00019721494714974565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 754 [0/90000 (0%)]	Loss: -5.9104	Cost: 23.42s
Train Epoch: 754 [20480/90000 (23%)]	Loss: -11.4494	Cost: 9.31s
Train Epoch: 754 [40960/90000 (45%)]	Loss: -11.2032	Cost: 9.32s
Train Epoch: 754 [61440/90000 (68%)]	Loss: -10.7935	Cost: 9.06s
Train Epoch: 754 [81920/90000 (91%)]	Loss: -10.2637	Cost: 9.16s
Train Epoch: 754 	Average Loss: -10.6650
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6553

Learning rate: 0.00019720757966264256
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 755 [0/90000 (0%)]	Loss: -5.2965	Cost: 23.69s
Train Epoch: 755 [20480/90000 (23%)]	Loss: -10.9590	Cost: 9.32s
Train Epoch: 755 [40960/90000 (45%)]	Loss: -10.5560	Cost: 9.50s
Train Epoch: 755 [61440/90000 (68%)]	Loss: -10.7742	Cost: 9.11s
Train Epoch: 755 [81920/90000 (91%)]	Loss: -10.2293	Cost: 9.11s
Train Epoch: 755 	Average Loss: -10.4380
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8870

Learning rate: 0.00019720020258153596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 756 [0/90000 (0%)]	Loss: -5.8630	Cost: 22.95s
Train Epoch: 756 [20480/90000 (23%)]	Loss: -11.3398	Cost: 9.34s
Train Epoch: 756 [40960/90000 (45%)]	Loss: -10.8695	Cost: 9.32s
Train Epoch: 756 [61440/90000 (68%)]	Loss: -10.8544	Cost: 9.06s
Train Epoch: 756 [81920/90000 (91%)]	Loss: -10.6502	Cost: 9.17s
Train Epoch: 756 	Average Loss: -10.6619
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1155

Learning rate: 0.000197192815907154
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 757 [0/90000 (0%)]	Loss: -5.9136	Cost: 24.83s
Train Epoch: 757 [20480/90000 (23%)]	Loss: -11.3013	Cost: 9.24s
Train Epoch: 757 [40960/90000 (45%)]	Loss: -11.0876	Cost: 9.45s
Train Epoch: 757 [61440/90000 (68%)]	Loss: -10.7256	Cost: 9.03s
Train Epoch: 757 [81920/90000 (91%)]	Loss: -10.8502	Cost: 8.83s
Train Epoch: 757 	Average Loss: -10.7270
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1182

Learning rate: 0.00019718541964022568
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 758 [0/90000 (0%)]	Loss: -5.9332	Cost: 23.82s
Train Epoch: 758 [20480/90000 (23%)]	Loss: -11.5002	Cost: 9.31s
Train Epoch: 758 [40960/90000 (45%)]	Loss: -11.0938	Cost: 9.32s
Train Epoch: 758 [61440/90000 (68%)]	Loss: -11.1228	Cost: 9.22s
Train Epoch: 758 [81920/90000 (91%)]	Loss: -10.9019	Cost: 8.71s
Train Epoch: 758 	Average Loss: -10.8069
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2020

Learning rate: 0.00019717801378148098
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 759 [0/90000 (0%)]	Loss: -6.0311	Cost: 24.76s
Train Epoch: 759 [20480/90000 (23%)]	Loss: -11.1151	Cost: 9.31s
Train Epoch: 759 [40960/90000 (45%)]	Loss: -10.8790	Cost: 9.31s
Train Epoch: 759 [61440/90000 (68%)]	Loss: -11.0879	Cost: 9.32s
Train Epoch: 759 [81920/90000 (91%)]	Loss: -10.8033	Cost: 8.65s
Train Epoch: 759 	Average Loss: -10.7202
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1592

Learning rate: 0.0001971705983316508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 760 [0/90000 (0%)]	Loss: -6.2150	Cost: 24.21s
Train Epoch: 760 [20480/90000 (23%)]	Loss: -8.9001	Cost: 9.38s
Train Epoch: 760 [40960/90000 (45%)]	Loss: -8.6876	Cost: 9.34s
Train Epoch: 760 [61440/90000 (68%)]	Loss: -9.2110	Cost: 9.13s
Train Epoch: 760 [81920/90000 (91%)]	Loss: -9.2031	Cost: 8.80s
Train Epoch: 760 	Average Loss: -9.1281
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0194

Learning rate: 0.0001971631732914671
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 761 [0/90000 (0%)]	Loss: -4.5797	Cost: 25.04s
Train Epoch: 761 [20480/90000 (23%)]	Loss: -10.0982	Cost: 9.38s
Train Epoch: 761 [40960/90000 (45%)]	Loss: -10.2557	Cost: 9.31s
Train Epoch: 761 [61440/90000 (68%)]	Loss: -10.5280	Cost: 9.27s
Train Epoch: 761 [81920/90000 (91%)]	Loss: -10.3543	Cost: 8.83s
Train Epoch: 761 	Average Loss: -10.0228
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8676

Learning rate: 0.00019715573866166262
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 762 [0/90000 (0%)]	Loss: -5.9677	Cost: 26.99s
Train Epoch: 762 [20480/90000 (23%)]	Loss: -11.1449	Cost: 9.33s
Train Epoch: 762 [40960/90000 (45%)]	Loss: -10.9647	Cost: 9.30s
Train Epoch: 762 [61440/90000 (68%)]	Loss: -11.1574	Cost: 9.14s
Train Epoch: 762 [81920/90000 (91%)]	Loss: -10.8439	Cost: 8.82s
Train Epoch: 762 	Average Loss: -10.7545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2094

Learning rate: 0.0001971482944429712
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 763 [0/90000 (0%)]	Loss: -5.8160	Cost: 27.24s
Train Epoch: 763 [20480/90000 (23%)]	Loss: -11.1755	Cost: 9.31s
Train Epoch: 763 [40960/90000 (45%)]	Loss: -10.6354	Cost: 9.33s
Train Epoch: 763 [61440/90000 (68%)]	Loss: -10.8741	Cost: 9.41s
Train Epoch: 763 [81920/90000 (91%)]	Loss: -9.6944	Cost: 8.72s
Train Epoch: 763 	Average Loss: -10.4507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4112

Learning rate: 0.00019714084063612747
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 764 [0/90000 (0%)]	Loss: -5.0537	Cost: 24.05s
Train Epoch: 764 [20480/90000 (23%)]	Loss: -10.0133	Cost: 9.35s
Train Epoch: 764 [40960/90000 (45%)]	Loss: -10.4582	Cost: 9.21s
Train Epoch: 764 [61440/90000 (68%)]	Loss: -10.8325	Cost: 9.15s
Train Epoch: 764 [81920/90000 (91%)]	Loss: -10.5598	Cost: 8.77s
Train Epoch: 764 	Average Loss: -10.1618
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9302

Learning rate: 0.00019713337724186716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 765 [0/90000 (0%)]	Loss: -5.8220	Cost: 24.28s
Train Epoch: 765 [20480/90000 (23%)]	Loss: -11.3364	Cost: 9.33s
Train Epoch: 765 [40960/90000 (45%)]	Loss: -11.2516	Cost: 9.26s
Train Epoch: 765 [61440/90000 (68%)]	Loss: -11.2424	Cost: 9.39s
Train Epoch: 765 [81920/90000 (91%)]	Loss: -11.0189	Cost: 8.90s
Train Epoch: 765 	Average Loss: -10.8734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2911

Learning rate: 0.00019712590426092686
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 766 [0/90000 (0%)]	Loss: -6.3413	Cost: 23.74s
Train Epoch: 766 [20480/90000 (23%)]	Loss: -11.4858	Cost: 9.28s
Train Epoch: 766 [40960/90000 (45%)]	Loss: -11.2120	Cost: 9.23s
Train Epoch: 766 [61440/90000 (68%)]	Loss: -11.3702	Cost: 9.20s
Train Epoch: 766 [81920/90000 (91%)]	Loss: -11.1514	Cost: 8.99s
Train Epoch: 766 	Average Loss: -11.0145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4453

Learning rate: 0.0001971184216940441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 767 [0/90000 (0%)]	Loss: -6.5659	Cost: 26.35s
Train Epoch: 767 [20480/90000 (23%)]	Loss: -11.4689	Cost: 9.36s
Train Epoch: 767 [40960/90000 (45%)]	Loss: -11.2658	Cost: 9.27s
Train Epoch: 767 [61440/90000 (68%)]	Loss: -11.1667	Cost: 9.29s
Train Epoch: 767 [81920/90000 (91%)]	Loss: -11.1192	Cost: 8.96s
Train Epoch: 767 	Average Loss: -10.9915
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3363

Learning rate: 0.0001971109295419574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 768 [0/90000 (0%)]	Loss: -6.3599	Cost: 23.92s
Train Epoch: 768 [20480/90000 (23%)]	Loss: -11.6234	Cost: 9.46s
Train Epoch: 768 [40960/90000 (45%)]	Loss: -11.2474	Cost: 9.21s
Train Epoch: 768 [61440/90000 (68%)]	Loss: -11.1127	Cost: 9.10s
Train Epoch: 768 [81920/90000 (91%)]	Loss: -10.9776	Cost: 8.98s
Train Epoch: 768 	Average Loss: -10.9757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2755

Learning rate: 0.0001971034278054062
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 769 [0/90000 (0%)]	Loss: -6.3948	Cost: 24.81s
Train Epoch: 769 [20480/90000 (23%)]	Loss: -11.5054	Cost: 9.48s
Train Epoch: 769 [40960/90000 (45%)]	Loss: -11.0885	Cost: 9.29s
Train Epoch: 769 [61440/90000 (68%)]	Loss: -11.2380	Cost: 9.31s
Train Epoch: 769 [81920/90000 (91%)]	Loss: -11.0537	Cost: 9.02s
Train Epoch: 769 	Average Loss: -11.0549
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3919

Learning rate: 0.00019709591648513092
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 770 [0/90000 (0%)]	Loss: -6.1527	Cost: 23.95s
Train Epoch: 770 [20480/90000 (23%)]	Loss: -11.5318	Cost: 9.43s
Train Epoch: 770 [40960/90000 (45%)]	Loss: -11.3314	Cost: 9.31s
Train Epoch: 770 [61440/90000 (68%)]	Loss: -11.2465	Cost: 9.13s
Train Epoch: 770 [81920/90000 (91%)]	Loss: -11.0227	Cost: 9.16s
Train Epoch: 770 	Average Loss: -11.0677
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2749

Learning rate: 0.00019708839558187284
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 771 [0/90000 (0%)]	Loss: -5.9015	Cost: 24.02s
Train Epoch: 771 [20480/90000 (23%)]	Loss: -11.1439	Cost: 9.67s
Train Epoch: 771 [40960/90000 (45%)]	Loss: -10.8920	Cost: 9.33s
Train Epoch: 771 [61440/90000 (68%)]	Loss: -11.0001	Cost: 9.08s
Train Epoch: 771 [81920/90000 (91%)]	Loss: -10.9579	Cost: 9.09s
Train Epoch: 771 	Average Loss: -10.7194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2493

Learning rate: 0.0001970808650963743
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 772 [0/90000 (0%)]	Loss: -6.4596	Cost: 24.31s
Train Epoch: 772 [20480/90000 (23%)]	Loss: -11.3988	Cost: 9.51s
Train Epoch: 772 [40960/90000 (45%)]	Loss: -11.3583	Cost: 9.15s
Train Epoch: 772 [61440/90000 (68%)]	Loss: -11.3258	Cost: 9.01s
Train Epoch: 772 [81920/90000 (91%)]	Loss: -11.1916	Cost: 8.76s
Train Epoch: 772 	Average Loss: -11.0644
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3979

Learning rate: 0.00019707332502937847
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 773 [0/90000 (0%)]	Loss: -6.1391	Cost: 24.98s
Train Epoch: 773 [20480/90000 (23%)]	Loss: -11.6783	Cost: 9.20s
Train Epoch: 773 [40960/90000 (45%)]	Loss: -11.3410	Cost: 9.97s
Train Epoch: 773 [61440/90000 (68%)]	Loss: -11.3735	Cost: 9.12s
Train Epoch: 773 [81920/90000 (91%)]	Loss: -11.2195	Cost: 8.66s
Train Epoch: 773 	Average Loss: -11.2085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6475

Learning rate: 0.00019706577538162957
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 774 [0/90000 (0%)]	Loss: -6.4139	Cost: 24.72s
Train Epoch: 774 [20480/90000 (23%)]	Loss: -11.6187	Cost: 9.08s
Train Epoch: 774 [40960/90000 (45%)]	Loss: -11.4880	Cost: 9.35s
Train Epoch: 774 [61440/90000 (68%)]	Loss: -11.1408	Cost: 8.99s
Train Epoch: 774 [81920/90000 (91%)]	Loss: -11.1961	Cost: 8.64s
Train Epoch: 774 	Average Loss: -11.0787
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1670

Learning rate: 0.00019705821615387272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 775 [0/90000 (0%)]	Loss: -6.1467	Cost: 24.79s
Train Epoch: 775 [20480/90000 (23%)]	Loss: -11.3436	Cost: 9.07s
Train Epoch: 775 [40960/90000 (45%)]	Loss: -11.3848	Cost: 9.80s
Train Epoch: 775 [61440/90000 (68%)]	Loss: -11.3637	Cost: 9.13s
Train Epoch: 775 [81920/90000 (91%)]	Loss: -10.9232	Cost: 9.17s
Train Epoch: 775 	Average Loss: -10.9390
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2078

Learning rate: 0.000197050647346854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 776 [0/90000 (0%)]	Loss: -5.8000	Cost: 23.14s
Train Epoch: 776 [20480/90000 (23%)]	Loss: -11.4203	Cost: 9.16s
Train Epoch: 776 [40960/90000 (45%)]	Loss: -11.3810	Cost: 9.17s
Train Epoch: 776 [61440/90000 (68%)]	Loss: -11.4295	Cost: 9.12s
Train Epoch: 776 [81920/90000 (91%)]	Loss: -11.2336	Cost: 9.52s
Train Epoch: 776 	Average Loss: -11.0020
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4685

Learning rate: 0.0001970430689613204
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 777 [0/90000 (0%)]	Loss: -6.7014	Cost: 24.18s
Train Epoch: 777 [20480/90000 (23%)]	Loss: -11.6512	Cost: 9.12s
Train Epoch: 777 [40960/90000 (45%)]	Loss: -11.4707	Cost: 9.32s
Train Epoch: 777 [61440/90000 (68%)]	Loss: -11.4541	Cost: 9.28s
Train Epoch: 777 [81920/90000 (91%)]	Loss: -11.2799	Cost: 10.19s
Train Epoch: 777 	Average Loss: -11.2023
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4435

Learning rate: 0.00019703548099801984
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 778 [0/90000 (0%)]	Loss: -6.3567	Cost: 24.36s
Train Epoch: 778 [20480/90000 (23%)]	Loss: -11.8426	Cost: 9.26s
Train Epoch: 778 [40960/90000 (45%)]	Loss: -11.4441	Cost: 9.06s
Train Epoch: 778 [61440/90000 (68%)]	Loss: -11.5238	Cost: 9.06s
Train Epoch: 778 [81920/90000 (91%)]	Loss: -11.3053	Cost: 9.53s
Train Epoch: 778 	Average Loss: -11.2154
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4959

Learning rate: 0.00019702788345770126
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 779 [0/90000 (0%)]	Loss: -5.8073	Cost: 23.40s
Train Epoch: 779 [20480/90000 (23%)]	Loss: -11.1002	Cost: 9.23s
Train Epoch: 779 [40960/90000 (45%)]	Loss: -10.9208	Cost: 9.36s
Train Epoch: 779 [61440/90000 (68%)]	Loss: -11.1143	Cost: 9.27s
Train Epoch: 779 [81920/90000 (91%)]	Loss: -11.0735	Cost: 9.04s
Train Epoch: 779 	Average Loss: -10.8499
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4308

Learning rate: 0.0001970202763411145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 780 [0/90000 (0%)]	Loss: -5.5978	Cost: 22.80s
Train Epoch: 780 [20480/90000 (23%)]	Loss: -11.4846	Cost: 9.38s
Train Epoch: 780 [40960/90000 (45%)]	Loss: -11.5557	Cost: 9.35s
Train Epoch: 780 [61440/90000 (68%)]	Loss: -11.4636	Cost: 9.28s
Train Epoch: 780 [81920/90000 (91%)]	Loss: -11.2392	Cost: 9.17s
Train Epoch: 780 	Average Loss: -11.1915
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6614

Learning rate: 0.00019701265964901035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 781 [0/90000 (0%)]	Loss: -6.9749	Cost: 22.54s
Train Epoch: 781 [20480/90000 (23%)]	Loss: -11.7938	Cost: 9.40s
Train Epoch: 781 [40960/90000 (45%)]	Loss: -11.3619	Cost: 9.22s
Train Epoch: 781 [61440/90000 (68%)]	Loss: -11.5177	Cost: 9.27s
Train Epoch: 781 [81920/90000 (91%)]	Loss: -11.2690	Cost: 9.15s
Train Epoch: 781 	Average Loss: -11.2519
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5402

Learning rate: 0.00019700503338214057
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 782 [0/90000 (0%)]	Loss: -6.4888	Cost: 23.70s
Train Epoch: 782 [20480/90000 (23%)]	Loss: -11.7885	Cost: 9.30s
Train Epoch: 782 [40960/90000 (45%)]	Loss: -11.4558	Cost: 9.27s
Train Epoch: 782 [61440/90000 (68%)]	Loss: -11.5143	Cost: 9.05s
Train Epoch: 782 [81920/90000 (91%)]	Loss: -11.1211	Cost: 9.19s
Train Epoch: 782 	Average Loss: -11.2178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6019

Learning rate: 0.0001969973975412578
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 783 [0/90000 (0%)]	Loss: -6.8970	Cost: 22.99s
Train Epoch: 783 [20480/90000 (23%)]	Loss: -11.5534	Cost: 9.55s
Train Epoch: 783 [40960/90000 (45%)]	Loss: -11.7534	Cost: 9.29s
Train Epoch: 783 [61440/90000 (68%)]	Loss: -11.3916	Cost: 9.20s
Train Epoch: 783 [81920/90000 (91%)]	Loss: -11.2247	Cost: 8.77s
Train Epoch: 783 	Average Loss: -11.2127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4423

Learning rate: 0.00019698975212711572
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 784 [0/90000 (0%)]	Loss: -6.1731	Cost: 25.74s
Train Epoch: 784 [20480/90000 (23%)]	Loss: -11.6284	Cost: 9.31s
Train Epoch: 784 [40960/90000 (45%)]	Loss: -11.5017	Cost: 9.36s
Train Epoch: 784 [61440/90000 (68%)]	Loss: -11.4664	Cost: 9.10s
Train Epoch: 784 [81920/90000 (91%)]	Loss: -10.9746	Cost: 8.65s
Train Epoch: 784 	Average Loss: -11.1945
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3743

Learning rate: 0.00019698209714046885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 785 [0/90000 (0%)]	Loss: -5.8979	Cost: 25.57s
Train Epoch: 785 [20480/90000 (23%)]	Loss: -11.5235	Cost: 9.27s
Train Epoch: 785 [40960/90000 (45%)]	Loss: -11.5298	Cost: 9.34s
Train Epoch: 785 [61440/90000 (68%)]	Loss: -11.6310	Cost: 9.21s
Train Epoch: 785 [81920/90000 (91%)]	Loss: -11.4074	Cost: 8.69s
Train Epoch: 785 	Average Loss: -11.2211
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6381

Learning rate: 0.00019697443258207274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 786 [0/90000 (0%)]	Loss: -6.2413	Cost: 25.21s
Train Epoch: 786 [20480/90000 (23%)]	Loss: -11.0201	Cost: 9.33s
Train Epoch: 786 [40960/90000 (45%)]	Loss: -10.8891	Cost: 9.34s
Train Epoch: 786 [61440/90000 (68%)]	Loss: -11.1707	Cost: 9.25s
Train Epoch: 786 [81920/90000 (91%)]	Loss: -10.9070	Cost: 8.74s
Train Epoch: 786 	Average Loss: -10.9005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4284

Learning rate: 0.00019696675845268385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 787 [0/90000 (0%)]	Loss: -6.6779	Cost: 24.57s
Train Epoch: 787 [20480/90000 (23%)]	Loss: -11.8477	Cost: 9.36s
Train Epoch: 787 [40960/90000 (45%)]	Loss: -11.6244	Cost: 9.23s
Train Epoch: 787 [61440/90000 (68%)]	Loss: -11.8395	Cost: 9.30s
Train Epoch: 787 [81920/90000 (91%)]	Loss: -11.6325	Cost: 9.05s
Train Epoch: 787 	Average Loss: -11.4043
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6061

Learning rate: 0.00019695907475305956
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 788 [0/90000 (0%)]	Loss: -6.5881	Cost: 24.16s
Train Epoch: 788 [20480/90000 (23%)]	Loss: -11.7764	Cost: 9.41s
Train Epoch: 788 [40960/90000 (45%)]	Loss: -11.5995	Cost: 9.32s
Train Epoch: 788 [61440/90000 (68%)]	Loss: -11.7620	Cost: 9.19s
Train Epoch: 788 [81920/90000 (91%)]	Loss: -11.6534	Cost: 8.87s
Train Epoch: 788 	Average Loss: -11.4637
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7668

Learning rate: 0.00019695138148395828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 789 [0/90000 (0%)]	Loss: -6.7477	Cost: 24.68s
Train Epoch: 789 [20480/90000 (23%)]	Loss: -12.1186	Cost: 9.35s
Train Epoch: 789 [40960/90000 (45%)]	Loss: -11.7019	Cost: 9.27s
Train Epoch: 789 [61440/90000 (68%)]	Loss: -11.7110	Cost: 9.30s
Train Epoch: 789 [81920/90000 (91%)]	Loss: -11.3957	Cost: 8.92s
Train Epoch: 789 	Average Loss: -11.4987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6314

Learning rate: 0.00019694367864613922
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 790 [0/90000 (0%)]	Loss: -6.5498	Cost: 25.03s
Train Epoch: 790 [20480/90000 (23%)]	Loss: -12.0717	Cost: 9.56s
Train Epoch: 790 [40960/90000 (45%)]	Loss: -11.8755	Cost: 9.33s
Train Epoch: 790 [61440/90000 (68%)]	Loss: -11.7086	Cost: 9.17s
Train Epoch: 790 [81920/90000 (91%)]	Loss: -11.5204	Cost: 8.97s
Train Epoch: 790 	Average Loss: -11.4784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6838

Learning rate: 0.00019693596624036267
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 791 [0/90000 (0%)]	Loss: -6.2804	Cost: 24.56s
Train Epoch: 791 [20480/90000 (23%)]	Loss: -11.7368	Cost: 9.40s
Train Epoch: 791 [40960/90000 (45%)]	Loss: -11.6908	Cost: 9.29s
Train Epoch: 791 [61440/90000 (68%)]	Loss: -11.5313	Cost: 9.29s
Train Epoch: 791 [81920/90000 (91%)]	Loss: -11.4326	Cost: 9.09s
Train Epoch: 791 	Average Loss: -11.3320
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5988

Learning rate: 0.00019692824426738987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 792 [0/90000 (0%)]	Loss: -6.5840	Cost: 23.95s
Train Epoch: 792 [20480/90000 (23%)]	Loss: -12.1158	Cost: 9.48s
Train Epoch: 792 [40960/90000 (45%)]	Loss: -11.9092	Cost: 9.30s
Train Epoch: 792 [61440/90000 (68%)]	Loss: -11.8012	Cost: 9.00s
Train Epoch: 792 [81920/90000 (91%)]	Loss: -11.6465	Cost: 9.13s
Train Epoch: 792 	Average Loss: -11.5712
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9194

Learning rate: 0.0001969205127279828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 793 [0/90000 (0%)]	Loss: -6.2926	Cost: 23.96s
Train Epoch: 793 [20480/90000 (23%)]	Loss: -12.1029	Cost: 9.45s
Train Epoch: 793 [40960/90000 (45%)]	Loss: -11.8204	Cost: 9.29s
Train Epoch: 793 [61440/90000 (68%)]	Loss: -11.8591	Cost: 9.23s
Train Epoch: 793 [81920/90000 (91%)]	Loss: -11.5759	Cost: 8.78s
Train Epoch: 793 	Average Loss: -11.6288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7771

Learning rate: 0.00019691277162290467
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 794 [0/90000 (0%)]	Loss: -6.9665	Cost: 23.85s
Train Epoch: 794 [20480/90000 (23%)]	Loss: -11.9589	Cost: 9.08s
Train Epoch: 794 [40960/90000 (45%)]	Loss: -11.7022	Cost: 9.04s
Train Epoch: 794 [61440/90000 (68%)]	Loss: -11.7045	Cost: 8.93s
Train Epoch: 794 [81920/90000 (91%)]	Loss: -11.3882	Cost: 8.63s
Train Epoch: 794 	Average Loss: -11.4428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5062

Learning rate: 0.00019690502095291943
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 795 [0/90000 (0%)]	Loss: -6.1248	Cost: 24.01s
Train Epoch: 795 [20480/90000 (23%)]	Loss: -11.7814	Cost: 9.08s
Train Epoch: 795 [40960/90000 (45%)]	Loss: -11.2905	Cost: 9.67s
Train Epoch: 795 [61440/90000 (68%)]	Loss: -11.5679	Cost: 9.13s
Train Epoch: 795 [81920/90000 (91%)]	Loss: -11.3154	Cost: 8.94s
Train Epoch: 795 	Average Loss: -11.2285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6095

Learning rate: 0.00019689726071879206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 796 [0/90000 (0%)]	Loss: -5.9030	Cost: 22.67s
Train Epoch: 796 [20480/90000 (23%)]	Loss: -12.0037	Cost: 9.16s
Train Epoch: 796 [40960/90000 (45%)]	Loss: -11.6676	Cost: 9.31s
Train Epoch: 796 [61440/90000 (68%)]	Loss: -11.6473	Cost: 9.11s
Train Epoch: 796 [81920/90000 (91%)]	Loss: -11.5754	Cost: 9.55s
Train Epoch: 796 	Average Loss: -11.4250
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7304

Learning rate: 0.00019688949092128843
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 797 [0/90000 (0%)]	Loss: -5.8076	Cost: 23.73s
Train Epoch: 797 [20480/90000 (23%)]	Loss: -11.9160	Cost: 9.11s
Train Epoch: 797 [40960/90000 (45%)]	Loss: -11.9575	Cost: 9.79s
Train Epoch: 797 [61440/90000 (68%)]	Loss: -11.8574	Cost: 9.19s
Train Epoch: 797 [81920/90000 (91%)]	Loss: -11.6764	Cost: 9.75s
Train Epoch: 797 	Average Loss: -11.5986
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7320

Learning rate: 0.00019688171156117545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 798 [0/90000 (0%)]	Loss: -6.5527	Cost: 24.29s
Train Epoch: 798 [20480/90000 (23%)]	Loss: -12.0578	Cost: 9.25s
Train Epoch: 798 [40960/90000 (45%)]	Loss: -11.3352	Cost: 9.19s
Train Epoch: 798 [61440/90000 (68%)]	Loss: -11.6541	Cost: 9.12s
Train Epoch: 798 [81920/90000 (91%)]	Loss: -11.4168	Cost: 9.26s
Train Epoch: 798 	Average Loss: -11.3808
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6660

Learning rate: 0.00019687392263922088
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 799 [0/90000 (0%)]	Loss: -6.7390	Cost: 23.74s
Train Epoch: 799 [20480/90000 (23%)]	Loss: -11.9003	Cost: 9.33s
Train Epoch: 799 [40960/90000 (45%)]	Loss: -11.6695	Cost: 9.27s
Train Epoch: 799 [61440/90000 (68%)]	Loss: -11.7592	Cost: 9.29s
Train Epoch: 799 [81920/90000 (91%)]	Loss: -11.3781	Cost: 9.04s
Train Epoch: 799 	Average Loss: -11.4577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6716

Learning rate: 0.00019686612415619346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 800 [0/90000 (0%)]	Loss: -6.7626	Cost: 22.27s
Train Epoch: 800 [20480/90000 (23%)]	Loss: -11.8668	Cost: 9.35s
Train Epoch: 800 [40960/90000 (45%)]	Loss: -11.6920	Cost: 9.32s
Train Epoch: 800 [61440/90000 (68%)]	Loss: -11.7583	Cost: 9.33s
Train Epoch: 800 [81920/90000 (91%)]	Loss: -11.5421	Cost: 9.11s
Train Epoch: 800 	Average Loss: -11.3356
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7571

Saving model as model.pt_e800 & waveforms_supplementary.hdf5_e800
Learning rate: 0.00019685831611286286
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 801 [0/90000 (0%)]	Loss: -6.7061	Cost: 22.46s
Train Epoch: 801 [20480/90000 (23%)]	Loss: -12.1718	Cost: 9.34s
Train Epoch: 801 [40960/90000 (45%)]	Loss: -11.7773	Cost: 9.25s
Train Epoch: 801 [61440/90000 (68%)]	Loss: -11.8206	Cost: 9.27s
Train Epoch: 801 [81920/90000 (91%)]	Loss: -11.9545	Cost: 9.18s
Train Epoch: 801 	Average Loss: -11.5994
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8660

Learning rate: 0.0001968504985099997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 802 [0/90000 (0%)]	Loss: -6.5888	Cost: 21.87s
Train Epoch: 802 [20480/90000 (23%)]	Loss: -12.2321	Cost: 9.43s
Train Epoch: 802 [40960/90000 (45%)]	Loss: -11.9420	Cost: 9.28s
Train Epoch: 802 [61440/90000 (68%)]	Loss: -12.0667	Cost: 9.07s
Train Epoch: 802 [81920/90000 (91%)]	Loss: -11.6994	Cost: 9.13s
Train Epoch: 802 	Average Loss: -11.7799
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9677

Learning rate: 0.00019684267134837557
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 803 [0/90000 (0%)]	Loss: -7.1440	Cost: 24.16s
Train Epoch: 803 [20480/90000 (23%)]	Loss: -12.1319	Cost: 9.27s
Train Epoch: 803 [40960/90000 (45%)]	Loss: -11.9074	Cost: 9.32s
Train Epoch: 803 [61440/90000 (68%)]	Loss: -11.9112	Cost: 9.09s
Train Epoch: 803 [81920/90000 (91%)]	Loss: -11.5505	Cost: 9.22s
Train Epoch: 803 	Average Loss: -11.5758
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9303

Learning rate: 0.00019683483462876295
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 804 [0/90000 (0%)]	Loss: -6.8626	Cost: 23.73s
Train Epoch: 804 [20480/90000 (23%)]	Loss: -12.2237	Cost: 9.34s
Train Epoch: 804 [40960/90000 (45%)]	Loss: -11.9577	Cost: 9.38s
Train Epoch: 804 [61440/90000 (68%)]	Loss: -12.2506	Cost: 9.04s
Train Epoch: 804 [81920/90000 (91%)]	Loss: -11.8265	Cost: 9.20s
Train Epoch: 804 	Average Loss: -11.7662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0761

Learning rate: 0.0001968269883519353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 805 [0/90000 (0%)]	Loss: -6.6997	Cost: 24.32s
Train Epoch: 805 [20480/90000 (23%)]	Loss: -12.4282	Cost: 9.54s
Train Epoch: 805 [40960/90000 (45%)]	Loss: -12.1556	Cost: 9.25s
Train Epoch: 805 [61440/90000 (68%)]	Loss: -12.1812	Cost: 9.08s
Train Epoch: 805 [81920/90000 (91%)]	Loss: -11.8493	Cost: 8.96s
Train Epoch: 805 	Average Loss: -11.8688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1178

Learning rate: 0.00019681913251866706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 806 [0/90000 (0%)]	Loss: -6.8070	Cost: 23.56s
Train Epoch: 806 [20480/90000 (23%)]	Loss: -12.4794	Cost: 9.44s
Train Epoch: 806 [40960/90000 (45%)]	Loss: -11.9155	Cost: 9.25s
Train Epoch: 806 [61440/90000 (68%)]	Loss: -11.8588	Cost: 9.06s
Train Epoch: 806 [81920/90000 (91%)]	Loss: -11.7862	Cost: 8.82s
Train Epoch: 806 	Average Loss: -11.7522
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8968

Learning rate: 0.00019681126712973353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 807 [0/90000 (0%)]	Loss: -6.5575	Cost: 23.67s
Train Epoch: 807 [20480/90000 (23%)]	Loss: -12.4089	Cost: 9.32s
Train Epoch: 807 [40960/90000 (45%)]	Loss: -11.8018	Cost: 9.69s
Train Epoch: 807 [61440/90000 (68%)]	Loss: -11.9336	Cost: 9.16s
Train Epoch: 807 [81920/90000 (91%)]	Loss: -11.8848	Cost: 8.77s
Train Epoch: 807 	Average Loss: -11.7083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0279

Learning rate: 0.00019680339218591098
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 808 [0/90000 (0%)]	Loss: -7.1145	Cost: 24.52s
Train Epoch: 808 [20480/90000 (23%)]	Loss: -12.3282	Cost: 9.37s
Train Epoch: 808 [40960/90000 (45%)]	Loss: -12.2134	Cost: 9.26s
Train Epoch: 808 [61440/90000 (68%)]	Loss: -12.2319	Cost: 9.15s
Train Epoch: 808 [81920/90000 (91%)]	Loss: -12.1140	Cost: 8.76s
Train Epoch: 808 	Average Loss: -11.9257
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1060

Learning rate: 0.00019679550768797666
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 809 [0/90000 (0%)]	Loss: -6.6162	Cost: 24.60s
Train Epoch: 809 [20480/90000 (23%)]	Loss: -12.3196	Cost: 9.37s
Train Epoch: 809 [40960/90000 (45%)]	Loss: -12.1940	Cost: 9.56s
Train Epoch: 809 [61440/90000 (68%)]	Loss: -12.2216	Cost: 9.08s
Train Epoch: 809 [81920/90000 (91%)]	Loss: -11.7431	Cost: 8.70s
Train Epoch: 809 	Average Loss: -11.8974
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9746

Learning rate: 0.00019678761363670875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 810 [0/90000 (0%)]	Loss: -6.6433	Cost: 25.15s
Train Epoch: 810 [20480/90000 (23%)]	Loss: -12.2592	Cost: 9.41s
Train Epoch: 810 [40960/90000 (45%)]	Loss: -11.7130	Cost: 9.26s
Train Epoch: 810 [61440/90000 (68%)]	Loss: -12.1080	Cost: 9.12s
Train Epoch: 810 [81920/90000 (91%)]	Loss: -11.7177	Cost: 8.88s
Train Epoch: 810 	Average Loss: -11.7202
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9950

Learning rate: 0.0001967797100328863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 811 [0/90000 (0%)]	Loss: -6.4755	Cost: 27.04s
Train Epoch: 811 [20480/90000 (23%)]	Loss: -12.4110	Cost: 9.33s
Train Epoch: 811 [40960/90000 (45%)]	Loss: -12.0807	Cost: 9.40s
Train Epoch: 811 [61440/90000 (68%)]	Loss: -12.0795	Cost: 9.24s
Train Epoch: 811 [81920/90000 (91%)]	Loss: -11.9405	Cost: 8.78s
Train Epoch: 811 	Average Loss: -11.8675
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1059

Learning rate: 0.00019677179687728943
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 812 [0/90000 (0%)]	Loss: -6.0016	Cost: 24.88s
Train Epoch: 812 [20480/90000 (23%)]	Loss: -12.2456	Cost: 9.33s
Train Epoch: 812 [40960/90000 (45%)]	Loss: -12.2334	Cost: 9.35s
Train Epoch: 812 [61440/90000 (68%)]	Loss: -12.1004	Cost: 9.28s
Train Epoch: 812 [81920/90000 (91%)]	Loss: -12.0568	Cost: 8.82s
Train Epoch: 812 	Average Loss: -11.8612
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1590

Learning rate: 0.00019676387417069913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 813 [0/90000 (0%)]	Loss: -7.0775	Cost: 24.08s
Train Epoch: 813 [20480/90000 (23%)]	Loss: -12.4291	Cost: 9.37s
Train Epoch: 813 [40960/90000 (45%)]	Loss: -12.1857	Cost: 9.44s
Train Epoch: 813 [61440/90000 (68%)]	Loss: -12.3518	Cost: 9.18s
Train Epoch: 813 [81920/90000 (91%)]	Loss: -11.8848	Cost: 8.89s
Train Epoch: 813 	Average Loss: -11.9807
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9899

Learning rate: 0.0001967559419138973
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 814 [0/90000 (0%)]	Loss: -6.8828	Cost: 26.88s
Train Epoch: 814 [20480/90000 (23%)]	Loss: -12.1989	Cost: 9.35s
Train Epoch: 814 [40960/90000 (45%)]	Loss: -11.9440	Cost: 9.26s
Train Epoch: 814 [61440/90000 (68%)]	Loss: -12.1706	Cost: 9.19s
Train Epoch: 814 [81920/90000 (91%)]	Loss: -12.0306	Cost: 8.80s
Train Epoch: 814 	Average Loss: -11.8130
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9496

Learning rate: 0.00019674800010766687
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 815 [0/90000 (0%)]	Loss: -6.7079	Cost: 26.29s
Train Epoch: 815 [20480/90000 (23%)]	Loss: -12.1520	Cost: 9.38s
Train Epoch: 815 [40960/90000 (45%)]	Loss: -11.8789	Cost: 9.50s
Train Epoch: 815 [61440/90000 (68%)]	Loss: -11.9901	Cost: 9.08s
Train Epoch: 815 [81920/90000 (91%)]	Loss: -12.0402	Cost: 8.78s
Train Epoch: 815 	Average Loss: -11.8138
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8719

Learning rate: 0.00019674004875279162
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 816 [0/90000 (0%)]	Loss: -6.9199	Cost: 26.81s
Train Epoch: 816 [20480/90000 (23%)]	Loss: -12.4551	Cost: 9.28s
Train Epoch: 816 [40960/90000 (45%)]	Loss: -12.2503	Cost: 9.30s
Train Epoch: 816 [61440/90000 (68%)]	Loss: -12.4551	Cost: 9.28s
Train Epoch: 816 [81920/90000 (91%)]	Loss: -11.8847	Cost: 8.77s
Train Epoch: 816 	Average Loss: -12.0355
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9440

Learning rate: 0.00019673208785005636
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 817 [0/90000 (0%)]	Loss: -7.7679	Cost: 26.78s
Train Epoch: 817 [20480/90000 (23%)]	Loss: -12.3300	Cost: 9.42s
Train Epoch: 817 [40960/90000 (45%)]	Loss: -12.0848	Cost: 9.49s
Train Epoch: 817 [61440/90000 (68%)]	Loss: -12.1469	Cost: 9.06s
Train Epoch: 817 [81920/90000 (91%)]	Loss: -11.6889	Cost: 8.71s
Train Epoch: 817 	Average Loss: -11.8314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0350

Learning rate: 0.00019672411740024673
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 818 [0/90000 (0%)]	Loss: -6.7867	Cost: 23.84s
Train Epoch: 818 [20480/90000 (23%)]	Loss: -12.4679	Cost: 9.76s
Train Epoch: 818 [40960/90000 (45%)]	Loss: -12.3615	Cost: 9.31s
Train Epoch: 818 [61440/90000 (68%)]	Loss: -12.3139	Cost: 9.17s
Train Epoch: 818 [81920/90000 (91%)]	Loss: -12.0320	Cost: 8.89s
Train Epoch: 818 	Average Loss: -11.9290
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9733

Learning rate: 0.0001967161374041495
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 819 [0/90000 (0%)]	Loss: -6.5001	Cost: 24.50s
Train Epoch: 819 [20480/90000 (23%)]	Loss: -12.3937	Cost: 9.40s
Train Epoch: 819 [40960/90000 (45%)]	Loss: -12.1685	Cost: 9.51s
Train Epoch: 819 [61440/90000 (68%)]	Loss: -12.0951	Cost: 9.08s
Train Epoch: 819 [81920/90000 (91%)]	Loss: -11.8564	Cost: 8.91s
Train Epoch: 819 	Average Loss: -11.8884
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0007

Learning rate: 0.00019670814786255217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 820 [0/90000 (0%)]	Loss: -6.9240	Cost: 24.24s
Train Epoch: 820 [20480/90000 (23%)]	Loss: -12.4363	Cost: 9.40s
Train Epoch: 820 [40960/90000 (45%)]	Loss: -12.4666	Cost: 9.32s
Train Epoch: 820 [61440/90000 (68%)]	Loss: -12.3802	Cost: 9.14s
Train Epoch: 820 [81920/90000 (91%)]	Loss: -12.0275	Cost: 9.05s
Train Epoch: 820 	Average Loss: -12.0929
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1860

Learning rate: 0.0001967001487762433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 821 [0/90000 (0%)]	Loss: -6.7621	Cost: 24.12s
Train Epoch: 821 [20480/90000 (23%)]	Loss: -12.7464	Cost: 9.38s
Train Epoch: 821 [40960/90000 (45%)]	Loss: -12.3975	Cost: 9.27s
Train Epoch: 821 [61440/90000 (68%)]	Loss: -12.5656	Cost: 9.37s
Train Epoch: 821 [81920/90000 (91%)]	Loss: -11.9872	Cost: 8.90s
Train Epoch: 821 	Average Loss: -12.0960
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9817

Learning rate: 0.00019669214014601236
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 822 [0/90000 (0%)]	Loss: -6.9188	Cost: 24.40s
Train Epoch: 822 [20480/90000 (23%)]	Loss: -12.7373	Cost: 9.39s
Train Epoch: 822 [40960/90000 (45%)]	Loss: -12.0576	Cost: 9.34s
Train Epoch: 822 [61440/90000 (68%)]	Loss: -12.2861	Cost: 9.28s
Train Epoch: 822 [81920/90000 (91%)]	Loss: -11.9908	Cost: 8.99s
Train Epoch: 822 	Average Loss: -12.0003
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0256

Learning rate: 0.00019668412197264976
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 823 [0/90000 (0%)]	Loss: -7.0332	Cost: 24.55s
Train Epoch: 823 [20480/90000 (23%)]	Loss: -11.8053	Cost: 9.40s
Train Epoch: 823 [40960/90000 (45%)]	Loss: -11.5705	Cost: 9.36s
Train Epoch: 823 [61440/90000 (68%)]	Loss: -12.0516	Cost: 9.16s
Train Epoch: 823 [81920/90000 (91%)]	Loss: -11.6023	Cost: 9.18s
Train Epoch: 823 	Average Loss: -11.4753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9165

Learning rate: 0.0001966760942569469
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 824 [0/90000 (0%)]	Loss: -6.4926	Cost: 24.14s
Train Epoch: 824 [20480/90000 (23%)]	Loss: -12.3922	Cost: 9.36s
Train Epoch: 824 [40960/90000 (45%)]	Loss: -11.9787	Cost: 9.35s
Train Epoch: 824 [61440/90000 (68%)]	Loss: -12.1542	Cost: 9.10s
Train Epoch: 824 [81920/90000 (91%)]	Loss: -11.9827	Cost: 9.03s
Train Epoch: 824 	Average Loss: -11.8480
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0334

Learning rate: 0.00019666805699969608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 825 [0/90000 (0%)]	Loss: -6.6665	Cost: 23.95s
Train Epoch: 825 [20480/90000 (23%)]	Loss: -11.9269	Cost: 9.63s
Train Epoch: 825 [40960/90000 (45%)]	Loss: -11.5821	Cost: 9.27s
Train Epoch: 825 [61440/90000 (68%)]	Loss: -11.8239	Cost: 8.93s
Train Epoch: 825 [81920/90000 (91%)]	Loss: -11.8438	Cost: 9.12s
Train Epoch: 825 	Average Loss: -11.5576
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0056

Learning rate: 0.00019666001020169052
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 826 [0/90000 (0%)]	Loss: -6.4566	Cost: 24.20s
Train Epoch: 826 [20480/90000 (23%)]	Loss: -12.5209	Cost: 9.43s
Train Epoch: 826 [40960/90000 (45%)]	Loss: -12.4334	Cost: 9.24s
Train Epoch: 826 [61440/90000 (68%)]	Loss: -12.4065	Cost: 9.03s
Train Epoch: 826 [81920/90000 (91%)]	Loss: -12.1181	Cost: 8.89s
Train Epoch: 826 	Average Loss: -12.0376
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1815

Learning rate: 0.00019665195386372441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 827 [0/90000 (0%)]	Loss: -7.3525	Cost: 24.01s
Train Epoch: 827 [20480/90000 (23%)]	Loss: -12.4344	Cost: 9.35s
Train Epoch: 827 [40960/90000 (45%)]	Loss: -12.2542	Cost: 9.16s
Train Epoch: 827 [61440/90000 (68%)]	Loss: -12.4553	Cost: 8.93s
Train Epoch: 827 [81920/90000 (91%)]	Loss: -12.2779	Cost: 8.67s
Train Epoch: 827 	Average Loss: -12.0920
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3009

Learning rate: 0.00019664388798659287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 828 [0/90000 (0%)]	Loss: -6.8063	Cost: 23.77s
Train Epoch: 828 [20480/90000 (23%)]	Loss: -12.7501	Cost: 9.13s
Train Epoch: 828 [40960/90000 (45%)]	Loss: -11.9768	Cost: 9.03s
Train Epoch: 828 [61440/90000 (68%)]	Loss: -12.0902	Cost: 9.02s
Train Epoch: 828 [81920/90000 (91%)]	Loss: -11.9824	Cost: 8.64s
Train Epoch: 828 	Average Loss: -12.0565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2815

Learning rate: 0.00019663581257109203
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 829 [0/90000 (0%)]	Loss: -7.0037	Cost: 22.58s
Train Epoch: 829 [20480/90000 (23%)]	Loss: -12.7301	Cost: 9.07s
Train Epoch: 829 [40960/90000 (45%)]	Loss: -11.4748	Cost: 9.35s
Train Epoch: 829 [61440/90000 (68%)]	Loss: -11.7748	Cost: 9.01s
Train Epoch: 829 [81920/90000 (91%)]	Loss: -11.3804	Cost: 9.77s
Train Epoch: 829 	Average Loss: -11.6177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6741

Learning rate: 0.00019662772761801884
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 830 [0/90000 (0%)]	Loss: -6.4981	Cost: 23.27s
Train Epoch: 830 [20480/90000 (23%)]	Loss: -11.9630	Cost: 9.12s
Train Epoch: 830 [40960/90000 (45%)]	Loss: -11.9802	Cost: 9.17s
Train Epoch: 830 [61440/90000 (68%)]	Loss: -12.1553	Cost: 9.05s
Train Epoch: 830 [81920/90000 (91%)]	Loss: -11.6396	Cost: 9.70s
Train Epoch: 830 	Average Loss: -11.7367
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1624

Learning rate: 0.00019661963312817126
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 831 [0/90000 (0%)]	Loss: -6.6943	Cost: 22.70s
Train Epoch: 831 [20480/90000 (23%)]	Loss: -12.3626	Cost: 9.25s
Train Epoch: 831 [40960/90000 (45%)]	Loss: -12.2987	Cost: 9.28s
Train Epoch: 831 [61440/90000 (68%)]	Loss: -12.2373	Cost: 9.15s
Train Epoch: 831 [81920/90000 (91%)]	Loss: -12.1354	Cost: 9.31s
Train Epoch: 831 	Average Loss: -12.0326
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3186

Learning rate: 0.00019661152910234822
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 832 [0/90000 (0%)]	Loss: -7.0931	Cost: 23.97s
Train Epoch: 832 [20480/90000 (23%)]	Loss: -12.5017	Cost: 9.04s
Train Epoch: 832 [40960/90000 (45%)]	Loss: -12.0378	Cost: 9.53s
Train Epoch: 832 [61440/90000 (68%)]	Loss: -12.0852	Cost: 9.11s
Train Epoch: 832 [81920/90000 (91%)]	Loss: -12.0653	Cost: 9.30s
Train Epoch: 832 	Average Loss: -11.9605
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4720

Learning rate: 0.0001966034155413495
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 833 [0/90000 (0%)]	Loss: -7.2351	Cost: 22.18s
Train Epoch: 833 [20480/90000 (23%)]	Loss: -12.6556	Cost: 9.32s
Train Epoch: 833 [40960/90000 (45%)]	Loss: -12.2811	Cost: 9.34s
Train Epoch: 833 [61440/90000 (68%)]	Loss: -12.3056	Cost: 9.31s
Train Epoch: 833 [81920/90000 (91%)]	Loss: -12.1086	Cost: 9.15s
Train Epoch: 833 	Average Loss: -12.0943
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0879

Learning rate: 0.00019659529244597592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 834 [0/90000 (0%)]	Loss: -6.7485	Cost: 22.63s
Train Epoch: 834 [20480/90000 (23%)]	Loss: -12.5976	Cost: 9.35s
Train Epoch: 834 [40960/90000 (45%)]	Loss: -11.7345	Cost: 9.47s
Train Epoch: 834 [61440/90000 (68%)]	Loss: -11.7000	Cost: 9.03s
Train Epoch: 834 [81920/90000 (91%)]	Loss: -11.6088	Cost: 9.15s
Train Epoch: 834 	Average Loss: -11.7258
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0375

Learning rate: 0.00019658715981702915
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 835 [0/90000 (0%)]	Loss: -6.5795	Cost: 23.30s
Train Epoch: 835 [20480/90000 (23%)]	Loss: -12.4124	Cost: 9.31s
Train Epoch: 835 [40960/90000 (45%)]	Loss: -12.0815	Cost: 9.37s
Train Epoch: 835 [61440/90000 (68%)]	Loss: -12.1765	Cost: 9.10s
Train Epoch: 835 [81920/90000 (91%)]	Loss: -12.0919	Cost: 9.05s
Train Epoch: 835 	Average Loss: -11.9488
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0682

Learning rate: 0.00019657901765531195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 836 [0/90000 (0%)]	Loss: -7.1693	Cost: 24.55s
Train Epoch: 836 [20480/90000 (23%)]	Loss: -12.2717	Cost: 9.33s
Train Epoch: 836 [40960/90000 (45%)]	Loss: -12.1515	Cost: 9.31s
Train Epoch: 836 [61440/90000 (68%)]	Loss: -12.0142	Cost: 9.37s
Train Epoch: 836 [81920/90000 (91%)]	Loss: -11.8703	Cost: 8.70s
Train Epoch: 836 	Average Loss: -11.9083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1649

Learning rate: 0.0001965708659616278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 837 [0/90000 (0%)]	Loss: -7.3641	Cost: 23.61s
Train Epoch: 837 [20480/90000 (23%)]	Loss: -12.5922	Cost: 9.36s
Train Epoch: 837 [40960/90000 (45%)]	Loss: -12.1736	Cost: 9.32s
Train Epoch: 837 [61440/90000 (68%)]	Loss: -12.0939	Cost: 9.09s
Train Epoch: 837 [81920/90000 (91%)]	Loss: -11.9981	Cost: 8.77s
Train Epoch: 837 	Average Loss: -11.9594
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1189

Learning rate: 0.00019656270473678128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 838 [0/90000 (0%)]	Loss: -7.0331	Cost: 24.32s
Train Epoch: 838 [20480/90000 (23%)]	Loss: -12.5069	Cost: 9.39s
Train Epoch: 838 [40960/90000 (45%)]	Loss: -12.2047	Cost: 9.24s
Train Epoch: 838 [61440/90000 (68%)]	Loss: -12.3614	Cost: 9.18s
Train Epoch: 838 [81920/90000 (91%)]	Loss: -11.3770	Cost: 9.06s
Train Epoch: 838 	Average Loss: -11.9163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6331

Learning rate: 0.0001965545339815779
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 839 [0/90000 (0%)]	Loss: -6.5335	Cost: 23.68s
Train Epoch: 839 [20480/90000 (23%)]	Loss: -12.0408	Cost: 9.38s
Train Epoch: 839 [40960/90000 (45%)]	Loss: -11.7476	Cost: 9.36s
Train Epoch: 839 [61440/90000 (68%)]	Loss: -11.7910	Cost: 9.12s
Train Epoch: 839 [81920/90000 (91%)]	Loss: -11.7849	Cost: 8.93s
Train Epoch: 839 	Average Loss: -11.5622
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1765

Learning rate: 0.00019654635369682408
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 840 [0/90000 (0%)]	Loss: -6.3518	Cost: 24.00s
Train Epoch: 840 [20480/90000 (23%)]	Loss: -12.5418	Cost: 9.33s
Train Epoch: 840 [40960/90000 (45%)]	Loss: -12.3772	Cost: 9.32s
Train Epoch: 840 [61440/90000 (68%)]	Loss: -12.3356	Cost: 9.07s
Train Epoch: 840 [81920/90000 (91%)]	Loss: -12.1660	Cost: 9.01s
Train Epoch: 840 	Average Loss: -12.1058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2866

Learning rate: 0.00019653816388332714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 841 [0/90000 (0%)]	Loss: -7.1776	Cost: 24.56s
Train Epoch: 841 [20480/90000 (23%)]	Loss: -12.8780	Cost: 9.39s
Train Epoch: 841 [40960/90000 (45%)]	Loss: -12.7182	Cost: 9.34s
Train Epoch: 841 [61440/90000 (68%)]	Loss: -12.5882	Cost: 9.02s
Train Epoch: 841 [81920/90000 (91%)]	Loss: -12.3497	Cost: 9.08s
Train Epoch: 841 	Average Loss: -12.3456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2923

Learning rate: 0.00019652996454189544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 842 [0/90000 (0%)]	Loss: -7.3600	Cost: 25.02s
Train Epoch: 842 [20480/90000 (23%)]	Loss: -12.7137	Cost: 9.63s
Train Epoch: 842 [40960/90000 (45%)]	Loss: -12.6613	Cost: 9.69s
Train Epoch: 842 [61440/90000 (68%)]	Loss: -12.7941	Cost: 9.00s
Train Epoch: 842 [81920/90000 (91%)]	Loss: -12.0637	Cost: 9.10s
Train Epoch: 842 	Average Loss: -12.2867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1531

Learning rate: 0.00019652175567333815
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 843 [0/90000 (0%)]	Loss: -6.4763	Cost: 24.23s
Train Epoch: 843 [20480/90000 (23%)]	Loss: -12.6569	Cost: 10.13s
Train Epoch: 843 [40960/90000 (45%)]	Loss: -12.2818	Cost: 9.41s
Train Epoch: 843 [61440/90000 (68%)]	Loss: -12.1203	Cost: 8.97s
Train Epoch: 843 [81920/90000 (91%)]	Loss: -12.2829	Cost: 9.16s
Train Epoch: 843 	Average Loss: -12.0364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2191

Learning rate: 0.00019651353727846553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 844 [0/90000 (0%)]	Loss: -7.5069	Cost: 24.38s
Train Epoch: 844 [20480/90000 (23%)]	Loss: -12.6357	Cost: 9.45s
Train Epoch: 844 [40960/90000 (45%)]	Loss: -12.4468	Cost: 9.24s
Train Epoch: 844 [61440/90000 (68%)]	Loss: -12.3289	Cost: 9.10s
Train Epoch: 844 [81920/90000 (91%)]	Loss: -12.1314	Cost: 8.81s
Train Epoch: 844 	Average Loss: -12.1641
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1002

Learning rate: 0.00019650530935808866
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 845 [0/90000 (0%)]	Loss: -6.4750	Cost: 24.04s
Train Epoch: 845 [20480/90000 (23%)]	Loss: -12.7401	Cost: 9.11s
Train Epoch: 845 [40960/90000 (45%)]	Loss: -12.4689	Cost: 9.03s
Train Epoch: 845 [61440/90000 (68%)]	Loss: -12.1082	Cost: 8.92s
Train Epoch: 845 [81920/90000 (91%)]	Loss: -11.9340	Cost: 8.63s
Train Epoch: 845 	Average Loss: -12.0922
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1845

Learning rate: 0.00019649707191301958
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 846 [0/90000 (0%)]	Loss: -6.9585	Cost: 24.50s
Train Epoch: 846 [20480/90000 (23%)]	Loss: -12.7108	Cost: 9.05s
Train Epoch: 846 [40960/90000 (45%)]	Loss: -12.6473	Cost: 9.51s
Train Epoch: 846 [61440/90000 (68%)]	Loss: -12.1923	Cost: 8.99s
Train Epoch: 846 [81920/90000 (91%)]	Loss: -11.9278	Cost: 9.16s
Train Epoch: 846 	Average Loss: -12.0630
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9730

Learning rate: 0.00019648882494407134
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 847 [0/90000 (0%)]	Loss: -6.7903	Cost: 23.16s
Train Epoch: 847 [20480/90000 (23%)]	Loss: -12.6116	Cost: 9.08s
Train Epoch: 847 [40960/90000 (45%)]	Loss: -12.2788	Cost: 9.14s
Train Epoch: 847 [61440/90000 (68%)]	Loss: -12.3460	Cost: 9.07s
Train Epoch: 847 [81920/90000 (91%)]	Loss: -11.8590	Cost: 9.76s
Train Epoch: 847 	Average Loss: -11.9764
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1184

Learning rate: 0.0001964805684520579
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 848 [0/90000 (0%)]	Loss: -6.7679	Cost: 23.34s
Train Epoch: 848 [20480/90000 (23%)]	Loss: -12.2340	Cost: 9.08s
Train Epoch: 848 [40960/90000 (45%)]	Loss: -11.9262	Cost: 9.36s
Train Epoch: 848 [61440/90000 (68%)]	Loss: -11.8811	Cost: 9.05s
Train Epoch: 848 [81920/90000 (91%)]	Loss: -11.6338	Cost: 9.74s
Train Epoch: 848 	Average Loss: -11.6308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8583

Learning rate: 0.00019647230243779407
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 849 [0/90000 (0%)]	Loss: -6.8026	Cost: 24.32s
Train Epoch: 849 [20480/90000 (23%)]	Loss: -12.2707	Cost: 9.41s
Train Epoch: 849 [40960/90000 (45%)]	Loss: -12.3642	Cost: 9.47s
Train Epoch: 849 [61440/90000 (68%)]	Loss: -12.0282	Cost: 9.07s
Train Epoch: 849 [81920/90000 (91%)]	Loss: -11.9958	Cost: 9.07s
Train Epoch: 849 	Average Loss: -11.9510
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1992

Learning rate: 0.00019646402690209574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 850 [0/90000 (0%)]	Loss: -7.0625	Cost: 22.60s
Train Epoch: 850 [20480/90000 (23%)]	Loss: -12.6004	Cost: 9.38s
Train Epoch: 850 [40960/90000 (45%)]	Loss: -12.4238	Cost: 9.39s
Train Epoch: 850 [61440/90000 (68%)]	Loss: -12.5716	Cost: 9.29s
Train Epoch: 850 [81920/90000 (91%)]	Loss: -12.3687	Cost: 9.08s
Train Epoch: 850 	Average Loss: -12.2080
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2826

Saving model as model.pt_e850 & waveforms_supplementary.hdf5_e850
Learning rate: 0.0001964557418457796
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 851 [0/90000 (0%)]	Loss: -7.1489	Cost: 22.88s
Train Epoch: 851 [20480/90000 (23%)]	Loss: -12.2389	Cost: 9.47s
Train Epoch: 851 [40960/90000 (45%)]	Loss: -12.3131	Cost: 9.29s
Train Epoch: 851 [61440/90000 (68%)]	Loss: -12.3540	Cost: 9.25s
Train Epoch: 851 [81920/90000 (91%)]	Loss: -11.5373	Cost: 9.05s
Train Epoch: 851 	Average Loss: -11.8460
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5544

Learning rate: 0.0001964474472696634
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 852 [0/90000 (0%)]	Loss: -6.4023	Cost: 22.46s
Train Epoch: 852 [20480/90000 (23%)]	Loss: -11.9516	Cost: 9.42s
Train Epoch: 852 [40960/90000 (45%)]	Loss: -11.9465	Cost: 9.26s
Train Epoch: 852 [61440/90000 (68%)]	Loss: -11.8717	Cost: 9.18s
Train Epoch: 852 [81920/90000 (91%)]	Loss: -11.9455	Cost: 9.13s
Train Epoch: 852 	Average Loss: -11.6587
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0734

Learning rate: 0.00019643914317456578
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 853 [0/90000 (0%)]	Loss: -6.3559	Cost: 23.31s
Train Epoch: 853 [20480/90000 (23%)]	Loss: -12.6567	Cost: 9.51s
Train Epoch: 853 [40960/90000 (45%)]	Loss: -12.4469	Cost: 9.32s
Train Epoch: 853 [61440/90000 (68%)]	Loss: -12.2459	Cost: 9.04s
Train Epoch: 853 [81920/90000 (91%)]	Loss: -12.2325	Cost: 9.02s
Train Epoch: 853 	Average Loss: -12.0588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3315

Learning rate: 0.00019643082956130633
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 854 [0/90000 (0%)]	Loss: -6.6992	Cost: 22.19s
Train Epoch: 854 [20480/90000 (23%)]	Loss: -12.7743	Cost: 9.13s
Train Epoch: 854 [40960/90000 (45%)]	Loss: -12.7556	Cost: 9.06s
Train Epoch: 854 [61440/90000 (68%)]	Loss: -12.6539	Cost: 8.91s
Train Epoch: 854 [81920/90000 (91%)]	Loss: -12.4122	Cost: 8.89s
Train Epoch: 854 	Average Loss: -12.3157
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4205

Learning rate: 0.00019642250643070558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 855 [0/90000 (0%)]	Loss: -7.3827	Cost: 23.21s
Train Epoch: 855 [20480/90000 (23%)]	Loss: -12.9490	Cost: 9.35s
Train Epoch: 855 [40960/90000 (45%)]	Loss: -12.5550	Cost: 9.46s
Train Epoch: 855 [61440/90000 (68%)]	Loss: -12.5079	Cost: 9.15s
Train Epoch: 855 [81920/90000 (91%)]	Loss: -12.5318	Cost: 8.99s
Train Epoch: 855 	Average Loss: -12.3401
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5183

Learning rate: 0.00019641417378358494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 856 [0/90000 (0%)]	Loss: -7.5777	Cost: 23.53s
Train Epoch: 856 [20480/90000 (23%)]	Loss: -12.9796	Cost: 9.35s
Train Epoch: 856 [40960/90000 (45%)]	Loss: -12.6891	Cost: 9.64s
Train Epoch: 856 [61440/90000 (68%)]	Loss: -12.5996	Cost: 9.43s
Train Epoch: 856 [81920/90000 (91%)]	Loss: -12.6312	Cost: 8.76s
Train Epoch: 856 	Average Loss: -12.4337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6040

Learning rate: 0.00019640583162076685
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 857 [0/90000 (0%)]	Loss: -7.1746	Cost: 25.09s
Train Epoch: 857 [20480/90000 (23%)]	Loss: -13.2914	Cost: 9.36s
Train Epoch: 857 [40960/90000 (45%)]	Loss: -12.9339	Cost: 9.30s
Train Epoch: 857 [61440/90000 (68%)]	Loss: -12.8523	Cost: 9.27s
Train Epoch: 857 [81920/90000 (91%)]	Loss: -12.7256	Cost: 8.80s
Train Epoch: 857 	Average Loss: -12.5427
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6524

Learning rate: 0.00019639747994307463
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 858 [0/90000 (0%)]	Loss: -6.9684	Cost: 24.45s
Train Epoch: 858 [20480/90000 (23%)]	Loss: -13.3029	Cost: 9.35s
Train Epoch: 858 [40960/90000 (45%)]	Loss: -12.7209	Cost: 9.37s
Train Epoch: 858 [61440/90000 (68%)]	Loss: -12.7513	Cost: 9.12s
Train Epoch: 858 [81920/90000 (91%)]	Loss: -12.6548	Cost: 8.76s
Train Epoch: 858 	Average Loss: -12.5670
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6832

Learning rate: 0.0001963891187513326
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 859 [0/90000 (0%)]	Loss: -7.5745	Cost: 26.23s
Train Epoch: 859 [20480/90000 (23%)]	Loss: -13.0775	Cost: 9.32s
Train Epoch: 859 [40960/90000 (45%)]	Loss: -12.9653	Cost: 9.35s
Train Epoch: 859 [61440/90000 (68%)]	Loss: -12.9973	Cost: 9.20s
Train Epoch: 859 [81920/90000 (91%)]	Loss: -12.7137	Cost: 9.15s
Train Epoch: 859 	Average Loss: -12.6542
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5479

Learning rate: 0.0001963807480463659
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 860 [0/90000 (0%)]	Loss: -7.6776	Cost: 26.34s
Train Epoch: 860 [20480/90000 (23%)]	Loss: -12.9302	Cost: 9.29s
Train Epoch: 860 [40960/90000 (45%)]	Loss: -12.6734	Cost: 9.32s
Train Epoch: 860 [61440/90000 (68%)]	Loss: -12.8263	Cost: 9.09s
Train Epoch: 860 [81920/90000 (91%)]	Loss: -12.8032	Cost: 8.81s
Train Epoch: 860 	Average Loss: -12.5147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6905

Learning rate: 0.00019637236782900076
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 861 [0/90000 (0%)]	Loss: -7.2864	Cost: 26.09s
Train Epoch: 861 [20480/90000 (23%)]	Loss: -13.1322	Cost: 9.30s
Train Epoch: 861 [40960/90000 (45%)]	Loss: -12.6184	Cost: 9.31s
Train Epoch: 861 [61440/90000 (68%)]	Loss: -12.5294	Cost: 9.17s
Train Epoch: 861 [81920/90000 (91%)]	Loss: -12.4330	Cost: 8.70s
Train Epoch: 861 	Average Loss: -12.4654
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6636

Learning rate: 0.0001963639781000642
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 862 [0/90000 (0%)]	Loss: -7.3101	Cost: 23.85s
Train Epoch: 862 [20480/90000 (23%)]	Loss: -13.1948	Cost: 9.35s
Train Epoch: 862 [40960/90000 (45%)]	Loss: -12.6271	Cost: 9.23s
Train Epoch: 862 [61440/90000 (68%)]	Loss: -12.6838	Cost: 9.17s
Train Epoch: 862 [81920/90000 (91%)]	Loss: -12.6717	Cost: 8.85s
Train Epoch: 862 	Average Loss: -12.4604
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7284

Learning rate: 0.00019635557886038432
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 863 [0/90000 (0%)]	Loss: -7.2170	Cost: 24.62s
Train Epoch: 863 [20480/90000 (23%)]	Loss: -13.2988	Cost: 9.39s
Train Epoch: 863 [40960/90000 (45%)]	Loss: -12.9805	Cost: 9.24s
Train Epoch: 863 [61440/90000 (68%)]	Loss: -12.6404	Cost: 9.19s
Train Epoch: 863 [81920/90000 (91%)]	Loss: -12.3228	Cost: 8.93s
Train Epoch: 863 	Average Loss: -12.6012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4292

Learning rate: 0.00019634717011079007
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 864 [0/90000 (0%)]	Loss: -7.2094	Cost: 25.52s
Train Epoch: 864 [20480/90000 (23%)]	Loss: -12.8102	Cost: 9.38s
Train Epoch: 864 [40960/90000 (45%)]	Loss: -12.6868	Cost: 9.23s
Train Epoch: 864 [61440/90000 (68%)]	Loss: -12.7028	Cost: 9.11s
Train Epoch: 864 [81920/90000 (91%)]	Loss: -12.5259	Cost: 8.88s
Train Epoch: 864 	Average Loss: -12.3822
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4099

Learning rate: 0.00019633875185211136
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 865 [0/90000 (0%)]	Loss: -6.9529	Cost: 24.64s
Train Epoch: 865 [20480/90000 (23%)]	Loss: -12.7121	Cost: 9.37s
Train Epoch: 865 [40960/90000 (45%)]	Loss: -12.5357	Cost: 9.27s
Train Epoch: 865 [61440/90000 (68%)]	Loss: -12.6585	Cost: 9.21s
Train Epoch: 865 [81920/90000 (91%)]	Loss: -12.5423	Cost: 9.03s
Train Epoch: 865 	Average Loss: -12.3137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6528

Learning rate: 0.00019633032408517903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 866 [0/90000 (0%)]	Loss: -7.5508	Cost: 24.43s
Train Epoch: 866 [20480/90000 (23%)]	Loss: -13.2353	Cost: 9.34s
Train Epoch: 866 [40960/90000 (45%)]	Loss: -12.8569	Cost: 9.23s
Train Epoch: 866 [61440/90000 (68%)]	Loss: -12.6720	Cost: 9.52s
Train Epoch: 866 [81920/90000 (91%)]	Loss: -11.4286	Cost: 8.93s
Train Epoch: 866 	Average Loss: -12.2382
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6656

Learning rate: 0.00019632188681082487
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 867 [0/90000 (0%)]	Loss: -6.9146	Cost: 24.61s
Train Epoch: 867 [20480/90000 (23%)]	Loss: -12.1369	Cost: 9.34s
Train Epoch: 867 [40960/90000 (45%)]	Loss: -12.2783	Cost: 9.22s
Train Epoch: 867 [61440/90000 (68%)]	Loss: -12.4812	Cost: 9.59s
Train Epoch: 867 [81920/90000 (91%)]	Loss: -12.4229	Cost: 8.98s
Train Epoch: 867 	Average Loss: -11.9559
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3214

Learning rate: 0.00019631344002988158
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 868 [0/90000 (0%)]	Loss: -7.7393	Cost: 24.99s
Train Epoch: 868 [20480/90000 (23%)]	Loss: -13.0020	Cost: 9.45s
Train Epoch: 868 [40960/90000 (45%)]	Loss: -12.9294	Cost: 9.24s
Train Epoch: 868 [61440/90000 (68%)]	Loss: -12.9485	Cost: 9.17s
Train Epoch: 868 [81920/90000 (91%)]	Loss: -12.7370	Cost: 8.99s
Train Epoch: 868 	Average Loss: -12.6564
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5898

Learning rate: 0.00019630498374318287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 869 [0/90000 (0%)]	Loss: -7.3549	Cost: 25.02s
Train Epoch: 869 [20480/90000 (23%)]	Loss: -13.2391	Cost: 9.42s
Train Epoch: 869 [40960/90000 (45%)]	Loss: -12.7543	Cost: 9.23s
Train Epoch: 869 [61440/90000 (68%)]	Loss: -12.8438	Cost: 9.14s
Train Epoch: 869 [81920/90000 (91%)]	Loss: -12.8088	Cost: 9.08s
Train Epoch: 869 	Average Loss: -12.6771
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7575

Learning rate: 0.00019629651795156333
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 870 [0/90000 (0%)]	Loss: -7.6536	Cost: 24.74s
Train Epoch: 870 [20480/90000 (23%)]	Loss: -12.7578	Cost: 9.35s
Train Epoch: 870 [40960/90000 (45%)]	Loss: -12.6504	Cost: 9.55s
Train Epoch: 870 [61440/90000 (68%)]	Loss: -12.5845	Cost: 9.10s
Train Epoch: 870 [81920/90000 (91%)]	Loss: -12.5475	Cost: 8.98s
Train Epoch: 870 	Average Loss: -12.4396
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5154

Learning rate: 0.00019628804265585853
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 871 [0/90000 (0%)]	Loss: -7.4799	Cost: 23.80s
Train Epoch: 871 [20480/90000 (23%)]	Loss: -13.1094	Cost: 9.34s
Train Epoch: 871 [40960/90000 (45%)]	Loss: -13.0302	Cost: 9.31s
Train Epoch: 871 [61440/90000 (68%)]	Loss: -12.9160	Cost: 9.09s
Train Epoch: 871 [81920/90000 (91%)]	Loss: -12.7604	Cost: 9.09s
Train Epoch: 871 	Average Loss: -12.6772
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6959

Learning rate: 0.00019627955785690487
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 872 [0/90000 (0%)]	Loss: -7.6319	Cost: 24.59s
Train Epoch: 872 [20480/90000 (23%)]	Loss: -13.2394	Cost: 9.47s
Train Epoch: 872 [40960/90000 (45%)]	Loss: -13.1497	Cost: 9.26s
Train Epoch: 872 [61440/90000 (68%)]	Loss: -12.4752	Cost: 9.14s
Train Epoch: 872 [81920/90000 (91%)]	Loss: -12.7315	Cost: 8.89s
Train Epoch: 872 	Average Loss: -12.6541
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6147

Learning rate: 0.00019627106355553982
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 873 [0/90000 (0%)]	Loss: -7.0731	Cost: 24.16s
Train Epoch: 873 [20480/90000 (23%)]	Loss: -13.1521	Cost: 9.40s
Train Epoch: 873 [40960/90000 (45%)]	Loss: -13.1113	Cost: 9.21s
Train Epoch: 873 [61440/90000 (68%)]	Loss: -12.7560	Cost: 9.06s
Train Epoch: 873 [81920/90000 (91%)]	Loss: -12.7440	Cost: 8.89s
Train Epoch: 873 	Average Loss: -12.7479
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6931

Learning rate: 0.00019626255975260172
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 874 [0/90000 (0%)]	Loss: -7.5152	Cost: 23.93s
Train Epoch: 874 [20480/90000 (23%)]	Loss: -13.2271	Cost: 9.12s
Train Epoch: 874 [40960/90000 (45%)]	Loss: -13.2538	Cost: 9.07s
Train Epoch: 874 [61440/90000 (68%)]	Loss: -13.2507	Cost: 8.96s
Train Epoch: 874 [81920/90000 (91%)]	Loss: -12.6848	Cost: 8.79s
Train Epoch: 874 	Average Loss: -12.8349
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8023

Learning rate: 0.00019625404644892983
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 875 [0/90000 (0%)]	Loss: -7.5591	Cost: 24.26s
Train Epoch: 875 [20480/90000 (23%)]	Loss: -13.4139	Cost: 9.07s
Train Epoch: 875 [40960/90000 (45%)]	Loss: -13.0932	Cost: 9.44s
Train Epoch: 875 [61440/90000 (68%)]	Loss: -12.9427	Cost: 9.01s
Train Epoch: 875 [81920/90000 (91%)]	Loss: -12.3014	Cost: 8.89s
Train Epoch: 875 	Average Loss: -12.6821
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4291

Learning rate: 0.00019624552364536446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 876 [0/90000 (0%)]	Loss: -7.5071	Cost: 23.09s
Train Epoch: 876 [20480/90000 (23%)]	Loss: -13.1015	Cost: 9.12s
Train Epoch: 876 [40960/90000 (45%)]	Loss: -12.9687	Cost: 9.46s
Train Epoch: 876 [61440/90000 (68%)]	Loss: -13.0980	Cost: 9.01s
Train Epoch: 876 [81920/90000 (91%)]	Loss: -12.7746	Cost: 9.56s
Train Epoch: 876 	Average Loss: -12.6857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6536

Learning rate: 0.00019623699134274674
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 877 [0/90000 (0%)]	Loss: -7.0267	Cost: 23.49s
Train Epoch: 877 [20480/90000 (23%)]	Loss: -12.8037	Cost: 9.11s
Train Epoch: 877 [40960/90000 (45%)]	Loss: -12.6837	Cost: 9.28s
Train Epoch: 877 [61440/90000 (68%)]	Loss: -12.9426	Cost: 9.18s
Train Epoch: 877 [81920/90000 (91%)]	Loss: -12.5407	Cost: 9.86s
Train Epoch: 877 	Average Loss: -12.4908
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0741

Learning rate: 0.00019622844954191875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 878 [0/90000 (0%)]	Loss: -7.1373	Cost: 22.72s
Train Epoch: 878 [20480/90000 (23%)]	Loss: -12.3194	Cost: 9.57s
Train Epoch: 878 [40960/90000 (45%)]	Loss: -12.3148	Cost: 9.17s
Train Epoch: 878 [61440/90000 (68%)]	Loss: -12.5711	Cost: 9.13s
Train Epoch: 878 [81920/90000 (91%)]	Loss: -12.3930	Cost: 9.19s
Train Epoch: 878 	Average Loss: -12.0189
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5252

Learning rate: 0.00019621989824372354
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 879 [0/90000 (0%)]	Loss: -7.2577	Cost: 22.89s
Train Epoch: 879 [20480/90000 (23%)]	Loss: -13.1614	Cost: 9.22s
Train Epoch: 879 [40960/90000 (45%)]	Loss: -12.9901	Cost: 9.31s
Train Epoch: 879 [61440/90000 (68%)]	Loss: -12.9711	Cost: 9.11s
Train Epoch: 879 [81920/90000 (91%)]	Loss: -12.8967	Cost: 9.76s
Train Epoch: 879 	Average Loss: -12.6754
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8170

Learning rate: 0.0001962113374490051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 880 [0/90000 (0%)]	Loss: -7.6927	Cost: 22.87s
Train Epoch: 880 [20480/90000 (23%)]	Loss: -13.3209	Cost: 9.87s
Train Epoch: 880 [40960/90000 (45%)]	Loss: -13.0754	Cost: 9.39s
Train Epoch: 880 [61440/90000 (68%)]	Loss: -13.1353	Cost: 9.24s
Train Epoch: 880 [81920/90000 (91%)]	Loss: -12.8623	Cost: 9.17s
Train Epoch: 880 	Average Loss: -12.8336
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9268

Learning rate: 0.00019620276715860832
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 881 [0/90000 (0%)]	Loss: -7.3984	Cost: 22.03s
Train Epoch: 881 [20480/90000 (23%)]	Loss: -13.4164	Cost: 9.28s
Train Epoch: 881 [40960/90000 (45%)]	Loss: -13.1082	Cost: 9.48s
Train Epoch: 881 [61440/90000 (68%)]	Loss: -13.2498	Cost: 9.15s
Train Epoch: 881 [81920/90000 (91%)]	Loss: -13.0737	Cost: 9.20s
Train Epoch: 881 	Average Loss: -12.9102
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1530

Learning rate: 0.0001961941873733791
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 882 [0/90000 (0%)]	Loss: -7.8939	Cost: 23.15s
Train Epoch: 882 [20480/90000 (23%)]	Loss: -13.5243	Cost: 9.33s
Train Epoch: 882 [40960/90000 (45%)]	Loss: -12.3537	Cost: 9.36s
Train Epoch: 882 [61440/90000 (68%)]	Loss: -12.0433	Cost: 9.29s
Train Epoch: 882 [81920/90000 (91%)]	Loss: -11.9740	Cost: 9.08s
Train Epoch: 882 	Average Loss: -12.3089
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2038

Learning rate: 0.0001961855980941642
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 883 [0/90000 (0%)]	Loss: -7.1424	Cost: 23.86s
Train Epoch: 883 [20480/90000 (23%)]	Loss: -12.7864	Cost: 9.31s
Train Epoch: 883 [40960/90000 (45%)]	Loss: -12.5810	Cost: 9.27s
Train Epoch: 883 [61440/90000 (68%)]	Loss: -12.8206	Cost: 9.08s
Train Epoch: 883 [81920/90000 (91%)]	Loss: -12.6971	Cost: 8.99s
Train Epoch: 883 	Average Loss: -12.4479
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8405

Learning rate: 0.0001961769993218114
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 884 [0/90000 (0%)]	Loss: -7.5933	Cost: 23.57s
Train Epoch: 884 [20480/90000 (23%)]	Loss: -12.7678	Cost: 9.36s
Train Epoch: 884 [40960/90000 (45%)]	Loss: -12.5037	Cost: 9.24s
Train Epoch: 884 [61440/90000 (68%)]	Loss: -12.6669	Cost: 9.05s
Train Epoch: 884 [81920/90000 (91%)]	Loss: -12.7100	Cost: 8.91s
Train Epoch: 884 	Average Loss: -12.5322
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0971

Learning rate: 0.00019616839105716927
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 885 [0/90000 (0%)]	Loss: -6.7823	Cost: 24.49s
Train Epoch: 885 [20480/90000 (23%)]	Loss: -12.3405	Cost: 9.44s
Train Epoch: 885 [40960/90000 (45%)]	Loss: -12.4329	Cost: 9.51s
Train Epoch: 885 [61440/90000 (68%)]	Loss: -12.6537	Cost: 9.06s
Train Epoch: 885 [81920/90000 (91%)]	Loss: -12.6249	Cost: 8.75s
Train Epoch: 885 	Average Loss: -12.2144
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8670

Learning rate: 0.00019615977330108747
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 886 [0/90000 (0%)]	Loss: -7.6194	Cost: 23.39s
Train Epoch: 886 [20480/90000 (23%)]	Loss: -13.2917	Cost: 9.53s
Train Epoch: 886 [40960/90000 (45%)]	Loss: -12.8326	Cost: 9.30s
Train Epoch: 886 [61440/90000 (68%)]	Loss: -13.1573	Cost: 9.15s
Train Epoch: 886 [81920/90000 (91%)]	Loss: -12.9674	Cost: 8.71s
Train Epoch: 886 	Average Loss: -12.7786
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0574

Learning rate: 0.00019615114605441654
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 887 [0/90000 (0%)]	Loss: -7.6152	Cost: 24.42s
Train Epoch: 887 [20480/90000 (23%)]	Loss: -13.4933	Cost: 9.36s
Train Epoch: 887 [40960/90000 (45%)]	Loss: -13.2321	Cost: 9.27s
Train Epoch: 887 [61440/90000 (68%)]	Loss: -13.2685	Cost: 9.39s
Train Epoch: 887 [81920/90000 (91%)]	Loss: -13.0178	Cost: 8.74s
Train Epoch: 887 	Average Loss: -12.9445
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8554

Learning rate: 0.00019614250931800791
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 888 [0/90000 (0%)]	Loss: -7.8992	Cost: 24.16s
Train Epoch: 888 [20480/90000 (23%)]	Loss: -13.5318	Cost: 9.43s
Train Epoch: 888 [40960/90000 (45%)]	Loss: -13.2607	Cost: 9.25s
Train Epoch: 888 [61440/90000 (68%)]	Loss: -13.3482	Cost: 9.04s
Train Epoch: 888 [81920/90000 (91%)]	Loss: -13.1688	Cost: 9.06s
Train Epoch: 888 	Average Loss: -13.0176
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0129

Learning rate: 0.00019613386309271408
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 889 [0/90000 (0%)]	Loss: -7.7458	Cost: 24.21s
Train Epoch: 889 [20480/90000 (23%)]	Loss: -13.5630	Cost: 9.36s
Train Epoch: 889 [40960/90000 (45%)]	Loss: -13.3488	Cost: 9.58s
Train Epoch: 889 [61440/90000 (68%)]	Loss: -13.5555	Cost: 9.51s
Train Epoch: 889 [81920/90000 (91%)]	Loss: -13.3113	Cost: 9.17s
Train Epoch: 889 	Average Loss: -13.1741
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0895

Learning rate: 0.0001961252073793883
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 890 [0/90000 (0%)]	Loss: -7.5050	Cost: 24.65s
Train Epoch: 890 [20480/90000 (23%)]	Loss: -13.4358	Cost: 9.39s
Train Epoch: 890 [40960/90000 (45%)]	Loss: -13.0018	Cost: 9.27s
Train Epoch: 890 [61440/90000 (68%)]	Loss: -13.1637	Cost: 9.03s
Train Epoch: 890 [81920/90000 (91%)]	Loss: -13.0097	Cost: 9.08s
Train Epoch: 890 	Average Loss: -12.9226
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9764

Learning rate: 0.00019611654217888494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 891 [0/90000 (0%)]	Loss: -7.6989	Cost: 23.97s
Train Epoch: 891 [20480/90000 (23%)]	Loss: -13.4958	Cost: 9.52s
Train Epoch: 891 [40960/90000 (45%)]	Loss: -13.1236	Cost: 9.41s
Train Epoch: 891 [61440/90000 (68%)]	Loss: -13.1587	Cost: 9.04s
Train Epoch: 891 [81920/90000 (91%)]	Loss: -13.1841	Cost: 8.82s
Train Epoch: 891 	Average Loss: -12.9357
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9802

Learning rate: 0.00019610786749205917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 892 [0/90000 (0%)]	Loss: -8.4521	Cost: 23.98s
Train Epoch: 892 [20480/90000 (23%)]	Loss: -13.7512	Cost: 9.16s
Train Epoch: 892 [40960/90000 (45%)]	Loss: -12.9753	Cost: 9.06s
Train Epoch: 892 [61440/90000 (68%)]	Loss: -13.2902	Cost: 8.95s
Train Epoch: 892 [81920/90000 (91%)]	Loss: -13.0963	Cost: 8.64s
Train Epoch: 892 	Average Loss: -12.9792
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0291

Learning rate: 0.00019609918331976714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 893 [0/90000 (0%)]	Loss: -8.3344	Cost: 23.36s
Train Epoch: 893 [20480/90000 (23%)]	Loss: -13.6203	Cost: 9.14s
Train Epoch: 893 [40960/90000 (45%)]	Loss: -13.3812	Cost: 9.43s
Train Epoch: 893 [61440/90000 (68%)]	Loss: -13.3187	Cost: 9.03s
Train Epoch: 893 [81920/90000 (91%)]	Loss: -13.3078	Cost: 9.38s
Train Epoch: 893 	Average Loss: -13.1015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1435

Learning rate: 0.00019609048966286597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 894 [0/90000 (0%)]	Loss: -7.5608	Cost: 22.88s
Train Epoch: 894 [20480/90000 (23%)]	Loss: -13.6708	Cost: 9.06s
Train Epoch: 894 [40960/90000 (45%)]	Loss: -13.4193	Cost: 9.35s
Train Epoch: 894 [61440/90000 (68%)]	Loss: -13.3896	Cost: 9.02s
Train Epoch: 894 [81920/90000 (91%)]	Loss: -12.9322	Cost: 9.82s
Train Epoch: 894 	Average Loss: -13.1017
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8462

Learning rate: 0.0001960817865222137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 895 [0/90000 (0%)]	Loss: -7.7041	Cost: 22.69s
Train Epoch: 895 [20480/90000 (23%)]	Loss: -13.5251	Cost: 9.28s
Train Epoch: 895 [40960/90000 (45%)]	Loss: -13.5502	Cost: 9.14s
Train Epoch: 895 [61440/90000 (68%)]	Loss: -13.3584	Cost: 9.08s
Train Epoch: 895 [81920/90000 (91%)]	Loss: -13.3244	Cost: 9.11s
Train Epoch: 895 	Average Loss: -13.1165
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2473

Learning rate: 0.00019607307389866925
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 896 [0/90000 (0%)]	Loss: -8.0040	Cost: 22.66s
Train Epoch: 896 [20480/90000 (23%)]	Loss: -13.8967	Cost: 9.15s
Train Epoch: 896 [40960/90000 (45%)]	Loss: -13.6512	Cost: 9.25s
Train Epoch: 896 [61440/90000 (68%)]	Loss: -13.4756	Cost: 9.10s
Train Epoch: 896 [81920/90000 (91%)]	Loss: -13.3829	Cost: 9.03s
Train Epoch: 896 	Average Loss: -13.2335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2033

Learning rate: 0.00019606435179309254
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 897 [0/90000 (0%)]	Loss: -8.2110	Cost: 21.84s
Train Epoch: 897 [20480/90000 (23%)]	Loss: -13.3291	Cost: 9.00s
Train Epoch: 897 [40960/90000 (45%)]	Loss: -13.1444	Cost: 9.25s
Train Epoch: 897 [61440/90000 (68%)]	Loss: -13.1220	Cost: 9.23s
Train Epoch: 897 [81920/90000 (91%)]	Loss: -12.9829	Cost: 9.05s
Train Epoch: 897 	Average Loss: -12.9486
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9176

Learning rate: 0.00019605562020634444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 898 [0/90000 (0%)]	Loss: -7.7053	Cost: 22.36s
Train Epoch: 898 [20480/90000 (23%)]	Loss: -13.5418	Cost: 9.32s
Train Epoch: 898 [40960/90000 (45%)]	Loss: -13.3034	Cost: 9.81s
Train Epoch: 898 [61440/90000 (68%)]	Loss: -13.3537	Cost: 9.22s
Train Epoch: 898 [81920/90000 (91%)]	Loss: -13.1602	Cost: 9.15s
Train Epoch: 898 	Average Loss: -13.0024
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0654

Learning rate: 0.0001960468791392867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 899 [0/90000 (0%)]	Loss: -7.4615	Cost: 22.46s
Train Epoch: 899 [20480/90000 (23%)]	Loss: -13.8559	Cost: 9.35s
Train Epoch: 899 [40960/90000 (45%)]	Loss: -13.3988	Cost: 9.23s
Train Epoch: 899 [61440/90000 (68%)]	Loss: -13.4947	Cost: 9.06s
Train Epoch: 899 [81920/90000 (91%)]	Loss: -13.3122	Cost: 9.05s
Train Epoch: 899 	Average Loss: -13.1026
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0950

Learning rate: 0.000196038128592782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 900 [0/90000 (0%)]	Loss: -8.0105	Cost: 23.13s
Train Epoch: 900 [20480/90000 (23%)]	Loss: -13.7329	Cost: 9.30s
Train Epoch: 900 [40960/90000 (45%)]	Loss: -13.5796	Cost: 9.57s
Train Epoch: 900 [61440/90000 (68%)]	Loss: -13.6535	Cost: 9.05s
Train Epoch: 900 [81920/90000 (91%)]	Loss: -13.3593	Cost: 8.94s
Train Epoch: 900 	Average Loss: -13.2362
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0546

Saving model as model.pt_e900 & waveforms_supplementary.hdf5_e900
Learning rate: 0.00019602936856769404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 901 [0/90000 (0%)]	Loss: -7.9895	Cost: 23.10s
Train Epoch: 901 [20480/90000 (23%)]	Loss: -13.3697	Cost: 9.34s
Train Epoch: 901 [40960/90000 (45%)]	Loss: -12.2055	Cost: 9.25s
Train Epoch: 901 [61440/90000 (68%)]	Loss: -12.7558	Cost: 9.06s
Train Epoch: 901 [81920/90000 (91%)]	Loss: -12.7298	Cost: 9.31s
Train Epoch: 901 	Average Loss: -12.6051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8335

Learning rate: 0.0001960205990648874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 902 [0/90000 (0%)]	Loss: -7.5052	Cost: 22.95s
Train Epoch: 902 [20480/90000 (23%)]	Loss: -13.2396	Cost: 9.35s
Train Epoch: 902 [40960/90000 (45%)]	Loss: -13.2189	Cost: 9.45s
Train Epoch: 902 [61440/90000 (68%)]	Loss: -12.9915	Cost: 9.12s
Train Epoch: 902 [81920/90000 (91%)]	Loss: -13.1172	Cost: 9.01s
Train Epoch: 902 	Average Loss: -12.8821
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1592

Learning rate: 0.0001960118200852275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 903 [0/90000 (0%)]	Loss: -7.7615	Cost: 24.06s
Train Epoch: 903 [20480/90000 (23%)]	Loss: -13.7189	Cost: 9.40s
Train Epoch: 903 [40960/90000 (45%)]	Loss: -13.5864	Cost: 9.30s
Train Epoch: 903 [61440/90000 (68%)]	Loss: -13.3956	Cost: 9.01s
Train Epoch: 903 [81920/90000 (91%)]	Loss: -13.3757	Cost: 8.87s
Train Epoch: 903 	Average Loss: -13.1793
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3526

Learning rate: 0.00019600303162958089
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 904 [0/90000 (0%)]	Loss: -6.9943	Cost: 23.32s
Train Epoch: 904 [20480/90000 (23%)]	Loss: -13.9305	Cost: 9.44s
Train Epoch: 904 [40960/90000 (45%)]	Loss: -13.6036	Cost: 9.50s
Train Epoch: 904 [61440/90000 (68%)]	Loss: -13.4143	Cost: 9.27s
Train Epoch: 904 [81920/90000 (91%)]	Loss: -13.4818	Cost: 8.78s
Train Epoch: 904 	Average Loss: -13.2258
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2973

Learning rate: 0.00019599423369881492
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 905 [0/90000 (0%)]	Loss: -7.6252	Cost: 24.22s
Train Epoch: 905 [20480/90000 (23%)]	Loss: -14.0316	Cost: 9.24s
Train Epoch: 905 [40960/90000 (45%)]	Loss: -13.5155	Cost: 9.26s
Train Epoch: 905 [61440/90000 (68%)]	Loss: -13.2620	Cost: 9.05s
Train Epoch: 905 [81920/90000 (91%)]	Loss: -13.1495	Cost: 8.66s
Train Epoch: 905 	Average Loss: -13.2051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9643

Learning rate: 0.0001959854262937979
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 906 [0/90000 (0%)]	Loss: -7.6002	Cost: 23.91s
Train Epoch: 906 [20480/90000 (23%)]	Loss: -13.4196	Cost: 9.42s
Train Epoch: 906 [40960/90000 (45%)]	Loss: -13.4076	Cost: 9.25s
Train Epoch: 906 [61440/90000 (68%)]	Loss: -13.3253	Cost: 9.24s
Train Epoch: 906 [81920/90000 (91%)]	Loss: -13.2625	Cost: 9.17s
Train Epoch: 906 	Average Loss: -13.0706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2497

Learning rate: 0.0001959766094153991
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 907 [0/90000 (0%)]	Loss: -7.6492	Cost: 24.66s
Train Epoch: 907 [20480/90000 (23%)]	Loss: -13.6020	Cost: 9.40s
Train Epoch: 907 [40960/90000 (45%)]	Loss: -13.2701	Cost: 9.32s
Train Epoch: 907 [61440/90000 (68%)]	Loss: -13.6396	Cost: 9.19s
Train Epoch: 907 [81920/90000 (91%)]	Loss: -13.4679	Cost: 8.93s
Train Epoch: 907 	Average Loss: -13.2232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3255

Learning rate: 0.00019596778306448873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 908 [0/90000 (0%)]	Loss: -8.3918	Cost: 25.07s
Train Epoch: 908 [20480/90000 (23%)]	Loss: -13.8968	Cost: 9.42s
Train Epoch: 908 [40960/90000 (45%)]	Loss: -13.5246	Cost: 9.50s
Train Epoch: 908 [61440/90000 (68%)]	Loss: -13.3724	Cost: 9.09s
Train Epoch: 908 [81920/90000 (91%)]	Loss: -13.2082	Cost: 8.82s
Train Epoch: 908 	Average Loss: -13.1753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1533

Learning rate: 0.0001959589472419379
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 909 [0/90000 (0%)]	Loss: -7.3575	Cost: 24.27s
Train Epoch: 909 [20480/90000 (23%)]	Loss: -13.6740	Cost: 9.37s
Train Epoch: 909 [40960/90000 (45%)]	Loss: -13.4899	Cost: 9.30s
Train Epoch: 909 [61440/90000 (68%)]	Loss: -13.2809	Cost: 9.23s
Train Epoch: 909 [81920/90000 (91%)]	Loss: -13.2146	Cost: 8.95s
Train Epoch: 909 	Average Loss: -13.1136
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3419

Learning rate: 0.00019595010194861865
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 910 [0/90000 (0%)]	Loss: -7.9319	Cost: 26.71s
Train Epoch: 910 [20480/90000 (23%)]	Loss: -13.8823	Cost: 11.96s
Train Epoch: 910 [40960/90000 (45%)]	Loss: -13.5655	Cost: 17.93s
Train Epoch: 910 [61440/90000 (68%)]	Loss: -13.4094	Cost: 11.89s
Train Epoch: 910 [81920/90000 (91%)]	Loss: -13.4755	Cost: 20.39s
Train Epoch: 910 	Average Loss: -13.2755
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2555

Learning rate: 0.00019594124718540402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 911 [0/90000 (0%)]	Loss: -6.9456	Cost: 35.83s
Train Epoch: 911 [20480/90000 (23%)]	Loss: -13.8526	Cost: 9.51s
Train Epoch: 911 [40960/90000 (45%)]	Loss: -13.7591	Cost: 16.32s
Train Epoch: 911 [61440/90000 (68%)]	Loss: -13.6330	Cost: 11.57s
Train Epoch: 911 [81920/90000 (91%)]	Loss: -13.5047	Cost: 19.41s
Train Epoch: 911 	Average Loss: -13.3651
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.6828

Learning rate: 0.00019593238295316788
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 912 [0/90000 (0%)]	Loss: -8.4084	Cost: 41.09s
Train Epoch: 912 [20480/90000 (23%)]	Loss: -13.9829	Cost: 9.24s
Train Epoch: 912 [40960/90000 (45%)]	Loss: -13.7385	Cost: 9.37s
Train Epoch: 912 [61440/90000 (68%)]	Loss: -13.7546	Cost: 9.10s
Train Epoch: 912 [81920/90000 (91%)]	Loss: -13.5560	Cost: 9.21s
Train Epoch: 912 	Average Loss: -13.4657
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5331

Learning rate: 0.00019592350925278515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 913 [0/90000 (0%)]	Loss: -8.2782	Cost: 24.66s
Train Epoch: 913 [20480/90000 (23%)]	Loss: -13.9603	Cost: 9.92s
Train Epoch: 913 [40960/90000 (45%)]	Loss: -13.7668	Cost: 9.07s
Train Epoch: 913 [61440/90000 (68%)]	Loss: -13.5375	Cost: 9.02s
Train Epoch: 913 [81920/90000 (91%)]	Loss: -13.5426	Cost: 8.70s
Train Epoch: 913 	Average Loss: -13.4631
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3806

Learning rate: 0.0001959146260851316
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 914 [0/90000 (0%)]	Loss: -7.3645	Cost: 24.23s
Train Epoch: 914 [20480/90000 (23%)]	Loss: -14.0617	Cost: 9.52s
Train Epoch: 914 [40960/90000 (45%)]	Loss: -13.7980	Cost: 9.31s
Train Epoch: 914 [61440/90000 (68%)]	Loss: -13.7712	Cost: 9.02s
Train Epoch: 914 [81920/90000 (91%)]	Loss: -13.3157	Cost: 9.61s
Train Epoch: 914 	Average Loss: -13.4324
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2856

Learning rate: 0.00019590573345108395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 915 [0/90000 (0%)]	Loss: -8.1588	Cost: 23.89s
Train Epoch: 915 [20480/90000 (23%)]	Loss: -13.9129	Cost: 9.56s
Train Epoch: 915 [40960/90000 (45%)]	Loss: -13.6548	Cost: 9.10s
Train Epoch: 915 [61440/90000 (68%)]	Loss: -13.4225	Cost: 9.12s
Train Epoch: 915 [81920/90000 (91%)]	Loss: -13.1767	Cost: 9.73s
Train Epoch: 915 	Average Loss: -13.3033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1937

Learning rate: 0.00019589683135151992
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 916 [0/90000 (0%)]	Loss: -8.2757	Cost: 23.14s
Train Epoch: 916 [20480/90000 (23%)]	Loss: -13.5958	Cost: 9.49s
Train Epoch: 916 [40960/90000 (45%)]	Loss: -13.4800	Cost: 9.05s
Train Epoch: 916 [61440/90000 (68%)]	Loss: -13.4829	Cost: 9.07s
Train Epoch: 916 [81920/90000 (91%)]	Loss: -13.5591	Cost: 9.85s
Train Epoch: 916 	Average Loss: -13.3714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3620

Learning rate: 0.00019588791978731806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 917 [0/90000 (0%)]	Loss: -8.4702	Cost: 23.12s
Train Epoch: 917 [20480/90000 (23%)]	Loss: -13.9423	Cost: 9.30s
Train Epoch: 917 [40960/90000 (45%)]	Loss: -13.8330	Cost: 9.54s
Train Epoch: 917 [61440/90000 (68%)]	Loss: -13.6973	Cost: 9.29s
Train Epoch: 917 [81920/90000 (91%)]	Loss: -13.9242	Cost: 9.04s
Train Epoch: 917 	Average Loss: -13.5599
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5838

Learning rate: 0.00019587899875935793
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 918 [0/90000 (0%)]	Loss: -8.2698	Cost: 22.73s
Train Epoch: 918 [20480/90000 (23%)]	Loss: -14.2427	Cost: 9.34s
Train Epoch: 918 [40960/90000 (45%)]	Loss: -13.9603	Cost: 9.40s
Train Epoch: 918 [61440/90000 (68%)]	Loss: -13.7967	Cost: 9.37s
Train Epoch: 918 [81920/90000 (91%)]	Loss: -13.3559	Cost: 9.10s
Train Epoch: 918 	Average Loss: -13.5597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2335

Learning rate: 0.00019587006826851997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 919 [0/90000 (0%)]	Loss: -8.2047	Cost: 23.00s
Train Epoch: 919 [20480/90000 (23%)]	Loss: -13.7671	Cost: 9.39s
Train Epoch: 919 [40960/90000 (45%)]	Loss: -13.3257	Cost: 9.32s
Train Epoch: 919 [61440/90000 (68%)]	Loss: -13.5987	Cost: 9.24s
Train Epoch: 919 [81920/90000 (91%)]	Loss: -13.0625	Cost: 9.02s
Train Epoch: 919 	Average Loss: -13.2263
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7164

Learning rate: 0.00019586112831568563
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 920 [0/90000 (0%)]	Loss: -7.6810	Cost: 23.96s
Train Epoch: 920 [20480/90000 (23%)]	Loss: -13.3301	Cost: 9.31s
Train Epoch: 920 [40960/90000 (45%)]	Loss: -13.4304	Cost: 9.30s
Train Epoch: 920 [61440/90000 (68%)]	Loss: -13.4997	Cost: 9.15s
Train Epoch: 920 [81920/90000 (91%)]	Loss: -13.3820	Cost: 9.31s
Train Epoch: 920 	Average Loss: -13.1084
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4564

Learning rate: 0.00019585217890173725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 921 [0/90000 (0%)]	Loss: -8.4401	Cost: 26.34s
Train Epoch: 921 [20480/90000 (23%)]	Loss: -14.2771	Cost: 9.42s
Train Epoch: 921 [40960/90000 (45%)]	Loss: -13.3868	Cost: 9.30s
Train Epoch: 921 [61440/90000 (68%)]	Loss: -13.2600	Cost: 9.10s
Train Epoch: 921 [81920/90000 (91%)]	Loss: -11.5285	Cost: 9.30s
Train Epoch: 921 	Average Loss: -12.9433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9250

Learning rate: 0.0001958432200275581
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 922 [0/90000 (0%)]	Loss: -6.8175	Cost: 26.84s
Train Epoch: 922 [20480/90000 (23%)]	Loss: -12.6052	Cost: 9.28s
Train Epoch: 922 [40960/90000 (45%)]	Loss: -12.5616	Cost: 9.26s
Train Epoch: 922 [61440/90000 (68%)]	Loss: -13.0057	Cost: 9.42s
Train Epoch: 922 [81920/90000 (91%)]	Loss: -12.8166	Cost: 9.56s
Train Epoch: 922 	Average Loss: -12.3691
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1067

Learning rate: 0.00019583425169403235
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 923 [0/90000 (0%)]	Loss: -8.1591	Cost: 25.31s
Train Epoch: 923 [20480/90000 (23%)]	Loss: -13.6339	Cost: 9.42s
Train Epoch: 923 [40960/90000 (45%)]	Loss: -13.6966	Cost: 9.48s
Train Epoch: 923 [61440/90000 (68%)]	Loss: -13.5490	Cost: 9.17s
Train Epoch: 923 [81920/90000 (91%)]	Loss: -13.3727	Cost: 8.92s
Train Epoch: 923 	Average Loss: -13.3243
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3566

Learning rate: 0.00019582527390204514
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 924 [0/90000 (0%)]	Loss: -7.8953	Cost: 25.33s
Train Epoch: 924 [20480/90000 (23%)]	Loss: -14.1388	Cost: 9.33s
Train Epoch: 924 [40960/90000 (45%)]	Loss: -13.6091	Cost: 9.31s
Train Epoch: 924 [61440/90000 (68%)]	Loss: -13.6565	Cost: 9.23s
Train Epoch: 924 [81920/90000 (91%)]	Loss: -13.7088	Cost: 8.90s
Train Epoch: 924 	Average Loss: -13.4224
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4990

Learning rate: 0.00019581628665248256
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 925 [0/90000 (0%)]	Loss: -8.3323	Cost: 58.35s
Train Epoch: 925 [20480/90000 (23%)]	Loss: -14.2130	Cost: 11.13s
Train Epoch: 925 [40960/90000 (45%)]	Loss: -13.8063	Cost: 21.72s
Train Epoch: 925 [61440/90000 (68%)]	Loss: -13.7009	Cost: 10.83s
Train Epoch: 925 [81920/90000 (91%)]	Loss: -13.5507	Cost: 13.40s
Train Epoch: 925 	Average Loss: -13.5612
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4129

Learning rate: 0.00019580728994623165
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 926 [0/90000 (0%)]	Loss: -8.2903	Cost: 59.60s
Train Epoch: 926 [20480/90000 (23%)]	Loss: -13.9151	Cost: 11.12s
Train Epoch: 926 [40960/90000 (45%)]	Loss: -14.0329	Cost: 17.89s
Train Epoch: 926 [61440/90000 (68%)]	Loss: -13.9689	Cost: 8.94s
Train Epoch: 926 [81920/90000 (91%)]	Loss: -13.8077	Cost: 8.84s
Train Epoch: 926 	Average Loss: -13.5632
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5127

Learning rate: 0.00019579828378418028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 927 [0/90000 (0%)]	Loss: -8.4222	Cost: 25.14s
Train Epoch: 927 [20480/90000 (23%)]	Loss: -14.3344	Cost: 9.25s
Train Epoch: 927 [40960/90000 (45%)]	Loss: -14.0846	Cost: 9.83s
Train Epoch: 927 [61440/90000 (68%)]	Loss: -13.9450	Cost: 9.06s
Train Epoch: 927 [81920/90000 (91%)]	Loss: -13.7494	Cost: 9.05s
Train Epoch: 927 	Average Loss: -13.7229
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5050

Learning rate: 0.00019578926816721736
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 928 [0/90000 (0%)]	Loss: -8.3148	Cost: 25.00s
Train Epoch: 928 [20480/90000 (23%)]	Loss: -14.2480	Cost: 9.12s
Train Epoch: 928 [40960/90000 (45%)]	Loss: -14.0049	Cost: 9.38s
Train Epoch: 928 [61440/90000 (68%)]	Loss: -13.8819	Cost: 9.11s
Train Epoch: 928 [81920/90000 (91%)]	Loss: -13.8821	Cost: 8.89s
Train Epoch: 928 	Average Loss: -13.6898
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.6425

Learning rate: 0.00019578024309623268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 929 [0/90000 (0%)]	Loss: -7.8358	Cost: 25.99s
Train Epoch: 929 [20480/90000 (23%)]	Loss: -14.2562	Cost: 9.22s
Train Epoch: 929 [40960/90000 (45%)]	Loss: -14.0536	Cost: 9.35s
Train Epoch: 929 [61440/90000 (68%)]	Loss: -14.1615	Cost: 9.08s
Train Epoch: 929 [81920/90000 (91%)]	Loss: -13.7233	Cost: 8.94s
Train Epoch: 929 	Average Loss: -13.7663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.6208

Learning rate: 0.00019577120857211698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 930 [0/90000 (0%)]	Loss: -8.5773	Cost: 25.76s
Train Epoch: 930 [20480/90000 (23%)]	Loss: -14.4232	Cost: 9.35s
Train Epoch: 930 [40960/90000 (45%)]	Loss: -14.2007	Cost: 9.13s
Train Epoch: 930 [61440/90000 (68%)]	Loss: -13.9993	Cost: 9.19s
Train Epoch: 930 [81920/90000 (91%)]	Loss: -13.8733	Cost: 8.75s
Train Epoch: 930 	Average Loss: -13.7551
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5670

Learning rate: 0.00019576216459576195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 931 [0/90000 (0%)]	Loss: -8.2223	Cost: 25.39s
Train Epoch: 931 [20480/90000 (23%)]	Loss: -14.1953	Cost: 9.59s
Train Epoch: 931 [40960/90000 (45%)]	Loss: -13.8494	Cost: 9.06s
Train Epoch: 931 [61440/90000 (68%)]	Loss: -13.9655	Cost: 9.03s
Train Epoch: 931 [81920/90000 (91%)]	Loss: -13.8947	Cost: 9.56s
Train Epoch: 931 	Average Loss: -13.6777
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.6669

Learning rate: 0.0001957531111680602
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 932 [0/90000 (0%)]	Loss: -7.9729	Cost: 24.06s
Train Epoch: 932 [20480/90000 (23%)]	Loss: -14.2128	Cost: 9.53s
Train Epoch: 932 [40960/90000 (45%)]	Loss: -14.1855	Cost: 9.25s
Train Epoch: 932 [61440/90000 (68%)]	Loss: -13.8768	Cost: 9.01s
Train Epoch: 932 [81920/90000 (91%)]	Loss: -13.5828	Cost: 10.06s
Train Epoch: 932 	Average Loss: -13.7021
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5290

Learning rate: 0.00019574404828990522
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 933 [0/90000 (0%)]	Loss: -8.6497	Cost: 23.34s
Train Epoch: 933 [20480/90000 (23%)]	Loss: -14.3483	Cost: 9.65s
Train Epoch: 933 [40960/90000 (45%)]	Loss: -13.4718	Cost: 9.07s
Train Epoch: 933 [61440/90000 (68%)]	Loss: -13.4661	Cost: 9.10s
Train Epoch: 933 [81920/90000 (91%)]	Loss: -13.4440	Cost: 10.10s
Train Epoch: 933 	Average Loss: -13.4540
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4976

Learning rate: 0.00019573497596219155
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 934 [0/90000 (0%)]	Loss: -7.6425	Cost: 25.37s
Train Epoch: 934 [20480/90000 (23%)]	Loss: -14.2271	Cost: 9.09s
Train Epoch: 934 [40960/90000 (45%)]	Loss: -13.9637	Cost: 10.00s
Train Epoch: 934 [61440/90000 (68%)]	Loss: -13.9272	Cost: 9.05s
Train Epoch: 934 [81920/90000 (91%)]	Loss: -13.8106	Cost: 10.12s
Train Epoch: 934 	Average Loss: -13.6269
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.6558

Learning rate: 0.00019572589418581453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 935 [0/90000 (0%)]	Loss: -8.7683	Cost: 23.02s
Train Epoch: 935 [20480/90000 (23%)]	Loss: -14.3645	Cost: 9.02s
Train Epoch: 935 [40960/90000 (45%)]	Loss: -14.0893	Cost: 9.11s
Train Epoch: 935 [61440/90000 (68%)]	Loss: -14.0709	Cost: 9.04s
Train Epoch: 935 [81920/90000 (91%)]	Loss: -14.0841	Cost: 8.99s
Train Epoch: 935 	Average Loss: -13.8165
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.7680

Learning rate: 0.00019571680296167054
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 936 [0/90000 (0%)]	Loss: -8.2510	Cost: 24.58s
Train Epoch: 936 [20480/90000 (23%)]	Loss: -14.6685	Cost: 9.06s
Train Epoch: 936 [40960/90000 (45%)]	Loss: -14.0229	Cost: 10.12s
Train Epoch: 936 [61440/90000 (68%)]	Loss: -14.1251	Cost: 9.08s
Train Epoch: 936 [81920/90000 (91%)]	Loss: -13.6732	Cost: 10.44s
Train Epoch: 936 	Average Loss: -13.7812
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4050

Learning rate: 0.00019570770229065682
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 937 [0/90000 (0%)]	Loss: -8.0042	Cost: 23.58s
Train Epoch: 937 [20480/90000 (23%)]	Loss: -13.5197	Cost: 9.13s
Train Epoch: 937 [40960/90000 (45%)]	Loss: -13.6882	Cost: 9.45s
Train Epoch: 937 [61440/90000 (68%)]	Loss: -14.0793	Cost: 9.02s
Train Epoch: 937 [81920/90000 (91%)]	Loss: -13.8404	Cost: 9.04s
Train Epoch: 937 	Average Loss: -13.4524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.7834

Learning rate: 0.0001956985921736716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 938 [0/90000 (0%)]	Loss: -8.3627	Cost: 26.38s
Train Epoch: 938 [20480/90000 (23%)]	Loss: -14.3803	Cost: 9.03s
Train Epoch: 938 [40960/90000 (45%)]	Loss: -13.5202	Cost: 9.21s
Train Epoch: 938 [61440/90000 (68%)]	Loss: -13.8449	Cost: 8.91s
Train Epoch: 938 [81920/90000 (91%)]	Loss: -13.5528	Cost: 8.81s
Train Epoch: 938 	Average Loss: -13.4569
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.7111

Learning rate: 0.00019568947261161396
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 939 [0/90000 (0%)]	Loss: -8.7067	Cost: 25.30s
Train Epoch: 939 [20480/90000 (23%)]	Loss: -14.0658	Cost: 9.01s
Train Epoch: 939 [40960/90000 (45%)]	Loss: -14.1901	Cost: 9.49s
Train Epoch: 939 [61440/90000 (68%)]	Loss: -14.1049	Cost: 8.96s
Train Epoch: 939 [81920/90000 (91%)]	Loss: -14.0832	Cost: 9.24s
Train Epoch: 939 	Average Loss: -13.7603
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8119

Learning rate: 0.00019568034360538402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 940 [0/90000 (0%)]	Loss: -7.7546	Cost: 25.31s
Train Epoch: 940 [20480/90000 (23%)]	Loss: -14.1789	Cost: 9.04s
Train Epoch: 940 [40960/90000 (45%)]	Loss: -14.1547	Cost: 9.02s
Train Epoch: 940 [61440/90000 (68%)]	Loss: -14.2220	Cost: 9.17s
Train Epoch: 940 [81920/90000 (91%)]	Loss: -14.0771	Cost: 8.77s
Train Epoch: 940 	Average Loss: -13.8237
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8525

Learning rate: 0.00019567120515588275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 941 [0/90000 (0%)]	Loss: -8.8596	Cost: 25.29s
Train Epoch: 941 [20480/90000 (23%)]	Loss: -14.5139	Cost: 9.12s
Train Epoch: 941 [40960/90000 (45%)]	Loss: -14.3156	Cost: 9.78s
Train Epoch: 941 [61440/90000 (68%)]	Loss: -14.2760	Cost: 8.98s
Train Epoch: 941 [81920/90000 (91%)]	Loss: -14.1702	Cost: 8.82s
Train Epoch: 941 	Average Loss: -13.9971
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8501

Learning rate: 0.0001956620572640121
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 942 [0/90000 (0%)]	Loss: -8.6212	Cost: 25.36s
Train Epoch: 942 [20480/90000 (23%)]	Loss: -14.5565	Cost: 9.25s
Train Epoch: 942 [40960/90000 (45%)]	Loss: -13.9342	Cost: 9.34s
Train Epoch: 942 [61440/90000 (68%)]	Loss: -13.9861	Cost: 9.10s
Train Epoch: 942 [81920/90000 (91%)]	Loss: -13.8935	Cost: 8.99s
Train Epoch: 942 	Average Loss: -13.8507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8617

Learning rate: 0.0001956528999306749
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 943 [0/90000 (0%)]	Loss: -8.0824	Cost: 24.84s
Train Epoch: 943 [20480/90000 (23%)]	Loss: -14.5556	Cost: 10.15s
Train Epoch: 943 [40960/90000 (45%)]	Loss: -14.2510	Cost: 9.07s
Train Epoch: 943 [61440/90000 (68%)]	Loss: -14.1051	Cost: 9.04s
Train Epoch: 943 [81920/90000 (91%)]	Loss: -14.0798	Cost: 8.75s
Train Epoch: 943 	Average Loss: -13.9933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8117

Learning rate: 0.00019564373315677494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 944 [0/90000 (0%)]	Loss: -8.9861	Cost: 25.37s
Train Epoch: 944 [20480/90000 (23%)]	Loss: -14.6302	Cost: 9.62s
Train Epoch: 944 [40960/90000 (45%)]	Loss: -14.2312	Cost: 9.16s
Train Epoch: 944 [61440/90000 (68%)]	Loss: -14.4382	Cost: 9.03s
Train Epoch: 944 [81920/90000 (91%)]	Loss: -14.0307	Cost: 9.84s
Train Epoch: 944 	Average Loss: -13.9970
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.9502

Learning rate: 0.00019563455694321697
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 945 [0/90000 (0%)]	Loss: -8.6236	Cost: 23.48s
Train Epoch: 945 [20480/90000 (23%)]	Loss: -14.6394	Cost: 9.04s
Train Epoch: 945 [40960/90000 (45%)]	Loss: -14.3494	Cost: 9.87s
Train Epoch: 945 [61440/90000 (68%)]	Loss: -14.4125	Cost: 9.08s
Train Epoch: 945 [81920/90000 (91%)]	Loss: -14.2850	Cost: 9.97s
Train Epoch: 945 	Average Loss: -14.0796
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.9365

Learning rate: 0.00019562537129090663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 946 [0/90000 (0%)]	Loss: -9.5470	Cost: 23.31s
Train Epoch: 946 [20480/90000 (23%)]	Loss: -14.7693	Cost: 9.01s
Train Epoch: 946 [40960/90000 (45%)]	Loss: -14.2497	Cost: 9.75s
Train Epoch: 946 [61440/90000 (68%)]	Loss: -14.4278	Cost: 9.01s
Train Epoch: 946 [81920/90000 (91%)]	Loss: -14.1400	Cost: 10.47s
Train Epoch: 946 	Average Loss: -14.1330
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8388

Learning rate: 0.00019561617620075054
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 947 [0/90000 (0%)]	Loss: -8.2915	Cost: 23.34s
Train Epoch: 947 [20480/90000 (23%)]	Loss: -14.7253	Cost: 9.07s
Train Epoch: 947 [40960/90000 (45%)]	Loss: -14.4110	Cost: 9.24s
Train Epoch: 947 [61440/90000 (68%)]	Loss: -14.5885	Cost: 9.08s
Train Epoch: 947 [81920/90000 (91%)]	Loss: -14.3384	Cost: 10.22s
Train Epoch: 947 	Average Loss: -14.1321
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.0643

Learning rate: 0.00019560697167365617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 948 [0/90000 (0%)]	Loss: -8.6078	Cost: 23.62s
Train Epoch: 948 [20480/90000 (23%)]	Loss: -14.6062	Cost: 9.15s
Train Epoch: 948 [40960/90000 (45%)]	Loss: -14.4529	Cost: 9.22s
Train Epoch: 948 [61440/90000 (68%)]	Loss: -14.1999	Cost: 9.17s
Train Epoch: 948 [81920/90000 (91%)]	Loss: -14.0709	Cost: 9.06s
Train Epoch: 948 	Average Loss: -14.1021
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.9889

Learning rate: 0.00019559775771053198
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 949 [0/90000 (0%)]	Loss: -9.2463	Cost: 23.00s
Train Epoch: 949 [20480/90000 (23%)]	Loss: -14.6114	Cost: 9.03s
Train Epoch: 949 [40960/90000 (45%)]	Loss: -14.2578	Cost: 9.25s
Train Epoch: 949 [61440/90000 (68%)]	Loss: -14.4875	Cost: 9.24s
Train Epoch: 949 [81920/90000 (91%)]	Loss: -14.2742	Cost: 9.14s
Train Epoch: 949 	Average Loss: -14.1339
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.9778

Learning rate: 0.0001955885343122874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 950 [0/90000 (0%)]	Loss: -8.4727	Cost: 23.84s
Train Epoch: 950 [20480/90000 (23%)]	Loss: -14.7126	Cost: 9.33s
Train Epoch: 950 [40960/90000 (45%)]	Loss: -14.1617	Cost: 9.25s
Train Epoch: 950 [61440/90000 (68%)]	Loss: -14.4158	Cost: 9.11s
Train Epoch: 950 [81920/90000 (91%)]	Loss: -14.1703	Cost: 9.38s
Train Epoch: 950 	Average Loss: -14.0259
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.0063

Saving model as model.pt_e950 & waveforms_supplementary.hdf5_e950
Learning rate: 0.0001955793014798327
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 951 [0/90000 (0%)]	Loss: -8.7519	Cost: 23.84s
Train Epoch: 951 [20480/90000 (23%)]	Loss: -14.6045	Cost: 9.39s
Train Epoch: 951 [40960/90000 (45%)]	Loss: -14.2970	Cost: 9.20s
Train Epoch: 951 [61440/90000 (68%)]	Loss: -14.1371	Cost: 9.08s
Train Epoch: 951 [81920/90000 (91%)]	Loss: -14.2539	Cost: 9.08s
Train Epoch: 951 	Average Loss: -14.0407
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.9069

Learning rate: 0.00019557005921407914
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 952 [0/90000 (0%)]	Loss: -8.3081	Cost: 26.07s
Train Epoch: 952 [20480/90000 (23%)]	Loss: -14.3692	Cost: 9.33s
Train Epoch: 952 [40960/90000 (45%)]	Loss: -14.4197	Cost: 10.19s
Train Epoch: 952 [61440/90000 (68%)]	Loss: -14.3322	Cost: 9.18s
Train Epoch: 952 [81920/90000 (91%)]	Loss: -14.1968	Cost: 9.30s
Train Epoch: 952 	Average Loss: -14.0276
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8761

Learning rate: 0.0001955608075159389
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 953 [0/90000 (0%)]	Loss: -8.4434	Cost: 23.84s
Train Epoch: 953 [20480/90000 (23%)]	Loss: -14.2805	Cost: 9.40s
Train Epoch: 953 [40960/90000 (45%)]	Loss: -14.1608	Cost: 9.20s
Train Epoch: 953 [61440/90000 (68%)]	Loss: -14.0883	Cost: 9.21s
Train Epoch: 953 [81920/90000 (91%)]	Loss: -14.2425	Cost: 9.16s
Train Epoch: 953 	Average Loss: -13.9515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.9733

Learning rate: 0.00019555154638632502
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 954 [0/90000 (0%)]	Loss: -8.6499	Cost: 25.52s
Train Epoch: 954 [20480/90000 (23%)]	Loss: -14.3984	Cost: 9.33s
Train Epoch: 954 [40960/90000 (45%)]	Loss: -14.4801	Cost: 9.24s
Train Epoch: 954 [61440/90000 (68%)]	Loss: -14.3538	Cost: 9.25s
Train Epoch: 954 [81920/90000 (91%)]	Loss: -14.1524	Cost: 9.29s
Train Epoch: 954 	Average Loss: -14.1038
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.0588

Learning rate: 0.00019554227582615162
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 955 [0/90000 (0%)]	Loss: -9.0221	Cost: 24.58s
Train Epoch: 955 [20480/90000 (23%)]	Loss: -13.6679	Cost: 9.27s
Train Epoch: 955 [40960/90000 (45%)]	Loss: -13.2641	Cost: 9.19s
Train Epoch: 955 [61440/90000 (68%)]	Loss: -13.5572	Cost: 9.17s
Train Epoch: 955 [81920/90000 (91%)]	Loss: -13.5983	Cost: 9.56s
Train Epoch: 955 	Average Loss: -13.3365
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5809

Learning rate: 0.00019553299583633364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 956 [0/90000 (0%)]	Loss: -8.1850	Cost: 25.86s
Train Epoch: 956 [20480/90000 (23%)]	Loss: -14.4599	Cost: 9.38s
Train Epoch: 956 [40960/90000 (45%)]	Loss: -14.0999	Cost: 9.30s
Train Epoch: 956 [61440/90000 (68%)]	Loss: -14.1570	Cost: 9.28s
Train Epoch: 956 [81920/90000 (91%)]	Loss: -13.7985	Cost: 9.06s
Train Epoch: 956 	Average Loss: -13.7664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.6400

Learning rate: 0.00019552370641778697
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 957 [0/90000 (0%)]	Loss: -7.9276	Cost: 27.50s
Train Epoch: 957 [20480/90000 (23%)]	Loss: -14.2382	Cost: 9.40s
Train Epoch: 957 [40960/90000 (45%)]	Loss: -13.8116	Cost: 9.24s
Train Epoch: 957 [61440/90000 (68%)]	Loss: -13.8699	Cost: 9.09s
Train Epoch: 957 [81920/90000 (91%)]	Loss: -14.0789	Cost: 8.84s
Train Epoch: 957 	Average Loss: -13.7162
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.9423

Learning rate: 0.00019551440757142847
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 958 [0/90000 (0%)]	Loss: -8.8712	Cost: 25.31s
Train Epoch: 958 [20480/90000 (23%)]	Loss: -14.6401	Cost: 9.30s
Train Epoch: 958 [40960/90000 (45%)]	Loss: -14.3289	Cost: 9.31s
Train Epoch: 958 [61440/90000 (68%)]	Loss: -14.5190	Cost: 9.18s
Train Epoch: 958 [81920/90000 (91%)]	Loss: -14.0819	Cost: 8.90s
Train Epoch: 958 	Average Loss: -14.1615
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.7778

Learning rate: 0.00019550509929817583
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 959 [0/90000 (0%)]	Loss: -8.7784	Cost: 25.27s
Train Epoch: 959 [20480/90000 (23%)]	Loss: -14.5882	Cost: 9.25s
Train Epoch: 959 [40960/90000 (45%)]	Loss: -14.5578	Cost: 9.39s
Train Epoch: 959 [61440/90000 (68%)]	Loss: -14.4069	Cost: 9.12s
Train Epoch: 959 [81920/90000 (91%)]	Loss: -13.0959	Cost: 8.84s
Train Epoch: 959 	Average Loss: -13.9253
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1310

Learning rate: 0.00019549578159894782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 960 [0/90000 (0%)]	Loss: -7.7472	Cost: 24.63s
Train Epoch: 960 [20480/90000 (23%)]	Loss: -13.7351	Cost: 9.14s
Train Epoch: 960 [40960/90000 (45%)]	Loss: -14.0136	Cost: 9.39s
Train Epoch: 960 [61440/90000 (68%)]	Loss: -13.9909	Cost: 9.08s
Train Epoch: 960 [81920/90000 (91%)]	Loss: -13.9231	Cost: 8.90s
Train Epoch: 960 	Average Loss: -13.5586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8609

Learning rate: 0.00019548645447466402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 961 [0/90000 (0%)]	Loss: -8.8449	Cost: 25.39s
Train Epoch: 961 [20480/90000 (23%)]	Loss: -14.6386	Cost: 9.26s
Train Epoch: 961 [40960/90000 (45%)]	Loss: -14.4738	Cost: 9.15s
Train Epoch: 961 [61440/90000 (68%)]	Loss: -14.5147	Cost: 9.11s
Train Epoch: 961 [81920/90000 (91%)]	Loss: -14.3072	Cost: 8.84s
Train Epoch: 961 	Average Loss: -14.1327
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.1389

Learning rate: 0.00019547711792624497
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 962 [0/90000 (0%)]	Loss: -8.9854	Cost: 25.23s
Train Epoch: 962 [20480/90000 (23%)]	Loss: -14.7848	Cost: 10.14s
Train Epoch: 962 [40960/90000 (45%)]	Loss: -14.5626	Cost: 9.09s
Train Epoch: 962 [61440/90000 (68%)]	Loss: -14.3517	Cost: 8.94s
Train Epoch: 962 [81920/90000 (91%)]	Loss: -14.1570	Cost: 8.74s
Train Epoch: 962 	Average Loss: -14.2032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.0737

Learning rate: 0.00019546777195461216
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 963 [0/90000 (0%)]	Loss: -8.9001	Cost: 24.85s
Train Epoch: 963 [20480/90000 (23%)]	Loss: -14.7543	Cost: 9.52s
Train Epoch: 963 [40960/90000 (45%)]	Loss: -14.5190	Cost: 9.17s
Train Epoch: 963 [61440/90000 (68%)]	Loss: -14.5305	Cost: 9.11s
Train Epoch: 963 [81920/90000 (91%)]	Loss: -14.4032	Cost: 9.25s
Train Epoch: 963 	Average Loss: -14.1737
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2404

Learning rate: 0.00019545841656068801
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 964 [0/90000 (0%)]	Loss: -8.7210	Cost: 24.40s
Train Epoch: 964 [20480/90000 (23%)]	Loss: -14.7256	Cost: 9.06s
Train Epoch: 964 [40960/90000 (45%)]	Loss: -14.5781	Cost: 9.81s
Train Epoch: 964 [61440/90000 (68%)]	Loss: -14.4114	Cost: 9.03s
Train Epoch: 964 [81920/90000 (91%)]	Loss: -14.3784	Cost: 10.30s
Train Epoch: 964 	Average Loss: -14.3075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.0962

Learning rate: 0.00019544905174539588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 965 [0/90000 (0%)]	Loss: -9.1643	Cost: 24.44s
Train Epoch: 965 [20480/90000 (23%)]	Loss: -14.9472	Cost: 9.54s
Train Epoch: 965 [40960/90000 (45%)]	Loss: -14.7430	Cost: 9.79s
Train Epoch: 965 [61440/90000 (68%)]	Loss: -14.6637	Cost: 9.17s
Train Epoch: 965 [81920/90000 (91%)]	Loss: -14.4522	Cost: 10.07s
Train Epoch: 965 	Average Loss: -14.3768
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.1438

Learning rate: 0.00019543967750965997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 966 [0/90000 (0%)]	Loss: -8.0904	Cost: 24.48s
Train Epoch: 966 [20480/90000 (23%)]	Loss: -14.4128	Cost: 9.16s
Train Epoch: 966 [40960/90000 (45%)]	Loss: -14.0268	Cost: 9.72s
Train Epoch: 966 [61440/90000 (68%)]	Loss: -14.2240	Cost: 9.07s
Train Epoch: 966 [81920/90000 (91%)]	Loss: -14.2535	Cost: 10.31s
Train Epoch: 966 	Average Loss: -13.9944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.9624

Learning rate: 0.00019543029385440556
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 967 [0/90000 (0%)]	Loss: -8.7091	Cost: 24.86s
Train Epoch: 967 [20480/90000 (23%)]	Loss: -14.6958	Cost: 9.19s
Train Epoch: 967 [40960/90000 (45%)]	Loss: -14.3993	Cost: 9.22s
Train Epoch: 967 [61440/90000 (68%)]	Loss: -14.7203	Cost: 9.12s
Train Epoch: 967 [81920/90000 (91%)]	Loss: -14.5483	Cost: 9.20s
Train Epoch: 967 	Average Loss: -14.3087
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.1618

Learning rate: 0.00019542090078055873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 968 [0/90000 (0%)]	Loss: -8.7918	Cost: 23.98s
Train Epoch: 968 [20480/90000 (23%)]	Loss: -14.6559	Cost: 9.13s
Train Epoch: 968 [40960/90000 (45%)]	Loss: -14.5099	Cost: 9.16s
Train Epoch: 968 [61440/90000 (68%)]	Loss: -14.3876	Cost: 9.15s
Train Epoch: 968 [81920/90000 (91%)]	Loss: -14.5810	Cost: 9.03s
Train Epoch: 968 	Average Loss: -14.2373
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3214

Learning rate: 0.00019541149828904657
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 969 [0/90000 (0%)]	Loss: -8.2939	Cost: 24.28s
Train Epoch: 969 [20480/90000 (23%)]	Loss: -14.5250	Cost: 9.08s
Train Epoch: 969 [40960/90000 (45%)]	Loss: -14.4935	Cost: 9.05s
Train Epoch: 969 [61440/90000 (68%)]	Loss: -14.4117	Cost: 8.99s
Train Epoch: 969 [81920/90000 (91%)]	Loss: -14.3340	Cost: 9.11s
Train Epoch: 969 	Average Loss: -14.1256
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.9006

Learning rate: 0.00019540208638079703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 970 [0/90000 (0%)]	Loss: -8.4913	Cost: 24.95s
Train Epoch: 970 [20480/90000 (23%)]	Loss: -14.9315	Cost: 9.07s
Train Epoch: 970 [40960/90000 (45%)]	Loss: -14.6415	Cost: 9.49s
Train Epoch: 970 [61440/90000 (68%)]	Loss: -14.7736	Cost: 8.99s
Train Epoch: 970 [81920/90000 (91%)]	Loss: -14.5876	Cost: 9.03s
Train Epoch: 970 	Average Loss: -14.3986
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.1766

Learning rate: 0.00019539266505673905
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 971 [0/90000 (0%)]	Loss: -8.9484	Cost: 24.82s
Train Epoch: 971 [20480/90000 (23%)]	Loss: -14.9156	Cost: 9.04s
Train Epoch: 971 [40960/90000 (45%)]	Loss: -14.6013	Cost: 10.19s
Train Epoch: 971 [61440/90000 (68%)]	Loss: -14.7195	Cost: 8.98s
Train Epoch: 971 [81920/90000 (91%)]	Loss: -14.3486	Cost: 8.84s
Train Epoch: 971 	Average Loss: -14.3214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8940

Learning rate: 0.0001953832343178025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 972 [0/90000 (0%)]	Loss: -8.6931	Cost: 24.16s
Train Epoch: 972 [20480/90000 (23%)]	Loss: -14.9756	Cost: 9.39s
Train Epoch: 972 [40960/90000 (45%)]	Loss: -14.5012	Cost: 9.24s
Train Epoch: 972 [61440/90000 (68%)]	Loss: -14.4827	Cost: 9.02s
Train Epoch: 972 [81920/90000 (91%)]	Loss: -14.4937	Cost: 8.77s
Train Epoch: 972 	Average Loss: -14.2790
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2357

Learning rate: 0.00019537379416491811
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 973 [0/90000 (0%)]	Loss: -8.0785	Cost: 25.62s
Train Epoch: 973 [20480/90000 (23%)]	Loss: -14.8493	Cost: 9.79s
Train Epoch: 973 [40960/90000 (45%)]	Loss: -14.5749	Cost: 9.26s
Train Epoch: 973 [61440/90000 (68%)]	Loss: -14.6992	Cost: 9.06s
Train Epoch: 973 [81920/90000 (91%)]	Loss: -14.7711	Cost: 8.79s
Train Epoch: 973 	Average Loss: -14.3817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4593

Learning rate: 0.00019536434459901765
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 974 [0/90000 (0%)]	Loss: -8.9888	Cost: 25.80s
Train Epoch: 974 [20480/90000 (23%)]	Loss: -15.0569	Cost: 9.34s
Train Epoch: 974 [40960/90000 (45%)]	Loss: -14.7172	Cost: 9.76s
Train Epoch: 974 [61440/90000 (68%)]	Loss: -14.7786	Cost: 9.32s
Train Epoch: 974 [81920/90000 (91%)]	Loss: -14.5660	Cost: 8.91s
Train Epoch: 974 	Average Loss: -14.4578
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2828

Learning rate: 0.0001953548856210337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 975 [0/90000 (0%)]	Loss: -8.6393	Cost: 24.95s
Train Epoch: 975 [20480/90000 (23%)]	Loss: -15.0045	Cost: 9.44s
Train Epoch: 975 [40960/90000 (45%)]	Loss: -14.8184	Cost: 9.23s
Train Epoch: 975 [61440/90000 (68%)]	Loss: -14.7369	Cost: 9.10s
Train Epoch: 975 [81920/90000 (91%)]	Loss: -14.7504	Cost: 8.83s
Train Epoch: 975 	Average Loss: -14.5192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2891

Learning rate: 0.00019534541723189978
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 976 [0/90000 (0%)]	Loss: -8.6515	Cost: 24.60s
Train Epoch: 976 [20480/90000 (23%)]	Loss: -14.8454	Cost: 9.38s
Train Epoch: 976 [40960/90000 (45%)]	Loss: -14.7123	Cost: 9.29s
Train Epoch: 976 [61440/90000 (68%)]	Loss: -14.7535	Cost: 9.14s
Train Epoch: 976 [81920/90000 (91%)]	Loss: -14.1251	Cost: 9.06s
Train Epoch: 976 	Average Loss: -14.3103
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.9177

Learning rate: 0.00019533593943255054
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 977 [0/90000 (0%)]	Loss: -8.1621	Cost: 25.00s
Train Epoch: 977 [20480/90000 (23%)]	Loss: -14.6389	Cost: 9.17s
Train Epoch: 977 [40960/90000 (45%)]	Loss: -14.6777	Cost: 9.39s
Train Epoch: 977 [61440/90000 (68%)]	Loss: -14.7858	Cost: 9.09s
Train Epoch: 977 [81920/90000 (91%)]	Loss: -14.5257	Cost: 9.17s
Train Epoch: 977 	Average Loss: -14.2798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2867

Learning rate: 0.00019532645222392127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 978 [0/90000 (0%)]	Loss: -8.8964	Cost: 25.39s
Train Epoch: 978 [20480/90000 (23%)]	Loss: -15.0630	Cost: 9.38s
Train Epoch: 978 [40960/90000 (45%)]	Loss: -14.6727	Cost: 9.43s
Train Epoch: 978 [61440/90000 (68%)]	Loss: -14.6341	Cost: 9.16s
Train Epoch: 978 [81920/90000 (91%)]	Loss: -14.7312	Cost: 9.65s
Train Epoch: 978 	Average Loss: -14.4127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2753

Learning rate: 0.00019531695560694832
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 979 [0/90000 (0%)]	Loss: -8.3163	Cost: 25.05s
Train Epoch: 979 [20480/90000 (23%)]	Loss: -14.9253	Cost: 9.39s
Train Epoch: 979 [40960/90000 (45%)]	Loss: -14.8609	Cost: 9.06s
Train Epoch: 979 [61440/90000 (68%)]	Loss: -14.6709	Cost: 9.01s
Train Epoch: 979 [81920/90000 (91%)]	Loss: -14.5416	Cost: 8.71s
Train Epoch: 979 	Average Loss: -14.4270
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3688

Learning rate: 0.00019530744958256901
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 980 [0/90000 (0%)]	Loss: -8.7720	Cost: 24.87s
Train Epoch: 980 [20480/90000 (23%)]	Loss: -15.1277	Cost: 9.47s
Train Epoch: 980 [40960/90000 (45%)]	Loss: -14.9183	Cost: 9.18s
Train Epoch: 980 [61440/90000 (68%)]	Loss: -14.8223	Cost: 9.03s
Train Epoch: 980 [81920/90000 (91%)]	Loss: -14.6860	Cost: 9.60s
Train Epoch: 980 	Average Loss: -14.5657
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4207

Learning rate: 0.00019529793415172156
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 981 [0/90000 (0%)]	Loss: -8.9400	Cost: 24.19s
Train Epoch: 981 [20480/90000 (23%)]	Loss: -15.3532	Cost: 9.55s
Train Epoch: 981 [40960/90000 (45%)]	Loss: -14.9978	Cost: 9.23s
Train Epoch: 981 [61440/90000 (68%)]	Loss: -14.8843	Cost: 9.06s
Train Epoch: 981 [81920/90000 (91%)]	Loss: -14.7435	Cost: 10.03s
Train Epoch: 981 	Average Loss: -14.5873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3486

Learning rate: 0.00019528840931534505
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 982 [0/90000 (0%)]	Loss: -9.1896	Cost: 24.59s
Train Epoch: 982 [20480/90000 (23%)]	Loss: -14.9686	Cost: 9.39s
Train Epoch: 982 [40960/90000 (45%)]	Loss: -14.8095	Cost: 9.40s
Train Epoch: 982 [61440/90000 (68%)]	Loss: -14.6105	Cost: 9.13s
Train Epoch: 982 [81920/90000 (91%)]	Loss: -14.6778	Cost: 10.16s
Train Epoch: 982 	Average Loss: -14.4912
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3372

Learning rate: 0.0001952788750743796
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 983 [0/90000 (0%)]	Loss: -8.6807	Cost: 25.05s
Train Epoch: 983 [20480/90000 (23%)]	Loss: -14.7335	Cost: 9.09s
Train Epoch: 983 [40960/90000 (45%)]	Loss: -14.7039	Cost: 9.60s
Train Epoch: 983 [61440/90000 (68%)]	Loss: -14.5540	Cost: 9.13s
Train Epoch: 983 [81920/90000 (91%)]	Loss: -14.7050	Cost: 10.11s
Train Epoch: 983 	Average Loss: -14.4197
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3788

Learning rate: 0.0001952693314297662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 984 [0/90000 (0%)]	Loss: -9.5713	Cost: 24.00s
Train Epoch: 984 [20480/90000 (23%)]	Loss: -14.7637	Cost: 9.07s
Train Epoch: 984 [40960/90000 (45%)]	Loss: -14.3809	Cost: 9.61s
Train Epoch: 984 [61440/90000 (68%)]	Loss: -14.4137	Cost: 9.05s
Train Epoch: 984 [81920/90000 (91%)]	Loss: -14.4672	Cost: 9.02s
Train Epoch: 984 	Average Loss: -14.2497
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2126

Learning rate: 0.00019525977838244672
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 985 [0/90000 (0%)]	Loss: -9.2413	Cost: 22.82s
Train Epoch: 985 [20480/90000 (23%)]	Loss: -14.8927	Cost: 9.07s
Train Epoch: 985 [40960/90000 (45%)]	Loss: -14.6221	Cost: 9.00s
Train Epoch: 985 [61440/90000 (68%)]	Loss: -14.9385	Cost: 9.01s
Train Epoch: 985 [81920/90000 (91%)]	Loss: -14.6580	Cost: 9.04s
Train Epoch: 985 	Average Loss: -14.4266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3478

Learning rate: 0.00019525021593336405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 986 [0/90000 (0%)]	Loss: -8.7127	Cost: 23.13s
Train Epoch: 986 [20480/90000 (23%)]	Loss: -15.0892	Cost: 9.10s
Train Epoch: 986 [40960/90000 (45%)]	Loss: -14.9097	Cost: 9.18s
Train Epoch: 986 [61440/90000 (68%)]	Loss: -14.7000	Cost: 9.00s
Train Epoch: 986 [81920/90000 (91%)]	Loss: -14.7438	Cost: 9.00s
Train Epoch: 986 	Average Loss: -14.5544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5762

Learning rate: 0.00019524064408346195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 987 [0/90000 (0%)]	Loss: -9.1891	Cost: 24.21s
Train Epoch: 987 [20480/90000 (23%)]	Loss: -15.0405	Cost: 9.06s
Train Epoch: 987 [40960/90000 (45%)]	Loss: -14.9114	Cost: 9.05s
Train Epoch: 987 [61440/90000 (68%)]	Loss: -14.6755	Cost: 8.97s
Train Epoch: 987 [81920/90000 (91%)]	Loss: -14.4714	Cost: 8.75s
Train Epoch: 987 	Average Loss: -14.5367
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2702

Learning rate: 0.00019523106283368514
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 988 [0/90000 (0%)]	Loss: -8.8003	Cost: 26.55s
Train Epoch: 988 [20480/90000 (23%)]	Loss: -14.9908	Cost: 9.32s
Train Epoch: 988 [40960/90000 (45%)]	Loss: -14.8217	Cost: 9.27s
Train Epoch: 988 [61440/90000 (68%)]	Loss: -14.8206	Cost: 9.08s
Train Epoch: 988 [81920/90000 (91%)]	Loss: -14.7212	Cost: 8.80s
Train Epoch: 988 	Average Loss: -14.5405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6192

Learning rate: 0.00019522147218497925
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 989 [0/90000 (0%)]	Loss: -8.6327	Cost: 25.03s
Train Epoch: 989 [20480/90000 (23%)]	Loss: -14.9822	Cost: 9.39s
Train Epoch: 989 [40960/90000 (45%)]	Loss: -14.6505	Cost: 9.30s
Train Epoch: 989 [61440/90000 (68%)]	Loss: -14.6984	Cost: 9.16s
Train Epoch: 989 [81920/90000 (91%)]	Loss: -14.5619	Cost: 8.92s
Train Epoch: 989 	Average Loss: -14.3739
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3278

Learning rate: 0.0001952118721382908
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 990 [0/90000 (0%)]	Loss: -9.7585	Cost: 25.08s
Train Epoch: 990 [20480/90000 (23%)]	Loss: -14.9948	Cost: 9.38s
Train Epoch: 990 [40960/90000 (45%)]	Loss: -14.7478	Cost: 9.27s
Train Epoch: 990 [61440/90000 (68%)]	Loss: -14.9676	Cost: 9.20s
Train Epoch: 990 [81920/90000 (91%)]	Loss: -14.8297	Cost: 9.09s
Train Epoch: 990 	Average Loss: -14.5718
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4531

Learning rate: 0.0001952022626945673
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 991 [0/90000 (0%)]	Loss: -9.4886	Cost: 25.19s
Train Epoch: 991 [20480/90000 (23%)]	Loss: -15.1047	Cost: 9.31s
Train Epoch: 991 [40960/90000 (45%)]	Loss: -14.9301	Cost: 9.31s
Train Epoch: 991 [61440/90000 (68%)]	Loss: -14.6656	Cost: 9.30s
Train Epoch: 991 [81920/90000 (91%)]	Loss: -14.4780	Cost: 8.97s
Train Epoch: 991 	Average Loss: -14.5271
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.1449

Learning rate: 0.00019519264385475717
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 992 [0/90000 (0%)]	Loss: -8.3655	Cost: 26.62s
Train Epoch: 992 [20480/90000 (23%)]	Loss: -15.0544	Cost: 9.35s
Train Epoch: 992 [40960/90000 (45%)]	Loss: -14.8994	Cost: 9.87s
Train Epoch: 992 [61440/90000 (68%)]	Loss: -14.7540	Cost: 9.25s
Train Epoch: 992 [81920/90000 (91%)]	Loss: -14.6209	Cost: 9.10s
Train Epoch: 992 	Average Loss: -14.4831
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4547

Learning rate: 0.00019518301561980976
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 993 [0/90000 (0%)]	Loss: -8.8754	Cost: 25.67s
Train Epoch: 993 [20480/90000 (23%)]	Loss: -15.0766	Cost: 9.13s
Train Epoch: 993 [40960/90000 (45%)]	Loss: -14.8933	Cost: 10.38s
Train Epoch: 993 [61440/90000 (68%)]	Loss: -14.8247	Cost: 9.31s
Train Epoch: 993 [81920/90000 (91%)]	Loss: -14.7495	Cost: 9.28s
Train Epoch: 993 	Average Loss: -14.5646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4216

Learning rate: 0.00019517337799067536
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 994 [0/90000 (0%)]	Loss: -9.1187	Cost: 25.45s
Train Epoch: 994 [20480/90000 (23%)]	Loss: -15.2288	Cost: 9.15s
Train Epoch: 994 [40960/90000 (45%)]	Loss: -14.9439	Cost: 9.42s
Train Epoch: 994 [61440/90000 (68%)]	Loss: -15.0315	Cost: 9.17s
Train Epoch: 994 [81920/90000 (91%)]	Loss: -14.7016	Cost: 8.82s
Train Epoch: 994 	Average Loss: -14.5849
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3179

Learning rate: 0.00019516373096830513
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 995 [0/90000 (0%)]	Loss: -8.9384	Cost: 25.17s
Train Epoch: 995 [20480/90000 (23%)]	Loss: -15.1449	Cost: 9.54s
Train Epoch: 995 [40960/90000 (45%)]	Loss: -14.7958	Cost: 9.05s
Train Epoch: 995 [61440/90000 (68%)]	Loss: -14.8849	Cost: 9.01s
Train Epoch: 995 [81920/90000 (91%)]	Loss: -14.6223	Cost: 8.75s
Train Epoch: 995 	Average Loss: -14.5190
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2310

Learning rate: 0.00019515407455365116
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 996 [0/90000 (0%)]	Loss: -8.8971	Cost: 25.42s
Train Epoch: 996 [20480/90000 (23%)]	Loss: -15.0923	Cost: 9.51s
Train Epoch: 996 [40960/90000 (45%)]	Loss: -14.9244	Cost: 9.20s
Train Epoch: 996 [61440/90000 (68%)]	Loss: -14.8539	Cost: 9.07s
Train Epoch: 996 [81920/90000 (91%)]	Loss: -14.9129	Cost: 9.56s
Train Epoch: 996 	Average Loss: -14.5933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4239

Learning rate: 0.00019514440874766656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 997 [0/90000 (0%)]	Loss: -9.2217	Cost: 24.60s
Train Epoch: 997 [20480/90000 (23%)]	Loss: -14.8452	Cost: 9.38s
Train Epoch: 997 [40960/90000 (45%)]	Loss: -14.7404	Cost: 9.35s
Train Epoch: 997 [61440/90000 (68%)]	Loss: -14.8642	Cost: 9.10s
Train Epoch: 997 [81920/90000 (91%)]	Loss: -14.5617	Cost: 9.87s
Train Epoch: 997 	Average Loss: -14.5330
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3654

Learning rate: 0.00019513473355130528
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 998 [0/90000 (0%)]	Loss: -9.0073	Cost: 22.85s
Train Epoch: 998 [20480/90000 (23%)]	Loss: -15.0749	Cost: 9.38s
Train Epoch: 998 [40960/90000 (45%)]	Loss: -14.8511	Cost: 9.06s
Train Epoch: 998 [61440/90000 (68%)]	Loss: -14.5309	Cost: 9.07s
Train Epoch: 998 [81920/90000 (91%)]	Loss: -14.5357	Cost: 10.29s
Train Epoch: 998 	Average Loss: -14.4360
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3241

Learning rate: 0.00019512504896552222
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 999 [0/90000 (0%)]	Loss: -8.5633	Cost: 24.65s
Train Epoch: 999 [20480/90000 (23%)]	Loss: -15.1089	Cost: 9.26s
Train Epoch: 999 [40960/90000 (45%)]	Loss: -15.0573	Cost: 9.83s
Train Epoch: 999 [61440/90000 (68%)]	Loss: -14.8751	Cost: 9.10s
Train Epoch: 999 [81920/90000 (91%)]	Loss: -14.7851	Cost: 10.36s
Train Epoch: 999 	Average Loss: -14.5886
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4745

Learning rate: 0.00019511535499127324
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1000 [0/90000 (0%)]	Loss: -8.3988	Cost: 24.30s
Train Epoch: 1000 [20480/90000 (23%)]	Loss: -15.2642	Cost: 9.03s
Train Epoch: 1000 [40960/90000 (45%)]	Loss: -15.1669	Cost: 10.03s
Train Epoch: 1000 [61440/90000 (68%)]	Loss: -15.0026	Cost: 9.04s
Train Epoch: 1000 [81920/90000 (91%)]	Loss: -14.6087	Cost: 10.55s
Train Epoch: 1000 	Average Loss: -14.6614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3882

Saving model as model.pt_e1000 & waveforms_supplementary.hdf5_e1000
Learning rate: 0.00019510565162951505
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1001 [0/90000 (0%)]	Loss: -9.3133	Cost: 22.38s
Train Epoch: 1001 [20480/90000 (23%)]	Loss: -15.0898	Cost: 9.06s
Train Epoch: 1001 [40960/90000 (45%)]	Loss: -14.8061	Cost: 9.04s
Train Epoch: 1001 [61440/90000 (68%)]	Loss: -14.6519	Cost: 9.09s
Train Epoch: 1001 [81920/90000 (91%)]	Loss: -14.6671	Cost: 8.99s
Train Epoch: 1001 	Average Loss: -14.4684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4350

Learning rate: 0.00019509593888120534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1002 [0/90000 (0%)]	Loss: -8.8104	Cost: 23.47s
Train Epoch: 1002 [20480/90000 (23%)]	Loss: -15.2688	Cost: 9.04s
Train Epoch: 1002 [40960/90000 (45%)]	Loss: -15.0617	Cost: 9.18s
Train Epoch: 1002 [61440/90000 (68%)]	Loss: -14.7116	Cost: 9.04s
Train Epoch: 1002 [81920/90000 (91%)]	Loss: -14.7115	Cost: 9.05s
Train Epoch: 1002 	Average Loss: -14.5967
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3674

Learning rate: 0.00019508621674730277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1003 [0/90000 (0%)]	Loss: -9.0287	Cost: 24.94s
Train Epoch: 1003 [20480/90000 (23%)]	Loss: -15.2436	Cost: 9.06s
Train Epoch: 1003 [40960/90000 (45%)]	Loss: -15.1351	Cost: 9.64s
Train Epoch: 1003 [61440/90000 (68%)]	Loss: -15.0494	Cost: 8.93s
Train Epoch: 1003 [81920/90000 (91%)]	Loss: -14.7888	Cost: 8.92s
Train Epoch: 1003 	Average Loss: -14.6643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4119

Learning rate: 0.00019507648522876684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1004 [0/90000 (0%)]	Loss: -8.7344	Cost: 23.84s
Train Epoch: 1004 [20480/90000 (23%)]	Loss: -15.2285	Cost: 9.04s
Train Epoch: 1004 [40960/90000 (45%)]	Loss: -15.0854	Cost: 9.03s
Train Epoch: 1004 [61440/90000 (68%)]	Loss: -15.0847	Cost: 9.01s
Train Epoch: 1004 [81920/90000 (91%)]	Loss: -15.0978	Cost: 8.89s
Train Epoch: 1004 	Average Loss: -14.7738
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7085

Learning rate: 0.00019506674432655802
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1005 [0/90000 (0%)]	Loss: -9.6943	Cost: 24.75s
Train Epoch: 1005 [20480/90000 (23%)]	Loss: -15.4041	Cost: 9.18s
Train Epoch: 1005 [40960/90000 (45%)]	Loss: -15.1884	Cost: 9.24s
Train Epoch: 1005 [61440/90000 (68%)]	Loss: -14.2782	Cost: 9.11s
Train Epoch: 1005 [81920/90000 (91%)]	Loss: -14.3379	Cost: 8.81s
Train Epoch: 1005 	Average Loss: -14.4821
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.0766

Learning rate: 0.0001950569940416377
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1006 [0/90000 (0%)]	Loss: -9.2196	Cost: 25.74s
Train Epoch: 1006 [20480/90000 (23%)]	Loss: -14.7754	Cost: 9.44s
Train Epoch: 1006 [40960/90000 (45%)]	Loss: -11.3521	Cost: 9.25s
Train Epoch: 1006 [61440/90000 (68%)]	Loss: -10.5407	Cost: 9.14s
Train Epoch: 1006 [81920/90000 (91%)]	Loss: -11.2915	Cost: 8.90s
Train Epoch: 1006 	Average Loss: -12.3514
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8058

Learning rate: 0.00019504723437496817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1007 [0/90000 (0%)]	Loss: -6.6621	Cost: 25.28s
Train Epoch: 1007 [20480/90000 (23%)]	Loss: -12.9034	Cost: 9.28s
Train Epoch: 1007 [40960/90000 (45%)]	Loss: -13.2357	Cost: 9.38s
Train Epoch: 1007 [61440/90000 (68%)]	Loss: -13.8597	Cost: 9.22s
Train Epoch: 1007 [81920/90000 (91%)]	Loss: -13.9382	Cost: 9.03s
Train Epoch: 1007 	Average Loss: -12.9070
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.6998

Learning rate: 0.0001950374653275127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1008 [0/90000 (0%)]	Loss: -8.8275	Cost: 25.50s
Train Epoch: 1008 [20480/90000 (23%)]	Loss: -14.5004	Cost: 9.38s
Train Epoch: 1008 [40960/90000 (45%)]	Loss: -14.0048	Cost: 9.27s
Train Epoch: 1008 [61440/90000 (68%)]	Loss: -14.3687	Cost: 9.09s
Train Epoch: 1008 [81920/90000 (91%)]	Loss: -14.3813	Cost: 8.96s
Train Epoch: 1008 	Average Loss: -13.9952
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2256

Learning rate: 0.00019502768690023544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1009 [0/90000 (0%)]	Loss: -8.7606	Cost: 24.90s
Train Epoch: 1009 [20480/90000 (23%)]	Loss: -15.0300	Cost: 9.35s
Train Epoch: 1009 [40960/90000 (45%)]	Loss: -14.5446	Cost: 9.32s
Train Epoch: 1009 [61440/90000 (68%)]	Loss: -14.5114	Cost: 9.10s
Train Epoch: 1009 [81920/90000 (91%)]	Loss: -14.4095	Cost: 8.85s
Train Epoch: 1009 	Average Loss: -14.3600
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2604

Learning rate: 0.0001950178990941015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1010 [0/90000 (0%)]	Loss: -8.8838	Cost: 25.68s
Train Epoch: 1010 [20480/90000 (23%)]	Loss: -14.8537	Cost: 9.44s
Train Epoch: 1010 [40960/90000 (45%)]	Loss: -14.0012	Cost: 9.20s
Train Epoch: 1010 [61440/90000 (68%)]	Loss: -14.1817	Cost: 9.07s
Train Epoch: 1010 [81920/90000 (91%)]	Loss: -14.3078	Cost: 8.81s
Train Epoch: 1010 	Average Loss: -14.0285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8463

Learning rate: 0.00019500810191007685
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1011 [0/90000 (0%)]	Loss: -8.8165	Cost: 25.48s
Train Epoch: 1011 [20480/90000 (23%)]	Loss: -15.0371	Cost: 9.38s
Train Epoch: 1011 [40960/90000 (45%)]	Loss: -14.9271	Cost: 9.06s
Train Epoch: 1011 [61440/90000 (68%)]	Loss: -14.9309	Cost: 9.04s
Train Epoch: 1011 [81920/90000 (91%)]	Loss: -14.7143	Cost: 8.73s
Train Epoch: 1011 	Average Loss: -14.5152
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3838

Learning rate: 0.0001949982953491285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1012 [0/90000 (0%)]	Loss: -8.9694	Cost: 25.14s
Train Epoch: 1012 [20480/90000 (23%)]	Loss: -15.1124	Cost: 9.62s
Train Epoch: 1012 [40960/90000 (45%)]	Loss: -14.8937	Cost: 9.04s
Train Epoch: 1012 [61440/90000 (68%)]	Loss: -14.9134	Cost: 8.99s
Train Epoch: 1012 [81920/90000 (91%)]	Loss: -15.0298	Cost: 9.00s
Train Epoch: 1012 	Average Loss: -14.6771
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6431

Learning rate: 0.0001949884794122243
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1013 [0/90000 (0%)]	Loss: -8.9295	Cost: 24.88s
Train Epoch: 1013 [20480/90000 (23%)]	Loss: -15.2295	Cost: 9.56s
Train Epoch: 1013 [40960/90000 (45%)]	Loss: -14.8428	Cost: 9.26s
Train Epoch: 1013 [61440/90000 (68%)]	Loss: -14.8381	Cost: 9.11s
Train Epoch: 1013 [81920/90000 (91%)]	Loss: -14.7164	Cost: 9.72s
Train Epoch: 1013 	Average Loss: -14.6070
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4900

Learning rate: 0.000194978654100333
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1014 [0/90000 (0%)]	Loss: -9.0021	Cost: 24.04s
Train Epoch: 1014 [20480/90000 (23%)]	Loss: -15.2563	Cost: 9.52s
Train Epoch: 1014 [40960/90000 (45%)]	Loss: -14.7382	Cost: 9.35s
Train Epoch: 1014 [61440/90000 (68%)]	Loss: -14.8292	Cost: 9.19s
Train Epoch: 1014 [81920/90000 (91%)]	Loss: -14.5901	Cost: 9.92s
Train Epoch: 1014 	Average Loss: -14.5241
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.1823

Learning rate: 0.00019496881941442437
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1015 [0/90000 (0%)]	Loss: -9.3207	Cost: 25.18s
Train Epoch: 1015 [20480/90000 (23%)]	Loss: -15.0375	Cost: 9.09s
Train Epoch: 1015 [40960/90000 (45%)]	Loss: -14.9355	Cost: 9.89s
Train Epoch: 1015 [61440/90000 (68%)]	Loss: -15.0413	Cost: 9.05s
Train Epoch: 1015 [81920/90000 (91%)]	Loss: -14.7453	Cost: 10.16s
Train Epoch: 1015 	Average Loss: -14.5820
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2497

Learning rate: 0.00019495897535546904
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1016 [0/90000 (0%)]	Loss: -8.7617	Cost: 25.15s
Train Epoch: 1016 [20480/90000 (23%)]	Loss: -14.8948	Cost: 9.01s
Train Epoch: 1016 [40960/90000 (45%)]	Loss: -14.8754	Cost: 9.10s
Train Epoch: 1016 [61440/90000 (68%)]	Loss: -14.9948	Cost: 9.04s
Train Epoch: 1016 [81920/90000 (91%)]	Loss: -14.1881	Cost: 9.97s
Train Epoch: 1016 	Average Loss: -14.5029
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.9705

Learning rate: 0.00019494912192443854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1017 [0/90000 (0%)]	Loss: -8.5038	Cost: 24.02s
Train Epoch: 1017 [20480/90000 (23%)]	Loss: -14.7368	Cost: 9.06s
Train Epoch: 1017 [40960/90000 (45%)]	Loss: -14.7628	Cost: 10.00s
Train Epoch: 1017 [61440/90000 (68%)]	Loss: -14.8948	Cost: 9.08s
Train Epoch: 1017 [81920/90000 (91%)]	Loss: -14.8884	Cost: 10.17s
Train Epoch: 1017 	Average Loss: -14.4254
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4057

Learning rate: 0.00019493925912230544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1018 [0/90000 (0%)]	Loss: -8.9938	Cost: 22.86s
Train Epoch: 1018 [20480/90000 (23%)]	Loss: -15.0771	Cost: 9.01s
Train Epoch: 1018 [40960/90000 (45%)]	Loss: -14.9476	Cost: 9.00s
Train Epoch: 1018 [61440/90000 (68%)]	Loss: -14.9556	Cost: 9.02s
Train Epoch: 1018 [81920/90000 (91%)]	Loss: -14.7308	Cost: 8.97s
Train Epoch: 1018 	Average Loss: -14.6400
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3084

Learning rate: 0.00019492938695004312
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1019 [0/90000 (0%)]	Loss: -9.2355	Cost: 23.67s
Train Epoch: 1019 [20480/90000 (23%)]	Loss: -15.2262	Cost: 9.03s
Train Epoch: 1019 [40960/90000 (45%)]	Loss: -15.0493	Cost: 9.02s
Train Epoch: 1019 [61440/90000 (68%)]	Loss: -15.1827	Cost: 8.91s
Train Epoch: 1019 [81920/90000 (91%)]	Loss: -14.9508	Cost: 8.88s
Train Epoch: 1019 	Average Loss: -14.8146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5651

Learning rate: 0.00019491950540862592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1020 [0/90000 (0%)]	Loss: -9.3021	Cost: 24.88s
Train Epoch: 1020 [20480/90000 (23%)]	Loss: -14.9682	Cost: 9.00s
Train Epoch: 1020 [40960/90000 (45%)]	Loss: -14.6528	Cost: 9.83s
Train Epoch: 1020 [61440/90000 (68%)]	Loss: -14.8030	Cost: 8.98s
Train Epoch: 1020 [81920/90000 (91%)]	Loss: -15.0092	Cost: 8.99s
Train Epoch: 1020 	Average Loss: -14.6161
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6526

Learning rate: 0.0001949096144990291
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1021 [0/90000 (0%)]	Loss: -8.8923	Cost: 26.63s
Train Epoch: 1021 [20480/90000 (23%)]	Loss: -15.4315	Cost: 9.42s
Train Epoch: 1021 [40960/90000 (45%)]	Loss: -15.0550	Cost: 9.30s
Train Epoch: 1021 [61440/90000 (68%)]	Loss: -15.2888	Cost: 9.16s
Train Epoch: 1021 [81920/90000 (91%)]	Loss: -15.0954	Cost: 8.79s
Train Epoch: 1021 	Average Loss: -14.9050
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6058

Learning rate: 0.0001948997142222289
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1022 [0/90000 (0%)]	Loss: -9.0854	Cost: 24.72s
Train Epoch: 1022 [20480/90000 (23%)]	Loss: -15.4457	Cost: 9.48s
Train Epoch: 1022 [40960/90000 (45%)]	Loss: -15.2697	Cost: 9.30s
Train Epoch: 1022 [61440/90000 (68%)]	Loss: -15.4165	Cost: 9.24s
Train Epoch: 1022 [81920/90000 (91%)]	Loss: -15.1117	Cost: 9.08s
Train Epoch: 1022 	Average Loss: -14.9446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8093

Learning rate: 0.00019488980457920237
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1023 [0/90000 (0%)]	Loss: -9.5274	Cost: 25.17s
Train Epoch: 1023 [20480/90000 (23%)]	Loss: -15.4112	Cost: 9.41s
Train Epoch: 1023 [40960/90000 (45%)]	Loss: -15.3075	Cost: 9.29s
Train Epoch: 1023 [61440/90000 (68%)]	Loss: -15.5096	Cost: 9.20s
Train Epoch: 1023 [81920/90000 (91%)]	Loss: -15.2550	Cost: 8.97s
Train Epoch: 1023 	Average Loss: -15.0658
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7144

Learning rate: 0.00019487988557092759
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1024 [0/90000 (0%)]	Loss: -9.2691	Cost: 26.23s
Train Epoch: 1024 [20480/90000 (23%)]	Loss: -15.4121	Cost: 9.41s
Train Epoch: 1024 [40960/90000 (45%)]	Loss: -15.2365	Cost: 9.21s
Train Epoch: 1024 [61440/90000 (68%)]	Loss: -15.3382	Cost: 9.15s
Train Epoch: 1024 [81920/90000 (91%)]	Loss: -14.9360	Cost: 9.13s
Train Epoch: 1024 	Average Loss: -14.9036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6445

Learning rate: 0.00019486995719838354
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1025 [0/90000 (0%)]	Loss: -8.7846	Cost: 25.86s
Train Epoch: 1025 [20480/90000 (23%)]	Loss: -15.4485	Cost: 9.43s
Train Epoch: 1025 [40960/90000 (45%)]	Loss: -15.2124	Cost: 9.28s
Train Epoch: 1025 [61440/90000 (68%)]	Loss: -15.3185	Cost: 9.19s
Train Epoch: 1025 [81920/90000 (91%)]	Loss: -15.2392	Cost: 8.87s
Train Epoch: 1025 	Average Loss: -14.9191
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6591

Learning rate: 0.00019486001946255008
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1026 [0/90000 (0%)]	Loss: -9.1088	Cost: 25.55s
Train Epoch: 1026 [20480/90000 (23%)]	Loss: -15.5146	Cost: 9.22s
Train Epoch: 1026 [40960/90000 (45%)]	Loss: -15.2742	Cost: 9.36s
Train Epoch: 1026 [61440/90000 (68%)]	Loss: -15.3262	Cost: 9.06s
Train Epoch: 1026 [81920/90000 (91%)]	Loss: -14.9331	Cost: 8.93s
Train Epoch: 1026 	Average Loss: -14.9800
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5132

Learning rate: 0.00019485007236440808
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1027 [0/90000 (0%)]	Loss: -9.2202	Cost: 24.85s
Train Epoch: 1027 [20480/90000 (23%)]	Loss: -15.4142	Cost: 9.23s
Train Epoch: 1027 [40960/90000 (45%)]	Loss: -15.1228	Cost: 9.19s
Train Epoch: 1027 [61440/90000 (68%)]	Loss: -14.9815	Cost: 9.13s
Train Epoch: 1027 [81920/90000 (91%)]	Loss: -15.2634	Cost: 8.80s
Train Epoch: 1027 	Average Loss: -14.8418
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6066

Learning rate: 0.00019484011590493924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1028 [0/90000 (0%)]	Loss: -9.1690	Cost: 25.42s
Train Epoch: 1028 [20480/90000 (23%)]	Loss: -15.4879	Cost: 9.56s
Train Epoch: 1028 [40960/90000 (45%)]	Loss: -15.2481	Cost: 9.06s
Train Epoch: 1028 [61440/90000 (68%)]	Loss: -15.1236	Cost: 8.95s
Train Epoch: 1028 [81920/90000 (91%)]	Loss: -14.4809	Cost: 8.73s
Train Epoch: 1028 	Average Loss: -14.7699
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.1391

Learning rate: 0.0001948301500851262
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1029 [0/90000 (0%)]	Loss: -8.2984	Cost: 24.61s
Train Epoch: 1029 [20480/90000 (23%)]	Loss: -15.1092	Cost: 9.52s
Train Epoch: 1029 [40960/90000 (45%)]	Loss: -14.9897	Cost: 9.21s
Train Epoch: 1029 [61440/90000 (68%)]	Loss: -14.7245	Cost: 9.04s
Train Epoch: 1029 [81920/90000 (91%)]	Loss: -14.6162	Cost: 9.59s
Train Epoch: 1029 	Average Loss: -14.5013
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.1363

Learning rate: 0.00019482017490595255
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1030 [0/90000 (0%)]	Loss: -8.2967	Cost: 23.47s
Train Epoch: 1030 [20480/90000 (23%)]	Loss: -14.8287	Cost: 9.61s
Train Epoch: 1030 [40960/90000 (45%)]	Loss: -14.6272	Cost: 9.06s
Train Epoch: 1030 [61440/90000 (68%)]	Loss: -14.6611	Cost: 9.08s
Train Epoch: 1030 [81920/90000 (91%)]	Loss: -14.6596	Cost: 9.72s
Train Epoch: 1030 	Average Loss: -14.3438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4301

Learning rate: 0.00019481019036840283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1031 [0/90000 (0%)]	Loss: -9.2253	Cost: 24.86s
Train Epoch: 1031 [20480/90000 (23%)]	Loss: -15.3316	Cost: 9.44s
Train Epoch: 1031 [40960/90000 (45%)]	Loss: -15.2001	Cost: 9.15s
Train Epoch: 1031 [61440/90000 (68%)]	Loss: -14.9519	Cost: 9.05s
Train Epoch: 1031 [81920/90000 (91%)]	Loss: -14.9298	Cost: 10.12s
Train Epoch: 1031 	Average Loss: -14.7184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6121

Learning rate: 0.0001948001964734625
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1032 [0/90000 (0%)]	Loss: -9.7571	Cost: 25.16s
Train Epoch: 1032 [20480/90000 (23%)]	Loss: -15.5608	Cost: 9.04s
Train Epoch: 1032 [40960/90000 (45%)]	Loss: -15.3235	Cost: 9.24s
Train Epoch: 1032 [61440/90000 (68%)]	Loss: -15.0822	Cost: 9.03s
Train Epoch: 1032 [81920/90000 (91%)]	Loss: -14.9776	Cost: 10.33s
Train Epoch: 1032 	Average Loss: -14.8303
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4400

Learning rate: 0.00019479019322211785
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1033 [0/90000 (0%)]	Loss: -9.6752	Cost: 23.70s
Train Epoch: 1033 [20480/90000 (23%)]	Loss: -15.4028	Cost: 9.01s
Train Epoch: 1033 [40960/90000 (45%)]	Loss: -15.2251	Cost: 9.06s
Train Epoch: 1033 [61440/90000 (68%)]	Loss: -14.8995	Cost: 9.07s
Train Epoch: 1033 [81920/90000 (91%)]	Loss: -14.8296	Cost: 9.35s
Train Epoch: 1033 	Average Loss: -14.7335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5139

Learning rate: 0.00019478018061535622
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1034 [0/90000 (0%)]	Loss: -9.2942	Cost: 25.32s
Train Epoch: 1034 [20480/90000 (23%)]	Loss: -15.3635	Cost: 9.28s
Train Epoch: 1034 [40960/90000 (45%)]	Loss: -15.1528	Cost: 9.27s
Train Epoch: 1034 [61440/90000 (68%)]	Loss: -14.9705	Cost: 9.28s
Train Epoch: 1034 [81920/90000 (91%)]	Loss: -14.8087	Cost: 9.10s
Train Epoch: 1034 	Average Loss: -14.6868
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5777

Learning rate: 0.0001947701586541658
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1035 [0/90000 (0%)]	Loss: -9.7154	Cost: 23.57s
Train Epoch: 1035 [20480/90000 (23%)]	Loss: -15.3967	Cost: 9.50s
Train Epoch: 1035 [40960/90000 (45%)]	Loss: -15.0861	Cost: 9.26s
Train Epoch: 1035 [61440/90000 (68%)]	Loss: -14.8910	Cost: 9.12s
Train Epoch: 1035 [81920/90000 (91%)]	Loss: -14.9607	Cost: 9.18s
Train Epoch: 1035 	Average Loss: -14.7769
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7517

Learning rate: 0.00019476012733953566
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1036 [0/90000 (0%)]	Loss: -9.4069	Cost: 24.65s
Train Epoch: 1036 [20480/90000 (23%)]	Loss: -15.5730	Cost: 9.34s
Train Epoch: 1036 [40960/90000 (45%)]	Loss: -14.8409	Cost: 9.22s
Train Epoch: 1036 [61440/90000 (68%)]	Loss: -14.9078	Cost: 9.05s
Train Epoch: 1036 [81920/90000 (91%)]	Loss: -14.8493	Cost: 9.18s
Train Epoch: 1036 	Average Loss: -14.7765
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6201

Learning rate: 0.0001947500866724559
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1037 [0/90000 (0%)]	Loss: -9.4769	Cost: 25.68s
Train Epoch: 1037 [20480/90000 (23%)]	Loss: -15.5229	Cost: 9.48s
Train Epoch: 1037 [40960/90000 (45%)]	Loss: -14.8683	Cost: 9.43s
Train Epoch: 1037 [61440/90000 (68%)]	Loss: -14.6957	Cost: 9.61s
Train Epoch: 1037 [81920/90000 (91%)]	Loss: -14.9436	Cost: 9.63s
Train Epoch: 1037 	Average Loss: -14.6813
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4716

Learning rate: 0.00019474003665391753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1038 [0/90000 (0%)]	Loss: -9.0693	Cost: 24.21s
Train Epoch: 1038 [20480/90000 (23%)]	Loss: -15.3063	Cost: 9.31s
Train Epoch: 1038 [40960/90000 (45%)]	Loss: -14.7293	Cost: 9.30s
Train Epoch: 1038 [61440/90000 (68%)]	Loss: -14.5931	Cost: 9.10s
Train Epoch: 1038 [81920/90000 (91%)]	Loss: -14.9303	Cost: 9.01s
Train Epoch: 1038 	Average Loss: -14.6597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5117

Learning rate: 0.0001947299772849124
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1039 [0/90000 (0%)]	Loss: -9.2969	Cost: 24.80s
Train Epoch: 1039 [20480/90000 (23%)]	Loss: -15.2099	Cost: 9.28s
Train Epoch: 1039 [40960/90000 (45%)]	Loss: -15.0633	Cost: 9.35s
Train Epoch: 1039 [61440/90000 (68%)]	Loss: -15.0461	Cost: 9.27s
Train Epoch: 1039 [81920/90000 (91%)]	Loss: -15.2095	Cost: 9.02s
Train Epoch: 1039 	Average Loss: -14.8052
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7415

Learning rate: 0.00019471990856643334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1040 [0/90000 (0%)]	Loss: -8.8134	Cost: 25.97s
Train Epoch: 1040 [20480/90000 (23%)]	Loss: -15.0279	Cost: 9.35s
Train Epoch: 1040 [40960/90000 (45%)]	Loss: -15.0355	Cost: 9.27s
Train Epoch: 1040 [61440/90000 (68%)]	Loss: -15.0710	Cost: 9.26s
Train Epoch: 1040 [81920/90000 (91%)]	Loss: -15.2189	Cost: 9.14s
Train Epoch: 1040 	Average Loss: -14.8344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5873

Learning rate: 0.0001947098304994741
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1041 [0/90000 (0%)]	Loss: -8.9801	Cost: 26.43s
Train Epoch: 1041 [20480/90000 (23%)]	Loss: -15.3108	Cost: 9.31s
Train Epoch: 1041 [40960/90000 (45%)]	Loss: -15.2421	Cost: 9.32s
Train Epoch: 1041 [61440/90000 (68%)]	Loss: -15.2848	Cost: 9.24s
Train Epoch: 1041 [81920/90000 (91%)]	Loss: -15.3035	Cost: 8.85s
Train Epoch: 1041 	Average Loss: -14.9458
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8151

Learning rate: 0.0001946997430850293
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1042 [0/90000 (0%)]	Loss: -9.5716	Cost: 24.94s
Train Epoch: 1042 [20480/90000 (23%)]	Loss: -15.6376	Cost: 9.48s
Train Epoch: 1042 [40960/90000 (45%)]	Loss: -15.5773	Cost: 9.86s
Train Epoch: 1042 [61440/90000 (68%)]	Loss: -15.4756	Cost: 9.77s
Train Epoch: 1042 [81920/90000 (91%)]	Loss: -15.5985	Cost: 9.01s
Train Epoch: 1042 	Average Loss: -15.1382
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8533

Learning rate: 0.0001946896463240946
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1043 [0/90000 (0%)]	Loss: -8.9404	Cost: 25.44s
Train Epoch: 1043 [20480/90000 (23%)]	Loss: -15.8904	Cost: 9.43s
Train Epoch: 1043 [40960/90000 (45%)]	Loss: -15.4256	Cost: 9.32s
Train Epoch: 1043 [61440/90000 (68%)]	Loss: -15.6108	Cost: 9.23s
Train Epoch: 1043 [81920/90000 (91%)]	Loss: -15.1031	Cost: 9.05s
Train Epoch: 1043 	Average Loss: -15.1311
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7737

Learning rate: 0.00019467954021766648
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1044 [0/90000 (0%)]	Loss: -9.0682	Cost: 25.99s
Train Epoch: 1044 [20480/90000 (23%)]	Loss: -15.4217	Cost: 9.38s
Train Epoch: 1044 [40960/90000 (45%)]	Loss: -15.2519	Cost: 9.47s
Train Epoch: 1044 [61440/90000 (68%)]	Loss: -15.3265	Cost: 9.25s
Train Epoch: 1044 [81920/90000 (91%)]	Loss: -15.2909	Cost: 9.01s
Train Epoch: 1044 	Average Loss: -14.9980
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8802

Learning rate: 0.00019466942476674236
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1045 [0/90000 (0%)]	Loss: -9.4582	Cost: 25.07s
Train Epoch: 1045 [20480/90000 (23%)]	Loss: -15.6256	Cost: 9.35s
Train Epoch: 1045 [40960/90000 (45%)]	Loss: -15.4220	Cost: 9.47s
Train Epoch: 1045 [61440/90000 (68%)]	Loss: -15.5367	Cost: 9.38s
Train Epoch: 1045 [81920/90000 (91%)]	Loss: -15.3746	Cost: 8.89s
Train Epoch: 1045 	Average Loss: -15.1047
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.9106

Learning rate: 0.00019465929997232058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1046 [0/90000 (0%)]	Loss: -9.9130	Cost: 25.39s
Train Epoch: 1046 [20480/90000 (23%)]	Loss: -15.6899	Cost: 9.98s
Train Epoch: 1046 [40960/90000 (45%)]	Loss: -15.6590	Cost: 9.07s
Train Epoch: 1046 [61440/90000 (68%)]	Loss: -15.6899	Cost: 9.01s
Train Epoch: 1046 [81920/90000 (91%)]	Loss: -15.6004	Cost: 8.73s
Train Epoch: 1046 	Average Loss: -15.2874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1428

Learning rate: 0.00019464916583540045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1047 [0/90000 (0%)]	Loss: -9.3428	Cost: 24.69s
Train Epoch: 1047 [20480/90000 (23%)]	Loss: -15.8258	Cost: 9.47s
Train Epoch: 1047 [40960/90000 (45%)]	Loss: -15.4578	Cost: 9.57s
Train Epoch: 1047 [61440/90000 (68%)]	Loss: -15.6278	Cost: 9.03s
Train Epoch: 1047 [81920/90000 (91%)]	Loss: -15.3734	Cost: 10.07s
Train Epoch: 1047 	Average Loss: -15.2976
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.9925

Learning rate: 0.00019463902235698218
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1048 [0/90000 (0%)]	Loss: -9.6182	Cost: 23.74s
Train Epoch: 1048 [20480/90000 (23%)]	Loss: -15.9421	Cost: 9.57s
Train Epoch: 1048 [40960/90000 (45%)]	Loss: -15.6045	Cost: 9.06s
Train Epoch: 1048 [61440/90000 (68%)]	Loss: -15.5797	Cost: 9.08s
Train Epoch: 1048 [81920/90000 (91%)]	Loss: -15.1797	Cost: 10.00s
Train Epoch: 1048 	Average Loss: -15.2539
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7700

Learning rate: 0.00019462886953806687
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1049 [0/90000 (0%)]	Loss: -9.4358	Cost: 23.49s
Train Epoch: 1049 [20480/90000 (23%)]	Loss: -15.7701	Cost: 9.27s
Train Epoch: 1049 [40960/90000 (45%)]	Loss: -15.1391	Cost: 9.25s
Train Epoch: 1049 [61440/90000 (68%)]	Loss: -15.2256	Cost: 9.04s
Train Epoch: 1049 [81920/90000 (91%)]	Loss: -15.2544	Cost: 10.18s
Train Epoch: 1049 	Average Loss: -14.9482
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.9179

Learning rate: 0.00019461870737965656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1050 [0/90000 (0%)]	Loss: -9.7818	Cost: 24.09s
Train Epoch: 1050 [20480/90000 (23%)]	Loss: -15.5522	Cost: 9.00s
Train Epoch: 1050 [40960/90000 (45%)]	Loss: -15.2174	Cost: 9.68s
Train Epoch: 1050 [61440/90000 (68%)]	Loss: -15.2232	Cost: 9.05s
Train Epoch: 1050 [81920/90000 (91%)]	Loss: -15.0261	Cost: 10.45s
Train Epoch: 1050 	Average Loss: -15.0191
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8736

Saving model as model.pt_e1050 & waveforms_supplementary.hdf5_e1050
Learning rate: 0.00019460853588275422
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1051 [0/90000 (0%)]	Loss: -9.6903	Cost: 25.02s
Train Epoch: 1051 [20480/90000 (23%)]	Loss: -15.5690	Cost: 9.01s
Train Epoch: 1051 [40960/90000 (45%)]	Loss: -15.1874	Cost: 9.50s
Train Epoch: 1051 [61440/90000 (68%)]	Loss: -15.2452	Cost: 9.03s
Train Epoch: 1051 [81920/90000 (91%)]	Loss: -15.2768	Cost: 10.88s
Train Epoch: 1051 	Average Loss: -15.0270
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.9251

Learning rate: 0.00019459835504836374
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1052 [0/90000 (0%)]	Loss: -9.6048	Cost: 24.11s
Train Epoch: 1052 [20480/90000 (23%)]	Loss: -15.7457	Cost: 9.10s
Train Epoch: 1052 [40960/90000 (45%)]	Loss: -15.5299	Cost: 10.12s
Train Epoch: 1052 [61440/90000 (68%)]	Loss: -15.5541	Cost: 9.04s
Train Epoch: 1052 [81920/90000 (91%)]	Loss: -15.4961	Cost: 10.38s
Train Epoch: 1052 	Average Loss: -15.2251
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1761

Learning rate: 0.0001945881648774899
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1053 [0/90000 (0%)]	Loss: -9.6961	Cost: 24.47s
Train Epoch: 1053 [20480/90000 (23%)]	Loss: -16.0044	Cost: 9.08s
Train Epoch: 1053 [40960/90000 (45%)]	Loss: -15.5624	Cost: 9.44s
Train Epoch: 1053 [61440/90000 (68%)]	Loss: -15.6593	Cost: 9.13s
Train Epoch: 1053 [81920/90000 (91%)]	Loss: -15.5449	Cost: 9.08s
Train Epoch: 1053 	Average Loss: -15.3677
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.0056

Learning rate: 0.00019457796537113845
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1054 [0/90000 (0%)]	Loss: -9.7339	Cost: 25.27s
Train Epoch: 1054 [20480/90000 (23%)]	Loss: -15.3744	Cost: 9.11s
Train Epoch: 1054 [40960/90000 (45%)]	Loss: -15.1858	Cost: 9.09s
Train Epoch: 1054 [61440/90000 (68%)]	Loss: -15.3088	Cost: 8.95s
Train Epoch: 1054 [81920/90000 (91%)]	Loss: -15.2924	Cost: 8.99s
Train Epoch: 1054 	Average Loss: -14.9379
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.0430

Learning rate: 0.00019456775653031605
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1055 [0/90000 (0%)]	Loss: -9.4113	Cost: 26.04s
Train Epoch: 1055 [20480/90000 (23%)]	Loss: -15.7783	Cost: 9.00s
Train Epoch: 1055 [40960/90000 (45%)]	Loss: -15.6345	Cost: 9.96s
Train Epoch: 1055 [61440/90000 (68%)]	Loss: -15.6887	Cost: 9.06s
Train Epoch: 1055 [81920/90000 (91%)]	Loss: -15.5056	Cost: 8.80s
Train Epoch: 1055 	Average Loss: -15.2778
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.0776

Learning rate: 0.0001945575383560303
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1056 [0/90000 (0%)]	Loss: -9.9006	Cost: 26.22s
Train Epoch: 1056 [20480/90000 (23%)]	Loss: -16.0539	Cost: 9.33s
Train Epoch: 1056 [40960/90000 (45%)]	Loss: -15.6932	Cost: 9.30s
Train Epoch: 1056 [61440/90000 (68%)]	Loss: -15.7516	Cost: 9.10s
Train Epoch: 1056 [81920/90000 (91%)]	Loss: -15.6496	Cost: 8.83s
Train Epoch: 1056 	Average Loss: -15.4355
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1074

Learning rate: 0.00019454731084928963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1057 [0/90000 (0%)]	Loss: -8.7964	Cost: 25.15s
Train Epoch: 1057 [20480/90000 (23%)]	Loss: -16.0793	Cost: 9.47s
Train Epoch: 1057 [40960/90000 (45%)]	Loss: -15.6751	Cost: 9.25s
Train Epoch: 1057 [61440/90000 (68%)]	Loss: -15.8201	Cost: 9.35s
Train Epoch: 1057 [81920/90000 (91%)]	Loss: -15.6242	Cost: 9.04s
Train Epoch: 1057 	Average Loss: -15.3811
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.0609

Learning rate: 0.0001945370740111035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1058 [0/90000 (0%)]	Loss: -9.8469	Cost: 27.03s
Train Epoch: 1058 [20480/90000 (23%)]	Loss: -15.9065	Cost: 9.26s
Train Epoch: 1058 [40960/90000 (45%)]	Loss: -15.8978	Cost: 9.35s
Train Epoch: 1058 [61440/90000 (68%)]	Loss: -15.5242	Cost: 9.19s
Train Epoch: 1058 [81920/90000 (91%)]	Loss: -15.4540	Cost: 8.97s
Train Epoch: 1058 	Average Loss: -15.3792
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.9159

Learning rate: 0.00019452682784248221
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1059 [0/90000 (0%)]	Loss: -9.5678	Cost: 24.72s
Train Epoch: 1059 [20480/90000 (23%)]	Loss: -15.9482	Cost: 9.36s
Train Epoch: 1059 [40960/90000 (45%)]	Loss: -15.4130	Cost: 9.22s
Train Epoch: 1059 [61440/90000 (68%)]	Loss: -15.5064	Cost: 9.21s
Train Epoch: 1059 [81920/90000 (91%)]	Loss: -15.4581	Cost: 9.20s
Train Epoch: 1059 	Average Loss: -15.2740
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.0657

Learning rate: 0.00019451657234443705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1060 [0/90000 (0%)]	Loss: -9.2674	Cost: 25.71s
Train Epoch: 1060 [20480/90000 (23%)]	Loss: -15.9451	Cost: 9.31s
Train Epoch: 1060 [40960/90000 (45%)]	Loss: -15.7447	Cost: 9.29s
Train Epoch: 1060 [61440/90000 (68%)]	Loss: -15.7486	Cost: 9.20s
Train Epoch: 1060 [81920/90000 (91%)]	Loss: -15.7443	Cost: 8.95s
Train Epoch: 1060 	Average Loss: -15.4226
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1473

Learning rate: 0.00019450630751798018
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1061 [0/90000 (0%)]	Loss: -9.9971	Cost: 25.41s
Train Epoch: 1061 [20480/90000 (23%)]	Loss: -16.0886	Cost: 9.38s
Train Epoch: 1061 [40960/90000 (45%)]	Loss: -15.8469	Cost: 9.30s
Train Epoch: 1061 [61440/90000 (68%)]	Loss: -15.5507	Cost: 9.22s
Train Epoch: 1061 [81920/90000 (91%)]	Loss: -15.7467	Cost: 9.21s
Train Epoch: 1061 	Average Loss: -15.4765
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1228

Learning rate: 0.0001944960333641247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1062 [0/90000 (0%)]	Loss: -10.2817	Cost: 25.50s
Train Epoch: 1062 [20480/90000 (23%)]	Loss: -16.1247	Cost: 9.18s
Train Epoch: 1062 [40960/90000 (45%)]	Loss: -15.4761	Cost: 9.46s
Train Epoch: 1062 [61440/90000 (68%)]	Loss: -15.8431	Cost: 9.23s
Train Epoch: 1062 [81920/90000 (91%)]	Loss: -15.6385	Cost: 9.00s
Train Epoch: 1062 	Average Loss: -15.4938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2281

Learning rate: 0.0001944857498838846
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1063 [0/90000 (0%)]	Loss: -9.4913	Cost: 26.48s
Train Epoch: 1063 [20480/90000 (23%)]	Loss: -16.1035	Cost: 9.08s
Train Epoch: 1063 [40960/90000 (45%)]	Loss: -15.9456	Cost: 10.75s
Train Epoch: 1063 [61440/90000 (68%)]	Loss: -15.7211	Cost: 9.18s
Train Epoch: 1063 [81920/90000 (91%)]	Loss: -15.8065	Cost: 9.37s
Train Epoch: 1063 	Average Loss: -15.5798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.3866

Learning rate: 0.00019447545707827488
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1064 [0/90000 (0%)]	Loss: -9.9391	Cost: 25.12s
Train Epoch: 1064 [20480/90000 (23%)]	Loss: -16.0552	Cost: 9.17s
Train Epoch: 1064 [40960/90000 (45%)]	Loss: -15.7343	Cost: 9.33s
Train Epoch: 1064 [61440/90000 (68%)]	Loss: -15.6522	Cost: 9.17s
Train Epoch: 1064 [81920/90000 (91%)]	Loss: -15.6451	Cost: 9.14s
Train Epoch: 1064 	Average Loss: -15.4544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2005

Learning rate: 0.00019446515494831135
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1065 [0/90000 (0%)]	Loss: -9.1569	Cost: 25.64s
Train Epoch: 1065 [20480/90000 (23%)]	Loss: -16.1607	Cost: 9.25s
Train Epoch: 1065 [40960/90000 (45%)]	Loss: -16.1176	Cost: 9.60s
Train Epoch: 1065 [61440/90000 (68%)]	Loss: -15.6144	Cost: 9.09s
Train Epoch: 1065 [81920/90000 (91%)]	Loss: -15.8719	Cost: 9.04s
Train Epoch: 1065 	Average Loss: -15.5789
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4189

Learning rate: 0.00019445484349501084
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1066 [0/90000 (0%)]	Loss: -9.6168	Cost: 25.69s
Train Epoch: 1066 [20480/90000 (23%)]	Loss: -16.2346	Cost: 9.35s
Train Epoch: 1066 [40960/90000 (45%)]	Loss: -15.8195	Cost: 9.25s
Train Epoch: 1066 [61440/90000 (68%)]	Loss: -15.6082	Cost: 9.12s
Train Epoch: 1066 [81920/90000 (91%)]	Loss: -15.6520	Cost: 8.77s
Train Epoch: 1066 	Average Loss: -15.4992
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2156

Learning rate: 0.00019444452271939096
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1067 [0/90000 (0%)]	Loss: -9.8369	Cost: 24.81s
Train Epoch: 1067 [20480/90000 (23%)]	Loss: -16.0722	Cost: 9.06s
Train Epoch: 1067 [40960/90000 (45%)]	Loss: -15.8419	Cost: 9.77s
Train Epoch: 1067 [61440/90000 (68%)]	Loss: -15.5480	Cost: 9.05s
Train Epoch: 1067 [81920/90000 (91%)]	Loss: -15.6114	Cost: 9.24s
Train Epoch: 1067 	Average Loss: -15.4495
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1851

Learning rate: 0.0001944341926224704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1068 [0/90000 (0%)]	Loss: -9.8155	Cost: 24.51s
Train Epoch: 1068 [20480/90000 (23%)]	Loss: -16.3247	Cost: 9.48s
Train Epoch: 1068 [40960/90000 (45%)]	Loss: -15.8024	Cost: 9.19s
Train Epoch: 1068 [61440/90000 (68%)]	Loss: -15.8763	Cost: 9.05s
Train Epoch: 1068 [81920/90000 (91%)]	Loss: -15.3999	Cost: 9.65s
Train Epoch: 1068 	Average Loss: -15.4833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.0012

Learning rate: 0.00019442385320526872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1069 [0/90000 (0%)]	Loss: -10.0667	Cost: 24.06s
Train Epoch: 1069 [20480/90000 (23%)]	Loss: -16.0401	Cost: 9.57s
Train Epoch: 1069 [40960/90000 (45%)]	Loss: -15.7578	Cost: 9.33s
Train Epoch: 1069 [61440/90000 (68%)]	Loss: -15.7491	Cost: 9.11s
Train Epoch: 1069 [81920/90000 (91%)]	Loss: -15.5089	Cost: 9.98s
Train Epoch: 1069 	Average Loss: -15.4668
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.0473

Learning rate: 0.00019441350446880632
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1070 [0/90000 (0%)]	Loss: -9.1853	Cost: 25.14s
Train Epoch: 1070 [20480/90000 (23%)]	Loss: -15.5737	Cost: 9.29s
Train Epoch: 1070 [40960/90000 (45%)]	Loss: -15.3327	Cost: 9.37s
Train Epoch: 1070 [61440/90000 (68%)]	Loss: -15.5621	Cost: 9.06s
Train Epoch: 1070 [81920/90000 (91%)]	Loss: -15.6549	Cost: 10.31s
Train Epoch: 1070 	Average Loss: -15.2757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2494

Learning rate: 0.00019440314641410464
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1071 [0/90000 (0%)]	Loss: -9.6479	Cost: 23.81s
Train Epoch: 1071 [20480/90000 (23%)]	Loss: -16.2312	Cost: 9.01s
Train Epoch: 1071 [40960/90000 (45%)]	Loss: -16.0014	Cost: 9.17s
Train Epoch: 1071 [61440/90000 (68%)]	Loss: -16.0673	Cost: 9.11s
Train Epoch: 1071 [81920/90000 (91%)]	Loss: -15.9170	Cost: 9.35s
Train Epoch: 1071 	Average Loss: -15.6564
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1930

Learning rate: 0.0001943927790421859
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1072 [0/90000 (0%)]	Loss: -10.7213	Cost: 24.95s
Train Epoch: 1072 [20480/90000 (23%)]	Loss: -16.2385	Cost: 9.06s
Train Epoch: 1072 [40960/90000 (45%)]	Loss: -16.0838	Cost: 9.89s
Train Epoch: 1072 [61440/90000 (68%)]	Loss: -16.0984	Cost: 9.05s
Train Epoch: 1072 [81920/90000 (91%)]	Loss: -15.8923	Cost: 10.73s
Train Epoch: 1072 	Average Loss: -15.7182
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.3261

Learning rate: 0.00019438240235407337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1073 [0/90000 (0%)]	Loss: -9.7719	Cost: 22.93s
Train Epoch: 1073 [20480/90000 (23%)]	Loss: -16.4627	Cost: 9.10s
Train Epoch: 1073 [40960/90000 (45%)]	Loss: -15.4035	Cost: 9.02s
Train Epoch: 1073 [61440/90000 (68%)]	Loss: -15.4408	Cost: 8.95s
Train Epoch: 1073 [81920/90000 (91%)]	Loss: -15.3332	Cost: 9.05s
Train Epoch: 1073 	Average Loss: -15.4048
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.9631

Learning rate: 0.0001943720163507912
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1074 [0/90000 (0%)]	Loss: -9.1920	Cost: 23.53s
Train Epoch: 1074 [20480/90000 (23%)]	Loss: -16.0797	Cost: 9.09s
Train Epoch: 1074 [40960/90000 (45%)]	Loss: -15.6806	Cost: 9.09s
Train Epoch: 1074 [61440/90000 (68%)]	Loss: -15.6339	Cost: 8.96s
Train Epoch: 1074 [81920/90000 (91%)]	Loss: -15.7189	Cost: 8.91s
Train Epoch: 1074 	Average Loss: -15.3726
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2406

Learning rate: 0.0001943616210333644
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1075 [0/90000 (0%)]	Loss: -9.5147	Cost: 25.57s
Train Epoch: 1075 [20480/90000 (23%)]	Loss: -16.0816	Cost: 9.01s
Train Epoch: 1075 [40960/90000 (45%)]	Loss: -15.8292	Cost: 9.80s
Train Epoch: 1075 [61440/90000 (68%)]	Loss: -15.8065	Cost: 8.97s
Train Epoch: 1075 [81920/90000 (91%)]	Loss: -15.7627	Cost: 8.85s
Train Epoch: 1075 	Average Loss: -15.5478
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4274

Learning rate: 0.000194351216402819
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1076 [0/90000 (0%)]	Loss: -10.1852	Cost: 26.24s
Train Epoch: 1076 [20480/90000 (23%)]	Loss: -16.2095	Cost: 9.00s
Train Epoch: 1076 [40960/90000 (45%)]	Loss: -16.0546	Cost: 9.09s
Train Epoch: 1076 [61440/90000 (68%)]	Loss: -16.0132	Cost: 8.96s
Train Epoch: 1076 [81920/90000 (91%)]	Loss: -15.9858	Cost: 8.73s
Train Epoch: 1076 	Average Loss: -15.7161
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.3257

Learning rate: 0.00019434080246018187
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1077 [0/90000 (0%)]	Loss: -9.8889	Cost: 26.56s
Train Epoch: 1077 [20480/90000 (23%)]	Loss: -16.4531	Cost: 9.06s
Train Epoch: 1077 [40960/90000 (45%)]	Loss: -16.1458	Cost: 9.14s
Train Epoch: 1077 [61440/90000 (68%)]	Loss: -15.8840	Cost: 9.02s
Train Epoch: 1077 [81920/90000 (91%)]	Loss: -15.2372	Cost: 8.94s
Train Epoch: 1077 	Average Loss: -15.6777
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.9636

Learning rate: 0.00019433037920648082
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1078 [0/90000 (0%)]	Loss: -10.2502	Cost: 25.47s
Train Epoch: 1078 [20480/90000 (23%)]	Loss: -16.1140	Cost: 9.04s
Train Epoch: 1078 [40960/90000 (45%)]	Loss: -15.7515	Cost: 9.08s
Train Epoch: 1078 [61440/90000 (68%)]	Loss: -15.9191	Cost: 9.02s
Train Epoch: 1078 [81920/90000 (91%)]	Loss: -15.3175	Cost: 8.77s
Train Epoch: 1078 	Average Loss: -15.4118
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1225

Learning rate: 0.0001943199466427446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1079 [0/90000 (0%)]	Loss: -10.0885	Cost: 25.62s
Train Epoch: 1079 [20480/90000 (23%)]	Loss: -16.0922	Cost: 9.10s
Train Epoch: 1079 [40960/90000 (45%)]	Loss: -15.9307	Cost: 9.23s
Train Epoch: 1079 [61440/90000 (68%)]	Loss: -15.8641	Cost: 8.96s
Train Epoch: 1079 [81920/90000 (91%)]	Loss: -15.5902	Cost: 9.26s
Train Epoch: 1079 	Average Loss: -15.5071
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4323

Learning rate: 0.0001943095047700028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1080 [0/90000 (0%)]	Loss: -9.9480	Cost: 25.63s
Train Epoch: 1080 [20480/90000 (23%)]	Loss: -16.0842	Cost: 9.34s
Train Epoch: 1080 [40960/90000 (45%)]	Loss: -15.9623	Cost: 9.34s
Train Epoch: 1080 [61440/90000 (68%)]	Loss: -15.8755	Cost: 9.13s
Train Epoch: 1080 [81920/90000 (91%)]	Loss: -15.9199	Cost: 8.98s
Train Epoch: 1080 	Average Loss: -15.5416
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.3672

Learning rate: 0.00019429905358928608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1081 [0/90000 (0%)]	Loss: -9.1830	Cost: 25.67s
Train Epoch: 1081 [20480/90000 (23%)]	Loss: -16.3790	Cost: 9.22s
Train Epoch: 1081 [40960/90000 (45%)]	Loss: -16.1024	Cost: 10.05s
Train Epoch: 1081 [61440/90000 (68%)]	Loss: -15.6536	Cost: 9.26s
Train Epoch: 1081 [81920/90000 (91%)]	Loss: -15.5568	Cost: 8.86s
Train Epoch: 1081 	Average Loss: -15.5576
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2367

Learning rate: 0.0001942885931016259
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1082 [0/90000 (0%)]	Loss: -9.7763	Cost: 25.84s
Train Epoch: 1082 [20480/90000 (23%)]	Loss: -15.8897	Cost: 9.47s
Train Epoch: 1082 [40960/90000 (45%)]	Loss: -15.9242	Cost: 9.37s
Train Epoch: 1082 [61440/90000 (68%)]	Loss: -15.8177	Cost: 9.03s
Train Epoch: 1082 [81920/90000 (91%)]	Loss: -15.6868	Cost: 9.03s
Train Epoch: 1082 	Average Loss: -15.5388
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2790

Learning rate: 0.00019427812330805462
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1083 [0/90000 (0%)]	Loss: -9.4598	Cost: 25.67s
Train Epoch: 1083 [20480/90000 (23%)]	Loss: -16.3798	Cost: 9.45s
Train Epoch: 1083 [40960/90000 (45%)]	Loss: -16.1265	Cost: 9.29s
Train Epoch: 1083 [61440/90000 (68%)]	Loss: -16.1601	Cost: 9.14s
Train Epoch: 1083 [81920/90000 (91%)]	Loss: -16.0201	Cost: 8.83s
Train Epoch: 1083 	Average Loss: -15.8162
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4627

Learning rate: 0.00019426764420960564
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1084 [0/90000 (0%)]	Loss: -9.7227	Cost: 24.92s
Train Epoch: 1084 [20480/90000 (23%)]	Loss: -16.5292	Cost: 9.54s
Train Epoch: 1084 [40960/90000 (45%)]	Loss: -16.2472	Cost: 9.71s
Train Epoch: 1084 [61440/90000 (68%)]	Loss: -16.1554	Cost: 9.04s
Train Epoch: 1084 [81920/90000 (91%)]	Loss: -16.0000	Cost: 8.72s
Train Epoch: 1084 	Average Loss: -15.8832
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5224

Learning rate: 0.00019425715580731318
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1085 [0/90000 (0%)]	Loss: -9.5975	Cost: 24.43s
Train Epoch: 1085 [20480/90000 (23%)]	Loss: -16.4052	Cost: 9.60s
Train Epoch: 1085 [40960/90000 (45%)]	Loss: -16.0876	Cost: 9.11s
Train Epoch: 1085 [61440/90000 (68%)]	Loss: -15.5850	Cost: 9.05s
Train Epoch: 1085 [81920/90000 (91%)]	Loss: -15.6098	Cost: 10.19s
Train Epoch: 1085 	Average Loss: -15.6368
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1167

Learning rate: 0.00019424665810221242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1086 [0/90000 (0%)]	Loss: -9.7989	Cost: 24.52s
Train Epoch: 1086 [20480/90000 (23%)]	Loss: -16.0322	Cost: 9.55s
Train Epoch: 1086 [40960/90000 (45%)]	Loss: -16.0256	Cost: 9.16s
Train Epoch: 1086 [61440/90000 (68%)]	Loss: -15.9426	Cost: 9.27s
Train Epoch: 1086 [81920/90000 (91%)]	Loss: -16.0094	Cost: 9.80s
Train Epoch: 1086 	Average Loss: -15.5784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5224

Learning rate: 0.00019423615109533942
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1087 [0/90000 (0%)]	Loss: -9.9094	Cost: 25.12s
Train Epoch: 1087 [20480/90000 (23%)]	Loss: -16.2769	Cost: 9.43s
Train Epoch: 1087 [40960/90000 (45%)]	Loss: -16.1351	Cost: 9.21s
Train Epoch: 1087 [61440/90000 (68%)]	Loss: -16.1165	Cost: 9.13s
Train Epoch: 1087 [81920/90000 (91%)]	Loss: -15.8742	Cost: 9.96s
Train Epoch: 1087 	Average Loss: -15.7575
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.3330

Learning rate: 0.00019422563478773116
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1088 [0/90000 (0%)]	Loss: -10.2108	Cost: 23.72s
Train Epoch: 1088 [20480/90000 (23%)]	Loss: -16.2126	Cost: 9.10s
Train Epoch: 1088 [40960/90000 (45%)]	Loss: -15.8470	Cost: 9.29s
Train Epoch: 1088 [61440/90000 (68%)]	Loss: -16.0405	Cost: 9.04s
Train Epoch: 1088 [81920/90000 (91%)]	Loss: -15.9014	Cost: 10.09s
Train Epoch: 1088 	Average Loss: -15.6649
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5647

Learning rate: 0.00019421510918042557
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1089 [0/90000 (0%)]	Loss: -9.4208	Cost: 24.92s
Train Epoch: 1089 [20480/90000 (23%)]	Loss: -16.3946	Cost: 8.97s
Train Epoch: 1089 [40960/90000 (45%)]	Loss: -16.1521	Cost: 9.70s
Train Epoch: 1089 [61440/90000 (68%)]	Loss: -16.2536	Cost: 9.10s
Train Epoch: 1089 [81920/90000 (91%)]	Loss: -15.7888	Cost: 10.36s
Train Epoch: 1089 	Average Loss: -15.8060
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2571

Learning rate: 0.0001942045742744615
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1090 [0/90000 (0%)]	Loss: -10.2664	Cost: 23.66s
Train Epoch: 1090 [20480/90000 (23%)]	Loss: -16.2690	Cost: 9.05s
Train Epoch: 1090 [40960/90000 (45%)]	Loss: -16.1142	Cost: 9.03s
Train Epoch: 1090 [61440/90000 (68%)]	Loss: -16.2359	Cost: 9.04s
Train Epoch: 1090 [81920/90000 (91%)]	Loss: -15.7115	Cost: 9.02s
Train Epoch: 1090 	Average Loss: -15.6995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4639

Learning rate: 0.0001941940300708787
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1091 [0/90000 (0%)]	Loss: -9.5421	Cost: 23.50s
Train Epoch: 1091 [20480/90000 (23%)]	Loss: -16.2727	Cost: 9.06s
Train Epoch: 1091 [40960/90000 (45%)]	Loss: -15.7732	Cost: 9.06s
Train Epoch: 1091 [61440/90000 (68%)]	Loss: -15.9218	Cost: 8.97s
Train Epoch: 1091 [81920/90000 (91%)]	Loss: -15.7346	Cost: 9.00s
Train Epoch: 1091 	Average Loss: -15.6525
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.3708

Learning rate: 0.00019418347657071785
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1092 [0/90000 (0%)]	Loss: -10.1910	Cost: 26.28s
Train Epoch: 1092 [20480/90000 (23%)]	Loss: -16.2570	Cost: 9.24s
Train Epoch: 1092 [40960/90000 (45%)]	Loss: -15.9162	Cost: 9.05s
Train Epoch: 1092 [61440/90000 (68%)]	Loss: -16.0104	Cost: 8.91s
Train Epoch: 1092 [81920/90000 (91%)]	Loss: -15.7571	Cost: 8.97s
Train Epoch: 1092 	Average Loss: -15.6358
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4342

Learning rate: 0.0001941729137750205
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1093 [0/90000 (0%)]	Loss: -9.1670	Cost: 24.70s
Train Epoch: 1093 [20480/90000 (23%)]	Loss: -15.2352	Cost: 8.97s
Train Epoch: 1093 [40960/90000 (45%)]	Loss: -15.3562	Cost: 9.17s
Train Epoch: 1093 [61440/90000 (68%)]	Loss: -15.6594	Cost: 8.94s
Train Epoch: 1093 [81920/90000 (91%)]	Loss: -15.4910	Cost: 8.82s
Train Epoch: 1093 	Average Loss: -15.0073
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1842

Learning rate: 0.0001941623416848292
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1094 [0/90000 (0%)]	Loss: -9.7926	Cost: 26.38s
Train Epoch: 1094 [20480/90000 (23%)]	Loss: -16.1123	Cost: 9.10s
Train Epoch: 1094 [40960/90000 (45%)]	Loss: -15.9590	Cost: 9.08s
Train Epoch: 1094 [61440/90000 (68%)]	Loss: -16.0188	Cost: 8.94s
Train Epoch: 1094 [81920/90000 (91%)]	Loss: -15.9615	Cost: 8.76s
Train Epoch: 1094 	Average Loss: -15.7287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.6047

Learning rate: 0.00019415176030118734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1095 [0/90000 (0%)]	Loss: -10.2559	Cost: 25.04s
Train Epoch: 1095 [20480/90000 (23%)]	Loss: -16.3874	Cost: 9.35s
Train Epoch: 1095 [40960/90000 (45%)]	Loss: -16.0677	Cost: 9.28s
Train Epoch: 1095 [61440/90000 (68%)]	Loss: -15.9560	Cost: 9.10s
Train Epoch: 1095 [81920/90000 (91%)]	Loss: -15.8516	Cost: 8.77s
Train Epoch: 1095 	Average Loss: -15.7567
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5616

Learning rate: 0.00019414116962513932
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1096 [0/90000 (0%)]	Loss: -9.7843	Cost: 24.87s
Train Epoch: 1096 [20480/90000 (23%)]	Loss: -16.4707	Cost: 9.35s
Train Epoch: 1096 [40960/90000 (45%)]	Loss: -16.0996	Cost: 9.28s
Train Epoch: 1096 [61440/90000 (68%)]	Loss: -16.0316	Cost: 9.19s
Train Epoch: 1096 [81920/90000 (91%)]	Loss: -15.8554	Cost: 8.87s
Train Epoch: 1096 	Average Loss: -15.8235
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4992

Learning rate: 0.00019413056965773032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1097 [0/90000 (0%)]	Loss: -10.1737	Cost: 24.76s
Train Epoch: 1097 [20480/90000 (23%)]	Loss: -16.0619	Cost: 9.45s
Train Epoch: 1097 [40960/90000 (45%)]	Loss: -15.6832	Cost: 9.32s
Train Epoch: 1097 [61440/90000 (68%)]	Loss: -15.8214	Cost: 9.18s
Train Epoch: 1097 [81920/90000 (91%)]	Loss: -15.8873	Cost: 8.85s
Train Epoch: 1097 	Average Loss: -15.4960
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2196

Learning rate: 0.00019411996040000657
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1098 [0/90000 (0%)]	Loss: -10.1728	Cost: 25.30s
Train Epoch: 1098 [20480/90000 (23%)]	Loss: -15.8956	Cost: 9.36s
Train Epoch: 1098 [40960/90000 (45%)]	Loss: -15.8470	Cost: 9.34s
Train Epoch: 1098 [61440/90000 (68%)]	Loss: -16.0447	Cost: 9.10s
Train Epoch: 1098 [81920/90000 (91%)]	Loss: -15.9367	Cost: 8.84s
Train Epoch: 1098 	Average Loss: -15.6185
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5839

Learning rate: 0.00019410934185301514
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1099 [0/90000 (0%)]	Loss: -10.3721	Cost: 25.74s
Train Epoch: 1099 [20480/90000 (23%)]	Loss: -16.4012	Cost: 9.27s
Train Epoch: 1099 [40960/90000 (45%)]	Loss: -16.1039	Cost: 9.29s
Train Epoch: 1099 [61440/90000 (68%)]	Loss: -16.0392	Cost: 9.05s
Train Epoch: 1099 [81920/90000 (91%)]	Loss: -16.1458	Cost: 9.12s
Train Epoch: 1099 	Average Loss: -15.8405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5753

Learning rate: 0.00019409871401780405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1100 [0/90000 (0%)]	Loss: -10.3658	Cost: 25.86s
Train Epoch: 1100 [20480/90000 (23%)]	Loss: -16.6630	Cost: 9.27s
Train Epoch: 1100 [40960/90000 (45%)]	Loss: -16.4762	Cost: 10.39s
Train Epoch: 1100 [61440/90000 (68%)]	Loss: -16.1647	Cost: 9.16s
Train Epoch: 1100 [81920/90000 (91%)]	Loss: -15.9249	Cost: 8.81s
Train Epoch: 1100 	Average Loss: -16.0443
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7074

Saving model as model.pt_e1100 & waveforms_supplementary.hdf5_e1100
Learning rate: 0.0001940880768954222
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1101 [0/90000 (0%)]	Loss: -10.0075	Cost: 26.01s
Train Epoch: 1101 [20480/90000 (23%)]	Loss: -16.3131	Cost: 9.41s
Train Epoch: 1101 [40960/90000 (45%)]	Loss: -16.2869	Cost: 9.21s
Train Epoch: 1101 [61440/90000 (68%)]	Loss: -16.2491	Cost: 9.06s
Train Epoch: 1101 [81920/90000 (91%)]	Loss: -16.1810	Cost: 8.82s
Train Epoch: 1101 	Average Loss: -15.9699
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7021

Learning rate: 0.00019407743048691943
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1102 [0/90000 (0%)]	Loss: -10.3346	Cost: 24.80s
Train Epoch: 1102 [20480/90000 (23%)]	Loss: -16.7000	Cost: 9.71s
Train Epoch: 1102 [40960/90000 (45%)]	Loss: -16.4391	Cost: 9.09s
Train Epoch: 1102 [61440/90000 (68%)]	Loss: -16.2499	Cost: 8.98s
Train Epoch: 1102 [81920/90000 (91%)]	Loss: -16.0395	Cost: 8.75s
Train Epoch: 1102 	Average Loss: -16.0146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7246

Learning rate: 0.00019406677479334654
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1103 [0/90000 (0%)]	Loss: -9.5771	Cost: 25.04s
Train Epoch: 1103 [20480/90000 (23%)]	Loss: -16.3859	Cost: 9.57s
Train Epoch: 1103 [40960/90000 (45%)]	Loss: -16.3090	Cost: 9.23s
Train Epoch: 1103 [61440/90000 (68%)]	Loss: -16.0943	Cost: 9.07s
Train Epoch: 1103 [81920/90000 (91%)]	Loss: -16.1322	Cost: 9.40s
Train Epoch: 1103 	Average Loss: -15.9227
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.6605

Learning rate: 0.0001940561098157552
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1104 [0/90000 (0%)]	Loss: -9.1481	Cost: 24.15s
Train Epoch: 1104 [20480/90000 (23%)]	Loss: -16.5072	Cost: 9.47s
Train Epoch: 1104 [40960/90000 (45%)]	Loss: -16.1608	Cost: 9.92s
Train Epoch: 1104 [61440/90000 (68%)]	Loss: -15.9829	Cost: 9.11s
Train Epoch: 1104 [81920/90000 (91%)]	Loss: -16.1597	Cost: 9.93s
Train Epoch: 1104 	Average Loss: -15.8681
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.8217

Learning rate: 0.00019404543555519795
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1105 [0/90000 (0%)]	Loss: -10.1847	Cost: 24.35s
Train Epoch: 1105 [20480/90000 (23%)]	Loss: -16.6572	Cost: 9.54s
Train Epoch: 1105 [40960/90000 (45%)]	Loss: -16.5214	Cost: 9.32s
Train Epoch: 1105 [61440/90000 (68%)]	Loss: -16.2184	Cost: 9.30s
Train Epoch: 1105 [81920/90000 (91%)]	Loss: -16.2209	Cost: 10.05s
Train Epoch: 1105 	Average Loss: -16.0913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7231

Learning rate: 0.00019403475201272834
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1106 [0/90000 (0%)]	Loss: -10.0689	Cost: 24.24s
Train Epoch: 1106 [20480/90000 (23%)]	Loss: -16.7926	Cost: 9.24s
Train Epoch: 1106 [40960/90000 (45%)]	Loss: -16.1936	Cost: 9.64s
Train Epoch: 1106 [61440/90000 (68%)]	Loss: -15.9743	Cost: 9.07s
Train Epoch: 1106 [81920/90000 (91%)]	Loss: -16.1827	Cost: 10.07s
Train Epoch: 1106 	Average Loss: -15.9052
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5726

Learning rate: 0.00019402405918940077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1107 [0/90000 (0%)]	Loss: -10.3888	Cost: 24.95s
Train Epoch: 1107 [20480/90000 (23%)]	Loss: -16.1085	Cost: 9.33s
Train Epoch: 1107 [40960/90000 (45%)]	Loss: -16.1606	Cost: 9.66s
Train Epoch: 1107 [61440/90000 (68%)]	Loss: -15.9725	Cost: 9.46s
Train Epoch: 1107 [81920/90000 (91%)]	Loss: -16.0658	Cost: 9.84s
Train Epoch: 1107 	Average Loss: -15.7813
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5930

Learning rate: 0.00019401335708627064
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1108 [0/90000 (0%)]	Loss: -10.7301	Cost: 23.28s
Train Epoch: 1108 [20480/90000 (23%)]	Loss: -16.6943	Cost: 9.41s
Train Epoch: 1108 [40960/90000 (45%)]	Loss: -16.5061	Cost: 9.29s
Train Epoch: 1108 [61440/90000 (68%)]	Loss: -16.4629	Cost: 9.59s
Train Epoch: 1108 [81920/90000 (91%)]	Loss: -16.3185	Cost: 9.79s
Train Epoch: 1108 	Average Loss: -16.1010
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.6914

Learning rate: 0.00019400264570439412
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1109 [0/90000 (0%)]	Loss: -10.3225	Cost: 22.93s
Train Epoch: 1109 [20480/90000 (23%)]	Loss: -16.6032	Cost: 9.41s
Train Epoch: 1109 [40960/90000 (45%)]	Loss: -16.5331	Cost: 9.32s
Train Epoch: 1109 [61440/90000 (68%)]	Loss: -16.4070	Cost: 9.28s
Train Epoch: 1109 [81920/90000 (91%)]	Loss: -16.5344	Cost: 9.37s
Train Epoch: 1109 	Average Loss: -16.2165
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7163

Learning rate: 0.0001939919250448284
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1110 [0/90000 (0%)]	Loss: -11.0220	Cost: 24.38s
Train Epoch: 1110 [20480/90000 (23%)]	Loss: -16.7829	Cost: 9.41s
Train Epoch: 1110 [40960/90000 (45%)]	Loss: -16.6790	Cost: 9.31s
Train Epoch: 1110 [61440/90000 (68%)]	Loss: -16.5719	Cost: 9.13s
Train Epoch: 1110 [81920/90000 (91%)]	Loss: -16.2084	Cost: 9.12s
Train Epoch: 1110 	Average Loss: -16.1798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7217

Learning rate: 0.00019398119510863161
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1111 [0/90000 (0%)]	Loss: -10.9424	Cost: 25.23s
Train Epoch: 1111 [20480/90000 (23%)]	Loss: -16.6616	Cost: 9.53s
Train Epoch: 1111 [40960/90000 (45%)]	Loss: -16.5944	Cost: 9.90s
Train Epoch: 1111 [61440/90000 (68%)]	Loss: -16.5418	Cost: 9.71s
Train Epoch: 1111 [81920/90000 (91%)]	Loss: -16.1125	Cost: 9.75s
Train Epoch: 1111 	Average Loss: -16.2120
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7448

Learning rate: 0.00019397045589686273
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1112 [0/90000 (0%)]	Loss: -9.8773	Cost: 26.38s
Train Epoch: 1112 [20480/90000 (23%)]	Loss: -16.6709	Cost: 9.34s
Train Epoch: 1112 [40960/90000 (45%)]	Loss: -16.4417	Cost: 9.32s
Train Epoch: 1112 [61440/90000 (68%)]	Loss: -16.4790	Cost: 9.10s
Train Epoch: 1112 [81920/90000 (91%)]	Loss: -16.0069	Cost: 9.10s
Train Epoch: 1112 	Average Loss: -16.0582
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5394

Learning rate: 0.00019395970741058167
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1113 [0/90000 (0%)]	Loss: -10.7825	Cost: 26.03s
Train Epoch: 1113 [20480/90000 (23%)]	Loss: -16.5026	Cost: 9.37s
Train Epoch: 1113 [40960/90000 (45%)]	Loss: -16.3220	Cost: 9.29s
Train Epoch: 1113 [61440/90000 (68%)]	Loss: -16.3791	Cost: 9.14s
Train Epoch: 1113 [81920/90000 (91%)]	Loss: -16.3067	Cost: 9.27s
Train Epoch: 1113 	Average Loss: -16.0517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.8666

Learning rate: 0.00019394894965084927
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1114 [0/90000 (0%)]	Loss: -10.0274	Cost: 24.36s
Train Epoch: 1114 [20480/90000 (23%)]	Loss: -16.8280	Cost: 9.35s
Train Epoch: 1114 [40960/90000 (45%)]	Loss: -16.4589	Cost: 9.31s
Train Epoch: 1114 [61440/90000 (68%)]	Loss: -16.4549	Cost: 9.21s
Train Epoch: 1114 [81920/90000 (91%)]	Loss: -15.9158	Cost: 9.23s
Train Epoch: 1114 	Average Loss: -16.0854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5255

Learning rate: 0.00019393818261872732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1115 [0/90000 (0%)]	Loss: -9.8993	Cost: 25.10s
Train Epoch: 1115 [20480/90000 (23%)]	Loss: -16.4896	Cost: 9.33s
Train Epoch: 1115 [40960/90000 (45%)]	Loss: -16.3322	Cost: 9.28s
Train Epoch: 1115 [61440/90000 (68%)]	Loss: -16.5323	Cost: 9.25s
Train Epoch: 1115 [81920/90000 (91%)]	Loss: -16.1460	Cost: 9.83s
Train Epoch: 1115 	Average Loss: -16.0058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.8727

Learning rate: 0.0001939274063152784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1116 [0/90000 (0%)]	Loss: -10.5025	Cost: 24.65s
Train Epoch: 1116 [20480/90000 (23%)]	Loss: -16.4292	Cost: 9.41s
Train Epoch: 1116 [40960/90000 (45%)]	Loss: -16.1890	Cost: 9.27s
Train Epoch: 1116 [61440/90000 (68%)]	Loss: -16.1535	Cost: 9.43s
Train Epoch: 1116 [81920/90000 (91%)]	Loss: -16.1246	Cost: 8.80s
Train Epoch: 1116 	Average Loss: -15.9672
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5541

Learning rate: 0.00019391662074156612
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1117 [0/90000 (0%)]	Loss: -10.3495	Cost: 24.67s
Train Epoch: 1117 [20480/90000 (23%)]	Loss: -16.5986	Cost: 9.36s
Train Epoch: 1117 [40960/90000 (45%)]	Loss: -16.4468	Cost: 9.31s
Train Epoch: 1117 [61440/90000 (68%)]	Loss: -15.8793	Cost: 9.24s
Train Epoch: 1117 [81920/90000 (91%)]	Loss: -15.7499	Cost: 9.12s
Train Epoch: 1117 	Average Loss: -15.8215
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.3019

Learning rate: 0.00019390582589865496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1118 [0/90000 (0%)]	Loss: -9.8925	Cost: 24.87s
Train Epoch: 1118 [20480/90000 (23%)]	Loss: -16.2995	Cost: 9.31s
Train Epoch: 1118 [40960/90000 (45%)]	Loss: -16.4314	Cost: 9.24s
Train Epoch: 1118 [61440/90000 (68%)]	Loss: -16.3742	Cost: 9.21s
Train Epoch: 1118 [81920/90000 (91%)]	Loss: -16.3728	Cost: 8.97s
Train Epoch: 1118 	Average Loss: -15.9404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7766

Learning rate: 0.0001938950217876104
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1119 [0/90000 (0%)]	Loss: -10.3225	Cost: 24.85s
Train Epoch: 1119 [20480/90000 (23%)]	Loss: -16.6789	Cost: 9.30s
Train Epoch: 1119 [40960/90000 (45%)]	Loss: -16.5399	Cost: 9.43s
Train Epoch: 1119 [61440/90000 (68%)]	Loss: -16.4705	Cost: 9.15s
Train Epoch: 1119 [81920/90000 (91%)]	Loss: -16.4790	Cost: 9.04s
Train Epoch: 1119 	Average Loss: -16.1411
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0150

Learning rate: 0.00019388420840949869
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1120 [0/90000 (0%)]	Loss: -11.0027	Cost: 24.85s
Train Epoch: 1120 [20480/90000 (23%)]	Loss: -16.7076	Cost: 9.06s
Train Epoch: 1120 [40960/90000 (45%)]	Loss: -16.5668	Cost: 9.36s
Train Epoch: 1120 [61440/90000 (68%)]	Loss: -16.7410	Cost: 9.05s
Train Epoch: 1120 [81920/90000 (91%)]	Loss: -16.6070	Cost: 8.88s
Train Epoch: 1120 	Average Loss: -16.2740
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.8701

Learning rate: 0.00019387338576538711
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1121 [0/90000 (0%)]	Loss: -10.8444	Cost: 25.25s
Train Epoch: 1121 [20480/90000 (23%)]	Loss: -16.7171	Cost: 9.21s
Train Epoch: 1121 [40960/90000 (45%)]	Loss: -16.7666	Cost: 9.56s
Train Epoch: 1121 [61440/90000 (68%)]	Loss: -16.5210	Cost: 9.11s
Train Epoch: 1121 [81920/90000 (91%)]	Loss: -16.2556	Cost: 8.92s
Train Epoch: 1121 	Average Loss: -16.2793
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9236

Learning rate: 0.00019386255385634376
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1122 [0/90000 (0%)]	Loss: -10.5137	Cost: 25.26s
Train Epoch: 1122 [20480/90000 (23%)]	Loss: -16.8097	Cost: 8.98s
Train Epoch: 1122 [40960/90000 (45%)]	Loss: -16.6754	Cost: 9.53s
Train Epoch: 1122 [61440/90000 (68%)]	Loss: -16.6072	Cost: 8.93s
Train Epoch: 1122 [81920/90000 (91%)]	Loss: -16.4778	Cost: 8.67s
Train Epoch: 1122 	Average Loss: -16.2967
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5565

Learning rate: 0.00019385171268343775
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1123 [0/90000 (0%)]	Loss: -9.9011	Cost: 24.65s
Train Epoch: 1123 [20480/90000 (23%)]	Loss: -16.0884	Cost: 9.55s
Train Epoch: 1123 [40960/90000 (45%)]	Loss: -16.1997	Cost: 9.40s
Train Epoch: 1123 [61440/90000 (68%)]	Loss: -16.2207	Cost: 9.14s
Train Epoch: 1123 [81920/90000 (91%)]	Loss: -15.6045	Cost: 9.66s
Train Epoch: 1123 	Average Loss: -15.7277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2682

Learning rate: 0.00019384086224773903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1124 [0/90000 (0%)]	Loss: -10.2131	Cost: 23.83s
Train Epoch: 1124 [20480/90000 (23%)]	Loss: -16.3853	Cost: 9.02s
Train Epoch: 1124 [40960/90000 (45%)]	Loss: -16.2775	Cost: 9.64s
Train Epoch: 1124 [61440/90000 (68%)]	Loss: -16.3947	Cost: 9.04s
Train Epoch: 1124 [81920/90000 (91%)]	Loss: -16.3867	Cost: 10.01s
Train Epoch: 1124 	Average Loss: -15.9422
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.6099

Learning rate: 0.00019383000255031852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1125 [0/90000 (0%)]	Loss: -11.2179	Cost: 24.84s
Train Epoch: 1125 [20480/90000 (23%)]	Loss: -16.9013	Cost: 9.05s
Train Epoch: 1125 [40960/90000 (45%)]	Loss: -16.4947	Cost: 10.31s
Train Epoch: 1125 [61440/90000 (68%)]	Loss: -16.5811	Cost: 9.13s
Train Epoch: 1125 [81920/90000 (91%)]	Loss: -16.2409	Cost: 10.41s
Train Epoch: 1125 	Average Loss: -16.3260
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9691

Learning rate: 0.00019381913359224807
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1126 [0/90000 (0%)]	Loss: -10.7548	Cost: 25.34s
Train Epoch: 1126 [20480/90000 (23%)]	Loss: -16.9158	Cost: 9.04s
Train Epoch: 1126 [40960/90000 (45%)]	Loss: -16.5866	Cost: 10.44s
Train Epoch: 1126 [61440/90000 (68%)]	Loss: -16.3358	Cost: 9.00s
Train Epoch: 1126 [81920/90000 (91%)]	Loss: -16.1702	Cost: 10.54s
Train Epoch: 1126 	Average Loss: -16.2551
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9946

Learning rate: 0.00019380825537460033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1127 [0/90000 (0%)]	Loss: -10.3366	Cost: 24.59s
Train Epoch: 1127 [20480/90000 (23%)]	Loss: -16.7552	Cost: 9.05s
Train Epoch: 1127 [40960/90000 (45%)]	Loss: -16.4613	Cost: 9.47s
Train Epoch: 1127 [61440/90000 (68%)]	Loss: -16.5475	Cost: 9.04s
Train Epoch: 1127 [81920/90000 (91%)]	Loss: -16.4237	Cost: 10.80s
Train Epoch: 1127 	Average Loss: -16.1866
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0715

Learning rate: 0.00019379736789844898
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1128 [0/90000 (0%)]	Loss: -11.0558	Cost: 23.01s
Train Epoch: 1128 [20480/90000 (23%)]	Loss: -16.8070	Cost: 9.22s
Train Epoch: 1128 [40960/90000 (45%)]	Loss: -16.5485	Cost: 9.27s
Train Epoch: 1128 [61440/90000 (68%)]	Loss: -16.6699	Cost: 9.19s
Train Epoch: 1128 [81920/90000 (91%)]	Loss: -16.4160	Cost: 9.09s
Train Epoch: 1128 	Average Loss: -16.2859
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0796

Learning rate: 0.00019378647116486856
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1129 [0/90000 (0%)]	Loss: -10.9242	Cost: 23.66s
Train Epoch: 1129 [20480/90000 (23%)]	Loss: -16.9469	Cost: 9.41s
Train Epoch: 1129 [40960/90000 (45%)]	Loss: -16.5586	Cost: 9.26s
Train Epoch: 1129 [61440/90000 (68%)]	Loss: -16.6354	Cost: 9.11s
Train Epoch: 1129 [81920/90000 (91%)]	Loss: -16.3540	Cost: 9.34s
Train Epoch: 1129 	Average Loss: -16.2993
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0828

Learning rate: 0.0001937755651749345
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1130 [0/90000 (0%)]	Loss: -10.5891	Cost: 23.62s
Train Epoch: 1130 [20480/90000 (23%)]	Loss: -16.9787	Cost: 9.44s
Train Epoch: 1130 [40960/90000 (45%)]	Loss: -16.6065	Cost: 9.30s
Train Epoch: 1130 [61440/90000 (68%)]	Loss: -16.7005	Cost: 9.12s
Train Epoch: 1130 [81920/90000 (91%)]	Loss: -16.5004	Cost: 9.14s
Train Epoch: 1130 	Average Loss: -16.3235
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1144

Learning rate: 0.0001937646499297232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1131 [0/90000 (0%)]	Loss: -10.5740	Cost: 26.31s
Train Epoch: 1131 [20480/90000 (23%)]	Loss: -17.0044	Cost: 9.36s
Train Epoch: 1131 [40960/90000 (45%)]	Loss: -16.6177	Cost: 9.30s
Train Epoch: 1131 [61440/90000 (68%)]	Loss: -16.6440	Cost: 9.13s
Train Epoch: 1131 [81920/90000 (91%)]	Loss: -16.4997	Cost: 9.25s
Train Epoch: 1131 	Average Loss: -16.3925
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1335

Learning rate: 0.000193753725430312
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1132 [0/90000 (0%)]	Loss: -10.0469	Cost: 25.84s
Train Epoch: 1132 [20480/90000 (23%)]	Loss: -17.1028	Cost: 9.33s
Train Epoch: 1132 [40960/90000 (45%)]	Loss: -16.8169	Cost: 9.27s
Train Epoch: 1132 [61440/90000 (68%)]	Loss: -16.5262	Cost: 9.03s
Train Epoch: 1132 [81920/90000 (91%)]	Loss: -16.6819	Cost: 8.78s
Train Epoch: 1132 	Average Loss: -16.3704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2481

Learning rate: 0.00019374279167777905
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1133 [0/90000 (0%)]	Loss: -10.3823	Cost: 25.91s
Train Epoch: 1133 [20480/90000 (23%)]	Loss: -16.8453	Cost: 9.37s
Train Epoch: 1133 [40960/90000 (45%)]	Loss: -16.6018	Cost: 9.33s
Train Epoch: 1133 [61440/90000 (68%)]	Loss: -16.5135	Cost: 9.21s
Train Epoch: 1133 [81920/90000 (91%)]	Loss: -16.2918	Cost: 9.12s
Train Epoch: 1133 	Average Loss: -16.2998
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9517

Learning rate: 0.00019373184867320348
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1134 [0/90000 (0%)]	Loss: -10.1721	Cost: 27.46s
Train Epoch: 1134 [20480/90000 (23%)]	Loss: -16.6999	Cost: 9.50s
Train Epoch: 1134 [40960/90000 (45%)]	Loss: -16.2832	Cost: 9.43s
Train Epoch: 1134 [61440/90000 (68%)]	Loss: -16.3707	Cost: 9.04s
Train Epoch: 1134 [81920/90000 (91%)]	Loss: -16.4225	Cost: 8.80s
Train Epoch: 1134 	Average Loss: -16.0925
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9147

Learning rate: 0.00019372089641766534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1135 [0/90000 (0%)]	Loss: -10.1936	Cost: 24.80s
Train Epoch: 1135 [20480/90000 (23%)]	Loss: -16.8451	Cost: 9.36s
Train Epoch: 1135 [40960/90000 (45%)]	Loss: -16.3054	Cost: 9.25s
Train Epoch: 1135 [61440/90000 (68%)]	Loss: -16.5294	Cost: 9.12s
Train Epoch: 1135 [81920/90000 (91%)]	Loss: -16.2144	Cost: 8.81s
Train Epoch: 1135 	Average Loss: -16.0844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5857

Learning rate: 0.00019370993491224555
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1136 [0/90000 (0%)]	Loss: -9.2361	Cost: 25.05s
Train Epoch: 1136 [20480/90000 (23%)]	Loss: -16.7826	Cost: 9.42s
Train Epoch: 1136 [40960/90000 (45%)]	Loss: -16.5945	Cost: 9.25s
Train Epoch: 1136 [61440/90000 (68%)]	Loss: -16.6735	Cost: 9.19s
Train Epoch: 1136 [81920/90000 (91%)]	Loss: -16.4616	Cost: 8.92s
Train Epoch: 1136 	Average Loss: -16.2219
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9096

Learning rate: 0.00019369896415802597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1137 [0/90000 (0%)]	Loss: -10.7861	Cost: 24.69s
Train Epoch: 1137 [20480/90000 (23%)]	Loss: -16.7556	Cost: 9.26s
Train Epoch: 1137 [40960/90000 (45%)]	Loss: -16.7006	Cost: 9.37s
Train Epoch: 1137 [61440/90000 (68%)]	Loss: -16.7829	Cost: 9.15s
Train Epoch: 1137 [81920/90000 (91%)]	Loss: -16.5633	Cost: 9.10s
Train Epoch: 1137 	Average Loss: -16.3695
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0863

Learning rate: 0.0001936879841560894
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1138 [0/90000 (0%)]	Loss: -10.6814	Cost: 25.60s
Train Epoch: 1138 [20480/90000 (23%)]	Loss: -16.9414	Cost: 9.23s
Train Epoch: 1138 [40960/90000 (45%)]	Loss: -16.7432	Cost: 9.34s
Train Epoch: 1138 [61440/90000 (68%)]	Loss: -16.7430	Cost: 9.07s
Train Epoch: 1138 [81920/90000 (91%)]	Loss: -16.5760	Cost: 8.93s
Train Epoch: 1138 	Average Loss: -16.4313
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9776

Learning rate: 0.00019367699490751948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1139 [0/90000 (0%)]	Loss: -11.1350	Cost: 24.99s
Train Epoch: 1139 [20480/90000 (23%)]	Loss: -16.9137	Cost: 9.18s
Train Epoch: 1139 [40960/90000 (45%)]	Loss: -16.7590	Cost: 9.21s
Train Epoch: 1139 [61440/90000 (68%)]	Loss: -16.7618	Cost: 9.12s
Train Epoch: 1139 [81920/90000 (91%)]	Loss: -16.4189	Cost: 8.83s
Train Epoch: 1139 	Average Loss: -16.3700
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.8409

Learning rate: 0.0001936659964134008
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1140 [0/90000 (0%)]	Loss: -10.8584	Cost: 24.99s
Train Epoch: 1140 [20480/90000 (23%)]	Loss: -17.0270	Cost: 9.62s
Train Epoch: 1140 [40960/90000 (45%)]	Loss: -16.5274	Cost: 9.02s
Train Epoch: 1140 [61440/90000 (68%)]	Loss: -16.5615	Cost: 8.94s
Train Epoch: 1140 [81920/90000 (91%)]	Loss: -16.3486	Cost: 8.68s
Train Epoch: 1140 	Average Loss: -16.3056
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9170

Learning rate: 0.0001936549886748189
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1141 [0/90000 (0%)]	Loss: -10.6675	Cost: 25.27s
Train Epoch: 1141 [20480/90000 (23%)]	Loss: -16.7426	Cost: 9.53s
Train Epoch: 1141 [40960/90000 (45%)]	Loss: -16.6549	Cost: 9.93s
Train Epoch: 1141 [61440/90000 (68%)]	Loss: -16.6328	Cost: 9.05s
Train Epoch: 1141 [81920/90000 (91%)]	Loss: -16.5262	Cost: 9.36s
Train Epoch: 1141 	Average Loss: -16.3438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1057

Learning rate: 0.00019364397169286022
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1142 [0/90000 (0%)]	Loss: -10.4956	Cost: 24.13s
Train Epoch: 1142 [20480/90000 (23%)]	Loss: -17.0150	Cost: 9.56s
Train Epoch: 1142 [40960/90000 (45%)]	Loss: -16.9466	Cost: 9.16s
Train Epoch: 1142 [61440/90000 (68%)]	Loss: -16.9263	Cost: 9.06s
Train Epoch: 1142 [81920/90000 (91%)]	Loss: -16.6877	Cost: 9.86s
Train Epoch: 1142 	Average Loss: -16.5082
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2663

Learning rate: 0.00019363294546861204
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1143 [0/90000 (0%)]	Loss: -10.5128	Cost: 24.12s
Train Epoch: 1143 [20480/90000 (23%)]	Loss: -17.0637	Cost: 9.59s
Train Epoch: 1143 [40960/90000 (45%)]	Loss: -16.5170	Cost: 9.09s
Train Epoch: 1143 [61440/90000 (68%)]	Loss: -16.3480	Cost: 9.09s
Train Epoch: 1143 [81920/90000 (91%)]	Loss: -16.1565	Cost: 10.36s
Train Epoch: 1143 	Average Loss: -16.2878
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.6926

Learning rate: 0.00019362191000316264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1144 [0/90000 (0%)]	Loss: -10.4939	Cost: 23.12s
Train Epoch: 1144 [20480/90000 (23%)]	Loss: -16.5757	Cost: 9.39s
Train Epoch: 1144 [40960/90000 (45%)]	Loss: -16.4747	Cost: 9.09s
Train Epoch: 1144 [61440/90000 (68%)]	Loss: -16.5326	Cost: 9.10s
Train Epoch: 1144 [81920/90000 (91%)]	Loss: -16.6210	Cost: 9.74s
Train Epoch: 1144 	Average Loss: -16.1542
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9253

Learning rate: 0.0001936108652976012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1145 [0/90000 (0%)]	Loss: -10.2214	Cost: 24.35s
Train Epoch: 1145 [20480/90000 (23%)]	Loss: -17.0710	Cost: 9.06s
Train Epoch: 1145 [40960/90000 (45%)]	Loss: -16.8001	Cost: 9.16s
Train Epoch: 1145 [61440/90000 (68%)]	Loss: -16.7511	Cost: 9.10s
Train Epoch: 1145 [81920/90000 (91%)]	Loss: -16.5757	Cost: 9.27s
Train Epoch: 1145 	Average Loss: -16.4961
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0895

Learning rate: 0.0001935998113530177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1146 [0/90000 (0%)]	Loss: -11.0433	Cost: 22.24s
Train Epoch: 1146 [20480/90000 (23%)]	Loss: -16.5711	Cost: 9.02s
Train Epoch: 1146 [40960/90000 (45%)]	Loss: -15.7797	Cost: 9.30s
Train Epoch: 1146 [61440/90000 (68%)]	Loss: -15.8651	Cost: 9.20s
Train Epoch: 1146 [81920/90000 (91%)]	Loss: -15.9699	Cost: 9.00s
Train Epoch: 1146 	Average Loss: -15.8984
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7306

Learning rate: 0.0001935887481705032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1147 [0/90000 (0%)]	Loss: -10.5259	Cost: 24.94s
Train Epoch: 1147 [20480/90000 (23%)]	Loss: -16.7173	Cost: 9.08s
Train Epoch: 1147 [40960/90000 (45%)]	Loss: -16.6489	Cost: 9.20s
Train Epoch: 1147 [61440/90000 (68%)]	Loss: -16.6836	Cost: 8.91s
Train Epoch: 1147 [81920/90000 (91%)]	Loss: -16.4355	Cost: 8.97s
Train Epoch: 1147 	Average Loss: -16.3044
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0570

Learning rate: 0.00019357767575114954
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1148 [0/90000 (0%)]	Loss: -10.4698	Cost: 23.69s
Train Epoch: 1148 [20480/90000 (23%)]	Loss: -17.0682	Cost: 9.06s
Train Epoch: 1148 [40960/90000 (45%)]	Loss: -16.8836	Cost: 9.00s
Train Epoch: 1148 [61440/90000 (68%)]	Loss: -16.9030	Cost: 8.95s
Train Epoch: 1148 [81920/90000 (91%)]	Loss: -16.5308	Cost: 8.80s
Train Epoch: 1148 	Average Loss: -16.4984
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1028

Learning rate: 0.0001935665940960496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1149 [0/90000 (0%)]	Loss: -10.2468	Cost: 25.03s
Train Epoch: 1149 [20480/90000 (23%)]	Loss: -16.8926	Cost: 9.00s
Train Epoch: 1149 [40960/90000 (45%)]	Loss: -16.7007	Cost: 9.54s
Train Epoch: 1149 [61440/90000 (68%)]	Loss: -16.9217	Cost: 8.93s
Train Epoch: 1149 [81920/90000 (91%)]	Loss: -16.7383	Cost: 9.48s
Train Epoch: 1149 	Average Loss: -16.4440
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2244

Learning rate: 0.000193555503206297
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1150 [0/90000 (0%)]	Loss: -10.7400	Cost: 25.07s
Train Epoch: 1150 [20480/90000 (23%)]	Loss: -17.2562	Cost: 9.28s
Train Epoch: 1150 [40960/90000 (45%)]	Loss: -16.8200	Cost: 9.23s
Train Epoch: 1150 [61440/90000 (68%)]	Loss: -16.8548	Cost: 9.05s
Train Epoch: 1150 [81920/90000 (91%)]	Loss: -16.7368	Cost: 8.81s
Train Epoch: 1150 	Average Loss: -16.5291
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2513

Saving model as model.pt_e1150 & waveforms_supplementary.hdf5_e1150
Learning rate: 0.00019354440308298645
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1151 [0/90000 (0%)]	Loss: -11.2542	Cost: 23.88s
Train Epoch: 1151 [20480/90000 (23%)]	Loss: -17.1060	Cost: 9.38s
Train Epoch: 1151 [40960/90000 (45%)]	Loss: -17.0101	Cost: 9.27s
Train Epoch: 1151 [61440/90000 (68%)]	Loss: -16.7892	Cost: 9.02s
Train Epoch: 1151 [81920/90000 (91%)]	Loss: -16.5723	Cost: 8.78s
Train Epoch: 1151 	Average Loss: -16.6368
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1896

Learning rate: 0.00019353329372721341
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1152 [0/90000 (0%)]	Loss: -10.6869	Cost: 25.23s
Train Epoch: 1152 [20480/90000 (23%)]	Loss: -17.2770	Cost: 9.12s
Train Epoch: 1152 [40960/90000 (45%)]	Loss: -16.7884	Cost: 9.14s
Train Epoch: 1152 [61440/90000 (68%)]	Loss: -16.7606	Cost: 8.99s
Train Epoch: 1152 [81920/90000 (91%)]	Loss: -16.8761	Cost: 8.78s
Train Epoch: 1152 	Average Loss: -16.5375
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.3342

Learning rate: 0.0001935221751400744
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1153 [0/90000 (0%)]	Loss: -10.4275	Cost: 25.35s
Train Epoch: 1153 [20480/90000 (23%)]	Loss: -17.1054	Cost: 9.09s
Train Epoch: 1153 [40960/90000 (45%)]	Loss: -16.7300	Cost: 9.28s
Train Epoch: 1153 [61440/90000 (68%)]	Loss: -16.5824	Cost: 9.09s
Train Epoch: 1153 [81920/90000 (91%)]	Loss: -16.4530	Cost: 8.89s
Train Epoch: 1153 	Average Loss: -16.4214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0669

Learning rate: 0.00019351104732266675
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1154 [0/90000 (0%)]	Loss: -10.6633	Cost: 25.25s
Train Epoch: 1154 [20480/90000 (23%)]	Loss: -17.0900	Cost: 9.38s
Train Epoch: 1154 [40960/90000 (45%)]	Loss: -16.8000	Cost: 9.32s
Train Epoch: 1154 [61440/90000 (68%)]	Loss: -16.8651	Cost: 9.06s
Train Epoch: 1154 [81920/90000 (91%)]	Loss: -16.5709	Cost: 9.17s
Train Epoch: 1154 	Average Loss: -16.4456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2686

Learning rate: 0.00019349991027608872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1155 [0/90000 (0%)]	Loss: -11.0558	Cost: 25.80s
Train Epoch: 1155 [20480/90000 (23%)]	Loss: -17.1454	Cost: 9.73s
Train Epoch: 1155 [40960/90000 (45%)]	Loss: -16.8316	Cost: 9.26s
Train Epoch: 1155 [61440/90000 (68%)]	Loss: -16.5722	Cost: 9.14s
Train Epoch: 1155 [81920/90000 (91%)]	Loss: -16.4763	Cost: 8.77s
Train Epoch: 1155 	Average Loss: -16.4827
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1619

Learning rate: 0.0001934887640014395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1156 [0/90000 (0%)]	Loss: -11.2375	Cost: 24.97s
Train Epoch: 1156 [20480/90000 (23%)]	Loss: -17.3704	Cost: 9.04s
Train Epoch: 1156 [40960/90000 (45%)]	Loss: -17.1510	Cost: 9.72s
Train Epoch: 1156 [61440/90000 (68%)]	Loss: -16.8081	Cost: 9.01s
Train Epoch: 1156 [81920/90000 (91%)]	Loss: -16.8415	Cost: 8.81s
Train Epoch: 1156 	Average Loss: -16.6951
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4040

Learning rate: 0.00019347760849981922
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1157 [0/90000 (0%)]	Loss: -10.7113	Cost: 25.40s
Train Epoch: 1157 [20480/90000 (23%)]	Loss: -17.1221	Cost: 9.02s
Train Epoch: 1157 [40960/90000 (45%)]	Loss: -16.8680	Cost: 9.99s
Train Epoch: 1157 [61440/90000 (68%)]	Loss: -16.9768	Cost: 9.26s
Train Epoch: 1157 [81920/90000 (91%)]	Loss: -16.7964	Cost: 9.48s
Train Epoch: 1157 	Average Loss: -16.5887
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.3326

Learning rate: 0.00019346644377232883
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1158 [0/90000 (0%)]	Loss: -10.3293	Cost: 23.54s
Train Epoch: 1158 [20480/90000 (23%)]	Loss: -17.1002	Cost: 9.58s
Train Epoch: 1158 [40960/90000 (45%)]	Loss: -17.0095	Cost: 9.07s
Train Epoch: 1158 [61440/90000 (68%)]	Loss: -16.8431	Cost: 9.10s
Train Epoch: 1158 [81920/90000 (91%)]	Loss: -16.4738	Cost: 9.80s
Train Epoch: 1158 	Average Loss: -16.5581
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1001

Learning rate: 0.0001934552698200703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1159 [0/90000 (0%)]	Loss: -10.0341	Cost: 24.70s
Train Epoch: 1159 [20480/90000 (23%)]	Loss: -16.8477	Cost: 9.31s
Train Epoch: 1159 [40960/90000 (45%)]	Loss: -16.7053	Cost: 9.63s
Train Epoch: 1159 [61440/90000 (68%)]	Loss: -16.7206	Cost: 9.21s
Train Epoch: 1159 [81920/90000 (91%)]	Loss: -16.4364	Cost: 10.04s
Train Epoch: 1159 	Average Loss: -16.3985
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1382

Learning rate: 0.0001934440866441464
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1160 [0/90000 (0%)]	Loss: -9.6505	Cost: 25.04s
Train Epoch: 1160 [20480/90000 (23%)]	Loss: -16.6937	Cost: 9.06s
Train Epoch: 1160 [40960/90000 (45%)]	Loss: -16.6074	Cost: 9.68s
Train Epoch: 1160 [61440/90000 (68%)]	Loss: -16.3511	Cost: 9.09s
Train Epoch: 1160 [81920/90000 (91%)]	Loss: -16.4781	Cost: 10.19s
Train Epoch: 1160 	Average Loss: -16.3376
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0131

Learning rate: 0.0001934328942456609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1161 [0/90000 (0%)]	Loss: -10.7924	Cost: 24.01s
Train Epoch: 1161 [20480/90000 (23%)]	Loss: -17.2065	Cost: 9.30s
Train Epoch: 1161 [40960/90000 (45%)]	Loss: -16.7499	Cost: 10.03s
Train Epoch: 1161 [61440/90000 (68%)]	Loss: -16.9610	Cost: 9.11s
Train Epoch: 1161 [81920/90000 (91%)]	Loss: -16.6427	Cost: 11.09s
Train Epoch: 1161 	Average Loss: -16.5109
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1570

Learning rate: 0.0001934216926257184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1162 [0/90000 (0%)]	Loss: -10.9432	Cost: 23.73s
Train Epoch: 1162 [20480/90000 (23%)]	Loss: -17.0384	Cost: 9.26s
Train Epoch: 1162 [40960/90000 (45%)]	Loss: -16.8027	Cost: 9.25s
Train Epoch: 1162 [61440/90000 (68%)]	Loss: -16.8401	Cost: 9.22s
Train Epoch: 1162 [81920/90000 (91%)]	Loss: -16.1719	Cost: 9.35s
Train Epoch: 1162 	Average Loss: -16.3035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9778

Learning rate: 0.0001934104817854245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1163 [0/90000 (0%)]	Loss: -10.5579	Cost: 22.73s
Train Epoch: 1163 [20480/90000 (23%)]	Loss: -16.7510	Cost: 9.40s
Train Epoch: 1163 [40960/90000 (45%)]	Loss: -16.8153	Cost: 9.27s
Train Epoch: 1163 [61440/90000 (68%)]	Loss: -16.9286	Cost: 9.09s
Train Epoch: 1163 [81920/90000 (91%)]	Loss: -16.5330	Cost: 9.22s
Train Epoch: 1163 	Average Loss: -16.3472
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.3394

Learning rate: 0.00019339926172588564
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1164 [0/90000 (0%)]	Loss: -10.9343	Cost: 23.30s
Train Epoch: 1164 [20480/90000 (23%)]	Loss: -17.1048	Cost: 9.18s
Train Epoch: 1164 [40960/90000 (45%)]	Loss: -16.9489	Cost: 9.12s
Train Epoch: 1164 [61440/90000 (68%)]	Loss: -16.8127	Cost: 9.06s
Train Epoch: 1164 [81920/90000 (91%)]	Loss: -16.8441	Cost: 8.82s
Train Epoch: 1164 	Average Loss: -16.5578
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.3277

Learning rate: 0.00019338803244820925
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1165 [0/90000 (0%)]	Loss: -10.8288	Cost: 25.21s
Train Epoch: 1165 [20480/90000 (23%)]	Loss: -17.0474	Cost: 9.35s
Train Epoch: 1165 [40960/90000 (45%)]	Loss: -16.6353	Cost: 9.22s
Train Epoch: 1165 [61440/90000 (68%)]	Loss: -16.7637	Cost: 9.03s
Train Epoch: 1165 [81920/90000 (91%)]	Loss: -16.7971	Cost: 8.98s
Train Epoch: 1165 	Average Loss: -16.5408
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.3550

Learning rate: 0.00019337679395350357
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1166 [0/90000 (0%)]	Loss: -11.2293	Cost: 24.56s
Train Epoch: 1166 [20480/90000 (23%)]	Loss: -17.2901	Cost: 9.47s
Train Epoch: 1166 [40960/90000 (45%)]	Loss: -17.2493	Cost: 9.26s
Train Epoch: 1166 [61440/90000 (68%)]	Loss: -16.9719	Cost: 9.09s
Train Epoch: 1166 [81920/90000 (91%)]	Loss: -16.6453	Cost: 9.29s
Train Epoch: 1166 	Average Loss: -16.7092
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2753

Learning rate: 0.00019336554624287778
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1167 [0/90000 (0%)]	Loss: -11.2040	Cost: 26.14s
Train Epoch: 1167 [20480/90000 (23%)]	Loss: -17.0905	Cost: 9.36s
Train Epoch: 1167 [40960/90000 (45%)]	Loss: -17.0152	Cost: 9.30s
Train Epoch: 1167 [61440/90000 (68%)]	Loss: -16.9127	Cost: 9.09s
Train Epoch: 1167 [81920/90000 (91%)]	Loss: -16.7048	Cost: 9.16s
Train Epoch: 1167 	Average Loss: -16.6265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2349

Learning rate: 0.00019335428931744204
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1168 [0/90000 (0%)]	Loss: -10.9050	Cost: 24.92s
Train Epoch: 1168 [20480/90000 (23%)]	Loss: -17.1558	Cost: 9.40s
Train Epoch: 1168 [40960/90000 (45%)]	Loss: -16.6674	Cost: 9.24s
Train Epoch: 1168 [61440/90000 (68%)]	Loss: -16.5674	Cost: 9.12s
Train Epoch: 1168 [81920/90000 (91%)]	Loss: -16.3703	Cost: 8.85s
Train Epoch: 1168 	Average Loss: -16.5004
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1932

Learning rate: 0.0001933430231783073
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1169 [0/90000 (0%)]	Loss: -10.9819	Cost: 27.92s
Train Epoch: 1169 [20480/90000 (23%)]	Loss: -16.7604	Cost: 9.39s
Train Epoch: 1169 [40960/90000 (45%)]	Loss: -16.8989	Cost: 9.44s
Train Epoch: 1169 [61440/90000 (68%)]	Loss: -16.6233	Cost: 9.10s
Train Epoch: 1169 [81920/90000 (91%)]	Loss: -16.6627	Cost: 9.06s
Train Epoch: 1169 	Average Loss: -16.4914
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4324

Learning rate: 0.00019333174782658552
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1170 [0/90000 (0%)]	Loss: -10.3397	Cost: 25.87s
Train Epoch: 1170 [20480/90000 (23%)]	Loss: -17.3482	Cost: 9.36s
Train Epoch: 1170 [40960/90000 (45%)]	Loss: -16.9535	Cost: 9.95s
Train Epoch: 1170 [61440/90000 (68%)]	Loss: -17.1893	Cost: 9.34s
Train Epoch: 1170 [81920/90000 (91%)]	Loss: -16.7621	Cost: 8.83s
Train Epoch: 1170 	Average Loss: -16.6380
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0177

Learning rate: 0.0001933204632633895
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1171 [0/90000 (0%)]	Loss: -10.5589	Cost: 26.09s
Train Epoch: 1171 [20480/90000 (23%)]	Loss: -16.9802	Cost: 9.41s
Train Epoch: 1171 [40960/90000 (45%)]	Loss: -16.9138	Cost: 9.27s
Train Epoch: 1171 [61440/90000 (68%)]	Loss: -16.6159	Cost: 9.13s
Train Epoch: 1171 [81920/90000 (91%)]	Loss: -15.9669	Cost: 9.23s
Train Epoch: 1171 	Average Loss: -16.3524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7078

Learning rate: 0.00019330916948983305
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1172 [0/90000 (0%)]	Loss: -9.8420	Cost: 24.99s
Train Epoch: 1172 [20480/90000 (23%)]	Loss: -16.5196	Cost: 9.29s
Train Epoch: 1172 [40960/90000 (45%)]	Loss: -15.9985	Cost: 9.55s
Train Epoch: 1172 [61440/90000 (68%)]	Loss: -16.1441	Cost: 9.19s
Train Epoch: 1172 [81920/90000 (91%)]	Loss: -16.3347	Cost: 8.88s
Train Epoch: 1172 	Average Loss: -15.9497
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0616

Learning rate: 0.00019329786650703075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1173 [0/90000 (0%)]	Loss: -10.4813	Cost: 25.36s
Train Epoch: 1173 [20480/90000 (23%)]	Loss: -16.4119	Cost: 9.46s
Train Epoch: 1173 [40960/90000 (45%)]	Loss: -16.2893	Cost: 9.24s
Train Epoch: 1173 [61440/90000 (68%)]	Loss: -16.4718	Cost: 9.17s
Train Epoch: 1173 [81920/90000 (91%)]	Loss: -16.6713	Cost: 9.29s
Train Epoch: 1173 	Average Loss: -16.1932
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0739

Learning rate: 0.00019328655431609818
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1174 [0/90000 (0%)]	Loss: -9.5426	Cost: 26.04s
Train Epoch: 1174 [20480/90000 (23%)]	Loss: -16.9503	Cost: 9.25s
Train Epoch: 1174 [40960/90000 (45%)]	Loss: -16.7398	Cost: 9.25s
Train Epoch: 1174 [61440/90000 (68%)]	Loss: -16.5432	Cost: 9.29s
Train Epoch: 1174 [81920/90000 (91%)]	Loss: -15.4064	Cost: 9.24s
Train Epoch: 1174 	Average Loss: -16.2210
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1358

Learning rate: 0.00019327523291815183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1175 [0/90000 (0%)]	Loss: -9.0426	Cost: 25.02s
Train Epoch: 1175 [20480/90000 (23%)]	Loss: -15.9356	Cost: 9.37s
Train Epoch: 1175 [40960/90000 (45%)]	Loss: -16.1106	Cost: 9.37s
Train Epoch: 1175 [61440/90000 (68%)]	Loss: -16.3294	Cost: 9.11s
Train Epoch: 1175 [81920/90000 (91%)]	Loss: -16.3685	Cost: 9.40s
Train Epoch: 1175 	Average Loss: -15.8050
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0160

Learning rate: 0.00019326390231430904
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1176 [0/90000 (0%)]	Loss: -10.9427	Cost: 24.96s
Train Epoch: 1176 [20480/90000 (23%)]	Loss: -16.9608	Cost: 9.44s
Train Epoch: 1176 [40960/90000 (45%)]	Loss: -16.7761	Cost: 9.51s
Train Epoch: 1176 [61440/90000 (68%)]	Loss: -16.7569	Cost: 9.04s
Train Epoch: 1176 [81920/90000 (91%)]	Loss: -16.4752	Cost: 9.01s
Train Epoch: 1176 	Average Loss: -16.4406
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0864

Learning rate: 0.00019325256250568812
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1177 [0/90000 (0%)]	Loss: -10.1996	Cost: 25.77s
Train Epoch: 1177 [20480/90000 (23%)]	Loss: -16.7916	Cost: 9.95s
Train Epoch: 1177 [40960/90000 (45%)]	Loss: -16.8547	Cost: 9.14s
Train Epoch: 1177 [61440/90000 (68%)]	Loss: -16.8305	Cost: 9.15s
Train Epoch: 1177 [81920/90000 (91%)]	Loss: -16.6294	Cost: 8.92s
Train Epoch: 1177 	Average Loss: -16.3527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0286

Learning rate: 0.00019324121349340828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1178 [0/90000 (0%)]	Loss: -10.9149	Cost: 24.43s
Train Epoch: 1178 [20480/90000 (23%)]	Loss: -17.0447	Cost: 9.01s
Train Epoch: 1178 [40960/90000 (45%)]	Loss: -16.8568	Cost: 9.81s
Train Epoch: 1178 [61440/90000 (68%)]	Loss: -17.0235	Cost: 9.06s
Train Epoch: 1178 [81920/90000 (91%)]	Loss: -16.8752	Cost: 9.33s
Train Epoch: 1178 	Average Loss: -16.6396
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.3909

Learning rate: 0.0001932298552785896
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1179 [0/90000 (0%)]	Loss: -10.8406	Cost: 23.69s
Train Epoch: 1179 [20480/90000 (23%)]	Loss: -17.3937	Cost: 9.61s
Train Epoch: 1179 [40960/90000 (45%)]	Loss: -17.1659	Cost: 9.33s
Train Epoch: 1179 [61440/90000 (68%)]	Loss: -17.1645	Cost: 9.03s
Train Epoch: 1179 [81920/90000 (91%)]	Loss: -16.8214	Cost: 10.36s
Train Epoch: 1179 	Average Loss: -16.7556
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.3519

Learning rate: 0.00019321848786235313
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1180 [0/90000 (0%)]	Loss: -10.7149	Cost: 24.71s
Train Epoch: 1180 [20480/90000 (23%)]	Loss: -17.1791	Cost: 9.47s
Train Epoch: 1180 [40960/90000 (45%)]	Loss: -17.1294	Cost: 9.16s
Train Epoch: 1180 [61440/90000 (68%)]	Loss: -17.1823	Cost: 9.13s
Train Epoch: 1180 [81920/90000 (91%)]	Loss: -16.8907	Cost: 10.06s
Train Epoch: 1180 	Average Loss: -16.7423
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2955

Learning rate: 0.0001932071112458207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1181 [0/90000 (0%)]	Loss: -10.4778	Cost: 23.24s
Train Epoch: 1181 [20480/90000 (23%)]	Loss: -16.9530	Cost: 9.38s
Train Epoch: 1181 [40960/90000 (45%)]	Loss: -16.6229	Cost: 9.07s
Train Epoch: 1181 [61440/90000 (68%)]	Loss: -16.8500	Cost: 9.07s
Train Epoch: 1181 [81920/90000 (91%)]	Loss: -15.7585	Cost: 10.10s
Train Epoch: 1181 	Average Loss: -16.2740
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5495

Learning rate: 0.00019319572543011524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1182 [0/90000 (0%)]	Loss: -9.7026	Cost: 24.65s
Train Epoch: 1182 [20480/90000 (23%)]	Loss: -16.4263	Cost: 9.30s
Train Epoch: 1182 [40960/90000 (45%)]	Loss: -16.3882	Cost: 9.43s
Train Epoch: 1182 [61440/90000 (68%)]	Loss: -16.0373	Cost: 9.18s
Train Epoch: 1182 [81920/90000 (91%)]	Loss: -16.0854	Cost: 9.26s
Train Epoch: 1182 	Average Loss: -15.8826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7166

Learning rate: 0.0001931843304163604
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1183 [0/90000 (0%)]	Loss: -10.3265	Cost: 23.22s
Train Epoch: 1183 [20480/90000 (23%)]	Loss: -16.1143	Cost: 9.38s
Train Epoch: 1183 [40960/90000 (45%)]	Loss: -15.2781	Cost: 9.22s
Train Epoch: 1183 [61440/90000 (68%)]	Loss: -15.3197	Cost: 9.43s
Train Epoch: 1183 [81920/90000 (91%)]	Loss: -15.4268	Cost: 9.12s
Train Epoch: 1183 	Average Loss: -15.3072
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.0329

Learning rate: 0.0001931729262056809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1184 [0/90000 (0%)]	Loss: -9.7731	Cost: 24.70s
Train Epoch: 1184 [20480/90000 (23%)]	Loss: -16.0530	Cost: 9.37s
Train Epoch: 1184 [40960/90000 (45%)]	Loss: -16.0456	Cost: 9.26s
Train Epoch: 1184 [61440/90000 (68%)]	Loss: -16.4207	Cost: 9.16s
Train Epoch: 1184 [81920/90000 (91%)]	Loss: -16.3479	Cost: 9.05s
Train Epoch: 1184 	Average Loss: -15.7926
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9355

Learning rate: 0.0001931615127992022
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1185 [0/90000 (0%)]	Loss: -9.9718	Cost: 25.61s
Train Epoch: 1185 [20480/90000 (23%)]	Loss: -16.8848	Cost: 9.39s
Train Epoch: 1185 [40960/90000 (45%)]	Loss: -16.6927	Cost: 9.32s
Train Epoch: 1185 [61440/90000 (68%)]	Loss: -16.7870	Cost: 9.23s
Train Epoch: 1185 [81920/90000 (91%)]	Loss: -16.7226	Cost: 9.11s
Train Epoch: 1185 	Average Loss: -16.4272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2616

Learning rate: 0.00019315009019805086
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1186 [0/90000 (0%)]	Loss: -10.8802	Cost: 24.74s
Train Epoch: 1186 [20480/90000 (23%)]	Loss: -17.1658	Cost: 9.29s
Train Epoch: 1186 [40960/90000 (45%)]	Loss: -17.0678	Cost: 9.24s
Train Epoch: 1186 [61440/90000 (68%)]	Loss: -16.9755	Cost: 9.17s
Train Epoch: 1186 [81920/90000 (91%)]	Loss: -16.7121	Cost: 8.90s
Train Epoch: 1186 	Average Loss: -16.6464
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.3563

Learning rate: 0.00019313865840335417
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1187 [0/90000 (0%)]	Loss: -10.4088	Cost: 25.11s
Train Epoch: 1187 [20480/90000 (23%)]	Loss: -17.3118	Cost: 9.38s
Train Epoch: 1187 [40960/90000 (45%)]	Loss: -14.2223	Cost: 9.19s
Train Epoch: 1187 [61440/90000 (68%)]	Loss: -14.4150	Cost: 9.06s
Train Epoch: 1187 [81920/90000 (91%)]	Loss: -14.7066	Cost: 9.00s
Train Epoch: 1187 	Average Loss: -15.1720
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7461

Learning rate: 0.00019312721741624044
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1188 [0/90000 (0%)]	Loss: -8.3276	Cost: 25.02s
Train Epoch: 1188 [20480/90000 (23%)]	Loss: -15.5819	Cost: 9.31s
Train Epoch: 1188 [40960/90000 (45%)]	Loss: -15.6501	Cost: 9.16s
Train Epoch: 1188 [61440/90000 (68%)]	Loss: -15.9013	Cost: 9.09s
Train Epoch: 1188 [81920/90000 (91%)]	Loss: -16.0488	Cost: 9.43s
Train Epoch: 1188 	Average Loss: -15.2761
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7234

Learning rate: 0.00019311576723783885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1189 [0/90000 (0%)]	Loss: -10.2072	Cost: 25.21s
Train Epoch: 1189 [20480/90000 (23%)]	Loss: -16.7427	Cost: 9.32s
Train Epoch: 1189 [40960/90000 (45%)]	Loss: -16.3463	Cost: 9.32s
Train Epoch: 1189 [61440/90000 (68%)]	Loss: -16.3949	Cost: 9.06s
Train Epoch: 1189 [81920/90000 (91%)]	Loss: -16.3970	Cost: 8.89s
Train Epoch: 1189 	Average Loss: -16.1125
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1469

Learning rate: 0.00019310430786927943
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1190 [0/90000 (0%)]	Loss: -10.9479	Cost: 24.95s
Train Epoch: 1190 [20480/90000 (23%)]	Loss: -16.7677	Cost: 9.47s
Train Epoch: 1190 [40960/90000 (45%)]	Loss: -16.4036	Cost: 9.29s
Train Epoch: 1190 [61440/90000 (68%)]	Loss: -16.6219	Cost: 9.15s
Train Epoch: 1190 [81920/90000 (91%)]	Loss: -16.7255	Cost: 8.86s
Train Epoch: 1190 	Average Loss: -16.2374
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2194

Learning rate: 0.0001930928393116932
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1191 [0/90000 (0%)]	Loss: -10.6034	Cost: 25.23s
Train Epoch: 1191 [20480/90000 (23%)]	Loss: -16.9857	Cost: 9.15s
Train Epoch: 1191 [40960/90000 (45%)]	Loss: -16.4540	Cost: 9.73s
Train Epoch: 1191 [61440/90000 (68%)]	Loss: -16.6683	Cost: 9.10s
Train Epoch: 1191 [81920/90000 (91%)]	Loss: -16.6187	Cost: 8.97s
Train Epoch: 1191 	Average Loss: -16.4131
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.8783

Learning rate: 0.00019308136156621214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1192 [0/90000 (0%)]	Loss: -10.5706	Cost: 24.83s
Train Epoch: 1192 [20480/90000 (23%)]	Loss: -16.6995	Cost: 9.37s
Train Epoch: 1192 [40960/90000 (45%)]	Loss: -16.4141	Cost: 9.23s
Train Epoch: 1192 [61440/90000 (68%)]	Loss: -16.8538	Cost: 9.11s
Train Epoch: 1192 [81920/90000 (91%)]	Loss: -16.8204	Cost: 8.89s
Train Epoch: 1192 	Average Loss: -16.3329
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1135

Learning rate: 0.00019306987463396896
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1193 [0/90000 (0%)]	Loss: -10.6821	Cost: 25.74s
Train Epoch: 1193 [20480/90000 (23%)]	Loss: -16.5821	Cost: 9.57s
Train Epoch: 1193 [40960/90000 (45%)]	Loss: -16.4688	Cost: 9.31s
Train Epoch: 1193 [61440/90000 (68%)]	Loss: -16.5404	Cost: 9.13s
Train Epoch: 1193 [81920/90000 (91%)]	Loss: -16.5643	Cost: 8.89s
Train Epoch: 1193 	Average Loss: -16.2143
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9094

Learning rate: 0.00019305837851609745
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1194 [0/90000 (0%)]	Loss: -10.8450	Cost: 25.19s
Train Epoch: 1194 [20480/90000 (23%)]	Loss: -16.3795	Cost: 9.39s
Train Epoch: 1194 [40960/90000 (45%)]	Loss: -14.2650	Cost: 9.64s
Train Epoch: 1194 [61440/90000 (68%)]	Loss: -14.5876	Cost: 9.06s
Train Epoch: 1194 [81920/90000 (91%)]	Loss: -14.2312	Cost: 9.25s
Train Epoch: 1194 	Average Loss: -14.8132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6948

Learning rate: 0.00019304687321373217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1195 [0/90000 (0%)]	Loss: -9.5136	Cost: 25.14s
Train Epoch: 1195 [20480/90000 (23%)]	Loss: -15.6117	Cost: 9.01s
Train Epoch: 1195 [40960/90000 (45%)]	Loss: -15.7560	Cost: 10.11s
Train Epoch: 1195 [61440/90000 (68%)]	Loss: -15.6779	Cost: 9.05s
Train Epoch: 1195 [81920/90000 (91%)]	Loss: -15.9541	Cost: 9.58s
Train Epoch: 1195 	Average Loss: -15.2588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0253

Learning rate: 0.00019303535872800865
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1196 [0/90000 (0%)]	Loss: -10.1526	Cost: 24.07s
Train Epoch: 1196 [20480/90000 (23%)]	Loss: -16.8427	Cost: 9.54s
Train Epoch: 1196 [40960/90000 (45%)]	Loss: -16.6253	Cost: 9.37s
Train Epoch: 1196 [61440/90000 (68%)]	Loss: -16.6207	Cost: 9.17s
Train Epoch: 1196 [81920/90000 (91%)]	Loss: -16.4522	Cost: 9.86s
Train Epoch: 1196 	Average Loss: -16.2217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2172

Learning rate: 0.00019302383506006335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1197 [0/90000 (0%)]	Loss: -11.4414	Cost: 24.78s
Train Epoch: 1197 [20480/90000 (23%)]	Loss: -17.0474	Cost: 9.33s
Train Epoch: 1197 [40960/90000 (45%)]	Loss: -16.9315	Cost: 9.63s
Train Epoch: 1197 [61440/90000 (68%)]	Loss: -16.7985	Cost: 9.14s
Train Epoch: 1197 [81920/90000 (91%)]	Loss: -16.7187	Cost: 10.23s
Train Epoch: 1197 	Average Loss: -16.5549
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.3102

Learning rate: 0.00019301230221103362
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1198 [0/90000 (0%)]	Loss: -9.4566	Cost: 23.13s
Train Epoch: 1198 [20480/90000 (23%)]	Loss: -16.9466	Cost: 9.13s
Train Epoch: 1198 [40960/90000 (45%)]	Loss: -16.8861	Cost: 9.20s
Train Epoch: 1198 [61440/90000 (68%)]	Loss: -16.6387	Cost: 9.09s
Train Epoch: 1198 [81920/90000 (91%)]	Loss: -16.8464	Cost: 9.27s
Train Epoch: 1198 	Average Loss: -16.4503
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4456

Learning rate: 0.0001930007601820577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1199 [0/90000 (0%)]	Loss: -11.1361	Cost: 24.57s
Train Epoch: 1199 [20480/90000 (23%)]	Loss: -17.0824	Cost: 9.06s
Train Epoch: 1199 [40960/90000 (45%)]	Loss: -17.2400	Cost: 9.91s
Train Epoch: 1199 [61440/90000 (68%)]	Loss: -16.9482	Cost: 9.03s
Train Epoch: 1199 [81920/90000 (91%)]	Loss: -16.4548	Cost: 11.01s
Train Epoch: 1199 	Average Loss: -16.6184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1914

Learning rate: 0.00019298920897427473
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1200 [0/90000 (0%)]	Loss: -10.6520	Cost: 23.09s
Train Epoch: 1200 [20480/90000 (23%)]	Loss: -17.0164	Cost: 9.14s
Train Epoch: 1200 [40960/90000 (45%)]	Loss: -16.9323	Cost: 9.05s
Train Epoch: 1200 [61440/90000 (68%)]	Loss: -16.4844	Cost: 9.07s
Train Epoch: 1200 [81920/90000 (91%)]	Loss: -16.6605	Cost: 8.98s
Train Epoch: 1200 	Average Loss: -16.4128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4055

Saving model as model.pt_e1200 & waveforms_supplementary.hdf5_e1200
Learning rate: 0.00019297764858882476
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1201 [0/90000 (0%)]	Loss: -10.6070	Cost: 23.86s
Train Epoch: 1201 [20480/90000 (23%)]	Loss: -17.1984	Cost: 9.42s
Train Epoch: 1201 [40960/90000 (45%)]	Loss: -16.0896	Cost: 9.17s
Train Epoch: 1201 [61440/90000 (68%)]	Loss: -15.8947	Cost: 9.23s
Train Epoch: 1201 [81920/90000 (91%)]	Loss: -16.0116	Cost: 9.04s
Train Epoch: 1201 	Average Loss: -16.1185
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2696

Learning rate: 0.0001929660790268488
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1202 [0/90000 (0%)]	Loss: -9.6702	Cost: 22.71s
Train Epoch: 1202 [20480/90000 (23%)]	Loss: -16.0761	Cost: 9.11s
Train Epoch: 1202 [40960/90000 (45%)]	Loss: -16.1838	Cost: 9.25s
Train Epoch: 1202 [61440/90000 (68%)]	Loss: -16.0628	Cost: 8.99s
Train Epoch: 1202 [81920/90000 (91%)]	Loss: -16.4467	Cost: 9.02s
Train Epoch: 1202 	Average Loss: -15.7855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1669

Learning rate: 0.00019295450028948867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1203 [0/90000 (0%)]	Loss: -11.0673	Cost: 24.27s
Train Epoch: 1203 [20480/90000 (23%)]	Loss: -17.0785	Cost: 9.01s
Train Epoch: 1203 [40960/90000 (45%)]	Loss: -16.8052	Cost: 9.02s
Train Epoch: 1203 [61440/90000 (68%)]	Loss: -16.9549	Cost: 8.96s
Train Epoch: 1203 [81920/90000 (91%)]	Loss: -16.7938	Cost: 8.73s
Train Epoch: 1203 	Average Loss: -16.5491
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2875

Learning rate: 0.00019294291237788717
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1204 [0/90000 (0%)]	Loss: -11.3557	Cost: 24.48s
Train Epoch: 1204 [20480/90000 (23%)]	Loss: -17.3418	Cost: 9.20s
Train Epoch: 1204 [40960/90000 (45%)]	Loss: -17.3934	Cost: 9.16s
Train Epoch: 1204 [61440/90000 (68%)]	Loss: -17.3361	Cost: 9.05s
Train Epoch: 1204 [81920/90000 (91%)]	Loss: -17.0341	Cost: 8.77s
Train Epoch: 1204 	Average Loss: -16.8951
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6511

Learning rate: 0.00019293131529318796
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1205 [0/90000 (0%)]	Loss: -11.1933	Cost: 24.74s
Train Epoch: 1205 [20480/90000 (23%)]	Loss: -17.2283	Cost: 9.41s
Train Epoch: 1205 [40960/90000 (45%)]	Loss: -16.9407	Cost: 9.47s
Train Epoch: 1205 [61440/90000 (68%)]	Loss: -16.9511	Cost: 9.10s
Train Epoch: 1205 [81920/90000 (91%)]	Loss: -16.6128	Cost: 9.31s
Train Epoch: 1205 	Average Loss: -16.6969
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.5244

Learning rate: 0.00019291970903653568
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1206 [0/90000 (0%)]	Loss: -10.8625	Cost: 25.08s
Train Epoch: 1206 [20480/90000 (23%)]	Loss: -17.3546	Cost: 9.34s
Train Epoch: 1206 [40960/90000 (45%)]	Loss: -16.9305	Cost: 9.35s
Train Epoch: 1206 [61440/90000 (68%)]	Loss: -16.8173	Cost: 9.02s
Train Epoch: 1206 [81920/90000 (91%)]	Loss: -16.6476	Cost: 9.11s
Train Epoch: 1206 	Average Loss: -16.6843
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.5009

Learning rate: 0.00019290809360907572
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1207 [0/90000 (0%)]	Loss: -10.7914	Cost: 25.51s
Train Epoch: 1207 [20480/90000 (23%)]	Loss: -17.5197	Cost: 9.48s
Train Epoch: 1207 [40960/90000 (45%)]	Loss: -17.2325	Cost: 9.38s
Train Epoch: 1207 [61440/90000 (68%)]	Loss: -16.9363	Cost: 9.36s
Train Epoch: 1207 [81920/90000 (91%)]	Loss: -16.6342	Cost: 8.81s
Train Epoch: 1207 	Average Loss: -16.7854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4089

Learning rate: 0.0001928964690119546
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1208 [0/90000 (0%)]	Loss: -9.9552	Cost: 25.54s
Train Epoch: 1208 [20480/90000 (23%)]	Loss: -17.1714	Cost: 10.26s
Train Epoch: 1208 [40960/90000 (45%)]	Loss: -17.2657	Cost: 9.12s
Train Epoch: 1208 [61440/90000 (68%)]	Loss: -17.2286	Cost: 9.07s
Train Epoch: 1208 [81920/90000 (91%)]	Loss: -17.1167	Cost: 8.74s
Train Epoch: 1208 	Average Loss: -16.7998
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6858

Learning rate: 0.00019288483524631953
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1209 [0/90000 (0%)]	Loss: -11.4389	Cost: 24.84s
Train Epoch: 1209 [20480/90000 (23%)]	Loss: -16.1231	Cost: 9.55s
Train Epoch: 1209 [40960/90000 (45%)]	Loss: -15.8327	Cost: 9.67s
Train Epoch: 1209 [61440/90000 (68%)]	Loss: -15.9621	Cost: 9.21s
Train Epoch: 1209 [81920/90000 (91%)]	Loss: -16.0053	Cost: 9.75s
Train Epoch: 1209 	Average Loss: -15.9843
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1226

Learning rate: 0.00019287319231331873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1210 [0/90000 (0%)]	Loss: -10.5420	Cost: 24.69s
Train Epoch: 1210 [20480/90000 (23%)]	Loss: -16.8071	Cost: 9.50s
Train Epoch: 1210 [40960/90000 (45%)]	Loss: -16.9284	Cost: 9.15s
Train Epoch: 1210 [61440/90000 (68%)]	Loss: -16.7981	Cost: 9.15s
Train Epoch: 1210 [81920/90000 (91%)]	Loss: -16.9620	Cost: 9.87s
Train Epoch: 1210 	Average Loss: -16.4274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.3786

Learning rate: 0.00019286154021410135
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1211 [0/90000 (0%)]	Loss: -10.9300	Cost: 23.83s
Train Epoch: 1211 [20480/90000 (23%)]	Loss: -17.1299	Cost: 9.57s
Train Epoch: 1211 [40960/90000 (45%)]	Loss: -17.2220	Cost: 9.21s
Train Epoch: 1211 [61440/90000 (68%)]	Loss: -17.1114	Cost: 9.09s
Train Epoch: 1211 [81920/90000 (91%)]	Loss: -17.2245	Cost: 10.26s
Train Epoch: 1211 	Average Loss: -16.9083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7942

Learning rate: 0.0001928498789498174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1212 [0/90000 (0%)]	Loss: -10.6679	Cost: 25.36s
Train Epoch: 1212 [20480/90000 (23%)]	Loss: -17.5568	Cost: 9.07s
Train Epoch: 1212 [40960/90000 (45%)]	Loss: -17.4173	Cost: 9.59s
Train Epoch: 1212 [61440/90000 (68%)]	Loss: -17.3792	Cost: 9.04s
Train Epoch: 1212 [81920/90000 (91%)]	Loss: -17.5261	Cost: 10.55s
Train Epoch: 1212 	Average Loss: -17.1049
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8774

Learning rate: 0.00019283820852161778
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1213 [0/90000 (0%)]	Loss: -11.2030	Cost: 24.81s
Train Epoch: 1213 [20480/90000 (23%)]	Loss: -17.7385	Cost: 9.12s
Train Epoch: 1213 [40960/90000 (45%)]	Loss: -17.1501	Cost: 9.42s
Train Epoch: 1213 [61440/90000 (68%)]	Loss: -17.2384	Cost: 9.09s
Train Epoch: 1213 [81920/90000 (91%)]	Loss: -17.0750	Cost: 10.18s
Train Epoch: 1213 	Average Loss: -16.9904
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.5332

Learning rate: 0.00019282652893065432
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1214 [0/90000 (0%)]	Loss: -10.9453	Cost: 23.66s
Train Epoch: 1214 [20480/90000 (23%)]	Loss: -17.5386	Cost: 9.00s
Train Epoch: 1214 [40960/90000 (45%)]	Loss: -17.3580	Cost: 9.04s
Train Epoch: 1214 [61440/90000 (68%)]	Loss: -17.4147	Cost: 9.02s
Train Epoch: 1214 [81920/90000 (91%)]	Loss: -17.2857	Cost: 9.22s
Train Epoch: 1214 	Average Loss: -16.9879
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8489

Learning rate: 0.00019281484017807975
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1215 [0/90000 (0%)]	Loss: -11.0979	Cost: 24.47s
Train Epoch: 1215 [20480/90000 (23%)]	Loss: -17.5855	Cost: 9.05s
Train Epoch: 1215 [40960/90000 (45%)]	Loss: -17.7071	Cost: 9.42s
Train Epoch: 1215 [61440/90000 (68%)]	Loss: -17.4176	Cost: 8.92s
Train Epoch: 1215 [81920/90000 (91%)]	Loss: -17.3625	Cost: 9.15s
Train Epoch: 1215 	Average Loss: -17.2300
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0983

Learning rate: 0.00019280314226504771
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1216 [0/90000 (0%)]	Loss: -11.0454	Cost: 24.12s
Train Epoch: 1216 [20480/90000 (23%)]	Loss: -17.6225	Cost: 9.03s
Train Epoch: 1216 [40960/90000 (45%)]	Loss: -17.4691	Cost: 9.05s
Train Epoch: 1216 [61440/90000 (68%)]	Loss: -17.1117	Cost: 8.97s
Train Epoch: 1216 [81920/90000 (91%)]	Loss: -17.1822	Cost: 8.77s
Train Epoch: 1216 	Average Loss: -17.1002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7687

Learning rate: 0.00019279143519271272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1217 [0/90000 (0%)]	Loss: -11.7500	Cost: 26.39s
Train Epoch: 1217 [20480/90000 (23%)]	Loss: -17.6087	Cost: 9.11s
Train Epoch: 1217 [40960/90000 (45%)]	Loss: -17.2835	Cost: 9.09s
Train Epoch: 1217 [61440/90000 (68%)]	Loss: -17.2100	Cost: 8.96s
Train Epoch: 1217 [81920/90000 (91%)]	Loss: -17.3330	Cost: 8.88s
Train Epoch: 1217 	Average Loss: -17.0211
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7605

Learning rate: 0.00019277971896223024
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1218 [0/90000 (0%)]	Loss: -10.9138	Cost: 25.42s
Train Epoch: 1218 [20480/90000 (23%)]	Loss: -17.5599	Cost: 9.16s
Train Epoch: 1218 [40960/90000 (45%)]	Loss: -17.3674	Cost: 9.19s
Train Epoch: 1218 [61440/90000 (68%)]	Loss: -17.4594	Cost: 8.99s
Train Epoch: 1218 [81920/90000 (91%)]	Loss: -17.2675	Cost: 8.75s
Train Epoch: 1218 	Average Loss: -17.1039
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8879

Learning rate: 0.00019276799357475661
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1219 [0/90000 (0%)]	Loss: -11.5335	Cost: 25.28s
Train Epoch: 1219 [20480/90000 (23%)]	Loss: -17.6210	Cost: 9.44s
Train Epoch: 1219 [40960/90000 (45%)]	Loss: -17.6418	Cost: 9.34s
Train Epoch: 1219 [61440/90000 (68%)]	Loss: -17.3542	Cost: 9.27s
Train Epoch: 1219 [81920/90000 (91%)]	Loss: -17.1945	Cost: 8.99s
Train Epoch: 1219 	Average Loss: -17.1498
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7333

Learning rate: 0.00019275625903144908
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1220 [0/90000 (0%)]	Loss: -11.4955	Cost: 25.81s
Train Epoch: 1220 [20480/90000 (23%)]	Loss: -17.4956	Cost: 9.44s
Train Epoch: 1220 [40960/90000 (45%)]	Loss: -17.5394	Cost: 9.71s
Train Epoch: 1220 [61440/90000 (68%)]	Loss: -17.3634	Cost: 9.24s
Train Epoch: 1220 [81920/90000 (91%)]	Loss: -17.3009	Cost: 9.00s
Train Epoch: 1220 	Average Loss: -17.1069
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6611

Learning rate: 0.0001927445153334658
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1221 [0/90000 (0%)]	Loss: -10.5943	Cost: 25.00s
Train Epoch: 1221 [20480/90000 (23%)]	Loss: -17.6377	Cost: 9.23s
Train Epoch: 1221 [40960/90000 (45%)]	Loss: -17.5934	Cost: 9.73s
Train Epoch: 1221 [61440/90000 (68%)]	Loss: -16.9933	Cost: 9.16s
Train Epoch: 1221 [81920/90000 (91%)]	Loss: -16.6684	Cost: 9.20s
Train Epoch: 1221 	Average Loss: -16.9267
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6242

Learning rate: 0.00019273276248196581
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1222 [0/90000 (0%)]	Loss: -10.6817	Cost: 25.08s
Train Epoch: 1222 [20480/90000 (23%)]	Loss: -17.4485	Cost: 9.45s
Train Epoch: 1222 [40960/90000 (45%)]	Loss: -17.4714	Cost: 9.38s
Train Epoch: 1222 [61440/90000 (68%)]	Loss: -16.6612	Cost: 9.12s
Train Epoch: 1222 [81920/90000 (91%)]	Loss: -16.6483	Cost: 9.05s
Train Epoch: 1222 	Average Loss: -16.6618
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.3598

Learning rate: 0.0001927210004781091
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1223 [0/90000 (0%)]	Loss: -10.8013	Cost: 25.67s
Train Epoch: 1223 [20480/90000 (23%)]	Loss: -17.1501	Cost: 9.43s
Train Epoch: 1223 [40960/90000 (45%)]	Loss: -17.2831	Cost: 9.53s
Train Epoch: 1223 [61440/90000 (68%)]	Loss: -17.2555	Cost: 9.07s
Train Epoch: 1223 [81920/90000 (91%)]	Loss: -17.1841	Cost: 9.24s
Train Epoch: 1223 	Average Loss: -16.8533
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8629

Learning rate: 0.0001927092293230565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1224 [0/90000 (0%)]	Loss: -11.2165	Cost: 25.59s
Train Epoch: 1224 [20480/90000 (23%)]	Loss: -17.7281	Cost: 9.86s
Train Epoch: 1224 [40960/90000 (45%)]	Loss: -17.6971	Cost: 9.07s
Train Epoch: 1224 [61440/90000 (68%)]	Loss: -17.4729	Cost: 9.01s
Train Epoch: 1224 [81920/90000 (91%)]	Loss: -17.3188	Cost: 8.74s
Train Epoch: 1224 	Average Loss: -17.2125
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8204

Learning rate: 0.00019269744901796983
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1225 [0/90000 (0%)]	Loss: -11.7288	Cost: 24.99s
Train Epoch: 1225 [20480/90000 (23%)]	Loss: -17.6505	Cost: 9.03s
Train Epoch: 1225 [40960/90000 (45%)]	Loss: -17.5927	Cost: 10.04s
Train Epoch: 1225 [61440/90000 (68%)]	Loss: -17.6057	Cost: 9.04s
Train Epoch: 1225 [81920/90000 (91%)]	Loss: -17.2363	Cost: 9.40s
Train Epoch: 1225 	Average Loss: -17.2352
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8698

Learning rate: 0.0001926856595640117
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1226 [0/90000 (0%)]	Loss: -12.2137	Cost: 24.45s
Train Epoch: 1226 [20480/90000 (23%)]	Loss: -17.8235	Cost: 9.49s
Train Epoch: 1226 [40960/90000 (45%)]	Loss: -17.7197	Cost: 9.17s
Train Epoch: 1226 [61440/90000 (68%)]	Loss: -17.5329	Cost: 9.05s
Train Epoch: 1226 [81920/90000 (91%)]	Loss: -16.3713	Cost: 9.84s
Train Epoch: 1226 	Average Loss: -17.1678
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.8366

Learning rate: 0.00019267386096234575
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1227 [0/90000 (0%)]	Loss: -9.9763	Cost: 24.15s
Train Epoch: 1227 [20480/90000 (23%)]	Loss: -16.3493	Cost: 9.56s
Train Epoch: 1227 [40960/90000 (45%)]	Loss: -16.5131	Cost: 9.17s
Train Epoch: 1227 [61440/90000 (68%)]	Loss: -16.6302	Cost: 9.15s
Train Epoch: 1227 [81920/90000 (91%)]	Loss: -16.7811	Cost: 10.12s
Train Epoch: 1227 	Average Loss: -16.2372
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.5248

Learning rate: 0.0001926620532141364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1228 [0/90000 (0%)]	Loss: -11.0611	Cost: 23.46s
Train Epoch: 1228 [20480/90000 (23%)]	Loss: -17.2915	Cost: 9.20s
Train Epoch: 1228 [40960/90000 (45%)]	Loss: -17.4904	Cost: 9.14s
Train Epoch: 1228 [61440/90000 (68%)]	Loss: -17.2199	Cost: 9.09s
Train Epoch: 1228 [81920/90000 (91%)]	Loss: -17.1390	Cost: 10.10s
Train Epoch: 1228 	Average Loss: -16.9455
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6981

Learning rate: 0.00019265023632054903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1229 [0/90000 (0%)]	Loss: -11.6879	Cost: 23.41s
Train Epoch: 1229 [20480/90000 (23%)]	Loss: -17.6676	Cost: 9.26s
Train Epoch: 1229 [40960/90000 (45%)]	Loss: -17.5179	Cost: 9.10s
Train Epoch: 1229 [61440/90000 (68%)]	Loss: -17.4393	Cost: 9.08s
Train Epoch: 1229 [81920/90000 (91%)]	Loss: -17.3997	Cost: 9.16s
Train Epoch: 1229 	Average Loss: -17.2102
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.9170

Learning rate: 0.00019263841028274996
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1230 [0/90000 (0%)]	Loss: -11.1557	Cost: 24.51s
Train Epoch: 1230 [20480/90000 (23%)]	Loss: -17.7622	Cost: 9.15s
Train Epoch: 1230 [40960/90000 (45%)]	Loss: -17.6969	Cost: 9.77s
Train Epoch: 1230 [61440/90000 (68%)]	Loss: -17.5239	Cost: 9.09s
Train Epoch: 1230 [81920/90000 (91%)]	Loss: -17.3095	Cost: 10.66s
Train Epoch: 1230 	Average Loss: -17.2902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8626

Learning rate: 0.0001926265751019063
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1231 [0/90000 (0%)]	Loss: -11.6033	Cost: 24.73s
Train Epoch: 1231 [20480/90000 (23%)]	Loss: -17.5565	Cost: 9.40s
Train Epoch: 1231 [40960/90000 (45%)]	Loss: -17.3496	Cost: 9.24s
Train Epoch: 1231 [61440/90000 (68%)]	Loss: -17.5602	Cost: 9.14s
Train Epoch: 1231 [81920/90000 (91%)]	Loss: -17.2191	Cost: 9.41s
Train Epoch: 1231 	Average Loss: -17.1790
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8720

Learning rate: 0.00019261473077918618
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1232 [0/90000 (0%)]	Loss: -11.1367	Cost: 23.81s
Train Epoch: 1232 [20480/90000 (23%)]	Loss: -17.6731	Cost: 9.19s
Train Epoch: 1232 [40960/90000 (45%)]	Loss: -17.1830	Cost: 9.10s
Train Epoch: 1232 [61440/90000 (68%)]	Loss: -17.0205	Cost: 9.15s
Train Epoch: 1232 [81920/90000 (91%)]	Loss: -17.1087	Cost: 9.02s
Train Epoch: 1232 	Average Loss: -16.8795
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7427

Learning rate: 0.00019260287731575864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1233 [0/90000 (0%)]	Loss: -10.2439	Cost: 25.52s
Train Epoch: 1233 [20480/90000 (23%)]	Loss: -17.3538	Cost: 9.19s
Train Epoch: 1233 [40960/90000 (45%)]	Loss: -15.9800	Cost: 9.15s
Train Epoch: 1233 [61440/90000 (68%)]	Loss: -16.4752	Cost: 9.03s
Train Epoch: 1233 [81920/90000 (91%)]	Loss: -16.3882	Cost: 9.03s
Train Epoch: 1233 	Average Loss: -16.2337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.3226

Learning rate: 0.0001925910147127935
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1234 [0/90000 (0%)]	Loss: -9.9913	Cost: 24.10s
Train Epoch: 1234 [20480/90000 (23%)]	Loss: -17.2697	Cost: 9.45s
Train Epoch: 1234 [40960/90000 (45%)]	Loss: -17.0631	Cost: 9.22s
Train Epoch: 1234 [61440/90000 (68%)]	Loss: -17.3168	Cost: 9.12s
Train Epoch: 1234 [81920/90000 (91%)]	Loss: -17.2518	Cost: 9.46s
Train Epoch: 1234 	Average Loss: -16.7818
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.9126

Learning rate: 0.00019257914297146156
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1235 [0/90000 (0%)]	Loss: -11.4424	Cost: 24.55s
Train Epoch: 1235 [20480/90000 (23%)]	Loss: -17.8798	Cost: 9.44s
Train Epoch: 1235 [40960/90000 (45%)]	Loss: -17.5211	Cost: 9.27s
Train Epoch: 1235 [61440/90000 (68%)]	Loss: -17.5023	Cost: 9.05s
Train Epoch: 1235 [81920/90000 (91%)]	Loss: -17.2379	Cost: 9.83s
Train Epoch: 1235 	Average Loss: -17.2659
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.9855

Learning rate: 0.00019256726209293456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1236 [0/90000 (0%)]	Loss: -10.7160	Cost: 24.65s
Train Epoch: 1236 [20480/90000 (23%)]	Loss: -17.4220	Cost: 9.40s
Train Epoch: 1236 [40960/90000 (45%)]	Loss: -17.1508	Cost: 9.32s
Train Epoch: 1236 [61440/90000 (68%)]	Loss: -17.2381	Cost: 9.07s
Train Epoch: 1236 [81920/90000 (91%)]	Loss: -17.1965	Cost: 9.00s
Train Epoch: 1236 	Average Loss: -16.9291
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8872

Learning rate: 0.00019255537207838502
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1237 [0/90000 (0%)]	Loss: -11.9661	Cost: 25.34s
Train Epoch: 1237 [20480/90000 (23%)]	Loss: -17.7895	Cost: 9.32s
Train Epoch: 1237 [40960/90000 (45%)]	Loss: -17.5542	Cost: 9.35s
Train Epoch: 1237 [61440/90000 (68%)]	Loss: -17.6307	Cost: 9.35s
Train Epoch: 1237 [81920/90000 (91%)]	Loss: -17.4071	Cost: 10.02s
Train Epoch: 1237 	Average Loss: -17.2888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0882

Learning rate: 0.0001925434729289865
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1238 [0/90000 (0%)]	Loss: -11.2971	Cost: 26.24s
Train Epoch: 1238 [20480/90000 (23%)]	Loss: -17.6823	Cost: 9.32s
Train Epoch: 1238 [40960/90000 (45%)]	Loss: -17.4821	Cost: 9.31s
Train Epoch: 1238 [61440/90000 (68%)]	Loss: -17.5809	Cost: 9.21s
Train Epoch: 1238 [81920/90000 (91%)]	Loss: -17.6145	Cost: 8.93s
Train Epoch: 1238 	Average Loss: -17.2420
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.9734

Learning rate: 0.00019253156464591338
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1239 [0/90000 (0%)]	Loss: -11.3603	Cost: 26.04s
Train Epoch: 1239 [20480/90000 (23%)]	Loss: -17.9298	Cost: 9.42s
Train Epoch: 1239 [40960/90000 (45%)]	Loss: -17.5175	Cost: 9.28s
Train Epoch: 1239 [61440/90000 (68%)]	Loss: -17.3295	Cost: 9.18s
Train Epoch: 1239 [81920/90000 (91%)]	Loss: -17.3832	Cost: 9.23s
Train Epoch: 1239 	Average Loss: -17.1917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7946

Learning rate: 0.00019251964723034095
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1240 [0/90000 (0%)]	Loss: -10.6173	Cost: 25.07s
Train Epoch: 1240 [20480/90000 (23%)]	Loss: -17.7666	Cost: 9.41s
Train Epoch: 1240 [40960/90000 (45%)]	Loss: -17.4624	Cost: 9.28s
Train Epoch: 1240 [61440/90000 (68%)]	Loss: -17.5163	Cost: 9.28s
Train Epoch: 1240 [81920/90000 (91%)]	Loss: -17.1799	Cost: 9.09s
Train Epoch: 1240 	Average Loss: -17.1427
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.9020

Learning rate: 0.00019250772068344542
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1241 [0/90000 (0%)]	Loss: -11.8307	Cost: 25.55s
Train Epoch: 1241 [20480/90000 (23%)]	Loss: -17.6933	Cost: 9.33s
Train Epoch: 1241 [40960/90000 (45%)]	Loss: -17.8549	Cost: 9.69s
Train Epoch: 1241 [61440/90000 (68%)]	Loss: -17.5921	Cost: 9.17s
Train Epoch: 1241 [81920/90000 (91%)]	Loss: -17.3861	Cost: 9.09s
Train Epoch: 1241 	Average Loss: -17.3335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8531

Learning rate: 0.0001924957850064039
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1242 [0/90000 (0%)]	Loss: -12.0794	Cost: 26.93s
Train Epoch: 1242 [20480/90000 (23%)]	Loss: -17.8176	Cost: 9.48s
Train Epoch: 1242 [40960/90000 (45%)]	Loss: -17.4983	Cost: 9.28s
Train Epoch: 1242 [61440/90000 (68%)]	Loss: -17.3979	Cost: 9.15s
Train Epoch: 1242 [81920/90000 (91%)]	Loss: -17.6140	Cost: 8.82s
Train Epoch: 1242 	Average Loss: -17.3373
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0737

Learning rate: 0.0001924838402003944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1243 [0/90000 (0%)]	Loss: -11.8282	Cost: 25.28s
Train Epoch: 1243 [20480/90000 (23%)]	Loss: -18.0109	Cost: 9.39s
Train Epoch: 1243 [40960/90000 (45%)]	Loss: -17.7266	Cost: 10.02s
Train Epoch: 1243 [61440/90000 (68%)]	Loss: -17.7408	Cost: 9.14s
Train Epoch: 1243 [81920/90000 (91%)]	Loss: -17.6680	Cost: 9.07s
Train Epoch: 1243 	Average Loss: -17.4537
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0601

Learning rate: 0.0001924718862665958
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1244 [0/90000 (0%)]	Loss: -10.9232	Cost: 24.93s
Train Epoch: 1244 [20480/90000 (23%)]	Loss: -17.9782	Cost: 9.33s
Train Epoch: 1244 [40960/90000 (45%)]	Loss: -17.7218	Cost: 9.31s
Train Epoch: 1244 [61440/90000 (68%)]	Loss: -17.6841	Cost: 9.21s
Train Epoch: 1244 [81920/90000 (91%)]	Loss: -17.4559	Cost: 9.13s
Train Epoch: 1244 	Average Loss: -17.4060
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2708

Learning rate: 0.0001924599232061879
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1245 [0/90000 (0%)]	Loss: -12.2085	Cost: 25.22s
Train Epoch: 1245 [20480/90000 (23%)]	Loss: -18.0662	Cost: 9.47s
Train Epoch: 1245 [40960/90000 (45%)]	Loss: -17.5363	Cost: 9.34s
Train Epoch: 1245 [61440/90000 (68%)]	Loss: -17.4324	Cost: 9.06s
Train Epoch: 1245 [81920/90000 (91%)]	Loss: -17.0519	Cost: 9.56s
Train Epoch: 1245 	Average Loss: -17.2453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.5589

Learning rate: 0.00019244795102035147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1246 [0/90000 (0%)]	Loss: -11.7211	Cost: 25.64s
Train Epoch: 1246 [20480/90000 (23%)]	Loss: -17.6564	Cost: 9.21s
Train Epoch: 1246 [40960/90000 (45%)]	Loss: -17.6842	Cost: 9.46s
Train Epoch: 1246 [61440/90000 (68%)]	Loss: -17.7161	Cost: 9.08s
Train Epoch: 1246 [81920/90000 (91%)]	Loss: -17.2734	Cost: 8.73s
Train Epoch: 1246 	Average Loss: -17.2731
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7325

Learning rate: 0.00019243596971026803
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1247 [0/90000 (0%)]	Loss: -11.2278	Cost: 25.19s
Train Epoch: 1247 [20480/90000 (23%)]	Loss: -17.8527	Cost: 9.01s
Train Epoch: 1247 [40960/90000 (45%)]	Loss: -17.4903	Cost: 9.79s
Train Epoch: 1247 [61440/90000 (68%)]	Loss: -17.5709	Cost: 8.92s
Train Epoch: 1247 [81920/90000 (91%)]	Loss: -17.2372	Cost: 8.83s
Train Epoch: 1247 	Average Loss: -17.2004
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8700

Learning rate: 0.00019242397927712014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1248 [0/90000 (0%)]	Loss: -11.1716	Cost: 25.44s
Train Epoch: 1248 [20480/90000 (23%)]	Loss: -17.6906	Cost: 9.05s
Train Epoch: 1248 [40960/90000 (45%)]	Loss: -17.5785	Cost: 9.92s
Train Epoch: 1248 [61440/90000 (68%)]	Loss: -17.5838	Cost: 9.01s
Train Epoch: 1248 [81920/90000 (91%)]	Loss: -17.5619	Cost: 9.61s
Train Epoch: 1248 	Average Loss: -17.2643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0495

Learning rate: 0.00019241197972209119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1249 [0/90000 (0%)]	Loss: -10.9205	Cost: 23.50s
Train Epoch: 1249 [20480/90000 (23%)]	Loss: -17.7778	Cost: 9.65s
Train Epoch: 1249 [40960/90000 (45%)]	Loss: -17.5772	Cost: 9.27s
Train Epoch: 1249 [61440/90000 (68%)]	Loss: -17.6463	Cost: 9.04s
Train Epoch: 1249 [81920/90000 (91%)]	Loss: -17.4267	Cost: 10.18s
Train Epoch: 1249 	Average Loss: -17.2637
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0653

Learning rate: 0.0001923999710463655
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1250 [0/90000 (0%)]	Loss: -11.2957	Cost: 25.80s
Train Epoch: 1250 [20480/90000 (23%)]	Loss: -17.8739	Cost: 9.37s
Train Epoch: 1250 [40960/90000 (45%)]	Loss: -17.7963	Cost: 9.39s
Train Epoch: 1250 [61440/90000 (68%)]	Loss: -17.5506	Cost: 9.04s
Train Epoch: 1250 [81920/90000 (91%)]	Loss: -17.3793	Cost: 10.22s
Train Epoch: 1250 	Average Loss: -17.3930
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7754

Saving model as model.pt_e1250 & waveforms_supplementary.hdf5_e1250
Learning rate: 0.0001923879532511283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1251 [0/90000 (0%)]	Loss: -12.2757	Cost: 25.64s
Train Epoch: 1251 [20480/90000 (23%)]	Loss: -17.7906	Cost: 9.40s
Train Epoch: 1251 [40960/90000 (45%)]	Loss: -17.6630	Cost: 9.94s
Train Epoch: 1251 [61440/90000 (68%)]	Loss: -17.7771	Cost: 9.13s
Train Epoch: 1251 [81920/90000 (91%)]	Loss: -17.5649	Cost: 10.35s
Train Epoch: 1251 	Average Loss: -17.3684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1485

Learning rate: 0.00019237592633756566
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1252 [0/90000 (0%)]	Loss: -11.6396	Cost: 24.06s
Train Epoch: 1252 [20480/90000 (23%)]	Loss: -17.9307	Cost: 9.13s
Train Epoch: 1252 [40960/90000 (45%)]	Loss: -17.6493	Cost: 9.15s
Train Epoch: 1252 [61440/90000 (68%)]	Loss: -17.9327	Cost: 9.08s
Train Epoch: 1252 [81920/90000 (91%)]	Loss: -17.5428	Cost: 9.76s
Train Epoch: 1252 	Average Loss: -17.4934
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1874

Learning rate: 0.00019236389030686458
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1253 [0/90000 (0%)]	Loss: -11.1814	Cost: 24.47s
Train Epoch: 1253 [20480/90000 (23%)]	Loss: -17.3918	Cost: 9.22s
Train Epoch: 1253 [40960/90000 (45%)]	Loss: -16.8521	Cost: 9.42s
Train Epoch: 1253 [61440/90000 (68%)]	Loss: -17.0704	Cost: 9.14s
Train Epoch: 1253 [81920/90000 (91%)]	Loss: -17.2592	Cost: 9.01s
Train Epoch: 1253 	Average Loss: -16.9000
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.9073

Learning rate: 0.000192351845160213
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1254 [0/90000 (0%)]	Loss: -11.4158	Cost: 23.03s
Train Epoch: 1254 [20480/90000 (23%)]	Loss: -17.8278	Cost: 9.35s
Train Epoch: 1254 [40960/90000 (45%)]	Loss: -17.5678	Cost: 9.47s
Train Epoch: 1254 [61440/90000 (68%)]	Loss: -17.6382	Cost: 9.60s
Train Epoch: 1254 [81920/90000 (91%)]	Loss: -17.4714	Cost: 9.11s
Train Epoch: 1254 	Average Loss: -17.3037
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1007

Learning rate: 0.00019233979089879974
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1255 [0/90000 (0%)]	Loss: -11.6098	Cost: 23.56s
Train Epoch: 1255 [20480/90000 (23%)]	Loss: -18.1191	Cost: 9.35s
Train Epoch: 1255 [40960/90000 (45%)]	Loss: -17.8067	Cost: 9.36s
Train Epoch: 1255 [61440/90000 (68%)]	Loss: -17.6980	Cost: 9.44s
Train Epoch: 1255 [81920/90000 (91%)]	Loss: -17.6683	Cost: 9.09s
Train Epoch: 1255 	Average Loss: -17.5148
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2636

Learning rate: 0.00019232772752381447
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1256 [0/90000 (0%)]	Loss: -11.7015	Cost: 24.15s
Train Epoch: 1256 [20480/90000 (23%)]	Loss: -18.1365	Cost: 9.43s
Train Epoch: 1256 [40960/90000 (45%)]	Loss: -17.8580	Cost: 9.27s
Train Epoch: 1256 [61440/90000 (68%)]	Loss: -17.8701	Cost: 9.17s
Train Epoch: 1256 [81920/90000 (91%)]	Loss: -17.5875	Cost: 9.17s
Train Epoch: 1256 	Average Loss: -17.5091
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1422

Learning rate: 0.00019231565503644783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1257 [0/90000 (0%)]	Loss: -12.2599	Cost: 24.46s
Train Epoch: 1257 [20480/90000 (23%)]	Loss: -18.0052	Cost: 9.59s
Train Epoch: 1257 [40960/90000 (45%)]	Loss: -17.7954	Cost: 9.20s
Train Epoch: 1257 [61440/90000 (68%)]	Loss: -17.3968	Cost: 9.17s
Train Epoch: 1257 [81920/90000 (91%)]	Loss: -17.2374	Cost: 9.25s
Train Epoch: 1257 	Average Loss: -17.3153
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7153

Learning rate: 0.0001923035734378913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1258 [0/90000 (0%)]	Loss: -10.7749	Cost: 25.11s
Train Epoch: 1258 [20480/90000 (23%)]	Loss: -17.7407	Cost: 9.33s
Train Epoch: 1258 [40960/90000 (45%)]	Loss: -17.6394	Cost: 9.28s
Train Epoch: 1258 [61440/90000 (68%)]	Loss: -17.4750	Cost: 9.16s
Train Epoch: 1258 [81920/90000 (91%)]	Loss: -17.1936	Cost: 9.71s
Train Epoch: 1258 	Average Loss: -17.1440
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8765

Learning rate: 0.00019229148272933733
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1259 [0/90000 (0%)]	Loss: -11.5706	Cost: 26.85s
Train Epoch: 1259 [20480/90000 (23%)]	Loss: -17.7647	Cost: 9.35s
Train Epoch: 1259 [40960/90000 (45%)]	Loss: -17.7878	Cost: 9.30s
Train Epoch: 1259 [61440/90000 (68%)]	Loss: -17.6595	Cost: 9.18s
Train Epoch: 1259 [81920/90000 (91%)]	Loss: -17.5551	Cost: 9.06s
Train Epoch: 1259 	Average Loss: -17.3723
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0872

Learning rate: 0.00019227938291197918
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1260 [0/90000 (0%)]	Loss: -11.3688	Cost: 27.44s
Train Epoch: 1260 [20480/90000 (23%)]	Loss: -18.2094	Cost: 9.32s
Train Epoch: 1260 [40960/90000 (45%)]	Loss: -18.0487	Cost: 9.37s
Train Epoch: 1260 [61440/90000 (68%)]	Loss: -18.0613	Cost: 9.20s
Train Epoch: 1260 [81920/90000 (91%)]	Loss: -17.8293	Cost: 8.94s
Train Epoch: 1260 	Average Loss: -17.6054
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2554

Learning rate: 0.00019226727398701107
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1261 [0/90000 (0%)]	Loss: -11.8473	Cost: 27.16s
Train Epoch: 1261 [20480/90000 (23%)]	Loss: -18.1345	Cost: 9.31s
Train Epoch: 1261 [40960/90000 (45%)]	Loss: -17.8905	Cost: 9.33s
Train Epoch: 1261 [61440/90000 (68%)]	Loss: -17.9652	Cost: 9.16s
Train Epoch: 1261 [81920/90000 (91%)]	Loss: -17.7128	Cost: 8.95s
Train Epoch: 1261 	Average Loss: -17.6287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1280

Learning rate: 0.00019225515595562809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1262 [0/90000 (0%)]	Loss: -12.2859	Cost: 28.07s
Train Epoch: 1262 [20480/90000 (23%)]	Loss: -17.8731	Cost: 9.33s
Train Epoch: 1262 [40960/90000 (45%)]	Loss: -17.6216	Cost: 9.32s
Train Epoch: 1262 [61440/90000 (68%)]	Loss: -17.5453	Cost: 9.22s
Train Epoch: 1262 [81920/90000 (91%)]	Loss: -17.6059	Cost: 8.82s
Train Epoch: 1262 	Average Loss: -17.3308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0792

Learning rate: 0.00019224302881902622
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1263 [0/90000 (0%)]	Loss: -12.2250	Cost: 24.92s
Train Epoch: 1263 [20480/90000 (23%)]	Loss: -18.0369	Cost: 9.40s
Train Epoch: 1263 [40960/90000 (45%)]	Loss: -17.5409	Cost: 9.95s
Train Epoch: 1263 [61440/90000 (68%)]	Loss: -17.3881	Cost: 9.42s
Train Epoch: 1263 [81920/90000 (91%)]	Loss: -17.3724	Cost: 8.84s
Train Epoch: 1263 	Average Loss: -17.2250
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8987

Learning rate: 0.00019223089257840243
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1264 [0/90000 (0%)]	Loss: -10.6259	Cost: 28.06s
Train Epoch: 1264 [20480/90000 (23%)]	Loss: -17.8411	Cost: 9.28s
Train Epoch: 1264 [40960/90000 (45%)]	Loss: -17.7046	Cost: 9.34s
Train Epoch: 1264 [61440/90000 (68%)]	Loss: -17.6706	Cost: 9.16s
Train Epoch: 1264 [81920/90000 (91%)]	Loss: -17.5740	Cost: 8.88s
Train Epoch: 1264 	Average Loss: -17.3565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2634

Learning rate: 0.0001922187472349545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1265 [0/90000 (0%)]	Loss: -11.2565	Cost: 25.71s
Train Epoch: 1265 [20480/90000 (23%)]	Loss: -18.0777	Cost: 9.39s
Train Epoch: 1265 [40960/90000 (45%)]	Loss: -17.8711	Cost: 9.33s
Train Epoch: 1265 [61440/90000 (68%)]	Loss: -17.8443	Cost: 9.25s
Train Epoch: 1265 [81920/90000 (91%)]	Loss: -17.7891	Cost: 8.98s
Train Epoch: 1265 	Average Loss: -17.5833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3805

Learning rate: 0.0001922065927898811
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1266 [0/90000 (0%)]	Loss: -11.7949	Cost: 28.27s
Train Epoch: 1266 [20480/90000 (23%)]	Loss: -18.0807	Cost: 9.33s
Train Epoch: 1266 [40960/90000 (45%)]	Loss: -18.1591	Cost: 9.45s
Train Epoch: 1266 [61440/90000 (68%)]	Loss: -18.0105	Cost: 9.13s
Train Epoch: 1266 [81920/90000 (91%)]	Loss: -17.8257	Cost: 8.85s
Train Epoch: 1266 	Average Loss: -17.6596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3762

Learning rate: 0.0001921944292443818
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1267 [0/90000 (0%)]	Loss: -11.4215	Cost: 25.00s
Train Epoch: 1267 [20480/90000 (23%)]	Loss: -17.9247	Cost: 9.37s
Train Epoch: 1267 [40960/90000 (45%)]	Loss: -17.9221	Cost: 9.24s
Train Epoch: 1267 [61440/90000 (68%)]	Loss: -17.7981	Cost: 9.16s
Train Epoch: 1267 [81920/90000 (91%)]	Loss: -17.0617	Cost: 8.99s
Train Epoch: 1267 	Average Loss: -17.4260
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6983

Learning rate: 0.00019218225659965716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1268 [0/90000 (0%)]	Loss: -10.3792	Cost: 26.37s
Train Epoch: 1268 [20480/90000 (23%)]	Loss: -17.4790	Cost: 9.30s
Train Epoch: 1268 [40960/90000 (45%)]	Loss: -17.7248	Cost: 9.27s
Train Epoch: 1268 [61440/90000 (68%)]	Loss: -17.5572	Cost: 9.23s
Train Epoch: 1268 [81920/90000 (91%)]	Loss: -17.4671	Cost: 9.04s
Train Epoch: 1268 	Average Loss: -17.2245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1265

Learning rate: 0.00019217007485690854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1269 [0/90000 (0%)]	Loss: -11.7801	Cost: 25.28s
Train Epoch: 1269 [20480/90000 (23%)]	Loss: -18.0540	Cost: 9.25s
Train Epoch: 1269 [40960/90000 (45%)]	Loss: -17.9367	Cost: 9.32s
Train Epoch: 1269 [61440/90000 (68%)]	Loss: -18.0389	Cost: 9.06s
Train Epoch: 1269 [81920/90000 (91%)]	Loss: -17.8937	Cost: 8.84s
Train Epoch: 1269 	Average Loss: -17.6281
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3317

Learning rate: 0.00019215788401733824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1270 [0/90000 (0%)]	Loss: -11.9149	Cost: 25.81s
Train Epoch: 1270 [20480/90000 (23%)]	Loss: -18.2768	Cost: 9.46s
Train Epoch: 1270 [40960/90000 (45%)]	Loss: -18.0016	Cost: 9.30s
Train Epoch: 1270 [61440/90000 (68%)]	Loss: -17.3167	Cost: 9.08s
Train Epoch: 1270 [81920/90000 (91%)]	Loss: -17.4390	Cost: 8.85s
Train Epoch: 1270 	Average Loss: -17.5051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1325

Learning rate: 0.00019214568408214942
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1271 [0/90000 (0%)]	Loss: -11.1055	Cost: 25.90s
Train Epoch: 1271 [20480/90000 (23%)]	Loss: -18.0846	Cost: 9.45s
Train Epoch: 1271 [40960/90000 (45%)]	Loss: -16.1624	Cost: 9.18s
Train Epoch: 1271 [61440/90000 (68%)]	Loss: -16.4537	Cost: 9.11s
Train Epoch: 1271 [81920/90000 (91%)]	Loss: -16.5987	Cost: 8.95s
Train Epoch: 1271 	Average Loss: -16.7371
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1284

Learning rate: 0.00019213347505254617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1272 [0/90000 (0%)]	Loss: -10.3135	Cost: 25.74s
Train Epoch: 1272 [20480/90000 (23%)]	Loss: -17.2407	Cost: 10.00s
Train Epoch: 1272 [40960/90000 (45%)]	Loss: -17.2402	Cost: 9.05s
Train Epoch: 1272 [61440/90000 (68%)]	Loss: -17.1971	Cost: 8.96s
Train Epoch: 1272 [81920/90000 (91%)]	Loss: -17.5340	Cost: 8.73s
Train Epoch: 1272 	Average Loss: -16.9188
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0105

Learning rate: 0.0001921212569297335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1273 [0/90000 (0%)]	Loss: -12.4319	Cost: 25.36s
Train Epoch: 1273 [20480/90000 (23%)]	Loss: -18.0932	Cost: 9.46s
Train Epoch: 1273 [40960/90000 (45%)]	Loss: -18.0476	Cost: 9.40s
Train Epoch: 1273 [61440/90000 (68%)]	Loss: -18.0134	Cost: 9.04s
Train Epoch: 1273 [81920/90000 (91%)]	Loss: -17.8629	Cost: 9.63s
Train Epoch: 1273 	Average Loss: -17.6577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4698

Learning rate: 0.00019210902971491728
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1274 [0/90000 (0%)]	Loss: -12.0459	Cost: 24.16s
Train Epoch: 1274 [20480/90000 (23%)]	Loss: -18.1805	Cost: 9.58s
Train Epoch: 1274 [40960/90000 (45%)]	Loss: -17.9060	Cost: 9.13s
Train Epoch: 1274 [61440/90000 (68%)]	Loss: -17.9267	Cost: 9.07s
Train Epoch: 1274 [81920/90000 (91%)]	Loss: -17.7850	Cost: 9.72s
Train Epoch: 1274 	Average Loss: -17.6668
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2378

Learning rate: 0.0001920967934093043
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1275 [0/90000 (0%)]	Loss: -11.9173	Cost: 24.13s
Train Epoch: 1275 [20480/90000 (23%)]	Loss: -18.2126	Cost: 9.05s
Train Epoch: 1275 [40960/90000 (45%)]	Loss: -18.2783	Cost: 9.62s
Train Epoch: 1275 [61440/90000 (68%)]	Loss: -17.9278	Cost: 9.11s
Train Epoch: 1275 [81920/90000 (91%)]	Loss: -17.6982	Cost: 10.08s
Train Epoch: 1275 	Average Loss: -17.6989
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2830

Learning rate: 0.00019208454801410222
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1276 [0/90000 (0%)]	Loss: -11.4181	Cost: 23.39s
Train Epoch: 1276 [20480/90000 (23%)]	Loss: -18.0171	Cost: 9.08s
Train Epoch: 1276 [40960/90000 (45%)]	Loss: -17.9905	Cost: 9.15s
Train Epoch: 1276 [61440/90000 (68%)]	Loss: -18.0959	Cost: 9.01s
Train Epoch: 1276 [81920/90000 (91%)]	Loss: -17.9554	Cost: 10.11s
Train Epoch: 1276 	Average Loss: -17.6146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3692

Learning rate: 0.00019207229353051958
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1277 [0/90000 (0%)]	Loss: -11.8820	Cost: 23.34s
Train Epoch: 1277 [20480/90000 (23%)]	Loss: -18.2516	Cost: 9.08s
Train Epoch: 1277 [40960/90000 (45%)]	Loss: -17.9359	Cost: 9.02s
Train Epoch: 1277 [61440/90000 (68%)]	Loss: -18.2678	Cost: 9.05s
Train Epoch: 1277 [81920/90000 (91%)]	Loss: -18.0650	Cost: 9.00s
Train Epoch: 1277 	Average Loss: -17.7675
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4947

Learning rate: 0.00019206002995976587
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1278 [0/90000 (0%)]	Loss: -11.8772	Cost: 23.18s
Train Epoch: 1278 [20480/90000 (23%)]	Loss: -18.3103	Cost: 9.11s
Train Epoch: 1278 [40960/90000 (45%)]	Loss: -18.2335	Cost: 9.27s
Train Epoch: 1278 [61440/90000 (68%)]	Loss: -18.1701	Cost: 9.11s
Train Epoch: 1278 [81920/90000 (91%)]	Loss: -18.0758	Cost: 9.01s
Train Epoch: 1278 	Average Loss: -17.8689
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4408

Learning rate: 0.00019204775730305153
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1279 [0/90000 (0%)]	Loss: -11.6333	Cost: 23.98s
Train Epoch: 1279 [20480/90000 (23%)]	Loss: -18.2193	Cost: 9.00s
Train Epoch: 1279 [40960/90000 (45%)]	Loss: -18.1739	Cost: 9.02s
Train Epoch: 1279 [61440/90000 (68%)]	Loss: -18.2002	Cost: 8.94s
Train Epoch: 1279 [81920/90000 (91%)]	Loss: -17.8519	Cost: 8.96s
Train Epoch: 1279 	Average Loss: -17.7653
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5244

Learning rate: 0.00019203547556158768
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1280 [0/90000 (0%)]	Loss: -12.0631	Cost: 23.94s
Train Epoch: 1280 [20480/90000 (23%)]	Loss: -18.3342	Cost: 9.09s
Train Epoch: 1280 [40960/90000 (45%)]	Loss: -17.7959	Cost: 9.08s
Train Epoch: 1280 [61440/90000 (68%)]	Loss: -17.6667	Cost: 8.94s
Train Epoch: 1280 [81920/90000 (91%)]	Loss: -17.4696	Cost: 8.82s
Train Epoch: 1280 	Average Loss: -17.5378
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8640

Learning rate: 0.0001920231847365866
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1281 [0/90000 (0%)]	Loss: -11.2734	Cost: 25.08s
Train Epoch: 1281 [20480/90000 (23%)]	Loss: -17.8033	Cost: 9.17s
Train Epoch: 1281 [40960/90000 (45%)]	Loss: -17.6702	Cost: 9.21s
Train Epoch: 1281 [61440/90000 (68%)]	Loss: -17.6125	Cost: 9.03s
Train Epoch: 1281 [81920/90000 (91%)]	Loss: -17.7873	Cost: 8.74s
Train Epoch: 1281 	Average Loss: -17.3067
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2102

Learning rate: 0.00019201088482926132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1282 [0/90000 (0%)]	Loss: -11.2720	Cost: 24.51s
Train Epoch: 1282 [20480/90000 (23%)]	Loss: -18.1677	Cost: 9.32s
Train Epoch: 1282 [40960/90000 (45%)]	Loss: -17.9111	Cost: 9.29s
Train Epoch: 1282 [61440/90000 (68%)]	Loss: -17.9399	Cost: 9.07s
Train Epoch: 1282 [81920/90000 (91%)]	Loss: -18.0053	Cost: 8.80s
Train Epoch: 1282 	Average Loss: -17.5985
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4562

Learning rate: 0.00019199857584082573
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1283 [0/90000 (0%)]	Loss: -11.6168	Cost: 25.01s
Train Epoch: 1283 [20480/90000 (23%)]	Loss: -18.3476	Cost: 9.45s
Train Epoch: 1283 [40960/90000 (45%)]	Loss: -18.2203	Cost: 9.24s
Train Epoch: 1283 [61440/90000 (68%)]	Loss: -17.9142	Cost: 9.19s
Train Epoch: 1283 [81920/90000 (91%)]	Loss: -17.8955	Cost: 8.85s
Train Epoch: 1283 	Average Loss: -17.7363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3164

Learning rate: 0.00019198625777249478
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1284 [0/90000 (0%)]	Loss: -12.1521	Cost: 25.78s
Train Epoch: 1284 [20480/90000 (23%)]	Loss: -17.7032	Cost: 9.29s
Train Epoch: 1284 [40960/90000 (45%)]	Loss: -17.4761	Cost: 9.46s
Train Epoch: 1284 [61440/90000 (68%)]	Loss: -17.7557	Cost: 9.07s
Train Epoch: 1284 [81920/90000 (91%)]	Loss: -17.6121	Cost: 8.89s
Train Epoch: 1284 	Average Loss: -17.3132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1865

Learning rate: 0.00019197393062548413
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1285 [0/90000 (0%)]	Loss: -11.4278	Cost: 25.46s
Train Epoch: 1285 [20480/90000 (23%)]	Loss: -17.9144	Cost: 9.20s
Train Epoch: 1285 [40960/90000 (45%)]	Loss: -17.6798	Cost: 9.40s
Train Epoch: 1285 [61440/90000 (68%)]	Loss: -17.3307	Cost: 9.18s
Train Epoch: 1285 [81920/90000 (91%)]	Loss: -17.3366	Cost: 8.93s
Train Epoch: 1285 	Average Loss: -17.2969
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8611

Learning rate: 0.00019196159440101047
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1286 [0/90000 (0%)]	Loss: -11.2409	Cost: 25.49s
Train Epoch: 1286 [20480/90000 (23%)]	Loss: -17.7886	Cost: 9.37s
Train Epoch: 1286 [40960/90000 (45%)]	Loss: -17.7121	Cost: 9.17s
Train Epoch: 1286 [61440/90000 (68%)]	Loss: -17.8192	Cost: 9.12s
Train Epoch: 1286 [81920/90000 (91%)]	Loss: -17.7936	Cost: 8.79s
Train Epoch: 1286 	Average Loss: -17.3836
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3648

Learning rate: 0.0001919492491002913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1287 [0/90000 (0%)]	Loss: -11.7971	Cost: 25.15s
Train Epoch: 1287 [20480/90000 (23%)]	Loss: -18.1560	Cost: 9.64s
Train Epoch: 1287 [40960/90000 (45%)]	Loss: -17.9307	Cost: 9.04s
Train Epoch: 1287 [61440/90000 (68%)]	Loss: -17.8376	Cost: 9.02s
Train Epoch: 1287 [81920/90000 (91%)]	Loss: -17.7836	Cost: 8.73s
Train Epoch: 1287 	Average Loss: -17.5922
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1020

Learning rate: 0.00019193689472454505
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1288 [0/90000 (0%)]	Loss: -11.3194	Cost: 25.02s
Train Epoch: 1288 [20480/90000 (23%)]	Loss: -18.0642	Cost: 9.45s
Train Epoch: 1288 [40960/90000 (45%)]	Loss: -18.0043	Cost: 9.20s
Train Epoch: 1288 [61440/90000 (68%)]	Loss: -17.8761	Cost: 9.05s
Train Epoch: 1288 [81920/90000 (91%)]	Loss: -17.8026	Cost: 9.77s
Train Epoch: 1288 	Average Loss: -17.5632
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3414

Learning rate: 0.0001919245312749911
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1289 [0/90000 (0%)]	Loss: -12.0729	Cost: 23.79s
Train Epoch: 1289 [20480/90000 (23%)]	Loss: -18.1107	Cost: 9.57s
Train Epoch: 1289 [40960/90000 (45%)]	Loss: -18.0914	Cost: 9.13s
Train Epoch: 1289 [61440/90000 (68%)]	Loss: -17.9588	Cost: 9.09s
Train Epoch: 1289 [81920/90000 (91%)]	Loss: -17.8419	Cost: 10.16s
Train Epoch: 1289 	Average Loss: -17.6736
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5274

Learning rate: 0.00019191215875284963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1290 [0/90000 (0%)]	Loss: -12.5033	Cost: 24.91s
Train Epoch: 1290 [20480/90000 (23%)]	Loss: -18.1795	Cost: 9.31s
Train Epoch: 1290 [40960/90000 (45%)]	Loss: -18.0170	Cost: 9.46s
Train Epoch: 1290 [61440/90000 (68%)]	Loss: -18.1376	Cost: 9.08s
Train Epoch: 1290 [81920/90000 (91%)]	Loss: -18.1585	Cost: 10.07s
Train Epoch: 1290 	Average Loss: -17.8509
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5667

Learning rate: 0.00019189977715934172
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1291 [0/90000 (0%)]	Loss: -11.8674	Cost: 25.18s
Train Epoch: 1291 [20480/90000 (23%)]	Loss: -17.0907	Cost: 9.04s
Train Epoch: 1291 [40960/90000 (45%)]	Loss: -17.0996	Cost: 9.51s
Train Epoch: 1291 [61440/90000 (68%)]	Loss: -17.1550	Cost: 9.07s
Train Epoch: 1291 [81920/90000 (91%)]	Loss: -17.2310	Cost: 10.23s
Train Epoch: 1291 	Average Loss: -16.8075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8212

Learning rate: 0.0001918873864956895
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1292 [0/90000 (0%)]	Loss: -11.2527	Cost: 24.68s
Train Epoch: 1292 [20480/90000 (23%)]	Loss: -17.8813	Cost: 9.09s
Train Epoch: 1292 [40960/90000 (45%)]	Loss: -18.0228	Cost: 9.16s
Train Epoch: 1292 [61440/90000 (68%)]	Loss: -17.9675	Cost: 9.05s
Train Epoch: 1292 [81920/90000 (91%)]	Loss: -17.8172	Cost: 9.34s
Train Epoch: 1292 	Average Loss: -17.5214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4391

Learning rate: 0.00019187498676311577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1293 [0/90000 (0%)]	Loss: -11.2907	Cost: 23.72s
Train Epoch: 1293 [20480/90000 (23%)]	Loss: -18.1024	Cost: 9.07s
Train Epoch: 1293 [40960/90000 (45%)]	Loss: -17.9611	Cost: 9.24s
Train Epoch: 1293 [61440/90000 (68%)]	Loss: -17.9155	Cost: 8.99s
Train Epoch: 1293 [81920/90000 (91%)]	Loss: -17.2345	Cost: 9.01s
Train Epoch: 1293 	Average Loss: -17.5041
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9860

Learning rate: 0.0001918625779628444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1294 [0/90000 (0%)]	Loss: -10.9467	Cost: 23.62s
Train Epoch: 1294 [20480/90000 (23%)]	Loss: -16.6283	Cost: 9.07s
Train Epoch: 1294 [40960/90000 (45%)]	Loss: -16.5999	Cost: 9.08s
Train Epoch: 1294 [61440/90000 (68%)]	Loss: -16.9560	Cost: 8.93s
Train Epoch: 1294 [81920/90000 (91%)]	Loss: -16.9645	Cost: 8.99s
Train Epoch: 1294 	Average Loss: -16.3766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8803

Learning rate: 0.00019185016009610006
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1295 [0/90000 (0%)]	Loss: -11.3826	Cost: 23.78s
Train Epoch: 1295 [20480/90000 (23%)]	Loss: -17.6151	Cost: 9.03s
Train Epoch: 1295 [40960/90000 (45%)]	Loss: -17.5919	Cost: 9.04s
Train Epoch: 1295 [61440/90000 (68%)]	Loss: -17.8455	Cost: 8.99s
Train Epoch: 1295 [81920/90000 (91%)]	Loss: -17.7821	Cost: 8.72s
Train Epoch: 1295 	Average Loss: -17.3432
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3912

Learning rate: 0.00019183773316410835
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1296 [0/90000 (0%)]	Loss: -12.3692	Cost: 25.30s
Train Epoch: 1296 [20480/90000 (23%)]	Loss: -18.1705	Cost: 9.29s
Train Epoch: 1296 [40960/90000 (45%)]	Loss: -18.1312	Cost: 9.25s
Train Epoch: 1296 [61440/90000 (68%)]	Loss: -17.8960	Cost: 9.00s
Train Epoch: 1296 [81920/90000 (91%)]	Loss: -17.5890	Cost: 8.72s
Train Epoch: 1296 	Average Loss: -17.6684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4233

Learning rate: 0.00019182529716809578
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1297 [0/90000 (0%)]	Loss: -11.4403	Cost: 25.13s
Train Epoch: 1297 [20480/90000 (23%)]	Loss: -18.0915	Cost: 9.28s
Train Epoch: 1297 [40960/90000 (45%)]	Loss: -18.1076	Cost: 9.08s
Train Epoch: 1297 [61440/90000 (68%)]	Loss: -18.1670	Cost: 9.02s
Train Epoch: 1297 [81920/90000 (91%)]	Loss: -17.9190	Cost: 8.76s
Train Epoch: 1297 	Average Loss: -17.7544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4931

Learning rate: 0.0001918128521092897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1298 [0/90000 (0%)]	Loss: -12.2285	Cost: 25.23s
Train Epoch: 1298 [20480/90000 (23%)]	Loss: -18.4299	Cost: 9.30s
Train Epoch: 1298 [40960/90000 (45%)]	Loss: -18.2420	Cost: 9.23s
Train Epoch: 1298 [61440/90000 (68%)]	Loss: -18.2218	Cost: 9.14s
Train Epoch: 1298 [81920/90000 (91%)]	Loss: -17.8568	Cost: 9.07s
Train Epoch: 1298 	Average Loss: -17.7617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0978

Learning rate: 0.0001918003979889184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1299 [0/90000 (0%)]	Loss: -11.5713	Cost: 25.96s
Train Epoch: 1299 [20480/90000 (23%)]	Loss: -17.9636	Cost: 9.38s
Train Epoch: 1299 [40960/90000 (45%)]	Loss: -17.8068	Cost: 9.29s
Train Epoch: 1299 [61440/90000 (68%)]	Loss: -17.7413	Cost: 9.05s
Train Epoch: 1299 [81920/90000 (91%)]	Loss: -17.7400	Cost: 8.85s
Train Epoch: 1299 	Average Loss: -17.5377
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4439

Learning rate: 0.00019178793480821105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1300 [0/90000 (0%)]	Loss: -11.4858	Cost: 25.64s
Train Epoch: 1300 [20480/90000 (23%)]	Loss: -17.9518	Cost: 9.32s
Train Epoch: 1300 [40960/90000 (45%)]	Loss: -17.7277	Cost: 9.28s
Train Epoch: 1300 [61440/90000 (68%)]	Loss: -17.8976	Cost: 9.21s
Train Epoch: 1300 [81920/90000 (91%)]	Loss: -17.8146	Cost: 9.14s
Train Epoch: 1300 	Average Loss: -17.5471
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4757

Saving model as model.pt_e1300 & waveforms_supplementary.hdf5_e1300
Learning rate: 0.00019177546256839772
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1301 [0/90000 (0%)]	Loss: -11.5765	Cost: 24.57s
Train Epoch: 1301 [20480/90000 (23%)]	Loss: -18.0672	Cost: 9.34s
Train Epoch: 1301 [40960/90000 (45%)]	Loss: -18.0659	Cost: 9.30s
Train Epoch: 1301 [61440/90000 (68%)]	Loss: -18.1029	Cost: 9.18s
Train Epoch: 1301 [81920/90000 (91%)]	Loss: -17.8615	Cost: 9.10s
Train Epoch: 1301 	Average Loss: -17.6954
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3946

Learning rate: 0.00019176298127070938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1302 [0/90000 (0%)]	Loss: -11.5644	Cost: 24.66s
Train Epoch: 1302 [20480/90000 (23%)]	Loss: -18.2211	Cost: 9.39s
Train Epoch: 1302 [40960/90000 (45%)]	Loss: -17.8404	Cost: 9.33s
Train Epoch: 1302 [61440/90000 (68%)]	Loss: -18.1031	Cost: 9.18s
Train Epoch: 1302 [81920/90000 (91%)]	Loss: -17.9197	Cost: 9.42s
Train Epoch: 1302 	Average Loss: -17.6148
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2989

Learning rate: 0.00019175049091637786
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1303 [0/90000 (0%)]	Loss: -11.0815	Cost: 24.96s
Train Epoch: 1303 [20480/90000 (23%)]	Loss: -17.9060	Cost: 9.37s
Train Epoch: 1303 [40960/90000 (45%)]	Loss: -17.8942	Cost: 9.32s
Train Epoch: 1303 [61440/90000 (68%)]	Loss: -18.0409	Cost: 9.25s
Train Epoch: 1303 [81920/90000 (91%)]	Loss: -18.0041	Cost: 8.99s
Train Epoch: 1303 	Average Loss: -17.5245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5325

Learning rate: 0.00019173799150663595
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1304 [0/90000 (0%)]	Loss: -10.9754	Cost: 25.16s
Train Epoch: 1304 [20480/90000 (23%)]	Loss: -18.3269	Cost: 9.36s
Train Epoch: 1304 [40960/90000 (45%)]	Loss: -18.1691	Cost: 9.88s
Train Epoch: 1304 [61440/90000 (68%)]	Loss: -18.1446	Cost: 9.72s
Train Epoch: 1304 [81920/90000 (91%)]	Loss: -18.1978	Cost: 9.39s
Train Epoch: 1304 	Average Loss: -17.8138
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5971

Learning rate: 0.00019172548304271725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1305 [0/90000 (0%)]	Loss: -11.8241	Cost: 25.18s
Train Epoch: 1305 [20480/90000 (23%)]	Loss: -18.4532	Cost: 9.48s
Train Epoch: 1305 [40960/90000 (45%)]	Loss: -18.2894	Cost: 9.35s
Train Epoch: 1305 [61440/90000 (68%)]	Loss: -18.1736	Cost: 9.00s
Train Epoch: 1305 [81920/90000 (91%)]	Loss: -18.1484	Cost: 9.09s
Train Epoch: 1305 	Average Loss: -17.9214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6311

Learning rate: 0.00019171296552585629
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1306 [0/90000 (0%)]	Loss: -12.1177	Cost: 25.97s
Train Epoch: 1306 [20480/90000 (23%)]	Loss: -18.4952	Cost: 9.49s
Train Epoch: 1306 [40960/90000 (45%)]	Loss: -18.2568	Cost: 9.23s
Train Epoch: 1306 [61440/90000 (68%)]	Loss: -18.1879	Cost: 9.35s
Train Epoch: 1306 [81920/90000 (91%)]	Loss: -18.2108	Cost: 8.81s
Train Epoch: 1306 	Average Loss: -18.0046
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5456

Learning rate: 0.00019170043895728857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1307 [0/90000 (0%)]	Loss: -12.6406	Cost: 24.75s
Train Epoch: 1307 [20480/90000 (23%)]	Loss: -18.6077	Cost: 9.82s
Train Epoch: 1307 [40960/90000 (45%)]	Loss: -18.2592	Cost: 9.09s
Train Epoch: 1307 [61440/90000 (68%)]	Loss: -18.2175	Cost: 8.98s
Train Epoch: 1307 [81920/90000 (91%)]	Loss: -18.0949	Cost: 8.75s
Train Epoch: 1307 	Average Loss: -17.9935
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5765

Learning rate: 0.00019168790333825032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1308 [0/90000 (0%)]	Loss: -12.1105	Cost: 25.00s
Train Epoch: 1308 [20480/90000 (23%)]	Loss: -18.5886	Cost: 9.57s
Train Epoch: 1308 [40960/90000 (45%)]	Loss: -18.2425	Cost: 9.31s
Train Epoch: 1308 [61440/90000 (68%)]	Loss: -18.1920	Cost: 9.01s
Train Epoch: 1308 [81920/90000 (91%)]	Loss: -18.3048	Cost: 9.73s
Train Epoch: 1308 	Average Loss: -17.8690
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6620

Learning rate: 0.00019167535866997882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1309 [0/90000 (0%)]	Loss: -12.5826	Cost: 24.07s
Train Epoch: 1309 [20480/90000 (23%)]	Loss: -18.3184	Cost: 9.58s
Train Epoch: 1309 [40960/90000 (45%)]	Loss: -17.9448	Cost: 9.89s
Train Epoch: 1309 [61440/90000 (68%)]	Loss: -17.9724	Cost: 9.07s
Train Epoch: 1309 [81920/90000 (91%)]	Loss: -18.0705	Cost: 9.98s
Train Epoch: 1309 	Average Loss: -17.8053
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6858

Learning rate: 0.0001916628049537122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1310 [0/90000 (0%)]	Loss: -12.7117	Cost: 24.62s
Train Epoch: 1310 [20480/90000 (23%)]	Loss: -18.4272	Cost: 9.23s
Train Epoch: 1310 [40960/90000 (45%)]	Loss: -18.1808	Cost: 9.23s
Train Epoch: 1310 [61440/90000 (68%)]	Loss: -18.1830	Cost: 9.10s
Train Epoch: 1310 [81920/90000 (91%)]	Loss: -17.9568	Cost: 10.07s
Train Epoch: 1310 	Average Loss: -17.7791
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2629

Learning rate: 0.00019165024219068937
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1311 [0/90000 (0%)]	Loss: -10.3621	Cost: 23.66s
Train Epoch: 1311 [20480/90000 (23%)]	Loss: -18.0399	Cost: 8.98s
Train Epoch: 1311 [40960/90000 (45%)]	Loss: -18.1400	Cost: 9.26s
Train Epoch: 1311 [61440/90000 (68%)]	Loss: -17.9985	Cost: 9.07s
Train Epoch: 1311 [81920/90000 (91%)]	Loss: -17.9376	Cost: 10.15s
Train Epoch: 1311 	Average Loss: -17.5622
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2903

Learning rate: 0.0001916376703821503
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1312 [0/90000 (0%)]	Loss: -11.5861	Cost: 22.73s
Train Epoch: 1312 [20480/90000 (23%)]	Loss: -18.0371	Cost: 9.11s
Train Epoch: 1312 [40960/90000 (45%)]	Loss: -18.1276	Cost: 9.21s
Train Epoch: 1312 [61440/90000 (68%)]	Loss: -18.0388	Cost: 9.25s
Train Epoch: 1312 [81920/90000 (91%)]	Loss: -18.1338	Cost: 9.10s
Train Epoch: 1312 	Average Loss: -17.7390
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6290

Learning rate: 0.00019162508952933575
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1313 [0/90000 (0%)]	Loss: -12.2171	Cost: 23.54s
Train Epoch: 1313 [20480/90000 (23%)]	Loss: -18.4990	Cost: 9.09s
Train Epoch: 1313 [40960/90000 (45%)]	Loss: -18.2748	Cost: 9.23s
Train Epoch: 1313 [61440/90000 (68%)]	Loss: -18.1374	Cost: 9.14s
Train Epoch: 1313 [81920/90000 (91%)]	Loss: -18.1562	Cost: 9.03s
Train Epoch: 1313 	Average Loss: -17.9526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6066

Learning rate: 0.0001916124996334874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1314 [0/90000 (0%)]	Loss: -11.8101	Cost: 25.15s
Train Epoch: 1314 [20480/90000 (23%)]	Loss: -18.3879	Cost: 9.03s
Train Epoch: 1314 [40960/90000 (45%)]	Loss: -18.3645	Cost: 9.34s
Train Epoch: 1314 [61440/90000 (68%)]	Loss: -18.1711	Cost: 8.91s
Train Epoch: 1314 [81920/90000 (91%)]	Loss: -18.1065	Cost: 8.94s
Train Epoch: 1314 	Average Loss: -17.8822
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3804

Learning rate: 0.00019159990069584783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1315 [0/90000 (0%)]	Loss: -11.1507	Cost: 26.35s
Train Epoch: 1315 [20480/90000 (23%)]	Loss: -18.2717	Cost: 9.01s
Train Epoch: 1315 [40960/90000 (45%)]	Loss: -17.9982	Cost: 9.72s
Train Epoch: 1315 [61440/90000 (68%)]	Loss: -17.8169	Cost: 8.92s
Train Epoch: 1315 [81920/90000 (91%)]	Loss: -17.9916	Cost: 8.80s
Train Epoch: 1315 	Average Loss: -17.7147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2274

Learning rate: 0.0001915872927176605
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1316 [0/90000 (0%)]	Loss: -11.7356	Cost: 23.75s
Train Epoch: 1316 [20480/90000 (23%)]	Loss: -18.0013	Cost: 9.08s
Train Epoch: 1316 [40960/90000 (45%)]	Loss: -17.9483	Cost: 9.12s
Train Epoch: 1316 [61440/90000 (68%)]	Loss: -18.2317	Cost: 9.00s
Train Epoch: 1316 [81920/90000 (91%)]	Loss: -17.8966	Cost: 8.73s
Train Epoch: 1316 	Average Loss: -17.6470
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.9751

Learning rate: 0.0001915746757001698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1317 [0/90000 (0%)]	Loss: -12.1099	Cost: 24.97s
Train Epoch: 1317 [20480/90000 (23%)]	Loss: -17.8074	Cost: 9.37s
Train Epoch: 1317 [40960/90000 (45%)]	Loss: -17.8370	Cost: 9.25s
Train Epoch: 1317 [61440/90000 (68%)]	Loss: -17.6081	Cost: 9.14s
Train Epoch: 1317 [81920/90000 (91%)]	Loss: -17.4359	Cost: 9.02s
Train Epoch: 1317 	Average Loss: -17.3431
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1734

Learning rate: 0.00019156204964462093
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1318 [0/90000 (0%)]	Loss: -11.7866	Cost: 24.84s
Train Epoch: 1318 [20480/90000 (23%)]	Loss: -18.1624	Cost: 9.37s
Train Epoch: 1318 [40960/90000 (45%)]	Loss: -18.0592	Cost: 9.57s
Train Epoch: 1318 [61440/90000 (68%)]	Loss: -17.9920	Cost: 9.15s
Train Epoch: 1318 [81920/90000 (91%)]	Loss: -17.5816	Cost: 9.02s
Train Epoch: 1318 	Average Loss: -17.6191
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3586

Learning rate: 0.00019154941455226007
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1319 [0/90000 (0%)]	Loss: -12.0382	Cost: 24.76s
Train Epoch: 1319 [20480/90000 (23%)]	Loss: -18.4274	Cost: 9.40s
Train Epoch: 1319 [40960/90000 (45%)]	Loss: -18.3547	Cost: 9.26s
Train Epoch: 1319 [61440/90000 (68%)]	Loss: -18.2196	Cost: 9.12s
Train Epoch: 1319 [81920/90000 (91%)]	Loss: -18.0799	Cost: 9.03s
Train Epoch: 1319 	Average Loss: -17.8215
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3246

Learning rate: 0.00019153677042433424
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1320 [0/90000 (0%)]	Loss: -11.3635	Cost: 25.35s
Train Epoch: 1320 [20480/90000 (23%)]	Loss: -18.0002	Cost: 9.17s
Train Epoch: 1320 [40960/90000 (45%)]	Loss: -18.1346	Cost: 9.33s
Train Epoch: 1320 [61440/90000 (68%)]	Loss: -18.0374	Cost: 9.11s
Train Epoch: 1320 [81920/90000 (91%)]	Loss: -17.6892	Cost: 8.85s
Train Epoch: 1320 	Average Loss: -17.6337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2208

Learning rate: 0.00019152411726209133
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1321 [0/90000 (0%)]	Loss: -11.7647	Cost: 24.99s
Train Epoch: 1321 [20480/90000 (23%)]	Loss: -17.9113	Cost: 9.34s
Train Epoch: 1321 [40960/90000 (45%)]	Loss: -17.7996	Cost: 9.23s
Train Epoch: 1321 [61440/90000 (68%)]	Loss: -17.5239	Cost: 9.05s
Train Epoch: 1321 [81920/90000 (91%)]	Loss: -17.6349	Cost: 8.82s
Train Epoch: 1321 	Average Loss: -17.4003
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2594

Learning rate: 0.00019151145506678021
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1322 [0/90000 (0%)]	Loss: -11.3112	Cost: 25.39s
Train Epoch: 1322 [20480/90000 (23%)]	Loss: -18.0586	Cost: 9.56s
Train Epoch: 1322 [40960/90000 (45%)]	Loss: -17.6869	Cost: 9.07s
Train Epoch: 1322 [61440/90000 (68%)]	Loss: -17.6858	Cost: 9.10s
Train Epoch: 1322 [81920/90000 (91%)]	Loss: -17.6462	Cost: 8.71s
Train Epoch: 1322 	Average Loss: -17.4903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3134

Learning rate: 0.00019149878383965054
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1323 [0/90000 (0%)]	Loss: -11.6319	Cost: 25.00s
Train Epoch: 1323 [20480/90000 (23%)]	Loss: -17.8889	Cost: 9.53s
Train Epoch: 1323 [40960/90000 (45%)]	Loss: -17.4728	Cost: 9.92s
Train Epoch: 1323 [61440/90000 (68%)]	Loss: -17.5931	Cost: 9.04s
Train Epoch: 1323 [81920/90000 (91%)]	Loss: -17.6853	Cost: 9.42s
Train Epoch: 1323 	Average Loss: -17.4089
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2227

Learning rate: 0.00019148610358195298
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1324 [0/90000 (0%)]	Loss: -12.1837	Cost: 24.51s
Train Epoch: 1324 [20480/90000 (23%)]	Loss: -18.1807	Cost: 9.48s
Train Epoch: 1324 [40960/90000 (45%)]	Loss: -17.9369	Cost: 9.11s
Train Epoch: 1324 [61440/90000 (68%)]	Loss: -18.1038	Cost: 9.05s
Train Epoch: 1324 [81920/90000 (91%)]	Loss: -17.8967	Cost: 10.02s
Train Epoch: 1324 	Average Loss: -17.7205
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4037

Learning rate: 0.00019147341429493896
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1325 [0/90000 (0%)]	Loss: -12.0080	Cost: 22.90s
Train Epoch: 1325 [20480/90000 (23%)]	Loss: -18.3916	Cost: 9.04s
Train Epoch: 1325 [40960/90000 (45%)]	Loss: -18.0737	Cost: 9.81s
Train Epoch: 1325 [61440/90000 (68%)]	Loss: -17.7374	Cost: 9.09s
Train Epoch: 1325 [81920/90000 (91%)]	Loss: -17.6825	Cost: 10.31s
Train Epoch: 1325 	Average Loss: -17.6984
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3465

Learning rate: 0.00019146071597986092
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1326 [0/90000 (0%)]	Loss: -11.8049	Cost: 24.90s
Train Epoch: 1326 [20480/90000 (23%)]	Loss: -17.9034	Cost: 9.07s
Train Epoch: 1326 [40960/90000 (45%)]	Loss: -17.8401	Cost: 9.83s
Train Epoch: 1326 [61440/90000 (68%)]	Loss: -17.8459	Cost: 9.05s
Train Epoch: 1326 [81920/90000 (91%)]	Loss: -17.8901	Cost: 10.19s
Train Epoch: 1326 	Average Loss: -17.5455
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4276

Learning rate: 0.00019144800863797208
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1327 [0/90000 (0%)]	Loss: -12.2452	Cost: 23.99s
Train Epoch: 1327 [20480/90000 (23%)]	Loss: -18.4528	Cost: 9.32s
Train Epoch: 1327 [40960/90000 (45%)]	Loss: -18.0579	Cost: 9.54s
Train Epoch: 1327 [61440/90000 (68%)]	Loss: -18.1099	Cost: 9.15s
Train Epoch: 1327 [81920/90000 (91%)]	Loss: -17.8382	Cost: 9.09s
Train Epoch: 1327 	Average Loss: -17.7761
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3159

Learning rate: 0.00019143529227052663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1328 [0/90000 (0%)]	Loss: -11.7390	Cost: 23.50s
Train Epoch: 1328 [20480/90000 (23%)]	Loss: -18.3646	Cost: 9.32s
Train Epoch: 1328 [40960/90000 (45%)]	Loss: -18.3023	Cost: 9.31s
Train Epoch: 1328 [61440/90000 (68%)]	Loss: -17.9019	Cost: 9.19s
Train Epoch: 1328 [81920/90000 (91%)]	Loss: -18.0207	Cost: 9.13s
Train Epoch: 1328 	Average Loss: -17.7920
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5205

Learning rate: 0.00019142256687877963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1329 [0/90000 (0%)]	Loss: -12.4435	Cost: 24.22s
Train Epoch: 1329 [20480/90000 (23%)]	Loss: -18.4350	Cost: 9.33s
Train Epoch: 1329 [40960/90000 (45%)]	Loss: -18.3368	Cost: 10.37s
Train Epoch: 1329 [61440/90000 (68%)]	Loss: -17.6484	Cost: 9.05s
Train Epoch: 1329 [81920/90000 (91%)]	Loss: -17.1674	Cost: 9.19s
Train Epoch: 1329 	Average Loss: -17.6321
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7976

Learning rate: 0.00019140983246398704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1330 [0/90000 (0%)]	Loss: -10.2302	Cost: 24.85s
Train Epoch: 1330 [20480/90000 (23%)]	Loss: -17.6512	Cost: 9.35s
Train Epoch: 1330 [40960/90000 (45%)]	Loss: -17.7114	Cost: 9.80s
Train Epoch: 1330 [61440/90000 (68%)]	Loss: -17.6179	Cost: 9.11s
Train Epoch: 1330 [81920/90000 (91%)]	Loss: -17.5728	Cost: 9.23s
Train Epoch: 1330 	Average Loss: -17.2704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0728

Learning rate: 0.00019139708902740564
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1331 [0/90000 (0%)]	Loss: -10.7393	Cost: 25.78s
Train Epoch: 1331 [20480/90000 (23%)]	Loss: -18.0996	Cost: 9.36s
Train Epoch: 1331 [40960/90000 (45%)]	Loss: -18.0115	Cost: 9.29s
Train Epoch: 1331 [61440/90000 (68%)]	Loss: -17.8080	Cost: 9.14s
Train Epoch: 1331 [81920/90000 (91%)]	Loss: -17.7245	Cost: 9.19s
Train Epoch: 1331 	Average Loss: -17.6071
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3928

Learning rate: 0.00019138433657029324
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1332 [0/90000 (0%)]	Loss: -11.8779	Cost: 24.01s
Train Epoch: 1332 [20480/90000 (23%)]	Loss: -17.9837	Cost: 9.42s
Train Epoch: 1332 [40960/90000 (45%)]	Loss: -17.9662	Cost: 9.26s
Train Epoch: 1332 [61440/90000 (68%)]	Loss: -17.8799	Cost: 9.17s
Train Epoch: 1332 [81920/90000 (91%)]	Loss: -17.7699	Cost: 9.17s
Train Epoch: 1332 	Average Loss: -17.6328
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3449

Learning rate: 0.0001913715750939084
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1333 [0/90000 (0%)]	Loss: -11.9250	Cost: 26.04s
Train Epoch: 1333 [20480/90000 (23%)]	Loss: -18.0960	Cost: 9.25s
Train Epoch: 1333 [40960/90000 (45%)]	Loss: -17.7631	Cost: 9.48s
Train Epoch: 1333 [61440/90000 (68%)]	Loss: -17.5788	Cost: 9.14s
Train Epoch: 1333 [81920/90000 (91%)]	Loss: -17.3033	Cost: 9.09s
Train Epoch: 1333 	Average Loss: -17.4338
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7490

Learning rate: 0.00019135880459951061
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1334 [0/90000 (0%)]	Loss: -11.6920	Cost: 25.41s
Train Epoch: 1334 [20480/90000 (23%)]	Loss: -17.7832	Cost: 9.41s
Train Epoch: 1334 [40960/90000 (45%)]	Loss: -17.7169	Cost: 9.30s
Train Epoch: 1334 [61440/90000 (68%)]	Loss: -17.8141	Cost: 9.37s
Train Epoch: 1334 [81920/90000 (91%)]	Loss: -17.8209	Cost: 9.66s
Train Epoch: 1334 	Average Loss: -17.3545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1821

Learning rate: 0.00019134602508836032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1335 [0/90000 (0%)]	Loss: -11.3506	Cost: 26.02s
Train Epoch: 1335 [20480/90000 (23%)]	Loss: -17.8204	Cost: 9.39s
Train Epoch: 1335 [40960/90000 (45%)]	Loss: -17.8268	Cost: 9.21s
Train Epoch: 1335 [61440/90000 (68%)]	Loss: -17.8987	Cost: 9.14s
Train Epoch: 1335 [81920/90000 (91%)]	Loss: -17.8165	Cost: 8.99s
Train Epoch: 1335 	Average Loss: -17.4619
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1464

Learning rate: 0.00019133323656171877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1336 [0/90000 (0%)]	Loss: -12.5420	Cost: 25.33s
Train Epoch: 1336 [20480/90000 (23%)]	Loss: -18.1237	Cost: 9.34s
Train Epoch: 1336 [40960/90000 (45%)]	Loss: -18.0199	Cost: 9.48s
Train Epoch: 1336 [61440/90000 (68%)]	Loss: -18.0946	Cost: 9.16s
Train Epoch: 1336 [81920/90000 (91%)]	Loss: -17.5871	Cost: 9.03s
Train Epoch: 1336 	Average Loss: -17.5038
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.9054

Learning rate: 0.0001913204390208482
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1337 [0/90000 (0%)]	Loss: -11.1775	Cost: 24.79s
Train Epoch: 1337 [20480/90000 (23%)]	Loss: -18.0409	Cost: 9.40s
Train Epoch: 1337 [40960/90000 (45%)]	Loss: -17.8867	Cost: 9.28s
Train Epoch: 1337 [61440/90000 (68%)]	Loss: -17.8196	Cost: 9.05s
Train Epoch: 1337 [81920/90000 (91%)]	Loss: -17.5397	Cost: 8.84s
Train Epoch: 1337 	Average Loss: -17.4427
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1889

Learning rate: 0.0001913076324670116
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1338 [0/90000 (0%)]	Loss: -12.2088	Cost: 24.98s
Train Epoch: 1338 [20480/90000 (23%)]	Loss: -18.4245	Cost: 9.43s
Train Epoch: 1338 [40960/90000 (45%)]	Loss: -18.2173	Cost: 9.25s
Train Epoch: 1338 [61440/90000 (68%)]	Loss: -18.0523	Cost: 9.12s
Train Epoch: 1338 [81920/90000 (91%)]	Loss: -17.8087	Cost: 9.10s
Train Epoch: 1338 	Average Loss: -17.6191
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1653

Learning rate: 0.00019129481690147293
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1339 [0/90000 (0%)]	Loss: -11.2791	Cost: 28.54s
Train Epoch: 1339 [20480/90000 (23%)]	Loss: -18.1846	Cost: 9.22s
Train Epoch: 1339 [40960/90000 (45%)]	Loss: -17.5590	Cost: 9.70s
Train Epoch: 1339 [61440/90000 (68%)]	Loss: -17.7498	Cost: 9.11s
Train Epoch: 1339 [81920/90000 (91%)]	Loss: -17.7985	Cost: 8.84s
Train Epoch: 1339 	Average Loss: -17.5078
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6903

Learning rate: 0.0001912819923254971
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1340 [0/90000 (0%)]	Loss: -12.0949	Cost: 27.42s
Train Epoch: 1340 [20480/90000 (23%)]	Loss: -16.4064	Cost: 9.31s
Train Epoch: 1340 [40960/90000 (45%)]	Loss: -16.3271	Cost: 9.30s
Train Epoch: 1340 [61440/90000 (68%)]	Loss: -16.6510	Cost: 9.24s
Train Epoch: 1340 [81920/90000 (91%)]	Loss: -16.9246	Cost: 8.78s
Train Epoch: 1340 	Average Loss: -16.3893
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8007

Learning rate: 0.00019126915874034982
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1341 [0/90000 (0%)]	Loss: -11.4903	Cost: 25.45s
Train Epoch: 1341 [20480/90000 (23%)]	Loss: -17.4469	Cost: 9.40s
Train Epoch: 1341 [40960/90000 (45%)]	Loss: -17.6641	Cost: 9.30s
Train Epoch: 1341 [61440/90000 (68%)]	Loss: -17.5558	Cost: 9.20s
Train Epoch: 1341 [81920/90000 (91%)]	Loss: -17.6096	Cost: 9.07s
Train Epoch: 1341 	Average Loss: -17.1415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1082

Learning rate: 0.00019125631614729769
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1342 [0/90000 (0%)]	Loss: -10.8737	Cost: 24.94s
Train Epoch: 1342 [20480/90000 (23%)]	Loss: -18.0380	Cost: 9.51s
Train Epoch: 1342 [40960/90000 (45%)]	Loss: -17.0624	Cost: 9.49s
Train Epoch: 1342 [61440/90000 (68%)]	Loss: -16.9410	Cost: 9.32s
Train Epoch: 1342 [81920/90000 (91%)]	Loss: -17.1224	Cost: 9.18s
Train Epoch: 1342 	Average Loss: -16.9732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7678

Learning rate: 0.00019124346454760824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1343 [0/90000 (0%)]	Loss: -11.8839	Cost: 24.40s
Train Epoch: 1343 [20480/90000 (23%)]	Loss: -17.7041	Cost: 9.43s
Train Epoch: 1343 [40960/90000 (45%)]	Loss: -17.7493	Cost: 9.24s
Train Epoch: 1343 [61440/90000 (68%)]	Loss: -17.6106	Cost: 9.18s
Train Epoch: 1343 [81920/90000 (91%)]	Loss: -17.5847	Cost: 8.83s
Train Epoch: 1343 	Average Loss: -17.2938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4535

Learning rate: 0.00019123060394254988
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1344 [0/90000 (0%)]	Loss: -11.9874	Cost: 25.57s
Train Epoch: 1344 [20480/90000 (23%)]	Loss: -18.2677	Cost: 9.38s
Train Epoch: 1344 [40960/90000 (45%)]	Loss: -18.2827	Cost: 9.35s
Train Epoch: 1344 [61440/90000 (68%)]	Loss: -18.1794	Cost: 9.05s
Train Epoch: 1344 [81920/90000 (91%)]	Loss: -18.1397	Cost: 8.89s
Train Epoch: 1344 	Average Loss: -17.8900
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6663

Learning rate: 0.00019121773433339187
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1345 [0/90000 (0%)]	Loss: -12.2481	Cost: 24.99s
Train Epoch: 1345 [20480/90000 (23%)]	Loss: -18.6908	Cost: 9.46s
Train Epoch: 1345 [40960/90000 (45%)]	Loss: -18.5115	Cost: 9.07s
Train Epoch: 1345 [61440/90000 (68%)]	Loss: -18.5062	Cost: 9.07s
Train Epoch: 1345 [81920/90000 (91%)]	Loss: -18.4157	Cost: 8.72s
Train Epoch: 1345 	Average Loss: -18.1821
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9384

Learning rate: 0.00019120485572140446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1346 [0/90000 (0%)]	Loss: -12.5637	Cost: 24.74s
Train Epoch: 1346 [20480/90000 (23%)]	Loss: -18.7680	Cost: 9.56s
Train Epoch: 1346 [40960/90000 (45%)]	Loss: -18.5602	Cost: 9.61s
Train Epoch: 1346 [61440/90000 (68%)]	Loss: -18.3757	Cost: 9.06s
Train Epoch: 1346 [81920/90000 (91%)]	Loss: -18.0686	Cost: 9.12s
Train Epoch: 1346 	Average Loss: -18.1761
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4700

Learning rate: 0.00019119196810785867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1347 [0/90000 (0%)]	Loss: -11.9319	Cost: 25.26s
Train Epoch: 1347 [20480/90000 (23%)]	Loss: -17.9773	Cost: 9.46s
Train Epoch: 1347 [40960/90000 (45%)]	Loss: -18.0830	Cost: 9.34s
Train Epoch: 1347 [61440/90000 (68%)]	Loss: -17.9297	Cost: 9.06s
Train Epoch: 1347 [81920/90000 (91%)]	Loss: -17.9668	Cost: 9.58s
Train Epoch: 1347 	Average Loss: -17.6255
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6887

Learning rate: 0.0001911790714940264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1348 [0/90000 (0%)]	Loss: -11.8866	Cost: 25.10s
Train Epoch: 1348 [20480/90000 (23%)]	Loss: -18.4142	Cost: 9.41s
Train Epoch: 1348 [40960/90000 (45%)]	Loss: -18.4047	Cost: 9.28s
Train Epoch: 1348 [61440/90000 (68%)]	Loss: -18.3779	Cost: 9.11s
Train Epoch: 1348 [81920/90000 (91%)]	Loss: -18.3251	Cost: 10.08s
Train Epoch: 1348 	Average Loss: -18.0007
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.7731

Learning rate: 0.0001911661658811806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1349 [0/90000 (0%)]	Loss: -12.1443	Cost: 24.47s
Train Epoch: 1349 [20480/90000 (23%)]	Loss: -18.6734	Cost: 9.54s
Train Epoch: 1349 [40960/90000 (45%)]	Loss: -18.5264	Cost: 9.08s
Train Epoch: 1349 [61440/90000 (68%)]	Loss: -18.4756	Cost: 9.10s
Train Epoch: 1349 [81920/90000 (91%)]	Loss: -18.1978	Cost: 10.04s
Train Epoch: 1349 	Average Loss: -18.0625
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.8763

Learning rate: 0.00019115325127059494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1350 [0/90000 (0%)]	Loss: -10.4583	Cost: 23.60s
Train Epoch: 1350 [20480/90000 (23%)]	Loss: -18.5417	Cost: 9.03s
Train Epoch: 1350 [40960/90000 (45%)]	Loss: -18.6623	Cost: 9.09s
Train Epoch: 1350 [61440/90000 (68%)]	Loss: -18.3631	Cost: 9.04s
Train Epoch: 1350 [81920/90000 (91%)]	Loss: -18.1825	Cost: 9.91s
Train Epoch: 1350 	Average Loss: -18.0858
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9187

Saving model as model.pt_e1350 & waveforms_supplementary.hdf5_e1350
Learning rate: 0.00019114032766354405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1351 [0/90000 (0%)]	Loss: -11.8087	Cost: 23.05s
Train Epoch: 1351 [20480/90000 (23%)]	Loss: -18.8833	Cost: 9.26s
Train Epoch: 1351 [40960/90000 (45%)]	Loss: -18.5089	Cost: 9.39s
Train Epoch: 1351 [61440/90000 (68%)]	Loss: -18.5493	Cost: 9.15s
Train Epoch: 1351 [81920/90000 (91%)]	Loss: -18.2664	Cost: 9.08s
Train Epoch: 1351 	Average Loss: -18.1267
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.7167

Learning rate: 0.00019112739506130344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1352 [0/90000 (0%)]	Loss: -11.2682	Cost: 23.95s
Train Epoch: 1352 [20480/90000 (23%)]	Loss: -18.2314	Cost: 9.12s
Train Epoch: 1352 [40960/90000 (45%)]	Loss: -18.1768	Cost: 9.72s
Train Epoch: 1352 [61440/90000 (68%)]	Loss: -18.2414	Cost: 9.12s
Train Epoch: 1352 [81920/90000 (91%)]	Loss: -18.0535	Cost: 10.59s
Train Epoch: 1352 	Average Loss: -17.8875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5534

Learning rate: 0.0001911144534651495
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1353 [0/90000 (0%)]	Loss: -11.4468	Cost: 23.91s
Train Epoch: 1353 [20480/90000 (23%)]	Loss: -18.5300	Cost: 9.10s
Train Epoch: 1353 [40960/90000 (45%)]	Loss: -18.3947	Cost: 9.97s
Train Epoch: 1353 [61440/90000 (68%)]	Loss: -18.4830	Cost: 8.99s
Train Epoch: 1353 [81920/90000 (91%)]	Loss: -18.5118	Cost: 9.61s
Train Epoch: 1353 	Average Loss: -18.1099
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9364

Learning rate: 0.00019110150287635953
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1354 [0/90000 (0%)]	Loss: -12.7894	Cost: 24.11s
Train Epoch: 1354 [20480/90000 (23%)]	Loss: -18.6576	Cost: 9.31s
Train Epoch: 1354 [40960/90000 (45%)]	Loss: -18.4589	Cost: 10.21s
Train Epoch: 1354 [61440/90000 (68%)]	Loss: -18.5314	Cost: 9.06s
Train Epoch: 1354 [81920/90000 (91%)]	Loss: -18.5101	Cost: 8.98s
Train Epoch: 1354 	Average Loss: -18.1395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6728

Learning rate: 0.00019108854329621171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1355 [0/90000 (0%)]	Loss: -12.3823	Cost: 24.70s
Train Epoch: 1355 [20480/90000 (23%)]	Loss: -18.4827	Cost: 9.09s
Train Epoch: 1355 [40960/90000 (45%)]	Loss: -18.4963	Cost: 10.35s
Train Epoch: 1355 [61440/90000 (68%)]	Loss: -18.3479	Cost: 8.92s
Train Epoch: 1355 [81920/90000 (91%)]	Loss: -17.9963	Cost: 8.93s
Train Epoch: 1355 	Average Loss: -18.0393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5846

Learning rate: 0.0001910755747259851
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1356 [0/90000 (0%)]	Loss: -12.5154	Cost: 24.41s
Train Epoch: 1356 [20480/90000 (23%)]	Loss: -18.5725	Cost: 9.03s
Train Epoch: 1356 [40960/90000 (45%)]	Loss: -18.4517	Cost: 9.30s
Train Epoch: 1356 [61440/90000 (68%)]	Loss: -18.1602	Cost: 8.98s
Train Epoch: 1356 [81920/90000 (91%)]	Loss: -18.0861	Cost: 8.80s
Train Epoch: 1356 	Average Loss: -17.9699
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6939

Learning rate: 0.0001910625971669596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1357 [0/90000 (0%)]	Loss: -11.7405	Cost: 24.85s
Train Epoch: 1357 [20480/90000 (23%)]	Loss: -18.6585	Cost: 9.01s
Train Epoch: 1357 [40960/90000 (45%)]	Loss: -18.4074	Cost: 9.46s
Train Epoch: 1357 [61440/90000 (68%)]	Loss: -18.4501	Cost: 8.93s
Train Epoch: 1357 [81920/90000 (91%)]	Loss: -18.3509	Cost: 9.54s
Train Epoch: 1357 	Average Loss: -18.0666
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.7615

Learning rate: 0.00019104961062041612
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1358 [0/90000 (0%)]	Loss: -11.7434	Cost: 24.89s
Train Epoch: 1358 [20480/90000 (23%)]	Loss: -18.6783	Cost: 9.38s
Train Epoch: 1358 [40960/90000 (45%)]	Loss: -18.4972	Cost: 9.52s
Train Epoch: 1358 [61440/90000 (68%)]	Loss: -18.3529	Cost: 8.97s
Train Epoch: 1358 [81920/90000 (91%)]	Loss: -18.2756	Cost: 8.82s
Train Epoch: 1358 	Average Loss: -18.0545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6114

Learning rate: 0.0001910366150876363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1359 [0/90000 (0%)]	Loss: -12.4826	Cost: 25.02s
Train Epoch: 1359 [20480/90000 (23%)]	Loss: -18.5336	Cost: 9.37s
Train Epoch: 1359 [40960/90000 (45%)]	Loss: -18.0703	Cost: 9.23s
Train Epoch: 1359 [61440/90000 (68%)]	Loss: -17.7281	Cost: 9.12s
Train Epoch: 1359 [81920/90000 (91%)]	Loss: -17.7473	Cost: 9.30s
Train Epoch: 1359 	Average Loss: -17.7819
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4036

Learning rate: 0.0001910236105699028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1360 [0/90000 (0%)]	Loss: -11.6996	Cost: 25.75s
Train Epoch: 1360 [20480/90000 (23%)]	Loss: -18.3304	Cost: 9.31s
Train Epoch: 1360 [40960/90000 (45%)]	Loss: -18.0770	Cost: 9.88s
Train Epoch: 1360 [61440/90000 (68%)]	Loss: -18.0767	Cost: 9.11s
Train Epoch: 1360 [81920/90000 (91%)]	Loss: -18.2885	Cost: 8.81s
Train Epoch: 1360 	Average Loss: -17.8039
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.7862

Learning rate: 0.00019101059706849906
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1361 [0/90000 (0%)]	Loss: -12.5970	Cost: 25.20s
Train Epoch: 1361 [20480/90000 (23%)]	Loss: -18.6513	Cost: 9.36s
Train Epoch: 1361 [40960/90000 (45%)]	Loss: -18.4568	Cost: 9.22s
Train Epoch: 1361 [61440/90000 (68%)]	Loss: -18.6385	Cost: 9.24s
Train Epoch: 1361 [81920/90000 (91%)]	Loss: -18.2080	Cost: 9.06s
Train Epoch: 1361 	Average Loss: -18.1869
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.8995

Learning rate: 0.00019099757458470952
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1362 [0/90000 (0%)]	Loss: -12.5626	Cost: 25.31s
Train Epoch: 1362 [20480/90000 (23%)]	Loss: -18.8147	Cost: 9.37s
Train Epoch: 1362 [40960/90000 (45%)]	Loss: -18.4312	Cost: 9.51s
Train Epoch: 1362 [61440/90000 (68%)]	Loss: -18.2537	Cost: 9.06s
Train Epoch: 1362 [81920/90000 (91%)]	Loss: -18.2852	Cost: 8.80s
Train Epoch: 1362 	Average Loss: -18.0757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.8458

Learning rate: 0.00019098454311981946
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1363 [0/90000 (0%)]	Loss: -12.0975	Cost: 25.17s
Train Epoch: 1363 [20480/90000 (23%)]	Loss: -18.1437	Cost: 9.20s
Train Epoch: 1363 [40960/90000 (45%)]	Loss: -17.9849	Cost: 9.62s
Train Epoch: 1363 [61440/90000 (68%)]	Loss: -18.1685	Cost: 9.16s
Train Epoch: 1363 [81920/90000 (91%)]	Loss: -18.2320	Cost: 8.96s
Train Epoch: 1363 	Average Loss: -17.8746
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.8158

Learning rate: 0.000190971502675115
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1364 [0/90000 (0%)]	Loss: -12.1766	Cost: 25.70s
Train Epoch: 1364 [20480/90000 (23%)]	Loss: -18.8165	Cost: 9.76s
Train Epoch: 1364 [40960/90000 (45%)]	Loss: -18.2189	Cost: 9.23s
Train Epoch: 1364 [61440/90000 (68%)]	Loss: -18.3506	Cost: 8.93s
Train Epoch: 1364 [81920/90000 (91%)]	Loss: -18.4227	Cost: 8.71s
Train Epoch: 1364 	Average Loss: -18.1036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9641

Learning rate: 0.00019095845325188318
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1365 [0/90000 (0%)]	Loss: -13.1076	Cost: 25.84s
Train Epoch: 1365 [20480/90000 (23%)]	Loss: -18.9836	Cost: 9.44s
Train Epoch: 1365 [40960/90000 (45%)]	Loss: -18.5614	Cost: 9.54s
Train Epoch: 1365 [61440/90000 (68%)]	Loss: -18.4412	Cost: 9.04s
Train Epoch: 1365 [81920/90000 (91%)]	Loss: -18.4810	Cost: 9.51s
Train Epoch: 1365 	Average Loss: -18.3137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.8358

Learning rate: 0.0001909453948514119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1366 [0/90000 (0%)]	Loss: -12.2415	Cost: 24.61s
Train Epoch: 1366 [20480/90000 (23%)]	Loss: -18.8075	Cost: 9.53s
Train Epoch: 1366 [40960/90000 (45%)]	Loss: -18.1444	Cost: 9.37s
Train Epoch: 1366 [61440/90000 (68%)]	Loss: -18.1761	Cost: 9.05s
Train Epoch: 1366 [81920/90000 (91%)]	Loss: -18.1196	Cost: 9.72s
Train Epoch: 1366 	Average Loss: -18.0344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6809

Learning rate: 0.00019093232747499004
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1367 [0/90000 (0%)]	Loss: -12.1555	Cost: 24.78s
Train Epoch: 1367 [20480/90000 (23%)]	Loss: -18.4673	Cost: 9.43s
Train Epoch: 1367 [40960/90000 (45%)]	Loss: -18.4784	Cost: 9.17s
Train Epoch: 1367 [61440/90000 (68%)]	Loss: -18.4271	Cost: 9.19s
Train Epoch: 1367 [81920/90000 (91%)]	Loss: -18.4620	Cost: 9.96s
Train Epoch: 1367 	Average Loss: -18.1041
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9169

Learning rate: 0.00019091925112390724
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1368 [0/90000 (0%)]	Loss: -11.8252	Cost: 25.95s
Train Epoch: 1368 [20480/90000 (23%)]	Loss: -18.8419	Cost: 9.08s
Train Epoch: 1368 [40960/90000 (45%)]	Loss: -18.5712	Cost: 9.78s
Train Epoch: 1368 [61440/90000 (68%)]	Loss: -18.7346	Cost: 9.03s
Train Epoch: 1368 [81920/90000 (91%)]	Loss: -18.6742	Cost: 9.85s
Train Epoch: 1368 	Average Loss: -18.3406
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0213

Learning rate: 0.0001909061657994541
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1369 [0/90000 (0%)]	Loss: -12.1541	Cost: 24.03s
Train Epoch: 1369 [20480/90000 (23%)]	Loss: -18.8682	Cost: 9.36s
Train Epoch: 1369 [40960/90000 (45%)]	Loss: -18.7310	Cost: 9.56s
Train Epoch: 1369 [61440/90000 (68%)]	Loss: -17.9827	Cost: 9.10s
Train Epoch: 1369 [81920/90000 (91%)]	Loss: -18.1543	Cost: 9.86s
Train Epoch: 1369 	Average Loss: -18.0639
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6804

Learning rate: 0.0001908930715029221
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1370 [0/90000 (0%)]	Loss: -12.2208	Cost: 23.55s
Train Epoch: 1370 [20480/90000 (23%)]	Loss: -18.5746	Cost: 9.35s
Train Epoch: 1370 [40960/90000 (45%)]	Loss: -18.3525	Cost: 9.50s
Train Epoch: 1370 [61440/90000 (68%)]	Loss: -18.5452	Cost: 9.26s
Train Epoch: 1370 [81920/90000 (91%)]	Loss: -18.4377	Cost: 9.09s
Train Epoch: 1370 	Average Loss: -18.1275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.8820

Learning rate: 0.0001908799682356036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1371 [0/90000 (0%)]	Loss: -12.4197	Cost: 23.60s
Train Epoch: 1371 [20480/90000 (23%)]	Loss: -18.9134	Cost: 9.86s
Train Epoch: 1371 [40960/90000 (45%)]	Loss: -18.5965	Cost: 9.27s
Train Epoch: 1371 [61440/90000 (68%)]	Loss: -18.6463	Cost: 9.55s
Train Epoch: 1371 [81920/90000 (91%)]	Loss: -18.6331	Cost: 9.55s
Train Epoch: 1371 	Average Loss: -18.3120
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9834

Learning rate: 0.0001908668559987918
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1372 [0/90000 (0%)]	Loss: -12.5738	Cost: 24.41s
Train Epoch: 1372 [20480/90000 (23%)]	Loss: -18.8515	Cost: 9.42s
Train Epoch: 1372 [40960/90000 (45%)]	Loss: -18.5943	Cost: 9.51s
Train Epoch: 1372 [61440/90000 (68%)]	Loss: -17.7605	Cost: 9.19s
Train Epoch: 1372 [81920/90000 (91%)]	Loss: -17.7390	Cost: 9.09s
Train Epoch: 1372 	Average Loss: -17.9282
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2719

Learning rate: 0.00019085373479378083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1373 [0/90000 (0%)]	Loss: -11.1290	Cost: 23.92s
Train Epoch: 1373 [20480/90000 (23%)]	Loss: -18.3524	Cost: 9.39s
Train Epoch: 1373 [40960/90000 (45%)]	Loss: -18.1954	Cost: 9.20s
Train Epoch: 1373 [61440/90000 (68%)]	Loss: -18.3897	Cost: 9.08s
Train Epoch: 1373 [81920/90000 (91%)]	Loss: -18.3806	Cost: 8.93s
Train Epoch: 1373 	Average Loss: -17.9745
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6903

Learning rate: 0.00019084060462186577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1374 [0/90000 (0%)]	Loss: -11.4594	Cost: 26.39s
Train Epoch: 1374 [20480/90000 (23%)]	Loss: -18.7309	Cost: 9.29s
Train Epoch: 1374 [40960/90000 (45%)]	Loss: -18.6201	Cost: 9.45s
Train Epoch: 1374 [61440/90000 (68%)]	Loss: -18.7003	Cost: 9.05s
Train Epoch: 1374 [81920/90000 (91%)]	Loss: -18.4662	Cost: 8.82s
Train Epoch: 1374 	Average Loss: -18.2507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9905

Learning rate: 0.00019082746548434244
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1375 [0/90000 (0%)]	Loss: -13.0035	Cost: 24.10s
Train Epoch: 1375 [20480/90000 (23%)]	Loss: -19.0618	Cost: 9.41s
Train Epoch: 1375 [40960/90000 (45%)]	Loss: -18.7064	Cost: 9.23s
Train Epoch: 1375 [61440/90000 (68%)]	Loss: -18.7550	Cost: 9.12s
Train Epoch: 1375 [81920/90000 (91%)]	Loss: -18.6616	Cost: 9.54s
Train Epoch: 1375 	Average Loss: -18.5395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0608

Learning rate: 0.0001908143173825077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1376 [0/90000 (0%)]	Loss: -12.0940	Cost: 25.60s
Train Epoch: 1376 [20480/90000 (23%)]	Loss: -19.1009	Cost: 9.34s
Train Epoch: 1376 [40960/90000 (45%)]	Loss: -18.9225	Cost: 9.57s
Train Epoch: 1376 [61440/90000 (68%)]	Loss: -18.6779	Cost: 9.11s
Train Epoch: 1376 [81920/90000 (91%)]	Loss: -18.7299	Cost: 8.85s
Train Epoch: 1376 	Average Loss: -18.4265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1500

Learning rate: 0.00019080116031765912
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1377 [0/90000 (0%)]	Loss: -13.1707	Cost: 28.13s
Train Epoch: 1377 [20480/90000 (23%)]	Loss: -19.1252	Cost: 9.32s
Train Epoch: 1377 [40960/90000 (45%)]	Loss: -18.6604	Cost: 9.24s
Train Epoch: 1377 [61440/90000 (68%)]	Loss: -18.6284	Cost: 9.20s
Train Epoch: 1377 [81920/90000 (91%)]	Loss: -18.5761	Cost: 8.81s
Train Epoch: 1377 	Average Loss: -18.4896
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3338

Learning rate: 0.00019078799429109533
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1378 [0/90000 (0%)]	Loss: -12.2571	Cost: 25.88s
Train Epoch: 1378 [20480/90000 (23%)]	Loss: -18.9158	Cost: 9.41s
Train Epoch: 1378 [40960/90000 (45%)]	Loss: -18.8122	Cost: 9.46s
Train Epoch: 1378 [61440/90000 (68%)]	Loss: -18.6817	Cost: 9.04s
Train Epoch: 1378 [81920/90000 (91%)]	Loss: -18.4181	Cost: 8.83s
Train Epoch: 1378 	Average Loss: -18.4022
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0676

Learning rate: 0.0001907748193041157
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1379 [0/90000 (0%)]	Loss: -13.0397	Cost: 25.50s
Train Epoch: 1379 [20480/90000 (23%)]	Loss: -18.9131	Cost: 9.37s
Train Epoch: 1379 [40960/90000 (45%)]	Loss: -18.7881	Cost: 9.29s
Train Epoch: 1379 [61440/90000 (68%)]	Loss: -18.6818	Cost: 9.09s
Train Epoch: 1379 [81920/90000 (91%)]	Loss: -18.6676	Cost: 8.83s
Train Epoch: 1379 	Average Loss: -18.4084
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0980

Learning rate: 0.00019076163535802063
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1380 [0/90000 (0%)]	Loss: -12.6364	Cost: 24.75s
Train Epoch: 1380 [20480/90000 (23%)]	Loss: -19.1027	Cost: 9.38s
Train Epoch: 1380 [40960/90000 (45%)]	Loss: -18.4580	Cost: 9.54s
Train Epoch: 1380 [61440/90000 (68%)]	Loss: -18.3971	Cost: 9.20s
Train Epoch: 1380 [81920/90000 (91%)]	Loss: -18.5098	Cost: 8.86s
Train Epoch: 1380 	Average Loss: -18.3099
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1179

Learning rate: 0.00019074844245411124
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1381 [0/90000 (0%)]	Loss: -12.5405	Cost: 24.91s
Train Epoch: 1381 [20480/90000 (23%)]	Loss: -18.6294	Cost: 9.09s
Train Epoch: 1381 [40960/90000 (45%)]	Loss: -18.3926	Cost: 9.95s
Train Epoch: 1381 [61440/90000 (68%)]	Loss: -18.1012	Cost: 9.10s
Train Epoch: 1381 [81920/90000 (91%)]	Loss: -18.2526	Cost: 8.89s
Train Epoch: 1381 	Average Loss: -18.0915
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.8424

Learning rate: 0.00019073524059368967
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1382 [0/90000 (0%)]	Loss: -11.5371	Cost: 24.88s
Train Epoch: 1382 [20480/90000 (23%)]	Loss: -18.9142	Cost: 9.37s
Train Epoch: 1382 [40960/90000 (45%)]	Loss: -18.6075	Cost: 9.45s
Train Epoch: 1382 [61440/90000 (68%)]	Loss: -18.6075	Cost: 9.09s
Train Epoch: 1382 [81920/90000 (91%)]	Loss: -18.7056	Cost: 8.90s
Train Epoch: 1382 	Average Loss: -18.3091
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1906

Learning rate: 0.00019072202977805887
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1383 [0/90000 (0%)]	Loss: -11.7279	Cost: 25.62s
Train Epoch: 1383 [20480/90000 (23%)]	Loss: -19.0337	Cost: 9.54s
Train Epoch: 1383 [40960/90000 (45%)]	Loss: -18.8584	Cost: 9.07s
Train Epoch: 1383 [61440/90000 (68%)]	Loss: -18.7322	Cost: 9.07s
Train Epoch: 1383 [81920/90000 (91%)]	Loss: -18.6625	Cost: 8.73s
Train Epoch: 1383 	Average Loss: -18.4175
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0532

Learning rate: 0.0001907088100085227
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1384 [0/90000 (0%)]	Loss: -11.9747	Cost: 25.34s
Train Epoch: 1384 [20480/90000 (23%)]	Loss: -18.9474	Cost: 9.35s
Train Epoch: 1384 [40960/90000 (45%)]	Loss: -18.6434	Cost: 9.82s
Train Epoch: 1384 [61440/90000 (68%)]	Loss: -18.4743	Cost: 9.02s
Train Epoch: 1384 [81920/90000 (91%)]	Loss: -18.4935	Cost: 8.73s
Train Epoch: 1384 	Average Loss: -18.2804
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0372

Learning rate: 0.00019069558128638592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1385 [0/90000 (0%)]	Loss: -11.9986	Cost: 24.92s
Train Epoch: 1385 [20480/90000 (23%)]	Loss: -18.6880	Cost: 9.48s
Train Epoch: 1385 [40960/90000 (45%)]	Loss: -18.8254	Cost: 9.14s
Train Epoch: 1385 [61440/90000 (68%)]	Loss: -18.5834	Cost: 9.06s
Train Epoch: 1385 [81920/90000 (91%)]	Loss: -18.5672	Cost: 9.90s
Train Epoch: 1385 	Average Loss: -18.3674
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1570

Learning rate: 0.0001906823436129541
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1386 [0/90000 (0%)]	Loss: -12.4990	Cost: 24.91s
Train Epoch: 1386 [20480/90000 (23%)]	Loss: -19.1791	Cost: 9.05s
Train Epoch: 1386 [40960/90000 (45%)]	Loss: -18.9930	Cost: 10.00s
Train Epoch: 1386 [61440/90000 (68%)]	Loss: -18.9085	Cost: 9.17s
Train Epoch: 1386 [81920/90000 (91%)]	Loss: -18.4854	Cost: 9.78s
Train Epoch: 1386 	Average Loss: -18.6025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.8967

Learning rate: 0.00019066909698953378
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1387 [0/90000 (0%)]	Loss: -12.5682	Cost: 25.01s
Train Epoch: 1387 [20480/90000 (23%)]	Loss: -19.0715	Cost: 9.10s
Train Epoch: 1387 [40960/90000 (45%)]	Loss: -18.8417	Cost: 10.00s
Train Epoch: 1387 [61440/90000 (68%)]	Loss: -18.9480	Cost: 9.09s
Train Epoch: 1387 [81920/90000 (91%)]	Loss: -18.6508	Cost: 10.02s
Train Epoch: 1387 	Average Loss: -18.4828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0187

Learning rate: 0.0001906558414174324
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1388 [0/90000 (0%)]	Loss: -13.0369	Cost: 24.87s
Train Epoch: 1388 [20480/90000 (23%)]	Loss: -19.0485	Cost: 9.14s
Train Epoch: 1388 [40960/90000 (45%)]	Loss: -19.1364	Cost: 9.73s
Train Epoch: 1388 [61440/90000 (68%)]	Loss: -18.9298	Cost: 9.03s
Train Epoch: 1388 [81920/90000 (91%)]	Loss: -18.4727	Cost: 9.93s
Train Epoch: 1388 	Average Loss: -18.6026
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9270

Learning rate: 0.0001906425768979581
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1389 [0/90000 (0%)]	Loss: -12.2774	Cost: 23.77s
Train Epoch: 1389 [20480/90000 (23%)]	Loss: -19.0480	Cost: 9.31s
Train Epoch: 1389 [40960/90000 (45%)]	Loss: -18.7012	Cost: 9.18s
Train Epoch: 1389 [61440/90000 (68%)]	Loss: -18.7978	Cost: 9.17s
Train Epoch: 1389 [81920/90000 (91%)]	Loss: -18.6638	Cost: 9.11s
Train Epoch: 1389 	Average Loss: -18.4268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2163

Learning rate: 0.00019062930343242013
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1390 [0/90000 (0%)]	Loss: -12.8497	Cost: 24.28s
Train Epoch: 1390 [20480/90000 (23%)]	Loss: -19.2745	Cost: 9.34s
Train Epoch: 1390 [40960/90000 (45%)]	Loss: -18.8506	Cost: 9.58s
Train Epoch: 1390 [61440/90000 (68%)]	Loss: -18.6709	Cost: 9.49s
Train Epoch: 1390 [81920/90000 (91%)]	Loss: -18.5557	Cost: 9.99s
Train Epoch: 1390 	Average Loss: -18.4555
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.8180

Learning rate: 0.00019061602102212854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1391 [0/90000 (0%)]	Loss: -11.4548	Cost: 22.17s
Train Epoch: 1391 [20480/90000 (23%)]	Loss: -18.8439	Cost: 9.33s
Train Epoch: 1391 [40960/90000 (45%)]	Loss: -18.7517	Cost: 9.29s
Train Epoch: 1391 [61440/90000 (68%)]	Loss: -18.7953	Cost: 9.14s
Train Epoch: 1391 [81920/90000 (91%)]	Loss: -18.6482	Cost: 9.24s
Train Epoch: 1391 	Average Loss: -18.3776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1150

Learning rate: 0.0001906027296683942
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1392 [0/90000 (0%)]	Loss: -12.3750	Cost: 23.98s
Train Epoch: 1392 [20480/90000 (23%)]	Loss: -18.8114	Cost: 9.41s
Train Epoch: 1392 [40960/90000 (45%)]	Loss: -18.8946	Cost: 9.23s
Train Epoch: 1392 [61440/90000 (68%)]	Loss: -18.8374	Cost: 9.30s
Train Epoch: 1392 [81920/90000 (91%)]	Loss: -18.5350	Cost: 9.20s
Train Epoch: 1392 	Average Loss: -18.3980
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9975

Learning rate: 0.00019058942937252897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1393 [0/90000 (0%)]	Loss: -12.3199	Cost: 24.23s
Train Epoch: 1393 [20480/90000 (23%)]	Loss: -19.2241	Cost: 9.36s
Train Epoch: 1393 [40960/90000 (45%)]	Loss: -18.8355	Cost: 9.27s
Train Epoch: 1393 [61440/90000 (68%)]	Loss: -18.9376	Cost: 9.19s
Train Epoch: 1393 [81920/90000 (91%)]	Loss: -18.8466	Cost: 9.02s
Train Epoch: 1393 	Average Loss: -18.5683
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1700

Learning rate: 0.00019057612013584547
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1394 [0/90000 (0%)]	Loss: -12.5850	Cost: 26.22s
Train Epoch: 1394 [20480/90000 (23%)]	Loss: -18.9278	Cost: 9.32s
Train Epoch: 1394 [40960/90000 (45%)]	Loss: -18.6501	Cost: 9.31s
Train Epoch: 1394 [61440/90000 (68%)]	Loss: -18.5638	Cost: 9.35s
Train Epoch: 1394 [81920/90000 (91%)]	Loss: -18.6511	Cost: 8.91s
Train Epoch: 1394 	Average Loss: -18.3400
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0915

Learning rate: 0.00019056280195965734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1395 [0/90000 (0%)]	Loss: -12.0625	Cost: 24.44s
Train Epoch: 1395 [20480/90000 (23%)]	Loss: -19.0735	Cost: 9.38s
Train Epoch: 1395 [40960/90000 (45%)]	Loss: -18.6074	Cost: 9.33s
Train Epoch: 1395 [61440/90000 (68%)]	Loss: -18.6188	Cost: 9.12s
Train Epoch: 1395 [81920/90000 (91%)]	Loss: -18.1266	Cost: 8.91s
Train Epoch: 1395 	Average Loss: -18.2718
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.8923

Learning rate: 0.000190549474845279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1396 [0/90000 (0%)]	Loss: -11.3312	Cost: 25.53s
Train Epoch: 1396 [20480/90000 (23%)]	Loss: -18.5859	Cost: 9.51s
Train Epoch: 1396 [40960/90000 (45%)]	Loss: -18.5825	Cost: 9.31s
Train Epoch: 1396 [61440/90000 (68%)]	Loss: -18.6935	Cost: 9.37s
Train Epoch: 1396 [81920/90000 (91%)]	Loss: -18.7394	Cost: 8.78s
Train Epoch: 1396 	Average Loss: -18.1518
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0126

Learning rate: 0.00019053613879402572
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1397 [0/90000 (0%)]	Loss: -11.9931	Cost: 25.72s
Train Epoch: 1397 [20480/90000 (23%)]	Loss: -18.8209	Cost: 9.59s
Train Epoch: 1397 [40960/90000 (45%)]	Loss: -18.8875	Cost: 9.31s
Train Epoch: 1397 [61440/90000 (68%)]	Loss: -18.9926	Cost: 9.22s
Train Epoch: 1397 [81920/90000 (91%)]	Loss: -18.5627	Cost: 9.03s
Train Epoch: 1397 	Average Loss: -18.4301
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1489

Learning rate: 0.00019052279380721383
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1398 [0/90000 (0%)]	Loss: -12.0142	Cost: 26.34s
Train Epoch: 1398 [20480/90000 (23%)]	Loss: -19.1574	Cost: 9.34s
Train Epoch: 1398 [40960/90000 (45%)]	Loss: -18.8412	Cost: 9.33s
Train Epoch: 1398 [61440/90000 (68%)]	Loss: -18.9052	Cost: 9.41s
Train Epoch: 1398 [81920/90000 (91%)]	Loss: -18.4366	Cost: 8.89s
Train Epoch: 1398 	Average Loss: -18.4518
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9366

Learning rate: 0.00019050943988616038
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1399 [0/90000 (0%)]	Loss: -12.5603	Cost: 25.59s
Train Epoch: 1399 [20480/90000 (23%)]	Loss: -18.6411	Cost: 9.43s
Train Epoch: 1399 [40960/90000 (45%)]	Loss: -18.6122	Cost: 9.25s
Train Epoch: 1399 [61440/90000 (68%)]	Loss: -19.0575	Cost: 9.21s
Train Epoch: 1399 [81920/90000 (91%)]	Loss: -18.6472	Cost: 8.86s
Train Epoch: 1399 	Average Loss: -18.3287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0317

Learning rate: 0.0001904960770321833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1400 [0/90000 (0%)]	Loss: -12.1087	Cost: 26.14s
Train Epoch: 1400 [20480/90000 (23%)]	Loss: -19.0356	Cost: 9.34s
Train Epoch: 1400 [40960/90000 (45%)]	Loss: -18.8682	Cost: 9.36s
Train Epoch: 1400 [61440/90000 (68%)]	Loss: -19.0280	Cost: 9.45s
Train Epoch: 1400 [81920/90000 (91%)]	Loss: -18.8524	Cost: 9.00s
Train Epoch: 1400 	Average Loss: -18.5415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2032

Saving model as model.pt_e1400 & waveforms_supplementary.hdf5_e1400
Learning rate: 0.00019048270524660153
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1401 [0/90000 (0%)]	Loss: -12.4090	Cost: 26.30s
Train Epoch: 1401 [20480/90000 (23%)]	Loss: -19.0059	Cost: 9.40s
Train Epoch: 1401 [40960/90000 (45%)]	Loss: -19.0295	Cost: 9.32s
Train Epoch: 1401 [61440/90000 (68%)]	Loss: -18.8972	Cost: 9.16s
Train Epoch: 1401 [81920/90000 (91%)]	Loss: -18.6867	Cost: 8.87s
Train Epoch: 1401 	Average Loss: -18.4597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.7878

Learning rate: 0.00019046932453073475
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1402 [0/90000 (0%)]	Loss: -11.5962	Cost: 25.95s
Train Epoch: 1402 [20480/90000 (23%)]	Loss: -18.4126	Cost: 9.37s
Train Epoch: 1402 [40960/90000 (45%)]	Loss: -18.5440	Cost: 9.97s
Train Epoch: 1402 [61440/90000 (68%)]	Loss: -18.7435	Cost: 9.16s
Train Epoch: 1402 [81920/90000 (91%)]	Loss: -18.5933	Cost: 9.01s
Train Epoch: 1402 	Average Loss: -18.1729
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9665

Learning rate: 0.0001904559348859036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1403 [0/90000 (0%)]	Loss: -11.5996	Cost: 25.02s
Train Epoch: 1403 [20480/90000 (23%)]	Loss: -19.0053	Cost: 9.18s
Train Epoch: 1403 [40960/90000 (45%)]	Loss: -18.8827	Cost: 9.35s
Train Epoch: 1403 [61440/90000 (68%)]	Loss: -17.9542	Cost: 9.16s
Train Epoch: 1403 [81920/90000 (91%)]	Loss: -18.3130	Cost: 9.01s
Train Epoch: 1403 	Average Loss: -18.2378
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.8129

Learning rate: 0.00019044253631342962
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1404 [0/90000 (0%)]	Loss: -12.7569	Cost: 25.70s
Train Epoch: 1404 [20480/90000 (23%)]	Loss: -18.5849	Cost: 9.37s
Train Epoch: 1404 [40960/90000 (45%)]	Loss: -18.5217	Cost: 9.35s
Train Epoch: 1404 [61440/90000 (68%)]	Loss: -18.6101	Cost: 9.06s
Train Epoch: 1404 [81920/90000 (91%)]	Loss: -18.6161	Cost: 8.85s
Train Epoch: 1404 	Average Loss: -18.2315
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0880

Learning rate: 0.00019042912881463516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1405 [0/90000 (0%)]	Loss: -12.1469	Cost: 24.87s
Train Epoch: 1405 [20480/90000 (23%)]	Loss: -19.0679	Cost: 9.71s
Train Epoch: 1405 [40960/90000 (45%)]	Loss: -18.7890	Cost: 9.07s
Train Epoch: 1405 [61440/90000 (68%)]	Loss: -18.8733	Cost: 8.94s
Train Epoch: 1405 [81920/90000 (91%)]	Loss: -18.6670	Cost: 8.70s
Train Epoch: 1405 	Average Loss: -18.4689
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9933

Learning rate: 0.0001904157123908435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1406 [0/90000 (0%)]	Loss: -11.8318	Cost: 25.23s
Train Epoch: 1406 [20480/90000 (23%)]	Loss: -18.9133	Cost: 9.56s
Train Epoch: 1406 [40960/90000 (45%)]	Loss: -18.6855	Cost: 9.40s
Train Epoch: 1406 [61440/90000 (68%)]	Loss: -18.4226	Cost: 9.02s
Train Epoch: 1406 [81920/90000 (91%)]	Loss: -18.4647	Cost: 9.63s
Train Epoch: 1406 	Average Loss: -18.2508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0805

Learning rate: 0.00019040228704337876
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1407 [0/90000 (0%)]	Loss: -11.6589	Cost: 24.07s
Train Epoch: 1407 [20480/90000 (23%)]	Loss: -18.9172	Cost: 9.13s
Train Epoch: 1407 [40960/90000 (45%)]	Loss: -18.8004	Cost: 9.88s
Train Epoch: 1407 [61440/90000 (68%)]	Loss: -18.9103	Cost: 9.00s
Train Epoch: 1407 [81920/90000 (91%)]	Loss: -18.8315	Cost: 10.25s
Train Epoch: 1407 	Average Loss: -18.4649
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2741

Learning rate: 0.00019038885277356603
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1408 [0/90000 (0%)]	Loss: -12.1964	Cost: 23.29s
Train Epoch: 1408 [20480/90000 (23%)]	Loss: -19.0361	Cost: 9.11s
Train Epoch: 1408 [40960/90000 (45%)]	Loss: -19.0838	Cost: 9.87s
Train Epoch: 1408 [61440/90000 (68%)]	Loss: -18.7473	Cost: 9.10s
Train Epoch: 1408 [81920/90000 (91%)]	Loss: -18.4043	Cost: 10.22s
Train Epoch: 1408 	Average Loss: -18.4889
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.8834

Learning rate: 0.00019037540958273115
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1409 [0/90000 (0%)]	Loss: -12.2821	Cost: 25.16s
Train Epoch: 1409 [20480/90000 (23%)]	Loss: -18.7253	Cost: 9.09s
Train Epoch: 1409 [40960/90000 (45%)]	Loss: -17.2835	Cost: 9.52s
Train Epoch: 1409 [61440/90000 (68%)]	Loss: -17.6617	Cost: 9.04s
Train Epoch: 1409 [81920/90000 (91%)]	Loss: -17.7769	Cost: 10.22s
Train Epoch: 1409 	Average Loss: -17.6045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4183

Learning rate: 0.00019036195747220095
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1410 [0/90000 (0%)]	Loss: -10.8544	Cost: 23.61s
Train Epoch: 1410 [20480/90000 (23%)]	Loss: -18.1601	Cost: 9.13s
Train Epoch: 1410 [40960/90000 (45%)]	Loss: -18.2075	Cost: 9.78s
Train Epoch: 1410 [61440/90000 (68%)]	Loss: -18.5467	Cost: 9.08s
Train Epoch: 1410 [81920/90000 (91%)]	Loss: -18.5700	Cost: 10.70s
Train Epoch: 1410 	Average Loss: -17.9590
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0881

Learning rate: 0.0001903484964433031
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1411 [0/90000 (0%)]	Loss: -13.3248	Cost: 24.05s
Train Epoch: 1411 [20480/90000 (23%)]	Loss: -19.1274	Cost: 9.07s
Train Epoch: 1411 [40960/90000 (45%)]	Loss: -18.6798	Cost: 9.03s
Train Epoch: 1411 [61440/90000 (68%)]	Loss: -18.8624	Cost: 9.03s
Train Epoch: 1411 [81920/90000 (91%)]	Loss: -18.5559	Cost: 9.37s
Train Epoch: 1411 	Average Loss: -18.5453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1977

Learning rate: 0.00019033502649736612
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1412 [0/90000 (0%)]	Loss: -12.4975	Cost: 23.30s
Train Epoch: 1412 [20480/90000 (23%)]	Loss: -18.9206	Cost: 9.11s
Train Epoch: 1412 [40960/90000 (45%)]	Loss: -18.8457	Cost: 9.04s
Train Epoch: 1412 [61440/90000 (68%)]	Loss: -18.7193	Cost: 8.99s
Train Epoch: 1412 [81920/90000 (91%)]	Loss: -18.6468	Cost: 8.99s
Train Epoch: 1412 	Average Loss: -18.4223
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2101

Learning rate: 0.00019032154763571946
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1413 [0/90000 (0%)]	Loss: -12.9804	Cost: 24.47s
Train Epoch: 1413 [20480/90000 (23%)]	Loss: -19.1154	Cost: 8.99s
Train Epoch: 1413 [40960/90000 (45%)]	Loss: -19.1677	Cost: 9.02s
Train Epoch: 1413 [61440/90000 (68%)]	Loss: -19.0818	Cost: 8.96s
Train Epoch: 1413 [81920/90000 (91%)]	Loss: -18.9087	Cost: 8.81s
Train Epoch: 1413 	Average Loss: -18.6591
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2494

Learning rate: 0.00019030805985969346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1414 [0/90000 (0%)]	Loss: -12.5112	Cost: 24.71s
Train Epoch: 1414 [20480/90000 (23%)]	Loss: -18.9834	Cost: 9.02s
Train Epoch: 1414 [40960/90000 (45%)]	Loss: -18.8122	Cost: 9.06s
Train Epoch: 1414 [61440/90000 (68%)]	Loss: -18.8099	Cost: 9.01s
Train Epoch: 1414 [81920/90000 (91%)]	Loss: -18.6095	Cost: 8.74s
Train Epoch: 1414 	Average Loss: -18.5816
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3202

Learning rate: 0.00019029456317061927
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1415 [0/90000 (0%)]	Loss: -12.9573	Cost: 25.93s
Train Epoch: 1415 [20480/90000 (23%)]	Loss: -19.2471	Cost: 9.23s
Train Epoch: 1415 [40960/90000 (45%)]	Loss: -19.1350	Cost: 9.37s
Train Epoch: 1415 [61440/90000 (68%)]	Loss: -18.7937	Cost: 9.25s
Train Epoch: 1415 [81920/90000 (91%)]	Loss: -18.7321	Cost: 8.84s
Train Epoch: 1415 	Average Loss: -18.5864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1515

Learning rate: 0.00019028105756982897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1416 [0/90000 (0%)]	Loss: -11.2947	Cost: 24.73s
Train Epoch: 1416 [20480/90000 (23%)]	Loss: -18.9658	Cost: 9.42s
Train Epoch: 1416 [40960/90000 (45%)]	Loss: -18.8425	Cost: 9.29s
Train Epoch: 1416 [61440/90000 (68%)]	Loss: -18.8271	Cost: 9.18s
Train Epoch: 1416 [81920/90000 (91%)]	Loss: -18.4960	Cost: 8.82s
Train Epoch: 1416 	Average Loss: -18.3894
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3138

Learning rate: 0.00019026754305865554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1417 [0/90000 (0%)]	Loss: -13.3197	Cost: 25.46s
Train Epoch: 1417 [20480/90000 (23%)]	Loss: -19.1238	Cost: 9.18s
Train Epoch: 1417 [40960/90000 (45%)]	Loss: -18.9671	Cost: 9.39s
Train Epoch: 1417 [61440/90000 (68%)]	Loss: -18.8045	Cost: 9.58s
Train Epoch: 1417 [81920/90000 (91%)]	Loss: -18.7571	Cost: 8.99s
Train Epoch: 1417 	Average Loss: -18.6388
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2916

Learning rate: 0.00019025401963843275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1418 [0/90000 (0%)]	Loss: -11.9422	Cost: 24.82s
Train Epoch: 1418 [20480/90000 (23%)]	Loss: -19.4404	Cost: 9.29s
Train Epoch: 1418 [40960/90000 (45%)]	Loss: -19.1456	Cost: 9.18s
Train Epoch: 1418 [61440/90000 (68%)]	Loss: -18.8409	Cost: 9.23s
Train Epoch: 1418 [81920/90000 (91%)]	Loss: -18.6643	Cost: 8.83s
Train Epoch: 1418 	Average Loss: -18.6638
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0992

Learning rate: 0.00019024048731049536
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1419 [0/90000 (0%)]	Loss: -12.3893	Cost: 25.38s
Train Epoch: 1419 [20480/90000 (23%)]	Loss: -19.1496	Cost: 9.66s
Train Epoch: 1419 [40960/90000 (45%)]	Loss: -18.8575	Cost: 9.38s
Train Epoch: 1419 [61440/90000 (68%)]	Loss: -18.9482	Cost: 9.20s
Train Epoch: 1419 [81920/90000 (91%)]	Loss: -18.8024	Cost: 8.74s
Train Epoch: 1419 	Average Loss: -18.5231
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2624

Learning rate: 0.00019022694607617892
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1420 [0/90000 (0%)]	Loss: -13.1027	Cost: 25.32s
Train Epoch: 1420 [20480/90000 (23%)]	Loss: -19.3796	Cost: 9.51s
Train Epoch: 1420 [40960/90000 (45%)]	Loss: -19.1317	Cost: 9.35s
Train Epoch: 1420 [61440/90000 (68%)]	Loss: -19.1453	Cost: 9.10s
Train Epoch: 1420 [81920/90000 (91%)]	Loss: -18.9728	Cost: 9.56s
Train Epoch: 1420 	Average Loss: -18.7760
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3078

Learning rate: 0.0001902133959368199
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1421 [0/90000 (0%)]	Loss: -12.5879	Cost: 24.44s
Train Epoch: 1421 [20480/90000 (23%)]	Loss: -19.2860	Cost: 9.15s
Train Epoch: 1421 [40960/90000 (45%)]	Loss: -18.9409	Cost: 9.72s
Train Epoch: 1421 [61440/90000 (68%)]	Loss: -19.0486	Cost: 9.05s
Train Epoch: 1421 [81920/90000 (91%)]	Loss: -19.0032	Cost: 9.99s
Train Epoch: 1421 	Average Loss: -18.7297
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4398

Learning rate: 0.00019019983689375568
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1422 [0/90000 (0%)]	Loss: -13.0082	Cost: 24.53s
Train Epoch: 1422 [20480/90000 (23%)]	Loss: -19.4678	Cost: 9.06s
Train Epoch: 1422 [40960/90000 (45%)]	Loss: -19.1078	Cost: 9.80s
Train Epoch: 1422 [61440/90000 (68%)]	Loss: -19.0645	Cost: 9.17s
Train Epoch: 1422 [81920/90000 (91%)]	Loss: -19.2007	Cost: 10.05s
Train Epoch: 1422 	Average Loss: -18.7976
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4832

Learning rate: 0.00019018626894832442
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1423 [0/90000 (0%)]	Loss: -12.5698	Cost: 24.96s
Train Epoch: 1423 [20480/90000 (23%)]	Loss: -19.3738	Cost: 9.35s
Train Epoch: 1423 [40960/90000 (45%)]	Loss: -18.8907	Cost: 9.45s
Train Epoch: 1423 [61440/90000 (68%)]	Loss: -18.7367	Cost: 9.07s
Train Epoch: 1423 [81920/90000 (91%)]	Loss: -18.8034	Cost: 10.41s
Train Epoch: 1423 	Average Loss: -18.5953
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0194

Learning rate: 0.00019017269210186527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1424 [0/90000 (0%)]	Loss: -12.7868	Cost: 24.89s
Train Epoch: 1424 [20480/90000 (23%)]	Loss: -19.3641	Cost: 9.02s
Train Epoch: 1424 [40960/90000 (45%)]	Loss: -19.2281	Cost: 9.95s
Train Epoch: 1424 [61440/90000 (68%)]	Loss: -18.6204	Cost: 9.05s
Train Epoch: 1424 [81920/90000 (91%)]	Loss: -18.5502	Cost: 10.28s
Train Epoch: 1424 	Average Loss: -18.5500
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1710

Learning rate: 0.00019015910635571823
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1425 [0/90000 (0%)]	Loss: -12.3094	Cost: 24.52s
Train Epoch: 1425 [20480/90000 (23%)]	Loss: -19.3337	Cost: 9.29s
Train Epoch: 1425 [40960/90000 (45%)]	Loss: -18.8008	Cost: 9.78s
Train Epoch: 1425 [61440/90000 (68%)]	Loss: -18.7049	Cost: 9.16s
Train Epoch: 1425 [81920/90000 (91%)]	Loss: -18.3958	Cost: 10.54s
Train Epoch: 1425 	Average Loss: -18.5058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.7765

Learning rate: 0.0001901455117112241
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1426 [0/90000 (0%)]	Loss: -12.3131	Cost: 24.83s
Train Epoch: 1426 [20480/90000 (23%)]	Loss: -18.3730	Cost: 9.36s
Train Epoch: 1426 [40960/90000 (45%)]	Loss: -18.4109	Cost: 9.29s
Train Epoch: 1426 [61440/90000 (68%)]	Loss: -18.4253	Cost: 9.27s
Train Epoch: 1426 [81920/90000 (91%)]	Loss: -18.6608	Cost: 9.15s
Train Epoch: 1426 	Average Loss: -18.1047
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.7660

Learning rate: 0.0001901319081697247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1427 [0/90000 (0%)]	Loss: -12.5506	Cost: 23.94s
Train Epoch: 1427 [20480/90000 (23%)]	Loss: -18.8879	Cost: 9.73s
Train Epoch: 1427 [40960/90000 (45%)]	Loss: -19.1590	Cost: 9.27s
Train Epoch: 1427 [61440/90000 (68%)]	Loss: -18.3942	Cost: 9.23s
Train Epoch: 1427 [81920/90000 (91%)]	Loss: -18.0594	Cost: 9.14s
Train Epoch: 1427 	Average Loss: -18.1174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.7701

Learning rate: 0.00019011829573256257
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1428 [0/90000 (0%)]	Loss: -12.0943	Cost: 25.26s
Train Epoch: 1428 [20480/90000 (23%)]	Loss: -18.6375	Cost: 9.34s
Train Epoch: 1428 [40960/90000 (45%)]	Loss: -18.8315	Cost: 9.24s
Train Epoch: 1428 [61440/90000 (68%)]	Loss: -18.8984	Cost: 9.09s
Train Epoch: 1428 [81920/90000 (91%)]	Loss: -19.0637	Cost: 9.15s
Train Epoch: 1428 	Average Loss: -18.4696
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2354

Learning rate: 0.00019010467440108125
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1429 [0/90000 (0%)]	Loss: -12.0209	Cost: 23.70s
Train Epoch: 1429 [20480/90000 (23%)]	Loss: -19.3015	Cost: 9.38s
Train Epoch: 1429 [40960/90000 (45%)]	Loss: -19.0692	Cost: 9.29s
Train Epoch: 1429 [61440/90000 (68%)]	Loss: -18.8886	Cost: 9.10s
Train Epoch: 1429 [81920/90000 (91%)]	Loss: -19.0211	Cost: 9.07s
Train Epoch: 1429 	Average Loss: -18.6870
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3242

Learning rate: 0.0001900910441766251
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1430 [0/90000 (0%)]	Loss: -12.5493	Cost: 24.83s
Train Epoch: 1430 [20480/90000 (23%)]	Loss: -19.3436	Cost: 9.35s
Train Epoch: 1430 [40960/90000 (45%)]	Loss: -19.0282	Cost: 9.29s
Train Epoch: 1430 [61440/90000 (68%)]	Loss: -18.9321	Cost: 9.29s
Train Epoch: 1430 [81920/90000 (91%)]	Loss: -18.8840	Cost: 9.51s
Train Epoch: 1430 	Average Loss: -18.7209
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1381

Learning rate: 0.0001900774050605393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1431 [0/90000 (0%)]	Loss: -11.6569	Cost: 24.60s
Train Epoch: 1431 [20480/90000 (23%)]	Loss: -19.2333	Cost: 9.41s
Train Epoch: 1431 [40960/90000 (45%)]	Loss: -19.3532	Cost: 9.23s
Train Epoch: 1431 [61440/90000 (68%)]	Loss: -19.1816	Cost: 9.12s
Train Epoch: 1431 [81920/90000 (91%)]	Loss: -19.0016	Cost: 9.00s
Train Epoch: 1431 	Average Loss: -18.7572
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3485

Learning rate: 0.0001900637570541701
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1432 [0/90000 (0%)]	Loss: -13.3999	Cost: 27.58s
Train Epoch: 1432 [20480/90000 (23%)]	Loss: -19.1114	Cost: 9.67s
Train Epoch: 1432 [40960/90000 (45%)]	Loss: -19.1689	Cost: 9.29s
Train Epoch: 1432 [61440/90000 (68%)]	Loss: -19.0824	Cost: 9.18s
Train Epoch: 1432 [81920/90000 (91%)]	Loss: -18.8840	Cost: 8.83s
Train Epoch: 1432 	Average Loss: -18.7794
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2211

Learning rate: 0.00019005010015886445
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1433 [0/90000 (0%)]	Loss: -12.3340	Cost: 24.35s
Train Epoch: 1433 [20480/90000 (23%)]	Loss: -19.4184	Cost: 9.35s
Train Epoch: 1433 [40960/90000 (45%)]	Loss: -19.1486	Cost: 9.24s
Train Epoch: 1433 [61440/90000 (68%)]	Loss: -19.0896	Cost: 9.17s
Train Epoch: 1433 [81920/90000 (91%)]	Loss: -19.0833	Cost: 9.18s
Train Epoch: 1433 	Average Loss: -18.7899
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6031

Learning rate: 0.0001900364343759702
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1434 [0/90000 (0%)]	Loss: -12.8193	Cost: 25.59s
Train Epoch: 1434 [20480/90000 (23%)]	Loss: -19.5674	Cost: 9.32s
Train Epoch: 1434 [40960/90000 (45%)]	Loss: -19.2050	Cost: 9.29s
Train Epoch: 1434 [61440/90000 (68%)]	Loss: -19.0970	Cost: 9.14s
Train Epoch: 1434 [81920/90000 (91%)]	Loss: -19.0741	Cost: 8.76s
Train Epoch: 1434 	Average Loss: -18.9151
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4926

Learning rate: 0.00019002275970683615
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1435 [0/90000 (0%)]	Loss: -13.2199	Cost: 25.34s
Train Epoch: 1435 [20480/90000 (23%)]	Loss: -19.4164	Cost: 9.43s
Train Epoch: 1435 [40960/90000 (45%)]	Loss: -19.0508	Cost: 9.26s
Train Epoch: 1435 [61440/90000 (68%)]	Loss: -19.0687	Cost: 9.24s
Train Epoch: 1435 [81920/90000 (91%)]	Loss: -18.8523	Cost: 8.86s
Train Epoch: 1435 	Average Loss: -18.7435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1478

Learning rate: 0.00019000907615281188
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1436 [0/90000 (0%)]	Loss: -12.4333	Cost: 25.43s
Train Epoch: 1436 [20480/90000 (23%)]	Loss: -19.0715	Cost: 9.29s
Train Epoch: 1436 [40960/90000 (45%)]	Loss: -18.7919	Cost: 9.79s
Train Epoch: 1436 [61440/90000 (68%)]	Loss: -18.8078	Cost: 9.39s
Train Epoch: 1436 [81920/90000 (91%)]	Loss: -18.7886	Cost: 8.94s
Train Epoch: 1436 	Average Loss: -18.5580
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4542

Learning rate: 0.000189995383715248
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1437 [0/90000 (0%)]	Loss: -12.9297	Cost: 25.04s
Train Epoch: 1437 [20480/90000 (23%)]	Loss: -19.4316	Cost: 9.43s
Train Epoch: 1437 [40960/90000 (45%)]	Loss: -19.3584	Cost: 9.24s
Train Epoch: 1437 [61440/90000 (68%)]	Loss: -19.1205	Cost: 9.15s
Train Epoch: 1437 [81920/90000 (91%)]	Loss: -10.0938	Cost: 8.86s
Train Epoch: 1437 	Average Loss: -16.5302
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6792

Learning rate: 0.0001899816823954958
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1438 [0/90000 (0%)]	Loss: -5.0990	Cost: 24.77s
Train Epoch: 1438 [20480/90000 (23%)]	Loss: -11.7313	Cost: 9.21s
Train Epoch: 1438 [40960/90000 (45%)]	Loss: -13.1556	Cost: 9.41s
Train Epoch: 1438 [61440/90000 (68%)]	Loss: -14.5277	Cost: 9.04s
Train Epoch: 1438 [81920/90000 (91%)]	Loss: -15.5544	Cost: 9.21s
Train Epoch: 1438 	Average Loss: -12.9677
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5554

Learning rate: 0.0001899679721949076
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1439 [0/90000 (0%)]	Loss: -9.8115	Cost: 24.98s
Train Epoch: 1439 [20480/90000 (23%)]	Loss: -16.5461	Cost: 9.45s
Train Epoch: 1439 [40960/90000 (45%)]	Loss: -16.9618	Cost: 9.31s
Train Epoch: 1439 [61440/90000 (68%)]	Loss: -17.3707	Cost: 9.08s
Train Epoch: 1439 [81920/90000 (91%)]	Loss: -17.8662	Cost: 9.06s
Train Epoch: 1439 	Average Loss: -16.5819
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5290

Learning rate: 0.00018995425311483654
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1440 [0/90000 (0%)]	Loss: -12.2704	Cost: 24.98s
Train Epoch: 1440 [20480/90000 (23%)]	Loss: -18.2993	Cost: 9.48s
Train Epoch: 1440 [40960/90000 (45%)]	Loss: -18.5869	Cost: 9.39s
Train Epoch: 1440 [61440/90000 (68%)]	Loss: -18.5956	Cost: 9.09s
Train Epoch: 1440 [81920/90000 (91%)]	Loss: -18.7163	Cost: 8.94s
Train Epoch: 1440 	Average Loss: -18.1255
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1612

Learning rate: 0.00018994052515663662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1441 [0/90000 (0%)]	Loss: -12.3945	Cost: 25.51s
Train Epoch: 1441 [20480/90000 (23%)]	Loss: -19.0395	Cost: 10.13s
Train Epoch: 1441 [40960/90000 (45%)]	Loss: -18.9095	Cost: 9.12s
Train Epoch: 1441 [61440/90000 (68%)]	Loss: -18.9827	Cost: 9.00s
Train Epoch: 1441 [81920/90000 (91%)]	Loss: -19.0034	Cost: 8.72s
Train Epoch: 1441 	Average Loss: -18.5511
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3536

Learning rate: 0.00018992678832166273
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1442 [0/90000 (0%)]	Loss: -12.3966	Cost: 26.01s
Train Epoch: 1442 [20480/90000 (23%)]	Loss: -19.2318	Cost: 9.05s
Train Epoch: 1442 [40960/90000 (45%)]	Loss: -19.2142	Cost: 9.79s
Train Epoch: 1442 [61440/90000 (68%)]	Loss: -19.0858	Cost: 9.03s
Train Epoch: 1442 [81920/90000 (91%)]	Loss: -19.1126	Cost: 9.67s
Train Epoch: 1442 	Average Loss: -18.7687
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5453

Learning rate: 0.00018991304261127068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1443 [0/90000 (0%)]	Loss: -13.1505	Cost: 24.42s
Train Epoch: 1443 [20480/90000 (23%)]	Loss: -19.5127	Cost: 9.55s
Train Epoch: 1443 [40960/90000 (45%)]	Loss: -19.2534	Cost: 9.27s
Train Epoch: 1443 [61440/90000 (68%)]	Loss: -19.3665	Cost: 9.05s
Train Epoch: 1443 [81920/90000 (91%)]	Loss: -19.1770	Cost: 10.00s
Train Epoch: 1443 	Average Loss: -18.9797
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4042

Learning rate: 0.0001898992880268171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1444 [0/90000 (0%)]	Loss: -13.5495	Cost: 22.99s
Train Epoch: 1444 [20480/90000 (23%)]	Loss: -19.2595	Cost: 9.59s
Train Epoch: 1444 [40960/90000 (45%)]	Loss: -18.9833	Cost: 9.16s
Train Epoch: 1444 [61440/90000 (68%)]	Loss: -18.9125	Cost: 9.13s
Train Epoch: 1444 [81920/90000 (91%)]	Loss: -19.0270	Cost: 10.21s
Train Epoch: 1444 	Average Loss: -18.7063
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4435

Learning rate: 0.00018988552456965948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1445 [0/90000 (0%)]	Loss: -12.2232	Cost: 25.51s
Train Epoch: 1445 [20480/90000 (23%)]	Loss: -19.1857	Cost: 9.13s
Train Epoch: 1445 [40960/90000 (45%)]	Loss: -19.3444	Cost: 9.70s
Train Epoch: 1445 [61440/90000 (68%)]	Loss: -19.0339	Cost: 9.01s
Train Epoch: 1445 [81920/90000 (91%)]	Loss: -19.2545	Cost: 10.35s
Train Epoch: 1445 	Average Loss: -18.8512
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5252

Learning rate: 0.00018987175224115626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1446 [0/90000 (0%)]	Loss: -13.2203	Cost: 23.43s
Train Epoch: 1446 [20480/90000 (23%)]	Loss: -19.5824	Cost: 9.15s
Train Epoch: 1446 [40960/90000 (45%)]	Loss: -19.3228	Cost: 9.10s
Train Epoch: 1446 [61440/90000 (68%)]	Loss: -19.3420	Cost: 9.08s
Train Epoch: 1446 [81920/90000 (91%)]	Loss: -19.2731	Cost: 9.03s
Train Epoch: 1446 	Average Loss: -19.0207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5728

Learning rate: 0.00018985797104266667
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1447 [0/90000 (0%)]	Loss: -13.5528	Cost: 24.23s
Train Epoch: 1447 [20480/90000 (23%)]	Loss: -19.5767	Cost: 8.99s
Train Epoch: 1447 [40960/90000 (45%)]	Loss: -19.0350	Cost: 9.07s
Train Epoch: 1447 [61440/90000 (68%)]	Loss: -18.9624	Cost: 9.06s
Train Epoch: 1447 [81920/90000 (91%)]	Loss: -15.3442	Cost: 9.08s
Train Epoch: 1447 	Average Loss: -17.9361
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2784

Learning rate: 0.0001898441809755509
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1448 [0/90000 (0%)]	Loss: -10.0163	Cost: 22.77s
Train Epoch: 1448 [20480/90000 (23%)]	Loss: -16.3509	Cost: 9.04s
Train Epoch: 1448 [40960/90000 (45%)]	Loss: -16.6616	Cost: 9.05s
Train Epoch: 1448 [61440/90000 (68%)]	Loss: -17.5832	Cost: 8.95s
Train Epoch: 1448 [81920/90000 (91%)]	Loss: -17.7209	Cost: 9.01s
Train Epoch: 1448 	Average Loss: -16.5253
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4520

Learning rate: 0.00018983038204116998
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1449 [0/90000 (0%)]	Loss: -11.5196	Cost: 23.67s
Train Epoch: 1449 [20480/90000 (23%)]	Loss: -18.4685	Cost: 9.07s
Train Epoch: 1449 [40960/90000 (45%)]	Loss: -18.6166	Cost: 9.02s
Train Epoch: 1449 [61440/90000 (68%)]	Loss: -18.6805	Cost: 8.96s
Train Epoch: 1449 [81920/90000 (91%)]	Loss: -18.7984	Cost: 8.81s
Train Epoch: 1449 	Average Loss: -18.1591
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2905

Learning rate: 0.00018981657424088576
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1450 [0/90000 (0%)]	Loss: -12.6780	Cost: 26.15s
Train Epoch: 1450 [20480/90000 (23%)]	Loss: -19.1344	Cost: 9.02s
Train Epoch: 1450 [40960/90000 (45%)]	Loss: -19.1418	Cost: 9.04s
Train Epoch: 1450 [61440/90000 (68%)]	Loss: -19.1858	Cost: 8.94s
Train Epoch: 1450 [81920/90000 (91%)]	Loss: -19.0263	Cost: 8.71s
Train Epoch: 1450 	Average Loss: -18.7502
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3854

Saving model as model.pt_e1450 & waveforms_supplementary.hdf5_e1450
Learning rate: 0.00018980275757606106
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1451 [0/90000 (0%)]	Loss: -12.5601	Cost: 23.21s
Train Epoch: 1451 [20480/90000 (23%)]	Loss: -19.1503	Cost: 9.08s
Train Epoch: 1451 [40960/90000 (45%)]	Loss: -18.9673	Cost: 9.05s
Train Epoch: 1451 [61440/90000 (68%)]	Loss: -19.1864	Cost: 8.94s
Train Epoch: 1451 [81920/90000 (91%)]	Loss: -19.1094	Cost: 8.79s
Train Epoch: 1451 	Average Loss: -18.7813
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5740

Learning rate: 0.00018978893204805956
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1452 [0/90000 (0%)]	Loss: -12.9034	Cost: 24.34s
Train Epoch: 1452 [20480/90000 (23%)]	Loss: -19.4454	Cost: 9.17s
Train Epoch: 1452 [40960/90000 (45%)]	Loss: -19.6229	Cost: 9.33s
Train Epoch: 1452 [61440/90000 (68%)]	Loss: -19.2703	Cost: 9.02s
Train Epoch: 1452 [81920/90000 (91%)]	Loss: -19.2234	Cost: 9.40s
Train Epoch: 1452 	Average Loss: -18.9852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5897

Learning rate: 0.0001897750976582457
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1453 [0/90000 (0%)]	Loss: -13.0980	Cost: 24.94s
Train Epoch: 1453 [20480/90000 (23%)]	Loss: -19.4400	Cost: 9.30s
Train Epoch: 1453 [40960/90000 (45%)]	Loss: -19.2555	Cost: 9.30s
Train Epoch: 1453 [61440/90000 (68%)]	Loss: -19.2151	Cost: 9.10s
Train Epoch: 1453 [81920/90000 (91%)]	Loss: -18.6762	Cost: 9.01s
Train Epoch: 1453 	Average Loss: -18.8506
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4160

Learning rate: 0.00018976125440798493
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1454 [0/90000 (0%)]	Loss: -13.2233	Cost: 27.63s
Train Epoch: 1454 [20480/90000 (23%)]	Loss: -19.2603	Cost: 9.36s
Train Epoch: 1454 [40960/90000 (45%)]	Loss: -19.0869	Cost: 9.26s
Train Epoch: 1454 [61440/90000 (68%)]	Loss: -19.0166	Cost: 9.14s
Train Epoch: 1454 [81920/90000 (91%)]	Loss: -18.8486	Cost: 8.93s
Train Epoch: 1454 	Average Loss: -18.7433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2719

Learning rate: 0.00018974740229864355
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1455 [0/90000 (0%)]	Loss: -12.2454	Cost: 25.91s
Train Epoch: 1455 [20480/90000 (23%)]	Loss: -19.3113	Cost: 9.63s
Train Epoch: 1455 [40960/90000 (45%)]	Loss: -19.1624	Cost: 9.33s
Train Epoch: 1455 [61440/90000 (68%)]	Loss: -19.2806	Cost: 9.13s
Train Epoch: 1455 [81920/90000 (91%)]	Loss: -18.8738	Cost: 9.04s
Train Epoch: 1455 	Average Loss: -18.7509
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5934

Learning rate: 0.00018973354133158867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1456 [0/90000 (0%)]	Loss: -12.8201	Cost: 25.20s
Train Epoch: 1456 [20480/90000 (23%)]	Loss: -19.3702	Cost: 9.46s
Train Epoch: 1456 [40960/90000 (45%)]	Loss: -19.1583	Cost: 9.33s
Train Epoch: 1456 [61440/90000 (68%)]	Loss: -19.4268	Cost: 9.23s
Train Epoch: 1456 [81920/90000 (91%)]	Loss: -19.0035	Cost: 8.87s
Train Epoch: 1456 	Average Loss: -18.9250
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6340

Learning rate: 0.00018971967150818828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1457 [0/90000 (0%)]	Loss: -13.1277	Cost: 25.27s
Train Epoch: 1457 [20480/90000 (23%)]	Loss: -19.6220	Cost: 9.32s
Train Epoch: 1457 [40960/90000 (45%)]	Loss: -19.3307	Cost: 9.71s
Train Epoch: 1457 [61440/90000 (68%)]	Loss: -17.4765	Cost: 9.11s
Train Epoch: 1457 [81920/90000 (91%)]	Loss: -16.2938	Cost: 8.82s
Train Epoch: 1457 	Average Loss: -18.1005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2639

Learning rate: 0.00018970579282981132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1458 [0/90000 (0%)]	Loss: -10.7751	Cost: 26.02s
Train Epoch: 1458 [20480/90000 (23%)]	Loss: -17.2007	Cost: 9.38s
Train Epoch: 1458 [40960/90000 (45%)]	Loss: -17.4968	Cost: 10.65s
Train Epoch: 1458 [61440/90000 (68%)]	Loss: -18.1731	Cost: 9.04s
Train Epoch: 1458 [81920/90000 (91%)]	Loss: -18.1585	Cost: 9.14s
Train Epoch: 1458 	Average Loss: -17.2186
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.7715

Learning rate: 0.00018969190529782756
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1459 [0/90000 (0%)]	Loss: -12.2373	Cost: 25.45s
Train Epoch: 1459 [20480/90000 (23%)]	Loss: -18.7494	Cost: 9.45s
Train Epoch: 1459 [40960/90000 (45%)]	Loss: -18.9138	Cost: 9.46s
Train Epoch: 1459 [61440/90000 (68%)]	Loss: -18.8657	Cost: 9.00s
Train Epoch: 1459 [81920/90000 (91%)]	Loss: -19.1154	Cost: 8.90s
Train Epoch: 1459 	Average Loss: -18.5213
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6352

Learning rate: 0.00018967800891360765
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1460 [0/90000 (0%)]	Loss: -13.0531	Cost: 24.83s
Train Epoch: 1460 [20480/90000 (23%)]	Loss: -19.5403	Cost: 9.61s
Train Epoch: 1460 [40960/90000 (45%)]	Loss: -19.3260	Cost: 9.47s
Train Epoch: 1460 [61440/90000 (68%)]	Loss: -19.3868	Cost: 9.05s
Train Epoch: 1460 [81920/90000 (91%)]	Loss: -19.2994	Cost: 8.79s
Train Epoch: 1460 	Average Loss: -19.0138
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9039

Learning rate: 0.0001896641036785231
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1461 [0/90000 (0%)]	Loss: -13.5177	Cost: 25.42s
Train Epoch: 1461 [20480/90000 (23%)]	Loss: -19.6258	Cost: 9.54s
Train Epoch: 1461 [40960/90000 (45%)]	Loss: -19.7140	Cost: 9.36s
Train Epoch: 1461 [61440/90000 (68%)]	Loss: -19.5503	Cost: 9.06s
Train Epoch: 1461 [81920/90000 (91%)]	Loss: -19.5438	Cost: 8.95s
Train Epoch: 1461 	Average Loss: -19.2955
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9271

Learning rate: 0.00018965018959394628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1462 [0/90000 (0%)]	Loss: -12.5072	Cost: 23.96s
Train Epoch: 1462 [20480/90000 (23%)]	Loss: -19.6376	Cost: 9.61s
Train Epoch: 1462 [40960/90000 (45%)]	Loss: -19.5656	Cost: 10.14s
Train Epoch: 1462 [61440/90000 (68%)]	Loss: -19.4016	Cost: 9.03s
Train Epoch: 1462 [81920/90000 (91%)]	Loss: -19.2049	Cost: 10.15s
Train Epoch: 1462 	Average Loss: -18.9571
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7224

Learning rate: 0.0001896362666612505
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1463 [0/90000 (0%)]	Loss: -13.0776	Cost: 23.28s
Train Epoch: 1463 [20480/90000 (23%)]	Loss: -19.5755	Cost: 9.52s
Train Epoch: 1463 [40960/90000 (45%)]	Loss: -19.3189	Cost: 9.30s
Train Epoch: 1463 [61440/90000 (68%)]	Loss: -19.2644	Cost: 9.09s
Train Epoch: 1463 [81920/90000 (91%)]	Loss: -19.2181	Cost: 9.91s
Train Epoch: 1463 	Average Loss: -19.0347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7693

Learning rate: 0.00018962233488180989
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1464 [0/90000 (0%)]	Loss: -13.0301	Cost: 22.86s
Train Epoch: 1464 [20480/90000 (23%)]	Loss: -19.6253	Cost: 9.11s
Train Epoch: 1464 [40960/90000 (45%)]	Loss: -19.5561	Cost: 9.01s
Train Epoch: 1464 [61440/90000 (68%)]	Loss: -19.4464	Cost: 9.03s
Train Epoch: 1464 [81920/90000 (91%)]	Loss: -19.3001	Cost: 9.86s
Train Epoch: 1464 	Average Loss: -19.1285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7611

Learning rate: 0.0001896083942569994
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1465 [0/90000 (0%)]	Loss: -13.0469	Cost: 24.28s
Train Epoch: 1465 [20480/90000 (23%)]	Loss: -19.7701	Cost: 9.22s
Train Epoch: 1465 [40960/90000 (45%)]	Loss: -19.4315	Cost: 9.51s
Train Epoch: 1465 [61440/90000 (68%)]	Loss: -19.3773	Cost: 9.11s
Train Epoch: 1465 [81920/90000 (91%)]	Loss: -19.1049	Cost: 9.02s
Train Epoch: 1465 	Average Loss: -19.0253
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7483

Learning rate: 0.00018959444478819498
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1466 [0/90000 (0%)]	Loss: -13.7651	Cost: 23.20s
Train Epoch: 1466 [20480/90000 (23%)]	Loss: -19.6436	Cost: 9.04s
Train Epoch: 1466 [40960/90000 (45%)]	Loss: -19.3391	Cost: 9.07s
Train Epoch: 1466 [61440/90000 (68%)]	Loss: -19.5118	Cost: 9.10s
Train Epoch: 1466 [81920/90000 (91%)]	Loss: -19.0743	Cost: 9.89s
Train Epoch: 1466 	Average Loss: -19.1255
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5993

Learning rate: 0.00018958048647677335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1467 [0/90000 (0%)]	Loss: -12.5948	Cost: 25.04s
Train Epoch: 1467 [20480/90000 (23%)]	Loss: -19.7132	Cost: 9.04s
Train Epoch: 1467 [40960/90000 (45%)]	Loss: -19.3489	Cost: 9.68s
Train Epoch: 1467 [61440/90000 (68%)]	Loss: -19.4351	Cost: 9.04s
Train Epoch: 1467 [81920/90000 (91%)]	Loss: -19.0264	Cost: 9.00s
Train Epoch: 1467 	Average Loss: -18.9926
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7652

Learning rate: 0.00018956651932411218
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1468 [0/90000 (0%)]	Loss: -13.6017	Cost: 25.61s
Train Epoch: 1468 [20480/90000 (23%)]	Loss: -19.6659	Cost: 9.04s
Train Epoch: 1468 [40960/90000 (45%)]	Loss: -19.4319	Cost: 9.18s
Train Epoch: 1468 [61440/90000 (68%)]	Loss: -19.5273	Cost: 8.89s
Train Epoch: 1468 [81920/90000 (91%)]	Loss: -19.2920	Cost: 8.89s
Train Epoch: 1468 	Average Loss: -19.0364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7647

Learning rate: 0.00018955254333158996
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1469 [0/90000 (0%)]	Loss: -13.1468	Cost: 24.34s
Train Epoch: 1469 [20480/90000 (23%)]	Loss: -19.7791	Cost: 9.03s
Train Epoch: 1469 [40960/90000 (45%)]	Loss: -19.7510	Cost: 9.24s
Train Epoch: 1469 [61440/90000 (68%)]	Loss: -18.9239	Cost: 8.95s
Train Epoch: 1469 [81920/90000 (91%)]	Loss: -18.6570	Cost: 8.71s
Train Epoch: 1469 	Average Loss: -18.9417
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1700

Learning rate: 0.000189538558500586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1470 [0/90000 (0%)]	Loss: -12.5236	Cost: 25.38s
Train Epoch: 1470 [20480/90000 (23%)]	Loss: -19.1196	Cost: 9.32s
Train Epoch: 1470 [40960/90000 (45%)]	Loss: -18.9890	Cost: 9.24s
Train Epoch: 1470 [61440/90000 (68%)]	Loss: -19.0797	Cost: 9.16s
Train Epoch: 1470 [81920/90000 (91%)]	Loss: -19.1545	Cost: 8.84s
Train Epoch: 1470 	Average Loss: -18.6329
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4546

Learning rate: 0.00018952456483248067
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1471 [0/90000 (0%)]	Loss: -13.3491	Cost: 25.18s
Train Epoch: 1471 [20480/90000 (23%)]	Loss: -19.0490	Cost: 9.12s
Train Epoch: 1471 [40960/90000 (45%)]	Loss: -19.1818	Cost: 9.68s
Train Epoch: 1471 [61440/90000 (68%)]	Loss: -19.3185	Cost: 9.13s
Train Epoch: 1471 [81920/90000 (91%)]	Loss: -19.1475	Cost: 9.17s
Train Epoch: 1471 	Average Loss: -18.7380
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7922

Learning rate: 0.000189510562328655
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1472 [0/90000 (0%)]	Loss: -13.5225	Cost: 24.66s
Train Epoch: 1472 [20480/90000 (23%)]	Loss: -19.3509	Cost: 9.49s
Train Epoch: 1472 [40960/90000 (45%)]	Loss: -19.0991	Cost: 9.30s
Train Epoch: 1472 [61440/90000 (68%)]	Loss: -19.3395	Cost: 9.02s
Train Epoch: 1472 [81920/90000 (91%)]	Loss: -19.1922	Cost: 9.04s
Train Epoch: 1472 	Average Loss: -18.9076
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5175

Learning rate: 0.000189496550990491
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1473 [0/90000 (0%)]	Loss: -11.9604	Cost: 25.63s
Train Epoch: 1473 [20480/90000 (23%)]	Loss: -19.7240	Cost: 9.68s
Train Epoch: 1473 [40960/90000 (45%)]	Loss: -19.5683	Cost: 9.74s
Train Epoch: 1473 [61440/90000 (68%)]	Loss: -19.7853	Cost: 9.13s
Train Epoch: 1473 [81920/90000 (91%)]	Loss: -19.5286	Cost: 8.87s
Train Epoch: 1473 	Average Loss: -19.1663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8734

Learning rate: 0.00018948253081937154
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1474 [0/90000 (0%)]	Loss: -13.6543	Cost: 25.21s
Train Epoch: 1474 [20480/90000 (23%)]	Loss: -19.8793	Cost: 9.51s
Train Epoch: 1474 [40960/90000 (45%)]	Loss: -19.2161	Cost: 9.08s
Train Epoch: 1474 [61440/90000 (68%)]	Loss: -19.1763	Cost: 9.06s
Train Epoch: 1474 [81920/90000 (91%)]	Loss: -19.2427	Cost: 8.91s
Train Epoch: 1474 	Average Loss: -18.9936
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6124

Learning rate: 0.00018946850181668034
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1475 [0/90000 (0%)]	Loss: -12.0536	Cost: 24.33s
Train Epoch: 1475 [20480/90000 (23%)]	Loss: -19.4624	Cost: 9.54s
Train Epoch: 1475 [40960/90000 (45%)]	Loss: -19.5877	Cost: 9.27s
Train Epoch: 1475 [61440/90000 (68%)]	Loss: -19.4527	Cost: 9.04s
Train Epoch: 1475 [81920/90000 (91%)]	Loss: -19.2514	Cost: 9.97s
Train Epoch: 1475 	Average Loss: -19.0268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7818

Learning rate: 0.00018945446398380201
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1476 [0/90000 (0%)]	Loss: -13.1665	Cost: 23.95s
Train Epoch: 1476 [20480/90000 (23%)]	Loss: -19.1959	Cost: 9.57s
Train Epoch: 1476 [40960/90000 (45%)]	Loss: -19.1269	Cost: 9.14s
Train Epoch: 1476 [61440/90000 (68%)]	Loss: -19.2263	Cost: 9.09s
Train Epoch: 1476 [81920/90000 (91%)]	Loss: -19.1547	Cost: 10.12s
Train Epoch: 1476 	Average Loss: -18.8416
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3218

Learning rate: 0.00018944041732212207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1477 [0/90000 (0%)]	Loss: -12.2036	Cost: 23.79s
Train Epoch: 1477 [20480/90000 (23%)]	Loss: -18.8709	Cost: 9.32s
Train Epoch: 1477 [40960/90000 (45%)]	Loss: -18.9181	Cost: 9.39s
Train Epoch: 1477 [61440/90000 (68%)]	Loss: -18.8753	Cost: 9.04s
Train Epoch: 1477 [81920/90000 (91%)]	Loss: -18.8879	Cost: 10.09s
Train Epoch: 1477 	Average Loss: -18.4387
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5655

Learning rate: 0.00018942636183302684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1478 [0/90000 (0%)]	Loss: -13.0348	Cost: 23.72s
Train Epoch: 1478 [20480/90000 (23%)]	Loss: -19.5515	Cost: 9.36s
Train Epoch: 1478 [40960/90000 (45%)]	Loss: -19.2705	Cost: 9.25s
Train Epoch: 1478 [61440/90000 (68%)]	Loss: -19.0871	Cost: 9.21s
Train Epoch: 1478 [81920/90000 (91%)]	Loss: -19.1117	Cost: 9.18s
Train Epoch: 1478 	Average Loss: -18.8474
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5710

Learning rate: 0.0001894122975179035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1479 [0/90000 (0%)]	Loss: -13.5588	Cost: 23.13s
Train Epoch: 1479 [20480/90000 (23%)]	Loss: -19.4270	Cost: 9.17s
Train Epoch: 1479 [40960/90000 (45%)]	Loss: -19.1429	Cost: 9.33s
Train Epoch: 1479 [61440/90000 (68%)]	Loss: -19.2195	Cost: 9.06s
Train Epoch: 1479 [81920/90000 (91%)]	Loss: -19.4425	Cost: 10.15s
Train Epoch: 1479 	Average Loss: -19.0194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6235

Learning rate: 0.0001893982243781402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1480 [0/90000 (0%)]	Loss: -13.6519	Cost: 25.74s
Train Epoch: 1480 [20480/90000 (23%)]	Loss: -19.6108	Cost: 9.05s
Train Epoch: 1480 [40960/90000 (45%)]	Loss: -19.5838	Cost: 9.30s
Train Epoch: 1480 [61440/90000 (68%)]	Loss: -19.6309	Cost: 9.16s
Train Epoch: 1480 [81920/90000 (91%)]	Loss: -19.2842	Cost: 9.36s
Train Epoch: 1480 	Average Loss: -19.2110
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6796

Learning rate: 0.00018938414241512588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1481 [0/90000 (0%)]	Loss: -12.3592	Cost: 24.72s
Train Epoch: 1481 [20480/90000 (23%)]	Loss: -19.5349	Cost: 9.47s
Train Epoch: 1481 [40960/90000 (45%)]	Loss: -19.4600	Cost: 9.38s
Train Epoch: 1481 [61440/90000 (68%)]	Loss: -19.5967	Cost: 9.38s
Train Epoch: 1481 [81920/90000 (91%)]	Loss: -19.2582	Cost: 9.19s
Train Epoch: 1481 	Average Loss: -19.0355
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7325

Learning rate: 0.00018937005163025035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1482 [0/90000 (0%)]	Loss: -12.9086	Cost: 24.61s
Train Epoch: 1482 [20480/90000 (23%)]	Loss: -18.9250	Cost: 9.33s
Train Epoch: 1482 [40960/90000 (45%)]	Loss: -18.6554	Cost: 9.28s
Train Epoch: 1482 [61440/90000 (68%)]	Loss: -18.8885	Cost: 9.18s
Train Epoch: 1482 [81920/90000 (91%)]	Loss: -18.8470	Cost: 9.17s
Train Epoch: 1482 	Average Loss: -18.4556
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2813

Learning rate: 0.0001893559520249044
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1483 [0/90000 (0%)]	Loss: -13.0368	Cost: 24.17s
Train Epoch: 1483 [20480/90000 (23%)]	Loss: -19.3869	Cost: 9.22s
Train Epoch: 1483 [40960/90000 (45%)]	Loss: -19.3102	Cost: 9.28s
Train Epoch: 1483 [61440/90000 (68%)]	Loss: -19.2064	Cost: 9.03s
Train Epoch: 1483 [81920/90000 (91%)]	Loss: -19.1492	Cost: 8.91s
Train Epoch: 1483 	Average Loss: -18.9441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5826

Learning rate: 0.00018934184360047953
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1484 [0/90000 (0%)]	Loss: -13.7252	Cost: 24.52s
Train Epoch: 1484 [20480/90000 (23%)]	Loss: -19.6348	Cost: 9.16s
Train Epoch: 1484 [40960/90000 (45%)]	Loss: -19.8438	Cost: 9.16s
Train Epoch: 1484 [61440/90000 (68%)]	Loss: -19.5102	Cost: 8.99s
Train Epoch: 1484 [81920/90000 (91%)]	Loss: -19.5066	Cost: 8.76s
Train Epoch: 1484 	Average Loss: -19.1863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7845

Learning rate: 0.0001893277263583682
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1485 [0/90000 (0%)]	Loss: -12.9201	Cost: 25.28s
Train Epoch: 1485 [20480/90000 (23%)]	Loss: -19.6642	Cost: 9.29s
Train Epoch: 1485 [40960/90000 (45%)]	Loss: -19.3520	Cost: 9.34s
Train Epoch: 1485 [61440/90000 (68%)]	Loss: -19.3200	Cost: 9.02s
Train Epoch: 1485 [81920/90000 (91%)]	Loss: -19.1090	Cost: 8.79s
Train Epoch: 1485 	Average Loss: -19.0626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6867

Learning rate: 0.00018931360029996374
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1486 [0/90000 (0%)]	Loss: -13.0285	Cost: 26.97s
Train Epoch: 1486 [20480/90000 (23%)]	Loss: -19.5626	Cost: 9.37s
Train Epoch: 1486 [40960/90000 (45%)]	Loss: -19.4225	Cost: 9.27s
Train Epoch: 1486 [61440/90000 (68%)]	Loss: -19.3200	Cost: 9.15s
Train Epoch: 1486 [81920/90000 (91%)]	Loss: -19.1905	Cost: 8.98s
Train Epoch: 1486 	Average Loss: -19.0155
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7020

Learning rate: 0.00018929946542666032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1487 [0/90000 (0%)]	Loss: -13.1382	Cost: 26.95s
Train Epoch: 1487 [20480/90000 (23%)]	Loss: -19.5981	Cost: 9.30s
Train Epoch: 1487 [40960/90000 (45%)]	Loss: -19.4075	Cost: 9.49s
Train Epoch: 1487 [61440/90000 (68%)]	Loss: -19.2246	Cost: 9.30s
Train Epoch: 1487 [81920/90000 (91%)]	Loss: -19.2723	Cost: 8.89s
Train Epoch: 1487 	Average Loss: -18.9971
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8406

Learning rate: 0.00018928532173985302
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1488 [0/90000 (0%)]	Loss: -12.9424	Cost: 26.02s
Train Epoch: 1488 [20480/90000 (23%)]	Loss: -19.6474	Cost: 9.58s
Train Epoch: 1488 [40960/90000 (45%)]	Loss: -19.5483	Cost: 9.25s
Train Epoch: 1488 [61440/90000 (68%)]	Loss: -19.4760	Cost: 9.19s
Train Epoch: 1488 [81920/90000 (91%)]	Loss: -19.4842	Cost: 8.93s
Train Epoch: 1488 	Average Loss: -19.2067
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0855

Learning rate: 0.00018927116924093772
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1489 [0/90000 (0%)]	Loss: -13.4230	Cost: 26.19s
Train Epoch: 1489 [20480/90000 (23%)]	Loss: -19.7328	Cost: 9.41s
Train Epoch: 1489 [40960/90000 (45%)]	Loss: -19.1875	Cost: 10.01s
Train Epoch: 1489 [61440/90000 (68%)]	Loss: -19.2646	Cost: 9.17s
Train Epoch: 1489 [81920/90000 (91%)]	Loss: -19.1012	Cost: 8.93s
Train Epoch: 1489 	Average Loss: -19.0878
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4792

Learning rate: 0.00018925700793131125
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1490 [0/90000 (0%)]	Loss: -12.3460	Cost: 26.05s
Train Epoch: 1490 [20480/90000 (23%)]	Loss: -19.2197	Cost: 9.42s
Train Epoch: 1490 [40960/90000 (45%)]	Loss: -19.3132	Cost: 9.27s
Train Epoch: 1490 [61440/90000 (68%)]	Loss: -19.2032	Cost: 9.44s
Train Epoch: 1490 [81920/90000 (91%)]	Loss: -19.2414	Cost: 9.30s
Train Epoch: 1490 	Average Loss: -18.9018
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7650

Learning rate: 0.0001892428378123713
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1491 [0/90000 (0%)]	Loss: -13.6852	Cost: 26.39s
Train Epoch: 1491 [20480/90000 (23%)]	Loss: -19.7692	Cost: 9.44s
Train Epoch: 1491 [40960/90000 (45%)]	Loss: -19.5185	Cost: 10.11s
Train Epoch: 1491 [61440/90000 (68%)]	Loss: -19.1742	Cost: 9.03s
Train Epoch: 1491 [81920/90000 (91%)]	Loss: -18.9273	Cost: 8.83s
Train Epoch: 1491 	Average Loss: -18.9658
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3085

Learning rate: 0.00018922865888551635
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1492 [0/90000 (0%)]	Loss: -12.7359	Cost: 25.64s
Train Epoch: 1492 [20480/90000 (23%)]	Loss: -19.1631	Cost: 9.64s
Train Epoch: 1492 [40960/90000 (45%)]	Loss: -19.3194	Cost: 9.38s
Train Epoch: 1492 [61440/90000 (68%)]	Loss: -19.2029	Cost: 9.18s
Train Epoch: 1492 [81920/90000 (91%)]	Loss: -19.0767	Cost: 8.94s
Train Epoch: 1492 	Average Loss: -18.7869
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6781

Learning rate: 0.0001892144711521458
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1493 [0/90000 (0%)]	Loss: -12.5081	Cost: 25.84s
Train Epoch: 1493 [20480/90000 (23%)]	Loss: -19.4806	Cost: 9.53s
Train Epoch: 1493 [40960/90000 (45%)]	Loss: -18.8968	Cost: 9.30s
Train Epoch: 1493 [61440/90000 (68%)]	Loss: -19.2508	Cost: 9.02s
Train Epoch: 1493 [81920/90000 (91%)]	Loss: -19.1757	Cost: 8.74s
Train Epoch: 1493 	Average Loss: -18.8298
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5695

Learning rate: 0.00018920027461365998
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1494 [0/90000 (0%)]	Loss: -11.9858	Cost: 26.31s
Train Epoch: 1494 [20480/90000 (23%)]	Loss: -19.1424	Cost: 9.47s
Train Epoch: 1494 [40960/90000 (45%)]	Loss: -19.0139	Cost: 9.41s
Train Epoch: 1494 [61440/90000 (68%)]	Loss: -19.1638	Cost: 9.09s
Train Epoch: 1494 [81920/90000 (91%)]	Loss: -19.3263	Cost: 9.43s
Train Epoch: 1494 	Average Loss: -18.7723
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7343

Learning rate: 0.00018918606927145997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1495 [0/90000 (0%)]	Loss: -13.0737	Cost: 25.09s
Train Epoch: 1495 [20480/90000 (23%)]	Loss: -18.1557	Cost: 9.60s
Train Epoch: 1495 [40960/90000 (45%)]	Loss: -18.0143	Cost: 10.17s
Train Epoch: 1495 [61440/90000 (68%)]	Loss: -18.1913	Cost: 9.07s
Train Epoch: 1495 [81920/90000 (91%)]	Loss: -18.3745	Cost: 9.76s
Train Epoch: 1495 	Average Loss: -17.8483
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.8553

Learning rate: 0.00018917185512694784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1496 [0/90000 (0%)]	Loss: -10.9098	Cost: 25.40s
Train Epoch: 1496 [20480/90000 (23%)]	Loss: -18.7116	Cost: 9.27s
Train Epoch: 1496 [40960/90000 (45%)]	Loss: -18.5706	Cost: 9.69s
Train Epoch: 1496 [61440/90000 (68%)]	Loss: -18.7508	Cost: 9.13s
Train Epoch: 1496 [81920/90000 (91%)]	Loss: -18.7379	Cost: 10.17s
Train Epoch: 1496 	Average Loss: -18.2958
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3463

Learning rate: 0.00018915763218152647
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1497 [0/90000 (0%)]	Loss: -13.2094	Cost: 26.05s
Train Epoch: 1497 [20480/90000 (23%)]	Loss: -19.3748	Cost: 9.31s
Train Epoch: 1497 [40960/90000 (45%)]	Loss: -19.2893	Cost: 10.09s
Train Epoch: 1497 [61440/90000 (68%)]	Loss: -19.3318	Cost: 9.08s
Train Epoch: 1497 [81920/90000 (91%)]	Loss: -18.8282	Cost: 10.17s
Train Epoch: 1497 	Average Loss: -18.8093
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1654

Learning rate: 0.00018914340043659956
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1498 [0/90000 (0%)]	Loss: -13.0437	Cost: 23.82s
Train Epoch: 1498 [20480/90000 (23%)]	Loss: -19.0588	Cost: 9.46s
Train Epoch: 1498 [40960/90000 (45%)]	Loss: -19.2508	Cost: 9.25s
Train Epoch: 1498 [61440/90000 (68%)]	Loss: -19.0505	Cost: 9.20s
Train Epoch: 1498 [81920/90000 (91%)]	Loss: -19.0489	Cost: 9.30s
Train Epoch: 1498 	Average Loss: -18.7183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6634

Learning rate: 0.00018912915989357176
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1499 [0/90000 (0%)]	Loss: -13.0617	Cost: 25.16s
Train Epoch: 1499 [20480/90000 (23%)]	Loss: -19.4479	Cost: 9.34s
Train Epoch: 1499 [40960/90000 (45%)]	Loss: -19.3224	Cost: 9.99s
Train Epoch: 1499 [61440/90000 (68%)]	Loss: -19.3394	Cost: 9.20s
Train Epoch: 1499 [81920/90000 (91%)]	Loss: -19.2323	Cost: 10.37s
Train Epoch: 1499 	Average Loss: -18.8910
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7174

Learning rate: 0.00018911491055384854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1500 [0/90000 (0%)]	Loss: -13.2561	Cost: 24.53s
Train Epoch: 1500 [20480/90000 (23%)]	Loss: -19.6302	Cost: 9.35s
Train Epoch: 1500 [40960/90000 (45%)]	Loss: -19.4741	Cost: 9.24s
Train Epoch: 1500 [61440/90000 (68%)]	Loss: -19.2636	Cost: 9.40s
Train Epoch: 1500 [81920/90000 (91%)]	Loss: -19.0338	Cost: 9.31s
Train Epoch: 1500 	Average Loss: -19.0301
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5781

Saving model as model.pt_e1500 & waveforms_supplementary.hdf5_e1500
Learning rate: 0.00018910065241883626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1501 [0/90000 (0%)]	Loss: -13.6187	Cost: 44.48s
Train Epoch: 1501 [20480/90000 (23%)]	Loss: -19.4712	Cost: 10.98s
Train Epoch: 1501 [40960/90000 (45%)]	Loss: -19.4532	Cost: 17.86s
Train Epoch: 1501 [61440/90000 (68%)]	Loss: -18.9853	Cost: 11.63s
Train Epoch: 1501 [81920/90000 (91%)]	Loss: -19.1268	Cost: 19.55s
Train Epoch: 1501 	Average Loss: -18.8866
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4920

Learning rate: 0.00018908638548994214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1502 [0/90000 (0%)]	Loss: -12.8291	Cost: 74.90s
Train Epoch: 1502 [20480/90000 (23%)]	Loss: -19.3809	Cost: 14.67s
Train Epoch: 1502 [40960/90000 (45%)]	Loss: -18.9406	Cost: 32.91s
Train Epoch: 1502 [61440/90000 (68%)]	Loss: -18.9446	Cost: 15.75s
Train Epoch: 1502 [81920/90000 (91%)]	Loss: -18.8073	Cost: 35.00s
Train Epoch: 1502 	Average Loss: -18.6450
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.8910

Learning rate: 0.00018907210976857426
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1503 [0/90000 (0%)]	Loss: -12.4384	Cost: 79.07s
Train Epoch: 1503 [20480/90000 (23%)]	Loss: -18.9737	Cost: 16.38s
Train Epoch: 1503 [40960/90000 (45%)]	Loss: -18.9697	Cost: 34.04s
Train Epoch: 1503 [61440/90000 (68%)]	Loss: -18.7059	Cost: 15.26s
Train Epoch: 1503 [81920/90000 (91%)]	Loss: -18.9039	Cost: 37.26s
Train Epoch: 1503 	Average Loss: -18.5352
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4626

Learning rate: 0.00018905782525614157
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1504 [0/90000 (0%)]	Loss: -12.2392	Cost: 72.47s
Train Epoch: 1504 [20480/90000 (23%)]	Loss: -19.7104	Cost: 16.33s
Train Epoch: 1504 [40960/90000 (45%)]	Loss: -19.5942	Cost: 38.26s
Train Epoch: 1504 [61440/90000 (68%)]	Loss: -19.3584	Cost: 15.13s
Train Epoch: 1504 [81920/90000 (91%)]	Loss: -18.9062	Cost: 35.34s
Train Epoch: 1504 	Average Loss: -18.9256
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3747

Learning rate: 0.00018904353195405393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1505 [0/90000 (0%)]	Loss: -13.1367	Cost: 42.98s
Train Epoch: 1505 [20480/90000 (23%)]	Loss: -19.4162	Cost: 12.18s
Train Epoch: 1505 [40960/90000 (45%)]	Loss: -19.2401	Cost: 16.49s
Train Epoch: 1505 [61440/90000 (68%)]	Loss: -19.1829	Cost: 9.07s
Train Epoch: 1505 [81920/90000 (91%)]	Loss: -18.8649	Cost: 9.79s
Train Epoch: 1505 	Average Loss: -18.8158
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4468

Learning rate: 0.000189029229863722
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1506 [0/90000 (0%)]	Loss: -12.7381	Cost: 23.80s
Train Epoch: 1506 [20480/90000 (23%)]	Loss: -19.3801	Cost: 9.06s
Train Epoch: 1506 [40960/90000 (45%)]	Loss: -19.1944	Cost: 9.11s
Train Epoch: 1506 [61440/90000 (68%)]	Loss: -19.1177	Cost: 9.03s
Train Epoch: 1506 [81920/90000 (91%)]	Loss: -18.8596	Cost: 8.95s
Train Epoch: 1506 	Average Loss: -18.7483
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1615

Learning rate: 0.00018901491898655736
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1507 [0/90000 (0%)]	Loss: -12.2842	Cost: 24.38s
Train Epoch: 1507 [20480/90000 (23%)]	Loss: -19.2868	Cost: 9.06s
Train Epoch: 1507 [40960/90000 (45%)]	Loss: -19.4278	Cost: 9.12s
Train Epoch: 1507 [61440/90000 (68%)]	Loss: -19.3410	Cost: 9.03s
Train Epoch: 1507 [81920/90000 (91%)]	Loss: -19.2199	Cost: 8.86s
Train Epoch: 1507 	Average Loss: -18.8513
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7840

Learning rate: 0.00018900059932397246
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1508 [0/90000 (0%)]	Loss: -12.8159	Cost: 25.73s
Train Epoch: 1508 [20480/90000 (23%)]	Loss: -19.6410	Cost: 9.18s
Train Epoch: 1508 [40960/90000 (45%)]	Loss: -19.7358	Cost: 9.17s
Train Epoch: 1508 [61440/90000 (68%)]	Loss: -19.5316	Cost: 8.99s
Train Epoch: 1508 [81920/90000 (91%)]	Loss: -19.4454	Cost: 8.76s
Train Epoch: 1508 	Average Loss: -19.2732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7747

Learning rate: 0.00018898627087738054
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1509 [0/90000 (0%)]	Loss: -12.7151	Cost: 26.83s
Train Epoch: 1509 [20480/90000 (23%)]	Loss: -19.8340	Cost: 13.29s
Train Epoch: 1509 [40960/90000 (45%)]	Loss: -19.7225	Cost: 18.64s
Train Epoch: 1509 [61440/90000 (68%)]	Loss: -19.5353	Cost: 11.77s
Train Epoch: 1509 [81920/90000 (91%)]	Loss: -19.6099	Cost: 22.79s
Train Epoch: 1509 	Average Loss: -19.3279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1220

Learning rate: 0.00018897193364819577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1510 [0/90000 (0%)]	Loss: -13.1318	Cost: 71.19s
Train Epoch: 1510 [20480/90000 (23%)]	Loss: -19.8909	Cost: 11.89s
Train Epoch: 1510 [40960/90000 (45%)]	Loss: -19.7084	Cost: 27.88s
Train Epoch: 1510 [61440/90000 (68%)]	Loss: -19.5961	Cost: 13.52s
Train Epoch: 1510 [81920/90000 (91%)]	Loss: -19.4224	Cost: 25.71s
Train Epoch: 1510 	Average Loss: -19.3592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8732

Learning rate: 0.00018895758763783324
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1511 [0/90000 (0%)]	Loss: -12.7324	Cost: 72.13s
Train Epoch: 1511 [20480/90000 (23%)]	Loss: -19.9102	Cost: 14.03s
Train Epoch: 1511 [40960/90000 (45%)]	Loss: -19.8480	Cost: 25.60s
Train Epoch: 1511 [61440/90000 (68%)]	Loss: -19.6628	Cost: 12.57s
Train Epoch: 1511 [81920/90000 (91%)]	Loss: -19.3146	Cost: 24.25s
Train Epoch: 1511 	Average Loss: -19.3651
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7499

Learning rate: 0.00018894323284770876
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1512 [0/90000 (0%)]	Loss: -13.5145	Cost: 77.22s
Train Epoch: 1512 [20480/90000 (23%)]	Loss: -19.9866	Cost: 14.97s
Train Epoch: 1512 [40960/90000 (45%)]	Loss: -19.8419	Cost: 22.70s
Train Epoch: 1512 [61440/90000 (68%)]	Loss: -19.3901	Cost: 12.39s
Train Epoch: 1512 [81920/90000 (91%)]	Loss: -19.4008	Cost: 24.76s
Train Epoch: 1512 	Average Loss: -19.2822
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0126

Learning rate: 0.00018892886927923913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1513 [0/90000 (0%)]	Loss: -13.7330	Cost: 43.09s
Train Epoch: 1513 [20480/90000 (23%)]	Loss: -19.9700	Cost: 11.08s
Train Epoch: 1513 [40960/90000 (45%)]	Loss: -19.6646	Cost: 15.19s
Train Epoch: 1513 [61440/90000 (68%)]	Loss: -19.6880	Cost: 10.59s
Train Epoch: 1513 [81920/90000 (91%)]	Loss: -19.4950	Cost: 11.52s
Train Epoch: 1513 	Average Loss: -19.3214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8475

Learning rate: 0.000188914496933842
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1514 [0/90000 (0%)]	Loss: -13.6222	Cost: 24.29s
Train Epoch: 1514 [20480/90000 (23%)]	Loss: -19.7947	Cost: 9.28s
Train Epoch: 1514 [40960/90000 (45%)]	Loss: -19.7828	Cost: 9.33s
Train Epoch: 1514 [61440/90000 (68%)]	Loss: -19.7565	Cost: 9.16s
Train Epoch: 1514 [81920/90000 (91%)]	Loss: -19.5449	Cost: 9.91s
Train Epoch: 1514 	Average Loss: -19.3517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1005

Learning rate: 0.0001889001158129358
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1515 [0/90000 (0%)]	Loss: -13.2358	Cost: 23.61s
Train Epoch: 1515 [20480/90000 (23%)]	Loss: -19.7341	Cost: 9.37s
Train Epoch: 1515 [40960/90000 (45%)]	Loss: -19.6491	Cost: 9.45s
Train Epoch: 1515 [61440/90000 (68%)]	Loss: -19.6704	Cost: 9.23s
Train Epoch: 1515 [81920/90000 (91%)]	Loss: -19.4571	Cost: 9.18s
Train Epoch: 1515 	Average Loss: -19.3047
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0850

Learning rate: 0.00018888572591793995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1516 [0/90000 (0%)]	Loss: -12.9679	Cost: 23.97s
Train Epoch: 1516 [20480/90000 (23%)]	Loss: -19.8446	Cost: 9.39s
Train Epoch: 1516 [40960/90000 (45%)]	Loss: -19.9180	Cost: 9.20s
Train Epoch: 1516 [61440/90000 (68%)]	Loss: -19.3658	Cost: 9.38s
Train Epoch: 1516 [81920/90000 (91%)]	Loss: -19.3914	Cost: 9.18s
Train Epoch: 1516 	Average Loss: -19.2732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7187

Learning rate: 0.00018887132725027466
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1517 [0/90000 (0%)]	Loss: -13.1426	Cost: 24.57s
Train Epoch: 1517 [20480/90000 (23%)]	Loss: -19.6119	Cost: 9.32s
Train Epoch: 1517 [40960/90000 (45%)]	Loss: -19.5062	Cost: 9.32s
Train Epoch: 1517 [61440/90000 (68%)]	Loss: -19.3923	Cost: 9.14s
Train Epoch: 1517 [81920/90000 (91%)]	Loss: -18.7648	Cost: 9.33s
Train Epoch: 1517 	Average Loss: -19.0622
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1844

Learning rate: 0.00018885691981136103
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1518 [0/90000 (0%)]	Loss: -12.4025	Cost: 24.97s
Train Epoch: 1518 [20480/90000 (23%)]	Loss: -19.0960	Cost: 9.45s
Train Epoch: 1518 [40960/90000 (45%)]	Loss: -19.1533	Cost: 10.03s
Train Epoch: 1518 [61440/90000 (68%)]	Loss: -19.2850	Cost: 9.27s
Train Epoch: 1518 [81920/90000 (91%)]	Loss: -19.0909	Cost: 9.14s
Train Epoch: 1518 	Average Loss: -18.7722
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5669

Learning rate: 0.00018884250360262097
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1519 [0/90000 (0%)]	Loss: -12.9905	Cost: 24.67s
Train Epoch: 1519 [20480/90000 (23%)]	Loss: -19.4448	Cost: 9.45s
Train Epoch: 1519 [40960/90000 (45%)]	Loss: -19.4911	Cost: 9.29s
Train Epoch: 1519 [61440/90000 (68%)]	Loss: -19.3801	Cost: 9.17s
Train Epoch: 1519 [81920/90000 (91%)]	Loss: -19.3213	Cost: 9.00s
Train Epoch: 1519 	Average Loss: -19.1592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7280

Learning rate: 0.00018882807862547735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1520 [0/90000 (0%)]	Loss: -13.3586	Cost: 24.95s
Train Epoch: 1520 [20480/90000 (23%)]	Loss: -19.6484	Cost: 9.42s
Train Epoch: 1520 [40960/90000 (45%)]	Loss: -19.5387	Cost: 9.24s
Train Epoch: 1520 [61440/90000 (68%)]	Loss: -19.5983	Cost: 9.23s
Train Epoch: 1520 [81920/90000 (91%)]	Loss: -19.3755	Cost: 8.90s
Train Epoch: 1520 	Average Loss: -19.2247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5714

Learning rate: 0.00018881364488135388
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1521 [0/90000 (0%)]	Loss: -12.4889	Cost: 25.63s
Train Epoch: 1521 [20480/90000 (23%)]	Loss: -19.4878	Cost: 9.36s
Train Epoch: 1521 [40960/90000 (45%)]	Loss: -19.6401	Cost: 9.27s
Train Epoch: 1521 [61440/90000 (68%)]	Loss: -19.5340	Cost: 9.27s
Train Epoch: 1521 [81920/90000 (91%)]	Loss: -19.1521	Cost: 8.92s
Train Epoch: 1521 	Average Loss: -19.0931
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5447

Learning rate: 0.00018879920237167505
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1522 [0/90000 (0%)]	Loss: -13.3656	Cost: 25.15s
Train Epoch: 1522 [20480/90000 (23%)]	Loss: -19.6450	Cost: 11.70s
Train Epoch: 1522 [40960/90000 (45%)]	Loss: -19.5880	Cost: 18.77s
Train Epoch: 1522 [61440/90000 (68%)]	Loss: -19.6287	Cost: 11.87s
Train Epoch: 1522 [81920/90000 (91%)]	Loss: -19.4506	Cost: 20.26s
Train Epoch: 1522 	Average Loss: -19.2273
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0045

Learning rate: 0.0001887847510978663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1523 [0/90000 (0%)]	Loss: -13.1052	Cost: 25.82s
Train Epoch: 1523 [20480/90000 (23%)]	Loss: -19.9921	Cost: 9.27s
Train Epoch: 1523 [40960/90000 (45%)]	Loss: -19.6947	Cost: 9.20s
Train Epoch: 1523 [61440/90000 (68%)]	Loss: -19.6977	Cost: 9.11s
Train Epoch: 1523 [81920/90000 (91%)]	Loss: -19.4406	Cost: 8.85s
Train Epoch: 1523 	Average Loss: -19.2127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6710

Learning rate: 0.00018877029106135394
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1524 [0/90000 (0%)]	Loss: -12.7370	Cost: 24.98s
Train Epoch: 1524 [20480/90000 (23%)]	Loss: -19.8887	Cost: 9.98s
Train Epoch: 1524 [40960/90000 (45%)]	Loss: -19.9389	Cost: 9.06s
Train Epoch: 1524 [61440/90000 (68%)]	Loss: -19.5998	Cost: 8.95s
Train Epoch: 1524 [81920/90000 (91%)]	Loss: -19.4699	Cost: 8.70s
Train Epoch: 1524 	Average Loss: -19.2336
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8517

Learning rate: 0.00018875582226356508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1525 [0/90000 (0%)]	Loss: -13.4969	Cost: 25.52s
Train Epoch: 1525 [20480/90000 (23%)]	Loss: -19.7843	Cost: 9.44s
Train Epoch: 1525 [40960/90000 (45%)]	Loss: -19.5678	Cost: 9.12s
Train Epoch: 1525 [61440/90000 (68%)]	Loss: -19.4575	Cost: 9.02s
Train Epoch: 1525 [81920/90000 (91%)]	Loss: -19.4525	Cost: 9.23s
Train Epoch: 1525 	Average Loss: -19.2225
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8474

Learning rate: 0.00018874134470592778
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1526 [0/90000 (0%)]	Loss: -13.4715	Cost: 24.13s
Train Epoch: 1526 [20480/90000 (23%)]	Loss: -19.6839	Cost: 9.22s
Train Epoch: 1526 [40960/90000 (45%)]	Loss: -19.3346	Cost: 9.50s
Train Epoch: 1526 [61440/90000 (68%)]	Loss: -19.3282	Cost: 9.07s
Train Epoch: 1526 [81920/90000 (91%)]	Loss: -18.9858	Cost: 10.31s
Train Epoch: 1526 	Average Loss: -18.9830
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6721

Learning rate: 0.00018872685838987086
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1527 [0/90000 (0%)]	Loss: -12.6990	Cost: 37.58s
Train Epoch: 1527 [20480/90000 (23%)]	Loss: -19.6325	Cost: 12.89s
Train Epoch: 1527 [40960/90000 (45%)]	Loss: -19.4843	Cost: 18.79s
Train Epoch: 1527 [61440/90000 (68%)]	Loss: -19.4598	Cost: 11.55s
Train Epoch: 1527 [81920/90000 (91%)]	Loss: -19.2826	Cost: 23.16s
Train Epoch: 1527 	Average Loss: -19.0838
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8138

Learning rate: 0.0001887123633168241
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1528 [0/90000 (0%)]	Loss: -12.6784	Cost: 50.99s
Train Epoch: 1528 [20480/90000 (23%)]	Loss: -19.6695	Cost: 11.63s
Train Epoch: 1528 [40960/90000 (45%)]	Loss: -19.2678	Cost: 23.66s
Train Epoch: 1528 [61440/90000 (68%)]	Loss: -19.1540	Cost: 12.00s
Train Epoch: 1528 [81920/90000 (91%)]	Loss: -19.0585	Cost: 24.30s
Train Epoch: 1528 	Average Loss: -18.9554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4734

Learning rate: 0.0001886978594882181
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1529 [0/90000 (0%)]	Loss: -13.2631	Cost: 23.34s
Train Epoch: 1529 [20480/90000 (23%)]	Loss: -19.4791	Cost: 9.03s
Train Epoch: 1529 [40960/90000 (45%)]	Loss: -19.3508	Cost: 9.04s
Train Epoch: 1529 [61440/90000 (68%)]	Loss: -19.2426	Cost: 9.07s
Train Epoch: 1529 [81920/90000 (91%)]	Loss: -19.3171	Cost: 9.63s
Train Epoch: 1529 	Average Loss: -18.9936
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7617

Learning rate: 0.0001886833469054843
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1530 [0/90000 (0%)]	Loss: -13.4400	Cost: 24.13s
Train Epoch: 1530 [20480/90000 (23%)]	Loss: -19.5968	Cost: 9.06s
Train Epoch: 1530 [40960/90000 (45%)]	Loss: -19.4931	Cost: 10.45s
Train Epoch: 1530 [61440/90000 (68%)]	Loss: -19.3182	Cost: 9.02s
Train Epoch: 1530 [81920/90000 (91%)]	Loss: -19.3193	Cost: 10.43s
Train Epoch: 1530 	Average Loss: -19.1767
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8638

Learning rate: 0.00018866882557005513
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1531 [0/90000 (0%)]	Loss: -12.9658	Cost: 24.04s
Train Epoch: 1531 [20480/90000 (23%)]	Loss: -19.8820	Cost: 9.08s
Train Epoch: 1531 [40960/90000 (45%)]	Loss: -19.4353	Cost: 9.01s
Train Epoch: 1531 [61440/90000 (68%)]	Loss: -19.6455	Cost: 8.94s
Train Epoch: 1531 [81920/90000 (91%)]	Loss: -19.2569	Cost: 9.00s
Train Epoch: 1531 	Average Loss: -19.1968
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8503

Learning rate: 0.00018865429548336365
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1532 [0/90000 (0%)]	Loss: -13.3389	Cost: 25.56s
Train Epoch: 1532 [20480/90000 (23%)]	Loss: -19.7821	Cost: 9.04s
Train Epoch: 1532 [40960/90000 (45%)]	Loss: -17.7498	Cost: 9.08s
Train Epoch: 1532 [61440/90000 (68%)]	Loss: -17.9840	Cost: 8.98s
Train Epoch: 1532 [81920/90000 (91%)]	Loss: -18.2366	Cost: 8.94s
Train Epoch: 1532 	Average Loss: -18.2420
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9563

Learning rate: 0.00018863975664684402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1533 [0/90000 (0%)]	Loss: -12.1433	Cost: 25.35s
Train Epoch: 1533 [20480/90000 (23%)]	Loss: -18.9562	Cost: 9.02s
Train Epoch: 1533 [40960/90000 (45%)]	Loss: -18.4720	Cost: 9.02s
Train Epoch: 1533 [61440/90000 (68%)]	Loss: -18.6745	Cost: 8.97s
Train Epoch: 1533 [81920/90000 (91%)]	Loss: -18.9314	Cost: 8.73s
Train Epoch: 1533 	Average Loss: -18.4187
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5434

Learning rate: 0.00018862520906193114
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1534 [0/90000 (0%)]	Loss: -13.6755	Cost: 27.18s
Train Epoch: 1534 [20480/90000 (23%)]	Loss: -19.4671	Cost: 9.04s
Train Epoch: 1534 [40960/90000 (45%)]	Loss: -19.1770	Cost: 9.32s
Train Epoch: 1534 [61440/90000 (68%)]	Loss: -19.3139	Cost: 9.01s
Train Epoch: 1534 [81920/90000 (91%)]	Loss: -19.4883	Cost: 8.78s
Train Epoch: 1534 	Average Loss: -19.0206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0308

Learning rate: 0.0001886106527300608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1535 [0/90000 (0%)]	Loss: -14.0051	Cost: 26.21s
Train Epoch: 1535 [20480/90000 (23%)]	Loss: -19.7930	Cost: 9.30s
Train Epoch: 1535 [40960/90000 (45%)]	Loss: -19.5310	Cost: 9.30s
Train Epoch: 1535 [61440/90000 (68%)]	Loss: -19.5009	Cost: 9.15s
Train Epoch: 1535 [81920/90000 (91%)]	Loss: -19.6253	Cost: 8.78s
Train Epoch: 1535 	Average Loss: -19.2944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9767

Learning rate: 0.00018859608765266965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1536 [0/90000 (0%)]	Loss: -14.0466	Cost: 26.21s
Train Epoch: 1536 [20480/90000 (23%)]	Loss: -19.3872	Cost: 9.42s
Train Epoch: 1536 [40960/90000 (45%)]	Loss: -19.1690	Cost: 9.22s
Train Epoch: 1536 [61440/90000 (68%)]	Loss: -19.2261	Cost: 9.17s
Train Epoch: 1536 [81920/90000 (91%)]	Loss: -18.9089	Cost: 8.98s
Train Epoch: 1536 	Average Loss: -18.9683
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7058

Learning rate: 0.00018858151383119523
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1537 [0/90000 (0%)]	Loss: -12.7680	Cost: 27.19s
Train Epoch: 1537 [20480/90000 (23%)]	Loss: -19.2908	Cost: 9.36s
Train Epoch: 1537 [40960/90000 (45%)]	Loss: -19.4871	Cost: 9.22s
Train Epoch: 1537 [61440/90000 (68%)]	Loss: -18.1056	Cost: 9.13s
Train Epoch: 1537 [81920/90000 (91%)]	Loss: -17.5062	Cost: 8.95s
Train Epoch: 1537 	Average Loss: -18.4509
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5016

Learning rate: 0.00018856693126707586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1538 [0/90000 (0%)]	Loss: -11.4199	Cost: 26.36s
Train Epoch: 1538 [20480/90000 (23%)]	Loss: -18.3551	Cost: 9.40s
Train Epoch: 1538 [40960/90000 (45%)]	Loss: -18.7200	Cost: 9.30s
Train Epoch: 1538 [61440/90000 (68%)]	Loss: -18.9878	Cost: 9.12s
Train Epoch: 1538 [81920/90000 (91%)]	Loss: -18.8205	Cost: 8.91s
Train Epoch: 1538 	Average Loss: -18.2206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4694

Learning rate: 0.00018855233996175081
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1539 [0/90000 (0%)]	Loss: -13.2795	Cost: 26.66s
Train Epoch: 1539 [20480/90000 (23%)]	Loss: -19.5923	Cost: 9.35s
Train Epoch: 1539 [40960/90000 (45%)]	Loss: -19.7510	Cost: 9.26s
Train Epoch: 1539 [61440/90000 (68%)]	Loss: -19.7896	Cost: 9.19s
Train Epoch: 1539 [81920/90000 (91%)]	Loss: -19.7054	Cost: 8.84s
Train Epoch: 1539 	Average Loss: -19.2851
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2059

Learning rate: 0.00018853773991666024
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1540 [0/90000 (0%)]	Loss: -13.0947	Cost: 25.09s
Train Epoch: 1540 [20480/90000 (23%)]	Loss: -19.9769	Cost: 9.28s
Train Epoch: 1540 [40960/90000 (45%)]	Loss: -19.8807	Cost: 9.26s
Train Epoch: 1540 [61440/90000 (68%)]	Loss: -20.0037	Cost: 9.08s
Train Epoch: 1540 [81920/90000 (91%)]	Loss: -19.7701	Cost: 8.79s
Train Epoch: 1540 	Average Loss: -19.5414
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3295

Learning rate: 0.00018852313113324503
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1541 [0/90000 (0%)]	Loss: -13.8226	Cost: 27.27s
Train Epoch: 1541 [20480/90000 (23%)]	Loss: -20.2761	Cost: 9.32s
Train Epoch: 1541 [40960/90000 (45%)]	Loss: -20.1097	Cost: 9.24s
Train Epoch: 1541 [61440/90000 (68%)]	Loss: -19.9200	Cost: 9.11s
Train Epoch: 1541 [81920/90000 (91%)]	Loss: -19.6763	Cost: 8.89s
Train Epoch: 1541 	Average Loss: -19.6369
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2415

Learning rate: 0.00018850851361294706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1542 [0/90000 (0%)]	Loss: -13.6625	Cost: 25.28s
Train Epoch: 1542 [20480/90000 (23%)]	Loss: -20.0569	Cost: 9.44s
Train Epoch: 1542 [40960/90000 (45%)]	Loss: -20.0845	Cost: 9.30s
Train Epoch: 1542 [61440/90000 (68%)]	Loss: -20.0929	Cost: 9.23s
Train Epoch: 1542 [81920/90000 (91%)]	Loss: -19.9897	Cost: 8.83s
Train Epoch: 1542 	Average Loss: -19.7260
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4799

Learning rate: 0.000188493887357209
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1543 [0/90000 (0%)]	Loss: -13.8556	Cost: 28.47s
Train Epoch: 1543 [20480/90000 (23%)]	Loss: -20.2198	Cost: 9.53s
Train Epoch: 1543 [40960/90000 (45%)]	Loss: -19.6513	Cost: 9.35s
Train Epoch: 1543 [61440/90000 (68%)]	Loss: -19.4274	Cost: 9.19s
Train Epoch: 1543 [81920/90000 (91%)]	Loss: -19.3840	Cost: 8.99s
Train Epoch: 1543 	Average Loss: -19.3715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9475

Learning rate: 0.0001884792523674744
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1544 [0/90000 (0%)]	Loss: -13.4914	Cost: 26.87s
Train Epoch: 1544 [20480/90000 (23%)]	Loss: -20.0202	Cost: 9.33s
Train Epoch: 1544 [40960/90000 (45%)]	Loss: -19.8186	Cost: 9.37s
Train Epoch: 1544 [61440/90000 (68%)]	Loss: -19.9735	Cost: 9.19s
Train Epoch: 1544 [81920/90000 (91%)]	Loss: -19.4421	Cost: 8.80s
Train Epoch: 1544 	Average Loss: -19.4263
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0435

Learning rate: 0.00018846460864518772
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1545 [0/90000 (0%)]	Loss: -13.9327	Cost: 25.72s
Train Epoch: 1545 [20480/90000 (23%)]	Loss: -19.9897	Cost: 9.38s
Train Epoch: 1545 [40960/90000 (45%)]	Loss: -19.9433	Cost: 9.35s
Train Epoch: 1545 [61440/90000 (68%)]	Loss: -19.7589	Cost: 9.17s
Train Epoch: 1545 [81920/90000 (91%)]	Loss: -19.6709	Cost: 9.02s
Train Epoch: 1545 	Average Loss: -19.4664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0751

Learning rate: 0.00018844995619179416
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1546 [0/90000 (0%)]	Loss: -13.6971	Cost: 25.41s
Train Epoch: 1546 [20480/90000 (23%)]	Loss: -19.9794	Cost: 9.37s
Train Epoch: 1546 [40960/90000 (45%)]	Loss: -19.9493	Cost: 9.33s
Train Epoch: 1546 [61440/90000 (68%)]	Loss: -19.9461	Cost: 9.23s
Train Epoch: 1546 [81920/90000 (91%)]	Loss: -19.6702	Cost: 9.04s
Train Epoch: 1546 	Average Loss: -19.5380
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3704

Learning rate: 0.0001884352950087399
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1547 [0/90000 (0%)]	Loss: -12.9934	Cost: 25.50s
Train Epoch: 1547 [20480/90000 (23%)]	Loss: -20.0388	Cost: 9.43s
Train Epoch: 1547 [40960/90000 (45%)]	Loss: -20.0227	Cost: 9.26s
Train Epoch: 1547 [61440/90000 (68%)]	Loss: -20.0233	Cost: 9.18s
Train Epoch: 1547 [81920/90000 (91%)]	Loss: -19.8823	Cost: 9.08s
Train Epoch: 1547 	Average Loss: -19.5731
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2659

Learning rate: 0.00018842062509747198
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1548 [0/90000 (0%)]	Loss: -13.7138	Cost: 28.00s
Train Epoch: 1548 [20480/90000 (23%)]	Loss: -20.0175	Cost: 9.47s
Train Epoch: 1548 [40960/90000 (45%)]	Loss: -19.9984	Cost: 9.46s
Train Epoch: 1548 [61440/90000 (68%)]	Loss: -19.9746	Cost: 9.16s
Train Epoch: 1548 [81920/90000 (91%)]	Loss: -20.0155	Cost: 9.10s
Train Epoch: 1548 	Average Loss: -19.6219
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3852

Learning rate: 0.0001884059464594382
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1549 [0/90000 (0%)]	Loss: -13.2307	Cost: 25.06s
Train Epoch: 1549 [20480/90000 (23%)]	Loss: -20.3820	Cost: 9.33s
Train Epoch: 1549 [40960/90000 (45%)]	Loss: -20.0688	Cost: 9.35s
Train Epoch: 1549 [61440/90000 (68%)]	Loss: -19.4423	Cost: 9.30s
Train Epoch: 1549 [81920/90000 (91%)]	Loss: -19.3045	Cost: 8.86s
Train Epoch: 1549 	Average Loss: -19.4239
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8052

Learning rate: 0.0001883912590960873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1550 [0/90000 (0%)]	Loss: -12.6341	Cost: 26.49s
Train Epoch: 1550 [20480/90000 (23%)]	Loss: -19.3273	Cost: 9.27s
Train Epoch: 1550 [40960/90000 (45%)]	Loss: -19.3596	Cost: 10.42s
Train Epoch: 1550 [61440/90000 (68%)]	Loss: -19.2234	Cost: 9.11s
Train Epoch: 1550 [81920/90000 (91%)]	Loss: -19.4425	Cost: 8.88s
Train Epoch: 1550 	Average Loss: -18.9692
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8874

Saving model as model.pt_e1550 & waveforms_supplementary.hdf5_e1550
Learning rate: 0.00018837656300886888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1551 [0/90000 (0%)]	Loss: -12.5477	Cost: 25.82s
Train Epoch: 1551 [20480/90000 (23%)]	Loss: -19.6958	Cost: 9.44s
Train Epoch: 1551 [40960/90000 (45%)]	Loss: -19.5910	Cost: 9.23s
Train Epoch: 1551 [61440/90000 (68%)]	Loss: -19.6124	Cost: 9.13s
Train Epoch: 1551 [81920/90000 (91%)]	Loss: -19.0991	Cost: 8.85s
Train Epoch: 1551 	Average Loss: -19.2099
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9577

Learning rate: 0.0001883618581992334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1552 [0/90000 (0%)]	Loss: -11.7544	Cost: 25.96s
Train Epoch: 1552 [20480/90000 (23%)]	Loss: -19.5775	Cost: 9.38s
Train Epoch: 1552 [40960/90000 (45%)]	Loss: -19.9073	Cost: 9.88s
Train Epoch: 1552 [61440/90000 (68%)]	Loss: -19.6175	Cost: 9.88s
Train Epoch: 1552 [81920/90000 (91%)]	Loss: -19.7343	Cost: 9.77s
Train Epoch: 1552 	Average Loss: -19.2296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3024

Learning rate: 0.0001883471446686321
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1553 [0/90000 (0%)]	Loss: -13.6450	Cost: 25.26s
Train Epoch: 1553 [20480/90000 (23%)]	Loss: -19.9857	Cost: 9.36s
Train Epoch: 1553 [40960/90000 (45%)]	Loss: -19.8321	Cost: 9.24s
Train Epoch: 1553 [61440/90000 (68%)]	Loss: -19.8614	Cost: 9.17s
Train Epoch: 1553 [81920/90000 (91%)]	Loss: -19.8208	Cost: 9.04s
Train Epoch: 1553 	Average Loss: -19.4662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4490

Learning rate: 0.00018833242241851722
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1554 [0/90000 (0%)]	Loss: -14.1826	Cost: 26.34s
Train Epoch: 1554 [20480/90000 (23%)]	Loss: -20.1837	Cost: 9.59s
Train Epoch: 1554 [40960/90000 (45%)]	Loss: -19.5055	Cost: 9.34s
Train Epoch: 1554 [61440/90000 (68%)]	Loss: -19.5984	Cost: 9.18s
Train Epoch: 1554 [81920/90000 (91%)]	Loss: -19.7004	Cost: 9.39s
Train Epoch: 1554 	Average Loss: -19.4396
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2923

Learning rate: 0.00018831769145034177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1555 [0/90000 (0%)]	Loss: -14.0333	Cost: 25.34s
Train Epoch: 1555 [20480/90000 (23%)]	Loss: -20.2398	Cost: 9.31s
Train Epoch: 1555 [40960/90000 (45%)]	Loss: -20.1663	Cost: 9.58s
Train Epoch: 1555 [61440/90000 (68%)]	Loss: -20.0124	Cost: 9.17s
Train Epoch: 1555 [81920/90000 (91%)]	Loss: -20.0674	Cost: 8.92s
Train Epoch: 1555 	Average Loss: -19.6798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2517

Learning rate: 0.00018830295176555965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1556 [0/90000 (0%)]	Loss: -13.4455	Cost: 27.00s
Train Epoch: 1556 [20480/90000 (23%)]	Loss: -20.2450	Cost: 9.21s
Train Epoch: 1556 [40960/90000 (45%)]	Loss: -19.8292	Cost: 10.76s
Train Epoch: 1556 [61440/90000 (68%)]	Loss: -19.7776	Cost: 9.03s
Train Epoch: 1556 [81920/90000 (91%)]	Loss: -19.7578	Cost: 8.91s
Train Epoch: 1556 	Average Loss: -19.5111
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3152

Learning rate: 0.00018828820336562555
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1557 [0/90000 (0%)]	Loss: -12.9390	Cost: 25.13s
Train Epoch: 1557 [20480/90000 (23%)]	Loss: -19.9890	Cost: 9.45s
Train Epoch: 1557 [40960/90000 (45%)]	Loss: -20.0460	Cost: 9.35s
Train Epoch: 1557 [61440/90000 (68%)]	Loss: -19.9310	Cost: 9.15s
Train Epoch: 1557 [81920/90000 (91%)]	Loss: -20.0591	Cost: 8.88s
Train Epoch: 1557 	Average Loss: -19.6689
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2385

Learning rate: 0.00018827344625199513
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1558 [0/90000 (0%)]	Loss: -13.2327	Cost: 25.50s
Train Epoch: 1558 [20480/90000 (23%)]	Loss: -20.5011	Cost: 9.62s
Train Epoch: 1558 [40960/90000 (45%)]	Loss: -19.8600	Cost: 9.26s
Train Epoch: 1558 [61440/90000 (68%)]	Loss: -19.8738	Cost: 9.21s
Train Epoch: 1558 [81920/90000 (91%)]	Loss: -19.8246	Cost: 8.72s
Train Epoch: 1558 	Average Loss: -19.6629
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1933

Learning rate: 0.00018825868042612485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1559 [0/90000 (0%)]	Loss: -13.9300	Cost: 25.04s
Train Epoch: 1559 [20480/90000 (23%)]	Loss: -20.4293	Cost: 9.54s
Train Epoch: 1559 [40960/90000 (45%)]	Loss: -19.9424	Cost: 9.04s
Train Epoch: 1559 [61440/90000 (68%)]	Loss: -19.8428	Cost: 9.00s
Train Epoch: 1559 [81920/90000 (91%)]	Loss: -20.0112	Cost: 9.18s
Train Epoch: 1559 	Average Loss: -19.7179
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4362

Learning rate: 0.00018824390588947204
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1560 [0/90000 (0%)]	Loss: -13.5318	Cost: 24.68s
Train Epoch: 1560 [20480/90000 (23%)]	Loss: -19.9885	Cost: 9.02s
Train Epoch: 1560 [40960/90000 (45%)]	Loss: -19.8270	Cost: 10.04s
Train Epoch: 1560 [61440/90000 (68%)]	Loss: -19.7346	Cost: 9.01s
Train Epoch: 1560 [81920/90000 (91%)]	Loss: -19.9190	Cost: 10.01s
Train Epoch: 1560 	Average Loss: -19.4930
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2596

Learning rate: 0.0001882291226434949
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1561 [0/90000 (0%)]	Loss: -13.4992	Cost: 23.71s
Train Epoch: 1561 [20480/90000 (23%)]	Loss: -20.0445	Cost: 9.07s
Train Epoch: 1561 [40960/90000 (45%)]	Loss: -19.6362	Cost: 9.90s
Train Epoch: 1561 [61440/90000 (68%)]	Loss: -19.6487	Cost: 9.03s
Train Epoch: 1561 [81920/90000 (91%)]	Loss: -19.4823	Cost: 10.30s
Train Epoch: 1561 	Average Loss: -19.3688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2337

Learning rate: 0.00018821433068965244
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1562 [0/90000 (0%)]	Loss: -13.0518	Cost: 25.09s
Train Epoch: 1562 [20480/90000 (23%)]	Loss: -19.8182	Cost: 9.49s
Train Epoch: 1562 [40960/90000 (45%)]	Loss: -19.6834	Cost: 9.25s
Train Epoch: 1562 [61440/90000 (68%)]	Loss: -19.7339	Cost: 9.06s
Train Epoch: 1562 [81920/90000 (91%)]	Loss: -18.9180	Cost: 10.15s
Train Epoch: 1562 	Average Loss: -19.2281
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4161

Learning rate: 0.00018819953002940457
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1563 [0/90000 (0%)]	Loss: -13.0345	Cost: 25.61s
Train Epoch: 1563 [20480/90000 (23%)]	Loss: -19.3664	Cost: 9.03s
Train Epoch: 1563 [40960/90000 (45%)]	Loss: -19.4674	Cost: 9.81s
Train Epoch: 1563 [61440/90000 (68%)]	Loss: -19.4117	Cost: 9.03s
Train Epoch: 1563 [81920/90000 (91%)]	Loss: -19.4852	Cost: 10.15s
Train Epoch: 1563 	Average Loss: -19.0012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1859

Learning rate: 0.0001881847206642121
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1564 [0/90000 (0%)]	Loss: -12.7867	Cost: 23.76s
Train Epoch: 1564 [20480/90000 (23%)]	Loss: -20.0155	Cost: 9.17s
Train Epoch: 1564 [40960/90000 (45%)]	Loss: -19.8920	Cost: 9.26s
Train Epoch: 1564 [61440/90000 (68%)]	Loss: -19.9756	Cost: 9.16s
Train Epoch: 1564 [81920/90000 (91%)]	Loss: -19.8859	Cost: 9.03s
Train Epoch: 1564 	Average Loss: -19.5828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5590

Learning rate: 0.0001881699025955366
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1565 [0/90000 (0%)]	Loss: -13.4152	Cost: 23.67s
Train Epoch: 1565 [20480/90000 (23%)]	Loss: -20.3890	Cost: 9.04s
Train Epoch: 1565 [40960/90000 (45%)]	Loss: -20.2117	Cost: 10.47s
Train Epoch: 1565 [61440/90000 (68%)]	Loss: -20.1048	Cost: 9.14s
Train Epoch: 1565 [81920/90000 (91%)]	Loss: -20.1562	Cost: 9.76s
Train Epoch: 1565 	Average Loss: -19.8612
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6550

Learning rate: 0.0001881550758248406
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1566 [0/90000 (0%)]	Loss: -13.8775	Cost: 24.48s
Train Epoch: 1566 [20480/90000 (23%)]	Loss: -20.4929	Cost: 9.37s
Train Epoch: 1566 [40960/90000 (45%)]	Loss: -20.2921	Cost: 9.43s
Train Epoch: 1566 [61440/90000 (68%)]	Loss: -20.1522	Cost: 9.18s
Train Epoch: 1566 [81920/90000 (91%)]	Loss: -19.5906	Cost: 9.19s
Train Epoch: 1566 	Average Loss: -19.7364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2972

Learning rate: 0.00018814024035358743
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1567 [0/90000 (0%)]	Loss: -14.0008	Cost: 24.95s
Train Epoch: 1567 [20480/90000 (23%)]	Loss: -19.9579	Cost: 9.28s
Train Epoch: 1567 [40960/90000 (45%)]	Loss: -19.5682	Cost: 9.59s
Train Epoch: 1567 [61440/90000 (68%)]	Loss: -19.6545	Cost: 9.10s
Train Epoch: 1567 [81920/90000 (91%)]	Loss: -19.4524	Cost: 9.23s
Train Epoch: 1567 	Average Loss: -19.4164
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9522

Learning rate: 0.0001881253961832413
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1568 [0/90000 (0%)]	Loss: -13.5902	Cost: 25.53s
Train Epoch: 1568 [20480/90000 (23%)]	Loss: -19.9338	Cost: 9.41s
Train Epoch: 1568 [40960/90000 (45%)]	Loss: -19.8633	Cost: 9.51s
Train Epoch: 1568 [61440/90000 (68%)]	Loss: -19.7018	Cost: 9.11s
Train Epoch: 1568 [81920/90000 (91%)]	Loss: -19.8138	Cost: 9.05s
Train Epoch: 1568 	Average Loss: -19.4408
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3165

Learning rate: 0.00018811054331526725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1569 [0/90000 (0%)]	Loss: -13.6124	Cost: 26.24s
Train Epoch: 1569 [20480/90000 (23%)]	Loss: -20.4904	Cost: 9.01s
Train Epoch: 1569 [40960/90000 (45%)]	Loss: -19.8450	Cost: 9.09s
Train Epoch: 1569 [61440/90000 (68%)]	Loss: -19.8045	Cost: 8.97s
Train Epoch: 1569 [81920/90000 (91%)]	Loss: -19.7786	Cost: 8.80s
Train Epoch: 1569 	Average Loss: -19.6864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3963

Learning rate: 0.0001880956817511312
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1570 [0/90000 (0%)]	Loss: -13.4386	Cost: 25.72s
Train Epoch: 1570 [20480/90000 (23%)]	Loss: -20.3343	Cost: 9.14s
Train Epoch: 1570 [40960/90000 (45%)]	Loss: -20.1869	Cost: 9.25s
Train Epoch: 1570 [61440/90000 (68%)]	Loss: -19.6726	Cost: 9.00s
Train Epoch: 1570 [81920/90000 (91%)]	Loss: -19.9021	Cost: 8.90s
Train Epoch: 1570 	Average Loss: -19.6390
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3606

Learning rate: 0.00018808081149229993
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1571 [0/90000 (0%)]	Loss: -12.9912	Cost: 25.50s
Train Epoch: 1571 [20480/90000 (23%)]	Loss: -20.2167	Cost: 9.31s
Train Epoch: 1571 [40960/90000 (45%)]	Loss: -20.0525	Cost: 9.32s
Train Epoch: 1571 [61440/90000 (68%)]	Loss: -20.2285	Cost: 9.09s
Train Epoch: 1571 [81920/90000 (91%)]	Loss: -19.8641	Cost: 8.84s
Train Epoch: 1571 	Average Loss: -19.7267
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3604

Learning rate: 0.0001880659325402411
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1572 [0/90000 (0%)]	Loss: -14.3085	Cost: 26.86s
Train Epoch: 1572 [20480/90000 (23%)]	Loss: -20.3941	Cost: 9.33s
Train Epoch: 1572 [40960/90000 (45%)]	Loss: -20.2115	Cost: 9.47s
Train Epoch: 1572 [61440/90000 (68%)]	Loss: -20.0421	Cost: 9.13s
Train Epoch: 1572 [81920/90000 (91%)]	Loss: -19.9209	Cost: 8.85s
Train Epoch: 1572 	Average Loss: -19.8297
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2765

Learning rate: 0.00018805104489642317
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1573 [0/90000 (0%)]	Loss: -13.6696	Cost: 25.06s
Train Epoch: 1573 [20480/90000 (23%)]	Loss: -20.4792	Cost: 9.48s
Train Epoch: 1573 [40960/90000 (45%)]	Loss: -20.4325	Cost: 9.23s
Train Epoch: 1573 [61440/90000 (68%)]	Loss: -20.0730	Cost: 9.19s
Train Epoch: 1573 [81920/90000 (91%)]	Loss: -19.9781	Cost: 9.13s
Train Epoch: 1573 	Average Loss: -19.7976
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4692

Learning rate: 0.00018803614856231554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1574 [0/90000 (0%)]	Loss: -14.0235	Cost: 25.88s
Train Epoch: 1574 [20480/90000 (23%)]	Loss: -20.3431	Cost: 9.33s
Train Epoch: 1574 [40960/90000 (45%)]	Loss: -19.9723	Cost: 9.61s
Train Epoch: 1574 [61440/90000 (68%)]	Loss: -19.9043	Cost: 9.23s
Train Epoch: 1574 [81920/90000 (91%)]	Loss: -19.6871	Cost: 8.96s
Train Epoch: 1574 	Average Loss: -19.6390
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3170

Learning rate: 0.0001880212435393884
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1575 [0/90000 (0%)]	Loss: -13.2072	Cost: 25.28s
Train Epoch: 1575 [20480/90000 (23%)]	Loss: -20.0549	Cost: 9.39s
Train Epoch: 1575 [40960/90000 (45%)]	Loss: -20.0345	Cost: 9.40s
Train Epoch: 1575 [61440/90000 (68%)]	Loss: -19.9530	Cost: 9.09s
Train Epoch: 1575 [81920/90000 (91%)]	Loss: -19.7597	Cost: 8.83s
Train Epoch: 1575 	Average Loss: -19.4941
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3271

Learning rate: 0.0001880063298291128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1576 [0/90000 (0%)]	Loss: -13.5741	Cost: 25.17s
Train Epoch: 1576 [20480/90000 (23%)]	Loss: -20.2538	Cost: 10.10s
Train Epoch: 1576 [40960/90000 (45%)]	Loss: -20.0024	Cost: 9.22s
Train Epoch: 1576 [61440/90000 (68%)]	Loss: -19.7528	Cost: 8.95s
Train Epoch: 1576 [81920/90000 (91%)]	Loss: -19.6992	Cost: 8.72s
Train Epoch: 1576 	Average Loss: -19.5753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3300

Learning rate: 0.00018799140743296064
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1577 [0/90000 (0%)]	Loss: -14.0101	Cost: 25.16s
Train Epoch: 1577 [20480/90000 (23%)]	Loss: -20.3181	Cost: 9.59s
Train Epoch: 1577 [40960/90000 (45%)]	Loss: -20.2614	Cost: 9.32s
Train Epoch: 1577 [61440/90000 (68%)]	Loss: -20.2898	Cost: 9.08s
Train Epoch: 1577 [81920/90000 (91%)]	Loss: -20.0924	Cost: 9.84s
Train Epoch: 1577 	Average Loss: -19.8829
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5777

Learning rate: 0.00018797647635240475
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1578 [0/90000 (0%)]	Loss: -13.3122	Cost: 24.77s
Train Epoch: 1578 [20480/90000 (23%)]	Loss: -20.4867	Cost: 9.53s
Train Epoch: 1578 [40960/90000 (45%)]	Loss: -20.1760	Cost: 9.42s
Train Epoch: 1578 [61440/90000 (68%)]	Loss: -20.1970	Cost: 8.99s
Train Epoch: 1578 [81920/90000 (91%)]	Loss: -20.0000	Cost: 9.98s
Train Epoch: 1578 	Average Loss: -19.8861
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5342

Learning rate: 0.00018796153658891875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1579 [0/90000 (0%)]	Loss: -14.0667	Cost: 23.64s
Train Epoch: 1579 [20480/90000 (23%)]	Loss: -20.4232	Cost: 9.56s
Train Epoch: 1579 [40960/90000 (45%)]	Loss: -20.2031	Cost: 9.19s
Train Epoch: 1579 [61440/90000 (68%)]	Loss: -19.6871	Cost: 9.11s
Train Epoch: 1579 [81920/90000 (91%)]	Loss: -19.6199	Cost: 10.06s
Train Epoch: 1579 	Average Loss: -19.7381
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2569

Learning rate: 0.00018794658814397716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1580 [0/90000 (0%)]	Loss: -13.1757	Cost: 24.12s
Train Epoch: 1580 [20480/90000 (23%)]	Loss: -20.1260	Cost: 9.32s
Train Epoch: 1580 [40960/90000 (45%)]	Loss: -20.0299	Cost: 9.49s
Train Epoch: 1580 [61440/90000 (68%)]	Loss: -20.0695	Cost: 9.04s
Train Epoch: 1580 [81920/90000 (91%)]	Loss: -20.0419	Cost: 10.34s
Train Epoch: 1580 	Average Loss: -19.6678
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4742

Learning rate: 0.00018793163101905527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1581 [0/90000 (0%)]	Loss: -13.4809	Cost: 23.58s
Train Epoch: 1581 [20480/90000 (23%)]	Loss: -20.2434	Cost: 9.03s
Train Epoch: 1581 [40960/90000 (45%)]	Loss: -20.1221	Cost: 9.08s
Train Epoch: 1581 [61440/90000 (68%)]	Loss: -19.9260	Cost: 9.04s
Train Epoch: 1581 [81920/90000 (91%)]	Loss: -20.0041	Cost: 10.13s
Train Epoch: 1581 	Average Loss: -19.7774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5249

Learning rate: 0.00018791666521562935
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1582 [0/90000 (0%)]	Loss: -14.1350	Cost: 24.51s
Train Epoch: 1582 [20480/90000 (23%)]	Loss: -20.3899	Cost: 9.01s
Train Epoch: 1582 [40960/90000 (45%)]	Loss: -19.9159	Cost: 9.91s
Train Epoch: 1582 [61440/90000 (68%)]	Loss: -19.7812	Cost: 9.07s
Train Epoch: 1582 [81920/90000 (91%)]	Loss: -19.9465	Cost: 10.61s
Train Epoch: 1582 	Average Loss: -19.6730
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5119

Learning rate: 0.00018790169073517642
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1583 [0/90000 (0%)]	Loss: -13.8464	Cost: 23.46s
Train Epoch: 1583 [20480/90000 (23%)]	Loss: -20.4540	Cost: 9.04s
Train Epoch: 1583 [40960/90000 (45%)]	Loss: -20.1533	Cost: 9.33s
Train Epoch: 1583 [61440/90000 (68%)]	Loss: -20.0280	Cost: 9.25s
Train Epoch: 1583 [81920/90000 (91%)]	Loss: -19.8622	Cost: 9.18s
Train Epoch: 1583 	Average Loss: -19.7591
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3447

Learning rate: 0.0001878867075791744
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1584 [0/90000 (0%)]	Loss: -13.8734	Cost: 23.88s
Train Epoch: 1584 [20480/90000 (23%)]	Loss: -19.8352	Cost: 9.43s
Train Epoch: 1584 [40960/90000 (45%)]	Loss: -19.2305	Cost: 9.36s
Train Epoch: 1584 [61440/90000 (68%)]	Loss: -19.2090	Cost: 9.29s
Train Epoch: 1584 [81920/90000 (91%)]	Loss: -19.0621	Cost: 9.68s
Train Epoch: 1584 	Average Loss: -19.0663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3951

Learning rate: 0.00018787171574910212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1585 [0/90000 (0%)]	Loss: -13.1784	Cost: 25.16s
Train Epoch: 1585 [20480/90000 (23%)]	Loss: -19.2110	Cost: 9.32s
Train Epoch: 1585 [40960/90000 (45%)]	Loss: -18.7711	Cost: 9.33s
Train Epoch: 1585 [61440/90000 (68%)]	Loss: -18.5636	Cost: 9.09s
Train Epoch: 1585 [81920/90000 (91%)]	Loss: -18.7956	Cost: 9.60s
Train Epoch: 1585 	Average Loss: -18.4942
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6244

Learning rate: 0.0001878567152464392
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1586 [0/90000 (0%)]	Loss: -13.2193	Cost: 24.80s
Train Epoch: 1586 [20480/90000 (23%)]	Loss: -19.6569	Cost: 9.38s
Train Epoch: 1586 [40960/90000 (45%)]	Loss: -19.9620	Cost: 9.51s
Train Epoch: 1586 [61440/90000 (68%)]	Loss: -19.8269	Cost: 9.26s
Train Epoch: 1586 [81920/90000 (91%)]	Loss: -19.8210	Cost: 9.45s
Train Epoch: 1586 	Average Loss: -19.3008
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1272

Learning rate: 0.0001878417060726661
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1587 [0/90000 (0%)]	Loss: -14.0748	Cost: 27.56s
Train Epoch: 1587 [20480/90000 (23%)]	Loss: -20.1273	Cost: 9.37s
Train Epoch: 1587 [40960/90000 (45%)]	Loss: -20.0247	Cost: 9.19s
Train Epoch: 1587 [61440/90000 (68%)]	Loss: -19.8509	Cost: 9.33s
Train Epoch: 1587 [81920/90000 (91%)]	Loss: -20.0891	Cost: 9.03s
Train Epoch: 1587 	Average Loss: -19.6878
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5371

Learning rate: 0.0001878266882292642
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1588 [0/90000 (0%)]	Loss: -14.0416	Cost: 27.16s
Train Epoch: 1588 [20480/90000 (23%)]	Loss: -19.8854	Cost: 9.04s
Train Epoch: 1588 [40960/90000 (45%)]	Loss: -17.9278	Cost: 9.23s
Train Epoch: 1588 [61440/90000 (68%)]	Loss: -18.1903	Cost: 8.96s
Train Epoch: 1588 [81920/90000 (91%)]	Loss: -18.1985	Cost: 8.76s
Train Epoch: 1588 	Average Loss: -18.3320
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1810

Learning rate: 0.00018781166171771566
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1589 [0/90000 (0%)]	Loss: -11.7326	Cost: 25.03s
Train Epoch: 1589 [20480/90000 (23%)]	Loss: -19.4965	Cost: 9.04s
Train Epoch: 1589 [40960/90000 (45%)]	Loss: -19.5875	Cost: 9.08s
Train Epoch: 1589 [61440/90000 (68%)]	Loss: -19.6760	Cost: 9.04s
Train Epoch: 1589 [81920/90000 (91%)]	Loss: -19.6154	Cost: 8.71s
Train Epoch: 1589 	Average Loss: -19.0799
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1976

Learning rate: 0.00018779662653950358
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1590 [0/90000 (0%)]	Loss: -13.3295	Cost: 25.68s
Train Epoch: 1590 [20480/90000 (23%)]	Loss: -20.2710	Cost: 9.37s
Train Epoch: 1590 [40960/90000 (45%)]	Loss: -20.1671	Cost: 9.42s
Train Epoch: 1590 [61440/90000 (68%)]	Loss: -20.1580	Cost: 9.13s
Train Epoch: 1590 [81920/90000 (91%)]	Loss: -20.1881	Cost: 8.79s
Train Epoch: 1590 	Average Loss: -19.8538
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6849

Learning rate: 0.00018778158269611183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1591 [0/90000 (0%)]	Loss: -12.7349	Cost: 24.88s
Train Epoch: 1591 [20480/90000 (23%)]	Loss: -20.4091	Cost: 9.40s
Train Epoch: 1591 [40960/90000 (45%)]	Loss: -20.1619	Cost: 9.21s
Train Epoch: 1591 [61440/90000 (68%)]	Loss: -20.2013	Cost: 9.28s
Train Epoch: 1591 [81920/90000 (91%)]	Loss: -19.2770	Cost: 9.51s
Train Epoch: 1591 	Average Loss: -19.6618
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9945

Learning rate: 0.00018776653018902522
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1592 [0/90000 (0%)]	Loss: -13.6165	Cost: 25.87s
Train Epoch: 1592 [20480/90000 (23%)]	Loss: -19.5444	Cost: 9.30s
Train Epoch: 1592 [40960/90000 (45%)]	Loss: -19.0664	Cost: 9.57s
Train Epoch: 1592 [61440/90000 (68%)]	Loss: -19.2353	Cost: 9.18s
Train Epoch: 1592 [81920/90000 (91%)]	Loss: -19.2246	Cost: 8.82s
Train Epoch: 1592 	Average Loss: -18.9286
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8399

Learning rate: 0.00018775146901972933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1593 [0/90000 (0%)]	Loss: -13.1051	Cost: 24.82s
Train Epoch: 1593 [20480/90000 (23%)]	Loss: -19.8895	Cost: 9.24s
Train Epoch: 1593 [40960/90000 (45%)]	Loss: -19.4880	Cost: 9.40s
Train Epoch: 1593 [61440/90000 (68%)]	Loss: -19.7524	Cost: 9.24s
Train Epoch: 1593 [81920/90000 (91%)]	Loss: -19.2213	Cost: 8.98s
Train Epoch: 1593 	Average Loss: -19.1940
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8484

Learning rate: 0.00018773639918971073
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1594 [0/90000 (0%)]	Loss: -13.1184	Cost: 25.52s
Train Epoch: 1594 [20480/90000 (23%)]	Loss: -20.0056	Cost: 9.46s
Train Epoch: 1594 [40960/90000 (45%)]	Loss: -19.9416	Cost: 9.46s
Train Epoch: 1594 [61440/90000 (68%)]	Loss: -19.9856	Cost: 9.02s
Train Epoch: 1594 [81920/90000 (91%)]	Loss: -20.0393	Cost: 9.15s
Train Epoch: 1594 	Average Loss: -19.5452
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6061

Learning rate: 0.00018772132070045663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1595 [0/90000 (0%)]	Loss: -13.1051	Cost: 25.27s
Train Epoch: 1595 [20480/90000 (23%)]	Loss: -20.4995	Cost: 9.57s
Train Epoch: 1595 [40960/90000 (45%)]	Loss: -20.2845	Cost: 9.25s
Train Epoch: 1595 [61440/90000 (68%)]	Loss: -20.2046	Cost: 9.20s
Train Epoch: 1595 [81920/90000 (91%)]	Loss: -19.9334	Cost: 8.74s
Train Epoch: 1595 	Average Loss: -19.8933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4994

Learning rate: 0.0001877062335534553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1596 [0/90000 (0%)]	Loss: -13.1375	Cost: 25.66s
Train Epoch: 1596 [20480/90000 (23%)]	Loss: -20.4658	Cost: 9.49s
Train Epoch: 1596 [40960/90000 (45%)]	Loss: -20.5262	Cost: 9.37s
Train Epoch: 1596 [61440/90000 (68%)]	Loss: -20.4389	Cost: 9.00s
Train Epoch: 1596 [81920/90000 (91%)]	Loss: -20.5330	Cost: 9.01s
Train Epoch: 1596 	Average Loss: -20.0076
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8567

Learning rate: 0.00018769113775019572
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1597 [0/90000 (0%)]	Loss: -14.8444	Cost: 24.45s
Train Epoch: 1597 [20480/90000 (23%)]	Loss: -20.7243	Cost: 9.54s
Train Epoch: 1597 [40960/90000 (45%)]	Loss: -20.4648	Cost: 9.31s
Train Epoch: 1597 [61440/90000 (68%)]	Loss: -20.1659	Cost: 9.05s
Train Epoch: 1597 [81920/90000 (91%)]	Loss: -20.0294	Cost: 10.02s
Train Epoch: 1597 	Average Loss: -20.0734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6204

Learning rate: 0.00018767603329216783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1598 [0/90000 (0%)]	Loss: -14.5074	Cost: 23.81s
Train Epoch: 1598 [20480/90000 (23%)]	Loss: -20.5468	Cost: 9.56s
Train Epoch: 1598 [40960/90000 (45%)]	Loss: -20.5559	Cost: 9.31s
Train Epoch: 1598 [61440/90000 (68%)]	Loss: -20.0370	Cost: 9.14s
Train Epoch: 1598 [81920/90000 (91%)]	Loss: -19.9972	Cost: 10.14s
Train Epoch: 1598 	Average Loss: -19.9631
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6057

Learning rate: 0.0001876609201808624
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1599 [0/90000 (0%)]	Loss: -13.1324	Cost: 23.60s
Train Epoch: 1599 [20480/90000 (23%)]	Loss: -20.4840	Cost: 9.10s
Train Epoch: 1599 [40960/90000 (45%)]	Loss: -20.2766	Cost: 9.69s
Train Epoch: 1599 [61440/90000 (68%)]	Loss: -20.3760	Cost: 8.99s
Train Epoch: 1599 [81920/90000 (91%)]	Loss: -20.2480	Cost: 10.33s
Train Epoch: 1599 	Average Loss: -19.9387
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7011

Learning rate: 0.00018764579841777095
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1600 [0/90000 (0%)]	Loss: -13.7891	Cost: 24.88s
Train Epoch: 1600 [20480/90000 (23%)]	Loss: -20.6252	Cost: 9.03s
Train Epoch: 1600 [40960/90000 (45%)]	Loss: -20.5555	Cost: 10.11s
Train Epoch: 1600 [61440/90000 (68%)]	Loss: -20.6567	Cost: 9.04s
Train Epoch: 1600 [81920/90000 (91%)]	Loss: -20.4627	Cost: 10.38s
Train Epoch: 1600 	Average Loss: -20.1625
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8337

Saving model as model.pt_e1600 & waveforms_supplementary.hdf5_e1600
Learning rate: 0.000187630668004386
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1601 [0/90000 (0%)]	Loss: -14.3653	Cost: 25.41s
Train Epoch: 1601 [20480/90000 (23%)]	Loss: -20.8220	Cost: 9.06s
Train Epoch: 1601 [40960/90000 (45%)]	Loss: -20.4879	Cost: 9.68s
Train Epoch: 1601 [61440/90000 (68%)]	Loss: -20.3077	Cost: 9.08s
Train Epoch: 1601 [81920/90000 (91%)]	Loss: -20.2458	Cost: 10.28s
Train Epoch: 1601 	Average Loss: -20.1096
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6465

Learning rate: 0.0001876155289422009
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1602 [0/90000 (0%)]	Loss: -14.1064	Cost: 24.82s
Train Epoch: 1602 [20480/90000 (23%)]	Loss: -20.4058	Cost: 9.03s
Train Epoch: 1602 [40960/90000 (45%)]	Loss: -20.5136	Cost: 9.95s
Train Epoch: 1602 [61440/90000 (68%)]	Loss: -20.3147	Cost: 9.06s
Train Epoch: 1602 [81920/90000 (91%)]	Loss: -20.3520	Cost: 11.01s
Train Epoch: 1602 	Average Loss: -20.0660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6960

Learning rate: 0.00018760038123270977
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1603 [0/90000 (0%)]	Loss: -14.3547	Cost: 24.46s
Train Epoch: 1603 [20480/90000 (23%)]	Loss: -20.6400	Cost: 9.13s
Train Epoch: 1603 [40960/90000 (45%)]	Loss: -20.6242	Cost: 10.18s
Train Epoch: 1603 [61440/90000 (68%)]	Loss: -20.6007	Cost: 9.14s
Train Epoch: 1603 [81920/90000 (91%)]	Loss: -20.3010	Cost: 10.38s
Train Epoch: 1603 	Average Loss: -20.1094
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7674

Learning rate: 0.0001875852248774076
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1604 [0/90000 (0%)]	Loss: -13.6884	Cost: 24.34s
Train Epoch: 1604 [20480/90000 (23%)]	Loss: -20.7757	Cost: 9.39s
Train Epoch: 1604 [40960/90000 (45%)]	Loss: -20.4021	Cost: 9.60s
Train Epoch: 1604 [61440/90000 (68%)]	Loss: -20.3435	Cost: 9.53s
Train Epoch: 1604 [81920/90000 (91%)]	Loss: -20.0564	Cost: 9.23s
Train Epoch: 1604 	Average Loss: -20.1027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7921

Learning rate: 0.0001875700598777903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1605 [0/90000 (0%)]	Loss: -14.4329	Cost: 23.59s
Train Epoch: 1605 [20480/90000 (23%)]	Loss: -20.7126	Cost: 9.67s
Train Epoch: 1605 [40960/90000 (45%)]	Loss: -20.6095	Cost: 9.67s
Train Epoch: 1605 [61440/90000 (68%)]	Loss: -20.3996	Cost: 9.09s
Train Epoch: 1605 [81920/90000 (91%)]	Loss: -20.1867	Cost: 9.18s
Train Epoch: 1605 	Average Loss: -19.9873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7731

Learning rate: 0.00018755488623535457
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1606 [0/90000 (0%)]	Loss: -13.9588	Cost: 24.75s
Train Epoch: 1606 [20480/90000 (23%)]	Loss: -20.7636	Cost: 9.34s
Train Epoch: 1606 [40960/90000 (45%)]	Loss: -20.3934	Cost: 9.19s
Train Epoch: 1606 [61440/90000 (68%)]	Loss: -20.2804	Cost: 9.16s
Train Epoch: 1606 [81920/90000 (91%)]	Loss: -20.0552	Cost: 9.02s
Train Epoch: 1606 	Average Loss: -19.9917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4606

Learning rate: 0.00018753970395159802
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1607 [0/90000 (0%)]	Loss: -13.5119	Cost: 24.51s
Train Epoch: 1607 [20480/90000 (23%)]	Loss: -20.5132	Cost: 9.24s
Train Epoch: 1607 [40960/90000 (45%)]	Loss: -20.3601	Cost: 9.56s
Train Epoch: 1607 [61440/90000 (68%)]	Loss: -19.6941	Cost: 9.04s
Train Epoch: 1607 [81920/90000 (91%)]	Loss: -19.7004	Cost: 8.82s
Train Epoch: 1607 	Average Loss: -19.7137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3849

Learning rate: 0.00018752451302801905
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1608 [0/90000 (0%)]	Loss: -13.0879	Cost: 24.21s
Train Epoch: 1608 [20480/90000 (23%)]	Loss: -20.2081	Cost: 9.16s
Train Epoch: 1608 [40960/90000 (45%)]	Loss: -20.3134	Cost: 9.10s
Train Epoch: 1608 [61440/90000 (68%)]	Loss: -20.0809	Cost: 9.00s
Train Epoch: 1608 [81920/90000 (91%)]	Loss: -20.1417	Cost: 8.74s
Train Epoch: 1608 	Average Loss: -19.7127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5843

Learning rate: 0.00018750931346611698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1609 [0/90000 (0%)]	Loss: -13.8569	Cost: 25.56s
Train Epoch: 1609 [20480/90000 (23%)]	Loss: -20.5364	Cost: 9.34s
Train Epoch: 1609 [40960/90000 (45%)]	Loss: -20.1553	Cost: 9.29s
Train Epoch: 1609 [61440/90000 (68%)]	Loss: -19.8083	Cost: 9.33s
Train Epoch: 1609 [81920/90000 (91%)]	Loss: -19.8466	Cost: 8.85s
Train Epoch: 1609 	Average Loss: -19.7574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5108

Learning rate: 0.00018749410526739193
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1610 [0/90000 (0%)]	Loss: -13.7300	Cost: 25.03s
Train Epoch: 1610 [20480/90000 (23%)]	Loss: -20.4562	Cost: 9.46s
Train Epoch: 1610 [40960/90000 (45%)]	Loss: -20.3806	Cost: 9.27s
Train Epoch: 1610 [61440/90000 (68%)]	Loss: -20.4486	Cost: 9.26s
Train Epoch: 1610 [81920/90000 (91%)]	Loss: -20.2324	Cost: 8.93s
Train Epoch: 1610 	Average Loss: -19.9223
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6088

Learning rate: 0.0001874788884333449
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1611 [0/90000 (0%)]	Loss: -14.2710	Cost: 24.72s
Train Epoch: 1611 [20480/90000 (23%)]	Loss: -20.4758	Cost: 9.26s
Train Epoch: 1611 [40960/90000 (45%)]	Loss: -20.6096	Cost: 9.89s
Train Epoch: 1611 [61440/90000 (68%)]	Loss: -20.2051	Cost: 9.13s
Train Epoch: 1611 [81920/90000 (91%)]	Loss: -19.9792	Cost: 8.94s
Train Epoch: 1611 	Average Loss: -19.9688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5140

Learning rate: 0.0001874636629654777
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1612 [0/90000 (0%)]	Loss: -13.2874	Cost: 24.89s
Train Epoch: 1612 [20480/90000 (23%)]	Loss: -20.2262	Cost: 9.17s
Train Epoch: 1612 [40960/90000 (45%)]	Loss: -20.3110	Cost: 9.38s
Train Epoch: 1612 [61440/90000 (68%)]	Loss: -20.2557	Cost: 9.15s
Train Epoch: 1612 [81920/90000 (91%)]	Loss: -20.0843	Cost: 9.13s
Train Epoch: 1612 	Average Loss: -19.9280
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6657

Learning rate: 0.00018744842886529302
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1613 [0/90000 (0%)]	Loss: -14.3821	Cost: 25.03s
Train Epoch: 1613 [20480/90000 (23%)]	Loss: -20.5342	Cost: 9.36s
Train Epoch: 1613 [40960/90000 (45%)]	Loss: -20.3158	Cost: 9.44s
Train Epoch: 1613 [61440/90000 (68%)]	Loss: -20.2925	Cost: 9.16s
Train Epoch: 1613 [81920/90000 (91%)]	Loss: -19.6004	Cost: 8.74s
Train Epoch: 1613 	Average Loss: -19.8235
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4815

Learning rate: 0.00018743318613429448
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1614 [0/90000 (0%)]	Loss: -12.8256	Cost: 25.28s
Train Epoch: 1614 [20480/90000 (23%)]	Loss: -20.4587	Cost: 9.58s
Train Epoch: 1614 [40960/90000 (45%)]	Loss: -19.9725	Cost: 9.24s
Train Epoch: 1614 [61440/90000 (68%)]	Loss: -20.1876	Cost: 8.99s
Train Epoch: 1614 [81920/90000 (91%)]	Loss: -19.7756	Cost: 9.02s
Train Epoch: 1614 	Average Loss: -19.6846
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1673

Learning rate: 0.0001874179347739864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1615 [0/90000 (0%)]	Loss: -13.6836	Cost: 24.77s
Train Epoch: 1615 [20480/90000 (23%)]	Loss: -19.9821	Cost: 9.43s
Train Epoch: 1615 [40960/90000 (45%)]	Loss: -19.9277	Cost: 9.62s
Train Epoch: 1615 [61440/90000 (68%)]	Loss: -20.1424	Cost: 8.99s
Train Epoch: 1615 [81920/90000 (91%)]	Loss: -20.0077	Cost: 9.90s
Train Epoch: 1615 	Average Loss: -19.6681
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5158

Learning rate: 0.00018740267478587405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1616 [0/90000 (0%)]	Loss: -14.0610	Cost: 24.08s
Train Epoch: 1616 [20480/90000 (23%)]	Loss: -20.5191	Cost: 9.02s
Train Epoch: 1616 [40960/90000 (45%)]	Loss: -20.3790	Cost: 9.91s
Train Epoch: 1616 [61440/90000 (68%)]	Loss: -20.3617	Cost: 9.02s
Train Epoch: 1616 [81920/90000 (91%)]	Loss: -20.2936	Cost: 10.32s
Train Epoch: 1616 	Average Loss: -19.8835
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6820

Learning rate: 0.00018738740617146353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1617 [0/90000 (0%)]	Loss: -14.0842	Cost: 24.89s
Train Epoch: 1617 [20480/90000 (23%)]	Loss: -20.5940	Cost: 9.45s
Train Epoch: 1617 [40960/90000 (45%)]	Loss: -20.3726	Cost: 9.45s
Train Epoch: 1617 [61440/90000 (68%)]	Loss: -20.3982	Cost: 9.08s
Train Epoch: 1617 [81920/90000 (91%)]	Loss: -20.3737	Cost: 10.19s
Train Epoch: 1617 	Average Loss: -19.9827
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8013

Learning rate: 0.0001873721289322618
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1618 [0/90000 (0%)]	Loss: -13.5373	Cost: 23.38s
Train Epoch: 1618 [20480/90000 (23%)]	Loss: -20.5898	Cost: 9.03s
Train Epoch: 1618 [40960/90000 (45%)]	Loss: -20.2016	Cost: 9.12s
Train Epoch: 1618 [61440/90000 (68%)]	Loss: -20.4485	Cost: 9.06s
Train Epoch: 1618 [81920/90000 (91%)]	Loss: -20.1264	Cost: 10.27s
Train Epoch: 1618 	Average Loss: -19.9974
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8373

Learning rate: 0.00018735684306977666
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1619 [0/90000 (0%)]	Loss: -14.8029	Cost: 22.91s
Train Epoch: 1619 [20480/90000 (23%)]	Loss: -20.2790	Cost: 9.03s
Train Epoch: 1619 [40960/90000 (45%)]	Loss: -20.2639	Cost: 9.00s
Train Epoch: 1619 [61440/90000 (68%)]	Loss: -20.3510	Cost: 9.07s
Train Epoch: 1619 [81920/90000 (91%)]	Loss: -20.2399	Cost: 9.10s
Train Epoch: 1619 	Average Loss: -19.9949
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8138

Learning rate: 0.00018734154858551677
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1620 [0/90000 (0%)]	Loss: -13.8582	Cost: 23.41s
Train Epoch: 1620 [20480/90000 (23%)]	Loss: -20.6248	Cost: 9.17s
Train Epoch: 1620 [40960/90000 (45%)]	Loss: -20.4353	Cost: 9.26s
Train Epoch: 1620 [61440/90000 (68%)]	Loss: -20.2542	Cost: 9.07s
Train Epoch: 1620 [81920/90000 (91%)]	Loss: -20.2577	Cost: 9.01s
Train Epoch: 1620 	Average Loss: -20.0201
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7218

Learning rate: 0.00018732624548099163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1621 [0/90000 (0%)]	Loss: -14.1372	Cost: 23.77s
Train Epoch: 1621 [20480/90000 (23%)]	Loss: -20.6421	Cost: 9.08s
Train Epoch: 1621 [40960/90000 (45%)]	Loss: -20.2652	Cost: 9.12s
Train Epoch: 1621 [61440/90000 (68%)]	Loss: -20.2069	Cost: 8.98s
Train Epoch: 1621 [81920/90000 (91%)]	Loss: -20.2340	Cost: 8.87s
Train Epoch: 1621 	Average Loss: -19.9362
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8527

Learning rate: 0.00018731093375771158
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1622 [0/90000 (0%)]	Loss: -13.6945	Cost: 24.09s
Train Epoch: 1622 [20480/90000 (23%)]	Loss: -20.3902	Cost: 9.30s
Train Epoch: 1622 [40960/90000 (45%)]	Loss: -20.2790	Cost: 9.27s
Train Epoch: 1622 [61440/90000 (68%)]	Loss: -20.1427	Cost: 9.16s
Train Epoch: 1622 [81920/90000 (91%)]	Loss: -19.7622	Cost: 8.77s
Train Epoch: 1622 	Average Loss: -19.8234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2242

Learning rate: 0.00018729561341718784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1623 [0/90000 (0%)]	Loss: -12.7472	Cost: 25.53s
Train Epoch: 1623 [20480/90000 (23%)]	Loss: -20.0877	Cost: 9.37s
Train Epoch: 1623 [40960/90000 (45%)]	Loss: -19.9868	Cost: 9.37s
Train Epoch: 1623 [61440/90000 (68%)]	Loss: -19.7264	Cost: 9.15s
Train Epoch: 1623 [81920/90000 (91%)]	Loss: -19.8520	Cost: 9.00s
Train Epoch: 1623 	Average Loss: -19.5446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3823

Learning rate: 0.0001872802844609325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1624 [0/90000 (0%)]	Loss: -13.9833	Cost: 26.79s
Train Epoch: 1624 [20480/90000 (23%)]	Loss: -20.1636	Cost: 10.01s
Train Epoch: 1624 [40960/90000 (45%)]	Loss: -20.0833	Cost: 10.04s
Train Epoch: 1624 [61440/90000 (68%)]	Loss: -20.2376	Cost: 9.25s
Train Epoch: 1624 [81920/90000 (91%)]	Loss: -20.0744	Cost: 8.77s
Train Epoch: 1624 	Average Loss: -19.7960
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3344

Learning rate: 0.00018726494689045838
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1625 [0/90000 (0%)]	Loss: -13.0535	Cost: 25.13s
Train Epoch: 1625 [20480/90000 (23%)]	Loss: -20.4501	Cost: 9.41s
Train Epoch: 1625 [40960/90000 (45%)]	Loss: -20.6443	Cost: 9.34s
Train Epoch: 1625 [61440/90000 (68%)]	Loss: -19.9745	Cost: 9.17s
Train Epoch: 1625 [81920/90000 (91%)]	Loss: -19.8586	Cost: 8.93s
Train Epoch: 1625 	Average Loss: -19.9296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2126

Learning rate: 0.00018724960070727934
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1626 [0/90000 (0%)]	Loss: -13.5625	Cost: 24.55s
Train Epoch: 1626 [20480/90000 (23%)]	Loss: -20.1784	Cost: 9.46s
Train Epoch: 1626 [40960/90000 (45%)]	Loss: -20.2303	Cost: 9.29s
Train Epoch: 1626 [61440/90000 (68%)]	Loss: -20.2987	Cost: 9.13s
Train Epoch: 1626 [81920/90000 (91%)]	Loss: -20.4064	Cost: 8.77s
Train Epoch: 1626 	Average Loss: -19.8901
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7295

Learning rate: 0.0001872342459129099
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1627 [0/90000 (0%)]	Loss: -13.4347	Cost: 25.42s
Train Epoch: 1627 [20480/90000 (23%)]	Loss: -20.6511	Cost: 9.46s
Train Epoch: 1627 [40960/90000 (45%)]	Loss: -20.4417	Cost: 9.27s
Train Epoch: 1627 [61440/90000 (68%)]	Loss: -20.5796	Cost: 9.35s
Train Epoch: 1627 [81920/90000 (91%)]	Loss: -20.2397	Cost: 8.85s
Train Epoch: 1627 	Average Loss: -20.0769
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5998

Learning rate: 0.00018721888250886555
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1628 [0/90000 (0%)]	Loss: -13.9901	Cost: 25.03s
Train Epoch: 1628 [20480/90000 (23%)]	Loss: -20.7245	Cost: 9.47s
Train Epoch: 1628 [40960/90000 (45%)]	Loss: -20.5241	Cost: 9.28s
Train Epoch: 1628 [61440/90000 (68%)]	Loss: -20.1581	Cost: 9.02s
Train Epoch: 1628 [81920/90000 (91%)]	Loss: -20.2330	Cost: 9.12s
Train Epoch: 1628 	Average Loss: -20.0675
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4503

Learning rate: 0.00018720351049666265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1629 [0/90000 (0%)]	Loss: -13.8761	Cost: 25.13s
Train Epoch: 1629 [20480/90000 (23%)]	Loss: -20.6448	Cost: 9.44s
Train Epoch: 1629 [40960/90000 (45%)]	Loss: -20.4952	Cost: 9.32s
Train Epoch: 1629 [61440/90000 (68%)]	Loss: -20.1109	Cost: 9.19s
Train Epoch: 1629 [81920/90000 (91%)]	Loss: -20.2390	Cost: 8.90s
Train Epoch: 1629 	Average Loss: -20.0020
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5352

Learning rate: 0.0001871881298778183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1630 [0/90000 (0%)]	Loss: -13.4195	Cost: 25.15s
Train Epoch: 1630 [20480/90000 (23%)]	Loss: -20.2551	Cost: 9.66s
Train Epoch: 1630 [40960/90000 (45%)]	Loss: -20.2957	Cost: 9.24s
Train Epoch: 1630 [61440/90000 (68%)]	Loss: -20.1644	Cost: 8.99s
Train Epoch: 1630 [81920/90000 (91%)]	Loss: -20.1725	Cost: 8.73s
Train Epoch: 1630 	Average Loss: -19.7920
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7736

Learning rate: 0.0001871727406538505
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1631 [0/90000 (0%)]	Loss: -13.5848	Cost: 27.68s
Train Epoch: 1631 [20480/90000 (23%)]	Loss: -20.6838	Cost: 9.26s
Train Epoch: 1631 [40960/90000 (45%)]	Loss: -20.4784	Cost: 9.50s
Train Epoch: 1631 [61440/90000 (68%)]	Loss: -20.6313	Cost: 9.08s
Train Epoch: 1631 [81920/90000 (91%)]	Loss: -20.2559	Cost: 9.06s
Train Epoch: 1631 	Average Loss: -20.1040
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6618

Learning rate: 0.0001871573428262781
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1632 [0/90000 (0%)]	Loss: -13.9898	Cost: 24.90s
Train Epoch: 1632 [20480/90000 (23%)]	Loss: -20.8242	Cost: 9.51s
Train Epoch: 1632 [40960/90000 (45%)]	Loss: -20.7125	Cost: 9.32s
Train Epoch: 1632 [61440/90000 (68%)]	Loss: -20.3167	Cost: 9.04s
Train Epoch: 1632 [81920/90000 (91%)]	Loss: -20.3235	Cost: 9.95s
Train Epoch: 1632 	Average Loss: -20.1664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8786

Learning rate: 0.00018714193639662085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1633 [0/90000 (0%)]	Loss: -13.5103	Cost: 24.48s
Train Epoch: 1633 [20480/90000 (23%)]	Loss: -20.4652	Cost: 9.03s
Train Epoch: 1633 [40960/90000 (45%)]	Loss: -20.2243	Cost: 9.75s
Train Epoch: 1633 [61440/90000 (68%)]	Loss: -20.4890	Cost: 9.11s
Train Epoch: 1633 [81920/90000 (91%)]	Loss: -20.1431	Cost: 10.02s
Train Epoch: 1633 	Average Loss: -19.9876
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4142

Learning rate: 0.0001871265213663993
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1634 [0/90000 (0%)]	Loss: -13.7491	Cost: 25.23s
Train Epoch: 1634 [20480/90000 (23%)]	Loss: -20.5955	Cost: 9.39s
Train Epoch: 1634 [40960/90000 (45%)]	Loss: -20.3004	Cost: 9.29s
Train Epoch: 1634 [61440/90000 (68%)]	Loss: -20.1547	Cost: 9.08s
Train Epoch: 1634 [81920/90000 (91%)]	Loss: -20.2014	Cost: 10.08s
Train Epoch: 1634 	Average Loss: -19.9587
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6799

Learning rate: 0.00018711109773713482
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1635 [0/90000 (0%)]	Loss: -13.8765	Cost: 24.88s
Train Epoch: 1635 [20480/90000 (23%)]	Loss: -20.4615	Cost: 9.10s
Train Epoch: 1635 [40960/90000 (45%)]	Loss: -20.1563	Cost: 9.81s
Train Epoch: 1635 [61440/90000 (68%)]	Loss: -20.1250	Cost: 9.06s
Train Epoch: 1635 [81920/90000 (91%)]	Loss: -20.0617	Cost: 10.20s
Train Epoch: 1635 	Average Loss: -19.9159
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5607

Learning rate: 0.00018709566551034968
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1636 [0/90000 (0%)]	Loss: -13.6364	Cost: 23.41s
Train Epoch: 1636 [20480/90000 (23%)]	Loss: -20.4233	Cost: 9.04s
Train Epoch: 1636 [40960/90000 (45%)]	Loss: -20.3041	Cost: 9.14s
Train Epoch: 1636 [61440/90000 (68%)]	Loss: -20.5502	Cost: 9.05s
Train Epoch: 1636 [81920/90000 (91%)]	Loss: -20.3457	Cost: 9.28s
Train Epoch: 1636 	Average Loss: -20.0629
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7047

Learning rate: 0.00018708022468756698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1637 [0/90000 (0%)]	Loss: -14.6995	Cost: 25.03s
Train Epoch: 1637 [20480/90000 (23%)]	Loss: -20.7737	Cost: 9.12s
Train Epoch: 1637 [40960/90000 (45%)]	Loss: -20.4095	Cost: 10.08s
Train Epoch: 1637 [61440/90000 (68%)]	Loss: -19.7621	Cost: 9.08s
Train Epoch: 1637 [81920/90000 (91%)]	Loss: -19.7403	Cost: 10.91s
Train Epoch: 1637 	Average Loss: -19.9252
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4090

Learning rate: 0.00018706477527031065
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1638 [0/90000 (0%)]	Loss: -13.9311	Cost: 24.38s
Train Epoch: 1638 [20480/90000 (23%)]	Loss: -20.3180	Cost: 9.06s
Train Epoch: 1638 [40960/90000 (45%)]	Loss: -20.2118	Cost: 9.69s
Train Epoch: 1638 [61440/90000 (68%)]	Loss: -20.2818	Cost: 9.10s
Train Epoch: 1638 [81920/90000 (91%)]	Loss: -20.3169	Cost: 10.27s
Train Epoch: 1638 	Average Loss: -19.8586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7362

Learning rate: 0.0001870493172601055
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1639 [0/90000 (0%)]	Loss: -14.0336	Cost: 24.03s
Train Epoch: 1639 [20480/90000 (23%)]	Loss: -20.6205	Cost: 9.75s
Train Epoch: 1639 [40960/90000 (45%)]	Loss: -20.4087	Cost: 9.60s
Train Epoch: 1639 [61440/90000 (68%)]	Loss: -20.3777	Cost: 9.22s
Train Epoch: 1639 [81920/90000 (91%)]	Loss: -20.2797	Cost: 9.13s
Train Epoch: 1639 	Average Loss: -20.0563
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9634

Learning rate: 0.0001870338506584772
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1640 [0/90000 (0%)]	Loss: -13.9680	Cost: 23.86s
Train Epoch: 1640 [20480/90000 (23%)]	Loss: -20.6137	Cost: 9.40s
Train Epoch: 1640 [40960/90000 (45%)]	Loss: -20.2981	Cost: 9.29s
Train Epoch: 1640 [61440/90000 (68%)]	Loss: -20.4522	Cost: 9.15s
Train Epoch: 1640 [81920/90000 (91%)]	Loss: -20.1040	Cost: 9.13s
Train Epoch: 1640 	Average Loss: -20.0100
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4063

Learning rate: 0.00018701837546695218
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1641 [0/90000 (0%)]	Loss: -14.0561	Cost: 24.67s
Train Epoch: 1641 [20480/90000 (23%)]	Loss: -20.2839	Cost: 9.37s
Train Epoch: 1641 [40960/90000 (45%)]	Loss: -19.8522	Cost: 9.97s
Train Epoch: 1641 [61440/90000 (68%)]	Loss: -19.9699	Cost: 9.11s
Train Epoch: 1641 [81920/90000 (91%)]	Loss: -20.1416	Cost: 9.20s
Train Epoch: 1641 	Average Loss: -19.6561
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4909

Learning rate: 0.00018700289168705782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1642 [0/90000 (0%)]	Loss: -14.0231	Cost: 24.87s
Train Epoch: 1642 [20480/90000 (23%)]	Loss: -20.4898	Cost: 9.41s
Train Epoch: 1642 [40960/90000 (45%)]	Loss: -20.1140	Cost: 9.27s
Train Epoch: 1642 [61440/90000 (68%)]	Loss: -20.2313	Cost: 9.13s
Train Epoch: 1642 [81920/90000 (91%)]	Loss: -19.9455	Cost: 9.13s
Train Epoch: 1642 	Average Loss: -19.8369
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6324

Learning rate: 0.00018698739932032228
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1643 [0/90000 (0%)]	Loss: -13.8346	Cost: 24.42s
Train Epoch: 1643 [20480/90000 (23%)]	Loss: -20.5266	Cost: 9.30s
Train Epoch: 1643 [40960/90000 (45%)]	Loss: -20.2492	Cost: 9.24s
Train Epoch: 1643 [61440/90000 (68%)]	Loss: -20.4893	Cost: 9.21s
Train Epoch: 1643 [81920/90000 (91%)]	Loss: -20.2180	Cost: 9.08s
Train Epoch: 1643 	Average Loss: -19.9772
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7069

Learning rate: 0.00018697189836827465
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1644 [0/90000 (0%)]	Loss: -13.5349	Cost: 25.39s
Train Epoch: 1644 [20480/90000 (23%)]	Loss: -20.5278	Cost: 9.47s
Train Epoch: 1644 [40960/90000 (45%)]	Loss: -20.0344	Cost: 9.33s
Train Epoch: 1644 [61440/90000 (68%)]	Loss: -19.9405	Cost: 9.12s
Train Epoch: 1644 [81920/90000 (91%)]	Loss: -20.0818	Cost: 8.91s
Train Epoch: 1644 	Average Loss: -19.8366
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7407

Learning rate: 0.0001869563888324448
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1645 [0/90000 (0%)]	Loss: -13.9468	Cost: 25.92s
Train Epoch: 1645 [20480/90000 (23%)]	Loss: -20.7413	Cost: 9.46s
Train Epoch: 1645 [40960/90000 (45%)]	Loss: -20.5963	Cost: 9.30s
Train Epoch: 1645 [61440/90000 (68%)]	Loss: -20.4510	Cost: 9.13s
Train Epoch: 1645 [81920/90000 (91%)]	Loss: -20.4338	Cost: 9.14s
Train Epoch: 1645 	Average Loss: -20.1585
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9586

Learning rate: 0.0001869408707143634
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1646 [0/90000 (0%)]	Loss: -14.8955	Cost: 26.93s
Train Epoch: 1646 [20480/90000 (23%)]	Loss: -20.8662	Cost: 9.34s
Train Epoch: 1646 [40960/90000 (45%)]	Loss: -20.3780	Cost: 9.79s
Train Epoch: 1646 [61440/90000 (68%)]	Loss: -20.2285	Cost: 9.55s
Train Epoch: 1646 [81920/90000 (91%)]	Loss: -20.0638	Cost: 8.90s
Train Epoch: 1646 	Average Loss: -20.0657
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6823

Learning rate: 0.00018692534401556208
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1647 [0/90000 (0%)]	Loss: -12.7752	Cost: 25.54s
Train Epoch: 1647 [20480/90000 (23%)]	Loss: -20.5022	Cost: 9.35s
Train Epoch: 1647 [40960/90000 (45%)]	Loss: -20.3509	Cost: 9.36s
Train Epoch: 1647 [61440/90000 (68%)]	Loss: -20.5056	Cost: 9.15s
Train Epoch: 1647 [81920/90000 (91%)]	Loss: -20.3953	Cost: 8.94s
Train Epoch: 1647 	Average Loss: -19.9593
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7278

Learning rate: 0.00018690980873757327
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1648 [0/90000 (0%)]	Loss: -14.4298	Cost: 25.62s
Train Epoch: 1648 [20480/90000 (23%)]	Loss: -20.4603	Cost: 9.40s
Train Epoch: 1648 [40960/90000 (45%)]	Loss: -19.9642	Cost: 9.19s
Train Epoch: 1648 [61440/90000 (68%)]	Loss: -19.8762	Cost: 9.12s
Train Epoch: 1648 [81920/90000 (91%)]	Loss: -19.9009	Cost: 8.83s
Train Epoch: 1648 	Average Loss: -19.8355
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6474

Learning rate: 0.00018689426488193022
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1649 [0/90000 (0%)]	Loss: -13.7058	Cost: 26.86s
Train Epoch: 1649 [20480/90000 (23%)]	Loss: -20.1689	Cost: 9.31s
Train Epoch: 1649 [40960/90000 (45%)]	Loss: -20.1033	Cost: 9.29s
Train Epoch: 1649 [61440/90000 (68%)]	Loss: -20.4608	Cost: 9.12s
Train Epoch: 1649 [81920/90000 (91%)]	Loss: -20.1992	Cost: 8.81s
Train Epoch: 1649 	Average Loss: -19.8433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7930

Learning rate: 0.00018687871245016703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1650 [0/90000 (0%)]	Loss: -14.1639	Cost: 25.52s
Train Epoch: 1650 [20480/90000 (23%)]	Loss: -20.5762	Cost: 9.28s
Train Epoch: 1650 [40960/90000 (45%)]	Loss: -20.3401	Cost: 9.46s
Train Epoch: 1650 [61440/90000 (68%)]	Loss: -20.4704	Cost: 9.19s
Train Epoch: 1650 [81920/90000 (91%)]	Loss: -20.5060	Cost: 8.82s
Train Epoch: 1650 	Average Loss: -20.0735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9985

Saving model as model.pt_e1650 & waveforms_supplementary.hdf5_e1650
Learning rate: 0.00018686315144381872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1651 [0/90000 (0%)]	Loss: -14.5821	Cost: 26.23s
Train Epoch: 1651 [20480/90000 (23%)]	Loss: -20.9184	Cost: 9.34s
Train Epoch: 1651 [40960/90000 (45%)]	Loss: -20.4861	Cost: 9.50s
Train Epoch: 1651 [61440/90000 (68%)]	Loss: -20.4922	Cost: 9.06s
Train Epoch: 1651 [81920/90000 (91%)]	Loss: -20.5620	Cost: 8.80s
Train Epoch: 1651 	Average Loss: -20.2808
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0460

Learning rate: 0.000186847581864421
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1652 [0/90000 (0%)]	Loss: -14.3586	Cost: 25.96s
Train Epoch: 1652 [20480/90000 (23%)]	Loss: -20.8371	Cost: 9.31s
Train Epoch: 1652 [40960/90000 (45%)]	Loss: -20.8973	Cost: 9.36s
Train Epoch: 1652 [61440/90000 (68%)]	Loss: -20.5725	Cost: 9.28s
Train Epoch: 1652 [81920/90000 (91%)]	Loss: -19.9270	Cost: 9.35s
Train Epoch: 1652 	Average Loss: -20.3013
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4442

Learning rate: 0.00018683200371351065
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1653 [0/90000 (0%)]	Loss: -12.6645	Cost: 25.42s
Train Epoch: 1653 [20480/90000 (23%)]	Loss: -20.1592	Cost: 9.42s
Train Epoch: 1653 [40960/90000 (45%)]	Loss: -20.1538	Cost: 9.66s
Train Epoch: 1653 [61440/90000 (68%)]	Loss: -20.0117	Cost: 9.13s
Train Epoch: 1653 [81920/90000 (91%)]	Loss: -20.2639	Cost: 8.94s
Train Epoch: 1653 	Average Loss: -19.6990
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6772

Learning rate: 0.00018681641699262508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1654 [0/90000 (0%)]	Loss: -13.9100	Cost: 25.28s
Train Epoch: 1654 [20480/90000 (23%)]	Loss: -20.6318	Cost: 9.39s
Train Epoch: 1654 [40960/90000 (45%)]	Loss: -20.4238	Cost: 9.29s
Train Epoch: 1654 [61440/90000 (68%)]	Loss: -20.4725	Cost: 9.08s
Train Epoch: 1654 [81920/90000 (91%)]	Loss: -20.4555	Cost: 8.83s
Train Epoch: 1654 	Average Loss: -20.1377
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8602

Learning rate: 0.0001868008217033027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1655 [0/90000 (0%)]	Loss: -13.5150	Cost: 26.39s
Train Epoch: 1655 [20480/90000 (23%)]	Loss: -20.2505	Cost: 9.13s
Train Epoch: 1655 [40960/90000 (45%)]	Loss: -19.9364	Cost: 9.90s
Train Epoch: 1655 [61440/90000 (68%)]	Loss: -20.1845	Cost: 9.29s
Train Epoch: 1655 [81920/90000 (91%)]	Loss: -20.0508	Cost: 8.84s
Train Epoch: 1655 	Average Loss: -19.8018
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8018

Learning rate: 0.00018678521784708263
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1656 [0/90000 (0%)]	Loss: -13.9611	Cost: 25.16s
Train Epoch: 1656 [20480/90000 (23%)]	Loss: -20.6498	Cost: 9.71s
Train Epoch: 1656 [40960/90000 (45%)]	Loss: -20.4208	Cost: 9.37s
Train Epoch: 1656 [61440/90000 (68%)]	Loss: -20.2063	Cost: 8.99s
Train Epoch: 1656 [81920/90000 (91%)]	Loss: -20.1431	Cost: 8.73s
Train Epoch: 1656 	Average Loss: -20.0517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8121

Learning rate: 0.00018676960542550494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1657 [0/90000 (0%)]	Loss: -14.5051	Cost: 24.85s
Train Epoch: 1657 [20480/90000 (23%)]	Loss: -20.7366	Cost: 9.57s
Train Epoch: 1657 [40960/90000 (45%)]	Loss: -20.4848	Cost: 9.23s
Train Epoch: 1657 [61440/90000 (68%)]	Loss: -20.1923	Cost: 9.20s
Train Epoch: 1657 [81920/90000 (91%)]	Loss: -20.4033	Cost: 9.11s
Train Epoch: 1657 	Average Loss: -20.1684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9467

Learning rate: 0.00018675398444011054
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1658 [0/90000 (0%)]	Loss: -14.3825	Cost: 24.10s
Train Epoch: 1658 [20480/90000 (23%)]	Loss: -20.5553	Cost: 9.52s
Train Epoch: 1658 [40960/90000 (45%)]	Loss: -20.2439	Cost: 9.29s
Train Epoch: 1658 [61440/90000 (68%)]	Loss: -20.1077	Cost: 9.03s
Train Epoch: 1658 [81920/90000 (91%)]	Loss: -20.0339	Cost: 10.16s
Train Epoch: 1658 	Average Loss: -19.8241
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4850

Learning rate: 0.00018673835489244116
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1659 [0/90000 (0%)]	Loss: -13.5690	Cost: 25.17s
Train Epoch: 1659 [20480/90000 (23%)]	Loss: -20.6220	Cost: 9.54s
Train Epoch: 1659 [40960/90000 (45%)]	Loss: -20.3613	Cost: 9.36s
Train Epoch: 1659 [61440/90000 (68%)]	Loss: -20.4695	Cost: 9.09s
Train Epoch: 1659 [81920/90000 (91%)]	Loss: -20.4080	Cost: 10.28s
Train Epoch: 1659 	Average Loss: -20.0289
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7049

Learning rate: 0.00018672271678403936
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1660 [0/90000 (0%)]	Loss: -14.1272	Cost: 24.49s
Train Epoch: 1660 [20480/90000 (23%)]	Loss: -20.4091	Cost: 9.04s
Train Epoch: 1660 [40960/90000 (45%)]	Loss: -20.2514	Cost: 10.18s
Train Epoch: 1660 [61440/90000 (68%)]	Loss: -20.1635	Cost: 9.02s
Train Epoch: 1660 [81920/90000 (91%)]	Loss: -20.0952	Cost: 10.41s
Train Epoch: 1660 	Average Loss: -19.8547
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8564

Learning rate: 0.00018670707011644852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1661 [0/90000 (0%)]	Loss: -14.3075	Cost: 23.31s
Train Epoch: 1661 [20480/90000 (23%)]	Loss: -20.5738	Cost: 9.35s
Train Epoch: 1661 [40960/90000 (45%)]	Loss: -20.4925	Cost: 9.27s
Train Epoch: 1661 [61440/90000 (68%)]	Loss: -20.1961	Cost: 9.12s
Train Epoch: 1661 [81920/90000 (91%)]	Loss: -20.2565	Cost: 9.28s
Train Epoch: 1661 	Average Loss: -20.0715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9525

Learning rate: 0.00018669141489121297
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1662 [0/90000 (0%)]	Loss: -13.9661	Cost: 24.24s
Train Epoch: 1662 [20480/90000 (23%)]	Loss: -20.7029	Cost: 9.08s
Train Epoch: 1662 [40960/90000 (45%)]	Loss: -20.6344	Cost: 9.99s
Train Epoch: 1662 [61440/90000 (68%)]	Loss: -20.3859	Cost: 9.23s
Train Epoch: 1662 [81920/90000 (91%)]	Loss: -20.3053	Cost: 10.06s
Train Epoch: 1662 	Average Loss: -20.1229
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8146

Learning rate: 0.0001866757511098778
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1663 [0/90000 (0%)]	Loss: -13.8995	Cost: 23.31s
Train Epoch: 1663 [20480/90000 (23%)]	Loss: -20.6144	Cost: 9.38s
Train Epoch: 1663 [40960/90000 (45%)]	Loss: -20.6966	Cost: 9.15s
Train Epoch: 1663 [61440/90000 (68%)]	Loss: -19.6027	Cost: 9.10s
Train Epoch: 1663 [81920/90000 (91%)]	Loss: -19.6177	Cost: 9.28s
Train Epoch: 1663 	Average Loss: -19.8887
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1170

Learning rate: 0.00018666007877398894
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1664 [0/90000 (0%)]	Loss: -13.8100	Cost: 24.14s
Train Epoch: 1664 [20480/90000 (23%)]	Loss: -20.0615	Cost: 9.12s
Train Epoch: 1664 [40960/90000 (45%)]	Loss: -20.0775	Cost: 9.20s
Train Epoch: 1664 [61440/90000 (68%)]	Loss: -19.9034	Cost: 8.96s
Train Epoch: 1664 [81920/90000 (91%)]	Loss: -20.0153	Cost: 8.93s
Train Epoch: 1664 	Average Loss: -19.5702
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3285

Learning rate: 0.00018664439788509322
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1665 [0/90000 (0%)]	Loss: -13.4312	Cost: 25.03s
Train Epoch: 1665 [20480/90000 (23%)]	Loss: -20.3288	Cost: 9.05s
Train Epoch: 1665 [40960/90000 (45%)]	Loss: -20.3610	Cost: 9.05s
Train Epoch: 1665 [61440/90000 (68%)]	Loss: -20.3272	Cost: 8.99s
Train Epoch: 1665 [81920/90000 (91%)]	Loss: -20.1519	Cost: 8.78s
Train Epoch: 1665 	Average Loss: -19.8485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4665

Learning rate: 0.00018662870844473827
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1666 [0/90000 (0%)]	Loss: -13.8132	Cost: 24.55s
Train Epoch: 1666 [20480/90000 (23%)]	Loss: -20.4076	Cost: 9.25s
Train Epoch: 1666 [40960/90000 (45%)]	Loss: -20.3065	Cost: 9.27s
Train Epoch: 1666 [61440/90000 (68%)]	Loss: -20.3763	Cost: 9.01s
Train Epoch: 1666 [81920/90000 (91%)]	Loss: -19.9743	Cost: 8.73s
Train Epoch: 1666 	Average Loss: -19.9773
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4299

Learning rate: 0.00018661301045447254
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1667 [0/90000 (0%)]	Loss: -14.1925	Cost: 25.51s
Train Epoch: 1667 [20480/90000 (23%)]	Loss: -20.5751	Cost: 9.39s
Train Epoch: 1667 [40960/90000 (45%)]	Loss: -20.5205	Cost: 9.28s
Train Epoch: 1667 [61440/90000 (68%)]	Loss: -20.2451	Cost: 9.21s
Train Epoch: 1667 [81920/90000 (91%)]	Loss: -20.1404	Cost: 8.94s
Train Epoch: 1667 	Average Loss: -19.9335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0583

Learning rate: 0.00018659730391584541
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1668 [0/90000 (0%)]	Loss: -12.5781	Cost: 25.63s
Train Epoch: 1668 [20480/90000 (23%)]	Loss: -20.1569	Cost: 9.44s
Train Epoch: 1668 [40960/90000 (45%)]	Loss: -20.1606	Cost: 9.28s
Train Epoch: 1668 [61440/90000 (68%)]	Loss: -20.2969	Cost: 9.13s
Train Epoch: 1668 [81920/90000 (91%)]	Loss: -20.3472	Cost: 8.86s
Train Epoch: 1668 	Average Loss: -19.7545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3834

Learning rate: 0.00018658158883040702
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1669 [0/90000 (0%)]	Loss: -13.5310	Cost: 25.12s
Train Epoch: 1669 [20480/90000 (23%)]	Loss: -20.0755	Cost: 9.41s
Train Epoch: 1669 [40960/90000 (45%)]	Loss: -20.1562	Cost: 9.33s
Train Epoch: 1669 [61440/90000 (68%)]	Loss: -20.2530	Cost: 9.24s
Train Epoch: 1669 [81920/90000 (91%)]	Loss: -20.2652	Cost: 9.01s
Train Epoch: 1669 	Average Loss: -19.7823
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4014

Learning rate: 0.00018656586519970837
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1670 [0/90000 (0%)]	Loss: -13.9288	Cost: 27.00s
Train Epoch: 1670 [20480/90000 (23%)]	Loss: -20.1480	Cost: 9.27s
Train Epoch: 1670 [40960/90000 (45%)]	Loss: -20.0140	Cost: 10.15s
Train Epoch: 1670 [61440/90000 (68%)]	Loss: -20.2521	Cost: 9.43s
Train Epoch: 1670 [81920/90000 (91%)]	Loss: -20.3149	Cost: 8.93s
Train Epoch: 1670 	Average Loss: -19.8067
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4069

Learning rate: 0.0001865501330253014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1671 [0/90000 (0%)]	Loss: -13.9012	Cost: 25.57s
Train Epoch: 1671 [20480/90000 (23%)]	Loss: -20.4179	Cost: 9.42s
Train Epoch: 1671 [40960/90000 (45%)]	Loss: -20.2345	Cost: 9.36s
Train Epoch: 1671 [61440/90000 (68%)]	Loss: -20.1664	Cost: 9.40s
Train Epoch: 1671 [81920/90000 (91%)]	Loss: -19.9493	Cost: 9.03s
Train Epoch: 1671 	Average Loss: -19.7887
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9050

Learning rate: 0.00018653439230873874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1672 [0/90000 (0%)]	Loss: -13.1758	Cost: 25.17s
Train Epoch: 1672 [20480/90000 (23%)]	Loss: -20.0978	Cost: 9.21s
Train Epoch: 1672 [40960/90000 (45%)]	Loss: -20.1402	Cost: 9.41s
Train Epoch: 1672 [61440/90000 (68%)]	Loss: -19.8736	Cost: 9.20s
Train Epoch: 1672 [81920/90000 (91%)]	Loss: -19.5087	Cost: 8.91s
Train Epoch: 1672 	Average Loss: -19.6087
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0466

Learning rate: 0.00018651864305157395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1673 [0/90000 (0%)]	Loss: -13.3077	Cost: 25.13s
Train Epoch: 1673 [20480/90000 (23%)]	Loss: -20.0507	Cost: 9.53s
Train Epoch: 1673 [40960/90000 (45%)]	Loss: -20.0377	Cost: 9.85s
Train Epoch: 1673 [61440/90000 (68%)]	Loss: -19.7191	Cost: 9.24s
Train Epoch: 1673 [81920/90000 (91%)]	Loss: -19.6928	Cost: 9.09s
Train Epoch: 1673 	Average Loss: -19.4733
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2546

Learning rate: 0.00018650288525536143
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1674 [0/90000 (0%)]	Loss: -14.6451	Cost: 25.10s
Train Epoch: 1674 [20480/90000 (23%)]	Loss: -20.2643	Cost: 9.35s
Train Epoch: 1674 [40960/90000 (45%)]	Loss: -20.0124	Cost: 10.87s
Train Epoch: 1674 [61440/90000 (68%)]	Loss: -18.1644	Cost: 9.07s
Train Epoch: 1674 [81920/90000 (91%)]	Loss: -18.2617	Cost: 8.87s
Train Epoch: 1674 	Average Loss: -19.1341
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1095

Learning rate: 0.00018648711892165642
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1675 [0/90000 (0%)]	Loss: -12.3366	Cost: 25.12s
Train Epoch: 1675 [20480/90000 (23%)]	Loss: -19.4306	Cost: 9.47s
Train Epoch: 1675 [40960/90000 (45%)]	Loss: -19.4405	Cost: 9.63s
Train Epoch: 1675 [61440/90000 (68%)]	Loss: -19.1733	Cost: 9.11s
Train Epoch: 1675 [81920/90000 (91%)]	Loss: -19.5477	Cost: 8.70s
Train Epoch: 1675 	Average Loss: -18.9572
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2695

Learning rate: 0.000186471344052015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1676 [0/90000 (0%)]	Loss: -13.5989	Cost: 25.29s
Train Epoch: 1676 [20480/90000 (23%)]	Loss: -20.4914	Cost: 9.39s
Train Epoch: 1676 [40960/90000 (45%)]	Loss: -20.2575	Cost: 9.63s
Train Epoch: 1676 [61440/90000 (68%)]	Loss: -20.2651	Cost: 9.04s
Train Epoch: 1676 [81920/90000 (91%)]	Loss: -20.3531	Cost: 9.55s
Train Epoch: 1676 	Average Loss: -19.9603
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8461

Learning rate: 0.00018645556064799404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1677 [0/90000 (0%)]	Loss: -14.3379	Cost: 23.36s
Train Epoch: 1677 [20480/90000 (23%)]	Loss: -20.8395	Cost: 9.56s
Train Epoch: 1677 [40960/90000 (45%)]	Loss: -20.4637	Cost: 10.34s
Train Epoch: 1677 [61440/90000 (68%)]	Loss: -19.9983	Cost: 9.21s
Train Epoch: 1677 [81920/90000 (91%)]	Loss: -19.8351	Cost: 9.92s
Train Epoch: 1677 	Average Loss: -20.0159
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2445

Learning rate: 0.00018643976871115134
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1678 [0/90000 (0%)]	Loss: -13.7216	Cost: 24.99s
Train Epoch: 1678 [20480/90000 (23%)]	Loss: -20.3978	Cost: 9.47s
Train Epoch: 1678 [40960/90000 (45%)]	Loss: -20.4006	Cost: 9.25s
Train Epoch: 1678 [61440/90000 (68%)]	Loss: -19.8535	Cost: 9.08s
Train Epoch: 1678 [81920/90000 (91%)]	Loss: -20.3221	Cost: 10.31s
Train Epoch: 1678 	Average Loss: -19.7989
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6013

Learning rate: 0.00018642396824304551
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1679 [0/90000 (0%)]	Loss: -12.9939	Cost: 23.84s
Train Epoch: 1679 [20480/90000 (23%)]	Loss: -20.6749	Cost: 9.44s
Train Epoch: 1679 [40960/90000 (45%)]	Loss: -20.5490	Cost: 9.51s
Train Epoch: 1679 [61440/90000 (68%)]	Loss: -20.3053	Cost: 9.25s
Train Epoch: 1679 [81920/90000 (91%)]	Loss: -20.5318	Cost: 10.09s
Train Epoch: 1679 	Average Loss: -20.1530
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8897

Learning rate: 0.000186408159245236
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1680 [0/90000 (0%)]	Loss: -13.6604	Cost: 23.70s
Train Epoch: 1680 [20480/90000 (23%)]	Loss: -20.9928	Cost: 9.02s
Train Epoch: 1680 [40960/90000 (45%)]	Loss: -20.8948	Cost: 9.31s
Train Epoch: 1680 [61440/90000 (68%)]	Loss: -20.5641	Cost: 9.18s
Train Epoch: 1680 [81920/90000 (91%)]	Loss: -20.7528	Cost: 9.05s
Train Epoch: 1680 	Average Loss: -20.3836
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9997

Learning rate: 0.000186392341719283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1681 [0/90000 (0%)]	Loss: -14.7178	Cost: 24.53s
Train Epoch: 1681 [20480/90000 (23%)]	Loss: -21.0811	Cost: 9.37s
Train Epoch: 1681 [40960/90000 (45%)]	Loss: -20.8526	Cost: 10.24s
Train Epoch: 1681 [61440/90000 (68%)]	Loss: -20.8639	Cost: 9.68s
Train Epoch: 1681 [81920/90000 (91%)]	Loss: -20.4573	Cost: 10.06s
Train Epoch: 1681 	Average Loss: -20.4375
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8170

Learning rate: 0.00018637651566674778
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1682 [0/90000 (0%)]	Loss: -13.7487	Cost: 23.58s
Train Epoch: 1682 [20480/90000 (23%)]	Loss: -20.8198	Cost: 9.34s
Train Epoch: 1682 [40960/90000 (45%)]	Loss: -20.8578	Cost: 9.42s
Train Epoch: 1682 [61440/90000 (68%)]	Loss: -20.7335	Cost: 9.11s
Train Epoch: 1682 [81920/90000 (91%)]	Loss: -20.8043	Cost: 9.21s
Train Epoch: 1682 	Average Loss: -20.4051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2124

Learning rate: 0.00018636068108919223
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1683 [0/90000 (0%)]	Loss: -14.7861	Cost: 24.13s
Train Epoch: 1683 [20480/90000 (23%)]	Loss: -21.0131	Cost: 9.64s
Train Epoch: 1683 [40960/90000 (45%)]	Loss: -21.0177	Cost: 9.30s
Train Epoch: 1683 [61440/90000 (68%)]	Loss: -20.8090	Cost: 9.41s
Train Epoch: 1683 [81920/90000 (91%)]	Loss: -15.9140	Cost: 9.18s
Train Epoch: 1683 	Average Loss: -19.8121
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1222

Learning rate: 0.00018634483798817914
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1684 [0/90000 (0%)]	Loss: -9.9201	Cost: 25.51s
Train Epoch: 1684 [20480/90000 (23%)]	Loss: -16.4534	Cost: 9.27s
Train Epoch: 1684 [40960/90000 (45%)]	Loss: -16.9342	Cost: 9.53s
Train Epoch: 1684 [61440/90000 (68%)]	Loss: -17.4278	Cost: 9.25s
Train Epoch: 1684 [81920/90000 (91%)]	Loss: -18.2403	Cost: 9.30s
Train Epoch: 1684 	Average Loss: -16.5683
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0199

Learning rate: 0.0001863289863652722
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1685 [0/90000 (0%)]	Loss: -12.6296	Cost: 24.29s
Train Epoch: 1685 [20480/90000 (23%)]	Loss: -19.3449	Cost: 9.32s
Train Epoch: 1685 [40960/90000 (45%)]	Loss: -19.4012	Cost: 9.21s
Train Epoch: 1685 [61440/90000 (68%)]	Loss: -19.6748	Cost: 9.17s
Train Epoch: 1685 [81920/90000 (91%)]	Loss: -19.8563	Cost: 8.81s
Train Epoch: 1685 	Average Loss: -19.0961
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4882

Learning rate: 0.0001863131262220359
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1686 [0/90000 (0%)]	Loss: -13.8074	Cost: 26.15s
Train Epoch: 1686 [20480/90000 (23%)]	Loss: -20.4967	Cost: 9.21s
Train Epoch: 1686 [40960/90000 (45%)]	Loss: -20.2717	Cost: 9.34s
Train Epoch: 1686 [61440/90000 (68%)]	Loss: -20.3071	Cost: 9.08s
Train Epoch: 1686 [81920/90000 (91%)]	Loss: -20.3340	Cost: 8.79s
Train Epoch: 1686 	Average Loss: -19.9999
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7452

Learning rate: 0.00018629725756003556
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1687 [0/90000 (0%)]	Loss: -14.2068	Cost: 25.31s
Train Epoch: 1687 [20480/90000 (23%)]	Loss: -20.7888	Cost: 9.35s
Train Epoch: 1687 [40960/90000 (45%)]	Loss: -20.7252	Cost: 9.25s
Train Epoch: 1687 [61440/90000 (68%)]	Loss: -20.8142	Cost: 9.18s
Train Epoch: 1687 [81920/90000 (91%)]	Loss: -20.6115	Cost: 9.03s
Train Epoch: 1687 	Average Loss: -20.3149
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1050

Learning rate: 0.00018628138038083734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1688 [0/90000 (0%)]	Loss: -14.1842	Cost: 27.10s
Train Epoch: 1688 [20480/90000 (23%)]	Loss: -21.1320	Cost: 9.29s
Train Epoch: 1688 [40960/90000 (45%)]	Loss: -20.9506	Cost: 9.37s
Train Epoch: 1688 [61440/90000 (68%)]	Loss: -20.7835	Cost: 9.25s
Train Epoch: 1688 [81920/90000 (91%)]	Loss: -20.7593	Cost: 8.96s
Train Epoch: 1688 	Average Loss: -20.5541
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0824

Learning rate: 0.0001862654946860083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1689 [0/90000 (0%)]	Loss: -14.3176	Cost: 27.15s
Train Epoch: 1689 [20480/90000 (23%)]	Loss: -21.1547	Cost: 9.29s
Train Epoch: 1689 [40960/90000 (45%)]	Loss: -21.0853	Cost: 9.28s
Train Epoch: 1689 [61440/90000 (68%)]	Loss: -20.9468	Cost: 9.15s
Train Epoch: 1689 [81920/90000 (91%)]	Loss: -20.8235	Cost: 9.19s
Train Epoch: 1689 	Average Loss: -20.6379
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3640

Learning rate: 0.00018624960047711623
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1690 [0/90000 (0%)]	Loss: -13.4099	Cost: 25.22s
Train Epoch: 1690 [20480/90000 (23%)]	Loss: -21.1926	Cost: 9.36s
Train Epoch: 1690 [40960/90000 (45%)]	Loss: -20.9776	Cost: 9.55s
Train Epoch: 1690 [61440/90000 (68%)]	Loss: -20.6769	Cost: 9.29s
Train Epoch: 1690 [81920/90000 (91%)]	Loss: -20.5619	Cost: 8.85s
Train Epoch: 1690 	Average Loss: -20.4720
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9396

Learning rate: 0.0001862336977557299
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1691 [0/90000 (0%)]	Loss: -13.0372	Cost: 24.98s
Train Epoch: 1691 [20480/90000 (23%)]	Loss: -21.0251	Cost: 9.41s
Train Epoch: 1691 [40960/90000 (45%)]	Loss: -20.6255	Cost: 9.29s
Train Epoch: 1691 [61440/90000 (68%)]	Loss: -20.5480	Cost: 9.20s
Train Epoch: 1691 [81920/90000 (91%)]	Loss: -20.6618	Cost: 8.97s
Train Epoch: 1691 	Average Loss: -20.2844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8924

Learning rate: 0.00018621778652341882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1692 [0/90000 (0%)]	Loss: -14.5251	Cost: 26.93s
Train Epoch: 1692 [20480/90000 (23%)]	Loss: -20.9955	Cost: 9.42s
Train Epoch: 1692 [40960/90000 (45%)]	Loss: -20.9513	Cost: 9.33s
Train Epoch: 1692 [61440/90000 (68%)]	Loss: -20.8008	Cost: 9.23s
Train Epoch: 1692 [81920/90000 (91%)]	Loss: -20.7376	Cost: 9.12s
Train Epoch: 1692 	Average Loss: -20.5018
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1647

Learning rate: 0.00018620186678175332
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1693 [0/90000 (0%)]	Loss: -14.3960	Cost: 25.42s
Train Epoch: 1693 [20480/90000 (23%)]	Loss: -21.0519	Cost: 9.31s
Train Epoch: 1693 [40960/90000 (45%)]	Loss: -20.8200	Cost: 9.30s
Train Epoch: 1693 [61440/90000 (68%)]	Loss: -20.7102	Cost: 9.21s
Train Epoch: 1693 [81920/90000 (91%)]	Loss: -20.4635	Cost: 9.02s
Train Epoch: 1693 	Average Loss: -20.4744
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7891

Learning rate: 0.00018618593853230467
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1694 [0/90000 (0%)]	Loss: -14.3510	Cost: 26.78s
Train Epoch: 1694 [20480/90000 (23%)]	Loss: -20.9531	Cost: 9.30s
Train Epoch: 1694 [40960/90000 (45%)]	Loss: -20.7028	Cost: 9.61s
Train Epoch: 1694 [61440/90000 (68%)]	Loss: -20.5992	Cost: 9.17s
Train Epoch: 1694 [81920/90000 (91%)]	Loss: -20.4781	Cost: 9.13s
Train Epoch: 1694 	Average Loss: -20.2917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0583

Learning rate: 0.00018617000177664493
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1695 [0/90000 (0%)]	Loss: -14.3079	Cost: 25.21s
Train Epoch: 1695 [20480/90000 (23%)]	Loss: -20.8687	Cost: 9.40s
Train Epoch: 1695 [40960/90000 (45%)]	Loss: -20.9941	Cost: 9.35s
Train Epoch: 1695 [61440/90000 (68%)]	Loss: -20.4199	Cost: 9.31s
Train Epoch: 1695 [81920/90000 (91%)]	Loss: -20.6373	Cost: 9.23s
Train Epoch: 1695 	Average Loss: -20.3614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9262

Learning rate: 0.00018615405651634695
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1696 [0/90000 (0%)]	Loss: -13.8832	Cost: 25.64s
Train Epoch: 1696 [20480/90000 (23%)]	Loss: -21.0063	Cost: 9.46s
Train Epoch: 1696 [40960/90000 (45%)]	Loss: -20.9446	Cost: 9.34s
Train Epoch: 1696 [61440/90000 (68%)]	Loss: -20.9370	Cost: 9.07s
Train Epoch: 1696 [81920/90000 (91%)]	Loss: -20.8862	Cost: 9.19s
Train Epoch: 1696 	Average Loss: -20.5366
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1951

Learning rate: 0.0001861381027529845
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1697 [0/90000 (0%)]	Loss: -14.3731	Cost: 25.47s
Train Epoch: 1697 [20480/90000 (23%)]	Loss: -20.9600	Cost: 9.37s
Train Epoch: 1697 [40960/90000 (45%)]	Loss: -20.9623	Cost: 9.74s
Train Epoch: 1697 [61440/90000 (68%)]	Loss: -20.9393	Cost: 9.07s
Train Epoch: 1697 [81920/90000 (91%)]	Loss: -20.9259	Cost: 9.02s
Train Epoch: 1697 	Average Loss: -20.5097
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2469

Learning rate: 0.00018612214048813213
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1698 [0/90000 (0%)]	Loss: -14.6017	Cost: 25.52s
Train Epoch: 1698 [20480/90000 (23%)]	Loss: -21.2079	Cost: 9.79s
Train Epoch: 1698 [40960/90000 (45%)]	Loss: -21.1085	Cost: 9.25s
Train Epoch: 1698 [61440/90000 (68%)]	Loss: -20.9210	Cost: 9.03s
Train Epoch: 1698 [81920/90000 (91%)]	Loss: -20.8757	Cost: 8.73s
Train Epoch: 1698 	Average Loss: -20.6214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3289

Learning rate: 0.00018610616972336525
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1699 [0/90000 (0%)]	Loss: -15.1876	Cost: 25.04s
Train Epoch: 1699 [20480/90000 (23%)]	Loss: -21.2095	Cost: 9.47s
Train Epoch: 1699 [40960/90000 (45%)]	Loss: -21.0332	Cost: 9.38s
Train Epoch: 1699 [61440/90000 (68%)]	Loss: -20.8498	Cost: 9.09s
Train Epoch: 1699 [81920/90000 (91%)]	Loss: -20.6972	Cost: 9.35s
Train Epoch: 1699 	Average Loss: -20.6398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8639

Learning rate: 0.00018609019046026014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1700 [0/90000 (0%)]	Loss: -14.2238	Cost: 24.49s
Train Epoch: 1700 [20480/90000 (23%)]	Loss: -21.0371	Cost: 9.49s
Train Epoch: 1700 [40960/90000 (45%)]	Loss: -20.8211	Cost: 10.21s
Train Epoch: 1700 [61440/90000 (68%)]	Loss: -20.9147	Cost: 9.04s
Train Epoch: 1700 [81920/90000 (91%)]	Loss: -20.5145	Cost: 10.13s
Train Epoch: 1700 	Average Loss: -20.3390
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8753

Saving model as model.pt_e1700 & waveforms_supplementary.hdf5_e1700
Learning rate: 0.00018607420270039387
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1701 [0/90000 (0%)]	Loss: -14.5763	Cost: 24.23s
Train Epoch: 1701 [20480/90000 (23%)]	Loss: -21.0663	Cost: 9.00s
Train Epoch: 1701 [40960/90000 (45%)]	Loss: -20.9889	Cost: 9.93s
Train Epoch: 1701 [61440/90000 (68%)]	Loss: -21.0027	Cost: 9.03s
Train Epoch: 1701 [81920/90000 (91%)]	Loss: -20.7407	Cost: 9.85s
Train Epoch: 1701 	Average Loss: -20.5033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3444

Learning rate: 0.0001860582064453444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1702 [0/90000 (0%)]	Loss: -14.2108	Cost: 24.33s
Train Epoch: 1702 [20480/90000 (23%)]	Loss: -21.0321	Cost: 9.05s
Train Epoch: 1702 [40960/90000 (45%)]	Loss: -21.0099	Cost: 9.86s
Train Epoch: 1702 [61440/90000 (68%)]	Loss: -20.9670	Cost: 9.11s
Train Epoch: 1702 [81920/90000 (91%)]	Loss: -20.8028	Cost: 10.07s
Train Epoch: 1702 	Average Loss: -20.5420
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1293

Learning rate: 0.00018604220169669041
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1703 [0/90000 (0%)]	Loss: -15.0294	Cost: 24.77s
Train Epoch: 1703 [20480/90000 (23%)]	Loss: -21.1010	Cost: 9.60s
Train Epoch: 1703 [40960/90000 (45%)]	Loss: -20.8275	Cost: 9.56s
Train Epoch: 1703 [61440/90000 (68%)]	Loss: -20.7983	Cost: 9.11s
Train Epoch: 1703 [81920/90000 (91%)]	Loss: -20.6407	Cost: 10.22s
Train Epoch: 1703 	Average Loss: -20.5503
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0894

Learning rate: 0.0001860261884560116
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1704 [0/90000 (0%)]	Loss: -14.1102	Cost: 23.34s
Train Epoch: 1704 [20480/90000 (23%)]	Loss: -20.8187	Cost: 9.25s
Train Epoch: 1704 [40960/90000 (45%)]	Loss: -20.2335	Cost: 9.56s
Train Epoch: 1704 [61440/90000 (68%)]	Loss: -20.1490	Cost: 9.20s
Train Epoch: 1704 [81920/90000 (91%)]	Loss: -20.1146	Cost: 9.07s
Train Epoch: 1704 	Average Loss: -20.0743
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5835

Learning rate: 0.00018601016672488836
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1705 [0/90000 (0%)]	Loss: -14.5618	Cost: 24.22s
Train Epoch: 1705 [20480/90000 (23%)]	Loss: -20.9424	Cost: 9.34s
Train Epoch: 1705 [40960/90000 (45%)]	Loss: -20.7953	Cost: 10.02s
Train Epoch: 1705 [61440/90000 (68%)]	Loss: -20.5374	Cost: 9.41s
Train Epoch: 1705 [81920/90000 (91%)]	Loss: -20.5611	Cost: 10.04s
Train Epoch: 1705 	Average Loss: -20.3232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1506

Learning rate: 0.000185994136504902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1706 [0/90000 (0%)]	Loss: -13.9030	Cost: 23.98s
Train Epoch: 1706 [20480/90000 (23%)]	Loss: -20.9767	Cost: 10.03s
Train Epoch: 1706 [40960/90000 (45%)]	Loss: -20.9060	Cost: 9.36s
Train Epoch: 1706 [61440/90000 (68%)]	Loss: -20.6003	Cost: 9.18s
Train Epoch: 1706 [81920/90000 (91%)]	Loss: -20.5366	Cost: 9.23s
Train Epoch: 1706 	Average Loss: -20.3616
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0424

Learning rate: 0.00018597809779763463
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1707 [0/90000 (0%)]	Loss: -13.9524	Cost: 24.07s
Train Epoch: 1707 [20480/90000 (23%)]	Loss: -20.8614	Cost: 9.38s
Train Epoch: 1707 [40960/90000 (45%)]	Loss: -20.7960	Cost: 9.55s
Train Epoch: 1707 [61440/90000 (68%)]	Loss: -20.8103	Cost: 9.21s
Train Epoch: 1707 [81920/90000 (91%)]	Loss: -20.7985	Cost: 9.15s
Train Epoch: 1707 	Average Loss: -20.4217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3087

Learning rate: 0.0001859620506046692
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1708 [0/90000 (0%)]	Loss: -14.0916	Cost: 24.94s
Train Epoch: 1708 [20480/90000 (23%)]	Loss: -21.3137	Cost: 9.33s
Train Epoch: 1708 [40960/90000 (45%)]	Loss: -21.1539	Cost: 9.26s
Train Epoch: 1708 [61440/90000 (68%)]	Loss: -20.9074	Cost: 9.22s
Train Epoch: 1708 [81920/90000 (91%)]	Loss: -20.9752	Cost: 9.15s
Train Epoch: 1708 	Average Loss: -20.7116
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3663

Learning rate: 0.00018594599492758953
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1709 [0/90000 (0%)]	Loss: -15.6342	Cost: 24.83s
Train Epoch: 1709 [20480/90000 (23%)]	Loss: -21.4296	Cost: 9.31s
Train Epoch: 1709 [40960/90000 (45%)]	Loss: -21.2627	Cost: 9.27s
Train Epoch: 1709 [61440/90000 (68%)]	Loss: -20.9329	Cost: 9.33s
Train Epoch: 1709 [81920/90000 (91%)]	Loss: -20.9061	Cost: 9.13s
Train Epoch: 1709 	Average Loss: -20.7691
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1106

Learning rate: 0.0001859299307679802
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1710 [0/90000 (0%)]	Loss: -13.6243	Cost: 25.19s
Train Epoch: 1710 [20480/90000 (23%)]	Loss: -20.9856	Cost: 9.30s
Train Epoch: 1710 [40960/90000 (45%)]	Loss: -20.7885	Cost: 9.22s
Train Epoch: 1710 [61440/90000 (68%)]	Loss: -20.2930	Cost: 9.18s
Train Epoch: 1710 [81920/90000 (91%)]	Loss: -20.3062	Cost: 9.07s
Train Epoch: 1710 	Average Loss: -20.2685
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6913

Learning rate: 0.00018591385812742676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1711 [0/90000 (0%)]	Loss: -13.6300	Cost: 25.45s
Train Epoch: 1711 [20480/90000 (23%)]	Loss: -20.6612	Cost: 9.43s
Train Epoch: 1711 [40960/90000 (45%)]	Loss: -20.8019	Cost: 9.30s
Train Epoch: 1711 [61440/90000 (68%)]	Loss: -20.7681	Cost: 9.53s
Train Epoch: 1711 [81920/90000 (91%)]	Loss: -20.6508	Cost: 8.96s
Train Epoch: 1711 	Average Loss: -20.2487
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0184

Learning rate: 0.00018589777700751543
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1712 [0/90000 (0%)]	Loss: -14.5130	Cost: 25.51s
Train Epoch: 1712 [20480/90000 (23%)]	Loss: -20.9978	Cost: 9.38s
Train Epoch: 1712 [40960/90000 (45%)]	Loss: -20.9435	Cost: 9.28s
Train Epoch: 1712 [61440/90000 (68%)]	Loss: -20.7359	Cost: 9.18s
Train Epoch: 1712 [81920/90000 (91%)]	Loss: -20.2987	Cost: 9.03s
Train Epoch: 1712 	Average Loss: -20.3265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7975

Learning rate: 0.0001858816874098334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1713 [0/90000 (0%)]	Loss: -14.4628	Cost: 25.43s
Train Epoch: 1713 [20480/90000 (23%)]	Loss: -20.8415	Cost: 9.30s
Train Epoch: 1713 [40960/90000 (45%)]	Loss: -20.8754	Cost: 9.48s
Train Epoch: 1713 [61440/90000 (68%)]	Loss: -20.8907	Cost: 9.52s
Train Epoch: 1713 [81920/90000 (91%)]	Loss: -20.6769	Cost: 9.94s
Train Epoch: 1713 	Average Loss: -20.3965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1985

Learning rate: 0.00018586558933596863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1714 [0/90000 (0%)]	Loss: -15.0511	Cost: 25.27s
Train Epoch: 1714 [20480/90000 (23%)]	Loss: -21.2014	Cost: 9.29s
Train Epoch: 1714 [40960/90000 (45%)]	Loss: -21.2021	Cost: 9.31s
Train Epoch: 1714 [61440/90000 (68%)]	Loss: -20.8197	Cost: 9.24s
Train Epoch: 1714 [81920/90000 (91%)]	Loss: -20.7106	Cost: 8.80s
Train Epoch: 1714 	Average Loss: -20.5769
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1220

Learning rate: 0.00018584948278750992
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1715 [0/90000 (0%)]	Loss: -14.5569	Cost: 26.04s
Train Epoch: 1715 [20480/90000 (23%)]	Loss: -21.0055	Cost: 9.43s
Train Epoch: 1715 [40960/90000 (45%)]	Loss: -21.1107	Cost: 9.26s
Train Epoch: 1715 [61440/90000 (68%)]	Loss: -20.7473	Cost: 9.34s
Train Epoch: 1715 [81920/90000 (91%)]	Loss: -20.9061	Cost: 8.83s
Train Epoch: 1715 	Average Loss: -20.6103
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1792

Learning rate: 0.00018583336776604697
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1716 [0/90000 (0%)]	Loss: -14.7369	Cost: 27.15s
Train Epoch: 1716 [20480/90000 (23%)]	Loss: -21.2962	Cost: 9.31s
Train Epoch: 1716 [40960/90000 (45%)]	Loss: -20.9869	Cost: 9.26s
Train Epoch: 1716 [61440/90000 (68%)]	Loss: -20.8648	Cost: 9.17s
Train Epoch: 1716 [81920/90000 (91%)]	Loss: -20.6693	Cost: 8.94s
Train Epoch: 1716 	Average Loss: -20.5858
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0943

Learning rate: 0.00018581724427317028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1717 [0/90000 (0%)]	Loss: -14.0161	Cost: 25.19s
Train Epoch: 1717 [20480/90000 (23%)]	Loss: -21.1436	Cost: 9.41s
Train Epoch: 1717 [40960/90000 (45%)]	Loss: -21.0060	Cost: 9.29s
Train Epoch: 1717 [61440/90000 (68%)]	Loss: -20.8777	Cost: 9.36s
Train Epoch: 1717 [81920/90000 (91%)]	Loss: -20.8357	Cost: 8.89s
Train Epoch: 1717 	Average Loss: -20.6045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2485

Learning rate: 0.0001858011123104711
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1718 [0/90000 (0%)]	Loss: -14.1145	Cost: 25.07s
Train Epoch: 1718 [20480/90000 (23%)]	Loss: -20.9224	Cost: 9.39s
Train Epoch: 1718 [40960/90000 (45%)]	Loss: -20.8168	Cost: 9.35s
Train Epoch: 1718 [61440/90000 (68%)]	Loss: -20.7221	Cost: 9.18s
Train Epoch: 1718 [81920/90000 (91%)]	Loss: -20.8353	Cost: 9.15s
Train Epoch: 1718 	Average Loss: -20.5075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8092

Learning rate: 0.00018578497187954164
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1719 [0/90000 (0%)]	Loss: -13.8367	Cost: 25.86s
Train Epoch: 1719 [20480/90000 (23%)]	Loss: -20.7577	Cost: 9.40s
Train Epoch: 1719 [40960/90000 (45%)]	Loss: -20.6586	Cost: 9.32s
Train Epoch: 1719 [61440/90000 (68%)]	Loss: -20.5980	Cost: 9.34s
Train Epoch: 1719 [81920/90000 (91%)]	Loss: -20.5203	Cost: 8.89s
Train Epoch: 1719 	Average Loss: -20.2659
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1300

Learning rate: 0.0001857688229819749
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1720 [0/90000 (0%)]	Loss: -13.7094	Cost: 25.80s
Train Epoch: 1720 [20480/90000 (23%)]	Loss: -21.0702	Cost: 9.46s
Train Epoch: 1720 [40960/90000 (45%)]	Loss: -21.0071	Cost: 9.33s
Train Epoch: 1720 [61440/90000 (68%)]	Loss: -20.9269	Cost: 9.09s
Train Epoch: 1720 [81920/90000 (91%)]	Loss: -20.7742	Cost: 8.82s
Train Epoch: 1720 	Average Loss: -20.5378
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2076

Learning rate: 0.00018575266561936469
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1721 [0/90000 (0%)]	Loss: -14.5338	Cost: 24.92s
Train Epoch: 1721 [20480/90000 (23%)]	Loss: -21.2479	Cost: 9.50s
Train Epoch: 1721 [40960/90000 (45%)]	Loss: -21.1505	Cost: 9.25s
Train Epoch: 1721 [61440/90000 (68%)]	Loss: -20.9657	Cost: 9.21s
Train Epoch: 1721 [81920/90000 (91%)]	Loss: -20.9716	Cost: 8.73s
Train Epoch: 1721 	Average Loss: -20.7112
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5328

Learning rate: 0.0001857364997933057
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1722 [0/90000 (0%)]	Loss: -14.7058	Cost: 25.16s
Train Epoch: 1722 [20480/90000 (23%)]	Loss: -21.6171	Cost: 9.53s
Train Epoch: 1722 [40960/90000 (45%)]	Loss: -21.2592	Cost: 9.09s
Train Epoch: 1722 [61440/90000 (68%)]	Loss: -21.1133	Cost: 9.02s
Train Epoch: 1722 [81920/90000 (91%)]	Loss: -21.1152	Cost: 8.80s
Train Epoch: 1722 	Average Loss: -20.8475
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4553

Learning rate: 0.00018572032550539342
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1723 [0/90000 (0%)]	Loss: -14.2612	Cost: 24.36s
Train Epoch: 1723 [20480/90000 (23%)]	Loss: -21.3848	Cost: 9.54s
Train Epoch: 1723 [40960/90000 (45%)]	Loss: -20.9687	Cost: 9.52s
Train Epoch: 1723 [61440/90000 (68%)]	Loss: -20.8945	Cost: 9.19s
Train Epoch: 1723 [81920/90000 (91%)]	Loss: -20.8346	Cost: 9.57s
Train Epoch: 1723 	Average Loss: -20.6672
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2318

Learning rate: 0.0001857041427572242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1724 [0/90000 (0%)]	Loss: -14.1790	Cost: 24.54s
Train Epoch: 1724 [20480/90000 (23%)]	Loss: -21.3123	Cost: 9.57s
Train Epoch: 1724 [40960/90000 (45%)]	Loss: -20.9866	Cost: 9.13s
Train Epoch: 1724 [61440/90000 (68%)]	Loss: -21.0311	Cost: 9.11s
Train Epoch: 1724 [81920/90000 (91%)]	Loss: -20.8243	Cost: 10.25s
Train Epoch: 1724 	Average Loss: -20.6285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1992

Learning rate: 0.0001856879515503952
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1725 [0/90000 (0%)]	Loss: -14.2197	Cost: 23.63s
Train Epoch: 1725 [20480/90000 (23%)]	Loss: -20.9388	Cost: 9.59s
Train Epoch: 1725 [40960/90000 (45%)]	Loss: -21.0284	Cost: 9.07s
Train Epoch: 1725 [61440/90000 (68%)]	Loss: -20.9215	Cost: 9.25s
Train Epoch: 1725 [81920/90000 (91%)]	Loss: -20.8137	Cost: 9.96s
Train Epoch: 1725 	Average Loss: -20.5505
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3083

Learning rate: 0.00018567175188650444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1726 [0/90000 (0%)]	Loss: -14.0627	Cost: 25.02s
Train Epoch: 1726 [20480/90000 (23%)]	Loss: -21.2243	Cost: 9.02s
Train Epoch: 1726 [40960/90000 (45%)]	Loss: -21.2016	Cost: 10.29s
Train Epoch: 1726 [61440/90000 (68%)]	Loss: -21.0697	Cost: 9.03s
Train Epoch: 1726 [81920/90000 (91%)]	Loss: -21.0662	Cost: 10.43s
Train Epoch: 1726 	Average Loss: -20.6989
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4756

Learning rate: 0.0001856555437671507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1727 [0/90000 (0%)]	Loss: -13.6680	Cost: 25.18s
Train Epoch: 1727 [20480/90000 (23%)]	Loss: -21.3694	Cost: 9.34s
Train Epoch: 1727 [40960/90000 (45%)]	Loss: -21.2510	Cost: 9.48s
Train Epoch: 1727 [61440/90000 (68%)]	Loss: -21.2013	Cost: 9.35s
Train Epoch: 1727 [81920/90000 (91%)]	Loss: -21.0707	Cost: 9.94s
Train Epoch: 1727 	Average Loss: -20.8033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5197

Learning rate: 0.00018563932719393376
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1728 [0/90000 (0%)]	Loss: -14.7146	Cost: 24.09s
Train Epoch: 1728 [20480/90000 (23%)]	Loss: -21.4510	Cost: 9.37s
Train Epoch: 1728 [40960/90000 (45%)]	Loss: -21.1061	Cost: 9.26s
Train Epoch: 1728 [61440/90000 (68%)]	Loss: -20.5595	Cost: 9.58s
Train Epoch: 1728 [81920/90000 (91%)]	Loss: -20.6228	Cost: 9.18s
Train Epoch: 1728 	Average Loss: -20.5922
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1121

Learning rate: 0.00018562310216845406
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1729 [0/90000 (0%)]	Loss: -13.9493	Cost: 24.81s
Train Epoch: 1729 [20480/90000 (23%)]	Loss: -21.1091	Cost: 9.41s
Train Epoch: 1729 [40960/90000 (45%)]	Loss: -20.7564	Cost: 10.52s
Train Epoch: 1729 [61440/90000 (68%)]	Loss: -20.6950	Cost: 9.61s
Train Epoch: 1729 [81920/90000 (91%)]	Loss: -20.7934	Cost: 9.17s
Train Epoch: 1729 	Average Loss: -20.4721
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3319

Learning rate: 0.000185606868692313
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1730 [0/90000 (0%)]	Loss: -13.8487	Cost: 23.96s
Train Epoch: 1730 [20480/90000 (23%)]	Loss: -21.0669	Cost: 9.41s
Train Epoch: 1730 [40960/90000 (45%)]	Loss: -20.9028	Cost: 9.25s
Train Epoch: 1730 [61440/90000 (68%)]	Loss: -20.7675	Cost: 9.09s
Train Epoch: 1730 [81920/90000 (91%)]	Loss: -20.8833	Cost: 9.24s
Train Epoch: 1730 	Average Loss: -20.5603
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2922

Learning rate: 0.0001855906267671127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1731 [0/90000 (0%)]	Loss: -13.7321	Cost: 24.32s
Train Epoch: 1731 [20480/90000 (23%)]	Loss: -20.7984	Cost: 9.18s
Train Epoch: 1731 [40960/90000 (45%)]	Loss: -20.6063	Cost: 9.13s
Train Epoch: 1731 [61440/90000 (68%)]	Loss: -20.6340	Cost: 9.27s
Train Epoch: 1731 [81920/90000 (91%)]	Loss: -20.6221	Cost: 8.86s
Train Epoch: 1731 	Average Loss: -20.2645
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9240

Learning rate: 0.00018557437639445622
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1732 [0/90000 (0%)]	Loss: -13.6063	Cost: 26.70s
Train Epoch: 1732 [20480/90000 (23%)]	Loss: -20.9854	Cost: 9.40s
Train Epoch: 1732 [40960/90000 (45%)]	Loss: -20.9255	Cost: 9.20s
Train Epoch: 1732 [61440/90000 (68%)]	Loss: -20.8719	Cost: 9.15s
Train Epoch: 1732 [81920/90000 (91%)]	Loss: -20.6277	Cost: 9.23s
Train Epoch: 1732 	Average Loss: -20.4372
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2347

Learning rate: 0.0001855581175759474
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1733 [0/90000 (0%)]	Loss: -15.2384	Cost: 27.25s
Train Epoch: 1733 [20480/90000 (23%)]	Loss: -21.2973	Cost: 9.29s
Train Epoch: 1733 [40960/90000 (45%)]	Loss: -21.0019	Cost: 9.26s
Train Epoch: 1733 [61440/90000 (68%)]	Loss: -20.9743	Cost: 9.33s
Train Epoch: 1733 [81920/90000 (91%)]	Loss: -20.8819	Cost: 9.01s
Train Epoch: 1733 	Average Loss: -20.7616
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1775

Learning rate: 0.0001855418503131909
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1734 [0/90000 (0%)]	Loss: -12.2471	Cost: 26.85s
Train Epoch: 1734 [20480/90000 (23%)]	Loss: -21.1779	Cost: 9.41s
Train Epoch: 1734 [40960/90000 (45%)]	Loss: -20.9951	Cost: 9.23s
Train Epoch: 1734 [61440/90000 (68%)]	Loss: -20.5364	Cost: 9.16s
Train Epoch: 1734 [81920/90000 (91%)]	Loss: -20.3693	Cost: 8.94s
Train Epoch: 1734 	Average Loss: -20.4283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0470

Learning rate: 0.00018552557460779223
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1735 [0/90000 (0%)]	Loss: -14.2745	Cost: 25.48s
Train Epoch: 1735 [20480/90000 (23%)]	Loss: -21.2276	Cost: 9.45s
Train Epoch: 1735 [40960/90000 (45%)]	Loss: -21.0549	Cost: 9.24s
Train Epoch: 1735 [61440/90000 (68%)]	Loss: -20.8930	Cost: 9.40s
Train Epoch: 1735 [81920/90000 (91%)]	Loss: -20.8291	Cost: 8.84s
Train Epoch: 1735 	Average Loss: -20.5941
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3155

Learning rate: 0.00018550929046135778
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1736 [0/90000 (0%)]	Loss: -15.6859	Cost: 25.44s
Train Epoch: 1736 [20480/90000 (23%)]	Loss: -21.3973	Cost: 9.42s
Train Epoch: 1736 [40960/90000 (45%)]	Loss: -21.1247	Cost: 9.23s
Train Epoch: 1736 [61440/90000 (68%)]	Loss: -20.8614	Cost: 9.11s
Train Epoch: 1736 [81920/90000 (91%)]	Loss: -20.9569	Cost: 9.04s
Train Epoch: 1736 	Average Loss: -20.7450
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2849

Learning rate: 0.0001854929978754947
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1737 [0/90000 (0%)]	Loss: -14.9793	Cost: 27.80s
Train Epoch: 1737 [20480/90000 (23%)]	Loss: -21.5059	Cost: 9.33s
Train Epoch: 1737 [40960/90000 (45%)]	Loss: -21.1589	Cost: 10.29s
Train Epoch: 1737 [61440/90000 (68%)]	Loss: -21.1528	Cost: 9.47s
Train Epoch: 1737 [81920/90000 (91%)]	Loss: -20.9305	Cost: 8.94s
Train Epoch: 1737 	Average Loss: -20.7644
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5280

Learning rate: 0.000185476696851811
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1738 [0/90000 (0%)]	Loss: -15.2315	Cost: 25.15s
Train Epoch: 1738 [20480/90000 (23%)]	Loss: -21.6065	Cost: 9.77s
Train Epoch: 1738 [40960/90000 (45%)]	Loss: -21.1245	Cost: 9.32s
Train Epoch: 1738 [61440/90000 (68%)]	Loss: -20.8740	Cost: 9.07s
Train Epoch: 1738 [81920/90000 (91%)]	Loss: -20.8178	Cost: 8.88s
Train Epoch: 1738 	Average Loss: -20.7615
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1813

Learning rate: 0.00018546038739191553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1739 [0/90000 (0%)]	Loss: -15.1045	Cost: 25.25s
Train Epoch: 1739 [20480/90000 (23%)]	Loss: -21.3536	Cost: 9.61s
Train Epoch: 1739 [40960/90000 (45%)]	Loss: -21.1881	Cost: 9.40s
Train Epoch: 1739 [61440/90000 (68%)]	Loss: -21.0270	Cost: 9.36s
Train Epoch: 1739 [81920/90000 (91%)]	Loss: -20.7049	Cost: 8.81s
Train Epoch: 1739 	Average Loss: -20.7788
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2904

Learning rate: 0.000185444069497418
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1740 [0/90000 (0%)]	Loss: -14.6950	Cost: 25.59s
Train Epoch: 1740 [20480/90000 (23%)]	Loss: -21.3614	Cost: 10.01s
Train Epoch: 1740 [40960/90000 (45%)]	Loss: -21.1260	Cost: 9.03s
Train Epoch: 1740 [61440/90000 (68%)]	Loss: -20.8380	Cost: 8.95s
Train Epoch: 1740 [81920/90000 (91%)]	Loss: -20.9558	Cost: 8.71s
Train Epoch: 1740 	Average Loss: -20.7442
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5276

Learning rate: 0.0001854277431699289
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1741 [0/90000 (0%)]	Loss: -14.7629	Cost: 25.37s
Train Epoch: 1741 [20480/90000 (23%)]	Loss: -21.2674	Cost: 9.50s
Train Epoch: 1741 [40960/90000 (45%)]	Loss: -21.1116	Cost: 9.76s
Train Epoch: 1741 [61440/90000 (68%)]	Loss: -21.0928	Cost: 9.17s
Train Epoch: 1741 [81920/90000 (91%)]	Loss: -20.9911	Cost: 9.54s
Train Epoch: 1741 	Average Loss: -20.7357
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3674

Learning rate: 0.00018541140841105955
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1742 [0/90000 (0%)]	Loss: -13.6202	Cost: 24.34s
Train Epoch: 1742 [20480/90000 (23%)]	Loss: -21.2115	Cost: 9.56s
Train Epoch: 1742 [40960/90000 (45%)]	Loss: -21.1890	Cost: 9.20s
Train Epoch: 1742 [61440/90000 (68%)]	Loss: -20.9082	Cost: 9.05s
Train Epoch: 1742 [81920/90000 (91%)]	Loss: -20.9113	Cost: 9.75s
Train Epoch: 1742 	Average Loss: -20.6660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2313

Learning rate: 0.00018539506522242215
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1743 [0/90000 (0%)]	Loss: -14.5046	Cost: 23.98s
Train Epoch: 1743 [20480/90000 (23%)]	Loss: -21.2298	Cost: 9.53s
Train Epoch: 1743 [40960/90000 (45%)]	Loss: -21.3774	Cost: 9.31s
Train Epoch: 1743 [61440/90000 (68%)]	Loss: -21.1777	Cost: 9.31s
Train Epoch: 1743 [81920/90000 (91%)]	Loss: -21.0968	Cost: 9.80s
Train Epoch: 1743 	Average Loss: -20.8599
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5007

Learning rate: 0.0001853787136056297
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1744 [0/90000 (0%)]	Loss: -15.3510	Cost: 24.90s
Train Epoch: 1744 [20480/90000 (23%)]	Loss: -21.3641	Cost: 9.34s
Train Epoch: 1744 [40960/90000 (45%)]	Loss: -21.0491	Cost: 9.47s
Train Epoch: 1744 [61440/90000 (68%)]	Loss: -21.1022	Cost: 9.02s
Train Epoch: 1744 [81920/90000 (91%)]	Loss: -20.7551	Cost: 10.15s
Train Epoch: 1744 	Average Loss: -20.7040
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0498

Learning rate: 0.00018536235356229606
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1745 [0/90000 (0%)]	Loss: -14.7868	Cost: 24.87s
Train Epoch: 1745 [20480/90000 (23%)]	Loss: -21.2492	Cost: 9.37s
Train Epoch: 1745 [40960/90000 (45%)]	Loss: -20.9795	Cost: 9.48s
Train Epoch: 1745 [61440/90000 (68%)]	Loss: -20.6376	Cost: 9.39s
Train Epoch: 1745 [81920/90000 (91%)]	Loss: -20.2899	Cost: 9.75s
Train Epoch: 1745 	Average Loss: -20.4318
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9377

Learning rate: 0.00018534598509403587
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1746 [0/90000 (0%)]	Loss: -14.5776	Cost: 23.24s
Train Epoch: 1746 [20480/90000 (23%)]	Loss: -20.9078	Cost: 9.38s
Train Epoch: 1746 [40960/90000 (45%)]	Loss: -20.4205	Cost: 9.36s
Train Epoch: 1746 [61440/90000 (68%)]	Loss: -20.3718	Cost: 9.39s
Train Epoch: 1746 [81920/90000 (91%)]	Loss: -20.4999	Cost: 9.14s
Train Epoch: 1746 	Average Loss: -20.1888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9606

Learning rate: 0.00018532960820246466
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1747 [0/90000 (0%)]	Loss: -14.2911	Cost: 24.04s
Train Epoch: 1747 [20480/90000 (23%)]	Loss: -20.5121	Cost: 9.36s
Train Epoch: 1747 [40960/90000 (45%)]	Loss: -20.1428	Cost: 9.66s
Train Epoch: 1747 [61440/90000 (68%)]	Loss: -20.4018	Cost: 9.27s
Train Epoch: 1747 [81920/90000 (91%)]	Loss: -20.4423	Cost: 9.46s
Train Epoch: 1747 	Average Loss: -19.9357
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9017

Learning rate: 0.00018531322288919874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1748 [0/90000 (0%)]	Loss: -15.4761	Cost: 24.36s
Train Epoch: 1748 [20480/90000 (23%)]	Loss: -21.0295	Cost: 9.37s
Train Epoch: 1748 [40960/90000 (45%)]	Loss: -21.1943	Cost: 9.20s
Train Epoch: 1748 [61440/90000 (68%)]	Loss: -21.0048	Cost: 9.17s
Train Epoch: 1748 [81920/90000 (91%)]	Loss: -21.1449	Cost: 9.18s
Train Epoch: 1748 	Average Loss: -20.6074
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4474

Learning rate: 0.0001852968291558553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1749 [0/90000 (0%)]	Loss: -14.7934	Cost: 25.50s
Train Epoch: 1749 [20480/90000 (23%)]	Loss: -21.5835	Cost: 9.43s
Train Epoch: 1749 [40960/90000 (45%)]	Loss: -21.1989	Cost: 9.21s
Train Epoch: 1749 [61440/90000 (68%)]	Loss: -20.8683	Cost: 9.35s
Train Epoch: 1749 [81920/90000 (91%)]	Loss: -20.8935	Cost: 8.97s
Train Epoch: 1749 	Average Loss: -20.8124
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5033

Learning rate: 0.00018528042700405233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1750 [0/90000 (0%)]	Loss: -14.2205	Cost: 25.68s
Train Epoch: 1750 [20480/90000 (23%)]	Loss: -20.8804	Cost: 9.32s
Train Epoch: 1750 [40960/90000 (45%)]	Loss: -20.6283	Cost: 9.32s
Train Epoch: 1750 [61440/90000 (68%)]	Loss: -20.9040	Cost: 9.21s
Train Epoch: 1750 [81920/90000 (91%)]	Loss: -20.7390	Cost: 9.01s
Train Epoch: 1750 	Average Loss: -20.4965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1363

Saving model as model.pt_e1750 & waveforms_supplementary.hdf5_e1750
Learning rate: 0.00018526401643540862
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1751 [0/90000 (0%)]	Loss: -14.5382	Cost: 25.16s
Train Epoch: 1751 [20480/90000 (23%)]	Loss: -20.7783	Cost: 9.43s
Train Epoch: 1751 [40960/90000 (45%)]	Loss: -20.5739	Cost: 9.25s
Train Epoch: 1751 [61440/90000 (68%)]	Loss: -20.2412	Cost: 9.12s
Train Epoch: 1751 [81920/90000 (91%)]	Loss: -20.5873	Cost: 9.12s
Train Epoch: 1751 	Average Loss: -20.2107
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8555

Learning rate: 0.0001852475974515439
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1752 [0/90000 (0%)]	Loss: -12.4550	Cost: 23.52s
Train Epoch: 1752 [20480/90000 (23%)]	Loss: -21.0184	Cost: 9.32s
Train Epoch: 1752 [40960/90000 (45%)]	Loss: -20.9634	Cost: 9.37s
Train Epoch: 1752 [61440/90000 (68%)]	Loss: -20.8516	Cost: 9.10s
Train Epoch: 1752 [81920/90000 (91%)]	Loss: -20.9627	Cost: 8.93s
Train Epoch: 1752 	Average Loss: -20.5045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3412

Learning rate: 0.0001852311700540786
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1753 [0/90000 (0%)]	Loss: -14.9458	Cost: 26.26s
Train Epoch: 1753 [20480/90000 (23%)]	Loss: -21.4512	Cost: 9.21s
Train Epoch: 1753 [40960/90000 (45%)]	Loss: -21.2766	Cost: 9.25s
Train Epoch: 1753 [61440/90000 (68%)]	Loss: -20.8495	Cost: 9.06s
Train Epoch: 1753 [81920/90000 (91%)]	Loss: -20.7990	Cost: 8.83s
Train Epoch: 1753 	Average Loss: -20.6953
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2105

Learning rate: 0.00018521473424463404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1754 [0/90000 (0%)]	Loss: -15.4953	Cost: 25.93s
Train Epoch: 1754 [20480/90000 (23%)]	Loss: -21.2972	Cost: 9.28s
Train Epoch: 1754 [40960/90000 (45%)]	Loss: -21.0027	Cost: 9.25s
Train Epoch: 1754 [61440/90000 (68%)]	Loss: -21.1312	Cost: 9.09s
Train Epoch: 1754 [81920/90000 (91%)]	Loss: -20.7230	Cost: 8.79s
Train Epoch: 1754 	Average Loss: -20.6698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4560

Learning rate: 0.0001851982900248324
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1755 [0/90000 (0%)]	Loss: -15.3330	Cost: 28.10s
Train Epoch: 1755 [20480/90000 (23%)]	Loss: -21.2042	Cost: 9.51s
Train Epoch: 1755 [40960/90000 (45%)]	Loss: -21.3103	Cost: 9.32s
Train Epoch: 1755 [61440/90000 (68%)]	Loss: -21.1523	Cost: 9.06s
Train Epoch: 1755 [81920/90000 (91%)]	Loss: -20.1089	Cost: 8.79s
Train Epoch: 1755 	Average Loss: -20.7260
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5937

Learning rate: 0.00018518183739629665
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1756 [0/90000 (0%)]	Loss: -13.6326	Cost: 24.97s
Train Epoch: 1756 [20480/90000 (23%)]	Loss: -20.2596	Cost: 9.36s
Train Epoch: 1756 [40960/90000 (45%)]	Loss: -14.8058	Cost: 9.29s
Train Epoch: 1756 [61440/90000 (68%)]	Loss: -13.7182	Cost: 9.07s
Train Epoch: 1756 [81920/90000 (91%)]	Loss: -14.6878	Cost: 9.00s
Train Epoch: 1756 	Average Loss: -15.9107
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.6916

Learning rate: 0.0001851653763606506
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1757 [0/90000 (0%)]	Loss: -10.0669	Cost: 26.71s
Train Epoch: 1757 [20480/90000 (23%)]	Loss: -17.0414	Cost: 9.43s
Train Epoch: 1757 [40960/90000 (45%)]	Loss: -17.7712	Cost: 9.48s
Train Epoch: 1757 [61440/90000 (68%)]	Loss: -18.3971	Cost: 9.10s
Train Epoch: 1757 [81920/90000 (91%)]	Loss: -19.1725	Cost: 8.82s
Train Epoch: 1757 	Average Loss: -17.4770
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0528

Learning rate: 0.00018514890691951886
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1758 [0/90000 (0%)]	Loss: -14.1630	Cost: 26.47s
Train Epoch: 1758 [20480/90000 (23%)]	Loss: -20.3871	Cost: 9.38s
Train Epoch: 1758 [40960/90000 (45%)]	Loss: -20.4439	Cost: 9.21s
Train Epoch: 1758 [61440/90000 (68%)]	Loss: -20.5402	Cost: 9.15s
Train Epoch: 1758 [81920/90000 (91%)]	Loss: -20.6346	Cost: 8.86s
Train Epoch: 1758 	Average Loss: -20.0227
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1781

Learning rate: 0.00018513242907452696
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1759 [0/90000 (0%)]	Loss: -13.8492	Cost: 26.53s
Train Epoch: 1759 [20480/90000 (23%)]	Loss: -21.0544	Cost: 9.40s
Train Epoch: 1759 [40960/90000 (45%)]	Loss: -21.0002	Cost: 9.58s
Train Epoch: 1759 [61440/90000 (68%)]	Loss: -20.7505	Cost: 9.18s
Train Epoch: 1759 [81920/90000 (91%)]	Loss: -20.6396	Cost: 8.84s
Train Epoch: 1759 	Average Loss: -20.4974
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1361

Learning rate: 0.00018511594282730114
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1760 [0/90000 (0%)]	Loss: -14.3627	Cost: 25.99s
Train Epoch: 1760 [20480/90000 (23%)]	Loss: -21.0492	Cost: 9.34s
Train Epoch: 1760 [40960/90000 (45%)]	Loss: -21.0640	Cost: 9.25s
Train Epoch: 1760 [61440/90000 (68%)]	Loss: -20.9253	Cost: 9.24s
Train Epoch: 1760 [81920/90000 (91%)]	Loss: -20.9618	Cost: 8.87s
Train Epoch: 1760 	Average Loss: -20.6345
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5190

Learning rate: 0.00018509944817946854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1761 [0/90000 (0%)]	Loss: -14.8236	Cost: 26.29s
Train Epoch: 1761 [20480/90000 (23%)]	Loss: -21.4516	Cost: 9.37s
Train Epoch: 1761 [40960/90000 (45%)]	Loss: -20.7032	Cost: 9.53s
Train Epoch: 1761 [61440/90000 (68%)]	Loss: -20.5200	Cost: 9.38s
Train Epoch: 1761 [81920/90000 (91%)]	Loss: -20.6209	Cost: 8.90s
Train Epoch: 1761 	Average Loss: -20.4683
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1602

Learning rate: 0.00018508294513265716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1762 [0/90000 (0%)]	Loss: -14.8012	Cost: 25.16s
Train Epoch: 1762 [20480/90000 (23%)]	Loss: -21.2526	Cost: 9.43s
Train Epoch: 1762 [40960/90000 (45%)]	Loss: -20.9990	Cost: 9.24s
Train Epoch: 1762 [61440/90000 (68%)]	Loss: -21.0754	Cost: 9.08s
Train Epoch: 1762 [81920/90000 (91%)]	Loss: -20.8285	Cost: 9.15s
Train Epoch: 1762 	Average Loss: -20.6902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3088

Learning rate: 0.0001850664336884957
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1763 [0/90000 (0%)]	Loss: -13.6927	Cost: 25.26s
Train Epoch: 1763 [20480/90000 (23%)]	Loss: -21.2489	Cost: 9.49s
Train Epoch: 1763 [40960/90000 (45%)]	Loss: -20.8188	Cost: 9.61s
Train Epoch: 1763 [61440/90000 (68%)]	Loss: -20.3104	Cost: 9.26s
Train Epoch: 1763 [81920/90000 (91%)]	Loss: -20.6208	Cost: 9.04s
Train Epoch: 1763 	Average Loss: -20.4441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3262

Learning rate: 0.0001850499138486139
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1764 [0/90000 (0%)]	Loss: -13.6390	Cost: 24.85s
Train Epoch: 1764 [20480/90000 (23%)]	Loss: -20.8732	Cost: 9.68s
Train Epoch: 1764 [40960/90000 (45%)]	Loss: -20.8249	Cost: 9.05s
Train Epoch: 1764 [61440/90000 (68%)]	Loss: -20.5430	Cost: 8.95s
Train Epoch: 1764 [81920/90000 (91%)]	Loss: -20.9491	Cost: 8.71s
Train Epoch: 1764 	Average Loss: -20.4687
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2672

Learning rate: 0.00018503338561464208
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1765 [0/90000 (0%)]	Loss: -14.7805	Cost: 25.24s
Train Epoch: 1765 [20480/90000 (23%)]	Loss: -21.3481	Cost: 9.55s
Train Epoch: 1765 [40960/90000 (45%)]	Loss: -21.1976	Cost: 9.43s
Train Epoch: 1765 [61440/90000 (68%)]	Loss: -21.0277	Cost: 9.21s
Train Epoch: 1765 [81920/90000 (91%)]	Loss: -20.9751	Cost: 9.39s
Train Epoch: 1765 	Average Loss: -20.7879
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4247

Learning rate: 0.00018501684898821158
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1766 [0/90000 (0%)]	Loss: -14.2568	Cost: 24.27s
Train Epoch: 1766 [20480/90000 (23%)]	Loss: -21.4779	Cost: 9.62s
Train Epoch: 1766 [40960/90000 (45%)]	Loss: -21.1149	Cost: 9.06s
Train Epoch: 1766 [61440/90000 (68%)]	Loss: -20.8404	Cost: 9.03s
Train Epoch: 1766 [81920/90000 (91%)]	Loss: -20.6105	Cost: 9.99s
Train Epoch: 1766 	Average Loss: -20.6806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1125

Learning rate: 0.0001850003039709545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1767 [0/90000 (0%)]	Loss: -14.2001	Cost: 24.87s
Train Epoch: 1767 [20480/90000 (23%)]	Loss: -21.1309	Cost: 9.46s
Train Epoch: 1767 [40960/90000 (45%)]	Loss: -21.0722	Cost: 9.33s
Train Epoch: 1767 [61440/90000 (68%)]	Loss: -21.0945	Cost: 9.28s
Train Epoch: 1767 [81920/90000 (91%)]	Loss: -20.6290	Cost: 9.87s
Train Epoch: 1767 	Average Loss: -20.5066
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0871

Learning rate: 0.0001849837505645037
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1768 [0/90000 (0%)]	Loss: -14.2989	Cost: 22.68s
Train Epoch: 1768 [20480/90000 (23%)]	Loss: -21.1921	Cost: 9.15s
Train Epoch: 1768 [40960/90000 (45%)]	Loss: -21.0187	Cost: 9.10s
Train Epoch: 1768 [61440/90000 (68%)]	Loss: -20.8567	Cost: 9.02s
Train Epoch: 1768 [81920/90000 (91%)]	Loss: -20.7760	Cost: 10.02s
Train Epoch: 1768 	Average Loss: -20.5662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8672

Learning rate: 0.00018496718877049302
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1769 [0/90000 (0%)]	Loss: -14.9680	Cost: 24.37s
Train Epoch: 1769 [20480/90000 (23%)]	Loss: -21.0631	Cost: 9.28s
Train Epoch: 1769 [40960/90000 (45%)]	Loss: -20.9589	Cost: 9.55s
Train Epoch: 1769 [61440/90000 (68%)]	Loss: -20.6752	Cost: 9.38s
Train Epoch: 1769 [81920/90000 (91%)]	Loss: -21.0214	Cost: 9.37s
Train Epoch: 1769 	Average Loss: -20.5950
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2577

Learning rate: 0.00018495061859055697
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1770 [0/90000 (0%)]	Loss: -14.4366	Cost: 23.15s
Train Epoch: 1770 [20480/90000 (23%)]	Loss: -21.0416	Cost: 9.13s
Train Epoch: 1770 [40960/90000 (45%)]	Loss: -20.8664	Cost: 9.31s
Train Epoch: 1770 [61440/90000 (68%)]	Loss: -21.0209	Cost: 9.36s
Train Epoch: 1770 [81920/90000 (91%)]	Loss: -20.7582	Cost: 9.15s
Train Epoch: 1770 	Average Loss: -20.6234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1724

Learning rate: 0.000184934040026331
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1771 [0/90000 (0%)]	Loss: -14.3871	Cost: 23.65s
Train Epoch: 1771 [20480/90000 (23%)]	Loss: -21.1609	Cost: 9.38s
Train Epoch: 1771 [40960/90000 (45%)]	Loss: -20.9985	Cost: 9.29s
Train Epoch: 1771 [61440/90000 (68%)]	Loss: -20.9745	Cost: 9.37s
Train Epoch: 1771 [81920/90000 (91%)]	Loss: -21.0608	Cost: 9.09s
Train Epoch: 1771 	Average Loss: -20.6959
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5100

Learning rate: 0.0001849174530794514
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1772 [0/90000 (0%)]	Loss: -14.9801	Cost: 24.67s
Train Epoch: 1772 [20480/90000 (23%)]	Loss: -21.1339	Cost: 9.35s
Train Epoch: 1772 [40960/90000 (45%)]	Loss: -21.0760	Cost: 9.22s
Train Epoch: 1772 [61440/90000 (68%)]	Loss: -20.9454	Cost: 9.11s
Train Epoch: 1772 [81920/90000 (91%)]	Loss: -20.9776	Cost: 9.25s
Train Epoch: 1772 	Average Loss: -20.8374
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4833

Learning rate: 0.0001849008577515551
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1773 [0/90000 (0%)]	Loss: -12.6792	Cost: 24.95s
Train Epoch: 1773 [20480/90000 (23%)]	Loss: -20.1195	Cost: 9.38s
Train Epoch: 1773 [40960/90000 (45%)]	Loss: -19.6730	Cost: 9.86s
Train Epoch: 1773 [61440/90000 (68%)]	Loss: -19.8418	Cost: 9.32s
Train Epoch: 1773 [81920/90000 (91%)]	Loss: -20.1131	Cost: 9.12s
Train Epoch: 1773 	Average Loss: -19.7256
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7290

Learning rate: 0.00018488425404428012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1774 [0/90000 (0%)]	Loss: -13.8616	Cost: 26.15s
Train Epoch: 1774 [20480/90000 (23%)]	Loss: -20.7264	Cost: 9.34s
Train Epoch: 1774 [40960/90000 (45%)]	Loss: -20.5288	Cost: 9.27s
Train Epoch: 1774 [61440/90000 (68%)]	Loss: -20.4440	Cost: 9.16s
Train Epoch: 1774 [81920/90000 (91%)]	Loss: -20.8057	Cost: 9.13s
Train Epoch: 1774 	Average Loss: -20.2305
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2067

Learning rate: 0.00018486764195926517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1775 [0/90000 (0%)]	Loss: -14.6196	Cost: 24.88s
Train Epoch: 1775 [20480/90000 (23%)]	Loss: -20.6870	Cost: 9.39s
Train Epoch: 1775 [40960/90000 (45%)]	Loss: -20.8949	Cost: 9.37s
Train Epoch: 1775 [61440/90000 (68%)]	Loss: -20.6634	Cost: 9.44s
Train Epoch: 1775 [81920/90000 (91%)]	Loss: -20.7114	Cost: 8.88s
Train Epoch: 1775 	Average Loss: -20.4607
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1768

Learning rate: 0.00018485102149814973
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1776 [0/90000 (0%)]	Loss: -14.7146	Cost: 27.41s
Train Epoch: 1776 [20480/90000 (23%)]	Loss: -20.7599	Cost: 9.83s
Train Epoch: 1776 [40960/90000 (45%)]	Loss: -20.7804	Cost: 9.56s
Train Epoch: 1776 [61440/90000 (68%)]	Loss: -20.7662	Cost: 9.15s
Train Epoch: 1776 [81920/90000 (91%)]	Loss: -20.7650	Cost: 9.05s
Train Epoch: 1776 	Average Loss: -20.4528
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2304

Learning rate: 0.00018483439266257418
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1777 [0/90000 (0%)]	Loss: -14.8002	Cost: 25.79s
Train Epoch: 1777 [20480/90000 (23%)]	Loss: -21.1160	Cost: 9.35s
Train Epoch: 1777 [40960/90000 (45%)]	Loss: -21.1149	Cost: 9.31s
Train Epoch: 1777 [61440/90000 (68%)]	Loss: -20.7739	Cost: 9.39s
Train Epoch: 1777 [81920/90000 (91%)]	Loss: -21.0939	Cost: 8.78s
Train Epoch: 1777 	Average Loss: -20.6325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3873

Learning rate: 0.00018481775545417978
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1778 [0/90000 (0%)]	Loss: -14.4517	Cost: 25.57s
Train Epoch: 1778 [20480/90000 (23%)]	Loss: -21.2718	Cost: 9.33s
Train Epoch: 1778 [40960/90000 (45%)]	Loss: -21.2476	Cost: 9.26s
Train Epoch: 1778 [61440/90000 (68%)]	Loss: -21.1911	Cost: 9.09s
Train Epoch: 1778 [81920/90000 (91%)]	Loss: -21.2302	Cost: 8.82s
Train Epoch: 1778 	Average Loss: -20.8537
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5526

Learning rate: 0.00018480110987460852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1779 [0/90000 (0%)]	Loss: -14.5706	Cost: 25.22s
Train Epoch: 1779 [20480/90000 (23%)]	Loss: -21.2528	Cost: 9.51s
Train Epoch: 1779 [40960/90000 (45%)]	Loss: -21.0450	Cost: 9.36s
Train Epoch: 1779 [61440/90000 (68%)]	Loss: -21.0278	Cost: 9.38s
Train Epoch: 1779 [81920/90000 (91%)]	Loss: -20.7952	Cost: 8.81s
Train Epoch: 1779 	Average Loss: -20.5217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0955

Learning rate: 0.00018478445592550325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1780 [0/90000 (0%)]	Loss: -15.1000	Cost: 27.86s
Train Epoch: 1780 [20480/90000 (23%)]	Loss: -21.2665	Cost: 9.39s
Train Epoch: 1780 [40960/90000 (45%)]	Loss: -21.2825	Cost: 9.48s
Train Epoch: 1780 [61440/90000 (68%)]	Loss: -21.0434	Cost: 9.12s
Train Epoch: 1780 [81920/90000 (91%)]	Loss: -20.9096	Cost: 8.86s
Train Epoch: 1780 	Average Loss: -20.7660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3555

Learning rate: 0.00018476779360850767
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1781 [0/90000 (0%)]	Loss: -15.3787	Cost: 25.60s
Train Epoch: 1781 [20480/90000 (23%)]	Loss: -21.4072	Cost: 9.36s
Train Epoch: 1781 [40960/90000 (45%)]	Loss: -21.3728	Cost: 9.67s
Train Epoch: 1781 [61440/90000 (68%)]	Loss: -21.4543	Cost: 9.40s
Train Epoch: 1781 [81920/90000 (91%)]	Loss: -21.1419	Cost: 8.88s
Train Epoch: 1781 	Average Loss: -20.9743
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4802

Learning rate: 0.00018475112292526627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1782 [0/90000 (0%)]	Loss: -14.7414	Cost: 26.29s
Train Epoch: 1782 [20480/90000 (23%)]	Loss: -21.5100	Cost: 9.39s
Train Epoch: 1782 [40960/90000 (45%)]	Loss: -21.5075	Cost: 10.05s
Train Epoch: 1782 [61440/90000 (68%)]	Loss: -21.1849	Cost: 9.08s
Train Epoch: 1782 [81920/90000 (91%)]	Loss: -21.0363	Cost: 8.87s
Train Epoch: 1782 	Average Loss: -21.0077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4681

Learning rate: 0.00018473444387742438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1783 [0/90000 (0%)]	Loss: -14.5518	Cost: 25.81s
Train Epoch: 1783 [20480/90000 (23%)]	Loss: -21.3817	Cost: 9.09s
Train Epoch: 1783 [40960/90000 (45%)]	Loss: -21.1883	Cost: 9.36s
Train Epoch: 1783 [61440/90000 (68%)]	Loss: -21.0996	Cost: 9.41s
Train Epoch: 1783 [81920/90000 (91%)]	Loss: -21.0597	Cost: 8.97s
Train Epoch: 1783 	Average Loss: -20.8294
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2427

Learning rate: 0.00018471775646662815
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1784 [0/90000 (0%)]	Loss: -15.1281	Cost: 25.80s
Train Epoch: 1784 [20480/90000 (23%)]	Loss: -21.3987	Cost: 9.29s
Train Epoch: 1784 [40960/90000 (45%)]	Loss: -21.3750	Cost: 10.48s
Train Epoch: 1784 [61440/90000 (68%)]	Loss: -20.7791	Cost: 9.05s
Train Epoch: 1784 [81920/90000 (91%)]	Loss: -20.3976	Cost: 8.81s
Train Epoch: 1784 	Average Loss: -20.5882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6576

Learning rate: 0.00018470106069452455
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1785 [0/90000 (0%)]	Loss: -14.1532	Cost: 25.38s
Train Epoch: 1785 [20480/90000 (23%)]	Loss: -20.5617	Cost: 9.43s
Train Epoch: 1785 [40960/90000 (45%)]	Loss: -20.4717	Cost: 9.38s
Train Epoch: 1785 [61440/90000 (68%)]	Loss: -20.3412	Cost: 9.27s
Train Epoch: 1785 [81920/90000 (91%)]	Loss: -20.6853	Cost: 8.76s
Train Epoch: 1785 	Average Loss: -20.1180
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7735

Learning rate: 0.00018468435656276142
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1786 [0/90000 (0%)]	Loss: -13.7850	Cost: 24.71s
Train Epoch: 1786 [20480/90000 (23%)]	Loss: -20.8436	Cost: 9.00s
Train Epoch: 1786 [40960/90000 (45%)]	Loss: -20.8339	Cost: 10.04s
Train Epoch: 1786 [61440/90000 (68%)]	Loss: -20.7254	Cost: 9.01s
Train Epoch: 1786 [81920/90000 (91%)]	Loss: -20.3519	Cost: 9.95s
Train Epoch: 1786 	Average Loss: -20.2714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9952

Learning rate: 0.0001846676440729874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1787 [0/90000 (0%)]	Loss: -14.3549	Cost: 24.41s
Train Epoch: 1787 [20480/90000 (23%)]	Loss: -20.9253	Cost: 9.44s
Train Epoch: 1787 [40960/90000 (45%)]	Loss: -20.8741	Cost: 9.55s
Train Epoch: 1787 [61440/90000 (68%)]	Loss: -20.6186	Cost: 9.27s
Train Epoch: 1787 [81920/90000 (91%)]	Loss: -20.3298	Cost: 10.40s
Train Epoch: 1787 	Average Loss: -20.2878
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8216

Learning rate: 0.00018465092322685192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1788 [0/90000 (0%)]	Loss: -13.9855	Cost: 24.87s
Train Epoch: 1788 [20480/90000 (23%)]	Loss: -21.0412	Cost: 9.34s
Train Epoch: 1788 [40960/90000 (45%)]	Loss: -21.1665	Cost: 10.07s
Train Epoch: 1788 [61440/90000 (68%)]	Loss: -20.6498	Cost: 9.06s
Train Epoch: 1788 [81920/90000 (91%)]	Loss: -20.5126	Cost: 10.35s
Train Epoch: 1788 	Average Loss: -20.4796
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1090

Learning rate: 0.00018463419402600523
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1789 [0/90000 (0%)]	Loss: -14.0837	Cost: 24.61s
Train Epoch: 1789 [20480/90000 (23%)]	Loss: -20.9845	Cost: 9.23s
Train Epoch: 1789 [40960/90000 (45%)]	Loss: -21.2994	Cost: 9.51s
Train Epoch: 1789 [61440/90000 (68%)]	Loss: -20.8455	Cost: 9.23s
Train Epoch: 1789 [81920/90000 (91%)]	Loss: -20.9667	Cost: 9.98s
Train Epoch: 1789 	Average Loss: -20.6933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2340

Learning rate: 0.0001846174564720985
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1790 [0/90000 (0%)]	Loss: -15.1203	Cost: 24.74s
Train Epoch: 1790 [20480/90000 (23%)]	Loss: -21.3398	Cost: 9.30s
Train Epoch: 1790 [40960/90000 (45%)]	Loss: -21.1140	Cost: 9.77s
Train Epoch: 1790 [61440/90000 (68%)]	Loss: -20.5242	Cost: 9.09s
Train Epoch: 1790 [81920/90000 (91%)]	Loss: -20.8548	Cost: 11.06s
Train Epoch: 1790 	Average Loss: -20.6425
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2507

Learning rate: 0.0001846007105667836
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1791 [0/90000 (0%)]	Loss: -15.2176	Cost: 23.71s
Train Epoch: 1791 [20480/90000 (23%)]	Loss: -21.4163	Cost: 9.32s
Train Epoch: 1791 [40960/90000 (45%)]	Loss: -21.2740	Cost: 9.28s
Train Epoch: 1791 [61440/90000 (68%)]	Loss: -21.1126	Cost: 9.37s
Train Epoch: 1791 [81920/90000 (91%)]	Loss: -20.8713	Cost: 9.04s
Train Epoch: 1791 	Average Loss: -20.7784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4589

Learning rate: 0.0001845839563117133
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1792 [0/90000 (0%)]	Loss: -14.1782	Cost: 23.37s
Train Epoch: 1792 [20480/90000 (23%)]	Loss: -21.4609	Cost: 9.39s
Train Epoch: 1792 [40960/90000 (45%)]	Loss: -21.2977	Cost: 9.23s
Train Epoch: 1792 [61440/90000 (68%)]	Loss: -20.7475	Cost: 9.17s
Train Epoch: 1792 [81920/90000 (91%)]	Loss: -20.9011	Cost: 9.16s
Train Epoch: 1792 	Average Loss: -20.6984
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1632

Learning rate: 0.00018456719370854124
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1793 [0/90000 (0%)]	Loss: -14.2639	Cost: 24.01s
Train Epoch: 1793 [20480/90000 (23%)]	Loss: -21.3398	Cost: 9.45s
Train Epoch: 1793 [40960/90000 (45%)]	Loss: -21.3134	Cost: 9.22s
Train Epoch: 1793 [61440/90000 (68%)]	Loss: -21.0835	Cost: 9.47s
Train Epoch: 1793 [81920/90000 (91%)]	Loss: -21.0024	Cost: 9.14s
Train Epoch: 1793 	Average Loss: -20.8147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2823

Learning rate: 0.00018455042275892174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1794 [0/90000 (0%)]	Loss: -15.0036	Cost: 24.75s
Train Epoch: 1794 [20480/90000 (23%)]	Loss: -21.4350	Cost: 9.34s
Train Epoch: 1794 [40960/90000 (45%)]	Loss: -21.2178	Cost: 9.28s
Train Epoch: 1794 [61440/90000 (68%)]	Loss: -20.8239	Cost: 9.10s
Train Epoch: 1794 [81920/90000 (91%)]	Loss: -20.9921	Cost: 9.16s
Train Epoch: 1794 	Average Loss: -20.7250
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3835

Learning rate: 0.0001845336434645101
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1795 [0/90000 (0%)]	Loss: -14.8215	Cost: 26.10s
Train Epoch: 1795 [20480/90000 (23%)]	Loss: -21.2750	Cost: 9.37s
Train Epoch: 1795 [40960/90000 (45%)]	Loss: -21.0249	Cost: 9.65s
Train Epoch: 1795 [61440/90000 (68%)]	Loss: -20.7382	Cost: 9.37s
Train Epoch: 1795 [81920/90000 (91%)]	Loss: -20.5797	Cost: 9.05s
Train Epoch: 1795 	Average Loss: -20.5807
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8863

Learning rate: 0.0001845168558269623
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1796 [0/90000 (0%)]	Loss: -14.4743	Cost: 25.99s
Train Epoch: 1796 [20480/90000 (23%)]	Loss: -20.9990	Cost: 9.33s
Train Epoch: 1796 [40960/90000 (45%)]	Loss: -21.0792	Cost: 9.34s
Train Epoch: 1796 [61440/90000 (68%)]	Loss: -20.7100	Cost: 9.15s
Train Epoch: 1796 [81920/90000 (91%)]	Loss: -20.7417	Cost: 9.04s
Train Epoch: 1796 	Average Loss: -20.5758
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0992

Learning rate: 0.00018450005984793527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1797 [0/90000 (0%)]	Loss: -14.1416	Cost: 26.38s
Train Epoch: 1797 [20480/90000 (23%)]	Loss: -21.1147	Cost: 9.39s
Train Epoch: 1797 [40960/90000 (45%)]	Loss: -21.1694	Cost: 9.24s
Train Epoch: 1797 [61440/90000 (68%)]	Loss: -21.0210	Cost: 9.36s
Train Epoch: 1797 [81920/90000 (91%)]	Loss: -21.1554	Cost: 9.33s
Train Epoch: 1797 	Average Loss: -20.7337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5446

Learning rate: 0.00018448325552908668
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1798 [0/90000 (0%)]	Loss: -14.2206	Cost: 25.89s
Train Epoch: 1798 [20480/90000 (23%)]	Loss: -21.3321	Cost: 9.35s
Train Epoch: 1798 [40960/90000 (45%)]	Loss: -21.2342	Cost: 9.28s
Train Epoch: 1798 [61440/90000 (68%)]	Loss: -21.2383	Cost: 9.17s
Train Epoch: 1798 [81920/90000 (91%)]	Loss: -21.1103	Cost: 8.89s
Train Epoch: 1798 	Average Loss: -20.8445
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4571

Learning rate: 0.00018446644287207505
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1799 [0/90000 (0%)]	Loss: -15.2923	Cost: 27.09s
Train Epoch: 1799 [20480/90000 (23%)]	Loss: -21.4065	Cost: 9.32s
Train Epoch: 1799 [40960/90000 (45%)]	Loss: -21.3378	Cost: 9.23s
Train Epoch: 1799 [61440/90000 (68%)]	Loss: -21.0806	Cost: 9.35s
Train Epoch: 1799 [81920/90000 (91%)]	Loss: -21.0556	Cost: 9.67s
Train Epoch: 1799 	Average Loss: -20.9043
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3131

Learning rate: 0.00018444962187855974
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1800 [0/90000 (0%)]	Loss: -14.4627	Cost: 25.94s
Train Epoch: 1800 [20480/90000 (23%)]	Loss: -21.1318	Cost: 9.32s
Train Epoch: 1800 [40960/90000 (45%)]	Loss: -21.0871	Cost: 9.23s
Train Epoch: 1800 [61440/90000 (68%)]	Loss: -21.2192	Cost: 9.21s
Train Epoch: 1800 [81920/90000 (91%)]	Loss: -20.9937	Cost: 8.87s
Train Epoch: 1800 	Average Loss: -20.7628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2730

Saving model as model.pt_e1800 & waveforms_supplementary.hdf5_e1800
Learning rate: 0.00018443279255020087
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1801 [0/90000 (0%)]	Loss: -14.1654	Cost: 25.21s
Train Epoch: 1801 [20480/90000 (23%)]	Loss: -21.0806	Cost: 9.85s
Train Epoch: 1801 [40960/90000 (45%)]	Loss: -20.9151	Cost: 9.32s
Train Epoch: 1801 [61440/90000 (68%)]	Loss: -20.6165	Cost: 9.36s
Train Epoch: 1801 [81920/90000 (91%)]	Loss: -20.4289	Cost: 9.56s
Train Epoch: 1801 	Average Loss: -20.5361
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9041

Learning rate: 0.00018441595488865947
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1802 [0/90000 (0%)]	Loss: -13.8496	Cost: 24.48s
Train Epoch: 1802 [20480/90000 (23%)]	Loss: -20.8469	Cost: 9.41s
Train Epoch: 1802 [40960/90000 (45%)]	Loss: -20.6829	Cost: 9.23s
Train Epoch: 1802 [61440/90000 (68%)]	Loss: -20.8044	Cost: 9.16s
Train Epoch: 1802 [81920/90000 (91%)]	Loss: -20.5503	Cost: 9.06s
Train Epoch: 1802 	Average Loss: -20.2534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9836

Learning rate: 0.00018439910889559734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1803 [0/90000 (0%)]	Loss: -14.1252	Cost: 25.04s
Train Epoch: 1803 [20480/90000 (23%)]	Loss: -21.1245	Cost: 9.41s
Train Epoch: 1803 [40960/90000 (45%)]	Loss: -20.9284	Cost: 9.26s
Train Epoch: 1803 [61440/90000 (68%)]	Loss: -20.8423	Cost: 9.11s
Train Epoch: 1803 [81920/90000 (91%)]	Loss: -20.8791	Cost: 9.00s
Train Epoch: 1803 	Average Loss: -20.5899
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3199

Learning rate: 0.00018438225457267712
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1804 [0/90000 (0%)]	Loss: -14.8471	Cost: 25.33s
Train Epoch: 1804 [20480/90000 (23%)]	Loss: -21.4409	Cost: 9.37s
Train Epoch: 1804 [40960/90000 (45%)]	Loss: -21.4177	Cost: 9.34s
Train Epoch: 1804 [61440/90000 (68%)]	Loss: -21.2084	Cost: 9.17s
Train Epoch: 1804 [81920/90000 (91%)]	Loss: -21.3228	Cost: 9.10s
Train Epoch: 1804 	Average Loss: -20.9163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6011

Learning rate: 0.00018436539192156226
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1805 [0/90000 (0%)]	Loss: -15.0900	Cost: 25.64s
Train Epoch: 1805 [20480/90000 (23%)]	Loss: -21.7161	Cost: 9.53s
Train Epoch: 1805 [40960/90000 (45%)]	Loss: -21.5126	Cost: 9.37s
Train Epoch: 1805 [61440/90000 (68%)]	Loss: -21.2012	Cost: 9.12s
Train Epoch: 1805 [81920/90000 (91%)]	Loss: -20.7994	Cost: 9.15s
Train Epoch: 1805 	Average Loss: -20.9346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9413

Learning rate: 0.00018434852094391705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1806 [0/90000 (0%)]	Loss: -14.0753	Cost: 25.41s
Train Epoch: 1806 [20480/90000 (23%)]	Loss: -21.1936	Cost: 9.38s
Train Epoch: 1806 [40960/90000 (45%)]	Loss: -21.2847	Cost: 9.33s
Train Epoch: 1806 [61440/90000 (68%)]	Loss: -20.9815	Cost: 9.20s
Train Epoch: 1806 [81920/90000 (91%)]	Loss: -20.9804	Cost: 8.97s
Train Epoch: 1806 	Average Loss: -20.6400
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3251

Learning rate: 0.00018433164164140655
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1807 [0/90000 (0%)]	Loss: -14.4697	Cost: 25.52s
Train Epoch: 1807 [20480/90000 (23%)]	Loss: -20.7066	Cost: 9.37s
Train Epoch: 1807 [40960/90000 (45%)]	Loss: -20.5018	Cost: 9.56s
Train Epoch: 1807 [61440/90000 (68%)]	Loss: -20.4448	Cost: 9.22s
Train Epoch: 1807 [81920/90000 (91%)]	Loss: -20.5086	Cost: 8.80s
Train Epoch: 1807 	Average Loss: -20.2542
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0620

Learning rate: 0.00018431475401569668
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1808 [0/90000 (0%)]	Loss: -14.1329	Cost: 25.19s
Train Epoch: 1808 [20480/90000 (23%)]	Loss: -20.9799	Cost: 9.32s
Train Epoch: 1808 [40960/90000 (45%)]	Loss: -21.0494	Cost: 9.34s
Train Epoch: 1808 [61440/90000 (68%)]	Loss: -21.1389	Cost: 9.23s
Train Epoch: 1808 [81920/90000 (91%)]	Loss: -21.3182	Cost: 8.86s
Train Epoch: 1808 	Average Loss: -20.7078
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3654

Learning rate: 0.00018429785806845425
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1809 [0/90000 (0%)]	Loss: -15.0688	Cost: 25.85s
Train Epoch: 1809 [20480/90000 (23%)]	Loss: -21.4916	Cost: 9.34s
Train Epoch: 1809 [40960/90000 (45%)]	Loss: -21.4095	Cost: 9.49s
Train Epoch: 1809 [61440/90000 (68%)]	Loss: -21.4521	Cost: 9.13s
Train Epoch: 1809 [81920/90000 (91%)]	Loss: -21.4319	Cost: 8.92s
Train Epoch: 1809 	Average Loss: -21.0056
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7137

Learning rate: 0.00018428095380134676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1810 [0/90000 (0%)]	Loss: -14.7384	Cost: 25.78s
Train Epoch: 1810 [20480/90000 (23%)]	Loss: -21.6358	Cost: 9.39s
Train Epoch: 1810 [40960/90000 (45%)]	Loss: -21.3107	Cost: 9.24s
Train Epoch: 1810 [61440/90000 (68%)]	Loss: -21.4290	Cost: 9.08s
Train Epoch: 1810 [81920/90000 (91%)]	Loss: -21.1942	Cost: 8.97s
Train Epoch: 1810 	Average Loss: -21.0004
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5273

Learning rate: 0.00018426404121604263
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1811 [0/90000 (0%)]	Loss: -15.3473	Cost: 25.40s
Train Epoch: 1811 [20480/90000 (23%)]	Loss: -21.5288	Cost: 9.50s
Train Epoch: 1811 [40960/90000 (45%)]	Loss: -21.2771	Cost: 9.49s
Train Epoch: 1811 [61440/90000 (68%)]	Loss: -21.1849	Cost: 9.14s
Train Epoch: 1811 [81920/90000 (91%)]	Loss: -20.9676	Cost: 9.12s
Train Epoch: 1811 	Average Loss: -20.8930
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3345

Learning rate: 0.00018424712031421103
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1812 [0/90000 (0%)]	Loss: -15.1122	Cost: 25.75s
Train Epoch: 1812 [20480/90000 (23%)]	Loss: -21.5201	Cost: 9.74s
Train Epoch: 1812 [40960/90000 (45%)]	Loss: -21.2090	Cost: 9.07s
Train Epoch: 1812 [61440/90000 (68%)]	Loss: -21.0706	Cost: 8.99s
Train Epoch: 1812 [81920/90000 (91%)]	Loss: -21.1500	Cost: 8.73s
Train Epoch: 1812 	Average Loss: -20.8652
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2265

Learning rate: 0.000184230191097522
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1813 [0/90000 (0%)]	Loss: -15.0897	Cost: 25.74s
Train Epoch: 1813 [20480/90000 (23%)]	Loss: -21.4326	Cost: 9.57s
Train Epoch: 1813 [40960/90000 (45%)]	Loss: -20.8951	Cost: 9.44s
Train Epoch: 1813 [61440/90000 (68%)]	Loss: -20.5229	Cost: 9.24s
Train Epoch: 1813 [81920/90000 (91%)]	Loss: -20.7289	Cost: 9.27s
Train Epoch: 1813 	Average Loss: -20.6417
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0507

Learning rate: 0.00018421325356764642
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1814 [0/90000 (0%)]	Loss: -14.1896	Cost: 24.30s
Train Epoch: 1814 [20480/90000 (23%)]	Loss: -20.8751	Cost: 9.07s
Train Epoch: 1814 [40960/90000 (45%)]	Loss: -19.5638	Cost: 9.98s
Train Epoch: 1814 [61440/90000 (68%)]	Loss: -19.7071	Cost: 9.07s
Train Epoch: 1814 [81920/90000 (91%)]	Loss: -19.8155	Cost: 9.91s
Train Epoch: 1814 	Average Loss: -19.6545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4901

Learning rate: 0.00018419630772625588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1815 [0/90000 (0%)]	Loss: -13.9716	Cost: 23.67s
Train Epoch: 1815 [20480/90000 (23%)]	Loss: -20.6827	Cost: 9.54s
Train Epoch: 1815 [40960/90000 (45%)]	Loss: -20.8141	Cost: 9.49s
Train Epoch: 1815 [61440/90000 (68%)]	Loss: -20.7547	Cost: 9.22s
Train Epoch: 1815 [81920/90000 (91%)]	Loss: -20.9362	Cost: 10.08s
Train Epoch: 1815 	Average Loss: -20.2688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3356

Learning rate: 0.00018417935357502294
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1816 [0/90000 (0%)]	Loss: -14.9211	Cost: 23.74s
Train Epoch: 1816 [20480/90000 (23%)]	Loss: -21.3123	Cost: 9.08s
Train Epoch: 1816 [40960/90000 (45%)]	Loss: -21.4607	Cost: 9.23s
Train Epoch: 1816 [61440/90000 (68%)]	Loss: -21.0804	Cost: 9.01s
Train Epoch: 1816 [81920/90000 (91%)]	Loss: -21.1515	Cost: 10.08s
Train Epoch: 1816 	Average Loss: -20.9565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5450

Learning rate: 0.00018416239111562088
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1817 [0/90000 (0%)]	Loss: -15.3008	Cost: 24.12s
Train Epoch: 1817 [20480/90000 (23%)]	Loss: -21.6440	Cost: 9.07s
Train Epoch: 1817 [40960/90000 (45%)]	Loss: -21.5767	Cost: 9.96s
Train Epoch: 1817 [61440/90000 (68%)]	Loss: -20.7693	Cost: 9.20s
Train Epoch: 1817 [81920/90000 (91%)]	Loss: -20.2662	Cost: 10.28s
Train Epoch: 1817 	Average Loss: -20.7715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5664

Learning rate: 0.0001841454203497238
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1818 [0/90000 (0%)]	Loss: -14.0824	Cost: 24.13s
Train Epoch: 1818 [20480/90000 (23%)]	Loss: -20.9459	Cost: 9.06s
Train Epoch: 1818 [40960/90000 (45%)]	Loss: -20.9459	Cost: 9.02s
Train Epoch: 1818 [61440/90000 (68%)]	Loss: -20.8804	Cost: 9.07s
Train Epoch: 1818 [81920/90000 (91%)]	Loss: -20.9986	Cost: 9.13s
Train Epoch: 1818 	Average Loss: -20.5439
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0718

Learning rate: 0.00018412844127900673
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1819 [0/90000 (0%)]	Loss: -14.8009	Cost: 23.92s
Train Epoch: 1819 [20480/90000 (23%)]	Loss: -21.4067	Cost: 9.35s
Train Epoch: 1819 [40960/90000 (45%)]	Loss: -21.1867	Cost: 9.15s
Train Epoch: 1819 [61440/90000 (68%)]	Loss: -21.0077	Cost: 9.34s
Train Epoch: 1819 [81920/90000 (91%)]	Loss: -20.6153	Cost: 9.05s
Train Epoch: 1819 	Average Loss: -20.6766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9439

Learning rate: 0.00018411145390514536
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1820 [0/90000 (0%)]	Loss: -14.5668	Cost: 23.85s
Train Epoch: 1820 [20480/90000 (23%)]	Loss: -21.1788	Cost: 9.33s
Train Epoch: 1820 [40960/90000 (45%)]	Loss: -21.0559	Cost: 9.30s
Train Epoch: 1820 [61440/90000 (68%)]	Loss: -21.0007	Cost: 9.11s
Train Epoch: 1820 [81920/90000 (91%)]	Loss: -21.1209	Cost: 8.97s
Train Epoch: 1820 	Average Loss: -20.6756
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3369

Learning rate: 0.0001840944582298163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1821 [0/90000 (0%)]	Loss: -14.7746	Cost: 25.37s
Train Epoch: 1821 [20480/90000 (23%)]	Loss: -21.5434	Cost: 9.37s
Train Epoch: 1821 [40960/90000 (45%)]	Loss: -21.2110	Cost: 9.29s
Train Epoch: 1821 [61440/90000 (68%)]	Loss: -20.8993	Cost: 9.25s
Train Epoch: 1821 [81920/90000 (91%)]	Loss: -21.0254	Cost: 8.79s
Train Epoch: 1821 	Average Loss: -20.8272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3040

Learning rate: 0.00018407745425469697
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1822 [0/90000 (0%)]	Loss: -14.4232	Cost: 26.65s
Train Epoch: 1822 [20480/90000 (23%)]	Loss: -21.5427	Cost: 9.31s
Train Epoch: 1822 [40960/90000 (45%)]	Loss: -21.1647	Cost: 9.19s
Train Epoch: 1822 [61440/90000 (68%)]	Loss: -21.1949	Cost: 9.18s
Train Epoch: 1822 [81920/90000 (91%)]	Loss: -21.1063	Cost: 8.79s
Train Epoch: 1822 	Average Loss: -20.8107
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3998

Learning rate: 0.00018406044198146558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1823 [0/90000 (0%)]	Loss: -15.0316	Cost: 25.07s
Train Epoch: 1823 [20480/90000 (23%)]	Loss: -21.3739	Cost: 9.43s
Train Epoch: 1823 [40960/90000 (45%)]	Loss: -21.0703	Cost: 9.25s
Train Epoch: 1823 [61440/90000 (68%)]	Loss: -20.7646	Cost: 9.38s
Train Epoch: 1823 [81920/90000 (91%)]	Loss: -20.5961	Cost: 8.98s
Train Epoch: 1823 	Average Loss: -20.6552
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0327

Learning rate: 0.00018404342141180118
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1824 [0/90000 (0%)]	Loss: -15.0637	Cost: 25.46s
Train Epoch: 1824 [20480/90000 (23%)]	Loss: -21.2441	Cost: 9.32s
Train Epoch: 1824 [40960/90000 (45%)]	Loss: -20.8774	Cost: 9.39s
Train Epoch: 1824 [61440/90000 (68%)]	Loss: -20.5326	Cost: 9.31s
Train Epoch: 1824 [81920/90000 (91%)]	Loss: -20.8004	Cost: 8.77s
Train Epoch: 1824 	Average Loss: -20.5378
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1260

Learning rate: 0.00018402639254738363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1825 [0/90000 (0%)]	Loss: -14.8179	Cost: 26.57s
Train Epoch: 1825 [20480/90000 (23%)]	Loss: -21.2315	Cost: 9.42s
Train Epoch: 1825 [40960/90000 (45%)]	Loss: -21.2805	Cost: 9.20s
Train Epoch: 1825 [61440/90000 (68%)]	Loss: -21.1741	Cost: 9.37s
Train Epoch: 1825 [81920/90000 (91%)]	Loss: -20.8819	Cost: 8.86s
Train Epoch: 1825 	Average Loss: -20.7231
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1181

Learning rate: 0.0001840093553898936
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1826 [0/90000 (0%)]	Loss: -15.6987	Cost: 27.64s
Train Epoch: 1826 [20480/90000 (23%)]	Loss: -21.1859	Cost: 9.28s
Train Epoch: 1826 [40960/90000 (45%)]	Loss: -20.9713	Cost: 9.31s
Train Epoch: 1826 [61440/90000 (68%)]	Loss: -20.8124	Cost: 9.17s
Train Epoch: 1826 [81920/90000 (91%)]	Loss: -20.8436	Cost: 9.03s
Train Epoch: 1826 	Average Loss: -20.6297
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2403

Learning rate: 0.00018399230994101262
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1827 [0/90000 (0%)]	Loss: -14.6687	Cost: 25.86s
Train Epoch: 1827 [20480/90000 (23%)]	Loss: -21.1190	Cost: 9.35s
Train Epoch: 1827 [40960/90000 (45%)]	Loss: -20.9044	Cost: 9.32s
Train Epoch: 1827 [61440/90000 (68%)]	Loss: -20.9332	Cost: 9.54s
Train Epoch: 1827 [81920/90000 (91%)]	Loss: -20.8966	Cost: 8.81s
Train Epoch: 1827 	Average Loss: -20.5139
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9782

Learning rate: 0.00018397525620242298
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1828 [0/90000 (0%)]	Loss: -13.7467	Cost: 25.78s
Train Epoch: 1828 [20480/90000 (23%)]	Loss: -21.1904	Cost: 9.37s
Train Epoch: 1828 [40960/90000 (45%)]	Loss: -20.9240	Cost: 9.32s
Train Epoch: 1828 [61440/90000 (68%)]	Loss: -20.9716	Cost: 9.09s
Train Epoch: 1828 [81920/90000 (91%)]	Loss: -20.7413	Cost: 8.80s
Train Epoch: 1828 	Average Loss: -20.5799
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2010

Learning rate: 0.0001839581941758078
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1829 [0/90000 (0%)]	Loss: -14.2839	Cost: 25.67s
Train Epoch: 1829 [20480/90000 (23%)]	Loss: -21.1531	Cost: 9.35s
Train Epoch: 1829 [40960/90000 (45%)]	Loss: -20.8179	Cost: 9.30s
Train Epoch: 1829 [61440/90000 (68%)]	Loss: -20.6928	Cost: 9.38s
Train Epoch: 1829 [81920/90000 (91%)]	Loss: -20.7101	Cost: 8.85s
Train Epoch: 1829 	Average Loss: -20.5696
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1557

Learning rate: 0.00018394112386285107
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1830 [0/90000 (0%)]	Loss: -13.6865	Cost: 25.11s
Train Epoch: 1830 [20480/90000 (23%)]	Loss: -21.1613	Cost: 9.25s
Train Epoch: 1830 [40960/90000 (45%)]	Loss: -21.2289	Cost: 9.36s
Train Epoch: 1830 [61440/90000 (68%)]	Loss: -20.7252	Cost: 9.14s
Train Epoch: 1830 [81920/90000 (91%)]	Loss: -20.5807	Cost: 8.95s
Train Epoch: 1830 	Average Loss: -20.4792
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8894

Learning rate: 0.00018392404526523755
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1831 [0/90000 (0%)]	Loss: -13.8000	Cost: 25.15s
Train Epoch: 1831 [20480/90000 (23%)]	Loss: -20.9697	Cost: 9.43s
Train Epoch: 1831 [40960/90000 (45%)]	Loss: -20.8088	Cost: 9.67s
Train Epoch: 1831 [61440/90000 (68%)]	Loss: -20.6641	Cost: 9.23s
Train Epoch: 1831 [81920/90000 (91%)]	Loss: -20.3800	Cost: 8.82s
Train Epoch: 1831 	Average Loss: -20.3447
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1714

Learning rate: 0.00018390695838465284
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1832 [0/90000 (0%)]	Loss: -14.5882	Cost: 24.82s
Train Epoch: 1832 [20480/90000 (23%)]	Loss: -20.8313	Cost: 9.89s
Train Epoch: 1832 [40960/90000 (45%)]	Loss: -20.7078	Cost: 9.03s
Train Epoch: 1832 [61440/90000 (68%)]	Loss: -20.5804	Cost: 8.96s
Train Epoch: 1832 [81920/90000 (91%)]	Loss: -20.3130	Cost: 8.71s
Train Epoch: 1832 	Average Loss: -20.2563
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9847

Learning rate: 0.0001838898632227834
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1833 [0/90000 (0%)]	Loss: -14.7802	Cost: 24.65s
Train Epoch: 1833 [20480/90000 (23%)]	Loss: -21.0463	Cost: 9.53s
Train Epoch: 1833 [40960/90000 (45%)]	Loss: -20.7886	Cost: 9.49s
Train Epoch: 1833 [61440/90000 (68%)]	Loss: -20.6631	Cost: 9.15s
Train Epoch: 1833 [81920/90000 (91%)]	Loss: -20.9256	Cost: 9.44s
Train Epoch: 1833 	Average Loss: -20.4982
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4549

Learning rate: 0.00018387275978131633
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1834 [0/90000 (0%)]	Loss: -14.0875	Cost: 24.43s
Train Epoch: 1834 [20480/90000 (23%)]	Loss: -20.8132	Cost: 9.38s
Train Epoch: 1834 [40960/90000 (45%)]	Loss: -20.6401	Cost: 9.62s
Train Epoch: 1834 [61440/90000 (68%)]	Loss: -20.7495	Cost: 9.10s
Train Epoch: 1834 [81920/90000 (91%)]	Loss: -20.8501	Cost: 10.08s
Train Epoch: 1834 	Average Loss: -20.4738
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3584

Learning rate: 0.00018385564806193977
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1835 [0/90000 (0%)]	Loss: -14.6415	Cost: 23.55s
Train Epoch: 1835 [20480/90000 (23%)]	Loss: -21.1750	Cost: 9.59s
Train Epoch: 1835 [40960/90000 (45%)]	Loss: -20.7855	Cost: 9.22s
Train Epoch: 1835 [61440/90000 (68%)]	Loss: -20.9391	Cost: 9.26s
Train Epoch: 1835 [81920/90000 (91%)]	Loss: -20.6542	Cost: 9.96s
Train Epoch: 1835 	Average Loss: -20.6061
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3665

Learning rate: 0.00018383852806634252
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1836 [0/90000 (0%)]	Loss: -13.6683	Cost: 23.19s
Train Epoch: 1836 [20480/90000 (23%)]	Loss: -20.9636	Cost: 9.08s
Train Epoch: 1836 [40960/90000 (45%)]	Loss: -20.9982	Cost: 9.34s
Train Epoch: 1836 [61440/90000 (68%)]	Loss: -21.1022	Cost: 9.04s
Train Epoch: 1836 [81920/90000 (91%)]	Loss: -20.8557	Cost: 9.96s
Train Epoch: 1836 	Average Loss: -20.6417
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4237

Learning rate: 0.0001838213997962143
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1837 [0/90000 (0%)]	Loss: -14.3773	Cost: 24.85s
Train Epoch: 1837 [20480/90000 (23%)]	Loss: -21.3397	Cost: 9.37s
Train Epoch: 1837 [40960/90000 (45%)]	Loss: -20.9000	Cost: 9.24s
Train Epoch: 1837 [61440/90000 (68%)]	Loss: -20.9740	Cost: 9.33s
Train Epoch: 1837 [81920/90000 (91%)]	Loss: -20.9792	Cost: 9.81s
Train Epoch: 1837 	Average Loss: -20.7707
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4071

Learning rate: 0.00018380426325324557
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1838 [0/90000 (0%)]	Loss: -14.9197	Cost: 24.06s
Train Epoch: 1838 [20480/90000 (23%)]	Loss: -21.2491	Cost: 9.40s
Train Epoch: 1838 [40960/90000 (45%)]	Loss: -20.9925	Cost: 9.26s
Train Epoch: 1838 [61440/90000 (68%)]	Loss: -20.9269	Cost: 9.15s
Train Epoch: 1838 [81920/90000 (91%)]	Loss: -21.0183	Cost: 9.07s
Train Epoch: 1838 	Average Loss: -20.6388
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3879

Learning rate: 0.00018378711843912768
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1839 [0/90000 (0%)]	Loss: -14.5468	Cost: 23.99s
Train Epoch: 1839 [20480/90000 (23%)]	Loss: -21.4305	Cost: 9.39s
Train Epoch: 1839 [40960/90000 (45%)]	Loss: -20.9273	Cost: 9.26s
Train Epoch: 1839 [61440/90000 (68%)]	Loss: -20.9698	Cost: 9.34s
Train Epoch: 1839 [81920/90000 (91%)]	Loss: -20.8952	Cost: 9.18s
Train Epoch: 1839 	Average Loss: -20.7273
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4188

Learning rate: 0.00018376996535555268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1840 [0/90000 (0%)]	Loss: -15.1918	Cost: 24.43s
Train Epoch: 1840 [20480/90000 (23%)]	Loss: -21.3775	Cost: 9.34s
Train Epoch: 1840 [40960/90000 (45%)]	Loss: -20.5169	Cost: 9.27s
Train Epoch: 1840 [61440/90000 (68%)]	Loss: -20.6877	Cost: 9.13s
Train Epoch: 1840 [81920/90000 (91%)]	Loss: -20.3473	Cost: 9.06s
Train Epoch: 1840 	Average Loss: -20.4080
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8837

Learning rate: 0.00018375280400421363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1841 [0/90000 (0%)]	Loss: -14.7368	Cost: 26.26s
Train Epoch: 1841 [20480/90000 (23%)]	Loss: -20.7920	Cost: 9.34s
Train Epoch: 1841 [40960/90000 (45%)]	Loss: -20.9692	Cost: 9.17s
Train Epoch: 1841 [61440/90000 (68%)]	Loss: -21.0423	Cost: 9.27s
Train Epoch: 1841 [81920/90000 (91%)]	Loss: -20.8056	Cost: 8.84s
Train Epoch: 1841 	Average Loss: -20.5126
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.3323

Learning rate: 0.00018373563438680416
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1842 [0/90000 (0%)]	Loss: -14.7557	Cost: 25.80s
Train Epoch: 1842 [20480/90000 (23%)]	Loss: -21.4939	Cost: 9.22s
Train Epoch: 1842 [40960/90000 (45%)]	Loss: -21.3387	Cost: 9.28s
Train Epoch: 1842 [61440/90000 (68%)]	Loss: -21.4746	Cost: 8.96s
Train Epoch: 1842 [81920/90000 (91%)]	Loss: -20.9497	Cost: 8.76s
Train Epoch: 1842 	Average Loss: -20.8780
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4421

Learning rate: 0.00018371845650501893
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1843 [0/90000 (0%)]	Loss: -15.2499	Cost: 25.31s
Train Epoch: 1843 [20480/90000 (23%)]	Loss: -21.5257	Cost: 9.41s
Train Epoch: 1843 [40960/90000 (45%)]	Loss: -21.1573	Cost: 9.30s
Train Epoch: 1843 [61440/90000 (68%)]	Loss: -21.1523	Cost: 9.44s
Train Epoch: 1843 [81920/90000 (91%)]	Loss: -20.6476	Cost: 8.83s
Train Epoch: 1843 	Average Loss: -20.6926
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2718

Learning rate: 0.0001837012703605533
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1844 [0/90000 (0%)]	Loss: -14.0517	Cost: 26.59s
Train Epoch: 1844 [20480/90000 (23%)]	Loss: -21.1705	Cost: 9.37s
Train Epoch: 1844 [40960/90000 (45%)]	Loss: -21.0595	Cost: 9.29s
Train Epoch: 1844 [61440/90000 (68%)]	Loss: -21.2225	Cost: 9.20s
Train Epoch: 1844 [81920/90000 (91%)]	Loss: -21.0014	Cost: 9.09s
Train Epoch: 1844 	Average Loss: -20.7455
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6487

Learning rate: 0.00018368407595510344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1845 [0/90000 (0%)]	Loss: -14.2971	Cost: 27.20s
Train Epoch: 1845 [20480/90000 (23%)]	Loss: -21.5457	Cost: 9.29s
Train Epoch: 1845 [40960/90000 (45%)]	Loss: -21.4177	Cost: 9.36s
Train Epoch: 1845 [61440/90000 (68%)]	Loss: -21.2862	Cost: 9.50s
Train Epoch: 1845 [81920/90000 (91%)]	Loss: -21.2866	Cost: 8.77s
Train Epoch: 1845 	Average Loss: -20.9385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7831

Learning rate: 0.00018366687329036643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1846 [0/90000 (0%)]	Loss: -14.9035	Cost: 25.10s
Train Epoch: 1846 [20480/90000 (23%)]	Loss: -21.6688	Cost: 9.46s
Train Epoch: 1846 [40960/90000 (45%)]	Loss: -21.4615	Cost: 9.24s
Train Epoch: 1846 [61440/90000 (68%)]	Loss: -21.5223	Cost: 9.20s
Train Epoch: 1846 [81920/90000 (91%)]	Loss: -21.3081	Cost: 8.94s
Train Epoch: 1846 	Average Loss: -21.0579
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5987

Learning rate: 0.00018364966236804009
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1847 [0/90000 (0%)]	Loss: -14.5037	Cost: 25.03s
Train Epoch: 1847 [20480/90000 (23%)]	Loss: -21.7006	Cost: 9.35s
Train Epoch: 1847 [40960/90000 (45%)]	Loss: -21.4338	Cost: 9.61s
Train Epoch: 1847 [61440/90000 (68%)]	Loss: -21.7492	Cost: 9.53s
Train Epoch: 1847 [81920/90000 (91%)]	Loss: -21.4747	Cost: 8.87s
Train Epoch: 1847 	Average Loss: -21.1171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7325

Learning rate: 0.00018363244318982304
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1848 [0/90000 (0%)]	Loss: -13.7398	Cost: 25.93s
Train Epoch: 1848 [20480/90000 (23%)]	Loss: -21.8754	Cost: 9.38s
Train Epoch: 1848 [40960/90000 (45%)]	Loss: -21.3805	Cost: 10.02s
Train Epoch: 1848 [61440/90000 (68%)]	Loss: -21.5472	Cost: 9.24s
Train Epoch: 1848 [81920/90000 (91%)]	Loss: -21.5115	Cost: 9.02s
Train Epoch: 1848 	Average Loss: -21.1295
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8800

Learning rate: 0.00018361521575741477
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1849 [0/90000 (0%)]	Loss: -15.2873	Cost: 26.23s
Train Epoch: 1849 [20480/90000 (23%)]	Loss: -21.8372	Cost: 9.50s
Train Epoch: 1849 [40960/90000 (45%)]	Loss: -21.7641	Cost: 9.65s
Train Epoch: 1849 [61440/90000 (68%)]	Loss: -21.6067	Cost: 9.37s
Train Epoch: 1849 [81920/90000 (91%)]	Loss: -21.4887	Cost: 8.87s
Train Epoch: 1849 	Average Loss: -21.2653
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9316

Learning rate: 0.00018359798007251555
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1850 [0/90000 (0%)]	Loss: -15.3442	Cost: 25.54s
Train Epoch: 1850 [20480/90000 (23%)]	Loss: -21.8414	Cost: 9.32s
Train Epoch: 1850 [40960/90000 (45%)]	Loss: -21.3590	Cost: 9.45s
Train Epoch: 1850 [61440/90000 (68%)]	Loss: -21.3477	Cost: 9.08s
Train Epoch: 1850 [81920/90000 (91%)]	Loss: -21.0567	Cost: 8.87s
Train Epoch: 1850 	Average Loss: -21.0450
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5169

Saving model as model.pt_e1850 & waveforms_supplementary.hdf5_e1850
Learning rate: 0.0001835807361368265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1851 [0/90000 (0%)]	Loss: -14.8668	Cost: 24.97s
Train Epoch: 1851 [20480/90000 (23%)]	Loss: -21.6758	Cost: 9.52s
Train Epoch: 1851 [40960/90000 (45%)]	Loss: -21.4693	Cost: 9.27s
Train Epoch: 1851 [61440/90000 (68%)]	Loss: -21.6465	Cost: 9.15s
Train Epoch: 1851 [81920/90000 (91%)]	Loss: -21.5670	Cost: 8.86s
Train Epoch: 1851 	Average Loss: -21.0715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8569

Learning rate: 0.00018356348395204945
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1852 [0/90000 (0%)]	Loss: -15.0720	Cost: 25.00s
Train Epoch: 1852 [20480/90000 (23%)]	Loss: -21.8429	Cost: 9.50s
Train Epoch: 1852 [40960/90000 (45%)]	Loss: -21.6432	Cost: 9.42s
Train Epoch: 1852 [61440/90000 (68%)]	Loss: -21.7495	Cost: 9.12s
Train Epoch: 1852 [81920/90000 (91%)]	Loss: -21.5827	Cost: 8.79s
Train Epoch: 1852 	Average Loss: -21.3003
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9295

Learning rate: 0.00018354622351988723
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1853 [0/90000 (0%)]	Loss: -15.2822	Cost: 25.28s
Train Epoch: 1853 [20480/90000 (23%)]	Loss: -22.0075	Cost: 9.58s
Train Epoch: 1853 [40960/90000 (45%)]	Loss: -21.8621	Cost: 9.23s
Train Epoch: 1853 [61440/90000 (68%)]	Loss: -21.7093	Cost: 9.02s
Train Epoch: 1853 [81920/90000 (91%)]	Loss: -21.1351	Cost: 8.79s
Train Epoch: 1853 	Average Loss: -21.2883
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6257

Learning rate: 0.0001835289548420433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1854 [0/90000 (0%)]	Loss: -15.0881	Cost: 24.83s
Train Epoch: 1854 [20480/90000 (23%)]	Loss: -21.6308	Cost: 9.57s
Train Epoch: 1854 [40960/90000 (45%)]	Loss: -21.5750	Cost: 9.22s
Train Epoch: 1854 [61440/90000 (68%)]	Loss: -21.5177	Cost: 9.02s
Train Epoch: 1854 [81920/90000 (91%)]	Loss: -21.4109	Cost: 9.73s
Train Epoch: 1854 	Average Loss: -21.0994
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5360

Learning rate: 0.00018351167792022202
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1855 [0/90000 (0%)]	Loss: -14.7695	Cost: 24.80s
Train Epoch: 1855 [20480/90000 (23%)]	Loss: -21.2679	Cost: 9.70s
Train Epoch: 1855 [40960/90000 (45%)]	Loss: -21.0919	Cost: 9.92s
Train Epoch: 1855 [61440/90000 (68%)]	Loss: -21.2828	Cost: 9.06s
Train Epoch: 1855 [81920/90000 (91%)]	Loss: -21.1304	Cost: 10.21s
Train Epoch: 1855 	Average Loss: -20.7703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5536

Learning rate: 0.0001834943927561286
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1856 [0/90000 (0%)]	Loss: -14.3035	Cost: 23.80s
Train Epoch: 1856 [20480/90000 (23%)]	Loss: -21.1580	Cost: 9.62s
Train Epoch: 1856 [40960/90000 (45%)]	Loss: -20.7820	Cost: 9.18s
Train Epoch: 1856 [61440/90000 (68%)]	Loss: -21.0638	Cost: 9.12s
Train Epoch: 1856 [81920/90000 (91%)]	Loss: -20.9974	Cost: 10.17s
Train Epoch: 1856 	Average Loss: -20.6334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6052

Learning rate: 0.00018347709935146895
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1857 [0/90000 (0%)]	Loss: -15.6223	Cost: 25.22s
Train Epoch: 1857 [20480/90000 (23%)]	Loss: -21.6081	Cost: 9.00s
Train Epoch: 1857 [40960/90000 (45%)]	Loss: -21.5595	Cost: 9.52s
Train Epoch: 1857 [61440/90000 (68%)]	Loss: -21.8902	Cost: 9.02s
Train Epoch: 1857 [81920/90000 (91%)]	Loss: -21.4977	Cost: 10.19s
Train Epoch: 1857 	Average Loss: -21.2093
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0151

Learning rate: 0.00018345979770794995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1858 [0/90000 (0%)]	Loss: -15.5350	Cost: 23.78s
Train Epoch: 1858 [20480/90000 (23%)]	Loss: -21.9121	Cost: 9.09s
Train Epoch: 1858 [40960/90000 (45%)]	Loss: -21.7710	Cost: 9.57s
Train Epoch: 1858 [61440/90000 (68%)]	Loss: -21.5981	Cost: 9.10s
Train Epoch: 1858 [81920/90000 (91%)]	Loss: -21.4052	Cost: 10.28s
Train Epoch: 1858 	Average Loss: -21.3566
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7973

Learning rate: 0.00018344248782727914
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1859 [0/90000 (0%)]	Loss: -15.1588	Cost: 23.51s
Train Epoch: 1859 [20480/90000 (23%)]	Loss: -21.4292	Cost: 9.05s
Train Epoch: 1859 [40960/90000 (45%)]	Loss: -21.2591	Cost: 9.22s
Train Epoch: 1859 [61440/90000 (68%)]	Loss: -21.4543	Cost: 9.02s
Train Epoch: 1859 [81920/90000 (91%)]	Loss: -21.5110	Cost: 9.02s
Train Epoch: 1859 	Average Loss: -21.0828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9354

Learning rate: 0.0001834251697111649
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1860 [0/90000 (0%)]	Loss: -15.3018	Cost: 23.58s
Train Epoch: 1860 [20480/90000 (23%)]	Loss: -21.6935	Cost: 9.07s
Train Epoch: 1860 [40960/90000 (45%)]	Loss: -21.4859	Cost: 9.08s
Train Epoch: 1860 [61440/90000 (68%)]	Loss: -21.5724	Cost: 9.21s
Train Epoch: 1860 [81920/90000 (91%)]	Loss: -21.5363	Cost: 9.07s
Train Epoch: 1860 	Average Loss: -21.1878
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9117

Learning rate: 0.00018340784336131656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1861 [0/90000 (0%)]	Loss: -16.0290	Cost: 24.34s
Train Epoch: 1861 [20480/90000 (23%)]	Loss: -21.7010	Cost: 9.04s
Train Epoch: 1861 [40960/90000 (45%)]	Loss: -21.6798	Cost: 9.16s
Train Epoch: 1861 [61440/90000 (68%)]	Loss: -21.7058	Cost: 9.12s
Train Epoch: 1861 [81920/90000 (91%)]	Loss: -21.5668	Cost: 8.81s
Train Epoch: 1861 	Average Loss: -21.3472
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9865

Learning rate: 0.00018339050877944408
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1862 [0/90000 (0%)]	Loss: -15.7458	Cost: 25.83s
Train Epoch: 1862 [20480/90000 (23%)]	Loss: -22.0564	Cost: 9.34s
Train Epoch: 1862 [40960/90000 (45%)]	Loss: -21.6054	Cost: 9.28s
Train Epoch: 1862 [61440/90000 (68%)]	Loss: -21.3304	Cost: 9.16s
Train Epoch: 1862 [81920/90000 (91%)]	Loss: -21.2873	Cost: 8.88s
Train Epoch: 1862 	Average Loss: -21.2570
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9916

Learning rate: 0.00018337316596725835
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1863 [0/90000 (0%)]	Loss: -15.0178	Cost: 26.32s
Train Epoch: 1863 [20480/90000 (23%)]	Loss: -22.0125	Cost: 9.40s
Train Epoch: 1863 [40960/90000 (45%)]	Loss: -21.8283	Cost: 9.31s
Train Epoch: 1863 [61440/90000 (68%)]	Loss: -21.6787	Cost: 9.36s
Train Epoch: 1863 [81920/90000 (91%)]	Loss: -21.5755	Cost: 8.81s
Train Epoch: 1863 	Average Loss: -21.3797
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9432

Learning rate: 0.000183355814926471
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1864 [0/90000 (0%)]	Loss: -13.6504	Cost: 27.57s
Train Epoch: 1864 [20480/90000 (23%)]	Loss: -21.6156	Cost: 9.30s
Train Epoch: 1864 [40960/90000 (45%)]	Loss: -21.6543	Cost: 9.22s
Train Epoch: 1864 [61440/90000 (68%)]	Loss: -21.5640	Cost: 9.15s
Train Epoch: 1864 [81920/90000 (91%)]	Loss: -21.3411	Cost: 8.83s
Train Epoch: 1864 	Average Loss: -21.0551
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8414

Learning rate: 0.00018333845565879456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1865 [0/90000 (0%)]	Loss: -13.6705	Cost: 25.60s
Train Epoch: 1865 [20480/90000 (23%)]	Loss: -21.5002	Cost: 9.40s
Train Epoch: 1865 [40960/90000 (45%)]	Loss: -21.5917	Cost: 9.27s
Train Epoch: 1865 [61440/90000 (68%)]	Loss: -21.4582	Cost: 9.34s
Train Epoch: 1865 [81920/90000 (91%)]	Loss: -21.2838	Cost: 8.82s
Train Epoch: 1865 	Average Loss: -21.1075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8307

Learning rate: 0.00018332108816594234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1866 [0/90000 (0%)]	Loss: -15.7856	Cost: 27.85s
Train Epoch: 1866 [20480/90000 (23%)]	Loss: -21.6315	Cost: 9.31s
Train Epoch: 1866 [40960/90000 (45%)]	Loss: -21.6171	Cost: 9.34s
Train Epoch: 1866 [61440/90000 (68%)]	Loss: -21.6159	Cost: 9.38s
Train Epoch: 1866 [81920/90000 (91%)]	Loss: -21.4983	Cost: 8.88s
Train Epoch: 1866 	Average Loss: -21.2487
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9497

Learning rate: 0.00018330371244962835
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1867 [0/90000 (0%)]	Loss: -14.7718	Cost: 25.14s
Train Epoch: 1867 [20480/90000 (23%)]	Loss: -21.7055	Cost: 9.44s
Train Epoch: 1867 [40960/90000 (45%)]	Loss: -21.7027	Cost: 9.26s
Train Epoch: 1867 [61440/90000 (68%)]	Loss: -21.7445	Cost: 9.33s
Train Epoch: 1867 [81920/90000 (91%)]	Loss: -21.4604	Cost: 8.82s
Train Epoch: 1867 	Average Loss: -21.2991
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1456

Learning rate: 0.0001832863285115676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1868 [0/90000 (0%)]	Loss: -15.8164	Cost: 25.18s
Train Epoch: 1868 [20480/90000 (23%)]	Loss: -22.1021	Cost: 9.43s
Train Epoch: 1868 [40960/90000 (45%)]	Loss: -21.7761	Cost: 9.25s
Train Epoch: 1868 [61440/90000 (68%)]	Loss: -21.6665	Cost: 9.24s
Train Epoch: 1868 [81920/90000 (91%)]	Loss: -21.8446	Cost: 8.86s
Train Epoch: 1868 	Average Loss: -21.4049
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2013

Learning rate: 0.00018326893635347573
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1869 [0/90000 (0%)]	Loss: -14.5417	Cost: 26.00s
Train Epoch: 1869 [20480/90000 (23%)]	Loss: -21.9004	Cost: 9.36s
Train Epoch: 1869 [40960/90000 (45%)]	Loss: -21.6679	Cost: 9.81s
Train Epoch: 1869 [61440/90000 (68%)]	Loss: -21.9670	Cost: 9.36s
Train Epoch: 1869 [81920/90000 (91%)]	Loss: -21.5450	Cost: 8.84s
Train Epoch: 1869 	Average Loss: -21.4757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9424

Learning rate: 0.00018325153597706937
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1870 [0/90000 (0%)]	Loss: -15.5468	Cost: 25.05s
Train Epoch: 1870 [20480/90000 (23%)]	Loss: -22.0258	Cost: 9.07s
Train Epoch: 1870 [40960/90000 (45%)]	Loss: -21.7914	Cost: 9.59s
Train Epoch: 1870 [61440/90000 (68%)]	Loss: -21.8696	Cost: 9.11s
Train Epoch: 1870 [81920/90000 (91%)]	Loss: -21.6061	Cost: 8.90s
Train Epoch: 1870 	Average Loss: -21.4309
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1874

Learning rate: 0.00018323412738406578
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1871 [0/90000 (0%)]	Loss: -13.6071	Cost: 26.22s
Train Epoch: 1871 [20480/90000 (23%)]	Loss: -21.7537	Cost: 9.47s
Train Epoch: 1871 [40960/90000 (45%)]	Loss: -21.8243	Cost: 10.06s
Train Epoch: 1871 [61440/90000 (68%)]	Loss: -21.2946	Cost: 9.15s
Train Epoch: 1871 [81920/90000 (91%)]	Loss: -21.3259	Cost: 9.14s
Train Epoch: 1871 	Average Loss: -21.1377
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8200

Learning rate: 0.00018321671057618317
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1872 [0/90000 (0%)]	Loss: -14.9619	Cost: 26.12s
Train Epoch: 1872 [20480/90000 (23%)]	Loss: -21.5995	Cost: 9.32s
Train Epoch: 1872 [40960/90000 (45%)]	Loss: -21.7006	Cost: 9.57s
Train Epoch: 1872 [61440/90000 (68%)]	Loss: -21.6406	Cost: 9.01s
Train Epoch: 1872 [81920/90000 (91%)]	Loss: -21.6831	Cost: 8.97s
Train Epoch: 1872 	Average Loss: -21.2569
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2143

Learning rate: 0.0001831992855551405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1873 [0/90000 (0%)]	Loss: -15.3902	Cost: 25.27s
Train Epoch: 1873 [20480/90000 (23%)]	Loss: -22.0334	Cost: 9.88s
Train Epoch: 1873 [40960/90000 (45%)]	Loss: -21.9273	Cost: 9.12s
Train Epoch: 1873 [61440/90000 (68%)]	Loss: -21.6433	Cost: 9.17s
Train Epoch: 1873 [81920/90000 (91%)]	Loss: -21.4467	Cost: 8.70s
Train Epoch: 1873 	Average Loss: -21.4002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9887

Learning rate: 0.00018318185232265753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1874 [0/90000 (0%)]	Loss: -15.3051	Cost: 24.70s
Train Epoch: 1874 [20480/90000 (23%)]	Loss: -22.1286	Cost: 9.57s
Train Epoch: 1874 [40960/90000 (45%)]	Loss: -21.9170	Cost: 9.18s
Train Epoch: 1874 [61440/90000 (68%)]	Loss: -21.4880	Cost: 9.04s
Train Epoch: 1874 [81920/90000 (91%)]	Loss: -20.8476	Cost: 9.37s
Train Epoch: 1874 	Average Loss: -21.2256
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5103

Learning rate: 0.0001831644108804549
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1875 [0/90000 (0%)]	Loss: -14.8723	Cost: 24.20s
Train Epoch: 1875 [20480/90000 (23%)]	Loss: -20.9544	Cost: 9.61s
Train Epoch: 1875 [40960/90000 (45%)]	Loss: -21.0481	Cost: 9.43s
Train Epoch: 1875 [61440/90000 (68%)]	Loss: -21.1302	Cost: 9.27s
Train Epoch: 1875 [81920/90000 (91%)]	Loss: -21.2169	Cost: 9.80s
Train Epoch: 1875 	Average Loss: -20.7782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5360

Learning rate: 0.00018314696123025397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1876 [0/90000 (0%)]	Loss: -14.5434	Cost: 24.48s
Train Epoch: 1876 [20480/90000 (23%)]	Loss: -21.5949	Cost: 9.02s
Train Epoch: 1876 [40960/90000 (45%)]	Loss: -21.1101	Cost: 10.01s
Train Epoch: 1876 [61440/90000 (68%)]	Loss: -21.3138	Cost: 9.08s
Train Epoch: 1876 [81920/90000 (91%)]	Loss: -21.2392	Cost: 10.22s
Train Epoch: 1876 	Average Loss: -20.9322
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9727

Learning rate: 0.00018312950337377693
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1877 [0/90000 (0%)]	Loss: -15.2433	Cost: 24.39s
Train Epoch: 1877 [20480/90000 (23%)]	Loss: -21.4581	Cost: 9.19s
Train Epoch: 1877 [40960/90000 (45%)]	Loss: -21.4548	Cost: 9.44s
Train Epoch: 1877 [61440/90000 (68%)]	Loss: -21.2853	Cost: 9.27s
Train Epoch: 1877 [81920/90000 (91%)]	Loss: -21.2895	Cost: 9.91s
Train Epoch: 1877 	Average Loss: -20.9595
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9588

Learning rate: 0.0001831120373127469
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1878 [0/90000 (0%)]	Loss: -14.9673	Cost: 23.36s
Train Epoch: 1878 [20480/90000 (23%)]	Loss: -21.7212	Cost: 9.04s
Train Epoch: 1878 [40960/90000 (45%)]	Loss: -21.6777	Cost: 9.12s
Train Epoch: 1878 [61440/90000 (68%)]	Loss: -21.6260	Cost: 9.07s
Train Epoch: 1878 [81920/90000 (91%)]	Loss: -21.6156	Cost: 9.10s
Train Epoch: 1878 	Average Loss: -21.2296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9987

Learning rate: 0.00018309456304888762
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1879 [0/90000 (0%)]	Loss: -15.2195	Cost: 24.42s
Train Epoch: 1879 [20480/90000 (23%)]	Loss: -22.1750	Cost: 9.05s
Train Epoch: 1879 [40960/90000 (45%)]	Loss: -21.6892	Cost: 10.11s
Train Epoch: 1879 [61440/90000 (68%)]	Loss: -21.6624	Cost: 9.24s
Train Epoch: 1879 [81920/90000 (91%)]	Loss: -21.4350	Cost: 10.00s
Train Epoch: 1879 	Average Loss: -21.2812
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8773

Learning rate: 0.00018307708058392373
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1880 [0/90000 (0%)]	Loss: -15.2340	Cost: 24.14s
Train Epoch: 1880 [20480/90000 (23%)]	Loss: -21.9348	Cost: 9.18s
Train Epoch: 1880 [40960/90000 (45%)]	Loss: -21.8202	Cost: 9.77s
Train Epoch: 1880 [61440/90000 (68%)]	Loss: -21.8309	Cost: 9.03s
Train Epoch: 1880 [81920/90000 (91%)]	Loss: -21.7339	Cost: 8.99s
Train Epoch: 1880 	Average Loss: -21.4375
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2305

Learning rate: 0.00018305958991958072
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1881 [0/90000 (0%)]	Loss: -15.3982	Cost: 24.61s
Train Epoch: 1881 [20480/90000 (23%)]	Loss: -22.1145	Cost: 9.11s
Train Epoch: 1881 [40960/90000 (45%)]	Loss: -21.8637	Cost: 9.03s
Train Epoch: 1881 [61440/90000 (68%)]	Loss: -21.7833	Cost: 9.11s
Train Epoch: 1881 [81920/90000 (91%)]	Loss: -21.8631	Cost: 8.93s
Train Epoch: 1881 	Average Loss: -21.5308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0560

Learning rate: 0.00018304209105758483
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1882 [0/90000 (0%)]	Loss: -15.0618	Cost: 25.72s
Train Epoch: 1882 [20480/90000 (23%)]	Loss: -22.1021	Cost: 9.04s
Train Epoch: 1882 [40960/90000 (45%)]	Loss: -21.5593	Cost: 9.65s
Train Epoch: 1882 [61440/90000 (68%)]	Loss: -21.3748	Cost: 8.97s
Train Epoch: 1882 [81920/90000 (91%)]	Loss: -21.0480	Cost: 9.00s
Train Epoch: 1882 	Average Loss: -21.1288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5539

Learning rate: 0.00018302458399966314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1883 [0/90000 (0%)]	Loss: -15.5213	Cost: 25.07s
Train Epoch: 1883 [20480/90000 (23%)]	Loss: -21.5764	Cost: 9.18s
Train Epoch: 1883 [40960/90000 (45%)]	Loss: -21.6751	Cost: 9.16s
Train Epoch: 1883 [61440/90000 (68%)]	Loss: -21.5244	Cost: 9.21s
Train Epoch: 1883 [81920/90000 (91%)]	Loss: -21.5626	Cost: 8.77s
Train Epoch: 1883 	Average Loss: -21.1588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0485

Learning rate: 0.00018300706874754352
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1884 [0/90000 (0%)]	Loss: -15.4185	Cost: 25.54s
Train Epoch: 1884 [20480/90000 (23%)]	Loss: -21.9431	Cost: 9.40s
Train Epoch: 1884 [40960/90000 (45%)]	Loss: -22.1141	Cost: 9.29s
Train Epoch: 1884 [61440/90000 (68%)]	Loss: -21.8200	Cost: 9.15s
Train Epoch: 1884 [81920/90000 (91%)]	Loss: -21.8585	Cost: 8.88s
Train Epoch: 1884 	Average Loss: -21.4772
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2463

Learning rate: 0.00018298954530295467
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1885 [0/90000 (0%)]	Loss: -15.0073	Cost: 27.93s
Train Epoch: 1885 [20480/90000 (23%)]	Loss: -22.1654	Cost: 9.32s
Train Epoch: 1885 [40960/90000 (45%)]	Loss: -21.8624	Cost: 9.27s
Train Epoch: 1885 [61440/90000 (68%)]	Loss: -21.8601	Cost: 9.29s
Train Epoch: 1885 [81920/90000 (91%)]	Loss: -21.8899	Cost: 8.85s
Train Epoch: 1885 	Average Loss: -21.4762
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1673

Learning rate: 0.00018297201366762603
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1886 [0/90000 (0%)]	Loss: -15.5363	Cost: 27.34s
Train Epoch: 1886 [20480/90000 (23%)]	Loss: -22.2649	Cost: 9.30s
Train Epoch: 1886 [40960/90000 (45%)]	Loss: -21.9950	Cost: 9.30s
Train Epoch: 1886 [61440/90000 (68%)]	Loss: -21.7566	Cost: 9.16s
Train Epoch: 1886 [81920/90000 (91%)]	Loss: -21.6216	Cost: 8.79s
Train Epoch: 1886 	Average Loss: -21.4800
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8603

Learning rate: 0.00018295447384328797
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1887 [0/90000 (0%)]	Loss: -14.8631	Cost: 28.17s
Train Epoch: 1887 [20480/90000 (23%)]	Loss: -21.9531	Cost: 9.35s
Train Epoch: 1887 [40960/90000 (45%)]	Loss: -21.8941	Cost: 9.35s
Train Epoch: 1887 [61440/90000 (68%)]	Loss: -21.7284	Cost: 9.30s
Train Epoch: 1887 [81920/90000 (91%)]	Loss: -21.3228	Cost: 8.74s
Train Epoch: 1887 	Average Loss: -21.2917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9020

Learning rate: 0.00018293692583167158
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1888 [0/90000 (0%)]	Loss: -14.6418	Cost: 28.42s
Train Epoch: 1888 [20480/90000 (23%)]	Loss: -21.7908	Cost: 9.47s
Train Epoch: 1888 [40960/90000 (45%)]	Loss: -21.8714	Cost: 9.24s
Train Epoch: 1888 [61440/90000 (68%)]	Loss: -21.7298	Cost: 9.19s
Train Epoch: 1888 [81920/90000 (91%)]	Loss: -21.4858	Cost: 8.78s
Train Epoch: 1888 	Average Loss: -21.2728
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9801

Learning rate: 0.00018291936963450874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1889 [0/90000 (0%)]	Loss: -15.5499	Cost: 26.93s
Train Epoch: 1889 [20480/90000 (23%)]	Loss: -22.0329	Cost: 9.37s
Train Epoch: 1889 [40960/90000 (45%)]	Loss: -21.7185	Cost: 9.30s
Train Epoch: 1889 [61440/90000 (68%)]	Loss: -21.7648	Cost: 9.44s
Train Epoch: 1889 [81920/90000 (91%)]	Loss: -21.2768	Cost: 9.04s
Train Epoch: 1889 	Average Loss: -21.3318
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0241

Learning rate: 0.00018290180525353227
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1890 [0/90000 (0%)]	Loss: -15.2193	Cost: 25.82s
Train Epoch: 1890 [20480/90000 (23%)]	Loss: -21.9806	Cost: 9.42s
Train Epoch: 1890 [40960/90000 (45%)]	Loss: -21.4896	Cost: 9.35s
Train Epoch: 1890 [61440/90000 (68%)]	Loss: -21.6132	Cost: 9.11s
Train Epoch: 1890 [81920/90000 (91%)]	Loss: -21.2197	Cost: 9.02s
Train Epoch: 1890 	Average Loss: -21.1940
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7071

Learning rate: 0.00018288423269047563
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1891 [0/90000 (0%)]	Loss: -15.5554	Cost: 25.07s
Train Epoch: 1891 [20480/90000 (23%)]	Loss: -21.7111	Cost: 9.57s
Train Epoch: 1891 [40960/90000 (45%)]	Loss: -21.5750	Cost: 9.42s
Train Epoch: 1891 [61440/90000 (68%)]	Loss: -21.6937	Cost: 9.28s
Train Epoch: 1891 [81920/90000 (91%)]	Loss: -21.7584	Cost: 9.04s
Train Epoch: 1891 	Average Loss: -21.3191
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0814

Learning rate: 0.00018286665194707316
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1892 [0/90000 (0%)]	Loss: -15.4894	Cost: 25.77s
Train Epoch: 1892 [20480/90000 (23%)]	Loss: -22.0563	Cost: 9.65s
Train Epoch: 1892 [40960/90000 (45%)]	Loss: -21.7944	Cost: 10.00s
Train Epoch: 1892 [61440/90000 (68%)]	Loss: -21.7507	Cost: 9.07s
Train Epoch: 1892 [81920/90000 (91%)]	Loss: -21.4332	Cost: 8.87s
Train Epoch: 1892 	Average Loss: -21.3440
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0559

Learning rate: 0.00018284906302506006
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1893 [0/90000 (0%)]	Loss: -15.0674	Cost: 25.39s
Train Epoch: 1893 [20480/90000 (23%)]	Loss: -21.5162	Cost: 10.40s
Train Epoch: 1893 [40960/90000 (45%)]	Loss: -21.5590	Cost: 9.33s
Train Epoch: 1893 [61440/90000 (68%)]	Loss: -21.4731	Cost: 9.36s
Train Epoch: 1893 [81920/90000 (91%)]	Loss: -21.2953	Cost: 8.78s
Train Epoch: 1893 	Average Loss: -21.1017
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7993

Learning rate: 0.00018283146592617224
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1894 [0/90000 (0%)]	Loss: -15.1369	Cost: 25.13s
Train Epoch: 1894 [20480/90000 (23%)]	Loss: -21.8715	Cost: 9.78s
Train Epoch: 1894 [40960/90000 (45%)]	Loss: -21.7547	Cost: 9.23s
Train Epoch: 1894 [61440/90000 (68%)]	Loss: -20.4761	Cost: 9.13s
Train Epoch: 1894 [81920/90000 (91%)]	Loss: -19.4368	Cost: 9.35s
Train Epoch: 1894 	Average Loss: -20.6120
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1999

Learning rate: 0.0001828138606521465
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1895 [0/90000 (0%)]	Loss: -12.8501	Cost: 24.06s
Train Epoch: 1895 [20480/90000 (23%)]	Loss: -20.1648	Cost: 9.65s
Train Epoch: 1895 [40960/90000 (45%)]	Loss: -20.2162	Cost: 9.46s
Train Epoch: 1895 [61440/90000 (68%)]	Loss: -20.3784	Cost: 9.20s
Train Epoch: 1895 [81920/90000 (91%)]	Loss: -20.5258	Cost: 9.72s
Train Epoch: 1895 	Average Loss: -19.9149
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5454

Learning rate: 0.00018279624720472036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1896 [0/90000 (0%)]	Loss: -14.0829	Cost: 23.58s
Train Epoch: 1896 [20480/90000 (23%)]	Loss: -21.2694	Cost: 9.58s
Train Epoch: 1896 [40960/90000 (45%)]	Loss: -21.2230	Cost: 9.27s
Train Epoch: 1896 [61440/90000 (68%)]	Loss: -21.2515	Cost: 9.10s
Train Epoch: 1896 [81920/90000 (91%)]	Loss: -21.0706	Cost: 10.06s
Train Epoch: 1896 	Average Loss: -20.8039
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6161

Learning rate: 0.0001827786255856322
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1897 [0/90000 (0%)]	Loss: -13.4972	Cost: 23.83s
Train Epoch: 1897 [20480/90000 (23%)]	Loss: -21.6470	Cost: 9.18s
Train Epoch: 1897 [40960/90000 (45%)]	Loss: -21.5343	Cost: 9.86s
Train Epoch: 1897 [61440/90000 (68%)]	Loss: -21.6599	Cost: 9.23s
Train Epoch: 1897 [81920/90000 (91%)]	Loss: -21.5888	Cost: 10.30s
Train Epoch: 1897 	Average Loss: -21.1191
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0499

Learning rate: 0.0001827609957966213
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1898 [0/90000 (0%)]	Loss: -15.6219	Cost: 24.37s
Train Epoch: 1898 [20480/90000 (23%)]	Loss: -21.7349	Cost: 9.29s
Train Epoch: 1898 [40960/90000 (45%)]	Loss: -21.4942	Cost: 9.46s
Train Epoch: 1898 [61440/90000 (68%)]	Loss: -21.4760	Cost: 9.15s
Train Epoch: 1898 [81920/90000 (91%)]	Loss: -21.4517	Cost: 10.09s
Train Epoch: 1898 	Average Loss: -21.1572
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0080

Learning rate: 0.00018274335783942757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1899 [0/90000 (0%)]	Loss: -15.5468	Cost: 23.44s
Train Epoch: 1899 [20480/90000 (23%)]	Loss: -22.0732	Cost: 9.31s
Train Epoch: 1899 [40960/90000 (45%)]	Loss: -21.8802	Cost: 9.33s
Train Epoch: 1899 [61440/90000 (68%)]	Loss: -21.8960	Cost: 9.78s
Train Epoch: 1899 [81920/90000 (91%)]	Loss: -21.2447	Cost: 9.23s
Train Epoch: 1899 	Average Loss: -21.4222
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8642

Learning rate: 0.0001827257117157918
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1900 [0/90000 (0%)]	Loss: -14.6581	Cost: 23.91s
Train Epoch: 1900 [20480/90000 (23%)]	Loss: -21.6925	Cost: 9.37s
Train Epoch: 1900 [40960/90000 (45%)]	Loss: -21.6758	Cost: 9.30s
Train Epoch: 1900 [61440/90000 (68%)]	Loss: -21.3972	Cost: 9.06s
Train Epoch: 1900 [81920/90000 (91%)]	Loss: -21.5574	Cost: 9.20s
Train Epoch: 1900 	Average Loss: -21.1761
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9508

Saving model as model.pt_e1900 & waveforms_supplementary.hdf5_e1900
Learning rate: 0.0001827080574274556
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1901 [0/90000 (0%)]	Loss: -14.3839	Cost: 23.36s
Train Epoch: 1901 [20480/90000 (23%)]	Loss: -22.0461	Cost: 9.32s
Train Epoch: 1901 [40960/90000 (45%)]	Loss: -21.9080	Cost: 9.28s
Train Epoch: 1901 [61440/90000 (68%)]	Loss: -21.7985	Cost: 9.15s
Train Epoch: 1901 [81920/90000 (91%)]	Loss: -21.6221	Cost: 9.32s
Train Epoch: 1901 	Average Loss: -21.3792
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0505

Learning rate: 0.00018269039497616142
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1902 [0/90000 (0%)]	Loss: -15.1490	Cost: 24.78s
Train Epoch: 1902 [20480/90000 (23%)]	Loss: -21.6095	Cost: 9.40s
Train Epoch: 1902 [40960/90000 (45%)]	Loss: -21.7227	Cost: 9.28s
Train Epoch: 1902 [61440/90000 (68%)]	Loss: -21.5674	Cost: 9.14s
Train Epoch: 1902 [81920/90000 (91%)]	Loss: -21.2622	Cost: 9.01s
Train Epoch: 1902 	Average Loss: -21.1521
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7982

Learning rate: 0.00018267272436365244
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1903 [0/90000 (0%)]	Loss: -15.2182	Cost: 24.74s
Train Epoch: 1903 [20480/90000 (23%)]	Loss: -21.6602	Cost: 9.26s
Train Epoch: 1903 [40960/90000 (45%)]	Loss: -21.6077	Cost: 9.68s
Train Epoch: 1903 [61440/90000 (68%)]	Loss: -21.6065	Cost: 9.61s
Train Epoch: 1903 [81920/90000 (91%)]	Loss: -21.3154	Cost: 9.06s
Train Epoch: 1903 	Average Loss: -21.1249
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8728

Learning rate: 0.00018265504559167268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1904 [0/90000 (0%)]	Loss: -15.0799	Cost: 25.77s
Train Epoch: 1904 [20480/90000 (23%)]	Loss: -22.1058	Cost: 9.24s
Train Epoch: 1904 [40960/90000 (45%)]	Loss: -21.8918	Cost: 9.44s
Train Epoch: 1904 [61440/90000 (68%)]	Loss: -21.7261	Cost: 9.22s
Train Epoch: 1904 [81920/90000 (91%)]	Loss: -21.5429	Cost: 9.15s
Train Epoch: 1904 	Average Loss: -21.4602
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1146

Learning rate: 0.000182637358661967
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1905 [0/90000 (0%)]	Loss: -14.5062	Cost: 25.46s
Train Epoch: 1905 [20480/90000 (23%)]	Loss: -21.8706	Cost: 9.49s
Train Epoch: 1905 [40960/90000 (45%)]	Loss: -21.9176	Cost: 9.18s
Train Epoch: 1905 [61440/90000 (68%)]	Loss: -21.7081	Cost: 9.13s
Train Epoch: 1905 [81920/90000 (91%)]	Loss: -21.6709	Cost: 8.77s
Train Epoch: 1905 	Average Loss: -21.4004
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1675

Learning rate: 0.00018261966357628097
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1906 [0/90000 (0%)]	Loss: -15.9400	Cost: 26.65s
Train Epoch: 1906 [20480/90000 (23%)]	Loss: -21.8027	Cost: 9.35s
Train Epoch: 1906 [40960/90000 (45%)]	Loss: -22.1666	Cost: 9.25s
Train Epoch: 1906 [61440/90000 (68%)]	Loss: -22.1505	Cost: 9.16s
Train Epoch: 1906 [81920/90000 (91%)]	Loss: -21.8826	Cost: 8.94s
Train Epoch: 1906 	Average Loss: -21.6129
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2931

Learning rate: 0.00018260196033636106
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1907 [0/90000 (0%)]	Loss: -14.5004	Cost: 27.13s
Train Epoch: 1907 [20480/90000 (23%)]	Loss: -22.0635	Cost: 9.36s
Train Epoch: 1907 [40960/90000 (45%)]	Loss: -22.0271	Cost: 10.65s
Train Epoch: 1907 [61440/90000 (68%)]	Loss: -21.9277	Cost: 9.21s
Train Epoch: 1907 [81920/90000 (91%)]	Loss: -21.5034	Cost: 9.09s
Train Epoch: 1907 	Average Loss: -21.5060
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1883

Learning rate: 0.00018258424894395452
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1908 [0/90000 (0%)]	Loss: -15.0800	Cost: 25.38s
Train Epoch: 1908 [20480/90000 (23%)]	Loss: -22.0742	Cost: 9.35s
Train Epoch: 1908 [40960/90000 (45%)]	Loss: -21.7748	Cost: 9.29s
Train Epoch: 1908 [61440/90000 (68%)]	Loss: -21.9648	Cost: 9.22s
Train Epoch: 1908 [81920/90000 (91%)]	Loss: -21.5934	Cost: 9.47s
Train Epoch: 1908 	Average Loss: -21.4095
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9395

Learning rate: 0.00018256652940080935
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1909 [0/90000 (0%)]	Loss: -15.0229	Cost: 26.58s
Train Epoch: 1909 [20480/90000 (23%)]	Loss: -21.7861	Cost: 9.70s
Train Epoch: 1909 [40960/90000 (45%)]	Loss: -21.7874	Cost: 9.47s
Train Epoch: 1909 [61440/90000 (68%)]	Loss: -21.8917	Cost: 9.18s
Train Epoch: 1909 [81920/90000 (91%)]	Loss: -21.7282	Cost: 8.86s
Train Epoch: 1909 	Average Loss: -21.3867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0249

Learning rate: 0.00018254880170867445
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1910 [0/90000 (0%)]	Loss: -15.7460	Cost: 25.51s
Train Epoch: 1910 [20480/90000 (23%)]	Loss: -21.8727	Cost: 9.33s
Train Epoch: 1910 [40960/90000 (45%)]	Loss: -22.0776	Cost: 9.25s
Train Epoch: 1910 [61440/90000 (68%)]	Loss: -21.7233	Cost: 9.16s
Train Epoch: 1910 [81920/90000 (91%)]	Loss: -21.7136	Cost: 8.82s
Train Epoch: 1910 	Average Loss: -21.5138
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1965

Learning rate: 0.00018253106586929945
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1911 [0/90000 (0%)]	Loss: -15.0410	Cost: 26.07s
Train Epoch: 1911 [20480/90000 (23%)]	Loss: -21.9438	Cost: 9.35s
Train Epoch: 1911 [40960/90000 (45%)]	Loss: -21.7825	Cost: 9.54s
Train Epoch: 1911 [61440/90000 (68%)]	Loss: -21.8008	Cost: 9.09s
Train Epoch: 1911 [81920/90000 (91%)]	Loss: -21.5986	Cost: 8.80s
Train Epoch: 1911 	Average Loss: -21.2895
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1151

Learning rate: 0.00018251332188443478
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1912 [0/90000 (0%)]	Loss: -15.7156	Cost: 25.70s
Train Epoch: 1912 [20480/90000 (23%)]	Loss: -21.9758	Cost: 9.42s
Train Epoch: 1912 [40960/90000 (45%)]	Loss: -21.8749	Cost: 9.37s
Train Epoch: 1912 [61440/90000 (68%)]	Loss: -21.8149	Cost: 9.17s
Train Epoch: 1912 [81920/90000 (91%)]	Loss: -21.2568	Cost: 8.91s
Train Epoch: 1912 	Average Loss: -21.3755
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9312

Learning rate: 0.00018249556975583175
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1913 [0/90000 (0%)]	Loss: -14.9695	Cost: 25.62s
Train Epoch: 1913 [20480/90000 (23%)]	Loss: -21.7011	Cost: 9.39s
Train Epoch: 1913 [40960/90000 (45%)]	Loss: -21.3797	Cost: 9.43s
Train Epoch: 1913 [61440/90000 (68%)]	Loss: -21.6583	Cost: 9.15s
Train Epoch: 1913 [81920/90000 (91%)]	Loss: -21.4166	Cost: 8.96s
Train Epoch: 1913 	Average Loss: -21.1543
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8647

Learning rate: 0.0001824778094852424
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1914 [0/90000 (0%)]	Loss: -15.2382	Cost: 24.81s
Train Epoch: 1914 [20480/90000 (23%)]	Loss: -21.6937	Cost: 9.45s
Train Epoch: 1914 [40960/90000 (45%)]	Loss: -21.6334	Cost: 9.25s
Train Epoch: 1914 [61440/90000 (68%)]	Loss: -21.5252	Cost: 9.12s
Train Epoch: 1914 [81920/90000 (91%)]	Loss: -21.2963	Cost: 8.94s
Train Epoch: 1914 	Average Loss: -21.1500
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8612

Learning rate: 0.0001824600410744196
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1915 [0/90000 (0%)]	Loss: -14.0144	Cost: 25.35s
Train Epoch: 1915 [20480/90000 (23%)]	Loss: -21.6965	Cost: 9.66s
Train Epoch: 1915 [40960/90000 (45%)]	Loss: -21.7620	Cost: 9.52s
Train Epoch: 1915 [61440/90000 (68%)]	Loss: -21.6138	Cost: 9.12s
Train Epoch: 1915 [81920/90000 (91%)]	Loss: -21.6449	Cost: 8.75s
Train Epoch: 1915 	Average Loss: -21.2050
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1382

Learning rate: 0.000182442264525117
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1916 [0/90000 (0%)]	Loss: -16.0326	Cost: 24.83s
Train Epoch: 1916 [20480/90000 (23%)]	Loss: -22.0087	Cost: 9.56s
Train Epoch: 1916 [40960/90000 (45%)]	Loss: -22.0286	Cost: 9.26s
Train Epoch: 1916 [61440/90000 (68%)]	Loss: -21.4759	Cost: 9.08s
Train Epoch: 1916 [81920/90000 (91%)]	Loss: -21.4160	Cost: 9.23s
Train Epoch: 1916 	Average Loss: -21.3484
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8364

Learning rate: 0.00018242447983908916
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1917 [0/90000 (0%)]	Loss: -14.9791	Cost: 24.60s
Train Epoch: 1917 [20480/90000 (23%)]	Loss: -21.8992	Cost: 9.11s
Train Epoch: 1917 [40960/90000 (45%)]	Loss: -21.8799	Cost: 10.26s
Train Epoch: 1917 [61440/90000 (68%)]	Loss: -21.1207	Cost: 9.10s
Train Epoch: 1917 [81920/90000 (91%)]	Loss: -20.9770	Cost: 9.68s
Train Epoch: 1917 	Average Loss: -21.1466
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7244

Learning rate: 0.00018240668701809126
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1918 [0/90000 (0%)]	Loss: -15.5919	Cost: 24.12s
Train Epoch: 1918 [20480/90000 (23%)]	Loss: -21.9604	Cost: 9.50s
Train Epoch: 1918 [40960/90000 (45%)]	Loss: -22.0079	Cost: 9.21s
Train Epoch: 1918 [61440/90000 (68%)]	Loss: -21.7041	Cost: 9.08s
Train Epoch: 1918 [81920/90000 (91%)]	Loss: -21.3661	Cost: 10.27s
Train Epoch: 1918 	Average Loss: -21.3418
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1390

Learning rate: 0.0001823888860638794
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1919 [0/90000 (0%)]	Loss: -15.0716	Cost: 24.44s
Train Epoch: 1919 [20480/90000 (23%)]	Loss: -21.8497	Cost: 9.23s
Train Epoch: 1919 [40960/90000 (45%)]	Loss: -21.6141	Cost: 9.85s
Train Epoch: 1919 [61440/90000 (68%)]	Loss: -21.5575	Cost: 9.05s
Train Epoch: 1919 [81920/90000 (91%)]	Loss: -21.2932	Cost: 10.50s
Train Epoch: 1919 	Average Loss: -21.1697
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6614

Learning rate: 0.0001823710769782105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1920 [0/90000 (0%)]	Loss: -14.7587	Cost: 24.99s
Train Epoch: 1920 [20480/90000 (23%)]	Loss: -21.6957	Cost: 9.18s
Train Epoch: 1920 [40960/90000 (45%)]	Loss: -21.8201	Cost: 9.31s
Train Epoch: 1920 [61440/90000 (68%)]	Loss: -21.7599	Cost: 9.12s
Train Epoch: 1920 [81920/90000 (91%)]	Loss: -21.8159	Cost: 9.72s
Train Epoch: 1920 	Average Loss: -21.3517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2005

Learning rate: 0.0001823532597628422
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1921 [0/90000 (0%)]	Loss: -16.0089	Cost: 24.32s
Train Epoch: 1921 [20480/90000 (23%)]	Loss: -22.3453	Cost: 9.68s
Train Epoch: 1921 [40960/90000 (45%)]	Loss: -21.8606	Cost: 9.59s
Train Epoch: 1921 [61440/90000 (68%)]	Loss: -21.8982	Cost: 9.50s
Train Epoch: 1921 [81920/90000 (91%)]	Loss: -21.8586	Cost: 9.96s
Train Epoch: 1921 	Average Loss: -21.5301
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2822

Learning rate: 0.00018233543441953308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1922 [0/90000 (0%)]	Loss: -15.8266	Cost: 24.58s
Train Epoch: 1922 [20480/90000 (23%)]	Loss: -22.1111	Cost: 9.82s
Train Epoch: 1922 [40960/90000 (45%)]	Loss: -21.9638	Cost: 9.23s
Train Epoch: 1922 [61440/90000 (68%)]	Loss: -21.9476	Cost: 9.20s
Train Epoch: 1922 [81920/90000 (91%)]	Loss: -21.8747	Cost: 9.21s
Train Epoch: 1922 	Average Loss: -21.5963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2090

Learning rate: 0.00018231760095004234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1923 [0/90000 (0%)]	Loss: -15.3671	Cost: 24.76s
Train Epoch: 1923 [20480/90000 (23%)]	Loss: -22.1130	Cost: 9.38s
Train Epoch: 1923 [40960/90000 (45%)]	Loss: -21.7797	Cost: 9.24s
Train Epoch: 1923 [61440/90000 (68%)]	Loss: -21.6085	Cost: 9.31s
Train Epoch: 1923 [81920/90000 (91%)]	Loss: -21.4465	Cost: 9.17s
Train Epoch: 1923 	Average Loss: -21.4624
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9951

Learning rate: 0.00018229975935613008
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1924 [0/90000 (0%)]	Loss: -14.5458	Cost: 24.31s
Train Epoch: 1924 [20480/90000 (23%)]	Loss: -21.9597	Cost: 9.32s
Train Epoch: 1924 [40960/90000 (45%)]	Loss: -21.9999	Cost: 9.32s
Train Epoch: 1924 [61440/90000 (68%)]	Loss: -18.5952	Cost: 9.20s
Train Epoch: 1924 [81920/90000 (91%)]	Loss: -18.9074	Cost: 9.04s
Train Epoch: 1924 	Average Loss: -20.0094
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0990

Learning rate: 0.00018228190963955724
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1925 [0/90000 (0%)]	Loss: -13.2598	Cost: 26.23s
Train Epoch: 1925 [20480/90000 (23%)]	Loss: -20.1819	Cost: 9.37s
Train Epoch: 1925 [40960/90000 (45%)]	Loss: -20.5282	Cost: 9.31s
Train Epoch: 1925 [61440/90000 (68%)]	Loss: -20.6140	Cost: 9.45s
Train Epoch: 1925 [81920/90000 (91%)]	Loss: -20.7895	Cost: 9.08s
Train Epoch: 1925 	Average Loss: -20.0278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4369

Learning rate: 0.00018226405180208548
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1926 [0/90000 (0%)]	Loss: -14.5556	Cost: 25.25s
Train Epoch: 1926 [20480/90000 (23%)]	Loss: -21.6074	Cost: 9.37s
Train Epoch: 1926 [40960/90000 (45%)]	Loss: -21.4667	Cost: 9.35s
Train Epoch: 1926 [61440/90000 (68%)]	Loss: -21.4558	Cost: 9.15s
Train Epoch: 1926 [81920/90000 (91%)]	Loss: -21.5387	Cost: 9.18s
Train Epoch: 1926 	Average Loss: -21.0526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1175

Learning rate: 0.0001822461858454773
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1927 [0/90000 (0%)]	Loss: -15.6851	Cost: 25.75s
Train Epoch: 1927 [20480/90000 (23%)]	Loss: -21.9091	Cost: 9.31s
Train Epoch: 1927 [40960/90000 (45%)]	Loss: -22.1785	Cost: 9.35s
Train Epoch: 1927 [61440/90000 (68%)]	Loss: -21.9272	Cost: 9.33s
Train Epoch: 1927 [81920/90000 (91%)]	Loss: -21.8351	Cost: 9.11s
Train Epoch: 1927 	Average Loss: -21.5561
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2622

Learning rate: 0.00018222831177149603
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1928 [0/90000 (0%)]	Loss: -15.1206	Cost: 27.22s
Train Epoch: 1928 [20480/90000 (23%)]	Loss: -22.3218	Cost: 9.36s
Train Epoch: 1928 [40960/90000 (45%)]	Loss: -22.1016	Cost: 9.34s
Train Epoch: 1928 [61440/90000 (68%)]	Loss: -22.0384	Cost: 9.15s
Train Epoch: 1928 [81920/90000 (91%)]	Loss: -21.8104	Cost: 8.95s
Train Epoch: 1928 	Average Loss: -21.6039
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3064

Learning rate: 0.00018221042958190575
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1929 [0/90000 (0%)]	Loss: -14.6884	Cost: 25.84s
Train Epoch: 1929 [20480/90000 (23%)]	Loss: -22.1431	Cost: 9.37s
Train Epoch: 1929 [40960/90000 (45%)]	Loss: -21.7271	Cost: 9.29s
Train Epoch: 1929 [61440/90000 (68%)]	Loss: -21.4616	Cost: 9.38s
Train Epoch: 1929 [81920/90000 (91%)]	Loss: -21.4138	Cost: 8.79s
Train Epoch: 1929 	Average Loss: -21.3264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7880

Learning rate: 0.00018219253927847132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1930 [0/90000 (0%)]	Loss: -15.3698	Cost: 25.40s
Train Epoch: 1930 [20480/90000 (23%)]	Loss: -21.9100	Cost: 9.33s
Train Epoch: 1930 [40960/90000 (45%)]	Loss: -21.9167	Cost: 9.29s
Train Epoch: 1930 [61440/90000 (68%)]	Loss: -21.7016	Cost: 9.12s
Train Epoch: 1930 [81920/90000 (91%)]	Loss: -21.5757	Cost: 8.88s
Train Epoch: 1930 	Average Loss: -21.3181
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8326

Learning rate: 0.00018217464086295852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1931 [0/90000 (0%)]	Loss: -14.8816	Cost: 25.58s
Train Epoch: 1931 [20480/90000 (23%)]	Loss: -21.8082	Cost: 9.38s
Train Epoch: 1931 [40960/90000 (45%)]	Loss: -21.9362	Cost: 9.30s
Train Epoch: 1931 [61440/90000 (68%)]	Loss: -21.6416	Cost: 9.33s
Train Epoch: 1931 [81920/90000 (91%)]	Loss: -21.5039	Cost: 8.81s
Train Epoch: 1931 	Average Loss: -21.3987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1605

Learning rate: 0.0001821567343371338
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1932 [0/90000 (0%)]	Loss: -14.4021	Cost: 25.00s
Train Epoch: 1932 [20480/90000 (23%)]	Loss: -21.6099	Cost: 9.41s
Train Epoch: 1932 [40960/90000 (45%)]	Loss: -21.2658	Cost: 9.33s
Train Epoch: 1932 [61440/90000 (68%)]	Loss: -21.1425	Cost: 9.24s
Train Epoch: 1932 [81920/90000 (91%)]	Loss: -21.3727	Cost: 8.86s
Train Epoch: 1932 	Average Loss: -20.9004
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6694

Learning rate: 0.00018213881970276447
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1933 [0/90000 (0%)]	Loss: -14.0743	Cost: 25.74s
Train Epoch: 1933 [20480/90000 (23%)]	Loss: -20.7505	Cost: 9.28s
Train Epoch: 1933 [40960/90000 (45%)]	Loss: -20.3031	Cost: 9.35s
Train Epoch: 1933 [61440/90000 (68%)]	Loss: -20.4113	Cost: 9.24s
Train Epoch: 1933 [81920/90000 (91%)]	Loss: -20.8346	Cost: 8.95s
Train Epoch: 1933 	Average Loss: -20.1928
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2916

Learning rate: 0.00018212089696161864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1934 [0/90000 (0%)]	Loss: -13.7929	Cost: 25.46s
Train Epoch: 1934 [20480/90000 (23%)]	Loss: -21.2119	Cost: 9.70s
Train Epoch: 1934 [40960/90000 (45%)]	Loss: -21.2885	Cost: 9.33s
Train Epoch: 1934 [61440/90000 (68%)]	Loss: -21.4209	Cost: 9.08s
Train Epoch: 1934 [81920/90000 (91%)]	Loss: -21.3894	Cost: 9.09s
Train Epoch: 1934 	Average Loss: -20.8707
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8658

Learning rate: 0.00018210296611546526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1935 [0/90000 (0%)]	Loss: -15.3986	Cost: 25.22s
Train Epoch: 1935 [20480/90000 (23%)]	Loss: -21.9128	Cost: 9.39s
Train Epoch: 1935 [40960/90000 (45%)]	Loss: -21.8047	Cost: 9.76s
Train Epoch: 1935 [61440/90000 (68%)]	Loss: -21.7901	Cost: 9.36s
Train Epoch: 1935 [81920/90000 (91%)]	Loss: -21.7520	Cost: 8.84s
Train Epoch: 1935 	Average Loss: -21.3711
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3558

Learning rate: 0.00018208502716607393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1936 [0/90000 (0%)]	Loss: -15.0885	Cost: 25.68s
Train Epoch: 1936 [20480/90000 (23%)]	Loss: -22.3306	Cost: 9.63s
Train Epoch: 1936 [40960/90000 (45%)]	Loss: -22.2549	Cost: 9.04s
Train Epoch: 1936 [61440/90000 (68%)]	Loss: -22.2307	Cost: 9.01s
Train Epoch: 1936 [81920/90000 (91%)]	Loss: -22.0205	Cost: 8.75s
Train Epoch: 1936 	Average Loss: -21.7345
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6518

Learning rate: 0.00018206708011521527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1937 [0/90000 (0%)]	Loss: -15.6048	Cost: 24.74s
Train Epoch: 1937 [20480/90000 (23%)]	Loss: -22.3698	Cost: 9.54s
Train Epoch: 1937 [40960/90000 (45%)]	Loss: -22.4009	Cost: 9.56s
Train Epoch: 1937 [61440/90000 (68%)]	Loss: -22.3311	Cost: 9.19s
Train Epoch: 1937 [81920/90000 (91%)]	Loss: -22.0193	Cost: 9.50s
Train Epoch: 1937 	Average Loss: -21.8877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4844

Learning rate: 0.0001820491249646605
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1938 [0/90000 (0%)]	Loss: -15.4835	Cost: 24.37s
Train Epoch: 1938 [20480/90000 (23%)]	Loss: -22.3100	Cost: 9.03s
Train Epoch: 1938 [40960/90000 (45%)]	Loss: -22.3470	Cost: 10.11s
Train Epoch: 1938 [61440/90000 (68%)]	Loss: -22.2677	Cost: 9.10s
Train Epoch: 1938 [81920/90000 (91%)]	Loss: -22.0777	Cost: 10.29s
Train Epoch: 1938 	Average Loss: -21.7966
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4459

Learning rate: 0.00018203116171618174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1939 [0/90000 (0%)]	Loss: -15.6646	Cost: 23.66s
Train Epoch: 1939 [20480/90000 (23%)]	Loss: -22.3579	Cost: 9.05s
Train Epoch: 1939 [40960/90000 (45%)]	Loss: -22.1338	Cost: 9.86s
Train Epoch: 1939 [61440/90000 (68%)]	Loss: -22.0372	Cost: 9.28s
Train Epoch: 1939 [81920/90000 (91%)]	Loss: -21.9489	Cost: 10.07s
Train Epoch: 1939 	Average Loss: -21.6419
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3595

Learning rate: 0.00018201319037155193
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1940 [0/90000 (0%)]	Loss: -14.1432	Cost: 24.57s
Train Epoch: 1940 [20480/90000 (23%)]	Loss: -22.1242	Cost: 9.03s
Train Epoch: 1940 [40960/90000 (45%)]	Loss: -21.9000	Cost: 9.87s
Train Epoch: 1940 [61440/90000 (68%)]	Loss: -22.0132	Cost: 9.04s
Train Epoch: 1940 [81920/90000 (91%)]	Loss: -21.9200	Cost: 10.37s
Train Epoch: 1940 	Average Loss: -21.5142
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2750

Learning rate: 0.00018199521093254471
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1941 [0/90000 (0%)]	Loss: -15.5015	Cost: 24.64s
Train Epoch: 1941 [20480/90000 (23%)]	Loss: -22.2760	Cost: 9.06s
Train Epoch: 1941 [40960/90000 (45%)]	Loss: -22.0136	Cost: 9.65s
Train Epoch: 1941 [61440/90000 (68%)]	Loss: -21.9575	Cost: 9.17s
Train Epoch: 1941 [81920/90000 (91%)]	Loss: -21.5087	Cost: 10.28s
Train Epoch: 1941 	Average Loss: -21.6139
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0749

Learning rate: 0.0001819772234009346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1942 [0/90000 (0%)]	Loss: -14.7518	Cost: 22.94s
Train Epoch: 1942 [20480/90000 (23%)]	Loss: -22.2088	Cost: 9.03s
Train Epoch: 1942 [40960/90000 (45%)]	Loss: -22.0725	Cost: 9.00s
Train Epoch: 1942 [61440/90000 (68%)]	Loss: -22.0377	Cost: 8.94s
Train Epoch: 1942 [81920/90000 (91%)]	Loss: -22.0343	Cost: 9.08s
Train Epoch: 1942 	Average Loss: -21.5460
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4050

Learning rate: 0.00018195922777849695
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1943 [0/90000 (0%)]	Loss: -16.1388	Cost: 25.03s
Train Epoch: 1943 [20480/90000 (23%)]	Loss: -22.2735	Cost: 9.08s
Train Epoch: 1943 [40960/90000 (45%)]	Loss: -21.9199	Cost: 9.77s
Train Epoch: 1943 [61440/90000 (68%)]	Loss: -21.8360	Cost: 9.07s
Train Epoch: 1943 [81920/90000 (91%)]	Loss: -21.6550	Cost: 8.89s
Train Epoch: 1943 	Average Loss: -21.6040
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2179

Learning rate: 0.0001819412240670078
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1944 [0/90000 (0%)]	Loss: -15.5268	Cost: 24.85s
Train Epoch: 1944 [20480/90000 (23%)]	Loss: -21.9286	Cost: 9.03s
Train Epoch: 1944 [40960/90000 (45%)]	Loss: -21.8114	Cost: 9.60s
Train Epoch: 1944 [61440/90000 (68%)]	Loss: -21.5740	Cost: 8.99s
Train Epoch: 1944 [81920/90000 (91%)]	Loss: -21.1629	Cost: 8.81s
Train Epoch: 1944 	Average Loss: -21.3257
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6886

Learning rate: 0.00018192321226824404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1945 [0/90000 (0%)]	Loss: -15.0898	Cost: 25.45s
Train Epoch: 1945 [20480/90000 (23%)]	Loss: -21.6814	Cost: 9.33s
Train Epoch: 1945 [40960/90000 (45%)]	Loss: -20.8221	Cost: 9.21s
Train Epoch: 1945 [61440/90000 (68%)]	Loss: -21.2253	Cost: 9.37s
Train Epoch: 1945 [81920/90000 (91%)]	Loss: -21.2645	Cost: 8.79s
Train Epoch: 1945 	Average Loss: -20.9275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8977

Learning rate: 0.00018190519238398342
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1946 [0/90000 (0%)]	Loss: -14.8680	Cost: 25.66s
Train Epoch: 1946 [20480/90000 (23%)]	Loss: -21.8951	Cost: 9.35s
Train Epoch: 1946 [40960/90000 (45%)]	Loss: -21.8650	Cost: 9.25s
Train Epoch: 1946 [61440/90000 (68%)]	Loss: -21.7528	Cost: 9.18s
Train Epoch: 1946 [81920/90000 (91%)]	Loss: -21.6411	Cost: 8.96s
Train Epoch: 1946 	Average Loss: -21.3621
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0408

Learning rate: 0.00018188716441600435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1947 [0/90000 (0%)]	Loss: -15.6324	Cost: 28.62s
Train Epoch: 1947 [20480/90000 (23%)]	Loss: -21.7212	Cost: 9.36s
Train Epoch: 1947 [40960/90000 (45%)]	Loss: -21.6175	Cost: 9.30s
Train Epoch: 1947 [61440/90000 (68%)]	Loss: -21.7415	Cost: 9.31s
Train Epoch: 1947 [81920/90000 (91%)]	Loss: -21.5511	Cost: 8.85s
Train Epoch: 1947 	Average Loss: -21.2859
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0563

Learning rate: 0.0001818691283660862
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1948 [0/90000 (0%)]	Loss: -15.6476	Cost: 25.44s
Train Epoch: 1948 [20480/90000 (23%)]	Loss: -22.0869	Cost: 9.45s
Train Epoch: 1948 [40960/90000 (45%)]	Loss: -22.1995	Cost: 9.22s
Train Epoch: 1948 [61440/90000 (68%)]	Loss: -22.2366	Cost: 9.17s
Train Epoch: 1948 [81920/90000 (91%)]	Loss: -21.8898	Cost: 8.80s
Train Epoch: 1948 	Average Loss: -21.6741
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3436

Learning rate: 0.000181851084236009
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1949 [0/90000 (0%)]	Loss: -15.8506	Cost: 25.70s
Train Epoch: 1949 [20480/90000 (23%)]	Loss: -22.2158	Cost: 9.39s
Train Epoch: 1949 [40960/90000 (45%)]	Loss: -22.1211	Cost: 9.28s
Train Epoch: 1949 [61440/90000 (68%)]	Loss: -22.3630	Cost: 9.39s
Train Epoch: 1949 [81920/90000 (91%)]	Loss: -21.9412	Cost: 8.84s
Train Epoch: 1949 	Average Loss: -21.7896
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4089

Learning rate: 0.00018183303202755368
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1950 [0/90000 (0%)]	Loss: -15.7162	Cost: 25.18s
Train Epoch: 1950 [20480/90000 (23%)]	Loss: -22.2499	Cost: 9.31s
Train Epoch: 1950 [40960/90000 (45%)]	Loss: -22.2695	Cost: 9.28s
Train Epoch: 1950 [61440/90000 (68%)]	Loss: -22.2829	Cost: 9.18s
Train Epoch: 1950 [81920/90000 (91%)]	Loss: -22.1028	Cost: 9.15s
Train Epoch: 1950 	Average Loss: -21.8051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5047

Saving model as model.pt_e1950 & waveforms_supplementary.hdf5_e1950
Learning rate: 0.00018181497174250187
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1951 [0/90000 (0%)]	Loss: -15.1691	Cost: 25.37s
Train Epoch: 1951 [20480/90000 (23%)]	Loss: -22.3571	Cost: 9.32s
Train Epoch: 1951 [40960/90000 (45%)]	Loss: -22.1292	Cost: 9.15s
Train Epoch: 1951 [61440/90000 (68%)]	Loss: -21.9238	Cost: 9.11s
Train Epoch: 1951 [81920/90000 (91%)]	Loss: -21.4670	Cost: 8.80s
Train Epoch: 1951 	Average Loss: -21.5610
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9130

Learning rate: 0.00018179690338263608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1952 [0/90000 (0%)]	Loss: -14.9890	Cost: 25.04s
Train Epoch: 1952 [20480/90000 (23%)]	Loss: -21.8973	Cost: 9.43s
Train Epoch: 1952 [40960/90000 (45%)]	Loss: -21.9933	Cost: 9.28s
Train Epoch: 1952 [61440/90000 (68%)]	Loss: -21.8317	Cost: 9.20s
Train Epoch: 1952 [81920/90000 (91%)]	Loss: -21.7653	Cost: 9.20s
Train Epoch: 1952 	Average Loss: -21.4933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2236

Learning rate: 0.0001817788269497396
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1953 [0/90000 (0%)]	Loss: -15.6650	Cost: 25.99s
Train Epoch: 1953 [20480/90000 (23%)]	Loss: -22.1259	Cost: 9.42s
Train Epoch: 1953 [40960/90000 (45%)]	Loss: -21.9823	Cost: 9.27s
Train Epoch: 1953 [61440/90000 (68%)]	Loss: -22.1346	Cost: 9.15s
Train Epoch: 1953 [81920/90000 (91%)]	Loss: -22.0044	Cost: 8.86s
Train Epoch: 1953 	Average Loss: -21.6464
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2924

Learning rate: 0.00018176074244559645
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1954 [0/90000 (0%)]	Loss: -15.3709	Cost: 24.96s
Train Epoch: 1954 [20480/90000 (23%)]	Loss: -22.1582	Cost: 9.39s
Train Epoch: 1954 [40960/90000 (45%)]	Loss: -22.0166	Cost: 9.21s
Train Epoch: 1954 [61440/90000 (68%)]	Loss: -22.1524	Cost: 9.05s
Train Epoch: 1954 [81920/90000 (91%)]	Loss: -21.8357	Cost: 8.80s
Train Epoch: 1954 	Average Loss: -21.6885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3722

Learning rate: 0.00018174264987199154
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1955 [0/90000 (0%)]	Loss: -14.9159	Cost: 26.16s
Train Epoch: 1955 [20480/90000 (23%)]	Loss: -21.6897	Cost: 9.35s
Train Epoch: 1955 [40960/90000 (45%)]	Loss: -21.5466	Cost: 9.70s
Train Epoch: 1955 [61440/90000 (68%)]	Loss: -21.7371	Cost: 9.14s
Train Epoch: 1955 [81920/90000 (91%)]	Loss: -21.4828	Cost: 8.86s
Train Epoch: 1955 	Average Loss: -21.2913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8895

Learning rate: 0.00018172454923071058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1956 [0/90000 (0%)]	Loss: -14.8768	Cost: 25.56s
Train Epoch: 1956 [20480/90000 (23%)]	Loss: -21.7525	Cost: 9.38s
Train Epoch: 1956 [40960/90000 (45%)]	Loss: -21.7231	Cost: 9.47s
Train Epoch: 1956 [61440/90000 (68%)]	Loss: -21.7600	Cost: 9.09s
Train Epoch: 1956 [81920/90000 (91%)]	Loss: -21.8277	Cost: 8.87s
Train Epoch: 1956 	Average Loss: -21.2105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1008

Learning rate: 0.0001817064405235399
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1957 [0/90000 (0%)]	Loss: -14.5185	Cost: 25.69s
Train Epoch: 1957 [20480/90000 (23%)]	Loss: -21.9552	Cost: 9.53s
Train Epoch: 1957 [40960/90000 (45%)]	Loss: -21.6852	Cost: 9.71s
Train Epoch: 1957 [61440/90000 (68%)]	Loss: -21.7745	Cost: 9.09s
Train Epoch: 1957 [81920/90000 (91%)]	Loss: -22.0913	Cost: 8.73s
Train Epoch: 1957 	Average Loss: -21.4251
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4132

Learning rate: 0.00018168832375226686
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1958 [0/90000 (0%)]	Loss: -16.1575	Cost: 25.44s
Train Epoch: 1958 [20480/90000 (23%)]	Loss: -22.3025	Cost: 9.55s
Train Epoch: 1958 [40960/90000 (45%)]	Loss: -21.9743	Cost: 9.13s
Train Epoch: 1958 [61440/90000 (68%)]	Loss: -21.6508	Cost: 9.02s
Train Epoch: 1958 [81920/90000 (91%)]	Loss: -21.8241	Cost: 9.42s
Train Epoch: 1958 	Average Loss: -21.5556
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1617

Learning rate: 0.0001816701989186795
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1959 [0/90000 (0%)]	Loss: -15.0732	Cost: 24.59s
Train Epoch: 1959 [20480/90000 (23%)]	Loss: -22.1544	Cost: 9.51s
Train Epoch: 1959 [40960/90000 (45%)]	Loss: -21.6164	Cost: 9.48s
Train Epoch: 1959 [61440/90000 (68%)]	Loss: -21.1203	Cost: 9.02s
Train Epoch: 1959 [81920/90000 (91%)]	Loss: -21.1028	Cost: 9.88s
Train Epoch: 1959 	Average Loss: -21.1335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9323

Learning rate: 0.00018165206602456665
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1960 [0/90000 (0%)]	Loss: -14.3761	Cost: 25.13s
Train Epoch: 1960 [20480/90000 (23%)]	Loss: -21.8496	Cost: 9.03s
Train Epoch: 1960 [40960/90000 (45%)]	Loss: -21.9075	Cost: 9.88s
Train Epoch: 1960 [61440/90000 (68%)]	Loss: -21.4103	Cost: 9.12s
Train Epoch: 1960 [81920/90000 (91%)]	Loss: -21.5550	Cost: 10.52s
Train Epoch: 1960 	Average Loss: -21.2434
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8986

Learning rate: 0.00018163392507171799
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1961 [0/90000 (0%)]	Loss: -14.6332	Cost: 24.97s
Train Epoch: 1961 [20480/90000 (23%)]	Loss: -21.4437	Cost: 9.22s
Train Epoch: 1961 [40960/90000 (45%)]	Loss: -21.7557	Cost: 9.83s
Train Epoch: 1961 [61440/90000 (68%)]	Loss: -21.7738	Cost: 9.07s
Train Epoch: 1961 [81920/90000 (91%)]	Loss: -21.6256	Cost: 10.12s
Train Epoch: 1961 	Average Loss: -21.2862
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0560

Learning rate: 0.0001816157760619239
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1962 [0/90000 (0%)]	Loss: -15.0523	Cost: 24.91s
Train Epoch: 1962 [20480/90000 (23%)]	Loss: -21.8702	Cost: 9.29s
Train Epoch: 1962 [40960/90000 (45%)]	Loss: -21.5807	Cost: 9.25s
Train Epoch: 1962 [61440/90000 (68%)]	Loss: -21.6759	Cost: 9.09s
Train Epoch: 1962 [81920/90000 (91%)]	Loss: -21.5917	Cost: 9.87s
Train Epoch: 1962 	Average Loss: -21.3389
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0918

Learning rate: 0.0001815976189969757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1963 [0/90000 (0%)]	Loss: -15.1365	Cost: 24.75s
Train Epoch: 1963 [20480/90000 (23%)]	Loss: -22.0574	Cost: 9.44s
Train Epoch: 1963 [40960/90000 (45%)]	Loss: -21.7505	Cost: 9.69s
Train Epoch: 1963 [61440/90000 (68%)]	Loss: -21.7451	Cost: 9.21s
Train Epoch: 1963 [81920/90000 (91%)]	Loss: -21.5744	Cost: 9.96s
Train Epoch: 1963 	Average Loss: -21.4177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0915

Learning rate: 0.00018157945387866533
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1964 [0/90000 (0%)]	Loss: -14.4127	Cost: 23.76s
Train Epoch: 1964 [20480/90000 (23%)]	Loss: -22.1949	Cost: 9.35s
Train Epoch: 1964 [40960/90000 (45%)]	Loss: -21.7370	Cost: 9.91s
Train Epoch: 1964 [61440/90000 (68%)]	Loss: -21.6274	Cost: 9.30s
Train Epoch: 1964 [81920/90000 (91%)]	Loss: -21.5940	Cost: 9.72s
Train Epoch: 1964 	Average Loss: -21.4093
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9586

Learning rate: 0.00018156128070878565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1965 [0/90000 (0%)]	Loss: -14.9946	Cost: 24.80s
Train Epoch: 1965 [20480/90000 (23%)]	Loss: -21.9122	Cost: 9.18s
Train Epoch: 1965 [40960/90000 (45%)]	Loss: -21.9883	Cost: 9.74s
Train Epoch: 1965 [61440/90000 (68%)]	Loss: -22.0200	Cost: 9.34s
Train Epoch: 1965 [81920/90000 (91%)]	Loss: -21.8932	Cost: 9.01s
Train Epoch: 1965 	Average Loss: -21.5782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3204

Learning rate: 0.0001815430994891303
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1966 [0/90000 (0%)]	Loss: -16.0665	Cost: 25.23s
Train Epoch: 1966 [20480/90000 (23%)]	Loss: -22.2806	Cost: 9.35s
Train Epoch: 1966 [40960/90000 (45%)]	Loss: -22.2956	Cost: 10.14s
Train Epoch: 1966 [61440/90000 (68%)]	Loss: -22.0537	Cost: 9.16s
Train Epoch: 1966 [81920/90000 (91%)]	Loss: -21.9291	Cost: 9.24s
Train Epoch: 1966 	Average Loss: -21.8795
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3029

Learning rate: 0.00018152491022149368
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1967 [0/90000 (0%)]	Loss: -15.1743	Cost: 25.79s
Train Epoch: 1967 [20480/90000 (23%)]	Loss: -22.0326	Cost: 9.38s
Train Epoch: 1967 [40960/90000 (45%)]	Loss: -21.7843	Cost: 9.53s
Train Epoch: 1967 [61440/90000 (68%)]	Loss: -21.9019	Cost: 9.08s
Train Epoch: 1967 [81920/90000 (91%)]	Loss: -21.4792	Cost: 9.05s
Train Epoch: 1967 	Average Loss: -21.4215
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1312

Learning rate: 0.000181506712907671
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1968 [0/90000 (0%)]	Loss: -14.7119	Cost: 26.61s
Train Epoch: 1968 [20480/90000 (23%)]	Loss: -22.1153	Cost: 9.38s
Train Epoch: 1968 [40960/90000 (45%)]	Loss: -21.8694	Cost: 9.33s
Train Epoch: 1968 [61440/90000 (68%)]	Loss: -21.8740	Cost: 9.17s
Train Epoch: 1968 [81920/90000 (91%)]	Loss: -21.8476	Cost: 9.14s
Train Epoch: 1968 	Average Loss: -21.5079
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2519

Learning rate: 0.00018148850754945824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1969 [0/90000 (0%)]	Loss: -15.8301	Cost: 26.53s
Train Epoch: 1969 [20480/90000 (23%)]	Loss: -22.1252	Cost: 9.52s
Train Epoch: 1969 [40960/90000 (45%)]	Loss: -22.0205	Cost: 9.53s
Train Epoch: 1969 [61440/90000 (68%)]	Loss: -21.9278	Cost: 9.08s
Train Epoch: 1969 [81920/90000 (91%)]	Loss: -22.1176	Cost: 8.87s
Train Epoch: 1969 	Average Loss: -21.7068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7098

Learning rate: 0.00018147029414865222
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1970 [0/90000 (0%)]	Loss: -15.9990	Cost: 25.37s
Train Epoch: 1970 [20480/90000 (23%)]	Loss: -21.8814	Cost: 9.36s
Train Epoch: 1970 [40960/90000 (45%)]	Loss: -22.0546	Cost: 9.35s
Train Epoch: 1970 [61440/90000 (68%)]	Loss: -21.2284	Cost: 9.15s
Train Epoch: 1970 [81920/90000 (91%)]	Loss: -21.0089	Cost: 9.05s
Train Epoch: 1970 	Average Loss: -21.2078
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7072

Learning rate: 0.00018145207270705055
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1971 [0/90000 (0%)]	Loss: -14.9416	Cost: 26.68s
Train Epoch: 1971 [20480/90000 (23%)]	Loss: -21.7614	Cost: 9.33s
Train Epoch: 1971 [40960/90000 (45%)]	Loss: -21.2354	Cost: 9.58s
Train Epoch: 1971 [61440/90000 (68%)]	Loss: -21.3917	Cost: 9.13s
Train Epoch: 1971 [81920/90000 (91%)]	Loss: -21.1924	Cost: 8.74s
Train Epoch: 1971 	Average Loss: -21.0448
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7742

Learning rate: 0.00018143384322645158
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1972 [0/90000 (0%)]	Loss: -15.8673	Cost: 27.03s
Train Epoch: 1972 [20480/90000 (23%)]	Loss: -21.7503	Cost: 9.31s
Train Epoch: 1972 [40960/90000 (45%)]	Loss: -20.7595	Cost: 9.29s
Train Epoch: 1972 [61440/90000 (68%)]	Loss: -20.8682	Cost: 9.17s
Train Epoch: 1972 [81920/90000 (91%)]	Loss: -20.9243	Cost: 8.83s
Train Epoch: 1972 	Average Loss: -20.7836
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.4917

Learning rate: 0.0001814156057086545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1973 [0/90000 (0%)]	Loss: -14.7469	Cost: 25.22s
Train Epoch: 1973 [20480/90000 (23%)]	Loss: -21.4356	Cost: 9.39s
Train Epoch: 1973 [40960/90000 (45%)]	Loss: -21.4267	Cost: 9.53s
Train Epoch: 1973 [61440/90000 (68%)]	Loss: -21.5085	Cost: 9.21s
Train Epoch: 1973 [81920/90000 (91%)]	Loss: -21.0836	Cost: 8.83s
Train Epoch: 1973 	Average Loss: -20.8821
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6574

Learning rate: 0.0001813973601554593
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1974 [0/90000 (0%)]	Loss: -14.3004	Cost: 25.09s
Train Epoch: 1974 [20480/90000 (23%)]	Loss: -21.6159	Cost: 9.44s
Train Epoch: 1974 [40960/90000 (45%)]	Loss: -21.8665	Cost: 9.23s
Train Epoch: 1974 [61440/90000 (68%)]	Loss: -21.3923	Cost: 9.23s
Train Epoch: 1974 [81920/90000 (91%)]	Loss: -21.6024	Cost: 8.97s
Train Epoch: 1974 	Average Loss: -21.2748
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0920

Learning rate: 0.00018137910656866672
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1975 [0/90000 (0%)]	Loss: -15.1687	Cost: 25.35s
Train Epoch: 1975 [20480/90000 (23%)]	Loss: -22.0738	Cost: 9.40s
Train Epoch: 1975 [40960/90000 (45%)]	Loss: -22.3855	Cost: 9.51s
Train Epoch: 1975 [61440/90000 (68%)]	Loss: -22.0836	Cost: 9.17s
Train Epoch: 1975 [81920/90000 (91%)]	Loss: -21.7454	Cost: 8.89s
Train Epoch: 1975 	Average Loss: -21.6503
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4017

Learning rate: 0.00018136084495007834
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1976 [0/90000 (0%)]	Loss: -15.5338	Cost: 25.08s
Train Epoch: 1976 [20480/90000 (23%)]	Loss: -21.9719	Cost: 9.36s
Train Epoch: 1976 [40960/90000 (45%)]	Loss: -22.1940	Cost: 9.43s
Train Epoch: 1976 [61440/90000 (68%)]	Loss: -22.2918	Cost: 9.08s
Train Epoch: 1976 [81920/90000 (91%)]	Loss: -22.0054	Cost: 9.12s
Train Epoch: 1976 	Average Loss: -21.7651
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4600

Learning rate: 0.00018134257530149644
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1977 [0/90000 (0%)]	Loss: -15.1505	Cost: 25.37s
Train Epoch: 1977 [20480/90000 (23%)]	Loss: -22.4493	Cost: 9.34s
Train Epoch: 1977 [40960/90000 (45%)]	Loss: -21.9475	Cost: 9.69s
Train Epoch: 1977 [61440/90000 (68%)]	Loss: -21.7087	Cost: 9.09s
Train Epoch: 1977 [81920/90000 (91%)]	Loss: -21.5018	Cost: 8.82s
Train Epoch: 1977 	Average Loss: -21.5446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9710

Learning rate: 0.00018132429762472425
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1978 [0/90000 (0%)]	Loss: -15.4599	Cost: 25.47s
Train Epoch: 1978 [20480/90000 (23%)]	Loss: -21.9051	Cost: 9.91s
Train Epoch: 1978 [40960/90000 (45%)]	Loss: -21.8742	Cost: 9.10s
Train Epoch: 1978 [61440/90000 (68%)]	Loss: -21.8795	Cost: 9.00s
Train Epoch: 1978 [81920/90000 (91%)]	Loss: -21.9841	Cost: 8.72s
Train Epoch: 1978 	Average Loss: -21.4649
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2549

Learning rate: 0.00018130601192156568
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1979 [0/90000 (0%)]	Loss: -14.9824	Cost: 24.93s
Train Epoch: 1979 [20480/90000 (23%)]	Loss: -21.9822	Cost: 9.58s
Train Epoch: 1979 [40960/90000 (45%)]	Loss: -22.0061	Cost: 9.41s
Train Epoch: 1979 [61440/90000 (68%)]	Loss: -22.1145	Cost: 9.06s
Train Epoch: 1979 [81920/90000 (91%)]	Loss: -21.9796	Cost: 9.40s
Train Epoch: 1979 	Average Loss: -21.6288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4196

Learning rate: 0.00018128771819382543
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1980 [0/90000 (0%)]	Loss: -16.1018	Cost: 23.69s
Train Epoch: 1980 [20480/90000 (23%)]	Loss: -22.3004	Cost: 9.06s
Train Epoch: 1980 [40960/90000 (45%)]	Loss: -22.3068	Cost: 9.97s
Train Epoch: 1980 [61440/90000 (68%)]	Loss: -22.0458	Cost: 9.11s
Train Epoch: 1980 [81920/90000 (91%)]	Loss: -21.5059	Cost: 9.98s
Train Epoch: 1980 	Average Loss: -21.6036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1437

Learning rate: 0.000181269416443309
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1981 [0/90000 (0%)]	Loss: -14.4552	Cost: 24.72s
Train Epoch: 1981 [20480/90000 (23%)]	Loss: -21.8173	Cost: 9.41s
Train Epoch: 1981 [40960/90000 (45%)]	Loss: -21.8171	Cost: 9.34s
Train Epoch: 1981 [61440/90000 (68%)]	Loss: -21.7361	Cost: 9.11s
Train Epoch: 1981 [81920/90000 (91%)]	Loss: -21.6234	Cost: 10.00s
Train Epoch: 1981 	Average Loss: -21.3659
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0964

Learning rate: 0.00018125110667182277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1982 [0/90000 (0%)]	Loss: -14.6177	Cost: 25.35s
Train Epoch: 1982 [20480/90000 (23%)]	Loss: -22.2527	Cost: 9.10s
Train Epoch: 1982 [40960/90000 (45%)]	Loss: -21.9831	Cost: 9.55s
Train Epoch: 1982 [61440/90000 (68%)]	Loss: -22.0704	Cost: 9.08s
Train Epoch: 1982 [81920/90000 (91%)]	Loss: -21.8309	Cost: 10.08s
Train Epoch: 1982 	Average Loss: -21.5774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4426

Learning rate: 0.0001812327888811738
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1983 [0/90000 (0%)]	Loss: -15.5015	Cost: 24.08s
Train Epoch: 1983 [20480/90000 (23%)]	Loss: -22.2462	Cost: 9.04s
Train Epoch: 1983 [40960/90000 (45%)]	Loss: -22.1684	Cost: 9.42s
Train Epoch: 1983 [61440/90000 (68%)]	Loss: -22.3211	Cost: 9.05s
Train Epoch: 1983 [81920/90000 (91%)]	Loss: -21.8061	Cost: 9.53s
Train Epoch: 1983 	Average Loss: -21.8137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3161

Learning rate: 0.00018121446307317
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1984 [0/90000 (0%)]	Loss: -15.0054	Cost: 23.18s
Train Epoch: 1984 [20480/90000 (23%)]	Loss: -22.2369	Cost: 9.03s
Train Epoch: 1984 [40960/90000 (45%)]	Loss: -22.3019	Cost: 9.01s
Train Epoch: 1984 [61440/90000 (68%)]	Loss: -21.9067	Cost: 8.96s
Train Epoch: 1984 [81920/90000 (91%)]	Loss: -21.9932	Cost: 8.98s
Train Epoch: 1984 	Average Loss: -21.7441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4702

Learning rate: 0.00018119612924962004
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1985 [0/90000 (0%)]	Loss: -15.2098	Cost: 24.87s
Train Epoch: 1985 [20480/90000 (23%)]	Loss: -22.2996	Cost: 9.10s
Train Epoch: 1985 [40960/90000 (45%)]	Loss: -22.2740	Cost: 9.86s
Train Epoch: 1985 [61440/90000 (68%)]	Loss: -22.1442	Cost: 8.89s
Train Epoch: 1985 [81920/90000 (91%)]	Loss: -22.1093	Cost: 8.96s
Train Epoch: 1985 	Average Loss: -21.7823
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5742

Learning rate: 0.0001811777874123334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1986 [0/90000 (0%)]	Loss: -15.5408	Cost: 24.88s
Train Epoch: 1986 [20480/90000 (23%)]	Loss: -22.4881	Cost: 9.04s
Train Epoch: 1986 [40960/90000 (45%)]	Loss: -22.1181	Cost: 9.11s
Train Epoch: 1986 [61440/90000 (68%)]	Loss: -22.4475	Cost: 9.01s
Train Epoch: 1986 [81920/90000 (91%)]	Loss: -21.9026	Cost: 8.83s
Train Epoch: 1986 	Average Loss: -21.8582
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5802

Learning rate: 0.00018115943756312033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1987 [0/90000 (0%)]	Loss: -15.8311	Cost: 25.01s
Train Epoch: 1987 [20480/90000 (23%)]	Loss: -22.0850	Cost: 9.05s
Train Epoch: 1987 [40960/90000 (45%)]	Loss: -21.7576	Cost: 9.20s
Train Epoch: 1987 [61440/90000 (68%)]	Loss: -21.8134	Cost: 9.02s
Train Epoch: 1987 [81920/90000 (91%)]	Loss: -21.6098	Cost: 8.74s
Train Epoch: 1987 	Average Loss: -21.5644
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3332

Learning rate: 0.00018114107970379194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1988 [0/90000 (0%)]	Loss: -14.5595	Cost: 25.51s
Train Epoch: 1988 [20480/90000 (23%)]	Loss: -22.1676	Cost: 9.32s
Train Epoch: 1988 [40960/90000 (45%)]	Loss: -22.1519	Cost: 9.35s
Train Epoch: 1988 [61440/90000 (68%)]	Loss: -22.1888	Cost: 9.11s
Train Epoch: 1988 [81920/90000 (91%)]	Loss: -22.2328	Cost: 8.79s
Train Epoch: 1988 	Average Loss: -21.6900
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7726

Learning rate: 0.00018112271383616
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1989 [0/90000 (0%)]	Loss: -16.0569	Cost: 26.24s
Train Epoch: 1989 [20480/90000 (23%)]	Loss: -22.4705	Cost: 9.54s
Train Epoch: 1989 [40960/90000 (45%)]	Loss: -22.2558	Cost: 9.62s
Train Epoch: 1989 [61440/90000 (68%)]	Loss: -22.0580	Cost: 9.15s
Train Epoch: 1989 [81920/90000 (91%)]	Loss: -21.9910	Cost: 8.84s
Train Epoch: 1989 	Average Loss: -21.8546
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3909

Learning rate: 0.0001811043399620372
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1990 [0/90000 (0%)]	Loss: -15.0781	Cost: 24.94s
Train Epoch: 1990 [20480/90000 (23%)]	Loss: -22.1753	Cost: 9.39s
Train Epoch: 1990 [40960/90000 (45%)]	Loss: -21.8288	Cost: 9.30s
Train Epoch: 1990 [61440/90000 (68%)]	Loss: -21.7199	Cost: 9.18s
Train Epoch: 1990 [81920/90000 (91%)]	Loss: -21.9231	Cost: 9.31s
Train Epoch: 1990 	Average Loss: -21.5023
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2280

Learning rate: 0.00018108595808323698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1991 [0/90000 (0%)]	Loss: -15.1458	Cost: 27.43s
Train Epoch: 1991 [20480/90000 (23%)]	Loss: -21.9290	Cost: 9.31s
Train Epoch: 1991 [40960/90000 (45%)]	Loss: -21.6960	Cost: 9.64s
Train Epoch: 1991 [61440/90000 (68%)]	Loss: -21.7596	Cost: 9.13s
Train Epoch: 1991 [81920/90000 (91%)]	Loss: -21.7478	Cost: 9.09s
Train Epoch: 1991 	Average Loss: -21.4181
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2956

Learning rate: 0.00018106756820157353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1992 [0/90000 (0%)]	Loss: -15.7187	Cost: 25.02s
Train Epoch: 1992 [20480/90000 (23%)]	Loss: -22.3709	Cost: 9.54s
Train Epoch: 1992 [40960/90000 (45%)]	Loss: -22.1654	Cost: 9.41s
Train Epoch: 1992 [61440/90000 (68%)]	Loss: -22.1766	Cost: 9.24s
Train Epoch: 1992 [81920/90000 (91%)]	Loss: -22.2107	Cost: 9.17s
Train Epoch: 1992 	Average Loss: -21.8246
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4317

Learning rate: 0.00018104917031886187
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1993 [0/90000 (0%)]	Loss: -16.1119	Cost: 26.33s
Train Epoch: 1993 [20480/90000 (23%)]	Loss: -22.5999	Cost: 9.50s
Train Epoch: 1993 [40960/90000 (45%)]	Loss: -22.3543	Cost: 9.56s
Train Epoch: 1993 [61440/90000 (68%)]	Loss: -22.3145	Cost: 9.00s
Train Epoch: 1993 [81920/90000 (91%)]	Loss: -21.9214	Cost: 8.97s
Train Epoch: 1993 	Average Loss: -21.9166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5591

Learning rate: 0.00018103076443691778
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1994 [0/90000 (0%)]	Loss: -16.0303	Cost: 25.84s
Train Epoch: 1994 [20480/90000 (23%)]	Loss: -22.3233	Cost: 9.45s
Train Epoch: 1994 [40960/90000 (45%)]	Loss: -22.3763	Cost: 9.64s
Train Epoch: 1994 [61440/90000 (68%)]	Loss: -22.3641	Cost: 8.98s
Train Epoch: 1994 [81920/90000 (91%)]	Loss: -22.2095	Cost: 8.74s
Train Epoch: 1994 	Average Loss: -22.0125
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6716

Learning rate: 0.00018101235055755787
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1995 [0/90000 (0%)]	Loss: -15.2472	Cost: 24.89s
Train Epoch: 1995 [20480/90000 (23%)]	Loss: -22.7195	Cost: 9.04s
Train Epoch: 1995 [40960/90000 (45%)]	Loss: -22.7838	Cost: 10.32s
Train Epoch: 1995 [61440/90000 (68%)]	Loss: -22.5234	Cost: 9.23s
Train Epoch: 1995 [81920/90000 (91%)]	Loss: -22.2347	Cost: 9.48s
Train Epoch: 1995 	Average Loss: -22.0877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6464

Learning rate: 0.00018099392868259952
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1996 [0/90000 (0%)]	Loss: -15.9823	Cost: 24.22s
Train Epoch: 1996 [20480/90000 (23%)]	Loss: -22.7724	Cost: 9.53s
Train Epoch: 1996 [40960/90000 (45%)]	Loss: -22.4452	Cost: 9.16s
Train Epoch: 1996 [61440/90000 (68%)]	Loss: -22.4199	Cost: 9.07s
Train Epoch: 1996 [81920/90000 (91%)]	Loss: -22.0586	Cost: 10.11s
Train Epoch: 1996 	Average Loss: -21.9741
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4807

Learning rate: 0.00018097549881386087
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1997 [0/90000 (0%)]	Loss: -15.8528	Cost: 24.44s
Train Epoch: 1997 [20480/90000 (23%)]	Loss: -22.5881	Cost: 9.46s
Train Epoch: 1997 [40960/90000 (45%)]	Loss: -22.1925	Cost: 9.29s
Train Epoch: 1997 [61440/90000 (68%)]	Loss: -21.7903	Cost: 9.09s
Train Epoch: 1997 [81920/90000 (91%)]	Loss: -21.3680	Cost: 10.04s
Train Epoch: 1997 	Average Loss: -21.6688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9774

Learning rate: 0.0001809570609531609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1998 [0/90000 (0%)]	Loss: -15.0255	Cost: 24.04s
Train Epoch: 1998 [20480/90000 (23%)]	Loss: -21.6883	Cost: 9.09s
Train Epoch: 1998 [40960/90000 (45%)]	Loss: -21.7012	Cost: 9.16s
Train Epoch: 1998 [61440/90000 (68%)]	Loss: -22.0533	Cost: 9.06s
Train Epoch: 1998 [81920/90000 (91%)]	Loss: -21.9262	Cost: 10.12s
Train Epoch: 1998 	Average Loss: -21.4119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2530

Learning rate: 0.00018093861510231935
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1999 [0/90000 (0%)]	Loss: -15.2599	Cost: 24.82s
Train Epoch: 1999 [20480/90000 (23%)]	Loss: -21.2799	Cost: 9.39s
Train Epoch: 1999 [40960/90000 (45%)]	Loss: -21.4175	Cost: 9.64s
Train Epoch: 1999 [61440/90000 (68%)]	Loss: -21.9497	Cost: 9.05s
Train Epoch: 1999 [81920/90000 (91%)]	Loss: -21.8446	Cost: 10.18s
Train Epoch: 1999 	Average Loss: -21.2174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3447

Learning rate: 0.00018092016126315674
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2000 [0/90000 (0%)]	Loss: -15.7462	Cost: 24.26s
Train Epoch: 2000 [20480/90000 (23%)]	Loss: -22.1002	Cost: 9.22s
Train Epoch: 2000 [40960/90000 (45%)]	Loss: -21.6941	Cost: 9.78s
Train Epoch: 2000 [61440/90000 (68%)]	Loss: -21.7095	Cost: 9.36s
Train Epoch: 2000 [81920/90000 (91%)]	Loss: -22.0251	Cost: 9.76s
Train Epoch: 2000 	Average Loss: -21.5255
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5534

Saving model as model.pt_e2000 & waveforms_supplementary.hdf5_e2000
Learning rate: 0.0001809016994374944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2001 [0/90000 (0%)]	Loss: -16.0072	Cost: 24.63s
Train Epoch: 2001 [20480/90000 (23%)]	Loss: -22.4156	Cost: 9.36s
Train Epoch: 2001 [40960/90000 (45%)]	Loss: -22.2366	Cost: 9.23s
Train Epoch: 2001 [61440/90000 (68%)]	Loss: -22.2941	Cost: 9.43s
Train Epoch: 2001 [81920/90000 (91%)]	Loss: -22.1127	Cost: 9.73s
Train Epoch: 2001 	Average Loss: -21.8306
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7025

Learning rate: 0.00018088322962715446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2002 [0/90000 (0%)]	Loss: -16.3566	Cost: 23.73s
Train Epoch: 2002 [20480/90000 (23%)]	Loss: -22.5450	Cost: 9.42s
Train Epoch: 2002 [40960/90000 (45%)]	Loss: -22.3908	Cost: 9.21s
Train Epoch: 2002 [61440/90000 (68%)]	Loss: -22.1561	Cost: 9.22s
Train Epoch: 2002 [81920/90000 (91%)]	Loss: -21.9815	Cost: 9.10s
Train Epoch: 2002 	Average Loss: -21.9470
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7046

Learning rate: 0.00018086475183395974
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2003 [0/90000 (0%)]	Loss: -16.0166	Cost: 24.41s
Train Epoch: 2003 [20480/90000 (23%)]	Loss: -22.5084	Cost: 9.16s
Train Epoch: 2003 [40960/90000 (45%)]	Loss: -22.3568	Cost: 9.81s
Train Epoch: 2003 [61440/90000 (68%)]	Loss: -22.2480	Cost: 8.98s
Train Epoch: 2003 [81920/90000 (91%)]	Loss: -22.2192	Cost: 8.99s
Train Epoch: 2003 	Average Loss: -21.9466
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7840

Learning rate: 0.000180846266059734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2004 [0/90000 (0%)]	Loss: -16.5662	Cost: 23.65s
Train Epoch: 2004 [20480/90000 (23%)]	Loss: -22.6653	Cost: 9.00s
Train Epoch: 2004 [40960/90000 (45%)]	Loss: -22.5510	Cost: 9.05s
Train Epoch: 2004 [61440/90000 (68%)]	Loss: -22.2236	Cost: 9.03s
Train Epoch: 2004 [81920/90000 (91%)]	Loss: -22.1659	Cost: 8.75s
Train Epoch: 2004 	Average Loss: -21.9434
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5037

Learning rate: 0.0001808277723063017
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2005 [0/90000 (0%)]	Loss: -14.3382	Cost: 25.69s
Train Epoch: 2005 [20480/90000 (23%)]	Loss: -22.4085	Cost: 9.35s
Train Epoch: 2005 [40960/90000 (45%)]	Loss: -22.3194	Cost: 9.30s
Train Epoch: 2005 [61440/90000 (68%)]	Loss: -22.4222	Cost: 9.18s
Train Epoch: 2005 [81920/90000 (91%)]	Loss: -22.3791	Cost: 8.86s
Train Epoch: 2005 	Average Loss: -21.8913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6449

Learning rate: 0.0001808092705754881
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2006 [0/90000 (0%)]	Loss: -15.8090	Cost: 25.09s
Train Epoch: 2006 [20480/90000 (23%)]	Loss: -22.4734	Cost: 9.42s
Train Epoch: 2006 [40960/90000 (45%)]	Loss: -22.4916	Cost: 9.24s
Train Epoch: 2006 [61440/90000 (68%)]	Loss: -22.3737	Cost: 9.18s
Train Epoch: 2006 [81920/90000 (91%)]	Loss: -22.0127	Cost: 9.00s
Train Epoch: 2006 	Average Loss: -21.9662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6122

Learning rate: 0.00018079076086911924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2007 [0/90000 (0%)]	Loss: -15.4480	Cost: 27.82s
Train Epoch: 2007 [20480/90000 (23%)]	Loss: -22.1709	Cost: 9.31s
Train Epoch: 2007 [40960/90000 (45%)]	Loss: -21.7067	Cost: 9.32s
Train Epoch: 2007 [61440/90000 (68%)]	Loss: -21.8392	Cost: 9.44s
Train Epoch: 2007 [81920/90000 (91%)]	Loss: -21.6974	Cost: 8.80s
Train Epoch: 2007 	Average Loss: -21.6389
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2425

Learning rate: 0.00018077224318902195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2008 [0/90000 (0%)]	Loss: -15.2083	Cost: 27.35s
Train Epoch: 2008 [20480/90000 (23%)]	Loss: -22.1157	Cost: 9.33s
Train Epoch: 2008 [40960/90000 (45%)]	Loss: -22.0358	Cost: 9.29s
Train Epoch: 2008 [61440/90000 (68%)]	Loss: -21.8680	Cost: 9.12s
Train Epoch: 2008 [81920/90000 (91%)]	Loss: -21.5950	Cost: 8.78s
Train Epoch: 2008 	Average Loss: -21.5455
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3519

Learning rate: 0.00018075371753702385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2009 [0/90000 (0%)]	Loss: -15.7217	Cost: 25.18s
Train Epoch: 2009 [20480/90000 (23%)]	Loss: -22.1339	Cost: 9.46s
Train Epoch: 2009 [40960/90000 (45%)]	Loss: -21.7285	Cost: 9.23s
Train Epoch: 2009 [61440/90000 (68%)]	Loss: -21.8822	Cost: 9.19s
Train Epoch: 2009 [81920/90000 (91%)]	Loss: -21.5705	Cost: 9.10s
Train Epoch: 2009 	Average Loss: -21.4386
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2529

Learning rate: 0.00018073518391495337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2010 [0/90000 (0%)]	Loss: -15.0461	Cost: 25.06s
Train Epoch: 2010 [20480/90000 (23%)]	Loss: -22.0925	Cost: 9.36s
Train Epoch: 2010 [40960/90000 (45%)]	Loss: -22.0181	Cost: 9.35s
Train Epoch: 2010 [61440/90000 (68%)]	Loss: -22.1103	Cost: 9.26s
Train Epoch: 2010 [81920/90000 (91%)]	Loss: -21.9459	Cost: 8.95s
Train Epoch: 2010 	Average Loss: -21.6343
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2641

Learning rate: 0.00018071664232463967
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2011 [0/90000 (0%)]	Loss: -15.1112	Cost: 24.95s
Train Epoch: 2011 [20480/90000 (23%)]	Loss: -22.3445	Cost: 9.34s
Train Epoch: 2011 [40960/90000 (45%)]	Loss: -22.1961	Cost: 10.06s
Train Epoch: 2011 [61440/90000 (68%)]	Loss: -22.1752	Cost: 9.55s
Train Epoch: 2011 [81920/90000 (91%)]	Loss: -21.7144	Cost: 8.94s
Train Epoch: 2011 	Average Loss: -21.7866
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1881

Learning rate: 0.00018069809276791276
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2012 [0/90000 (0%)]	Loss: -15.9921	Cost: 25.05s
Train Epoch: 2012 [20480/90000 (23%)]	Loss: -22.4314	Cost: 9.28s
Train Epoch: 2012 [40960/90000 (45%)]	Loss: -22.1050	Cost: 9.44s
Train Epoch: 2012 [61440/90000 (68%)]	Loss: -22.1737	Cost: 8.97s
Train Epoch: 2012 [81920/90000 (91%)]	Loss: -22.0675	Cost: 8.85s
Train Epoch: 2012 	Average Loss: -21.7913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6076

Learning rate: 0.00018067953524660344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2013 [0/90000 (0%)]	Loss: -15.5932	Cost: 25.70s
Train Epoch: 2013 [20480/90000 (23%)]	Loss: -22.1160	Cost: 9.48s
Train Epoch: 2013 [40960/90000 (45%)]	Loss: -22.0637	Cost: 10.39s
Train Epoch: 2013 [61440/90000 (68%)]	Loss: -22.2196	Cost: 9.06s
Train Epoch: 2013 [81920/90000 (91%)]	Loss: -21.8267	Cost: 8.82s
Train Epoch: 2013 	Average Loss: -21.7611
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2385

Learning rate: 0.00018066096976254316
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2014 [0/90000 (0%)]	Loss: -15.7721	Cost: 24.73s
Train Epoch: 2014 [20480/90000 (23%)]	Loss: -22.0484	Cost: 9.94s
Train Epoch: 2014 [40960/90000 (45%)]	Loss: -22.1045	Cost: 9.10s
Train Epoch: 2014 [61440/90000 (68%)]	Loss: -21.6375	Cost: 8.97s
Train Epoch: 2014 [81920/90000 (91%)]	Loss: -20.1557	Cost: 8.69s
Train Epoch: 2014 	Average Loss: -21.1578
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7421

Learning rate: 0.00018064239631756436
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2015 [0/90000 (0%)]	Loss: -14.5075	Cost: 25.20s
Train Epoch: 2015 [20480/90000 (23%)]	Loss: -20.9413	Cost: 9.56s
Train Epoch: 2015 [40960/90000 (45%)]	Loss: -20.9100	Cost: 9.31s
Train Epoch: 2015 [61440/90000 (68%)]	Loss: -21.1767	Cost: 9.30s
Train Epoch: 2015 [81920/90000 (91%)]	Loss: -21.0142	Cost: 8.80s
Train Epoch: 2015 	Average Loss: -20.5542
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.6838

Learning rate: 0.00018062381491350013
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2016 [0/90000 (0%)]	Loss: -15.2812	Cost: 24.27s
Train Epoch: 2016 [20480/90000 (23%)]	Loss: -21.7347	Cost: 9.57s
Train Epoch: 2016 [40960/90000 (45%)]	Loss: -21.7232	Cost: 9.16s
Train Epoch: 2016 [61440/90000 (68%)]	Loss: -21.6927	Cost: 9.04s
Train Epoch: 2016 [81920/90000 (91%)]	Loss: -21.4127	Cost: 9.97s
Train Epoch: 2016 	Average Loss: -21.2402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2312

Learning rate: 0.00018060522555218435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2017 [0/90000 (0%)]	Loss: -14.9422	Cost: 23.69s
Train Epoch: 2017 [20480/90000 (23%)]	Loss: -22.1271	Cost: 9.71s
Train Epoch: 2017 [40960/90000 (45%)]	Loss: -22.3693	Cost: 9.05s
Train Epoch: 2017 [61440/90000 (68%)]	Loss: -21.3213	Cost: 9.09s
Train Epoch: 2017 [81920/90000 (91%)]	Loss: -21.4093	Cost: 9.89s
Train Epoch: 2017 	Average Loss: -21.3753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8231

Learning rate: 0.0001805866282354518
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2018 [0/90000 (0%)]	Loss: -14.8668	Cost: 23.54s
Train Epoch: 2018 [20480/90000 (23%)]	Loss: -21.9826	Cost: 9.19s
Train Epoch: 2018 [40960/90000 (45%)]	Loss: -21.4924	Cost: 9.11s
Train Epoch: 2018 [61440/90000 (68%)]	Loss: -21.7119	Cost: 9.05s
Train Epoch: 2018 [81920/90000 (91%)]	Loss: -21.6568	Cost: 10.06s
Train Epoch: 2018 	Average Loss: -21.2804
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3100

Learning rate: 0.00018056802296513786
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2019 [0/90000 (0%)]	Loss: -15.7012	Cost: 24.66s
Train Epoch: 2019 [20480/90000 (23%)]	Loss: -22.1792	Cost: 9.36s
Train Epoch: 2019 [40960/90000 (45%)]	Loss: -22.2268	Cost: 9.42s
Train Epoch: 2019 [61440/90000 (68%)]	Loss: -22.1318	Cost: 9.11s
Train Epoch: 2019 [81920/90000 (91%)]	Loss: -22.0389	Cost: 10.73s
Train Epoch: 2019 	Average Loss: -21.7226
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6674

Learning rate: 0.00018054940974307888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2020 [0/90000 (0%)]	Loss: -16.3655	Cost: 24.44s
Train Epoch: 2020 [20480/90000 (23%)]	Loss: -22.4587	Cost: 9.07s
Train Epoch: 2020 [40960/90000 (45%)]	Loss: -22.5946	Cost: 10.17s
Train Epoch: 2020 [61440/90000 (68%)]	Loss: -21.9565	Cost: 9.19s
Train Epoch: 2020 [81920/90000 (91%)]	Loss: -22.0095	Cost: 10.00s
Train Epoch: 2020 	Average Loss: -21.9650
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4590

Learning rate: 0.00018053078857111185
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2021 [0/90000 (0%)]	Loss: -14.8226	Cost: 23.16s
Train Epoch: 2021 [20480/90000 (23%)]	Loss: -22.2905	Cost: 9.33s
Train Epoch: 2021 [40960/90000 (45%)]	Loss: -22.1128	Cost: 9.19s
Train Epoch: 2021 [61440/90000 (68%)]	Loss: -21.9975	Cost: 9.18s
Train Epoch: 2021 [81920/90000 (91%)]	Loss: -21.7967	Cost: 9.82s
Train Epoch: 2021 	Average Loss: -21.6420
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5210

Learning rate: 0.00018051215945107463
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2022 [0/90000 (0%)]	Loss: -14.5360	Cost: 24.15s
Train Epoch: 2022 [20480/90000 (23%)]	Loss: -22.4053	Cost: 9.41s
Train Epoch: 2022 [40960/90000 (45%)]	Loss: -22.2837	Cost: 9.39s
Train Epoch: 2022 [61440/90000 (68%)]	Loss: -22.3800	Cost: 9.09s
Train Epoch: 2022 [81920/90000 (91%)]	Loss: -21.8774	Cost: 9.11s
Train Epoch: 2022 	Average Loss: -21.8208
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6112

Learning rate: 0.00018049352238480587
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2023 [0/90000 (0%)]	Loss: -15.4739	Cost: 24.39s
Train Epoch: 2023 [20480/90000 (23%)]	Loss: -22.8422	Cost: 9.36s
Train Epoch: 2023 [40960/90000 (45%)]	Loss: -22.4861	Cost: 9.17s
Train Epoch: 2023 [61440/90000 (68%)]	Loss: -22.2688	Cost: 9.16s
Train Epoch: 2023 [81920/90000 (91%)]	Loss: -22.1579	Cost: 9.04s
Train Epoch: 2023 	Average Loss: -22.0337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7105

Learning rate: 0.0001804748773741449
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2024 [0/90000 (0%)]	Loss: -15.3602	Cost: 24.56s
Train Epoch: 2024 [20480/90000 (23%)]	Loss: -22.7159	Cost: 9.30s
Train Epoch: 2024 [40960/90000 (45%)]	Loss: -22.4709	Cost: 9.35s
Train Epoch: 2024 [61440/90000 (68%)]	Loss: -22.3612	Cost: 9.08s
Train Epoch: 2024 [81920/90000 (91%)]	Loss: -22.1310	Cost: 8.74s
Train Epoch: 2024 	Average Loss: -22.0008
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6244

Learning rate: 0.000180456224420932
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2025 [0/90000 (0%)]	Loss: -14.3903	Cost: 24.99s
Train Epoch: 2025 [20480/90000 (23%)]	Loss: -22.5369	Cost: 9.31s
Train Epoch: 2025 [40960/90000 (45%)]	Loss: -22.4523	Cost: 9.26s
Train Epoch: 2025 [61440/90000 (68%)]	Loss: -22.2348	Cost: 9.29s
Train Epoch: 2025 [81920/90000 (91%)]	Loss: -22.2710	Cost: 8.80s
Train Epoch: 2025 	Average Loss: -21.8782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4374

Learning rate: 0.00018043756352700805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2026 [0/90000 (0%)]	Loss: -15.9143	Cost: 27.39s
Train Epoch: 2026 [20480/90000 (23%)]	Loss: -22.1616	Cost: 9.28s
Train Epoch: 2026 [40960/90000 (45%)]	Loss: -22.1028	Cost: 9.28s
Train Epoch: 2026 [61440/90000 (68%)]	Loss: -22.2938	Cost: 9.26s
Train Epoch: 2026 [81920/90000 (91%)]	Loss: -21.4821	Cost: 9.02s
Train Epoch: 2026 	Average Loss: -21.7871
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0574

Learning rate: 0.0001804188946942149
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2027 [0/90000 (0%)]	Loss: -15.2491	Cost: 25.34s
Train Epoch: 2027 [20480/90000 (23%)]	Loss: -22.0049	Cost: 9.39s
Train Epoch: 2027 [40960/90000 (45%)]	Loss: -21.8003	Cost: 9.27s
Train Epoch: 2027 [61440/90000 (68%)]	Loss: -21.9044	Cost: 9.18s
Train Epoch: 2027 [81920/90000 (91%)]	Loss: -21.7192	Cost: 8.81s
Train Epoch: 2027 	Average Loss: -21.5402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5394

Learning rate: 0.00018040021792439505
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2028 [0/90000 (0%)]	Loss: -15.6481	Cost: 25.84s
Train Epoch: 2028 [20480/90000 (23%)]	Loss: -22.4913	Cost: 9.42s
Train Epoch: 2028 [40960/90000 (45%)]	Loss: -21.9868	Cost: 9.22s
Train Epoch: 2028 [61440/90000 (68%)]	Loss: -21.9813	Cost: 9.26s
Train Epoch: 2028 [81920/90000 (91%)]	Loss: -22.0261	Cost: 9.00s
Train Epoch: 2028 	Average Loss: -21.7164
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5037

Learning rate: 0.00018038153321939178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2029 [0/90000 (0%)]	Loss: -15.9270	Cost: 25.35s
Train Epoch: 2029 [20480/90000 (23%)]	Loss: -22.5524	Cost: 9.39s
Train Epoch: 2029 [40960/90000 (45%)]	Loss: -22.4755	Cost: 9.30s
Train Epoch: 2029 [61440/90000 (68%)]	Loss: -22.4091	Cost: 9.20s
Train Epoch: 2029 [81920/90000 (91%)]	Loss: -22.3393	Cost: 9.02s
Train Epoch: 2029 	Average Loss: -22.0125
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9799

Learning rate: 0.00018036284058104926
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2030 [0/90000 (0%)]	Loss: -15.7203	Cost: 25.16s
Train Epoch: 2030 [20480/90000 (23%)]	Loss: -22.8083	Cost: 9.36s
Train Epoch: 2030 [40960/90000 (45%)]	Loss: -22.3465	Cost: 9.31s
Train Epoch: 2030 [61440/90000 (68%)]	Loss: -22.3184	Cost: 9.27s
Train Epoch: 2030 [81920/90000 (91%)]	Loss: -19.2679	Cost: 9.05s
Train Epoch: 2030 	Average Loss: -21.4564
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9319

Learning rate: 0.00018034414001121237
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2031 [0/90000 (0%)]	Loss: -12.8899	Cost: 25.78s
Train Epoch: 2031 [20480/90000 (23%)]	Loss: -19.8434	Cost: 9.38s
Train Epoch: 2031 [40960/90000 (45%)]	Loss: -20.1361	Cost: 9.67s
Train Epoch: 2031 [61440/90000 (68%)]	Loss: -20.5731	Cost: 9.09s
Train Epoch: 2031 [81920/90000 (91%)]	Loss: -20.8283	Cost: 9.24s
Train Epoch: 2031 	Average Loss: -19.8716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.8815

Learning rate: 0.00018032543151172672
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2032 [0/90000 (0%)]	Loss: -14.9842	Cost: 25.72s
Train Epoch: 2032 [20480/90000 (23%)]	Loss: -21.4933	Cost: 9.36s
Train Epoch: 2032 [40960/90000 (45%)]	Loss: -21.7908	Cost: 9.37s
Train Epoch: 2032 [61440/90000 (68%)]	Loss: -21.7764	Cost: 9.12s
Train Epoch: 2032 [81920/90000 (91%)]	Loss: -21.8654	Cost: 8.98s
Train Epoch: 2032 	Average Loss: -21.3130
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3231

Learning rate: 0.00018030671508443885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2033 [0/90000 (0%)]	Loss: -15.1488	Cost: 25.33s
Train Epoch: 2033 [20480/90000 (23%)]	Loss: -22.3252	Cost: 9.42s
Train Epoch: 2033 [40960/90000 (45%)]	Loss: -22.1866	Cost: 9.40s
Train Epoch: 2033 [61440/90000 (68%)]	Loss: -21.8117	Cost: 9.05s
Train Epoch: 2033 [81920/90000 (91%)]	Loss: -21.8056	Cost: 8.96s
Train Epoch: 2033 	Average Loss: -21.5789
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3703

Learning rate: 0.00018028799073119595
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2034 [0/90000 (0%)]	Loss: -15.5437	Cost: 25.58s
Train Epoch: 2034 [20480/90000 (23%)]	Loss: -22.2041	Cost: 10.59s
Train Epoch: 2034 [40960/90000 (45%)]	Loss: -22.1513	Cost: 9.21s
Train Epoch: 2034 [61440/90000 (68%)]	Loss: -22.1635	Cost: 9.24s
Train Epoch: 2034 [81920/90000 (91%)]	Loss: -22.0018	Cost: 8.76s
Train Epoch: 2034 	Average Loss: -21.8278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5318

Learning rate: 0.00018026925845384604
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2035 [0/90000 (0%)]	Loss: -15.9319	Cost: 24.91s
Train Epoch: 2035 [20480/90000 (23%)]	Loss: -22.6498	Cost: 9.54s
Train Epoch: 2035 [40960/90000 (45%)]	Loss: -22.3413	Cost: 9.24s
Train Epoch: 2035 [61440/90000 (68%)]	Loss: -22.1051	Cost: 9.03s
Train Epoch: 2035 [81920/90000 (91%)]	Loss: -22.2303	Cost: 9.48s
Train Epoch: 2035 	Average Loss: -21.9689
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7001

Learning rate: 0.00018025051825423794
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2036 [0/90000 (0%)]	Loss: -16.3124	Cost: 23.62s
Train Epoch: 2036 [20480/90000 (23%)]	Loss: -22.6819	Cost: 9.55s
Train Epoch: 2036 [40960/90000 (45%)]	Loss: -22.5088	Cost: 9.95s
Train Epoch: 2036 [61440/90000 (68%)]	Loss: -22.6173	Cost: 9.03s
Train Epoch: 2036 [81920/90000 (91%)]	Loss: -22.3231	Cost: 10.39s
Train Epoch: 2036 	Average Loss: -22.1283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6930

Learning rate: 0.00018023177013422125
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2037 [0/90000 (0%)]	Loss: -15.5059	Cost: 23.77s
Train Epoch: 2037 [20480/90000 (23%)]	Loss: -22.4680	Cost: 9.47s
Train Epoch: 2037 [40960/90000 (45%)]	Loss: -22.7738	Cost: 9.12s
Train Epoch: 2037 [61440/90000 (68%)]	Loss: -22.4867	Cost: 9.11s
Train Epoch: 2037 [81920/90000 (91%)]	Loss: -22.1905	Cost: 9.98s
Train Epoch: 2037 	Average Loss: -22.1076
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6354

Learning rate: 0.00018021301409564629
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2038 [0/90000 (0%)]	Loss: -15.3741	Cost: 23.80s
Train Epoch: 2038 [20480/90000 (23%)]	Loss: -22.7668	Cost: 9.24s
Train Epoch: 2038 [40960/90000 (45%)]	Loss: -22.7189	Cost: 9.07s
Train Epoch: 2038 [61440/90000 (68%)]	Loss: -22.7158	Cost: 9.06s
Train Epoch: 2038 [81920/90000 (91%)]	Loss: -22.2779	Cost: 9.91s
Train Epoch: 2038 	Average Loss: -22.1496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7867

Learning rate: 0.0001801942501403642
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2039 [0/90000 (0%)]	Loss: -15.2130	Cost: 24.10s
Train Epoch: 2039 [20480/90000 (23%)]	Loss: -22.7104	Cost: 9.12s
Train Epoch: 2039 [40960/90000 (45%)]	Loss: -22.7146	Cost: 9.26s
Train Epoch: 2039 [61440/90000 (68%)]	Loss: -22.6232	Cost: 9.05s
Train Epoch: 2039 [81920/90000 (91%)]	Loss: -22.3062	Cost: 9.99s
Train Epoch: 2039 	Average Loss: -22.1820
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6970

Learning rate: 0.00018017547827022697
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2040 [0/90000 (0%)]	Loss: -15.7272	Cost: 23.87s
Train Epoch: 2040 [20480/90000 (23%)]	Loss: -22.8569	Cost: 9.26s
Train Epoch: 2040 [40960/90000 (45%)]	Loss: -22.4369	Cost: 9.92s
Train Epoch: 2040 [61440/90000 (68%)]	Loss: -22.3012	Cost: 9.28s
Train Epoch: 2040 [81920/90000 (91%)]	Loss: -22.1080	Cost: 9.89s
Train Epoch: 2040 	Average Loss: -22.0101
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8550

Learning rate: 0.00018015669848708726
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2041 [0/90000 (0%)]	Loss: -16.1733	Cost: 23.97s
Train Epoch: 2041 [20480/90000 (23%)]	Loss: -22.6282	Cost: 9.29s
Train Epoch: 2041 [40960/90000 (45%)]	Loss: -22.1120	Cost: 9.24s
Train Epoch: 2041 [61440/90000 (68%)]	Loss: -22.0891	Cost: 9.22s
Train Epoch: 2041 [81920/90000 (91%)]	Loss: -21.9012	Cost: 9.81s
Train Epoch: 2041 	Average Loss: -21.8005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3090

Learning rate: 0.00018013791079279855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2042 [0/90000 (0%)]	Loss: -13.7115	Cost: 23.62s
Train Epoch: 2042 [20480/90000 (23%)]	Loss: -21.9537	Cost: 9.37s
Train Epoch: 2042 [40960/90000 (45%)]	Loss: -21.1625	Cost: 9.32s
Train Epoch: 2042 [61440/90000 (68%)]	Loss: -21.2372	Cost: 9.50s
Train Epoch: 2042 [81920/90000 (91%)]	Loss: -21.3797	Cost: 9.22s
Train Epoch: 2042 	Average Loss: -21.0486
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0476

Learning rate: 0.00018011911518921517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2043 [0/90000 (0%)]	Loss: -14.8374	Cost: 25.16s
Train Epoch: 2043 [20480/90000 (23%)]	Loss: -21.9839	Cost: 9.39s
Train Epoch: 2043 [40960/90000 (45%)]	Loss: -21.9671	Cost: 10.07s
Train Epoch: 2043 [61440/90000 (68%)]	Loss: -21.8812	Cost: 9.12s
Train Epoch: 2043 [81920/90000 (91%)]	Loss: -21.9170	Cost: 8.96s
Train Epoch: 2043 	Average Loss: -21.5267
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2511

Learning rate: 0.0001801003116781921
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2044 [0/90000 (0%)]	Loss: -15.1218	Cost: 24.52s
Train Epoch: 2044 [20480/90000 (23%)]	Loss: -22.1073	Cost: 9.34s
Train Epoch: 2044 [40960/90000 (45%)]	Loss: -22.1136	Cost: 9.28s
Train Epoch: 2044 [61440/90000 (68%)]	Loss: -22.0000	Cost: 9.04s
Train Epoch: 2044 [81920/90000 (91%)]	Loss: -21.9906	Cost: 8.76s
Train Epoch: 2044 	Average Loss: -21.6964
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7500

Learning rate: 0.00018008150026158523
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2045 [0/90000 (0%)]	Loss: -15.1867	Cost: 24.85s
Train Epoch: 2045 [20480/90000 (23%)]	Loss: -22.4585	Cost: 9.37s
Train Epoch: 2045 [40960/90000 (45%)]	Loss: -22.6071	Cost: 9.28s
Train Epoch: 2045 [61440/90000 (68%)]	Loss: -22.5963	Cost: 9.20s
Train Epoch: 2045 [81920/90000 (91%)]	Loss: -22.1349	Cost: 9.14s
Train Epoch: 2045 	Average Loss: -22.0414
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7533

Learning rate: 0.00018006268094125118
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2046 [0/90000 (0%)]	Loss: -15.1173	Cost: 25.90s
Train Epoch: 2046 [20480/90000 (23%)]	Loss: -22.5169	Cost: 9.41s
Train Epoch: 2046 [40960/90000 (45%)]	Loss: -22.2577	Cost: 9.31s
Train Epoch: 2046 [61440/90000 (68%)]	Loss: -22.3966	Cost: 9.19s
Train Epoch: 2046 [81920/90000 (91%)]	Loss: -22.3130	Cost: 9.08s
Train Epoch: 2046 	Average Loss: -21.9723
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0176

Learning rate: 0.0001800438537190473
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2047 [0/90000 (0%)]	Loss: -16.5978	Cost: 25.29s
Train Epoch: 2047 [20480/90000 (23%)]	Loss: -22.6840	Cost: 9.34s
Train Epoch: 2047 [40960/90000 (45%)]	Loss: -22.7082	Cost: 9.26s
Train Epoch: 2047 [61440/90000 (68%)]	Loss: -22.6686	Cost: 9.25s
Train Epoch: 2047 [81920/90000 (91%)]	Loss: -19.9260	Cost: 9.12s
Train Epoch: 2047 	Average Loss: -21.8586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4530

Learning rate: 0.00018002501859683173
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2048 [0/90000 (0%)]	Loss: -13.3739	Cost: 25.35s
Train Epoch: 2048 [20480/90000 (23%)]	Loss: -20.3582	Cost: 9.44s
Train Epoch: 2048 [40960/90000 (45%)]	Loss: -20.4906	Cost: 9.39s
Train Epoch: 2048 [61440/90000 (68%)]	Loss: -20.9209	Cost: 9.26s
Train Epoch: 2048 [81920/90000 (91%)]	Loss: -21.1845	Cost: 9.81s
Train Epoch: 2048 	Average Loss: -20.2404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.7444

Learning rate: 0.0001800061755764635
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2049 [0/90000 (0%)]	Loss: -15.5568	Cost: 25.21s
Train Epoch: 2049 [20480/90000 (23%)]	Loss: -21.7190	Cost: 9.51s
Train Epoch: 2049 [40960/90000 (45%)]	Loss: -21.8470	Cost: 9.36s
Train Epoch: 2049 [61440/90000 (68%)]	Loss: -22.0415	Cost: 9.26s
Train Epoch: 2049 [81920/90000 (91%)]	Loss: -22.0739	Cost: 9.57s
Train Epoch: 2049 	Average Loss: -21.4924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6460

Learning rate: 0.0001799873246598023
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2050 [0/90000 (0%)]	Loss: -16.3395	Cost: 24.96s
Train Epoch: 2050 [20480/90000 (23%)]	Loss: -22.2551	Cost: 10.16s
Train Epoch: 2050 [40960/90000 (45%)]	Loss: -22.1268	Cost: 9.10s
Train Epoch: 2050 [61440/90000 (68%)]	Loss: -22.2649	Cost: 8.97s
Train Epoch: 2050 [81920/90000 (91%)]	Loss: -22.1540	Cost: 8.73s
Train Epoch: 2050 	Average Loss: -21.8554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7808

Saving model as model.pt_e2050 & waveforms_supplementary.hdf5_e2050
Learning rate: 0.00017996846584870867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2051 [0/90000 (0%)]	Loss: -15.6390	Cost: 25.44s
Train Epoch: 2051 [20480/90000 (23%)]	Loss: -22.3939	Cost: 10.05s
Train Epoch: 2051 [40960/90000 (45%)]	Loss: -22.2072	Cost: 9.03s
Train Epoch: 2051 [61440/90000 (68%)]	Loss: -22.2851	Cost: 8.90s
Train Epoch: 2051 [81920/90000 (91%)]	Loss: -22.3643	Cost: 8.69s
Train Epoch: 2051 	Average Loss: -21.9744
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6999

Learning rate: 0.00017994959914504385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2052 [0/90000 (0%)]	Loss: -15.8212	Cost: 24.94s
Train Epoch: 2052 [20480/90000 (23%)]	Loss: -22.4442	Cost: 9.00s
Train Epoch: 2052 [40960/90000 (45%)]	Loss: -22.4763	Cost: 10.02s
Train Epoch: 2052 [61440/90000 (68%)]	Loss: -22.4991	Cost: 9.01s
Train Epoch: 2052 [81920/90000 (91%)]	Loss: -22.1774	Cost: 9.58s
Train Epoch: 2052 	Average Loss: -22.0570
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7646

Learning rate: 0.00017993072455066997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2053 [0/90000 (0%)]	Loss: -15.0049	Cost: 24.20s
Train Epoch: 2053 [20480/90000 (23%)]	Loss: -22.6905	Cost: 9.49s
Train Epoch: 2053 [40960/90000 (45%)]	Loss: -22.2076	Cost: 9.85s
Train Epoch: 2053 [61440/90000 (68%)]	Loss: -22.3148	Cost: 9.09s
Train Epoch: 2053 [81920/90000 (91%)]	Loss: -22.3352	Cost: 10.31s
Train Epoch: 2053 	Average Loss: -21.9416
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6204

Learning rate: 0.0001799118420674498
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2054 [0/90000 (0%)]	Loss: -15.4652	Cost: 23.69s
Train Epoch: 2054 [20480/90000 (23%)]	Loss: -22.5539	Cost: 9.46s
Train Epoch: 2054 [40960/90000 (45%)]	Loss: -22.4814	Cost: 9.19s
Train Epoch: 2054 [61440/90000 (68%)]	Loss: -22.4007	Cost: 9.04s
Train Epoch: 2054 [81920/90000 (91%)]	Loss: -22.1563	Cost: 10.48s
Train Epoch: 2054 	Average Loss: -22.0538
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7824

Learning rate: 0.00017989295169724704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2055 [0/90000 (0%)]	Loss: -16.8073	Cost: 25.99s
Train Epoch: 2055 [20480/90000 (23%)]	Loss: -22.7105	Cost: 9.47s
Train Epoch: 2055 [40960/90000 (45%)]	Loss: -22.3754	Cost: 9.37s
Train Epoch: 2055 [61440/90000 (68%)]	Loss: -22.6080	Cost: 9.16s
Train Epoch: 2055 [81920/90000 (91%)]	Loss: -22.5294	Cost: 9.90s
Train Epoch: 2055 	Average Loss: -22.1974
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8807

Learning rate: 0.00017987405344192608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2056 [0/90000 (0%)]	Loss: -16.2938	Cost: 23.84s
Train Epoch: 2056 [20480/90000 (23%)]	Loss: -22.8598	Cost: 9.33s
Train Epoch: 2056 [40960/90000 (45%)]	Loss: -22.6231	Cost: 9.37s
Train Epoch: 2056 [61440/90000 (68%)]	Loss: -22.6596	Cost: 9.17s
Train Epoch: 2056 [81920/90000 (91%)]	Loss: -22.3938	Cost: 9.64s
Train Epoch: 2056 	Average Loss: -22.2267
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9016

Learning rate: 0.00017985514730335208
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2057 [0/90000 (0%)]	Loss: -15.9717	Cost: 24.33s
Train Epoch: 2057 [20480/90000 (23%)]	Loss: -22.5729	Cost: 9.35s
Train Epoch: 2057 [40960/90000 (45%)]	Loss: -22.3675	Cost: 9.46s
Train Epoch: 2057 [61440/90000 (68%)]	Loss: -22.1199	Cost: 9.27s
Train Epoch: 2057 [81920/90000 (91%)]	Loss: -22.0500	Cost: 9.08s
Train Epoch: 2057 	Average Loss: -21.8113
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3212

Learning rate: 0.000179836233283391
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2058 [0/90000 (0%)]	Loss: -14.0747	Cost: 23.95s
Train Epoch: 2058 [20480/90000 (23%)]	Loss: -22.2240	Cost: 9.41s
Train Epoch: 2058 [40960/90000 (45%)]	Loss: -19.8090	Cost: 9.35s
Train Epoch: 2058 [61440/90000 (68%)]	Loss: -19.3521	Cost: 9.11s
Train Epoch: 2058 [81920/90000 (91%)]	Loss: -19.8397	Cost: 9.19s
Train Epoch: 2058 	Average Loss: -20.0695
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9249

Learning rate: 0.0001798173113839096
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2059 [0/90000 (0%)]	Loss: -13.6794	Cost: 25.27s
Train Epoch: 2059 [20480/90000 (23%)]	Loss: -21.0079	Cost: 9.40s
Train Epoch: 2059 [40960/90000 (45%)]	Loss: -21.2765	Cost: 9.20s
Train Epoch: 2059 [61440/90000 (68%)]	Loss: -21.4419	Cost: 9.29s
Train Epoch: 2059 [81920/90000 (91%)]	Loss: -21.3426	Cost: 9.03s
Train Epoch: 2059 	Average Loss: -20.8013
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1134

Learning rate: 0.0001797983816067754
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2060 [0/90000 (0%)]	Loss: -15.5977	Cost: 25.30s
Train Epoch: 2060 [20480/90000 (23%)]	Loss: -22.2482	Cost: 9.34s
Train Epoch: 2060 [40960/90000 (45%)]	Loss: -22.2863	Cost: 9.25s
Train Epoch: 2060 [61440/90000 (68%)]	Loss: -22.3050	Cost: 9.22s
Train Epoch: 2060 [81920/90000 (91%)]	Loss: -22.0105	Cost: 9.26s
Train Epoch: 2060 	Average Loss: -21.7532
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6350

Learning rate: 0.00017977944395385667
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2061 [0/90000 (0%)]	Loss: -15.8780	Cost: 24.51s
Train Epoch: 2061 [20480/90000 (23%)]	Loss: -22.5511	Cost: 9.40s
Train Epoch: 2061 [40960/90000 (45%)]	Loss: -22.3992	Cost: 9.38s
Train Epoch: 2061 [61440/90000 (68%)]	Loss: -22.2598	Cost: 9.19s
Train Epoch: 2061 [81920/90000 (91%)]	Loss: -22.0556	Cost: 9.03s
Train Epoch: 2061 	Average Loss: -21.9457
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8423

Learning rate: 0.0001797604984270225
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2062 [0/90000 (0%)]	Loss: -15.3065	Cost: 26.67s
Train Epoch: 2062 [20480/90000 (23%)]	Loss: -22.6972	Cost: 9.90s
Train Epoch: 2062 [40960/90000 (45%)]	Loss: -22.4102	Cost: 9.34s
Train Epoch: 2062 [61440/90000 (68%)]	Loss: -22.5119	Cost: 9.13s
Train Epoch: 2062 [81920/90000 (91%)]	Loss: -22.2169	Cost: 9.03s
Train Epoch: 2062 	Average Loss: -22.0754
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8236

Learning rate: 0.00017974154502814273
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2063 [0/90000 (0%)]	Loss: -16.1578	Cost: 24.88s
Train Epoch: 2063 [20480/90000 (23%)]	Loss: -22.7253	Cost: 9.37s
Train Epoch: 2063 [40960/90000 (45%)]	Loss: -22.6508	Cost: 9.23s
Train Epoch: 2063 [61440/90000 (68%)]	Loss: -22.6878	Cost: 9.15s
Train Epoch: 2063 [81920/90000 (91%)]	Loss: -22.4379	Cost: 9.03s
Train Epoch: 2063 	Average Loss: -22.1479
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0464

Learning rate: 0.000179722583759088
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2064 [0/90000 (0%)]	Loss: -16.2513	Cost: 26.11s
Train Epoch: 2064 [20480/90000 (23%)]	Loss: -22.9563	Cost: 9.33s
Train Epoch: 2064 [40960/90000 (45%)]	Loss: -22.8049	Cost: 9.24s
Train Epoch: 2064 [61440/90000 (68%)]	Loss: -22.4681	Cost: 9.23s
Train Epoch: 2064 [81920/90000 (91%)]	Loss: -22.0842	Cost: 9.05s
Train Epoch: 2064 	Average Loss: -22.2546
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8960

Learning rate: 0.00017970361462172967
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2065 [0/90000 (0%)]	Loss: -15.7580	Cost: 26.67s
Train Epoch: 2065 [20480/90000 (23%)]	Loss: -22.5664	Cost: 9.38s
Train Epoch: 2065 [40960/90000 (45%)]	Loss: -22.3480	Cost: 9.29s
Train Epoch: 2065 [61440/90000 (68%)]	Loss: -22.4331	Cost: 9.15s
Train Epoch: 2065 [81920/90000 (91%)]	Loss: -22.4834	Cost: 8.78s
Train Epoch: 2065 	Average Loss: -21.9941
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8029

Learning rate: 0.00017968463761793997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2066 [0/90000 (0%)]	Loss: -16.4688	Cost: 25.31s
Train Epoch: 2066 [20480/90000 (23%)]	Loss: -22.6314	Cost: 9.32s
Train Epoch: 2066 [40960/90000 (45%)]	Loss: -22.5734	Cost: 9.30s
Train Epoch: 2066 [61440/90000 (68%)]	Loss: -22.4671	Cost: 9.13s
Train Epoch: 2066 [81920/90000 (91%)]	Loss: -22.3866	Cost: 8.86s
Train Epoch: 2066 	Average Loss: -22.1513
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9839

Learning rate: 0.00017966565274959181
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2067 [0/90000 (0%)]	Loss: -16.2835	Cost: 25.72s
Train Epoch: 2067 [20480/90000 (23%)]	Loss: -22.6862	Cost: 9.38s
Train Epoch: 2067 [40960/90000 (45%)]	Loss: -22.5468	Cost: 9.40s
Train Epoch: 2067 [61440/90000 (68%)]	Loss: -22.6860	Cost: 9.17s
Train Epoch: 2067 [81920/90000 (91%)]	Loss: -22.4844	Cost: 9.11s
Train Epoch: 2067 	Average Loss: -22.2088
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0091

Learning rate: 0.00017964666001855898
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2068 [0/90000 (0%)]	Loss: -16.4981	Cost: 25.60s
Train Epoch: 2068 [20480/90000 (23%)]	Loss: -22.5454	Cost: 9.40s
Train Epoch: 2068 [40960/90000 (45%)]	Loss: -22.4568	Cost: 9.33s
Train Epoch: 2068 [61440/90000 (68%)]	Loss: -22.5076	Cost: 9.21s
Train Epoch: 2068 [81920/90000 (91%)]	Loss: -22.3843	Cost: 8.98s
Train Epoch: 2068 	Average Loss: -22.1429
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8748

Learning rate: 0.00017962765942671592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2069 [0/90000 (0%)]	Loss: -16.6981	Cost: 25.14s
Train Epoch: 2069 [20480/90000 (23%)]	Loss: -22.7079	Cost: 9.38s
Train Epoch: 2069 [40960/90000 (45%)]	Loss: -22.3980	Cost: 9.47s
Train Epoch: 2069 [61440/90000 (68%)]	Loss: -22.4529	Cost: 9.22s
Train Epoch: 2069 [81920/90000 (91%)]	Loss: -22.3035	Cost: 8.91s
Train Epoch: 2069 	Average Loss: -22.0566
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8633

Learning rate: 0.00017960865097593794
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2070 [0/90000 (0%)]	Loss: -14.4282	Cost: 25.53s
Train Epoch: 2070 [20480/90000 (23%)]	Loss: -22.2621	Cost: 9.52s
Train Epoch: 2070 [40960/90000 (45%)]	Loss: -22.3385	Cost: 9.47s
Train Epoch: 2070 [61440/90000 (68%)]	Loss: -22.4755	Cost: 9.12s
Train Epoch: 2070 [81920/90000 (91%)]	Loss: -22.1310	Cost: 8.83s
Train Epoch: 2070 	Average Loss: -21.8637
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6006

Learning rate: 0.00017958963466810113
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2071 [0/90000 (0%)]	Loss: -16.1191	Cost: 24.84s
Train Epoch: 2071 [20480/90000 (23%)]	Loss: -22.6281	Cost: 9.22s
Train Epoch: 2071 [40960/90000 (45%)]	Loss: -22.6163	Cost: 9.35s
Train Epoch: 2071 [61440/90000 (68%)]	Loss: -22.6728	Cost: 9.07s
Train Epoch: 2071 [81920/90000 (91%)]	Loss: -22.4231	Cost: 8.85s
Train Epoch: 2071 	Average Loss: -22.1446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9181

Learning rate: 0.0001795706105050823
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2072 [0/90000 (0%)]	Loss: -16.1582	Cost: 24.97s
Train Epoch: 2072 [20480/90000 (23%)]	Loss: -20.2555	Cost: 9.41s
Train Epoch: 2072 [40960/90000 (45%)]	Loss: -19.5828	Cost: 9.36s
Train Epoch: 2072 [61440/90000 (68%)]	Loss: -20.2415	Cost: 9.26s
Train Epoch: 2072 [81920/90000 (91%)]	Loss: -20.6376	Cost: 8.87s
Train Epoch: 2072 	Average Loss: -19.9309
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2172

Learning rate: 0.00017955157848875903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2073 [0/90000 (0%)]	Loss: -14.7258	Cost: 24.68s
Train Epoch: 2073 [20480/90000 (23%)]	Loss: -21.6409	Cost: 9.57s
Train Epoch: 2073 [40960/90000 (45%)]	Loss: -21.1746	Cost: 9.16s
Train Epoch: 2073 [61440/90000 (68%)]	Loss: -19.7932	Cost: 9.17s
Train Epoch: 2073 [81920/90000 (91%)]	Loss: -19.7265	Cost: 8.80s
Train Epoch: 2073 	Average Loss: -20.1696
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8063

Learning rate: 0.00017953253862100976
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2074 [0/90000 (0%)]	Loss: -14.4197	Cost: 25.42s
Train Epoch: 2074 [20480/90000 (23%)]	Loss: -20.7920	Cost: 9.58s
Train Epoch: 2074 [40960/90000 (45%)]	Loss: -21.1221	Cost: 9.75s
Train Epoch: 2074 [61440/90000 (68%)]	Loss: -21.3217	Cost: 9.04s
Train Epoch: 2074 [81920/90000 (91%)]	Loss: -21.4730	Cost: 9.08s
Train Epoch: 2074 	Average Loss: -20.7001
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.1338

Learning rate: 0.0001795134909037136
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2075 [0/90000 (0%)]	Loss: -15.5879	Cost: 24.82s
Train Epoch: 2075 [20480/90000 (23%)]	Loss: -22.1059	Cost: 9.56s
Train Epoch: 2075 [40960/90000 (45%)]	Loss: -22.2263	Cost: 9.33s
Train Epoch: 2075 [61440/90000 (68%)]	Loss: -22.1927	Cost: 9.07s
Train Epoch: 2075 [81920/90000 (91%)]	Loss: -22.3791	Cost: 9.72s
Train Epoch: 2075 	Average Loss: -21.8410
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8261

Learning rate: 0.00017949443533875055
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2076 [0/90000 (0%)]	Loss: -15.6532	Cost: 24.03s
Train Epoch: 2076 [20480/90000 (23%)]	Loss: -22.6833	Cost: 9.59s
Train Epoch: 2076 [40960/90000 (45%)]	Loss: -22.6104	Cost: 9.25s
Train Epoch: 2076 [61440/90000 (68%)]	Loss: -22.6257	Cost: 9.06s
Train Epoch: 2076 [81920/90000 (91%)]	Loss: -22.3940	Cost: 10.28s
Train Epoch: 2076 	Average Loss: -22.2635
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0970

Learning rate: 0.00017947537192800124
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2077 [0/90000 (0%)]	Loss: -16.3609	Cost: 23.84s
Train Epoch: 2077 [20480/90000 (23%)]	Loss: -22.8329	Cost: 9.05s
Train Epoch: 2077 [40960/90000 (45%)]	Loss: -22.6512	Cost: 9.85s
Train Epoch: 2077 [61440/90000 (68%)]	Loss: -22.7092	Cost: 9.11s
Train Epoch: 2077 [81920/90000 (91%)]	Loss: -22.6095	Cost: 10.09s
Train Epoch: 2077 	Average Loss: -22.3172
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0097

Learning rate: 0.0001794563006733472
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2078 [0/90000 (0%)]	Loss: -15.9503	Cost: 25.10s
Train Epoch: 2078 [20480/90000 (23%)]	Loss: -23.0929	Cost: 9.03s
Train Epoch: 2078 [40960/90000 (45%)]	Loss: -22.7323	Cost: 9.77s
Train Epoch: 2078 [61440/90000 (68%)]	Loss: -22.7473	Cost: 9.07s
Train Epoch: 2078 [81920/90000 (91%)]	Loss: -22.4625	Cost: 10.33s
Train Epoch: 2078 	Average Loss: -22.4051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1522

Learning rate: 0.00017943722157667068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2079 [0/90000 (0%)]	Loss: -17.3016	Cost: 24.55s
Train Epoch: 2079 [20480/90000 (23%)]	Loss: -23.1457	Cost: 9.14s
Train Epoch: 2079 [40960/90000 (45%)]	Loss: -23.0592	Cost: 9.63s
Train Epoch: 2079 [61440/90000 (68%)]	Loss: -23.0052	Cost: 9.15s
Train Epoch: 2079 [81920/90000 (91%)]	Loss: -22.5377	Cost: 10.01s
Train Epoch: 2079 	Average Loss: -22.4911
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8455

Learning rate: 0.00017941813463985472
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2080 [0/90000 (0%)]	Loss: -15.0459	Cost: 23.89s
Train Epoch: 2080 [20480/90000 (23%)]	Loss: -23.0933	Cost: 9.09s
Train Epoch: 2080 [40960/90000 (45%)]	Loss: -22.8768	Cost: 9.23s
Train Epoch: 2080 [61440/90000 (68%)]	Loss: -22.9168	Cost: 9.09s
Train Epoch: 2080 [81920/90000 (91%)]	Loss: -22.4457	Cost: 10.38s
Train Epoch: 2080 	Average Loss: -22.3551
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9007

Learning rate: 0.0001793990398647831
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2081 [0/90000 (0%)]	Loss: -15.8089	Cost: 23.99s
Train Epoch: 2081 [20480/90000 (23%)]	Loss: -23.0006	Cost: 9.09s
Train Epoch: 2081 [40960/90000 (45%)]	Loss: -22.7549	Cost: 9.18s
Train Epoch: 2081 [61440/90000 (68%)]	Loss: -22.7444	Cost: 9.03s
Train Epoch: 2081 [81920/90000 (91%)]	Loss: -22.5687	Cost: 9.08s
Train Epoch: 2081 	Average Loss: -22.3644
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0879

Learning rate: 0.00017937993725334041
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2082 [0/90000 (0%)]	Loss: -16.3920	Cost: 23.91s
Train Epoch: 2082 [20480/90000 (23%)]	Loss: -22.9010	Cost: 9.10s
Train Epoch: 2082 [40960/90000 (45%)]	Loss: -22.8355	Cost: 9.15s
Train Epoch: 2082 [61440/90000 (68%)]	Loss: -22.6448	Cost: 9.03s
Train Epoch: 2082 [81920/90000 (91%)]	Loss: -22.5397	Cost: 8.90s
Train Epoch: 2082 	Average Loss: -22.3504
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8184

Learning rate: 0.000179360826807412
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2083 [0/90000 (0%)]	Loss: -14.7221	Cost: 26.67s
Train Epoch: 2083 [20480/90000 (23%)]	Loss: -22.2092	Cost: 9.01s
Train Epoch: 2083 [40960/90000 (45%)]	Loss: -21.7763	Cost: 9.23s
Train Epoch: 2083 [61440/90000 (68%)]	Loss: -22.0458	Cost: 8.93s
Train Epoch: 2083 [81920/90000 (91%)]	Loss: -21.9521	Cost: 8.74s
Train Epoch: 2083 	Average Loss: -21.6095
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.4744

Learning rate: 0.000179341708528884
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2084 [0/90000 (0%)]	Loss: -15.5817	Cost: 24.58s
Train Epoch: 2084 [20480/90000 (23%)]	Loss: -22.4039	Cost: 9.05s
Train Epoch: 2084 [40960/90000 (45%)]	Loss: -21.9663	Cost: 8.98s
Train Epoch: 2084 [61440/90000 (68%)]	Loss: -22.1311	Cost: 8.95s
Train Epoch: 2084 [81920/90000 (91%)]	Loss: -22.2216	Cost: 8.71s
Train Epoch: 2084 	Average Loss: -21.7729
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7339

Learning rate: 0.0001793225824196433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2085 [0/90000 (0%)]	Loss: -14.9702	Cost: 26.07s
Train Epoch: 2085 [20480/90000 (23%)]	Loss: -22.3385	Cost: 9.34s
Train Epoch: 2085 [40960/90000 (45%)]	Loss: -22.0826	Cost: 9.24s
Train Epoch: 2085 [61440/90000 (68%)]	Loss: -22.3809	Cost: 9.44s
Train Epoch: 2085 [81920/90000 (91%)]	Loss: -22.3155	Cost: 9.03s
Train Epoch: 2085 	Average Loss: -21.8678
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9343

Learning rate: 0.00017930344848157757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2086 [0/90000 (0%)]	Loss: -15.3557	Cost: 25.85s
Train Epoch: 2086 [20480/90000 (23%)]	Loss: -22.8055	Cost: 9.45s
Train Epoch: 2086 [40960/90000 (45%)]	Loss: -22.5838	Cost: 9.24s
Train Epoch: 2086 [61440/90000 (68%)]	Loss: -22.6957	Cost: 9.15s
Train Epoch: 2086 [81920/90000 (91%)]	Loss: -22.7459	Cost: 8.80s
Train Epoch: 2086 	Average Loss: -22.2538
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0626

Learning rate: 0.0001792843067165753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2087 [0/90000 (0%)]	Loss: -16.6740	Cost: 27.94s
Train Epoch: 2087 [20480/90000 (23%)]	Loss: -22.8223	Cost: 9.38s
Train Epoch: 2087 [40960/90000 (45%)]	Loss: -22.7393	Cost: 9.26s
Train Epoch: 2087 [61440/90000 (68%)]	Loss: -22.3244	Cost: 9.17s
Train Epoch: 2087 [81920/90000 (91%)]	Loss: -22.1916	Cost: 9.20s
Train Epoch: 2087 	Average Loss: -22.1574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6355

Learning rate: 0.00017926515712652562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2088 [0/90000 (0%)]	Loss: -16.7290	Cost: 26.71s
Train Epoch: 2088 [20480/90000 (23%)]	Loss: -22.6720	Cost: 9.39s
Train Epoch: 2088 [40960/90000 (45%)]	Loss: -22.2132	Cost: 9.32s
Train Epoch: 2088 [61440/90000 (68%)]	Loss: -22.2354	Cost: 9.27s
Train Epoch: 2088 [81920/90000 (91%)]	Loss: -22.5532	Cost: 8.99s
Train Epoch: 2088 	Average Loss: -21.9890
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8641

Learning rate: 0.00017924599971331863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2089 [0/90000 (0%)]	Loss: -16.3031	Cost: 25.31s
Train Epoch: 2089 [20480/90000 (23%)]	Loss: -22.9280	Cost: 9.36s
Train Epoch: 2089 [40960/90000 (45%)]	Loss: -22.2361	Cost: 9.36s
Train Epoch: 2089 [61440/90000 (68%)]	Loss: -22.3889	Cost: 9.26s
Train Epoch: 2089 [81920/90000 (91%)]	Loss: -22.0357	Cost: 8.88s
Train Epoch: 2089 	Average Loss: -21.8897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6980

Learning rate: 0.000179226834478845
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2090 [0/90000 (0%)]	Loss: -16.5399	Cost: 25.64s
Train Epoch: 2090 [20480/90000 (23%)]	Loss: -22.4561	Cost: 9.32s
Train Epoch: 2090 [40960/90000 (45%)]	Loss: -22.3504	Cost: 9.37s
Train Epoch: 2090 [61440/90000 (68%)]	Loss: -22.2742	Cost: 9.13s
Train Epoch: 2090 [81920/90000 (91%)]	Loss: -22.0547	Cost: 8.91s
Train Epoch: 2090 	Average Loss: -21.9635
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9570

Learning rate: 0.00017920766142499628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2091 [0/90000 (0%)]	Loss: -15.4259	Cost: 25.50s
Train Epoch: 2091 [20480/90000 (23%)]	Loss: -22.4715	Cost: 9.32s
Train Epoch: 2091 [40960/90000 (45%)]	Loss: -22.3292	Cost: 9.32s
Train Epoch: 2091 [61440/90000 (68%)]	Loss: -22.3714	Cost: 9.12s
Train Epoch: 2091 [81920/90000 (91%)]	Loss: -22.3324	Cost: 9.23s
Train Epoch: 2091 	Average Loss: -21.9387
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8969

Learning rate: 0.00017918848055366478
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2092 [0/90000 (0%)]	Loss: -16.4217	Cost: 25.65s
Train Epoch: 2092 [20480/90000 (23%)]	Loss: -22.7921	Cost: 9.64s
Train Epoch: 2092 [40960/90000 (45%)]	Loss: -22.7475	Cost: 9.47s
Train Epoch: 2092 [61440/90000 (68%)]	Loss: -22.4737	Cost: 9.01s
Train Epoch: 2092 [81920/90000 (91%)]	Loss: -22.3387	Cost: 9.18s
Train Epoch: 2092 	Average Loss: -22.2329
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0211

Learning rate: 0.00017916929186674357
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2093 [0/90000 (0%)]	Loss: -16.5141	Cost: 25.18s
Train Epoch: 2093 [20480/90000 (23%)]	Loss: -22.3557	Cost: 10.05s
Train Epoch: 2093 [40960/90000 (45%)]	Loss: -21.9646	Cost: 9.14s
Train Epoch: 2093 [61440/90000 (68%)]	Loss: -21.9271	Cost: 9.15s
Train Epoch: 2093 [81920/90000 (91%)]	Loss: -21.9437	Cost: 8.90s
Train Epoch: 2093 	Average Loss: -21.7152
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7007

Learning rate: 0.00017915009536612655
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2094 [0/90000 (0%)]	Loss: -15.2966	Cost: 25.21s
Train Epoch: 2094 [20480/90000 (23%)]	Loss: -22.6521	Cost: 9.00s
Train Epoch: 2094 [40960/90000 (45%)]	Loss: -22.3780	Cost: 10.00s
Train Epoch: 2094 [61440/90000 (68%)]	Loss: -22.3018	Cost: 9.01s
Train Epoch: 2094 [81920/90000 (91%)]	Loss: -22.2450	Cost: 9.50s
Train Epoch: 2094 	Average Loss: -21.9337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8556

Learning rate: 0.00017913089105370828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2095 [0/90000 (0%)]	Loss: -14.9554	Cost: 24.51s
Train Epoch: 2095 [20480/90000 (23%)]	Loss: -22.5938	Cost: 9.57s
Train Epoch: 2095 [40960/90000 (45%)]	Loss: -22.4938	Cost: 9.34s
Train Epoch: 2095 [61440/90000 (68%)]	Loss: -22.3373	Cost: 9.05s
Train Epoch: 2095 [81920/90000 (91%)]	Loss: -22.5070	Cost: 10.07s
Train Epoch: 2095 	Average Loss: -22.0825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7875

Learning rate: 0.00017911167893138415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2096 [0/90000 (0%)]	Loss: -15.2875	Cost: 24.26s
Train Epoch: 2096 [20480/90000 (23%)]	Loss: -22.7847	Cost: 9.62s
Train Epoch: 2096 [40960/90000 (45%)]	Loss: -22.4283	Cost: 9.21s
Train Epoch: 2096 [61440/90000 (68%)]	Loss: -22.3471	Cost: 9.27s
Train Epoch: 2096 [81920/90000 (91%)]	Loss: -22.3387	Cost: 9.89s
Train Epoch: 2096 	Average Loss: -22.0609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8036

Learning rate: 0.00017909245900105036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2097 [0/90000 (0%)]	Loss: -15.9170	Cost: 25.67s
Train Epoch: 2097 [20480/90000 (23%)]	Loss: -22.1866	Cost: 9.14s
Train Epoch: 2097 [40960/90000 (45%)]	Loss: -22.2067	Cost: 9.83s
Train Epoch: 2097 [61440/90000 (68%)]	Loss: -22.0683	Cost: 9.03s
Train Epoch: 2097 [81920/90000 (91%)]	Loss: -21.3470	Cost: 10.67s
Train Epoch: 2097 	Average Loss: -21.6074
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.9981

Learning rate: 0.00017907323126460382
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2098 [0/90000 (0%)]	Loss: -15.5313	Cost: 52.25s
Train Epoch: 2098 [20480/90000 (23%)]	Loss: -21.8601	Cost: 13.76s
Train Epoch: 2098 [40960/90000 (45%)]	Loss: -22.0377	Cost: 22.01s
Train Epoch: 2098 [61440/90000 (68%)]	Loss: -22.1128	Cost: 13.21s
Train Epoch: 2098 [81920/90000 (91%)]	Loss: -22.2000	Cost: 24.95s
Train Epoch: 2098 	Average Loss: -21.6192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6804

Learning rate: 0.00017905399572394222
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2099 [0/90000 (0%)]	Loss: -15.3205	Cost: 23.37s
Train Epoch: 2099 [20480/90000 (23%)]	Loss: -22.5255	Cost: 9.13s
Train Epoch: 2099 [40960/90000 (45%)]	Loss: -22.4137	Cost: 9.18s
Train Epoch: 2099 [61440/90000 (68%)]	Loss: -22.3870	Cost: 9.03s
Train Epoch: 2099 [81920/90000 (91%)]	Loss: -22.5231	Cost: 10.09s
Train Epoch: 2099 	Average Loss: -22.0636
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9837

Learning rate: 0.00017903475238096407
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2100 [0/90000 (0%)]	Loss: -15.7924	Cost: 23.02s
Train Epoch: 2100 [20480/90000 (23%)]	Loss: -22.9270	Cost: 9.03s
Train Epoch: 2100 [40960/90000 (45%)]	Loss: -22.6618	Cost: 9.64s
Train Epoch: 2100 [61440/90000 (68%)]	Loss: -22.5824	Cost: 9.13s
Train Epoch: 2100 [81920/90000 (91%)]	Loss: -22.6258	Cost: 9.80s
Train Epoch: 2100 	Average Loss: -22.3005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1353

Saving model as model.pt_e2100 & waveforms_supplementary.hdf5_e2100
Learning rate: 0.00017901550123756852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2101 [0/90000 (0%)]	Loss: -16.2255	Cost: 23.67s
Train Epoch: 2101 [20480/90000 (23%)]	Loss: -22.8589	Cost: 9.07s
Train Epoch: 2101 [40960/90000 (45%)]	Loss: -22.5356	Cost: 9.62s
Train Epoch: 2101 [61440/90000 (68%)]	Loss: -22.6760	Cost: 8.99s
Train Epoch: 2101 [81920/90000 (91%)]	Loss: -22.5240	Cost: 10.35s
Train Epoch: 2101 	Average Loss: -22.2652
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9962

Learning rate: 0.00017899624229565574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2102 [0/90000 (0%)]	Loss: -16.2170	Cost: 22.86s
Train Epoch: 2102 [20480/90000 (23%)]	Loss: -22.7134	Cost: 9.02s
Train Epoch: 2102 [40960/90000 (45%)]	Loss: -22.6769	Cost: 9.23s
Train Epoch: 2102 [61440/90000 (68%)]	Loss: -22.6279	Cost: 9.20s
Train Epoch: 2102 [81920/90000 (91%)]	Loss: -22.5339	Cost: 9.07s
Train Epoch: 2102 	Average Loss: -22.2519
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8707

Learning rate: 0.00017897697555712636
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2103 [0/90000 (0%)]	Loss: -16.4278	Cost: 24.96s
Train Epoch: 2103 [20480/90000 (23%)]	Loss: -22.6447	Cost: 9.38s
Train Epoch: 2103 [40960/90000 (45%)]	Loss: -22.5702	Cost: 9.44s
Train Epoch: 2103 [61440/90000 (68%)]	Loss: -22.5977	Cost: 9.10s
Train Epoch: 2103 [81920/90000 (91%)]	Loss: -22.5935	Cost: 9.25s
Train Epoch: 2103 	Average Loss: -22.3069
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1096

Learning rate: 0.000178957701023882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2104 [0/90000 (0%)]	Loss: -15.6828	Cost: 24.26s
Train Epoch: 2104 [20480/90000 (23%)]	Loss: -22.9489	Cost: 9.34s
Train Epoch: 2104 [40960/90000 (45%)]	Loss: -22.3997	Cost: 9.52s
Train Epoch: 2104 [61440/90000 (68%)]	Loss: -22.5368	Cost: 9.15s
Train Epoch: 2104 [81920/90000 (91%)]	Loss: -22.4500	Cost: 9.27s
Train Epoch: 2104 	Average Loss: -22.1475
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9159

Learning rate: 0.000178938418697825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2105 [0/90000 (0%)]	Loss: -15.6287	Cost: 24.02s
Train Epoch: 2105 [20480/90000 (23%)]	Loss: -22.5462	Cost: 9.31s
Train Epoch: 2105 [40960/90000 (45%)]	Loss: -22.5689	Cost: 9.78s
Train Epoch: 2105 [61440/90000 (68%)]	Loss: -22.4666	Cost: 9.07s
Train Epoch: 2105 [81920/90000 (91%)]	Loss: -22.4467	Cost: 8.77s
Train Epoch: 2105 	Average Loss: -22.1185
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9365

Learning rate: 0.00017891912858085838
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2106 [0/90000 (0%)]	Loss: -16.3606	Cost: 27.06s
Train Epoch: 2106 [20480/90000 (23%)]	Loss: -22.2463	Cost: 9.29s
Train Epoch: 2106 [40960/90000 (45%)]	Loss: -20.5785	Cost: 9.29s
Train Epoch: 2106 [61440/90000 (68%)]	Loss: -20.3490	Cost: 9.32s
Train Epoch: 2106 [81920/90000 (91%)]	Loss: -20.7991	Cost: 9.36s
Train Epoch: 2106 	Average Loss: -20.8675
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5117

Learning rate: 0.00017889983067488605
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2107 [0/90000 (0%)]	Loss: -14.2054	Cost: 23.97s
Train Epoch: 2107 [20480/90000 (23%)]	Loss: -21.4147	Cost: 9.35s
Train Epoch: 2107 [40960/90000 (45%)]	Loss: -21.2863	Cost: 9.30s
Train Epoch: 2107 [61440/90000 (68%)]	Loss: -21.4528	Cost: 9.50s
Train Epoch: 2107 [81920/90000 (91%)]	Loss: -21.4989	Cost: 9.44s
Train Epoch: 2107 	Average Loss: -20.9862
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0947

Learning rate: 0.00017888052498181257
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2108 [0/90000 (0%)]	Loss: -14.1183	Cost: 27.11s
Train Epoch: 2108 [20480/90000 (23%)]	Loss: -21.7949	Cost: 9.25s
Train Epoch: 2108 [40960/90000 (45%)]	Loss: -21.6942	Cost: 9.31s
Train Epoch: 2108 [61440/90000 (68%)]	Loss: -21.7034	Cost: 9.17s
Train Epoch: 2108 [81920/90000 (91%)]	Loss: -21.6100	Cost: 9.49s
Train Epoch: 2108 	Average Loss: -21.2851
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2394

Learning rate: 0.00017886121150354346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2109 [0/90000 (0%)]	Loss: -14.4406	Cost: 24.03s
Train Epoch: 2109 [20480/90000 (23%)]	Loss: -21.9138	Cost: 9.40s
Train Epoch: 2109 [40960/90000 (45%)]	Loss: -22.0770	Cost: 9.24s
Train Epoch: 2109 [61440/90000 (68%)]	Loss: -21.7267	Cost: 9.45s
Train Epoch: 2109 [81920/90000 (91%)]	Loss: -21.8520	Cost: 8.94s
Train Epoch: 2109 	Average Loss: -21.4421
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2782

Learning rate: 0.0001788418902419848
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2110 [0/90000 (0%)]	Loss: -15.9917	Cost: 25.45s
Train Epoch: 2110 [20480/90000 (23%)]	Loss: -22.1039	Cost: 9.38s
Train Epoch: 2110 [40960/90000 (45%)]	Loss: -20.1708	Cost: 9.20s
Train Epoch: 2110 [61440/90000 (68%)]	Loss: -20.1687	Cost: 9.19s
Train Epoch: 2110 [81920/90000 (91%)]	Loss: -20.4882	Cost: 8.95s
Train Epoch: 2110 	Average Loss: -20.5713
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.5234

Learning rate: 0.0001788225611990435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2111 [0/90000 (0%)]	Loss: -15.0553	Cost: 24.79s
Train Epoch: 2111 [20480/90000 (23%)]	Loss: -20.9564	Cost: 9.40s
Train Epoch: 2111 [40960/90000 (45%)]	Loss: -21.3569	Cost: 9.36s
Train Epoch: 2111 [61440/90000 (68%)]	Loss: -21.4083	Cost: 9.17s
Train Epoch: 2111 [81920/90000 (91%)]	Loss: -21.4213	Cost: 9.02s
Train Epoch: 2111 	Average Loss: -20.8785
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.3668

Learning rate: 0.0001788032243766273
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2112 [0/90000 (0%)]	Loss: -14.6048	Cost: 24.63s
Train Epoch: 2112 [20480/90000 (23%)]	Loss: -22.0728	Cost: 9.54s
Train Epoch: 2112 [40960/90000 (45%)]	Loss: -21.7040	Cost: 9.33s
Train Epoch: 2112 [61440/90000 (68%)]	Loss: -21.9901	Cost: 9.16s
Train Epoch: 2112 [81920/90000 (91%)]	Loss: -21.7480	Cost: 9.00s
Train Epoch: 2112 	Average Loss: -21.4668
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6123

Learning rate: 0.0001787838797766447
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2113 [0/90000 (0%)]	Loss: -15.1458	Cost: 24.76s
Train Epoch: 2113 [20480/90000 (23%)]	Loss: -22.1574	Cost: 9.42s
Train Epoch: 2113 [40960/90000 (45%)]	Loss: -22.1922	Cost: 9.24s
Train Epoch: 2113 [61440/90000 (68%)]	Loss: -22.4981	Cost: 9.08s
Train Epoch: 2113 [81920/90000 (91%)]	Loss: -22.4748	Cost: 9.03s
Train Epoch: 2113 	Average Loss: -21.9563
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9412

Learning rate: 0.00017876452740100488
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2114 [0/90000 (0%)]	Loss: -15.6653	Cost: 24.52s
Train Epoch: 2114 [20480/90000 (23%)]	Loss: -22.8687	Cost: 9.44s
Train Epoch: 2114 [40960/90000 (45%)]	Loss: -23.1268	Cost: 9.36s
Train Epoch: 2114 [61440/90000 (68%)]	Loss: -22.8732	Cost: 9.08s
Train Epoch: 2114 [81920/90000 (91%)]	Loss: -22.4608	Cost: 8.95s
Train Epoch: 2114 	Average Loss: -22.4278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9682

Learning rate: 0.00017874516725161784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2115 [0/90000 (0%)]	Loss: -15.3779	Cost: 25.81s
Train Epoch: 2115 [20480/90000 (23%)]	Loss: -22.9086	Cost: 9.70s
Train Epoch: 2115 [40960/90000 (45%)]	Loss: -22.9510	Cost: 9.11s
Train Epoch: 2115 [61440/90000 (68%)]	Loss: -22.8900	Cost: 9.07s
Train Epoch: 2115 [81920/90000 (91%)]	Loss: -22.8129	Cost: 8.83s
Train Epoch: 2115 	Average Loss: -22.4272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2406

Learning rate: 0.0001787257993303944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2116 [0/90000 (0%)]	Loss: -16.1719	Cost: 25.52s
Train Epoch: 2116 [20480/90000 (23%)]	Loss: -23.0696	Cost: 9.51s
Train Epoch: 2116 [40960/90000 (45%)]	Loss: -23.1507	Cost: 9.16s
Train Epoch: 2116 [61440/90000 (68%)]	Loss: -22.6903	Cost: 8.96s
Train Epoch: 2116 [81920/90000 (91%)]	Loss: -22.4387	Cost: 8.71s
Train Epoch: 2116 	Average Loss: -22.4676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8201

Learning rate: 0.0001787064236392461
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2117 [0/90000 (0%)]	Loss: -16.1215	Cost: 24.50s
Train Epoch: 2117 [20480/90000 (23%)]	Loss: -23.0550	Cost: 9.66s
Train Epoch: 2117 [40960/90000 (45%)]	Loss: -23.0775	Cost: 9.50s
Train Epoch: 2117 [61440/90000 (68%)]	Loss: -22.8155	Cost: 9.10s
Train Epoch: 2117 [81920/90000 (91%)]	Loss: -22.4685	Cost: 9.36s
Train Epoch: 2117 	Average Loss: -22.4285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9806

Learning rate: 0.00017868704018008514
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2118 [0/90000 (0%)]	Loss: -16.2192	Cost: 23.57s
Train Epoch: 2118 [20480/90000 (23%)]	Loss: -22.6700	Cost: 9.50s
Train Epoch: 2118 [40960/90000 (45%)]	Loss: -22.7061	Cost: 9.28s
Train Epoch: 2118 [61440/90000 (68%)]	Loss: -22.3943	Cost: 9.10s
Train Epoch: 2118 [81920/90000 (91%)]	Loss: -21.8883	Cost: 11.29s
Train Epoch: 2118 	Average Loss: -21.9911
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5018

Learning rate: 0.0001786676489548247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2119 [0/90000 (0%)]	Loss: -15.4120	Cost: 50.56s
Train Epoch: 2119 [20480/90000 (23%)]	Loss: -22.4883	Cost: 13.26s
Train Epoch: 2119 [40960/90000 (45%)]	Loss: -22.4139	Cost: 19.19s
Train Epoch: 2119 [61440/90000 (68%)]	Loss: -22.2969	Cost: 12.82s
Train Epoch: 2119 [81920/90000 (91%)]	Loss: -21.7065	Cost: 20.09s
Train Epoch: 2119 	Average Loss: -21.8415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.2950

Learning rate: 0.00017864824996537858
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2120 [0/90000 (0%)]	Loss: -15.0184	Cost: 22.20s
Train Epoch: 2120 [20480/90000 (23%)]	Loss: -22.2752	Cost: 9.27s
Train Epoch: 2120 [40960/90000 (45%)]	Loss: -22.5215	Cost: 9.11s
Train Epoch: 2120 [61440/90000 (68%)]	Loss: -22.5395	Cost: 9.11s
Train Epoch: 2120 [81920/90000 (91%)]	Loss: -22.4243	Cost: 9.76s
Train Epoch: 2120 	Average Loss: -21.9949
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9259

Learning rate: 0.00017862884321366137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2121 [0/90000 (0%)]	Loss: -16.2225	Cost: 23.60s
Train Epoch: 2121 [20480/90000 (23%)]	Loss: -22.6674	Cost: 9.10s
Train Epoch: 2121 [40960/90000 (45%)]	Loss: -22.7586	Cost: 9.16s
Train Epoch: 2121 [61440/90000 (68%)]	Loss: -22.3579	Cost: 9.07s
Train Epoch: 2121 [81920/90000 (91%)]	Loss: -22.2831	Cost: 9.02s
Train Epoch: 2121 	Average Loss: -22.1990
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9167

Learning rate: 0.0001786094287015885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2122 [0/90000 (0%)]	Loss: -16.2233	Cost: 24.06s
Train Epoch: 2122 [20480/90000 (23%)]	Loss: -23.0550	Cost: 9.03s
Train Epoch: 2122 [40960/90000 (45%)]	Loss: -22.9859	Cost: 9.45s
Train Epoch: 2122 [61440/90000 (68%)]	Loss: -22.7106	Cost: 9.03s
Train Epoch: 2122 [81920/90000 (91%)]	Loss: -22.4433	Cost: 10.12s
Train Epoch: 2122 	Average Loss: -22.3308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8912

Learning rate: 0.000178590006431076
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2123 [0/90000 (0%)]	Loss: -16.0159	Cost: 22.64s
Train Epoch: 2123 [20480/90000 (23%)]	Loss: -23.1852	Cost: 9.06s
Train Epoch: 2123 [40960/90000 (45%)]	Loss: -22.9477	Cost: 9.23s
Train Epoch: 2123 [61440/90000 (68%)]	Loss: -22.9299	Cost: 9.03s
Train Epoch: 2123 [81920/90000 (91%)]	Loss: -22.7459	Cost: 8.97s
Train Epoch: 2123 	Average Loss: -22.5233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1730

Learning rate: 0.0001785705764040409
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2124 [0/90000 (0%)]	Loss: -16.0046	Cost: 23.20s
Train Epoch: 2124 [20480/90000 (23%)]	Loss: -23.1950	Cost: 9.07s
Train Epoch: 2124 [40960/90000 (45%)]	Loss: -23.1382	Cost: 9.09s
Train Epoch: 2124 [61440/90000 (68%)]	Loss: -22.9993	Cost: 8.90s
Train Epoch: 2124 [81920/90000 (91%)]	Loss: -22.8688	Cost: 8.91s
Train Epoch: 2124 	Average Loss: -22.5884
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1009

Learning rate: 0.00017855113862240074
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2125 [0/90000 (0%)]	Loss: -16.6530	Cost: 22.99s
Train Epoch: 2125 [20480/90000 (23%)]	Loss: -23.1716	Cost: 8.99s
Train Epoch: 2125 [40960/90000 (45%)]	Loss: -22.9801	Cost: 9.02s
Train Epoch: 2125 [61440/90000 (68%)]	Loss: -22.8287	Cost: 8.90s
Train Epoch: 2125 [81920/90000 (91%)]	Loss: -22.3191	Cost: 8.79s
Train Epoch: 2125 	Average Loss: -22.4250
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.7261

Learning rate: 0.00017853169308807402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2126 [0/90000 (0%)]	Loss: -15.7629	Cost: 24.29s
Train Epoch: 2126 [20480/90000 (23%)]	Loss: -23.0546	Cost: 9.03s
Train Epoch: 2126 [40960/90000 (45%)]	Loss: -22.8131	Cost: 9.20s
Train Epoch: 2126 [61440/90000 (68%)]	Loss: -22.7192	Cost: 9.03s
Train Epoch: 2126 [81920/90000 (91%)]	Loss: -22.3871	Cost: 8.73s
Train Epoch: 2126 	Average Loss: -22.3208
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0470

Learning rate: 0.00017851223980297994
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2127 [0/90000 (0%)]	Loss: -15.4976	Cost: 23.90s
Train Epoch: 2127 [20480/90000 (23%)]	Loss: -22.6394	Cost: 9.35s
Train Epoch: 2127 [40960/90000 (45%)]	Loss: -22.7489	Cost: 9.25s
Train Epoch: 2127 [61440/90000 (68%)]	Loss: -22.7662	Cost: 9.22s
Train Epoch: 2127 [81920/90000 (91%)]	Loss: -22.9423	Cost: 8.75s
Train Epoch: 2127 	Average Loss: -22.3666
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0933

Learning rate: 0.00017849277876903844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2128 [0/90000 (0%)]	Loss: -16.6045	Cost: 24.67s
Train Epoch: 2128 [20480/90000 (23%)]	Loss: -23.1182	Cost: 9.30s
Train Epoch: 2128 [40960/90000 (45%)]	Loss: -22.8739	Cost: 9.29s
Train Epoch: 2128 [61440/90000 (68%)]	Loss: -22.8433	Cost: 9.26s
Train Epoch: 2128 [81920/90000 (91%)]	Loss: -22.6133	Cost: 8.79s
Train Epoch: 2128 	Average Loss: -22.4759
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0344

Learning rate: 0.00017847330998817023
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2129 [0/90000 (0%)]	Loss: -16.1779	Cost: 24.51s
Train Epoch: 2129 [20480/90000 (23%)]	Loss: -23.0896	Cost: 9.43s
Train Epoch: 2129 [40960/90000 (45%)]	Loss: -23.0266	Cost: 9.23s
Train Epoch: 2129 [61440/90000 (68%)]	Loss: -23.0921	Cost: 9.09s
Train Epoch: 2129 [81920/90000 (91%)]	Loss: -22.6026	Cost: 8.88s
Train Epoch: 2129 	Average Loss: -22.5874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1629

Learning rate: 0.00017845383346229687
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2130 [0/90000 (0%)]	Loss: -15.8765	Cost: 24.67s
Train Epoch: 2130 [20480/90000 (23%)]	Loss: -22.8093	Cost: 9.43s
Train Epoch: 2130 [40960/90000 (45%)]	Loss: -22.5056	Cost: 9.61s
Train Epoch: 2130 [61440/90000 (68%)]	Loss: -22.8806	Cost: 9.05s
Train Epoch: 2130 [81920/90000 (91%)]	Loss: -22.3799	Cost: 8.95s
Train Epoch: 2130 	Average Loss: -22.2605
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8880

Learning rate: 0.00017843434919334055
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2131 [0/90000 (0%)]	Loss: -14.8017	Cost: 24.30s
Train Epoch: 2131 [20480/90000 (23%)]	Loss: -22.5805	Cost: 9.21s
Train Epoch: 2131 [40960/90000 (45%)]	Loss: -22.6282	Cost: 9.34s
Train Epoch: 2131 [61440/90000 (68%)]	Loss: -22.6156	Cost: 9.18s
Train Epoch: 2131 [81920/90000 (91%)]	Loss: -22.3425	Cost: 8.96s
Train Epoch: 2131 	Average Loss: -22.0222
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9679

Learning rate: 0.00017841485718322433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2132 [0/90000 (0%)]	Loss: -16.0836	Cost: 24.76s
Train Epoch: 2132 [20480/90000 (23%)]	Loss: -23.0854	Cost: 9.41s
Train Epoch: 2132 [40960/90000 (45%)]	Loss: -23.0327	Cost: 9.32s
Train Epoch: 2132 [61440/90000 (68%)]	Loss: -22.6501	Cost: 9.05s
Train Epoch: 2132 [81920/90000 (91%)]	Loss: -22.9390	Cost: 8.80s
Train Epoch: 2132 	Average Loss: -22.4517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.4320

Learning rate: 0.00017839535743387194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2133 [0/90000 (0%)]	Loss: -17.0536	Cost: 24.22s
Train Epoch: 2133 [20480/90000 (23%)]	Loss: -23.2693	Cost: 9.25s
Train Epoch: 2133 [40960/90000 (45%)]	Loss: -23.3594	Cost: 9.08s
Train Epoch: 2133 [61440/90000 (68%)]	Loss: -23.1150	Cost: 9.05s
Train Epoch: 2133 [81920/90000 (91%)]	Loss: -23.0056	Cost: 8.72s
Train Epoch: 2133 	Average Loss: -22.6815
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2283

Learning rate: 0.000178375849947208
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2134 [0/90000 (0%)]	Loss: -15.9559	Cost: 24.10s
Train Epoch: 2134 [20480/90000 (23%)]	Loss: -22.9703	Cost: 9.02s
Train Epoch: 2134 [40960/90000 (45%)]	Loss: -22.9793	Cost: 9.32s
Train Epoch: 2134 [61440/90000 (68%)]	Loss: -23.0101	Cost: 8.98s
Train Epoch: 2134 [81920/90000 (91%)]	Loss: -22.6571	Cost: 8.80s
Train Epoch: 2134 	Average Loss: -22.4212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9443

Learning rate: 0.00017835633472515776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2135 [0/90000 (0%)]	Loss: -15.8852	Cost: 24.01s
Train Epoch: 2135 [20480/90000 (23%)]	Loss: -22.6302	Cost: 9.06s
Train Epoch: 2135 [40960/90000 (45%)]	Loss: -22.8225	Cost: 9.43s
Train Epoch: 2135 [61440/90000 (68%)]	Loss: -22.8935	Cost: 9.03s
Train Epoch: 2135 [81920/90000 (91%)]	Loss: -22.7487	Cost: 9.23s
Train Epoch: 2135 	Average Loss: -22.2880
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1783

Learning rate: 0.00017833681176964737
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2136 [0/90000 (0%)]	Loss: -17.3174	Cost: 48.97s
Train Epoch: 2136 [20480/90000 (23%)]	Loss: -23.0778	Cost: 12.27s
Train Epoch: 2136 [40960/90000 (45%)]	Loss: -23.1618	Cost: 18.80s
Train Epoch: 2136 [61440/90000 (68%)]	Loss: -22.8601	Cost: 11.61s
Train Epoch: 2136 [81920/90000 (91%)]	Loss: -22.4965	Cost: 23.58s
Train Epoch: 2136 	Average Loss: -22.4697
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9175

Learning rate: 0.0001783172810826036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2137 [0/90000 (0%)]	Loss: -15.9075	Cost: 22.98s
Train Epoch: 2137 [20480/90000 (23%)]	Loss: -22.7182	Cost: 9.31s
Train Epoch: 2137 [40960/90000 (45%)]	Loss: -22.9152	Cost: 9.25s
Train Epoch: 2137 [61440/90000 (68%)]	Loss: -22.5333	Cost: 9.23s
Train Epoch: 2137 [81920/90000 (91%)]	Loss: -22.4148	Cost: 9.11s
Train Epoch: 2137 	Average Loss: -22.2681
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9406

Learning rate: 0.00017829774266595405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2138 [0/90000 (0%)]	Loss: -15.7371	Cost: 23.05s
Train Epoch: 2138 [20480/90000 (23%)]	Loss: -22.6881	Cost: 9.34s
Train Epoch: 2138 [40960/90000 (45%)]	Loss: -22.7735	Cost: 9.50s
Train Epoch: 2138 [61440/90000 (68%)]	Loss: -22.3223	Cost: 9.21s
Train Epoch: 2138 [81920/90000 (91%)]	Loss: -22.1623	Cost: 9.09s
Train Epoch: 2138 	Average Loss: -22.1953
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8791

Learning rate: 0.00017827819652162713
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2139 [0/90000 (0%)]	Loss: -15.6310	Cost: 22.37s
Train Epoch: 2139 [20480/90000 (23%)]	Loss: -22.8593	Cost: 9.37s
Train Epoch: 2139 [40960/90000 (45%)]	Loss: -22.7526	Cost: 9.19s
Train Epoch: 2139 [61440/90000 (68%)]	Loss: -22.7638	Cost: 9.25s
Train Epoch: 2139 [81920/90000 (91%)]	Loss: -22.3072	Cost: 9.19s
Train Epoch: 2139 	Average Loss: -22.3050
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9134

Learning rate: 0.00017825864265155194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2140 [0/90000 (0%)]	Loss: -15.9183	Cost: 22.35s
Train Epoch: 2140 [20480/90000 (23%)]	Loss: -22.7857	Cost: 9.34s
Train Epoch: 2140 [40960/90000 (45%)]	Loss: -22.9900	Cost: 9.83s
Train Epoch: 2140 [61440/90000 (68%)]	Loss: -22.9258	Cost: 9.04s
Train Epoch: 2140 [81920/90000 (91%)]	Loss: -22.7662	Cost: 9.15s
Train Epoch: 2140 	Average Loss: -22.4706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1232

Learning rate: 0.00017823908105765837
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2141 [0/90000 (0%)]	Loss: -17.0987	Cost: 23.54s
Train Epoch: 2141 [20480/90000 (23%)]	Loss: -22.7945	Cost: 9.31s
Train Epoch: 2141 [40960/90000 (45%)]	Loss: -22.9863	Cost: 9.33s
Train Epoch: 2141 [61440/90000 (68%)]	Loss: -22.8676	Cost: 9.02s
Train Epoch: 2141 [81920/90000 (91%)]	Loss: -22.6313	Cost: 9.19s
Train Epoch: 2141 	Average Loss: -22.4959
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2379

Learning rate: 0.00017821951174187711
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2142 [0/90000 (0%)]	Loss: -16.4764	Cost: 24.01s
Train Epoch: 2142 [20480/90000 (23%)]	Loss: -23.2824	Cost: 9.38s
Train Epoch: 2142 [40960/90000 (45%)]	Loss: -23.2106	Cost: 9.20s
Train Epoch: 2142 [61440/90000 (68%)]	Loss: -22.8623	Cost: 9.06s
Train Epoch: 2142 [81920/90000 (91%)]	Loss: -22.7982	Cost: 9.03s
Train Epoch: 2142 	Average Loss: -22.6116
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2367

Learning rate: 0.00017819993470613948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2143 [0/90000 (0%)]	Loss: -16.4848	Cost: 24.71s
Train Epoch: 2143 [20480/90000 (23%)]	Loss: -23.3675	Cost: 9.21s
Train Epoch: 2143 [40960/90000 (45%)]	Loss: -23.0639	Cost: 9.21s
Train Epoch: 2143 [61440/90000 (68%)]	Loss: -23.0463	Cost: 9.12s
Train Epoch: 2143 [81920/90000 (91%)]	Loss: -22.8892	Cost: 8.90s
Train Epoch: 2143 	Average Loss: -22.6797
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2304

Learning rate: 0.00017818034995237776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2144 [0/90000 (0%)]	Loss: -16.8646	Cost: 24.72s
Train Epoch: 2144 [20480/90000 (23%)]	Loss: -23.3142	Cost: 9.29s
Train Epoch: 2144 [40960/90000 (45%)]	Loss: -23.3312	Cost: 9.27s
Train Epoch: 2144 [61440/90000 (68%)]	Loss: -23.0987	Cost: 9.07s
Train Epoch: 2144 [81920/90000 (91%)]	Loss: -22.9150	Cost: 8.81s
Train Epoch: 2144 	Average Loss: -22.8341
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.3277

Learning rate: 0.00017816075748252483
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2145 [0/90000 (0%)]	Loss: -15.5508	Cost: 23.49s
Train Epoch: 2145 [20480/90000 (23%)]	Loss: -23.1164	Cost: 9.38s
Train Epoch: 2145 [40960/90000 (45%)]	Loss: -23.4408	Cost: 9.42s
Train Epoch: 2145 [61440/90000 (68%)]	Loss: -23.1263	Cost: 9.10s
Train Epoch: 2145 [81920/90000 (91%)]	Loss: -22.7698	Cost: 8.67s
Train Epoch: 2145 	Average Loss: -22.7664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.3609

Learning rate: 0.0001781411572985144
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2146 [0/90000 (0%)]	Loss: -16.9956	Cost: 24.19s
Train Epoch: 2146 [20480/90000 (23%)]	Loss: -23.0413	Cost: 9.42s
Train Epoch: 2146 [40960/90000 (45%)]	Loss: -23.0192	Cost: 9.21s
Train Epoch: 2146 [61440/90000 (68%)]	Loss: -23.1998	Cost: 9.13s
Train Epoch: 2146 [81920/90000 (91%)]	Loss: -22.8757	Cost: 8.77s
Train Epoch: 2146 	Average Loss: -22.6722
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.4151

Learning rate: 0.00017812154940228094
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2147 [0/90000 (0%)]	Loss: -16.5566	Cost: 27.42s
Train Epoch: 2147 [20480/90000 (23%)]	Loss: -22.9520	Cost: 9.31s
Train Epoch: 2147 [40960/90000 (45%)]	Loss: -22.7752	Cost: 9.31s
Train Epoch: 2147 [61440/90000 (68%)]	Loss: -22.5294	Cost: 9.39s
Train Epoch: 2147 [81920/90000 (91%)]	Loss: -22.3797	Cost: 8.74s
Train Epoch: 2147 	Average Loss: -22.3176
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0343

Learning rate: 0.00017810193379575966
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2148 [0/90000 (0%)]	Loss: -16.4183	Cost: 26.20s
Train Epoch: 2148 [20480/90000 (23%)]	Loss: -22.9401	Cost: 9.25s
Train Epoch: 2148 [40960/90000 (45%)]	Loss: -23.1439	Cost: 9.34s
Train Epoch: 2148 [61440/90000 (68%)]	Loss: -22.7121	Cost: 9.26s
Train Epoch: 2148 [81920/90000 (91%)]	Loss: -22.1818	Cost: 8.70s
Train Epoch: 2148 	Average Loss: -22.4268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8357

Learning rate: 0.00017808231048088656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2149 [0/90000 (0%)]	Loss: -16.4804	Cost: 24.79s
Train Epoch: 2149 [20480/90000 (23%)]	Loss: -22.9064	Cost: 9.34s
Train Epoch: 2149 [40960/90000 (45%)]	Loss: -22.6823	Cost: 9.25s
Train Epoch: 2149 [61440/90000 (68%)]	Loss: -22.7073	Cost: 9.18s
Train Epoch: 2149 [81920/90000 (91%)]	Loss: -22.5080	Cost: 8.91s
Train Epoch: 2149 	Average Loss: -22.3400
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2662

Learning rate: 0.00017806267945959833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2150 [0/90000 (0%)]	Loss: -16.5302	Cost: 24.19s
Train Epoch: 2150 [20480/90000 (23%)]	Loss: -23.1444	Cost: 9.35s
Train Epoch: 2150 [40960/90000 (45%)]	Loss: -23.0276	Cost: 9.27s
Train Epoch: 2150 [61440/90000 (68%)]	Loss: -22.9287	Cost: 9.13s
Train Epoch: 2150 [81920/90000 (91%)]	Loss: -22.8295	Cost: 8.87s
Train Epoch: 2150 	Average Loss: -22.5556
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2145

Saving model as model.pt_e2150 & waveforms_supplementary.hdf5_e2150
Learning rate: 0.00017804304073383256
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2151 [0/90000 (0%)]	Loss: -16.6527	Cost: 23.85s
Train Epoch: 2151 [20480/90000 (23%)]	Loss: -23.2206	Cost: 9.38s
Train Epoch: 2151 [40960/90000 (45%)]	Loss: -22.9539	Cost: 9.25s
Train Epoch: 2151 [61440/90000 (68%)]	Loss: -22.9385	Cost: 9.13s
Train Epoch: 2151 [81920/90000 (91%)]	Loss: -22.5738	Cost: 8.80s
Train Epoch: 2151 	Average Loss: -22.5314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2320

Learning rate: 0.00017802339430552746
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2152 [0/90000 (0%)]	Loss: -16.1953	Cost: 26.44s
Train Epoch: 2152 [20480/90000 (23%)]	Loss: -23.0685	Cost: 9.37s
Train Epoch: 2152 [40960/90000 (45%)]	Loss: -23.0537	Cost: 9.24s
Train Epoch: 2152 [61440/90000 (68%)]	Loss: -22.9940	Cost: 9.16s
Train Epoch: 2152 [81920/90000 (91%)]	Loss: -22.7820	Cost: 8.69s
Train Epoch: 2152 	Average Loss: -22.5864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2613

Learning rate: 0.00017800374017662207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2153 [0/90000 (0%)]	Loss: -16.4614	Cost: 24.73s
Train Epoch: 2153 [20480/90000 (23%)]	Loss: -23.0644	Cost: 9.41s
Train Epoch: 2153 [40960/90000 (45%)]	Loss: -22.7413	Cost: 9.54s
Train Epoch: 2153 [61440/90000 (68%)]	Loss: -22.9361	Cost: 9.33s
Train Epoch: 2153 [81920/90000 (91%)]	Loss: -22.7476	Cost: 8.94s
Train Epoch: 2153 	Average Loss: -22.4723
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1700

Learning rate: 0.00017798407834905615
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2154 [0/90000 (0%)]	Loss: -16.8570	Cost: 24.38s
Train Epoch: 2154 [20480/90000 (23%)]	Loss: -23.1480	Cost: 9.37s
Train Epoch: 2154 [40960/90000 (45%)]	Loss: -23.0558	Cost: 9.22s
Train Epoch: 2154 [61440/90000 (68%)]	Loss: -22.9528	Cost: 9.05s
Train Epoch: 2154 [81920/90000 (91%)]	Loss: -22.6547	Cost: 9.13s
Train Epoch: 2154 	Average Loss: -22.6350
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.3366

Learning rate: 0.00017796440882477025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2155 [0/90000 (0%)]	Loss: -16.0999	Cost: 24.64s
Train Epoch: 2155 [20480/90000 (23%)]	Loss: -23.3706	Cost: 9.50s
Train Epoch: 2155 [40960/90000 (45%)]	Loss: -22.9127	Cost: 9.33s
Train Epoch: 2155 [61440/90000 (68%)]	Loss: -22.6828	Cost: 9.20s
Train Epoch: 2155 [81920/90000 (91%)]	Loss: -22.3486	Cost: 9.09s
Train Epoch: 2155 	Average Loss: -22.4517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1506

Learning rate: 0.00017794473160570576
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2156 [0/90000 (0%)]	Loss: -16.4581	Cost: 23.68s
Train Epoch: 2156 [20480/90000 (23%)]	Loss: -23.0676	Cost: 9.47s
Train Epoch: 2156 [40960/90000 (45%)]	Loss: -22.8504	Cost: 9.28s
Train Epoch: 2156 [61440/90000 (68%)]	Loss: -23.0386	Cost: 9.01s
Train Epoch: 2156 [81920/90000 (91%)]	Loss: -22.8560	Cost: 8.88s
Train Epoch: 2156 	Average Loss: -22.5395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.4564

Learning rate: 0.0001779250466938046
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2157 [0/90000 (0%)]	Loss: -16.7439	Cost: 24.10s
Train Epoch: 2157 [20480/90000 (23%)]	Loss: -23.2952	Cost: 9.25s
Train Epoch: 2157 [40960/90000 (45%)]	Loss: -23.1391	Cost: 9.32s
Train Epoch: 2157 [61440/90000 (68%)]	Loss: -23.0148	Cost: 8.92s
Train Epoch: 2157 [81920/90000 (91%)]	Loss: -22.9777	Cost: 8.77s
Train Epoch: 2157 	Average Loss: -22.6668
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.4981

Learning rate: 0.00017790535409100967
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2158 [0/90000 (0%)]	Loss: -16.9553	Cost: 24.56s
Train Epoch: 2158 [20480/90000 (23%)]	Loss: -23.4165	Cost: 9.06s
Train Epoch: 2158 [40960/90000 (45%)]	Loss: -23.0845	Cost: 9.25s
Train Epoch: 2158 [61440/90000 (68%)]	Loss: -23.0201	Cost: 8.98s
Train Epoch: 2158 [81920/90000 (91%)]	Loss: -22.6915	Cost: 8.67s
Train Epoch: 2158 	Average Loss: -22.6458
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2869

Learning rate: 0.0001778856537992646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2159 [0/90000 (0%)]	Loss: -15.8792	Cost: 23.58s
Train Epoch: 2159 [20480/90000 (23%)]	Loss: -22.9829	Cost: 9.12s
Train Epoch: 2159 [40960/90000 (45%)]	Loss: -22.9539	Cost: 9.11s
Train Epoch: 2159 [61440/90000 (68%)]	Loss: -22.7826	Cost: 9.01s
Train Epoch: 2159 [81920/90000 (91%)]	Loss: -22.7782	Cost: 9.54s
Train Epoch: 2159 	Average Loss: -22.4137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1193

Learning rate: 0.0001778659458205136
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2160 [0/90000 (0%)]	Loss: -16.4165	Cost: 23.28s
Train Epoch: 2160 [20480/90000 (23%)]	Loss: -23.0264	Cost: 9.11s
Train Epoch: 2160 [40960/90000 (45%)]	Loss: -22.9675	Cost: 9.17s
Train Epoch: 2160 [61440/90000 (68%)]	Loss: -23.0489	Cost: 9.09s
Train Epoch: 2160 [81920/90000 (91%)]	Loss: -22.4800	Cost: 9.80s
Train Epoch: 2160 	Average Loss: -22.4449
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8813

Learning rate: 0.00017784623015670192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2161 [0/90000 (0%)]	Loss: -16.5104	Cost: 22.90s
Train Epoch: 2161 [20480/90000 (23%)]	Loss: -22.8708	Cost: 9.12s
Train Epoch: 2161 [40960/90000 (45%)]	Loss: -23.0704	Cost: 9.08s
Train Epoch: 2161 [61440/90000 (68%)]	Loss: -22.8504	Cost: 9.07s
Train Epoch: 2161 [81920/90000 (91%)]	Loss: -22.6373	Cost: 9.32s
Train Epoch: 2161 	Average Loss: -22.5220
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1951

Learning rate: 0.00017782650680977531
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2162 [0/90000 (0%)]	Loss: -16.1168	Cost: 23.48s
Train Epoch: 2162 [20480/90000 (23%)]	Loss: -22.9596	Cost: 9.17s
Train Epoch: 2162 [40960/90000 (45%)]	Loss: -22.5562	Cost: 9.33s
Train Epoch: 2162 [61440/90000 (68%)]	Loss: -22.2250	Cost: 9.14s
Train Epoch: 2162 [81920/90000 (91%)]	Loss: -22.2609	Cost: 9.08s
Train Epoch: 2162 	Average Loss: -22.2538
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8938

Learning rate: 0.0001778067757816804
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2163 [0/90000 (0%)]	Loss: -16.4218	Cost: 22.90s
Train Epoch: 2163 [20480/90000 (23%)]	Loss: -22.6992	Cost: 9.36s
Train Epoch: 2163 [40960/90000 (45%)]	Loss: -22.8540	Cost: 9.24s
Train Epoch: 2163 [61440/90000 (68%)]	Loss: -22.7043	Cost: 9.44s
Train Epoch: 2163 [81920/90000 (91%)]	Loss: -22.5143	Cost: 9.14s
Train Epoch: 2163 	Average Loss: -22.3449
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2044

Learning rate: 0.00017778703707436465
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2164 [0/90000 (0%)]	Loss: -16.5972	Cost: 22.62s
Train Epoch: 2164 [20480/90000 (23%)]	Loss: -23.1797	Cost: 9.34s
Train Epoch: 2164 [40960/90000 (45%)]	Loss: -23.2160	Cost: 9.66s
Train Epoch: 2164 [61440/90000 (68%)]	Loss: -23.0435	Cost: 9.12s
Train Epoch: 2164 [81920/90000 (91%)]	Loss: -23.1656	Cost: 9.21s
Train Epoch: 2164 	Average Loss: -22.7453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.5751

Learning rate: 0.00017776729068977608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2165 [0/90000 (0%)]	Loss: -15.9301	Cost: 23.09s
Train Epoch: 2165 [20480/90000 (23%)]	Loss: -23.3243	Cost: 9.38s
Train Epoch: 2165 [40960/90000 (45%)]	Loss: -23.2182	Cost: 9.32s
Train Epoch: 2165 [61440/90000 (68%)]	Loss: -23.0489	Cost: 9.29s
Train Epoch: 2165 [81920/90000 (91%)]	Loss: -22.8084	Cost: 9.25s
Train Epoch: 2165 	Average Loss: -22.7902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.4004

Learning rate: 0.00017774753662986364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2166 [0/90000 (0%)]	Loss: -16.5798	Cost: 23.40s
Train Epoch: 2166 [20480/90000 (23%)]	Loss: -23.0999	Cost: 9.30s
Train Epoch: 2166 [40960/90000 (45%)]	Loss: -22.9671	Cost: 9.30s
Train Epoch: 2166 [61440/90000 (68%)]	Loss: -23.0960	Cost: 9.02s
Train Epoch: 2166 [81920/90000 (91%)]	Loss: -22.9042	Cost: 9.10s
Train Epoch: 2166 	Average Loss: -22.6224
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1205

Learning rate: 0.00017772777489657697
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2167 [0/90000 (0%)]	Loss: -16.3750	Cost: 24.10s
Train Epoch: 2167 [20480/90000 (23%)]	Loss: -23.3410	Cost: 9.40s
Train Epoch: 2167 [40960/90000 (45%)]	Loss: -23.0887	Cost: 9.22s
Train Epoch: 2167 [61440/90000 (68%)]	Loss: -23.0397	Cost: 9.01s
Train Epoch: 2167 [81920/90000 (91%)]	Loss: -22.8111	Cost: 8.92s
Train Epoch: 2167 	Average Loss: -22.6184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.3542

Learning rate: 0.00017770800549186648
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2168 [0/90000 (0%)]	Loss: -16.3348	Cost: 25.60s
Train Epoch: 2168 [20480/90000 (23%)]	Loss: -23.0815	Cost: 9.25s
Train Epoch: 2168 [40960/90000 (45%)]	Loss: -22.8154	Cost: 9.38s
Train Epoch: 2168 [61440/90000 (68%)]	Loss: -22.7774	Cost: 8.92s
Train Epoch: 2168 [81920/90000 (91%)]	Loss: -22.6344	Cost: 8.75s
Train Epoch: 2168 	Average Loss: -22.5284
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.3047

Learning rate: 0.00017768822841768332
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2169 [0/90000 (0%)]	Loss: -16.0410	Cost: 25.12s
Train Epoch: 2169 [20480/90000 (23%)]	Loss: -23.1505	Cost: 9.27s
Train Epoch: 2169 [40960/90000 (45%)]	Loss: -22.8116	Cost: 9.24s
Train Epoch: 2169 [61440/90000 (68%)]	Loss: -22.8280	Cost: 9.05s
Train Epoch: 2169 [81920/90000 (91%)]	Loss: -22.7703	Cost: 8.74s
Train Epoch: 2169 	Average Loss: -22.5392
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.3096

Learning rate: 0.00017766844367597939
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2170 [0/90000 (0%)]	Loss: -16.7423	Cost: 25.83s
Train Epoch: 2170 [20480/90000 (23%)]	Loss: -23.1858	Cost: 9.77s
Train Epoch: 2170 [40960/90000 (45%)]	Loss: -23.1299	Cost: 9.23s
Train Epoch: 2170 [61440/90000 (68%)]	Loss: -22.9248	Cost: 9.22s
Train Epoch: 2170 [81920/90000 (91%)]	Loss: -22.8856	Cost: 8.71s
Train Epoch: 2170 	Average Loss: -22.6420
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.3778

Learning rate: 0.0001776486512687074
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2171 [0/90000 (0%)]	Loss: -15.9962	Cost: 26.27s
Train Epoch: 2171 [20480/90000 (23%)]	Loss: -23.1981	Cost: 9.31s
Train Epoch: 2171 [40960/90000 (45%)]	Loss: -23.1337	Cost: 9.26s
Train Epoch: 2171 [61440/90000 (68%)]	Loss: -22.8720	Cost: 9.04s
Train Epoch: 2171 [81920/90000 (91%)]	Loss: -22.6733	Cost: 8.71s
Train Epoch: 2171 	Average Loss: -22.5979
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2127

Learning rate: 0.00017762885119782077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2172 [0/90000 (0%)]	Loss: -17.1507	Cost: 23.89s
Train Epoch: 2172 [20480/90000 (23%)]	Loss: -23.1325	Cost: 9.39s
Train Epoch: 2172 [40960/90000 (45%)]	Loss: -22.9833	Cost: 9.23s
Train Epoch: 2172 [61440/90000 (68%)]	Loss: -22.8149	Cost: 9.19s
Train Epoch: 2172 [81920/90000 (91%)]	Loss: -22.4814	Cost: 8.92s
Train Epoch: 2172 	Average Loss: -22.4731
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1434

Learning rate: 0.00017760904346527368
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2173 [0/90000 (0%)]	Loss: -16.0473	Cost: 23.61s
Train Epoch: 2173 [20480/90000 (23%)]	Loss: -22.8700	Cost: 9.40s
Train Epoch: 2173 [40960/90000 (45%)]	Loss: -22.6567	Cost: 9.84s
Train Epoch: 2173 [61440/90000 (68%)]	Loss: -22.9312	Cost: 9.34s
Train Epoch: 2173 [81920/90000 (91%)]	Loss: -22.4545	Cost: 8.82s
Train Epoch: 2173 	Average Loss: -22.2191
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9764

Learning rate: 0.0001775892280730211
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2174 [0/90000 (0%)]	Loss: -16.5842	Cost: 24.54s
Train Epoch: 2174 [20480/90000 (23%)]	Loss: -22.9221	Cost: 9.33s
Train Epoch: 2174 [40960/90000 (45%)]	Loss: -22.8612	Cost: 9.23s
Train Epoch: 2174 [61440/90000 (68%)]	Loss: -22.9195	Cost: 9.14s
Train Epoch: 2174 [81920/90000 (91%)]	Loss: -22.8813	Cost: 9.00s
Train Epoch: 2174 	Average Loss: -22.5478
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.4025

Learning rate: 0.0001775694050230187
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2175 [0/90000 (0%)]	Loss: -16.0988	Cost: 26.87s
Train Epoch: 2175 [20480/90000 (23%)]	Loss: -23.1862	Cost: 9.38s
Train Epoch: 2175 [40960/90000 (45%)]	Loss: -23.0413	Cost: 9.23s
Train Epoch: 2175 [61440/90000 (68%)]	Loss: -22.9685	Cost: 9.16s
Train Epoch: 2175 [81920/90000 (91%)]	Loss: -23.2079	Cost: 8.85s
Train Epoch: 2175 	Average Loss: -22.7260
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.3080

Learning rate: 0.00017754957431722297
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2176 [0/90000 (0%)]	Loss: -16.4783	Cost: 24.19s
Train Epoch: 2176 [20480/90000 (23%)]	Loss: -23.3465	Cost: 9.43s
Train Epoch: 2176 [40960/90000 (45%)]	Loss: -23.0905	Cost: 9.25s
Train Epoch: 2176 [61440/90000 (68%)]	Loss: -22.9762	Cost: 9.30s
Train Epoch: 2176 [81920/90000 (91%)]	Loss: -22.9985	Cost: 8.92s
Train Epoch: 2176 	Average Loss: -22.6714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.3703

Learning rate: 0.0001775297359575911
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2177 [0/90000 (0%)]	Loss: -17.2095	Cost: 24.64s
Train Epoch: 2177 [20480/90000 (23%)]	Loss: -23.3870	Cost: 9.44s
Train Epoch: 2177 [40960/90000 (45%)]	Loss: -23.2092	Cost: 9.31s
Train Epoch: 2177 [61440/90000 (68%)]	Loss: -23.0650	Cost: 9.05s
Train Epoch: 2177 [81920/90000 (91%)]	Loss: -22.9106	Cost: 8.92s
Train Epoch: 2177 	Average Loss: -22.7954
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2100

Learning rate: 0.00017750988994608106
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2178 [0/90000 (0%)]	Loss: -17.0424	Cost: 23.97s
Train Epoch: 2178 [20480/90000 (23%)]	Loss: -22.8539	Cost: 9.41s
Train Epoch: 2178 [40960/90000 (45%)]	Loss: -22.8240	Cost: 9.23s
Train Epoch: 2178 [61440/90000 (68%)]	Loss: -22.3990	Cost: 9.19s
Train Epoch: 2178 [81920/90000 (91%)]	Loss: -22.4465	Cost: 9.00s
Train Epoch: 2178 	Average Loss: -22.3447
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9346

Learning rate: 0.00017749003628465156
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2179 [0/90000 (0%)]	Loss: -16.0085	Cost: 24.28s
Train Epoch: 2179 [20480/90000 (23%)]	Loss: -22.7269	Cost: 9.32s
Train Epoch: 2179 [40960/90000 (45%)]	Loss: -22.8038	Cost: 9.36s
Train Epoch: 2179 [61440/90000 (68%)]	Loss: -22.3690	Cost: 9.09s
Train Epoch: 2179 [81920/90000 (91%)]	Loss: -22.1345	Cost: 9.06s
Train Epoch: 2179 	Average Loss: -22.0722
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.5009

Learning rate: 0.00017747017497526208
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2180 [0/90000 (0%)]	Loss: -15.8467	Cost: 24.13s
Train Epoch: 2180 [20480/90000 (23%)]	Loss: -22.6441	Cost: 9.46s
Train Epoch: 2180 [40960/90000 (45%)]	Loss: -22.7440	Cost: 9.28s
Train Epoch: 2180 [61440/90000 (68%)]	Loss: -22.8136	Cost: 9.03s
Train Epoch: 2180 [81920/90000 (91%)]	Loss: -22.6744	Cost: 9.02s
Train Epoch: 2180 	Average Loss: -22.2325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9933

Learning rate: 0.00017745030601987286
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2181 [0/90000 (0%)]	Loss: -16.8541	Cost: 26.16s
Train Epoch: 2181 [20480/90000 (23%)]	Loss: -23.0058	Cost: 9.42s
Train Epoch: 2181 [40960/90000 (45%)]	Loss: -23.2583	Cost: 9.89s
Train Epoch: 2181 [61440/90000 (68%)]	Loss: -23.0757	Cost: 8.97s
Train Epoch: 2181 [81920/90000 (91%)]	Loss: -23.0054	Cost: 8.85s
Train Epoch: 2181 	Average Loss: -22.6351
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1949

Learning rate: 0.0001774304294204449
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2182 [0/90000 (0%)]	Loss: -16.5977	Cost: 24.55s
Train Epoch: 2182 [20480/90000 (23%)]	Loss: -23.5205	Cost: 9.48s
Train Epoch: 2182 [40960/90000 (45%)]	Loss: -22.8713	Cost: 9.31s
Train Epoch: 2182 [61440/90000 (68%)]	Loss: -21.2229	Cost: 9.01s
Train Epoch: 2182 [81920/90000 (91%)]	Loss: -21.4550	Cost: 8.84s
Train Epoch: 2182 	Average Loss: -21.9695
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.0076

Learning rate: 0.00017741054517893997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2183 [0/90000 (0%)]	Loss: -14.9014	Cost: 24.80s
Train Epoch: 2183 [20480/90000 (23%)]	Loss: -22.0973	Cost: 9.07s
Train Epoch: 2183 [40960/90000 (45%)]	Loss: -22.1457	Cost: 9.40s
Train Epoch: 2183 [61440/90000 (68%)]	Loss: -22.2891	Cost: 8.99s
Train Epoch: 2183 [81920/90000 (91%)]	Loss: -22.2153	Cost: 8.63s
Train Epoch: 2183 	Average Loss: -21.6887
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.8018

Learning rate: 0.0001773906532973205
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2184 [0/90000 (0%)]	Loss: -16.0410	Cost: 24.28s
Train Epoch: 2184 [20480/90000 (23%)]	Loss: -22.9467	Cost: 9.01s
Train Epoch: 2184 [40960/90000 (45%)]	Loss: -23.0602	Cost: 9.59s
Train Epoch: 2184 [61440/90000 (68%)]	Loss: -23.1279	Cost: 9.14s
Train Epoch: 2184 [81920/90000 (91%)]	Loss: -23.1085	Cost: 8.89s
Train Epoch: 2184 	Average Loss: -22.6365
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.4729

Learning rate: 0.00017737075377754978
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2185 [0/90000 (0%)]	Loss: -17.0877	Cost: 23.46s
Train Epoch: 2185 [20480/90000 (23%)]	Loss: -23.7720	Cost: 9.20s
Train Epoch: 2185 [40960/90000 (45%)]	Loss: -23.6001	Cost: 9.63s
Train Epoch: 2185 [61440/90000 (68%)]	Loss: -23.5310	Cost: 9.40s
Train Epoch: 2185 [81920/90000 (91%)]	Loss: -23.1843	Cost: 9.23s
Train Epoch: 2185 	Average Loss: -23.1513
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.5759

Learning rate: 0.00017735084662159182
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2186 [0/90000 (0%)]	Loss: -17.2497	Cost: 23.31s
Train Epoch: 2186 [20480/90000 (23%)]	Loss: -23.6201	Cost: 9.20s
Train Epoch: 2186 [40960/90000 (45%)]	Loss: -23.1821	Cost: 9.12s
Train Epoch: 2186 [61440/90000 (68%)]	Loss: -23.2366	Cost: 9.08s
Train Epoch: 2186 [81920/90000 (91%)]	Loss: -23.0079	Cost: 9.84s
Train Epoch: 2186 	Average Loss: -22.9045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.4519

Learning rate: 0.00017733093183141133
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2187 [0/90000 (0%)]	Loss: -15.9617	Cost: 23.46s
Train Epoch: 2187 [20480/90000 (23%)]	Loss: -23.5812	Cost: 9.30s
Train Epoch: 2187 [40960/90000 (45%)]	Loss: -23.2680	Cost: 9.45s
Train Epoch: 2187 [61440/90000 (68%)]	Loss: -23.3013	Cost: 9.12s
Train Epoch: 2187 [81920/90000 (91%)]	Loss: -23.1525	Cost: 9.27s
Train Epoch: 2187 	Average Loss: -22.9110
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.5201

Learning rate: 0.00017731100940897388
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2188 [0/90000 (0%)]	Loss: -17.3485	Cost: 22.42s
Train Epoch: 2188 [20480/90000 (23%)]	Loss: -23.5765	Cost: 9.33s
Train Epoch: 2188 [40960/90000 (45%)]	Loss: -23.1559	Cost: 9.35s
Train Epoch: 2188 [61440/90000 (68%)]	Loss: -23.3531	Cost: 9.39s
Train Epoch: 2188 [81920/90000 (91%)]	Loss: -22.8595	Cost: 9.17s
Train Epoch: 2188 	Average Loss: -22.9313
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.3238

Learning rate: 0.0001772910793562457
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2189 [0/90000 (0%)]	Loss: -16.1606	Cost: 22.74s
Train Epoch: 2189 [20480/90000 (23%)]	Loss: -23.0264	Cost: 9.34s
Train Epoch: 2189 [40960/90000 (45%)]	Loss: -19.5806	Cost: 9.27s
Train Epoch: 2189 [61440/90000 (68%)]	Loss: -19.8297	Cost: 9.12s
Train Epoch: 2189 [81920/90000 (91%)]	Loss: -20.1720	Cost: 9.15s
Train Epoch: 2189 	Average Loss: -20.7402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.2040

Learning rate: 0.00017727114167519377
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2190 [0/90000 (0%)]	Loss: -14.7118	Cost: 22.42s
Train Epoch: 2190 [20480/90000 (23%)]	Loss: -21.0255	Cost: 9.17s
Train Epoch: 2190 [40960/90000 (45%)]	Loss: -21.2962	Cost: 9.31s
Train Epoch: 2190 [61440/90000 (68%)]	Loss: -21.4349	Cost: 9.05s
Train Epoch: 2190 [81920/90000 (91%)]	Loss: -21.6217	Cost: 9.09s
Train Epoch: 2190 	Average Loss: -20.8371
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6044

Learning rate: 0.00017725119636778592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2191 [0/90000 (0%)]	Loss: -15.5254	Cost: 23.18s
Train Epoch: 2191 [20480/90000 (23%)]	Loss: -22.4500	Cost: 9.36s
Train Epoch: 2191 [40960/90000 (45%)]	Loss: -22.7514	Cost: 9.24s
Train Epoch: 2191 [61440/90000 (68%)]	Loss: -23.0563	Cost: 9.20s
Train Epoch: 2191 [81920/90000 (91%)]	Loss: -22.9897	Cost: 9.12s
Train Epoch: 2191 	Average Loss: -22.3050
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.5441

Learning rate: 0.00017723124343599068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2192 [0/90000 (0%)]	Loss: -16.4247	Cost: 23.09s
Train Epoch: 2192 [20480/90000 (23%)]	Loss: -23.5088	Cost: 9.33s
Train Epoch: 2192 [40960/90000 (45%)]	Loss: -23.1161	Cost: 9.14s
Train Epoch: 2192 [61440/90000 (68%)]	Loss: -23.1253	Cost: 8.86s
Train Epoch: 2192 [81920/90000 (91%)]	Loss: -22.9944	Cost: 8.88s
Train Epoch: 2192 	Average Loss: -22.7648
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.5035

Learning rate: 0.0001772112828817773
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2193 [0/90000 (0%)]	Loss: -16.4126	Cost: 23.86s
Train Epoch: 2193 [20480/90000 (23%)]	Loss: -23.1491	Cost: 9.32s
Train Epoch: 2193 [40960/90000 (45%)]	Loss: -23.0014	Cost: 9.69s
Train Epoch: 2193 [61440/90000 (68%)]	Loss: -23.1667	Cost: 9.20s
Train Epoch: 2193 [81920/90000 (91%)]	Loss: -23.0942	Cost: 8.80s
Train Epoch: 2193 	Average Loss: -22.7259
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.5097

Learning rate: 0.0001771913147071158
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2194 [0/90000 (0%)]	Loss: -16.7294	Cost: 23.54s
Train Epoch: 2194 [20480/90000 (23%)]	Loss: -22.9910	Cost: 9.31s
Train Epoch: 2194 [40960/90000 (45%)]	Loss: -22.8342	Cost: 9.25s
Train Epoch: 2194 [61440/90000 (68%)]	Loss: -22.6015	Cost: 9.15s
Train Epoch: 2194 [81920/90000 (91%)]	Loss: -22.8829	Cost: 8.77s
Train Epoch: 2194 	Average Loss: -22.4904
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2800

Learning rate: 0.00017717133891397696
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2195 [0/90000 (0%)]	Loss: -16.4212	Cost: 24.19s
Train Epoch: 2195 [20480/90000 (23%)]	Loss: -23.4653	Cost: 9.24s
Train Epoch: 2195 [40960/90000 (45%)]	Loss: -23.1320	Cost: 9.39s
Train Epoch: 2195 [61440/90000 (68%)]	Loss: -23.0026	Cost: 9.29s
Train Epoch: 2195 [81920/90000 (91%)]	Loss: -23.0031	Cost: 8.78s
Train Epoch: 2195 	Average Loss: -22.7035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.5918

Learning rate: 0.0001771513555043323
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2196 [0/90000 (0%)]	Loss: -16.3314	Cost: 24.57s
Train Epoch: 2196 [20480/90000 (23%)]	Loss: -23.5743	Cost: 9.41s
Train Epoch: 2196 [40960/90000 (45%)]	Loss: -23.0056	Cost: 9.25s
Train Epoch: 2196 [61440/90000 (68%)]	Loss: -23.3271	Cost: 9.22s
Train Epoch: 2196 [81920/90000 (91%)]	Loss: -23.1043	Cost: 8.78s
Train Epoch: 2196 	Average Loss: -22.8274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.5869

Learning rate: 0.00017713136448015417
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2197 [0/90000 (0%)]	Loss: -16.1231	Cost: 23.83s
Train Epoch: 2197 [20480/90000 (23%)]	Loss: -23.5669	Cost: 9.36s
Train Epoch: 2197 [40960/90000 (45%)]	Loss: -22.8787	Cost: 9.22s
Train Epoch: 2197 [61440/90000 (68%)]	Loss: -22.7349	Cost: 9.21s
Train Epoch: 2197 [81920/90000 (91%)]	Loss: -22.3803	Cost: 8.85s
Train Epoch: 2197 	Average Loss: -22.4132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.9701

Learning rate: 0.00017711136584341554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2198 [0/90000 (0%)]	Loss: -15.6527	Cost: 27.69s
Train Epoch: 2198 [20480/90000 (23%)]	Loss: -23.0530	Cost: 9.34s
Train Epoch: 2198 [40960/90000 (45%)]	Loss: -23.0027	Cost: 9.89s
Train Epoch: 2198 [61440/90000 (68%)]	Loss: -22.9683	Cost: 9.33s
Train Epoch: 2198 [81920/90000 (91%)]	Loss: -22.8708	Cost: 9.25s
Train Epoch: 2198 	Average Loss: -22.4178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2701

Learning rate: 0.00017709135959609023
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2199 [0/90000 (0%)]	Loss: -16.7126	Cost: 24.29s
Train Epoch: 2199 [20480/90000 (23%)]	Loss: -23.3365	Cost: 9.35s
Train Epoch: 2199 [40960/90000 (45%)]	Loss: -23.3604	Cost: 9.23s
Train Epoch: 2199 [61440/90000 (68%)]	Loss: -23.2777	Cost: 9.13s
Train Epoch: 2199 [81920/90000 (91%)]	Loss: -23.1567	Cost: 8.78s
Train Epoch: 2199 	Average Loss: -22.8208
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.6076

Learning rate: 0.00017707134574015276
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2200 [0/90000 (0%)]	Loss: -17.1784	Cost: 24.47s
Train Epoch: 2200 [20480/90000 (23%)]	Loss: -23.7447	Cost: 9.36s
Train Epoch: 2200 [40960/90000 (45%)]	Loss: -23.5396	Cost: 9.34s
Train Epoch: 2200 [61440/90000 (68%)]	Loss: -23.1900	Cost: 9.37s
Train Epoch: 2200 [81920/90000 (91%)]	Loss: -23.1990	Cost: 8.90s
Train Epoch: 2200 	Average Loss: -23.0206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.5424

Saving model as model.pt_e2200 & waveforms_supplementary.hdf5_e2200
Learning rate: 0.0001770513242775784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2201 [0/90000 (0%)]	Loss: -17.2127	Cost: 25.41s
Train Epoch: 2201 [20480/90000 (23%)]	Loss: -23.6988	Cost: 9.33s
Train Epoch: 2201 [40960/90000 (45%)]	Loss: -23.5007	Cost: 9.22s
Train Epoch: 2201 [61440/90000 (68%)]	Loss: -23.4701	Cost: 9.12s
Train Epoch: 2201 [81920/90000 (91%)]	Loss: -23.3471	Cost: 8.79s
Train Epoch: 2201 	Average Loss: -22.9667
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.5998

Learning rate: 0.00017703129521034322
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2202 [0/90000 (0%)]	Loss: -17.2991	Cost: 26.23s
Train Epoch: 2202 [20480/90000 (23%)]	Loss: -23.5013	Cost: 9.51s
Train Epoch: 2202 [40960/90000 (45%)]	Loss: -23.3161	Cost: 9.23s
Train Epoch: 2202 [61440/90000 (68%)]	Loss: -23.5237	Cost: 9.04s
Train Epoch: 2202 [81920/90000 (91%)]	Loss: -23.3687	Cost: 8.75s
Train Epoch: 2202 	Average Loss: -23.0677
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.8097

Learning rate: 0.000177011258540424
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2203 [0/90000 (0%)]	Loss: -15.9937	Cost: 25.61s
Train Epoch: 2203 [20480/90000 (23%)]	Loss: -23.5307	Cost: 9.31s
Train Epoch: 2203 [40960/90000 (45%)]	Loss: -22.5845	Cost: 9.30s
Train Epoch: 2203 [61440/90000 (68%)]	Loss: -22.6627	Cost: 9.16s
Train Epoch: 2203 [81920/90000 (91%)]	Loss: -22.5400	Cost: 8.66s
Train Epoch: 2203 	Average Loss: -22.4022
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0562

Learning rate: 0.0001769912142697983
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2204 [0/90000 (0%)]	Loss: -16.9615	Cost: 24.10s
Train Epoch: 2204 [20480/90000 (23%)]	Loss: -23.1406	Cost: 9.37s
Train Epoch: 2204 [40960/90000 (45%)]	Loss: -23.0155	Cost: 9.57s
Train Epoch: 2204 [61440/90000 (68%)]	Loss: -22.9693	Cost: 9.24s
Train Epoch: 2204 [81920/90000 (91%)]	Loss: -22.9276	Cost: 8.75s
Train Epoch: 2204 	Average Loss: -22.5971
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.4027

Learning rate: 0.00017697116240044438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2205 [0/90000 (0%)]	Loss: -15.1134	Cost: 24.49s
Train Epoch: 2205 [20480/90000 (23%)]	Loss: -23.2717	Cost: 9.35s
Train Epoch: 2205 [40960/90000 (45%)]	Loss: -23.2096	Cost: 9.33s
Train Epoch: 2205 [61440/90000 (68%)]	Loss: -23.2554	Cost: 9.10s
Train Epoch: 2205 [81920/90000 (91%)]	Loss: -23.2880	Cost: 9.10s
Train Epoch: 2205 	Average Loss: -22.7123
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.6501

Learning rate: 0.00017695110293434126
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2206 [0/90000 (0%)]	Loss: -15.7382	Cost: 24.04s
Train Epoch: 2206 [20480/90000 (23%)]	Loss: -23.7175	Cost: 9.39s
Train Epoch: 2206 [40960/90000 (45%)]	Loss: -23.3811	Cost: 9.35s
Train Epoch: 2206 [61440/90000 (68%)]	Loss: -22.9998	Cost: 9.13s
Train Epoch: 2206 [81920/90000 (91%)]	Loss: -22.9209	Cost: 8.97s
Train Epoch: 2206 	Average Loss: -22.8034
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.3500

Learning rate: 0.0001769310358734688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2207 [0/90000 (0%)]	Loss: -16.5377	Cost: 24.24s
Train Epoch: 2207 [20480/90000 (23%)]	Loss: -23.3217	Cost: 9.47s
Train Epoch: 2207 [40960/90000 (45%)]	Loss: -22.7891	Cost: 9.27s
Train Epoch: 2207 [61440/90000 (68%)]	Loss: -22.8185	Cost: 9.14s
Train Epoch: 2207 [81920/90000 (91%)]	Loss: -22.3603	Cost: 8.92s
Train Epoch: 2207 	Average Loss: -22.5081
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.0424

Learning rate: 0.00017691096121980748
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2208 [0/90000 (0%)]	Loss: -16.2174	Cost: 24.13s
Train Epoch: 2208 [20480/90000 (23%)]	Loss: -23.0049	Cost: 9.24s
Train Epoch: 2208 [40960/90000 (45%)]	Loss: -22.8167	Cost: 9.36s
Train Epoch: 2208 [61440/90000 (68%)]	Loss: -23.0157	Cost: 9.22s
Train Epoch: 2208 [81920/90000 (91%)]	Loss: -22.8702	Cost: 8.84s
Train Epoch: 2208 	Average Loss: -22.5035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.1523

Learning rate: 0.00017689087897533864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2209 [0/90000 (0%)]	Loss: -15.6553	Cost: 24.05s
Train Epoch: Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2205 [0/90000 (0%)]	Loss: -16.1554	Cost: 27.56s
Train Epoch: 2205 [20480/90000 (23%)]	Loss: -24.9154	Cost: 9.25s
Train Epoch: 2205 [40960/90000 (45%)]	Loss: -24.2977	Cost: 10.96s
TraRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.6650

Learning rate: 0.00017687078914204425
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2210 [0/90000 (0%)]	Loss: -17.1176	Cost: 23.18s
Train Epoch: Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2206 [0/90000 (0%)]	Loss: -14.2442	Cost: 27.35s
Train Epoch: 2206 [20480/90000 (23%)]	Loss: -21.7427	Cost: 9.72s
Train Epoch: 2206 [40960/90000 (45%)]	Loss: -21.7722	Cost: 9.97s
TraiRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.6543

Learning rate: 0.00017685069172190715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2211 [0/90000 (0%)]	Loss: -17.0533	Cost: 23.24s
Train Epoch:Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2207 [0/90000 (0%)]	Loss: -16.1895	Cost: 27.22s
Train Epoch: 2207 [20480/90000 (23%)]	Loss: -23.5546	Cost: 9.60s
Train Epoch: 2207 [40960/90000 (45%)]	Loss: -23.6916	Cost: 9.39s
TrainRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.5405

Learning rate: 0.00017683058671691084
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2212 [0/90000 (0%)]	Loss: -16.9203	Cost: 22.76s
Train EpochRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2208 [0/90000 (0%)]	Loss: -16.2294	Cost: 27.06s
Train Epoch: 2208 [20480/90000 (23%)]	Loss: -24.3615	Cost: 9.48s
Train Epoch: 2208 [40960/90000 (45%)]	Loss: -24.1987	Cost: 9.28s
Train Epoch: 2208 [61440/90000 (68%)]	Loss: -24.5373	Cost: 9.09s
Train Epoch: 2208 [81920/90000 (91%)]	Loss: -24.7126	Cost: 8.90s
Train Epoch: 2208 	Average Loss: -24.0456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2213 [0/90000 (0%)]	Loss: -16.1818	Cost: 22.29s
Train EpocRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2209 [0/90000 (0%)]	Loss: -16.7540	Cost: 25.19s
Train Epoch: 2209 [20480/90000 (23%)]	Loss: -25.0013	Cost: 9.42s
Train Epoch: 2209 [40960/90000 (45%)]	Loss: -24.9765	Cost: 9.70s
Train Epoch: 2209 [61440/90000 (68%)]	Loss: -24.9736	Cost: 9.12s
Train Epoch: 2209 [81920/90000 (91%)]	Loss: -24.8864	Cost: 9.26s
Train Epoch: 2209 	Average Loss: -24.4709
RRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2214 [0/90000 (0%)]	Loss: -17.0417	Cost: 22.63s
Train EpoRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2210 [0/90000 (0%)]	Loss: -14.4710	Cost: 24.67s
Train Epoch: 2210 [20480/90000 (23%)]	Loss: -25.2528	Cost: 9.31s
Train Epoch: 2210 [40960/90000 (45%)]	Loss: -24.7895	Cost: 9.25s
Train Epoch: 2210 [61440/90000 (68%)]	Loss: -25.1805	Cost: 9.27s
Train Epoch: 2210 [81920/90000 (91%)]	Loss: -24.9235	Cost: 9.19s
Train Epoch: 2210 	Average Loss: -24.6493
RRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2215 [0/90000 (0%)]	Loss: -16.4941	Cost: 22.84s
Train EpRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2211 [0/90000 (0%)]	Loss: -17.3957	Cost: 25.16s
Train Epoch: 2211 [20480/90000 (23%)]	Loss: -25.4982	Cost: 9.40s
Train Epoch: 2211 [40960/90000 (45%)]	Loss: -24.8362	Cost: 10.02s
Train Epoch: 2211 [61440/90000 (68%)]	Loss: -25.1896	Cost: 9.37s
Train Epoch: 2211 [81920/90000 (91%)]	Loss: -25.0867	Cost: 10.34s
Train Epoch: 2211 	Average Loss: -24.7920
RRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2216 [0/90000 (0%)]	Loss: -16.2408	Cost: 23.86s
Train EpoRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2212 [0/90000 (0%)]	Loss: -16.7564	Cost: 24.69s
Train Epoch: 2212 [20480/90000 (23%)]	Loss: -25.2924	Cost: 9.74s
Train Epoch: 2212 [40960/90000 (45%)]	Loss: -24.9276	Cost: 9.60s
Train Epoch: 2212 [61440/90000 (68%)]	Loss: -25.2252	Cost: 9.25s
Train Epoch: 2212 [81920/90000 (91%)]	Loss: -25.1743	Cost: 9.90s
Train Epoch: 2212 	Average Loss: -24.8461
ReRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2217 [0/90000 (0%)]	Loss: -16.9578	Cost: 23.05s
Train EpRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2213 [0/90000 (0%)]	Loss: -15.7144	Cost: 25.21s
Train Epoch: 2213 [20480/90000 (23%)]	Loss: -25.4749	Cost: 9.45s
Train Epoch: 2213 [40960/90000 (45%)]	Loss: -25.1669	Cost: 9.64s
Train Epoch: 2213 [61440/90000 (68%)]	Loss: -25.1890	Cost: 9.26s
Train Epoch: 2213 [81920/90000 (91%)]	Loss: -24.9996	Cost: 10.87s
Train Epoch: 2213 	Average Loss: -24.8056
ReRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2218 [0/90000 (0%)]	Loss: -16.7562	Cost: 24.90s
Train EpRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2214 [0/90000 (0%)]	Loss: -16.6238	Cost: 25.67s
Train Epoch: 2214 [20480/90000 (23%)]	Loss: -25.1618	Cost: 9.33s
Train Epoch: 2214 [40960/90000 (45%)]	Loss: -24.9285	Cost: 9.09s
Train Epoch: 2214 [61440/90000 (68%)]	Loss: -25.1229	Cost: 9.03s
Train Epoch: 2214 [81920/90000 (91%)]	Loss: -25.0681	Cost: 11.00s
Train Epoch: 2214 	Average Loss: -24.7200
ReRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2219 [0/90000 (0%)]	Loss: -16.5645	Cost: 24.24s
Train EpRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2215 [0/90000 (0%)]	Loss: -17.8649	Cost: 26.00s
Train Epoch: 2215 [20480/90000 (23%)]	Loss: -25.3759	Cost: 9.49s
Train Epoch: 2215 [40960/90000 (45%)]	Loss: -24.9716	Cost: 9.31s
Train Epoch: 2215 [61440/90000 (68%)]	Loss: -25.0303	Cost: 9.10s
Train Epoch: 2215 [81920/90000 (91%)]	Loss: -25.0705	Cost: 11.05s
Train Epoch: 2215 	Average Loss: -24.7697
RRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2220 [0/90000 (0%)]	Loss: -16.3133	Cost: 23.53s
Train EpRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2216 [0/90000 (0%)]	Loss: -15.5146	Cost: 25.54s
Train Epoch: 2216 [20480/90000 (23%)]	Loss: -25.4954	Cost: 9.48s
Train Epoch: 2216 [40960/90000 (45%)]	Loss: -25.0329	Cost: 10.15s
Train Epoch: 2216 [61440/90000 (68%)]	Loss: -25.3050	Cost: 9.25s
Train Epoch: 2216 [81920/90000 (91%)]	Loss: -25.2229	Cost: 10.89s
Train Epoch: 2216 	Average Loss: -24.8047
RRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2221 [0/90000 (0%)]	Loss: -16.3765	Cost: 25.50s
Train EpoRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2217 [0/90000 (0%)]	Loss: -15.6253	Cost: 25.39s
Train Epoch: 2217 [20480/90000 (23%)]	Loss: -25.6203	Cost: 9.45s
Train Epoch: 2217 [40960/90000 (45%)]	Loss: -24.9966	Cost: 9.96s
Train Epoch: 2217 [61440/90000 (68%)]	Loss: -25.1778	Cost: 9.09s
Train Epoch: 2217 [81920/90000 (91%)]	Loss: -25.1338	Cost: 10.84s
Train Epoch: 2217 	Average Loss: -24.8635
RRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2222 [0/90000 (0%)]	Loss: -17.2185	Cost: 24.13s
Train EpoRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2218 [0/90000 (0%)]	Loss: -17.8199	Cost: 25.79s
Train Epoch: 2218 [20480/90000 (23%)]	Loss: -25.4642	Cost: 9.50s
Train Epoch: 2218 [40960/90000 (45%)]	Loss: -25.3917	Cost: 10.47s
Train Epoch: 2218 [61440/90000 (68%)]	Loss: -25.3939	Cost: 9.12s
Train Epoch: 2218 [81920/90000 (91%)]	Loss: -25.3400	Cost: 11.21s
Train Epoch: 2218 	Average Loss: -25.0359
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.6547

Learning rate: 8.296185173042414e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2219 [0/90000 (0%)]	Loss: -16.4302	Cost: 25.32s
Train Epoch: 2219 [20480/90000 (23%)]	Loss: -25.4689	Cost: 9.14s
Train Epoch: 2219 [40960/90000 (45%)]	Loss: -25.3428	Cost: 11.08s
Train Epoch: 2219 [61440/90000 (68%)]	Loss: -25.3640	Cost: 9.29s
Train Epoch: 2219 [81920/90000 (91%)]	Loss: -25.3449	Cost: 10.85s
Train Epoch: 2219 	Average Loss: -25.012ReRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.7169

Learning rate: 8.288446557238075e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2220 [0/90000 (0%)]	Loss: -17.6063	Cost: 25.51s
Train Epoch: 2220 [20480/90000 (23%)]	Loss: -25.7533	Cost: 9.13s
Train Epoch: 2220 [40960/90000 (45%)]	Loss: -25.3388	Cost: 11.42s
Train Epoch: 2220 [61440/90000 (68%)]	Loss: -25.3683	Cost: 9.11s
Train Epoch: 2220 [81920/90000 (91%)]	Loss: -25.1750	Cost: 11.02s
Train Epoch: 2220 	Average Loss: -25.04Re-Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.7068

Learning rate: 8.280708997205892e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2221 [0/90000 (0%)]	Loss: -17.3627	Cost: 25.49s
Train Epoch: 2221 [20480/90000 (23%)]	Loss: -25.6184	Cost: 9.08s
Train Epoch: 2221 [40960/90000 (45%)]	Loss: -25.3681	Cost: 11.50s
Train Epoch: 2221 [61440/90000 (68%)]	Loss: -25.6088	Cost: 9.17s
Train Epoch: 2221 [81920/90000 (91%)]	Loss: -25.4855	Cost: 11.09s
Train Epoch: 2221 	Average Loss: -25.1Re-gRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -19.0277

Learning rate: 8.272972497718786e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2222 [0/90000 (0%)]	Loss: -16.6512	Cost: 25.90s
Train Epoch: 2222 [20480/90000 (23%)]	Loss: -25.8250	Cost: 9.12s
Train Epoch: 2222 [40960/90000 (45%)]	Loss: -25.4048	Cost: 11.40s
Train Epoch: 2222 [61440/90000 (68%)]	Loss: -25.5712	Cost: 9.08s
Train Epoch: 2222 [81920/90000 (91%)]	Loss: -25.5566	Cost: 10.86s
Train Epoch: 2222 	Average Loss: -25.Re-geRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.8426

Learning rate: 8.265237063549012e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2223 [0/90000 (0%)]	Loss: -16.3034	Cost: 25.73s
Train Epoch: 2223 [20480/90000 (23%)]	Loss: -25.6010	Cost: 9.05s
Train Epoch: 2223 [40960/90000 (45%)]	Loss: -24.9042	Cost: 11.45s
Train Epoch: 2223 [61440/90000 (68%)]	Loss: -25.1649	Cost: 9.10s
Train Epoch: 2223 [81920/90000 (91%)]	Loss: -25.3320	Cost: 10.79s
Train Epoch: 2223 	Average Loss: -24Re-genRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.6163

Learning rate: 8.257502699468179e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2224 [0/90000 (0%)]	Loss: -15.9342	Cost: 25.98s
Train Epoch: 2224 [20480/90000 (23%)]	Loss: -25.4432	Cost: 9.06s
Train Epoch: 2224 [40960/90000 (45%)]	Loss: -25.1460	Cost: 11.54s
Train Epoch: 2224 [61440/90000 (68%)]	Loss: -25.3449	Cost: 9.01s
Train Epoch: 2224 [81920/90000 (91%)]	Loss: -25.1287	Cost: 10.58s
Train Epoch: 2224 	Average Loss: -2Re-geneRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.7267

Learning rate: 8.24976941024723e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2225 [0/90000 (0%)]	Loss: -16.8011	Cost: 26.67s
Train Epoch: 2225 [20480/90000 (23%)]	Loss: -25.6199	Cost: 9.05s
Train Epoch: 2225 [40960/90000 (45%)]	Loss: -25.3412	Cost: 11.28s
Train Epoch: 2225 [61440/90000 (68%)]	Loss: -25.4755	Cost: 9.05s
Train Epoch: 2225 [81920/90000 (91%)]	Loss: -25.3403	Cost: 8.70s
Train Epoch: 2225 	Average Loss: -25Re-genRe-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.8348

Learning rate: 8.242037200656443e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2226 [0/90000 (0%)]	Loss: -16.9191	Cost: 27.24s
Train Epoch: 2226 [20480/90000 (23%)]	Loss: -25.5582	Cost: 9.02s
Train Epoch: 2226 [40960/90000 (45%)]	Loss: -25.2661	Cost: 11.21s
Train Epoch: 2226 [61440/90000 (68%)]	Loss: -25.5521	Cost: 8.89s
Train Epoch: 2226 [81920/90000 (91%)]	Loss: -25.2646	Cost: 8.61s
Train Epoch: 2226 	Average Loss: -25.0109
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.8214

Learning rate: 8.234306075465441e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2227 [0/90000 (0%)]	Loss: -17.1302	Cost: 27.47s
Train Epoch: 2227 [20480/90000 (23%)]	Loss: -25.5119	Cost: 9.42s
Train Epoch: 2227 [40960/90000 (45%)]	Loss: -25.1849	Cost: 10.90s
Train Epoch: 2227 [61440/90000 (68%)]	Loss: -25.3138	Cost: 9.10s
Train Epoch: 2227 [81920/90000 (91%)]	Loss: -25.3664	Cost: 9.29s
Train Epoch: 2227 	Average Loss: -25.0599
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.8727

Learning rate: 8.226576039443161e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2228 [0/90000 (0%)]	Loss: -17.4544	Cost: 27.67s
Train Epoch: 2228 [20480/90000 (23%)]	Loss: -25.7286	Cost: 9.52s
Train Epoch: 2228 [40960/90000 (45%)]	Loss: -25.4072	Cost: 9.61s
Train Epoch: 2228 [61440/90000 (68%)]	Loss: -25.4634	Cost: 9.23s
Train Epoch: 2228 [81920/90000 (91%)]	Loss: -25.4265	Cost: 8.89s
Train Epoch: 2228 	Average Loss: -25.1423
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.6010

Learning rate: 8.218847097357884e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2229 [0/90000 (0%)]	Loss: -15.6699	Cost: 28.10s
Train Epoch: 2229 [20480/90000 (23%)]	Loss: -25.5469	Cost: 9.40s
Train Epoch: 2229 [40960/90000 (45%)]	Loss: -25.1303	Cost: 9.31s
Train Epoch: 2229 [61440/90000 (68%)]	Loss: -25.2117	Cost: 9.16s
Train Epoch: 2229 [81920/90000 (91%)]	Loss: -25.0832	Cost: 8.93s
Train Epoch: 2229 	Average Loss: -24.6636
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.5917

Learning rate: 8.211119253977213e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2230 [0/90000 (0%)]	Loss: -17.2802	Cost: 25.65s
Train Epoch: 2230 [20480/90000 (23%)]	Loss: -25.3544	Cost: 9.51s
Train Epoch: 2230 [40960/90000 (45%)]	Loss: -25.1893	Cost: 9.48s
Train Epoch: 2230 [61440/90000 (68%)]	Loss: -25.4773	Cost: 9.12s
Train Epoch: 2230 [81920/90000 (91%)]	Loss: -25.3128	Cost: 9.25s
Train Epoch: 2230 	Average Loss: -24.9718
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.7695

Learning rate: 8.203392514068062e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2231 [0/90000 (0%)]	Loss: -16.4926	Cost: 24.18s
Train Epoch: 2231 [20480/90000 (23%)]	Loss: -25.8542	Cost: 9.28s
Train Epoch: 2231 [40960/90000 (45%)]	Loss: -25.5397	Cost: 10.67s
Train Epoch: 2231 [61440/90000 (68%)]	Loss: -25.5454	Cost: 9.34s
Train Epoch: 2231 [81920/90000 (91%)]	Loss: -25.5860	Cost: 9.84s
Train Epoch: 2231 	Average Loss: -25.2330
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.9025

Learning rate: 8.195666882396678e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2232 [0/90000 (0%)]	Loss: -17.1548	Cost: 24.75s
Train Epoch: 2232 [20480/90000 (23%)]	Loss: -25.8507	Cost: 9.43s
Train Epoch: 2232 [40960/90000 (45%)]	Loss: -25.3982	Cost: 9.95s
Train Epoch: 2232 [61440/90000 (68%)]	Loss: -24.8492	Cost: 9.42s
Train Epoch: 2232 [81920/90000 (91%)]	Loss: -24.4983	Cost: 9.95s
Train Epoch: 2232 	Average Loss: -24.8954
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.0027

Learning rate: 8.187942363728616e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2233 [0/90000 (0%)]	Loss: -17.2381	Cost: 25.75s
Train Epoch: 2233 [20480/90000 (23%)]	Loss: -24.9232	Cost: 9.31s
Train Epoch: 2233 [40960/90000 (45%)]	Loss: -24.4104	Cost: 9.35s
Train Epoch: 2233 [61440/90000 (68%)]	Loss: -25.1038	Cost: 9.17s
Train Epoch: 2233 [81920/90000 (91%)]	Loss: -25.0942	Cost: 11.39s
Train Epoch: 2233 	Average Loss: -24.5154
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.2563

Learning rate: 8.180218962828748e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2234 [0/90000 (0%)]	Loss: -16.8430	Cost: 25.61s
Train Epoch: 2234 [20480/90000 (23%)]	Loss: -25.5372	Cost: 9.41s
Train Epoch: 2234 [40960/90000 (45%)]	Loss: -25.2166	Cost: 9.61s
Train Epoch: 2234 [61440/90000 (68%)]	Loss: -25.4831	Cost: 9.12s
Train Epoch: 2234 [81920/90000 (91%)]	Loss: -25.4740	Cost: 11.24s
Train Epoch: 2234 	Average Loss: -24.8688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.6899

Learning rate: 8.172496684461254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2235 [0/90000 (0%)]	Loss: -17.6431	Cost: 25.39s
Train Epoch: 2235 [20480/90000 (23%)]	Loss: -25.6019	Cost: 9.53s
Train Epoch: 2235 [40960/90000 (45%)]	Loss: -25.1937	Cost: 9.68s
Train Epoch: 2235 [61440/90000 (68%)]	Loss: -25.5350	Cost: 9.17s
Train Epoch: 2235 [81920/90000 (91%)]	Loss: -25.6311	Cost: 11.09s
Train Epoch: 2235 	Average Loss: -25.1081
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.7707

Learning rate: 8.164775533389625e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2236 [0/90000 (0%)]	Loss: -17.8239	Cost: 25.52s
Train Epoch: 2236 [20480/90000 (23%)]	Loss: -25.9254	Cost: 9.53s
Train Epoch: 2236 [40960/90000 (45%)]	Loss: -25.2948	Cost: 9.97s
Train Epoch: 2236 [61440/90000 (68%)]	Loss: -25.6452	Cost: 9.19s
Train Epoch: 2236 [81920/90000 (91%)]	Loss: -25.6492	Cost: 11.09s
Train Epoch: 2236 	Average Loss: -25.1847
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.9333

Learning rate: 8.157055514376656e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2237 [0/90000 (0%)]	Loss: -16.5979	Cost: 25.48s
Train Epoch: 2237 [20480/90000 (23%)]	Loss: -25.6460	Cost: 9.52s
Train Epoch: 2237 [40960/90000 (45%)]	Loss: -25.2953	Cost: 10.29s
Train Epoch: 2237 [61440/90000 (68%)]	Loss: -25.5787	Cost: 9.11s
Train Epoch: 2237 [81920/90000 (91%)]	Loss: -25.7906	Cost: 11.12s
Train Epoch: 2237 	Average Loss: -25.2272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.7491

Learning rate: 8.149336632184441e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2238 [0/90000 (0%)]	Loss: -17.3526	Cost: 25.49s
Train Epoch: 2238 [20480/90000 (23%)]	Loss: -25.7697	Cost: 9.51s
Train Epoch: 2238 [40960/90000 (45%)]	Loss: -25.2139	Cost: 10.50s
Train Epoch: 2238 [61440/90000 (68%)]	Loss: -25.6599	Cost: 9.11s
Train Epoch: 2238 [81920/90000 (91%)]	Loss: -25.4248	Cost: 11.13s
Train Epoch: 2238 	Average Loss: -25.0949
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.7620

Learning rate: 8.141618891574376e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2239 [0/90000 (0%)]	Loss: -16.9533	Cost: 25.84s
Train Epoch: 2239 [20480/90000 (23%)]	Loss: -25.7895	Cost: 9.33s
Train Epoch: 2239 [40960/90000 (45%)]	Loss: -25.3194	Cost: 10.43s
Train Epoch: 2239 [61440/90000 (68%)]	Loss: -25.4778	Cost: 9.10s
Train Epoch: 2239 [81920/90000 (91%)]	Loss: -25.4918	Cost: 10.83s
Train Epoch: 2239 	Average Loss: -25.1453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.8482

Learning rate: 8.133902297307149e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2240 [0/90000 (0%)]	Loss: -16.7853	Cost: 25.25s
Train Epoch: 2240 [20480/90000 (23%)]	Loss: -25.7461	Cost: 9.23s
Train Epoch: 2240 [40960/90000 (45%)]	Loss: -25.2298	Cost: 10.93s
Train Epoch: 2240 [61440/90000 (68%)]	Loss: -25.5299	Cost: 9.05s
Train Epoch: 2240 [81920/90000 (91%)]	Loss: -24.4602	Cost: 11.03s
Train Epoch: 2240 	Average Loss: -24.8062
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.8367

Learning rate: 8.126186854142744e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2241 [0/90000 (0%)]	Loss: -15.9944	Cost: 25.22s
Train Epoch: 2241 [20480/90000 (23%)]	Loss: -24.9374	Cost: 9.09s
Train Epoch: 2241 [40960/90000 (45%)]	Loss: -24.7195	Cost: 11.00s
Train Epoch: 2241 [61440/90000 (68%)]	Loss: -25.0669	Cost: 9.09s
Train Epoch: 2241 [81920/90000 (91%)]	Loss: -24.9495	Cost: 10.86s
Train Epoch: 2241 	Average Loss: -24.5212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.3434

Learning rate: 8.118472566840434e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2242 [0/90000 (0%)]	Loss: -17.4442	Cost: 25.27s
Train Epoch: 2242 [20480/90000 (23%)]	Loss: -25.5406	Cost: 9.15s
Train Epoch: 2242 [40960/90000 (45%)]	Loss: -25.1279	Cost: 10.81s
Train Epoch: 2242 [61440/90000 (68%)]	Loss: -25.5828	Cost: 9.12s
Train Epoch: 2242 [81920/90000 (91%)]	Loss: -25.3810	Cost: 10.74s
Train Epoch: 2242 	Average Loss: -25.0142
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.5988

Learning rate: 8.110759440158779e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2243 [0/90000 (0%)]	Loss: -15.9232	Cost: 26.09s
Train Epoch: 2243 [20480/90000 (23%)]	Loss: -25.4064	Cost: 9.06s
Train Epoch: 2243 [40960/90000 (45%)]	Loss: -25.2340	Cost: 11.48s
Train Epoch: 2243 [61440/90000 (68%)]	Loss: -25.2261	Cost: 9.08s
Train Epoch: 2243 [81920/90000 (91%)]	Loss: -25.1053	Cost: 10.65s
Train Epoch: 2243 	Average Loss: -24.8941
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.3350

Learning rate: 8.103047478855625e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2244 [0/90000 (0%)]	Loss: -16.8563	Cost: 25.63s
Train Epoch: 2244 [20480/90000 (23%)]	Loss: -25.3980	Cost: 9.05s
Train Epoch: 2244 [40960/90000 (45%)]	Loss: -25.0661	Cost: 11.32s
Train Epoch: 2244 [61440/90000 (68%)]	Loss: -25.1897	Cost: 9.12s
Train Epoch: 2244 [81920/90000 (91%)]	Loss: -25.0879	Cost: 10.92s
Train Epoch: 2244 	Average Loss: -24.8158
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.4595

Learning rate: 8.095336687688092e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2245 [0/90000 (0%)]	Loss: -17.4149	Cost: 25.44s
Train Epoch: 2245 [20480/90000 (23%)]	Loss: -25.5882	Cost: 9.37s
Train Epoch: 2245 [40960/90000 (45%)]	Loss: -25.2481	Cost: 10.61s
Train Epoch: 2245 [61440/90000 (68%)]	Loss: -25.1738	Cost: 9.25s
Train Epoch: 2245 [81920/90000 (91%)]	Loss: -25.2633	Cost: 10.63s
Train Epoch: 2245 	Average Loss: -24.8523
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.5263

Learning rate: 8.087627071412591e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2246 [0/90000 (0%)]	Loss: -16.9778	Cost: 25.72s
Train Epoch: 2246 [20480/90000 (23%)]	Loss: -25.6465	Cost: 9.16s
Train Epoch: 2246 [40960/90000 (45%)]	Loss: -25.0057	Cost: 10.64s
Train Epoch: 2246 [61440/90000 (68%)]	Loss: -25.3311	Cost: 9.10s
Train Epoch: 2246 [81920/90000 (91%)]	Loss: -25.4018	Cost: 10.82s
Train Epoch: 2246 	Average Loss: -24.9506
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.5775

Learning rate: 8.079918634784792e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2247 [0/90000 (0%)]	Loss: -16.5450	Cost: 25.15s
Train Epoch: 2247 [20480/90000 (23%)]	Loss: -25.8388	Cost: 9.01s
Train Epoch: 2247 [40960/90000 (45%)]	Loss: -25.0825	Cost: 10.91s
Train Epoch: 2247 [61440/90000 (68%)]	Loss: -25.0443	Cost: 9.00s
Train Epoch: 2247 [81920/90000 (91%)]	Loss: -25.1710	Cost: 11.15s
Train Epoch: 2247 	Average Loss: -24.8013
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.4858

Learning rate: 8.07221138255965e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2248 [0/90000 (0%)]	Loss: -17.2976	Cost: 25.54s
Train Epoch: 2248 [20480/90000 (23%)]	Loss: -25.6914	Cost: 9.03s
Train Epoch: 2248 [40960/90000 (45%)]	Loss: -25.2680	Cost: 11.30s
Train Epoch: 2248 [61440/90000 (68%)]	Loss: -25.1942	Cost: 9.02s
Train Epoch: 2248 [81920/90000 (91%)]	Loss: -25.3251	Cost: 11.06s
Train Epoch: 2248 	Average Loss: -24.9771
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.6445

Learning rate: 8.06450531949139e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2249 [0/90000 (0%)]	Loss: -16.5607	Cost: 25.12s
Train Epoch: 2249 [20480/90000 (23%)]	Loss: -25.1015	Cost: 9.10s
Train Epoch: 2249 [40960/90000 (45%)]	Loss: -24.8375	Cost: 11.05s
Train Epoch: 2249 [61440/90000 (68%)]	Loss: -24.7045	Cost: 9.08s
Train Epoch: 2249 [81920/90000 (91%)]	Loss: -24.7912	Cost: 11.12s
Train Epoch: 2249 	Average Loss: -24.4970
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.1935

Learning rate: 8.05680045033349e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2250 [0/90000 (0%)]	Loss: -14.6063	Cost: 26.19s
Train Epoch: 2250 [20480/90000 (23%)]	Loss: -25.2237	Cost: 9.14s
Train Epoch: 2250 [40960/90000 (45%)]	Loss: -24.9961	Cost: 10.99s
Train Epoch: 2250 [61440/90000 (68%)]	Loss: -25.0256	Cost: 9.08s
Train Epoch: 2250 [81920/90000 (91%)]	Loss: -24.4915	Cost: 10.95s
Train Epoch: 2250 	Average Loss: -24.4118
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.7181

Saving model as model.pt_e2250 & waveforms_supplementary.hdf5_e2250
Learning rate: 8.049096779838708e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2251 [0/90000 (0%)]	Loss: -17.7661	Cost: 25.58s
Train Epoch: 2251 [20480/90000 (23%)]	Loss: -25.2286	Cost: 9.04s
Train Epoch: 2251 [40960/90000 (45%)]	Loss: -24.9243	Cost: 11.26s
Train Epoch: 2251 [61440/90000 (68%)]	Loss: -25.1722	Cost: 9.04s
Train Epoch: 2251 [81920/90000 (91%)]	Loss: -24.7898	Cost: 10.37s
Train Epoch: 2251 	Average Loss: -24.5828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.0201

Learning rate: 8.041394312759053e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2252 [0/90000 (0%)]	Loss: -16.9254	Cost: 25.69s
Train Epoch: 2252 [20480/90000 (23%)]	Loss: -25.4831	Cost: 9.08s
Train Epoch: 2252 [40960/90000 (45%)]	Loss: -24.9245	Cost: 11.37s
Train Epoch: 2252 [61440/90000 (68%)]	Loss: -25.1476	Cost: 9.12s
Train Epoch: 2252 [81920/90000 (91%)]	Loss: -25.0081	Cost: 10.51s
Train Epoch: 2252 	Average Loss: -24.7841
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.1851

Learning rate: 8.033693053845789e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2253 [0/90000 (0%)]	Loss: -17.3249	Cost: 25.82s
Train Epoch: 2253 [20480/90000 (23%)]	Loss: -25.5567	Cost: 9.05s
Train Epoch: 2253 [40960/90000 (45%)]	Loss: -25.1795	Cost: 11.50s
Train Epoch: 2253 [61440/90000 (68%)]	Loss: -25.5140	Cost: 9.29s
Train Epoch: 2253 [81920/90000 (91%)]	Loss: -25.0817	Cost: 10.09s
Train Epoch: 2253 	Average Loss: -24.9056
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.1708

Learning rate: 8.025993007849448e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2254 [0/90000 (0%)]	Loss: -17.6479	Cost: 27.12s
Train Epoch: 2254 [20480/90000 (23%)]	Loss: -25.6173	Cost: 9.04s
Train Epoch: 2254 [40960/90000 (45%)]	Loss: -25.5228	Cost: 11.20s
Train Epoch: 2254 [61440/90000 (68%)]	Loss: -25.2841	Cost: 8.92s
Train Epoch: 2254 [81920/90000 (91%)]	Loss: -25.3121	Cost: 8.85s
Train Epoch: 2254 	Average Loss: -25.0057
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.1887

Learning rate: 8.018294179519798e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2255 [0/90000 (0%)]	Loss: -17.0739	Cost: 27.45s
Train Epoch: 2255 [20480/90000 (23%)]	Loss: -25.1698	Cost: 9.20s
Train Epoch: 2255 [40960/90000 (45%)]	Loss: -25.0609	Cost: 10.87s
Train Epoch: 2255 [61440/90000 (68%)]	Loss: -25.2014	Cost: 9.05s
Train Epoch: 2255 [81920/90000 (91%)]	Loss: -24.9841	Cost: 8.84s
Train Epoch: 2255 	Average Loss: -24.7663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.8862

Learning rate: 8.010596573605866e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2256 [0/90000 (0%)]	Loss: -16.7203	Cost: 27.50s
Train Epoch: 2256 [20480/90000 (23%)]	Loss: -25.2969	Cost: 9.47s
Train Epoch: 2256 [40960/90000 (45%)]	Loss: -25.0794	Cost: 10.15s
Train Epoch: 2256 [61440/90000 (68%)]	Loss: -25.2791	Cost: 9.14s
Train Epoch: 2256 [81920/90000 (91%)]	Loss: -25.0236	Cost: 9.05s
Train Epoch: 2256 	Average Loss: -24.6364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.5750

Learning rate: 8.002900194855922e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2257 [0/90000 (0%)]	Loss: -16.4894	Cost: 28.70s
Train Epoch: 2257 [20480/90000 (23%)]	Loss: -25.5178	Cost: 9.44s
Train Epoch: 2257 [40960/90000 (45%)]	Loss: -25.2735	Cost: 9.30s
Train Epoch: 2257 [61440/90000 (68%)]	Loss: -25.1424	Cost: 9.24s
Train Epoch: 2257 [81920/90000 (91%)]	Loss: -24.9285	Cost: 9.34s
Train Epoch: 2257 	Average Loss: -24.7923
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.9629

Learning rate: 7.99520504801748e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2258 [0/90000 (0%)]	Loss: -15.5577	Cost: 25.68s
Train Epoch: 2258 [20480/90000 (23%)]	Loss: -25.4883	Cost: 9.37s
Train Epoch: 2258 [40960/90000 (45%)]	Loss: -24.9837	Cost: 9.25s
Train Epoch: 2258 [61440/90000 (68%)]	Loss: -24.9761	Cost: 9.10s
Train Epoch: 2258 [81920/90000 (91%)]	Loss: -24.5661	Cost: 9.22s
Train Epoch: 2258 	Average Loss: -24.5398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.9774

Learning rate: 7.987511137837289e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2259 [0/90000 (0%)]	Loss: -15.7896	Cost: 24.73s
Train Epoch: 2259 [20480/90000 (23%)]	Loss: -25.0592	Cost: 9.38s
Train Epoch: 2259 [40960/90000 (45%)]	Loss: -24.8410	Cost: 9.35s
Train Epoch: 2259 [61440/90000 (68%)]	Loss: -25.0004	Cost: 9.32s
Train Epoch: 2259 [81920/90000 (91%)]	Loss: -24.4893	Cost: 9.42s
Train Epoch: 2259 	Average Loss: -24.4455
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.2361

Learning rate: 7.979818469061344e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2260 [0/90000 (0%)]	Loss: -17.1989	Cost: 25.00s
Train Epoch: 2260 [20480/90000 (23%)]	Loss: -25.1943	Cost: 9.44s
Train Epoch: 2260 [40960/90000 (45%)]	Loss: -24.6204	Cost: 9.72s
Train Epoch: 2260 [61440/90000 (68%)]	Loss: -24.9256	Cost: 9.29s
Train Epoch: 2260 [81920/90000 (91%)]	Loss: -24.5969	Cost: 10.21s
Train Epoch: 2260 	Average Loss: -24.4456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.0616

Learning rate: 7.972127046434868e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2261 [0/90000 (0%)]	Loss: -15.5882	Cost: 24.93s
Train Epoch: 2261 [20480/90000 (23%)]	Loss: -25.1236	Cost: 9.35s
Train Epoch: 2261 [40960/90000 (45%)]	Loss: -24.7273	Cost: 9.59s
Train Epoch: 2261 [61440/90000 (68%)]	Loss: -24.8212	Cost: 9.28s
Train Epoch: 2261 [81920/90000 (91%)]	Loss: -24.7324	Cost: 10.45s
Train Epoch: 2261 	Average Loss: -24.3727
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.1273

Learning rate: 7.964436874702315e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2262 [0/90000 (0%)]	Loss: -16.9373	Cost: 25.89s
Train Epoch: 2262 [20480/90000 (23%)]	Loss: -24.9133	Cost: 9.38s
Train Epoch: 2262 [40960/90000 (45%)]	Loss: -24.7524	Cost: 9.68s
Train Epoch: 2262 [61440/90000 (68%)]	Loss: -24.9698	Cost: 9.20s
Train Epoch: 2262 [81920/90000 (91%)]	Loss: -24.9857	Cost: 10.07s
Train Epoch: 2262 	Average Loss: -24.5308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.2245

Learning rate: 7.956747958607377e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2263 [0/90000 (0%)]	Loss: -17.5558	Cost: 25.54s
Train Epoch: 2263 [20480/90000 (23%)]	Loss: -25.5814	Cost: 9.36s
Train Epoch: 2263 [40960/90000 (45%)]	Loss: -25.2300	Cost: 9.39s
Train Epoch: 2263 [61440/90000 (68%)]	Loss: -25.4823	Cost: 9.19s
Train Epoch: 2263 [81920/90000 (91%)]	Loss: -25.1036	Cost: 10.70s
Train Epoch: 2263 	Average Loss: -24.9849
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.5095

Learning rate: 7.949060302892951e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2264 [0/90000 (0%)]	Loss: -15.8748	Cost: 25.26s
Train Epoch: 2264 [20480/90000 (23%)]	Loss: -25.7303	Cost: 9.38s
Train Epoch: 2264 [40960/90000 (45%)]	Loss: -25.0558	Cost: 9.43s
Train Epoch: 2264 [61440/90000 (68%)]	Loss: -25.2841	Cost: 9.11s
Train Epoch: 2264 [81920/90000 (91%)]	Loss: -25.1777	Cost: 11.23s
Train Epoch: 2264 	Average Loss: -24.8723
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.5998

Learning rate: 7.941373912301178e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2265 [0/90000 (0%)]	Loss: -16.9312	Cost: 25.00s
Train Epoch: 2265 [20480/90000 (23%)]	Loss: -25.7682	Cost: 9.39s
Train Epoch: 2265 [40960/90000 (45%)]	Loss: -25.2281	Cost: 9.53s
Train Epoch: 2265 [61440/90000 (68%)]	Loss: -25.5313	Cost: 9.18s
Train Epoch: 2265 [81920/90000 (91%)]	Loss: -25.1071	Cost: 10.75s
Train Epoch: 2265 	Average Loss: -24.9783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.3040

Learning rate: 7.933688791573413e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2266 [0/90000 (0%)]	Loss: -16.7909	Cost: 25.43s
Train Epoch: 2266 [20480/90000 (23%)]	Loss: -25.4533	Cost: 9.57s
Train Epoch: 2266 [40960/90000 (45%)]	Loss: -25.1767	Cost: 9.16s
Train Epoch: 2266 [61440/90000 (68%)]	Loss: -25.3883	Cost: 9.15s
Train Epoch: 2266 [81920/90000 (91%)]	Loss: -25.3591	Cost: 10.63s
Train Epoch: 2266 	Average Loss: -24.9592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.6917

Learning rate: 7.926004945450215e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2267 [0/90000 (0%)]	Loss: -17.5464	Cost: 25.62s
Train Epoch: 2267 [20480/90000 (23%)]	Loss: -25.9716	Cost: 9.43s
Train Epoch: 2267 [40960/90000 (45%)]	Loss: -25.4360	Cost: 9.47s
Train Epoch: 2267 [61440/90000 (68%)]	Loss: -25.7363	Cost: 9.06s
Train Epoch: 2267 [81920/90000 (91%)]	Loss: -25.3643	Cost: 11.06s
Train Epoch: 2267 	Average Loss: -25.1535
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.6972

Learning rate: 7.918322378671375e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2268 [0/90000 (0%)]	Loss: -18.3364	Cost: 25.76s
Train Epoch: 2268 [20480/90000 (23%)]	Loss: -25.8866	Cost: 9.46s
Train Epoch: 2268 [40960/90000 (45%)]	Loss: -25.2707	Cost: 10.36s
Train Epoch: 2268 [61440/90000 (68%)]	Loss: -25.6018	Cost: 9.19s
Train Epoch: 2268 [81920/90000 (91%)]	Loss: -25.6279	Cost: 10.84s
Train Epoch: 2268 	Average Loss: -25.2339
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.6150

Learning rate: 7.910641095975877e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2269 [0/90000 (0%)]	Loss: -17.4016	Cost: 26.72s
Train Epoch: 2269 [20480/90000 (23%)]	Loss: -25.8467	Cost: 9.28s
Train Epoch: 2269 [40960/90000 (45%)]	Loss: -25.5546	Cost: 10.62s
Train Epoch: 2269 [61440/90000 (68%)]	Loss: -25.6730	Cost: 9.08s
Train Epoch: 2269 [81920/90000 (91%)]	Loss: -25.1794	Cost: 10.95s
Train Epoch: 2269 	Average Loss: -25.2376
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.3961

Learning rate: 7.902961102101932e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2270 [0/90000 (0%)]	Loss: -16.9508	Cost: 26.03s
Train Epoch: 2270 [20480/90000 (23%)]	Loss: -25.8737	Cost: 9.16s
Train Epoch: 2270 [40960/90000 (45%)]	Loss: -25.4011	Cost: 10.62s
Train Epoch: 2270 [61440/90000 (68%)]	Loss: -25.8019	Cost: 9.09s
Train Epoch: 2270 [81920/90000 (91%)]	Loss: -25.2821	Cost: 10.91s
Train Epoch: 2270 	Average Loss: -25.1825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.6392

Learning rate: 7.89528240178694e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2271 [0/90000 (0%)]	Loss: -15.3148	Cost: 26.13s
Train Epoch: 2271 [20480/90000 (23%)]	Loss: -25.8086	Cost: 9.24s
Train Epoch: 2271 [40960/90000 (45%)]	Loss: -25.2474	Cost: 10.53s
Train Epoch: 2271 [61440/90000 (68%)]	Loss: -25.8231	Cost: 9.06s
Train Epoch: 2271 [81920/90000 (91%)]	Loss: -25.5375	Cost: 10.93s
Train Epoch: 2271 	Average Loss: -25.2512
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.7428

Learning rate: 7.887604999767509e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2272 [0/90000 (0%)]	Loss: -16.9777	Cost: 25.69s
Train Epoch: 2272 [20480/90000 (23%)]	Loss: -25.8952	Cost: 9.18s
Train Epoch: 2272 [40960/90000 (45%)]	Loss: -25.7270	Cost: 11.29s
Train Epoch: 2272 [61440/90000 (68%)]	Loss: -25.9223	Cost: 9.06s
Train Epoch: 2272 [81920/90000 (91%)]	Loss: -25.7286	Cost: 10.83s
Train Epoch: 2272 	Average Loss: -25.3983
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.7304

Learning rate: 7.879928900779449e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2273 [0/90000 (0%)]	Loss: -16.0302	Cost: 26.18s
Train Epoch: 2273 [20480/90000 (23%)]	Loss: -25.9827	Cost: 9.09s
Train Epoch: 2273 [40960/90000 (45%)]	Loss: -25.7022	Cost: 10.83s
Train Epoch: 2273 [61440/90000 (68%)]	Loss: -25.6884	Cost: 9.15s
Train Epoch: 2273 [81920/90000 (91%)]	Loss: -25.4471	Cost: 10.91s
Train Epoch: 2273 	Average Loss: -25.2348
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.6380

Learning rate: 7.872254109557764e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2274 [0/90000 (0%)]	Loss: -16.3302	Cost: 25.91s
Train Epoch: 2274 [20480/90000 (23%)]	Loss: -25.7280	Cost: 9.41s
Train Epoch: 2274 [40960/90000 (45%)]	Loss: -25.2560	Cost: 10.84s
Train Epoch: 2274 [61440/90000 (68%)]	Loss: -25.5543	Cost: 9.09s
Train Epoch: 2274 [81920/90000 (91%)]	Loss: -25.3879	Cost: 10.76s
Train Epoch: 2274 	Average Loss: -25.0796
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.6939

Learning rate: 7.864580630836649e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2275 [0/90000 (0%)]	Loss: -17.6240	Cost: 25.58s
Train Epoch: 2275 [20480/90000 (23%)]	Loss: -25.9100	Cost: 9.61s
Train Epoch: 2275 [40960/90000 (45%)]	Loss: -25.4497	Cost: 10.42s
Train Epoch: 2275 [61440/90000 (68%)]	Loss: -25.9505	Cost: 9.07s
Train Epoch: 2275 [81920/90000 (91%)]	Loss: -25.6007	Cost: 10.58s
Train Epoch: 2275 	Average Loss: -25.2211
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.7436

Learning rate: 7.856908469349488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2276 [0/90000 (0%)]	Loss: -16.8335	Cost: 26.07s
Train Epoch: 2276 [20480/90000 (23%)]	Loss: -25.7390	Cost: 9.11s
Train Epoch: 2276 [40960/90000 (45%)]	Loss: -25.1958	Cost: 10.84s
Train Epoch: 2276 [61440/90000 (68%)]	Loss: -25.8012	Cost: 9.06s
Train Epoch: 2276 [81920/90000 (91%)]	Loss: -23.9471	Cost: 10.69s
Train Epoch: 2276 	Average Loss: -24.8816
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.2862

Learning rate: 7.849237629828862e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2277 [0/90000 (0%)]	Loss: -16.8631	Cost: 24.89s
Train Epoch: 2277 [20480/90000 (23%)]	Loss: -23.7090	Cost: 9.07s
Train Epoch: 2277 [40960/90000 (45%)]	Loss: -23.5687	Cost: 11.13s
Train Epoch: 2277 [61440/90000 (68%)]	Loss: -23.8638	Cost: 9.08s
Train Epoch: 2277 [81920/90000 (91%)]	Loss: -24.0242	Cost: 10.84s
Train Epoch: 2277 	Average Loss: -23.3949
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.9395

Learning rate: 7.841568117006527e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2278 [0/90000 (0%)]	Loss: -16.0261	Cost: 25.26s
Train Epoch: 2278 [20480/90000 (23%)]	Loss: -24.8620	Cost: 9.07s
Train Epoch: 2278 [40960/90000 (45%)]	Loss: -24.3484	Cost: 10.95s
Train Epoch: 2278 [61440/90000 (68%)]	Loss: -24.9169	Cost: 9.13s
Train Epoch: 2278 [81920/90000 (91%)]	Loss: -25.0889	Cost: 10.89s
Train Epoch: 2278 	Average Loss: -24.2317
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.5186

Learning rate: 7.833899935613426e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2279 [0/90000 (0%)]	Loss: -15.5405	Cost: 25.22s
Train Epoch: 2279 [20480/90000 (23%)]	Loss: -25.5831	Cost: 9.11s
Train Epoch: 2279 [40960/90000 (45%)]	Loss: -25.3024	Cost: 10.97s
Train Epoch: 2279 [61440/90000 (68%)]	Loss: -25.5084	Cost: 9.10s
Train Epoch: 2279 [81920/90000 (91%)]	Loss: -25.5111	Cost: 11.05s
Train Epoch: 2279 	Average Loss: -24.9190
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.3389

Learning rate: 7.826233090379676e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2280 [0/90000 (0%)]	Loss: -17.7132	Cost: 24.87s
Train Epoch: 2280 [20480/90000 (23%)]	Loss: -24.3913	Cost: 9.10s
Train Epoch: 2280 [40960/90000 (45%)]	Loss: -24.3323	Cost: 11.33s
Train Epoch: 2280 [61440/90000 (68%)]	Loss: -24.7559	Cost: 9.10s
Train Epoch: 2280 [81920/90000 (91%)]	Loss: -24.3547	Cost: 11.11s
Train Epoch: 2280 	Average Loss: -24.1052
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.8664

Learning rate: 7.818567586034571e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2281 [0/90000 (0%)]	Loss: -15.3945	Cost: 25.15s
Train Epoch: 2281 [20480/90000 (23%)]	Loss: -24.6909	Cost: 9.01s
Train Epoch: 2281 [40960/90000 (45%)]	Loss: -24.2596	Cost: 11.29s
Train Epoch: 2281 [61440/90000 (68%)]	Loss: -24.5706	Cost: 9.05s
Train Epoch: 2281 [81920/90000 (91%)]	Loss: -22.7725	Cost: 10.98s
Train Epoch: 2281 	Average Loss: -23.7641
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -16.6928

Learning rate: 7.810903427306586e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2282 [0/90000 (0%)]	Loss: -14.8768	Cost: 26.11s
Train Epoch: 2282 [20480/90000 (23%)]	Loss: -23.5939	Cost: 9.05s
Train Epoch: 2282 [40960/90000 (45%)]	Loss: -24.1038	Cost: 11.17s
Train Epoch: 2282 [61440/90000 (68%)]	Loss: -24.5237	Cost: 9.07s
Train Epoch: 2282 [81920/90000 (91%)]	Loss: -24.5740	Cost: 10.79s
Train Epoch: 2282 	Average Loss: -23.6240
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.0841

Learning rate: 7.80324061892335e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2283 [0/90000 (0%)]	Loss: -17.3108	Cost: 26.21s
Train Epoch: 2283 [20480/90000 (23%)]	Loss: -25.0244	Cost: 9.06s
Train Epoch: 2283 [40960/90000 (45%)]	Loss: -24.7844	Cost: 11.19s
Train Epoch: 2283 [61440/90000 (68%)]	Loss: -25.1312	Cost: 9.09s
Train Epoch: 2283 [81920/90000 (91%)]	Loss: -25.2691	Cost: 10.45s
Train Epoch: 2283 	Average Loss: -24.7458
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.7428

Learning rate: 7.795579165611671e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2284 [0/90000 (0%)]	Loss: -17.4693	Cost: 26.66s
Train Epoch: 2284 [20480/90000 (23%)]	Loss: -25.7068	Cost: 9.27s
Train Epoch: 2284 [40960/90000 (45%)]	Loss: -25.3451	Cost: 11.08s
Train Epoch: 2284 [61440/90000 (68%)]	Loss: -25.5592	Cost: 9.09s
Train Epoch: 2284 [81920/90000 (91%)]	Loss: -25.2146	Cost: 9.38s
Train Epoch: 2284 	Average Loss: -25.1548
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.6369

Learning rate: 7.787919072097527e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2285 [0/90000 (0%)]	Loss: -16.8529	Cost: 27.73s
Train Epoch: 2285 [20480/90000 (23%)]	Loss: -25.8113	Cost: 9.73s
Train Epoch: 2285 [40960/90000 (45%)]	Loss: -25.6556	Cost: 10.63s
Train Epoch: 2285 [61440/90000 (68%)]	Loss: -25.9330	Cost: 9.58s
Train Epoch: 2285 [81920/90000 (91%)]	Loss: -25.7476	Cost: 9.29s
Train Epoch: 2285 	Average Loss: -25.2994
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.6928

Learning rate: 7.780260343106037e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2286 [0/90000 (0%)]	Loss: -18.6418	Cost: 27.57s
Train Epoch: 2286 [20480/90000 (23%)]	Loss: -25.9886	Cost: 9.30s
Train Epoch: 2286 [40960/90000 (45%)]	Loss: -25.5385	Cost: 10.59s
Train Epoch: 2286 [61440/90000 (68%)]	Loss: -25.9321	Cost: 9.13s
Train Epoch: 2286 [81920/90000 (91%)]	Loss: -25.2515	Cost: 9.05s
Train Epoch: 2286 	Average Loss: -25.3578
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.7175

Learning rate: 7.772602983361496e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2287 [0/90000 (0%)]	Loss: -17.4599	Cost: 27.29s
Train Epoch: 2287 [20480/90000 (23%)]	Loss: -25.7417	Cost: 9.61s
Train Epoch: 2287 [40960/90000 (45%)]	Loss: -25.5012	Cost: 9.36s
Train Epoch: 2287 [61440/90000 (68%)]	Loss: -25.8432	Cost: 9.18s
Train Epoch: 2287 [81920/90000 (91%)]	Loss: -25.4776	Cost: 8.97s
Train Epoch: 2287 	Average Loss: -25.1435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.8685

Learning rate: 7.764946997587346e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2288 [0/90000 (0%)]	Loss: -16.0116	Cost: 29.04s
Train Epoch: 2288 [20480/90000 (23%)]	Loss: -25.9779	Cost: 9.68s
Train Epoch: 2288 [40960/90000 (45%)]	Loss: -25.4817	Cost: 9.65s
Train Epoch: 2288 [61440/90000 (68%)]	Loss: -25.8642	Cost: 9.14s
Train Epoch: 2288 [81920/90000 (91%)]	Loss: -25.6256	Cost: 9.27s
Train Epoch: 2288 	Average Loss: -25.2251
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.5885

Learning rate: 7.757292390506184e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2289 [0/90000 (0%)]	Loss: -16.6273	Cost: 25.19s
Train Epoch: 2289 [20480/90000 (23%)]	Loss: -26.0726	Cost: 9.35s
Train Epoch: 2289 [40960/90000 (45%)]	Loss: -25.6660	Cost: 9.29s
Train Epoch: 2289 [61440/90000 (68%)]	Loss: -25.9227	Cost: 9.17s
Train Epoch: 2289 [81920/90000 (91%)]	Loss: -25.6507	Cost: 9.17s
Train Epoch: 2289 	Average Loss: -25.3969
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.8346

Learning rate: 7.74963916683976e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2290 [0/90000 (0%)]	Loss: -13.9458	Cost: 24.34s
Train Epoch: 2290 [20480/90000 (23%)]	Loss: -25.8555	Cost: 9.40s
Train Epoch: 2290 [40960/90000 (45%)]	Loss: -25.2882	Cost: 9.38s
Train Epoch: 2290 [61440/90000 (68%)]	Loss: -24.2830	Cost: 9.45s
Train Epoch: 2290 [81920/90000 (91%)]	Loss: -24.3532	Cost: 9.35s
Train Epoch: 2290 	Average Loss: -24.5156
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.9577

Learning rate: 7.741987331308961e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2291 [0/90000 (0%)]	Loss: -15.4972	Cost: 24.32s
Train Epoch: 2291 [20480/90000 (23%)]	Loss: -25.0755	Cost: 9.32s
Train Epoch: 2291 [40960/90000 (45%)]	Loss: -25.1166	Cost: 10.07s
Train Epoch: 2291 [61440/90000 (68%)]	Loss: -25.1520	Cost: 9.22s
Train Epoch: 2291 [81920/90000 (91%)]	Loss: -25.3043	Cost: 9.64s
Train Epoch: 2291 	Average Loss: -24.6929
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.5216

Learning rate: 7.734336888633826e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2292 [0/90000 (0%)]	Loss: -16.9350	Cost: 24.64s
Train Epoch: 2292 [20480/90000 (23%)]	Loss: -25.4020	Cost: 9.47s
Train Epoch: 2292 [40960/90000 (45%)]	Loss: -25.1878	Cost: 9.64s
Train Epoch: 2292 [61440/90000 (68%)]	Loss: -25.5759	Cost: 9.29s
Train Epoch: 2292 [81920/90000 (91%)]	Loss: -25.0114	Cost: 10.65s
Train Epoch: 2292 	Average Loss: -24.9027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.9402

Learning rate: 7.726687843533534e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2293 [0/90000 (0%)]	Loss: -16.9424	Cost: 25.08s
Train Epoch: 2293 [20480/90000 (23%)]	Loss: -25.1895	Cost: 9.38s
Train Epoch: 2293 [40960/90000 (45%)]	Loss: -24.9621	Cost: 9.35s
Train Epoch: 2293 [61440/90000 (68%)]	Loss: -25.4325	Cost: 9.35s
Train Epoch: 2293 [81920/90000 (91%)]	Loss: -25.1972	Cost: 10.14s
Train Epoch: 2293 	Average Loss: -24.7361
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.6221

Learning rate: 7.719040200726398e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2294 [0/90000 (0%)]	Loss: -17.6481	Cost: 25.11s
Train Epoch: 2294 [20480/90000 (23%)]	Loss: -25.7999	Cost: 9.49s
Train Epoch: 2294 [40960/90000 (45%)]	Loss: -25.1576	Cost: 9.41s
Train Epoch: 2294 [61440/90000 (68%)]	Loss: -25.6267	Cost: 9.38s
Train Epoch: 2294 [81920/90000 (91%)]	Loss: -25.3487	Cost: 10.35s
Train Epoch: 2294 	Average Loss: -25.0512
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.7083

Learning rate: 7.711393964929868e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2295 [0/90000 (0%)]	Loss: -16.7012	Cost: 25.12s
Train Epoch: 2295 [20480/90000 (23%)]	Loss: -25.8903	Cost: 9.35s
Train Epoch: 2295 [40960/90000 (45%)]	Loss: -25.6324	Cost: 9.58s
Train Epoch: 2295 [61440/90000 (68%)]	Loss: -25.8945	Cost: 9.13s
Train Epoch: 2295 [81920/90000 (91%)]	Loss: -25.6650	Cost: 10.64s
Train Epoch: 2295 	Average Loss: -25.2750
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.9570

Learning rate: 7.703749140860528e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2296 [0/90000 (0%)]	Loss: -17.6841	Cost: 25.33s
Train Epoch: 2296 [20480/90000 (23%)]	Loss: -26.1106	Cost: 9.34s
Train Epoch: 2296 [40960/90000 (45%)]	Loss: -25.7070	Cost: 9.63s
Train Epoch: 2296 [61440/90000 (68%)]	Loss: -25.9724	Cost: 9.28s
Train Epoch: 2296 [81920/90000 (91%)]	Loss: -25.7789	Cost: 10.49s
Train Epoch: 2296 	Average Loss: -25.4437
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.9864

Learning rate: 7.696105733234093e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2297 [0/90000 (0%)]	Loss: -18.5664	Cost: 26.34s
Train Epoch: 2297 [20480/90000 (23%)]	Loss: -26.1478	Cost: 9.49s
Train Epoch: 2297 [40960/90000 (45%)]	Loss: -25.9149	Cost: 10.03s
Train Epoch: 2297 [61440/90000 (68%)]	Loss: -25.9842	Cost: 9.24s
Train Epoch: 2297 [81920/90000 (91%)]	Loss: -25.6478	Cost: 11.15s
Train Epoch: 2297 	Average Loss: -25.4877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.8858

Learning rate: 7.688463746765392e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2298 [0/90000 (0%)]	Loss: -16.9569	Cost: 25.51s
Train Epoch: 2298 [20480/90000 (23%)]	Loss: -25.9972	Cost: 9.55s
Train Epoch: 2298 [40960/90000 (45%)]	Loss: -25.8362	Cost: 10.59s
Train Epoch: 2298 [61440/90000 (68%)]	Loss: -25.9849	Cost: 9.11s
Train Epoch: 2298 [81920/90000 (91%)]	Loss: -25.6511	Cost: 10.85s
Train Epoch: 2298 	Average Loss: -25.3814
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -18.8461

Learning rate: 7.680823186168396e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2299 [0/90000 (0%)]	Loss: -17.7244	Cost: 25.84s
Train Epoch: 2299 [20480/90000 (23%)]	Loss: -25.9356	Cost: 9.16s
Train Epoch: 2299 [40960/90000 (45%)]	Loss: -25.8950	Cost: 10.42s
Train Epoch: 2299 [61440/90000 (68%)]	Loss: -26.2912	Cost: 9.13s
Train Epoch: 2299 [81920/90000 (91%)]	Loss: -26.0063	Cost: 10.96s
Train Epoch: 2299 	Average Loss: -25.6324
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -19.2337

Learning rate: 7.673184056156178e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2300 [0/90000 (0%)]	Loss: -15.0647	Cost: 26.32s
Train Epoch: 2300 [20480/90000 (23%)]	Loss: -26.0756	Cost: 9.18s
Train Epoch: 2300 [40960/90000 (45%)]	Loss: -25.8097	Cost: 11.14s
Train Epoch: 2300 [61440/90000 (68%)]	Loss: -26.0750	Cost: 9.09s
Train Epoch: 2300 [81920/90000 (91%)]	Loss: -25.9232	Cost: 10.84s
Train Epoch: 2300 	Average Loss: -25.4567
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -19.2909

Saving model as model.pt_e2300 & waveforms_supplementary.hdf5_e2300
Stopping timer.
Training time (including validation): 217500.43528532982 seconds
Saving model
7212	Cost: 9.22s
Train Epoch: 2305 [61440/90000 (68%)]	Loss: -23.4699	Cost: 9.13s
Train Epoch: 2305 [81920/90000 (91%)]	Loss: -23.7717	Cost: 8.82s
Train Epoch: 2305 	Average Loss: -23.2057
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.7401

Learning rate: 0.00017490713583964734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2306 [0/90000 (0%)]	Loss: -17.6243	Cost: 24.49s
Train Epoch: 2306 [20480/90000 (23%)]	Loss: -24.0132	Cost: 9.35s
Train Epoch: 2306 [40960/90000 (45%)]	Loss: -23.7893	Cost: 9.28s
Train Epoch: 2306 [61440/90000 (68%)]	Loss: -23.6414	Cost: 9.48s
Train Epoch: 2306 [81920/90000 (91%)]	Loss: -23.5651	Cost: 8.76s
Train Epoch: 2306 	Average Loss: -23.3250
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.7514

Learning rate: 0.00017488631942764107
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2307 [0/90000 (0%)]	Loss: -16.5366	Cost: 24.34s
Train Epoch: 2307 [20480/90000 (23%)]	Loss: -23.8463	Cost: 9.41s
Train Epoch: 2307 [40960/90000 (45%)]	Loss: -23.5489	Cost: 9.31s
Train Epoch: 2307 [61440/90000 (68%)]	Loss: -23.5059	Cost: 9.17s
Train Epoch: 2307 [81920/90000 (91%)]	Loss: -23.5349	Cost: 8.80s
Train Epoch: 2307 	Average Loss: -23.1943
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -17.7408

Learning rate: 0.0001748654956246514
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2308 [0/90000 (0%)]	Loss: -17.0920	Cost: 25.12s
Train Epoch: 2308 [20480/90000 (23%)]	Loss: -23.8971	Cost: 9.29s
Train Epoch: 2308 [40960/90000 (45%)]	Loss: -23.7553	Cost: 9.32s
Train Epoch: 2308 [61440/90000 (68%)]	Loss: -23.8350	Cost: 9.17s
Train Epoch: 2308 [81920/90000 (91%)]	Loss: -23.5888	Cost: 9.16s
Train Epoch: 2308 	Average Loss: -23.3586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.

Stopping timer.
Training time (including validation): 250725.91465449333 seconds
Saving model
