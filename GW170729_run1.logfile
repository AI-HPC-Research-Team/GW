Nestedspace(activation='elu', apply_unconditional_transform=False, base_transform_type='rq-coupling', basis_dir='data/GW170729_sample_prior_basis/', batch_norm=True, batch_size=2048, bw_dstar=None, cuda=True, data_dir='data/GW170729_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, dropout_probability=0.0, epochs=10000, flow_lr=None, hidden_dims=512, kl_annealing=True, lr=0.0001, lr_anneal_method='cosine', lr_annealing=True, mixed_alpha=0.0, mode='train', model_dir='models/GW170729_sample_uniform_100basis_all_posterior_prior/', model_source='new', model_type='nde', nbins=8, nflows=15, nsample=100000, nsamples_target_event=50000, num_transform_blocks=10, output_freq=10, sampling_from='posterior', save=True, save_aux_filename='waveforms_supplementary.hdf5', save_model_name='model.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, tail_bound=1.0, truncate_basis=100)
Waveform directory data/GW170729_sample_prior_basis/
Model directory models/GW170729_sample_uniform_100basis_all_posterior_prior/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from posterior prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Detectors: ['H1', 'L1', 'V1']

Constructing model of type nde

Initial learning rate 0.0001
Using cosine LR annealing.

Model hyperparameters:
input_dim 	 15
num_flow_steps 	 15
context_dim 	 600
base_transform_kwargs
	 hidden_dim 	 512
	 num_transform_blocks 	 10
	 activation 	 elu
	 dropout_probability 	 0.0
	 batch_norm 	 True
	 num_bins 	 8
	 tail_bound 	 1.0
	 apply_unconditional_transform 	 False
	 base_transform_type 	 rq-coupling

Training for 10000 epochs
Starting timer
Learning rate: 0.0001
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 28.7111	Cost: 18.45s
Train Epoch: 1 [20480/90000 (23%)]	Loss: 21.8260	Cost: 6.12s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 21.1473	Cost: 8.25s
Train Epoch: 1 [61440/90000 (68%)]	Loss: 20.6578	Cost: 6.14s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 20.2973	Cost: 8.03s
Train Epoch: 1 	Average Loss: 21.7875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1444

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 9.999999753259892e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 20.0824	Cost: 20.86s
Train Epoch: 2 [20480/90000 (23%)]	Loss: 19.7930	Cost: 6.99s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 19.6204	Cost: 7.82s
Train Epoch: 2 [61440/90000 (68%)]	Loss: 19.4452	Cost: 6.37s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 19.2602	Cost: 6.15s
Train Epoch: 2 	Average Loss: 19.6025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2103

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 9.999999013039593e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 19.3642	Cost: 21.00s
Train Epoch: 3 [20480/90000 (23%)]	Loss: 18.9504	Cost: 6.26s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 18.7380	Cost: 8.27s
Train Epoch: 3 [61440/90000 (68%)]	Loss: 18.6985	Cost: 6.08s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 18.5069	Cost: 7.02s
Train Epoch: 3 	Average Loss: 18.7913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3671

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 9.999997779339173e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 18.3157	Cost: 19.80s
Train Epoch: 4 [20480/90000 (23%)]	Loss: 18.1563	Cost: 6.48s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 18.0344	Cost: 6.67s
Train Epoch: 4 [61440/90000 (68%)]	Loss: 17.8159	Cost: 6.69s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 17.7887	Cost: 7.39s
Train Epoch: 4 	Average Loss: 18.0036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6936

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 9.99999605215876e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 17.6342	Cost: 19.05s
Train Epoch: 5 [20480/90000 (23%)]	Loss: 17.4247	Cost: 6.26s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 17.4487	Cost: 8.64s
Train Epoch: 5 [61440/90000 (68%)]	Loss: 17.4355	Cost: 6.23s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 17.3454	Cost: 8.70s
Train Epoch: 5 	Average Loss: 17.4378
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2668

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 9.999993831498517e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 17.2192	Cost: 20.50s
Train Epoch: 6 [20480/90000 (23%)]	Loss: 17.1259	Cost: 6.68s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 16.9629	Cost: 9.28s
Train Epoch: 6 [61440/90000 (68%)]	Loss: 17.0637	Cost: 6.77s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 16.8065	Cost: 14.94s
Train Epoch: 6 	Average Loss: 17.0331
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7971

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 9.999991117358668e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 16.9012	Cost: 26.83s
Train Epoch: 7 [20480/90000 (23%)]	Loss: 16.7082	Cost: 9.10s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 16.5673	Cost: 12.69s
Train Epoch: 7 [61440/90000 (68%)]	Loss: 16.5576	Cost: 12.41s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 16.5498	Cost: 12.38s
Train Epoch: 7 	Average Loss: 16.6758
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5720

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 9.99998790973948e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 16.5777	Cost: 27.91s
Train Epoch: 8 [20480/90000 (23%)]	Loss: 16.3636	Cost: 16.17s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 16.3348	Cost: 14.53s
Train Epoch: 8 [61440/90000 (68%)]	Loss: 16.3956	Cost: 12.39s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 16.2945	Cost: 12.19s
Train Epoch: 8 	Average Loss: 16.3900
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3296

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 9.99998420864127e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 16.2254	Cost: 42.45s
Train Epoch: 9 [20480/90000 (23%)]	Loss: 16.1827	Cost: 13.96s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 16.0713	Cost: 12.02s
Train Epoch: 9 [61440/90000 (68%)]	Loss: 16.1352	Cost: 6.22s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 16.0667	Cost: 6.08s
Train Epoch: 9 	Average Loss: 16.1686
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1285

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 9.999980014064402e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 15.9454	Cost: 28.60s
Train Epoch: 10 [20480/90000 (23%)]	Loss: 15.8951	Cost: 12.41s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 15.8144	Cost: 10.24s
Train Epoch: 10 [61440/90000 (68%)]	Loss: 15.9034	Cost: 6.16s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 15.9627	Cost: 7.90s
Train Epoch: 10 	Average Loss: 15.9398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9419

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 9.999975326009292e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 15.8815	Cost: 25.17s
Train Epoch: 11 [20480/90000 (23%)]	Loss: 15.8163	Cost: 9.34s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 15.7887	Cost: 6.95s
Train Epoch: 11 [61440/90000 (68%)]	Loss: 15.7339	Cost: 6.10s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 15.7948	Cost: 7.59s
Train Epoch: 11 	Average Loss: 15.7774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6589

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 9.999970144476398e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 15.7210	Cost: 28.25s
Train Epoch: 12 [20480/90000 (23%)]	Loss: 15.5645	Cost: 12.42s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 15.5170	Cost: 11.01s
Train Epoch: 12 [61440/90000 (68%)]	Loss: 15.5672	Cost: 6.07s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 15.5620	Cost: 6.87s
Train Epoch: 12 	Average Loss: 15.5931
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5636

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 9.999964469466236e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 15.5623	Cost: 29.39s
Train Epoch: 13 [20480/90000 (23%)]	Loss: 15.4838	Cost: 10.41s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 15.4141	Cost: 6.29s
Train Epoch: 13 [61440/90000 (68%)]	Loss: 15.5482	Cost: 6.33s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 15.5052	Cost: 8.75s
Train Epoch: 13 	Average Loss: 15.4655
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3936

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Learning rate: 9.999958300979366e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 15.4970	Cost: 22.04s
Train Epoch: 14 [20480/90000 (23%)]	Loss: 15.3460	Cost: 8.95s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 15.2933	Cost: 9.18s
Train Epoch: 14 [61440/90000 (68%)]	Loss: 15.3972	Cost: 8.91s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 15.1968	Cost: 8.43s
Train Epoch: 14 	Average Loss: 15.3314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2696

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Learning rate: 9.999951639016395e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 15.2975	Cost: 20.32s
Train Epoch: 15 [20480/90000 (23%)]	Loss: 15.1529	Cost: 9.23s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 15.0943	Cost: 10.68s
Train Epoch: 15 [61440/90000 (68%)]	Loss: 15.1692	Cost: 11.78s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 15.1394	Cost: 12.50s
Train Epoch: 15 	Average Loss: 15.1956
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1775

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Learning rate: 9.999944483577981e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 15.1008	Cost: 26.39s
Train Epoch: 16 [20480/90000 (23%)]	Loss: 15.2019	Cost: 11.35s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 14.9693	Cost: 12.89s
Train Epoch: 16 [61440/90000 (68%)]	Loss: 15.0430	Cost: 12.22s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 15.0011	Cost: 12.17s
Train Epoch: 16 	Average Loss: 15.0841
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0613

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Learning rate: 9.99993683466483e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 15.0399	Cost: 24.10s
Train Epoch: 17 [20480/90000 (23%)]	Loss: 14.8649	Cost: 11.23s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 14.8849	Cost: 12.94s
Train Epoch: 17 [61440/90000 (68%)]	Loss: 14.9145	Cost: 12.52s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 15.0020	Cost: 6.64s
Train Epoch: 17 	Average Loss: 14.9826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9272

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Learning rate: 9.999928692277696e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 14.9701	Cost: 32.15s
Train Epoch: 18 [20480/90000 (23%)]	Loss: 14.7547	Cost: 14.02s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 14.8155	Cost: 12.99s
Train Epoch: 18 [61440/90000 (68%)]	Loss: 14.8453	Cost: 6.90s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 14.8996	Cost: 6.79s
Train Epoch: 18 	Average Loss: 14.8811
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.8448

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Learning rate: 9.999920056417385e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 14.7959	Cost: 22.34s
Train Epoch: 19 [20480/90000 (23%)]	Loss: 14.8634	Cost: 10.03s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 14.7229	Cost: 10.61s
Train Epoch: 19 [61440/90000 (68%)]	Loss: 14.8010	Cost: 7.90s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 14.8670	Cost: 8.96s
Train Epoch: 19 	Average Loss: 14.7741
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7006

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Learning rate: 9.999910927084749e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 14.7732	Cost: 25.06s
Train Epoch: 20 [20480/90000 (23%)]	Loss: 14.7101	Cost: 8.23s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 14.5139	Cost: 9.24s
Train Epoch: 20 [61440/90000 (68%)]	Loss: 14.5922	Cost: 8.51s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 14.6468	Cost: 8.73s
Train Epoch: 20 	Average Loss: 14.6699
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6004

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Learning rate: 9.999901304280687e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 14.5830	Cost: 21.41s
Train Epoch: 21 [20480/90000 (23%)]	Loss: 14.4539	Cost: 9.07s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 14.5166	Cost: 9.00s
Train Epoch: 21 [61440/90000 (68%)]	Loss: 14.6090	Cost: 9.00s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 14.6056	Cost: 7.84s
Train Epoch: 21 	Average Loss: 14.5558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5271

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Learning rate: 9.99989118800615e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 14.4947	Cost: 20.65s
Train Epoch: 22 [20480/90000 (23%)]	Loss: 14.6177	Cost: 6.92s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 14.3766	Cost: 6.97s
Train Epoch: 22 [61440/90000 (68%)]	Loss: 14.4792	Cost: 7.44s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 14.4571	Cost: 13.47s
Train Epoch: 22 	Average Loss: 14.4648
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4210

Saving model as e22_model.pt & e22_waveforms_supplementary.hdf5
Learning rate: 9.999880578262136e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 14.3317	Cost: 23.80s
Train Epoch: 23 [20480/90000 (23%)]	Loss: 14.3053	Cost: 10.89s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 14.2807	Cost: 15.49s
Train Epoch: 23 [61440/90000 (68%)]	Loss: 14.3486	Cost: 14.15s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 14.3817	Cost: 12.22s
Train Epoch: 23 	Average Loss: 14.3684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3443

Saving model as e23_model.pt & e23_waveforms_supplementary.hdf5
Learning rate: 9.999869475049693e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 14.3887	Cost: 41.70s
Train Epoch: 24 [20480/90000 (23%)]	Loss: 14.2687	Cost: 14.25s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 14.3161	Cost: 12.68s
Train Epoch: 24 [61440/90000 (68%)]	Loss: 14.3559	Cost: 11.32s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 14.1867	Cost: 6.25s
Train Epoch: 24 	Average Loss: 14.2913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1998

Saving model as e24_model.pt & e24_waveforms_supplementary.hdf5
Learning rate: 9.999857878369916e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 14.2012	Cost: 27.65s
Train Epoch: 25 [20480/90000 (23%)]	Loss: 14.1833	Cost: 13.67s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 14.3652	Cost: 12.28s
Train Epoch: 25 [61440/90000 (68%)]	Loss: 14.1911	Cost: 7.80s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 14.1903	Cost: 6.32s
Train Epoch: 25 	Average Loss: 14.1799
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0870

Saving model as e25_model.pt & e25_waveforms_supplementary.hdf5
Learning rate: 9.99984578822395e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 14.0277	Cost: 22.40s
Train Epoch: 26 [20480/90000 (23%)]	Loss: 14.0830	Cost: 12.13s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 14.0038	Cost: 6.85s
Train Epoch: 26 [61440/90000 (68%)]	Loss: 14.1345	Cost: 6.24s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 14.0394	Cost: 7.90s
Train Epoch: 26 	Average Loss: 14.1017
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9991

Saving model as e26_model.pt & e26_waveforms_supplementary.hdf5
Learning rate: 9.999833204612988e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 13.9924	Cost: 25.61s
Train Epoch: 27 [20480/90000 (23%)]	Loss: 13.9972	Cost: 11.13s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 13.9748	Cost: 6.61s
Train Epoch: 27 [61440/90000 (68%)]	Loss: 14.1096	Cost: 6.51s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 13.9180	Cost: 9.15s
Train Epoch: 27 	Average Loss: 14.0219
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0193

Learning rate: 9.999820127538271e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 13.9180	Cost: 21.17s
Train Epoch: 28 [20480/90000 (23%)]	Loss: 13.7820	Cost: 9.87s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 13.8127	Cost: 9.65s
Train Epoch: 28 [61440/90000 (68%)]	Loss: 13.8862	Cost: 8.89s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 13.8375	Cost: 8.74s
Train Epoch: 28 	Average Loss: 13.9087
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8840

Saving model as e28_model.pt & e28_waveforms_supplementary.hdf5
Learning rate: 9.999806557001093e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 13.7888	Cost: 23.35s
Train Epoch: 29 [20480/90000 (23%)]	Loss: 13.7847	Cost: 11.57s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 13.6496	Cost: 10.11s
Train Epoch: 29 [61440/90000 (68%)]	Loss: 13.8436	Cost: 8.86s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 13.9172	Cost: 7.32s
Train Epoch: 29 	Average Loss: 13.8320
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7838

Saving model as e29_model.pt & e29_waveforms_supplementary.hdf5
Learning rate: 9.99979249300279e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 13.7507	Cost: 19.51s
Train Epoch: 30 [20480/90000 (23%)]	Loss: 13.8064	Cost: 6.42s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 13.6511	Cost: 8.75s
Train Epoch: 30 [61440/90000 (68%)]	Loss: 13.7684	Cost: 8.37s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 13.7978	Cost: 14.68s
Train Epoch: 30 	Average Loss: 13.7559
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7099

Saving model as e30_model.pt & e30_waveforms_supplementary.hdf5
Learning rate: 9.99977793554475e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 13.6576	Cost: 23.26s
Train Epoch: 31 [20480/90000 (23%)]	Loss: 13.6480	Cost: 13.03s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 13.7160	Cost: 12.49s
Train Epoch: 31 [61440/90000 (68%)]	Loss: 13.8342	Cost: 12.43s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 13.5512	Cost: 11.86s
Train Epoch: 31 	Average Loss: 13.6600
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6506

Saving model as e31_model.pt & e31_waveforms_supplementary.hdf5
Learning rate: 9.999762884628413e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 13.6309	Cost: 25.73s
Train Epoch: 32 [20480/90000 (23%)]	Loss: 13.5022	Cost: 11.34s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 13.5745	Cost: 12.53s
Train Epoch: 32 [61440/90000 (68%)]	Loss: 13.6661	Cost: 12.23s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 13.5272	Cost: 8.81s
Train Epoch: 32 	Average Loss: 13.6034
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5139

Saving model as e32_model.pt & e32_waveforms_supplementary.hdf5
Learning rate: 9.999747340255259e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 13.5522	Cost: 40.33s
Train Epoch: 33 [20480/90000 (23%)]	Loss: 13.5796	Cost: 11.98s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 13.4760	Cost: 7.76s
Train Epoch: 33 [61440/90000 (68%)]	Loss: 13.3820	Cost: 6.12s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 13.4098	Cost: 7.51s
Train Epoch: 33 	Average Loss: 13.4835
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4190

Saving model as e33_model.pt & e33_waveforms_supplementary.hdf5
Learning rate: 9.999731302426829e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 13.4776	Cost: 37.34s
Train Epoch: 34 [20480/90000 (23%)]	Loss: 13.3553	Cost: 9.63s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 13.3395	Cost: 6.25s
Train Epoch: 34 [61440/90000 (68%)]	Loss: 13.3653	Cost: 6.52s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 13.3407	Cost: 8.59s
Train Epoch: 34 	Average Loss: 13.3946
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3047

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Learning rate: 9.999714771144701e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 13.3235	Cost: 27.63s
Train Epoch: 35 [20480/90000 (23%)]	Loss: 13.3267	Cost: 9.85s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 13.2943	Cost: 6.30s
Train Epoch: 35 [61440/90000 (68%)]	Loss: 13.2933	Cost: 6.17s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 13.2364	Cost: 9.16s
Train Epoch: 35 	Average Loss: 13.3186
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2792

Saving model as e35_model.pt & e35_waveforms_supplementary.hdf5
Learning rate: 9.999697746410508e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 13.1922	Cost: 22.28s
Train Epoch: 36 [20480/90000 (23%)]	Loss: 13.2074	Cost: 9.00s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 13.1343	Cost: 9.20s
Train Epoch: 36 [61440/90000 (68%)]	Loss: 13.3121	Cost: 8.96s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 13.1677	Cost: 9.06s
Train Epoch: 36 	Average Loss: 13.2275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1901

Saving model as e36_model.pt & e36_waveforms_supplementary.hdf5
Learning rate: 9.99968022822593e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 13.2999	Cost: 29.50s
Train Epoch: 37 [20480/90000 (23%)]	Loss: 13.0889	Cost: 8.04s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 13.0901	Cost: 12.54s
Train Epoch: 37 [61440/90000 (68%)]	Loss: 13.1674	Cost: 12.14s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 13.1562	Cost: 12.36s
Train Epoch: 37 	Average Loss: 13.1601
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1072

Saving model as e37_model.pt & e37_waveforms_supplementary.hdf5
Learning rate: 9.999662216592697e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 13.0142	Cost: 24.79s
Train Epoch: 38 [20480/90000 (23%)]	Loss: 13.0328	Cost: 13.44s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 12.9566	Cost: 12.48s
Train Epoch: 38 [61440/90000 (68%)]	Loss: 13.0254	Cost: 12.07s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 13.0648	Cost: 9.91s
Train Epoch: 38 	Average Loss: 13.0547
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0457

Saving model as e38_model.pt & e38_waveforms_supplementary.hdf5
Learning rate: 9.999643711512586e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 13.1756	Cost: 31.15s
Train Epoch: 39 [20480/90000 (23%)]	Loss: 12.9901	Cost: 10.11s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 12.8851	Cost: 9.78s
Train Epoch: 39 [61440/90000 (68%)]	Loss: 12.9353	Cost: 6.19s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 13.0218	Cost: 6.97s
Train Epoch: 39 	Average Loss: 13.0125
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9660

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Learning rate: 9.999624712987422e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 12.9550	Cost: 28.09s
Train Epoch: 40 [20480/90000 (23%)]	Loss: 12.8922	Cost: 13.71s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 13.0322	Cost: 9.68s
Train Epoch: 40 [61440/90000 (68%)]	Loss: 12.8852	Cost: 6.35s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 12.7248	Cost: 7.87s
Train Epoch: 40 	Average Loss: 12.9176
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8835

Saving model as e40_model.pt & e40_waveforms_supplementary.hdf5
Learning rate: 9.999605221019082e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 12.9452	Cost: 22.45s
Train Epoch: 41 [20480/90000 (23%)]	Loss: 12.7554	Cost: 12.36s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 12.7533	Cost: 9.62s
Train Epoch: 41 [61440/90000 (68%)]	Loss: 12.9191	Cost: 8.48s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 12.8082	Cost: 8.90s
Train Epoch: 41 	Average Loss: 12.8533
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8015

Saving model as e41_model.pt & e41_waveforms_supplementary.hdf5
Learning rate: 9.999585235609488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 12.8746	Cost: 23.19s
Train Epoch: 42 [20480/90000 (23%)]	Loss: 12.9824	Cost: 8.13s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 12.7034	Cost: 9.79s
Train Epoch: 42 [61440/90000 (68%)]	Loss: 12.8028	Cost: 8.66s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 12.7684	Cost: 8.38s
Train Epoch: 42 	Average Loss: 12.7751
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7447

Saving model as e42_model.pt & e42_waveforms_supplementary.hdf5
Learning rate: 9.999564756760615e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 12.8539	Cost: 22.73s
Train Epoch: 43 [20480/90000 (23%)]	Loss: 12.7310	Cost: 7.00s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 12.7647	Cost: 9.01s
Train Epoch: 43 [61440/90000 (68%)]	Loss: 12.7431	Cost: 8.76s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 12.6201	Cost: 8.67s
Train Epoch: 43 	Average Loss: 12.7120
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7083

Saving model as e43_model.pt & e43_waveforms_supplementary.hdf5
Learning rate: 9.999543784474483e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 12.4760	Cost: 23.20s
Train Epoch: 44 [20480/90000 (23%)]	Loss: 12.5990	Cost: 9.28s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 12.6020	Cost: 9.00s
Train Epoch: 44 [61440/90000 (68%)]	Loss: 12.7155	Cost: 7.00s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 12.5654	Cost: 5.95s
Train Epoch: 44 	Average Loss: 12.6258
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5427

Saving model as e44_model.pt & e44_waveforms_supplementary.hdf5
Learning rate: 9.99952231875316e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 12.4907	Cost: 20.56s
Train Epoch: 45 [20480/90000 (23%)]	Loss: 12.5562	Cost: 9.58s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 12.5188	Cost: 11.07s
Train Epoch: 45 [61440/90000 (68%)]	Loss: 12.4773	Cost: 11.00s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 12.4122	Cost: 13.37s
Train Epoch: 45 	Average Loss: 12.5617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5350

Saving model as e45_model.pt & e45_waveforms_supplementary.hdf5
Learning rate: 9.999500359598768e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 12.5251	Cost: 19.56s
Train Epoch: 46 [20480/90000 (23%)]	Loss: 12.6208	Cost: 9.63s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 12.4142	Cost: 13.06s
Train Epoch: 46 [61440/90000 (68%)]	Loss: 12.4695	Cost: 13.46s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 12.4165	Cost: 13.24s
Train Epoch: 46 	Average Loss: 12.4809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4831

Saving model as e46_model.pt & e46_waveforms_supplementary.hdf5
Learning rate: 9.999477907013472e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 12.4327	Cost: 27.07s
Train Epoch: 47 [20480/90000 (23%)]	Loss: 12.3349	Cost: 15.14s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 12.4137	Cost: 13.88s
Train Epoch: 47 [61440/90000 (68%)]	Loss: 12.4128	Cost: 12.05s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 12.3554	Cost: 12.20s
Train Epoch: 47 	Average Loss: 12.3903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3267

Saving model as e47_model.pt & e47_waveforms_supplementary.hdf5
Learning rate: 9.999454960999486e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 12.5127	Cost: 35.14s
Train Epoch: 48 [20480/90000 (23%)]	Loss: 12.2556	Cost: 12.11s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 12.3239	Cost: 11.19s
Train Epoch: 48 [61440/90000 (68%)]	Loss: 12.2526	Cost: 6.36s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 12.2776	Cost: 7.37s
Train Epoch: 48 	Average Loss: 12.3548
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4268

Learning rate: 9.99943152155908e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 12.3728	Cost: 25.39s
Train Epoch: 49 [20480/90000 (23%)]	Loss: 12.2449	Cost: 9.85s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 12.2105	Cost: 6.44s
Train Epoch: 49 [61440/90000 (68%)]	Loss: 12.2331	Cost: 8.03s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 12.3720	Cost: 8.84s
Train Epoch: 49 	Average Loss: 12.2981
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2334

Saving model as e49_model.pt & e49_waveforms_supplementary.hdf5
Learning rate: 9.999407588694566e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 12.2543	Cost: 21.10s
Train Epoch: 50 [20480/90000 (23%)]	Loss: 12.1724	Cost: 9.93s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 12.1829	Cost: 10.45s
Train Epoch: 50 [61440/90000 (68%)]	Loss: 12.2958	Cost: 9.07s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 12.1795	Cost: 8.72s
Train Epoch: 50 	Average Loss: 12.2341
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2167

Saving model as e50_model.pt & e50_waveforms_supplementary.hdf5
Learning rate: 9.999383162408302e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 12.0806	Cost: 24.24s
Train Epoch: 51 [20480/90000 (23%)]	Loss: 12.2581	Cost: 10.46s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 12.1702	Cost: 9.78s
Train Epoch: 51 [61440/90000 (68%)]	Loss: 12.0709	Cost: 8.93s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 12.1673	Cost: 8.82s
Train Epoch: 51 	Average Loss: 12.1689
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1036

Saving model as e51_model.pt & e51_waveforms_supplementary.hdf5
Learning rate: 9.999358242702702e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 12.2283	Cost: 20.52s
Train Epoch: 52 [20480/90000 (23%)]	Loss: 11.8900	Cost: 8.92s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 12.0620	Cost: 8.77s
Train Epoch: 52 [61440/90000 (68%)]	Loss: 12.1630	Cost: 6.79s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 12.3070	Cost: 6.19s
Train Epoch: 52 	Average Loss: 12.1140
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0946

Saving model as e52_model.pt & e52_waveforms_supplementary.hdf5
Learning rate: 9.999332829580225e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 12.0972	Cost: 21.23s
Train Epoch: 53 [20480/90000 (23%)]	Loss: 11.9000	Cost: 7.48s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 12.0575	Cost: 12.14s
Train Epoch: 53 [61440/90000 (68%)]	Loss: 12.1286	Cost: 12.53s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 11.9892	Cost: 12.42s
Train Epoch: 53 	Average Loss: 12.0373
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0228

Saving model as e53_model.pt & e53_waveforms_supplementary.hdf5
Learning rate: 9.99930692304338e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 11.9773	Cost: 25.85s
Train Epoch: 54 [20480/90000 (23%)]	Loss: 12.1040	Cost: 14.73s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 11.9912	Cost: 13.71s
Train Epoch: 54 [61440/90000 (68%)]	Loss: 11.9484	Cost: 12.12s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 12.1371	Cost: 12.27s
Train Epoch: 54 	Average Loss: 11.9966
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0349

Learning rate: 9.999280523094723e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 12.1308	Cost: 32.86s
Train Epoch: 55 [20480/90000 (23%)]	Loss: 12.0952	Cost: 10.18s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 11.8880	Cost: 12.37s
Train Epoch: 55 [61440/90000 (68%)]	Loss: 11.9090	Cost: 12.11s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 11.9209	Cost: 7.00s
Train Epoch: 55 	Average Loss: 11.9303
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9226

Saving model as e55_model.pt & e55_waveforms_supplementary.hdf5
Learning rate: 9.999253629736859e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 12.1543	Cost: 26.50s
Train Epoch: 56 [20480/90000 (23%)]	Loss: 11.7892	Cost: 9.75s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 11.8757	Cost: 6.56s
Train Epoch: 56 [61440/90000 (68%)]	Loss: 11.8909	Cost: 6.82s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 11.8948	Cost: 9.44s
Train Epoch: 56 	Average Loss: 11.8748
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8501

Saving model as e56_model.pt & e56_waveforms_supplementary.hdf5
Learning rate: 9.999226242972442e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 11.8233	Cost: 23.88s
Train Epoch: 57 [20480/90000 (23%)]	Loss: 11.7957	Cost: 10.30s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 11.7978	Cost: 11.05s
Train Epoch: 57 [61440/90000 (68%)]	Loss: 11.8026	Cost: 9.01s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 11.8193	Cost: 8.81s
Train Epoch: 57 	Average Loss: 11.7923
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6988

Saving model as e57_model.pt & e57_waveforms_supplementary.hdf5
Learning rate: 9.999198362804177e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 11.7490	Cost: 25.86s
Train Epoch: 58 [20480/90000 (23%)]	Loss: 11.7079	Cost: 11.98s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 11.7042	Cost: 10.84s
Train Epoch: 58 [61440/90000 (68%)]	Loss: 11.8788	Cost: 8.66s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 11.6544	Cost: 6.37s
Train Epoch: 58 	Average Loss: 11.7762
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7084

Learning rate: 9.999169989234814e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 11.6953	Cost: 20.74s
Train Epoch: 59 [20480/90000 (23%)]	Loss: 11.6299	Cost: 7.21s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 11.6065	Cost: 7.09s
Train Epoch: 59 [61440/90000 (68%)]	Loss: 11.6710	Cost: 7.53s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 11.6177	Cost: 8.21s
Train Epoch: 59 	Average Loss: 11.7038
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6266

Saving model as e59_model.pt & e59_waveforms_supplementary.hdf5
Learning rate: 9.999141122267153e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 11.5772	Cost: 18.01s
Train Epoch: 60 [20480/90000 (23%)]	Loss: 11.6294	Cost: 8.64s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 11.6842	Cost: 12.49s
Train Epoch: 60 [61440/90000 (68%)]	Loss: 11.7853	Cost: 12.40s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 11.6425	Cost: 12.37s
Train Epoch: 60 	Average Loss: 11.6643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6452

Learning rate: 9.999111761904044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 11.6902	Cost: 24.36s
Train Epoch: 61 [20480/90000 (23%)]	Loss: 11.6013	Cost: 12.04s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 11.6769	Cost: 14.24s
Train Epoch: 61 [61440/90000 (68%)]	Loss: 11.6577	Cost: 12.60s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 11.5906	Cost: 12.23s
Train Epoch: 61 	Average Loss: 11.6006
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5652

Saving model as e61_model.pt & e61_waveforms_supplementary.hdf5
Learning rate: 9.999081908148385e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 11.6063	Cost: 43.81s
Train Epoch: 62 [20480/90000 (23%)]	Loss: 11.4040	Cost: 12.50s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 11.4696	Cost: 12.31s
Train Epoch: 62 [61440/90000 (68%)]	Loss: 11.5110	Cost: 10.19s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 11.4607	Cost: 6.33s
Train Epoch: 62 	Average Loss: 11.5340
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5878

Learning rate: 9.999051561003123e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 11.5615	Cost: 32.78s
Train Epoch: 63 [20480/90000 (23%)]	Loss: 11.5016	Cost: 11.98s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 11.4444	Cost: 6.82s
Train Epoch: 63 [61440/90000 (68%)]	Loss: 11.5716	Cost: 6.14s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 11.5329	Cost: 8.64s
Train Epoch: 63 	Average Loss: 11.5036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5095

Saving model as e63_model.pt & e63_waveforms_supplementary.hdf5
Learning rate: 9.999020720471253e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 11.3978	Cost: 22.50s
Train Epoch: 64 [20480/90000 (23%)]	Loss: 11.4416	Cost: 7.74s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 11.4551	Cost: 9.87s
Train Epoch: 64 [61440/90000 (68%)]	Loss: 11.4793	Cost: 9.35s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 11.4746	Cost: 9.00s
Train Epoch: 64 	Average Loss: 11.4671
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4155

Saving model as e64_model.pt & e64_waveforms_supplementary.hdf5
Learning rate: 9.998989386555816e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 11.3558	Cost: 25.16s
Train Epoch: 65 [20480/90000 (23%)]	Loss: 11.3169	Cost: 11.06s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 11.3596	Cost: 8.79s
Train Epoch: 65 [61440/90000 (68%)]	Loss: 11.4141	Cost: 6.33s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 11.4139	Cost: 6.46s
Train Epoch: 65 	Average Loss: 11.4396
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3793

Saving model as e65_model.pt & e65_waveforms_supplementary.hdf5
Learning rate: 9.998957559259906e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 11.4762	Cost: 20.85s
Train Epoch: 66 [20480/90000 (23%)]	Loss: 11.4006	Cost: 7.56s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 11.4268	Cost: 8.13s
Train Epoch: 66 [61440/90000 (68%)]	Loss: 11.4230	Cost: 12.58s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 11.3624	Cost: 12.45s
Train Epoch: 66 	Average Loss: 11.3924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3665

Saving model as e66_model.pt & e66_waveforms_supplementary.hdf5
Learning rate: 9.998925238586665e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 11.1729	Cost: 21.46s
Train Epoch: 67 [20480/90000 (23%)]	Loss: 11.2885	Cost: 13.24s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 11.3473	Cost: 13.18s
Train Epoch: 67 [61440/90000 (68%)]	Loss: 11.3246	Cost: 12.09s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 11.4308	Cost: 12.34s
Train Epoch: 67 	Average Loss: 11.3472
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3230

Saving model as e67_model.pt & e67_waveforms_supplementary.hdf5
Learning rate: 9.998892424539283e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 11.2935	Cost: 24.13s
Train Epoch: 68 [20480/90000 (23%)]	Loss: 11.0938	Cost: 11.88s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 11.1830	Cost: 12.07s
Train Epoch: 68 [61440/90000 (68%)]	Loss: 11.3333	Cost: 12.34s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 11.2154	Cost: 6.68s
Train Epoch: 68 	Average Loss: 11.2874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3225

Saving model as e68_model.pt & e68_waveforms_supplementary.hdf5
Learning rate: 9.998859117121e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 11.0742	Cost: 39.99s
Train Epoch: 69 [20480/90000 (23%)]	Loss: 11.1007	Cost: 9.95s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 11.2195	Cost: 8.86s
Train Epoch: 69 [61440/90000 (68%)]	Loss: 11.1175	Cost: 6.18s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 11.3004	Cost: 7.31s
Train Epoch: 69 	Average Loss: 11.2200
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2607

Saving model as e69_model.pt & e69_waveforms_supplementary.hdf5
Learning rate: 9.998825316335099e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 11.2649	Cost: 24.54s
Train Epoch: 70 [20480/90000 (23%)]	Loss: 11.1699	Cost: 7.18s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 11.2496	Cost: 9.56s
Train Epoch: 70 [61440/90000 (68%)]	Loss: 11.1422	Cost: 8.76s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 11.2515	Cost: 8.62s
Train Epoch: 70 	Average Loss: 11.2024
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1623

Saving model as e70_model.pt & e70_waveforms_supplementary.hdf5
Learning rate: 9.99879102218492e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 11.2556	Cost: 20.54s
Train Epoch: 71 [20480/90000 (23%)]	Loss: 11.0209	Cost: 7.42s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 11.0965	Cost: 9.12s
Train Epoch: 71 [61440/90000 (68%)]	Loss: 11.2726	Cost: 8.71s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 11.1524	Cost: 8.80s
Train Epoch: 71 	Average Loss: 11.1468
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1395

Saving model as e71_model.pt & e71_waveforms_supplementary.hdf5
Learning rate: 9.998756234673847e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 11.2256	Cost: 21.13s
Train Epoch: 72 [20480/90000 (23%)]	Loss: 11.0641	Cost: 9.13s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 11.2845	Cost: 8.07s
Train Epoch: 72 [61440/90000 (68%)]	Loss: 11.0225	Cost: 6.26s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 11.1694	Cost: 7.86s
Train Epoch: 72 	Average Loss: 11.1515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1189

Saving model as e72_model.pt & e72_waveforms_supplementary.hdf5
Learning rate: 9.998720953805312e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 11.0618	Cost: 18.73s
Train Epoch: 73 [20480/90000 (23%)]	Loss: 11.0445	Cost: 9.28s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 10.9792	Cost: 10.96s
Train Epoch: 73 [61440/90000 (68%)]	Loss: 11.0171	Cost: 13.08s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 11.2163	Cost: 12.55s
Train Epoch: 73 	Average Loss: 11.0700
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1793

Learning rate: 9.998685179582798e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 11.0017	Cost: 40.26s
Train Epoch: 74 [20480/90000 (23%)]	Loss: 11.0975	Cost: 13.51s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 11.0586	Cost: 12.63s
Train Epoch: 74 [61440/90000 (68%)]	Loss: 11.0216	Cost: 12.07s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 10.9247	Cost: 12.27s
Train Epoch: 74 	Average Loss: 11.0602
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0375

Saving model as e74_model.pt & e74_waveforms_supplementary.hdf5
Learning rate: 9.998648912009835e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 11.2604	Cost: 27.07s
Train Epoch: 75 [20480/90000 (23%)]	Loss: 10.9254	Cost: 12.03s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 11.0081	Cost: 12.61s
Train Epoch: 75 [61440/90000 (68%)]	Loss: 11.0136	Cost: 12.08s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 10.9911	Cost: 9.29s
Train Epoch: 75 	Average Loss: 11.0082
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0612

Learning rate: 9.998612151090003e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 11.1180	Cost: 25.12s
Train Epoch: 76 [20480/90000 (23%)]	Loss: 10.8044	Cost: 13.45s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 10.9261	Cost: 12.42s
Train Epoch: 76 [61440/90000 (68%)]	Loss: 10.8930	Cost: 9.00s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 11.0505	Cost: 6.69s
Train Epoch: 76 	Average Loss: 10.9672
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0692

Learning rate: 9.998574896826931e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 11.0430	Cost: 24.75s
Train Epoch: 77 [20480/90000 (23%)]	Loss: 11.0698	Cost: 6.39s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 10.8651	Cost: 7.97s
Train Epoch: 77 [61440/90000 (68%)]	Loss: 10.8942	Cost: 8.42s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 10.8854	Cost: 9.51s
Train Epoch: 77 	Average Loss: 10.9272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9015

Saving model as e77_model.pt & e77_waveforms_supplementary.hdf5
Learning rate: 9.998537149224293e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 11.0135	Cost: 20.09s
Train Epoch: 78 [20480/90000 (23%)]	Loss: 10.8397	Cost: 8.50s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 10.8325	Cost: 9.03s
Train Epoch: 78 [61440/90000 (68%)]	Loss: 10.9632	Cost: 8.78s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 11.0242	Cost: 8.71s
Train Epoch: 78 	Average Loss: 10.8986
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9254

Learning rate: 9.998498908285819e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 10.9892	Cost: 24.53s
Train Epoch: 79 [20480/90000 (23%)]	Loss: 10.9175	Cost: 8.55s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 10.9510	Cost: 8.96s
Train Epoch: 79 [61440/90000 (68%)]	Loss: 10.8859	Cost: 8.70s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 10.9013	Cost: 8.56s
Train Epoch: 79 	Average Loss: 10.8664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9112

Learning rate: 9.998460174015279e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 10.7747	Cost: 30.66s
Train Epoch: 80 [20480/90000 (23%)]	Loss: 10.7404	Cost: 8.90s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 10.8664	Cost: 8.87s
Train Epoch: 80 [61440/90000 (68%)]	Loss: 10.8402	Cost: 7.69s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 10.8779	Cost: 5.78s
Train Epoch: 80 	Average Loss: 10.8344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8214

Saving model as e80_model.pt & e80_waveforms_supplementary.hdf5
Learning rate: 9.998420946416499e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 10.8748	Cost: 22.56s
Train Epoch: 81 [20480/90000 (23%)]	Loss: 10.8296	Cost: 9.97s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 10.7626	Cost: 12.37s
Train Epoch: 81 [61440/90000 (68%)]	Loss: 10.8671	Cost: 13.36s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 10.7419	Cost: 11.85s
Train Epoch: 81 	Average Loss: 10.7908
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8520

Learning rate: 9.998381225493349e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 10.7639	Cost: 22.67s
Train Epoch: 82 [20480/90000 (23%)]	Loss: 10.6877	Cost: 9.77s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 10.7626	Cost: 14.87s
Train Epoch: 82 [61440/90000 (68%)]	Loss: 10.7434	Cost: 13.20s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 10.8177	Cost: 12.46s
Train Epoch: 82 	Average Loss: 10.7566
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7380

Saving model as e82_model.pt & e82_waveforms_supplementary.hdf5
Learning rate: 9.998341011249749e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 10.7117	Cost: 32.69s
Train Epoch: 83 [20480/90000 (23%)]	Loss: 10.7765	Cost: 12.07s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 10.6146	Cost: 12.34s
Train Epoch: 83 [61440/90000 (68%)]	Loss: 10.7277	Cost: 12.07s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 10.6735	Cost: 6.41s
Train Epoch: 83 	Average Loss: 10.7096
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7788

Learning rate: 9.99830030368967e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 10.7965	Cost: 25.76s
Train Epoch: 84 [20480/90000 (23%)]	Loss: 10.6743	Cost: 11.38s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 10.5817	Cost: 8.40s
Train Epoch: 84 [61440/90000 (68%)]	Loss: 10.6152	Cost: 6.10s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 10.6247	Cost: 7.62s
Train Epoch: 84 	Average Loss: 10.6768
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6249

Saving model as e84_model.pt & e84_waveforms_supplementary.hdf5
Learning rate: 9.998259102817127e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 10.6918	Cost: 27.42s
Train Epoch: 85 [20480/90000 (23%)]	Loss: 10.6180	Cost: 8.73s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 10.6419	Cost: 6.32s
Train Epoch: 85 [61440/90000 (68%)]	Loss: 10.7908	Cost: 6.97s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 10.7703	Cost: 8.40s
Train Epoch: 85 	Average Loss: 10.6558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6412

Learning rate: 9.99821740863619e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 10.7359	Cost: 20.10s
Train Epoch: 86 [20480/90000 (23%)]	Loss: 10.4578	Cost: 9.08s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 10.5325	Cost: 8.80s
Train Epoch: 86 [61440/90000 (68%)]	Loss: 10.7255	Cost: 9.16s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 10.5924	Cost: 9.29s
Train Epoch: 86 	Average Loss: 10.6157
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6634

Learning rate: 9.99817522115097e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 10.7591	Cost: 20.36s
Train Epoch: 87 [20480/90000 (23%)]	Loss: 10.7042	Cost: 9.42s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 10.6663	Cost: 11.41s
Train Epoch: 87 [61440/90000 (68%)]	Loss: 10.6984	Cost: 6.64s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 10.5820	Cost: 6.62s
Train Epoch: 87 	Average Loss: 10.5974
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5867

Saving model as e87_model.pt & e87_waveforms_supplementary.hdf5
Learning rate: 9.998132540365634e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 10.5533	Cost: 22.72s
Train Epoch: 88 [20480/90000 (23%)]	Loss: 10.4648	Cost: 10.50s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 10.4324	Cost: 9.58s
Train Epoch: 88 [61440/90000 (68%)]	Loss: 10.6367	Cost: 12.48s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 10.6242	Cost: 12.45s
Train Epoch: 88 	Average Loss: 10.5565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5349

Saving model as e88_model.pt & e88_waveforms_supplementary.hdf5
Learning rate: 9.998089366284391e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 10.6825	Cost: 22.93s
Train Epoch: 89 [20480/90000 (23%)]	Loss: 10.4642	Cost: 13.56s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 10.4951	Cost: 12.62s
Train Epoch: 89 [61440/90000 (68%)]	Loss: 10.5535	Cost: 12.51s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 10.3828	Cost: 11.97s
Train Epoch: 89 	Average Loss: 10.5232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5425

Learning rate: 9.998045698911504e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 10.5785	Cost: 28.21s
Train Epoch: 90 [20480/90000 (23%)]	Loss: 10.4912	Cost: 12.38s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 10.4144	Cost: 12.29s
Train Epoch: 90 [61440/90000 (68%)]	Loss: 10.5699	Cost: 6.42s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 10.5347	Cost: 6.32s
Train Epoch: 90 	Average Loss: 10.4799
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5293

Saving model as e90_model.pt & e90_waveforms_supplementary.hdf5
Learning rate: 9.998001538251281e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 10.2838	Cost: 33.95s
Train Epoch: 91 [20480/90000 (23%)]	Loss: 10.4938	Cost: 12.32s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 10.4767	Cost: 9.34s
Train Epoch: 91 [61440/90000 (68%)]	Loss: 10.4674	Cost: 6.28s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 10.4971	Cost: 7.50s
Train Epoch: 91 	Average Loss: 10.4561
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5702

Learning rate: 9.997956884308085e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 10.5471	Cost: 22.43s
Train Epoch: 92 [20480/90000 (23%)]	Loss: 10.3467	Cost: 9.85s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 10.4839	Cost: 12.16s
Train Epoch: 92 [61440/90000 (68%)]	Loss: 10.5079	Cost: 7.88s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 10.4533	Cost: 6.67s
Train Epoch: 92 	Average Loss: 10.4321
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5345

Learning rate: 9.99791173708632e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 10.4496	Cost: 23.45s
Train Epoch: 93 [20480/90000 (23%)]	Loss: 10.4051	Cost: 12.12s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 10.4309	Cost: 8.07s
Train Epoch: 93 [61440/90000 (68%)]	Loss: 10.5337	Cost: 6.32s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 10.5281	Cost: 7.51s
Train Epoch: 93 	Average Loss: 10.4554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.4070

Saving model as e93_model.pt & e93_waveforms_supplementary.hdf5
Learning rate: 9.997866096590442e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 10.2959	Cost: 33.85s
Train Epoch: 94 [20480/90000 (23%)]	Loss: 10.3871	Cost: 6.79s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 10.4570	Cost: 9.36s
Train Epoch: 94 [61440/90000 (68%)]	Loss: 10.5315	Cost: 8.54s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 10.4136	Cost: 8.45s
Train Epoch: 94 	Average Loss: 10.4144
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.4416

Learning rate: 9.997819962824954e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 10.3759	Cost: 30.66s
Train Epoch: 95 [20480/90000 (23%)]	Loss: 10.2658	Cost: 9.94s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 10.3911	Cost: 8.87s
Train Epoch: 95 [61440/90000 (68%)]	Loss: 10.3579	Cost: 8.65s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 10.2092	Cost: 8.56s
Train Epoch: 95 	Average Loss: 10.3618
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3045

Saving model as e95_model.pt & e95_waveforms_supplementary.hdf5
Learning rate: 9.997773335794414e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 10.5583	Cost: 18.85s
Train Epoch: 96 [20480/90000 (23%)]	Loss: 10.3628	Cost: 10.38s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 10.2348	Cost: 6.40s
Train Epoch: 96 [61440/90000 (68%)]	Loss: 10.3407	Cost: 7.99s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 10.2963	Cost: 9.33s
Train Epoch: 96 	Average Loss: 10.3362
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.4169

Learning rate: 9.99772621550342e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 10.3582	Cost: 19.44s
Train Epoch: 97 [20480/90000 (23%)]	Loss: 10.2634	Cost: 8.06s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 10.2853	Cost: 10.52s
Train Epoch: 97 [61440/90000 (68%)]	Loss: 10.2998	Cost: 12.60s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 10.4314	Cost: 12.65s
Train Epoch: 97 	Average Loss: 10.3173
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2799

Saving model as e97_model.pt & e97_waveforms_supplementary.hdf5
Learning rate: 9.997678601956623e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 10.3585	Cost: 24.80s
Train Epoch: 98 [20480/90000 (23%)]	Loss: 10.2740	Cost: 14.06s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 10.3143	Cost: 13.79s
Train Epoch: 98 [61440/90000 (68%)]	Loss: 10.4369	Cost: 12.25s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 10.1755	Cost: 10.63s
Train Epoch: 98 	Average Loss: 10.3015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3594

Learning rate: 9.997630495158724e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 10.5202	Cost: 39.19s
Train Epoch: 99 [20480/90000 (23%)]	Loss: 10.2513	Cost: 12.68s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 10.4253	Cost: 12.20s
Train Epoch: 99 [61440/90000 (68%)]	Loss: 10.1849	Cost: 7.83s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 10.2873	Cost: 6.11s
Train Epoch: 99 	Average Loss: 10.3081
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3687

Learning rate: 9.997581895114468e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 10.3580	Cost: 36.75s
Train Epoch: 100 [20480/90000 (23%)]	Loss: 10.2276	Cost: 6.31s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 10.1721	Cost: 9.62s
Train Epoch: 100 [61440/90000 (68%)]	Loss: 10.4291	Cost: 8.52s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 10.3666	Cost: 8.36s
Train Epoch: 100 	Average Loss: 10.2405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2195

Saving model as e100_model.pt & e100_waveforms_supplementary.hdf5
Learning rate: 9.997532801828656e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 10.3854	Cost: 20.37s
Train Epoch: 101 [20480/90000 (23%)]	Loss: 10.1241	Cost: 7.85s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 10.2944	Cost: 9.34s
Train Epoch: 101 [61440/90000 (68%)]	Loss: 10.1625	Cost: 9.34s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 10.2572	Cost: 9.20s
Train Epoch: 101 	Average Loss: 10.2493
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2729

Learning rate: 9.997483215306129e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 10.2364	Cost: 19.93s
Train Epoch: 102 [20480/90000 (23%)]	Loss: 10.0025	Cost: 9.09s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 10.2480	Cost: 8.68s
Train Epoch: 102 [61440/90000 (68%)]	Loss: 10.2644	Cost: 6.46s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 10.2595	Cost: 9.26s
Train Epoch: 102 	Average Loss: 10.1894
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2136

Saving model as e102_model.pt & e102_waveforms_supplementary.hdf5
Learning rate: 9.997433135551784e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 10.3363	Cost: 25.04s
Train Epoch: 103 [20480/90000 (23%)]	Loss: 10.1969	Cost: 10.58s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 10.2704	Cost: 13.96s
Train Epoch: 103 [61440/90000 (68%)]	Loss: 10.2751	Cost: 12.53s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 10.2575	Cost: 12.39s
Train Epoch: 103 	Average Loss: 10.1966
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2606

Learning rate: 9.99738256257056e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 10.4043	Cost: 23.89s
Train Epoch: 104 [20480/90000 (23%)]	Loss: 10.1790	Cost: 13.00s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 10.0632	Cost: 12.72s
Train Epoch: 104 [61440/90000 (68%)]	Loss: 10.1891	Cost: 12.10s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 10.0822	Cost: 12.42s
Train Epoch: 104 	Average Loss: 10.1837
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2385

Learning rate: 9.997331496367453e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 10.2115	Cost: 25.75s
Train Epoch: 105 [20480/90000 (23%)]	Loss: 10.1172	Cost: 12.53s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 10.1466	Cost: 12.74s
Train Epoch: 105 [61440/90000 (68%)]	Loss: 10.1031	Cost: 10.35s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 10.2923	Cost: 6.63s
Train Epoch: 105 	Average Loss: 10.1531
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0942

Saving model as e105_model.pt & e105_waveforms_supplementary.hdf5
Learning rate: 9.997279936947499e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 10.1724	Cost: 37.97s
Train Epoch: 106 [20480/90000 (23%)]	Loss: 10.1411	Cost: 13.01s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 10.0161	Cost: 7.79s
Train Epoch: 106 [61440/90000 (68%)]	Loss: 10.0591	Cost: 6.47s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 10.1323	Cost: 8.61s
Train Epoch: 106 	Average Loss: 10.1256
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1768

Learning rate: 9.997227884315788e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 10.2048	Cost: 25.36s
Train Epoch: 107 [20480/90000 (23%)]	Loss: 10.0946	Cost: 10.76s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 10.1575	Cost: 10.19s
Train Epoch: 107 [61440/90000 (68%)]	Loss: 10.2027	Cost: 8.43s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 9.9784	Cost: 8.64s
Train Epoch: 107 	Average Loss: 10.1136
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1808

Learning rate: 9.997175338477459e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 10.1371	Cost: 23.44s
Train Epoch: 108 [20480/90000 (23%)]	Loss: 10.0166	Cost: 6.85s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 10.1320	Cost: 9.75s
Train Epoch: 108 [61440/90000 (68%)]	Loss: 10.0349	Cost: 8.64s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 10.0217	Cost: 8.79s
Train Epoch: 108 	Average Loss: 10.1208
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0971

Learning rate: 9.997122299437696e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 10.1565	Cost: 21.93s
Train Epoch: 109 [20480/90000 (23%)]	Loss: 9.9978	Cost: 6.63s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 10.1702	Cost: 9.21s
Train Epoch: 109 [61440/90000 (68%)]	Loss: 10.0890	Cost: 8.95s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 10.0695	Cost: 8.45s
Train Epoch: 109 	Average Loss: 10.0649
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0560

Saving model as e109_model.pt & e109_waveforms_supplementary.hdf5
Learning rate: 9.997068767201736e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 10.1753	Cost: 22.58s
Train Epoch: 110 [20480/90000 (23%)]	Loss: 10.0925	Cost: 8.97s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 10.0065	Cost: 6.32s
Train Epoch: 110 [61440/90000 (68%)]	Loss: 9.9685	Cost: 6.48s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 9.9896	Cost: 6.45s
Train Epoch: 110 	Average Loss: 10.0434
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9971

Saving model as e110_model.pt & e110_waveforms_supplementary.hdf5
Learning rate: 9.997014741774862e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 10.0805	Cost: 23.44s
Train Epoch: 111 [20480/90000 (23%)]	Loss: 10.0133	Cost: 9.91s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 10.1301	Cost: 17.58s
Train Epoch: 111 [61440/90000 (68%)]	Loss: 10.0593	Cost: 12.53s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 10.0779	Cost: 12.17s
Train Epoch: 111 	Average Loss: 10.0493
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9994

Learning rate: 9.996960223162402e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 10.1339	Cost: 27.93s
Train Epoch: 112 [20480/90000 (23%)]	Loss: 9.9311	Cost: 14.78s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 10.0575	Cost: 14.52s
Train Epoch: 112 [61440/90000 (68%)]	Loss: 9.9979	Cost: 12.26s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 10.0516	Cost: 11.39s
Train Epoch: 112 	Average Loss: 10.0003
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0446

Learning rate: 9.996905211369744e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 9.9103	Cost: 41.84s
Train Epoch: 113 [20480/90000 (23%)]	Loss: 9.9556	Cost: 12.41s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 9.9627	Cost: 11.97s
Train Epoch: 113 [61440/90000 (68%)]	Loss: 10.0151	Cost: 6.36s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 10.0005	Cost: 6.40s
Train Epoch: 113 	Average Loss: 9.9726
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0684

Learning rate: 9.996849706402311e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 9.9690	Cost: 27.97s
Train Epoch: 114 [20480/90000 (23%)]	Loss: 9.9868	Cost: 9.79s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 9.9395	Cost: 11.43s
Train Epoch: 114 [61440/90000 (68%)]	Loss: 10.0613	Cost: 6.16s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 9.9278	Cost: 7.21s
Train Epoch: 114 	Average Loss: 9.9583
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0093

Learning rate: 9.996793708265583e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 9.8210	Cost: 31.17s
Train Epoch: 115 [20480/90000 (23%)]	Loss: 9.9454	Cost: 6.31s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 9.9732	Cost: 8.75s
Train Epoch: 115 [61440/90000 (68%)]	Loss: 9.9478	Cost: 8.71s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 9.9304	Cost: 8.46s
Train Epoch: 115 	Average Loss: 9.9414
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0282

Learning rate: 9.996737216965088e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 10.1047	Cost: 22.39s
Train Epoch: 116 [20480/90000 (23%)]	Loss: 9.9861	Cost: 7.86s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 9.9962	Cost: 9.24s
Train Epoch: 116 [61440/90000 (68%)]	Loss: 10.0950	Cost: 9.39s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 9.9581	Cost: 9.02s
Train Epoch: 116 	Average Loss: 9.9491
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0101

Learning rate: 9.9966802325064e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 10.0640	Cost: 21.24s
Train Epoch: 117 [20480/90000 (23%)]	Loss: 9.8559	Cost: 11.22s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 9.7452	Cost: 9.33s
Train Epoch: 117 [61440/90000 (68%)]	Loss: 9.8624	Cost: 9.10s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 9.9045	Cost: 8.14s
Train Epoch: 117 	Average Loss: 9.9290
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0098

Learning rate: 9.996622754895145e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 9.9713	Cost: 23.80s
Train Epoch: 118 [20480/90000 (23%)]	Loss: 9.9094	Cost: 10.76s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 9.9424	Cost: 14.48s
Train Epoch: 118 [61440/90000 (68%)]	Loss: 9.7958	Cost: 12.43s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 9.8690	Cost: 12.40s
Train Epoch: 118 	Average Loss: 9.8917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8664

Saving model as e118_model.pt & e118_waveforms_supplementary.hdf5
Learning rate: 9.996564784136994e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 9.8518	Cost: 23.53s
Train Epoch: 119 [20480/90000 (23%)]	Loss: 9.6802	Cost: 14.68s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 9.8325	Cost: 12.48s
Train Epoch: 119 [61440/90000 (68%)]	Loss: 9.9766	Cost: 12.14s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 9.7200	Cost: 10.56s
Train Epoch: 119 	Average Loss: 9.8806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8908

Learning rate: 9.99650632023767e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 9.8098	Cost: 28.49s
Train Epoch: 120 [20480/90000 (23%)]	Loss: 9.7792	Cost: 10.79s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 9.8508	Cost: 9.14s
Train Epoch: 120 [61440/90000 (68%)]	Loss: 9.8509	Cost: 6.38s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 9.8664	Cost: 7.26s
Train Epoch: 120 	Average Loss: 9.8774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8917

Learning rate: 9.996447363202941e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 9.9031	Cost: 35.84s
Train Epoch: 121 [20480/90000 (23%)]	Loss: 9.9790	Cost: 11.16s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 9.9659	Cost: 9.71s
Train Epoch: 121 [61440/90000 (68%)]	Loss: 9.9029	Cost: 6.81s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 9.8391	Cost: 8.95s
Train Epoch: 121 	Average Loss: 9.8573
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8436

Saving model as e121_model.pt & e121_waveforms_supplementary.hdf5
Learning rate: 9.996387913038628e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 9.8158	Cost: 23.21s
Train Epoch: 122 [20480/90000 (23%)]	Loss: 9.9062	Cost: 10.55s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 9.8582	Cost: 11.27s
Train Epoch: 122 [61440/90000 (68%)]	Loss: 10.0957	Cost: 8.82s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 9.8965	Cost: 8.61s
Train Epoch: 122 	Average Loss: 9.8443
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8659

Learning rate: 9.996327969750598e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 9.7515	Cost: 20.87s
Train Epoch: 123 [20480/90000 (23%)]	Loss: 9.8131	Cost: 9.48s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 9.7100	Cost: 8.13s
Train Epoch: 123 [61440/90000 (68%)]	Loss: 9.7392	Cost: 6.10s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 9.8989	Cost: 6.37s
Train Epoch: 123 	Average Loss: 9.8264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8221

Saving model as e123_model.pt & e123_waveforms_supplementary.hdf5
Learning rate: 9.996267533344767e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 9.9101	Cost: 20.61s
Train Epoch: 124 [20480/90000 (23%)]	Loss: 9.6560	Cost: 8.36s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 9.8296	Cost: 11.61s
Train Epoch: 124 [61440/90000 (68%)]	Loss: 9.7284	Cost: 12.21s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 9.7846	Cost: 12.55s
Train Epoch: 124 	Average Loss: 9.7923
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8846

Learning rate: 9.996206603827099e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 9.9344	Cost: 22.39s
Train Epoch: 125 [20480/90000 (23%)]	Loss: 9.8362	Cost: 14.23s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 9.8307	Cost: 14.31s
Train Epoch: 125 [61440/90000 (68%)]	Loss: 9.8963	Cost: 12.31s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 9.7000	Cost: 12.25s
Train Epoch: 125 	Average Loss: 9.8308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8220

Saving model as e125_model.pt & e125_waveforms_supplementary.hdf5
Learning rate: 9.99614518120361e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 9.9080	Cost: 33.83s
Train Epoch: 126 [20480/90000 (23%)]	Loss: 9.7320	Cost: 12.12s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 9.6991	Cost: 12.31s
Train Epoch: 126 [61440/90000 (68%)]	Loss: 9.7582	Cost: 11.45s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 9.6782	Cost: 6.45s
Train Epoch: 126 	Average Loss: 9.7858
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8196

Saving model as e126_model.pt & e126_waveforms_supplementary.hdf5
Learning rate: 9.99608326548036e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 9.9850	Cost: 21.15s
Train Epoch: 127 [20480/90000 (23%)]	Loss: 9.7006	Cost: 7.50s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 9.6608	Cost: 8.99s
Train Epoch: 127 [61440/90000 (68%)]	Loss: 9.7856	Cost: 9.47s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 9.7789	Cost: 8.94s
Train Epoch: 127 	Average Loss: 9.7563
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7622

Saving model as e127_model.pt & e127_waveforms_supplementary.hdf5
Learning rate: 9.996020856663458e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 9.7606	Cost: 29.16s
Train Epoch: 128 [20480/90000 (23%)]	Loss: 9.7653	Cost: 8.77s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 9.6022	Cost: 6.74s
Train Epoch: 128 [61440/90000 (68%)]	Loss: 9.8373	Cost: 6.99s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 9.8732	Cost: 7.17s
Train Epoch: 128 	Average Loss: 9.7446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7882

Learning rate: 9.995957954759067e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 9.5893	Cost: 22.91s
Train Epoch: 129 [20480/90000 (23%)]	Loss: 9.8000	Cost: 9.97s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 9.8434	Cost: 9.47s
Train Epoch: 129 [61440/90000 (68%)]	Loss: 9.7301	Cost: 9.91s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 9.6869	Cost: 14.03s
Train Epoch: 129 	Average Loss: 9.7435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8700

Learning rate: 9.995894559773395e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 9.8616	Cost: 20.85s
Train Epoch: 130 [20480/90000 (23%)]	Loss: 9.9065	Cost: 6.83s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 9.9510	Cost: 11.82s
Train Epoch: 130 [61440/90000 (68%)]	Loss: 9.7663	Cost: 12.87s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 9.8389	Cost: 12.36s
Train Epoch: 130 	Average Loss: 9.7599
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7039

Saving model as e130_model.pt & e130_waveforms_supplementary.hdf5
Learning rate: 9.995830671712695e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 9.6100	Cost: 24.87s
Train Epoch: 131 [20480/90000 (23%)]	Loss: 9.6392	Cost: 12.96s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 9.7153	Cost: 12.45s
Train Epoch: 131 [61440/90000 (68%)]	Loss: 9.7762	Cost: 12.31s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 9.8256	Cost: 11.72s
Train Epoch: 131 	Average Loss: 9.6852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7908

Learning rate: 9.995766290583277e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 9.7985	Cost: 23.31s
Train Epoch: 132 [20480/90000 (23%)]	Loss: 9.5252	Cost: 12.53s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 9.7867	Cost: 11.20s
Train Epoch: 132 [61440/90000 (68%)]	Loss: 9.7021	Cost: 6.41s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 9.7176	Cost: 6.61s
Train Epoch: 132 	Average Loss: 9.6771
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7965

Learning rate: 9.995701416391493e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 9.6948	Cost: 27.18s
Train Epoch: 133 [20480/90000 (23%)]	Loss: 9.6805	Cost: 13.62s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 9.7176	Cost: 12.60s
Train Epoch: 133 [61440/90000 (68%)]	Loss: 9.7416	Cost: 6.39s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 9.5671	Cost: 6.25s
Train Epoch: 133 	Average Loss: 9.6937
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7366

Learning rate: 9.995636049143747e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 9.8659	Cost: 24.37s
Train Epoch: 134 [20480/90000 (23%)]	Loss: 9.7162	Cost: 11.07s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 9.6252	Cost: 12.62s
Train Epoch: 134 [61440/90000 (68%)]	Loss: 9.6339	Cost: 6.75s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 9.6049	Cost: 6.47s
Train Epoch: 134 	Average Loss: 9.6782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7458

Learning rate: 9.995570188846488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 9.8638	Cost: 23.24s
Train Epoch: 135 [20480/90000 (23%)]	Loss: 9.6623	Cost: 7.94s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 9.6885	Cost: 12.21s
Train Epoch: 135 [61440/90000 (68%)]	Loss: 9.6984	Cost: 6.35s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 9.7764	Cost: 6.24s
Train Epoch: 135 	Average Loss: 9.6409
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6471

Saving model as e135_model.pt & e135_waveforms_supplementary.hdf5
Learning rate: 9.99550383550622e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 9.7066	Cost: 34.73s
Train Epoch: 136 [20480/90000 (23%)]	Loss: 9.5732	Cost: 9.68s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 9.5481	Cost: 6.54s
Train Epoch: 136 [61440/90000 (68%)]	Loss: 9.7146	Cost: 6.30s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 9.4851	Cost: 8.90s
Train Epoch: 136 	Average Loss: 9.6223
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6056

Saving model as e136_model.pt & e136_waveforms_supplementary.hdf5
Learning rate: 9.995436989129488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 9.6563	Cost: 20.37s
Train Epoch: 137 [20480/90000 (23%)]	Loss: 9.5677	Cost: 10.28s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 9.6286	Cost: 11.54s
Train Epoch: 137 [61440/90000 (68%)]	Loss: 9.7137	Cost: 8.99s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 9.4913	Cost: 8.74s
Train Epoch: 137 	Average Loss: 9.6208
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6210

Learning rate: 9.99536964972289e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 9.5959	Cost: 23.65s
Train Epoch: 138 [20480/90000 (23%)]	Loss: 9.4325	Cost: 8.30s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 9.5189	Cost: 6.25s
Train Epoch: 138 [61440/90000 (68%)]	Loss: 9.5608	Cost: 6.30s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 9.6953	Cost: 6.69s
Train Epoch: 138 	Average Loss: 9.5975
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6989

Learning rate: 9.995301817293077e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 9.8491	Cost: 18.00s
Train Epoch: 139 [20480/90000 (23%)]	Loss: 9.5463	Cost: 7.32s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 9.6313	Cost: 10.16s
Train Epoch: 139 [61440/90000 (68%)]	Loss: 9.5930	Cost: 8.20s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 9.6220	Cost: 13.48s
Train Epoch: 139 	Average Loss: 9.5882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6656

Learning rate: 9.995233491846737e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 9.7036	Cost: 25.65s
Train Epoch: 140 [20480/90000 (23%)]	Loss: 9.6962	Cost: 7.92s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 9.4426	Cost: 13.35s
Train Epoch: 140 [61440/90000 (68%)]	Loss: 9.5387	Cost: 12.48s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 9.4554	Cost: 12.47s
Train Epoch: 140 	Average Loss: 9.5638
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6514

Learning rate: 9.995164673390618e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 9.6427	Cost: 32.56s
Train Epoch: 141 [20480/90000 (23%)]	Loss: 9.4779	Cost: 15.35s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 9.4981	Cost: 14.06s
Train Epoch: 141 [61440/90000 (68%)]	Loss: 9.6766	Cost: 12.08s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 9.4142	Cost: 10.08s
Train Epoch: 141 	Average Loss: 9.5326
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6211

Learning rate: 9.995095361931511e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 9.7547	Cost: 41.40s
Train Epoch: 142 [20480/90000 (23%)]	Loss: 9.5844	Cost: 12.71s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 9.5801	Cost: 11.44s
Train Epoch: 142 [61440/90000 (68%)]	Loss: 9.7301	Cost: 6.31s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 9.5713	Cost: 6.38s
Train Epoch: 142 	Average Loss: 9.5454
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6392

Learning rate: 9.995025557476254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 9.6086	Cost: 36.22s
Train Epoch: 143 [20480/90000 (23%)]	Loss: 9.3495	Cost: 14.07s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 9.5902	Cost: 11.78s
Train Epoch: 143 [61440/90000 (68%)]	Loss: 9.6340	Cost: 10.42s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 9.7007	Cost: 9.64s
Train Epoch: 143 	Average Loss: 9.5479
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6954

Learning rate: 9.99495526003174e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 9.7099	Cost: 80.80s
Train Epoch: 144 [20480/90000 (23%)]	Loss: 9.3954	Cost: 13.04s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 9.6206	Cost: 15.08s
Train Epoch: 144 [61440/90000 (68%)]	Loss: 9.4614	Cost: 13.54s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 9.3830	Cost: 13.87s
Train Epoch: 144 	Average Loss: 9.5239
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5835

Saving model as e144_model.pt & e144_waveforms_supplementary.hdf5
Learning rate: 9.994884469604905e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 9.6026	Cost: 73.95s
Train Epoch: 145 [20480/90000 (23%)]	Loss: 9.5149	Cost: 18.09s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 9.5349	Cost: 18.84s
Train Epoch: 145 [61440/90000 (68%)]	Loss: 9.5047	Cost: 13.91s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 9.5216	Cost: 23.30s
Train Epoch: 145 	Average Loss: 9.5061
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5532

Saving model as e145_model.pt & e145_waveforms_supplementary.hdf5
Learning rate: 9.994813186202739e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 9.6564	Cost: 20.03s
Train Epoch: 146 [20480/90000 (23%)]	Loss: 9.4457	Cost: 9.09s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 9.5347	Cost: 10.99s
Train Epoch: 146 [61440/90000 (68%)]	Loss: 9.6152	Cost: 10.15s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 9.4271	Cost: 12.50s
Train Epoch: 146 	Average Loss: 9.5044
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5586

Learning rate: 9.994741409832273e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 9.5287	Cost: 22.31s
Train Epoch: 147 [20480/90000 (23%)]	Loss: 9.5680	Cost: 8.57s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 9.4688	Cost: 13.67s
Train Epoch: 147 [61440/90000 (68%)]	Loss: 9.5463	Cost: 13.57s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 9.5889	Cost: 12.51s
Train Epoch: 147 	Average Loss: 9.4832
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5927

Learning rate: 9.994669140500594e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 9.6028	Cost: 27.07s
Train Epoch: 148 [20480/90000 (23%)]	Loss: 9.4849	Cost: 15.20s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 9.4729	Cost: 13.96s
Train Epoch: 148 [61440/90000 (68%)]	Loss: 9.6441	Cost: 12.17s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 9.5087	Cost: 12.11s
Train Epoch: 148 	Average Loss: 9.4720
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4970

Saving model as e148_model.pt & e148_waveforms_supplementary.hdf5
Learning rate: 9.994596378214833e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 9.3952	Cost: 29.19s
Train Epoch: 149 [20480/90000 (23%)]	Loss: 9.3864	Cost: 10.74s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 9.5372	Cost: 12.31s
Train Epoch: 149 [61440/90000 (68%)]	Loss: 9.4745	Cost: 12.05s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 9.4071	Cost: 7.52s
Train Epoch: 149 	Average Loss: 9.4559
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5912

Learning rate: 9.994523122982173e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 9.6670	Cost: 30.57s
Train Epoch: 150 [20480/90000 (23%)]	Loss: 9.5210	Cost: 12.52s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 9.3732	Cost: 12.43s
Train Epoch: 150 [61440/90000 (68%)]	Loss: 9.3834	Cost: 8.54s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 9.3135	Cost: 6.36s
Train Epoch: 150 	Average Loss: 9.4620
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5341

Learning rate: 9.994449374809844e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 9.4601	Cost: 32.18s
Train Epoch: 151 [20480/90000 (23%)]	Loss: 9.4592	Cost: 7.00s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 9.3438	Cost: 13.22s
Train Epoch: 151 [61440/90000 (68%)]	Loss: 9.2620	Cost: 7.78s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 9.5377	Cost: 7.11s
Train Epoch: 151 	Average Loss: 9.4133
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4502

Saving model as e151_model.pt & e151_waveforms_supplementary.hdf5
Learning rate: 9.994375133705122e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 9.4093	Cost: 23.71s
Train Epoch: 152 [20480/90000 (23%)]	Loss: 9.4823	Cost: 10.49s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 9.4088	Cost: 9.49s
Train Epoch: 152 [61440/90000 (68%)]	Loss: 9.4811	Cost: 7.17s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 9.4717	Cost: 8.09s
Train Epoch: 152 	Average Loss: 9.4125
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4816

Learning rate: 9.994300399675336e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 9.6322	Cost: 20.43s
Train Epoch: 153 [20480/90000 (23%)]	Loss: 9.2279	Cost: 7.24s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 9.3487	Cost: 11.51s
Train Epoch: 153 [61440/90000 (68%)]	Loss: 9.3769	Cost: 8.88s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 9.4159	Cost: 8.71s
Train Epoch: 153 	Average Loss: 9.3939
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5118

Learning rate: 9.994225172727863e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 9.5715	Cost: 26.16s
Train Epoch: 154 [20480/90000 (23%)]	Loss: 9.3098	Cost: 9.41s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 9.2275	Cost: 8.86s
Train Epoch: 154 [61440/90000 (68%)]	Loss: 9.3456	Cost: 8.61s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 9.3743	Cost: 8.82s
Train Epoch: 154 	Average Loss: 9.3996
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4588

Learning rate: 9.994149452870126e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 9.5149	Cost: 29.46s
Train Epoch: 155 [20480/90000 (23%)]	Loss: 9.3145	Cost: 9.34s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 9.4479	Cost: 9.12s
Train Epoch: 155 [61440/90000 (68%)]	Loss: 9.3421	Cost: 8.68s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 9.3992	Cost: 8.54s
Train Epoch: 155 	Average Loss: 9.3754
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4265

Saving model as e155_model.pt & e155_waveforms_supplementary.hdf5
Learning rate: 9.9940732401096e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 9.4572	Cost: 21.20s
Train Epoch: 156 [20480/90000 (23%)]	Loss: 9.3278	Cost: 7.43s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 9.3253	Cost: 10.12s
Train Epoch: 156 [61440/90000 (68%)]	Loss: 9.3799	Cost: 9.78s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 9.4034	Cost: 12.33s
Train Epoch: 156 	Average Loss: 9.3654
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4303

Learning rate: 9.993996534453805e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 9.4195	Cost: 22.57s
Train Epoch: 157 [20480/90000 (23%)]	Loss: 9.2625	Cost: 8.14s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 9.4037	Cost: 13.09s
Train Epoch: 157 [61440/90000 (68%)]	Loss: 9.3328	Cost: 13.59s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 9.5123	Cost: 12.86s
Train Epoch: 157 	Average Loss: 9.3461
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4654

Learning rate: 9.993919335910311e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 9.5114	Cost: 27.91s
Train Epoch: 158 [20480/90000 (23%)]	Loss: 9.3829	Cost: 14.89s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 9.3084	Cost: 13.70s
Train Epoch: 158 [61440/90000 (68%)]	Loss: 9.2845	Cost: 12.18s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 9.2402	Cost: 11.85s
Train Epoch: 158 	Average Loss: 9.3127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3798

Saving model as e158_model.pt & e158_waveforms_supplementary.hdf5
Learning rate: 9.993841644486739e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 9.4110	Cost: 34.86s
Train Epoch: 159 [20480/90000 (23%)]	Loss: 9.2971	Cost: 12.13s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 9.2996	Cost: 9.63s
Train Epoch: 159 [61440/90000 (68%)]	Loss: 9.3778	Cost: 6.06s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 9.2974	Cost: 7.41s
Train Epoch: 159 	Average Loss: 9.3157
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4454

Learning rate: 9.993763460190757e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 9.3291	Cost: 29.22s
Train Epoch: 160 [20480/90000 (23%)]	Loss: 9.3951	Cost: 7.66s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 9.2641	Cost: 7.06s
Train Epoch: 160 [61440/90000 (68%)]	Loss: 9.4102	Cost: 6.91s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 9.2418	Cost: 8.77s
Train Epoch: 160 	Average Loss: 9.3252
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4315

Learning rate: 9.993684783030081e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 9.4024	Cost: 23.39s
Train Epoch: 161 [20480/90000 (23%)]	Loss: 9.2239	Cost: 7.60s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 9.2506	Cost: 8.67s
Train Epoch: 161 [61440/90000 (68%)]	Loss: 9.2623	Cost: 8.93s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 9.1907	Cost: 8.99s
Train Epoch: 161 	Average Loss: 9.2902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3381

Saving model as e161_model.pt & e161_waveforms_supplementary.hdf5
Learning rate: 9.993605613012475e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 9.3737	Cost: 28.63s
Train Epoch: 162 [20480/90000 (23%)]	Loss: 9.2271	Cost: 10.50s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 9.3413	Cost: 10.32s
Train Epoch: 162 [61440/90000 (68%)]	Loss: 9.2712	Cost: 9.10s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 9.3816	Cost: 12.17s
Train Epoch: 162 	Average Loss: 9.2995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3612

Learning rate: 9.993525950145754e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 9.4796	Cost: 25.60s
Train Epoch: 163 [20480/90000 (23%)]	Loss: 9.1852	Cost: 8.82s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 9.2342	Cost: 13.93s
Train Epoch: 163 [61440/90000 (68%)]	Loss: 9.2109	Cost: 13.16s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 9.1248	Cost: 12.35s
Train Epoch: 163 	Average Loss: 9.2783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3250

Saving model as e163_model.pt & e163_waveforms_supplementary.hdf5
Learning rate: 9.993445794437781e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 9.4870	Cost: 33.95s
Train Epoch: 164 [20480/90000 (23%)]	Loss: 9.3106	Cost: 12.54s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 9.1827	Cost: 12.57s
Train Epoch: 164 [61440/90000 (68%)]	Loss: 9.1473	Cost: 12.35s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 9.3270	Cost: 8.29s
Train Epoch: 164 	Average Loss: 9.2737
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3212

Saving model as e164_model.pt & e164_waveforms_supplementary.hdf5
Learning rate: 9.993365145896465e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 9.4281	Cost: 23.94s
Train Epoch: 165 [20480/90000 (23%)]	Loss: 9.2223	Cost: 11.84s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 9.2103	Cost: 6.82s
Train Epoch: 165 [61440/90000 (68%)]	Loss: 9.1908	Cost: 6.72s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 9.0881	Cost: 8.70s
Train Epoch: 165 	Average Loss: 9.2553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3226

Learning rate: 9.993284004529768e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 9.4414	Cost: 27.87s
Train Epoch: 166 [20480/90000 (23%)]	Loss: 9.1617	Cost: 12.90s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 9.3193	Cost: 8.89s
Train Epoch: 166 [61440/90000 (68%)]	Loss: 9.1716	Cost: 6.36s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 9.2673	Cost: 7.21s
Train Epoch: 166 	Average Loss: 9.2505
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3430

Learning rate: 9.993202370345697e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 9.3858	Cost: 22.25s
Train Epoch: 167 [20480/90000 (23%)]	Loss: 9.2998	Cost: 13.60s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 9.2666	Cost: 9.69s
Train Epoch: 167 [61440/90000 (68%)]	Loss: 9.2096	Cost: 8.94s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 9.0196	Cost: 9.02s
Train Epoch: 167 	Average Loss: 9.2334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3700

Learning rate: 9.993120243352309e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 9.3220	Cost: 23.21s
Train Epoch: 168 [20480/90000 (23%)]	Loss: 9.1128	Cost: 7.64s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 9.1856	Cost: 9.60s
Train Epoch: 168 [61440/90000 (68%)]	Loss: 9.3014	Cost: 8.90s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 9.2480	Cost: 8.62s
Train Epoch: 168 	Average Loss: 9.2099
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3282

Learning rate: 9.993037623557708e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 9.1498	Cost: 23.65s
Train Epoch: 169 [20480/90000 (23%)]	Loss: 9.0824	Cost: 7.96s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 9.0940	Cost: 9.40s
Train Epoch: 169 [61440/90000 (68%)]	Loss: 9.1159	Cost: 8.61s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 9.1626	Cost: 8.70s
Train Epoch: 169 	Average Loss: 9.2201
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3156

Saving model as e169_model.pt & e169_waveforms_supplementary.hdf5
Learning rate: 9.992954510970051e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 9.5283	Cost: 21.68s
Train Epoch: 170 [20480/90000 (23%)]	Loss: 9.3602	Cost: 8.35s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 9.2143	Cost: 6.12s
Train Epoch: 170 [61440/90000 (68%)]	Loss: 9.2466	Cost: 7.17s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 9.2083	Cost: 9.10s
Train Epoch: 170 	Average Loss: 9.2085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2620

Saving model as e170_model.pt & e170_waveforms_supplementary.hdf5
Learning rate: 9.99287090559754e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 9.3360	Cost: 30.80s
Train Epoch: 171 [20480/90000 (23%)]	Loss: 9.2418	Cost: 7.73s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 9.1670	Cost: 12.58s
Train Epoch: 171 [61440/90000 (68%)]	Loss: 9.0094	Cost: 12.44s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 9.0828	Cost: 12.43s
Train Epoch: 171 	Average Loss: 9.1707
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2447

Saving model as e171_model.pt & e171_waveforms_supplementary.hdf5
Learning rate: 9.992786807448426e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 9.3017	Cost: 38.42s
Train Epoch: 172 [20480/90000 (23%)]	Loss: 9.2911	Cost: 13.39s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 9.2319	Cost: 13.46s
Train Epoch: 172 [61440/90000 (68%)]	Loss: 9.1061	Cost: 12.52s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 9.0773	Cost: 8.92s
Train Epoch: 172 	Average Loss: 9.1578
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3037

Learning rate: 9.992702216531012e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 9.1253	Cost: 41.97s
Train Epoch: 173 [20480/90000 (23%)]	Loss: 9.0728	Cost: 13.21s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 9.1603	Cost: 10.27s
Train Epoch: 173 [61440/90000 (68%)]	Loss: 9.1378	Cost: 6.13s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 9.2057	Cost: 6.61s
Train Epoch: 173 	Average Loss: 9.1713
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2592

Learning rate: 9.992617132853643e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 9.3090	Cost: 29.93s
Train Epoch: 174 [20480/90000 (23%)]	Loss: 9.1672	Cost: 10.64s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 9.1323	Cost: 9.16s
Train Epoch: 174 [61440/90000 (68%)]	Loss: 9.3553	Cost: 6.11s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 9.0156	Cost: 6.53s
Train Epoch: 174 	Average Loss: 9.1411
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2327

Saving model as e174_model.pt & e174_waveforms_supplementary.hdf5
Learning rate: 9.992531556424718e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 9.1396	Cost: 19.94s
Train Epoch: 175 [20480/90000 (23%)]	Loss: 9.2299	Cost: 6.71s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 9.1965	Cost: 10.29s
Train Epoch: 175 [61440/90000 (68%)]	Loss: 9.1169	Cost: 8.54s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 9.0323	Cost: 8.43s
Train Epoch: 175 	Average Loss: 9.1401
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1693

Saving model as e175_model.pt & e175_waveforms_supplementary.hdf5
Learning rate: 9.992445487252684e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 9.1919	Cost: 23.02s
Train Epoch: 176 [20480/90000 (23%)]	Loss: 8.8639	Cost: 8.13s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 9.1358	Cost: 8.90s
Train Epoch: 176 [61440/90000 (68%)]	Loss: 9.0939	Cost: 8.61s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 9.0003	Cost: 8.72s
Train Epoch: 176 	Average Loss: 9.0878
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2257

Learning rate: 9.992358925346033e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 9.1320	Cost: 23.70s
Train Epoch: 177 [20480/90000 (23%)]	Loss: 9.0062	Cost: 11.16s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 9.1073	Cost: 11.11s
Train Epoch: 177 [61440/90000 (68%)]	Loss: 9.0439	Cost: 8.92s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 8.9855	Cost: 6.09s
Train Epoch: 177 	Average Loss: 9.0779
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1691

Saving model as e177_model.pt & e177_waveforms_supplementary.hdf5
Learning rate: 9.992271870713308e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 9.1214	Cost: 21.51s
Train Epoch: 178 [20480/90000 (23%)]	Loss: 9.0407	Cost: 10.85s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 9.1747	Cost: 10.24s
Train Epoch: 178 [61440/90000 (68%)]	Loss: 8.9916	Cost: 9.82s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 9.0556	Cost: 11.91s
Train Epoch: 178 	Average Loss: 9.0704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1304

Saving model as e178_model.pt & e178_waveforms_supplementary.hdf5
Learning rate: 9.992184323363105e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 9.2654	Cost: 28.86s
Train Epoch: 179 [20480/90000 (23%)]	Loss: 9.0653	Cost: 12.96s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 9.0112	Cost: 13.02s
Train Epoch: 179 [61440/90000 (68%)]	Loss: 9.3002	Cost: 12.37s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 8.9370	Cost: 12.47s
Train Epoch: 179 	Average Loss: 9.0754
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1194

Saving model as e179_model.pt & e179_waveforms_supplementary.hdf5
Learning rate: 9.992096283304062e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 9.0944	Cost: 25.24s
Train Epoch: 180 [20480/90000 (23%)]	Loss: 9.0893	Cost: 12.38s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 9.0832	Cost: 15.89s
Train Epoch: 180 [61440/90000 (68%)]	Loss: 8.9928	Cost: 14.03s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 9.0437	Cost: 12.22s
Train Epoch: 180 	Average Loss: 9.0206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0781

Saving model as e180_model.pt & e180_waveforms_supplementary.hdf5
Learning rate: 9.992007750544869e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 9.0410	Cost: 50.24s
Train Epoch: 181 [20480/90000 (23%)]	Loss: 8.9468	Cost: 16.37s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 8.9520	Cost: 10.36s
Train Epoch: 181 [61440/90000 (68%)]	Loss: 9.0325	Cost: 9.74s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 8.9723	Cost: 6.39s
Train Epoch: 181 	Average Loss: 9.0053
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1231

Learning rate: 9.991918725094262e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 9.0757	Cost: 26.78s
Train Epoch: 182 [20480/90000 (23%)]	Loss: 8.9463	Cost: 11.00s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 8.9480	Cost: 12.29s
Train Epoch: 182 [61440/90000 (68%)]	Loss: 8.9999	Cost: 6.80s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 9.0712	Cost: 7.18s
Train Epoch: 182 	Average Loss: 8.9980
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1406

Learning rate: 9.99182920696103e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 9.2666	Cost: 23.63s
Train Epoch: 183 [20480/90000 (23%)]	Loss: 8.9536	Cost: 11.38s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 9.0455	Cost: 9.32s
Train Epoch: 183 [61440/90000 (68%)]	Loss: 8.9973	Cost: 6.34s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 9.0022	Cost: 8.48s
Train Epoch: 183 	Average Loss: 8.9798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1238

Learning rate: 9.991739196154006e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 9.0102	Cost: 19.66s
Train Epoch: 184 [20480/90000 (23%)]	Loss: 9.0363	Cost: 6.60s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 8.8401	Cost: 10.48s
Train Epoch: 184 [61440/90000 (68%)]	Loss: 8.9951	Cost: 8.99s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 8.8391	Cost: 8.80s
Train Epoch: 184 	Average Loss: 8.9606
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0874

Learning rate: 9.991648692682075e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 8.8319	Cost: 32.46s
Train Epoch: 185 [20480/90000 (23%)]	Loss: 8.9349	Cost: 8.97s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 8.9950	Cost: 9.08s
Train Epoch: 185 [61440/90000 (68%)]	Loss: 8.9616	Cost: 9.12s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 8.8467	Cost: 6.78s
Train Epoch: 185 	Average Loss: 8.9594
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0643

Saving model as e185_model.pt & e185_waveforms_supplementary.hdf5
Learning rate: 9.991557696554169e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 9.2169	Cost: 23.38s
Train Epoch: 186 [20480/90000 (23%)]	Loss: 8.9311	Cost: 7.95s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 9.0281	Cost: 12.26s
Train Epoch: 186 [61440/90000 (68%)]	Loss: 8.9234	Cost: 9.81s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 8.9492	Cost: 13.14s
Train Epoch: 186 	Average Loss: 8.9397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0474

Saving model as e186_model.pt & e186_waveforms_supplementary.hdf5
Learning rate: 9.99146620777927e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 9.0716	Cost: 23.83s
Train Epoch: 187 [20480/90000 (23%)]	Loss: 8.8386	Cost: 14.20s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 8.9205	Cost: 14.01s
Train Epoch: 187 [61440/90000 (68%)]	Loss: 8.8740	Cost: 12.61s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 8.9139	Cost: 12.48s
Train Epoch: 187 	Average Loss: 8.9257
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0448

Saving model as e187_model.pt & e187_waveforms_supplementary.hdf5
Learning rate: 9.991374226366404e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 9.0402	Cost: 25.53s
Train Epoch: 188 [20480/90000 (23%)]	Loss: 8.8991	Cost: 12.22s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 8.9055	Cost: 13.96s
Train Epoch: 188 [61440/90000 (68%)]	Loss: 8.8329	Cost: 10.60s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 8.9069	Cost: 7.17s
Train Epoch: 188 	Average Loss: 8.9268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0546

Learning rate: 9.991281752324654e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 8.9698	Cost: 25.27s
Train Epoch: 189 [20480/90000 (23%)]	Loss: 8.8728	Cost: 11.56s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 8.9511	Cost: 8.17s
Train Epoch: 189 [61440/90000 (68%)]	Loss: 8.9111	Cost: 6.25s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 8.8674	Cost: 7.35s
Train Epoch: 189 	Average Loss: 8.8961
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0446

Saving model as e189_model.pt & e189_waveforms_supplementary.hdf5
Learning rate: 9.991188785663142e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 9.1156	Cost: 30.28s
Train Epoch: 190 [20480/90000 (23%)]	Loss: 8.8452	Cost: 10.73s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 8.8112	Cost: 9.02s
Train Epoch: 190 [61440/90000 (68%)]	Loss: 8.9233	Cost: 8.78s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 8.7804	Cost: 9.12s
Train Epoch: 190 	Average Loss: 8.9110
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0295

Saving model as e190_model.pt & e190_waveforms_supplementary.hdf5
Learning rate: 9.991095326391049e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 8.9515	Cost: 33.30s
Train Epoch: 191 [20480/90000 (23%)]	Loss: 8.7518	Cost: 8.97s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 8.9043	Cost: 8.83s
Train Epoch: 191 [61440/90000 (68%)]	Loss: 8.9187	Cost: 7.63s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 8.8303	Cost: 6.03s
Train Epoch: 191 	Average Loss: 8.8914
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9645

Saving model as e191_model.pt & e191_waveforms_supplementary.hdf5
Learning rate: 9.991001374517595e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 9.1915	Cost: 22.07s
Train Epoch: 192 [20480/90000 (23%)]	Loss: 8.7980	Cost: 9.19s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 8.9338	Cost: 14.35s
Train Epoch: 192 [61440/90000 (68%)]	Loss: 8.9489	Cost: 14.47s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 8.9484	Cost: 13.47s
Train Epoch: 192 	Average Loss: 8.8587
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0148

Learning rate: 9.990906930052053e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 8.9997	Cost: 21.87s
Train Epoch: 193 [20480/90000 (23%)]	Loss: 8.7851	Cost: 9.17s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 8.8156	Cost: 14.99s
Train Epoch: 193 [61440/90000 (68%)]	Loss: 8.7662	Cost: 14.89s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 8.9166	Cost: 12.74s
Train Epoch: 193 	Average Loss: 8.8674
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9848

Learning rate: 9.990811993003745e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 9.0184	Cost: 33.58s
Train Epoch: 194 [20480/90000 (23%)]	Loss: 8.7778	Cost: 12.79s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 8.8875	Cost: 12.48s
Train Epoch: 194 [61440/90000 (68%)]	Loss: 8.8521	Cost: 12.01s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 8.7939	Cost: 9.32s
Train Epoch: 194 	Average Loss: 8.8304
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9835

Learning rate: 9.990716563382042e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 9.0244	Cost: 35.52s
Train Epoch: 195 [20480/90000 (23%)]	Loss: 8.6770	Cost: 11.90s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 8.8725	Cost: 7.77s
Train Epoch: 195 [61440/90000 (68%)]	Loss: 8.8030	Cost: 6.17s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 8.8173	Cost: 7.79s
Train Epoch: 195 	Average Loss: 8.8204
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9033

Saving model as e195_model.pt & e195_waveforms_supplementary.hdf5
Learning rate: 9.990620641196361e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 8.8668	Cost: 22.60s
Train Epoch: 196 [20480/90000 (23%)]	Loss: 8.8093	Cost: 7.04s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 8.7550	Cost: 9.10s
Train Epoch: 196 [61440/90000 (68%)]	Loss: 8.8578	Cost: 9.01s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 8.7773	Cost: 9.03s
Train Epoch: 196 	Average Loss: 8.7981
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9114

Learning rate: 9.99052422645617e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 9.0875	Cost: 27.77s
Train Epoch: 197 [20480/90000 (23%)]	Loss: 8.6835	Cost: 10.30s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 8.7214	Cost: 9.45s
Train Epoch: 197 [61440/90000 (68%)]	Loss: 8.7111	Cost: 8.60s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 8.8041	Cost: 7.78s
Train Epoch: 197 	Average Loss: 8.7865
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9271

Learning rate: 9.990427319170984e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 8.9132	Cost: 24.02s
Train Epoch: 198 [20480/90000 (23%)]	Loss: 8.7291	Cost: 9.27s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 8.9678	Cost: 8.54s
Train Epoch: 198 [61440/90000 (68%)]	Loss: 8.7633	Cost: 6.47s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 8.8350	Cost: 6.51s
Train Epoch: 198 	Average Loss: 8.7872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8689

Saving model as e198_model.pt & e198_waveforms_supplementary.hdf5
Learning rate: 9.990329919350368e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 8.8851	Cost: 19.61s
Train Epoch: 199 [20480/90000 (23%)]	Loss: 8.8926	Cost: 9.02s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 8.7169	Cost: 11.48s
Train Epoch: 199 [61440/90000 (68%)]	Loss: 8.8992	Cost: 13.45s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 8.6695	Cost: 13.97s
Train Epoch: 199 	Average Loss: 8.7858
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9417

Learning rate: 9.990232027003935e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 8.8894	Cost: 24.16s
Train Epoch: 200 [20480/90000 (23%)]	Loss: 8.6001	Cost: 11.94s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 8.6231	Cost: 12.54s
Train Epoch: 200 [61440/90000 (68%)]	Loss: 8.6551	Cost: 12.40s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 8.8641	Cost: 12.74s
Train Epoch: 200 	Average Loss: 8.7528
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8613

Saving model as e200_model.pt & e200_waveforms_supplementary.hdf5
Learning rate: 9.990133642141346e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 8.8302	Cost: 24.07s
Train Epoch: 201 [20480/90000 (23%)]	Loss: 8.6864	Cost: 15.13s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 8.6615	Cost: 13.54s
Train Epoch: 201 [61440/90000 (68%)]	Loss: 8.6877	Cost: 12.23s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 8.6336	Cost: 8.16s
Train Epoch: 201 	Average Loss: 8.7296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8960

Learning rate: 9.990034764772311e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 8.7514	Cost: 29.12s
Train Epoch: 202 [20480/90000 (23%)]	Loss: 8.6907	Cost: 13.11s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 8.7794	Cost: 10.82s
Train Epoch: 202 [61440/90000 (68%)]	Loss: 8.7331	Cost: 6.18s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 8.6969	Cost: 7.26s
Train Epoch: 202 	Average Loss: 8.7475
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8651

Learning rate: 9.98993539490659e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 8.9009	Cost: 39.65s
Train Epoch: 203 [20480/90000 (23%)]	Loss: 8.7458	Cost: 8.75s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 8.8452	Cost: 7.27s
Train Epoch: 203 [61440/90000 (68%)]	Loss: 8.6786	Cost: 6.98s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 8.6341	Cost: 8.52s
Train Epoch: 203 	Average Loss: 8.7330
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8370

Saving model as e203_model.pt & e203_waveforms_supplementary.hdf5
Learning rate: 9.989835532553989e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 8.9876	Cost: 27.42s
Train Epoch: 204 [20480/90000 (23%)]	Loss: 8.7103	Cost: 12.34s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 8.7333	Cost: 7.43s
Train Epoch: 204 [61440/90000 (68%)]	Loss: 8.6805	Cost: 6.30s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 8.6874	Cost: 7.70s
Train Epoch: 204 	Average Loss: 8.7380
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8628

Learning rate: 9.989735177724366e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 8.9745	Cost: 18.99s
Train Epoch: 205 [20480/90000 (23%)]	Loss: 8.6310	Cost: 6.71s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 8.6947	Cost: 9.97s
Train Epoch: 205 [61440/90000 (68%)]	Loss: 8.6354	Cost: 8.69s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 8.6906	Cost: 8.48s
Train Epoch: 205 	Average Loss: 8.6957
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8408

Learning rate: 9.989634330427624e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 8.7845	Cost: 22.28s
Train Epoch: 206 [20480/90000 (23%)]	Loss: 8.7734	Cost: 8.99s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 8.7204	Cost: 9.08s
Train Epoch: 206 [61440/90000 (68%)]	Loss: 8.6566	Cost: 9.05s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 8.8201	Cost: 8.91s
Train Epoch: 206 	Average Loss: 8.7014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8675

Learning rate: 9.989532990673716e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 8.8120	Cost: 23.21s
Train Epoch: 207 [20480/90000 (23%)]	Loss: 8.7686	Cost: 9.86s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 8.8278	Cost: 8.88s
Train Epoch: 207 [61440/90000 (68%)]	Loss: 8.7177	Cost: 8.63s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 8.5613	Cost: 8.48s
Train Epoch: 207 	Average Loss: 8.6919
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8591

Learning rate: 9.989431158472645e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 8.7145	Cost: 55.03s
Train Epoch: 208 [20480/90000 (23%)]	Loss: 8.6006	Cost: 10.43s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 8.5886	Cost: 18.11s
Train Epoch: 208 [61440/90000 (68%)]	Loss: 8.7143	Cost: 13.45s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 8.6171	Cost: 20.82s
Train Epoch: 208 	Average Loss: 8.6535
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7705

Saving model as e208_model.pt & e208_waveforms_supplementary.hdf5
Learning rate: 9.98932883383446e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 8.7551	Cost: 21.67s
Train Epoch: 209 [20480/90000 (23%)]	Loss: 8.7389	Cost: 10.52s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 8.7949	Cost: 14.66s
Train Epoch: 209 [61440/90000 (68%)]	Loss: 8.6893	Cost: 12.81s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 8.7125	Cost: 12.58s
Train Epoch: 209 	Average Loss: 8.6826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8208

Learning rate: 9.989226016769262e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 8.7338	Cost: 30.23s
Train Epoch: 210 [20480/90000 (23%)]	Loss: 8.5949	Cost: 10.54s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 8.5190	Cost: 13.31s
Train Epoch: 210 [61440/90000 (68%)]	Loss: 8.6139	Cost: 12.71s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 8.7197	Cost: 9.44s
Train Epoch: 210 	Average Loss: 8.6494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8487

Learning rate: 9.989122707287198e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 8.8943	Cost: 23.86s
Train Epoch: 211 [20480/90000 (23%)]	Loss: 8.6297	Cost: 14.03s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 8.6049	Cost: 12.55s
Train Epoch: 211 [61440/90000 (68%)]	Loss: 8.5836	Cost: 10.84s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 8.6430	Cost: 6.18s
Train Epoch: 211 	Average Loss: 8.6628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7965

Learning rate: 9.989018905398462e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 8.7346	Cost: 36.38s
Train Epoch: 212 [20480/90000 (23%)]	Loss: 8.5473	Cost: 13.94s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 8.7096	Cost: 8.12s
Train Epoch: 212 [61440/90000 (68%)]	Loss: 8.5630	Cost: 7.06s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 8.5919	Cost: 8.80s
Train Epoch: 212 	Average Loss: 8.6068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7592

Saving model as e212_model.pt & e212_waveforms_supplementary.hdf5
Learning rate: 9.9889146111133e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 8.8669	Cost: 26.84s
Train Epoch: 213 [20480/90000 (23%)]	Loss: 8.6157	Cost: 10.62s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 8.7187	Cost: 8.98s
Train Epoch: 213 [61440/90000 (68%)]	Loss: 8.6942	Cost: 8.84s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 8.5064	Cost: 8.57s
Train Epoch: 213 	Average Loss: 8.6634
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8318

Learning rate: 9.988809824442008e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 8.9841	Cost: 22.69s
Train Epoch: 214 [20480/90000 (23%)]	Loss: 8.6511	Cost: 8.52s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 8.5987	Cost: 9.23s
Train Epoch: 214 [61440/90000 (68%)]	Loss: 8.6053	Cost: 8.75s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 8.6344	Cost: 9.43s
Train Epoch: 214 	Average Loss: 8.6082
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7444

Saving model as e214_model.pt & e214_waveforms_supplementary.hdf5
Learning rate: 9.988704545394925e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 8.8642	Cost: 39.79s
Train Epoch: 215 [20480/90000 (23%)]	Loss: 8.7272	Cost: 11.35s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 8.6398	Cost: 8.71s
Train Epoch: 215 [61440/90000 (68%)]	Loss: 8.6881	Cost: 7.65s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 8.5591	Cost: 8.67s
Train Epoch: 215 	Average Loss: 8.6183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7269

Saving model as e215_model.pt & e215_waveforms_supplementary.hdf5
Learning rate: 9.988598773982444e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 8.6710	Cost: 23.05s
Train Epoch: 216 [20480/90000 (23%)]	Loss: 8.4418	Cost: 8.92s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 8.6020	Cost: 13.37s
Train Epoch: 216 [61440/90000 (68%)]	Loss: 8.5247	Cost: 13.23s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 8.5251	Cost: 12.50s
Train Epoch: 216 	Average Loss: 8.5904
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7764

Learning rate: 9.988492510215002e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 8.7973	Cost: 28.69s
Train Epoch: 217 [20480/90000 (23%)]	Loss: 8.4839	Cost: 14.59s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 8.6173	Cost: 14.03s
Train Epoch: 217 [61440/90000 (68%)]	Loss: 8.5641	Cost: 12.05s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 8.6713	Cost: 12.16s
Train Epoch: 217 	Average Loss: 8.5983
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6726

Saving model as e217_model.pt & e217_waveforms_supplementary.hdf5
Learning rate: 9.988385754103088e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 8.7016	Cost: 29.52s
Train Epoch: 218 [20480/90000 (23%)]	Loss: 8.5396	Cost: 12.68s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 8.6303	Cost: 12.44s
Train Epoch: 218 [61440/90000 (68%)]	Loss: 8.5580	Cost: 7.41s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 8.6128	Cost: 6.43s
Train Epoch: 218 	Average Loss: 8.5660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7249

Learning rate: 9.988278505657238e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 8.7092	Cost: 28.06s
Train Epoch: 219 [20480/90000 (23%)]	Loss: 8.5451	Cost: 12.20s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 8.4767	Cost: 6.84s
Train Epoch: 219 [61440/90000 (68%)]	Loss: 8.5903	Cost: 6.31s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 8.5830	Cost: 8.44s
Train Epoch: 219 	Average Loss: 8.5441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6931

Learning rate: 9.988170764888036e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 8.6980	Cost: 21.69s
Train Epoch: 220 [20480/90000 (23%)]	Loss: 8.4604	Cost: 11.21s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 8.4854	Cost: 11.29s
Train Epoch: 220 [61440/90000 (68%)]	Loss: 8.6598	Cost: 9.17s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 8.4654	Cost: 8.80s
Train Epoch: 220 	Average Loss: 8.5408
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6995

Learning rate: 9.988062531806117e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 8.8715	Cost: 31.02s
Train Epoch: 221 [20480/90000 (23%)]	Loss: 8.4366	Cost: 10.29s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 8.5695	Cost: 9.15s
Train Epoch: 221 [61440/90000 (68%)]	Loss: 8.6188	Cost: 6.25s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 8.5547	Cost: 6.57s
Train Epoch: 221 	Average Loss: 8.5401
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6462

Saving model as e221_model.pt & e221_waveforms_supplementary.hdf5
Learning rate: 9.987953806422163e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 8.8124	Cost: 20.22s
Train Epoch: 222 [20480/90000 (23%)]	Loss: 8.5158	Cost: 7.48s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 8.5766	Cost: 9.43s
Train Epoch: 222 [61440/90000 (68%)]	Loss: 8.3584	Cost: 12.77s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 8.5000	Cost: 12.44s
Train Epoch: 222 	Average Loss: 8.4995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7125

Learning rate: 9.987844588746906e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 8.7425	Cost: 22.49s
Train Epoch: 223 [20480/90000 (23%)]	Loss: 8.4068	Cost: 10.01s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 8.5911	Cost: 12.72s
Train Epoch: 223 [61440/90000 (68%)]	Loss: 8.4668	Cost: 12.09s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 8.4929	Cost: 12.69s
Train Epoch: 223 	Average Loss: 8.4942
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6487

Learning rate: 9.987734878791122e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 8.6830	Cost: 34.20s
Train Epoch: 224 [20480/90000 (23%)]	Loss: 8.4776	Cost: 11.41s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 8.5739	Cost: 13.01s
Train Epoch: 224 [61440/90000 (68%)]	Loss: 8.4520	Cost: 12.23s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 8.5348	Cost: 8.29s
Train Epoch: 224 	Average Loss: 8.5110
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6987

Learning rate: 9.987624676565643e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 8.4155	Cost: 36.73s
Train Epoch: 225 [20480/90000 (23%)]	Loss: 8.4856	Cost: 6.60s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 8.5600	Cost: 7.07s
Train Epoch: 225 [61440/90000 (68%)]	Loss: 8.5269	Cost: 8.20s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 8.4357	Cost: 9.05s
Train Epoch: 225 	Average Loss: 8.4948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6780

Learning rate: 9.987513982081342e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 8.6471	Cost: 23.72s
Train Epoch: 226 [20480/90000 (23%)]	Loss: 8.4475	Cost: 6.84s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 8.5206	Cost: 10.91s
Train Epoch: 226 [61440/90000 (68%)]	Loss: 8.4393	Cost: 8.64s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 8.5716	Cost: 8.46s
Train Epoch: 226 	Average Loss: 8.4751
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6901

Learning rate: 9.987402795349145e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 8.5921	Cost: 22.36s
Train Epoch: 227 [20480/90000 (23%)]	Loss: 8.4640	Cost: 9.58s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 8.5178	Cost: 8.92s
Train Epoch: 227 [61440/90000 (68%)]	Loss: 8.5013	Cost: 9.52s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 8.3983	Cost: 6.81s
Train Epoch: 227 	Average Loss: 8.4747
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7118

Learning rate: 9.987291116380029e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 8.6644	Cost: 19.76s
Train Epoch: 228 [20480/90000 (23%)]	Loss: 8.4007	Cost: 8.25s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 8.5800	Cost: 9.60s
Train Epoch: 228 [61440/90000 (68%)]	Loss: 8.4340	Cost: 9.50s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 8.4844	Cost: 15.62s
Train Epoch: 228 	Average Loss: 8.4662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7329

Learning rate: 9.98717894518501e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 8.6898	Cost: 22.55s
Train Epoch: 229 [20480/90000 (23%)]	Loss: 8.3366	Cost: 10.00s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 8.5133	Cost: 18.37s
Train Epoch: 229 [61440/90000 (68%)]	Loss: 8.4366	Cost: 13.08s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 8.4153	Cost: 12.09s
Train Epoch: 229 	Average Loss: 8.4437
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6116

Saving model as e229_model.pt & e229_waveforms_supplementary.hdf5
Learning rate: 9.987066281775164e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 8.4326	Cost: 28.39s
Train Epoch: 230 [20480/90000 (23%)]	Loss: 8.4747	Cost: 12.81s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 8.4339	Cost: 12.85s
Train Epoch: 230 [61440/90000 (68%)]	Loss: 8.4137	Cost: 12.19s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 8.4270	Cost: 8.97s
Train Epoch: 230 	Average Loss: 8.4401
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5739

Saving model as e230_model.pt & e230_waveforms_supplementary.hdf5
Learning rate: 9.98695312616161e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 8.6933	Cost: 27.63s
Train Epoch: 231 [20480/90000 (23%)]	Loss: 8.3363	Cost: 12.68s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 8.3939	Cost: 10.41s
Train Epoch: 231 [61440/90000 (68%)]	Loss: 8.4653	Cost: 6.53s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 8.2960	Cost: 6.24s
Train Epoch: 231 	Average Loss: 8.4128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5995

Learning rate: 9.986839478355513e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 8.6536	Cost: 27.91s
Train Epoch: 232 [20480/90000 (23%)]	Loss: 8.4531	Cost: 10.80s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 8.4315	Cost: 10.56s
Train Epoch: 232 [61440/90000 (68%)]	Loss: 8.4593	Cost: 7.71s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 8.4293	Cost: 8.85s
Train Epoch: 232 	Average Loss: 8.4034
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5645

Saving model as e232_model.pt & e232_waveforms_supplementary.hdf5
Learning rate: 9.986725338368092e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 8.6069	Cost: 20.65s
Train Epoch: 233 [20480/90000 (23%)]	Loss: 8.6549	Cost: 9.83s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 8.4725	Cost: 11.96s
Train Epoch: 233 [61440/90000 (68%)]	Loss: 8.3071	Cost: 9.11s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 8.4747	Cost: 8.75s
Train Epoch: 233 	Average Loss: 8.4302
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5525

Saving model as e233_model.pt & e233_waveforms_supplementary.hdf5
Learning rate: 9.986610706210612e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 8.5449	Cost: 24.58s
Train Epoch: 234 [20480/90000 (23%)]	Loss: 8.3150	Cost: 9.10s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 8.2819	Cost: 9.03s
Train Epoch: 234 [61440/90000 (68%)]	Loss: 8.3590	Cost: 6.55s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 8.5138	Cost: 6.91s
Train Epoch: 234 	Average Loss: 8.3942
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6210

Learning rate: 9.986495581894385e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 8.6425	Cost: 19.02s
Train Epoch: 235 [20480/90000 (23%)]	Loss: 8.2563	Cost: 8.82s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 8.4379	Cost: 13.41s
Train Epoch: 235 [61440/90000 (68%)]	Loss: 8.3606	Cost: 12.28s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 8.3758	Cost: 12.54s
Train Epoch: 235 	Average Loss: 8.3935
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5427

Saving model as e235_model.pt & e235_waveforms_supplementary.hdf5
Learning rate: 9.986379965430775e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 8.6222	Cost: 24.47s
Train Epoch: 236 [20480/90000 (23%)]	Loss: 8.2450	Cost: 13.50s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 8.2380	Cost: 14.17s
Train Epoch: 236 [61440/90000 (68%)]	Loss: 8.3498	Cost: 12.33s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 8.3541	Cost: 12.22s
Train Epoch: 236 	Average Loss: 8.3600
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6666

Learning rate: 9.986263856831194e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 8.4891	Cost: 42.84s
Train Epoch: 237 [20480/90000 (23%)]	Loss: 8.4354	Cost: 12.39s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 8.3013	Cost: 12.21s
Train Epoch: 237 [61440/90000 (68%)]	Loss: 8.3370	Cost: 8.34s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 8.3363	Cost: 6.10s
Train Epoch: 237 	Average Loss: 8.3535
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4841

Saving model as e237_model.pt & e237_waveforms_supplementary.hdf5
Learning rate: 9.9861472561071e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 8.6611	Cost: 38.43s
Train Epoch: 238 [20480/90000 (23%)]	Loss: 8.3969	Cost: 11.25s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 8.4169	Cost: 6.46s
Train Epoch: 238 [61440/90000 (68%)]	Loss: 8.3430	Cost: 6.28s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 8.3925	Cost: 8.49s
Train Epoch: 238 	Average Loss: 8.3460
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5150

Learning rate: 9.98603016327e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 8.7225	Cost: 19.76s
Train Epoch: 239 [20480/90000 (23%)]	Loss: 8.2522	Cost: 7.30s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 8.1967	Cost: 10.37s
Train Epoch: 239 [61440/90000 (68%)]	Loss: 8.2464	Cost: 8.86s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 8.4635	Cost: 9.43s
Train Epoch: 239 	Average Loss: 8.3547
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5780

Learning rate: 9.985912578331452e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 8.5776	Cost: 21.89s
Train Epoch: 240 [20480/90000 (23%)]	Loss: 8.2339	Cost: 8.95s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 8.3746	Cost: 9.25s
Train Epoch: 240 [61440/90000 (68%)]	Loss: 8.2033	Cost: 9.40s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 8.3198	Cost: 7.69s
Train Epoch: 240 	Average Loss: 8.3329
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5690

Learning rate: 9.985794501303059e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 8.4953	Cost: 20.66s
Train Epoch: 241 [20480/90000 (23%)]	Loss: 8.2926	Cost: 9.24s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 8.2586	Cost: 9.90s
Train Epoch: 241 [61440/90000 (68%)]	Loss: 8.3671	Cost: 12.29s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 8.2700	Cost: 12.12s
Train Epoch: 241 	Average Loss: 8.3224
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4618

Saving model as e241_model.pt & e241_waveforms_supplementary.hdf5
Learning rate: 9.985675932196479e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 8.4386	Cost: 40.14s
Train Epoch: 242 [20480/90000 (23%)]	Loss: 8.1759	Cost: 12.42s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 8.2766	Cost: 12.76s
Train Epoch: 242 [61440/90000 (68%)]	Loss: 8.3932	Cost: 12.12s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 8.2531	Cost: 9.45s
Train Epoch: 242 	Average Loss: 8.3113
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5367

Learning rate: 9.985556871023408e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 8.5778	Cost: 30.12s
Train Epoch: 243 [20480/90000 (23%)]	Loss: 8.2858	Cost: 12.50s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 8.2535	Cost: 12.31s
Train Epoch: 243 [61440/90000 (68%)]	Loss: 8.2834	Cost: 7.34s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 8.2037	Cost: 6.15s
Train Epoch: 243 	Average Loss: 8.2957
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4753

Learning rate: 9.985437317795604e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 8.5722	Cost: 32.45s
Train Epoch: 244 [20480/90000 (23%)]	Loss: 8.1286	Cost: 6.51s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 8.4659	Cost: 11.07s
Train Epoch: 244 [61440/90000 (68%)]	Loss: 8.3120	Cost: 9.06s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 8.2405	Cost: 8.79s
Train Epoch: 244 	Average Loss: 8.2820
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4944

Learning rate: 9.985317272524864e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 8.4433	Cost: 22.50s
Train Epoch: 245 [20480/90000 (23%)]	Loss: 8.1270	Cost: 11.60s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 8.3674	Cost: 10.43s
Train Epoch: 245 [61440/90000 (68%)]	Loss: 8.1410	Cost: 8.55s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 8.1296	Cost: 6.28s
Train Epoch: 245 	Average Loss: 8.2765
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4724

Learning rate: 9.985196735223035e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 8.5387	Cost: 22.56s
Train Epoch: 246 [20480/90000 (23%)]	Loss: 8.2135	Cost: 7.31s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 8.1727	Cost: 10.94s
Train Epoch: 246 [61440/90000 (68%)]	Loss: 8.3444	Cost: 10.99s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 8.1192	Cost: 12.55s
Train Epoch: 246 	Average Loss: 8.2780
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4099

Saving model as e246_model.pt & e246_waveforms_supplementary.hdf5
Learning rate: 9.985075705902012e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 8.5218	Cost: 22.57s
Train Epoch: 247 [20480/90000 (23%)]	Loss: 8.1194	Cost: 8.50s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 8.1363	Cost: 11.70s
Train Epoch: 247 [61440/90000 (68%)]	Loss: 8.3036	Cost: 12.57s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 8.2529	Cost: 12.41s
Train Epoch: 247 	Average Loss: 8.2341
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4006

Saving model as e247_model.pt & e247_waveforms_supplementary.hdf5
Learning rate: 9.984954184573743e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 8.5440	Cost: 27.09s
Train Epoch: 248 [20480/90000 (23%)]	Loss: 8.3012	Cost: 12.82s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 8.3111	Cost: 12.47s
Train Epoch: 248 [61440/90000 (68%)]	Loss: 8.2416	Cost: 12.47s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 8.3397	Cost: 11.69s
Train Epoch: 248 	Average Loss: 8.2418
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4032

Learning rate: 9.984832171250219e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 8.5798	Cost: 24.13s
Train Epoch: 249 [20480/90000 (23%)]	Loss: 8.1321	Cost: 9.16s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 8.1035	Cost: 12.72s
Train Epoch: 249 [61440/90000 (68%)]	Loss: 8.2136	Cost: 6.49s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 8.2363	Cost: 6.18s
Train Epoch: 249 	Average Loss: 8.2424
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5258

Learning rate: 9.984709665943483e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 8.3643	Cost: 54.83s
Train Epoch: 250 [20480/90000 (23%)]	Loss: 8.2465	Cost: 13.13s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 8.2321	Cost: 15.25s
Train Epoch: 250 [61440/90000 (68%)]	Loss: 8.2414	Cost: 10.33s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 8.2005	Cost: 20.47s
Train Epoch: 250 	Average Loss: 8.2359
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4303

Learning rate: 9.98458666866563e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 8.4765	Cost: 39.00s
Train Epoch: 251 [20480/90000 (23%)]	Loss: 8.0944	Cost: 10.83s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 8.2279	Cost: 13.09s
Train Epoch: 251 [61440/90000 (68%)]	Loss: 8.1446	Cost: 8.76s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 8.3009	Cost: 8.67s
Train Epoch: 251 	Average Loss: 8.2415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4419

Learning rate: 9.984463179428794e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 8.4177	Cost: 21.83s
Train Epoch: 252 [20480/90000 (23%)]	Loss: 8.2317	Cost: 8.99s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 8.2033	Cost: 8.71s
Train Epoch: 252 [61440/90000 (68%)]	Loss: 8.1851	Cost: 8.47s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 8.1895	Cost: 6.16s
Train Epoch: 252 	Average Loss: 8.2203
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4515

Learning rate: 9.984339198245162e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 8.3437	Cost: 20.23s
Train Epoch: 253 [20480/90000 (23%)]	Loss: 8.0849	Cost: 7.31s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 8.2154	Cost: 10.91s
Train Epoch: 253 [61440/90000 (68%)]	Loss: 8.1913	Cost: 13.84s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 8.2976	Cost: 12.56s
Train Epoch: 253 	Average Loss: 8.1874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3852

Saving model as e253_model.pt & e253_waveforms_supplementary.hdf5
Learning rate: 9.984214725126977e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 8.4666	Cost: 25.45s
Train Epoch: 254 [20480/90000 (23%)]	Loss: 8.2138	Cost: 11.99s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 8.0861	Cost: 14.33s
Train Epoch: 254 [61440/90000 (68%)]	Loss: 8.1890	Cost: 12.64s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 8.0914	Cost: 12.16s
Train Epoch: 254 	Average Loss: 8.1958
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4444

Learning rate: 9.98408976008652e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 8.3395	Cost: 32.85s
Train Epoch: 255 [20480/90000 (23%)]	Loss: 8.0927	Cost: 12.52s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 8.1178	Cost: 13.45s
Train Epoch: 255 [61440/90000 (68%)]	Loss: 8.0266	Cost: 12.17s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 8.2337	Cost: 10.93s
Train Epoch: 255 	Average Loss: 8.1853
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4699

Learning rate: 9.983964303136122e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 8.4449	Cost: 34.55s
Train Epoch: 256 [20480/90000 (23%)]	Loss: 8.1279	Cost: 12.32s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 8.1530	Cost: 12.47s
Train Epoch: 256 [61440/90000 (68%)]	Loss: 8.1605	Cost: 6.40s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 8.2037	Cost: 6.42s
Train Epoch: 256 	Average Loss: 8.1741
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4812

Learning rate: 9.98383835428817e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 8.5408	Cost: 27.14s
Train Epoch: 257 [20480/90000 (23%)]	Loss: 8.1284	Cost: 13.77s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 8.1227	Cost: 10.72s
Train Epoch: 257 [61440/90000 (68%)]	Loss: 8.1403	Cost: 6.67s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 8.2999	Cost: 7.23s
Train Epoch: 257 	Average Loss: 8.1816
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4394

Learning rate: 9.983711913555091e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 8.4711	Cost: 24.23s
Train Epoch: 258 [20480/90000 (23%)]	Loss: 8.1342	Cost: 11.84s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 8.2168	Cost: 6.91s
Train Epoch: 258 [61440/90000 (68%)]	Loss: 8.1082	Cost: 8.51s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 8.0576	Cost: 8.57s
Train Epoch: 258 	Average Loss: 8.1462
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4053

Learning rate: 9.983584980949367e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 8.3876	Cost: 22.68s
Train Epoch: 259 [20480/90000 (23%)]	Loss: 8.0458	Cost: 7.17s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 8.1195	Cost: 9.02s
Train Epoch: 259 [61440/90000 (68%)]	Loss: 8.2049	Cost: 8.88s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 8.1463	Cost: 8.73s
Train Epoch: 259 	Average Loss: 8.1561
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4335

Learning rate: 9.983457556483523e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 8.3698	Cost: 27.09s
Train Epoch: 260 [20480/90000 (23%)]	Loss: 8.1102	Cost: 9.44s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 8.1520	Cost: 9.63s
Train Epoch: 260 [61440/90000 (68%)]	Loss: 8.1255	Cost: 8.68s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 8.2617	Cost: 8.45s
Train Epoch: 260 	Average Loss: 8.1465
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3941

Learning rate: 9.983329640170136e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 8.2739	Cost: 22.96s
Train Epoch: 261 [20480/90000 (23%)]	Loss: 8.0615	Cost: 10.57s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 8.1134	Cost: 10.40s
Train Epoch: 261 [61440/90000 (68%)]	Loss: 8.1493	Cost: 8.89s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 8.0876	Cost: 8.61s
Train Epoch: 261 	Average Loss: 8.1128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4234

Learning rate: 9.983201232021833e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 8.4298	Cost: 22.30s
Train Epoch: 262 [20480/90000 (23%)]	Loss: 8.0085	Cost: 8.96s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 8.1066	Cost: 9.25s
Train Epoch: 262 [61440/90000 (68%)]	Loss: 8.0323	Cost: 9.05s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 8.0119	Cost: 8.82s
Train Epoch: 262 	Average Loss: 8.1169
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3847

Saving model as e262_model.pt & e262_waveforms_supplementary.hdf5
Learning rate: 9.983072332051286e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 8.4282	Cost: 20.64s
Train Epoch: 263 [20480/90000 (23%)]	Loss: 8.1739	Cost: 9.29s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 8.1633	Cost: 8.80s
Train Epoch: 263 [61440/90000 (68%)]	Loss: 8.1351	Cost: 7.97s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 8.0152	Cost: 6.98s
Train Epoch: 263 	Average Loss: 8.0872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3589

Saving model as e263_model.pt & e263_waveforms_supplementary.hdf5
Learning rate: 9.982942940271217e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 8.2977	Cost: 19.44s
Train Epoch: 264 [20480/90000 (23%)]	Loss: 7.9999	Cost: 7.97s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 8.1028	Cost: 13.59s
Train Epoch: 264 [61440/90000 (68%)]	Loss: 8.0683	Cost: 15.01s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 8.0811	Cost: 14.26s
Train Epoch: 264 	Average Loss: 8.0940
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3635

Learning rate: 9.982813056694397e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 8.3008	Cost: 26.18s
Train Epoch: 265 [20480/90000 (23%)]	Loss: 7.9851	Cost: 14.55s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 8.0197	Cost: 14.47s
Train Epoch: 265 [61440/90000 (68%)]	Loss: 8.0244	Cost: 12.10s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 8.1757	Cost: 11.93s
Train Epoch: 265 	Average Loss: 8.0963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3180

Saving model as e265_model.pt & e265_waveforms_supplementary.hdf5
Learning rate: 9.982682681333644e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 8.2427	Cost: 30.75s
Train Epoch: 266 [20480/90000 (23%)]	Loss: 8.0703	Cost: 11.69s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 7.8537	Cost: 12.30s
Train Epoch: 266 [61440/90000 (68%)]	Loss: 8.1023	Cost: 11.32s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 8.1200	Cost: 6.10s
Train Epoch: 266 	Average Loss: 8.0548
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2746

Saving model as e266_model.pt & e266_waveforms_supplementary.hdf5
Learning rate: 9.982551814201825e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 8.2447	Cost: 23.44s
Train Epoch: 267 [20480/90000 (23%)]	Loss: 7.9310	Cost: 6.67s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 8.0711	Cost: 9.79s
Train Epoch: 267 [61440/90000 (68%)]	Loss: 8.0190	Cost: 9.07s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 7.9532	Cost: 9.12s
Train Epoch: 267 	Average Loss: 8.0411
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3656

Learning rate: 9.982420455311858e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 8.3826	Cost: 25.78s
Train Epoch: 268 [20480/90000 (23%)]	Loss: 7.9247	Cost: 10.74s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 8.0963	Cost: 8.91s
Train Epoch: 268 [61440/90000 (68%)]	Loss: 8.0651	Cost: 8.58s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 7.9644	Cost: 7.54s
Train Epoch: 268 	Average Loss: 8.0491
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3548

Learning rate: 9.982288604676707e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 8.3546	Cost: 32.08s
Train Epoch: 269 [20480/90000 (23%)]	Loss: 7.9926	Cost: 6.73s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 7.9201	Cost: 10.35s
Train Epoch: 269 [61440/90000 (68%)]	Loss: 8.0486	Cost: 8.97s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 8.0374	Cost: 13.46s
Train Epoch: 269 	Average Loss: 8.0375
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3330

Learning rate: 9.982156262309383e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 8.3980	Cost: 23.26s
Train Epoch: 270 [20480/90000 (23%)]	Loss: 8.0273	Cost: 12.61s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 8.1508	Cost: 14.16s
Train Epoch: 270 [61440/90000 (68%)]	Loss: 7.8761	Cost: 12.62s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 7.9965	Cost: 12.46s
Train Epoch: 270 	Average Loss: 8.0339
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3253

Learning rate: 9.98202342822295e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 8.2239	Cost: 27.28s
Train Epoch: 271 [20480/90000 (23%)]	Loss: 8.0316	Cost: 12.60s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 8.0108	Cost: 13.01s
Train Epoch: 271 [61440/90000 (68%)]	Loss: 8.0968	Cost: 12.85s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 8.1350	Cost: 10.08s
Train Epoch: 271 	Average Loss: 8.0186
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2640

Saving model as e271_model.pt & e271_waveforms_supplementary.hdf5
Learning rate: 9.981890102430519e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 8.3001	Cost: 25.53s
Train Epoch: 272 [20480/90000 (23%)]	Loss: 7.8619	Cost: 10.49s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 8.0613	Cost: 9.30s
Train Epoch: 272 [61440/90000 (68%)]	Loss: 8.0532	Cost: 6.22s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 7.9380	Cost: 6.84s
Train Epoch: 272 	Average Loss: 8.0031
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2900

Learning rate: 9.981756284945245e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 8.4054	Cost: 28.22s
Train Epoch: 273 [20480/90000 (23%)]	Loss: 8.0722	Cost: 12.95s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 7.9324	Cost: 8.29s
Train Epoch: 273 [61440/90000 (68%)]	Loss: 7.9619	Cost: 6.39s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 7.9981	Cost: 8.42s
Train Epoch: 273 	Average Loss: 7.9858
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2558

Saving model as e273_model.pt & e273_waveforms_supplementary.hdf5
Learning rate: 9.98162197578034e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 8.4237	Cost: 21.37s
Train Epoch: 274 [20480/90000 (23%)]	Loss: 7.9278	Cost: 10.32s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 8.0483	Cost: 11.41s
Train Epoch: 274 [61440/90000 (68%)]	Loss: 7.8621	Cost: 9.21s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 7.9775	Cost: 8.65s
Train Epoch: 274 	Average Loss: 7.9905
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3065

Learning rate: 9.981487174949054e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 8.1654	Cost: 23.73s
Train Epoch: 275 [20480/90000 (23%)]	Loss: 7.8371	Cost: 8.49s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 8.1339	Cost: 9.16s
Train Epoch: 275 [61440/90000 (68%)]	Loss: 7.9834	Cost: 9.02s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 8.0305	Cost: 8.82s
Train Epoch: 275 	Average Loss: 7.9804
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2768

Learning rate: 9.981351882464696e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 8.1980	Cost: 21.26s
Train Epoch: 276 [20480/90000 (23%)]	Loss: 7.9447	Cost: 9.04s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 7.8873	Cost: 8.26s
Train Epoch: 276 [61440/90000 (68%)]	Loss: 8.2186	Cost: 6.99s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 7.9988	Cost: 8.57s
Train Epoch: 276 	Average Loss: 7.9817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2705

Learning rate: 9.981216098340617e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 8.3174	Cost: 21.71s
Train Epoch: 277 [20480/90000 (23%)]	Loss: 7.9726	Cost: 6.73s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 8.0148	Cost: 14.93s
Train Epoch: 277 [61440/90000 (68%)]	Loss: 7.9497	Cost: 13.16s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 7.9167	Cost: 12.53s
Train Epoch: 277 	Average Loss: 7.9909
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2923

Learning rate: 9.981079822590219e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 8.3001	Cost: 24.16s
Train Epoch: 278 [20480/90000 (23%)]	Loss: 7.8762	Cost: 14.47s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 7.8258	Cost: 14.57s
Train Epoch: 278 [61440/90000 (68%)]	Loss: 7.9393	Cost: 12.22s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 7.8135	Cost: 12.09s
Train Epoch: 278 	Average Loss: 7.9710
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2466

Saving model as e278_model.pt & e278_waveforms_supplementary.hdf5
Learning rate: 9.980943055226952e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 8.3627	Cost: 28.33s
Train Epoch: 279 [20480/90000 (23%)]	Loss: 7.9841	Cost: 10.41s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 7.9088	Cost: 12.36s
Train Epoch: 279 [61440/90000 (68%)]	Loss: 7.8598	Cost: 12.05s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 7.9202	Cost: 6.78s
Train Epoch: 279 	Average Loss: 7.9554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2718

Learning rate: 9.980805796264313e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 8.1071	Cost: 37.47s
Train Epoch: 280 [20480/90000 (23%)]	Loss: 7.8036	Cost: 12.30s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 7.9297	Cost: 6.49s
Train Epoch: 280 [61440/90000 (68%)]	Loss: 7.8928	Cost: 6.27s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 7.7873	Cost: 8.10s
Train Epoch: 280 	Average Loss: 7.9467
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2349

Saving model as e280_model.pt & e280_waveforms_supplementary.hdf5
Learning rate: 9.98066804571585e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 8.2305	Cost: 23.89s
Train Epoch: 281 [20480/90000 (23%)]	Loss: 7.7724	Cost: 9.54s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 7.8890	Cost: 11.19s
Train Epoch: 281 [61440/90000 (68%)]	Loss: 7.9517	Cost: 9.01s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 7.8802	Cost: 8.66s
Train Epoch: 281 	Average Loss: 7.9208
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2912

Learning rate: 9.980529803595159e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 8.2339	Cost: 29.93s
Train Epoch: 282 [20480/90000 (23%)]	Loss: 7.8650	Cost: 8.94s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 7.9346	Cost: 7.64s
Train Epoch: 282 [61440/90000 (68%)]	Loss: 7.9359	Cost: 6.70s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 8.0220	Cost: 6.59s
Train Epoch: 282 	Average Loss: 7.9168
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1870

Saving model as e282_model.pt & e282_waveforms_supplementary.hdf5
Learning rate: 9.980391069915883e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 8.1182	Cost: 20.10s
Train Epoch: 283 [20480/90000 (23%)]	Loss: 7.9663	Cost: 8.02s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 7.8841	Cost: 9.47s
Train Epoch: 283 [61440/90000 (68%)]	Loss: 7.9154	Cost: 12.28s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 7.8582	Cost: 12.20s
Train Epoch: 283 	Average Loss: 7.9059
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2245

Learning rate: 9.980251844691714e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 8.1859	Cost: 23.61s
Train Epoch: 284 [20480/90000 (23%)]	Loss: 7.8842	Cost: 11.47s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 7.7212	Cost: 12.52s
Train Epoch: 284 [61440/90000 (68%)]	Loss: 7.7855	Cost: 12.35s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 7.8717	Cost: 12.66s
Train Epoch: 284 	Average Loss: 7.9038
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1960

Learning rate: 9.980112127936395e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 8.1773	Cost: 30.15s
Train Epoch: 285 [20480/90000 (23%)]	Loss: 7.8458	Cost: 13.28s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 7.8346	Cost: 13.18s
Train Epoch: 285 [61440/90000 (68%)]	Loss: 7.9967	Cost: 12.20s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 7.8841	Cost: 7.67s
Train Epoch: 285 	Average Loss: 7.8600
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2052

Learning rate: 9.979971919663715e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 8.3696	Cost: 32.96s
Train Epoch: 286 [20480/90000 (23%)]	Loss: 7.7703	Cost: 13.44s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 7.9190	Cost: 10.15s
Train Epoch: 286 [61440/90000 (68%)]	Loss: 7.8213	Cost: 6.43s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 7.8465	Cost: 7.36s
Train Epoch: 286 	Average Loss: 7.8969
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1487

Saving model as e286_model.pt & e286_waveforms_supplementary.hdf5
Learning rate: 9.97983121988751e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 8.1190	Cost: 27.20s
Train Epoch: 287 [20480/90000 (23%)]	Loss: 7.8454	Cost: 9.20s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 7.7687	Cost: 8.50s
Train Epoch: 287 [61440/90000 (68%)]	Loss: 7.7406	Cost: 7.59s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 7.8150	Cost: 8.72s
Train Epoch: 287 	Average Loss: 7.8579
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1804

Learning rate: 9.97969002862167e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 8.2121	Cost: 24.63s
Train Epoch: 288 [20480/90000 (23%)]	Loss: 7.8480	Cost: 7.88s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 7.8310	Cost: 13.71s
Train Epoch: 288 [61440/90000 (68%)]	Loss: 7.9021	Cost: 9.88s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 7.9092	Cost: 8.96s
Train Epoch: 288 	Average Loss: 7.8741
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1883

Learning rate: 9.979548345880126e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 8.2139	Cost: 21.27s
Train Epoch: 289 [20480/90000 (23%)]	Loss: 7.6754	Cost: 9.12s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 7.8753	Cost: 9.15s
Train Epoch: 289 [61440/90000 (68%)]	Loss: 7.7753	Cost: 8.48s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 7.9073	Cost: 6.63s
Train Epoch: 289 	Average Loss: 7.8431
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1421

Saving model as e289_model.pt & e289_waveforms_supplementary.hdf5
Learning rate: 9.979406171676863e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 8.2154	Cost: 19.55s
Train Epoch: 290 [20480/90000 (23%)]	Loss: 7.8530	Cost: 7.83s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 7.8436	Cost: 9.25s
Train Epoch: 290 [61440/90000 (68%)]	Loss: 7.7123	Cost: 13.34s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 7.8931	Cost: 12.94s
Train Epoch: 290 	Average Loss: 7.8294
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1628

Learning rate: 9.979263506025915e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 8.0289	Cost: 24.83s
Train Epoch: 291 [20480/90000 (23%)]	Loss: 7.7380	Cost: 11.30s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 7.7771	Cost: 14.79s
Train Epoch: 291 [61440/90000 (68%)]	Loss: 7.7707	Cost: 13.12s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 7.7341	Cost: 12.13s
Train Epoch: 291 	Average Loss: 7.8385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1612

Learning rate: 9.97912034894136e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 8.1256	Cost: 34.01s
Train Epoch: 292 [20480/90000 (23%)]	Loss: 7.7665	Cost: 14.88s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 7.7208	Cost: 13.58s
Train Epoch: 292 [61440/90000 (68%)]	Loss: 7.7561	Cost: 12.25s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 7.7829	Cost: 12.19s
Train Epoch: 292 	Average Loss: 7.8265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1956

Learning rate: 9.978976700437328e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 8.1437	Cost: 28.15s
Train Epoch: 293 [20480/90000 (23%)]	Loss: 7.7140	Cost: 13.50s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 7.9036	Cost: 12.52s
Train Epoch: 293 [61440/90000 (68%)]	Loss: 7.8351	Cost: 9.51s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 7.7915	Cost: 8.30s
Train Epoch: 293 	Average Loss: 7.8128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1577

Learning rate: 9.978832560527998e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 8.0736	Cost: 22.95s
Train Epoch: 294 [20480/90000 (23%)]	Loss: 7.7169	Cost: 6.77s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 7.7915	Cost: 8.24s
Train Epoch: 294 [61440/90000 (68%)]	Loss: 7.6285	Cost: 9.12s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 7.7895	Cost: 8.94s
Train Epoch: 294 	Average Loss: 7.7882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2077

Learning rate: 9.978687929227592e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 8.0547	Cost: 22.45s
Train Epoch: 295 [20480/90000 (23%)]	Loss: 7.7745	Cost: 9.67s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 7.7373	Cost: 8.89s
Train Epoch: 295 [61440/90000 (68%)]	Loss: 7.8096	Cost: 6.99s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 7.7802	Cost: 5.96s
Train Epoch: 295 	Average Loss: 7.7814
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0996

Saving model as e295_model.pt & e295_waveforms_supplementary.hdf5
Learning rate: 9.978542806550388e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 7.9454	Cost: 22.48s
Train Epoch: 296 [20480/90000 (23%)]	Loss: 7.7692	Cost: 6.81s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 7.6676	Cost: 8.83s
Train Epoch: 296 [61440/90000 (68%)]	Loss: 7.7820	Cost: 9.87s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 7.6979	Cost: 12.59s
Train Epoch: 296 	Average Loss: 7.7628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0604

Saving model as e296_model.pt & e296_waveforms_supplementary.hdf5
Learning rate: 9.978397192510708e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 8.0811	Cost: 30.69s
Train Epoch: 297 [20480/90000 (23%)]	Loss: 7.6984	Cost: 12.54s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 7.7902	Cost: 12.58s
Train Epoch: 297 [61440/90000 (68%)]	Loss: 7.7076	Cost: 12.26s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 7.8369	Cost: 12.52s
Train Epoch: 297 	Average Loss: 7.7748
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0951

Learning rate: 9.978251087122923e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 8.0121	Cost: 41.43s
Train Epoch: 298 [20480/90000 (23%)]	Loss: 7.5534	Cost: 12.92s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 7.6578	Cost: 12.59s
Train Epoch: 298 [61440/90000 (68%)]	Loss: 7.6933	Cost: 9.48s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 7.7737	Cost: 6.05s
Train Epoch: 298 	Average Loss: 7.7353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0933

Learning rate: 9.978104490401455e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 8.0382	Cost: 27.78s
Train Epoch: 299 [20480/90000 (23%)]	Loss: 7.7247	Cost: 14.70s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 7.6004	Cost: 12.17s
Train Epoch: 299 [61440/90000 (68%)]	Loss: 7.6858	Cost: 6.83s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 7.7816	Cost: 7.30s
Train Epoch: 299 	Average Loss: 7.7311
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0910

Learning rate: 9.977957402360771e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 8.1925	Cost: 23.67s
Train Epoch: 300 [20480/90000 (23%)]	Loss: 7.6363	Cost: 8.75s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 7.6617	Cost: 7.85s
Train Epoch: 300 [61440/90000 (68%)]	Loss: 7.8020	Cost: 8.57s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 7.7165	Cost: 8.41s
Train Epoch: 300 	Average Loss: 7.7395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0662

Learning rate: 9.977809823015388e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 8.0590	Cost: 23.37s
Train Epoch: 301 [20480/90000 (23%)]	Loss: 7.5664	Cost: 8.53s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 7.7138	Cost: 9.45s
Train Epoch: 301 [61440/90000 (68%)]	Loss: 7.7887	Cost: 8.71s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 7.6848	Cost: 8.38s
Train Epoch: 301 	Average Loss: 7.7179
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0657

Learning rate: 9.97766175237987e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 8.0190	Cost: 33.50s
Train Epoch: 302 [20480/90000 (23%)]	Loss: 7.6874	Cost: 8.98s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 7.7524	Cost: 8.96s
Train Epoch: 302 [61440/90000 (68%)]	Loss: 7.8080	Cost: 6.27s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 7.7057	Cost: 6.05s
Train Epoch: 302 	Average Loss: 7.7251
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0776

Learning rate: 9.977513190468834e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 8.1555	Cost: 20.30s
Train Epoch: 303 [20480/90000 (23%)]	Loss: 7.5791	Cost: 9.35s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 7.7348	Cost: 10.83s
Train Epoch: 303 [61440/90000 (68%)]	Loss: 7.6600	Cost: 9.59s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 7.6618	Cost: 15.83s
Train Epoch: 303 	Average Loss: 7.7264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0367

Saving model as e303_model.pt & e303_waveforms_supplementary.hdf5
Learning rate: 9.977364137296942e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 8.0025	Cost: 26.59s
Train Epoch: 304 [20480/90000 (23%)]	Loss: 7.6292	Cost: 11.39s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 7.7443	Cost: 13.86s
Train Epoch: 304 [61440/90000 (68%)]	Loss: 7.6907	Cost: 12.70s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 7.6490	Cost: 12.32s
Train Epoch: 304 	Average Loss: 7.7278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0708

Learning rate: 9.977214592878902e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 8.1258	Cost: 30.19s
Train Epoch: 305 [20480/90000 (23%)]	Loss: 7.6867	Cost: 15.35s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 7.6329	Cost: 12.92s
Train Epoch: 305 [61440/90000 (68%)]	Loss: 7.6227	Cost: 12.18s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 7.5830	Cost: 7.68s
Train Epoch: 305 	Average Loss: 7.6758
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0450

Learning rate: 9.977064557229477e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 7.9882	Cost: 30.96s
Train Epoch: 306 [20480/90000 (23%)]	Loss: 7.5683	Cost: 9.04s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 7.7610	Cost: 6.36s
Train Epoch: 306 [61440/90000 (68%)]	Loss: 7.7048	Cost: 6.75s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 7.7075	Cost: 8.41s
Train Epoch: 306 	Average Loss: 7.6933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0814

Learning rate: 9.976914030363472e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 8.1817	Cost: 21.94s
Train Epoch: 307 [20480/90000 (23%)]	Loss: 7.6611	Cost: 8.34s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 7.8960	Cost: 9.18s
Train Epoch: 307 [61440/90000 (68%)]	Loss: 7.6558	Cost: 8.65s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 7.6387	Cost: 8.85s
Train Epoch: 307 	Average Loss: 7.6817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9867

Saving model as e307_model.pt & e307_waveforms_supplementary.hdf5
Learning rate: 9.976763012295747e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 8.0921	Cost: 21.62s
Train Epoch: 308 [20480/90000 (23%)]	Loss: 7.5478	Cost: 11.33s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 7.6063	Cost: 10.18s
Train Epoch: 308 [61440/90000 (68%)]	Loss: 7.6952	Cost: 6.47s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 7.7114	Cost: 6.71s
Train Epoch: 308 	Average Loss: 7.6858
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0055

Learning rate: 9.976611503041203e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 8.0434	Cost: 24.71s
Train Epoch: 309 [20480/90000 (23%)]	Loss: 7.6521	Cost: 9.78s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 7.6377	Cost: 17.91s
Train Epoch: 309 [61440/90000 (68%)]	Loss: 7.5445	Cost: 12.75s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 7.6622	Cost: 12.41s
Train Epoch: 309 	Average Loss: 7.6600
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9903

Learning rate: 9.976459502614796e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 8.0837	Cost: 26.94s
Train Epoch: 310 [20480/90000 (23%)]	Loss: 7.7307	Cost: 11.82s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 7.6471	Cost: 12.79s
Train Epoch: 310 [61440/90000 (68%)]	Loss: 7.6453	Cost: 12.55s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 7.6090	Cost: 12.45s
Train Epoch: 310 	Average Loss: 7.6680
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0974

Learning rate: 9.976307011031527e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 7.9494	Cost: 27.28s
Train Epoch: 311 [20480/90000 (23%)]	Loss: 7.4849	Cost: 9.46s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 7.7192	Cost: 12.47s
Train Epoch: 311 [61440/90000 (68%)]	Loss: 7.6634	Cost: 12.42s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 7.7833	Cost: 9.68s
Train Epoch: 311 	Average Loss: 7.6328
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9744

Saving model as e311_model.pt & e311_waveforms_supplementary.hdf5
Learning rate: 9.976154028306446e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 8.1907	Cost: 23.04s
Train Epoch: 312 [20480/90000 (23%)]	Loss: 7.4572	Cost: 12.59s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 7.6351	Cost: 7.82s
Train Epoch: 312 [61440/90000 (68%)]	Loss: 7.6747	Cost: 6.39s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 7.5790	Cost: 8.36s
Train Epoch: 312 	Average Loss: 7.6204
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9944

Learning rate: 9.976000554454652e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 8.0743	Cost: 28.72s
Train Epoch: 313 [20480/90000 (23%)]	Loss: 7.4936	Cost: 11.04s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 7.4753	Cost: 9.27s
Train Epoch: 313 [61440/90000 (68%)]	Loss: 7.6602	Cost: 7.12s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 7.6315	Cost: 8.80s
Train Epoch: 313 	Average Loss: 7.6453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9647

Saving model as e313_model.pt & e313_waveforms_supplementary.hdf5
Learning rate: 9.975846589491293e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 7.8638	Cost: 19.63s
Train Epoch: 314 [20480/90000 (23%)]	Loss: 7.5513	Cost: 9.78s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 7.6491	Cost: 12.22s
Train Epoch: 314 [61440/90000 (68%)]	Loss: 7.5417	Cost: 9.56s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 7.5658	Cost: 8.82s
Train Epoch: 314 	Average Loss: 7.6116
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0315

Learning rate: 9.975692133431563e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 8.0162	Cost: 33.19s
Train Epoch: 315 [20480/90000 (23%)]	Loss: 7.6806	Cost: 8.86s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 7.5682	Cost: 8.85s
Train Epoch: 315 [61440/90000 (68%)]	Loss: 7.5846	Cost: 8.55s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 7.5643	Cost: 6.95s
Train Epoch: 315 	Average Loss: 7.6475
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9832

Learning rate: 9.975537186290708e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 7.9541	Cost: 19.82s
Train Epoch: 316 [20480/90000 (23%)]	Loss: 7.4844	Cost: 8.89s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 7.6161	Cost: 6.11s
Train Epoch: 316 [61440/90000 (68%)]	Loss: 7.5497	Cost: 6.87s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 7.6631	Cost: 9.57s
Train Epoch: 316 	Average Loss: 7.6005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9489

Saving model as e316_model.pt & e316_waveforms_supplementary.hdf5
Learning rate: 9.975381748084019e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 7.9270	Cost: 25.23s
Train Epoch: 317 [20480/90000 (23%)]	Loss: 7.3827	Cost: 8.23s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 7.5134	Cost: 11.86s
Train Epoch: 317 [61440/90000 (68%)]	Loss: 7.6654	Cost: 12.38s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 7.4244	Cost: 12.75s
Train Epoch: 317 	Average Loss: 7.5860
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9751

Learning rate: 9.975225818826839e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 8.1630	Cost: 35.06s
Train Epoch: 318 [20480/90000 (23%)]	Loss: 7.5030	Cost: 14.87s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 7.6062	Cost: 14.01s
Train Epoch: 318 [61440/90000 (68%)]	Loss: 7.4711	Cost: 12.07s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 7.5964	Cost: 12.47s
Train Epoch: 318 	Average Loss: 7.5742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9899

Learning rate: 9.975069398534559e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 7.9468	Cost: 42.98s
Train Epoch: 319 [20480/90000 (23%)]	Loss: 7.3930	Cost: 12.80s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 7.4770	Cost: 12.45s
Train Epoch: 319 [61440/90000 (68%)]	Loss: 7.5845	Cost: 8.28s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 7.5745	Cost: 6.08s
Train Epoch: 319 	Average Loss: 7.5527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9440

Saving model as e319_model.pt & e319_waveforms_supplementary.hdf5
Learning rate: 9.974912487222611e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 7.9774	Cost: 25.26s
Train Epoch: 320 [20480/90000 (23%)]	Loss: 7.4108	Cost: 11.98s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 7.6757	Cost: 7.92s
Train Epoch: 320 [61440/90000 (68%)]	Loss: 7.5013	Cost: 6.27s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 7.7283	Cost: 7.50s
Train Epoch: 320 	Average Loss: 7.5806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9870

Learning rate: 9.974755084906488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 7.9603	Cost: 20.02s
Train Epoch: 321 [20480/90000 (23%)]	Loss: 7.5114	Cost: 6.65s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 7.6190	Cost: 9.40s
Train Epoch: 321 [61440/90000 (68%)]	Loss: 7.4434	Cost: 8.69s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 7.5759	Cost: 8.40s
Train Epoch: 321 	Average Loss: 7.5310
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0011

Learning rate: 9.974597191601719e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 7.9773	Cost: 21.26s
Train Epoch: 322 [20480/90000 (23%)]	Loss: 7.4472	Cost: 7.72s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 7.4944	Cost: 8.91s
Train Epoch: 322 [61440/90000 (68%)]	Loss: 7.5321	Cost: 8.73s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 7.5759	Cost: 9.05s
Train Epoch: 322 	Average Loss: 7.5279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9721

Learning rate: 9.974438807323893e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 7.9698	Cost: 27.56s
Train Epoch: 323 [20480/90000 (23%)]	Loss: 7.3848	Cost: 10.07s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 7.4630	Cost: 9.29s
Train Epoch: 323 [61440/90000 (68%)]	Loss: 7.4874	Cost: 6.06s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 7.5804	Cost: 6.32s
Train Epoch: 323 	Average Loss: 7.5119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9843

Learning rate: 9.97427993208864e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 7.9024	Cost: 23.70s
Train Epoch: 324 [20480/90000 (23%)]	Loss: 7.4401	Cost: 10.00s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 7.5544	Cost: 11.61s
Train Epoch: 324 [61440/90000 (68%)]	Loss: 7.4625	Cost: 11.84s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 7.4125	Cost: 12.52s
Train Epoch: 324 	Average Loss: 7.5210
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9631

Learning rate: 9.97412056591164e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 8.0509	Cost: 26.24s
Train Epoch: 325 [20480/90000 (23%)]	Loss: 7.3597	Cost: 10.69s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 7.5544	Cost: 13.60s
Train Epoch: 325 [61440/90000 (68%)]	Loss: 7.5129	Cost: 12.37s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 7.4969	Cost: 12.39s
Train Epoch: 325 	Average Loss: 7.5085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9460

Learning rate: 9.973960708808621e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 7.9335	Cost: 29.55s
Train Epoch: 326 [20480/90000 (23%)]	Loss: 7.4240	Cost: 11.65s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 7.5640	Cost: 12.42s
Train Epoch: 326 [61440/90000 (68%)]	Loss: 7.4329	Cost: 12.00s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 7.6098	Cost: 8.44s
Train Epoch: 326 	Average Loss: 7.5101
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9189

Saving model as e326_model.pt & e326_waveforms_supplementary.hdf5
Learning rate: 9.97380036079536e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 7.9843	Cost: 24.94s
Train Epoch: 327 [20480/90000 (23%)]	Loss: 7.4033	Cost: 12.02s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 7.3551	Cost: 8.71s
Train Epoch: 327 [61440/90000 (68%)]	Loss: 7.3216	Cost: 6.29s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 7.5181	Cost: 7.62s
Train Epoch: 327 	Average Loss: 7.4696
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9134

Saving model as e327_model.pt & e327_waveforms_supplementary.hdf5
Learning rate: 9.973639521887684e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 7.8418	Cost: 27.07s
Train Epoch: 328 [20480/90000 (23%)]	Loss: 7.3901	Cost: 10.72s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 7.5825	Cost: 10.36s
Train Epoch: 328 [61440/90000 (68%)]	Loss: 7.3887	Cost: 9.15s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 7.5212	Cost: 8.74s
Train Epoch: 328 	Average Loss: 7.4628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0317

Learning rate: 9.973478192101466e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 7.9683	Cost: 21.50s
Train Epoch: 329 [20480/90000 (23%)]	Loss: 7.4628	Cost: 11.55s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 7.3925	Cost: 10.06s
Train Epoch: 329 [61440/90000 (68%)]	Loss: 7.4229	Cost: 9.03s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 7.4367	Cost: 8.85s
Train Epoch: 329 	Average Loss: 7.4776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8937

Saving model as e329_model.pt & e329_waveforms_supplementary.hdf5
Learning rate: 9.973316371452633e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 7.7897	Cost: 21.70s
Train Epoch: 330 [20480/90000 (23%)]	Loss: 7.3611	Cost: 8.50s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 7.4201	Cost: 9.13s
Train Epoch: 330 [61440/90000 (68%)]	Loss: 7.5296	Cost: 8.66s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 7.4867	Cost: 8.40s
Train Epoch: 330 	Average Loss: 7.4491
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8606

Saving model as e330_model.pt & e330_waveforms_supplementary.hdf5
Learning rate: 9.97315405995715e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 7.7357	Cost: 25.41s
Train Epoch: 331 [20480/90000 (23%)]	Loss: 7.3272	Cost: 8.76s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 7.4480	Cost: 8.89s
Train Epoch: 331 [61440/90000 (68%)]	Loss: 7.3544	Cost: 8.64s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 7.3893	Cost: 8.52s
Train Epoch: 331 	Average Loss: 7.4236
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7991

Saving model as e331_model.pt & e331_waveforms_supplementary.hdf5
Learning rate: 9.97299125763104e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 7.6903	Cost: 44.37s
Train Epoch: 332 [20480/90000 (23%)]	Loss: 7.3045	Cost: 12.88s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 7.4506	Cost: 13.32s
Train Epoch: 332 [61440/90000 (68%)]	Loss: 7.4612	Cost: 9.70s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 7.3450	Cost: 13.69s
Train Epoch: 332 	Average Loss: 7.4075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8420

Learning rate: 9.972827964490369e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 7.7299	Cost: 20.95s
Train Epoch: 333 [20480/90000 (23%)]	Loss: 7.3392	Cost: 7.36s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 7.3036	Cost: 12.70s
Train Epoch: 333 [61440/90000 (68%)]	Loss: 7.3594	Cost: 12.48s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 7.4762	Cost: 16.69s
Train Epoch: 333 	Average Loss: 7.4102
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8346

Learning rate: 9.972664180551254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 7.7175	Cost: 22.65s
Train Epoch: 334 [20480/90000 (23%)]	Loss: 7.3312	Cost: 12.89s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 7.4599	Cost: 14.53s
Train Epoch: 334 [61440/90000 (68%)]	Loss: 7.4437	Cost: 13.06s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 7.3793	Cost: 12.45s
Train Epoch: 334 	Average Loss: 7.4100
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8759

Learning rate: 9.972499905829862e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 7.7344	Cost: 25.56s
Train Epoch: 335 [20480/90000 (23%)]	Loss: 7.2657	Cost: 14.54s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 7.3506	Cost: 12.92s
Train Epoch: 335 [61440/90000 (68%)]	Loss: 7.4305	Cost: 12.11s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 7.3618	Cost: 7.75s
Train Epoch: 335 	Average Loss: 7.4042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8969

Learning rate: 9.972335140342403e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 7.8337	Cost: 38.13s
Train Epoch: 336 [20480/90000 (23%)]	Loss: 7.3302	Cost: 11.94s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 7.3480	Cost: 6.72s
Train Epoch: 336 [61440/90000 (68%)]	Loss: 7.3706	Cost: 6.28s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 7.3380	Cost: 7.82s
Train Epoch: 336 	Average Loss: 7.3685
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8664

Learning rate: 9.972169884105142e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 7.7051	Cost: 29.72s
Train Epoch: 337 [20480/90000 (23%)]	Loss: 7.2072	Cost: 6.43s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 7.3677	Cost: 10.96s
Train Epoch: 337 [61440/90000 (68%)]	Loss: 7.3040	Cost: 8.58s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 7.3915	Cost: 8.43s
Train Epoch: 337 	Average Loss: 7.3584
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8034

Learning rate: 9.972004137134385e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 7.7411	Cost: 24.20s
Train Epoch: 338 [20480/90000 (23%)]	Loss: 7.2537	Cost: 7.92s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 7.4396	Cost: 8.95s
Train Epoch: 338 [61440/90000 (68%)]	Loss: 7.3904	Cost: 9.11s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 7.3230	Cost: 8.86s
Train Epoch: 338 	Average Loss: 7.3554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8612

Learning rate: 9.971837899446494e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 7.9550	Cost: 24.10s
Train Epoch: 339 [20480/90000 (23%)]	Loss: 7.1670	Cost: 8.59s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 7.3578	Cost: 11.44s
Train Epoch: 339 [61440/90000 (68%)]	Loss: 7.5310	Cost: 9.50s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 7.3653	Cost: 13.48s
Train Epoch: 339 	Average Loss: 7.4072
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8497

Learning rate: 9.971671171057876e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 7.7820	Cost: 26.35s
Train Epoch: 340 [20480/90000 (23%)]	Loss: 7.3088	Cost: 10.80s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 7.5175	Cost: 15.12s
Train Epoch: 340 [61440/90000 (68%)]	Loss: 7.3280	Cost: 12.33s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 7.3577	Cost: 12.28s
Train Epoch: 340 	Average Loss: 7.4187
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8756

Learning rate: 9.971503951984984e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 7.7470	Cost: 29.26s
Train Epoch: 341 [20480/90000 (23%)]	Loss: 7.3601	Cost: 11.63s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 7.2925	Cost: 12.44s
Train Epoch: 341 [61440/90000 (68%)]	Loss: 7.3016	Cost: 12.19s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 7.3848	Cost: 8.56s
Train Epoch: 341 	Average Loss: 7.3427
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8839

Learning rate: 9.971336242244322e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 7.7250	Cost: 24.56s
Train Epoch: 342 [20480/90000 (23%)]	Loss: 7.3325	Cost: 10.44s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 7.1589	Cost: 9.98s
Train Epoch: 342 [61440/90000 (68%)]	Loss: 7.3398	Cost: 6.17s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 7.4690	Cost: 6.53s
Train Epoch: 342 	Average Loss: 7.3301
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7753

Saving model as e342_model.pt & e342_waveforms_supplementary.hdf5
Learning rate: 9.971168041852446e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 7.8222	Cost: 25.77s
Train Epoch: 343 [20480/90000 (23%)]	Loss: 7.1639	Cost: 11.10s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 7.3649	Cost: 9.51s
Train Epoch: 343 [61440/90000 (68%)]	Loss: 7.2472	Cost: 7.05s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 7.3456	Cost: 9.17s
Train Epoch: 343 	Average Loss: 7.3115
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8436

Learning rate: 9.970999350825954e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 7.8353	Cost: 19.32s
Train Epoch: 344 [20480/90000 (23%)]	Loss: 7.2395	Cost: 7.87s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 7.2383	Cost: 12.93s
Train Epoch: 344 [61440/90000 (68%)]	Loss: 7.1868	Cost: 9.12s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 7.3906	Cost: 8.86s
Train Epoch: 344 	Average Loss: 7.3047
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7494

Saving model as e344_model.pt & e344_waveforms_supplementary.hdf5
Learning rate: 9.970830169181494e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 7.6314	Cost: 23.72s
Train Epoch: 345 [20480/90000 (23%)]	Loss: 7.2297	Cost: 6.64s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 7.2510	Cost: 9.25s
Train Epoch: 345 [61440/90000 (68%)]	Loss: 7.2667	Cost: 10.63s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 7.1859	Cost: 12.73s
Train Epoch: 345 	Average Loss: 7.2905
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7631

Learning rate: 9.970660496935765e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 7.6965	Cost: 22.89s
Train Epoch: 346 [20480/90000 (23%)]	Loss: 7.2209	Cost: 10.02s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 7.2680	Cost: 13.24s
Train Epoch: 346 [61440/90000 (68%)]	Loss: 7.2628	Cost: 12.27s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 7.2513	Cost: 12.31s
Train Epoch: 346 	Average Loss: 7.2649
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7488

Saving model as e346_model.pt & e346_waveforms_supplementary.hdf5
Learning rate: 9.970490334105514e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 7.7927	Cost: 25.25s
Train Epoch: 347 [20480/90000 (23%)]	Loss: 7.1974	Cost: 13.70s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 7.2383	Cost: 14.04s
Train Epoch: 347 [61440/90000 (68%)]	Loss: 7.2900	Cost: 12.34s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 7.1746	Cost: 10.08s
Train Epoch: 347 	Average Loss: 7.2705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7843

Learning rate: 9.970319680707532e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 7.6714	Cost: 40.39s
Train Epoch: 348 [20480/90000 (23%)]	Loss: 7.1224	Cost: 13.26s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 7.3280	Cost: 12.26s
Train Epoch: 348 [61440/90000 (68%)]	Loss: 7.2534	Cost: 8.23s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 7.2567	Cost: 6.03s
Train Epoch: 348 	Average Loss: 7.2488
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7427

Saving model as e348_model.pt & e348_waveforms_supplementary.hdf5
Learning rate: 9.970148536758666e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 7.7230	Cost: 35.61s
Train Epoch: 349 [20480/90000 (23%)]	Loss: 7.0871	Cost: 8.15s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 7.1682	Cost: 6.55s
Train Epoch: 349 [61440/90000 (68%)]	Loss: 7.2458	Cost: 7.08s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 7.1074	Cost: 9.03s
Train Epoch: 349 	Average Loss: 7.2337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6862

Saving model as e349_model.pt & e349_waveforms_supplementary.hdf5
Learning rate: 9.969976902275804e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 7.7003	Cost: 19.80s
Train Epoch: 350 [20480/90000 (23%)]	Loss: 7.2044	Cost: 7.20s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 7.2900	Cost: 9.57s
Train Epoch: 350 [61440/90000 (68%)]	Loss: 7.1447	Cost: 8.73s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 7.1821	Cost: 9.15s
Train Epoch: 350 	Average Loss: 7.2278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6805

Saving model as e350_model.pt & e350_waveforms_supplementary.hdf5
Learning rate: 9.969804777275889e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 7.7044	Cost: 21.93s
Train Epoch: 351 [20480/90000 (23%)]	Loss: 7.2156	Cost: 9.12s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 7.2586	Cost: 8.97s
Train Epoch: 351 [61440/90000 (68%)]	Loss: 7.2786	Cost: 8.92s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 7.2565	Cost: 7.84s
Train Epoch: 351 	Average Loss: 7.2293
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7887

Learning rate: 9.969632161775905e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 7.8599	Cost: 23.73s
Train Epoch: 352 [20480/90000 (23%)]	Loss: 7.1067	Cost: 9.03s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 7.2452	Cost: 9.68s
Train Epoch: 352 [61440/90000 (68%)]	Loss: 7.1581	Cost: 11.59s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 7.1935	Cost: 12.53s
Train Epoch: 352 	Average Loss: 7.2161
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6999

Learning rate: 9.969459055792892e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 7.6614	Cost: 27.34s
Train Epoch: 353 [20480/90000 (23%)]	Loss: 7.0253	Cost: 10.71s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 7.2059	Cost: 12.80s
Train Epoch: 353 [61440/90000 (68%)]	Loss: 7.1096	Cost: 12.25s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 7.0549	Cost: 12.08s
Train Epoch: 353 	Average Loss: 7.1902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6857

Learning rate: 9.969285459343932e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 7.7238	Cost: 27.53s
Train Epoch: 354 [20480/90000 (23%)]	Loss: 7.1485	Cost: 11.88s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 7.1610	Cost: 12.63s
Train Epoch: 354 [61440/90000 (68%)]	Loss: 7.1376	Cost: 12.37s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 7.0752	Cost: 8.48s
Train Epoch: 354 	Average Loss: 7.1691
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6336

Saving model as e354_model.pt & e354_waveforms_supplementary.hdf5
Learning rate: 9.96911137244616e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 7.6205	Cost: 38.15s
Train Epoch: 355 [20480/90000 (23%)]	Loss: 7.0497	Cost: 13.90s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 7.1437	Cost: 11.51s
Train Epoch: 355 [61440/90000 (68%)]	Loss: 7.1021	Cost: 6.09s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 7.1506	Cost: 7.10s
Train Epoch: 355 	Average Loss: 7.1751
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6995

Learning rate: 9.968936795116758e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 7.6934	Cost: 25.02s
Train Epoch: 356 [20480/90000 (23%)]	Loss: 6.9230	Cost: 11.19s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 7.0840	Cost: 10.28s
Train Epoch: 356 [61440/90000 (68%)]	Loss: 7.1022	Cost: 9.40s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 7.1205	Cost: 8.64s
Train Epoch: 356 	Average Loss: 7.1759
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6248

Saving model as e356_model.pt & e356_waveforms_supplementary.hdf5
Learning rate: 9.968761727372955e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 7.6701	Cost: 24.41s
Train Epoch: 357 [20480/90000 (23%)]	Loss: 7.0541	Cost: 9.67s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 7.1124	Cost: 8.96s
Train Epoch: 357 [61440/90000 (68%)]	Loss: 7.1539	Cost: 8.92s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 7.1539	Cost: 6.38s
Train Epoch: 357 	Average Loss: 7.1517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7356

Learning rate: 9.96858616923203e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 7.6154	Cost: 19.93s
Train Epoch: 358 [20480/90000 (23%)]	Loss: 7.1233	Cost: 6.45s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 7.0874	Cost: 12.99s
Train Epoch: 358 [61440/90000 (68%)]	Loss: 7.1679	Cost: 11.92s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 7.1306	Cost: 11.76s
Train Epoch: 358 	Average Loss: 7.1585
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6947

Learning rate: 9.96841012071131e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 7.5521	Cost: 21.64s
Train Epoch: 359 [20480/90000 (23%)]	Loss: 7.0124	Cost: 9.53s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 7.0998	Cost: 10.82s
Train Epoch: 359 [61440/90000 (68%)]	Loss: 7.0898	Cost: 12.68s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 6.9346	Cost: 12.27s
Train Epoch: 359 	Average Loss: 7.1017
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6484

Learning rate: 9.968233581828168e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 7.6110	Cost: 26.28s
Train Epoch: 360 [20480/90000 (23%)]	Loss: 6.9514	Cost: 14.60s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 7.0417	Cost: 13.58s
Train Epoch: 360 [61440/90000 (68%)]	Loss: 7.0909	Cost: 12.33s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 7.1581	Cost: 10.00s
Train Epoch: 360 	Average Loss: 7.1070
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6198

Saving model as e360_model.pt & e360_waveforms_supplementary.hdf5
Learning rate: 9.968056552600032e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 7.6309	Cost: 41.01s
Train Epoch: 361 [20480/90000 (23%)]	Loss: 6.9960	Cost: 8.27s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 7.2104	Cost: 11.43s
Train Epoch: 361 [61440/90000 (68%)]	Loss: 7.0549	Cost: 6.15s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 6.9789	Cost: 6.07s
Train Epoch: 361 	Average Loss: 7.1030
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6758

Learning rate: 9.967879033044371e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 7.5140	Cost: 27.46s
Train Epoch: 362 [20480/90000 (23%)]	Loss: 6.9055	Cost: 11.15s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 7.1944	Cost: 12.50s
Train Epoch: 362 [61440/90000 (68%)]	Loss: 7.1599	Cost: 6.36s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 7.1039	Cost: 6.15s
Train Epoch: 362 	Average Loss: 7.0964
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6718

Learning rate: 9.967701023178707e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 7.7903	Cost: 34.65s
Train Epoch: 363 [20480/90000 (23%)]	Loss: 7.0640	Cost: 10.19s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 7.0781	Cost: 6.67s
Train Epoch: 363 [61440/90000 (68%)]	Loss: 7.1473	Cost: 6.57s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 7.1372	Cost: 8.78s
Train Epoch: 363 	Average Loss: 7.0885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6802

Learning rate: 9.967522523020609e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 7.5620	Cost: 19.43s
Train Epoch: 364 [20480/90000 (23%)]	Loss: 7.0066	Cost: 7.16s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 7.0198	Cost: 9.53s
Train Epoch: 364 [61440/90000 (68%)]	Loss: 6.9939	Cost: 8.71s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 7.1469	Cost: 8.89s
Train Epoch: 364 	Average Loss: 7.0729
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6714

Learning rate: 9.967343532587693e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 7.6561	Cost: 22.63s
Train Epoch: 365 [20480/90000 (23%)]	Loss: 6.9812	Cost: 7.50s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 7.0112	Cost: 9.14s
Train Epoch: 365 [61440/90000 (68%)]	Loss: 7.0471	Cost: 9.01s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 7.0350	Cost: 9.09s
Train Epoch: 365 	Average Loss: 7.0585
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6225

Learning rate: 9.967164051897624e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 7.5228	Cost: 29.96s
Train Epoch: 366 [20480/90000 (23%)]	Loss: 6.9890	Cost: 9.36s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 7.1570	Cost: 7.15s
Train Epoch: 366 [61440/90000 (68%)]	Loss: 7.0520	Cost: 6.78s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 6.9322	Cost: 6.64s
Train Epoch: 366 	Average Loss: 7.0639
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5980

Saving model as e366_model.pt & e366_waveforms_supplementary.hdf5
Learning rate: 9.966984080968118e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 7.5369	Cost: 38.10s
Train Epoch: 367 [20480/90000 (23%)]	Loss: 6.8545	Cost: 11.75s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 7.1195	Cost: 13.42s
Train Epoch: 367 [61440/90000 (68%)]	Loss: 6.9918	Cost: 12.23s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 7.0029	Cost: 12.18s
Train Epoch: 367 	Average Loss: 7.0375
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6423

Learning rate: 9.966803619816938e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 7.5624	Cost: 28.31s
Train Epoch: 368 [20480/90000 (23%)]	Loss: 6.9387	Cost: 11.92s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 7.0491	Cost: 12.78s
Train Epoch: 368 [61440/90000 (68%)]	Loss: 7.0920	Cost: 12.57s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 6.9799	Cost: 8.50s
Train Epoch: 368 	Average Loss: 7.0087
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5027

Saving model as e368_model.pt & e368_waveforms_supplementary.hdf5
Learning rate: 9.966622668461892e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 7.4121	Cost: 25.46s
Train Epoch: 369 [20480/90000 (23%)]	Loss: 6.8719	Cost: 12.34s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 6.9655	Cost: 12.58s
Train Epoch: 369 [61440/90000 (68%)]	Loss: 6.8582	Cost: 8.79s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 6.8730	Cost: 6.94s
Train Epoch: 369 	Average Loss: 6.9873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6056

Learning rate: 9.96644122692084e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 7.6581	Cost: 22.35s
Train Epoch: 370 [20480/90000 (23%)]	Loss: 7.0595	Cost: 11.81s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 6.8954	Cost: 9.55s
Train Epoch: 370 [61440/90000 (68%)]	Loss: 6.8261	Cost: 6.48s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 6.8300	Cost: 7.18s
Train Epoch: 370 	Average Loss: 7.0180
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4845

Saving model as e370_model.pt & e370_waveforms_supplementary.hdf5
Learning rate: 9.966259295211689e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 7.4374	Cost: 31.19s
Train Epoch: 371 [20480/90000 (23%)]	Loss: 6.9985	Cost: 10.33s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 6.9506	Cost: 8.90s
Train Epoch: 371 [61440/90000 (68%)]	Loss: 6.9417	Cost: 7.46s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 6.8060	Cost: 8.59s
Train Epoch: 371 	Average Loss: 6.9759
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5968

Learning rate: 9.966076873352397e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 7.5785	Cost: 28.23s
Train Epoch: 372 [20480/90000 (23%)]	Loss: 7.0038	Cost: 8.79s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 6.9743	Cost: 9.12s
Train Epoch: 372 [61440/90000 (68%)]	Loss: 6.9368	Cost: 8.57s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 6.9458	Cost: 8.59s
Train Epoch: 372 	Average Loss: 6.9697
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5671

Learning rate: 9.965893961360968e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 7.4304	Cost: 21.95s
Train Epoch: 373 [20480/90000 (23%)]	Loss: 7.0231	Cost: 8.81s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 6.8899	Cost: 8.93s
Train Epoch: 373 [61440/90000 (68%)]	Loss: 6.8260	Cost: 6.75s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 6.9629	Cost: 6.97s
Train Epoch: 373 	Average Loss: 6.9553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5907

Learning rate: 9.965710559255453e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 7.4817	Cost: 19.99s
Train Epoch: 374 [20480/90000 (23%)]	Loss: 6.8607	Cost: 8.02s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 6.9209	Cost: 9.50s
Train Epoch: 374 [61440/90000 (68%)]	Loss: 6.9118	Cost: 11.88s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 6.8111	Cost: 12.63s
Train Epoch: 374 	Average Loss: 6.9334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5906

Learning rate: 9.965526667053955e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 7.5778	Cost: 21.79s
Train Epoch: 375 [20480/90000 (23%)]	Loss: 6.7108	Cost: 10.41s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 6.9195	Cost: 14.72s
Train Epoch: 375 [61440/90000 (68%)]	Loss: 7.0344	Cost: 12.63s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 6.8788	Cost: 12.26s
Train Epoch: 375 	Average Loss: 6.9312
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5312

Learning rate: 9.965342284774624e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 7.4880	Cost: 41.51s
Train Epoch: 376 [20480/90000 (23%)]	Loss: 6.9109	Cost: 9.68s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 7.1296	Cost: 12.44s
Train Epoch: 376 [61440/90000 (68%)]	Loss: 6.8167	Cost: 12.23s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 6.9085	Cost: 7.60s
Train Epoch: 376 	Average Loss: 6.9493
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5752

Learning rate: 9.965157412435655e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 7.6324	Cost: 36.78s
Train Epoch: 377 [20480/90000 (23%)]	Loss: 6.7532	Cost: 9.41s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 6.8123	Cost: 6.55s
Train Epoch: 377 [61440/90000 (68%)]	Loss: 6.8558	Cost: 7.17s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 6.8210	Cost: 8.95s
Train Epoch: 377 	Average Loss: 6.9105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5288

Learning rate: 9.964972050055294e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 7.5053	Cost: 24.07s
Train Epoch: 378 [20480/90000 (23%)]	Loss: 6.7738	Cost: 10.52s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 6.9563	Cost: 11.07s
Train Epoch: 378 [61440/90000 (68%)]	Loss: 7.0512	Cost: 8.94s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 6.8500	Cost: 8.66s
Train Epoch: 378 	Average Loss: 6.9033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4935

Learning rate: 9.964786197651839e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 7.5382	Cost: 22.63s
Train Epoch: 379 [20480/90000 (23%)]	Loss: 6.8329	Cost: 10.96s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 6.9859	Cost: 10.32s
Train Epoch: 379 [61440/90000 (68%)]	Loss: 6.8505	Cost: 8.95s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 6.9385	Cost: 8.88s
Train Epoch: 379 	Average Loss: 6.8874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5481

Learning rate: 9.96459985524363e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 7.4861	Cost: 20.45s
Train Epoch: 380 [20480/90000 (23%)]	Loss: 6.7930	Cost: 8.87s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 6.8301	Cost: 8.75s
Train Epoch: 380 [61440/90000 (68%)]	Loss: 6.8874	Cost: 7.70s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 6.9450	Cost: 7.15s
Train Epoch: 380 	Average Loss: 6.8829
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5225

Learning rate: 9.96441302284906e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 7.3022	Cost: 19.85s
Train Epoch: 381 [20480/90000 (23%)]	Loss: 6.8773	Cost: 7.52s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 6.8906	Cost: 11.97s
Train Epoch: 381 [61440/90000 (68%)]	Loss: 6.8180	Cost: 13.90s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 6.8433	Cost: 16.01s
Train Epoch: 381 	Average Loss: 6.8597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5234

Learning rate: 9.964225700486566e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 7.4195	Cost: 29.32s
Train Epoch: 382 [20480/90000 (23%)]	Loss: 6.7560	Cost: 14.21s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 6.8016	Cost: 13.73s
Train Epoch: 382 [61440/90000 (68%)]	Loss: 6.7332	Cost: 11.99s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 6.8073	Cost: 12.14s
Train Epoch: 382 	Average Loss: 6.8582
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5128

Learning rate: 9.96403788817464e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 7.4140	Cost: 36.88s
Train Epoch: 383 [20480/90000 (23%)]	Loss: 6.7012	Cost: 12.06s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 6.8754	Cost: 7.37s
Train Epoch: 383 [61440/90000 (68%)]	Loss: 6.7207	Cost: 6.32s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 6.8378	Cost: 7.74s
Train Epoch: 383 	Average Loss: 6.8441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5563

Learning rate: 9.963849585931816e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 7.3812	Cost: 21.67s
Train Epoch: 384 [20480/90000 (23%)]	Loss: 6.8182	Cost: 8.61s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 6.9458	Cost: 8.96s
Train Epoch: 384 [61440/90000 (68%)]	Loss: 6.7896	Cost: 9.01s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 6.8387	Cost: 8.98s
Train Epoch: 384 	Average Loss: 6.8714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5150

Learning rate: 9.963660793776678e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 7.4421	Cost: 24.58s
Train Epoch: 385 [20480/90000 (23%)]	Loss: 6.8477	Cost: 9.94s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 6.7909	Cost: 6.77s
Train Epoch: 385 [61440/90000 (68%)]	Loss: 6.7354	Cost: 7.25s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 6.8950	Cost: 6.68s
Train Epoch: 385 	Average Loss: 6.8650
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5452

Learning rate: 9.963471511727859e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 7.4641	Cost: 28.79s
Train Epoch: 386 [20480/90000 (23%)]	Loss: 6.6512	Cost: 9.91s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 6.8995	Cost: 10.41s
Train Epoch: 386 [61440/90000 (68%)]	Loss: 6.7519	Cost: 13.10s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 6.9396	Cost: 12.72s
Train Epoch: 386 	Average Loss: 6.8420
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4686

Saving model as e386_model.pt & e386_waveforms_supplementary.hdf5
Learning rate: 9.963281739804043e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 7.3501	Cost: 29.66s
Train Epoch: 387 [20480/90000 (23%)]	Loss: 6.7320	Cost: 12.51s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 6.8219	Cost: 13.69s
Train Epoch: 387 [61440/90000 (68%)]	Loss: 6.7264	Cost: 12.23s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 6.7504	Cost: 12.16s
Train Epoch: 387 	Average Loss: 6.8153
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4859

Learning rate: 9.963091478023956e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 7.3245	Cost: 30.47s
Train Epoch: 388 [20480/90000 (23%)]	Loss: 6.8034	Cost: 11.18s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 6.7745	Cost: 12.71s
Train Epoch: 388 [61440/90000 (68%)]	Loss: 6.7702	Cost: 12.77s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 6.8875	Cost: 8.82s
Train Epoch: 388 	Average Loss: 6.8069
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4919

Learning rate: 9.962900726406379e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 7.5073	Cost: 25.43s
Train Epoch: 389 [20480/90000 (23%)]	Loss: 6.9161	Cost: 12.83s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 6.9081	Cost: 12.04s
Train Epoch: 389 [61440/90000 (68%)]	Loss: 6.8608	Cost: 6.44s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 6.8212	Cost: 6.86s
Train Epoch: 389 	Average Loss: 6.8352
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4568

Saving model as e389_model.pt & e389_waveforms_supplementary.hdf5
Learning rate: 9.962709484970139e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 7.5675	Cost: 19.36s
Train Epoch: 390 [20480/90000 (23%)]	Loss: 6.7152	Cost: 6.43s
Train Epoch: 390 [40960/90000 (45%)]	Loss: 6.7803	Cost: 10.95s
Train Epoch: 390 [61440/90000 (68%)]	Loss: 6.5778	Cost: 8.93s
Train Epoch: 390 [81920/90000 (91%)]	Loss: 6.7803	Cost: 8.74s
Train Epoch: 390 	Average Loss: 6.7614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4348

Saving model as e390_model.pt & e390_waveforms_supplementary.hdf5
Learning rate: 9.962517753734109e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 7.3798	Cost: 28.09s
Train Epoch: 391 [20480/90000 (23%)]	Loss: 6.7135	Cost: 8.81s
Train Epoch: 391 [40960/90000 (45%)]	Loss: 6.6377	Cost: 8.78s
Train Epoch: 391 [61440/90000 (68%)]	Loss: 6.7901	Cost: 5.95s
Train Epoch: 391 [81920/90000 (91%)]	Loss: 6.7840	Cost: 6.66s
Train Epoch: 391 	Average Loss: 6.7608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4347

Saving model as e391_model.pt & e391_waveforms_supplementary.hdf5
Learning rate: 9.962325532717212e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 7.2953	Cost: 29.53s
Train Epoch: 392 [20480/90000 (23%)]	Loss: 6.5947	Cost: 13.43s
Train Epoch: 392 [40960/90000 (45%)]	Loss: 6.7728	Cost: 15.78s
Train Epoch: 392 [61440/90000 (68%)]	Loss: 6.5544	Cost: 11.41s
Train Epoch: 392 [81920/90000 (91%)]	Loss: 6.5875	Cost: 18.65s
Train Epoch: 392 	Average Loss: 6.7266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3719

Saving model as e392_model.pt & e392_waveforms_supplementary.hdf5
Learning rate: 9.96213282193842e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 7.4866	Cost: 20.10s
Train Epoch: 393 [20480/90000 (23%)]	Loss: 6.7481	Cost: 8.23s
Train Epoch: 393 [40960/90000 (45%)]	Loss: 6.7922	Cost: 16.83s
Train Epoch: 393 [61440/90000 (68%)]	Loss: 6.6536	Cost: 12.49s
Train Epoch: 393 [81920/90000 (91%)]	Loss: 6.6177	Cost: 12.38s
Train Epoch: 393 	Average Loss: 6.7514
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3878

Learning rate: 9.961939621416751e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 7.3562	Cost: 31.65s
Train Epoch: 394 [20480/90000 (23%)]	Loss: 6.7523	Cost: 10.90s
Train Epoch: 394 [40960/90000 (45%)]	Loss: 6.8299	Cost: 12.07s
Train Epoch: 394 [61440/90000 (68%)]	Loss: 6.6964	Cost: 12.08s
Train Epoch: 394 [81920/90000 (91%)]	Loss: 6.6167	Cost: 9.12s
Train Epoch: 394 	Average Loss: 6.7311
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4438

Learning rate: 9.961745931171276e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 7.4190	Cost: 26.28s
Train Epoch: 395 [20480/90000 (23%)]	Loss: 6.7069	Cost: 12.87s
Train Epoch: 395 [40960/90000 (45%)]	Loss: 6.6105	Cost: 12.38s
Train Epoch: 395 [61440/90000 (68%)]	Loss: 6.6140	Cost: 7.82s
Train Epoch: 395 [81920/90000 (91%)]	Loss: 6.6477	Cost: 6.18s
Train Epoch: 395 	Average Loss: 6.7278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3907

Learning rate: 9.96155175122111e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 7.3965	Cost: 26.46s
Train Epoch: 396 [20480/90000 (23%)]	Loss: 6.8201	Cost: 12.06s
Train Epoch: 396 [40960/90000 (45%)]	Loss: 6.7401	Cost: 10.60s
Train Epoch: 396 [61440/90000 (68%)]	Loss: 6.6048	Cost: 6.29s
Train Epoch: 396 [81920/90000 (91%)]	Loss: 6.5876	Cost: 6.33s
Train Epoch: 396 	Average Loss: 6.6968
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4133

Learning rate: 9.96135708158542e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 7.2997	Cost: 37.55s
Train Epoch: 397 [20480/90000 (23%)]	Loss: 6.5784	Cost: 12.01s
Train Epoch: 397 [40960/90000 (45%)]	Loss: 6.6237	Cost: 8.90s
Train Epoch: 397 [61440/90000 (68%)]	Loss: 6.7121	Cost: 6.48s
Train Epoch: 397 [81920/90000 (91%)]	Loss: 6.6101	Cost: 8.51s
Train Epoch: 397 	Average Loss: 6.6591
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3275

Saving model as e397_model.pt & e397_waveforms_supplementary.hdf5
Learning rate: 9.961161922283415e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 7.2867	Cost: 23.60s
Train Epoch: 398 [20480/90000 (23%)]	Loss: 6.6215	Cost: 8.06s
Train Epoch: 398 [40960/90000 (45%)]	Loss: 6.7255	Cost: 10.42s
Train Epoch: 398 [61440/90000 (68%)]	Loss: 6.6842	Cost: 8.05s
Train Epoch: 398 [81920/90000 (91%)]	Loss: 6.6695	Cost: 8.71s
Train Epoch: 398 	Average Loss: 6.6768
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3178

Saving model as e398_model.pt & e398_waveforms_supplementary.hdf5
Learning rate: 9.960966273334359e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 7.2469	Cost: 24.12s
Train Epoch: 399 [20480/90000 (23%)]	Loss: 6.5145	Cost: 8.97s
Train Epoch: 399 [40960/90000 (45%)]	Loss: 6.5867	Cost: 9.03s
Train Epoch: 399 [61440/90000 (68%)]	Loss: 6.6925	Cost: 8.71s
Train Epoch: 399 [81920/90000 (91%)]	Loss: 6.6368	Cost: 8.78s
Train Epoch: 399 	Average Loss: 6.6575
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3797

Learning rate: 9.960770134757561e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 7.2509	Cost: 21.56s
Train Epoch: 400 [20480/90000 (23%)]	Loss: 6.5583	Cost: 6.93s
Train Epoch: 400 [40960/90000 (45%)]	Loss: 6.7107	Cost: 9.20s
Train Epoch: 400 [61440/90000 (68%)]	Loss: 6.6586	Cost: 13.15s
Train Epoch: 400 [81920/90000 (91%)]	Loss: 6.6023	Cost: 12.67s
Train Epoch: 400 	Average Loss: 6.6637
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3863

Learning rate: 9.96057350657238e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 401 [0/90000 (0%)]	Loss: 7.3920	Cost: 21.68s
Train Epoch: 401 [20480/90000 (23%)]	Loss: 6.5693	Cost: 12.50s
Train Epoch: 401 [40960/90000 (45%)]	Loss: 6.5555	Cost: 15.74s
Train Epoch: 401 [61440/90000 (68%)]	Loss: 6.7097	Cost: 12.38s
Train Epoch: 401 [81920/90000 (91%)]	Loss: 6.5553	Cost: 12.02s
Train Epoch: 401 	Average Loss: 6.6509
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3626

Learning rate: 9.960376388798222e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 402 [0/90000 (0%)]	Loss: 7.3749	Cost: 40.20s
Train Epoch: 402 [20480/90000 (23%)]	Loss: 6.4766	Cost: 11.97s
Train Epoch: 402 [40960/90000 (45%)]	Loss: 6.7023	Cost: 12.35s
Train Epoch: 402 [61440/90000 (68%)]	Loss: 6.5837	Cost: 11.33s
Train Epoch: 402 [81920/90000 (91%)]	Loss: 6.4912	Cost: 6.09s
Train Epoch: 402 	Average Loss: 6.6294
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3987

Learning rate: 9.960178781454541e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 403 [0/90000 (0%)]	Loss: 7.3692	Cost: 27.80s
Train Epoch: 403 [20480/90000 (23%)]	Loss: 6.5257	Cost: 12.80s
Train Epoch: 403 [40960/90000 (45%)]	Loss: 6.5159	Cost: 12.34s
Train Epoch: 403 [61440/90000 (68%)]	Loss: 6.6453	Cost: 7.62s
Train Epoch: 403 [81920/90000 (91%)]	Loss: 6.7619	Cost: 6.18s
Train Epoch: 403 	Average Loss: 6.6261
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2585

Saving model as e403_model.pt & e403_waveforms_supplementary.hdf5
Learning rate: 9.959980684560841e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 404 [0/90000 (0%)]	Loss: 7.2048	Cost: 27.92s
Train Epoch: 404 [20480/90000 (23%)]	Loss: 6.4440	Cost: 7.42s
Train Epoch: 404 [40960/90000 (45%)]	Loss: 6.5529	Cost: 9.44s
Train Epoch: 404 [61440/90000 (68%)]	Loss: 6.5148	Cost: 9.86s
Train Epoch: 404 [81920/90000 (91%)]	Loss: 6.6501	Cost: 9.09s
Train Epoch: 404 	Average Loss: 6.6002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3512

Learning rate: 9.959782098136674e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 405 [0/90000 (0%)]	Loss: 7.2071	Cost: 20.61s
Train Epoch: 405 [20480/90000 (23%)]	Loss: 6.5703	Cost: 10.14s
Train Epoch: 405 [40960/90000 (45%)]	Loss: 6.5662	Cost: 11.45s
Train Epoch: 405 [61440/90000 (68%)]	Loss: 6.5273	Cost: 8.93s
Train Epoch: 405 [81920/90000 (91%)]	Loss: 6.5866	Cost: 8.83s
Train Epoch: 405 	Average Loss: 6.5918
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3499

Learning rate: 9.959583022201639e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 406 [0/90000 (0%)]	Loss: 7.0840	Cost: 23.56s
Train Epoch: 406 [20480/90000 (23%)]	Loss: 6.4822	Cost: 9.24s
Train Epoch: 406 [40960/90000 (45%)]	Loss: 6.5672	Cost: 7.34s
Train Epoch: 406 [61440/90000 (68%)]	Loss: 6.4630	Cost: 5.97s
Train Epoch: 406 [81920/90000 (91%)]	Loss: 6.6282	Cost: 6.55s
Train Epoch: 406 	Average Loss: 6.5551
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3056

Learning rate: 9.959383456775382e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 407 [0/90000 (0%)]	Loss: 7.3364	Cost: 20.94s
Train Epoch: 407 [20480/90000 (23%)]	Loss: 6.3756	Cost: 7.17s
Train Epoch: 407 [40960/90000 (45%)]	Loss: 6.4755	Cost: 9.11s
Train Epoch: 407 [61440/90000 (68%)]	Loss: 6.5232	Cost: 12.44s
Train Epoch: 407 [81920/90000 (91%)]	Loss: 6.5446	Cost: 12.38s
Train Epoch: 407 	Average Loss: 6.5552
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2898

Learning rate: 9.959183401877603e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 408 [0/90000 (0%)]	Loss: 7.3188	Cost: 26.00s
Train Epoch: 408 [20480/90000 (23%)]	Loss: 6.4496	Cost: 12.33s
Train Epoch: 408 [40960/90000 (45%)]	Loss: 6.6253	Cost: 12.55s
Train Epoch: 408 [61440/90000 (68%)]	Loss: 6.5361	Cost: 12.39s
Train Epoch: 408 [81920/90000 (91%)]	Loss: 6.5506	Cost: 12.45s
Train Epoch: 408 	Average Loss: 6.5468
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2072

Saving model as e408_model.pt & e408_waveforms_supplementary.hdf5
Learning rate: 9.958982857528043e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 409 [0/90000 (0%)]	Loss: 7.0647	Cost: 29.93s
Train Epoch: 409 [20480/90000 (23%)]	Loss: 6.3619	Cost: 12.42s
Train Epoch: 409 [40960/90000 (45%)]	Loss: 6.5227	Cost: 14.22s
Train Epoch: 409 [61440/90000 (68%)]	Loss: 6.5350	Cost: 12.12s
Train Epoch: 409 [81920/90000 (91%)]	Loss: 6.3945	Cost: 9.48s
Train Epoch: 409 	Average Loss: 6.5454
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3044

Learning rate: 9.958781823746497e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 410 [0/90000 (0%)]	Loss: 7.2376	Cost: 31.65s
Train Epoch: 410 [20480/90000 (23%)]	Loss: 6.2934	Cost: 13.67s
Train Epoch: 410 [40960/90000 (45%)]	Loss: 6.5309	Cost: 11.89s
Train Epoch: 410 [61440/90000 (68%)]	Loss: 6.2323	Cost: 6.20s
Train Epoch: 410 [81920/90000 (91%)]	Loss: 6.5384	Cost: 6.04s
Train Epoch: 410 	Average Loss: 6.5250
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2326

Learning rate: 9.958580300552807e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 411 [0/90000 (0%)]	Loss: 7.2943	Cost: 26.96s
Train Epoch: 411 [20480/90000 (23%)]	Loss: 6.3812	Cost: 12.12s
Train Epoch: 411 [40960/90000 (45%)]	Loss: 6.4995	Cost: 6.78s
Train Epoch: 411 [61440/90000 (68%)]	Loss: 6.3443	Cost: 6.21s
Train Epoch: 411 [81920/90000 (91%)]	Loss: 6.5311	Cost: 8.40s
Train Epoch: 411 	Average Loss: 6.5098
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2420

Learning rate: 9.95837828796686e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 412 [0/90000 (0%)]	Loss: 7.2248	Cost: 27.92s
Train Epoch: 412 [20480/90000 (23%)]	Loss: 6.4548	Cost: 6.61s
Train Epoch: 412 [40960/90000 (45%)]	Loss: 6.4282	Cost: 9.08s
Train Epoch: 412 [61440/90000 (68%)]	Loss: 6.3708	Cost: 8.93s
Train Epoch: 412 [81920/90000 (91%)]	Loss: 6.4618	Cost: 8.60s
Train Epoch: 412 	Average Loss: 6.4734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2022

Saving model as e412_model.pt & e412_waveforms_supplementary.hdf5
Learning rate: 9.958175786008596e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 413 [0/90000 (0%)]	Loss: 7.1223	Cost: 22.53s
Train Epoch: 413 [20480/90000 (23%)]	Loss: 6.5151	Cost: 9.12s
Train Epoch: 413 [40960/90000 (45%)]	Loss: 6.3144	Cost: 8.48s
Train Epoch: 413 [61440/90000 (68%)]	Loss: 6.3802	Cost: 6.11s
Train Epoch: 413 [81920/90000 (91%)]	Loss: 6.3553	Cost: 6.48s
Train Epoch: 413 	Average Loss: 6.4851
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1974

Saving model as e413_model.pt & e413_waveforms_supplementary.hdf5
Learning rate: 9.957972794698001e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 414 [0/90000 (0%)]	Loss: 7.2067	Cost: 26.65s
Train Epoch: 414 [20480/90000 (23%)]	Loss: 6.4137	Cost: 10.80s
Train Epoch: 414 [40960/90000 (45%)]	Loss: 6.4896	Cost: 16.60s
Train Epoch: 414 [61440/90000 (68%)]	Loss: 6.3546	Cost: 13.15s
Train Epoch: 414 [81920/90000 (91%)]	Loss: 6.2689	Cost: 12.21s
Train Epoch: 414 	Average Loss: 6.4793
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2334

Learning rate: 9.957769314055109e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 415 [0/90000 (0%)]	Loss: 7.2497	Cost: 32.35s
Train Epoch: 415 [20480/90000 (23%)]	Loss: 6.4303	Cost: 14.57s
Train Epoch: 415 [40960/90000 (45%)]	Loss: 6.4435	Cost: 13.97s
Train Epoch: 415 [61440/90000 (68%)]	Loss: 6.3676	Cost: 12.08s
Train Epoch: 415 [81920/90000 (91%)]	Loss: 6.4059	Cost: 8.40s
Train Epoch: 415 	Average Loss: 6.4658
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1982

Learning rate: 9.957565344100001e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 416 [0/90000 (0%)]	Loss: 7.0977	Cost: 38.68s
Train Epoch: 416 [20480/90000 (23%)]	Loss: 6.4749	Cost: 12.58s
Train Epoch: 416 [40960/90000 (45%)]	Loss: 6.3999	Cost: 9.80s
Train Epoch: 416 [61440/90000 (68%)]	Loss: 6.5043	Cost: 6.12s
Train Epoch: 416 [81920/90000 (91%)]	Loss: 6.4105	Cost: 6.40s
Train Epoch: 416 	Average Loss: 6.4317
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1750

Saving model as e416_model.pt & e416_waveforms_supplementary.hdf5
Learning rate: 9.95736088485281e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 417 [0/90000 (0%)]	Loss: 7.1160	Cost: 25.62s
Train Epoch: 417 [20480/90000 (23%)]	Loss: 6.3703	Cost: 6.43s
Train Epoch: 417 [40960/90000 (45%)]	Loss: 6.4045	Cost: 9.55s
Train Epoch: 417 [61440/90000 (68%)]	Loss: 6.2240	Cost: 8.58s
Train Epoch: 417 [81920/90000 (91%)]	Loss: 6.5339	Cost: 8.39s
Train Epoch: 417 	Average Loss: 6.4449
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2387

Learning rate: 9.957155936333717e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 418 [0/90000 (0%)]	Loss: 7.2856	Cost: 21.15s
Train Epoch: 418 [20480/90000 (23%)]	Loss: 6.3138	Cost: 8.84s
Train Epoch: 418 [40960/90000 (45%)]	Loss: 6.3824	Cost: 8.79s
Train Epoch: 418 [61440/90000 (68%)]	Loss: 6.4210	Cost: 8.57s
Train Epoch: 418 [81920/90000 (91%)]	Loss: 6.5245	Cost: 7.70s
Train Epoch: 418 	Average Loss: 6.4367
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1686

Saving model as e418_model.pt & e418_waveforms_supplementary.hdf5
Learning rate: 9.956950498562945e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 419 [0/90000 (0%)]	Loss: 7.2624	Cost: 19.89s
Train Epoch: 419 [20480/90000 (23%)]	Loss: 6.4060	Cost: 8.04s
Train Epoch: 419 [40960/90000 (45%)]	Loss: 6.3860	Cost: 14.28s
Train Epoch: 419 [61440/90000 (68%)]	Loss: 6.4060	Cost: 11.99s
Train Epoch: 419 [81920/90000 (91%)]	Loss: 6.5487	Cost: 12.36s
Train Epoch: 419 	Average Loss: 6.4156
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2419

Learning rate: 9.956744571560774e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 420 [0/90000 (0%)]	Loss: 7.1691	Cost: 22.30s
Train Epoch: 420 [20480/90000 (23%)]	Loss: 6.3270	Cost: 8.67s
Train Epoch: 420 [40960/90000 (45%)]	Loss: 6.4239	Cost: 12.25s
Train Epoch: 420 [61440/90000 (68%)]	Loss: 6.2383	Cost: 8.42s
Train Epoch: 420 [81920/90000 (91%)]	Loss: 6.3445	Cost: 14.19s
Train Epoch: 420 	Average Loss: 6.3935
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2537

Learning rate: 9.956538155347526e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 421 [0/90000 (0%)]	Loss: 7.2329	Cost: 27.77s
Train Epoch: 421 [20480/90000 (23%)]	Loss: 6.2769	Cost: 12.60s
Train Epoch: 421 [40960/90000 (45%)]	Loss: 6.3132	Cost: 13.92s
Train Epoch: 421 [61440/90000 (68%)]	Loss: 6.2227	Cost: 12.38s
Train Epoch: 421 [81920/90000 (91%)]	Loss: 6.4006	Cost: 12.17s
Train Epoch: 421 	Average Loss: 6.3822
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1844

Learning rate: 9.956331249943575e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 422 [0/90000 (0%)]	Loss: 7.1596	Cost: 24.65s
Train Epoch: 422 [20480/90000 (23%)]	Loss: 6.3510	Cost: 12.20s
Train Epoch: 422 [40960/90000 (45%)]	Loss: 6.5395	Cost: 13.15s
Train Epoch: 422 [61440/90000 (68%)]	Loss: 6.3678	Cost: 12.60s
Train Epoch: 422 [81920/90000 (91%)]	Loss: 6.3326	Cost: 9.99s
Train Epoch: 422 	Average Loss: 6.4106
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1801

Learning rate: 9.956123855369338e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 423 [0/90000 (0%)]	Loss: 7.0829	Cost: 25.08s
Train Epoch: 423 [20480/90000 (23%)]	Loss: 6.3209	Cost: 11.56s
Train Epoch: 423 [40960/90000 (45%)]	Loss: 6.2354	Cost: 12.61s
Train Epoch: 423 [61440/90000 (68%)]	Loss: 6.2823	Cost: 12.59s
Train Epoch: 423 [81920/90000 (91%)]	Loss: 6.3509	Cost: 6.75s
Train Epoch: 423 	Average Loss: 6.3600
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2087

Learning rate: 9.95591597164529e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 424 [0/90000 (0%)]	Loss: 7.2309	Cost: 22.95s
Train Epoch: 424 [20480/90000 (23%)]	Loss: 6.1906	Cost: 12.71s
Train Epoch: 424 [40960/90000 (45%)]	Loss: 6.2242	Cost: 10.11s
Train Epoch: 424 [61440/90000 (68%)]	Loss: 6.2389	Cost: 6.34s
Train Epoch: 424 [81920/90000 (91%)]	Loss: 6.4366	Cost: 6.87s
Train Epoch: 424 	Average Loss: 6.3431
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1711

Learning rate: 9.955707598791946e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 425 [0/90000 (0%)]	Loss: 7.0622	Cost: 31.48s
Train Epoch: 425 [20480/90000 (23%)]	Loss: 6.2760	Cost: 8.70s
Train Epoch: 425 [40960/90000 (45%)]	Loss: 6.3891	Cost: 9.37s
Train Epoch: 425 [61440/90000 (68%)]	Loss: 6.3739	Cost: 7.70s
Train Epoch: 425 [81920/90000 (91%)]	Loss: 6.2304	Cost: 8.56s
Train Epoch: 425 	Average Loss: 6.3513
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1218

Saving model as e425_model.pt & e425_waveforms_supplementary.hdf5
Learning rate: 9.955498736829867e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 426 [0/90000 (0%)]	Loss: 7.1240	Cost: 23.15s
Train Epoch: 426 [20480/90000 (23%)]	Loss: 6.1907	Cost: 10.00s
Train Epoch: 426 [40960/90000 (45%)]	Loss: 6.2739	Cost: 10.55s
Train Epoch: 426 [61440/90000 (68%)]	Loss: 6.2044	Cost: 8.79s
Train Epoch: 426 [81920/90000 (91%)]	Loss: 6.3766	Cost: 8.75s
Train Epoch: 426 	Average Loss: 6.3171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0674

Saving model as e426_model.pt & e426_waveforms_supplementary.hdf5
Learning rate: 9.955289385779672e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 427 [0/90000 (0%)]	Loss: 6.9321	Cost: 19.50s
Train Epoch: 427 [20480/90000 (23%)]	Loss: 6.2947	Cost: 7.70s
Train Epoch: 427 [40960/90000 (45%)]	Loss: 6.3357	Cost: 7.35s
Train Epoch: 427 [61440/90000 (68%)]	Loss: 6.1798	Cost: 8.80s
Train Epoch: 427 [81920/90000 (91%)]	Loss: 6.3307	Cost: 10.07s
Train Epoch: 427 	Average Loss: 6.3138
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0960

Learning rate: 9.955079545662022e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 428 [0/90000 (0%)]	Loss: 6.9897	Cost: 19.40s
Train Epoch: 428 [20480/90000 (23%)]	Loss: 6.1555	Cost: 9.33s
Train Epoch: 428 [40960/90000 (45%)]	Loss: 6.3206	Cost: 13.27s
Train Epoch: 428 [61440/90000 (68%)]	Loss: 6.0280	Cost: 12.43s
Train Epoch: 428 [81920/90000 (91%)]	Loss: 6.1270	Cost: 12.54s
Train Epoch: 428 	Average Loss: 6.2913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0868

Learning rate: 9.954869216497627e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 429 [0/90000 (0%)]	Loss: 7.1616	Cost: 23.32s
Train Epoch: 429 [20480/90000 (23%)]	Loss: 6.2076	Cost: 14.46s
Train Epoch: 429 [40960/90000 (45%)]	Loss: 6.3538	Cost: 13.94s
Train Epoch: 429 [61440/90000 (68%)]	Loss: 6.1261	Cost: 12.21s
Train Epoch: 429 [81920/90000 (91%)]	Loss: 6.0715	Cost: 12.07s
Train Epoch: 429 	Average Loss: 6.2808
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0703

Learning rate: 9.954658398307247e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 430 [0/90000 (0%)]	Loss: 6.9088	Cost: 42.78s
Train Epoch: 430 [20480/90000 (23%)]	Loss: 6.1741	Cost: 12.16s
Train Epoch: 430 [40960/90000 (45%)]	Loss: 6.0512	Cost: 10.32s
Train Epoch: 430 [61440/90000 (68%)]	Loss: 6.2040	Cost: 6.10s
Train Epoch: 430 [81920/90000 (91%)]	Loss: 6.2685	Cost: 6.55s
Train Epoch: 430 	Average Loss: 6.2654
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0938

Learning rate: 9.954447091111686e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 431 [0/90000 (0%)]	Loss: 7.0090	Cost: 26.84s
Train Epoch: 431 [20480/90000 (23%)]	Loss: 6.1876	Cost: 11.08s
Train Epoch: 431 [40960/90000 (45%)]	Loss: 6.1668	Cost: 10.44s
Train Epoch: 431 [61440/90000 (68%)]	Loss: 6.1285	Cost: 6.26s
Train Epoch: 431 [81920/90000 (91%)]	Loss: 6.1675	Cost: 7.07s
Train Epoch: 431 	Average Loss: 6.2397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0540

Saving model as e431_model.pt & e431_waveforms_supplementary.hdf5
Learning rate: 9.954235294931802e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 432 [0/90000 (0%)]	Loss: 6.9464	Cost: 27.96s
Train Epoch: 432 [20480/90000 (23%)]	Loss: 6.0597	Cost: 6.64s
Train Epoch: 432 [40960/90000 (45%)]	Loss: 6.0378	Cost: 7.00s
Train Epoch: 432 [61440/90000 (68%)]	Loss: 6.2790	Cost: 8.30s
Train Epoch: 432 [81920/90000 (91%)]	Loss: 6.2002	Cost: 8.76s
Train Epoch: 432 	Average Loss: 6.2268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0348

Saving model as e432_model.pt & e432_waveforms_supplementary.hdf5
Learning rate: 9.954023009788497e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 433 [0/90000 (0%)]	Loss: 7.0155	Cost: 20.21s
Train Epoch: 433 [20480/90000 (23%)]	Loss: 6.0517	Cost: 8.33s
Train Epoch: 433 [40960/90000 (45%)]	Loss: 6.3627	Cost: 9.01s
Train Epoch: 433 [61440/90000 (68%)]	Loss: 6.1439	Cost: 8.52s
Train Epoch: 433 [81920/90000 (91%)]	Loss: 6.2945	Cost: 8.77s
Train Epoch: 433 	Average Loss: 6.2214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1039

Learning rate: 9.953810235702723e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 434 [0/90000 (0%)]	Loss: 7.0717	Cost: 22.38s
Train Epoch: 434 [20480/90000 (23%)]	Loss: 6.1139	Cost: 6.58s
Train Epoch: 434 [40960/90000 (45%)]	Loss: 6.2491	Cost: 12.26s
Train Epoch: 434 [61440/90000 (68%)]	Loss: 6.1788	Cost: 9.45s
Train Epoch: 434 [81920/90000 (91%)]	Loss: 6.1344	Cost: 13.03s
Train Epoch: 434 	Average Loss: 6.2229
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0670

Learning rate: 9.95359697269548e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 435 [0/90000 (0%)]	Loss: 7.1106	Cost: 22.33s
Train Epoch: 435 [20480/90000 (23%)]	Loss: 6.0888	Cost: 10.56s
Train Epoch: 435 [40960/90000 (45%)]	Loss: 6.2441	Cost: 12.20s
Train Epoch: 435 [61440/90000 (68%)]	Loss: 5.9926	Cost: 12.61s
Train Epoch: 435 [81920/90000 (91%)]	Loss: 6.1334	Cost: 12.38s
Train Epoch: 435 	Average Loss: 6.1930
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0320

Saving model as e435_model.pt & e435_waveforms_supplementary.hdf5
Learning rate: 9.953383220787815e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 436 [0/90000 (0%)]	Loss: 6.9465	Cost: 33.23s
Train Epoch: 436 [20480/90000 (23%)]	Loss: 6.0000	Cost: 13.94s
Train Epoch: 436 [40960/90000 (45%)]	Loss: 6.1677	Cost: 12.40s
Train Epoch: 436 [61440/90000 (68%)]	Loss: 6.0822	Cost: 12.18s
Train Epoch: 436 [81920/90000 (91%)]	Loss: 6.1609	Cost: 11.08s
Train Epoch: 436 	Average Loss: 6.1882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0826

Learning rate: 9.953168980000828e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 437 [0/90000 (0%)]	Loss: 6.9006	Cost: 27.42s
Train Epoch: 437 [20480/90000 (23%)]	Loss: 6.1796	Cost: 13.59s
Train Epoch: 437 [40960/90000 (45%)]	Loss: 6.2533	Cost: 14.22s
Train Epoch: 437 [61440/90000 (68%)]	Loss: 6.1855	Cost: 9.94s
Train Epoch: 437 [81920/90000 (91%)]	Loss: 6.0883	Cost: 6.58s
Train Epoch: 437 	Average Loss: 6.2006
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0891

Learning rate: 9.95295425035566e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 438 [0/90000 (0%)]	Loss: 7.0640	Cost: 25.38s
Train Epoch: 438 [20480/90000 (23%)]	Loss: 6.1017	Cost: 11.97s
Train Epoch: 438 [40960/90000 (45%)]	Loss: 6.2578	Cost: 12.06s
Train Epoch: 438 [61440/90000 (68%)]	Loss: 6.1279	Cost: 8.63s
Train Epoch: 438 [81920/90000 (91%)]	Loss: 6.2460	Cost: 7.73s
Train Epoch: 438 	Average Loss: 6.1771
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0086

Saving model as e438_model.pt & e438_waveforms_supplementary.hdf5
Learning rate: 9.952739031873505e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 439 [0/90000 (0%)]	Loss: 6.9020	Cost: 21.33s
Train Epoch: 439 [20480/90000 (23%)]	Loss: 5.9834	Cost: 8.62s
Train Epoch: 439 [40960/90000 (45%)]	Loss: 6.1907	Cost: 8.98s
Train Epoch: 439 [61440/90000 (68%)]	Loss: 6.0984	Cost: 8.94s
Train Epoch: 439 [81920/90000 (91%)]	Loss: 6.1186	Cost: 8.54s
Train Epoch: 439 	Average Loss: 6.1540
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9974

Saving model as e439_model.pt & e439_waveforms_supplementary.hdf5
Learning rate: 9.952523324575606e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 440 [0/90000 (0%)]	Loss: 6.8852	Cost: 29.18s
Train Epoch: 440 [20480/90000 (23%)]	Loss: 5.9238	Cost: 8.85s
Train Epoch: 440 [40960/90000 (45%)]	Loss: 6.0977	Cost: 8.83s
Train Epoch: 440 [61440/90000 (68%)]	Loss: 5.9491	Cost: 8.97s
Train Epoch: 440 [81920/90000 (91%)]	Loss: 6.0704	Cost: 8.22s
Train Epoch: 440 	Average Loss: 6.1215
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9625

Saving model as e440_model.pt & e440_waveforms_supplementary.hdf5
Learning rate: 9.952307128483249e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 441 [0/90000 (0%)]	Loss: 7.0857	Cost: 21.42s
Train Epoch: 441 [20480/90000 (23%)]	Loss: 6.0331	Cost: 7.59s
Train Epoch: 441 [40960/90000 (45%)]	Loss: 6.2582	Cost: 7.04s
Train Epoch: 441 [61440/90000 (68%)]	Loss: 6.1516	Cost: 6.62s
Train Epoch: 441 [81920/90000 (91%)]	Loss: 6.1321	Cost: 16.53s
Train Epoch: 441 	Average Loss: 6.1728
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0420

Learning rate: 9.952090443617776e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 442 [0/90000 (0%)]	Loss: 6.8929	Cost: 24.92s
Train Epoch: 442 [20480/90000 (23%)]	Loss: 6.0960	Cost: 10.63s
Train Epoch: 442 [40960/90000 (45%)]	Loss: 6.0197	Cost: 13.94s
Train Epoch: 442 [61440/90000 (68%)]	Loss: 6.2196	Cost: 14.40s
Train Epoch: 442 [81920/90000 (91%)]	Loss: 6.0815	Cost: 12.35s
Train Epoch: 442 	Average Loss: 6.1146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0158

Learning rate: 9.95187327000057e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 443 [0/90000 (0%)]	Loss: 6.7896	Cost: 24.46s
Train Epoch: 443 [20480/90000 (23%)]	Loss: 6.0550	Cost: 14.98s
Train Epoch: 443 [40960/90000 (45%)]	Loss: 6.0218	Cost: 14.88s
Train Epoch: 443 [61440/90000 (68%)]	Loss: 6.0640	Cost: 12.48s
Train Epoch: 443 [81920/90000 (91%)]	Loss: 6.0694	Cost: 11.94s
Train Epoch: 443 	Average Loss: 6.0821
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9520

Saving model as e443_model.pt & e443_waveforms_supplementary.hdf5
Learning rate: 9.951655607653065e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 444 [0/90000 (0%)]	Loss: 6.9243	Cost: 37.71s
Train Epoch: 444 [20480/90000 (23%)]	Loss: 5.9462	Cost: 12.24s
Train Epoch: 444 [40960/90000 (45%)]	Loss: 6.0241	Cost: 8.96s
Train Epoch: 444 [61440/90000 (68%)]	Loss: 6.0119	Cost: 6.07s
Train Epoch: 444 [81920/90000 (91%)]	Loss: 6.1405	Cost: 7.99s
Train Epoch: 444 	Average Loss: 6.0769
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9590

Learning rate: 9.951437456596745e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 445 [0/90000 (0%)]	Loss: 7.1749	Cost: 31.55s
Train Epoch: 445 [20480/90000 (23%)]	Loss: 5.9215	Cost: 9.93s
Train Epoch: 445 [40960/90000 (45%)]	Loss: 5.9936	Cost: 6.60s
Train Epoch: 445 [61440/90000 (68%)]	Loss: 5.8931	Cost: 6.84s
Train Epoch: 445 [81920/90000 (91%)]	Loss: 6.0584	Cost: 8.49s
Train Epoch: 445 	Average Loss: 6.0592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9680

Learning rate: 9.951218816853138e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 446 [0/90000 (0%)]	Loss: 6.9299	Cost: 24.37s
Train Epoch: 446 [20480/90000 (23%)]	Loss: 5.7967	Cost: 7.84s
Train Epoch: 446 [40960/90000 (45%)]	Loss: 5.9837	Cost: 9.57s
Train Epoch: 446 [61440/90000 (68%)]	Loss: 5.9040	Cost: 8.70s
Train Epoch: 446 [81920/90000 (91%)]	Loss: 6.0040	Cost: 8.49s
Train Epoch: 446 	Average Loss: 6.0344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9961

Learning rate: 9.950999688443825e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 447 [0/90000 (0%)]	Loss: 6.8143	Cost: 23.87s
Train Epoch: 447 [20480/90000 (23%)]	Loss: 5.9681	Cost: 12.02s
Train Epoch: 447 [40960/90000 (45%)]	Loss: 6.0723	Cost: 11.01s
Train Epoch: 447 [61440/90000 (68%)]	Loss: 6.0370	Cost: 7.65s
Train Epoch: 447 [81920/90000 (91%)]	Loss: 6.0062	Cost: 7.69s
Train Epoch: 447 	Average Loss: 6.0628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9588

Learning rate: 9.950780071390434e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 448 [0/90000 (0%)]	Loss: 6.7349	Cost: 20.17s
Train Epoch: 448 [20480/90000 (23%)]	Loss: 5.8780	Cost: 10.13s
Train Epoch: 448 [40960/90000 (45%)]	Loss: 5.9866	Cost: 12.82s
Train Epoch: 448 [61440/90000 (68%)]	Loss: 6.0403	Cost: 13.14s
Train Epoch: 448 [81920/90000 (91%)]	Loss: 5.9175	Cost: 12.12s
Train Epoch: 448 	Average Loss: 6.0076
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9448

Saving model as e448_model.pt & e448_waveforms_supplementary.hdf5
Learning rate: 9.95055996571464e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 449 [0/90000 (0%)]	Loss: 7.0067	Cost: 25.77s
Train Epoch: 449 [20480/90000 (23%)]	Loss: 5.8652	Cost: 13.51s
Train Epoch: 449 [40960/90000 (45%)]	Loss: 6.0162	Cost: 13.23s
Train Epoch: 449 [61440/90000 (68%)]	Loss: 5.8666	Cost: 12.27s
Train Epoch: 449 [81920/90000 (91%)]	Loss: 6.0437	Cost: 12.30s
Train Epoch: 449 	Average Loss: 6.0138
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9387

Saving model as e449_model.pt & e449_waveforms_supplementary.hdf5
Learning rate: 9.950339371438165e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 450 [0/90000 (0%)]	Loss: 6.9027	Cost: 21.79s
Train Epoch: 450 [20480/90000 (23%)]	Loss: 6.0033	Cost: 13.88s
Train Epoch: 450 [40960/90000 (45%)]	Loss: 6.0676	Cost: 12.35s
Train Epoch: 450 [61440/90000 (68%)]	Loss: 5.8324	Cost: 10.97s
Train Epoch: 450 [81920/90000 (91%)]	Loss: 6.1597	Cost: 6.27s
Train Epoch: 450 	Average Loss: 6.0448
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0109

Learning rate: 9.950118288582781e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 451 [0/90000 (0%)]	Loss: 6.9239	Cost: 27.83s
Train Epoch: 451 [20480/90000 (23%)]	Loss: 5.8673	Cost: 9.49s
Train Epoch: 451 [40960/90000 (45%)]	Loss: 6.0242	Cost: 6.42s
Train Epoch: 451 [61440/90000 (68%)]	Loss: 5.9243	Cost: 7.41s
Train Epoch: 451 [81920/90000 (91%)]	Loss: 5.8777	Cost: 9.06s
Train Epoch: 451 	Average Loss: 6.0171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9066

Saving model as e451_model.pt & e451_waveforms_supplementary.hdf5
Learning rate: 9.949896717170309e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 452 [0/90000 (0%)]	Loss: 6.8030	Cost: 26.29s
Train Epoch: 452 [20480/90000 (23%)]	Loss: 5.8000	Cost: 9.41s
Train Epoch: 452 [40960/90000 (45%)]	Loss: 5.9248	Cost: 9.51s
Train Epoch: 452 [61440/90000 (68%)]	Loss: 5.8968	Cost: 8.69s
Train Epoch: 452 [81920/90000 (91%)]	Loss: 6.0728	Cost: 8.55s
Train Epoch: 452 	Average Loss: 6.0046
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9275

Learning rate: 9.949674657222618e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 453 [0/90000 (0%)]	Loss: 6.8602	Cost: 31.51s
Train Epoch: 453 [20480/90000 (23%)]	Loss: 5.7798	Cost: 8.87s
Train Epoch: 453 [40960/90000 (45%)]	Loss: 5.9902	Cost: 9.13s
Train Epoch: 453 [61440/90000 (68%)]	Loss: 5.8807	Cost: 6.54s
Train Epoch: 453 [81920/90000 (91%)]	Loss: 5.8730	Cost: 6.93s
Train Epoch: 453 	Average Loss: 5.9661
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8503

Saving model as e453_model.pt & e453_waveforms_supplementary.hdf5
Learning rate: 9.949452108761622e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 454 [0/90000 (0%)]	Loss: 6.7550	Cost: 18.97s
Train Epoch: 454 [20480/90000 (23%)]	Loss: 5.9281	Cost: 8.53s
Train Epoch: 454 [40960/90000 (45%)]	Loss: 5.8023	Cost: 11.15s
Train Epoch: 454 [61440/90000 (68%)]	Loss: 5.8165	Cost: 12.83s
Train Epoch: 454 [81920/90000 (91%)]	Loss: 5.8913	Cost: 12.69s
Train Epoch: 454 	Average Loss: 5.9506
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8656

Learning rate: 9.949229071809287e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 455 [0/90000 (0%)]	Loss: 6.7400	Cost: 22.93s
Train Epoch: 455 [20480/90000 (23%)]	Loss: 5.8993	Cost: 12.15s
Train Epoch: 455 [40960/90000 (45%)]	Loss: 5.8617	Cost: 12.50s
Train Epoch: 455 [61440/90000 (68%)]	Loss: 5.9413	Cost: 12.45s
Train Epoch: 455 [81920/90000 (91%)]	Loss: 6.0272	Cost: 12.47s
Train Epoch: 455 	Average Loss: 5.9382
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8413

Saving model as e455_model.pt & e455_waveforms_supplementary.hdf5
Learning rate: 9.949005546387625e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 456 [0/90000 (0%)]	Loss: 6.5885	Cost: 23.61s
Train Epoch: 456 [20480/90000 (23%)]	Loss: 5.8427	Cost: 13.52s
Train Epoch: 456 [40960/90000 (45%)]	Loss: 5.8990	Cost: 12.48s
Train Epoch: 456 [61440/90000 (68%)]	Loss: 5.8807	Cost: 11.30s
Train Epoch: 456 [81920/90000 (91%)]	Loss: 5.9626	Cost: 5.99s
Train Epoch: 456 	Average Loss: 5.9319
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8883

Learning rate: 9.9487815325187e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 457 [0/90000 (0%)]	Loss: 6.8549	Cost: 31.61s
Train Epoch: 457 [20480/90000 (23%)]	Loss: 5.8716	Cost: 13.43s
Train Epoch: 457 [40960/90000 (45%)]	Loss: 5.7263	Cost: 9.21s
Train Epoch: 457 [61440/90000 (68%)]	Loss: 5.9152	Cost: 6.17s
Train Epoch: 457 [81920/90000 (91%)]	Loss: 5.8124	Cost: 7.74s
Train Epoch: 457 	Average Loss: 5.8997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8358

Saving model as e457_model.pt & e457_waveforms_supplementary.hdf5
Learning rate: 9.948557030224616e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 458 [0/90000 (0%)]	Loss: 6.9219	Cost: 25.36s
Train Epoch: 458 [20480/90000 (23%)]	Loss: 5.8180	Cost: 8.08s
Train Epoch: 458 [40960/90000 (45%)]	Loss: 5.7926	Cost: 8.27s
Train Epoch: 458 [61440/90000 (68%)]	Loss: 5.9250	Cost: 8.79s
Train Epoch: 458 [81920/90000 (91%)]	Loss: 5.8021	Cost: 8.71s
Train Epoch: 458 	Average Loss: 5.8937
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8448

Learning rate: 9.948332039527536e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 459 [0/90000 (0%)]	Loss: 6.7563	Cost: 22.07s
Train Epoch: 459 [20480/90000 (23%)]	Loss: 5.7691	Cost: 8.99s
Train Epoch: 459 [40960/90000 (45%)]	Loss: 5.8823	Cost: 9.23s
Train Epoch: 459 [61440/90000 (68%)]	Loss: 5.7880	Cost: 8.67s
Train Epoch: 459 [81920/90000 (91%)]	Loss: 5.8671	Cost: 8.74s
Train Epoch: 459 	Average Loss: 5.8937
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8563

Learning rate: 9.948106560449663e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 460 [0/90000 (0%)]	Loss: 6.7181	Cost: 21.23s
Train Epoch: 460 [20480/90000 (23%)]	Loss: 5.7743	Cost: 8.96s
Train Epoch: 460 [40960/90000 (45%)]	Loss: 5.8741	Cost: 9.11s
Train Epoch: 460 [61440/90000 (68%)]	Loss: 5.6836	Cost: 7.09s
Train Epoch: 460 [81920/90000 (91%)]	Loss: 5.8081	Cost: 7.69s
Train Epoch: 460 	Average Loss: 5.8597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8474

Learning rate: 9.947880593013248e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 461 [0/90000 (0%)]	Loss: 6.8828	Cost: 19.79s
Train Epoch: 461 [20480/90000 (23%)]	Loss: 5.8149	Cost: 9.34s
Train Epoch: 461 [40960/90000 (45%)]	Loss: 5.8209	Cost: 12.09s
Train Epoch: 461 [61440/90000 (68%)]	Loss: 5.9081	Cost: 13.09s
Train Epoch: 461 [81920/90000 (91%)]	Loss: 5.7804	Cost: 12.40s
Train Epoch: 461 	Average Loss: 5.8752
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8575

Learning rate: 9.9476541372406e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 462 [0/90000 (0%)]	Loss: 6.8521	Cost: 24.68s
Train Epoch: 462 [20480/90000 (23%)]	Loss: 5.6902	Cost: 10.75s
Train Epoch: 462 [40960/90000 (45%)]	Loss: 5.8132	Cost: 15.15s
Train Epoch: 462 [61440/90000 (68%)]	Loss: 5.8525	Cost: 12.67s
Train Epoch: 462 [81920/90000 (91%)]	Loss: 5.7269	Cost: 12.29s
Train Epoch: 462 	Average Loss: 5.8353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8260

Saving model as e462_model.pt & e462_waveforms_supplementary.hdf5
Learning rate: 9.947427193154066e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 463 [0/90000 (0%)]	Loss: 6.8944	Cost: 42.63s
Train Epoch: 463 [20480/90000 (23%)]	Loss: 5.7313	Cost: 12.67s
Train Epoch: 463 [40960/90000 (45%)]	Loss: 5.8301	Cost: 12.36s
Train Epoch: 463 [61440/90000 (68%)]	Loss: 5.7882	Cost: 9.93s
Train Epoch: 463 [81920/90000 (91%)]	Loss: 5.8036	Cost: 6.24s
Train Epoch: 463 	Average Loss: 5.8385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7959

Saving model as e463_model.pt & e463_waveforms_supplementary.hdf5
Learning rate: 9.947199760776042e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 464 [0/90000 (0%)]	Loss: 6.9326	Cost: 21.49s
Train Epoch: 464 [20480/90000 (23%)]	Loss: 5.7228	Cost: 9.01s
Train Epoch: 464 [40960/90000 (45%)]	Loss: 5.8463	Cost: 6.41s
Train Epoch: 464 [61440/90000 (68%)]	Loss: 5.7670	Cost: 7.28s
Train Epoch: 464 [81920/90000 (91%)]	Loss: 5.8812	Cost: 10.25s
Train Epoch: 464 	Average Loss: 5.8161
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7919

Saving model as e464_model.pt & e464_waveforms_supplementary.hdf5
Learning rate: 9.946971840128976e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 465 [0/90000 (0%)]	Loss: 6.6896	Cost: 21.58s
Train Epoch: 465 [20480/90000 (23%)]	Loss: 5.7323	Cost: 7.69s
Train Epoch: 465 [40960/90000 (45%)]	Loss: 5.7535	Cost: 9.46s
Train Epoch: 465 [61440/90000 (68%)]	Loss: 5.6168	Cost: 9.48s
Train Epoch: 465 [81920/90000 (91%)]	Loss: 5.8309	Cost: 9.07s
Train Epoch: 465 	Average Loss: 5.8013
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7771

Saving model as e465_model.pt & e465_waveforms_supplementary.hdf5
Learning rate: 9.946743431235365e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 466 [0/90000 (0%)]	Loss: 6.8445	Cost: 21.16s
Train Epoch: 466 [20480/90000 (23%)]	Loss: 5.6180	Cost: 8.23s
Train Epoch: 466 [40960/90000 (45%)]	Loss: 5.6934	Cost: 7.61s
Train Epoch: 466 [61440/90000 (68%)]	Loss: 5.5928	Cost: 9.79s
Train Epoch: 466 [81920/90000 (91%)]	Loss: 5.7247	Cost: 12.94s
Train Epoch: 466 	Average Loss: 5.7645
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8047

Learning rate: 9.94651453411775e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 467 [0/90000 (0%)]	Loss: 6.7700	Cost: 24.81s
Train Epoch: 467 [20480/90000 (23%)]	Loss: 5.6984	Cost: 8.19s
Train Epoch: 467 [40960/90000 (45%)]	Loss: 5.8475	Cost: 12.69s
Train Epoch: 467 [61440/90000 (68%)]	Loss: 5.7523	Cost: 12.50s
Train Epoch: 467 [81920/90000 (91%)]	Loss: 5.8323	Cost: 11.91s
Train Epoch: 467 	Average Loss: 5.7744
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7544

Saving model as e467_model.pt & e467_waveforms_supplementary.hdf5
Learning rate: 9.946285148798723e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 468 [0/90000 (0%)]	Loss: 6.6130	Cost: 26.03s
Train Epoch: 468 [20480/90000 (23%)]	Loss: 5.8378	Cost: 12.26s
Train Epoch: 468 [40960/90000 (45%)]	Loss: 5.7368	Cost: 12.42s
Train Epoch: 468 [61440/90000 (68%)]	Loss: 5.7290	Cost: 12.43s
Train Epoch: 468 [81920/90000 (91%)]	Loss: 5.6135	Cost: 7.84s
Train Epoch: 468 	Average Loss: 5.7579
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7963

Learning rate: 9.946055275300923e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 469 [0/90000 (0%)]	Loss: 6.6869	Cost: 29.65s
Train Epoch: 469 [20480/90000 (23%)]	Loss: 5.6222	Cost: 12.56s
Train Epoch: 469 [40960/90000 (45%)]	Loss: 5.6859	Cost: 13.64s
Train Epoch: 469 [61440/90000 (68%)]	Loss: 5.6525	Cost: 11.63s
Train Epoch: 469 [81920/90000 (91%)]	Loss: 5.8291	Cost: 6.22s
Train Epoch: 469 	Average Loss: 5.7740
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7555

Learning rate: 9.945824913647039e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 470 [0/90000 (0%)]	Loss: 6.5853	Cost: 25.13s
Train Epoch: 470 [20480/90000 (23%)]	Loss: 5.5714	Cost: 12.61s
Train Epoch: 470 [40960/90000 (45%)]	Loss: 5.7591	Cost: 12.97s
Train Epoch: 470 [61440/90000 (68%)]	Loss: 5.6809	Cost: 10.21s
Train Epoch: 470 [81920/90000 (91%)]	Loss: 5.6346	Cost: 8.20s
Train Epoch: 470 	Average Loss: 5.7289
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7667

Learning rate: 9.945594063859803e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 471 [0/90000 (0%)]	Loss: 6.6760	Cost: 24.26s
Train Epoch: 471 [20480/90000 (23%)]	Loss: 5.7059	Cost: 9.54s
Train Epoch: 471 [40960/90000 (45%)]	Loss: 5.5326	Cost: 7.18s
Train Epoch: 471 [61440/90000 (68%)]	Loss: 5.6310	Cost: 7.70s
Train Epoch: 471 [81920/90000 (91%)]	Loss: 5.7343	Cost: 8.81s
Train Epoch: 471 	Average Loss: 5.7027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6879

Saving model as e471_model.pt & e471_waveforms_supplementary.hdf5
Learning rate: 9.945362725962006e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 472 [0/90000 (0%)]	Loss: 6.6213	Cost: 24.67s
Train Epoch: 472 [20480/90000 (23%)]	Loss: 5.6213	Cost: 7.61s
Train Epoch: 472 [40960/90000 (45%)]	Loss: 5.7231	Cost: 9.46s
Train Epoch: 472 [61440/90000 (68%)]	Loss: 5.6300	Cost: 8.76s
Train Epoch: 472 [81920/90000 (91%)]	Loss: 5.6052	Cost: 8.58s
Train Epoch: 472 	Average Loss: 5.7111
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7380

Learning rate: 9.945130899976472e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 473 [0/90000 (0%)]	Loss: 6.8991	Cost: 28.74s
Train Epoch: 473 [20480/90000 (23%)]	Loss: 5.6022	Cost: 8.24s
Train Epoch: 473 [40960/90000 (45%)]	Loss: 5.6000	Cost: 8.92s
Train Epoch: 473 [61440/90000 (68%)]	Loss: 5.5187	Cost: 8.65s
Train Epoch: 473 [81920/90000 (91%)]	Loss: 5.7495	Cost: 8.64s
Train Epoch: 473 	Average Loss: 5.6844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7288

Learning rate: 9.944898585926086e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 474 [0/90000 (0%)]	Loss: 6.4995	Cost: 27.62s
Train Epoch: 474 [20480/90000 (23%)]	Loss: 5.5893	Cost: 6.55s
Train Epoch: 474 [40960/90000 (45%)]	Loss: 5.7039	Cost: 7.03s
Train Epoch: 474 [61440/90000 (68%)]	Loss: 5.6978	Cost: 8.65s
Train Epoch: 474 [81920/90000 (91%)]	Loss: 5.6199	Cost: 13.53s
Train Epoch: 474 	Average Loss: 5.7134
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6851

Saving model as e474_model.pt & e474_waveforms_supplementary.hdf5
Learning rate: 9.944665783833775e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 475 [0/90000 (0%)]	Loss: 6.4750	Cost: 21.52s
Train Epoch: 475 [20480/90000 (23%)]	Loss: 5.4580	Cost: 9.91s
Train Epoch: 475 [40960/90000 (45%)]	Loss: 5.6227	Cost: 12.68s
Train Epoch: 475 [61440/90000 (68%)]	Loss: 5.4918	Cost: 14.51s
Train Epoch: 475 [81920/90000 (91%)]	Loss: 5.8464	Cost: 12.96s
Train Epoch: 475 	Average Loss: 5.6422
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7481

Learning rate: 9.944432493722518e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 476 [0/90000 (0%)]	Loss: 6.5370	Cost: 27.95s
Train Epoch: 476 [20480/90000 (23%)]	Loss: 5.6971	Cost: 16.04s
Train Epoch: 476 [40960/90000 (45%)]	Loss: 5.6144	Cost: 14.62s
Train Epoch: 476 [61440/90000 (68%)]	Loss: 5.4760	Cost: 12.28s
Train Epoch: 476 [81920/90000 (91%)]	Loss: 5.5494	Cost: 12.26s
Train Epoch: 476 	Average Loss: 5.6517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6854

Learning rate: 9.944198715615337e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 477 [0/90000 (0%)]	Loss: 6.6196	Cost: 32.77s
Train Epoch: 477 [20480/90000 (23%)]	Loss: 5.4493	Cost: 10.73s
Train Epoch: 477 [40960/90000 (45%)]	Loss: 5.5791	Cost: 12.42s
Train Epoch: 477 [61440/90000 (68%)]	Loss: 5.5678	Cost: 12.30s
Train Epoch: 477 [81920/90000 (91%)]	Loss: 5.6452	Cost: 7.89s
Train Epoch: 477 	Average Loss: 5.6072
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6731

Saving model as e477_model.pt & e477_waveforms_supplementary.hdf5
Learning rate: 9.943964449535306e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 478 [0/90000 (0%)]	Loss: 6.5443	Cost: 23.38s
Train Epoch: 478 [20480/90000 (23%)]	Loss: 5.5038	Cost: 12.70s
Train Epoch: 478 [40960/90000 (45%)]	Loss: 5.6749	Cost: 6.85s
Train Epoch: 478 [61440/90000 (68%)]	Loss: 5.4660	Cost: 6.16s
Train Epoch: 478 [81920/90000 (91%)]	Loss: 5.4635	Cost: 8.51s
Train Epoch: 478 	Average Loss: 5.6026
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6899

Learning rate: 9.943729695505547e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 479 [0/90000 (0%)]	Loss: 6.5446	Cost: 19.72s
Train Epoch: 479 [20480/90000 (23%)]	Loss: 5.4535	Cost: 7.86s
Train Epoch: 479 [40960/90000 (45%)]	Loss: 5.5948	Cost: 9.04s
Train Epoch: 479 [61440/90000 (68%)]	Loss: 5.5316	Cost: 9.00s
Train Epoch: 479 [81920/90000 (91%)]	Loss: 5.5944	Cost: 8.72s
Train Epoch: 479 	Average Loss: 5.5658
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6346

Saving model as e479_model.pt & e479_waveforms_supplementary.hdf5
Learning rate: 9.943494453549226e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 480 [0/90000 (0%)]	Loss: 6.6346	Cost: 25.84s
Train Epoch: 480 [20480/90000 (23%)]	Loss: 5.3683	Cost: 8.93s
Train Epoch: 480 [40960/90000 (45%)]	Loss: 5.5238	Cost: 7.13s
Train Epoch: 480 [61440/90000 (68%)]	Loss: 5.3966	Cost: 6.34s
Train Epoch: 480 [81920/90000 (91%)]	Loss: 5.6255	Cost: 6.54s
Train Epoch: 480 	Average Loss: 5.5687
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7369

Learning rate: 9.943258723689565e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 481 [0/90000 (0%)]	Loss: 6.7641	Cost: 24.88s
Train Epoch: 481 [20480/90000 (23%)]	Loss: 5.6246	Cost: 8.17s
Train Epoch: 481 [40960/90000 (45%)]	Loss: 5.4889	Cost: 10.20s
Train Epoch: 481 [61440/90000 (68%)]	Loss: 5.5199	Cost: 12.82s
Train Epoch: 481 [81920/90000 (91%)]	Loss: 5.4171	Cost: 12.58s
Train Epoch: 481 	Average Loss: 5.6186
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6877

Learning rate: 9.943022505949827e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 482 [0/90000 (0%)]	Loss: 6.5593	Cost: 21.49s
Train Epoch: 482 [20480/90000 (23%)]	Loss: 5.3089	Cost: 7.65s
Train Epoch: 482 [40960/90000 (45%)]	Loss: 5.5545	Cost: 13.91s
Train Epoch: 482 [61440/90000 (68%)]	Loss: 5.4746	Cost: 12.59s
Train Epoch: 482 [81920/90000 (91%)]	Loss: 5.4103	Cost: 12.44s
Train Epoch: 482 	Average Loss: 5.5544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7079

Learning rate: 9.942785800353326e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 483 [0/90000 (0%)]	Loss: 6.7078	Cost: 33.80s
Train Epoch: 483 [20480/90000 (23%)]	Loss: 5.4959	Cost: 12.25s
Train Epoch: 483 [40960/90000 (45%)]	Loss: 5.5060	Cost: 12.32s
Train Epoch: 483 [61440/90000 (68%)]	Loss: 5.4540	Cost: 12.31s
Train Epoch: 483 [81920/90000 (91%)]	Loss: 5.5017	Cost: 7.13s
Train Epoch: 483 	Average Loss: 5.5497
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6284

Saving model as e483_model.pt & e483_waveforms_supplementary.hdf5
Learning rate: 9.942548606923424e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 484 [0/90000 (0%)]	Loss: 6.8635	Cost: 23.75s
Train Epoch: 484 [20480/90000 (23%)]	Loss: 5.5411	Cost: 12.16s
Train Epoch: 484 [40960/90000 (45%)]	Loss: 5.5359	Cost: 7.61s
Train Epoch: 484 [61440/90000 (68%)]	Loss: 5.3942	Cost: 6.35s
Train Epoch: 484 [81920/90000 (91%)]	Loss: 5.4992	Cost: 7.87s
Train Epoch: 484 	Average Loss: 5.5352
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6616

Learning rate: 9.942310925683532e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 485 [0/90000 (0%)]	Loss: 6.6079	Cost: 30.46s
Train Epoch: 485 [20480/90000 (23%)]	Loss: 5.4256	Cost: 9.48s
Train Epoch: 485 [40960/90000 (45%)]	Loss: 5.4245	Cost: 8.48s
Train Epoch: 485 [61440/90000 (68%)]	Loss: 5.4327	Cost: 8.59s
Train Epoch: 485 [81920/90000 (91%)]	Loss: 5.4930	Cost: 8.41s
Train Epoch: 485 	Average Loss: 5.5203
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5737

Saving model as e485_model.pt & e485_waveforms_supplementary.hdf5
Learning rate: 9.942072756657107e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 486 [0/90000 (0%)]	Loss: 6.5319	Cost: 27.09s
Train Epoch: 486 [20480/90000 (23%)]	Loss: 5.5152	Cost: 9.00s
Train Epoch: 486 [40960/90000 (45%)]	Loss: 5.4692	Cost: 9.07s
Train Epoch: 486 [61440/90000 (68%)]	Loss: 5.3385	Cost: 8.68s
Train Epoch: 486 [81920/90000 (91%)]	Loss: 5.4817	Cost: 7.94s
Train Epoch: 486 	Average Loss: 5.4915
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5181

Saving model as e486_model.pt & e486_waveforms_supplementary.hdf5
Learning rate: 9.941834099867654e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 487 [0/90000 (0%)]	Loss: 6.3630	Cost: 20.45s
Train Epoch: 487 [20480/90000 (23%)]	Loss: 5.4556	Cost: 8.27s
Train Epoch: 487 [40960/90000 (45%)]	Loss: 5.3156	Cost: 13.62s
Train Epoch: 487 [61440/90000 (68%)]	Loss: 5.3769	Cost: 13.08s
Train Epoch: 487 [81920/90000 (91%)]	Loss: 5.5406	Cost: 13.87s
Train Epoch: 487 	Average Loss: 5.4626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5892

Learning rate: 9.941594955338732e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 488 [0/90000 (0%)]	Loss: 6.4556	Cost: 23.13s
Train Epoch: 488 [20480/90000 (23%)]	Loss: 5.3123	Cost: 8.30s
Train Epoch: 488 [40960/90000 (45%)]	Loss: 5.5122	Cost: 14.44s
Train Epoch: 488 [61440/90000 (68%)]	Loss: 5.2956	Cost: 13.15s
Train Epoch: 488 [81920/90000 (91%)]	Loss: 5.6483	Cost: 12.22s
Train Epoch: 488 	Average Loss: 5.4625
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6340

Learning rate: 9.941355323093938e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 489 [0/90000 (0%)]	Loss: 6.6184	Cost: 43.58s
Train Epoch: 489 [20480/90000 (23%)]	Loss: 5.2894	Cost: 12.33s
Train Epoch: 489 [40960/90000 (45%)]	Loss: 5.3840	Cost: 12.18s
Train Epoch: 489 [61440/90000 (68%)]	Loss: 5.4319	Cost: 10.13s
Train Epoch: 489 [81920/90000 (91%)]	Loss: 5.5946	Cost: 6.43s
Train Epoch: 489 	Average Loss: 5.4790
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5542

Learning rate: 9.941115203156927e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 490 [0/90000 (0%)]	Loss: 6.5107	Cost: 29.43s
Train Epoch: 490 [20480/90000 (23%)]	Loss: 5.6625	Cost: 12.23s
Train Epoch: 490 [40960/90000 (45%)]	Loss: 5.4743	Cost: 6.47s
Train Epoch: 490 [61440/90000 (68%)]	Loss: 5.4998	Cost: 6.62s
Train Epoch: 490 [81920/90000 (91%)]	Loss: 5.3966	Cost: 8.37s
Train Epoch: 490 	Average Loss: 5.5072
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5361

Learning rate: 9.940874595551397e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 491 [0/90000 (0%)]	Loss: 6.7098	Cost: 22.88s
Train Epoch: 491 [20480/90000 (23%)]	Loss: 5.2926	Cost: 6.71s
Train Epoch: 491 [40960/90000 (45%)]	Loss: 5.2721	Cost: 10.14s
Train Epoch: 491 [61440/90000 (68%)]	Loss: 5.1835	Cost: 8.71s
Train Epoch: 491 [81920/90000 (91%)]	Loss: 5.4914	Cost: 8.52s
Train Epoch: 491 	Average Loss: 5.4370
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5976

Learning rate: 9.940633500301093e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 492 [0/90000 (0%)]	Loss: 6.3810	Cost: 21.82s
Train Epoch: 492 [20480/90000 (23%)]	Loss: 5.1960	Cost: 9.18s
Train Epoch: 492 [40960/90000 (45%)]	Loss: 5.3343	Cost: 8.64s
Train Epoch: 492 [61440/90000 (68%)]	Loss: 5.2073	Cost: 6.60s
Train Epoch: 492 [81920/90000 (91%)]	Loss: 5.5210	Cost: 7.93s
Train Epoch: 492 	Average Loss: 5.4056
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5282

Learning rate: 9.940391917429813e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 493 [0/90000 (0%)]	Loss: 6.4812	Cost: 23.14s
Train Epoch: 493 [20480/90000 (23%)]	Loss: 5.3322	Cost: 10.19s
Train Epoch: 493 [40960/90000 (45%)]	Loss: 5.5190	Cost: 12.48s
Train Epoch: 493 [61440/90000 (68%)]	Loss: 5.2681	Cost: 12.66s
Train Epoch: 493 [81920/90000 (91%)]	Loss: 5.3907	Cost: 12.15s
Train Epoch: 493 	Average Loss: 5.4276
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5489

Learning rate: 9.9401498469614e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 494 [0/90000 (0%)]	Loss: 6.5558	Cost: 28.32s
Train Epoch: 494 [20480/90000 (23%)]	Loss: 5.2793	Cost: 13.52s
Train Epoch: 494 [40960/90000 (45%)]	Loss: 5.4034	Cost: 13.85s
Train Epoch: 494 [61440/90000 (68%)]	Loss: 5.2370	Cost: 12.49s
Train Epoch: 494 [81920/90000 (91%)]	Loss: 5.3569	Cost: 12.26s
Train Epoch: 494 	Average Loss: 5.3892
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4767

Saving model as e494_model.pt & e494_waveforms_supplementary.hdf5
Learning rate: 9.93990728891974e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 495 [0/90000 (0%)]	Loss: 6.5111	Cost: 29.52s
Train Epoch: 495 [20480/90000 (23%)]	Loss: 5.2549	Cost: 12.63s
Train Epoch: 495 [40960/90000 (45%)]	Loss: 5.3997	Cost: 12.41s
Train Epoch: 495 [61440/90000 (68%)]	Loss: 5.2294	Cost: 9.90s
Train Epoch: 495 [81920/90000 (91%)]	Loss: 5.3930	Cost: 8.81s
Train Epoch: 495 	Average Loss: 5.3607
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4837

Learning rate: 9.939664243328781e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 496 [0/90000 (0%)]	Loss: 6.4676	Cost: 23.52s
Train Epoch: 496 [20480/90000 (23%)]	Loss: 5.3483	Cost: 6.62s
Train Epoch: 496 [40960/90000 (45%)]	Loss: 5.1763	Cost: 7.47s
Train Epoch: 496 [61440/90000 (68%)]	Loss: 5.1589	Cost: 8.40s
Train Epoch: 496 [81920/90000 (91%)]	Loss: 5.4462	Cost: 9.22s
Train Epoch: 496 	Average Loss: 5.3759
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5298

Learning rate: 9.939420710212505e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 497 [0/90000 (0%)]	Loss: 6.5987	Cost: 20.32s
Train Epoch: 497 [20480/90000 (23%)]	Loss: 5.4063	Cost: 8.96s
Train Epoch: 497 [40960/90000 (45%)]	Loss: 5.3286	Cost: 9.08s
Train Epoch: 497 [61440/90000 (68%)]	Loss: 5.1909	Cost: 8.79s
Train Epoch: 497 [81920/90000 (91%)]	Loss: 5.4233	Cost: 8.65s
Train Epoch: 497 	Average Loss: 5.3999
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5909

Learning rate: 9.939176689594949e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 498 [0/90000 (0%)]	Loss: 6.4429	Cost: 32.35s
Train Epoch: 498 [20480/90000 (23%)]	Loss: 5.2145	Cost: 8.83s
Train Epoch: 498 [40960/90000 (45%)]	Loss: 5.3236	Cost: 6.90s
Train Epoch: 498 [61440/90000 (68%)]	Loss: 5.2428	Cost: 6.55s
Train Epoch: 498 [81920/90000 (91%)]	Loss: 5.4054	Cost: 6.38s
Train Epoch: 498 	Average Loss: 5.3477
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5435

Learning rate: 9.938932181500198e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 499 [0/90000 (0%)]	Loss: 6.3613	Cost: 22.30s
Train Epoch: 499 [20480/90000 (23%)]	Loss: 5.3242	Cost: 7.22s
Train Epoch: 499 [40960/90000 (45%)]	Loss: 5.1946	Cost: 12.75s
Train Epoch: 499 [61440/90000 (68%)]	Loss: 5.2087	Cost: 11.57s
Train Epoch: 499 [81920/90000 (91%)]	Loss: 5.3625	Cost: 12.45s
Train Epoch: 499 	Average Loss: 5.3144
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4595

Saving model as e499_model.pt & e499_waveforms_supplementary.hdf5
Learning rate: 9.938687185952383e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 500 [0/90000 (0%)]	Loss: 6.3927	Cost: 21.44s
Train Epoch: 500 [20480/90000 (23%)]	Loss: 5.2439	Cost: 13.89s
Train Epoch: 500 [40960/90000 (45%)]	Loss: 5.1211	Cost: 13.88s
Train Epoch: 500 [61440/90000 (68%)]	Loss: 5.1281	Cost: 12.54s
Train Epoch: 500 [81920/90000 (91%)]	Loss: 5.2926	Cost: 12.41s
Train Epoch: 500 	Average Loss: 5.2884
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5409

Learning rate: 9.938441702975683e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 501 [0/90000 (0%)]	Loss: 6.2773	Cost: 24.20s
Train Epoch: 501 [20480/90000 (23%)]	Loss: 5.2195	Cost: 10.32s
Train Epoch: 501 [40960/90000 (45%)]	Loss: 5.2758	Cost: 12.60s
Train Epoch: 501 [61440/90000 (68%)]	Loss: 5.2017	Cost: 12.53s
Train Epoch: 501 [81920/90000 (91%)]	Loss: 5.2683	Cost: 7.52s
Train Epoch: 501 	Average Loss: 5.2955
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4430

Saving model as e501_model.pt & e501_waveforms_supplementary.hdf5
Learning rate: 9.938195732594328e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 502 [0/90000 (0%)]	Loss: 6.5000	Cost: 23.20s
Train Epoch: 502 [20480/90000 (23%)]	Loss: 5.3323	Cost: 12.06s
Train Epoch: 502 [40960/90000 (45%)]	Loss: 5.2923	Cost: 8.79s
Train Epoch: 502 [61440/90000 (68%)]	Loss: 5.1547	Cost: 6.41s
Train Epoch: 502 [81920/90000 (91%)]	Loss: 5.4467	Cost: 7.38s
Train Epoch: 502 	Average Loss: 5.3277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4243

Saving model as e502_model.pt & e502_waveforms_supplementary.hdf5
Learning rate: 9.937949274832593e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 503 [0/90000 (0%)]	Loss: 6.6284	Cost: 27.18s
Train Epoch: 503 [20480/90000 (23%)]	Loss: 5.2805	Cost: 11.96s
Train Epoch: 503 [40960/90000 (45%)]	Loss: 5.3080	Cost: 8.77s
Train Epoch: 503 [61440/90000 (68%)]	Loss: 4.9853	Cost: 6.35s
Train Epoch: 503 [81920/90000 (91%)]	Loss: 5.2594	Cost: 8.39s
Train Epoch: 503 	Average Loss: 5.2693
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4428

Learning rate: 9.937702329714805e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 504 [0/90000 (0%)]	Loss: 6.3178	Cost: 22.79s
Train Epoch: 504 [20480/90000 (23%)]	Loss: 5.1225	Cost: 11.96s
Train Epoch: 504 [40960/90000 (45%)]	Loss: 5.1946	Cost: 10.72s
Train Epoch: 504 [61440/90000 (68%)]	Loss: 5.3037	Cost: 7.28s
Train Epoch: 504 [81920/90000 (91%)]	Loss: 5.3902	Cost: 7.16s
Train Epoch: 504 	Average Loss: 5.2478
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4789

Learning rate: 9.937454897265332e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 505 [0/90000 (0%)]	Loss: 6.3209	Cost: 22.55s
Train Epoch: 505 [20480/90000 (23%)]	Loss: 5.0570	Cost: 8.63s
Train Epoch: 505 [40960/90000 (45%)]	Loss: 5.1613	Cost: 8.10s
Train Epoch: 505 [61440/90000 (68%)]	Loss: 5.1198	Cost: 8.69s
Train Epoch: 505 [81920/90000 (91%)]	Loss: 5.1221	Cost: 8.44s
Train Epoch: 505 	Average Loss: 5.2260
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4148

Saving model as e505_model.pt & e505_waveforms_supplementary.hdf5
Learning rate: 9.937206977508597e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 506 [0/90000 (0%)]	Loss: 6.3899	Cost: 27.02s
Train Epoch: 506 [20480/90000 (23%)]	Loss: 5.0701	Cost: 8.74s
Train Epoch: 506 [40960/90000 (45%)]	Loss: 5.1194	Cost: 8.87s
Train Epoch: 506 [61440/90000 (68%)]	Loss: 5.2163	Cost: 8.74s
Train Epoch: 506 [81920/90000 (91%)]	Loss: 5.0592	Cost: 8.64s
Train Epoch: 506 	Average Loss: 5.1824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4216

Learning rate: 9.936958570469071e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 507 [0/90000 (0%)]	Loss: 6.2899	Cost: 24.23s
Train Epoch: 507 [20480/90000 (23%)]	Loss: 5.1160	Cost: 8.81s
Train Epoch: 507 [40960/90000 (45%)]	Loss: 5.0586	Cost: 8.99s
Train Epoch: 507 [61440/90000 (68%)]	Loss: 5.1134	Cost: 8.55s
Train Epoch: 507 [81920/90000 (91%)]	Loss: 5.0966	Cost: 8.78s
Train Epoch: 507 	Average Loss: 5.2105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4071

Saving model as e507_model.pt & e507_waveforms_supplementary.hdf5
Learning rate: 9.936709676171268e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 508 [0/90000 (0%)]	Loss: 6.2912	Cost: 22.16s
Train Epoch: 508 [20480/90000 (23%)]	Loss: 5.0224	Cost: 10.35s
Train Epoch: 508 [40960/90000 (45%)]	Loss: 5.4035	Cost: 10.66s
Train Epoch: 508 [61440/90000 (68%)]	Loss: 5.2701	Cost: 11.98s
Train Epoch: 508 [81920/90000 (91%)]	Loss: 5.3129	Cost: 12.41s
Train Epoch: 508 	Average Loss: 5.3403
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4316

Learning rate: 9.936460294639754e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 509 [0/90000 (0%)]	Loss: 6.4131	Cost: 21.65s
Train Epoch: 509 [20480/90000 (23%)]	Loss: 5.1424	Cost: 10.34s
Train Epoch: 509 [40960/90000 (45%)]	Loss: 5.1929	Cost: 17.27s
Train Epoch: 509 [61440/90000 (68%)]	Loss: 5.1151	Cost: 14.11s
Train Epoch: 509 [81920/90000 (91%)]	Loss: 5.2032	Cost: 12.05s
Train Epoch: 509 	Average Loss: 5.2067
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3881

Saving model as e509_model.pt & e509_waveforms_supplementary.hdf5
Learning rate: 9.93621042589914e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 510 [0/90000 (0%)]	Loss: 6.2602	Cost: 35.82s
Train Epoch: 510 [20480/90000 (23%)]	Loss: 5.1439	Cost: 9.77s
Train Epoch: 510 [40960/90000 (45%)]	Loss: 5.2053	Cost: 12.35s
Train Epoch: 510 [61440/90000 (68%)]	Loss: 5.0414	Cost: 12.60s
Train Epoch: 510 [81920/90000 (91%)]	Loss: 5.2399	Cost: 7.71s
Train Epoch: 510 	Average Loss: 5.1701
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3552

Saving model as e510_model.pt & e510_waveforms_supplementary.hdf5
Learning rate: 9.935960069974091e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 511 [0/90000 (0%)]	Loss: 6.1043	Cost: 23.84s
Train Epoch: 511 [20480/90000 (23%)]	Loss: 5.1710	Cost: 10.27s
Train Epoch: 511 [40960/90000 (45%)]	Loss: 5.1147	Cost: 9.86s
Train Epoch: 511 [61440/90000 (68%)]	Loss: 5.0439	Cost: 6.03s
Train Epoch: 511 [81920/90000 (91%)]	Loss: 5.0961	Cost: 7.33s
Train Epoch: 511 	Average Loss: 5.1344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3575

Learning rate: 9.935709226889313e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 512 [0/90000 (0%)]	Loss: 6.7352	Cost: 25.94s
Train Epoch: 512 [20480/90000 (23%)]	Loss: 5.0280	Cost: 9.92s
Train Epoch: 512 [40960/90000 (45%)]	Loss: 5.0907	Cost: 11.47s
Train Epoch: 512 [61440/90000 (68%)]	Loss: 5.1482	Cost: 6.13s
Train Epoch: 512 [81920/90000 (91%)]	Loss: 5.2267	Cost: 7.01s
Train Epoch: 512 	Average Loss: 5.1444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4107

Learning rate: 9.935457896669563e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 513 [0/90000 (0%)]	Loss: 6.3334	Cost: 23.33s
Train Epoch: 513 [20480/90000 (23%)]	Loss: 5.0543	Cost: 8.26s
Train Epoch: 513 [40960/90000 (45%)]	Loss: 4.9822	Cost: 9.16s
Train Epoch: 513 [61440/90000 (68%)]	Loss: 4.9280	Cost: 9.47s
Train Epoch: 513 [81920/90000 (91%)]	Loss: 5.1616	Cost: 9.09s
Train Epoch: 513 	Average Loss: 5.1220
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3444

Saving model as e513_model.pt & e513_waveforms_supplementary.hdf5
Learning rate: 9.935206079339646e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 514 [0/90000 (0%)]	Loss: 6.4172	Cost: 21.06s
Train Epoch: 514 [20480/90000 (23%)]	Loss: 5.1511	Cost: 10.98s
Train Epoch: 514 [40960/90000 (45%)]	Loss: 5.0593	Cost: 10.54s
Train Epoch: 514 [61440/90000 (68%)]	Loss: 4.9299	Cost: 10.19s
Train Epoch: 514 [81920/90000 (91%)]	Loss: 4.9769	Cost: 12.76s
Train Epoch: 514 	Average Loss: 5.1415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3599

Learning rate: 9.934953774924418e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 515 [0/90000 (0%)]	Loss: 6.3820	Cost: 25.99s
Train Epoch: 515 [20480/90000 (23%)]	Loss: 5.0536	Cost: 10.41s
Train Epoch: 515 [40960/90000 (45%)]	Loss: 5.1900	Cost: 15.29s
Train Epoch: 515 [61440/90000 (68%)]	Loss: 5.0162	Cost: 12.27s
Train Epoch: 515 [81920/90000 (91%)]	Loss: 5.1067	Cost: 12.18s
Train Epoch: 515 	Average Loss: 5.1344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2739

Saving model as e515_model.pt & e515_waveforms_supplementary.hdf5
Learning rate: 9.93470098344878e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 516 [0/90000 (0%)]	Loss: 6.2099	Cost: 25.43s
Train Epoch: 516 [20480/90000 (23%)]	Loss: 5.1463	Cost: 10.85s
Train Epoch: 516 [40960/90000 (45%)]	Loss: 4.9724	Cost: 12.54s
Train Epoch: 516 [61440/90000 (68%)]	Loss: 4.9408	Cost: 12.06s
Train Epoch: 516 [81920/90000 (91%)]	Loss: 5.1060	Cost: 7.38s
Train Epoch: 516 	Average Loss: 5.1042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3227

Learning rate: 9.934447704937678e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 517 [0/90000 (0%)]	Loss: 6.3229	Cost: 25.02s
Train Epoch: 517 [20480/90000 (23%)]	Loss: 5.0470	Cost: 12.18s
Train Epoch: 517 [40960/90000 (45%)]	Loss: 5.0995	Cost: 10.29s
Train Epoch: 517 [61440/90000 (68%)]	Loss: 4.9177	Cost: 6.42s
Train Epoch: 517 [81920/90000 (91%)]	Loss: 5.0699	Cost: 7.22s
Train Epoch: 517 	Average Loss: 5.0760
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2935

Learning rate: 9.934193939416114e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 518 [0/90000 (0%)]	Loss: 6.1849	Cost: 22.63s
Train Epoch: 518 [20480/90000 (23%)]	Loss: 4.9457	Cost: 10.03s
Train Epoch: 518 [40960/90000 (45%)]	Loss: 5.0721	Cost: 10.55s
Train Epoch: 518 [61440/90000 (68%)]	Loss: 4.8538	Cost: 9.19s
Train Epoch: 518 [81920/90000 (91%)]	Loss: 4.9603	Cost: 8.95s
Train Epoch: 518 	Average Loss: 5.0327
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3221

Learning rate: 9.933939686909132e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 519 [0/90000 (0%)]	Loss: 6.0547	Cost: 22.11s
Train Epoch: 519 [20480/90000 (23%)]	Loss: 4.8473	Cost: 11.72s
Train Epoch: 519 [40960/90000 (45%)]	Loss: 4.8285	Cost: 12.33s
Train Epoch: 519 [61440/90000 (68%)]	Loss: 4.8392	Cost: 8.88s
Train Epoch: 519 [81920/90000 (91%)]	Loss: 4.9473	Cost: 7.60s
Train Epoch: 519 	Average Loss: 5.0223
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3391

Learning rate: 9.933684947441824e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 520 [0/90000 (0%)]	Loss: 6.2213	Cost: 22.84s
Train Epoch: 520 [20480/90000 (23%)]	Loss: 4.8697	Cost: 6.79s
Train Epoch: 520 [40960/90000 (45%)]	Loss: 4.9328	Cost: 10.20s
Train Epoch: 520 [61440/90000 (68%)]	Loss: 4.7959	Cost: 12.36s
Train Epoch: 520 [81920/90000 (91%)]	Loss: 4.9826	Cost: 12.63s
Train Epoch: 520 	Average Loss: 5.0265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1749

Saving model as e520_model.pt & e520_waveforms_supplementary.hdf5
Learning rate: 9.933429721039335e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 521 [0/90000 (0%)]	Loss: 6.1394	Cost: 27.09s
Train Epoch: 521 [20480/90000 (23%)]	Loss: 4.9462	Cost: 13.10s
Train Epoch: 521 [40960/90000 (45%)]	Loss: 4.9604	Cost: 12.42s
Train Epoch: 521 [61440/90000 (68%)]	Loss: 4.9034	Cost: 12.27s
Train Epoch: 521 [81920/90000 (91%)]	Loss: 4.9570	Cost: 11.15s
Train Epoch: 521 	Average Loss: 5.0147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2621

Learning rate: 9.933174007726853e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 522 [0/90000 (0%)]	Loss: 6.1121	Cost: 24.51s
Train Epoch: 522 [20480/90000 (23%)]	Loss: 4.8563	Cost: 12.63s
Train Epoch: 522 [40960/90000 (45%)]	Loss: 4.9496	Cost: 12.44s
Train Epoch: 522 [61440/90000 (68%)]	Loss: 4.8969	Cost: 9.69s
Train Epoch: 522 [81920/90000 (91%)]	Loss: 4.9559	Cost: 6.17s
Train Epoch: 522 	Average Loss: 4.9690
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1969

Learning rate: 9.932917807529615e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 523 [0/90000 (0%)]	Loss: 6.0244	Cost: 29.68s
Train Epoch: 523 [20480/90000 (23%)]	Loss: 4.9452	Cost: 11.32s
Train Epoch: 523 [40960/90000 (45%)]	Loss: 4.9589	Cost: 10.84s
Train Epoch: 523 [61440/90000 (68%)]	Loss: 4.8080	Cost: 6.18s
Train Epoch: 523 [81920/90000 (91%)]	Loss: 4.9428	Cost: 7.06s
Train Epoch: 523 	Average Loss: 4.9657
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2123

Learning rate: 9.93266112047291e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 524 [0/90000 (0%)]	Loss: 6.1259	Cost: 21.96s
Train Epoch: 524 [20480/90000 (23%)]	Loss: 4.8384	Cost: 13.30s
Train Epoch: 524 [40960/90000 (45%)]	Loss: 4.9583	Cost: 11.63s
Train Epoch: 524 [61440/90000 (68%)]	Loss: 4.8634	Cost: 7.93s
Train Epoch: 524 [81920/90000 (91%)]	Loss: 5.0669	Cost: 8.83s
Train Epoch: 524 	Average Loss: 4.9761
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2689

Learning rate: 9.932403946582067e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 525 [0/90000 (0%)]	Loss: 6.1132	Cost: 21.80s
Train Epoch: 525 [20480/90000 (23%)]	Loss: 4.9064	Cost: 7.94s
Train Epoch: 525 [40960/90000 (45%)]	Loss: 4.8395	Cost: 8.99s
Train Epoch: 525 [61440/90000 (68%)]	Loss: 4.9364	Cost: 8.91s
Train Epoch: 525 [81920/90000 (91%)]	Loss: 4.9346	Cost: 8.77s
Train Epoch: 525 	Average Loss: 4.9470
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1995

Learning rate: 9.932146285882473e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 526 [0/90000 (0%)]	Loss: 6.2370	Cost: 20.66s
Train Epoch: 526 [20480/90000 (23%)]	Loss: 4.7815	Cost: 9.09s
Train Epoch: 526 [40960/90000 (45%)]	Loss: 4.8753	Cost: 8.99s
Train Epoch: 526 [61440/90000 (68%)]	Loss: 4.6942	Cost: 6.98s
Train Epoch: 526 [81920/90000 (91%)]	Loss: 4.7912	Cost: 6.39s
Train Epoch: 526 	Average Loss: 4.9240
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2949

Learning rate: 9.931888138399556e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 527 [0/90000 (0%)]	Loss: 6.1721	Cost: 20.87s
Train Epoch: 527 [20480/90000 (23%)]	Loss: 4.8592	Cost: 7.16s
Train Epoch: 527 [40960/90000 (45%)]	Loss: 5.0226	Cost: 8.97s
Train Epoch: 527 [61440/90000 (68%)]	Loss: 4.8300	Cost: 12.28s
Train Epoch: 527 [81920/90000 (91%)]	Loss: 4.8113	Cost: 12.74s
Train Epoch: 527 	Average Loss: 4.9195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2221

Learning rate: 9.931629504158793e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 528 [0/90000 (0%)]	Loss: 6.0633	Cost: 32.76s
Train Epoch: 528 [20480/90000 (23%)]	Loss: 4.7113	Cost: 15.18s
Train Epoch: 528 [40960/90000 (45%)]	Loss: 4.8312	Cost: 14.81s
Train Epoch: 528 [61440/90000 (68%)]	Loss: 4.7316	Cost: 12.24s
Train Epoch: 528 [81920/90000 (91%)]	Loss: 4.9393	Cost: 12.03s
Train Epoch: 528 	Average Loss: 4.9027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2971

Learning rate: 9.931370383185712e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 529 [0/90000 (0%)]	Loss: 6.3451	Cost: 41.38s
Train Epoch: 529 [20480/90000 (23%)]	Loss: 4.7253	Cost: 12.34s
Train Epoch: 529 [40960/90000 (45%)]	Loss: 4.7252	Cost: 12.29s
Train Epoch: 529 [61440/90000 (68%)]	Loss: 4.6627	Cost: 10.02s
Train Epoch: 529 [81920/90000 (91%)]	Loss: 4.8861	Cost: 6.28s
Train Epoch: 529 	Average Loss: 4.8690
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1103

Saving model as e529_model.pt & e529_waveforms_supplementary.hdf5
Learning rate: 9.931110775505886e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 530 [0/90000 (0%)]	Loss: 5.9365	Cost: 26.00s
Train Epoch: 530 [20480/90000 (23%)]	Loss: 4.7668	Cost: 10.67s
Train Epoch: 530 [40960/90000 (45%)]	Loss: 4.7233	Cost: 6.25s
Train Epoch: 530 [61440/90000 (68%)]	Loss: 4.6829	Cost: 6.15s
Train Epoch: 530 [81920/90000 (91%)]	Loss: 4.8344	Cost: 8.77s
Train Epoch: 530 	Average Loss: 4.8284
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1723

Learning rate: 9.93085068114494e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 531 [0/90000 (0%)]	Loss: 6.2660	Cost: 22.15s
Train Epoch: 531 [20480/90000 (23%)]	Loss: 4.8032	Cost: 8.99s
Train Epoch: 531 [40960/90000 (45%)]	Loss: 4.8945	Cost: 9.03s
Train Epoch: 531 [61440/90000 (68%)]	Loss: 4.6575	Cost: 8.62s
Train Epoch: 531 [81920/90000 (91%)]	Loss: 4.7389	Cost: 8.80s
Train Epoch: 531 	Average Loss: 4.8421
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2043

Learning rate: 9.930590100128539e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 532 [0/90000 (0%)]	Loss: 6.0604	Cost: 19.40s
Train Epoch: 532 [20480/90000 (23%)]	Loss: 4.8148	Cost: 9.24s
Train Epoch: 532 [40960/90000 (45%)]	Loss: 4.7293	Cost: 12.32s
Train Epoch: 532 [61440/90000 (68%)]	Loss: 4.7038	Cost: 12.39s
Train Epoch: 532 [81920/90000 (91%)]	Loss: 4.7811	Cost: 12.29s
Train Epoch: 532 	Average Loss: 4.8098
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1616

Learning rate: 9.930329032482406e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 533 [0/90000 (0%)]	Loss: 6.0261	Cost: 40.19s
Train Epoch: 533 [20480/90000 (23%)]	Loss: 4.9148	Cost: 12.44s
Train Epoch: 533 [40960/90000 (45%)]	Loss: 4.6210	Cost: 12.36s
Train Epoch: 533 [61440/90000 (68%)]	Loss: 4.6231	Cost: 12.41s
Train Epoch: 533 [81920/90000 (91%)]	Loss: 4.8924	Cost: 11.84s
Train Epoch: 533 	Average Loss: 4.8127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1803

Learning rate: 9.930067478232305e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 534 [0/90000 (0%)]	Loss: 6.1194	Cost: 27.89s
Train Epoch: 534 [20480/90000 (23%)]	Loss: 4.8975	Cost: 13.24s
Train Epoch: 534 [40960/90000 (45%)]	Loss: 4.7400	Cost: 12.24s
Train Epoch: 534 [61440/90000 (68%)]	Loss: 4.8459	Cost: 11.31s
Train Epoch: 534 [81920/90000 (91%)]	Loss: 4.7198	Cost: 6.25s
Train Epoch: 534 	Average Loss: 4.8276
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1508

Learning rate: 9.929805437404053e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 535 [0/90000 (0%)]	Loss: 6.0517	Cost: 26.47s
Train Epoch: 535 [20480/90000 (23%)]	Loss: 4.6234	Cost: 12.83s
Train Epoch: 535 [40960/90000 (45%)]	Loss: 4.8629	Cost: 13.24s
Train Epoch: 535 [61440/90000 (68%)]	Loss: 4.6665	Cost: 8.87s
Train Epoch: 535 [81920/90000 (91%)]	Loss: 4.8292	Cost: 6.53s
Train Epoch: 535 	Average Loss: 4.8237
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1671

Learning rate: 9.92954291002351e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 536 [0/90000 (0%)]	Loss: 6.1048	Cost: 24.97s
Train Epoch: 536 [20480/90000 (23%)]	Loss: 4.7542	Cost: 11.27s
Train Epoch: 536 [40960/90000 (45%)]	Loss: 5.0400	Cost: 9.41s
Train Epoch: 536 [61440/90000 (68%)]	Loss: 4.8237	Cost: 6.40s
Train Epoch: 536 [81920/90000 (91%)]	Loss: 4.8827	Cost: 7.24s
Train Epoch: 536 	Average Loss: 4.8684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2476

Learning rate: 9.929279896116587e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 537 [0/90000 (0%)]	Loss: 5.9869	Cost: 19.68s
Train Epoch: 537 [20480/90000 (23%)]	Loss: 4.6290	Cost: 6.65s
Train Epoch: 537 [40960/90000 (45%)]	Loss: 4.5764	Cost: 10.58s
Train Epoch: 537 [61440/90000 (68%)]	Loss: 4.6827	Cost: 9.17s
Train Epoch: 537 [81920/90000 (91%)]	Loss: 4.8100	Cost: 8.80s
Train Epoch: 537 	Average Loss: 4.7754
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0743

Saving model as e537_model.pt & e537_waveforms_supplementary.hdf5
Learning rate: 9.929016395709243e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 538 [0/90000 (0%)]	Loss: 5.8249	Cost: 30.46s
Train Epoch: 538 [20480/90000 (23%)]	Loss: 4.5887	Cost: 8.85s
Train Epoch: 538 [40960/90000 (45%)]	Loss: 4.7779	Cost: 6.46s
Train Epoch: 538 [61440/90000 (68%)]	Loss: 4.6225	Cost: 6.52s
Train Epoch: 538 [81920/90000 (91%)]	Loss: 4.6423	Cost: 7.69s
Train Epoch: 538 	Average Loss: 4.7227
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0556

Saving model as e538_model.pt & e538_waveforms_supplementary.hdf5
Learning rate: 9.928752408827483e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 539 [0/90000 (0%)]	Loss: 6.0247	Cost: 33.08s
Train Epoch: 539 [20480/90000 (23%)]	Loss: 4.6440	Cost: 7.55s
Train Epoch: 539 [40960/90000 (45%)]	Loss: 4.6991	Cost: 13.34s
Train Epoch: 539 [61440/90000 (68%)]	Loss: 4.7623	Cost: 12.47s
Train Epoch: 539 [81920/90000 (91%)]	Loss: 4.8435	Cost: 12.16s
Train Epoch: 539 	Average Loss: 4.7906
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1567

Learning rate: 9.928487935497362e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 540 [0/90000 (0%)]	Loss: 6.0243	Cost: 28.32s
Train Epoch: 540 [20480/90000 (23%)]	Loss: 4.6771	Cost: 14.32s
Train Epoch: 540 [40960/90000 (45%)]	Loss: 4.6290	Cost: 12.99s
Train Epoch: 540 [61440/90000 (68%)]	Loss: 4.5305	Cost: 12.58s
Train Epoch: 540 [81920/90000 (91%)]	Loss: 4.9266	Cost: 9.96s
Train Epoch: 540 	Average Loss: 4.7404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1819

Learning rate: 9.928222975744984e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 541 [0/90000 (0%)]	Loss: 5.9747	Cost: 25.00s
Train Epoch: 541 [20480/90000 (23%)]	Loss: 4.8956	Cost: 10.55s
Train Epoch: 541 [40960/90000 (45%)]	Loss: 4.7438	Cost: 12.63s
Train Epoch: 541 [61440/90000 (68%)]	Loss: 4.7353	Cost: 12.46s
Train Epoch: 541 [81920/90000 (91%)]	Loss: 4.6959	Cost: 7.69s
Train Epoch: 541 	Average Loss: 4.8678
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1972

Learning rate: 9.927957529596498e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 542 [0/90000 (0%)]	Loss: 5.9778	Cost: 25.37s
Train Epoch: 542 [20480/90000 (23%)]	Loss: 4.6950	Cost: 12.80s
Train Epoch: 542 [40960/90000 (45%)]	Loss: 4.6740	Cost: 9.99s
Train Epoch: 542 [61440/90000 (68%)]	Loss: 4.5498	Cost: 6.32s
Train Epoch: 542 [81920/90000 (91%)]	Loss: 4.6141	Cost: 6.90s
Train Epoch: 542 	Average Loss: 4.7135
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0234

Saving model as e542_model.pt & e542_waveforms_supplementary.hdf5
Learning rate: 9.927691597078101e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 543 [0/90000 (0%)]	Loss: 6.2364	Cost: 33.71s
Train Epoch: 543 [20480/90000 (23%)]	Loss: 4.5581	Cost: 7.17s
Train Epoch: 543 [40960/90000 (45%)]	Loss: 4.5594	Cost: 9.31s
Train Epoch: 543 [61440/90000 (68%)]	Loss: 4.3224	Cost: 8.54s
Train Epoch: 543 [81920/90000 (91%)]	Loss: 4.6050	Cost: 8.43s
Train Epoch: 543 	Average Loss: 4.6391
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0291

Learning rate: 9.927425178216043e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 544 [0/90000 (0%)]	Loss: 6.0147	Cost: 28.12s
Train Epoch: 544 [20480/90000 (23%)]	Loss: 4.5189	Cost: 9.19s
Train Epoch: 544 [40960/90000 (45%)]	Loss: 4.6197	Cost: 9.00s
Train Epoch: 544 [61440/90000 (68%)]	Loss: 4.5692	Cost: 8.56s
Train Epoch: 544 [81920/90000 (91%)]	Loss: 4.6438	Cost: 8.38s
Train Epoch: 544 	Average Loss: 4.6411
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0098

Saving model as e544_model.pt & e544_waveforms_supplementary.hdf5
Learning rate: 9.927158273036618e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 545 [0/90000 (0%)]	Loss: 5.7636	Cost: 21.29s
Train Epoch: 545 [20480/90000 (23%)]	Loss: 4.4898	Cost: 6.37s
Train Epoch: 545 [40960/90000 (45%)]	Loss: 4.6234	Cost: 15.25s
Train Epoch: 545 [61440/90000 (68%)]	Loss: 4.4431	Cost: 12.52s
Train Epoch: 545 [81920/90000 (91%)]	Loss: 4.6570	Cost: 13.16s
Train Epoch: 545 	Average Loss: 4.6388
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0869

Learning rate: 9.926890881566166e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 546 [0/90000 (0%)]	Loss: 6.1684	Cost: 22.02s
Train Epoch: 546 [20480/90000 (23%)]	Loss: 4.5433	Cost: 6.87s
Train Epoch: 546 [40960/90000 (45%)]	Loss: 4.4237	Cost: 12.94s
Train Epoch: 546 [61440/90000 (68%)]	Loss: 4.4797	Cost: 13.84s
Train Epoch: 546 [81920/90000 (91%)]	Loss: 4.5420	Cost: 12.53s
Train Epoch: 546 	Average Loss: 4.6104
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9604

Saving model as e546_model.pt & e546_waveforms_supplementary.hdf5
Learning rate: 9.926623003831078e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 547 [0/90000 (0%)]	Loss: 5.9634	Cost: 30.01s
Train Epoch: 547 [20480/90000 (23%)]	Loss: 4.5630	Cost: 12.77s
Train Epoch: 547 [40960/90000 (45%)]	Loss: 4.5161	Cost: 13.88s
Train Epoch: 547 [61440/90000 (68%)]	Loss: 4.3409	Cost: 12.27s
Train Epoch: 547 [81920/90000 (91%)]	Loss: 4.6178	Cost: 7.07s
Train Epoch: 547 	Average Loss: 4.5896
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9402

Saving model as e547_model.pt & e547_waveforms_supplementary.hdf5
Learning rate: 9.926354639857796e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 548 [0/90000 (0%)]	Loss: 5.9128	Cost: 35.67s
Train Epoch: 548 [20480/90000 (23%)]	Loss: 4.4834	Cost: 10.50s
Train Epoch: 548 [40960/90000 (45%)]	Loss: 4.5855	Cost: 10.14s
Train Epoch: 548 [61440/90000 (68%)]	Loss: 4.4365	Cost: 6.04s
Train Epoch: 548 [81920/90000 (91%)]	Loss: 4.5982	Cost: 6.78s
Train Epoch: 548 	Average Loss: 4.5812
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9726

Learning rate: 9.926085789672802e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 549 [0/90000 (0%)]	Loss: 5.8331	Cost: 36.94s
Train Epoch: 549 [20480/90000 (23%)]	Loss: 4.4570	Cost: 9.39s
Train Epoch: 549 [40960/90000 (45%)]	Loss: 4.3910	Cost: 6.99s
Train Epoch: 549 [61440/90000 (68%)]	Loss: 4.6778	Cost: 7.39s
Train Epoch: 549 [81920/90000 (91%)]	Loss: 4.7804	Cost: 8.30s
Train Epoch: 549 	Average Loss: 4.5950
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0712

Learning rate: 9.92581645330263e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 550 [0/90000 (0%)]	Loss: 6.1218	Cost: 22.53s
Train Epoch: 550 [20480/90000 (23%)]	Loss: 4.4698	Cost: 8.24s
Train Epoch: 550 [40960/90000 (45%)]	Loss: 4.5356	Cost: 8.91s
Train Epoch: 550 [61440/90000 (68%)]	Loss: 4.4146	Cost: 9.40s
Train Epoch: 550 [81920/90000 (91%)]	Loss: 4.4538	Cost: 9.06s
Train Epoch: 550 	Average Loss: 4.6094
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9622

Learning rate: 9.925546630773865e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 551 [0/90000 (0%)]	Loss: 5.6910	Cost: 21.25s
Train Epoch: 551 [20480/90000 (23%)]	Loss: 4.4396	Cost: 11.33s
Train Epoch: 551 [40960/90000 (45%)]	Loss: 4.3616	Cost: 9.64s
Train Epoch: 551 [61440/90000 (68%)]	Loss: 4.3944	Cost: 8.83s
Train Epoch: 551 [81920/90000 (91%)]	Loss: 4.5111	Cost: 7.94s
Train Epoch: 551 	Average Loss: 4.5085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9711

Learning rate: 9.925276322113137e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 552 [0/90000 (0%)]	Loss: 5.8187	Cost: 26.47s
Train Epoch: 552 [20480/90000 (23%)]	Loss: 4.4341	Cost: 10.18s
Train Epoch: 552 [40960/90000 (45%)]	Loss: 4.4609	Cost: 11.22s
Train Epoch: 552 [61440/90000 (68%)]	Loss: 4.2280	Cost: 12.55s
Train Epoch: 552 [81920/90000 (91%)]	Loss: 4.4698	Cost: 12.43s
Train Epoch: 552 	Average Loss: 4.5056
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9108

Saving model as e552_model.pt & e552_waveforms_supplementary.hdf5
Learning rate: 9.925005527347125e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 553 [0/90000 (0%)]	Loss: 5.8482	Cost: 25.17s
Train Epoch: 553 [20480/90000 (23%)]	Loss: 4.5218	Cost: 13.98s
Train Epoch: 553 [40960/90000 (45%)]	Loss: 4.5729	Cost: 12.56s
Train Epoch: 553 [61440/90000 (68%)]	Loss: 4.4326	Cost: 12.06s
Train Epoch: 553 [81920/90000 (91%)]	Loss: 4.4411	Cost: 9.74s
Train Epoch: 553 	Average Loss: 4.5213
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9088

Saving model as e553_model.pt & e553_waveforms_supplementary.hdf5
Learning rate: 9.924734246502554e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 554 [0/90000 (0%)]	Loss: 5.9282	Cost: 27.13s
Train Epoch: 554 [20480/90000 (23%)]	Loss: 4.3933	Cost: 10.83s
Train Epoch: 554 [40960/90000 (45%)]	Loss: 4.5150	Cost: 9.31s
Train Epoch: 554 [61440/90000 (68%)]	Loss: 4.2336	Cost: 6.32s
Train Epoch: 554 [81920/90000 (91%)]	Loss: 4.4186	Cost: 7.24s
Train Epoch: 554 	Average Loss: 4.4753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8928

Saving model as e554_model.pt & e554_waveforms_supplementary.hdf5
Learning rate: 9.9244624796062e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 555 [0/90000 (0%)]	Loss: 5.7185	Cost: 23.29s
Train Epoch: 555 [20480/90000 (23%)]	Loss: 4.3319	Cost: 9.96s
Train Epoch: 555 [40960/90000 (45%)]	Loss: 4.4455	Cost: 9.68s
Train Epoch: 555 [61440/90000 (68%)]	Loss: 4.2475	Cost: 9.04s
Train Epoch: 555 [81920/90000 (91%)]	Loss: 4.6349	Cost: 8.72s
Train Epoch: 555 	Average Loss: 4.4529
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9645

Learning rate: 9.924190226684883e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 556 [0/90000 (0%)]	Loss: 5.8398	Cost: 19.50s
Train Epoch: 556 [20480/90000 (23%)]	Loss: 4.3765	Cost: 9.24s
Train Epoch: 556 [40960/90000 (45%)]	Loss: 4.4080	Cost: 13.30s
Train Epoch: 556 [61440/90000 (68%)]	Loss: 4.2971	Cost: 9.03s
Train Epoch: 556 [81920/90000 (91%)]	Loss: 4.4485	Cost: 8.91s
Train Epoch: 556 	Average Loss: 4.4411
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8911

Saving model as e556_model.pt & e556_waveforms_supplementary.hdf5
Learning rate: 9.923917487765477e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 557 [0/90000 (0%)]	Loss: 5.8533	Cost: 22.85s
Train Epoch: 557 [20480/90000 (23%)]	Loss: 4.5365	Cost: 8.70s
Train Epoch: 557 [40960/90000 (45%)]	Loss: 4.4833	Cost: 6.41s
Train Epoch: 557 [61440/90000 (68%)]	Loss: 4.2632	Cost: 7.41s
Train Epoch: 557 [81920/90000 (91%)]	Loss: 4.7727	Cost: 7.55s
Train Epoch: 557 	Average Loss: 4.6328
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1707

Learning rate: 9.923644262874898e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 558 [0/90000 (0%)]	Loss: 6.0199	Cost: 19.15s
Train Epoch: 558 [20480/90000 (23%)]	Loss: 4.6276	Cost: 7.65s
Train Epoch: 558 [40960/90000 (45%)]	Loss: 4.5797	Cost: 11.84s
Train Epoch: 558 [61440/90000 (68%)]	Loss: 4.4244	Cost: 12.47s
Train Epoch: 558 [81920/90000 (91%)]	Loss: 4.4658	Cost: 12.27s
Train Epoch: 558 	Average Loss: 4.5911
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9794

Learning rate: 9.92337055204011e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 559 [0/90000 (0%)]	Loss: 5.9751	Cost: 25.02s
Train Epoch: 559 [20480/90000 (23%)]	Loss: 4.4196	Cost: 10.72s
Train Epoch: 559 [40960/90000 (45%)]	Loss: 4.4964	Cost: 12.62s
Train Epoch: 559 [61440/90000 (68%)]	Loss: 4.2238	Cost: 12.57s
Train Epoch: 559 [81920/90000 (91%)]	Loss: 4.3258	Cost: 12.37s
Train Epoch: 559 	Average Loss: 4.4567
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8131

Saving model as e559_model.pt & e559_waveforms_supplementary.hdf5
Learning rate: 9.92309635528813e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 560 [0/90000 (0%)]	Loss: 5.7936	Cost: 40.43s
Train Epoch: 560 [20480/90000 (23%)]	Loss: 4.2812	Cost: 13.49s
Train Epoch: 560 [40960/90000 (45%)]	Loss: 4.3537	Cost: 12.29s
Train Epoch: 560 [61440/90000 (68%)]	Loss: 4.2326	Cost: 10.72s
Train Epoch: 560 [81920/90000 (91%)]	Loss: 4.3923	Cost: 6.04s
Train Epoch: 560 	Average Loss: 4.3981
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8311

Learning rate: 9.92282167264602e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 561 [0/90000 (0%)]	Loss: 5.6304	Cost: 41.68s
Train Epoch: 561 [20480/90000 (23%)]	Loss: 4.3079	Cost: 12.64s
Train Epoch: 561 [40960/90000 (45%)]	Loss: 4.4408	Cost: 9.13s
Train Epoch: 561 [61440/90000 (68%)]	Loss: 4.1784	Cost: 6.08s
Train Epoch: 561 [81920/90000 (91%)]	Loss: 4.2752	Cost: 7.34s
Train Epoch: 561 	Average Loss: 4.3925
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8741

Learning rate: 9.92254650414089e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 562 [0/90000 (0%)]	Loss: 6.1048	Cost: 26.56s
Train Epoch: 562 [20480/90000 (23%)]	Loss: 4.3153	Cost: 10.87s
Train Epoch: 562 [40960/90000 (45%)]	Loss: 4.4247	Cost: 10.24s
Train Epoch: 562 [61440/90000 (68%)]	Loss: 4.1902	Cost: 6.19s
Train Epoch: 562 [81920/90000 (91%)]	Loss: 4.4275	Cost: 7.24s
Train Epoch: 562 	Average Loss: 4.4079
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9515

Learning rate: 9.922270849799896e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 563 [0/90000 (0%)]	Loss: 5.6828	Cost: 19.49s
Train Epoch: 563 [20480/90000 (23%)]	Loss: 4.4225	Cost: 6.73s
Train Epoch: 563 [40960/90000 (45%)]	Loss: 4.4043	Cost: 10.04s
Train Epoch: 563 [61440/90000 (68%)]	Loss: 4.2248	Cost: 8.84s
Train Epoch: 563 [81920/90000 (91%)]	Loss: 4.3824	Cost: 8.53s
Train Epoch: 563 	Average Loss: 4.3965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8749

Learning rate: 9.921994709650246e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 564 [0/90000 (0%)]	Loss: 5.7477	Cost: 23.52s
Train Epoch: 564 [20480/90000 (23%)]	Loss: 4.1663	Cost: 8.99s
Train Epoch: 564 [40960/90000 (45%)]	Loss: 4.2796	Cost: 8.96s
Train Epoch: 564 [61440/90000 (68%)]	Loss: 4.1754	Cost: 9.25s
Train Epoch: 564 [81920/90000 (91%)]	Loss: 4.3578	Cost: 8.89s
Train Epoch: 564 	Average Loss: 4.3346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7918

Saving model as e564_model.pt & e564_waveforms_supplementary.hdf5
Learning rate: 9.921718083719194e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 565 [0/90000 (0%)]	Loss: 5.9466	Cost: 23.68s
Train Epoch: 565 [20480/90000 (23%)]	Loss: 4.2091	Cost: 9.70s
Train Epoch: 565 [40960/90000 (45%)]	Loss: 4.2658	Cost: 6.28s
Train Epoch: 565 [61440/90000 (68%)]	Loss: 4.2544	Cost: 7.13s
Train Epoch: 565 [81920/90000 (91%)]	Loss: 4.3484	Cost: 6.66s
Train Epoch: 565 	Average Loss: 4.3298
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7851

Saving model as e565_model.pt & e565_waveforms_supplementary.hdf5
Learning rate: 9.921440972034041e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 566 [0/90000 (0%)]	Loss: 5.6815	Cost: 24.92s
Train Epoch: 566 [20480/90000 (23%)]	Loss: 4.1809	Cost: 9.90s
Train Epoch: 566 [40960/90000 (45%)]	Loss: 4.2522	Cost: 13.93s
Train Epoch: 566 [61440/90000 (68%)]	Loss: 3.9644	Cost: 12.76s
Train Epoch: 566 [81920/90000 (91%)]	Loss: 4.2448	Cost: 12.43s
Train Epoch: 566 	Average Loss: 4.2810
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7072

Saving model as e566_model.pt & e566_waveforms_supplementary.hdf5
Learning rate: 9.921163374622138e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 567 [0/90000 (0%)]	Loss: 5.7853	Cost: 33.18s
Train Epoch: 567 [20480/90000 (23%)]	Loss: 4.1072	Cost: 12.83s
Train Epoch: 567 [40960/90000 (45%)]	Loss: 4.2679	Cost: 12.93s
Train Epoch: 567 [61440/90000 (68%)]	Loss: 4.1241	Cost: 12.26s
Train Epoch: 567 [81920/90000 (91%)]	Loss: 4.2917	Cost: 10.23s
Train Epoch: 567 	Average Loss: 4.2699
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9447

Learning rate: 9.920885291510881e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 568 [0/90000 (0%)]	Loss: 6.0136	Cost: 25.33s
Train Epoch: 568 [20480/90000 (23%)]	Loss: 4.2590	Cost: 12.52s
Train Epoch: 568 [40960/90000 (45%)]	Loss: 4.2222	Cost: 12.28s
Train Epoch: 568 [61440/90000 (68%)]	Loss: 4.2838	Cost: 10.37s
Train Epoch: 568 [81920/90000 (91%)]	Loss: 4.2434	Cost: 8.04s
Train Epoch: 568 	Average Loss: 4.3476
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7673

Learning rate: 9.920606722727717e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 569 [0/90000 (0%)]	Loss: 5.8848	Cost: 26.64s
Train Epoch: 569 [20480/90000 (23%)]	Loss: 4.2590	Cost: 11.55s
Train Epoch: 569 [40960/90000 (45%)]	Loss: 4.1494	Cost: 6.47s
Train Epoch: 569 [61440/90000 (68%)]	Loss: 4.1783	Cost: 6.20s
Train Epoch: 569 [81920/90000 (91%)]	Loss: 4.2199	Cost: 7.76s
Train Epoch: 569 	Average Loss: 4.2710
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8165

Learning rate: 9.920327668300141e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 570 [0/90000 (0%)]	Loss: 5.7699	Cost: 24.26s
Train Epoch: 570 [20480/90000 (23%)]	Loss: 4.1736	Cost: 11.09s
Train Epoch: 570 [40960/90000 (45%)]	Loss: 4.3600	Cost: 7.07s
Train Epoch: 570 [61440/90000 (68%)]	Loss: 4.1118	Cost: 6.63s
Train Epoch: 570 [81920/90000 (91%)]	Loss: 4.2891	Cost: 9.37s
Train Epoch: 570 	Average Loss: 4.2622
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8326

Learning rate: 9.920048128255691e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 571 [0/90000 (0%)]	Loss: 5.8289	Cost: 22.50s
Train Epoch: 571 [20480/90000 (23%)]	Loss: 4.2551	Cost: 9.80s
Train Epoch: 571 [40960/90000 (45%)]	Loss: 4.2463	Cost: 6.65s
Train Epoch: 571 [61440/90000 (68%)]	Loss: 4.2290	Cost: 8.13s
Train Epoch: 571 [81920/90000 (91%)]	Loss: 4.2279	Cost: 9.21s
Train Epoch: 571 	Average Loss: 4.2626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7371

Learning rate: 9.91976810262196e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 572 [0/90000 (0%)]	Loss: 5.4875	Cost: 21.39s
Train Epoch: 572 [20480/90000 (23%)]	Loss: 4.1703	Cost: 7.95s
Train Epoch: 572 [40960/90000 (45%)]	Loss: 4.2174	Cost: 10.71s
Train Epoch: 572 [61440/90000 (68%)]	Loss: 4.1916	Cost: 8.79s
Train Epoch: 572 [81920/90000 (91%)]	Loss: 4.2006	Cost: 8.50s
Train Epoch: 572 	Average Loss: 4.2279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7600

Learning rate: 9.919487591426583e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 573 [0/90000 (0%)]	Loss: 5.7881	Cost: 23.89s
Train Epoch: 573 [20480/90000 (23%)]	Loss: 4.0899	Cost: 9.00s
Train Epoch: 573 [40960/90000 (45%)]	Loss: 4.2578	Cost: 8.82s
Train Epoch: 573 [61440/90000 (68%)]	Loss: 3.9868	Cost: 7.26s
Train Epoch: 573 [81920/90000 (91%)]	Loss: 4.1868	Cost: 6.23s
Train Epoch: 573 	Average Loss: 4.1916
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7148

Learning rate: 9.919206594697245e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 574 [0/90000 (0%)]	Loss: 5.7005	Cost: 23.28s
Train Epoch: 574 [20480/90000 (23%)]	Loss: 4.1116	Cost: 7.73s
Train Epoch: 574 [40960/90000 (45%)]	Loss: 4.1384	Cost: 10.10s
Train Epoch: 574 [61440/90000 (68%)]	Loss: 4.1516	Cost: 11.89s
Train Epoch: 574 [81920/90000 (91%)]	Loss: 4.3471	Cost: 12.38s
Train Epoch: 574 	Average Loss: 4.3228
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7931

Learning rate: 9.918925112461682e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 575 [0/90000 (0%)]	Loss: 5.6393	Cost: 26.16s
Train Epoch: 575 [20480/90000 (23%)]	Loss: 4.1479	Cost: 12.90s
Train Epoch: 575 [40960/90000 (45%)]	Loss: 4.0360	Cost: 15.69s
Train Epoch: 575 [61440/90000 (68%)]	Loss: 3.9767	Cost: 12.86s
Train Epoch: 575 [81920/90000 (91%)]	Loss: 4.2314	Cost: 12.36s
Train Epoch: 575 	Average Loss: 4.1806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7689

Learning rate: 9.918643144747673e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 576 [0/90000 (0%)]	Loss: 5.5085	Cost: 23.85s
Train Epoch: 576 [20480/90000 (23%)]	Loss: 4.0977	Cost: 15.02s
Train Epoch: 576 [40960/90000 (45%)]	Loss: 4.0581	Cost: 13.69s
Train Epoch: 576 [61440/90000 (68%)]	Loss: 4.1974	Cost: 12.58s
Train Epoch: 576 [81920/90000 (91%)]	Loss: 4.2405	Cost: 7.11s
Train Epoch: 576 	Average Loss: 4.1944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7394

Learning rate: 9.918360691583047e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 577 [0/90000 (0%)]	Loss: 5.6018	Cost: 31.05s
Train Epoch: 577 [20480/90000 (23%)]	Loss: 4.1315	Cost: 12.54s
Train Epoch: 577 [40960/90000 (45%)]	Loss: 4.1692	Cost: 10.96s
Train Epoch: 577 [61440/90000 (68%)]	Loss: 4.0650	Cost: 6.24s
Train Epoch: 577 [81920/90000 (91%)]	Loss: 4.1164	Cost: 7.29s
Train Epoch: 577 	Average Loss: 4.1693
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6889

Saving model as e577_model.pt & e577_waveforms_supplementary.hdf5
Learning rate: 9.918077752995681e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 578 [0/90000 (0%)]	Loss: 5.6087	Cost: 26.74s
Train Epoch: 578 [20480/90000 (23%)]	Loss: 3.8939	Cost: 9.23s
Train Epoch: 578 [40960/90000 (45%)]	Loss: 4.0147	Cost: 6.46s
Train Epoch: 578 [61440/90000 (68%)]	Loss: 3.9532	Cost: 6.35s
Train Epoch: 578 [81920/90000 (91%)]	Loss: 4.0165	Cost: 8.87s
Train Epoch: 578 	Average Loss: 4.0916
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6429

Saving model as e578_model.pt & e578_waveforms_supplementary.hdf5
Learning rate: 9.917794329013504e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 579 [0/90000 (0%)]	Loss: 5.5958	Cost: 23.49s
Train Epoch: 579 [20480/90000 (23%)]	Loss: 3.9688	Cost: 7.30s
Train Epoch: 579 [40960/90000 (45%)]	Loss: 4.0095	Cost: 9.27s
Train Epoch: 579 [61440/90000 (68%)]	Loss: 4.0097	Cost: 8.94s
Train Epoch: 579 [81920/90000 (91%)]	Loss: 4.0355	Cost: 8.45s
Train Epoch: 579 	Average Loss: 4.0865
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6953

Learning rate: 9.917510419664483e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 580 [0/90000 (0%)]	Loss: 5.7832	Cost: 22.62s
Train Epoch: 580 [20480/90000 (23%)]	Loss: 4.0314	Cost: 9.43s
Train Epoch: 580 [40960/90000 (45%)]	Loss: 4.0459	Cost: 9.57s
Train Epoch: 580 [61440/90000 (68%)]	Loss: 3.8479	Cost: 9.50s
Train Epoch: 580 [81920/90000 (91%)]	Loss: 4.0894	Cost: 6.69s
Train Epoch: 580 	Average Loss: 4.0955
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6642

Learning rate: 9.91722602497664e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 581 [0/90000 (0%)]	Loss: 5.7382	Cost: 18.83s
Train Epoch: 581 [20480/90000 (23%)]	Loss: 4.1218	Cost: 7.20s
Train Epoch: 581 [40960/90000 (45%)]	Loss: 4.1384	Cost: 16.46s
Train Epoch: 581 [61440/90000 (68%)]	Loss: 3.9163	Cost: 12.95s
Train Epoch: 581 [81920/90000 (91%)]	Loss: 4.1682	Cost: 13.32s
Train Epoch: 581 	Average Loss: 4.1177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6441

Learning rate: 9.916941144978047e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 582 [0/90000 (0%)]	Loss: 5.7477	Cost: 24.70s
Train Epoch: 582 [20480/90000 (23%)]	Loss: 4.0391	Cost: 12.95s
Train Epoch: 582 [40960/90000 (45%)]	Loss: 3.8919	Cost: 14.27s
Train Epoch: 582 [61440/90000 (68%)]	Loss: 3.9025	Cost: 12.25s
Train Epoch: 582 [81920/90000 (91%)]	Loss: 3.9791	Cost: 12.17s
Train Epoch: 582 	Average Loss: 4.0677
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7597

Learning rate: 9.916655779696818e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 583 [0/90000 (0%)]	Loss: 5.9295	Cost: 29.75s
Train Epoch: 583 [20480/90000 (23%)]	Loss: 4.0439	Cost: 12.14s
Train Epoch: 583 [40960/90000 (45%)]	Loss: 3.8427	Cost: 12.10s
Train Epoch: 583 [61440/90000 (68%)]	Loss: 3.9147	Cost: 11.89s
Train Epoch: 583 [81920/90000 (91%)]	Loss: 4.0445	Cost: 6.17s
Train Epoch: 583 	Average Loss: 4.0949
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6819

Learning rate: 9.916369929161117e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 584 [0/90000 (0%)]	Loss: 5.8860	Cost: 26.24s
Train Epoch: 584 [20480/90000 (23%)]	Loss: 3.8617	Cost: 12.67s
Train Epoch: 584 [40960/90000 (45%)]	Loss: 3.9825	Cost: 12.32s
Train Epoch: 584 [61440/90000 (68%)]	Loss: 3.9240	Cost: 9.73s
Train Epoch: 584 [81920/90000 (91%)]	Loss: 4.0909	Cost: 6.30s
Train Epoch: 584 	Average Loss: 4.0468
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5875

Saving model as e584_model.pt & e584_waveforms_supplementary.hdf5
Learning rate: 9.916083593399158e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 585 [0/90000 (0%)]	Loss: 5.5791	Cost: 34.28s
Train Epoch: 585 [20480/90000 (23%)]	Loss: 3.8799	Cost: 10.68s
Train Epoch: 585 [40960/90000 (45%)]	Loss: 3.7841	Cost: 9.57s
Train Epoch: 585 [61440/90000 (68%)]	Loss: 3.8587	Cost: 8.21s
Train Epoch: 585 [81920/90000 (91%)]	Loss: 3.9860	Cost: 8.67s
Train Epoch: 585 	Average Loss: 3.9850
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5915

Learning rate: 9.9157967724392e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 586 [0/90000 (0%)]	Loss: 5.6627	Cost: 19.44s
Train Epoch: 586 [20480/90000 (23%)]	Loss: 3.8857	Cost: 8.54s
Train Epoch: 586 [40960/90000 (45%)]	Loss: 4.0530	Cost: 10.35s
Train Epoch: 586 [61440/90000 (68%)]	Loss: 3.8193	Cost: 10.01s
Train Epoch: 586 [81920/90000 (91%)]	Loss: 3.9297	Cost: 8.86s
Train Epoch: 586 	Average Loss: 3.9987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6158

Learning rate: 9.915509466309551e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 587 [0/90000 (0%)]	Loss: 5.6407	Cost: 25.04s
Train Epoch: 587 [20480/90000 (23%)]	Loss: 3.9103	Cost: 8.78s
Train Epoch: 587 [40960/90000 (45%)]	Loss: 3.8611	Cost: 7.10s
Train Epoch: 587 [61440/90000 (68%)]	Loss: 3.8529	Cost: 6.23s
Train Epoch: 587 [81920/90000 (91%)]	Loss: 3.9216	Cost: 6.74s
Train Epoch: 587 	Average Loss: 3.9767
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6707

Learning rate: 9.915221675038568e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 588 [0/90000 (0%)]	Loss: 5.5885	Cost: 20.62s
Train Epoch: 588 [20480/90000 (23%)]	Loss: 4.2074	Cost: 7.01s
Train Epoch: 588 [40960/90000 (45%)]	Loss: 3.9888	Cost: 9.51s
Train Epoch: 588 [61440/90000 (68%)]	Loss: 3.7015	Cost: 11.73s
Train Epoch: 588 [81920/90000 (91%)]	Loss: 3.9789	Cost: 12.40s
Train Epoch: 588 	Average Loss: 3.9965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6541

Learning rate: 9.914933398654654e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 589 [0/90000 (0%)]	Loss: 5.5797	Cost: 29.32s
Train Epoch: 589 [20480/90000 (23%)]	Loss: 3.9399	Cost: 9.59s
Train Epoch: 589 [40960/90000 (45%)]	Loss: 3.8437	Cost: 12.48s
Train Epoch: 589 [61440/90000 (68%)]	Loss: 3.8115	Cost: 12.48s
Train Epoch: 589 [81920/90000 (91%)]	Loss: 3.9182	Cost: 12.54s
Train Epoch: 589 	Average Loss: 3.9486
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5509

Saving model as e589_model.pt & e589_waveforms_supplementary.hdf5
Learning rate: 9.914644637186261e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 590 [0/90000 (0%)]	Loss: 5.2720	Cost: 33.54s
Train Epoch: 590 [20480/90000 (23%)]	Loss: 3.8827	Cost: 12.94s
Train Epoch: 590 [40960/90000 (45%)]	Loss: 3.9256	Cost: 13.45s
Train Epoch: 590 [61440/90000 (68%)]	Loss: 3.7103	Cost: 12.14s
Train Epoch: 590 [81920/90000 (91%)]	Loss: 3.8387	Cost: 8.38s
Train Epoch: 590 	Average Loss: 3.9180
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4551

Saving model as e590_model.pt & e590_waveforms_supplementary.hdf5
Learning rate: 9.914355390661888e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 591 [0/90000 (0%)]	Loss: 5.4329	Cost: 39.52s
Train Epoch: 591 [20480/90000 (23%)]	Loss: 3.8637	Cost: 11.93s
Train Epoch: 591 [40960/90000 (45%)]	Loss: 3.7410	Cost: 8.36s
Train Epoch: 591 [61440/90000 (68%)]	Loss: 3.8674	Cost: 6.30s
Train Epoch: 591 [81920/90000 (91%)]	Loss: 3.9535	Cost: 7.42s
Train Epoch: 591 	Average Loss: 3.8971
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5650

Learning rate: 9.914065659110084e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 592 [0/90000 (0%)]	Loss: 5.3291	Cost: 27.10s
Train Epoch: 592 [20480/90000 (23%)]	Loss: 3.7407	Cost: 12.68s
Train Epoch: 592 [40960/90000 (45%)]	Loss: 3.8965	Cost: 6.45s
Train Epoch: 592 [61440/90000 (68%)]	Loss: 3.6091	Cost: 6.25s
Train Epoch: 592 [81920/90000 (91%)]	Loss: 3.9847	Cost: 8.11s
Train Epoch: 592 	Average Loss: 3.9035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6920

Learning rate: 9.913775442559442e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 593 [0/90000 (0%)]	Loss: 5.4827	Cost: 19.80s
Train Epoch: 593 [20480/90000 (23%)]	Loss: 3.8966	Cost: 6.22s
Train Epoch: 593 [40960/90000 (45%)]	Loss: 3.8029	Cost: 10.27s
Train Epoch: 593 [61440/90000 (68%)]	Loss: 3.7648	Cost: 8.56s
Train Epoch: 593 [81920/90000 (91%)]	Loss: 3.7041	Cost: 8.39s
Train Epoch: 593 	Average Loss: 3.9108
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5387

Learning rate: 9.913484741038609e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 594 [0/90000 (0%)]	Loss: 5.3264	Cost: 20.72s
Train Epoch: 594 [20480/90000 (23%)]	Loss: 3.7139	Cost: 8.88s
Train Epoch: 594 [40960/90000 (45%)]	Loss: 3.6828	Cost: 9.19s
Train Epoch: 594 [61440/90000 (68%)]	Loss: 3.6879	Cost: 6.18s
Train Epoch: 594 [81920/90000 (91%)]	Loss: 3.9266	Cost: 6.45s
Train Epoch: 594 	Average Loss: 3.8864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5200

Learning rate: 9.913193554576272e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 595 [0/90000 (0%)]	Loss: 5.8377	Cost: 26.10s
Train Epoch: 595 [20480/90000 (23%)]	Loss: 3.7198	Cost: 10.65s
Train Epoch: 595 [40960/90000 (45%)]	Loss: 3.5900	Cost: 11.62s
Train Epoch: 595 [61440/90000 (68%)]	Loss: 3.6057	Cost: 12.82s
Train Epoch: 595 [81920/90000 (91%)]	Loss: 3.7884	Cost: 12.20s
Train Epoch: 595 	Average Loss: 3.8732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4753

Learning rate: 9.912901883201172e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 596 [0/90000 (0%)]	Loss: 5.1693	Cost: 34.41s
Train Epoch: 596 [20480/90000 (23%)]	Loss: 3.6736	Cost: 14.39s
Train Epoch: 596 [40960/90000 (45%)]	Loss: 3.7016	Cost: 13.04s
Train Epoch: 596 [61440/90000 (68%)]	Loss: 3.5796	Cost: 12.30s
Train Epoch: 596 [81920/90000 (91%)]	Loss: 3.7635	Cost: 12.12s
Train Epoch: 596 	Average Loss: 3.8085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5097

Learning rate: 9.912609726942096e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 597 [0/90000 (0%)]	Loss: 5.8086	Cost: 24.67s
Train Epoch: 597 [20480/90000 (23%)]	Loss: 3.7756	Cost: 10.65s
Train Epoch: 597 [40960/90000 (45%)]	Loss: 3.8214	Cost: 13.04s
Train Epoch: 597 [61440/90000 (68%)]	Loss: 3.7664	Cost: 12.29s
Train Epoch: 597 [81920/90000 (91%)]	Loss: 3.6440	Cost: 8.79s
Train Epoch: 597 	Average Loss: 3.8045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4417

Saving model as e597_model.pt & e597_waveforms_supplementary.hdf5
Learning rate: 9.912317085827877e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 598 [0/90000 (0%)]	Loss: 5.4137	Cost: 22.82s
Train Epoch: 598 [20480/90000 (23%)]	Loss: 3.6908	Cost: 9.20s
Train Epoch: 598 [40960/90000 (45%)]	Loss: 3.7817	Cost: 10.08s
Train Epoch: 598 [61440/90000 (68%)]	Loss: 3.5633	Cost: 6.47s
Train Epoch: 598 [81920/90000 (91%)]	Loss: 3.6366	Cost: 7.17s
Train Epoch: 598 	Average Loss: 3.8211
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4498

Learning rate: 9.9120239598874e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 599 [0/90000 (0%)]	Loss: 5.4738	Cost: 21.22s
Train Epoch: 599 [20480/90000 (23%)]	Loss: 3.7521	Cost: 6.61s
Train Epoch: 599 [40960/90000 (45%)]	Loss: 3.6600	Cost: 9.36s
Train Epoch: 599 [61440/90000 (68%)]	Loss: 3.6111	Cost: 9.32s
Train Epoch: 599 [81920/90000 (91%)]	Loss: 3.6925	Cost: 8.99s
Train Epoch: 599 	Average Loss: 3.7690
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5059

Learning rate: 9.911730349149594e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 600 [0/90000 (0%)]	Loss: 5.4596	Cost: 27.55s
Train Epoch: 600 [20480/90000 (23%)]	Loss: 3.6747	Cost: 8.87s
Train Epoch: 600 [40960/90000 (45%)]	Loss: 3.7050	Cost: 9.26s
Train Epoch: 600 [61440/90000 (68%)]	Loss: 3.6055	Cost: 7.68s
Train Epoch: 600 [81920/90000 (91%)]	Loss: 3.7710	Cost: 6.15s
Train Epoch: 600 	Average Loss: 3.7379
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4825

Learning rate: 9.911436253643436e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 601 [0/90000 (0%)]	Loss: 5.1872	Cost: 32.01s
Train Epoch: 601 [20480/90000 (23%)]	Loss: 3.8199	Cost: 6.72s
Train Epoch: 601 [40960/90000 (45%)]	Loss: 3.5212	Cost: 10.31s
Train Epoch: 601 [61440/90000 (68%)]	Loss: 3.6489	Cost: 10.65s
Train Epoch: 601 [81920/90000 (91%)]	Loss: 3.8316	Cost: 12.38s
Train Epoch: 601 	Average Loss: 3.7460
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4683

Learning rate: 9.911141673397953e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 602 [0/90000 (0%)]	Loss: 5.1545	Cost: 21.09s
Train Epoch: 602 [20480/90000 (23%)]	Loss: 3.5866	Cost: 11.46s
Train Epoch: 602 [40960/90000 (45%)]	Loss: 3.5788	Cost: 14.62s
Train Epoch: 602 [61440/90000 (68%)]	Loss: 3.4199	Cost: 12.58s
Train Epoch: 602 [81920/90000 (91%)]	Loss: 3.6012	Cost: 12.59s
Train Epoch: 602 	Average Loss: 3.6801
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4157

Saving model as e602_model.pt & e602_waveforms_supplementary.hdf5
Learning rate: 9.91084660844222e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 603 [0/90000 (0%)]	Loss: 5.5344	Cost: 22.88s
Train Epoch: 603 [20480/90000 (23%)]	Loss: 3.5249	Cost: 13.14s
Train Epoch: 603 [40960/90000 (45%)]	Loss: 3.6787	Cost: 12.83s
Train Epoch: 603 [61440/90000 (68%)]	Loss: 3.6621	Cost: 11.84s
Train Epoch: 603 [81920/90000 (91%)]	Loss: 3.6391	Cost: 6.58s
Train Epoch: 603 	Average Loss: 3.7166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4248

Learning rate: 9.910551058805357e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 604 [0/90000 (0%)]	Loss: 5.2336	Cost: 24.15s
Train Epoch: 604 [20480/90000 (23%)]	Loss: 3.6495	Cost: 10.93s
Train Epoch: 604 [40960/90000 (45%)]	Loss: 3.4770	Cost: 10.52s
Train Epoch: 604 [61440/90000 (68%)]	Loss: 3.5064	Cost: 6.15s
Train Epoch: 604 [81920/90000 (91%)]	Loss: 3.6285	Cost: 6.81s
Train Epoch: 604 	Average Loss: 3.6973
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4340

Learning rate: 9.910255024516536e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 605 [0/90000 (0%)]	Loss: 5.2072	Cost: 27.25s
Train Epoch: 605 [20480/90000 (23%)]	Loss: 3.7445	Cost: 12.49s
Train Epoch: 605 [40960/90000 (45%)]	Loss: 3.7057	Cost: 8.76s
Train Epoch: 605 [61440/90000 (68%)]	Loss: 3.5324	Cost: 7.00s
Train Epoch: 605 [81920/90000 (91%)]	Loss: 3.5612	Cost: 8.55s
Train Epoch: 605 	Average Loss: 3.6773
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3863

Saving model as e605_model.pt & e605_waveforms_supplementary.hdf5
Learning rate: 9.909958505604974e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 606 [0/90000 (0%)]	Loss: 5.3425	Cost: 38.39s
Train Epoch: 606 [20480/90000 (23%)]	Loss: 3.6032	Cost: 10.23s
Train Epoch: 606 [40960/90000 (45%)]	Loss: 3.6112	Cost: 10.18s
Train Epoch: 606 [61440/90000 (68%)]	Loss: 3.5121	Cost: 8.79s
Train Epoch: 606 [81920/90000 (91%)]	Loss: 3.7551	Cost: 8.81s
Train Epoch: 606 	Average Loss: 3.6919
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3426

Saving model as e606_model.pt & e606_waveforms_supplementary.hdf5
Learning rate: 9.909661502099934e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 607 [0/90000 (0%)]	Loss: 5.2132	Cost: 21.41s
Train Epoch: 607 [20480/90000 (23%)]	Loss: 3.4151	Cost: 9.18s
Train Epoch: 607 [40960/90000 (45%)]	Loss: 3.5852	Cost: 6.46s
Train Epoch: 607 [61440/90000 (68%)]	Loss: 3.3898	Cost: 7.84s
Train Epoch: 607 [81920/90000 (91%)]	Loss: 3.5527	Cost: 14.13s
Train Epoch: 607 	Average Loss: 3.6597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4187

Learning rate: 9.90936401403073e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 608 [0/90000 (0%)]	Loss: 5.3075	Cost: 21.43s
Train Epoch: 608 [20480/90000 (23%)]	Loss: 3.4468	Cost: 8.61s
Train Epoch: 608 [40960/90000 (45%)]	Loss: 3.4021	Cost: 12.99s
Train Epoch: 608 [61440/90000 (68%)]	Loss: 3.5022	Cost: 12.51s
Train Epoch: 608 [81920/90000 (91%)]	Loss: 3.5409	Cost: 12.26s
Train Epoch: 608 	Average Loss: 3.6483
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3958

Learning rate: 9.909066041426725e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 609 [0/90000 (0%)]	Loss: 5.4632	Cost: 28.92s
Train Epoch: 609 [20480/90000 (23%)]	Loss: 3.4905	Cost: 15.27s
Train Epoch: 609 [40960/90000 (45%)]	Loss: 3.4005	Cost: 13.38s
Train Epoch: 609 [61440/90000 (68%)]	Loss: 3.4028	Cost: 12.19s
Train Epoch: 609 [81920/90000 (91%)]	Loss: 3.6510	Cost: 8.24s
Train Epoch: 609 	Average Loss: 3.6218
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4918

Learning rate: 9.908767584317324e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 610 [0/90000 (0%)]	Loss: 5.4543	Cost: 43.52s
Train Epoch: 610 [20480/90000 (23%)]	Loss: 3.5247	Cost: 12.32s
Train Epoch: 610 [40960/90000 (45%)]	Loss: 3.5771	Cost: 10.98s
Train Epoch: 610 [61440/90000 (68%)]	Loss: 3.5105	Cost: 6.11s
Train Epoch: 610 [81920/90000 (91%)]	Loss: 3.6210	Cost: 6.86s
Train Epoch: 610 	Average Loss: 3.6664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3917

Learning rate: 9.908468642731985e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 611 [0/90000 (0%)]	Loss: 5.1175	Cost: 31.40s
Train Epoch: 611 [20480/90000 (23%)]	Loss: 3.5768	Cost: 6.38s
Train Epoch: 611 [40960/90000 (45%)]	Loss: 3.6324	Cost: 8.16s
Train Epoch: 611 [61440/90000 (68%)]	Loss: 3.5498	Cost: 8.49s
Train Epoch: 611 [81920/90000 (91%)]	Loss: 3.6082	Cost: 8.54s
Train Epoch: 611 	Average Loss: 3.6397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4590

Learning rate: 9.908169216700214e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 612 [0/90000 (0%)]	Loss: 5.4834	Cost: 18.27s
Train Epoch: 612 [20480/90000 (23%)]	Loss: 3.5247	Cost: 6.62s
Train Epoch: 612 [40960/90000 (45%)]	Loss: 3.6282	Cost: 10.71s
Train Epoch: 612 [61440/90000 (68%)]	Loss: 3.5279	Cost: 8.82s
Train Epoch: 612 [81920/90000 (91%)]	Loss: 3.7375	Cost: 9.62s
Train Epoch: 612 	Average Loss: 3.6650
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3514

Learning rate: 9.907869306251562e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 613 [0/90000 (0%)]	Loss: 5.3146	Cost: 18.60s
Train Epoch: 613 [20480/90000 (23%)]	Loss: 3.5405	Cost: 9.52s
Train Epoch: 613 [40960/90000 (45%)]	Loss: 3.4736	Cost: 7.42s
Train Epoch: 613 [61440/90000 (68%)]	Loss: 3.2988	Cost: 9.92s
Train Epoch: 613 [81920/90000 (91%)]	Loss: 3.5092	Cost: 10.74s
Train Epoch: 613 	Average Loss: 3.5788
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3234

Saving model as e613_model.pt & e613_waveforms_supplementary.hdf5
Learning rate: 9.907568911415629e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 614 [0/90000 (0%)]	Loss: 5.0256	Cost: 23.63s
Train Epoch: 614 [20480/90000 (23%)]	Loss: 3.4722	Cost: 11.09s
Train Epoch: 614 [40960/90000 (45%)]	Loss: 3.5931	Cost: 14.52s
Train Epoch: 614 [61440/90000 (68%)]	Loss: 3.4082	Cost: 12.36s
Train Epoch: 614 [81920/90000 (91%)]	Loss: 3.6582	Cost: 12.07s
Train Epoch: 614 	Average Loss: 3.5756
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3521

Learning rate: 9.907268032222063e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 615 [0/90000 (0%)]	Loss: 5.3062	Cost: 34.85s
Train Epoch: 615 [20480/90000 (23%)]	Loss: 3.4799	Cost: 12.52s
Train Epoch: 615 [40960/90000 (45%)]	Loss: 3.4061	Cost: 12.30s
Train Epoch: 615 [61440/90000 (68%)]	Loss: 3.4358	Cost: 10.66s
Train Epoch: 615 [81920/90000 (91%)]	Loss: 3.4120	Cost: 6.24s
Train Epoch: 615 	Average Loss: 3.5282
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2249

Saving model as e615_model.pt & e615_waveforms_supplementary.hdf5
Learning rate: 9.906966668700558e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 616 [0/90000 (0%)]	Loss: 5.1496	Cost: 29.13s
Train Epoch: 616 [20480/90000 (23%)]	Loss: 3.3056	Cost: 7.99s
Train Epoch: 616 [40960/90000 (45%)]	Loss: 3.4627	Cost: 6.79s
Train Epoch: 616 [61440/90000 (68%)]	Loss: 3.3687	Cost: 7.23s
Train Epoch: 616 [81920/90000 (91%)]	Loss: 3.4701	Cost: 9.05s
Train Epoch: 616 	Average Loss: 3.5037
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2460

Learning rate: 9.90666482088086e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 617 [0/90000 (0%)]	Loss: 5.1550	Cost: 23.40s
Train Epoch: 617 [20480/90000 (23%)]	Loss: 3.5752	Cost: 9.06s
Train Epoch: 617 [40960/90000 (45%)]	Loss: 3.5267	Cost: 10.76s
Train Epoch: 617 [61440/90000 (68%)]	Loss: 3.2707	Cost: 9.21s
Train Epoch: 617 [81920/90000 (91%)]	Loss: 3.4180	Cost: 8.87s
Train Epoch: 617 	Average Loss: 3.5087
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2117

Saving model as e617_model.pt & e617_waveforms_supplementary.hdf5
Learning rate: 9.906362488792757e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 618 [0/90000 (0%)]	Loss: 5.3112	Cost: 31.94s
Train Epoch: 618 [20480/90000 (23%)]	Loss: 3.3263	Cost: 9.47s
Train Epoch: 618 [40960/90000 (45%)]	Loss: 3.2283	Cost: 7.67s
Train Epoch: 618 [61440/90000 (68%)]	Loss: 3.2654	Cost: 6.82s
Train Epoch: 618 [81920/90000 (91%)]	Loss: 3.4712	Cost: 13.59s
Train Epoch: 618 	Average Loss: 3.4529
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2684

Learning rate: 9.906059672466091e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 619 [0/90000 (0%)]	Loss: 5.1655	Cost: 21.60s
Train Epoch: 619 [20480/90000 (23%)]	Loss: 3.3562	Cost: 7.92s
Train Epoch: 619 [40960/90000 (45%)]	Loss: 3.3465	Cost: 13.66s
Train Epoch: 619 [61440/90000 (68%)]	Loss: 3.1100	Cost: 12.77s
Train Epoch: 619 [81920/90000 (91%)]	Loss: 3.3224	Cost: 12.27s
Train Epoch: 619 	Average Loss: 3.4426
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2994

Learning rate: 9.905756371930748e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 620 [0/90000 (0%)]	Loss: 5.3199	Cost: 24.69s
Train Epoch: 620 [20480/90000 (23%)]	Loss: 3.3766	Cost: 14.36s
Train Epoch: 620 [40960/90000 (45%)]	Loss: 3.4089	Cost: 12.30s
Train Epoch: 620 [61440/90000 (68%)]	Loss: 3.4165	Cost: 12.21s
Train Epoch: 620 [81920/90000 (91%)]	Loss: 3.5274	Cost: 10.97s
Train Epoch: 620 	Average Loss: 3.5170
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3700

Learning rate: 9.905452587216662e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 621 [0/90000 (0%)]	Loss: 5.2030	Cost: 25.75s
Train Epoch: 621 [20480/90000 (23%)]	Loss: 3.4198	Cost: 12.51s
Train Epoch: 621 [40960/90000 (45%)]	Loss: 3.4249	Cost: 12.59s
Train Epoch: 621 [61440/90000 (68%)]	Loss: 3.2978	Cost: 6.85s
Train Epoch: 621 [81920/90000 (91%)]	Loss: 3.5955	Cost: 6.27s
Train Epoch: 621 	Average Loss: 3.4958
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2687

Learning rate: 9.905148318353815e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 622 [0/90000 (0%)]	Loss: 5.0819	Cost: 33.46s
Train Epoch: 622 [20480/90000 (23%)]	Loss: 3.3938	Cost: 11.58s
Train Epoch: 622 [40960/90000 (45%)]	Loss: 3.2728	Cost: 9.47s
Train Epoch: 622 [61440/90000 (68%)]	Loss: 3.3464	Cost: 7.63s
Train Epoch: 622 [81920/90000 (91%)]	Loss: 3.2115	Cost: 8.62s
Train Epoch: 622 	Average Loss: 3.4253
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2092

Saving model as e622_model.pt & e622_waveforms_supplementary.hdf5
Learning rate: 9.904843565372238e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 623 [0/90000 (0%)]	Loss: 5.0564	Cost: 22.38s
Train Epoch: 623 [20480/90000 (23%)]	Loss: 3.3468	Cost: 10.18s
Train Epoch: 623 [40960/90000 (45%)]	Loss: 3.1710	Cost: 11.98s
Train Epoch: 623 [61440/90000 (68%)]	Loss: 3.2906	Cost: 8.84s
Train Epoch: 623 [81920/90000 (91%)]	Loss: 3.3508	Cost: 8.73s
Train Epoch: 623 	Average Loss: 3.3703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2182

Learning rate: 9.904538328302008e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 624 [0/90000 (0%)]	Loss: 4.9296	Cost: 23.97s
Train Epoch: 624 [20480/90000 (23%)]	Loss: 3.2571	Cost: 9.02s
Train Epoch: 624 [40960/90000 (45%)]	Loss: 3.3673	Cost: 7.96s
Train Epoch: 624 [61440/90000 (68%)]	Loss: 3.2800	Cost: 7.18s
Train Epoch: 624 [81920/90000 (91%)]	Loss: 3.3208	Cost: 6.32s
Train Epoch: 624 	Average Loss: 3.3776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1641

Saving model as e624_model.pt & e624_waveforms_supplementary.hdf5
Learning rate: 9.904232607173254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 625 [0/90000 (0%)]	Loss: 5.1187	Cost: 19.62s
Train Epoch: 625 [20480/90000 (23%)]	Loss: 3.2892	Cost: 9.43s
Train Epoch: 625 [40960/90000 (45%)]	Loss: 3.2991	Cost: 10.65s
Train Epoch: 625 [61440/90000 (68%)]	Loss: 3.1937	Cost: 12.29s
Train Epoch: 625 [81920/90000 (91%)]	Loss: 3.2893	Cost: 12.30s
Train Epoch: 625 	Average Loss: 3.3282
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1580

Saving model as e625_model.pt & e625_waveforms_supplementary.hdf5
Learning rate: 9.903926402016143e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 626 [0/90000 (0%)]	Loss: 4.8970	Cost: 23.79s
Train Epoch: 626 [20480/90000 (23%)]	Loss: 3.1021	Cost: 12.37s
Train Epoch: 626 [40960/90000 (45%)]	Loss: 3.3711	Cost: 12.18s
Train Epoch: 626 [61440/90000 (68%)]	Loss: 3.2177	Cost: 12.58s
Train Epoch: 626 [81920/90000 (91%)]	Loss: 3.3402	Cost: 12.30s
Train Epoch: 626 	Average Loss: 3.3832
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3469

Learning rate: 9.903619712860903e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 627 [0/90000 (0%)]	Loss: 5.1340	Cost: 40.99s
Train Epoch: 627 [20480/90000 (23%)]	Loss: 3.2973	Cost: 12.63s
Train Epoch: 627 [40960/90000 (45%)]	Loss: 3.3721	Cost: 12.17s
Train Epoch: 627 [61440/90000 (68%)]	Loss: 3.2316	Cost: 9.97s
Train Epoch: 627 [81920/90000 (91%)]	Loss: 3.3377	Cost: 6.08s
Train Epoch: 627 	Average Loss: 3.4067
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2215

Learning rate: 9.903312539737797e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 628 [0/90000 (0%)]	Loss: 5.0891	Cost: 40.14s
Train Epoch: 628 [20480/90000 (23%)]	Loss: 3.1451	Cost: 10.72s
Train Epoch: 628 [40960/90000 (45%)]	Loss: 3.1690	Cost: 9.25s
Train Epoch: 628 [61440/90000 (68%)]	Loss: 3.2375	Cost: 6.38s
Train Epoch: 628 [81920/90000 (91%)]	Loss: 3.1305	Cost: 7.34s
Train Epoch: 628 	Average Loss: 3.2943
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1762

Learning rate: 9.903004882677146e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 629 [0/90000 (0%)]	Loss: 5.2214	Cost: 32.14s
Train Epoch: 629 [20480/90000 (23%)]	Loss: 3.2565	Cost: 11.53s
Train Epoch: 629 [40960/90000 (45%)]	Loss: 3.2889	Cost: 6.53s
Train Epoch: 629 [61440/90000 (68%)]	Loss: 3.2381	Cost: 6.32s
Train Epoch: 629 [81920/90000 (91%)]	Loss: 3.3122	Cost: 8.51s
Train Epoch: 629 	Average Loss: 3.3738
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1901

Learning rate: 9.902696741709314e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 630 [0/90000 (0%)]	Loss: 5.2469	Cost: 20.46s
Train Epoch: 630 [20480/90000 (23%)]	Loss: 3.3120	Cost: 8.57s
Train Epoch: 630 [40960/90000 (45%)]	Loss: 3.2851	Cost: 9.04s
Train Epoch: 630 [61440/90000 (68%)]	Loss: 3.1546	Cost: 8.68s
Train Epoch: 630 [81920/90000 (91%)]	Loss: 3.2876	Cost: 8.58s
Train Epoch: 630 	Average Loss: 3.2931
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1681

Learning rate: 9.902388116864713e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 631 [0/90000 (0%)]	Loss: 5.0874	Cost: 20.19s
Train Epoch: 631 [20480/90000 (23%)]	Loss: 3.0773	Cost: 10.04s
Train Epoch: 631 [40960/90000 (45%)]	Loss: 3.0080	Cost: 9.17s
Train Epoch: 631 [61440/90000 (68%)]	Loss: 2.9949	Cost: 6.31s
Train Epoch: 631 [81920/90000 (91%)]	Loss: 3.3740	Cost: 7.02s
Train Epoch: 631 	Average Loss: 3.2774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1254

Saving model as e631_model.pt & e631_waveforms_supplementary.hdf5
Learning rate: 9.902079008173801e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 632 [0/90000 (0%)]	Loss: 5.2236	Cost: 21.87s
Train Epoch: 632 [20480/90000 (23%)]	Loss: 3.0777	Cost: 8.62s
Train Epoch: 632 [40960/90000 (45%)]	Loss: 3.1152	Cost: 9.24s
Train Epoch: 632 [61440/90000 (68%)]	Loss: 3.0553	Cost: 7.28s
Train Epoch: 632 [81920/90000 (91%)]	Loss: 3.1331	Cost: 15.84s
Train Epoch: 632 	Average Loss: 3.2421
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1535

Learning rate: 9.90176941566709e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 633 [0/90000 (0%)]	Loss: 5.0678	Cost: 24.43s
Train Epoch: 633 [20480/90000 (23%)]	Loss: 3.2158	Cost: 10.75s
Train Epoch: 633 [40960/90000 (45%)]	Loss: 3.1055	Cost: 15.95s
Train Epoch: 633 [61440/90000 (68%)]	Loss: 3.0378	Cost: 12.58s
Train Epoch: 633 [81920/90000 (91%)]	Loss: 3.1487	Cost: 12.45s
Train Epoch: 633 	Average Loss: 3.2095
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0507

Saving model as e633_model.pt & e633_waveforms_supplementary.hdf5
Learning rate: 9.90145933937513e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 634 [0/90000 (0%)]	Loss: 5.1157	Cost: 26.38s
Train Epoch: 634 [20480/90000 (23%)]	Loss: 3.1384	Cost: 13.09s
Train Epoch: 634 [40960/90000 (45%)]	Loss: 3.4166	Cost: 13.23s
Train Epoch: 634 [61440/90000 (68%)]	Loss: 3.0870	Cost: 12.22s
Train Epoch: 634 [81920/90000 (91%)]	Loss: 3.2510	Cost: 9.28s
Train Epoch: 634 	Average Loss: 3.2543
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1323

Learning rate: 9.901148779328529e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 635 [0/90000 (0%)]	Loss: 5.2097	Cost: 25.20s
Train Epoch: 635 [20480/90000 (23%)]	Loss: 3.1291	Cost: 12.59s
Train Epoch: 635 [40960/90000 (45%)]	Loss: 2.9964	Cost: 10.76s
Train Epoch: 635 [61440/90000 (68%)]	Loss: 3.0386	Cost: 6.28s
Train Epoch: 635 [81920/90000 (91%)]	Loss: 3.1813	Cost: 6.84s
Train Epoch: 635 	Average Loss: 3.1919
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0617

Learning rate: 9.900837735557936e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 636 [0/90000 (0%)]	Loss: 5.1337	Cost: 25.01s
Train Epoch: 636 [20480/90000 (23%)]	Loss: 3.0144	Cost: 9.52s
Train Epoch: 636 [40960/90000 (45%)]	Loss: 3.1584	Cost: 11.05s
Train Epoch: 636 [61440/90000 (68%)]	Loss: 3.2555	Cost: 11.16s
Train Epoch: 636 [81920/90000 (91%)]	Loss: 3.2662	Cost: 10.27s
Train Epoch: 636 	Average Loss: 3.2073
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1409

Learning rate: 9.90052620809405e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 637 [0/90000 (0%)]	Loss: 4.9548	Cost: 24.26s
Train Epoch: 637 [20480/90000 (23%)]	Loss: 3.0303	Cost: 9.89s
Train Epoch: 637 [40960/90000 (45%)]	Loss: 3.0381	Cost: 10.45s
Train Epoch: 637 [61440/90000 (68%)]	Loss: 3.0519	Cost: 8.83s
Train Epoch: 637 [81920/90000 (91%)]	Loss: 3.1599	Cost: 8.64s
Train Epoch: 637 	Average Loss: 3.1925
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0668

Learning rate: 9.900214196967617e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 638 [0/90000 (0%)]	Loss: 4.9302	Cost: 32.25s
Train Epoch: 638 [20480/90000 (23%)]	Loss: 2.9645	Cost: 8.94s
Train Epoch: 638 [40960/90000 (45%)]	Loss: 3.1040	Cost: 6.59s
Train Epoch: 638 [61440/90000 (68%)]	Loss: 2.9749	Cost: 6.84s
Train Epoch: 638 [81920/90000 (91%)]	Loss: 3.0715	Cost: 12.16s
Train Epoch: 638 	Average Loss: 3.1314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0784

Learning rate: 9.899901702209434e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 639 [0/90000 (0%)]	Loss: 4.8959	Cost: 21.32s
Train Epoch: 639 [20480/90000 (23%)]	Loss: 2.9963	Cost: 8.58s
Train Epoch: 639 [40960/90000 (45%)]	Loss: 3.0008	Cost: 13.24s
Train Epoch: 639 [61440/90000 (68%)]	Loss: 2.9764	Cost: 12.83s
Train Epoch: 639 [81920/90000 (91%)]	Loss: 3.2550	Cost: 12.52s
Train Epoch: 639 	Average Loss: 3.1423
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0755

Learning rate: 9.899588723850338e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 640 [0/90000 (0%)]	Loss: 4.8267	Cost: 28.69s
Train Epoch: 640 [20480/90000 (23%)]	Loss: 3.0386	Cost: 13.00s
Train Epoch: 640 [40960/90000 (45%)]	Loss: 3.1334	Cost: 13.61s
Train Epoch: 640 [61440/90000 (68%)]	Loss: 3.0033	Cost: 12.57s
Train Epoch: 640 [81920/90000 (91%)]	Loss: 3.1660	Cost: 10.23s
Train Epoch: 640 	Average Loss: 3.2205
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0374

Saving model as e640_model.pt & e640_waveforms_supplementary.hdf5
Learning rate: 9.899275261921224e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 641 [0/90000 (0%)]	Loss: 5.0004	Cost: 28.36s
Train Epoch: 641 [20480/90000 (23%)]	Loss: 2.9849	Cost: 13.46s
Train Epoch: 641 [40960/90000 (45%)]	Loss: 3.0674	Cost: 12.11s
Train Epoch: 641 [61440/90000 (68%)]	Loss: 2.9141	Cost: 6.00s
Train Epoch: 641 [81920/90000 (91%)]	Loss: 3.1675	Cost: 6.98s
Train Epoch: 641 	Average Loss: 3.1236
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8714

Saving model as e641_model.pt & e641_waveforms_supplementary.hdf5
Learning rate: 9.898961316453026e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 642 [0/90000 (0%)]	Loss: 4.8154	Cost: 29.09s
Train Epoch: 642 [20480/90000 (23%)]	Loss: 3.0115	Cost: 6.55s
Train Epoch: 642 [40960/90000 (45%)]	Loss: 3.0436	Cost: 9.00s
Train Epoch: 642 [61440/90000 (68%)]	Loss: 3.0849	Cost: 8.69s
Train Epoch: 642 [81920/90000 (91%)]	Loss: 3.2012	Cost: 8.76s
Train Epoch: 642 	Average Loss: 3.1137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0777

Learning rate: 9.898646887476729e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 643 [0/90000 (0%)]	Loss: 5.0043	Cost: 22.50s
Train Epoch: 643 [20480/90000 (23%)]	Loss: 3.0575	Cost: 8.13s
Train Epoch: 643 [40960/90000 (45%)]	Loss: 2.9179	Cost: 8.93s
Train Epoch: 643 [61440/90000 (68%)]	Loss: 2.8079	Cost: 8.55s
Train Epoch: 643 [81920/90000 (91%)]	Loss: 3.1116	Cost: 8.39s
Train Epoch: 643 	Average Loss: 3.0809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0850

Learning rate: 9.898331975023371e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 644 [0/90000 (0%)]	Loss: 4.8119	Cost: 23.98s
Train Epoch: 644 [20480/90000 (23%)]	Loss: 3.0659	Cost: 11.27s
Train Epoch: 644 [40960/90000 (45%)]	Loss: 2.7978	Cost: 9.20s
Train Epoch: 644 [61440/90000 (68%)]	Loss: 2.9230	Cost: 6.76s
Train Epoch: 644 [81920/90000 (91%)]	Loss: 2.9857	Cost: 8.44s
Train Epoch: 644 	Average Loss: 3.0783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0284

Learning rate: 9.898016579124025e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 645 [0/90000 (0%)]	Loss: 4.9630	Cost: 19.89s
Train Epoch: 645 [20480/90000 (23%)]	Loss: 2.9242	Cost: 9.44s
Train Epoch: 645 [40960/90000 (45%)]	Loss: 2.8786	Cost: 17.52s
Train Epoch: 645 [61440/90000 (68%)]	Loss: 2.8795	Cost: 14.42s
Train Epoch: 645 [81920/90000 (91%)]	Loss: 3.0230	Cost: 12.12s
Train Epoch: 645 	Average Loss: 3.0404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0364

Learning rate: 9.897700699809825e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 646 [0/90000 (0%)]	Loss: 4.9970	Cost: 31.28s
Train Epoch: 646 [20480/90000 (23%)]	Loss: 2.8752	Cost: 14.83s
Train Epoch: 646 [40960/90000 (45%)]	Loss: 2.9136	Cost: 12.53s
Train Epoch: 646 [61440/90000 (68%)]	Loss: 2.8776	Cost: 12.17s
Train Epoch: 646 [81920/90000 (91%)]	Loss: 3.0733	Cost: 10.33s
Train Epoch: 646 	Average Loss: 3.0257
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9179

Learning rate: 9.897384337111944e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 647 [0/90000 (0%)]	Loss: 4.7644	Cost: 25.22s
Train Epoch: 647 [20480/90000 (23%)]	Loss: 2.8813	Cost: 10.03s
Train Epoch: 647 [40960/90000 (45%)]	Loss: 2.7554	Cost: 12.53s
Train Epoch: 647 [61440/90000 (68%)]	Loss: 2.7900	Cost: 12.31s
Train Epoch: 647 [81920/90000 (91%)]	Loss: 2.8062	Cost: 7.81s
Train Epoch: 647 	Average Loss: 2.9955
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8367

Saving model as e647_model.pt & e647_waveforms_supplementary.hdf5
Learning rate: 9.897067491061608e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 648 [0/90000 (0%)]	Loss: 4.8726	Cost: 29.77s
Train Epoch: 648 [20480/90000 (23%)]	Loss: 2.7842	Cost: 8.50s
Train Epoch: 648 [40960/90000 (45%)]	Loss: 2.8221	Cost: 6.53s
Train Epoch: 648 [61440/90000 (68%)]	Loss: 2.8248	Cost: 7.01s
Train Epoch: 648 [81920/90000 (91%)]	Loss: 2.8493	Cost: 9.08s
Train Epoch: 648 	Average Loss: 2.9468
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9180

Learning rate: 9.896750161690087e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 649 [0/90000 (0%)]	Loss: 4.9070	Cost: 21.31s
Train Epoch: 649 [20480/90000 (23%)]	Loss: 2.8235	Cost: 9.74s
Train Epoch: 649 [40960/90000 (45%)]	Loss: 2.8954	Cost: 10.11s
Train Epoch: 649 [61440/90000 (68%)]	Loss: 2.6870	Cost: 9.01s
Train Epoch: 649 [81920/90000 (91%)]	Loss: 2.9336	Cost: 8.71s
Train Epoch: 649 	Average Loss: 2.9334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9317

Learning rate: 9.8964323490287e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 650 [0/90000 (0%)]	Loss: 4.5745	Cost: 29.70s
Train Epoch: 650 [20480/90000 (23%)]	Loss: 2.8421	Cost: 11.82s
Train Epoch: 650 [40960/90000 (45%)]	Loss: 2.7275	Cost: 10.33s
Train Epoch: 650 [61440/90000 (68%)]	Loss: 2.6707	Cost: 6.30s
Train Epoch: 650 [81920/90000 (91%)]	Loss: 2.7822	Cost: 6.81s
Train Epoch: 650 	Average Loss: 2.9541
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9611

Learning rate: 9.896114053108814e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 651 [0/90000 (0%)]	Loss: 4.8764	Cost: 21.13s
Train Epoch: 651 [20480/90000 (23%)]	Loss: 2.7258	Cost: 6.92s
Train Epoch: 651 [40960/90000 (45%)]	Loss: 2.8496	Cost: 10.20s
Train Epoch: 651 [61440/90000 (68%)]	Loss: 2.6464	Cost: 10.92s
Train Epoch: 651 [81920/90000 (91%)]	Loss: 2.8798	Cost: 12.93s
Train Epoch: 651 	Average Loss: 2.9147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9368

Learning rate: 9.895795273961846e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 652 [0/90000 (0%)]	Loss: 5.0577	Cost: 24.03s
Train Epoch: 652 [20480/90000 (23%)]	Loss: 2.7248	Cost: 7.51s
Train Epoch: 652 [40960/90000 (45%)]	Loss: 2.7817	Cost: 13.07s
Train Epoch: 652 [61440/90000 (68%)]	Loss: 2.8870	Cost: 12.32s
Train Epoch: 652 [81920/90000 (91%)]	Loss: 3.0668	Cost: 12.13s
Train Epoch: 652 	Average Loss: 2.9956
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0145

Learning rate: 9.895476011619254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 653 [0/90000 (0%)]	Loss: 5.1188	Cost: 24.67s
Train Epoch: 653 [20480/90000 (23%)]	Loss: 2.9167	Cost: 13.00s
Train Epoch: 653 [40960/90000 (45%)]	Loss: 2.8070	Cost: 12.63s
Train Epoch: 653 [61440/90000 (68%)]	Loss: 2.7896	Cost: 12.41s
Train Epoch: 653 [81920/90000 (91%)]	Loss: 2.8978	Cost: 12.39s
Train Epoch: 653 	Average Loss: 3.0145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8837

Learning rate: 9.89515626611255e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 654 [0/90000 (0%)]	Loss: 4.7199	Cost: 24.65s
Train Epoch: 654 [20480/90000 (23%)]	Loss: 2.8699	Cost: 14.06s
Train Epoch: 654 [40960/90000 (45%)]	Loss: 2.9347	Cost: 12.17s
Train Epoch: 654 [61440/90000 (68%)]	Loss: 2.8017	Cost: 9.19s
Train Epoch: 654 [81920/90000 (91%)]	Loss: 2.7801	Cost: 6.12s
Train Epoch: 654 	Average Loss: 2.9005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7920

Saving model as e654_model.pt & e654_waveforms_supplementary.hdf5
Learning rate: 9.894836037473293e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 655 [0/90000 (0%)]	Loss: 4.5698	Cost: 34.07s
Train Epoch: 655 [20480/90000 (23%)]	Loss: 2.8229	Cost: 7.26s
Train Epoch: 655 [40960/90000 (45%)]	Loss: 2.6977	Cost: 8.76s
Train Epoch: 655 [61440/90000 (68%)]	Loss: 2.6681	Cost: 8.60s
Train Epoch: 655 [81920/90000 (91%)]	Loss: 2.7522	Cost: 8.43s
Train Epoch: 655 	Average Loss: 2.8207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8718

Learning rate: 9.894515325733087e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 656 [0/90000 (0%)]	Loss: 4.7652	Cost: 26.64s
Train Epoch: 656 [20480/90000 (23%)]	Loss: 2.6467	Cost: 7.89s
Train Epoch: 656 [40960/90000 (45%)]	Loss: 2.6942	Cost: 9.02s
Train Epoch: 656 [61440/90000 (68%)]	Loss: 2.6810	Cost: 8.76s
Train Epoch: 656 [81920/90000 (91%)]	Loss: 2.7835	Cost: 8.41s
Train Epoch: 656 	Average Loss: 2.8562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9013

Learning rate: 9.894194130923585e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 657 [0/90000 (0%)]	Loss: 5.1211	Cost: 22.46s
Train Epoch: 657 [20480/90000 (23%)]	Loss: 2.8237	Cost: 6.22s
Train Epoch: 657 [40960/90000 (45%)]	Loss: 3.1625	Cost: 12.07s
Train Epoch: 657 [61440/90000 (68%)]	Loss: 3.0186	Cost: 11.66s
Train Epoch: 657 [81920/90000 (91%)]	Loss: 2.9624	Cost: 13.93s
Train Epoch: 657 	Average Loss: 3.0756
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0275

Learning rate: 9.893872453076489e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 658 [0/90000 (0%)]	Loss: 4.6131	Cost: 21.75s
Train Epoch: 658 [20480/90000 (23%)]	Loss: 2.7733	Cost: 9.63s
Train Epoch: 658 [40960/90000 (45%)]	Loss: 2.9635	Cost: 14.89s
Train Epoch: 658 [61440/90000 (68%)]	Loss: 2.9925	Cost: 14.67s
Train Epoch: 658 [81920/90000 (91%)]	Loss: 3.2219	Cost: 12.47s
Train Epoch: 658 	Average Loss: 3.0975
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1661

Learning rate: 9.893550292223543e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 659 [0/90000 (0%)]	Loss: 5.1505	Cost: 27.49s
Train Epoch: 659 [20480/90000 (23%)]	Loss: 3.2277	Cost: 13.97s
Train Epoch: 659 [40960/90000 (45%)]	Loss: 3.0689	Cost: 12.90s
Train Epoch: 659 [61440/90000 (68%)]	Loss: 2.9348	Cost: 12.61s
Train Epoch: 659 [81920/90000 (91%)]	Loss: 2.9431	Cost: 7.89s
Train Epoch: 659 	Average Loss: 3.1825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8822

Learning rate: 9.893227648396548e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 660 [0/90000 (0%)]	Loss: 4.8930	Cost: 35.09s
Train Epoch: 660 [20480/90000 (23%)]	Loss: 2.6799	Cost: 10.32s
Train Epoch: 660 [40960/90000 (45%)]	Loss: 2.9261	Cost: 6.53s
Train Epoch: 660 [61440/90000 (68%)]	Loss: 2.8378	Cost: 6.29s
Train Epoch: 660 [81920/90000 (91%)]	Loss: 2.9362	Cost: 8.89s
Train Epoch: 660 	Average Loss: 2.9481
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9006

Learning rate: 9.892904521627345e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 661 [0/90000 (0%)]	Loss: 4.7699	Cost: 33.73s
Train Epoch: 661 [20480/90000 (23%)]	Loss: 2.8628	Cost: 6.45s
Train Epoch: 661 [40960/90000 (45%)]	Loss: 2.8675	Cost: 9.94s
Train Epoch: 661 [61440/90000 (68%)]	Loss: 2.7347	Cost: 8.56s
Train Epoch: 661 [81920/90000 (91%)]	Loss: 2.7105	Cost: 8.39s
Train Epoch: 661 	Average Loss: 2.9352
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9174

Learning rate: 9.892580911947826e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 662 [0/90000 (0%)]	Loss: 4.9527	Cost: 22.69s
Train Epoch: 662 [20480/90000 (23%)]	Loss: 2.9105	Cost: 12.26s
Train Epoch: 662 [40960/90000 (45%)]	Loss: 2.7583	Cost: 7.84s
Train Epoch: 662 [61440/90000 (68%)]	Loss: 2.5951	Cost: 9.21s
Train Epoch: 662 [81920/90000 (91%)]	Loss: 2.7185	Cost: 11.65s
Train Epoch: 662 	Average Loss: 2.8142
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6972

Saving model as e662_model.pt & e662_waveforms_supplementary.hdf5
Learning rate: 9.892256819389932e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 663 [0/90000 (0%)]	Loss: 4.6133	Cost: 22.80s
Train Epoch: 663 [20480/90000 (23%)]	Loss: 2.4892	Cost: 9.71s
Train Epoch: 663 [40960/90000 (45%)]	Loss: 2.7750	Cost: 14.18s
Train Epoch: 663 [61440/90000 (68%)]	Loss: 2.5059	Cost: 13.75s
Train Epoch: 663 [81920/90000 (91%)]	Loss: 2.6709	Cost: 12.19s
Train Epoch: 663 	Average Loss: 2.7054
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9209

Learning rate: 9.891932243985645e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 664 [0/90000 (0%)]	Loss: 5.0034	Cost: 30.14s
Train Epoch: 664 [20480/90000 (23%)]	Loss: 2.3702	Cost: 14.04s
Train Epoch: 664 [40960/90000 (45%)]	Loss: 2.5644	Cost: 12.58s
Train Epoch: 664 [61440/90000 (68%)]	Loss: 2.5300	Cost: 12.23s
Train Epoch: 664 [81920/90000 (91%)]	Loss: 2.5253	Cost: 12.36s
Train Epoch: 664 	Average Loss: 2.7402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7483

Learning rate: 9.891607185767004e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 665 [0/90000 (0%)]	Loss: 4.6571	Cost: 23.62s
Train Epoch: 665 [20480/90000 (23%)]	Loss: 2.6539	Cost: 12.81s
Train Epoch: 665 [40960/90000 (45%)]	Loss: 2.6491	Cost: 12.24s
Train Epoch: 665 [61440/90000 (68%)]	Loss: 2.5466	Cost: 11.77s
Train Epoch: 665 [81920/90000 (91%)]	Loss: 2.6580	Cost: 6.23s
Train Epoch: 665 	Average Loss: 2.7263
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8090

Learning rate: 9.891281644766087e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 666 [0/90000 (0%)]	Loss: 4.8672	Cost: 26.70s
Train Epoch: 666 [20480/90000 (23%)]	Loss: 2.5744	Cost: 11.14s
Train Epoch: 666 [40960/90000 (45%)]	Loss: 2.6426	Cost: 10.17s
Train Epoch: 666 [61440/90000 (68%)]	Loss: 2.5513	Cost: 6.36s
Train Epoch: 666 [81920/90000 (91%)]	Loss: 2.7364	Cost: 7.30s
Train Epoch: 666 	Average Loss: 2.7052
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7135

Learning rate: 9.890955621015026e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 667 [0/90000 (0%)]	Loss: 4.8463	Cost: 29.90s
Train Epoch: 667 [20480/90000 (23%)]	Loss: 2.6488	Cost: 6.55s
Train Epoch: 667 [40960/90000 (45%)]	Loss: 2.9379	Cost: 7.95s
Train Epoch: 667 [61440/90000 (68%)]	Loss: 2.6377	Cost: 9.48s
Train Epoch: 667 [81920/90000 (91%)]	Loss: 2.7336	Cost: 8.95s
Train Epoch: 667 	Average Loss: 2.8539
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8512

Learning rate: 9.890629114545997e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 668 [0/90000 (0%)]	Loss: 4.8140	Cost: 20.49s
Train Epoch: 668 [20480/90000 (23%)]	Loss: 2.6028	Cost: 9.65s
Train Epoch: 668 [40960/90000 (45%)]	Loss: 2.6174	Cost: 11.69s
Train Epoch: 668 [61440/90000 (68%)]	Loss: 2.5916	Cost: 9.91s
Train Epoch: 668 [81920/90000 (91%)]	Loss: 2.6473	Cost: 8.74s
Train Epoch: 668 	Average Loss: 2.7360
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7588

Learning rate: 9.890302125391226e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 669 [0/90000 (0%)]	Loss: 4.5577	Cost: 25.88s
Train Epoch: 669 [20480/90000 (23%)]	Loss: 2.7995	Cost: 9.08s
Train Epoch: 669 [40960/90000 (45%)]	Loss: 2.5969	Cost: 8.49s
Train Epoch: 669 [61440/90000 (68%)]	Loss: 2.6218	Cost: 6.72s
Train Epoch: 669 [81920/90000 (91%)]	Loss: 2.6106	Cost: 7.73s
Train Epoch: 669 	Average Loss: 2.7404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6698

Saving model as e669_model.pt & e669_waveforms_supplementary.hdf5
Learning rate: 9.889974653582986e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 670 [0/90000 (0%)]	Loss: 4.7282	Cost: 20.79s
Train Epoch: 670 [20480/90000 (23%)]	Loss: 2.5343	Cost: 8.11s
Train Epoch: 670 [40960/90000 (45%)]	Loss: 2.4998	Cost: 12.83s
Train Epoch: 670 [61440/90000 (68%)]	Loss: 2.5220	Cost: 12.60s
Train Epoch: 670 [81920/90000 (91%)]	Loss: 2.6258	Cost: 12.43s
Train Epoch: 670 	Average Loss: 2.6343
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7456

Learning rate: 9.889646699153596e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 671 [0/90000 (0%)]	Loss: 4.7255	Cost: 25.02s
Train Epoch: 671 [20480/90000 (23%)]	Loss: 2.4781	Cost: 12.85s
Train Epoch: 671 [40960/90000 (45%)]	Loss: 2.7600	Cost: 12.59s
Train Epoch: 671 [61440/90000 (68%)]	Loss: 2.4961	Cost: 12.34s
Train Epoch: 671 [81920/90000 (91%)]	Loss: 2.6528	Cost: 12.56s
Train Epoch: 671 	Average Loss: 2.7137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7966

Learning rate: 9.889318262135424e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 672 [0/90000 (0%)]	Loss: 4.3512	Cost: 23.98s
Train Epoch: 672 [20480/90000 (23%)]	Loss: 2.4928	Cost: 14.34s
Train Epoch: 672 [40960/90000 (45%)]	Loss: 2.6152	Cost: 12.14s
Train Epoch: 672 [61440/90000 (68%)]	Loss: 2.4185	Cost: 9.14s
Train Epoch: 672 [81920/90000 (91%)]	Loss: 2.6125	Cost: 6.13s
Train Epoch: 672 	Average Loss: 2.6572
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6402

Saving model as e672_model.pt & e672_waveforms_supplementary.hdf5
Learning rate: 9.888989342560885e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 673 [0/90000 (0%)]	Loss: 4.4462	Cost: 37.81s
Train Epoch: 673 [20480/90000 (23%)]	Loss: 2.4748	Cost: 6.95s
Train Epoch: 673 [40960/90000 (45%)]	Loss: 2.5581	Cost: 7.84s
Train Epoch: 673 [61440/90000 (68%)]	Loss: 2.3739	Cost: 7.82s
Train Epoch: 673 [81920/90000 (91%)]	Loss: 2.5143	Cost: 8.60s
Train Epoch: 673 	Average Loss: 2.6034
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6789

Learning rate: 9.888659940462443e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 674 [0/90000 (0%)]	Loss: 4.6438	Cost: 25.10s
Train Epoch: 674 [20480/90000 (23%)]	Loss: 2.4654	Cost: 8.36s
Train Epoch: 674 [40960/90000 (45%)]	Loss: 2.5127	Cost: 8.97s
Train Epoch: 674 [61440/90000 (68%)]	Loss: 3.4115	Cost: 8.62s
Train Epoch: 674 [81920/90000 (91%)]	Loss: 3.2401	Cost: 8.50s
Train Epoch: 674 	Average Loss: 2.8926
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2145

Learning rate: 9.88833005587261e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 675 [0/90000 (0%)]	Loss: 5.1753	Cost: 22.19s
Train Epoch: 675 [20480/90000 (23%)]	Loss: 3.0109	Cost: 9.08s
Train Epoch: 675 [40960/90000 (45%)]	Loss: 2.7659	Cost: 7.48s
Train Epoch: 675 [61440/90000 (68%)]	Loss: 2.6216	Cost: 10.08s
Train Epoch: 675 [81920/90000 (91%)]	Loss: 2.8635	Cost: 7.82s
Train Epoch: 675 	Average Loss: 2.9809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7708

Learning rate: 9.887999688823941e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 676 [0/90000 (0%)]	Loss: 4.5645	Cost: 19.97s
Train Epoch: 676 [20480/90000 (23%)]	Loss: 2.4894	Cost: 8.13s
Train Epoch: 676 [40960/90000 (45%)]	Loss: 2.6291	Cost: 13.17s
Train Epoch: 676 [61440/90000 (68%)]	Loss: 2.3150	Cost: 15.60s
Train Epoch: 676 [81920/90000 (91%)]	Loss: 2.5895	Cost: 13.59s
Train Epoch: 676 	Average Loss: 2.6761
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7525

Learning rate: 9.887668839349044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 677 [0/90000 (0%)]	Loss: 4.7243	Cost: 29.56s
Train Epoch: 677 [20480/90000 (23%)]	Loss: 2.6083	Cost: 13.95s
Train Epoch: 677 [40960/90000 (45%)]	Loss: 2.4738	Cost: 13.12s
Train Epoch: 677 [61440/90000 (68%)]	Loss: 2.4034	Cost: 12.10s
Train Epoch: 677 [81920/90000 (91%)]	Loss: 2.4586	Cost: 10.20s
Train Epoch: 677 	Average Loss: 2.6742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6031

Saving model as e677_model.pt & e677_waveforms_supplementary.hdf5
Learning rate: 9.887337507480573e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 678 [0/90000 (0%)]	Loss: 4.3839	Cost: 31.77s
Train Epoch: 678 [20480/90000 (23%)]	Loss: 2.4419	Cost: 11.37s
Train Epoch: 678 [40960/90000 (45%)]	Loss: 2.4187	Cost: 9.24s
Train Epoch: 678 [61440/90000 (68%)]	Loss: 2.2190	Cost: 6.12s
Train Epoch: 678 [81920/90000 (91%)]	Loss: 2.5092	Cost: 7.51s
Train Epoch: 678 	Average Loss: 2.5330
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6398

Learning rate: 9.887005693251226e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 679 [0/90000 (0%)]	Loss: 4.6219	Cost: 36.04s
Train Epoch: 679 [20480/90000 (23%)]	Loss: 2.4061	Cost: 12.01s
Train Epoch: 679 [40960/90000 (45%)]	Loss: 2.5119	Cost: 6.86s
Train Epoch: 679 [61440/90000 (68%)]	Loss: 2.2166	Cost: 6.48s
Train Epoch: 679 [81920/90000 (91%)]	Loss: 2.3664	Cost: 8.36s
Train Epoch: 679 	Average Loss: 2.5088
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6005

Saving model as e679_model.pt & e679_waveforms_supplementary.hdf5
Learning rate: 9.886673396693755e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 680 [0/90000 (0%)]	Loss: 4.6328	Cost: 22.17s
Train Epoch: 680 [20480/90000 (23%)]	Loss: 2.3726	Cost: 7.38s
Train Epoch: 680 [40960/90000 (45%)]	Loss: 2.2172	Cost: 8.58s
Train Epoch: 680 [61440/90000 (68%)]	Loss: 2.3723	Cost: 8.68s
Train Epoch: 680 [81920/90000 (91%)]	Loss: 2.6073	Cost: 8.45s
Train Epoch: 680 	Average Loss: 2.4909
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6227

Learning rate: 9.886340617840956e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 681 [0/90000 (0%)]	Loss: 4.4382	Cost: 25.42s
Train Epoch: 681 [20480/90000 (23%)]	Loss: 2.3925	Cost: 11.52s
Train Epoch: 681 [40960/90000 (45%)]	Loss: 2.4763	Cost: 11.02s
Train Epoch: 681 [61440/90000 (68%)]	Loss: 2.2820	Cost: 6.93s
Train Epoch: 681 [81920/90000 (91%)]	Loss: 2.3360	Cost: 7.91s
Train Epoch: 681 	Average Loss: 2.4922
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6276

Learning rate: 9.886007356725671e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 682 [0/90000 (0%)]	Loss: 4.2310	Cost: 20.97s
Train Epoch: 682 [20480/90000 (23%)]	Loss: 2.3541	Cost: 10.26s
Train Epoch: 682 [40960/90000 (45%)]	Loss: 2.5019	Cost: 10.10s
Train Epoch: 682 [61440/90000 (68%)]	Loss: 2.2158	Cost: 12.84s
Train Epoch: 682 [81920/90000 (91%)]	Loss: 2.2821	Cost: 12.52s
Train Epoch: 682 	Average Loss: 2.4746
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6183

Learning rate: 9.885673613380794e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 683 [0/90000 (0%)]	Loss: 4.4864	Cost: 30.34s
Train Epoch: 683 [20480/90000 (23%)]	Loss: 2.2487	Cost: 13.71s
Train Epoch: 683 [40960/90000 (45%)]	Loss: 2.4043	Cost: 12.66s
Train Epoch: 683 [61440/90000 (68%)]	Loss: 2.4046	Cost: 12.28s
Train Epoch: 683 [81920/90000 (91%)]	Loss: 2.3715	Cost: 12.07s
Train Epoch: 683 	Average Loss: 2.4909
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5530

Saving model as e683_model.pt & e683_waveforms_supplementary.hdf5
Learning rate: 9.885339387839263e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 684 [0/90000 (0%)]	Loss: 4.6128	Cost: 23.46s
Train Epoch: 684 [20480/90000 (23%)]	Loss: 2.3704	Cost: 13.40s
Train Epoch: 684 [40960/90000 (45%)]	Loss: 2.5717	Cost: 12.36s
Train Epoch: 684 [61440/90000 (68%)]	Loss: 2.3870	Cost: 10.73s
Train Epoch: 684 [81920/90000 (91%)]	Loss: 2.4700	Cost: 6.42s
Train Epoch: 684 	Average Loss: 2.4924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5623

Learning rate: 9.885004680134064e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 685 [0/90000 (0%)]	Loss: 4.3808	Cost: 26.60s
Train Epoch: 685 [20480/90000 (23%)]	Loss: 2.2797	Cost: 7.87s
Train Epoch: 685 [40960/90000 (45%)]	Loss: 2.3374	Cost: 12.43s
Train Epoch: 685 [61440/90000 (68%)]	Loss: 2.0721	Cost: 6.87s
Train Epoch: 685 [81920/90000 (91%)]	Loss: 2.2738	Cost: 6.28s
Train Epoch: 685 	Average Loss: 2.4132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5284

Saving model as e685_model.pt & e685_waveforms_supplementary.hdf5
Learning rate: 9.884669490298232e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 686 [0/90000 (0%)]	Loss: 4.6120	Cost: 27.63s
Train Epoch: 686 [20480/90000 (23%)]	Loss: 2.3236	Cost: 8.34s
Train Epoch: 686 [40960/90000 (45%)]	Loss: 2.4331	Cost: 10.27s
Train Epoch: 686 [61440/90000 (68%)]	Loss: 2.2043	Cost: 9.08s
Train Epoch: 686 [81920/90000 (91%)]	Loss: 2.3016	Cost: 8.79s
Train Epoch: 686 	Average Loss: 2.4048
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6515

Learning rate: 9.884333818364849e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 687 [0/90000 (0%)]	Loss: 4.3233	Cost: 25.95s
Train Epoch: 687 [20480/90000 (23%)]	Loss: 2.1774	Cost: 10.76s
Train Epoch: 687 [40960/90000 (45%)]	Loss: 2.2510	Cost: 10.84s
Train Epoch: 687 [61440/90000 (68%)]	Loss: 2.1815	Cost: 8.86s
Train Epoch: 687 [81920/90000 (91%)]	Loss: 2.3238	Cost: 6.59s
Train Epoch: 687 	Average Loss: 2.3684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4725

Saving model as e687_model.pt & e687_waveforms_supplementary.hdf5
Learning rate: 9.883997664367044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 688 [0/90000 (0%)]	Loss: 4.3264	Cost: 19.79s
Train Epoch: 688 [20480/90000 (23%)]	Loss: 2.4810	Cost: 7.47s
Train Epoch: 688 [40960/90000 (45%)]	Loss: 2.5080	Cost: 13.40s
Train Epoch: 688 [61440/90000 (68%)]	Loss: 2.1444	Cost: 12.78s
Train Epoch: 688 [81920/90000 (91%)]	Loss: 2.4466	Cost: 12.61s
Train Epoch: 688 	Average Loss: 2.4395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5774

Learning rate: 9.883661028337996e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 689 [0/90000 (0%)]	Loss: 4.4757	Cost: 24.59s
Train Epoch: 689 [20480/90000 (23%)]	Loss: 2.3166	Cost: 12.82s
Train Epoch: 689 [40960/90000 (45%)]	Loss: 2.1155	Cost: 12.39s
Train Epoch: 689 [61440/90000 (68%)]	Loss: 2.0860	Cost: 12.52s
Train Epoch: 689 [81920/90000 (91%)]	Loss: 2.5107	Cost: 12.20s
Train Epoch: 689 	Average Loss: 2.3827
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4687

Saving model as e689_model.pt & e689_waveforms_supplementary.hdf5
Learning rate: 9.883323910310927e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 690 [0/90000 (0%)]	Loss: 4.4395	Cost: 26.38s
Train Epoch: 690 [20480/90000 (23%)]	Loss: 2.2612	Cost: 12.31s
Train Epoch: 690 [40960/90000 (45%)]	Loss: 2.2307	Cost: 12.25s
Train Epoch: 690 [61440/90000 (68%)]	Loss: 2.0411	Cost: 6.16s
Train Epoch: 690 [81920/90000 (91%)]	Loss: 2.3784	Cost: 6.53s
Train Epoch: 690 	Average Loss: 2.3802
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5358

Learning rate: 9.88298631031911e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 691 [0/90000 (0%)]	Loss: 4.6703	Cost: 31.94s
Train Epoch: 691 [20480/90000 (23%)]	Loss: 2.1124	Cost: 6.92s
Train Epoch: 691 [40960/90000 (45%)]	Loss: 2.2679	Cost: 9.21s
Train Epoch: 691 [61440/90000 (68%)]	Loss: 2.1183	Cost: 8.86s
Train Epoch: 691 [81920/90000 (91%)]	Loss: 2.2108	Cost: 9.11s
Train Epoch: 691 	Average Loss: 2.3103
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4248

Saving model as e691_model.pt & e691_waveforms_supplementary.hdf5
Learning rate: 9.882648228395867e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 692 [0/90000 (0%)]	Loss: 4.6410	Cost: 23.60s
Train Epoch: 692 [20480/90000 (23%)]	Loss: 2.1484	Cost: 9.26s
Train Epoch: 692 [40960/90000 (45%)]	Loss: 2.2785	Cost: 8.91s
Train Epoch: 692 [61440/90000 (68%)]	Loss: 2.1024	Cost: 8.71s
Train Epoch: 692 [81920/90000 (91%)]	Loss: 2.1490	Cost: 8.51s
Train Epoch: 692 	Average Loss: 2.2658
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4460

Learning rate: 9.882309664574563e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 693 [0/90000 (0%)]	Loss: 4.2888	Cost: 21.14s
Train Epoch: 693 [20480/90000 (23%)]	Loss: 2.1326	Cost: 9.33s
Train Epoch: 693 [40960/90000 (45%)]	Loss: 1.9660	Cost: 7.70s
Train Epoch: 693 [61440/90000 (68%)]	Loss: 2.0558	Cost: 7.51s
Train Epoch: 693 [81920/90000 (91%)]	Loss: 2.2570	Cost: 9.74s
Train Epoch: 693 	Average Loss: 2.2651
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4379

Learning rate: 9.881970618888613e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 694 [0/90000 (0%)]	Loss: 4.6113	Cost: 19.33s
Train Epoch: 694 [20480/90000 (23%)]	Loss: 2.1159	Cost: 7.32s
Train Epoch: 694 [40960/90000 (45%)]	Loss: 2.0379	Cost: 12.29s
Train Epoch: 694 [61440/90000 (68%)]	Loss: 2.1106	Cost: 14.41s
Train Epoch: 694 [81920/90000 (91%)]	Loss: 2.2073	Cost: 13.70s
Train Epoch: 694 	Average Loss: 2.2592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3361

Saving model as e694_model.pt & e694_waveforms_supplementary.hdf5
Learning rate: 9.88163109137148e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 695 [0/90000 (0%)]	Loss: 4.1670	Cost: 24.77s
Train Epoch: 695 [20480/90000 (23%)]	Loss: 2.2536	Cost: 14.98s
Train Epoch: 695 [40960/90000 (45%)]	Loss: 2.3046	Cost: 13.72s
Train Epoch: 695 [61440/90000 (68%)]	Loss: 2.0425	Cost: 12.19s
Train Epoch: 695 [81920/90000 (91%)]	Loss: 2.2070	Cost: 10.55s
Train Epoch: 695 	Average Loss: 2.2546
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4570

Learning rate: 9.881291082056673e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 696 [0/90000 (0%)]	Loss: 4.1956	Cost: 42.24s
Train Epoch: 696 [20480/90000 (23%)]	Loss: 1.9879	Cost: 12.47s
Train Epoch: 696 [40960/90000 (45%)]	Loss: 2.1368	Cost: 12.27s
Train Epoch: 696 [61440/90000 (68%)]	Loss: 1.9075	Cost: 7.08s
Train Epoch: 696 [81920/90000 (91%)]	Loss: 2.1287	Cost: 6.11s
Train Epoch: 696 	Average Loss: 2.2680
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3631

Learning rate: 9.880950590977753e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 697 [0/90000 (0%)]	Loss: 4.3668	Cost: 35.73s
Train Epoch: 697 [20480/90000 (23%)]	Loss: 2.0950	Cost: 10.79s
Train Epoch: 697 [40960/90000 (45%)]	Loss: 2.1430	Cost: 6.81s
Train Epoch: 697 [61440/90000 (68%)]	Loss: 1.9498	Cost: 6.09s
Train Epoch: 697 [81920/90000 (91%)]	Loss: 2.1930	Cost: 7.90s
Train Epoch: 697 	Average Loss: 2.2526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4687

Learning rate: 9.88060961816832e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 698 [0/90000 (0%)]	Loss: 4.3885	Cost: 24.56s
Train Epoch: 698 [20480/90000 (23%)]	Loss: 2.0492	Cost: 7.12s
Train Epoch: 698 [40960/90000 (45%)]	Loss: 2.0404	Cost: 10.27s
Train Epoch: 698 [61440/90000 (68%)]	Loss: 1.8353	Cost: 8.85s
Train Epoch: 698 [81920/90000 (91%)]	Loss: 2.1149	Cost: 9.29s
Train Epoch: 698 	Average Loss: 2.1624
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3165

Saving model as e698_model.pt & e698_waveforms_supplementary.hdf5
Learning rate: 9.88026816366203e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 699 [0/90000 (0%)]	Loss: 4.4167	Cost: 20.09s
Train Epoch: 699 [20480/90000 (23%)]	Loss: 1.9783	Cost: 10.58s
Train Epoch: 699 [40960/90000 (45%)]	Loss: 2.1643	Cost: 10.98s
Train Epoch: 699 [61440/90000 (68%)]	Loss: 2.0337	Cost: 10.81s
Train Epoch: 699 [81920/90000 (91%)]	Loss: 2.1324	Cost: 14.47s
Train Epoch: 699 	Average Loss: 2.2029
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4273

Learning rate: 9.879926227492583e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 700 [0/90000 (0%)]	Loss: 4.3376	Cost: 28.72s
Train Epoch: 700 [20480/90000 (23%)]	Loss: 1.8870	Cost: 13.20s
Train Epoch: 700 [40960/90000 (45%)]	Loss: 2.1165	Cost: 13.63s
Train Epoch: 700 [61440/90000 (68%)]	Loss: 1.9680	Cost: 12.24s
Train Epoch: 700 [81920/90000 (91%)]	Loss: 2.0830	Cost: 12.39s
Train Epoch: 700 	Average Loss: 2.1866
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3995

Learning rate: 9.879583809693725e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 701 [0/90000 (0%)]	Loss: 4.4456	Cost: 29.05s
Train Epoch: 701 [20480/90000 (23%)]	Loss: 1.9593	Cost: 13.12s
Train Epoch: 701 [40960/90000 (45%)]	Loss: 2.1023	Cost: 12.10s
Train Epoch: 701 [61440/90000 (68%)]	Loss: 1.9937	Cost: 8.73s
Train Epoch: 701 [81920/90000 (91%)]	Loss: 1.9882	Cost: 6.05s
Train Epoch: 701 	Average Loss: 2.1617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3520

Learning rate: 9.879240910299253e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 702 [0/90000 (0%)]	Loss: 4.3817	Cost: 21.84s
Train Epoch: 702 [20480/90000 (23%)]	Loss: 2.3391	Cost: 6.83s
Train Epoch: 702 [40960/90000 (45%)]	Loss: 2.3022	Cost: 9.46s
Train Epoch: 702 [61440/90000 (68%)]	Loss: 2.1233	Cost: 9.08s
Train Epoch: 702 [81920/90000 (91%)]	Loss: 2.0060	Cost: 8.93s
Train Epoch: 702 	Average Loss: 2.2747
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5261

Learning rate: 9.87889752934301e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 703 [0/90000 (0%)]	Loss: 4.1760	Cost: 29.54s
Train Epoch: 703 [20480/90000 (23%)]	Loss: 2.0175	Cost: 8.87s
Train Epoch: 703 [40960/90000 (45%)]	Loss: 2.1019	Cost: 6.85s
Train Epoch: 703 [61440/90000 (68%)]	Loss: 1.9970	Cost: 6.71s
Train Epoch: 703 [81920/90000 (91%)]	Loss: 2.2635	Cost: 7.64s
Train Epoch: 703 	Average Loss: 2.2434
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4817

Learning rate: 9.878553666858885e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 704 [0/90000 (0%)]	Loss: 4.3043	Cost: 22.47s
Train Epoch: 704 [20480/90000 (23%)]	Loss: 2.2359	Cost: 10.19s
Train Epoch: 704 [40960/90000 (45%)]	Loss: 2.2220	Cost: 10.10s
Train Epoch: 704 [61440/90000 (68%)]	Loss: 1.9376	Cost: 7.50s
Train Epoch: 704 [81920/90000 (91%)]	Loss: 2.0929	Cost: 14.00s
Train Epoch: 704 	Average Loss: 2.2714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3945

Learning rate: 9.878209322880817e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 705 [0/90000 (0%)]	Loss: 4.5215	Cost: 21.54s
Train Epoch: 705 [20480/90000 (23%)]	Loss: 1.9708	Cost: 8.89s
Train Epoch: 705 [40960/90000 (45%)]	Loss: 1.7441	Cost: 12.51s
Train Epoch: 705 [61440/90000 (68%)]	Loss: 1.8673	Cost: 12.61s
Train Epoch: 705 [81920/90000 (91%)]	Loss: 2.0339	Cost: 12.43s
Train Epoch: 705 	Average Loss: 2.1050
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4441

Learning rate: 9.87786449744279e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 706 [0/90000 (0%)]	Loss: 3.9460	Cost: 23.13s
Train Epoch: 706 [20480/90000 (23%)]	Loss: 1.9868	Cost: 13.90s
Train Epoch: 706 [40960/90000 (45%)]	Loss: 1.9062	Cost: 12.46s
Train Epoch: 706 [61440/90000 (68%)]	Loss: 2.0381	Cost: 12.18s
Train Epoch: 706 [81920/90000 (91%)]	Loss: 2.0336	Cost: 12.50s
Train Epoch: 706 	Average Loss: 2.1805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4896

Learning rate: 9.87751919057884e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 707 [0/90000 (0%)]	Loss: 4.2881	Cost: 25.23s
Train Epoch: 707 [20480/90000 (23%)]	Loss: 2.1912	Cost: 13.57s
Train Epoch: 707 [40960/90000 (45%)]	Loss: 2.0764	Cost: 12.43s
Train Epoch: 707 [61440/90000 (68%)]	Loss: 2.1610	Cost: 10.25s
Train Epoch: 707 [81920/90000 (91%)]	Loss: 2.3979	Cost: 6.20s
Train Epoch: 707 	Average Loss: 2.2600
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6399

Learning rate: 9.877173402323044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 708 [0/90000 (0%)]	Loss: 4.8106	Cost: 40.96s
Train Epoch: 708 [20480/90000 (23%)]	Loss: 2.2167	Cost: 9.19s
Train Epoch: 708 [40960/90000 (45%)]	Loss: 2.2394	Cost: 6.78s
Train Epoch: 708 [61440/90000 (68%)]	Loss: 2.0422	Cost: 7.63s
Train Epoch: 708 [81920/90000 (91%)]	Loss: 2.1094	Cost: 8.53s
Train Epoch: 708 	Average Loss: 2.2542
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3785

Learning rate: 9.876827132709531e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 709 [0/90000 (0%)]	Loss: 4.2024	Cost: 23.97s
Train Epoch: 709 [20480/90000 (23%)]	Loss: 1.8137	Cost: 7.76s
Train Epoch: 709 [40960/90000 (45%)]	Loss: 1.9568	Cost: 9.38s
Train Epoch: 709 [61440/90000 (68%)]	Loss: 1.9799	Cost: 8.84s
Train Epoch: 709 [81920/90000 (91%)]	Loss: 2.1384	Cost: 8.49s
Train Epoch: 709 	Average Loss: 2.1129
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4492

Learning rate: 9.876480381772478e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 710 [0/90000 (0%)]	Loss: 4.5974	Cost: 20.46s
Train Epoch: 710 [20480/90000 (23%)]	Loss: 1.9362	Cost: 9.42s
Train Epoch: 710 [40960/90000 (45%)]	Loss: 2.1747	Cost: 8.86s
Train Epoch: 710 [61440/90000 (68%)]	Loss: 1.9966	Cost: 8.76s
Train Epoch: 710 [81920/90000 (91%)]	Loss: 2.2915	Cost: 9.79s
Train Epoch: 710 	Average Loss: 2.2914
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5691

Learning rate: 9.876133149546104e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 711 [0/90000 (0%)]	Loss: 4.3670	Cost: 20.15s
Train Epoch: 711 [20480/90000 (23%)]	Loss: 2.1250	Cost: 9.27s
Train Epoch: 711 [40960/90000 (45%)]	Loss: 2.0872	Cost: 9.29s
Train Epoch: 711 [61440/90000 (68%)]	Loss: 1.8178	Cost: 7.22s
Train Epoch: 711 [81920/90000 (91%)]	Loss: 1.9396	Cost: 6.24s
Train Epoch: 711 	Average Loss: 2.1788
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2459

Saving model as e711_model.pt & e711_waveforms_supplementary.hdf5
Learning rate: 9.875785436064683e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 712 [0/90000 (0%)]	Loss: 4.0196	Cost: 25.70s
Train Epoch: 712 [20480/90000 (23%)]	Loss: 1.9889	Cost: 12.02s
Train Epoch: 712 [40960/90000 (45%)]	Loss: 1.7862	Cost: 13.61s
Train Epoch: 712 [61440/90000 (68%)]	Loss: 1.9882	Cost: 12.40s
Train Epoch: 712 [81920/90000 (91%)]	Loss: 1.9416	Cost: 12.16s
Train Epoch: 712 	Average Loss: 2.0092
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2789

Learning rate: 9.875437241362533e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 713 [0/90000 (0%)]	Loss: 4.2685	Cost: 29.46s
Train Epoch: 713 [20480/90000 (23%)]	Loss: 1.7977	Cost: 12.49s
Train Epoch: 713 [40960/90000 (45%)]	Loss: 1.8992	Cost: 12.76s
Train Epoch: 713 [61440/90000 (68%)]	Loss: 1.7776	Cost: 12.11s
Train Epoch: 713 [81920/90000 (91%)]	Loss: 2.0019	Cost: 9.03s
Train Epoch: 713 	Average Loss: 2.0261
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3236

Learning rate: 9.875088565474018e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 714 [0/90000 (0%)]	Loss: 4.3625	Cost: 27.96s
Train Epoch: 714 [20480/90000 (23%)]	Loss: 1.8839	Cost: 10.01s
Train Epoch: 714 [40960/90000 (45%)]	Loss: 1.8645	Cost: 10.35s
Train Epoch: 714 [61440/90000 (68%)]	Loss: 1.7629	Cost: 6.59s
Train Epoch: 714 [81920/90000 (91%)]	Loss: 1.9242	Cost: 6.64s
Train Epoch: 714 	Average Loss: 2.0268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3450

Learning rate: 9.874739408433551e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 715 [0/90000 (0%)]	Loss: 4.2932	Cost: 25.24s
Train Epoch: 715 [20480/90000 (23%)]	Loss: 1.8016	Cost: 11.21s
Train Epoch: 715 [40960/90000 (45%)]	Loss: 1.7660	Cost: 10.80s
Train Epoch: 715 [61440/90000 (68%)]	Loss: 1.6508	Cost: 7.74s
Train Epoch: 715 [81920/90000 (91%)]	Loss: 1.8815	Cost: 8.96s
Train Epoch: 715 	Average Loss: 1.9706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2272

Saving model as e715_model.pt & e715_waveforms_supplementary.hdf5
Learning rate: 9.874389770275595e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 716 [0/90000 (0%)]	Loss: 4.0630	Cost: 19.44s
Train Epoch: 716 [20480/90000 (23%)]	Loss: 1.7321	Cost: 8.68s
Train Epoch: 716 [40960/90000 (45%)]	Loss: 1.6906	Cost: 10.97s
Train Epoch: 716 [61440/90000 (68%)]	Loss: 1.7053	Cost: 9.15s
Train Epoch: 716 [81920/90000 (91%)]	Loss: 1.7229	Cost: 8.89s
Train Epoch: 716 	Average Loss: 1.8526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1148

Saving model as e716_model.pt & e716_waveforms_supplementary.hdf5
Learning rate: 9.874039651034654e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 717 [0/90000 (0%)]	Loss: 4.2113	Cost: 26.68s
Train Epoch: 717 [20480/90000 (23%)]	Loss: 1.7183	Cost: 8.73s
Train Epoch: 717 [40960/90000 (45%)]	Loss: 1.7322	Cost: 8.92s
Train Epoch: 717 [61440/90000 (68%)]	Loss: 1.9074	Cost: 6.29s
Train Epoch: 717 [81920/90000 (91%)]	Loss: 1.8335	Cost: 7.32s
Train Epoch: 717 	Average Loss: 1.9039
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1627

Learning rate: 9.873689050745284e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 718 [0/90000 (0%)]	Loss: 4.2325	Cost: 18.52s
Train Epoch: 718 [20480/90000 (23%)]	Loss: 1.7232	Cost: 7.35s
Train Epoch: 718 [40960/90000 (45%)]	Loss: 1.7982	Cost: 11.19s
Train Epoch: 718 [61440/90000 (68%)]	Loss: 1.5989	Cost: 9.65s
Train Epoch: 718 [81920/90000 (91%)]	Loss: 1.8707	Cost: 12.41s
Train Epoch: 718 	Average Loss: 1.9563
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2736

Learning rate: 9.873337969442089e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 719 [0/90000 (0%)]	Loss: 4.2358	Cost: 24.10s
Train Epoch: 719 [20480/90000 (23%)]	Loss: 1.7982	Cost: 10.84s
Train Epoch: 719 [40960/90000 (45%)]	Loss: 1.6324	Cost: 12.69s
Train Epoch: 719 [61440/90000 (68%)]	Loss: 1.7253	Cost: 12.37s
Train Epoch: 719 [81920/90000 (91%)]	Loss: 1.8504	Cost: 12.48s
Train Epoch: 719 	Average Loss: 1.9166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1261

Learning rate: 9.87298640715972e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 720 [0/90000 (0%)]	Loss: 4.0915	Cost: 31.74s
Train Epoch: 720 [20480/90000 (23%)]	Loss: 1.6976	Cost: 13.99s
Train Epoch: 720 [40960/90000 (45%)]	Loss: 1.6528	Cost: 13.33s
Train Epoch: 720 [61440/90000 (68%)]	Loss: 1.4681	Cost: 12.31s
Train Epoch: 720 [81920/90000 (91%)]	Loss: 1.7720	Cost: 9.92s
Train Epoch: 720 	Average Loss: 1.8417
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0694

Saving model as e720_model.pt & e720_waveforms_supplementary.hdf5
Learning rate: 9.872634363932875e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 721 [0/90000 (0%)]	Loss: 3.9915	Cost: 28.72s
Train Epoch: 721 [20480/90000 (23%)]	Loss: 1.7450	Cost: 14.12s
Train Epoch: 721 [40960/90000 (45%)]	Loss: 1.6143	Cost: 13.40s
Train Epoch: 721 [61440/90000 (68%)]	Loss: 1.7208	Cost: 6.43s
Train Epoch: 721 [81920/90000 (91%)]	Loss: 1.8238	Cost: 6.17s
Train Epoch: 721 	Average Loss: 1.8612
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1628

Learning rate: 9.872281839796297e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 722 [0/90000 (0%)]	Loss: 4.1328	Cost: 24.20s
Train Epoch: 722 [20480/90000 (23%)]	Loss: 1.7404	Cost: 7.11s
Train Epoch: 722 [40960/90000 (45%)]	Loss: 1.6645	Cost: 9.65s
Train Epoch: 722 [61440/90000 (68%)]	Loss: 1.5823	Cost: 8.83s
Train Epoch: 722 [81920/90000 (91%)]	Loss: 1.9274	Cost: 8.64s
Train Epoch: 722 	Average Loss: 1.8681
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0985

Learning rate: 9.87192883478478e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 723 [0/90000 (0%)]	Loss: 3.7660	Cost: 19.73s
Train Epoch: 723 [20480/90000 (23%)]	Loss: 1.7844	Cost: 9.17s
Train Epoch: 723 [40960/90000 (45%)]	Loss: 1.6691	Cost: 9.01s
Train Epoch: 723 [61440/90000 (68%)]	Loss: 1.6415	Cost: 8.65s
Train Epoch: 723 [81920/90000 (91%)]	Loss: 1.6172	Cost: 6.29s
Train Epoch: 723 	Average Loss: 1.8104
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1325

Learning rate: 9.871575348933164e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 724 [0/90000 (0%)]	Loss: 3.8455	Cost: 21.43s
Train Epoch: 724 [20480/90000 (23%)]	Loss: 1.7073	Cost: 8.05s
Train Epoch: 724 [40960/90000 (45%)]	Loss: 1.6701	Cost: 7.07s
Train Epoch: 724 [61440/90000 (68%)]	Loss: 1.4247	Cost: 6.53s
Train Epoch: 724 [81920/90000 (91%)]	Loss: 1.6775	Cost: 12.16s
Train Epoch: 724 	Average Loss: 1.7782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1382

Learning rate: 9.871221382276338e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 725 [0/90000 (0%)]	Loss: 4.3364	Cost: 25.77s
Train Epoch: 725 [20480/90000 (23%)]	Loss: 1.6409	Cost: 10.80s
Train Epoch: 725 [40960/90000 (45%)]	Loss: 1.8425	Cost: 17.07s
Train Epoch: 725 [61440/90000 (68%)]	Loss: 1.7123	Cost: 14.92s
Train Epoch: 725 [81920/90000 (91%)]	Loss: 1.8695	Cost: 12.32s
Train Epoch: 725 	Average Loss: 1.8709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2080

Learning rate: 9.870866934849235e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 726 [0/90000 (0%)]	Loss: 4.3280	Cost: 38.81s
Train Epoch: 726 [20480/90000 (23%)]	Loss: 1.7571	Cost: 12.83s
Train Epoch: 726 [40960/90000 (45%)]	Loss: 1.9341	Cost: 12.91s
Train Epoch: 726 [61440/90000 (68%)]	Loss: 1.6272	Cost: 12.22s
Train Epoch: 726 [81920/90000 (91%)]	Loss: 1.7483	Cost: 7.62s
Train Epoch: 726 	Average Loss: 1.9101
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1879

Learning rate: 9.870512006686839e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 727 [0/90000 (0%)]	Loss: 4.2870	Cost: 28.75s
Train Epoch: 727 [20480/90000 (23%)]	Loss: 1.7064	Cost: 12.65s
Train Epoch: 727 [40960/90000 (45%)]	Loss: 1.8909	Cost: 12.57s
Train Epoch: 727 [61440/90000 (68%)]	Loss: 2.3684	Cost: 9.74s
Train Epoch: 727 [81920/90000 (91%)]	Loss: 2.3042	Cost: 6.36s
Train Epoch: 727 	Average Loss: 2.1894
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5852

Learning rate: 9.870156597824179e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 728 [0/90000 (0%)]	Loss: 4.1715	Cost: 27.41s
Train Epoch: 728 [20480/90000 (23%)]	Loss: 2.0004	Cost: 11.96s
Train Epoch: 728 [40960/90000 (45%)]	Loss: 1.7360	Cost: 6.50s
Train Epoch: 728 [61440/90000 (68%)]	Loss: 1.6751	Cost: 6.24s
Train Epoch: 728 [81920/90000 (91%)]	Loss: 1.8577	Cost: 8.30s
Train Epoch: 728 	Average Loss: 2.0747
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1770

Learning rate: 9.869800708296334e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 729 [0/90000 (0%)]	Loss: 3.9412	Cost: 22.59s
Train Epoch: 729 [20480/90000 (23%)]	Loss: 1.6705	Cost: 6.72s
Train Epoch: 729 [40960/90000 (45%)]	Loss: 1.6246	Cost: 8.58s
Train Epoch: 729 [61440/90000 (68%)]	Loss: 1.4788	Cost: 8.89s
Train Epoch: 729 [81920/90000 (91%)]	Loss: 1.6796	Cost: 9.07s
Train Epoch: 729 	Average Loss: 1.7871
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1115

Learning rate: 9.869444338138427e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 730 [0/90000 (0%)]	Loss: 4.0482	Cost: 24.86s
Train Epoch: 730 [20480/90000 (23%)]	Loss: 1.5560	Cost: 10.69s
Train Epoch: 730 [40960/90000 (45%)]	Loss: 1.6289	Cost: 9.22s
Train Epoch: 730 [61440/90000 (68%)]	Loss: 1.3200	Cost: 8.63s
Train Epoch: 730 [81920/90000 (91%)]	Loss: 1.5559	Cost: 6.50s
Train Epoch: 730 	Average Loss: 1.7266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0528

Saving model as e730_model.pt & e730_waveforms_supplementary.hdf5
Learning rate: 9.869087487385631e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 731 [0/90000 (0%)]	Loss: 4.2745	Cost: 23.93s
Train Epoch: 731 [20480/90000 (23%)]	Loss: 1.6050	Cost: 10.37s
Train Epoch: 731 [40960/90000 (45%)]	Loss: 1.4598	Cost: 7.97s
Train Epoch: 731 [61440/90000 (68%)]	Loss: 1.3328	Cost: 6.53s
Train Epoch: 731 [81920/90000 (91%)]	Loss: 1.4838	Cost: 6.75s
Train Epoch: 731 	Average Loss: 1.7294
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0503

Saving model as e731_model.pt & e731_waveforms_supplementary.hdf5
Learning rate: 9.868730156073167e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 732 [0/90000 (0%)]	Loss: 3.7299	Cost: 22.23s
Train Epoch: 732 [20480/90000 (23%)]	Loss: 1.6578	Cost: 8.98s
Train Epoch: 732 [40960/90000 (45%)]	Loss: 1.6305	Cost: 17.12s
Train Epoch: 732 [61440/90000 (68%)]	Loss: 1.5224	Cost: 12.71s
Train Epoch: 732 [81920/90000 (91%)]	Loss: 1.4847	Cost: 12.32s
Train Epoch: 732 	Average Loss: 1.6784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9473

Saving model as e732_model.pt & e732_waveforms_supplementary.hdf5
Learning rate: 9.8683723442363e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 733 [0/90000 (0%)]	Loss: 3.7403	Cost: 25.86s
Train Epoch: 733 [20480/90000 (23%)]	Loss: 1.6273	Cost: 13.80s
Train Epoch: 733 [40960/90000 (45%)]	Loss: 1.5425	Cost: 12.50s
Train Epoch: 733 [61440/90000 (68%)]	Loss: 1.5992	Cost: 12.57s
Train Epoch: 733 [81920/90000 (91%)]	Loss: 1.7323	Cost: 9.29s
Train Epoch: 733 	Average Loss: 1.7428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1847

Learning rate: 9.868014051910347e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 734 [0/90000 (0%)]	Loss: 4.0997	Cost: 25.46s
Train Epoch: 734 [20480/90000 (23%)]	Loss: 1.5621	Cost: 12.47s
Train Epoch: 734 [40960/90000 (45%)]	Loss: 1.5262	Cost: 12.33s
Train Epoch: 734 [61440/90000 (68%)]	Loss: 1.4402	Cost: 10.50s
Train Epoch: 734 [81920/90000 (91%)]	Loss: 1.4919	Cost: 6.61s
Train Epoch: 734 	Average Loss: 1.7004
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0077

Learning rate: 9.86765527913067e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 735 [0/90000 (0%)]	Loss: 3.9539	Cost: 24.28s
Train Epoch: 735 [20480/90000 (23%)]	Loss: 1.7768	Cost: 12.93s
Train Epoch: 735 [40960/90000 (45%)]	Loss: 1.8408	Cost: 8.35s
Train Epoch: 735 [61440/90000 (68%)]	Loss: 1.6605	Cost: 6.44s
Train Epoch: 735 [81920/90000 (91%)]	Loss: 1.7860	Cost: 7.40s
Train Epoch: 735 	Average Loss: 1.8824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2351

Learning rate: 9.867296025932675e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 736 [0/90000 (0%)]	Loss: 4.5377	Cost: 31.80s
Train Epoch: 736 [20480/90000 (23%)]	Loss: 1.6397	Cost: 8.50s
Train Epoch: 736 [40960/90000 (45%)]	Loss: 1.5961	Cost: 7.57s
Train Epoch: 736 [61440/90000 (68%)]	Loss: 1.3071	Cost: 8.81s
Train Epoch: 736 [81920/90000 (91%)]	Loss: 1.6788	Cost: 8.60s
Train Epoch: 736 	Average Loss: 1.7386
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0366

Learning rate: 9.866936292351822e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 737 [0/90000 (0%)]	Loss: 3.6381	Cost: 31.01s
Train Epoch: 737 [20480/90000 (23%)]	Loss: 1.5223	Cost: 8.79s
Train Epoch: 737 [40960/90000 (45%)]	Loss: 1.4862	Cost: 8.84s
Train Epoch: 737 [61440/90000 (68%)]	Loss: 1.3052	Cost: 8.67s
Train Epoch: 737 [81920/90000 (91%)]	Loss: 1.6047	Cost: 7.03s
Train Epoch: 737 	Average Loss: 1.5963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9247

Saving model as e737_model.pt & e737_waveforms_supplementary.hdf5
Learning rate: 9.866576078423615e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 738 [0/90000 (0%)]	Loss: 3.9255	Cost: 21.00s
Train Epoch: 738 [20480/90000 (23%)]	Loss: 1.3812	Cost: 8.07s
Train Epoch: 738 [40960/90000 (45%)]	Loss: 1.4252	Cost: 13.12s
Train Epoch: 738 [61440/90000 (68%)]	Loss: 1.2641	Cost: 12.52s
Train Epoch: 738 [81920/90000 (91%)]	Loss: 1.3982	Cost: 13.43s
Train Epoch: 738 	Average Loss: 1.5392
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9517

Learning rate: 9.866215384183606e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 739 [0/90000 (0%)]	Loss: 3.5917	Cost: 25.62s
Train Epoch: 739 [20480/90000 (23%)]	Loss: 1.4783	Cost: 12.51s
Train Epoch: 739 [40960/90000 (45%)]	Loss: 1.3115	Cost: 14.41s
Train Epoch: 739 [61440/90000 (68%)]	Loss: 1.1954	Cost: 12.49s
Train Epoch: 739 [81920/90000 (91%)]	Loss: 1.3777	Cost: 11.09s
Train Epoch: 739 	Average Loss: 1.5604
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9858

Learning rate: 9.865854209667392e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 740 [0/90000 (0%)]	Loss: 3.9083	Cost: 26.24s
Train Epoch: 740 [20480/90000 (23%)]	Loss: 1.6216	Cost: 14.26s
Train Epoch: 740 [40960/90000 (45%)]	Loss: 1.4590	Cost: 12.29s
Train Epoch: 740 [61440/90000 (68%)]	Loss: 1.3214	Cost: 8.76s
Train Epoch: 740 [81920/90000 (91%)]	Loss: 1.5740	Cost: 6.06s
Train Epoch: 740 	Average Loss: 1.6330
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9669

Learning rate: 9.865492554910621e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 741 [0/90000 (0%)]	Loss: 3.9929	Cost: 36.05s
Train Epoch: 741 [20480/90000 (23%)]	Loss: 1.6349	Cost: 6.32s
Train Epoch: 741 [40960/90000 (45%)]	Loss: 1.5337	Cost: 9.66s
Train Epoch: 741 [61440/90000 (68%)]	Loss: 1.1369	Cost: 8.75s
Train Epoch: 741 [81920/90000 (91%)]	Loss: 1.3296	Cost: 8.54s
Train Epoch: 741 	Average Loss: 1.5453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9225

Saving model as e741_model.pt & e741_waveforms_supplementary.hdf5
Learning rate: 9.865130419948984e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 742 [0/90000 (0%)]	Loss: 4.0727	Cost: 23.76s
Train Epoch: 742 [20480/90000 (23%)]	Loss: 1.2700	Cost: 9.07s
Train Epoch: 742 [40960/90000 (45%)]	Loss: 1.5372	Cost: 9.04s
Train Epoch: 742 [61440/90000 (68%)]	Loss: 1.2539	Cost: 8.67s
Train Epoch: 742 [81920/90000 (91%)]	Loss: 1.4716	Cost: 5.75s
Train Epoch: 742 	Average Loss: 1.5479
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8280

Saving model as e742_model.pt & e742_waveforms_supplementary.hdf5
Learning rate: 9.864767804818229e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 743 [0/90000 (0%)]	Loss: 3.9790	Cost: 20.39s
Train Epoch: 743 [20480/90000 (23%)]	Loss: 1.3318	Cost: 9.98s
Train Epoch: 743 [40960/90000 (45%)]	Loss: 1.3016	Cost: 9.54s
Train Epoch: 743 [61440/90000 (68%)]	Loss: 1.1636	Cost: 12.94s
Train Epoch: 743 [81920/90000 (91%)]	Loss: 1.3703	Cost: 14.53s
Train Epoch: 743 	Average Loss: 1.4475
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8512

Learning rate: 9.864404709554137e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 744 [0/90000 (0%)]	Loss: 3.7761	Cost: 23.86s
Train Epoch: 744 [20480/90000 (23%)]	Loss: 1.2691	Cost: 12.25s
Train Epoch: 744 [40960/90000 (45%)]	Loss: 1.2631	Cost: 13.28s
Train Epoch: 744 [61440/90000 (68%)]	Loss: 1.2051	Cost: 12.72s
Train Epoch: 744 [81920/90000 (91%)]	Loss: 1.1922	Cost: 12.47s
Train Epoch: 744 	Average Loss: 1.4399
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8806

Learning rate: 9.864041134192549e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 745 [0/90000 (0%)]	Loss: 3.5300	Cost: 27.73s
Train Epoch: 745 [20480/90000 (23%)]	Loss: 1.3104	Cost: 11.85s
Train Epoch: 745 [40960/90000 (45%)]	Loss: 1.3622	Cost: 12.99s
Train Epoch: 745 [61440/90000 (68%)]	Loss: 1.3180	Cost: 12.11s
Train Epoch: 745 [81920/90000 (91%)]	Loss: 1.4677	Cost: 8.12s
Train Epoch: 745 	Average Loss: 1.5241
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8315

Learning rate: 9.863677078769347e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 746 [0/90000 (0%)]	Loss: 3.8297	Cost: 39.07s
Train Epoch: 746 [20480/90000 (23%)]	Loss: 1.2906	Cost: 12.02s
Train Epoch: 746 [40960/90000 (45%)]	Loss: 1.3105	Cost: 11.41s
Train Epoch: 746 [61440/90000 (68%)]	Loss: 1.1281	Cost: 6.02s
Train Epoch: 746 [81920/90000 (91%)]	Loss: 1.3071	Cost: 6.56s
Train Epoch: 746 	Average Loss: 1.4138
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8440

Learning rate: 9.863312543320462e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 747 [0/90000 (0%)]	Loss: 4.0716	Cost: 38.03s
Train Epoch: 747 [20480/90000 (23%)]	Loss: 1.3944	Cost: 11.94s
Train Epoch: 747 [40960/90000 (45%)]	Loss: 1.3154	Cost: 7.93s
Train Epoch: 747 [61440/90000 (68%)]	Loss: 1.2706	Cost: 6.13s
Train Epoch: 747 [81920/90000 (91%)]	Loss: 1.4073	Cost: 7.64s
Train Epoch: 747 	Average Loss: 1.4697
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7001

Saving model as e747_model.pt & e747_waveforms_supplementary.hdf5
Learning rate: 9.862947527881872e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 748 [0/90000 (0%)]	Loss: 3.7169	Cost: 19.78s
Train Epoch: 748 [20480/90000 (23%)]	Loss: 1.2172	Cost: 6.60s
Train Epoch: 748 [40960/90000 (45%)]	Loss: 1.2578	Cost: 10.94s
Train Epoch: 748 [61440/90000 (68%)]	Loss: 0.9739	Cost: 8.83s
Train Epoch: 748 [81920/90000 (91%)]	Loss: 1.2929	Cost: 9.39s
Train Epoch: 748 	Average Loss: 1.3515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7905

Learning rate: 9.862582032489604e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 749 [0/90000 (0%)]	Loss: 3.7417	Cost: 21.18s
Train Epoch: 749 [20480/90000 (23%)]	Loss: 1.2647	Cost: 8.93s
Train Epoch: 749 [40960/90000 (45%)]	Loss: 1.3290	Cost: 9.13s
Train Epoch: 749 [61440/90000 (68%)]	Loss: 1.1154	Cost: 9.23s
Train Epoch: 749 [81920/90000 (91%)]	Loss: 1.2609	Cost: 6.79s
Train Epoch: 749 	Average Loss: 1.3826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8948

Learning rate: 9.862216057179729e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 750 [0/90000 (0%)]	Loss: 4.0083	Cost: 23.41s
Train Epoch: 750 [20480/90000 (23%)]	Loss: 1.3093	Cost: 10.41s
Train Epoch: 750 [40960/90000 (45%)]	Loss: 1.4171	Cost: 9.24s
Train Epoch: 750 [61440/90000 (68%)]	Loss: 1.2151	Cost: 10.92s
Train Epoch: 750 [81920/90000 (91%)]	Loss: 1.2789	Cost: 12.42s
Train Epoch: 750 	Average Loss: 1.4456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8782

Learning rate: 9.861849601988368e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 751 [0/90000 (0%)]	Loss: 4.0077	Cost: 30.88s
Train Epoch: 751 [20480/90000 (23%)]	Loss: 1.1884	Cost: 9.72s
Train Epoch: 751 [40960/90000 (45%)]	Loss: 1.4616	Cost: 12.40s
Train Epoch: 751 [61440/90000 (68%)]	Loss: 1.0859	Cost: 12.37s
Train Epoch: 751 [81920/90000 (91%)]	Loss: 1.2340	Cost: 12.10s
Train Epoch: 751 	Average Loss: 1.4015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8511

Learning rate: 9.86148266695169e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 752 [0/90000 (0%)]	Loss: 3.8104	Cost: 25.27s
Train Epoch: 752 [20480/90000 (23%)]	Loss: 1.1752	Cost: 12.30s
Train Epoch: 752 [40960/90000 (45%)]	Loss: 1.0829	Cost: 12.58s
Train Epoch: 752 [61440/90000 (68%)]	Loss: 1.2149	Cost: 12.49s
Train Epoch: 752 [81920/90000 (91%)]	Loss: 1.2340	Cost: 12.18s
Train Epoch: 752 	Average Loss: 1.3703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8090

Learning rate: 9.861115252105906e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 753 [0/90000 (0%)]	Loss: 3.5909	Cost: 39.00s
Train Epoch: 753 [20480/90000 (23%)]	Loss: 1.2326	Cost: 13.13s
Train Epoch: 753 [40960/90000 (45%)]	Loss: 1.2871	Cost: 12.40s
Train Epoch: 753 [61440/90000 (68%)]	Loss: 0.9967	Cost: 11.79s
Train Epoch: 753 [81920/90000 (91%)]	Loss: 1.2791	Cost: 6.02s
Train Epoch: 753 	Average Loss: 1.3376
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7649

Learning rate: 9.860747357487283e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 754 [0/90000 (0%)]	Loss: 3.7657	Cost: 31.41s
Train Epoch: 754 [20480/90000 (23%)]	Loss: 1.1858	Cost: 13.53s
Train Epoch: 754 [40960/90000 (45%)]	Loss: 1.1250	Cost: 13.10s
Train Epoch: 754 [61440/90000 (68%)]	Loss: 0.9109	Cost: 6.27s
Train Epoch: 754 [81920/90000 (91%)]	Loss: 1.3909	Cost: 6.14s
Train Epoch: 754 	Average Loss: 1.3308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9275

Learning rate: 9.860378983132128e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 755 [0/90000 (0%)]	Loss: 4.0229	Cost: 26.45s
Train Epoch: 755 [20480/90000 (23%)]	Loss: 1.2395	Cost: 10.43s
Train Epoch: 755 [40960/90000 (45%)]	Loss: 1.4007	Cost: 6.46s
Train Epoch: 755 [61440/90000 (68%)]	Loss: 1.1613	Cost: 6.33s
Train Epoch: 755 [81920/90000 (91%)]	Loss: 1.2657	Cost: 8.54s
Train Epoch: 755 	Average Loss: 1.5045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9630

Learning rate: 9.860010129076798e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 756 [0/90000 (0%)]	Loss: 3.9580	Cost: 24.87s
Train Epoch: 756 [20480/90000 (23%)]	Loss: 1.3145	Cost: 6.58s
Train Epoch: 756 [40960/90000 (45%)]	Loss: 1.3947	Cost: 9.35s
Train Epoch: 756 [61440/90000 (68%)]	Loss: 1.1281	Cost: 9.04s
Train Epoch: 756 [81920/90000 (91%)]	Loss: 1.4510	Cost: 8.91s
Train Epoch: 756 	Average Loss: 1.4430
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8152

Learning rate: 9.8596407953577e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 757 [0/90000 (0%)]	Loss: 3.7195	Cost: 23.03s
Train Epoch: 757 [20480/90000 (23%)]	Loss: 1.2416	Cost: 9.36s
Train Epoch: 757 [40960/90000 (45%)]	Loss: 1.2134	Cost: 8.89s
Train Epoch: 757 [61440/90000 (68%)]	Loss: 1.1124	Cost: 8.61s
Train Epoch: 757 [81920/90000 (91%)]	Loss: 1.1488	Cost: 8.43s
Train Epoch: 757 	Average Loss: 1.3609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7814

Learning rate: 9.859270982011284e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 758 [0/90000 (0%)]	Loss: 3.9582	Cost: 22.36s
Train Epoch: 758 [20480/90000 (23%)]	Loss: 1.0608	Cost: 7.49s
Train Epoch: 758 [40960/90000 (45%)]	Loss: 1.2101	Cost: 13.18s
Train Epoch: 758 [61440/90000 (68%)]	Loss: 1.0694	Cost: 9.72s
Train Epoch: 758 [81920/90000 (91%)]	Loss: 1.2565	Cost: 15.11s
Train Epoch: 758 	Average Loss: 1.3376
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7925

Learning rate: 9.858900689074049e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 759 [0/90000 (0%)]	Loss: 3.5612	Cost: 19.02s
Train Epoch: 759 [20480/90000 (23%)]	Loss: 1.1418	Cost: 6.40s
Train Epoch: 759 [40960/90000 (45%)]	Loss: 1.1389	Cost: 16.03s
Train Epoch: 759 [61440/90000 (68%)]	Loss: 1.0386	Cost: 13.70s
Train Epoch: 759 [81920/90000 (91%)]	Loss: 1.2064	Cost: 13.57s
Train Epoch: 759 	Average Loss: 1.2397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7881

Learning rate: 9.85852991658254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 760 [0/90000 (0%)]	Loss: 3.7186	Cost: 26.19s
Train Epoch: 760 [20480/90000 (23%)]	Loss: 1.1849	Cost: 15.44s
Train Epoch: 760 [40960/90000 (45%)]	Loss: 1.1358	Cost: 13.42s
Train Epoch: 760 [61440/90000 (68%)]	Loss: 1.1560	Cost: 11.62s
Train Epoch: 760 [81920/90000 (91%)]	Loss: 1.3486	Cost: 12.32s
Train Epoch: 760 	Average Loss: 1.3147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7456

Learning rate: 9.858158664573355e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 761 [0/90000 (0%)]	Loss: 3.9175	Cost: 29.71s
Train Epoch: 761 [20480/90000 (23%)]	Loss: 1.0600	Cost: 12.04s
Train Epoch: 761 [40960/90000 (45%)]	Loss: 1.1388	Cost: 12.42s
Train Epoch: 761 [61440/90000 (68%)]	Loss: 1.1351	Cost: 11.21s
Train Epoch: 761 [81920/90000 (91%)]	Loss: 1.1355	Cost: 6.00s
Train Epoch: 761 	Average Loss: 1.3137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6660

Saving model as e761_model.pt & e761_waveforms_supplementary.hdf5
Learning rate: 9.857786933083131e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 762 [0/90000 (0%)]	Loss: 3.4337	Cost: 23.82s
Train Epoch: 762 [20480/90000 (23%)]	Loss: 1.2649	Cost: 7.10s
Train Epoch: 762 [40960/90000 (45%)]	Loss: 0.9614	Cost: 6.85s
Train Epoch: 762 [61440/90000 (68%)]	Loss: 0.8751	Cost: 7.35s
Train Epoch: 762 [81920/90000 (91%)]	Loss: 0.9188	Cost: 8.92s
Train Epoch: 762 	Average Loss: 1.1753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5778

Saving model as e762_model.pt & e762_waveforms_supplementary.hdf5
Learning rate: 9.85741472214856e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 763 [0/90000 (0%)]	Loss: 3.7196	Cost: 23.49s
Train Epoch: 763 [20480/90000 (23%)]	Loss: 0.9252	Cost: 9.72s
Train Epoch: 763 [40960/90000 (45%)]	Loss: 0.9678	Cost: 9.24s
Train Epoch: 763 [61440/90000 (68%)]	Loss: 0.9778	Cost: 8.77s
Train Epoch: 763 [81920/90000 (91%)]	Loss: 0.9898	Cost: 8.65s
Train Epoch: 763 	Average Loss: 1.1243
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6481

Learning rate: 9.857042031806373e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 764 [0/90000 (0%)]	Loss: 3.4589	Cost: 25.52s
Train Epoch: 764 [20480/90000 (23%)]	Loss: 1.0023	Cost: 10.99s
Train Epoch: 764 [40960/90000 (45%)]	Loss: 0.9572	Cost: 9.12s
Train Epoch: 764 [61440/90000 (68%)]	Loss: 0.8839	Cost: 8.74s
Train Epoch: 764 [81920/90000 (91%)]	Loss: 1.1175	Cost: 6.88s
Train Epoch: 764 	Average Loss: 1.1554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6908

Learning rate: 9.856668862093358e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 765 [0/90000 (0%)]	Loss: 3.9576	Cost: 19.19s
Train Epoch: 765 [20480/90000 (23%)]	Loss: 0.9555	Cost: 7.35s
Train Epoch: 765 [40960/90000 (45%)]	Loss: 1.4314	Cost: 9.48s
Train Epoch: 765 [61440/90000 (68%)]	Loss: 1.2049	Cost: 8.62s
Train Epoch: 765 [81920/90000 (91%)]	Loss: 1.5230	Cost: 15.25s
Train Epoch: 765 	Average Loss: 1.3834
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0186

Learning rate: 9.856295213046343e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 766 [0/90000 (0%)]	Loss: 3.6041	Cost: 21.68s
Train Epoch: 766 [20480/90000 (23%)]	Loss: 1.1557	Cost: 9.34s
Train Epoch: 766 [40960/90000 (45%)]	Loss: 1.2601	Cost: 12.24s
Train Epoch: 766 [61440/90000 (68%)]	Loss: 1.0763	Cost: 12.37s
Train Epoch: 766 [81920/90000 (91%)]	Loss: 1.2938	Cost: 12.41s
Train Epoch: 766 	Average Loss: 1.3745
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7175

Learning rate: 9.855921084702205e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 767 [0/90000 (0%)]	Loss: 3.7043	Cost: 24.48s
Train Epoch: 767 [20480/90000 (23%)]	Loss: 1.1211	Cost: 14.32s
Train Epoch: 767 [40960/90000 (45%)]	Loss: 1.0753	Cost: 14.23s
Train Epoch: 767 [61440/90000 (68%)]	Loss: 0.9624	Cost: 12.29s
Train Epoch: 767 [81920/90000 (91%)]	Loss: 1.1281	Cost: 10.67s
Train Epoch: 767 	Average Loss: 1.2162
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6166

Learning rate: 9.85554647709787e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 768 [0/90000 (0%)]	Loss: 3.5972	Cost: 44.81s
Train Epoch: 768 [20480/90000 (23%)]	Loss: 1.4036	Cost: 11.35s
Train Epoch: 768 [40960/90000 (45%)]	Loss: 1.2724	Cost: 9.04s
Train Epoch: 768 [61440/90000 (68%)]	Loss: 1.1768	Cost: 6.29s
Train Epoch: 768 [81920/90000 (91%)]	Loss: 1.2533	Cost: 7.92s
Train Epoch: 768 	Average Loss: 1.4701
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7708

Learning rate: 9.85517139027031e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 769 [0/90000 (0%)]	Loss: 3.6860	Cost: 32.22s
Train Epoch: 769 [20480/90000 (23%)]	Loss: 1.0043	Cost: 6.55s
Train Epoch: 769 [40960/90000 (45%)]	Loss: 1.1717	Cost: 10.47s
Train Epoch: 769 [61440/90000 (68%)]	Loss: 0.8991	Cost: 8.85s
Train Epoch: 769 [81920/90000 (91%)]	Loss: 1.0294	Cost: 8.53s
Train Epoch: 769 	Average Loss: 1.2158
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6390

Learning rate: 9.854795824256546e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 770 [0/90000 (0%)]	Loss: 3.4359	Cost: 21.27s
Train Epoch: 770 [20480/90000 (23%)]	Loss: 1.0029	Cost: 9.60s
Train Epoch: 770 [40960/90000 (45%)]	Loss: 1.0821	Cost: 8.85s
Train Epoch: 770 [61440/90000 (68%)]	Loss: 1.0412	Cost: 8.76s
Train Epoch: 770 [81920/90000 (91%)]	Loss: 1.1534	Cost: 7.39s
Train Epoch: 770 	Average Loss: 1.1890
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5997

Learning rate: 9.854419779093642e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 771 [0/90000 (0%)]	Loss: 3.5619	Cost: 18.10s
Train Epoch: 771 [20480/90000 (23%)]	Loss: 0.9961	Cost: 7.24s
Train Epoch: 771 [40960/90000 (45%)]	Loss: 0.6882	Cost: 13.45s
Train Epoch: 771 [61440/90000 (68%)]	Loss: 0.8497	Cost: 14.52s
Train Epoch: 771 [81920/90000 (91%)]	Loss: 1.1173	Cost: 14.46s
Train Epoch: 771 	Average Loss: 1.1141
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5903

Learning rate: 9.854043254818714e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 772 [0/90000 (0%)]	Loss: 3.7254	Cost: 25.30s
Train Epoch: 772 [20480/90000 (23%)]	Loss: 0.9907	Cost: 15.28s
Train Epoch: 772 [40960/90000 (45%)]	Loss: 1.1588	Cost: 13.66s
Train Epoch: 772 [61440/90000 (68%)]	Loss: 0.9769	Cost: 11.91s
Train Epoch: 772 [81920/90000 (91%)]	Loss: 1.1341	Cost: 12.07s
Train Epoch: 772 	Average Loss: 1.1998
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5694

Saving model as e772_model.pt & e772_waveforms_supplementary.hdf5
Learning rate: 9.853666251468923e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 773 [0/90000 (0%)]	Loss: 3.6249	Cost: 32.06s
Train Epoch: 773 [20480/90000 (23%)]	Loss: 0.8568	Cost: 12.83s
Train Epoch: 773 [40960/90000 (45%)]	Loss: 0.8508	Cost: 12.16s
Train Epoch: 773 [61440/90000 (68%)]	Loss: 0.7161	Cost: 7.57s
Train Epoch: 773 [81920/90000 (91%)]	Loss: 0.9385	Cost: 5.98s
Train Epoch: 773 	Average Loss: 1.0441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6858

Learning rate: 9.853288769081479e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 774 [0/90000 (0%)]	Loss: 3.6009	Cost: 22.97s
Train Epoch: 774 [20480/90000 (23%)]	Loss: 0.9140	Cost: 6.64s
Train Epoch: 774 [40960/90000 (45%)]	Loss: 0.7936	Cost: 9.53s
Train Epoch: 774 [61440/90000 (68%)]	Loss: 0.8073	Cost: 8.70s
Train Epoch: 774 [81920/90000 (91%)]	Loss: 0.8920	Cost: 9.04s
Train Epoch: 774 	Average Loss: 1.0917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6134

Learning rate: 9.852910807693636e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 775 [0/90000 (0%)]	Loss: 3.6373	Cost: 28.88s
Train Epoch: 775 [20480/90000 (23%)]	Loss: 0.8973	Cost: 9.97s
Train Epoch: 775 [40960/90000 (45%)]	Loss: 0.8579	Cost: 8.95s
Train Epoch: 775 [61440/90000 (68%)]	Loss: 0.7990	Cost: 8.66s
Train Epoch: 775 [81920/90000 (91%)]	Loss: 0.9912	Cost: 7.95s
Train Epoch: 775 	Average Loss: 1.0640
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6532

Learning rate: 9.8525323673427e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 776 [0/90000 (0%)]	Loss: 3.6889	Cost: 33.24s
Train Epoch: 776 [20480/90000 (23%)]	Loss: 0.8937	Cost: 6.88s
Train Epoch: 776 [40960/90000 (45%)]	Loss: 0.7343	Cost: 11.04s
Train Epoch: 776 [61440/90000 (68%)]	Loss: 0.8261	Cost: 10.05s
Train Epoch: 776 [81920/90000 (91%)]	Loss: 0.8432	Cost: 12.42s
Train Epoch: 776 	Average Loss: 1.0296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6307

Learning rate: 9.85215344806602e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 777 [0/90000 (0%)]	Loss: 3.3858	Cost: 21.42s
Train Epoch: 777 [20480/90000 (23%)]	Loss: 0.8407	Cost: 10.09s
Train Epoch: 777 [40960/90000 (45%)]	Loss: 0.8045	Cost: 15.07s
Train Epoch: 777 [61440/90000 (68%)]	Loss: 0.7011	Cost: 12.82s
Train Epoch: 777 [81920/90000 (91%)]	Loss: 1.1954	Cost: 12.50s
Train Epoch: 777 	Average Loss: 1.0127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0039

Learning rate: 9.851774049900992e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 778 [0/90000 (0%)]	Loss: 3.9120	Cost: 27.59s
Train Epoch: 778 [20480/90000 (23%)]	Loss: 1.3692	Cost: 12.22s
Train Epoch: 778 [40960/90000 (45%)]	Loss: 1.1355	Cost: 14.26s
Train Epoch: 778 [61440/90000 (68%)]	Loss: 1.2019	Cost: 12.61s
Train Epoch: 778 [81920/90000 (91%)]	Loss: 1.4289	Cost: 8.78s
Train Epoch: 778 	Average Loss: 1.4429
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8198

Learning rate: 9.851394172885063e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 779 [0/90000 (0%)]	Loss: 3.7189	Cost: 25.64s
Train Epoch: 779 [20480/90000 (23%)]	Loss: 1.0521	Cost: 11.99s
Train Epoch: 779 [40960/90000 (45%)]	Loss: 1.0741	Cost: 11.29s
Train Epoch: 779 [61440/90000 (68%)]	Loss: 0.7939	Cost: 6.24s
Train Epoch: 779 [81920/90000 (91%)]	Loss: 0.8024	Cost: 6.54s
Train Epoch: 779 	Average Loss: 1.1296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4564

Saving model as e779_model.pt & e779_waveforms_supplementary.hdf5
Learning rate: 9.851013817055725e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 780 [0/90000 (0%)]	Loss: 3.1436	Cost: 26.60s
Train Epoch: 780 [20480/90000 (23%)]	Loss: 0.8801	Cost: 7.25s
Train Epoch: 780 [40960/90000 (45%)]	Loss: 0.7246	Cost: 9.80s
Train Epoch: 780 [61440/90000 (68%)]	Loss: 0.8417	Cost: 8.77s
Train Epoch: 780 [81920/90000 (91%)]	Loss: 0.9649	Cost: 8.52s
Train Epoch: 780 	Average Loss: 1.0499
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6484

Learning rate: 9.850632982450517e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 781 [0/90000 (0%)]	Loss: 3.4080	Cost: 31.21s
Train Epoch: 781 [20480/90000 (23%)]	Loss: 1.0078	Cost: 8.81s
Train Epoch: 781 [40960/90000 (45%)]	Loss: 0.8131	Cost: 8.90s
Train Epoch: 781 [61440/90000 (68%)]	Loss: 0.6960	Cost: 8.81s
Train Epoch: 781 [81920/90000 (91%)]	Loss: 0.8810	Cost: 6.39s
Train Epoch: 781 	Average Loss: 1.0378
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6430

Learning rate: 9.850251669107029e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 782 [0/90000 (0%)]	Loss: 3.5993	Cost: 22.11s
Train Epoch: 782 [20480/90000 (23%)]	Loss: 0.8484	Cost: 6.70s
Train Epoch: 782 [40960/90000 (45%)]	Loss: 0.8945	Cost: 8.77s
Train Epoch: 782 [61440/90000 (68%)]	Loss: 0.7559	Cost: 8.74s
Train Epoch: 782 [81920/90000 (91%)]	Loss: 0.9105	Cost: 13.04s
Train Epoch: 782 	Average Loss: 1.0332
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5864

Learning rate: 9.84986987706289e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 783 [0/90000 (0%)]	Loss: 3.2508	Cost: 22.44s
Train Epoch: 783 [20480/90000 (23%)]	Loss: 0.8378	Cost: 10.43s
Train Epoch: 783 [40960/90000 (45%)]	Loss: 0.7837	Cost: 14.17s
Train Epoch: 783 [61440/90000 (68%)]	Loss: 0.6307	Cost: 13.56s
Train Epoch: 783 [81920/90000 (91%)]	Loss: 0.7768	Cost: 12.47s
Train Epoch: 783 	Average Loss: 0.9416
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4383

Saving model as e783_model.pt & e783_waveforms_supplementary.hdf5
Learning rate: 9.849487606355786e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 784 [0/90000 (0%)]	Loss: 3.7071	Cost: 33.07s
Train Epoch: 784 [20480/90000 (23%)]	Loss: 0.7944	Cost: 14.73s
Train Epoch: 784 [40960/90000 (45%)]	Loss: 0.6202	Cost: 13.75s
Train Epoch: 784 [61440/90000 (68%)]	Loss: 0.6115	Cost: 12.35s
Train Epoch: 784 [81920/90000 (91%)]	Loss: 0.8126	Cost: 9.50s
Train Epoch: 784 	Average Loss: 0.8705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5377

Learning rate: 9.849104857023443e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 785 [0/90000 (0%)]	Loss: 3.3165	Cost: 31.27s
Train Epoch: 785 [20480/90000 (23%)]	Loss: 0.7516	Cost: 12.63s
Train Epoch: 785 [40960/90000 (45%)]	Loss: 0.6946	Cost: 12.31s
Train Epoch: 785 [61440/90000 (68%)]	Loss: 0.6153	Cost: 9.60s
Train Epoch: 785 [81920/90000 (91%)]	Loss: 0.8493	Cost: 6.32s
Train Epoch: 785 	Average Loss: 0.9217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6161

Learning rate: 9.848721629103637e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 786 [0/90000 (0%)]	Loss: 3.3600	Cost: 25.28s
Train Epoch: 786 [20480/90000 (23%)]	Loss: 0.8016	Cost: 11.28s
Train Epoch: 786 [40960/90000 (45%)]	Loss: 0.6064	Cost: 12.10s
Train Epoch: 786 [61440/90000 (68%)]	Loss: 0.6912	Cost: 5.97s
Train Epoch: 786 [81920/90000 (91%)]	Loss: 0.8469	Cost: 6.14s
Train Epoch: 786 	Average Loss: 0.9298
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4904

Learning rate: 9.848337922634192e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 787 [0/90000 (0%)]	Loss: 3.5308	Cost: 29.56s
Train Epoch: 787 [20480/90000 (23%)]	Loss: 0.8297	Cost: 8.70s
Train Epoch: 787 [40960/90000 (45%)]	Loss: 0.8387	Cost: 6.35s
Train Epoch: 787 [61440/90000 (68%)]	Loss: 0.5347	Cost: 7.02s
Train Epoch: 787 [81920/90000 (91%)]	Loss: 0.8203	Cost: 8.64s
Train Epoch: 787 	Average Loss: 0.8527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4005

Saving model as e787_model.pt & e787_waveforms_supplementary.hdf5
Learning rate: 9.847953737652978e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 788 [0/90000 (0%)]	Loss: 3.3173	Cost: 28.70s
Train Epoch: 788 [20480/90000 (23%)]	Loss: 0.6097	Cost: 12.51s
Train Epoch: 788 [40960/90000 (45%)]	Loss: 0.5973	Cost: 10.48s
Train Epoch: 788 [61440/90000 (68%)]	Loss: 0.5160	Cost: 8.87s
Train Epoch: 788 [81920/90000 (91%)]	Loss: 0.6923	Cost: 7.29s
Train Epoch: 788 	Average Loss: 0.8073
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3810

Saving model as e788_model.pt & e788_waveforms_supplementary.hdf5
Learning rate: 9.847569074197914e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 789 [0/90000 (0%)]	Loss: 3.3432	Cost: 23.62s
Train Epoch: 789 [20480/90000 (23%)]	Loss: 0.6793	Cost: 7.62s
Train Epoch: 789 [40960/90000 (45%)]	Loss: 0.9552	Cost: 13.29s
Train Epoch: 789 [61440/90000 (68%)]	Loss: 0.7791	Cost: 10.10s
Train Epoch: 789 [81920/90000 (91%)]	Loss: 0.8657	Cost: 12.47s
Train Epoch: 789 	Average Loss: 0.9478
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4662

Learning rate: 9.847183932306961e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 790 [0/90000 (0%)]	Loss: 3.4854	Cost: 22.69s
Train Epoch: 790 [20480/90000 (23%)]	Loss: 0.6070	Cost: 9.61s
Train Epoch: 790 [40960/90000 (45%)]	Loss: 0.8363	Cost: 11.27s
Train Epoch: 790 [61440/90000 (68%)]	Loss: 0.7099	Cost: 12.56s
Train Epoch: 790 [81920/90000 (91%)]	Loss: 0.8285	Cost: 12.06s
Train Epoch: 790 	Average Loss: 0.9610
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5437

Learning rate: 9.846798312018134e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 791 [0/90000 (0%)]	Loss: 3.4843	Cost: 23.46s
Train Epoch: 791 [20480/90000 (23%)]	Loss: 0.7010	Cost: 13.18s
Train Epoch: 791 [40960/90000 (45%)]	Loss: 0.7524	Cost: 12.65s
Train Epoch: 791 [61440/90000 (68%)]	Loss: 0.4514	Cost: 12.08s
Train Epoch: 791 [81920/90000 (91%)]	Loss: 0.7341	Cost: 12.19s
Train Epoch: 791 	Average Loss: 0.8589
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4772

Learning rate: 9.846412213369493e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 792 [0/90000 (0%)]	Loss: 3.4230	Cost: 25.76s
Train Epoch: 792 [20480/90000 (23%)]	Loss: 0.7479	Cost: 11.98s
Train Epoch: 792 [40960/90000 (45%)]	Loss: 0.6452	Cost: 12.80s
Train Epoch: 792 [61440/90000 (68%)]	Loss: 0.4969	Cost: 12.20s
Train Epoch: 792 [81920/90000 (91%)]	Loss: 0.5295	Cost: 6.75s
Train Epoch: 792 	Average Loss: 0.8580
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3750

Saving model as e792_model.pt & e792_waveforms_supplementary.hdf5
Learning rate: 9.84602563639914e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 793 [0/90000 (0%)]	Loss: 3.3494	Cost: 38.37s
Train Epoch: 793 [20480/90000 (23%)]	Loss: 0.7094	Cost: 12.71s
Train Epoch: 793 [40960/90000 (45%)]	Loss: 0.6448	Cost: 8.22s
Train Epoch: 793 [61440/90000 (68%)]	Loss: 0.5416	Cost: 6.14s
Train Epoch: 793 [81920/90000 (91%)]	Loss: 0.6341	Cost: 7.87s
Train Epoch: 793 	Average Loss: 0.7927
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4865

Learning rate: 9.845638581145233e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 794 [0/90000 (0%)]	Loss: 3.1179	Cost: 22.33s
Train Epoch: 794 [20480/90000 (23%)]	Loss: 0.4166	Cost: 10.97s
Train Epoch: 794 [40960/90000 (45%)]	Loss: 0.5940	Cost: 9.86s
Train Epoch: 794 [61440/90000 (68%)]	Loss: 0.5172	Cost: 9.31s
Train Epoch: 794 [81920/90000 (91%)]	Loss: 0.6024	Cost: 8.74s
Train Epoch: 794 	Average Loss: 0.7250
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3727

Saving model as e794_model.pt & e794_waveforms_supplementary.hdf5
Learning rate: 9.845251047645971e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 795 [0/90000 (0%)]	Loss: 3.2025	Cost: 23.71s
Train Epoch: 795 [20480/90000 (23%)]	Loss: 0.5687	Cost: 9.10s
Train Epoch: 795 [40960/90000 (45%)]	Loss: 0.5040	Cost: 8.96s
Train Epoch: 795 [61440/90000 (68%)]	Loss: 0.4614	Cost: 8.20s
Train Epoch: 795 [81920/90000 (91%)]	Loss: 0.6436	Cost: 6.54s
Train Epoch: 795 	Average Loss: 0.6523
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1608

Saving model as e795_model.pt & e795_waveforms_supplementary.hdf5
Learning rate: 9.844863035939603e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 796 [0/90000 (0%)]	Loss: 3.2539	Cost: 19.11s
Train Epoch: 796 [20480/90000 (23%)]	Loss: 0.3307	Cost: 8.03s
Train Epoch: 796 [40960/90000 (45%)]	Loss: 0.6406	Cost: 9.87s
Train Epoch: 796 [61440/90000 (68%)]	Loss: 0.3770	Cost: 11.11s
Train Epoch: 796 [81920/90000 (91%)]	Loss: 0.4819	Cost: 12.30s
Train Epoch: 796 	Average Loss: 0.6501
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3156

Learning rate: 9.844474546064422e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 797 [0/90000 (0%)]	Loss: 3.1320	Cost: 24.49s
Train Epoch: 797 [20480/90000 (23%)]	Loss: 0.5713	Cost: 12.39s
Train Epoch: 797 [40960/90000 (45%)]	Loss: 0.4960	Cost: 12.81s
Train Epoch: 797 [61440/90000 (68%)]	Loss: 0.2346	Cost: 12.38s
Train Epoch: 797 [81920/90000 (91%)]	Loss: 0.6080	Cost: 12.40s
Train Epoch: 797 	Average Loss: 0.6467
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2470

Learning rate: 9.844085578058772e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 798 [0/90000 (0%)]	Loss: 3.5718	Cost: 30.49s
Train Epoch: 798 [20480/90000 (23%)]	Loss: 0.7739	Cost: 14.24s
Train Epoch: 798 [40960/90000 (45%)]	Loss: 0.7040	Cost: 13.33s
Train Epoch: 798 [61440/90000 (68%)]	Loss: 0.6228	Cost: 12.05s
Train Epoch: 798 [81920/90000 (91%)]	Loss: 0.5325	Cost: 8.33s
Train Epoch: 798 	Average Loss: 0.8263
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4429

Learning rate: 9.843696131961044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 799 [0/90000 (0%)]	Loss: 3.3699	Cost: 38.83s
Train Epoch: 799 [20480/90000 (23%)]	Loss: 0.4030	Cost: 12.95s
Train Epoch: 799 [40960/90000 (45%)]	Loss: 0.3286	Cost: 11.12s
Train Epoch: 799 [61440/90000 (68%)]	Loss: 0.2954	Cost: 6.69s
Train Epoch: 799 [81920/90000 (91%)]	Loss: 0.6500	Cost: 7.41s
Train Epoch: 799 	Average Loss: 0.6737
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3015

Learning rate: 9.843306207809673e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 800 [0/90000 (0%)]	Loss: 2.9498	Cost: 31.97s
Train Epoch: 800 [20480/90000 (23%)]	Loss: 0.6783	Cost: 9.20s
Train Epoch: 800 [40960/90000 (45%)]	Loss: 1.0708	Cost: 6.52s
Train Epoch: 800 [61440/90000 (68%)]	Loss: 0.6868	Cost: 8.07s
Train Epoch: 800 [81920/90000 (91%)]	Loss: 0.8605	Cost: 8.68s
Train Epoch: 800 	Average Loss: 0.9592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4169

Learning rate: 9.842915805643143e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 801 [0/90000 (0%)]	Loss: 3.5423	Cost: 21.68s
Train Epoch: 801 [20480/90000 (23%)]	Loss: 0.6440	Cost: 6.75s
Train Epoch: 801 [40960/90000 (45%)]	Loss: 0.5660	Cost: 9.30s
Train Epoch: 801 [61440/90000 (68%)]	Loss: 0.6505	Cost: 8.89s
Train Epoch: 801 [81920/90000 (91%)]	Loss: 0.7204	Cost: 8.45s
Train Epoch: 801 	Average Loss: 0.7820
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3869

Learning rate: 9.842524925499985e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 802 [0/90000 (0%)]	Loss: 3.2107	Cost: 23.20s
Train Epoch: 802 [20480/90000 (23%)]	Loss: 0.5217	Cost: 8.24s
Train Epoch: 802 [40960/90000 (45%)]	Loss: 0.3314	Cost: 9.08s
Train Epoch: 802 [61440/90000 (68%)]	Loss: 0.5478	Cost: 8.72s
Train Epoch: 802 [81920/90000 (91%)]	Loss: 0.6789	Cost: 8.46s
Train Epoch: 802 	Average Loss: 0.6565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3114

Learning rate: 9.842133567418779e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 803 [0/90000 (0%)]	Loss: 3.2431	Cost: 23.59s
Train Epoch: 803 [20480/90000 (23%)]	Loss: 0.5468	Cost: 12.13s
Train Epoch: 803 [40960/90000 (45%)]	Loss: 0.5053	Cost: 9.73s
Train Epoch: 803 [61440/90000 (68%)]	Loss: 0.2001	Cost: 7.48s
Train Epoch: 803 [81920/90000 (91%)]	Loss: 0.5934	Cost: 8.37s
Train Epoch: 803 	Average Loss: 0.6156
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3430

Learning rate: 9.841741731438147e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 804 [0/90000 (0%)]	Loss: 3.1535	Cost: 19.98s
Train Epoch: 804 [20480/90000 (23%)]	Loss: 0.6452	Cost: 9.62s
Train Epoch: 804 [40960/90000 (45%)]	Loss: 0.5697	Cost: 14.88s
Train Epoch: 804 [61440/90000 (68%)]	Loss: 0.1424	Cost: 13.40s
Train Epoch: 804 [81920/90000 (91%)]	Loss: 0.5556	Cost: 12.41s
Train Epoch: 804 	Average Loss: 0.6627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2151

Learning rate: 9.841349417596765e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 805 [0/90000 (0%)]	Loss: 3.2420	Cost: 33.39s
Train Epoch: 805 [20480/90000 (23%)]	Loss: 0.2023	Cost: 13.47s
Train Epoch: 805 [40960/90000 (45%)]	Loss: 0.3396	Cost: 12.67s
Train Epoch: 805 [61440/90000 (68%)]	Loss: 0.3801	Cost: 12.34s
Train Epoch: 805 [81920/90000 (91%)]	Loss: 0.5254	Cost: 12.25s
Train Epoch: 805 	Average Loss: 0.5735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4881

Learning rate: 9.840956625933353e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 806 [0/90000 (0%)]	Loss: 3.6631	Cost: 23.46s
Train Epoch: 806 [20480/90000 (23%)]	Loss: 0.6604	Cost: 13.94s
Train Epoch: 806 [40960/90000 (45%)]	Loss: 0.7656	Cost: 12.30s
Train Epoch: 806 [61440/90000 (68%)]	Loss: 0.5398	Cost: 9.04s
Train Epoch: 806 [81920/90000 (91%)]	Loss: 0.4540	Cost: 6.44s
Train Epoch: 806 	Average Loss: 0.7361
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2956

Learning rate: 9.840563356486677e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 807 [0/90000 (0%)]	Loss: 3.2503	Cost: 23.65s
Train Epoch: 807 [20480/90000 (23%)]	Loss: 0.4682	Cost: 10.50s
Train Epoch: 807 [40960/90000 (45%)]	Loss: 0.2829	Cost: 6.42s
Train Epoch: 807 [61440/90000 (68%)]	Loss: 0.3005	Cost: 6.25s
Train Epoch: 807 [81920/90000 (91%)]	Loss: 0.4293	Cost: 8.95s
Train Epoch: 807 	Average Loss: 0.5304
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2123

Learning rate: 9.840169609295549e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 808 [0/90000 (0%)]	Loss: 3.4041	Cost: 21.65s
Train Epoch: 808 [20480/90000 (23%)]	Loss: 0.3115	Cost: 9.96s
Train Epoch: 808 [40960/90000 (45%)]	Loss: 0.2933	Cost: 11.27s
Train Epoch: 808 [61440/90000 (68%)]	Loss: 0.5492	Cost: 8.98s
Train Epoch: 808 [81920/90000 (91%)]	Loss: 0.5834	Cost: 8.74s
Train Epoch: 808 	Average Loss: 0.6433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4696

Learning rate: 9.839775384398833e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 809 [0/90000 (0%)]	Loss: 3.3746	Cost: 26.67s
Train Epoch: 809 [20480/90000 (23%)]	Loss: 0.3881	Cost: 11.29s
Train Epoch: 809 [40960/90000 (45%)]	Loss: 0.5326	Cost: 10.23s
Train Epoch: 809 [61440/90000 (68%)]	Loss: 0.3586	Cost: 8.69s
Train Epoch: 809 [81920/90000 (91%)]	Loss: 0.5871	Cost: 6.19s
Train Epoch: 809 	Average Loss: 0.7288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4128

Learning rate: 9.839380681835437e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 810 [0/90000 (0%)]	Loss: 3.4893	Cost: 21.34s
Train Epoch: 810 [20480/90000 (23%)]	Loss: 0.3152	Cost: 6.60s
Train Epoch: 810 [40960/90000 (45%)]	Loss: 0.4546	Cost: 7.94s
Train Epoch: 810 [61440/90000 (68%)]	Loss: 0.1346	Cost: 8.28s
Train Epoch: 810 [81920/90000 (91%)]	Loss: 0.4385	Cost: 16.05s
Train Epoch: 810 	Average Loss: 0.5628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2205

Learning rate: 9.838985501644315e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 811 [0/90000 (0%)]	Loss: 3.3411	Cost: 20.33s
Train Epoch: 811 [20480/90000 (23%)]	Loss: 0.2928	Cost: 9.77s
Train Epoch: 811 [40960/90000 (45%)]	Loss: 0.2357	Cost: 13.34s
Train Epoch: 811 [61440/90000 (68%)]	Loss: 0.0591	Cost: 12.27s
Train Epoch: 811 [81920/90000 (91%)]	Loss: 0.3458	Cost: 12.14s
Train Epoch: 811 	Average Loss: 0.4797
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0533

Saving model as e811_model.pt & e811_waveforms_supplementary.hdf5
Learning rate: 9.838589843864472e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 812 [0/90000 (0%)]	Loss: 3.1320	Cost: 23.41s
Train Epoch: 812 [20480/90000 (23%)]	Loss: 0.3188	Cost: 11.16s
Train Epoch: 812 [40960/90000 (45%)]	Loss: 0.4347	Cost: 13.98s
Train Epoch: 812 [61440/90000 (68%)]	Loss: 0.1283	Cost: 12.38s
Train Epoch: 812 [81920/90000 (91%)]	Loss: 0.3301	Cost: 7.79s
Train Epoch: 812 	Average Loss: 0.4690
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1597

Learning rate: 9.838193708534956e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 813 [0/90000 (0%)]	Loss: 3.2071	Cost: 30.83s
Train Epoch: 813 [20480/90000 (23%)]	Loss: 0.1906	Cost: 14.69s
Train Epoch: 813 [40960/90000 (45%)]	Loss: 0.2623	Cost: 12.56s
Train Epoch: 813 [61440/90000 (68%)]	Loss: 0.1148	Cost: 8.34s
Train Epoch: 813 [81920/90000 (91%)]	Loss: 0.6647	Cost: 6.07s
Train Epoch: 813 	Average Loss: 0.5049
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4759

Learning rate: 9.837797095694866e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 814 [0/90000 (0%)]	Loss: 3.4337	Cost: 25.44s
Train Epoch: 814 [20480/90000 (23%)]	Loss: 0.5580	Cost: 11.65s
Train Epoch: 814 [40960/90000 (45%)]	Loss: 0.3354	Cost: 11.05s
Train Epoch: 814 [61440/90000 (68%)]	Loss: 0.1284	Cost: 6.40s
Train Epoch: 814 [81920/90000 (91%)]	Loss: 0.4237	Cost: 6.41s
Train Epoch: 814 	Average Loss: 0.5708
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2387

Learning rate: 9.837400005383343e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 815 [0/90000 (0%)]	Loss: 3.0020	Cost: 23.33s
Train Epoch: 815 [20480/90000 (23%)]	Loss: 0.4109	Cost: 12.57s
Train Epoch: 815 [40960/90000 (45%)]	Loss: 0.2628	Cost: 8.26s
Train Epoch: 815 [61440/90000 (68%)]	Loss: 0.1142	Cost: 6.23s
Train Epoch: 815 [81920/90000 (91%)]	Loss: 0.5800	Cost: 8.36s
Train Epoch: 815 	Average Loss: 0.4566
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1410

Learning rate: 9.837002437639581e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 816 [0/90000 (0%)]	Loss: 3.0966	Cost: 28.42s
Train Epoch: 816 [20480/90000 (23%)]	Loss: 0.3450	Cost: 6.51s
Train Epoch: 816 [40960/90000 (45%)]	Loss: 0.1882	Cost: 9.42s
Train Epoch: 816 [61440/90000 (68%)]	Loss: 0.1718	Cost: 8.59s
Train Epoch: 816 [81920/90000 (91%)]	Loss: 0.3173	Cost: 8.80s
Train Epoch: 816 	Average Loss: 0.3839
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0942

Learning rate: 9.836604392502818e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 817 [0/90000 (0%)]	Loss: 3.2088	Cost: 26.10s
Train Epoch: 817 [20480/90000 (23%)]	Loss: 0.1656	Cost: 8.75s
Train Epoch: 817 [40960/90000 (45%)]	Loss: 0.3323	Cost: 8.98s
Train Epoch: 817 [61440/90000 (68%)]	Loss: 0.0674	Cost: 9.10s
Train Epoch: 817 [81920/90000 (91%)]	Loss: 0.1124	Cost: 8.99s
Train Epoch: 817 	Average Loss: 0.3603
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1602

Learning rate: 9.836205870012337e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 818 [0/90000 (0%)]	Loss: 3.0646	Cost: 24.29s
Train Epoch: 818 [20480/90000 (23%)]	Loss: 0.0872	Cost: 8.97s
Train Epoch: 818 [40960/90000 (45%)]	Loss: 0.1814	Cost: 13.40s
Train Epoch: 818 [61440/90000 (68%)]	Loss: -0.0614	Cost: 13.10s
Train Epoch: 818 [81920/90000 (91%)]	Loss: 0.2634	Cost: 12.58s
Train Epoch: 818 	Average Loss: 0.3503
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0742

Learning rate: 9.835806870207475e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 819 [0/90000 (0%)]	Loss: 3.4734	Cost: 21.48s
Train Epoch: 819 [20480/90000 (23%)]	Loss: 0.4266	Cost: 11.48s
Train Epoch: 819 [40960/90000 (45%)]	Loss: 0.1748	Cost: 15.00s
Train Epoch: 819 [61440/90000 (68%)]	Loss: 0.2274	Cost: 14.04s
Train Epoch: 819 [81920/90000 (91%)]	Loss: 0.2972	Cost: 12.46s
Train Epoch: 819 	Average Loss: 0.4293
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1544

Learning rate: 9.835407393127609e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 820 [0/90000 (0%)]	Loss: 3.2379	Cost: 34.26s
Train Epoch: 820 [20480/90000 (23%)]	Loss: 0.1521	Cost: 13.67s
Train Epoch: 820 [40960/90000 (45%)]	Loss: 0.1057	Cost: 12.44s
Train Epoch: 820 [61440/90000 (68%)]	Loss: 0.0112	Cost: 12.25s
Train Epoch: 820 [81920/90000 (91%)]	Loss: 0.1998	Cost: 9.71s
Train Epoch: 820 	Average Loss: 0.3561
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0828

Learning rate: 9.835007438812164e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 821 [0/90000 (0%)]	Loss: 3.0587	Cost: 26.11s
Train Epoch: 821 [20480/90000 (23%)]	Loss: 0.1674	Cost: 10.28s
Train Epoch: 821 [40960/90000 (45%)]	Loss: 0.1482	Cost: 9.83s
Train Epoch: 821 [61440/90000 (68%)]	Loss: 0.2244	Cost: 6.11s
Train Epoch: 821 [81920/90000 (91%)]	Loss: 0.1942	Cost: 7.06s
Train Epoch: 821 	Average Loss: 0.3650
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1473

Learning rate: 9.834607007300618e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 822 [0/90000 (0%)]	Loss: 3.1362	Cost: 29.48s
Train Epoch: 822 [20480/90000 (23%)]	Loss: 0.2716	Cost: 9.62s
Train Epoch: 822 [40960/90000 (45%)]	Loss: 0.1612	Cost: 6.42s
Train Epoch: 822 [61440/90000 (68%)]	Loss: 0.0564	Cost: 6.98s
Train Epoch: 822 [81920/90000 (91%)]	Loss: 0.3361	Cost: 8.54s
Train Epoch: 822 	Average Loss: 0.3998
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0885

Learning rate: 9.834206098632488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 823 [0/90000 (0%)]	Loss: 2.7847	Cost: 23.96s
Train Epoch: 823 [20480/90000 (23%)]	Loss: 0.3855	Cost: 8.59s
Train Epoch: 823 [40960/90000 (45%)]	Loss: 0.5173	Cost: 11.83s
Train Epoch: 823 [61440/90000 (68%)]	Loss: 0.2602	Cost: 9.02s
Train Epoch: 823 [81920/90000 (91%)]	Loss: 0.3015	Cost: 8.92s
Train Epoch: 823 	Average Loss: 0.4933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1163

Learning rate: 9.833804712847345e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 824 [0/90000 (0%)]	Loss: 3.3907	Cost: 27.32s
Train Epoch: 824 [20480/90000 (23%)]	Loss: 0.3179	Cost: 10.85s
Train Epoch: 824 [40960/90000 (45%)]	Loss: 0.2846	Cost: 9.69s
Train Epoch: 824 [61440/90000 (68%)]	Loss: 0.1023	Cost: 6.20s
Train Epoch: 824 [81920/90000 (91%)]	Loss: 0.2672	Cost: 6.71s
Train Epoch: 824 	Average Loss: 0.3957
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0380

Saving model as e824_model.pt & e824_waveforms_supplementary.hdf5
Learning rate: 9.833402849984804e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 825 [0/90000 (0%)]	Loss: 3.1139	Cost: 20.26s
Train Epoch: 825 [20480/90000 (23%)]	Loss: 0.0301	Cost: 7.74s
Train Epoch: 825 [40960/90000 (45%)]	Loss: 0.0797	Cost: 12.46s
Train Epoch: 825 [61440/90000 (68%)]	Loss: 0.0648	Cost: 13.65s
Train Epoch: 825 [81920/90000 (91%)]	Loss: 0.1484	Cost: 12.31s
Train Epoch: 825 	Average Loss: 0.2795
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0014

Saving model as e825_model.pt & e825_waveforms_supplementary.hdf5
Learning rate: 9.833000510084526e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 826 [0/90000 (0%)]	Loss: 2.9605	Cost: 24.74s
Train Epoch: 826 [20480/90000 (23%)]	Loss: 0.0416	Cost: 12.95s
Train Epoch: 826 [40960/90000 (45%)]	Loss: 0.0246	Cost: 12.34s
Train Epoch: 826 [61440/90000 (68%)]	Loss: -0.2444	Cost: 12.40s
Train Epoch: 826 [81920/90000 (91%)]	Loss: 0.1562	Cost: 10.37s
Train Epoch: 826 	Average Loss: 0.2437
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9367

Saving model as e826_model.pt & e826_waveforms_supplementary.hdf5
Learning rate: 9.832597693186221e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 827 [0/90000 (0%)]	Loss: 2.6873	Cost: 23.09s
Train Epoch: 827 [20480/90000 (23%)]	Loss: 0.0450	Cost: 10.37s
Train Epoch: 827 [40960/90000 (45%)]	Loss: 0.0363	Cost: 9.94s
Train Epoch: 827 [61440/90000 (68%)]	Loss: -0.0777	Cost: 6.47s
Train Epoch: 827 [81920/90000 (91%)]	Loss: 0.1024	Cost: 7.11s
Train Epoch: 827 	Average Loss: 0.1902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8812

Saving model as e827_model.pt & e827_waveforms_supplementary.hdf5
Learning rate: 9.832194399329644e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 828 [0/90000 (0%)]	Loss: 2.8065	Cost: 27.51s
Train Epoch: 828 [20480/90000 (23%)]	Loss: -0.0016	Cost: 12.49s
Train Epoch: 828 [40960/90000 (45%)]	Loss: 0.1772	Cost: 8.89s
Train Epoch: 828 [61440/90000 (68%)]	Loss: -0.0474	Cost: 6.50s
Train Epoch: 828 [81920/90000 (91%)]	Loss: 0.2205	Cost: 8.27s
Train Epoch: 828 	Average Loss: 0.2773
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9953

Learning rate: 9.831790628554601e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 829 [0/90000 (0%)]	Loss: 3.1162	Cost: 20.63s
Train Epoch: 829 [20480/90000 (23%)]	Loss: 0.0440	Cost: 9.90s
Train Epoch: 829 [40960/90000 (45%)]	Loss: 0.2699	Cost: 9.74s
Train Epoch: 829 [61440/90000 (68%)]	Loss: -0.0591	Cost: 9.08s
Train Epoch: 829 [81920/90000 (91%)]	Loss: 0.4101	Cost: 9.15s
Train Epoch: 829 	Average Loss: 0.3220
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1195

Learning rate: 9.831386380900942e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 830 [0/90000 (0%)]	Loss: 3.1232	Cost: 21.89s
Train Epoch: 830 [20480/90000 (23%)]	Loss: 0.1283	Cost: 8.38s
Train Epoch: 830 [40960/90000 (45%)]	Loss: -0.0517	Cost: 9.11s
Train Epoch: 830 [61440/90000 (68%)]	Loss: -0.1800	Cost: 8.70s
Train Epoch: 830 [81920/90000 (91%)]	Loss: 0.1033	Cost: 8.37s
Train Epoch: 830 	Average Loss: 0.2141
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9348

Learning rate: 9.830981656408563e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 831 [0/90000 (0%)]	Loss: 3.0485	Cost: 21.65s
Train Epoch: 831 [20480/90000 (23%)]	Loss: -0.0911	Cost: 9.14s
Train Epoch: 831 [40960/90000 (45%)]	Loss: -0.0433	Cost: 7.14s
Train Epoch: 831 [61440/90000 (68%)]	Loss: -0.0725	Cost: 6.41s
Train Epoch: 831 [81920/90000 (91%)]	Loss: 0.0272	Cost: 6.72s
Train Epoch: 831 	Average Loss: 0.1490
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0284

Learning rate: 9.830576455117411e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 832 [0/90000 (0%)]	Loss: 3.0825	Cost: 21.52s
Train Epoch: 832 [20480/90000 (23%)]	Loss: 0.0178	Cost: 9.23s
Train Epoch: 832 [40960/90000 (45%)]	Loss: -0.0769	Cost: 8.96s
Train Epoch: 832 [61440/90000 (68%)]	Loss: -0.1227	Cost: 11.57s
Train Epoch: 832 [81920/90000 (91%)]	Loss: -0.1793	Cost: 12.43s
Train Epoch: 832 	Average Loss: 0.1574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8646

Saving model as e832_model.pt & e832_waveforms_supplementary.hdf5
Learning rate: 9.830170777067474e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 833 [0/90000 (0%)]	Loss: 2.9682	Cost: 24.49s
Train Epoch: 833 [20480/90000 (23%)]	Loss: -0.1853	Cost: 12.12s
Train Epoch: 833 [40960/90000 (45%)]	Loss: -0.1223	Cost: 12.84s
Train Epoch: 833 [61440/90000 (68%)]	Loss: -0.0303	Cost: 12.83s
Train Epoch: 833 [81920/90000 (91%)]	Loss: 0.0650	Cost: 12.48s
Train Epoch: 833 	Average Loss: 0.1369
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9459

Learning rate: 9.829764622298796e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 834 [0/90000 (0%)]	Loss: 3.0385	Cost: 26.96s
Train Epoch: 834 [20480/90000 (23%)]	Loss: 0.0466	Cost: 10.19s
Train Epoch: 834 [40960/90000 (45%)]	Loss: -0.0802	Cost: 14.59s
Train Epoch: 834 [61440/90000 (68%)]	Loss: -0.1128	Cost: 12.61s
Train Epoch: 834 [81920/90000 (91%)]	Loss: 0.0343	Cost: 10.67s
Train Epoch: 834 	Average Loss: 0.1528
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9700

Learning rate: 9.829357990851458e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 835 [0/90000 (0%)]	Loss: 2.8794	Cost: 27.00s
Train Epoch: 835 [20480/90000 (23%)]	Loss: -0.1883	Cost: 10.87s
Train Epoch: 835 [40960/90000 (45%)]	Loss: -0.2457	Cost: 13.25s
Train Epoch: 835 [61440/90000 (68%)]	Loss: -0.1429	Cost: 12.15s
Train Epoch: 835 [81920/90000 (91%)]	Loss: -0.0313	Cost: 8.56s
Train Epoch: 835 	Average Loss: 0.0353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7817

Saving model as e835_model.pt & e835_waveforms_supplementary.hdf5
Learning rate: 9.828950882765597e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 836 [0/90000 (0%)]	Loss: 2.9856	Cost: 38.73s
Train Epoch: 836 [20480/90000 (23%)]	Loss: -0.0343	Cost: 11.38s
Train Epoch: 836 [40960/90000 (45%)]	Loss: -0.2521	Cost: 8.49s
Train Epoch: 836 [61440/90000 (68%)]	Loss: -0.1685	Cost: 6.26s
Train Epoch: 836 [81920/90000 (91%)]	Loss: 0.0358	Cost: 8.00s
Train Epoch: 836 	Average Loss: 0.0969
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3754

Learning rate: 9.82854329808139e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 837 [0/90000 (0%)]	Loss: 3.4807	Cost: 33.13s
Train Epoch: 837 [20480/90000 (23%)]	Loss: 0.4449	Cost: 6.43s
Train Epoch: 837 [40960/90000 (45%)]	Loss: 0.1714	Cost: 8.42s
Train Epoch: 837 [61440/90000 (68%)]	Loss: 0.2640	Cost: 8.87s
Train Epoch: 837 [81920/90000 (91%)]	Loss: 0.2070	Cost: 8.88s
Train Epoch: 837 	Average Loss: 0.5414
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1098

Learning rate: 9.828135236839064e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 838 [0/90000 (0%)]	Loss: 3.0200	Cost: 20.20s
Train Epoch: 838 [20480/90000 (23%)]	Loss: -0.0800	Cost: 9.31s
Train Epoch: 838 [40960/90000 (45%)]	Loss: -0.0952	Cost: 8.94s
Train Epoch: 838 [61440/90000 (68%)]	Loss: -0.1366	Cost: 8.71s
Train Epoch: 838 [81920/90000 (91%)]	Loss: -0.0042	Cost: 9.35s
Train Epoch: 838 	Average Loss: 0.1663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8025

Learning rate: 9.827726699078896e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 839 [0/90000 (0%)]	Loss: 2.4643	Cost: 19.11s
Train Epoch: 839 [20480/90000 (23%)]	Loss: -0.0290	Cost: 9.06s
Train Epoch: 839 [40960/90000 (45%)]	Loss: 0.0103	Cost: 11.16s
Train Epoch: 839 [61440/90000 (68%)]	Loss: -0.3158	Cost: 9.23s
Train Epoch: 839 [81920/90000 (91%)]	Loss: -0.0582	Cost: 6.61s
Train Epoch: 839 	Average Loss: 0.1097
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7991

Learning rate: 9.827317684841204e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 840 [0/90000 (0%)]	Loss: 3.0727	Cost: 22.17s
Train Epoch: 840 [20480/90000 (23%)]	Loss: -0.2360	Cost: 6.41s
Train Epoch: 840 [40960/90000 (45%)]	Loss: -0.0406	Cost: 11.55s
Train Epoch: 840 [61440/90000 (68%)]	Loss: -0.2109	Cost: 7.85s
Train Epoch: 840 [81920/90000 (91%)]	Loss: 0.1825	Cost: 12.62s
Train Epoch: 840 	Average Loss: 0.1066
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8850

Learning rate: 9.826908194166357e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 841 [0/90000 (0%)]	Loss: 2.9140	Cost: 34.05s
Train Epoch: 841 [20480/90000 (23%)]	Loss: -0.1064	Cost: 12.84s
Train Epoch: 841 [40960/90000 (45%)]	Loss: 0.0030	Cost: 12.82s
Train Epoch: 841 [61440/90000 (68%)]	Loss: 0.0192	Cost: 12.23s
Train Epoch: 841 [81920/90000 (91%)]	Loss: 0.4724	Cost: 12.12s
Train Epoch: 841 	Average Loss: 0.2428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0655

Learning rate: 9.826498227094772e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 842 [0/90000 (0%)]	Loss: 2.9185	Cost: 30.82s
Train Epoch: 842 [20480/90000 (23%)]	Loss: 0.0239	Cost: 12.30s
Train Epoch: 842 [40960/90000 (45%)]	Loss: 0.0033	Cost: 10.45s
Train Epoch: 842 [61440/90000 (68%)]	Loss: -0.2917	Cost: 6.32s
Train Epoch: 842 [81920/90000 (91%)]	Loss: -0.0603	Cost: 7.41s
Train Epoch: 842 	Average Loss: 0.0983
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7983

Learning rate: 9.826087783666908e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 843 [0/90000 (0%)]	Loss: 2.6679	Cost: 30.57s
Train Epoch: 843 [20480/90000 (23%)]	Loss: -0.3003	Cost: 7.39s
Train Epoch: 843 [40960/90000 (45%)]	Loss: -0.1830	Cost: 9.17s
Train Epoch: 843 [61440/90000 (68%)]	Loss: -0.3044	Cost: 8.50s
Train Epoch: 843 [81920/90000 (91%)]	Loss: -0.1363	Cost: 8.92s
Train Epoch: 843 	Average Loss: 0.0024
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7764

Saving model as e843_model.pt & e843_waveforms_supplementary.hdf5
Learning rate: 9.825676863923276e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 844 [0/90000 (0%)]	Loss: 3.0242	Cost: 20.35s
Train Epoch: 844 [20480/90000 (23%)]	Loss: -0.0777	Cost: 9.90s
Train Epoch: 844 [40960/90000 (45%)]	Loss: -0.0485	Cost: 13.30s
Train Epoch: 844 [61440/90000 (68%)]	Loss: -0.3491	Cost: 8.96s
Train Epoch: 844 [81920/90000 (91%)]	Loss: -0.1836	Cost: 8.71s
Train Epoch: 844 	Average Loss: -0.0080
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8111

Learning rate: 9.825265467904433e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 845 [0/90000 (0%)]	Loss: 2.9378	Cost: 21.86s
Train Epoch: 845 [20480/90000 (23%)]	Loss: -0.3451	Cost: 9.08s
Train Epoch: 845 [40960/90000 (45%)]	Loss: -0.3058	Cost: 6.49s
Train Epoch: 845 [61440/90000 (68%)]	Loss: -0.3109	Cost: 7.48s
Train Epoch: 845 [81920/90000 (91%)]	Loss: -0.0129	Cost: 6.91s
Train Epoch: 845 	Average Loss: -0.0577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7053

Saving model as e845_model.pt & e845_waveforms_supplementary.hdf5
Learning rate: 9.824853595650979e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 846 [0/90000 (0%)]	Loss: 2.6580	Cost: 19.40s
Train Epoch: 846 [20480/90000 (23%)]	Loss: -0.2970	Cost: 8.46s
Train Epoch: 846 [40960/90000 (45%)]	Loss: -0.3017	Cost: 13.69s
Train Epoch: 846 [61440/90000 (68%)]	Loss: -0.3580	Cost: 12.37s
Train Epoch: 846 [81920/90000 (91%)]	Loss: -0.1938	Cost: 12.28s
Train Epoch: 846 	Average Loss: -0.0543
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7949

Learning rate: 9.824441247203567e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 847 [0/90000 (0%)]	Loss: 2.7371	Cost: 24.32s
Train Epoch: 847 [20480/90000 (23%)]	Loss: -0.3014	Cost: 12.99s
Train Epoch: 847 [40960/90000 (45%)]	Loss: -0.2788	Cost: 13.30s
Train Epoch: 847 [61440/90000 (68%)]	Loss: -0.3841	Cost: 12.46s
Train Epoch: 847 [81920/90000 (91%)]	Loss: -0.2326	Cost: 12.24s
Train Epoch: 847 	Average Loss: -0.1084
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7248

Learning rate: 9.824028422602895e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 848 [0/90000 (0%)]	Loss: 2.8186	Cost: 40.63s
Train Epoch: 848 [20480/90000 (23%)]	Loss: -0.2672	Cost: 12.20s
Train Epoch: 848 [40960/90000 (45%)]	Loss: -0.1621	Cost: 12.06s
Train Epoch: 848 [61440/90000 (68%)]	Loss: -0.0519	Cost: 11.95s
Train Epoch: 848 [81920/90000 (91%)]	Loss: -0.1925	Cost: 6.16s
Train Epoch: 848 	Average Loss: 0.0631
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8353

Learning rate: 9.823615121889704e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 849 [0/90000 (0%)]	Loss: 3.0162	Cost: 34.25s
Train Epoch: 849 [20480/90000 (23%)]	Loss: -0.1437	Cost: 12.98s
Train Epoch: 849 [40960/90000 (45%)]	Loss: -0.1776	Cost: 12.46s
Train Epoch: 849 [61440/90000 (68%)]	Loss: -0.3093	Cost: 6.77s
Train Epoch: 849 [81920/90000 (91%)]	Loss: -0.1488	Cost: 6.08s
Train Epoch: 849 	Average Loss: -0.0253
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8457

Learning rate: 9.823201345104787e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 850 [0/90000 (0%)]	Loss: 2.6658	Cost: 30.02s
Train Epoch: 850 [20480/90000 (23%)]	Loss: -0.1607	Cost: 11.75s
Train Epoch: 850 [40960/90000 (45%)]	Loss: -0.3118	Cost: 6.39s
Train Epoch: 850 [61440/90000 (68%)]	Loss: -0.4470	Cost: 6.57s
Train Epoch: 850 [81920/90000 (91%)]	Loss: -0.3015	Cost: 8.18s
Train Epoch: 850 	Average Loss: -0.1333
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7578

Learning rate: 9.82278709228898e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 851 [0/90000 (0%)]	Loss: 2.7056	Cost: 20.25s
Train Epoch: 851 [20480/90000 (23%)]	Loss: -0.3749	Cost: 7.54s
Train Epoch: 851 [40960/90000 (45%)]	Loss: -0.5251	Cost: 8.92s
Train Epoch: 851 [61440/90000 (68%)]	Loss: -0.4973	Cost: 8.60s
Train Epoch: 851 [81920/90000 (91%)]	Loss: -0.2856	Cost: 8.87s
Train Epoch: 851 	Average Loss: -0.1653
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7083

Learning rate: 9.82237236348317e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 852 [0/90000 (0%)]	Loss: 2.6368	Cost: 18.96s
Train Epoch: 852 [20480/90000 (23%)]	Loss: -0.3493	Cost: 9.23s
Train Epoch: 852 [40960/90000 (45%)]	Loss: -0.4738	Cost: 7.08s
Train Epoch: 852 [61440/90000 (68%)]	Loss: -0.5744	Cost: 9.30s
Train Epoch: 852 [81920/90000 (91%)]	Loss: -0.2863	Cost: 11.23s
Train Epoch: 852 	Average Loss: -0.1676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6978

Saving model as e852_model.pt & e852_waveforms_supplementary.hdf5
Learning rate: 9.821957158728289e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 853 [0/90000 (0%)]	Loss: 2.4896	Cost: 27.90s
Train Epoch: 853 [20480/90000 (23%)]	Loss: -0.2740	Cost: 12.03s
Train Epoch: 853 [40960/90000 (45%)]	Loss: -0.1856	Cost: 14.42s
Train Epoch: 853 [61440/90000 (68%)]	Loss: -0.4420	Cost: 12.48s
Train Epoch: 853 [81920/90000 (91%)]	Loss: -0.1709	Cost: 11.83s
Train Epoch: 853 	Average Loss: -0.0994
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8248

Learning rate: 9.821541478065316e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 854 [0/90000 (0%)]	Loss: 2.6006	Cost: 41.57s
Train Epoch: 854 [20480/90000 (23%)]	Loss: -0.2327	Cost: 12.54s
Train Epoch: 854 [40960/90000 (45%)]	Loss: -0.5497	Cost: 12.59s
Train Epoch: 854 [61440/90000 (68%)]	Loss: -0.4633	Cost: 12.05s
Train Epoch: 854 [81920/90000 (91%)]	Loss: -0.1788	Cost: 6.47s
Train Epoch: 854 	Average Loss: -0.1385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7603

Learning rate: 9.821125321535279e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 855 [0/90000 (0%)]	Loss: 2.6066	Cost: 22.69s
Train Epoch: 855 [20480/90000 (23%)]	Loss: -0.4657	Cost: 10.09s
Train Epoch: 855 [40960/90000 (45%)]	Loss: -0.3558	Cost: 11.26s
Train Epoch: 855 [61440/90000 (68%)]	Loss: -0.6102	Cost: 6.22s
Train Epoch: 855 [81920/90000 (91%)]	Loss: -0.2136	Cost: 6.30s
Train Epoch: 855 	Average Loss: -0.1575
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7007

Learning rate: 9.820708689179247e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 856 [0/90000 (0%)]	Loss: 2.8229	Cost: 22.42s
Train Epoch: 856 [20480/90000 (23%)]	Loss: -0.3760	Cost: 7.18s
Train Epoch: 856 [40960/90000 (45%)]	Loss: -0.3104	Cost: 8.68s
Train Epoch: 856 [61440/90000 (68%)]	Loss: -0.5103	Cost: 9.15s
Train Epoch: 856 [81920/90000 (91%)]	Loss: -0.4590	Cost: 9.24s
Train Epoch: 856 	Average Loss: -0.2188
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6369

Saving model as e856_model.pt & e856_waveforms_supplementary.hdf5
Learning rate: 9.820291581038343e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 857 [0/90000 (0%)]	Loss: 2.4950	Cost: 21.97s
Train Epoch: 857 [20480/90000 (23%)]	Loss: -0.3540	Cost: 8.14s
Train Epoch: 857 [40960/90000 (45%)]	Loss: -0.3266	Cost: 8.98s
Train Epoch: 857 [61440/90000 (68%)]	Loss: -0.3943	Cost: 8.09s
Train Epoch: 857 [81920/90000 (91%)]	Loss: -0.2269	Cost: 13.17s
Train Epoch: 857 	Average Loss: -0.1760
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7067

Learning rate: 9.819873997153732e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 858 [0/90000 (0%)]	Loss: 2.5035	Cost: 25.77s
Train Epoch: 858 [20480/90000 (23%)]	Loss: -0.4067	Cost: 7.12s
Train Epoch: 858 [40960/90000 (45%)]	Loss: -0.2347	Cost: 12.76s
Train Epoch: 858 [61440/90000 (68%)]	Loss: -0.4754	Cost: 12.56s
Train Epoch: 858 [81920/90000 (91%)]	Loss: -0.1937	Cost: 12.19s
Train Epoch: 858 	Average Loss: -0.0769
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7393

Learning rate: 9.81945593756663e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 859 [0/90000 (0%)]	Loss: 2.8686	Cost: 26.04s
Train Epoch: 859 [20480/90000 (23%)]	Loss: -0.0077	Cost: 12.96s
Train Epoch: 859 [40960/90000 (45%)]	Loss: -0.2278	Cost: 12.56s
Train Epoch: 859 [61440/90000 (68%)]	Loss: -0.4346	Cost: 12.32s
Train Epoch: 859 [81920/90000 (91%)]	Loss: -0.1558	Cost: 12.35s
Train Epoch: 859 	Average Loss: -0.0145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7214

Learning rate: 9.819037402318296e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 860 [0/90000 (0%)]	Loss: 2.8218	Cost: 39.71s
Train Epoch: 860 [20480/90000 (23%)]	Loss: -0.2664	Cost: 13.78s
Train Epoch: 860 [40960/90000 (45%)]	Loss: -0.6484	Cost: 12.23s
Train Epoch: 860 [61440/90000 (68%)]	Loss: -0.5754	Cost: 10.01s
Train Epoch: 860 [81920/90000 (91%)]	Loss: -0.3006	Cost: 6.16s
Train Epoch: 860 	Average Loss: -0.2381
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7009

Learning rate: 9.818618391450038e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 861 [0/90000 (0%)]	Loss: 3.1776	Cost: 24.72s
Train Epoch: 861 [20480/90000 (23%)]	Loss: -0.3018	Cost: 13.08s
Train Epoch: 861 [40960/90000 (45%)]	Loss: -0.4844	Cost: 11.88s
Train Epoch: 861 [61440/90000 (68%)]	Loss: -0.6263	Cost: 6.29s
Train Epoch: 861 [81920/90000 (91%)]	Loss: -0.4966	Cost: 6.39s
Train Epoch: 861 	Average Loss: -0.2527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5517

Saving model as e861_model.pt & e861_waveforms_supplementary.hdf5
Learning rate: 9.81819890500321e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 862 [0/90000 (0%)]	Loss: 2.6124	Cost: 31.28s
Train Epoch: 862 [20480/90000 (23%)]	Loss: -0.4516	Cost: 6.52s
Train Epoch: 862 [40960/90000 (45%)]	Loss: -0.5876	Cost: 9.93s
Train Epoch: 862 [61440/90000 (68%)]	Loss: -0.5506	Cost: 8.62s
Train Epoch: 862 [81920/90000 (91%)]	Loss: -0.4825	Cost: 8.81s
Train Epoch: 862 	Average Loss: -0.3300
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5681

Learning rate: 9.817778943019216e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 863 [0/90000 (0%)]	Loss: 2.3661	Cost: 23.12s
Train Epoch: 863 [20480/90000 (23%)]	Loss: -0.5377	Cost: 7.65s
Train Epoch: 863 [40960/90000 (45%)]	Loss: -0.5206	Cost: 8.36s
Train Epoch: 863 [61440/90000 (68%)]	Loss: -0.5669	Cost: 8.88s
Train Epoch: 863 [81920/90000 (91%)]	Loss: -0.2945	Cost: 11.77s
Train Epoch: 863 	Average Loss: -0.3475
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5661

Learning rate: 9.817358505539504e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 864 [0/90000 (0%)]	Loss: 2.7626	Cost: 19.97s
Train Epoch: 864 [20480/90000 (23%)]	Loss: -0.3817	Cost: 9.39s
Train Epoch: 864 [40960/90000 (45%)]	Loss: -0.4266	Cost: 13.61s
Train Epoch: 864 [61440/90000 (68%)]	Loss: -0.6609	Cost: 13.49s
Train Epoch: 864 [81920/90000 (91%)]	Loss: -0.4711	Cost: 12.19s
Train Epoch: 864 	Average Loss: -0.2911
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7261

Learning rate: 9.816937592605568e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 865 [0/90000 (0%)]	Loss: 2.5193	Cost: 29.85s
Train Epoch: 865 [20480/90000 (23%)]	Loss: -0.4470	Cost: 8.46s
Train Epoch: 865 [40960/90000 (45%)]	Loss: -0.5069	Cost: 13.78s
Train Epoch: 865 [61440/90000 (68%)]	Loss: -0.6389	Cost: 12.50s
Train Epoch: 865 [81920/90000 (91%)]	Loss: -0.4427	Cost: 12.16s
Train Epoch: 865 	Average Loss: -0.3650
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5236

Saving model as e865_model.pt & e865_waveforms_supplementary.hdf5
Learning rate: 9.816516204258952e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 866 [0/90000 (0%)]	Loss: 2.5576	Cost: 27.47s
Train Epoch: 866 [20480/90000 (23%)]	Loss: -0.6093	Cost: 13.14s
Train Epoch: 866 [40960/90000 (45%)]	Loss: -0.3498	Cost: 12.49s
Train Epoch: 866 [61440/90000 (68%)]	Loss: -0.6470	Cost: 12.42s
Train Epoch: 866 [81920/90000 (91%)]	Loss: -0.4715	Cost: 10.91s
Train Epoch: 866 	Average Loss: -0.3174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5861

Learning rate: 9.816094340541243e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 867 [0/90000 (0%)]	Loss: 2.3488	Cost: 36.21s
Train Epoch: 867 [20480/90000 (23%)]	Loss: -0.5515	Cost: 14.03s
Train Epoch: 867 [40960/90000 (45%)]	Loss: -0.6220	Cost: 12.85s
Train Epoch: 867 [61440/90000 (68%)]	Loss: -0.7429	Cost: 6.64s
Train Epoch: 867 [81920/90000 (91%)]	Loss: -0.5563	Cost: 6.15s
Train Epoch: 867 	Average Loss: -0.3882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5054

Saving model as e867_model.pt & e867_waveforms_supplementary.hdf5
Learning rate: 9.815672001494079e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 868 [0/90000 (0%)]	Loss: 2.4047	Cost: 22.87s
Train Epoch: 868 [20480/90000 (23%)]	Loss: -0.5792	Cost: 12.74s
Train Epoch: 868 [40960/90000 (45%)]	Loss: -0.4835	Cost: 10.73s
Train Epoch: 868 [61440/90000 (68%)]	Loss: -0.6725	Cost: 7.82s
Train Epoch: 868 [81920/90000 (91%)]	Loss: -0.0125	Cost: 8.79s
Train Epoch: 868 	Average Loss: -0.2245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8294

Learning rate: 9.815249187159144e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 869 [0/90000 (0%)]	Loss: 3.2232	Cost: 21.53s
Train Epoch: 869 [20480/90000 (23%)]	Loss: -0.2608	Cost: 7.73s
Train Epoch: 869 [40960/90000 (45%)]	Loss: -0.4954	Cost: 8.74s
Train Epoch: 869 [61440/90000 (68%)]	Loss: -0.4697	Cost: 8.75s
Train Epoch: 869 [81920/90000 (91%)]	Loss: -0.3347	Cost: 8.52s
Train Epoch: 869 	Average Loss: -0.2106
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6999

Learning rate: 9.814825897578167e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 870 [0/90000 (0%)]	Loss: 2.8293	Cost: 21.98s
Train Epoch: 870 [20480/90000 (23%)]	Loss: -0.5505	Cost: 9.06s
Train Epoch: 870 [40960/90000 (45%)]	Loss: -0.6614	Cost: 9.04s
Train Epoch: 870 [61440/90000 (68%)]	Loss: -0.8417	Cost: 8.82s
Train Epoch: 870 [81920/90000 (91%)]	Loss: -0.6191	Cost: 8.43s
Train Epoch: 870 	Average Loss: -0.4253
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3772

Saving model as e870_model.pt & e870_waveforms_supplementary.hdf5
Learning rate: 9.814402132792926e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 871 [0/90000 (0%)]	Loss: 2.4355	Cost: 20.79s
Train Epoch: 871 [20480/90000 (23%)]	Loss: -0.6838	Cost: 6.78s
Train Epoch: 871 [40960/90000 (45%)]	Loss: -0.6824	Cost: 10.64s
Train Epoch: 871 [61440/90000 (68%)]	Loss: -0.8895	Cost: 9.55s
Train Epoch: 871 [81920/90000 (91%)]	Loss: -0.4683	Cost: 12.94s
Train Epoch: 871 	Average Loss: -0.5295
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4443

Learning rate: 9.813977892845244e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 872 [0/90000 (0%)]	Loss: 3.0445	Cost: 25.47s
Train Epoch: 872 [20480/90000 (23%)]	Loss: -0.7184	Cost: 10.18s
Train Epoch: 872 [40960/90000 (45%)]	Loss: -0.7188	Cost: 14.17s
Train Epoch: 872 [61440/90000 (68%)]	Loss: -0.7660	Cost: 13.45s
Train Epoch: 872 [81920/90000 (91%)]	Loss: -0.5609	Cost: 12.20s
Train Epoch: 872 	Average Loss: -0.4914
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3520

Saving model as e872_model.pt & e872_waveforms_supplementary.hdf5
Learning rate: 9.813553177776991e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 873 [0/90000 (0%)]	Loss: 2.4540	Cost: 39.37s
Train Epoch: 873 [20480/90000 (23%)]	Loss: -0.7968	Cost: 13.11s
Train Epoch: 873 [40960/90000 (45%)]	Loss: -0.8728	Cost: 12.13s
Train Epoch: 873 [61440/90000 (68%)]	Loss: -0.8237	Cost: 12.29s
Train Epoch: 873 [81920/90000 (91%)]	Loss: -0.4940	Cost: 7.12s
Train Epoch: 873 	Average Loss: -0.4878
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5485

Learning rate: 9.813127987630086e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 874 [0/90000 (0%)]	Loss: 2.1005	Cost: 31.95s
Train Epoch: 874 [20480/90000 (23%)]	Loss: -0.6041	Cost: 12.81s
Train Epoch: 874 [40960/90000 (45%)]	Loss: -0.8445	Cost: 12.31s
Train Epoch: 874 [61440/90000 (68%)]	Loss: -0.7488	Cost: 7.69s
Train Epoch: 874 [81920/90000 (91%)]	Loss: -0.5564	Cost: 6.39s
Train Epoch: 874 	Average Loss: -0.5216
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5310

Learning rate: 9.812702322446492e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 875 [0/90000 (0%)]	Loss: 2.4149	Cost: 26.79s
Train Epoch: 875 [20480/90000 (23%)]	Loss: -0.7345	Cost: 11.79s
Train Epoch: 875 [40960/90000 (45%)]	Loss: -0.5975	Cost: 6.44s
Train Epoch: 875 [61440/90000 (68%)]	Loss: -0.8005	Cost: 6.26s
Train Epoch: 875 [81920/90000 (91%)]	Loss: -0.5235	Cost: 8.63s
Train Epoch: 875 	Average Loss: -0.4261
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4629

Learning rate: 9.812276182268223e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 876 [0/90000 (0%)]	Loss: 2.5319	Cost: 23.54s
Train Epoch: 876 [20480/90000 (23%)]	Loss: -0.7886	Cost: 9.27s
Train Epoch: 876 [40960/90000 (45%)]	Loss: -0.7562	Cost: 9.15s
Train Epoch: 876 [61440/90000 (68%)]	Loss: -1.0170	Cost: 9.08s
Train Epoch: 876 [81920/90000 (91%)]	Loss: -0.7005	Cost: 6.68s
Train Epoch: 876 	Average Loss: -0.5496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3595

Learning rate: 9.811849567137337e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 877 [0/90000 (0%)]	Loss: 2.4323	Cost: 29.11s
Train Epoch: 877 [20480/90000 (23%)]	Loss: -0.6409	Cost: 6.49s
Train Epoch: 877 [40960/90000 (45%)]	Loss: -0.6878	Cost: 8.47s
Train Epoch: 877 [61440/90000 (68%)]	Loss: -0.8757	Cost: 6.93s
Train Epoch: 877 [81920/90000 (91%)]	Loss: -0.4999	Cost: 16.21s
Train Epoch: 877 	Average Loss: -0.5033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4799

Learning rate: 9.811422477095938e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 878 [0/90000 (0%)]	Loss: 2.7835	Cost: 27.78s
Train Epoch: 878 [20480/90000 (23%)]	Loss: -0.7545	Cost: 10.07s
Train Epoch: 878 [40960/90000 (45%)]	Loss: -0.8828	Cost: 15.59s
Train Epoch: 878 [61440/90000 (68%)]	Loss: -0.8740	Cost: 12.28s
Train Epoch: 878 [81920/90000 (91%)]	Loss: -0.7572	Cost: 12.32s
Train Epoch: 878 	Average Loss: -0.5755
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3598

Learning rate: 9.810994912186177e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 879 [0/90000 (0%)]	Loss: 2.8264	Cost: 28.06s
Train Epoch: 879 [20480/90000 (23%)]	Loss: -0.8526	Cost: 14.25s
Train Epoch: 879 [40960/90000 (45%)]	Loss: -0.9199	Cost: 13.39s
Train Epoch: 879 [61440/90000 (68%)]	Loss: -1.0461	Cost: 12.23s
Train Epoch: 879 [81920/90000 (91%)]	Loss: -0.6274	Cost: 8.88s
Train Epoch: 879 	Average Loss: -0.6114
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4044

Learning rate: 9.810566872450255e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 880 [0/90000 (0%)]	Loss: 2.4779	Cost: 25.42s
Train Epoch: 880 [20480/90000 (23%)]	Loss: -0.6338	Cost: 12.75s
Train Epoch: 880 [40960/90000 (45%)]	Loss: -0.8988	Cost: 10.96s
Train Epoch: 880 [61440/90000 (68%)]	Loss: -0.7934	Cost: 6.16s
Train Epoch: 880 [81920/90000 (91%)]	Loss: -0.6437	Cost: 7.96s
Train Epoch: 880 	Average Loss: -0.5526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4289

Learning rate: 9.810138357930416e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 881 [0/90000 (0%)]	Loss: 2.5311	Cost: 20.08s
Train Epoch: 881 [20480/90000 (23%)]	Loss: -0.4738	Cost: 7.51s
Train Epoch: 881 [40960/90000 (45%)]	Loss: -0.7308	Cost: 9.63s
Train Epoch: 881 [61440/90000 (68%)]	Loss: -1.0268	Cost: 8.85s
Train Epoch: 881 [81920/90000 (91%)]	Loss: -0.6315	Cost: 8.78s
Train Epoch: 881 	Average Loss: -0.4993
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4056

Learning rate: 9.809709368668956e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 882 [0/90000 (0%)]	Loss: 2.5643	Cost: 25.90s
Train Epoch: 882 [20480/90000 (23%)]	Loss: -0.7758	Cost: 8.98s
Train Epoch: 882 [40960/90000 (45%)]	Loss: -0.7699	Cost: 8.87s
Train Epoch: 882 [61440/90000 (68%)]	Loss: -0.9256	Cost: 5.92s
Train Epoch: 882 [81920/90000 (91%)]	Loss: -0.6364	Cost: 6.47s
Train Epoch: 882 	Average Loss: -0.5851
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4008

Learning rate: 9.80927990470821e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 883 [0/90000 (0%)]	Loss: 2.4359	Cost: 22.57s
Train Epoch: 883 [20480/90000 (23%)]	Loss: -0.7059	Cost: 7.22s
Train Epoch: 883 [40960/90000 (45%)]	Loss: -0.6542	Cost: 10.03s
Train Epoch: 883 [61440/90000 (68%)]	Loss: -0.6866	Cost: 11.86s
Train Epoch: 883 [81920/90000 (91%)]	Loss: -0.6085	Cost: 12.39s
Train Epoch: 883 	Average Loss: -0.4559
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4789

Learning rate: 9.80884996609057e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 884 [0/90000 (0%)]	Loss: 2.4536	Cost: 22.88s
Train Epoch: 884 [20480/90000 (23%)]	Loss: -0.7585	Cost: 10.00s
Train Epoch: 884 [40960/90000 (45%)]	Loss: -0.7402	Cost: 14.53s
Train Epoch: 884 [61440/90000 (68%)]	Loss: -0.8919	Cost: 12.11s
Train Epoch: 884 [81920/90000 (91%)]	Loss: -0.6038	Cost: 12.58s
Train Epoch: 884 	Average Loss: -0.5296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4341

Learning rate: 9.808419552858463e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 885 [0/90000 (0%)]	Loss: 2.5174	Cost: 27.09s
Train Epoch: 885 [20480/90000 (23%)]	Loss: -0.8238	Cost: 12.58s
Train Epoch: 885 [40960/90000 (45%)]	Loss: -0.8341	Cost: 12.74s
Train Epoch: 885 [61440/90000 (68%)]	Loss: -1.0766	Cost: 12.42s
Train Epoch: 885 [81920/90000 (91%)]	Loss: -0.7595	Cost: 8.23s
Train Epoch: 885 	Average Loss: -0.6760
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2985

Saving model as e885_model.pt & e885_waveforms_supplementary.hdf5
Learning rate: 9.807988665054374e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 886 [0/90000 (0%)]	Loss: 1.8134	Cost: 24.52s
Train Epoch: 886 [20480/90000 (23%)]	Loss: -0.7933	Cost: 11.62s
Train Epoch: 886 [40960/90000 (45%)]	Loss: -0.6965	Cost: 12.08s
Train Epoch: 886 [61440/90000 (68%)]	Loss: -1.1655	Cost: 6.16s
Train Epoch: 886 [81920/90000 (91%)]	Loss: -0.8005	Cost: 6.44s
Train Epoch: 886 	Average Loss: -0.6759
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3635

Learning rate: 9.807557302720827e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 887 [0/90000 (0%)]	Loss: 2.1938	Cost: 25.03s
Train Epoch: 887 [20480/90000 (23%)]	Loss: -0.9401	Cost: 9.30s
Train Epoch: 887 [40960/90000 (45%)]	Loss: -0.9189	Cost: 7.09s
Train Epoch: 887 [61440/90000 (68%)]	Loss: -0.9541	Cost: 8.89s
Train Epoch: 887 [81920/90000 (91%)]	Loss: -0.5404	Cost: 8.41s
Train Epoch: 887 	Average Loss: -0.6217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2995

Learning rate: 9.807125465900396e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 888 [0/90000 (0%)]	Loss: 2.4802	Cost: 23.36s
Train Epoch: 888 [20480/90000 (23%)]	Loss: -0.8598	Cost: 10.67s
Train Epoch: 888 [40960/90000 (45%)]	Loss: -0.8616	Cost: 9.43s
Train Epoch: 888 [61440/90000 (68%)]	Loss: -1.1168	Cost: 8.73s
Train Epoch: 888 [81920/90000 (91%)]	Loss: -0.7306	Cost: 8.69s
Train Epoch: 888 	Average Loss: -0.6735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2493

Saving model as e888_model.pt & e888_waveforms_supplementary.hdf5
Learning rate: 9.806693154635704e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 889 [0/90000 (0%)]	Loss: 2.4867	Cost: 18.70s
Train Epoch: 889 [20480/90000 (23%)]	Loss: -0.8698	Cost: 9.86s
Train Epoch: 889 [40960/90000 (45%)]	Loss: -0.7652	Cost: 7.82s
Train Epoch: 889 [61440/90000 (68%)]	Loss: -1.0701	Cost: 6.43s
Train Epoch: 889 [81920/90000 (91%)]	Loss: -0.6147	Cost: 6.81s
Train Epoch: 889 	Average Loss: -0.6767
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4181

Learning rate: 9.806260368969415e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 890 [0/90000 (0%)]	Loss: 1.9662	Cost: 22.81s
Train Epoch: 890 [20480/90000 (23%)]	Loss: -0.8132	Cost: 7.71s
Train Epoch: 890 [40960/90000 (45%)]	Loss: -0.9498	Cost: 11.74s
Train Epoch: 890 [61440/90000 (68%)]	Loss: -0.7971	Cost: 12.38s
Train Epoch: 890 [81920/90000 (91%)]	Loss: -0.6991	Cost: 12.52s
Train Epoch: 890 	Average Loss: -0.5717
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4035

Learning rate: 9.805827108944247e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 891 [0/90000 (0%)]	Loss: 2.1098	Cost: 23.74s
Train Epoch: 891 [20480/90000 (23%)]	Loss: -0.9255	Cost: 15.66s
Train Epoch: 891 [40960/90000 (45%)]	Loss: -0.9539	Cost: 13.83s
Train Epoch: 891 [61440/90000 (68%)]	Loss: -1.1109	Cost: 12.24s
Train Epoch: 891 [81920/90000 (91%)]	Loss: -0.8667	Cost: 11.34s
Train Epoch: 891 	Average Loss: -0.6719
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4525

Learning rate: 9.805393374602958e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 892 [0/90000 (0%)]	Loss: 2.2174	Cost: 35.21s
Train Epoch: 892 [20480/90000 (23%)]	Loss: -0.9250	Cost: 11.12s
Train Epoch: 892 [40960/90000 (45%)]	Loss: -0.8857	Cost: 12.38s
Train Epoch: 892 [61440/90000 (68%)]	Loss: -1.1417	Cost: 12.24s
Train Epoch: 892 [81920/90000 (91%)]	Loss: -0.8668	Cost: 7.04s
Train Epoch: 892 	Average Loss: -0.7693
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2680

Learning rate: 9.804959165988357e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 893 [0/90000 (0%)]	Loss: 2.1995	Cost: 40.95s
Train Epoch: 893 [20480/90000 (23%)]	Loss: -1.0113	Cost: 12.27s
Train Epoch: 893 [40960/90000 (45%)]	Loss: -1.0640	Cost: 12.05s
Train Epoch: 893 [61440/90000 (68%)]	Loss: -1.1506	Cost: 6.21s
Train Epoch: 893 [81920/90000 (91%)]	Loss: -0.8619	Cost: 6.72s
Train Epoch: 893 	Average Loss: -0.7715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3311

Learning rate: 9.804524483143299e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 894 [0/90000 (0%)]	Loss: 2.4347	Cost: 20.96s
Train Epoch: 894 [20480/90000 (23%)]	Loss: -1.0046	Cost: 6.96s
Train Epoch: 894 [40960/90000 (45%)]	Loss: -0.9998	Cost: 10.53s
Train Epoch: 894 [61440/90000 (68%)]	Loss: -0.9955	Cost: 8.93s
Train Epoch: 894 [81920/90000 (91%)]	Loss: -0.8531	Cost: 9.46s
Train Epoch: 894 	Average Loss: -0.7352
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2312

Saving model as e894_model.pt & e894_waveforms_supplementary.hdf5
Learning rate: 9.804089326110685e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 895 [0/90000 (0%)]	Loss: 2.5938	Cost: 19.86s
Train Epoch: 895 [20480/90000 (23%)]	Loss: -1.1057	Cost: 9.54s
Train Epoch: 895 [40960/90000 (45%)]	Loss: -0.9139	Cost: 10.63s
Train Epoch: 895 [61440/90000 (68%)]	Loss: -0.9586	Cost: 7.74s
Train Epoch: 895 [81920/90000 (91%)]	Loss: -0.8697	Cost: 9.45s
Train Epoch: 895 	Average Loss: -0.7113
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2524

Learning rate: 9.803653694933463e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 896 [0/90000 (0%)]	Loss: 2.5678	Cost: 21.01s
Train Epoch: 896 [20480/90000 (23%)]	Loss: -0.8969	Cost: 11.04s
Train Epoch: 896 [40960/90000 (45%)]	Loss: -1.0964	Cost: 11.49s
Train Epoch: 896 [61440/90000 (68%)]	Loss: -1.2420	Cost: 12.22s
Train Epoch: 896 [81920/90000 (91%)]	Loss: -1.0328	Cost: 12.36s
Train Epoch: 896 	Average Loss: -0.7901
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1624

Saving model as e896_model.pt & e896_waveforms_supplementary.hdf5
Learning rate: 9.803217589654627e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 897 [0/90000 (0%)]	Loss: 2.4241	Cost: 27.43s
Train Epoch: 897 [20480/90000 (23%)]	Loss: -0.6150	Cost: 12.86s
Train Epoch: 897 [40960/90000 (45%)]	Loss: -0.7722	Cost: 12.89s
Train Epoch: 897 [61440/90000 (68%)]	Loss: -0.8863	Cost: 12.26s
Train Epoch: 897 [81920/90000 (91%)]	Loss: -0.7289	Cost: 11.85s
Train Epoch: 897 	Average Loss: -0.5146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5213

Learning rate: 9.802781010317222e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 898 [0/90000 (0%)]	Loss: 2.7013	Cost: 26.14s
Train Epoch: 898 [20480/90000 (23%)]	Loss: -0.7523	Cost: 11.24s
Train Epoch: 898 [40960/90000 (45%)]	Loss: -0.9368	Cost: 13.00s
Train Epoch: 898 [61440/90000 (68%)]	Loss: -1.0473	Cost: 12.30s
Train Epoch: 898 [81920/90000 (91%)]	Loss: -0.8924	Cost: 6.59s
Train Epoch: 898 	Average Loss: -0.6288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3428

Learning rate: 9.802343956964335e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 899 [0/90000 (0%)]	Loss: 2.1049	Cost: 40.23s
Train Epoch: 899 [20480/90000 (23%)]	Loss: -1.1759	Cost: 12.98s
Train Epoch: 899 [40960/90000 (45%)]	Loss: -1.0166	Cost: 8.62s
Train Epoch: 899 [61440/90000 (68%)]	Loss: -1.1680	Cost: 6.38s
Train Epoch: 899 [81920/90000 (91%)]	Loss: -0.9425	Cost: 8.34s
Train Epoch: 899 	Average Loss: -0.8531
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2453

Learning rate: 9.8019064296391e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 900 [0/90000 (0%)]	Loss: 1.8215	Cost: 23.29s
Train Epoch: 900 [20480/90000 (23%)]	Loss: -0.9792	Cost: 12.10s
Train Epoch: 900 [40960/90000 (45%)]	Loss: -1.0080	Cost: 9.91s
Train Epoch: 900 [61440/90000 (68%)]	Loss: -1.0912	Cost: 7.55s
Train Epoch: 900 [81920/90000 (91%)]	Loss: -0.7959	Cost: 8.57s
Train Epoch: 900 	Average Loss: -0.7393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7125

Learning rate: 9.801468428384702e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 901 [0/90000 (0%)]	Loss: 2.3537	Cost: 22.31s
Train Epoch: 901 [20480/90000 (23%)]	Loss: -0.6058	Cost: 7.46s
Train Epoch: 901 [40960/90000 (45%)]	Loss: -0.8279	Cost: 9.25s
Train Epoch: 901 [61440/90000 (68%)]	Loss: -1.0150	Cost: 8.58s
Train Epoch: 901 [81920/90000 (91%)]	Loss: -0.8361	Cost: 8.67s
Train Epoch: 901 	Average Loss: -0.5577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3280

Learning rate: 9.80102995324437e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 902 [0/90000 (0%)]	Loss: 2.1861	Cost: 20.98s
Train Epoch: 902 [20480/90000 (23%)]	Loss: -0.9157	Cost: 9.28s
Train Epoch: 902 [40960/90000 (45%)]	Loss: -0.8095	Cost: 9.19s
Train Epoch: 902 [61440/90000 (68%)]	Loss: -0.9566	Cost: 8.60s
Train Epoch: 902 [81920/90000 (91%)]	Loss: -0.9985	Cost: 7.69s
Train Epoch: 902 	Average Loss: -0.6554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2823

Learning rate: 9.800591004261374e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 903 [0/90000 (0%)]	Loss: 2.3607	Cost: 19.53s
Train Epoch: 903 [20480/90000 (23%)]	Loss: -1.0054	Cost: 7.04s
Train Epoch: 903 [40960/90000 (45%)]	Loss: -1.0328	Cost: 10.70s
Train Epoch: 903 [61440/90000 (68%)]	Loss: -1.0912	Cost: 11.57s
Train Epoch: 903 [81920/90000 (91%)]	Loss: -0.9664	Cost: 13.09s
Train Epoch: 903 	Average Loss: -0.7554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3260

Learning rate: 9.800151581479044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 904 [0/90000 (0%)]	Loss: 2.1058	Cost: 25.63s
Train Epoch: 904 [20480/90000 (23%)]	Loss: -0.9860	Cost: 10.07s
Train Epoch: 904 [40960/90000 (45%)]	Loss: -1.0987	Cost: 12.42s
Train Epoch: 904 [61440/90000 (68%)]	Loss: -1.2604	Cost: 13.63s
Train Epoch: 904 [81920/90000 (91%)]	Loss: -1.0445	Cost: 12.38s
Train Epoch: 904 	Average Loss: -0.8753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0826

Saving model as e904_model.pt & e904_waveforms_supplementary.hdf5
Learning rate: 9.799711684940746e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 905 [0/90000 (0%)]	Loss: 2.2103	Cost: 39.25s
Train Epoch: 905 [20480/90000 (23%)]	Loss: -1.1350	Cost: 14.09s
Train Epoch: 905 [40960/90000 (45%)]	Loss: -1.1724	Cost: 12.58s
Train Epoch: 905 [61440/90000 (68%)]	Loss: -1.1977	Cost: 12.29s
Train Epoch: 905 [81920/90000 (91%)]	Loss: -1.0884	Cost: 7.65s
Train Epoch: 905 	Average Loss: -0.9031
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2041

Learning rate: 9.799271314689895e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 906 [0/90000 (0%)]	Loss: 2.0671	Cost: 27.51s
Train Epoch: 906 [20480/90000 (23%)]	Loss: -1.1569	Cost: 12.68s
Train Epoch: 906 [40960/90000 (45%)]	Loss: -1.0161	Cost: 12.70s
Train Epoch: 906 [61440/90000 (68%)]	Loss: -1.2772	Cost: 8.44s
Train Epoch: 906 [81920/90000 (91%)]	Loss: -0.9679	Cost: 6.17s
Train Epoch: 906 	Average Loss: -0.8626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1282

Learning rate: 9.798830470769955e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 907 [0/90000 (0%)]	Loss: 2.3097	Cost: 22.89s
Train Epoch: 907 [20480/90000 (23%)]	Loss: -1.1826	Cost: 11.88s
Train Epoch: 907 [40960/90000 (45%)]	Loss: -1.1698	Cost: 6.73s
Train Epoch: 907 [61440/90000 (68%)]	Loss: -1.2209	Cost: 6.20s
Train Epoch: 907 [81920/90000 (91%)]	Loss: -1.0260	Cost: 9.00s
Train Epoch: 907 	Average Loss: -0.9817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1671

Learning rate: 9.798389153224436e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 908 [0/90000 (0%)]	Loss: 2.0160	Cost: 21.51s
Train Epoch: 908 [20480/90000 (23%)]	Loss: -1.0043	Cost: 7.28s
Train Epoch: 908 [40960/90000 (45%)]	Loss: -1.1796	Cost: 9.19s
Train Epoch: 908 [61440/90000 (68%)]	Loss: -1.3976	Cost: 9.42s
Train Epoch: 908 [81920/90000 (91%)]	Loss: -1.1585	Cost: 8.92s
Train Epoch: 908 	Average Loss: -0.9673
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0087

Saving model as e908_model.pt & e908_waveforms_supplementary.hdf5
Learning rate: 9.797947362096895e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 909 [0/90000 (0%)]	Loss: 2.2989	Cost: 31.86s
Train Epoch: 909 [20480/90000 (23%)]	Loss: -1.1209	Cost: 6.68s
Train Epoch: 909 [40960/90000 (45%)]	Loss: -1.1633	Cost: 8.20s
Train Epoch: 909 [61440/90000 (68%)]	Loss: -1.2170	Cost: 6.68s
Train Epoch: 909 [81920/90000 (91%)]	Loss: -1.0399	Cost: 14.83s
Train Epoch: 909 	Average Loss: -0.9130
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1716

Learning rate: 9.797505097430932e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 910 [0/90000 (0%)]	Loss: 2.0758	Cost: 38.15s
Train Epoch: 910 [20480/90000 (23%)]	Loss: -0.9677	Cost: 12.84s
Train Epoch: 910 [40960/90000 (45%)]	Loss: -1.0789	Cost: 12.89s
Train Epoch: 910 [61440/90000 (68%)]	Loss: -1.2209	Cost: 12.29s
Train Epoch: 910 [81920/90000 (91%)]	Loss: -1.2044	Cost: 12.07s
Train Epoch: 910 	Average Loss: -0.9216
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9952

Saving model as e910_model.pt & e910_waveforms_supplementary.hdf5
Learning rate: 9.797062359270201e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 911 [0/90000 (0%)]	Loss: 2.1377	Cost: 27.45s
Train Epoch: 911 [20480/90000 (23%)]	Loss: -1.2732	Cost: 13.99s
Train Epoch: 911 [40960/90000 (45%)]	Loss: -1.2087	Cost: 12.50s
Train Epoch: 911 [61440/90000 (68%)]	Loss: -1.0367	Cost: 8.77s
Train Epoch: 911 [81920/90000 (91%)]	Loss: -1.0311	Cost: 6.74s
Train Epoch: 911 	Average Loss: -0.9560
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1153

Learning rate: 9.796619147658394e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 912 [0/90000 (0%)]	Loss: 2.6885	Cost: 24.42s
Train Epoch: 912 [20480/90000 (23%)]	Loss: -1.2017	Cost: 11.22s
Train Epoch: 912 [40960/90000 (45%)]	Loss: -1.2376	Cost: 6.80s
Train Epoch: 912 [61440/90000 (68%)]	Loss: -1.4422	Cost: 6.68s
Train Epoch: 912 [81920/90000 (91%)]	Loss: -1.2996	Cost: 9.02s
Train Epoch: 912 	Average Loss: -1.0059
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0391

Learning rate: 9.796175462639258e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 913 [0/90000 (0%)]	Loss: 2.2339	Cost: 21.16s
Train Epoch: 913 [20480/90000 (23%)]	Loss: -1.3824	Cost: 9.26s
Train Epoch: 913 [40960/90000 (45%)]	Loss: -0.9464	Cost: 9.08s
Train Epoch: 913 [61440/90000 (68%)]	Loss: -1.2083	Cost: 8.74s
Train Epoch: 913 [81920/90000 (91%)]	Loss: -1.0141	Cost: 8.57s
Train Epoch: 913 	Average Loss: -0.9836
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1141

Learning rate: 9.79573130425658e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 914 [0/90000 (0%)]	Loss: 2.3904	Cost: 28.39s
Train Epoch: 914 [20480/90000 (23%)]	Loss: -1.2267	Cost: 8.68s
Train Epoch: 914 [40960/90000 (45%)]	Loss: -1.5148	Cost: 8.04s
Train Epoch: 914 [61440/90000 (68%)]	Loss: -1.4606	Cost: 6.18s
Train Epoch: 914 [81920/90000 (91%)]	Loss: -1.2263	Cost: 7.01s
Train Epoch: 914 	Average Loss: -1.0446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0274

Learning rate: 9.795286672554198e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 915 [0/90000 (0%)]	Loss: 2.1874	Cost: 22.12s
Train Epoch: 915 [20480/90000 (23%)]	Loss: -1.2716	Cost: 9.70s
Train Epoch: 915 [40960/90000 (45%)]	Loss: -1.2704	Cost: 9.65s
Train Epoch: 915 [61440/90000 (68%)]	Loss: -1.2668	Cost: 12.11s
Train Epoch: 915 [81920/90000 (91%)]	Loss: -1.1796	Cost: 12.40s
Train Epoch: 915 	Average Loss: -0.9770
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0859

Learning rate: 9.794841567575996e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 916 [0/90000 (0%)]	Loss: 2.3368	Cost: 24.02s
Train Epoch: 916 [20480/90000 (23%)]	Loss: -0.9118	Cost: 13.79s
Train Epoch: 916 [40960/90000 (45%)]	Loss: -1.0622	Cost: 13.53s
Train Epoch: 916 [61440/90000 (68%)]	Loss: -1.1931	Cost: 12.57s
Train Epoch: 916 [81920/90000 (91%)]	Loss: -0.9814	Cost: 12.55s
Train Epoch: 916 	Average Loss: -0.9288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1127

Learning rate: 9.794395989365903e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 917 [0/90000 (0%)]	Loss: 1.9321	Cost: 23.31s
Train Epoch: 917 [20480/90000 (23%)]	Loss: -1.2818	Cost: 11.35s
Train Epoch: 917 [40960/90000 (45%)]	Loss: -0.9459	Cost: 13.56s
Train Epoch: 917 [61440/90000 (68%)]	Loss: -1.1172	Cost: 12.61s
Train Epoch: 917 [81920/90000 (91%)]	Loss: -1.0286	Cost: 7.55s
Train Epoch: 917 	Average Loss: -0.8748
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1616

Learning rate: 9.793949937967896e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 918 [0/90000 (0%)]	Loss: 2.4077	Cost: 25.66s
Train Epoch: 918 [20480/90000 (23%)]	Loss: -1.1806	Cost: 12.55s
Train Epoch: 918 [40960/90000 (45%)]	Loss: -1.2306	Cost: 11.36s
Train Epoch: 918 [61440/90000 (68%)]	Loss: -1.2596	Cost: 6.19s
Train Epoch: 918 [81920/90000 (91%)]	Loss: -0.9749	Cost: 6.73s
Train Epoch: 918 	Average Loss: -0.9362
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2047

Learning rate: 9.793503413425998e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 919 [0/90000 (0%)]	Loss: 2.2585	Cost: 34.57s
Train Epoch: 919 [20480/90000 (23%)]	Loss: -1.2918	Cost: 6.52s
Train Epoch: 919 [40960/90000 (45%)]	Loss: -1.2374	Cost: 9.62s
Train Epoch: 919 [61440/90000 (68%)]	Loss: -1.3477	Cost: 8.62s
Train Epoch: 919 [81920/90000 (91%)]	Loss: -1.0780	Cost: 8.65s
Train Epoch: 919 	Average Loss: -1.0463
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0801

Learning rate: 9.793056415784282e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 920 [0/90000 (0%)]	Loss: 1.9847	Cost: 25.88s
Train Epoch: 920 [20480/90000 (23%)]	Loss: -1.3150	Cost: 9.14s
Train Epoch: 920 [40960/90000 (45%)]	Loss: -1.3695	Cost: 9.44s
Train Epoch: 920 [61440/90000 (68%)]	Loss: -1.3197	Cost: 9.02s
Train Epoch: 920 [81920/90000 (91%)]	Loss: -1.1897	Cost: 7.64s
Train Epoch: 920 	Average Loss: -1.0808
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9816

Saving model as e920_model.pt & e920_waveforms_supplementary.hdf5
Learning rate: 9.792608945086863e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 921 [0/90000 (0%)]	Loss: 1.9685	Cost: 22.75s
Train Epoch: 921 [20480/90000 (23%)]	Loss: -1.3150	Cost: 10.11s
Train Epoch: 921 [40960/90000 (45%)]	Loss: -1.4796	Cost: 15.57s
Train Epoch: 921 [61440/90000 (68%)]	Loss: -1.3648	Cost: 13.94s
Train Epoch: 921 [81920/90000 (91%)]	Loss: -1.2642	Cost: 11.96s
Train Epoch: 921 	Average Loss: -1.1596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0572

Learning rate: 9.792161001377905e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 922 [0/90000 (0%)]	Loss: 2.3937	Cost: 22.27s
Train Epoch: 922 [20480/90000 (23%)]	Loss: -1.3980	Cost: 13.52s
Train Epoch: 922 [40960/90000 (45%)]	Loss: -1.3509	Cost: 14.86s
Train Epoch: 922 [61440/90000 (68%)]	Loss: -1.7192	Cost: 12.84s
Train Epoch: 922 [81920/90000 (91%)]	Loss: -1.3269	Cost: 12.42s
Train Epoch: 922 	Average Loss: -1.1526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9033

Saving model as e922_model.pt & e922_waveforms_supplementary.hdf5
Learning rate: 9.791712584701618e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 923 [0/90000 (0%)]	Loss: 2.0341	Cost: 29.15s
Train Epoch: 923 [20480/90000 (23%)]	Loss: -1.5929	Cost: 13.30s
Train Epoch: 923 [40960/90000 (45%)]	Loss: -1.6572	Cost: 12.45s
Train Epoch: 923 [61440/90000 (68%)]	Loss: -1.5864	Cost: 12.21s
Train Epoch: 923 [81920/90000 (91%)]	Loss: -1.3338	Cost: 7.90s
Train Epoch: 923 	Average Loss: -1.2610
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9745

Learning rate: 9.791263695102257e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 924 [0/90000 (0%)]	Loss: 2.3673	Cost: 28.96s
Train Epoch: 924 [20480/90000 (23%)]	Loss: -1.2972	Cost: 12.72s
Train Epoch: 924 [40960/90000 (45%)]	Loss: -1.4914	Cost: 12.24s
Train Epoch: 924 [61440/90000 (68%)]	Loss: -1.5490	Cost: 9.45s
Train Epoch: 924 [81920/90000 (91%)]	Loss: -1.4308	Cost: 6.03s
Train Epoch: 924 	Average Loss: -1.2142
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9674

Learning rate: 9.790814332624128e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 925 [0/90000 (0%)]	Loss: 1.9358	Cost: 26.01s
Train Epoch: 925 [20480/90000 (23%)]	Loss: -1.5279	Cost: 8.85s
Train Epoch: 925 [40960/90000 (45%)]	Loss: -1.6716	Cost: 10.89s
Train Epoch: 925 [61440/90000 (68%)]	Loss: -0.7102	Cost: 6.09s
Train Epoch: 925 [81920/90000 (91%)]	Loss: -0.6576	Cost: 6.88s
Train Epoch: 925 	Average Loss: -0.8656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9016

Learning rate: 9.790364497311582e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 926 [0/90000 (0%)]	Loss: 2.7260	Cost: 24.83s
Train Epoch: 926 [20480/90000 (23%)]	Loss: -0.2755	Cost: 7.59s
Train Epoch: 926 [40960/90000 (45%)]	Loss: -0.5406	Cost: 11.15s
Train Epoch: 926 [61440/90000 (68%)]	Loss: -0.9567	Cost: 9.23s
Train Epoch: 926 [81920/90000 (91%)]	Loss: -0.9327	Cost: 8.92s
Train Epoch: 926 	Average Loss: -0.4290
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1505

Learning rate: 9.789914189209014e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 927 [0/90000 (0%)]	Loss: 2.3117	Cost: 21.48s
Train Epoch: 927 [20480/90000 (23%)]	Loss: -1.0782	Cost: 11.51s
Train Epoch: 927 [40960/90000 (45%)]	Loss: -1.3041	Cost: 9.60s
Train Epoch: 927 [61440/90000 (68%)]	Loss: -1.2735	Cost: 9.57s
Train Epoch: 927 [81920/90000 (91%)]	Loss: -0.9937	Cost: 7.60s
Train Epoch: 927 	Average Loss: -0.9530
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0254

Learning rate: 9.789463408360868e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 928 [0/90000 (0%)]	Loss: 2.0087	Cost: 26.07s
Train Epoch: 928 [20480/90000 (23%)]	Loss: -1.3698	Cost: 10.70s
Train Epoch: 928 [40960/90000 (45%)]	Loss: -1.4854	Cost: 11.23s
Train Epoch: 928 [61440/90000 (68%)]	Loss: -1.5820	Cost: 12.67s
Train Epoch: 928 [81920/90000 (91%)]	Loss: -1.3911	Cost: 12.38s
Train Epoch: 928 	Average Loss: -1.2326
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8423

Saving model as e928_model.pt & e928_waveforms_supplementary.hdf5
Learning rate: 9.789012154811634e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 929 [0/90000 (0%)]	Loss: 1.6694	Cost: 23.10s
Train Epoch: 929 [20480/90000 (23%)]	Loss: -1.4648	Cost: 13.87s
Train Epoch: 929 [40960/90000 (45%)]	Loss: -1.5548	Cost: 12.36s
Train Epoch: 929 [61440/90000 (68%)]	Loss: -1.7038	Cost: 12.07s
Train Epoch: 929 [81920/90000 (91%)]	Loss: -1.3526	Cost: 11.10s
Train Epoch: 929 	Average Loss: -1.2759
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9371

Learning rate: 9.788560428605849e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 930 [0/90000 (0%)]	Loss: 1.9465	Cost: 27.43s
Train Epoch: 930 [20480/90000 (23%)]	Loss: -1.5597	Cost: 12.44s
Train Epoch: 930 [40960/90000 (45%)]	Loss: -1.5143	Cost: 12.61s
Train Epoch: 930 [61440/90000 (68%)]	Loss: -1.6192	Cost: 9.22s
Train Epoch: 930 [81920/90000 (91%)]	Loss: -1.2492	Cost: 6.31s
Train Epoch: 930 	Average Loss: -1.1698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9476

Learning rate: 9.788108229788097e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 931 [0/90000 (0%)]	Loss: 1.9947	Cost: 27.27s
Train Epoch: 931 [20480/90000 (23%)]	Loss: -1.2014	Cost: 11.36s
Train Epoch: 931 [40960/90000 (45%)]	Loss: -1.5645	Cost: 10.72s
Train Epoch: 931 [61440/90000 (68%)]	Loss: -1.5732	Cost: 9.64s
Train Epoch: 931 [81920/90000 (91%)]	Loss: -0.9534	Cost: 6.19s
Train Epoch: 931 	Average Loss: -1.1308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1086

Learning rate: 9.78765555840301e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 932 [0/90000 (0%)]	Loss: 2.3861	Cost: 23.72s
Train Epoch: 932 [20480/90000 (23%)]	Loss: -1.2964	Cost: 9.93s
Train Epoch: 932 [40960/90000 (45%)]	Loss: -1.5408	Cost: 11.49s
Train Epoch: 932 [61440/90000 (68%)]	Loss: -1.4674	Cost: 8.62s
Train Epoch: 932 [81920/90000 (91%)]	Loss: -1.4121	Cost: 7.99s
Train Epoch: 932 	Average Loss: -1.1310
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9223

Learning rate: 9.787202414495261e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 933 [0/90000 (0%)]	Loss: 2.0566	Cost: 21.77s
Train Epoch: 933 [20480/90000 (23%)]	Loss: -1.4744	Cost: 9.60s
Train Epoch: 933 [40960/90000 (45%)]	Loss: -1.4512	Cost: 6.76s
Train Epoch: 933 [61440/90000 (68%)]	Loss: -1.6066	Cost: 7.37s
Train Epoch: 933 [81920/90000 (91%)]	Loss: -1.2912	Cost: 8.87s
Train Epoch: 933 	Average Loss: -1.2024
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8861

Learning rate: 9.786748798109577e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 934 [0/90000 (0%)]	Loss: 1.8367	Cost: 22.89s
Train Epoch: 934 [20480/90000 (23%)]	Loss: -1.1347	Cost: 9.78s
Train Epoch: 934 [40960/90000 (45%)]	Loss: -1.2178	Cost: 10.75s
Train Epoch: 934 [61440/90000 (68%)]	Loss: -1.4358	Cost: 8.91s
Train Epoch: 934 [81920/90000 (91%)]	Loss: -1.2322	Cost: 8.67s
Train Epoch: 934 	Average Loss: -1.0084
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9164

Learning rate: 9.786294709290727e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 935 [0/90000 (0%)]	Loss: 2.5339	Cost: 25.68s
Train Epoch: 935 [20480/90000 (23%)]	Loss: -1.5368	Cost: 9.95s
Train Epoch: 935 [40960/90000 (45%)]	Loss: -1.5498	Cost: 9.86s
Train Epoch: 935 [61440/90000 (68%)]	Loss: -1.7256	Cost: 8.70s
Train Epoch: 935 [81920/90000 (91%)]	Loss: -1.4541	Cost: 8.63s
Train Epoch: 935 	Average Loss: -1.3139
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8410

Saving model as e935_model.pt & e935_waveforms_supplementary.hdf5
Learning rate: 9.785840148083527e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 936 [0/90000 (0%)]	Loss: 2.1230	Cost: 20.05s
Train Epoch: 936 [20480/90000 (23%)]	Loss: -1.3456	Cost: 8.24s
Train Epoch: 936 [40960/90000 (45%)]	Loss: -1.3860	Cost: 7.25s
Train Epoch: 936 [61440/90000 (68%)]	Loss: -1.5687	Cost: 8.64s
Train Epoch: 936 [81920/90000 (91%)]	Loss: -1.3870	Cost: 8.97s
Train Epoch: 936 	Average Loss: -1.2232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8560

Learning rate: 9.785385114532841e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 937 [0/90000 (0%)]	Loss: 1.9832	Cost: 21.27s
Train Epoch: 937 [20480/90000 (23%)]	Loss: -1.5101	Cost: 8.17s
Train Epoch: 937 [40960/90000 (45%)]	Loss: -1.4317	Cost: 12.10s
Train Epoch: 937 [61440/90000 (68%)]	Loss: -1.4653	Cost: 12.38s
Train Epoch: 937 [81920/90000 (91%)]	Loss: -1.3444	Cost: 12.58s
Train Epoch: 937 	Average Loss: -1.2014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8788

Learning rate: 9.78492960868358e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 938 [0/90000 (0%)]	Loss: 1.9113	Cost: 23.73s
Train Epoch: 938 [20480/90000 (23%)]	Loss: -1.6097	Cost: 15.56s
Train Epoch: 938 [40960/90000 (45%)]	Loss: -1.4073	Cost: 14.08s
Train Epoch: 938 [61440/90000 (68%)]	Loss: -1.6522	Cost: 12.25s
Train Epoch: 938 [81920/90000 (91%)]	Loss: -1.6344	Cost: 10.61s
Train Epoch: 938 	Average Loss: -1.3391
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7616

Saving model as e938_model.pt & e938_waveforms_supplementary.hdf5
Learning rate: 9.784473630580698e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 939 [0/90000 (0%)]	Loss: 1.6001	Cost: 42.33s
Train Epoch: 939 [20480/90000 (23%)]	Loss: -1.6013	Cost: 12.33s
Train Epoch: 939 [40960/90000 (45%)]	Loss: -1.6586	Cost: 7.32s
Train Epoch: 939 [61440/90000 (68%)]	Loss: -1.7424	Cost: 6.31s
Train Epoch: 939 [81920/90000 (91%)]	Loss: -1.6038	Cost: 7.93s
Train Epoch: 939 	Average Loss: -1.4503
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7391

Saving model as e939_model.pt & e939_waveforms_supplementary.hdf5
Learning rate: 9.784017180269201e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 940 [0/90000 (0%)]	Loss: 1.7167	Cost: 30.00s
Train Epoch: 940 [20480/90000 (23%)]	Loss: -1.3938	Cost: 6.50s
Train Epoch: 940 [40960/90000 (45%)]	Loss: -1.4143	Cost: 9.45s
Train Epoch: 940 [61440/90000 (68%)]	Loss: -1.4374	Cost: 8.81s
Train Epoch: 940 [81920/90000 (91%)]	Loss: -1.4067	Cost: 8.58s
Train Epoch: 940 	Average Loss: -1.2424
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0537

Learning rate: 9.783560257794138e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 941 [0/90000 (0%)]	Loss: 1.9212	Cost: 21.10s
Train Epoch: 941 [20480/90000 (23%)]	Loss: -1.5224	Cost: 9.53s
Train Epoch: 941 [40960/90000 (45%)]	Loss: -1.7082	Cost: 8.86s
Train Epoch: 941 [61440/90000 (68%)]	Loss: -1.6421	Cost: 9.12s
Train Epoch: 941 [81920/90000 (91%)]	Loss: -1.4352	Cost: 8.98s
Train Epoch: 941 	Average Loss: -1.2527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8349

Learning rate: 9.783102863200605e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 942 [0/90000 (0%)]	Loss: 1.7178	Cost: 19.73s
Train Epoch: 942 [20480/90000 (23%)]	Loss: -1.5509	Cost: 7.22s
Train Epoch: 942 [40960/90000 (45%)]	Loss: -1.5084	Cost: 12.21s
Train Epoch: 942 [61440/90000 (68%)]	Loss: -1.5817	Cost: 11.32s
Train Epoch: 942 [81920/90000 (91%)]	Loss: -1.6096	Cost: 12.68s
Train Epoch: 942 	Average Loss: -1.3018
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8174

Learning rate: 9.782644996533745e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 943 [0/90000 (0%)]	Loss: 2.0500	Cost: 26.79s
Train Epoch: 943 [20480/90000 (23%)]	Loss: -1.5608	Cost: 11.63s
Train Epoch: 943 [40960/90000 (45%)]	Loss: -1.6557	Cost: 14.21s
Train Epoch: 943 [61440/90000 (68%)]	Loss: -1.8159	Cost: 12.19s
Train Epoch: 943 [81920/90000 (91%)]	Loss: -1.5796	Cost: 11.90s
Train Epoch: 943 	Average Loss: -1.3823
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8314

Learning rate: 9.782186657838747e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 944 [0/90000 (0%)]	Loss: 1.6796	Cost: 35.23s
Train Epoch: 944 [20480/90000 (23%)]	Loss: -1.7073	Cost: 10.59s
Train Epoch: 944 [40960/90000 (45%)]	Loss: -1.7586	Cost: 12.51s
Train Epoch: 944 [61440/90000 (68%)]	Loss: -1.8692	Cost: 12.09s
Train Epoch: 944 [81920/90000 (91%)]	Loss: -1.4095	Cost: 7.34s
Train Epoch: 944 	Average Loss: -1.4055
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8286

Learning rate: 9.781727847160849e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 945 [0/90000 (0%)]	Loss: 1.9908	Cost: 25.15s
Train Epoch: 945 [20480/90000 (23%)]	Loss: -1.7359	Cost: 12.49s
Train Epoch: 945 [40960/90000 (45%)]	Loss: -1.8327	Cost: 12.00s
Train Epoch: 945 [61440/90000 (68%)]	Loss: -1.8063	Cost: 6.14s
Train Epoch: 945 [81920/90000 (91%)]	Loss: -1.5179	Cost: 6.40s
Train Epoch: 945 	Average Loss: -1.4296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6800

Saving model as e945_model.pt & e945_waveforms_supplementary.hdf5
Learning rate: 9.781268564545331e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 946 [0/90000 (0%)]	Loss: 1.4577	Cost: 24.30s
Train Epoch: 946 [20480/90000 (23%)]	Loss: -1.6328	Cost: 7.44s
Train Epoch: 946 [40960/90000 (45%)]	Loss: -1.9008	Cost: 10.80s
Train Epoch: 946 [61440/90000 (68%)]	Loss: -1.9620	Cost: 9.85s
Train Epoch: 946 [81920/90000 (91%)]	Loss: -1.1063	Cost: 9.05s
Train Epoch: 946 	Average Loss: -1.4298
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9869

Learning rate: 9.780808810037527e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 947 [0/90000 (0%)]	Loss: 2.1099	Cost: 23.09s
Train Epoch: 947 [20480/90000 (23%)]	Loss: -1.3583	Cost: 11.17s
Train Epoch: 947 [40960/90000 (45%)]	Loss: -1.5046	Cost: 10.92s
Train Epoch: 947 [61440/90000 (68%)]	Loss: -1.1815	Cost: 6.78s
Train Epoch: 947 [81920/90000 (91%)]	Loss: -1.1563	Cost: 7.23s
Train Epoch: 947 	Average Loss: -1.1014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9673

Learning rate: 9.780348583682808e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 948 [0/90000 (0%)]	Loss: 2.3150	Cost: 21.17s
Train Epoch: 948 [20480/90000 (23%)]	Loss: -1.4136	Cost: 8.92s
Train Epoch: 948 [40960/90000 (45%)]	Loss: -1.6251	Cost: 10.27s
Train Epoch: 948 [61440/90000 (68%)]	Loss: -1.7433	Cost: 12.59s
Train Epoch: 948 [81920/90000 (91%)]	Loss: -1.5445	Cost: 12.50s
Train Epoch: 948 	Average Loss: -1.3096
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7641

Learning rate: 9.779887885526599e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 949 [0/90000 (0%)]	Loss: 1.8532	Cost: 23.43s
Train Epoch: 949 [20480/90000 (23%)]	Loss: -1.7589	Cost: 13.98s
Train Epoch: 949 [40960/90000 (45%)]	Loss: -2.0082	Cost: 12.55s
Train Epoch: 949 [61440/90000 (68%)]	Loss: -1.8199	Cost: 12.14s
Train Epoch: 949 [81920/90000 (91%)]	Loss: -1.5616	Cost: 12.47s
Train Epoch: 949 	Average Loss: -1.4932
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7579

Learning rate: 9.77942671561437e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 950 [0/90000 (0%)]	Loss: 1.8626	Cost: 25.39s
Train Epoch: 950 [20480/90000 (23%)]	Loss: -1.8029	Cost: 12.69s
Train Epoch: 950 [40960/90000 (45%)]	Loss: -1.8425	Cost: 12.58s
Train Epoch: 950 [61440/90000 (68%)]	Loss: -2.0706	Cost: 9.01s
Train Epoch: 950 [81920/90000 (91%)]	Loss: -1.6746	Cost: 6.25s
Train Epoch: 950 	Average Loss: -1.5375
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6124

Saving model as e950_model.pt & e950_waveforms_supplementary.hdf5
Learning rate: 9.778965073991635e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 951 [0/90000 (0%)]	Loss: 1.5707	Cost: 34.98s
Train Epoch: 951 [20480/90000 (23%)]	Loss: -1.7589	Cost: 11.12s
Train Epoch: 951 [40960/90000 (45%)]	Loss: -1.8446	Cost: 9.66s
Train Epoch: 951 [61440/90000 (68%)]	Loss: -1.8193	Cost: 7.05s
Train Epoch: 951 [81920/90000 (91%)]	Loss: -1.6389	Cost: 8.58s
Train Epoch: 951 	Average Loss: -1.5177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7518

Learning rate: 9.778502960703957e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 952 [0/90000 (0%)]	Loss: 1.5372	Cost: 20.83s
Train Epoch: 952 [20480/90000 (23%)]	Loss: -1.7153	Cost: 8.79s
Train Epoch: 952 [40960/90000 (45%)]	Loss: -1.7741	Cost: 9.53s
Train Epoch: 952 [61440/90000 (68%)]	Loss: -2.0209	Cost: 8.89s
Train Epoch: 952 [81920/90000 (91%)]	Loss: -1.7055	Cost: 9.06s
Train Epoch: 952 	Average Loss: -1.5195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7359

Learning rate: 9.778040375796944e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 953 [0/90000 (0%)]	Loss: 1.7354	Cost: 24.55s
Train Epoch: 953 [20480/90000 (23%)]	Loss: -1.7154	Cost: 7.65s
Train Epoch: 953 [40960/90000 (45%)]	Loss: -1.9137	Cost: 8.90s
Train Epoch: 953 [61440/90000 (68%)]	Loss: -1.9600	Cost: 8.66s
Train Epoch: 953 [81920/90000 (91%)]	Loss: -1.6801	Cost: 8.41s
Train Epoch: 953 	Average Loss: -1.5716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6561

Learning rate: 9.777577319316251e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 954 [0/90000 (0%)]	Loss: 1.9706	Cost: 27.17s
Train Epoch: 954 [20480/90000 (23%)]	Loss: -1.9197	Cost: 8.67s
Train Epoch: 954 [40960/90000 (45%)]	Loss: -1.9150	Cost: 8.83s
Train Epoch: 954 [61440/90000 (68%)]	Loss: -2.1326	Cost: 6.23s
Train Epoch: 954 [81920/90000 (91%)]	Loss: -1.8041	Cost: 6.35s
Train Epoch: 954 	Average Loss: -1.6844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7466

Learning rate: 9.777113791307581e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 955 [0/90000 (0%)]	Loss: 2.0276	Cost: 22.58s
Train Epoch: 955 [20480/90000 (23%)]	Loss: -1.6709	Cost: 8.01s
Train Epoch: 955 [40960/90000 (45%)]	Loss: -1.6156	Cost: 8.81s
Train Epoch: 955 [61440/90000 (68%)]	Loss: -1.8964	Cost: 12.21s
Train Epoch: 955 [81920/90000 (91%)]	Loss: -1.7451	Cost: 12.73s
Train Epoch: 955 	Average Loss: -1.5133
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6423

Learning rate: 9.776649791816682e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 956 [0/90000 (0%)]	Loss: 1.8088	Cost: 30.11s
Train Epoch: 956 [20480/90000 (23%)]	Loss: -1.7391	Cost: 15.50s
Train Epoch: 956 [40960/90000 (45%)]	Loss: -1.8523	Cost: 14.43s
Train Epoch: 956 [61440/90000 (68%)]	Loss: -1.9775	Cost: 12.59s
Train Epoch: 956 [81920/90000 (91%)]	Loss: -1.8510	Cost: 12.16s
Train Epoch: 956 	Average Loss: -1.5910
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7312

Learning rate: 9.776185320889348e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 957 [0/90000 (0%)]	Loss: 1.6150	Cost: 31.04s
Train Epoch: 957 [20480/90000 (23%)]	Loss: -1.0945	Cost: 13.74s
Train Epoch: 957 [40960/90000 (45%)]	Loss: -1.4315	Cost: 13.93s
Train Epoch: 957 [61440/90000 (68%)]	Loss: -1.4868	Cost: 12.15s
Train Epoch: 957 [81920/90000 (91%)]	Loss: -1.2114	Cost: 6.60s
Train Epoch: 957 	Average Loss: -1.1270
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9414

Learning rate: 9.775720378571423e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 958 [0/90000 (0%)]	Loss: 1.8153	Cost: 34.02s
Train Epoch: 958 [20480/90000 (23%)]	Loss: -1.5736	Cost: 12.04s
Train Epoch: 958 [40960/90000 (45%)]	Loss: -1.6127	Cost: 10.07s
Train Epoch: 958 [61440/90000 (68%)]	Loss: -1.8384	Cost: 6.22s
Train Epoch: 958 [81920/90000 (91%)]	Loss: -1.5357	Cost: 7.42s
Train Epoch: 958 	Average Loss: -1.4467
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6597

Learning rate: 9.775254964908792e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 959 [0/90000 (0%)]	Loss: 1.4217	Cost: 30.35s
Train Epoch: 959 [20480/90000 (23%)]	Loss: -1.6086	Cost: 10.24s
Train Epoch: 959 [40960/90000 (45%)]	Loss: -1.8834	Cost: 9.73s
Train Epoch: 959 [61440/90000 (68%)]	Loss: -1.8754	Cost: 6.28s
Train Epoch: 959 [81920/90000 (91%)]	Loss: -1.7529	Cost: 6.99s
Train Epoch: 959 	Average Loss: -1.5784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5966

Saving model as e959_model.pt & e959_waveforms_supplementary.hdf5
Learning rate: 9.774789079947391e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 960 [0/90000 (0%)]	Loss: 1.7524	Cost: 28.34s
Train Epoch: 960 [20480/90000 (23%)]	Loss: -2.0643	Cost: 7.05s
Train Epoch: 960 [40960/90000 (45%)]	Loss: -2.1376	Cost: 10.14s
Train Epoch: 960 [61440/90000 (68%)]	Loss: -2.1189	Cost: 8.64s
Train Epoch: 960 [81920/90000 (91%)]	Loss: -1.7745	Cost: 8.39s
Train Epoch: 960 	Average Loss: -1.6715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5758

Saving model as e960_model.pt & e960_waveforms_supplementary.hdf5
Learning rate: 9.774322723733201e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 961 [0/90000 (0%)]	Loss: 1.4267	Cost: 25.31s
Train Epoch: 961 [20480/90000 (23%)]	Loss: -2.1540	Cost: 9.19s
Train Epoch: 961 [40960/90000 (45%)]	Loss: -2.0333	Cost: 10.96s
Train Epoch: 961 [61440/90000 (68%)]	Loss: -2.1671	Cost: 6.81s
Train Epoch: 961 [81920/90000 (91%)]	Loss: -1.9351	Cost: 9.49s
Train Epoch: 961 	Average Loss: -1.7826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5696

Saving model as e961_model.pt & e961_waveforms_supplementary.hdf5
Learning rate: 9.773855896312248e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 962 [0/90000 (0%)]	Loss: 1.7306	Cost: 19.75s
Train Epoch: 962 [20480/90000 (23%)]	Loss: -1.8733	Cost: 10.70s
Train Epoch: 962 [40960/90000 (45%)]	Loss: -1.9854	Cost: 14.51s
Train Epoch: 962 [61440/90000 (68%)]	Loss: -2.0283	Cost: 14.49s
Train Epoch: 962 [81920/90000 (91%)]	Loss: -1.8263	Cost: 13.19s
Train Epoch: 962 	Average Loss: -1.6479
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5258

Saving model as e962_model.pt & e962_waveforms_supplementary.hdf5
Learning rate: 9.773388597730608e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 963 [0/90000 (0%)]	Loss: 1.6934	Cost: 28.30s
Train Epoch: 963 [20480/90000 (23%)]	Loss: -1.9013	Cost: 15.34s
Train Epoch: 963 [40960/90000 (45%)]	Loss: -1.7627	Cost: 12.73s
Train Epoch: 963 [61440/90000 (68%)]	Loss: -2.0256	Cost: 12.32s
Train Epoch: 963 [81920/90000 (91%)]	Loss: -1.9140	Cost: 11.28s
Train Epoch: 963 	Average Loss: -1.6617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5237

Saving model as e963_model.pt & e963_waveforms_supplementary.hdf5
Learning rate: 9.772920828034401e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 964 [0/90000 (0%)]	Loss: 1.8274	Cost: 24.65s
Train Epoch: 964 [20480/90000 (23%)]	Loss: -1.7957	Cost: 13.29s
Train Epoch: 964 [40960/90000 (45%)]	Loss: -1.9001	Cost: 10.26s
Train Epoch: 964 [61440/90000 (68%)]	Loss: -2.0815	Cost: 6.06s
Train Epoch: 964 [81920/90000 (91%)]	Loss: -1.6216	Cost: 7.49s
Train Epoch: 964 	Average Loss: -1.6214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7623

Learning rate: 9.772452587269794e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 965 [0/90000 (0%)]	Loss: 2.3754	Cost: 24.63s
Train Epoch: 965 [20480/90000 (23%)]	Loss: -1.7672	Cost: 6.50s
Train Epoch: 965 [40960/90000 (45%)]	Loss: -1.9171	Cost: 7.92s
Train Epoch: 965 [61440/90000 (68%)]	Loss: -2.0389	Cost: 9.01s
Train Epoch: 965 [81920/90000 (91%)]	Loss: -1.8427	Cost: 9.04s
Train Epoch: 965 	Average Loss: -1.5759
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5317

Learning rate: 9.771983875482999e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 966 [0/90000 (0%)]	Loss: 1.4701	Cost: 26.30s
Train Epoch: 966 [20480/90000 (23%)]	Loss: -1.7601	Cost: 10.67s
Train Epoch: 966 [40960/90000 (45%)]	Loss: -0.4485	Cost: 10.27s
Train Epoch: 966 [61440/90000 (68%)]	Loss: -0.9162	Cost: 8.71s
Train Epoch: 966 [81920/90000 (91%)]	Loss: -0.8631	Cost: 8.08s
Train Epoch: 966 	Average Loss: -0.8493
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1853

Learning rate: 9.771514692720278e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 967 [0/90000 (0%)]	Loss: 1.8694	Cost: 30.69s
Train Epoch: 967 [20480/90000 (23%)]	Loss: -1.4028	Cost: 8.58s
Train Epoch: 967 [40960/90000 (45%)]	Loss: -1.6869	Cost: 6.48s
Train Epoch: 967 [61440/90000 (68%)]	Loss: -1.5921	Cost: 7.29s
Train Epoch: 967 [81920/90000 (91%)]	Loss: -1.5354	Cost: 8.28s
Train Epoch: 967 	Average Loss: -1.3181
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6800

Learning rate: 9.771045039027936e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 968 [0/90000 (0%)]	Loss: 1.9869	Cost: 20.41s
Train Epoch: 968 [20480/90000 (23%)]	Loss: -1.9230	Cost: 7.13s
Train Epoch: 968 [40960/90000 (45%)]	Loss: -1.9345	Cost: 14.23s
Train Epoch: 968 [61440/90000 (68%)]	Loss: -2.0479	Cost: 13.04s
Train Epoch: 968 [81920/90000 (91%)]	Loss: -1.6757	Cost: 12.61s
Train Epoch: 968 	Average Loss: -1.6978
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6033

Learning rate: 9.770574914452328e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 969 [0/90000 (0%)]	Loss: 1.8530	Cost: 25.03s
Train Epoch: 969 [20480/90000 (23%)]	Loss: -2.0677	Cost: 12.65s
Train Epoch: 969 [40960/90000 (45%)]	Loss: -2.0548	Cost: 12.47s
Train Epoch: 969 [61440/90000 (68%)]	Loss: -2.2212	Cost: 12.44s
Train Epoch: 969 [81920/90000 (91%)]	Loss: -1.7675	Cost: 12.53s
Train Epoch: 969 	Average Loss: -1.7329
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6263

Learning rate: 9.770104319039851e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 970 [0/90000 (0%)]	Loss: 1.9614	Cost: 23.24s
Train Epoch: 970 [20480/90000 (23%)]	Loss: -1.8564	Cost: 13.71s
Train Epoch: 970 [40960/90000 (45%)]	Loss: -1.7530	Cost: 12.43s
Train Epoch: 970 [61440/90000 (68%)]	Loss: -1.8888	Cost: 6.79s
Train Epoch: 970 [81920/90000 (91%)]	Loss: -1.9330	Cost: 6.17s
Train Epoch: 970 	Average Loss: -1.6069
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5340

Learning rate: 9.769633252836953e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 971 [0/90000 (0%)]	Loss: 1.5413	Cost: 34.82s
Train Epoch: 971 [20480/90000 (23%)]	Loss: -1.7733	Cost: 8.75s
Train Epoch: 971 [40960/90000 (45%)]	Loss: -2.0418	Cost: 7.41s
Train Epoch: 971 [61440/90000 (68%)]	Loss: -2.0897	Cost: 7.24s
Train Epoch: 971 [81920/90000 (91%)]	Loss: -1.9339	Cost: 8.61s
Train Epoch: 971 	Average Loss: -1.7498
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4246

Saving model as e971_model.pt & e971_waveforms_supplementary.hdf5
Learning rate: 9.769161715890125e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 972 [0/90000 (0%)]	Loss: 1.6172	Cost: 25.17s
Train Epoch: 972 [20480/90000 (23%)]	Loss: -2.1115	Cost: 8.65s
Train Epoch: 972 [40960/90000 (45%)]	Loss: -1.6680	Cost: 9.18s
Train Epoch: 972 [61440/90000 (68%)]	Loss: -1.5141	Cost: 8.79s
Train Epoch: 972 [81920/90000 (91%)]	Loss: -1.2626	Cost: 8.58s
Train Epoch: 972 	Average Loss: -1.4875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9230

Learning rate: 9.768689708245906e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 973 [0/90000 (0%)]	Loss: 2.2301	Cost: 20.13s
Train Epoch: 973 [20480/90000 (23%)]	Loss: -1.5580	Cost: 9.43s
Train Epoch: 973 [40960/90000 (45%)]	Loss: -1.8671	Cost: 8.90s
Train Epoch: 973 [61440/90000 (68%)]	Loss: -2.0447	Cost: 9.15s
Train Epoch: 973 [81920/90000 (91%)]	Loss: -1.8018	Cost: 6.53s
Train Epoch: 973 	Average Loss: -1.5266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6081

Learning rate: 9.768217229950883e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 974 [0/90000 (0%)]	Loss: 1.4215	Cost: 20.68s
Train Epoch: 974 [20480/90000 (23%)]	Loss: -2.0884	Cost: 8.13s
Train Epoch: 974 [40960/90000 (45%)]	Loss: -2.1452	Cost: 9.50s
Train Epoch: 974 [61440/90000 (68%)]	Loss: -2.2206	Cost: 10.21s
Train Epoch: 974 [81920/90000 (91%)]	Loss: -2.1019	Cost: 14.01s
Train Epoch: 974 	Average Loss: -1.8232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3487

Saving model as e974_model.pt & e974_waveforms_supplementary.hdf5
Learning rate: 9.767744281051684e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 975 [0/90000 (0%)]	Loss: 1.5214	Cost: 22.22s
Train Epoch: 975 [20480/90000 (23%)]	Loss: -2.1163	Cost: 12.20s
Train Epoch: 975 [40960/90000 (45%)]	Loss: -2.2259	Cost: 14.25s
Train Epoch: 975 [61440/90000 (68%)]	Loss: -2.2077	Cost: 12.09s
Train Epoch: 975 [81920/90000 (91%)]	Loss: -2.0176	Cost: 12.07s
Train Epoch: 975 	Average Loss: -1.8227
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5264

Learning rate: 9.767270861594989e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 976 [0/90000 (0%)]	Loss: 1.4200	Cost: 33.96s
Train Epoch: 976 [20480/90000 (23%)]	Loss: -1.8377	Cost: 11.22s
Train Epoch: 976 [40960/90000 (45%)]	Loss: -2.0383	Cost: 12.51s
Train Epoch: 976 [61440/90000 (68%)]	Loss: -2.1491	Cost: 12.09s
Train Epoch: 976 [81920/90000 (91%)]	Loss: -1.9377	Cost: 7.73s
Train Epoch: 976 	Average Loss: -1.7847
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6633

Learning rate: 9.766796971627527e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 977 [0/90000 (0%)]	Loss: 1.6350	Cost: 30.67s
Train Epoch: 977 [20480/90000 (23%)]	Loss: -1.9782	Cost: 12.57s
Train Epoch: 977 [40960/90000 (45%)]	Loss: -2.1905	Cost: 10.82s
Train Epoch: 977 [61440/90000 (68%)]	Loss: -2.2308	Cost: 6.34s
Train Epoch: 977 [81920/90000 (91%)]	Loss: -2.0158	Cost: 6.25s
Train Epoch: 977 	Average Loss: -1.8577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4281

Learning rate: 9.766322611196063e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 978 [0/90000 (0%)]	Loss: 1.4575	Cost: 28.13s
Train Epoch: 978 [20480/90000 (23%)]	Loss: -2.1589	Cost: 7.11s
Train Epoch: 978 [40960/90000 (45%)]	Loss: -2.0358	Cost: 10.59s
Train Epoch: 978 [61440/90000 (68%)]	Loss: -2.2188	Cost: 9.12s
Train Epoch: 978 [81920/90000 (91%)]	Loss: -2.1779	Cost: 8.91s
Train Epoch: 978 	Average Loss: -1.8852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5519

Learning rate: 9.765847780347416e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 979 [0/90000 (0%)]	Loss: 1.6771	Cost: 21.82s
Train Epoch: 979 [20480/90000 (23%)]	Loss: -1.9612	Cost: 9.71s
Train Epoch: 979 [40960/90000 (45%)]	Loss: -2.2743	Cost: 12.14s
Train Epoch: 979 [61440/90000 (68%)]	Loss: -2.0217	Cost: 9.05s
Train Epoch: 979 [81920/90000 (91%)]	Loss: -1.8060	Cost: 8.70s
Train Epoch: 979 	Average Loss: -1.8217
