Nestedspace(activation='elu', apply_unconditional_transform=False, base_transform_type='rq-coupling', basis_dir='data/GW170729_sample_prior_basis/', batch_norm=True, batch_size=2048, bw_dstar=None, cuda=True, data_dir='data/GW170729_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, dropout_probability=0.0, epochs=10000, flow_lr=None, hidden_dims=512, kl_annealing=True, lr=0.0001, lr_anneal_method='cosine', lr_annealing=True, mixed_alpha=0.0, mode='train', model_dir='models/GW170729_sample_uniform_100basis_all_posterior_prior/', model_source='new', model_type='nde', nbins=8, nflows=15, nsample=100000, nsamples_target_event=50000, num_transform_blocks=10, output_freq=10, sampling_from='posterior', save=True, save_aux_filename='waveforms_supplementary.hdf5', save_model_name='model.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, tail_bound=1.0, truncate_basis=100)
Waveform directory data/GW170729_sample_prior_basis/
Model directory models/GW170729_sample_uniform_100basis_all_posterior_prior/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from posterior prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Detectors: ['H1', 'L1', 'V1']

Constructing model of type nde

Initial learning rate 0.0001
Using cosine LR annealing.

Model hyperparameters:
input_dim 	 15
num_flow_steps 	 15
context_dim 	 600
base_transform_kwargs
	 hidden_dim 	 512
	 num_transform_blocks 	 10
	 activation 	 elu
	 dropout_probability 	 0.0
	 batch_norm 	 True
	 num_bins 	 8
	 tail_bound 	 1.0
	 apply_unconditional_transform 	 False
	 base_transform_type 	 rq-coupling

Training for 10000 epochs
Starting timer
Learning rate: 0.0001
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 28.7111	Cost: 18.45s
Train Epoch: 1 [20480/90000 (23%)]	Loss: 21.8260	Cost: 6.12s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 21.1473	Cost: 8.25s
Train Epoch: 1 [61440/90000 (68%)]	Loss: 20.6578	Cost: 6.14s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 20.2973	Cost: 8.03s
Train Epoch: 1 	Average Loss: 21.7875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.1444

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 9.999999753259892e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 20.0824	Cost: 20.86s
Train Epoch: 2 [20480/90000 (23%)]	Loss: 19.7930	Cost: 6.99s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 19.6204	Cost: 7.82s
Train Epoch: 2 [61440/90000 (68%)]	Loss: 19.4452	Cost: 6.37s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 19.2602	Cost: 6.15s
Train Epoch: 2 	Average Loss: 19.6025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.2103

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 9.999999013039593e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 19.3642	Cost: 21.00s
Train Epoch: 3 [20480/90000 (23%)]	Loss: 18.9504	Cost: 6.26s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 18.7380	Cost: 8.27s
Train Epoch: 3 [61440/90000 (68%)]	Loss: 18.6985	Cost: 6.08s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 18.5069	Cost: 7.02s
Train Epoch: 3 	Average Loss: 18.7913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3671

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 9.999997779339173e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 18.3157	Cost: 19.80s
Train Epoch: 4 [20480/90000 (23%)]	Loss: 18.1563	Cost: 6.48s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 18.0344	Cost: 6.67s
Train Epoch: 4 [61440/90000 (68%)]	Loss: 17.8159	Cost: 6.69s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 17.7887	Cost: 7.39s
Train Epoch: 4 	Average Loss: 18.0036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.6936

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 9.99999605215876e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 17.6342	Cost: 19.05s
Train Epoch: 5 [20480/90000 (23%)]	Loss: 17.4247	Cost: 6.26s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 17.4487	Cost: 8.64s
Train Epoch: 5 [61440/90000 (68%)]	Loss: 17.4355	Cost: 6.23s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 17.3454	Cost: 8.70s
Train Epoch: 5 	Average Loss: 17.4378
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.2668

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 9.999993831498517e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 17.2192	Cost: 20.50s
Train Epoch: 6 [20480/90000 (23%)]	Loss: 17.1259	Cost: 6.68s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 16.9629	Cost: 9.28s
Train Epoch: 6 [61440/90000 (68%)]	Loss: 17.0637	Cost: 6.77s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 16.8065	Cost: 14.94s
Train Epoch: 6 	Average Loss: 17.0331
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.7971

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 9.999991117358668e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 16.9012	Cost: 26.83s
Train Epoch: 7 [20480/90000 (23%)]	Loss: 16.7082	Cost: 9.10s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 16.5673	Cost: 12.69s
Train Epoch: 7 [61440/90000 (68%)]	Loss: 16.5576	Cost: 12.41s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 16.5498	Cost: 12.38s
Train Epoch: 7 	Average Loss: 16.6758
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.5720

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 9.99998790973948e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 16.5777	Cost: 27.91s
Train Epoch: 8 [20480/90000 (23%)]	Loss: 16.3636	Cost: 16.17s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 16.3348	Cost: 14.53s
Train Epoch: 8 [61440/90000 (68%)]	Loss: 16.3956	Cost: 12.39s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 16.2945	Cost: 12.19s
Train Epoch: 8 	Average Loss: 16.3900
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.3296

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 9.99998420864127e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 16.2254	Cost: 42.45s
Train Epoch: 9 [20480/90000 (23%)]	Loss: 16.1827	Cost: 13.96s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 16.0713	Cost: 12.02s
Train Epoch: 9 [61440/90000 (68%)]	Loss: 16.1352	Cost: 6.22s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 16.0667	Cost: 6.08s
Train Epoch: 9 	Average Loss: 16.1686
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.1285

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 9.999980014064402e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 15.9454	Cost: 28.60s
Train Epoch: 10 [20480/90000 (23%)]	Loss: 15.8951	Cost: 12.41s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 15.8144	Cost: 10.24s
Train Epoch: 10 [61440/90000 (68%)]	Loss: 15.9034	Cost: 6.16s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 15.9627	Cost: 7.90s
Train Epoch: 10 	Average Loss: 15.9398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.9419

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 9.999975326009292e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 15.8815	Cost: 25.17s
Train Epoch: 11 [20480/90000 (23%)]	Loss: 15.8163	Cost: 9.34s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 15.7887	Cost: 6.95s
Train Epoch: 11 [61440/90000 (68%)]	Loss: 15.7339	Cost: 6.10s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 15.7948	Cost: 7.59s
Train Epoch: 11 	Average Loss: 15.7774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6589

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 9.999970144476398e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 15.7210	Cost: 28.25s
Train Epoch: 12 [20480/90000 (23%)]	Loss: 15.5645	Cost: 12.42s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 15.5170	Cost: 11.01s
Train Epoch: 12 [61440/90000 (68%)]	Loss: 15.5672	Cost: 6.07s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 15.5620	Cost: 6.87s
Train Epoch: 12 	Average Loss: 15.5931
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.5636

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 9.999964469466236e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 15.5623	Cost: 29.39s
Train Epoch: 13 [20480/90000 (23%)]	Loss: 15.4838	Cost: 10.41s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 15.4141	Cost: 6.29s
Train Epoch: 13 [61440/90000 (68%)]	Loss: 15.5482	Cost: 6.33s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 15.5052	Cost: 8.75s
Train Epoch: 13 	Average Loss: 15.4655
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.3936

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Learning rate: 9.999958300979366e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 15.4970	Cost: 22.04s
Train Epoch: 14 [20480/90000 (23%)]	Loss: 15.3460	Cost: 8.95s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 15.2933	Cost: 9.18s
Train Epoch: 14 [61440/90000 (68%)]	Loss: 15.3972	Cost: 8.91s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 15.1968	Cost: 8.43s
Train Epoch: 14 	Average Loss: 15.3314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2696

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Learning rate: 9.999951639016395e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 15.2975	Cost: 20.32s
Train Epoch: 15 [20480/90000 (23%)]	Loss: 15.1529	Cost: 9.23s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 15.0943	Cost: 10.68s
Train Epoch: 15 [61440/90000 (68%)]	Loss: 15.1692	Cost: 11.78s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 15.1394	Cost: 12.50s
Train Epoch: 15 	Average Loss: 15.1956
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.1775

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Learning rate: 9.999944483577981e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 15.1008	Cost: 26.39s
Train Epoch: 16 [20480/90000 (23%)]	Loss: 15.2019	Cost: 11.35s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 14.9693	Cost: 12.89s
Train Epoch: 16 [61440/90000 (68%)]	Loss: 15.0430	Cost: 12.22s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 15.0011	Cost: 12.17s
Train Epoch: 16 	Average Loss: 15.0841
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.0613

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Learning rate: 9.99993683466483e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 15.0399	Cost: 24.10s
Train Epoch: 17 [20480/90000 (23%)]	Loss: 14.8649	Cost: 11.23s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 14.8849	Cost: 12.94s
Train Epoch: 17 [61440/90000 (68%)]	Loss: 14.9145	Cost: 12.52s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 15.0020	Cost: 6.64s
Train Epoch: 17 	Average Loss: 14.9826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9272

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Learning rate: 9.999928692277696e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 14.9701	Cost: 32.15s
Train Epoch: 18 [20480/90000 (23%)]	Loss: 14.7547	Cost: 14.02s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 14.8155	Cost: 12.99s
Train Epoch: 18 [61440/90000 (68%)]	Loss: 14.8453	Cost: 6.90s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 14.8996	Cost: 6.79s
Train Epoch: 18 	Average Loss: 14.8811
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.8448

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Learning rate: 9.999920056417385e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 14.7959	Cost: 22.34s
Train Epoch: 19 [20480/90000 (23%)]	Loss: 14.8634	Cost: 10.03s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 14.7229	Cost: 10.61s
Train Epoch: 19 [61440/90000 (68%)]	Loss: 14.8010	Cost: 7.90s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 14.8670	Cost: 8.96s
Train Epoch: 19 	Average Loss: 14.7741
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7006

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Learning rate: 9.999910927084749e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 14.7732	Cost: 25.06s
Train Epoch: 20 [20480/90000 (23%)]	Loss: 14.7101	Cost: 8.23s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 14.5139	Cost: 9.24s
Train Epoch: 20 [61440/90000 (68%)]	Loss: 14.5922	Cost: 8.51s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 14.6468	Cost: 8.73s
Train Epoch: 20 	Average Loss: 14.6699
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6004

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Learning rate: 9.999901304280687e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 14.5830	Cost: 21.41s
Train Epoch: 21 [20480/90000 (23%)]	Loss: 14.4539	Cost: 9.07s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 14.5166	Cost: 9.00s
Train Epoch: 21 [61440/90000 (68%)]	Loss: 14.6090	Cost: 9.00s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 14.6056	Cost: 7.84s
Train Epoch: 21 	Average Loss: 14.5558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.5271

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Learning rate: 9.99989118800615e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 14.4947	Cost: 20.65s
Train Epoch: 22 [20480/90000 (23%)]	Loss: 14.6177	Cost: 6.92s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 14.3766	Cost: 6.97s
Train Epoch: 22 [61440/90000 (68%)]	Loss: 14.4792	Cost: 7.44s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 14.4571	Cost: 13.47s
Train Epoch: 22 	Average Loss: 14.4648
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.4210

Saving model as e22_model.pt & e22_waveforms_supplementary.hdf5
Learning rate: 9.999880578262136e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 14.3317	Cost: 23.80s
Train Epoch: 23 [20480/90000 (23%)]	Loss: 14.3053	Cost: 10.89s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 14.2807	Cost: 15.49s
Train Epoch: 23 [61440/90000 (68%)]	Loss: 14.3486	Cost: 14.15s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 14.3817	Cost: 12.22s
Train Epoch: 23 	Average Loss: 14.3684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3443

Saving model as e23_model.pt & e23_waveforms_supplementary.hdf5
Learning rate: 9.999869475049693e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 14.3887	Cost: 41.70s
Train Epoch: 24 [20480/90000 (23%)]	Loss: 14.2687	Cost: 14.25s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 14.3161	Cost: 12.68s
Train Epoch: 24 [61440/90000 (68%)]	Loss: 14.3559	Cost: 11.32s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 14.1867	Cost: 6.25s
Train Epoch: 24 	Average Loss: 14.2913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1998

Saving model as e24_model.pt & e24_waveforms_supplementary.hdf5
Learning rate: 9.999857878369916e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 14.2012	Cost: 27.65s
Train Epoch: 25 [20480/90000 (23%)]	Loss: 14.1833	Cost: 13.67s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 14.3652	Cost: 12.28s
Train Epoch: 25 [61440/90000 (68%)]	Loss: 14.1911	Cost: 7.80s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 14.1903	Cost: 6.32s
Train Epoch: 25 	Average Loss: 14.1799
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0870

Saving model as e25_model.pt & e25_waveforms_supplementary.hdf5
Learning rate: 9.99984578822395e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 14.0277	Cost: 22.40s
Train Epoch: 26 [20480/90000 (23%)]	Loss: 14.0830	Cost: 12.13s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 14.0038	Cost: 6.85s
Train Epoch: 26 [61440/90000 (68%)]	Loss: 14.1345	Cost: 6.24s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 14.0394	Cost: 7.90s
Train Epoch: 26 	Average Loss: 14.1017
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9991

Saving model as e26_model.pt & e26_waveforms_supplementary.hdf5
Learning rate: 9.999833204612988e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 13.9924	Cost: 25.61s
Train Epoch: 27 [20480/90000 (23%)]	Loss: 13.9972	Cost: 11.13s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 13.9748	Cost: 6.61s
Train Epoch: 27 [61440/90000 (68%)]	Loss: 14.1096	Cost: 6.51s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 13.9180	Cost: 9.15s
Train Epoch: 27 	Average Loss: 14.0219
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0193

Learning rate: 9.999820127538271e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 13.9180	Cost: 21.17s
Train Epoch: 28 [20480/90000 (23%)]	Loss: 13.7820	Cost: 9.87s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 13.8127	Cost: 9.65s
Train Epoch: 28 [61440/90000 (68%)]	Loss: 13.8862	Cost: 8.89s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 13.8375	Cost: 8.74s
Train Epoch: 28 	Average Loss: 13.9087
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.8840

Saving model as e28_model.pt & e28_waveforms_supplementary.hdf5
Learning rate: 9.999806557001093e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 13.7888	Cost: 23.35s
Train Epoch: 29 [20480/90000 (23%)]	Loss: 13.7847	Cost: 11.57s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 13.6496	Cost: 10.11s
Train Epoch: 29 [61440/90000 (68%)]	Loss: 13.8436	Cost: 8.86s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 13.9172	Cost: 7.32s
Train Epoch: 29 	Average Loss: 13.8320
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7838

Saving model as e29_model.pt & e29_waveforms_supplementary.hdf5
Learning rate: 9.99979249300279e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 13.7507	Cost: 19.51s
Train Epoch: 30 [20480/90000 (23%)]	Loss: 13.8064	Cost: 6.42s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 13.6511	Cost: 8.75s
Train Epoch: 30 [61440/90000 (68%)]	Loss: 13.7684	Cost: 8.37s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 13.7978	Cost: 14.68s
Train Epoch: 30 	Average Loss: 13.7559
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7099

Saving model as e30_model.pt & e30_waveforms_supplementary.hdf5
Learning rate: 9.99977793554475e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 13.6576	Cost: 23.26s
Train Epoch: 31 [20480/90000 (23%)]	Loss: 13.6480	Cost: 13.03s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 13.7160	Cost: 12.49s
Train Epoch: 31 [61440/90000 (68%)]	Loss: 13.8342	Cost: 12.43s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 13.5512	Cost: 11.86s
Train Epoch: 31 	Average Loss: 13.6600
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6506

Saving model as e31_model.pt & e31_waveforms_supplementary.hdf5
Learning rate: 9.999762884628413e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 13.6309	Cost: 25.73s
Train Epoch: 32 [20480/90000 (23%)]	Loss: 13.5022	Cost: 11.34s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 13.5745	Cost: 12.53s
Train Epoch: 32 [61440/90000 (68%)]	Loss: 13.6661	Cost: 12.23s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 13.5272	Cost: 8.81s
Train Epoch: 32 	Average Loss: 13.6034
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5139

Saving model as e32_model.pt & e32_waveforms_supplementary.hdf5
Learning rate: 9.999747340255259e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 13.5522	Cost: 40.33s
Train Epoch: 33 [20480/90000 (23%)]	Loss: 13.5796	Cost: 11.98s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 13.4760	Cost: 7.76s
Train Epoch: 33 [61440/90000 (68%)]	Loss: 13.3820	Cost: 6.12s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 13.4098	Cost: 7.51s
Train Epoch: 33 	Average Loss: 13.4835
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4190

Saving model as e33_model.pt & e33_waveforms_supplementary.hdf5
Learning rate: 9.999731302426829e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 13.4776	Cost: 37.34s
Train Epoch: 34 [20480/90000 (23%)]	Loss: 13.3553	Cost: 9.63s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 13.3395	Cost: 6.25s
Train Epoch: 34 [61440/90000 (68%)]	Loss: 13.3653	Cost: 6.52s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 13.3407	Cost: 8.59s
Train Epoch: 34 	Average Loss: 13.3946
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3047

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Learning rate: 9.999714771144701e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 13.3235	Cost: 27.63s
Train Epoch: 35 [20480/90000 (23%)]	Loss: 13.3267	Cost: 9.85s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 13.2943	Cost: 6.30s
Train Epoch: 35 [61440/90000 (68%)]	Loss: 13.2933	Cost: 6.17s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 13.2364	Cost: 9.16s
Train Epoch: 35 	Average Loss: 13.3186
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.2792

Saving model as e35_model.pt & e35_waveforms_supplementary.hdf5
Learning rate: 9.999697746410508e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 13.1922	Cost: 22.28s
Train Epoch: 36 [20480/90000 (23%)]	Loss: 13.2074	Cost: 9.00s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 13.1343	Cost: 9.20s
Train Epoch: 36 [61440/90000 (68%)]	Loss: 13.3121	Cost: 8.96s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 13.1677	Cost: 9.06s
Train Epoch: 36 	Average Loss: 13.2275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1901

Saving model as e36_model.pt & e36_waveforms_supplementary.hdf5
Learning rate: 9.99968022822593e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 13.2999	Cost: 29.50s
Train Epoch: 37 [20480/90000 (23%)]	Loss: 13.0889	Cost: 8.04s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 13.0901	Cost: 12.54s
Train Epoch: 37 [61440/90000 (68%)]	Loss: 13.1674	Cost: 12.14s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 13.1562	Cost: 12.36s
Train Epoch: 37 	Average Loss: 13.1601
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1072

Saving model as e37_model.pt & e37_waveforms_supplementary.hdf5
Learning rate: 9.999662216592697e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 13.0142	Cost: 24.79s
Train Epoch: 38 [20480/90000 (23%)]	Loss: 13.0328	Cost: 13.44s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 12.9566	Cost: 12.48s
Train Epoch: 38 [61440/90000 (68%)]	Loss: 13.0254	Cost: 12.07s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 13.0648	Cost: 9.91s
Train Epoch: 38 	Average Loss: 13.0547
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.0457

Saving model as e38_model.pt & e38_waveforms_supplementary.hdf5
Learning rate: 9.999643711512586e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 13.1756	Cost: 31.15s
Train Epoch: 39 [20480/90000 (23%)]	Loss: 12.9901	Cost: 10.11s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 12.8851	Cost: 9.78s
Train Epoch: 39 [61440/90000 (68%)]	Loss: 12.9353	Cost: 6.19s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 13.0218	Cost: 6.97s
Train Epoch: 39 	Average Loss: 13.0125
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9660

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Learning rate: 9.999624712987422e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 12.9550	Cost: 28.09s
Train Epoch: 40 [20480/90000 (23%)]	Loss: 12.8922	Cost: 13.71s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 13.0322	Cost: 9.68s
Train Epoch: 40 [61440/90000 (68%)]	Loss: 12.8852	Cost: 6.35s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 12.7248	Cost: 7.87s
Train Epoch: 40 	Average Loss: 12.9176
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8835

Saving model as e40_model.pt & e40_waveforms_supplementary.hdf5
Learning rate: 9.999605221019082e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 12.9452	Cost: 22.45s
Train Epoch: 41 [20480/90000 (23%)]	Loss: 12.7554	Cost: 12.36s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 12.7533	Cost: 9.62s
Train Epoch: 41 [61440/90000 (68%)]	Loss: 12.9191	Cost: 8.48s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 12.8082	Cost: 8.90s
Train Epoch: 41 	Average Loss: 12.8533
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8015

Saving model as e41_model.pt & e41_waveforms_supplementary.hdf5
Learning rate: 9.999585235609488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 12.8746	Cost: 23.19s
Train Epoch: 42 [20480/90000 (23%)]	Loss: 12.9824	Cost: 8.13s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 12.7034	Cost: 9.79s
Train Epoch: 42 [61440/90000 (68%)]	Loss: 12.8028	Cost: 8.66s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 12.7684	Cost: 8.38s
Train Epoch: 42 	Average Loss: 12.7751
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7447

Saving model as e42_model.pt & e42_waveforms_supplementary.hdf5
Learning rate: 9.999564756760615e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 12.8539	Cost: 22.73s
Train Epoch: 43 [20480/90000 (23%)]	Loss: 12.7310	Cost: 7.00s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 12.7647	Cost: 9.01s
Train Epoch: 43 [61440/90000 (68%)]	Loss: 12.7431	Cost: 8.76s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 12.6201	Cost: 8.67s
Train Epoch: 43 	Average Loss: 12.7120
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7083

Saving model as e43_model.pt & e43_waveforms_supplementary.hdf5
Learning rate: 9.999543784474483e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 12.4760	Cost: 23.20s
Train Epoch: 44 [20480/90000 (23%)]	Loss: 12.5990	Cost: 9.28s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 12.6020	Cost: 9.00s
Train Epoch: 44 [61440/90000 (68%)]	Loss: 12.7155	Cost: 7.00s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 12.5654	Cost: 5.95s
Train Epoch: 44 	Average Loss: 12.6258
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5427

Saving model as e44_model.pt & e44_waveforms_supplementary.hdf5
Learning rate: 9.99952231875316e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 12.4907	Cost: 20.56s
Train Epoch: 45 [20480/90000 (23%)]	Loss: 12.5562	Cost: 9.58s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 12.5188	Cost: 11.07s
Train Epoch: 45 [61440/90000 (68%)]	Loss: 12.4773	Cost: 11.00s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 12.4122	Cost: 13.37s
Train Epoch: 45 	Average Loss: 12.5617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5350

Saving model as e45_model.pt & e45_waveforms_supplementary.hdf5
Learning rate: 9.999500359598768e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 12.5251	Cost: 19.56s
Train Epoch: 46 [20480/90000 (23%)]	Loss: 12.6208	Cost: 9.63s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 12.4142	Cost: 13.06s
Train Epoch: 46 [61440/90000 (68%)]	Loss: 12.4695	Cost: 13.46s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 12.4165	Cost: 13.24s
Train Epoch: 46 	Average Loss: 12.4809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4831

Saving model as e46_model.pt & e46_waveforms_supplementary.hdf5
Learning rate: 9.999477907013472e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 12.4327	Cost: 27.07s
Train Epoch: 47 [20480/90000 (23%)]	Loss: 12.3349	Cost: 15.14s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 12.4137	Cost: 13.88s
Train Epoch: 47 [61440/90000 (68%)]	Loss: 12.4128	Cost: 12.05s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 12.3554	Cost: 12.20s
Train Epoch: 47 	Average Loss: 12.3903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3267

Saving model as e47_model.pt & e47_waveforms_supplementary.hdf5
Learning rate: 9.999454960999486e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 12.5127	Cost: 35.14s
Train Epoch: 48 [20480/90000 (23%)]	Loss: 12.2556	Cost: 12.11s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 12.3239	Cost: 11.19s
Train Epoch: 48 [61440/90000 (68%)]	Loss: 12.2526	Cost: 6.36s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 12.2776	Cost: 7.37s
Train Epoch: 48 	Average Loss: 12.3548
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4268

Learning rate: 9.99943152155908e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 12.3728	Cost: 25.39s
Train Epoch: 49 [20480/90000 (23%)]	Loss: 12.2449	Cost: 9.85s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 12.2105	Cost: 6.44s
Train Epoch: 49 [61440/90000 (68%)]	Loss: 12.2331	Cost: 8.03s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 12.3720	Cost: 8.84s
Train Epoch: 49 	Average Loss: 12.2981
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2334

Saving model as e49_model.pt & e49_waveforms_supplementary.hdf5
Learning rate: 9.999407588694566e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 12.2543	Cost: 21.10s
Train Epoch: 50 [20480/90000 (23%)]	Loss: 12.1724	Cost: 9.93s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 12.1829	Cost: 10.45s
Train Epoch: 50 [61440/90000 (68%)]	Loss: 12.2958	Cost: 9.07s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 12.1795	Cost: 8.72s
Train Epoch: 50 	Average Loss: 12.2341
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2167

Saving model as e50_model.pt & e50_waveforms_supplementary.hdf5
Learning rate: 9.999383162408302e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 12.0806	Cost: 24.24s
Train Epoch: 51 [20480/90000 (23%)]	Loss: 12.2581	Cost: 10.46s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 12.1702	Cost: 9.78s
Train Epoch: 51 [61440/90000 (68%)]	Loss: 12.0709	Cost: 8.93s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 12.1673	Cost: 8.82s
Train Epoch: 51 	Average Loss: 12.1689
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1036

Saving model as e51_model.pt & e51_waveforms_supplementary.hdf5
Learning rate: 9.999358242702702e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 12.2283	Cost: 20.52s
Train Epoch: 52 [20480/90000 (23%)]	Loss: 11.8900	Cost: 8.92s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 12.0620	Cost: 8.77s
Train Epoch: 52 [61440/90000 (68%)]	Loss: 12.1630	Cost: 6.79s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 12.3070	Cost: 6.19s
Train Epoch: 52 	Average Loss: 12.1140
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0946

Saving model as e52_model.pt & e52_waveforms_supplementary.hdf5
Learning rate: 9.999332829580225e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 12.0972	Cost: 21.23s
Train Epoch: 53 [20480/90000 (23%)]	Loss: 11.9000	Cost: 7.48s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 12.0575	Cost: 12.14s
Train Epoch: 53 [61440/90000 (68%)]	Loss: 12.1286	Cost: 12.53s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 11.9892	Cost: 12.42s
Train Epoch: 53 	Average Loss: 12.0373
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0228

Saving model as e53_model.pt & e53_waveforms_supplementary.hdf5
Learning rate: 9.99930692304338e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 11.9773	Cost: 25.85s
Train Epoch: 54 [20480/90000 (23%)]	Loss: 12.1040	Cost: 14.73s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 11.9912	Cost: 13.71s
Train Epoch: 54 [61440/90000 (68%)]	Loss: 11.9484	Cost: 12.12s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 12.1371	Cost: 12.27s
Train Epoch: 54 	Average Loss: 11.9966
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0349

Learning rate: 9.999280523094723e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 12.1308	Cost: 32.86s
Train Epoch: 55 [20480/90000 (23%)]	Loss: 12.0952	Cost: 10.18s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 11.8880	Cost: 12.37s
Train Epoch: 55 [61440/90000 (68%)]	Loss: 11.9090	Cost: 12.11s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 11.9209	Cost: 7.00s
Train Epoch: 55 	Average Loss: 11.9303
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9226

Saving model as e55_model.pt & e55_waveforms_supplementary.hdf5
Learning rate: 9.999253629736859e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 12.1543	Cost: 26.50s
Train Epoch: 56 [20480/90000 (23%)]	Loss: 11.7892	Cost: 9.75s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 11.8757	Cost: 6.56s
Train Epoch: 56 [61440/90000 (68%)]	Loss: 11.8909	Cost: 6.82s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 11.8948	Cost: 9.44s
Train Epoch: 56 	Average Loss: 11.8748
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8501

Saving model as e56_model.pt & e56_waveforms_supplementary.hdf5
Learning rate: 9.999226242972442e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 11.8233	Cost: 23.88s
Train Epoch: 57 [20480/90000 (23%)]	Loss: 11.7957	Cost: 10.30s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 11.7978	Cost: 11.05s
Train Epoch: 57 [61440/90000 (68%)]	Loss: 11.8026	Cost: 9.01s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 11.8193	Cost: 8.81s
Train Epoch: 57 	Average Loss: 11.7923
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6988

Saving model as e57_model.pt & e57_waveforms_supplementary.hdf5
Learning rate: 9.999198362804177e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 11.7490	Cost: 25.86s
Train Epoch: 58 [20480/90000 (23%)]	Loss: 11.7079	Cost: 11.98s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 11.7042	Cost: 10.84s
Train Epoch: 58 [61440/90000 (68%)]	Loss: 11.8788	Cost: 8.66s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 11.6544	Cost: 6.37s
Train Epoch: 58 	Average Loss: 11.7762
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7084

Learning rate: 9.999169989234814e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 11.6953	Cost: 20.74s
Train Epoch: 59 [20480/90000 (23%)]	Loss: 11.6299	Cost: 7.21s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 11.6065	Cost: 7.09s
Train Epoch: 59 [61440/90000 (68%)]	Loss: 11.6710	Cost: 7.53s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 11.6177	Cost: 8.21s
Train Epoch: 59 	Average Loss: 11.7038
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6266

Saving model as e59_model.pt & e59_waveforms_supplementary.hdf5
Learning rate: 9.999141122267153e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 11.5772	Cost: 18.01s
Train Epoch: 60 [20480/90000 (23%)]	Loss: 11.6294	Cost: 8.64s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 11.6842	Cost: 12.49s
Train Epoch: 60 [61440/90000 (68%)]	Loss: 11.7853	Cost: 12.40s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 11.6425	Cost: 12.37s
Train Epoch: 60 	Average Loss: 11.6643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6452

Learning rate: 9.999111761904044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 11.6902	Cost: 24.36s
Train Epoch: 61 [20480/90000 (23%)]	Loss: 11.6013	Cost: 12.04s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 11.6769	Cost: 14.24s
Train Epoch: 61 [61440/90000 (68%)]	Loss: 11.6577	Cost: 12.60s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 11.5906	Cost: 12.23s
Train Epoch: 61 	Average Loss: 11.6006
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5652

Saving model as e61_model.pt & e61_waveforms_supplementary.hdf5
Learning rate: 9.999081908148385e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 11.6063	Cost: 43.81s
Train Epoch: 62 [20480/90000 (23%)]	Loss: 11.4040	Cost: 12.50s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 11.4696	Cost: 12.31s
Train Epoch: 62 [61440/90000 (68%)]	Loss: 11.5110	Cost: 10.19s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 11.4607	Cost: 6.33s
Train Epoch: 62 	Average Loss: 11.5340
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5878

Learning rate: 9.999051561003123e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 11.5615	Cost: 32.78s
Train Epoch: 63 [20480/90000 (23%)]	Loss: 11.5016	Cost: 11.98s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 11.4444	Cost: 6.82s
Train Epoch: 63 [61440/90000 (68%)]	Loss: 11.5716	Cost: 6.14s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 11.5329	Cost: 8.64s
Train Epoch: 63 	Average Loss: 11.5036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5095

Saving model as e63_model.pt & e63_waveforms_supplementary.hdf5
Learning rate: 9.999020720471253e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 11.3978	Cost: 22.50s
Train Epoch: 64 [20480/90000 (23%)]	Loss: 11.4416	Cost: 7.74s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 11.4551	Cost: 9.87s
Train Epoch: 64 [61440/90000 (68%)]	Loss: 11.4793	Cost: 9.35s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 11.4746	Cost: 9.00s
Train Epoch: 64 	Average Loss: 11.4671
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4155

Saving model as e64_model.pt & e64_waveforms_supplementary.hdf5
Learning rate: 9.998989386555816e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 11.3558	Cost: 25.16s
Train Epoch: 65 [20480/90000 (23%)]	Loss: 11.3169	Cost: 11.06s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 11.3596	Cost: 8.79s
Train Epoch: 65 [61440/90000 (68%)]	Loss: 11.4141	Cost: 6.33s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 11.4139	Cost: 6.46s
Train Epoch: 65 	Average Loss: 11.4396
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3793

Saving model as e65_model.pt & e65_waveforms_supplementary.hdf5
Learning rate: 9.998957559259906e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 11.4762	Cost: 20.85s
Train Epoch: 66 [20480/90000 (23%)]	Loss: 11.4006	Cost: 7.56s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 11.4268	Cost: 8.13s
Train Epoch: 66 [61440/90000 (68%)]	Loss: 11.4230	Cost: 12.58s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 11.3624	Cost: 12.45s
Train Epoch: 66 	Average Loss: 11.3924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3665

Saving model as e66_model.pt & e66_waveforms_supplementary.hdf5
Learning rate: 9.998925238586665e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 11.1729	Cost: 21.46s
Train Epoch: 67 [20480/90000 (23%)]	Loss: 11.2885	Cost: 13.24s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 11.3473	Cost: 13.18s
Train Epoch: 67 [61440/90000 (68%)]	Loss: 11.3246	Cost: 12.09s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 11.4308	Cost: 12.34s
Train Epoch: 67 	Average Loss: 11.3472
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3230

Saving model as e67_model.pt & e67_waveforms_supplementary.hdf5
Learning rate: 9.998892424539283e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 11.2935	Cost: 24.13s
Train Epoch: 68 [20480/90000 (23%)]	Loss: 11.0938	Cost: 11.88s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 11.1830	Cost: 12.07s
Train Epoch: 68 [61440/90000 (68%)]	Loss: 11.3333	Cost: 12.34s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 11.2154	Cost: 6.68s
Train Epoch: 68 	Average Loss: 11.2874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3225

Saving model as e68_model.pt & e68_waveforms_supplementary.hdf5
Learning rate: 9.998859117121e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 11.0742	Cost: 39.99s
Train Epoch: 69 [20480/90000 (23%)]	Loss: 11.1007	Cost: 9.95s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 11.2195	Cost: 8.86s
Train Epoch: 69 [61440/90000 (68%)]	Loss: 11.1175	Cost: 6.18s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 11.3004	Cost: 7.31s
Train Epoch: 69 	Average Loss: 11.2200
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2607

Saving model as e69_model.pt & e69_waveforms_supplementary.hdf5
Learning rate: 9.998825316335099e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 11.2649	Cost: 24.54s
Train Epoch: 70 [20480/90000 (23%)]	Loss: 11.1699	Cost: 7.18s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 11.2496	Cost: 9.56s
Train Epoch: 70 [61440/90000 (68%)]	Loss: 11.1422	Cost: 8.76s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 11.2515	Cost: 8.62s
Train Epoch: 70 	Average Loss: 11.2024
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1623

Saving model as e70_model.pt & e70_waveforms_supplementary.hdf5
Learning rate: 9.99879102218492e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 11.2556	Cost: 20.54s
Train Epoch: 71 [20480/90000 (23%)]	Loss: 11.0209	Cost: 7.42s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 11.0965	Cost: 9.12s
Train Epoch: 71 [61440/90000 (68%)]	Loss: 11.2726	Cost: 8.71s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 11.1524	Cost: 8.80s
Train Epoch: 71 	Average Loss: 11.1468
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1395

Saving model as e71_model.pt & e71_waveforms_supplementary.hdf5
Learning rate: 9.998756234673847e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 11.2256	Cost: 21.13s
Train Epoch: 72 [20480/90000 (23%)]	Loss: 11.0641	Cost: 9.13s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 11.2845	Cost: 8.07s
Train Epoch: 72 [61440/90000 (68%)]	Loss: 11.0225	Cost: 6.26s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 11.1694	Cost: 7.86s
Train Epoch: 72 	Average Loss: 11.1515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1189

Saving model as e72_model.pt & e72_waveforms_supplementary.hdf5
Learning rate: 9.998720953805312e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 11.0618	Cost: 18.73s
Train Epoch: 73 [20480/90000 (23%)]	Loss: 11.0445	Cost: 9.28s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 10.9792	Cost: 10.96s
Train Epoch: 73 [61440/90000 (68%)]	Loss: 11.0171	Cost: 13.08s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 11.2163	Cost: 12.55s
Train Epoch: 73 	Average Loss: 11.0700
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1793

Learning rate: 9.998685179582798e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 11.0017	Cost: 40.26s
Train Epoch: 74 [20480/90000 (23%)]	Loss: 11.0975	Cost: 13.51s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 11.0586	Cost: 12.63s
Train Epoch: 74 [61440/90000 (68%)]	Loss: 11.0216	Cost: 12.07s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 10.9247	Cost: 12.27s
Train Epoch: 74 	Average Loss: 11.0602
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0375

Saving model as e74_model.pt & e74_waveforms_supplementary.hdf5
Learning rate: 9.998648912009835e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 11.2604	Cost: 27.07s
Train Epoch: 75 [20480/90000 (23%)]	Loss: 10.9254	Cost: 12.03s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 11.0081	Cost: 12.61s
Train Epoch: 75 [61440/90000 (68%)]	Loss: 11.0136	Cost: 12.08s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 10.9911	Cost: 9.29s
Train Epoch: 75 	Average Loss: 11.0082
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0612

Learning rate: 9.998612151090003e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 11.1180	Cost: 25.12s
Train Epoch: 76 [20480/90000 (23%)]	Loss: 10.8044	Cost: 13.45s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 10.9261	Cost: 12.42s
Train Epoch: 76 [61440/90000 (68%)]	Loss: 10.8930	Cost: 9.00s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 11.0505	Cost: 6.69s
Train Epoch: 76 	Average Loss: 10.9672
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0692

Learning rate: 9.998574896826931e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 11.0430	Cost: 24.75s
Train Epoch: 77 [20480/90000 (23%)]	Loss: 11.0698	Cost: 6.39s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 10.8651	Cost: 7.97s
Train Epoch: 77 [61440/90000 (68%)]	Loss: 10.8942	Cost: 8.42s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 10.8854	Cost: 9.51s
Train Epoch: 77 	Average Loss: 10.9272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9015

Saving model as e77_model.pt & e77_waveforms_supplementary.hdf5
Learning rate: 9.998537149224293e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 11.0135	Cost: 20.09s
Train Epoch: 78 [20480/90000 (23%)]	Loss: 10.8397	Cost: 8.50s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 10.8325	Cost: 9.03s
Train Epoch: 78 [61440/90000 (68%)]	Loss: 10.9632	Cost: 8.78s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 11.0242	Cost: 8.71s
Train Epoch: 78 	Average Loss: 10.8986
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9254

Learning rate: 9.998498908285819e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 10.9892	Cost: 24.53s
Train Epoch: 79 [20480/90000 (23%)]	Loss: 10.9175	Cost: 8.55s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 10.9510	Cost: 8.96s
Train Epoch: 79 [61440/90000 (68%)]	Loss: 10.8859	Cost: 8.70s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 10.9013	Cost: 8.56s
Train Epoch: 79 	Average Loss: 10.8664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9112

Learning rate: 9.998460174015279e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 10.7747	Cost: 30.66s
Train Epoch: 80 [20480/90000 (23%)]	Loss: 10.7404	Cost: 8.90s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 10.8664	Cost: 8.87s
Train Epoch: 80 [61440/90000 (68%)]	Loss: 10.8402	Cost: 7.69s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 10.8779	Cost: 5.78s
Train Epoch: 80 	Average Loss: 10.8344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8214

Saving model as e80_model.pt & e80_waveforms_supplementary.hdf5
Learning rate: 9.998420946416499e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 10.8748	Cost: 22.56s
Train Epoch: 81 [20480/90000 (23%)]	Loss: 10.8296	Cost: 9.97s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 10.7626	Cost: 12.37s
Train Epoch: 81 [61440/90000 (68%)]	Loss: 10.8671	Cost: 13.36s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 10.7419	Cost: 11.85s
Train Epoch: 81 	Average Loss: 10.7908
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8520

Learning rate: 9.998381225493349e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 10.7639	Cost: 22.67s
Train Epoch: 82 [20480/90000 (23%)]	Loss: 10.6877	Cost: 9.77s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 10.7626	Cost: 14.87s
Train Epoch: 82 [61440/90000 (68%)]	Loss: 10.7434	Cost: 13.20s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 10.8177	Cost: 12.46s
Train Epoch: 82 	Average Loss: 10.7566
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7380

Saving model as e82_model.pt & e82_waveforms_supplementary.hdf5
Learning rate: 9.998341011249749e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 10.7117	Cost: 32.69s
Train Epoch: 83 [20480/90000 (23%)]	Loss: 10.7765	Cost: 12.07s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 10.6146	Cost: 12.34s
Train Epoch: 83 [61440/90000 (68%)]	Loss: 10.7277	Cost: 12.07s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 10.6735	Cost: 6.41s
Train Epoch: 83 	Average Loss: 10.7096
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7788

Learning rate: 9.99830030368967e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 10.7965	Cost: 25.76s
Train Epoch: 84 [20480/90000 (23%)]	Loss: 10.6743	Cost: 11.38s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 10.5817	Cost: 8.40s
Train Epoch: 84 [61440/90000 (68%)]	Loss: 10.6152	Cost: 6.10s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 10.6247	Cost: 7.62s
Train Epoch: 84 	Average Loss: 10.6768
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6249

Saving model as e84_model.pt & e84_waveforms_supplementary.hdf5
Learning rate: 9.998259102817127e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 10.6918	Cost: 27.42s
Train Epoch: 85 [20480/90000 (23%)]	Loss: 10.6180	Cost: 8.73s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 10.6419	Cost: 6.32s
Train Epoch: 85 [61440/90000 (68%)]	Loss: 10.7908	Cost: 6.97s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 10.7703	Cost: 8.40s
Train Epoch: 85 	Average Loss: 10.6558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6412

Learning rate: 9.99821740863619e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 10.7359	Cost: 20.10s
Train Epoch: 86 [20480/90000 (23%)]	Loss: 10.4578	Cost: 9.08s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 10.5325	Cost: 8.80s
Train Epoch: 86 [61440/90000 (68%)]	Loss: 10.7255	Cost: 9.16s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 10.5924	Cost: 9.29s
Train Epoch: 86 	Average Loss: 10.6157
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6634

Learning rate: 9.99817522115097e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 10.7591	Cost: 20.36s
Train Epoch: 87 [20480/90000 (23%)]	Loss: 10.7042	Cost: 9.42s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 10.6663	Cost: 11.41s
Train Epoch: 87 [61440/90000 (68%)]	Loss: 10.6984	Cost: 6.64s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 10.5820	Cost: 6.62s
Train Epoch: 87 	Average Loss: 10.5974
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5867

Saving model as e87_model.pt & e87_waveforms_supplementary.hdf5
Learning rate: 9.998132540365634e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 10.5533	Cost: 22.72s
Train Epoch: 88 [20480/90000 (23%)]	Loss: 10.4648	Cost: 10.50s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 10.4324	Cost: 9.58s
Train Epoch: 88 [61440/90000 (68%)]	Loss: 10.6367	Cost: 12.48s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 10.6242	Cost: 12.45s
Train Epoch: 88 	Average Loss: 10.5565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5349

Saving model as e88_model.pt & e88_waveforms_supplementary.hdf5
Learning rate: 9.998089366284391e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 10.6825	Cost: 22.93s
Train Epoch: 89 [20480/90000 (23%)]	Loss: 10.4642	Cost: 13.56s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 10.4951	Cost: 12.62s
Train Epoch: 89 [61440/90000 (68%)]	Loss: 10.5535	Cost: 12.51s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 10.3828	Cost: 11.97s
Train Epoch: 89 	Average Loss: 10.5232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5425

Learning rate: 9.998045698911504e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 10.5785	Cost: 28.21s
Train Epoch: 90 [20480/90000 (23%)]	Loss: 10.4912	Cost: 12.38s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 10.4144	Cost: 12.29s
Train Epoch: 90 [61440/90000 (68%)]	Loss: 10.5699	Cost: 6.42s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 10.5347	Cost: 6.32s
Train Epoch: 90 	Average Loss: 10.4799
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5293

Saving model as e90_model.pt & e90_waveforms_supplementary.hdf5
Learning rate: 9.998001538251281e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 10.2838	Cost: 33.95s
Train Epoch: 91 [20480/90000 (23%)]	Loss: 10.4938	Cost: 12.32s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 10.4767	Cost: 9.34s
Train Epoch: 91 [61440/90000 (68%)]	Loss: 10.4674	Cost: 6.28s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 10.4971	Cost: 7.50s
Train Epoch: 91 	Average Loss: 10.4561
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5702

Learning rate: 9.997956884308085e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 10.5471	Cost: 22.43s
Train Epoch: 92 [20480/90000 (23%)]	Loss: 10.3467	Cost: 9.85s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 10.4839	Cost: 12.16s
Train Epoch: 92 [61440/90000 (68%)]	Loss: 10.5079	Cost: 7.88s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 10.4533	Cost: 6.67s
Train Epoch: 92 	Average Loss: 10.4321
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5345

Learning rate: 9.99791173708632e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 10.4496	Cost: 23.45s
Train Epoch: 93 [20480/90000 (23%)]	Loss: 10.4051	Cost: 12.12s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 10.4309	Cost: 8.07s
Train Epoch: 93 [61440/90000 (68%)]	Loss: 10.5337	Cost: 6.32s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 10.5281	Cost: 7.51s
Train Epoch: 93 	Average Loss: 10.4554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.4070

Saving model as e93_model.pt & e93_waveforms_supplementary.hdf5
Learning rate: 9.997866096590442e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 10.2959	Cost: 33.85s
Train Epoch: 94 [20480/90000 (23%)]	Loss: 10.3871	Cost: 6.79s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 10.4570	Cost: 9.36s
Train Epoch: 94 [61440/90000 (68%)]	Loss: 10.5315	Cost: 8.54s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 10.4136	Cost: 8.45s
Train Epoch: 94 	Average Loss: 10.4144
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.4416

Learning rate: 9.997819962824954e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 10.3759	Cost: 30.66s
Train Epoch: 95 [20480/90000 (23%)]	Loss: 10.2658	Cost: 9.94s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 10.3911	Cost: 8.87s
Train Epoch: 95 [61440/90000 (68%)]	Loss: 10.3579	Cost: 8.65s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 10.2092	Cost: 8.56s
Train Epoch: 95 	Average Loss: 10.3618
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3045

Saving model as e95_model.pt & e95_waveforms_supplementary.hdf5
Learning rate: 9.997773335794414e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 10.5583	Cost: 18.85s
Train Epoch: 96 [20480/90000 (23%)]	Loss: 10.3628	Cost: 10.38s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 10.2348	Cost: 6.40s
Train Epoch: 96 [61440/90000 (68%)]	Loss: 10.3407	Cost: 7.99s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 10.2963	Cost: 9.33s
Train Epoch: 96 	Average Loss: 10.3362
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.4169

Learning rate: 9.99772621550342e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 10.3582	Cost: 19.44s
Train Epoch: 97 [20480/90000 (23%)]	Loss: 10.2634	Cost: 8.06s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 10.2853	Cost: 10.52s
Train Epoch: 97 [61440/90000 (68%)]	Loss: 10.2998	Cost: 12.60s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 10.4314	Cost: 12.65s
Train Epoch: 97 	Average Loss: 10.3173
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2799

Saving model as e97_model.pt & e97_waveforms_supplementary.hdf5
Learning rate: 9.997678601956623e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 10.3585	Cost: 24.80s
Train Epoch: 98 [20480/90000 (23%)]	Loss: 10.2740	Cost: 14.06s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 10.3143	Cost: 13.79s
Train Epoch: 98 [61440/90000 (68%)]	Loss: 10.4369	Cost: 12.25s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 10.1755	Cost: 10.63s
Train Epoch: 98 	Average Loss: 10.3015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3594

Learning rate: 9.997630495158724e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 10.5202	Cost: 39.19s
Train Epoch: 99 [20480/90000 (23%)]	Loss: 10.2513	Cost: 12.68s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 10.4253	Cost: 12.20s
Train Epoch: 99 [61440/90000 (68%)]	Loss: 10.1849	Cost: 7.83s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 10.2873	Cost: 6.11s
Train Epoch: 99 	Average Loss: 10.3081
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3687

Learning rate: 9.997581895114468e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 10.3580	Cost: 36.75s
Train Epoch: 100 [20480/90000 (23%)]	Loss: 10.2276	Cost: 6.31s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 10.1721	Cost: 9.62s
Train Epoch: 100 [61440/90000 (68%)]	Loss: 10.4291	Cost: 8.52s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 10.3666	Cost: 8.36s
Train Epoch: 100 	Average Loss: 10.2405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2195

Saving model as e100_model.pt & e100_waveforms_supplementary.hdf5
Learning rate: 9.997532801828656e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 10.3854	Cost: 20.37s
Train Epoch: 101 [20480/90000 (23%)]	Loss: 10.1241	Cost: 7.85s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 10.2944	Cost: 9.34s
Train Epoch: 101 [61440/90000 (68%)]	Loss: 10.1625	Cost: 9.34s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 10.2572	Cost: 9.20s
Train Epoch: 101 	Average Loss: 10.2493
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2729

Learning rate: 9.997483215306129e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 10.2364	Cost: 19.93s
Train Epoch: 102 [20480/90000 (23%)]	Loss: 10.0025	Cost: 9.09s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 10.2480	Cost: 8.68s
Train Epoch: 102 [61440/90000 (68%)]	Loss: 10.2644	Cost: 6.46s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 10.2595	Cost: 9.26s
Train Epoch: 102 	Average Loss: 10.1894
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2136

Saving model as e102_model.pt & e102_waveforms_supplementary.hdf5
Learning rate: 9.997433135551784e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 10.3363	Cost: 25.04s
Train Epoch: 103 [20480/90000 (23%)]	Loss: 10.1969	Cost: 10.58s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 10.2704	Cost: 13.96s
Train Epoch: 103 [61440/90000 (68%)]	Loss: 10.2751	Cost: 12.53s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 10.2575	Cost: 12.39s
Train Epoch: 103 	Average Loss: 10.1966
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2606

Learning rate: 9.99738256257056e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 10.4043	Cost: 23.89s
Train Epoch: 104 [20480/90000 (23%)]	Loss: 10.1790	Cost: 13.00s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 10.0632	Cost: 12.72s
Train Epoch: 104 [61440/90000 (68%)]	Loss: 10.1891	Cost: 12.10s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 10.0822	Cost: 12.42s
Train Epoch: 104 	Average Loss: 10.1837
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2385

Learning rate: 9.997331496367453e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 10.2115	Cost: 25.75s
Train Epoch: 105 [20480/90000 (23%)]	Loss: 10.1172	Cost: 12.53s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 10.1466	Cost: 12.74s
Train Epoch: 105 [61440/90000 (68%)]	Loss: 10.1031	Cost: 10.35s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 10.2923	Cost: 6.63s
Train Epoch: 105 	Average Loss: 10.1531
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0942

Saving model as e105_model.pt & e105_waveforms_supplementary.hdf5
Learning rate: 9.997279936947499e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 10.1724	Cost: 37.97s
Train Epoch: 106 [20480/90000 (23%)]	Loss: 10.1411	Cost: 13.01s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 10.0161	Cost: 7.79s
Train Epoch: 106 [61440/90000 (68%)]	Loss: 10.0591	Cost: 6.47s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 10.1323	Cost: 8.61s
Train Epoch: 106 	Average Loss: 10.1256
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1768

Learning rate: 9.997227884315788e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 10.2048	Cost: 25.36s
Train Epoch: 107 [20480/90000 (23%)]	Loss: 10.0946	Cost: 10.76s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 10.1575	Cost: 10.19s
Train Epoch: 107 [61440/90000 (68%)]	Loss: 10.2027	Cost: 8.43s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 9.9784	Cost: 8.64s
Train Epoch: 107 	Average Loss: 10.1136
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1808

Learning rate: 9.997175338477459e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 10.1371	Cost: 23.44s
Train Epoch: 108 [20480/90000 (23%)]	Loss: 10.0166	Cost: 6.85s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 10.1320	Cost: 9.75s
Train Epoch: 108 [61440/90000 (68%)]	Loss: 10.0349	Cost: 8.64s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 10.0217	Cost: 8.79s
Train Epoch: 108 	Average Loss: 10.1208
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0971

Learning rate: 9.997122299437696e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 10.1565	Cost: 21.93s
Train Epoch: 109 [20480/90000 (23%)]	Loss: 9.9978	Cost: 6.63s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 10.1702	Cost: 9.21s
Train Epoch: 109 [61440/90000 (68%)]	Loss: 10.0890	Cost: 8.95s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 10.0695	Cost: 8.45s
Train Epoch: 109 	Average Loss: 10.0649
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0560

Saving model as e109_model.pt & e109_waveforms_supplementary.hdf5
Learning rate: 9.997068767201736e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 10.1753	Cost: 22.58s
Train Epoch: 110 [20480/90000 (23%)]	Loss: 10.0925	Cost: 8.97s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 10.0065	Cost: 6.32s
Train Epoch: 110 [61440/90000 (68%)]	Loss: 9.9685	Cost: 6.48s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 9.9896	Cost: 6.45s
Train Epoch: 110 	Average Loss: 10.0434
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9971

Saving model as e110_model.pt & e110_waveforms_supplementary.hdf5
Learning rate: 9.997014741774862e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 10.0805	Cost: 23.44s
Train Epoch: 111 [20480/90000 (23%)]	Loss: 10.0133	Cost: 9.91s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 10.1301	Cost: 17.58s
Train Epoch: 111 [61440/90000 (68%)]	Loss: 10.0593	Cost: 12.53s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 10.0779	Cost: 12.17s
Train Epoch: 111 	Average Loss: 10.0493
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9994

Learning rate: 9.996960223162402e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 10.1339	Cost: 27.93s
Train Epoch: 112 [20480/90000 (23%)]	Loss: 9.9311	Cost: 14.78s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 10.0575	Cost: 14.52s
Train Epoch: 112 [61440/90000 (68%)]	Loss: 9.9979	Cost: 12.26s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 10.0516	Cost: 11.39s
Train Epoch: 112 	Average Loss: 10.0003
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0446

Learning rate: 9.996905211369744e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 9.9103	Cost: 41.84s
Train Epoch: 113 [20480/90000 (23%)]	Loss: 9.9556	Cost: 12.41s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 9.9627	Cost: 11.97s
Train Epoch: 113 [61440/90000 (68%)]	Loss: 10.0151	Cost: 6.36s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 10.0005	Cost: 6.40s
Train Epoch: 113 	Average Loss: 9.9726
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0684

Learning rate: 9.996849706402311e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 9.9690	Cost: 27.97s
Train Epoch: 114 [20480/90000 (23%)]	Loss: 9.9868	Cost: 9.79s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 9.9395	Cost: 11.43s
Train Epoch: 114 [61440/90000 (68%)]	Loss: 10.0613	Cost: 6.16s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 9.9278	Cost: 7.21s
Train Epoch: 114 	Average Loss: 9.9583
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0093

Learning rate: 9.996793708265583e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 9.8210	Cost: 31.17s
Train Epoch: 115 [20480/90000 (23%)]	Loss: 9.9454	Cost: 6.31s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 9.9732	Cost: 8.75s
Train Epoch: 115 [61440/90000 (68%)]	Loss: 9.9478	Cost: 8.71s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 9.9304	Cost: 8.46s
Train Epoch: 115 	Average Loss: 9.9414
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0282

Learning rate: 9.996737216965088e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 10.1047	Cost: 22.39s
Train Epoch: 116 [20480/90000 (23%)]	Loss: 9.9861	Cost: 7.86s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 9.9962	Cost: 9.24s
Train Epoch: 116 [61440/90000 (68%)]	Loss: 10.0950	Cost: 9.39s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 9.9581	Cost: 9.02s
Train Epoch: 116 	Average Loss: 9.9491
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0101

Learning rate: 9.9966802325064e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 10.0640	Cost: 21.24s
Train Epoch: 117 [20480/90000 (23%)]	Loss: 9.8559	Cost: 11.22s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 9.7452	Cost: 9.33s
Train Epoch: 117 [61440/90000 (68%)]	Loss: 9.8624	Cost: 9.10s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 9.9045	Cost: 8.14s
Train Epoch: 117 	Average Loss: 9.9290
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0098

Learning rate: 9.996622754895145e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 9.9713	Cost: 23.80s
Train Epoch: 118 [20480/90000 (23%)]	Loss: 9.9094	Cost: 10.76s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 9.9424	Cost: 14.48s
Train Epoch: 118 [61440/90000 (68%)]	Loss: 9.7958	Cost: 12.43s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 9.8690	Cost: 12.40s
Train Epoch: 118 	Average Loss: 9.8917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8664

Saving model as e118_model.pt & e118_waveforms_supplementary.hdf5
Learning rate: 9.996564784136994e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 9.8518	Cost: 23.53s
Train Epoch: 119 [20480/90000 (23%)]	Loss: 9.6802	Cost: 14.68s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 9.8325	Cost: 12.48s
Train Epoch: 119 [61440/90000 (68%)]	Loss: 9.9766	Cost: 12.14s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 9.7200	Cost: 10.56s
Train Epoch: 119 	Average Loss: 9.8806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8908

Learning rate: 9.99650632023767e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 9.8098	Cost: 28.49s
Train Epoch: 120 [20480/90000 (23%)]	Loss: 9.7792	Cost: 10.79s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 9.8508	Cost: 9.14s
Train Epoch: 120 [61440/90000 (68%)]	Loss: 9.8509	Cost: 6.38s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 9.8664	Cost: 7.26s
Train Epoch: 120 	Average Loss: 9.8774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8917

Learning rate: 9.996447363202941e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 9.9031	Cost: 35.84s
Train Epoch: 121 [20480/90000 (23%)]	Loss: 9.9790	Cost: 11.16s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 9.9659	Cost: 9.71s
Train Epoch: 121 [61440/90000 (68%)]	Loss: 9.9029	Cost: 6.81s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 9.8391	Cost: 8.95s
Train Epoch: 121 	Average Loss: 9.8573
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8436

Saving model as e121_model.pt & e121_waveforms_supplementary.hdf5
Learning rate: 9.996387913038628e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 9.8158	Cost: 23.21s
Train Epoch: 122 [20480/90000 (23%)]	Loss: 9.9062	Cost: 10.55s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 9.8582	Cost: 11.27s
Train Epoch: 122 [61440/90000 (68%)]	Loss: 10.0957	Cost: 8.82s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 9.8965	Cost: 8.61s
Train Epoch: 122 	Average Loss: 9.8443
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8659

Learning rate: 9.996327969750598e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 9.7515	Cost: 20.87s
Train Epoch: 123 [20480/90000 (23%)]	Loss: 9.8131	Cost: 9.48s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 9.7100	Cost: 8.13s
Train Epoch: 123 [61440/90000 (68%)]	Loss: 9.7392	Cost: 6.10s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 9.8989	Cost: 6.37s
Train Epoch: 123 	Average Loss: 9.8264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8221

Saving model as e123_model.pt & e123_waveforms_supplementary.hdf5
Learning rate: 9.996267533344767e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 9.9101	Cost: 20.61s
Train Epoch: 124 [20480/90000 (23%)]	Loss: 9.6560	Cost: 8.36s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 9.8296	Cost: 11.61s
Train Epoch: 124 [61440/90000 (68%)]	Loss: 9.7284	Cost: 12.21s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 9.7846	Cost: 12.55s
Train Epoch: 124 	Average Loss: 9.7923
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8846

Learning rate: 9.996206603827099e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 9.9344	Cost: 22.39s
Train Epoch: 125 [20480/90000 (23%)]	Loss: 9.8362	Cost: 14.23s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 9.8307	Cost: 14.31s
Train Epoch: 125 [61440/90000 (68%)]	Loss: 9.8963	Cost: 12.31s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 9.7000	Cost: 12.25s
Train Epoch: 125 	Average Loss: 9.8308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8220

Saving model as e125_model.pt & e125_waveforms_supplementary.hdf5
Learning rate: 9.99614518120361e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 9.9080	Cost: 33.83s
Train Epoch: 126 [20480/90000 (23%)]	Loss: 9.7320	Cost: 12.12s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 9.6991	Cost: 12.31s
Train Epoch: 126 [61440/90000 (68%)]	Loss: 9.7582	Cost: 11.45s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 9.6782	Cost: 6.45s
Train Epoch: 126 	Average Loss: 9.7858
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8196

Saving model as e126_model.pt & e126_waveforms_supplementary.hdf5
Learning rate: 9.99608326548036e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 9.9850	Cost: 21.15s
Train Epoch: 127 [20480/90000 (23%)]	Loss: 9.7006	Cost: 7.50s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 9.6608	Cost: 8.99s
Train Epoch: 127 [61440/90000 (68%)]	Loss: 9.7856	Cost: 9.47s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 9.7789	Cost: 8.94s
Train Epoch: 127 	Average Loss: 9.7563
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7622

Saving model as e127_model.pt & e127_waveforms_supplementary.hdf5
Learning rate: 9.996020856663458e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 9.7606	Cost: 29.16s
Train Epoch: 128 [20480/90000 (23%)]	Loss: 9.7653	Cost: 8.77s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 9.6022	Cost: 6.74s
Train Epoch: 128 [61440/90000 (68%)]	Loss: 9.8373	Cost: 6.99s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 9.8732	Cost: 7.17s
Train Epoch: 128 	Average Loss: 9.7446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7882

Learning rate: 9.995957954759067e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 9.5893	Cost: 22.91s
Train Epoch: 129 [20480/90000 (23%)]	Loss: 9.8000	Cost: 9.97s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 9.8434	Cost: 9.47s
Train Epoch: 129 [61440/90000 (68%)]	Loss: 9.7301	Cost: 9.91s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 9.6869	Cost: 14.03s
Train Epoch: 129 	Average Loss: 9.7435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8700

Learning rate: 9.995894559773395e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 9.8616	Cost: 20.85s
Train Epoch: 130 [20480/90000 (23%)]	Loss: 9.9065	Cost: 6.83s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 9.9510	Cost: 11.82s
Train Epoch: 130 [61440/90000 (68%)]	Loss: 9.7663	Cost: 12.87s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 9.8389	Cost: 12.36s
Train Epoch: 130 	Average Loss: 9.7599
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7039

Saving model as e130_model.pt & e130_waveforms_supplementary.hdf5
Learning rate: 9.995830671712695e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 9.6100	Cost: 24.87s
Train Epoch: 131 [20480/90000 (23%)]	Loss: 9.6392	Cost: 12.96s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 9.7153	Cost: 12.45s
Train Epoch: 131 [61440/90000 (68%)]	Loss: 9.7762	Cost: 12.31s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 9.8256	Cost: 11.72s
Train Epoch: 131 	Average Loss: 9.6852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7908

Learning rate: 9.995766290583277e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 9.7985	Cost: 23.31s
Train Epoch: 132 [20480/90000 (23%)]	Loss: 9.5252	Cost: 12.53s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 9.7867	Cost: 11.20s
Train Epoch: 132 [61440/90000 (68%)]	Loss: 9.7021	Cost: 6.41s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 9.7176	Cost: 6.61s
Train Epoch: 132 	Average Loss: 9.6771
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7965

Learning rate: 9.995701416391493e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 9.6948	Cost: 27.18s
Train Epoch: 133 [20480/90000 (23%)]	Loss: 9.6805	Cost: 13.62s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 9.7176	Cost: 12.60s
Train Epoch: 133 [61440/90000 (68%)]	Loss: 9.7416	Cost: 6.39s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 9.5671	Cost: 6.25s
Train Epoch: 133 	Average Loss: 9.6937
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7366

Learning rate: 9.995636049143747e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 9.8659	Cost: 24.37s
Train Epoch: 134 [20480/90000 (23%)]	Loss: 9.7162	Cost: 11.07s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 9.6252	Cost: 12.62s
Train Epoch: 134 [61440/90000 (68%)]	Loss: 9.6339	Cost: 6.75s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 9.6049	Cost: 6.47s
Train Epoch: 134 	Average Loss: 9.6782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7458

Learning rate: 9.995570188846488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 9.8638	Cost: 23.24s
Train Epoch: 135 [20480/90000 (23%)]	Loss: 9.6623	Cost: 7.94s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 9.6885	Cost: 12.21s
Train Epoch: 135 [61440/90000 (68%)]	Loss: 9.6984	Cost: 6.35s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 9.7764	Cost: 6.24s
Train Epoch: 135 	Average Loss: 9.6409
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6471

Saving model as e135_model.pt & e135_waveforms_supplementary.hdf5
Learning rate: 9.99550383550622e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 9.7066	Cost: 34.73s
Train Epoch: 136 [20480/90000 (23%)]	Loss: 9.5732	Cost: 9.68s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 9.5481	Cost: 6.54s
Train Epoch: 136 [61440/90000 (68%)]	Loss: 9.7146	Cost: 6.30s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 9.4851	Cost: 8.90s
Train Epoch: 136 	Average Loss: 9.6223
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6056

Saving model as e136_model.pt & e136_waveforms_supplementary.hdf5
Learning rate: 9.995436989129488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 9.6563	Cost: 20.37s
Train Epoch: 137 [20480/90000 (23%)]	Loss: 9.5677	Cost: 10.28s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 9.6286	Cost: 11.54s
Train Epoch: 137 [61440/90000 (68%)]	Loss: 9.7137	Cost: 8.99s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 9.4913	Cost: 8.74s
Train Epoch: 137 	Average Loss: 9.6208
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6210

Learning rate: 9.99536964972289e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 9.5959	Cost: 23.65s
Train Epoch: 138 [20480/90000 (23%)]	Loss: 9.4325	Cost: 8.30s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 9.5189	Cost: 6.25s
Train Epoch: 138 [61440/90000 (68%)]	Loss: 9.5608	Cost: 6.30s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 9.6953	Cost: 6.69s
Train Epoch: 138 	Average Loss: 9.5975
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6989

Learning rate: 9.995301817293077e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 9.8491	Cost: 18.00s
Train Epoch: 139 [20480/90000 (23%)]	Loss: 9.5463	Cost: 7.32s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 9.6313	Cost: 10.16s
Train Epoch: 139 [61440/90000 (68%)]	Loss: 9.5930	Cost: 8.20s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 9.6220	Cost: 13.48s
Train Epoch: 139 	Average Loss: 9.5882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6656

Learning rate: 9.995233491846737e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 9.7036	Cost: 25.65s
Train Epoch: 140 [20480/90000 (23%)]	Loss: 9.6962	Cost: 7.92s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 9.4426	Cost: 13.35s
Train Epoch: 140 [61440/90000 (68%)]	Loss: 9.5387	Cost: 12.48s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 9.4554	Cost: 12.47s
Train Epoch: 140 	Average Loss: 9.5638
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6514

Learning rate: 9.995164673390618e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 9.6427	Cost: 32.56s
Train Epoch: 141 [20480/90000 (23%)]	Loss: 9.4779	Cost: 15.35s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 9.4981	Cost: 14.06s
Train Epoch: 141 [61440/90000 (68%)]	Loss: 9.6766	Cost: 12.08s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 9.4142	Cost: 10.08s
Train Epoch: 141 	Average Loss: 9.5326
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6211

Learning rate: 9.995095361931511e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 9.7547	Cost: 41.40s
Train Epoch: 142 [20480/90000 (23%)]	Loss: 9.5844	Cost: 12.71s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 9.5801	Cost: 11.44s
Train Epoch: 142 [61440/90000 (68%)]	Loss: 9.7301	Cost: 6.31s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 9.5713	Cost: 6.38s
Train Epoch: 142 	Average Loss: 9.5454
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6392

Learning rate: 9.995025557476254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 9.6086	Cost: 36.22s
Train Epoch: 143 [20480/90000 (23%)]	Loss: 9.3495	Cost: 14.07s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 9.5902	Cost: 11.78s
Train Epoch: 143 [61440/90000 (68%)]	Loss: 9.6340	Cost: 10.42s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 9.7007	Cost: 9.64s
Train Epoch: 143 	Average Loss: 9.5479
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6954

Learning rate: 9.99495526003174e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 9.7099	Cost: 80.80s
Train Epoch: 144 [20480/90000 (23%)]	Loss: 9.3954	Cost: 13.04s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 9.6206	Cost: 15.08s
Train Epoch: 144 [61440/90000 (68%)]	Loss: 9.4614	Cost: 13.54s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 9.3830	Cost: 13.87s
Train Epoch: 144 	Average Loss: 9.5239
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5835

Saving model as e144_model.pt & e144_waveforms_supplementary.hdf5
Learning rate: 9.994884469604905e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 9.6026	Cost: 73.95s
Train Epoch: 145 [20480/90000 (23%)]	Loss: 9.5149	Cost: 18.09s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 9.5349	Cost: 18.84s
Train Epoch: 145 [61440/90000 (68%)]	Loss: 9.5047	Cost: 13.91s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 9.5216	Cost: 23.30s
Train Epoch: 145 	Average Loss: 9.5061
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5532

Saving model as e145_model.pt & e145_waveforms_supplementary.hdf5
Learning rate: 9.994813186202739e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 9.6564	Cost: 20.03s
Train Epoch: 146 [20480/90000 (23%)]	Loss: 9.4457	Cost: 9.09s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 9.5347	Cost: 10.99s
Train Epoch: 146 [61440/90000 (68%)]	Loss: 9.6152	Cost: 10.15s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 9.4271	Cost: 12.50s
Train Epoch: 146 	Average Loss: 9.5044
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5586

Learning rate: 9.994741409832273e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 9.5287	Cost: 22.31s
Train Epoch: 147 [20480/90000 (23%)]	Loss: 9.5680	Cost: 8.57s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 9.4688	Cost: 13.67s
Train Epoch: 147 [61440/90000 (68%)]	Loss: 9.5463	Cost: 13.57s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 9.5889	Cost: 12.51s
Train Epoch: 147 	Average Loss: 9.4832
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5927

Learning rate: 9.994669140500594e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 9.6028	Cost: 27.07s
Train Epoch: 148 [20480/90000 (23%)]	Loss: 9.4849	Cost: 15.20s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 9.4729	Cost: 13.96s
Train Epoch: 148 [61440/90000 (68%)]	Loss: 9.6441	Cost: 12.17s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 9.5087	Cost: 12.11s
Train Epoch: 148 	Average Loss: 9.4720
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4970

Saving model as e148_model.pt & e148_waveforms_supplementary.hdf5
Learning rate: 9.994596378214833e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 9.3952	Cost: 29.19s
Train Epoch: 149 [20480/90000 (23%)]	Loss: 9.3864	Cost: 10.74s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 9.5372	Cost: 12.31s
Train Epoch: 149 [61440/90000 (68%)]	Loss: 9.4745	Cost: 12.05s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 9.4071	Cost: 7.52s
Train Epoch: 149 	Average Loss: 9.4559
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5912

Learning rate: 9.994523122982173e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 9.6670	Cost: 30.57s
Train Epoch: 150 [20480/90000 (23%)]	Loss: 9.5210	Cost: 12.52s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 9.3732	Cost: 12.43s
Train Epoch: 150 [61440/90000 (68%)]	Loss: 9.3834	Cost: 8.54s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 9.3135	Cost: 6.36s
Train Epoch: 150 	Average Loss: 9.4620
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5341

Learning rate: 9.994449374809844e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 9.4601	Cost: 32.18s
Train Epoch: 151 [20480/90000 (23%)]	Loss: 9.4592	Cost: 7.00s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 9.3438	Cost: 13.22s
Train Epoch: 151 [61440/90000 (68%)]	Loss: 9.2620	Cost: 7.78s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 9.5377	Cost: 7.11s
Train Epoch: 151 	Average Loss: 9.4133
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4502

Saving model as e151_model.pt & e151_waveforms_supplementary.hdf5
Learning rate: 9.994375133705122e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 9.4093	Cost: 23.71s
Train Epoch: 152 [20480/90000 (23%)]	Loss: 9.4823	Cost: 10.49s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 9.4088	Cost: 9.49s
Train Epoch: 152 [61440/90000 (68%)]	Loss: 9.4811	Cost: 7.17s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 9.4717	Cost: 8.09s
Train Epoch: 152 	Average Loss: 9.4125
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4816

Learning rate: 9.994300399675336e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 9.6322	Cost: 20.43s
Train Epoch: 153 [20480/90000 (23%)]	Loss: 9.2279	Cost: 7.24s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 9.3487	Cost: 11.51s
Train Epoch: 153 [61440/90000 (68%)]	Loss: 9.3769	Cost: 8.88s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 9.4159	Cost: 8.71s
Train Epoch: 153 	Average Loss: 9.3939
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5118

Learning rate: 9.994225172727863e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 9.5715	Cost: 26.16s
Train Epoch: 154 [20480/90000 (23%)]	Loss: 9.3098	Cost: 9.41s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 9.2275	Cost: 8.86s
Train Epoch: 154 [61440/90000 (68%)]	Loss: 9.3456	Cost: 8.61s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 9.3743	Cost: 8.82s
Train Epoch: 154 	Average Loss: 9.3996
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4588

Learning rate: 9.994149452870126e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 9.5149	Cost: 29.46s
Train Epoch: 155 [20480/90000 (23%)]	Loss: 9.3145	Cost: 9.34s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 9.4479	Cost: 9.12s
Train Epoch: 155 [61440/90000 (68%)]	Loss: 9.3421	Cost: 8.68s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 9.3992	Cost: 8.54s
Train Epoch: 155 	Average Loss: 9.3754
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4265

Saving model as e155_model.pt & e155_waveforms_supplementary.hdf5
Learning rate: 9.9940732401096e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 9.4572	Cost: 21.20s
Train Epoch: 156 [20480/90000 (23%)]	Loss: 9.3278	Cost: 7.43s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 9.3253	Cost: 10.12s
Train Epoch: 156 [61440/90000 (68%)]	Loss: 9.3799	Cost: 9.78s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 9.4034	Cost: 12.33s
Train Epoch: 156 	Average Loss: 9.3654
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4303

Learning rate: 9.993996534453805e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 9.4195	Cost: 22.57s
Train Epoch: 157 [20480/90000 (23%)]	Loss: 9.2625	Cost: 8.14s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 9.4037	Cost: 13.09s
Train Epoch: 157 [61440/90000 (68%)]	Loss: 9.3328	Cost: 13.59s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 9.5123	Cost: 12.86s
Train Epoch: 157 	Average Loss: 9.3461
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4654

Learning rate: 9.993919335910311e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 9.5114	Cost: 27.91s
Train Epoch: 158 [20480/90000 (23%)]	Loss: 9.3829	Cost: 14.89s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 9.3084	Cost: 13.70s
Train Epoch: 158 [61440/90000 (68%)]	Loss: 9.2845	Cost: 12.18s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 9.2402	Cost: 11.85s
Train Epoch: 158 	Average Loss: 9.3127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3798

Saving model as e158_model.pt & e158_waveforms_supplementary.hdf5
Learning rate: 9.993841644486739e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 9.4110	Cost: 34.86s
Train Epoch: 159 [20480/90000 (23%)]	Loss: 9.2971	Cost: 12.13s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 9.2996	Cost: 9.63s
Train Epoch: 159 [61440/90000 (68%)]	Loss: 9.3778	Cost: 6.06s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 9.2974	Cost: 7.41s
Train Epoch: 159 	Average Loss: 9.3157
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4454

Learning rate: 9.993763460190757e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 9.3291	Cost: 29.22s
Train Epoch: 160 [20480/90000 (23%)]	Loss: 9.3951	Cost: 7.66s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 9.2641	Cost: 7.06s
Train Epoch: 160 [61440/90000 (68%)]	Loss: 9.4102	Cost: 6.91s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 9.2418	Cost: 8.77s
Train Epoch: 160 	Average Loss: 9.3252
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4315

Learning rate: 9.993684783030081e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 9.4024	Cost: 23.39s
Train Epoch: 161 [20480/90000 (23%)]	Loss: 9.2239	Cost: 7.60s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 9.2506	Cost: 8.67s
Train Epoch: 161 [61440/90000 (68%)]	Loss: 9.2623	Cost: 8.93s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 9.1907	Cost: 8.99s
Train Epoch: 161 	Average Loss: 9.2902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3381

Saving model as e161_model.pt & e161_waveforms_supplementary.hdf5
Learning rate: 9.993605613012475e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 9.3737	Cost: 28.63s
Train Epoch: 162 [20480/90000 (23%)]	Loss: 9.2271	Cost: 10.50s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 9.3413	Cost: 10.32s
Train Epoch: 162 [61440/90000 (68%)]	Loss: 9.2712	Cost: 9.10s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 9.3816	Cost: 12.17s
Train Epoch: 162 	Average Loss: 9.2995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3612

Learning rate: 9.993525950145754e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 9.4796	Cost: 25.60s
Train Epoch: 163 [20480/90000 (23%)]	Loss: 9.1852	Cost: 8.82s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 9.2342	Cost: 13.93s
Train Epoch: 163 [61440/90000 (68%)]	Loss: 9.2109	Cost: 13.16s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 9.1248	Cost: 12.35s
Train Epoch: 163 	Average Loss: 9.2783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3250

Saving model as e163_model.pt & e163_waveforms_supplementary.hdf5
Learning rate: 9.993445794437781e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 9.4870	Cost: 33.95s
Train Epoch: 164 [20480/90000 (23%)]	Loss: 9.3106	Cost: 12.54s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 9.1827	Cost: 12.57s
Train Epoch: 164 [61440/90000 (68%)]	Loss: 9.1473	Cost: 12.35s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 9.3270	Cost: 8.29s
Train Epoch: 164 	Average Loss: 9.2737
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3212

Saving model as e164_model.pt & e164_waveforms_supplementary.hdf5
Learning rate: 9.993365145896465e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 9.4281	Cost: 23.94s
Train Epoch: 165 [20480/90000 (23%)]	Loss: 9.2223	Cost: 11.84s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 9.2103	Cost: 6.82s
Train Epoch: 165 [61440/90000 (68%)]	Loss: 9.1908	Cost: 6.72s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 9.0881	Cost: 8.70s
Train Epoch: 165 	Average Loss: 9.2553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3226

Learning rate: 9.993284004529768e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 9.4414	Cost: 27.87s
Train Epoch: 166 [20480/90000 (23%)]	Loss: 9.1617	Cost: 12.90s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 9.3193	Cost: 8.89s
Train Epoch: 166 [61440/90000 (68%)]	Loss: 9.1716	Cost: 6.36s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 9.2673	Cost: 7.21s
Train Epoch: 166 	Average Loss: 9.2505
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3430

Learning rate: 9.993202370345697e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 9.3858	Cost: 22.25s
Train Epoch: 167 [20480/90000 (23%)]	Loss: 9.2998	Cost: 13.60s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 9.2666	Cost: 9.69s
Train Epoch: 167 [61440/90000 (68%)]	Loss: 9.2096	Cost: 8.94s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 9.0196	Cost: 9.02s
Train Epoch: 167 	Average Loss: 9.2334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3700

Learning rate: 9.993120243352309e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 9.3220	Cost: 23.21s
Train Epoch: 168 [20480/90000 (23%)]	Loss: 9.1128	Cost: 7.64s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 9.1856	Cost: 9.60s
Train Epoch: 168 [61440/90000 (68%)]	Loss: 9.3014	Cost: 8.90s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 9.2480	Cost: 8.62s
Train Epoch: 168 	Average Loss: 9.2099
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3282

Learning rate: 9.993037623557708e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 9.1498	Cost: 23.65s
Train Epoch: 169 [20480/90000 (23%)]	Loss: 9.0824	Cost: 7.96s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 9.0940	Cost: 9.40s
Train Epoch: 169 [61440/90000 (68%)]	Loss: 9.1159	Cost: 8.61s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 9.1626	Cost: 8.70s
Train Epoch: 169 	Average Loss: 9.2201
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3156

Saving model as e169_model.pt & e169_waveforms_supplementary.hdf5
Learning rate: 9.992954510970051e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 9.5283	Cost: 21.68s
Train Epoch: 170 [20480/90000 (23%)]	Loss: 9.3602	Cost: 8.35s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 9.2143	Cost: 6.12s
Train Epoch: 170 [61440/90000 (68%)]	Loss: 9.2466	Cost: 7.17s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 9.2083	Cost: 9.10s
Train Epoch: 170 	Average Loss: 9.2085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2620

Saving model as e170_model.pt & e170_waveforms_supplementary.hdf5
Learning rate: 9.99287090559754e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 9.3360	Cost: 30.80s
Train Epoch: 171 [20480/90000 (23%)]	Loss: 9.2418	Cost: 7.73s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 9.1670	Cost: 12.58s
Train Epoch: 171 [61440/90000 (68%)]	Loss: 9.0094	Cost: 12.44s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 9.0828	Cost: 12.43s
Train Epoch: 171 	Average Loss: 9.1707
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2447

Saving model as e171_model.pt & e171_waveforms_supplementary.hdf5
Learning rate: 9.992786807448426e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 9.3017	Cost: 38.42s
Train Epoch: 172 [20480/90000 (23%)]	Loss: 9.2911	Cost: 13.39s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 9.2319	Cost: 13.46s
Train Epoch: 172 [61440/90000 (68%)]	Loss: 9.1061	Cost: 12.52s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 9.0773	Cost: 8.92s
Train Epoch: 172 	Average Loss: 9.1578
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3037

Learning rate: 9.992702216531012e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 9.1253	Cost: 41.97s
Train Epoch: 173 [20480/90000 (23%)]	Loss: 9.0728	Cost: 13.21s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 9.1603	Cost: 10.27s
Train Epoch: 173 [61440/90000 (68%)]	Loss: 9.1378	Cost: 6.13s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 9.2057	Cost: 6.61s
Train Epoch: 173 	Average Loss: 9.1713
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2592

Learning rate: 9.992617132853643e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 9.3090	Cost: 29.93s
Train Epoch: 174 [20480/90000 (23%)]	Loss: 9.1672	Cost: 10.64s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 9.1323	Cost: 9.16s
Train Epoch: 174 [61440/90000 (68%)]	Loss: 9.3553	Cost: 6.11s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 9.0156	Cost: 6.53s
Train Epoch: 174 	Average Loss: 9.1411
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2327

Saving model as e174_model.pt & e174_waveforms_supplementary.hdf5
Learning rate: 9.992531556424718e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 9.1396	Cost: 19.94s
Train Epoch: 175 [20480/90000 (23%)]	Loss: 9.2299	Cost: 6.71s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 9.1965	Cost: 10.29s
Train Epoch: 175 [61440/90000 (68%)]	Loss: 9.1169	Cost: 8.54s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 9.0323	Cost: 8.43s
Train Epoch: 175 	Average Loss: 9.1401
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1693

Saving model as e175_model.pt & e175_waveforms_supplementary.hdf5
Learning rate: 9.992445487252684e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 9.1919	Cost: 23.02s
Train Epoch: 176 [20480/90000 (23%)]	Loss: 8.8639	Cost: 8.13s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 9.1358	Cost: 8.90s
Train Epoch: 176 [61440/90000 (68%)]	Loss: 9.0939	Cost: 8.61s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 9.0003	Cost: 8.72s
Train Epoch: 176 	Average Loss: 9.0878
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2257

Learning rate: 9.992358925346033e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 9.1320	Cost: 23.70s
Train Epoch: 177 [20480/90000 (23%)]	Loss: 9.0062	Cost: 11.16s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 9.1073	Cost: 11.11s
Train Epoch: 177 [61440/90000 (68%)]	Loss: 9.0439	Cost: 8.92s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 8.9855	Cost: 6.09s
Train Epoch: 177 	Average Loss: 9.0779
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1691

Saving model as e177_model.pt & e177_waveforms_supplementary.hdf5
Learning rate: 9.992271870713308e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 9.1214	Cost: 21.51s
Train Epoch: 178 [20480/90000 (23%)]	Loss: 9.0407	Cost: 10.85s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 9.1747	Cost: 10.24s
Train Epoch: 178 [61440/90000 (68%)]	Loss: 8.9916	Cost: 9.82s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 9.0556	Cost: 11.91s
Train Epoch: 178 	Average Loss: 9.0704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1304

Saving model as e178_model.pt & e178_waveforms_supplementary.hdf5
Learning rate: 9.992184323363105e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 9.2654	Cost: 28.86s
Train Epoch: 179 [20480/90000 (23%)]	Loss: 9.0653	Cost: 12.96s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 9.0112	Cost: 13.02s
Train Epoch: 179 [61440/90000 (68%)]	Loss: 9.3002	Cost: 12.37s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 8.9370	Cost: 12.47s
Train Epoch: 179 	Average Loss: 9.0754
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1194

Saving model as e179_model.pt & e179_waveforms_supplementary.hdf5
Learning rate: 9.992096283304062e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 9.0944	Cost: 25.24s
Train Epoch: 180 [20480/90000 (23%)]	Loss: 9.0893	Cost: 12.38s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 9.0832	Cost: 15.89s
Train Epoch: 180 [61440/90000 (68%)]	Loss: 8.9928	Cost: 14.03s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 9.0437	Cost: 12.22s
Train Epoch: 180 	Average Loss: 9.0206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0781

Saving model as e180_model.pt & e180_waveforms_supplementary.hdf5
Learning rate: 9.992007750544869e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 9.0410	Cost: 50.24s
Train Epoch: 181 [20480/90000 (23%)]	Loss: 8.9468	Cost: 16.37s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 8.9520	Cost: 10.36s
Train Epoch: 181 [61440/90000 (68%)]	Loss: 9.0325	Cost: 9.74s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 8.9723	Cost: 6.39s
Train Epoch: 181 	Average Loss: 9.0053
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1231

Learning rate: 9.991918725094262e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 9.0757	Cost: 26.78s
Train Epoch: 182 [20480/90000 (23%)]	Loss: 8.9463	Cost: 11.00s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 8.9480	Cost: 12.29s
Train Epoch: 182 [61440/90000 (68%)]	Loss: 8.9999	Cost: 6.80s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 9.0712	Cost: 7.18s
Train Epoch: 182 	Average Loss: 8.9980
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1406

Learning rate: 9.99182920696103e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 9.2666	Cost: 23.63s
Train Epoch: 183 [20480/90000 (23%)]	Loss: 8.9536	Cost: 11.38s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 9.0455	Cost: 9.32s
Train Epoch: 183 [61440/90000 (68%)]	Loss: 8.9973	Cost: 6.34s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 9.0022	Cost: 8.48s
Train Epoch: 183 	Average Loss: 8.9798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1238

Learning rate: 9.991739196154006e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 9.0102	Cost: 19.66s
Train Epoch: 184 [20480/90000 (23%)]	Loss: 9.0363	Cost: 6.60s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 8.8401	Cost: 10.48s
Train Epoch: 184 [61440/90000 (68%)]	Loss: 8.9951	Cost: 8.99s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 8.8391	Cost: 8.80s
Train Epoch: 184 	Average Loss: 8.9606
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0874

Learning rate: 9.991648692682075e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 8.8319	Cost: 32.46s
Train Epoch: 185 [20480/90000 (23%)]	Loss: 8.9349	Cost: 8.97s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 8.9950	Cost: 9.08s
Train Epoch: 185 [61440/90000 (68%)]	Loss: 8.9616	Cost: 9.12s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 8.8467	Cost: 6.78s
Train Epoch: 185 	Average Loss: 8.9594
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0643

Saving model as e185_model.pt & e185_waveforms_supplementary.hdf5
Learning rate: 9.991557696554169e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 9.2169	Cost: 23.38s
Train Epoch: 186 [20480/90000 (23%)]	Loss: 8.9311	Cost: 7.95s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 9.0281	Cost: 12.26s
Train Epoch: 186 [61440/90000 (68%)]	Loss: 8.9234	Cost: 9.81s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 8.9492	Cost: 13.14s
Train Epoch: 186 	Average Loss: 8.9397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0474

Saving model as e186_model.pt & e186_waveforms_supplementary.hdf5
Learning rate: 9.99146620777927e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 9.0716	Cost: 23.83s
Train Epoch: 187 [20480/90000 (23%)]	Loss: 8.8386	Cost: 14.20s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 8.9205	Cost: 14.01s
Train Epoch: 187 [61440/90000 (68%)]	Loss: 8.8740	Cost: 12.61s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 8.9139	Cost: 12.48s
Train Epoch: 187 	Average Loss: 8.9257
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0448

Saving model as e187_model.pt & e187_waveforms_supplementary.hdf5
Learning rate: 9.991374226366404e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 9.0402	Cost: 25.53s
Train Epoch: 188 [20480/90000 (23%)]	Loss: 8.8991	Cost: 12.22s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 8.9055	Cost: 13.96s
Train Epoch: 188 [61440/90000 (68%)]	Loss: 8.8329	Cost: 10.60s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 8.9069	Cost: 7.17s
Train Epoch: 188 	Average Loss: 8.9268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0546

Learning rate: 9.991281752324654e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 8.9698	Cost: 25.27s
Train Epoch: 189 [20480/90000 (23%)]	Loss: 8.8728	Cost: 11.56s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 8.9511	Cost: 8.17s
Train Epoch: 189 [61440/90000 (68%)]	Loss: 8.9111	Cost: 6.25s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 8.8674	Cost: 7.35s
Train Epoch: 189 	Average Loss: 8.8961
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0446

Saving model as e189_model.pt & e189_waveforms_supplementary.hdf5
Learning rate: 9.991188785663142e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 9.1156	Cost: 30.28s
Train Epoch: 190 [20480/90000 (23%)]	Loss: 8.8452	Cost: 10.73s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 8.8112	Cost: 9.02s
Train Epoch: 190 [61440/90000 (68%)]	Loss: 8.9233	Cost: 8.78s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 8.7804	Cost: 9.12s
Train Epoch: 190 	Average Loss: 8.9110
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0295

Saving model as e190_model.pt & e190_waveforms_supplementary.hdf5
Learning rate: 9.991095326391049e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 8.9515	Cost: 33.30s
Train Epoch: 191 [20480/90000 (23%)]	Loss: 8.7518	Cost: 8.97s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 8.9043	Cost: 8.83s
Train Epoch: 191 [61440/90000 (68%)]	Loss: 8.9187	Cost: 7.63s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 8.8303	Cost: 6.03s
Train Epoch: 191 	Average Loss: 8.8914
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9645

Saving model as e191_model.pt & e191_waveforms_supplementary.hdf5
Learning rate: 9.991001374517595e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 9.1915	Cost: 22.07s
Train Epoch: 192 [20480/90000 (23%)]	Loss: 8.7980	Cost: 9.19s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 8.9338	Cost: 14.35s
Train Epoch: 192 [61440/90000 (68%)]	Loss: 8.9489	Cost: 14.47s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 8.9484	Cost: 13.47s
Train Epoch: 192 	Average Loss: 8.8587
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0148

Learning rate: 9.990906930052053e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 8.9997	Cost: 21.87s
Train Epoch: 193 [20480/90000 (23%)]	Loss: 8.7851	Cost: 9.17s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 8.8156	Cost: 14.99s
Train Epoch: 193 [61440/90000 (68%)]	Loss: 8.7662	Cost: 14.89s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 8.9166	Cost: 12.74s
Train Epoch: 193 	Average Loss: 8.8674
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9848

Learning rate: 9.990811993003745e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 9.0184	Cost: 33.58s
Train Epoch: 194 [20480/90000 (23%)]	Loss: 8.7778	Cost: 12.79s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 8.8875	Cost: 12.48s
Train Epoch: 194 [61440/90000 (68%)]	Loss: 8.8521	Cost: 12.01s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 8.7939	Cost: 9.32s
Train Epoch: 194 	Average Loss: 8.8304
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9835

Learning rate: 9.990716563382042e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 9.0244	Cost: 35.52s
Train Epoch: 195 [20480/90000 (23%)]	Loss: 8.6770	Cost: 11.90s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 8.8725	Cost: 7.77s
Train Epoch: 195 [61440/90000 (68%)]	Loss: 8.8030	Cost: 6.17s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 8.8173	Cost: 7.79s
Train Epoch: 195 	Average Loss: 8.8204
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9033

Saving model as e195_model.pt & e195_waveforms_supplementary.hdf5
Learning rate: 9.990620641196361e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 8.8668	Cost: 22.60s
Train Epoch: 196 [20480/90000 (23%)]	Loss: 8.8093	Cost: 7.04s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 8.7550	Cost: 9.10s
Train Epoch: 196 [61440/90000 (68%)]	Loss: 8.8578	Cost: 9.01s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 8.7773	Cost: 9.03s
Train Epoch: 196 	Average Loss: 8.7981
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9114

Learning rate: 9.99052422645617e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 9.0875	Cost: 27.77s
Train Epoch: 197 [20480/90000 (23%)]	Loss: 8.6835	Cost: 10.30s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 8.7214	Cost: 9.45s
Train Epoch: 197 [61440/90000 (68%)]	Loss: 8.7111	Cost: 8.60s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 8.8041	Cost: 7.78s
Train Epoch: 197 	Average Loss: 8.7865
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9271

Learning rate: 9.990427319170984e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 8.9132	Cost: 24.02s
Train Epoch: 198 [20480/90000 (23%)]	Loss: 8.7291	Cost: 9.27s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 8.9678	Cost: 8.54s
Train Epoch: 198 [61440/90000 (68%)]	Loss: 8.7633	Cost: 6.47s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 8.8350	Cost: 6.51s
Train Epoch: 198 	Average Loss: 8.7872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8689

Saving model as e198_model.pt & e198_waveforms_supplementary.hdf5
Learning rate: 9.990329919350368e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 8.8851	Cost: 19.61s
Train Epoch: 199 [20480/90000 (23%)]	Loss: 8.8926	Cost: 9.02s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 8.7169	Cost: 11.48s
Train Epoch: 199 [61440/90000 (68%)]	Loss: 8.8992	Cost: 13.45s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 8.6695	Cost: 13.97s
Train Epoch: 199 	Average Loss: 8.7858
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9417

Learning rate: 9.990232027003935e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 8.8894	Cost: 24.16s
Train Epoch: 200 [20480/90000 (23%)]	Loss: 8.6001	Cost: 11.94s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 8.6231	Cost: 12.54s
Train Epoch: 200 [61440/90000 (68%)]	Loss: 8.6551	Cost: 12.40s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 8.8641	Cost: 12.74s
Train Epoch: 200 	Average Loss: 8.7528
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8613

Saving model as e200_model.pt & e200_waveforms_supplementary.hdf5
Learning rate: 9.990133642141346e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 8.8302	Cost: 24.07s
Train Epoch: 201 [20480/90000 (23%)]	Loss: 8.6864	Cost: 15.13s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 8.6615	Cost: 13.54s
Train Epoch: 201 [61440/90000 (68%)]	Loss: 8.6877	Cost: 12.23s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 8.6336	Cost: 8.16s
Train Epoch: 201 	Average Loss: 8.7296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8960

Learning rate: 9.990034764772311e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 8.7514	Cost: 29.12s
Train Epoch: 202 [20480/90000 (23%)]	Loss: 8.6907	Cost: 13.11s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 8.7794	Cost: 10.82s
Train Epoch: 202 [61440/90000 (68%)]	Loss: 8.7331	Cost: 6.18s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 8.6969	Cost: 7.26s
Train Epoch: 202 	Average Loss: 8.7475
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8651

Learning rate: 9.98993539490659e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 8.9009	Cost: 39.65s
Train Epoch: 203 [20480/90000 (23%)]	Loss: 8.7458	Cost: 8.75s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 8.8452	Cost: 7.27s
Train Epoch: 203 [61440/90000 (68%)]	Loss: 8.6786	Cost: 6.98s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 8.6341	Cost: 8.52s
Train Epoch: 203 	Average Loss: 8.7330
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8370

Saving model as e203_model.pt & e203_waveforms_supplementary.hdf5
Learning rate: 9.989835532553989e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 8.9876	Cost: 27.42s
Train Epoch: 204 [20480/90000 (23%)]	Loss: 8.7103	Cost: 12.34s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 8.7333	Cost: 7.43s
Train Epoch: 204 [61440/90000 (68%)]	Loss: 8.6805	Cost: 6.30s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 8.6874	Cost: 7.70s
Train Epoch: 204 	Average Loss: 8.7380
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8628

Learning rate: 9.989735177724366e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 8.9745	Cost: 18.99s
Train Epoch: 205 [20480/90000 (23%)]	Loss: 8.6310	Cost: 6.71s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 8.6947	Cost: 9.97s
Train Epoch: 205 [61440/90000 (68%)]	Loss: 8.6354	Cost: 8.69s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 8.6906	Cost: 8.48s
Train Epoch: 205 	Average Loss: 8.6957
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8408

Learning rate: 9.989634330427624e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 8.7845	Cost: 22.28s
Train Epoch: 206 [20480/90000 (23%)]	Loss: 8.7734	Cost: 8.99s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 8.7204	Cost: 9.08s
Train Epoch: 206 [61440/90000 (68%)]	Loss: 8.6566	Cost: 9.05s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 8.8201	Cost: 8.91s
Train Epoch: 206 	Average Loss: 8.7014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8675

Learning rate: 9.989532990673716e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 8.8120	Cost: 23.21s
Train Epoch: 207 [20480/90000 (23%)]	Loss: 8.7686	Cost: 9.86s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 8.8278	Cost: 8.88s
Train Epoch: 207 [61440/90000 (68%)]	Loss: 8.7177	Cost: 8.63s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 8.5613	Cost: 8.48s
Train Epoch: 207 	Average Loss: 8.6919
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8591

Learning rate: 9.989431158472645e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 8.7145	Cost: 55.03s
Train Epoch: 208 [20480/90000 (23%)]	Loss: 8.6006	Cost: 10.43s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 8.5886	Cost: 18.11s
Train Epoch: 208 [61440/90000 (68%)]	Loss: 8.7143	Cost: 13.45s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 8.6171	Cost: 20.82s
Train Epoch: 208 	Average Loss: 8.6535
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7705

Saving model as e208_model.pt & e208_waveforms_supplementary.hdf5
Learning rate: 9.98932883383446e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 8.7551	Cost: 21.67s
Train Epoch: 209 [20480/90000 (23%)]	Loss: 8.7389	Cost: 10.52s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 8.7949	Cost: 14.66s
Train Epoch: 209 [61440/90000 (68%)]	Loss: 8.6893	Cost: 12.81s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 8.7125	Cost: 12.58s
Train Epoch: 209 	Average Loss: 8.6826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8208

Learning rate: 9.989226016769262e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 8.7338	Cost: 30.23s
Train Epoch: 210 [20480/90000 (23%)]	Loss: 8.5949	Cost: 10.54s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 8.5190	Cost: 13.31s
Train Epoch: 210 [61440/90000 (68%)]	Loss: 8.6139	Cost: 12.71s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 8.7197	Cost: 9.44s
Train Epoch: 210 	Average Loss: 8.6494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8487

Learning rate: 9.989122707287198e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 8.8943	Cost: 23.86s
Train Epoch: 211 [20480/90000 (23%)]	Loss: 8.6297	Cost: 14.03s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 8.6049	Cost: 12.55s
Train Epoch: 211 [61440/90000 (68%)]	Loss: 8.5836	Cost: 10.84s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 8.6430	Cost: 6.18s
Train Epoch: 211 	Average Loss: 8.6628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7965

Learning rate: 9.989018905398462e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 8.7346	Cost: 36.38s
Train Epoch: 212 [20480/90000 (23%)]	Loss: 8.5473	Cost: 13.94s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 8.7096	Cost: 8.12s
Train Epoch: 212 [61440/90000 (68%)]	Loss: 8.5630	Cost: 7.06s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 8.5919	Cost: 8.80s
Train Epoch: 212 	Average Loss: 8.6068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7592

Saving model as e212_model.pt & e212_waveforms_supplementary.hdf5
Learning rate: 9.9889146111133e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 8.8669	Cost: 26.84s
Train Epoch: 213 [20480/90000 (23%)]	Loss: 8.6157	Cost: 10.62s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 8.7187	Cost: 8.98s
Train Epoch: 213 [61440/90000 (68%)]	Loss: 8.6942	Cost: 8.84s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 8.5064	Cost: 8.57s
Train Epoch: 213 	Average Loss: 8.6634
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8318

Learning rate: 9.988809824442008e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 8.9841	Cost: 22.69s
Train Epoch: 214 [20480/90000 (23%)]	Loss: 8.6511	Cost: 8.52s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 8.5987	Cost: 9.23s
Train Epoch: 214 [61440/90000 (68%)]	Loss: 8.6053	Cost: 8.75s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 8.6344	Cost: 9.43s
Train Epoch: 214 	Average Loss: 8.6082
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7444

Saving model as e214_model.pt & e214_waveforms_supplementary.hdf5
Learning rate: 9.988704545394925e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 8.8642	Cost: 39.79s
Train Epoch: 215 [20480/90000 (23%)]	Loss: 8.7272	Cost: 11.35s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 8.6398	Cost: 8.71s
Train Epoch: 215 [61440/90000 (68%)]	Loss: 8.6881	Cost: 7.65s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 8.5591	Cost: 8.67s
Train Epoch: 215 	Average Loss: 8.6183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7269

Saving model as e215_model.pt & e215_waveforms_supplementary.hdf5
Learning rate: 9.988598773982444e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 8.6710	Cost: 23.05s
Train Epoch: 216 [20480/90000 (23%)]	Loss: 8.4418	Cost: 8.92s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 8.6020	Cost: 13.37s
Train Epoch: 216 [61440/90000 (68%)]	Loss: 8.5247	Cost: 13.23s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 8.5251	Cost: 12.50s
Train Epoch: 216 	Average Loss: 8.5904
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7764

Learning rate: 9.988492510215002e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 8.7973	Cost: 28.69s
Train Epoch: 217 [20480/90000 (23%)]	Loss: 8.4839	Cost: 14.59s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 8.6173	Cost: 14.03s
Train Epoch: 217 [61440/90000 (68%)]	Loss: 8.5641	Cost: 12.05s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 8.6713	Cost: 12.16s
Train Epoch: 217 	Average Loss: 8.5983
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6726

Saving model as e217_model.pt & e217_waveforms_supplementary.hdf5
Learning rate: 9.988385754103088e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 8.7016	Cost: 29.52s
Train Epoch: 218 [20480/90000 (23%)]	Loss: 8.5396	Cost: 12.68s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 8.6303	Cost: 12.44s
Train Epoch: 218 [61440/90000 (68%)]	Loss: 8.5580	Cost: 7.41s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 8.6128	Cost: 6.43s
Train Epoch: 218 	Average Loss: 8.5660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7249

Learning rate: 9.988278505657238e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 8.7092	Cost: 28.06s
Train Epoch: 219 [20480/90000 (23%)]	Loss: 8.5451	Cost: 12.20s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 8.4767	Cost: 6.84s
Train Epoch: 219 [61440/90000 (68%)]	Loss: 8.5903	Cost: 6.31s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 8.5830	Cost: 8.44s
Train Epoch: 219 	Average Loss: 8.5441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6931

Learning rate: 9.988170764888036e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 8.6980	Cost: 21.69s
Train Epoch: 220 [20480/90000 (23%)]	Loss: 8.4604	Cost: 11.21s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 8.4854	Cost: 11.29s
Train Epoch: 220 [61440/90000 (68%)]	Loss: 8.6598	Cost: 9.17s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 8.4654	Cost: 8.80s
Train Epoch: 220 	Average Loss: 8.5408
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6995

Learning rate: 9.988062531806117e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 8.8715	Cost: 31.02s
Train Epoch: 221 [20480/90000 (23%)]	Loss: 8.4366	Cost: 10.29s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 8.5695	Cost: 9.15s
Train Epoch: 221 [61440/90000 (68%)]	Loss: 8.6188	Cost: 6.25s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 8.5547	Cost: 6.57s
Train Epoch: 221 	Average Loss: 8.5401
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6462

Saving model as e221_model.pt & e221_waveforms_supplementary.hdf5
Learning rate: 9.987953806422163e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 8.8124	Cost: 20.22s
Train Epoch: 222 [20480/90000 (23%)]	Loss: 8.5158	Cost: 7.48s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 8.5766	Cost: 9.43s
Train Epoch: 222 [61440/90000 (68%)]	Loss: 8.3584	Cost: 12.77s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 8.5000	Cost: 12.44s
Train Epoch: 222 	Average Loss: 8.4995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7125

Learning rate: 9.987844588746906e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 8.7425	Cost: 22.49s
Train Epoch: 223 [20480/90000 (23%)]	Loss: 8.4068	Cost: 10.01s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 8.5911	Cost: 12.72s
Train Epoch: 223 [61440/90000 (68%)]	Loss: 8.4668	Cost: 12.09s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 8.4929	Cost: 12.69s
Train Epoch: 223 	Average Loss: 8.4942
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6487

Learning rate: 9.987734878791122e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 8.6830	Cost: 34.20s
Train Epoch: 224 [20480/90000 (23%)]	Loss: 8.4776	Cost: 11.41s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 8.5739	Cost: 13.01s
Train Epoch: 224 [61440/90000 (68%)]	Loss: 8.4520	Cost: 12.23s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 8.5348	Cost: 8.29s
Train Epoch: 224 	Average Loss: 8.5110
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6987

Learning rate: 9.987624676565643e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 8.4155	Cost: 36.73s
Train Epoch: 225 [20480/90000 (23%)]	Loss: 8.4856	Cost: 6.60s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 8.5600	Cost: 7.07s
Train Epoch: 225 [61440/90000 (68%)]	Loss: 8.5269	Cost: 8.20s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 8.4357	Cost: 9.05s
Train Epoch: 225 	Average Loss: 8.4948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6780

Learning rate: 9.987513982081342e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 8.6471	Cost: 23.72s
Train Epoch: 226 [20480/90000 (23%)]	Loss: 8.4475	Cost: 6.84s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 8.5206	Cost: 10.91s
Train Epoch: 226 [61440/90000 (68%)]	Loss: 8.4393	Cost: 8.64s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 8.5716	Cost: 8.46s
Train Epoch: 226 	Average Loss: 8.4751
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6901

Learning rate: 9.987402795349145e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 8.5921	Cost: 22.36s
Train Epoch: 227 [20480/90000 (23%)]	Loss: 8.4640	Cost: 9.58s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 8.5178	Cost: 8.92s
Train Epoch: 227 [61440/90000 (68%)]	Loss: 8.5013	Cost: 9.52s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 8.3983	Cost: 6.81s
Train Epoch: 227 	Average Loss: 8.4747
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7118

Learning rate: 9.987291116380029e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 8.6644	Cost: 19.76s
Train Epoch: 228 [20480/90000 (23%)]	Loss: 8.4007	Cost: 8.25s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 8.5800	Cost: 9.60s
Train Epoch: 228 [61440/90000 (68%)]	Loss: 8.4340	Cost: 9.50s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 8.4844	Cost: 15.62s
Train Epoch: 228 	Average Loss: 8.4662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7329

Learning rate: 9.98717894518501e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 8.6898	Cost: 22.55s
Train Epoch: 229 [20480/90000 (23%)]	Loss: 8.3366	Cost: 10.00s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 8.5133	Cost: 18.37s
Train Epoch: 229 [61440/90000 (68%)]	Loss: 8.4366	Cost: 13.08s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 8.4153	Cost: 12.09s
Train Epoch: 229 	Average Loss: 8.4437
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6116

Saving model as e229_model.pt & e229_waveforms_supplementary.hdf5
Learning rate: 9.987066281775164e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 8.4326	Cost: 28.39s
Train Epoch: 230 [20480/90000 (23%)]	Loss: 8.4747	Cost: 12.81s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 8.4339	Cost: 12.85s
Train Epoch: 230 [61440/90000 (68%)]	Loss: 8.4137	Cost: 12.19s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 8.4270	Cost: 8.97s
Train Epoch: 230 	Average Loss: 8.4401
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5739

Saving model as e230_model.pt & e230_waveforms_supplementary.hdf5
Learning rate: 9.98695312616161e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 8.6933	Cost: 27.63s
Train Epoch: 231 [20480/90000 (23%)]	Loss: 8.3363	Cost: 12.68s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 8.3939	Cost: 10.41s
Train Epoch: 231 [61440/90000 (68%)]	Loss: 8.4653	Cost: 6.53s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 8.2960	Cost: 6.24s
Train Epoch: 231 	Average Loss: 8.4128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5995

Learning rate: 9.986839478355513e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 8.6536	Cost: 27.91s
Train Epoch: 232 [20480/90000 (23%)]	Loss: 8.4531	Cost: 10.80s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 8.4315	Cost: 10.56s
Train Epoch: 232 [61440/90000 (68%)]	Loss: 8.4593	Cost: 7.71s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 8.4293	Cost: 8.85s
Train Epoch: 232 	Average Loss: 8.4034
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5645

Saving model as e232_model.pt & e232_waveforms_supplementary.hdf5
Learning rate: 9.986725338368092e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 8.6069	Cost: 20.65s
Train Epoch: 233 [20480/90000 (23%)]	Loss: 8.6549	Cost: 9.83s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 8.4725	Cost: 11.96s
Train Epoch: 233 [61440/90000 (68%)]	Loss: 8.3071	Cost: 9.11s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 8.4747	Cost: 8.75s
Train Epoch: 233 	Average Loss: 8.4302
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5525

Saving model as e233_model.pt & e233_waveforms_supplementary.hdf5
Learning rate: 9.986610706210612e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 8.5449	Cost: 24.58s
Train Epoch: 234 [20480/90000 (23%)]	Loss: 8.3150	Cost: 9.10s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 8.2819	Cost: 9.03s
Train Epoch: 234 [61440/90000 (68%)]	Loss: 8.3590	Cost: 6.55s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 8.5138	Cost: 6.91s
Train Epoch: 234 	Average Loss: 8.3942
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6210

Learning rate: 9.986495581894385e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 8.6425	Cost: 19.02s
Train Epoch: 235 [20480/90000 (23%)]	Loss: 8.2563	Cost: 8.82s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 8.4379	Cost: 13.41s
Train Epoch: 235 [61440/90000 (68%)]	Loss: 8.3606	Cost: 12.28s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 8.3758	Cost: 12.54s
Train Epoch: 235 	Average Loss: 8.3935
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5427

Saving model as e235_model.pt & e235_waveforms_supplementary.hdf5
Learning rate: 9.986379965430775e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 8.6222	Cost: 24.47s
Train Epoch: 236 [20480/90000 (23%)]	Loss: 8.2450	Cost: 13.50s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 8.2380	Cost: 14.17s
Train Epoch: 236 [61440/90000 (68%)]	Loss: 8.3498	Cost: 12.33s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 8.3541	Cost: 12.22s
Train Epoch: 236 	Average Loss: 8.3600
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6666

Learning rate: 9.986263856831194e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 8.4891	Cost: 42.84s
Train Epoch: 237 [20480/90000 (23%)]	Loss: 8.4354	Cost: 12.39s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 8.3013	Cost: 12.21s
Train Epoch: 237 [61440/90000 (68%)]	Loss: 8.3370	Cost: 8.34s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 8.3363	Cost: 6.10s
Train Epoch: 237 	Average Loss: 8.3535
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4841

Saving model as e237_model.pt & e237_waveforms_supplementary.hdf5
Learning rate: 9.9861472561071e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 8.6611	Cost: 38.43s
Train Epoch: 238 [20480/90000 (23%)]	Loss: 8.3969	Cost: 11.25s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 8.4169	Cost: 6.46s
Train Epoch: 238 [61440/90000 (68%)]	Loss: 8.3430	Cost: 6.28s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 8.3925	Cost: 8.49s
Train Epoch: 238 	Average Loss: 8.3460
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5150

Learning rate: 9.98603016327e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 8.7225	Cost: 19.76s
Train Epoch: 239 [20480/90000 (23%)]	Loss: 8.2522	Cost: 7.30s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 8.1967	Cost: 10.37s
Train Epoch: 239 [61440/90000 (68%)]	Loss: 8.2464	Cost: 8.86s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 8.4635	Cost: 9.43s
Train Epoch: 239 	Average Loss: 8.3547
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5780

Learning rate: 9.985912578331452e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 8.5776	Cost: 21.89s
Train Epoch: 240 [20480/90000 (23%)]	Loss: 8.2339	Cost: 8.95s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 8.3746	Cost: 9.25s
Train Epoch: 240 [61440/90000 (68%)]	Loss: 8.2033	Cost: 9.40s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 8.3198	Cost: 7.69s
Train Epoch: 240 	Average Loss: 8.3329
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5690

Learning rate: 9.985794501303059e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 8.4953	Cost: 20.66s
Train Epoch: 241 [20480/90000 (23%)]	Loss: 8.2926	Cost: 9.24s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 8.2586	Cost: 9.90s
Train Epoch: 241 [61440/90000 (68%)]	Loss: 8.3671	Cost: 12.29s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 8.2700	Cost: 12.12s
Train Epoch: 241 	Average Loss: 8.3224
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4618

Saving model as e241_model.pt & e241_waveforms_supplementary.hdf5
Learning rate: 9.985675932196479e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 8.4386	Cost: 40.14s
Train Epoch: 242 [20480/90000 (23%)]	Loss: 8.1759	Cost: 12.42s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 8.2766	Cost: 12.76s
Train Epoch: 242 [61440/90000 (68%)]	Loss: 8.3932	Cost: 12.12s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 8.2531	Cost: 9.45s
Train Epoch: 242 	Average Loss: 8.3113
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5367

Learning rate: 9.985556871023408e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 8.5778	Cost: 30.12s
Train Epoch: 243 [20480/90000 (23%)]	Loss: 8.2858	Cost: 12.50s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 8.2535	Cost: 12.31s
Train Epoch: 243 [61440/90000 (68%)]	Loss: 8.2834	Cost: 7.34s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 8.2037	Cost: 6.15s
Train Epoch: 243 	Average Loss: 8.2957
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4753

Learning rate: 9.985437317795604e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 8.5722	Cost: 32.45s
Train Epoch: 244 [20480/90000 (23%)]	Loss: 8.1286	Cost: 6.51s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 8.4659	Cost: 11.07s
Train Epoch: 244 [61440/90000 (68%)]	Loss: 8.3120	Cost: 9.06s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 8.2405	Cost: 8.79s
Train Epoch: 244 	Average Loss: 8.2820
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4944

Learning rate: 9.985317272524864e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 8.4433	Cost: 22.50s
Train Epoch: 245 [20480/90000 (23%)]	Loss: 8.1270	Cost: 11.60s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 8.3674	Cost: 10.43s
Train Epoch: 245 [61440/90000 (68%)]	Loss: 8.1410	Cost: 8.55s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 8.1296	Cost: 6.28s
Train Epoch: 245 	Average Loss: 8.2765
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4724

Learning rate: 9.985196735223035e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 8.5387	Cost: 22.56s
Train Epoch: 246 [20480/90000 (23%)]	Loss: 8.2135	Cost: 7.31s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 8.1727	Cost: 10.94s
Train Epoch: 246 [61440/90000 (68%)]	Loss: 8.3444	Cost: 10.99s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 8.1192	Cost: 12.55s
Train Epoch: 246 	Average Loss: 8.2780
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4099

Saving model as e246_model.pt & e246_waveforms_supplementary.hdf5
Learning rate: 9.985075705902012e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 8.5218	Cost: 22.57s
Train Epoch: 247 [20480/90000 (23%)]	Loss: 8.1194	Cost: 8.50s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 8.1363	Cost: 11.70s
Train Epoch: 247 [61440/90000 (68%)]	Loss: 8.3036	Cost: 12.57s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 8.2529	Cost: 12.41s
Train Epoch: 247 	Average Loss: 8.2341
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4006

Saving model as e247_model.pt & e247_waveforms_supplementary.hdf5
Learning rate: 9.984954184573743e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 8.5440	Cost: 27.09s
Train Epoch: 248 [20480/90000 (23%)]	Loss: 8.3012	Cost: 12.82s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 8.3111	Cost: 12.47s
Train Epoch: 248 [61440/90000 (68%)]	Loss: 8.2416	Cost: 12.47s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 8.3397	Cost: 11.69s
Train Epoch: 248 	Average Loss: 8.2418
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4032

Learning rate: 9.984832171250219e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 8.5798	Cost: 24.13s
Train Epoch: 249 [20480/90000 (23%)]	Loss: 8.1321	Cost: 9.16s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 8.1035	Cost: 12.72s
Train Epoch: 249 [61440/90000 (68%)]	Loss: 8.2136	Cost: 6.49s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 8.2363	Cost: 6.18s
Train Epoch: 249 	Average Loss: 8.2424
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5258

Learning rate: 9.984709665943483e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 8.3643	Cost: 54.83s
Train Epoch: 250 [20480/90000 (23%)]	Loss: 8.2465	Cost: 13.13s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 8.2321	Cost: 15.25s
Train Epoch: 250 [61440/90000 (68%)]	Loss: 8.2414	Cost: 10.33s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 8.2005	Cost: 20.47s
Train Epoch: 250 	Average Loss: 8.2359
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4303

Learning rate: 9.98458666866563e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 8.4765	Cost: 39.00s
Train Epoch: 251 [20480/90000 (23%)]	Loss: 8.0944	Cost: 10.83s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 8.2279	Cost: 13.09s
Train Epoch: 251 [61440/90000 (68%)]	Loss: 8.1446	Cost: 8.76s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 8.3009	Cost: 8.67s
Train Epoch: 251 	Average Loss: 8.2415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4419

Learning rate: 9.984463179428794e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 8.4177	Cost: 21.83s
Train Epoch: 252 [20480/90000 (23%)]	Loss: 8.2317	Cost: 8.99s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 8.2033	Cost: 8.71s
Train Epoch: 252 [61440/90000 (68%)]	Loss: 8.1851	Cost: 8.47s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 8.1895	Cost: 6.16s
Train Epoch: 252 	Average Loss: 8.2203
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4515

Learning rate: 9.984339198245162e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 8.3437	Cost: 20.23s
Train Epoch: 253 [20480/90000 (23%)]	Loss: 8.0849	Cost: 7.31s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 8.2154	Cost: 10.91s
Train Epoch: 253 [61440/90000 (68%)]	Loss: 8.1913	Cost: 13.84s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 8.2976	Cost: 12.56s
Train Epoch: 253 	Average Loss: 8.1874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3852

Saving model as e253_model.pt & e253_waveforms_supplementary.hdf5
Learning rate: 9.984214725126977e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 8.4666	Cost: 25.45s
Train Epoch: 254 [20480/90000 (23%)]	Loss: 8.2138	Cost: 11.99s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 8.0861	Cost: 14.33s
Train Epoch: 254 [61440/90000 (68%)]	Loss: 8.1890	Cost: 12.64s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 8.0914	Cost: 12.16s
Train Epoch: 254 	Average Loss: 8.1958
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4444

Learning rate: 9.98408976008652e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 8.3395	Cost: 32.85s
Train Epoch: 255 [20480/90000 (23%)]	Loss: 8.0927	Cost: 12.52s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 8.1178	Cost: 13.45s
Train Epoch: 255 [61440/90000 (68%)]	Loss: 8.0266	Cost: 12.17s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 8.2337	Cost: 10.93s
Train Epoch: 255 	Average Loss: 8.1853
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4699

Learning rate: 9.983964303136122e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 8.4449	Cost: 34.55s
Train Epoch: 256 [20480/90000 (23%)]	Loss: 8.1279	Cost: 12.32s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 8.1530	Cost: 12.47s
Train Epoch: 256 [61440/90000 (68%)]	Loss: 8.1605	Cost: 6.40s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 8.2037	Cost: 6.42s
Train Epoch: 256 	Average Loss: 8.1741
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4812

Learning rate: 9.98383835428817e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 8.5408	Cost: 27.14s
Train Epoch: 257 [20480/90000 (23%)]	Loss: 8.1284	Cost: 13.77s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 8.1227	Cost: 10.72s
Train Epoch: 257 [61440/90000 (68%)]	Loss: 8.1403	Cost: 6.67s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 8.2999	Cost: 7.23s
Train Epoch: 257 	Average Loss: 8.1816
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4394

Learning rate: 9.983711913555091e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 8.4711	Cost: 24.23s
Train Epoch: 258 [20480/90000 (23%)]	Loss: 8.1342	Cost: 11.84s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 8.2168	Cost: 6.91s
Train Epoch: 258 [61440/90000 (68%)]	Loss: 8.1082	Cost: 8.51s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 8.0576	Cost: 8.57s
Train Epoch: 258 	Average Loss: 8.1462
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4053

Learning rate: 9.983584980949367e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 8.3876	Cost: 22.68s
Train Epoch: 259 [20480/90000 (23%)]	Loss: 8.0458	Cost: 7.17s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 8.1195	Cost: 9.02s
Train Epoch: 259 [61440/90000 (68%)]	Loss: 8.2049	Cost: 8.88s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 8.1463	Cost: 8.73s
Train Epoch: 259 	Average Loss: 8.1561
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4335

Learning rate: 9.983457556483523e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 8.3698	Cost: 27.09s
Train Epoch: 260 [20480/90000 (23%)]	Loss: 8.1102	Cost: 9.44s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 8.1520	Cost: 9.63s
Train Epoch: 260 [61440/90000 (68%)]	Loss: 8.1255	Cost: 8.68s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 8.2617	Cost: 8.45s
Train Epoch: 260 	Average Loss: 8.1465
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3941

Learning rate: 9.983329640170136e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 8.2739	Cost: 22.96s
Train Epoch: 261 [20480/90000 (23%)]	Loss: 8.0615	Cost: 10.57s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 8.1134	Cost: 10.40s
Train Epoch: 261 [61440/90000 (68%)]	Loss: 8.1493	Cost: 8.89s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 8.0876	Cost: 8.61s
Train Epoch: 261 	Average Loss: 8.1128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4234

Learning rate: 9.983201232021833e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 8.4298	Cost: 22.30s
Train Epoch: 262 [20480/90000 (23%)]	Loss: 8.0085	Cost: 8.96s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 8.1066	Cost: 9.25s
Train Epoch: 262 [61440/90000 (68%)]	Loss: 8.0323	Cost: 9.05s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 8.0119	Cost: 8.82s
Train Epoch: 262 	Average Loss: 8.1169
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3847

Saving model as e262_model.pt & e262_waveforms_supplementary.hdf5
Learning rate: 9.983072332051286e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 8.4282	Cost: 20.64s
Train Epoch: 263 [20480/90000 (23%)]	Loss: 8.1739	Cost: 9.29s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 8.1633	Cost: 8.80s
Train Epoch: 263 [61440/90000 (68%)]	Loss: 8.1351	Cost: 7.97s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 8.0152	Cost: 6.98s
Train Epoch: 263 	Average Loss: 8.0872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3589

Saving model as e263_model.pt & e263_waveforms_supplementary.hdf5
Learning rate: 9.982942940271217e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 8.2977	Cost: 19.44s
Train Epoch: 264 [20480/90000 (23%)]	Loss: 7.9999	Cost: 7.97s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 8.1028	Cost: 13.59s
Train Epoch: 264 [61440/90000 (68%)]	Loss: 8.0683	Cost: 15.01s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 8.0811	Cost: 14.26s
Train Epoch: 264 	Average Loss: 8.0940
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3635

Learning rate: 9.982813056694397e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 8.3008	Cost: 26.18s
Train Epoch: 265 [20480/90000 (23%)]	Loss: 7.9851	Cost: 14.55s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 8.0197	Cost: 14.47s
Train Epoch: 265 [61440/90000 (68%)]	Loss: 8.0244	Cost: 12.10s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 8.1757	Cost: 11.93s
Train Epoch: 265 	Average Loss: 8.0963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3180

Saving model as e265_model.pt & e265_waveforms_supplementary.hdf5
Learning rate: 9.982682681333644e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 8.2427	Cost: 30.75s
Train Epoch: 266 [20480/90000 (23%)]	Loss: 8.0703	Cost: 11.69s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 7.8537	Cost: 12.30s
Train Epoch: 266 [61440/90000 (68%)]	Loss: 8.1023	Cost: 11.32s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 8.1200	Cost: 6.10s
Train Epoch: 266 	Average Loss: 8.0548
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2746

Saving model as e266_model.pt & e266_waveforms_supplementary.hdf5
Learning rate: 9.982551814201825e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 8.2447	Cost: 23.44s
Train Epoch: 267 [20480/90000 (23%)]	Loss: 7.9310	Cost: 6.67s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 8.0711	Cost: 9.79s
Train Epoch: 267 [61440/90000 (68%)]	Loss: 8.0190	Cost: 9.07s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 7.9532	Cost: 9.12s
Train Epoch: 267 	Average Loss: 8.0411
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3656

Learning rate: 9.982420455311858e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 8.3826	Cost: 25.78s
Train Epoch: 268 [20480/90000 (23%)]	Loss: 7.9247	Cost: 10.74s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 8.0963	Cost: 8.91s
Train Epoch: 268 [61440/90000 (68%)]	Loss: 8.0651	Cost: 8.58s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 7.9644	Cost: 7.54s
Train Epoch: 268 	Average Loss: 8.0491
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3548

Learning rate: 9.982288604676707e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 8.3546	Cost: 32.08s
Train Epoch: 269 [20480/90000 (23%)]	Loss: 7.9926	Cost: 6.73s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 7.9201	Cost: 10.35s
Train Epoch: 269 [61440/90000 (68%)]	Loss: 8.0486	Cost: 8.97s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 8.0374	Cost: 13.46s
Train Epoch: 269 	Average Loss: 8.0375
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3330

Learning rate: 9.982156262309383e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 8.3980	Cost: 23.26s
Train Epoch: 270 [20480/90000 (23%)]	Loss: 8.0273	Cost: 12.61s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 8.1508	Cost: 14.16s
Train Epoch: 270 [61440/90000 (68%)]	Loss: 7.8761	Cost: 12.62s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 7.9965	Cost: 12.46s
Train Epoch: 270 	Average Loss: 8.0339
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3253

Learning rate: 9.98202342822295e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 8.2239	Cost: 27.28s
Train Epoch: 271 [20480/90000 (23%)]	Loss: 8.0316	Cost: 12.60s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 8.0108	Cost: 13.01s
Train Epoch: 271 [61440/90000 (68%)]	Loss: 8.0968	Cost: 12.85s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 8.1350	Cost: 10.08s
Train Epoch: 271 	Average Loss: 8.0186
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2640

Saving model as e271_model.pt & e271_waveforms_supplementary.hdf5
Learning rate: 9.981890102430519e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 8.3001	Cost: 25.53s
Train Epoch: 272 [20480/90000 (23%)]	Loss: 7.8619	Cost: 10.49s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 8.0613	Cost: 9.30s
Train Epoch: 272 [61440/90000 (68%)]	Loss: 8.0532	Cost: 6.22s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 7.9380	Cost: 6.84s
Train Epoch: 272 	Average Loss: 8.0031
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2900

Learning rate: 9.981756284945245e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 8.4054	Cost: 28.22s
Train Epoch: 273 [20480/90000 (23%)]	Loss: 8.0722	Cost: 12.95s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 7.9324	Cost: 8.29s
Train Epoch: 273 [61440/90000 (68%)]	Loss: 7.9619	Cost: 6.39s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 7.9981	Cost: 8.42s
Train Epoch: 273 	Average Loss: 7.9858
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2558

Saving model as e273_model.pt & e273_waveforms_supplementary.hdf5
Learning rate: 9.98162197578034e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 8.4237	Cost: 21.37s
Train Epoch: 274 [20480/90000 (23%)]	Loss: 7.9278	Cost: 10.32s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 8.0483	Cost: 11.41s
Train Epoch: 274 [61440/90000 (68%)]	Loss: 7.8621	Cost: 9.21s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 7.9775	Cost: 8.65s
Train Epoch: 274 	Average Loss: 7.9905
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3065

Learning rate: 9.981487174949054e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 8.1654	Cost: 23.73s
Train Epoch: 275 [20480/90000 (23%)]	Loss: 7.8371	Cost: 8.49s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 8.1339	Cost: 9.16s
Train Epoch: 275 [61440/90000 (68%)]	Loss: 7.9834	Cost: 9.02s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 8.0305	Cost: 8.82s
Train Epoch: 275 	Average Loss: 7.9804
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2768

Learning rate: 9.981351882464696e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 8.1980	Cost: 21.26s
Train Epoch: 276 [20480/90000 (23%)]	Loss: 7.9447	Cost: 9.04s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 7.8873	Cost: 8.26s
Train Epoch: 276 [61440/90000 (68%)]	Loss: 8.2186	Cost: 6.99s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 7.9988	Cost: 8.57s
Train Epoch: 276 	Average Loss: 7.9817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2705

Learning rate: 9.981216098340617e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 8.3174	Cost: 21.71s
Train Epoch: 277 [20480/90000 (23%)]	Loss: 7.9726	Cost: 6.73s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 8.0148	Cost: 14.93s
Train Epoch: 277 [61440/90000 (68%)]	Loss: 7.9497	Cost: 13.16s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 7.9167	Cost: 12.53s
Train Epoch: 277 	Average Loss: 7.9909
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2923

Learning rate: 9.981079822590219e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 8.3001	Cost: 24.16s
Train Epoch: 278 [20480/90000 (23%)]	Loss: 7.8762	Cost: 14.47s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 7.8258	Cost: 14.57s
Train Epoch: 278 [61440/90000 (68%)]	Loss: 7.9393	Cost: 12.22s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 7.8135	Cost: 12.09s
Train Epoch: 278 	Average Loss: 7.9710
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2466

Saving model as e278_model.pt & e278_waveforms_supplementary.hdf5
Learning rate: 9.980943055226952e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 8.3627	Cost: 28.33s
Train Epoch: 279 [20480/90000 (23%)]	Loss: 7.9841	Cost: 10.41s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 7.9088	Cost: 12.36s
Train Epoch: 279 [61440/90000 (68%)]	Loss: 7.8598	Cost: 12.05s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 7.9202	Cost: 6.78s
Train Epoch: 279 	Average Loss: 7.9554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2718

Learning rate: 9.980805796264313e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 8.1071	Cost: 37.47s
Train Epoch: 280 [20480/90000 (23%)]	Loss: 7.8036	Cost: 12.30s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 7.9297	Cost: 6.49s
Train Epoch: 280 [61440/90000 (68%)]	Loss: 7.8928	Cost: 6.27s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 7.7873	Cost: 8.10s
Train Epoch: 280 	Average Loss: 7.9467
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2349

Saving model as e280_model.pt & e280_waveforms_supplementary.hdf5
Learning rate: 9.98066804571585e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 8.2305	Cost: 23.89s
Train Epoch: 281 [20480/90000 (23%)]	Loss: 7.7724	Cost: 9.54s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 7.8890	Cost: 11.19s
Train Epoch: 281 [61440/90000 (68%)]	Loss: 7.9517	Cost: 9.01s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 7.8802	Cost: 8.66s
Train Epoch: 281 	Average Loss: 7.9208
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2912

Learning rate: 9.980529803595159e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 8.2339	Cost: 29.93s
Train Epoch: 282 [20480/90000 (23%)]	Loss: 7.8650	Cost: 8.94s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 7.9346	Cost: 7.64s
Train Epoch: 282 [61440/90000 (68%)]	Loss: 7.9359	Cost: 6.70s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 8.0220	Cost: 6.59s
Train Epoch: 282 	Average Loss: 7.9168
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1870

Saving model as e282_model.pt & e282_waveforms_supplementary.hdf5
Learning rate: 9.980391069915883e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 8.1182	Cost: 20.10s
Train Epoch: 283 [20480/90000 (23%)]	Loss: 7.9663	Cost: 8.02s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 7.8841	Cost: 9.47s
Train Epoch: 283 [61440/90000 (68%)]	Loss: 7.9154	Cost: 12.28s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 7.8582	Cost: 12.20s
Train Epoch: 283 	Average Loss: 7.9059
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2245

Learning rate: 9.980251844691714e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 8.1859	Cost: 23.61s
Train Epoch: 284 [20480/90000 (23%)]	Loss: 7.8842	Cost: 11.47s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 7.7212	Cost: 12.52s
Train Epoch: 284 [61440/90000 (68%)]	Loss: 7.7855	Cost: 12.35s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 7.8717	Cost: 12.66s
Train Epoch: 284 	Average Loss: 7.9038
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1960

Learning rate: 9.980112127936395e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 8.1773	Cost: 30.15s
Train Epoch: 285 [20480/90000 (23%)]	Loss: 7.8458	Cost: 13.28s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 7.8346	Cost: 13.18s
Train Epoch: 285 [61440/90000 (68%)]	Loss: 7.9967	Cost: 12.20s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 7.8841	Cost: 7.67s
Train Epoch: 285 	Average Loss: 7.8600
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2052

Learning rate: 9.979971919663715e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 8.3696	Cost: 32.96s
Train Epoch: 286 [20480/90000 (23%)]	Loss: 7.7703	Cost: 13.44s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 7.9190	Cost: 10.15s
Train Epoch: 286 [61440/90000 (68%)]	Loss: 7.8213	Cost: 6.43s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 7.8465	Cost: 7.36s
Train Epoch: 286 	Average Loss: 7.8969
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1487

Saving model as e286_model.pt & e286_waveforms_supplementary.hdf5
Learning rate: 9.97983121988751e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 8.1190	Cost: 27.20s
Train Epoch: 287 [20480/90000 (23%)]	Loss: 7.8454	Cost: 9.20s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 7.7687	Cost: 8.50s
Train Epoch: 287 [61440/90000 (68%)]	Loss: 7.7406	Cost: 7.59s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 7.8150	Cost: 8.72s
Train Epoch: 287 	Average Loss: 7.8579
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1804

Learning rate: 9.97969002862167e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 8.2121	Cost: 24.63s
Train Epoch: 288 [20480/90000 (23%)]	Loss: 7.8480	Cost: 7.88s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 7.8310	Cost: 13.71s
Train Epoch: 288 [61440/90000 (68%)]	Loss: 7.9021	Cost: 9.88s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 7.9092	Cost: 8.96s
Train Epoch: 288 	Average Loss: 7.8741
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1883

Learning rate: 9.979548345880126e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 8.2139	Cost: 21.27s
Train Epoch: 289 [20480/90000 (23%)]	Loss: 7.6754	Cost: 9.12s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 7.8753	Cost: 9.15s
Train Epoch: 289 [61440/90000 (68%)]	Loss: 7.7753	Cost: 8.48s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 7.9073	Cost: 6.63s
Train Epoch: 289 	Average Loss: 7.8431
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1421

Saving model as e289_model.pt & e289_waveforms_supplementary.hdf5
Learning rate: 9.979406171676863e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 8.2154	Cost: 19.55s
Train Epoch: 290 [20480/90000 (23%)]	Loss: 7.8530	Cost: 7.83s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 7.8436	Cost: 9.25s
Train Epoch: 290 [61440/90000 (68%)]	Loss: 7.7123	Cost: 13.34s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 7.8931	Cost: 12.94s
Train Epoch: 290 	Average Loss: 7.8294
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1628

Learning rate: 9.979263506025915e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 8.0289	Cost: 24.83s
Train Epoch: 291 [20480/90000 (23%)]	Loss: 7.7380	Cost: 11.30s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 7.7771	Cost: 14.79s
Train Epoch: 291 [61440/90000 (68%)]	Loss: 7.7707	Cost: 13.12s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 7.7341	Cost: 12.13s
Train Epoch: 291 	Average Loss: 7.8385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1612

Learning rate: 9.97912034894136e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 8.1256	Cost: 34.01s
Train Epoch: 292 [20480/90000 (23%)]	Loss: 7.7665	Cost: 14.88s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 7.7208	Cost: 13.58s
Train Epoch: 292 [61440/90000 (68%)]	Loss: 7.7561	Cost: 12.25s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 7.7829	Cost: 12.19s
Train Epoch: 292 	Average Loss: 7.8265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1956

Learning rate: 9.978976700437328e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 8.1437	Cost: 28.15s
Train Epoch: 293 [20480/90000 (23%)]	Loss: 7.7140	Cost: 13.50s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 7.9036	Cost: 12.52s
Train Epoch: 293 [61440/90000 (68%)]	Loss: 7.8351	Cost: 9.51s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 7.7915	Cost: 8.30s
Train Epoch: 293 	Average Loss: 7.8128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1577

Learning rate: 9.978832560527998e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 8.0736	Cost: 22.95s
Train Epoch: 294 [20480/90000 (23%)]	Loss: 7.7169	Cost: 6.77s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 7.7915	Cost: 8.24s
Train Epoch: 294 [61440/90000 (68%)]	Loss: 7.6285	Cost: 9.12s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 7.7895	Cost: 8.94s
Train Epoch: 294 	Average Loss: 7.7882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2077

Learning rate: 9.978687929227592e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 8.0547	Cost: 22.45s
Train Epoch: 295 [20480/90000 (23%)]	Loss: 7.7745	Cost: 9.67s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 7.7373	Cost: 8.89s
Train Epoch: 295 [61440/90000 (68%)]	Loss: 7.8096	Cost: 6.99s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 7.7802	Cost: 5.96s
Train Epoch: 295 	Average Loss: 7.7814
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0996

Saving model as e295_model.pt & e295_waveforms_supplementary.hdf5
Learning rate: 9.978542806550388e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 7.9454	Cost: 22.48s
Train Epoch: 296 [20480/90000 (23%)]	Loss: 7.7692	Cost: 6.81s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 7.6676	Cost: 8.83s
Train Epoch: 296 [61440/90000 (68%)]	Loss: 7.7820	Cost: 9.87s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 7.6979	Cost: 12.59s
Train Epoch: 296 	Average Loss: 7.7628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0604

Saving model as e296_model.pt & e296_waveforms_supplementary.hdf5
Learning rate: 9.978397192510708e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 8.0811	Cost: 30.69s
Train Epoch: 297 [20480/90000 (23%)]	Loss: 7.6984	Cost: 12.54s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 7.7902	Cost: 12.58s
Train Epoch: 297 [61440/90000 (68%)]	Loss: 7.7076	Cost: 12.26s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 7.8369	Cost: 12.52s
Train Epoch: 297 	Average Loss: 7.7748
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0951

Learning rate: 9.978251087122923e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 8.0121	Cost: 41.43s
Train Epoch: 298 [20480/90000 (23%)]	Loss: 7.5534	Cost: 12.92s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 7.6578	Cost: 12.59s
Train Epoch: 298 [61440/90000 (68%)]	Loss: 7.6933	Cost: 9.48s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 7.7737	Cost: 6.05s
Train Epoch: 298 	Average Loss: 7.7353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0933

Learning rate: 9.978104490401455e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 8.0382	Cost: 27.78s
Train Epoch: 299 [20480/90000 (23%)]	Loss: 7.7247	Cost: 14.70s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 7.6004	Cost: 12.17s
Train Epoch: 299 [61440/90000 (68%)]	Loss: 7.6858	Cost: 6.83s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 7.7816	Cost: 7.30s
Train Epoch: 299 	Average Loss: 7.7311
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0910

Learning rate: 9.977957402360771e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 8.1925	Cost: 23.67s
Train Epoch: 300 [20480/90000 (23%)]	Loss: 7.6363	Cost: 8.75s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 7.6617	Cost: 7.85s
Train Epoch: 300 [61440/90000 (68%)]	Loss: 7.8020	Cost: 8.57s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 7.7165	Cost: 8.41s
Train Epoch: 300 	Average Loss: 7.7395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0662

Learning rate: 9.977809823015388e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 8.0590	Cost: 23.37s
Train Epoch: 301 [20480/90000 (23%)]	Loss: 7.5664	Cost: 8.53s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 7.7138	Cost: 9.45s
Train Epoch: 301 [61440/90000 (68%)]	Loss: 7.7887	Cost: 8.71s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 7.6848	Cost: 8.38s
Train Epoch: 301 	Average Loss: 7.7179
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0657

Learning rate: 9.97766175237987e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 8.0190	Cost: 33.50s
Train Epoch: 302 [20480/90000 (23%)]	Loss: 7.6874	Cost: 8.98s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 7.7524	Cost: 8.96s
Train Epoch: 302 [61440/90000 (68%)]	Loss: 7.8080	Cost: 6.27s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 7.7057	Cost: 6.05s
Train Epoch: 302 	Average Loss: 7.7251
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0776

Learning rate: 9.977513190468834e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 8.1555	Cost: 20.30s
Train Epoch: 303 [20480/90000 (23%)]	Loss: 7.5791	Cost: 9.35s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 7.7348	Cost: 10.83s
Train Epoch: 303 [61440/90000 (68%)]	Loss: 7.6600	Cost: 9.59s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 7.6618	Cost: 15.83s
Train Epoch: 303 	Average Loss: 7.7264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0367

Saving model as e303_model.pt & e303_waveforms_supplementary.hdf5
Learning rate: 9.977364137296942e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 8.0025	Cost: 26.59s
Train Epoch: 304 [20480/90000 (23%)]	Loss: 7.6292	Cost: 11.39s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 7.7443	Cost: 13.86s
Train Epoch: 304 [61440/90000 (68%)]	Loss: 7.6907	Cost: 12.70s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 7.6490	Cost: 12.32s
Train Epoch: 304 	Average Loss: 7.7278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0708

Learning rate: 9.977214592878902e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 8.1258	Cost: 30.19s
Train Epoch: 305 [20480/90000 (23%)]	Loss: 7.6867	Cost: 15.35s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 7.6329	Cost: 12.92s
Train Epoch: 305 [61440/90000 (68%)]	Loss: 7.6227	Cost: 12.18s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 7.5830	Cost: 7.68s
Train Epoch: 305 	Average Loss: 7.6758
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0450

Learning rate: 9.977064557229477e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 7.9882	Cost: 30.96s
Train Epoch: 306 [20480/90000 (23%)]	Loss: 7.5683	Cost: 9.04s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 7.7610	Cost: 6.36s
Train Epoch: 306 [61440/90000 (68%)]	Loss: 7.7048	Cost: 6.75s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 7.7075	Cost: 8.41s
Train Epoch: 306 	Average Loss: 7.6933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0814

Learning rate: 9.976914030363472e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 8.1817	Cost: 21.94s
Train Epoch: 307 [20480/90000 (23%)]	Loss: 7.6611	Cost: 8.34s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 7.8960	Cost: 9.18s
Train Epoch: 307 [61440/90000 (68%)]	Loss: 7.6558	Cost: 8.65s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 7.6387	Cost: 8.85s
Train Epoch: 307 	Average Loss: 7.6817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9867

Saving model as e307_model.pt & e307_waveforms_supplementary.hdf5
Learning rate: 9.976763012295747e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 8.0921	Cost: 21.62s
Train Epoch: 308 [20480/90000 (23%)]	Loss: 7.5478	Cost: 11.33s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 7.6063	Cost: 10.18s
Train Epoch: 308 [61440/90000 (68%)]	Loss: 7.6952	Cost: 6.47s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 7.7114	Cost: 6.71s
Train Epoch: 308 	Average Loss: 7.6858
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0055

Learning rate: 9.976611503041203e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 8.0434	Cost: 24.71s
Train Epoch: 309 [20480/90000 (23%)]	Loss: 7.6521	Cost: 9.78s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 7.6377	Cost: 17.91s
Train Epoch: 309 [61440/90000 (68%)]	Loss: 7.5445	Cost: 12.75s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 7.6622	Cost: 12.41s
Train Epoch: 309 	Average Loss: 7.6600
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9903

Learning rate: 9.976459502614796e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 8.0837	Cost: 26.94s
Train Epoch: 310 [20480/90000 (23%)]	Loss: 7.7307	Cost: 11.82s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 7.6471	Cost: 12.79s
Train Epoch: 310 [61440/90000 (68%)]	Loss: 7.6453	Cost: 12.55s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 7.6090	Cost: 12.45s
Train Epoch: 310 	Average Loss: 7.6680
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0974

Learning rate: 9.976307011031527e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 7.9494	Cost: 27.28s
Train Epoch: 311 [20480/90000 (23%)]	Loss: 7.4849	Cost: 9.46s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 7.7192	Cost: 12.47s
Train Epoch: 311 [61440/90000 (68%)]	Loss: 7.6634	Cost: 12.42s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 7.7833	Cost: 9.68s
Train Epoch: 311 	Average Loss: 7.6328
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9744

Saving model as e311_model.pt & e311_waveforms_supplementary.hdf5
Learning rate: 9.976154028306446e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 8.1907	Cost: 23.04s
Train Epoch: 312 [20480/90000 (23%)]	Loss: 7.4572	Cost: 12.59s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 7.6351	Cost: 7.82s
Train Epoch: 312 [61440/90000 (68%)]	Loss: 7.6747	Cost: 6.39s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 7.5790	Cost: 8.36s
Train Epoch: 312 	Average Loss: 7.6204
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9944

Learning rate: 9.976000554454652e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 8.0743	Cost: 28.72s
Train Epoch: 313 [20480/90000 (23%)]	Loss: 7.4936	Cost: 11.04s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 7.4753	Cost: 9.27s
Train Epoch: 313 [61440/90000 (68%)]	Loss: 7.6602	Cost: 7.12s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 7.6315	Cost: 8.80s
Train Epoch: 313 	Average Loss: 7.6453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9647

Saving model as e313_model.pt & e313_waveforms_supplementary.hdf5
Learning rate: 9.975846589491293e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 7.8638	Cost: 19.63s
Train Epoch: 314 [20480/90000 (23%)]	Loss: 7.5513	Cost: 9.78s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 7.6491	Cost: 12.22s
Train Epoch: 314 [61440/90000 (68%)]	Loss: 7.5417	Cost: 9.56s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 7.5658	Cost: 8.82s
Train Epoch: 314 	Average Loss: 7.6116
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0315

Learning rate: 9.975692133431563e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 8.0162	Cost: 33.19s
Train Epoch: 315 [20480/90000 (23%)]	Loss: 7.6806	Cost: 8.86s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 7.5682	Cost: 8.85s
Train Epoch: 315 [61440/90000 (68%)]	Loss: 7.5846	Cost: 8.55s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 7.5643	Cost: 6.95s
Train Epoch: 315 	Average Loss: 7.6475
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9832

Learning rate: 9.975537186290708e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 7.9541	Cost: 19.82s
Train Epoch: 316 [20480/90000 (23%)]	Loss: 7.4844	Cost: 8.89s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 7.6161	Cost: 6.11s
Train Epoch: 316 [61440/90000 (68%)]	Loss: 7.5497	Cost: 6.87s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 7.6631	Cost: 9.57s
Train Epoch: 316 	Average Loss: 7.6005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9489

Saving model as e316_model.pt & e316_waveforms_supplementary.hdf5
Learning rate: 9.975381748084019e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 7.9270	Cost: 25.23s
Train Epoch: 317 [20480/90000 (23%)]	Loss: 7.3827	Cost: 8.23s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 7.5134	Cost: 11.86s
Train Epoch: 317 [61440/90000 (68%)]	Loss: 7.6654	Cost: 12.38s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 7.4244	Cost: 12.75s
Train Epoch: 317 	Average Loss: 7.5860
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9751

Learning rate: 9.975225818826839e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 8.1630	Cost: 35.06s
Train Epoch: 318 [20480/90000 (23%)]	Loss: 7.5030	Cost: 14.87s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 7.6062	Cost: 14.01s
Train Epoch: 318 [61440/90000 (68%)]	Loss: 7.4711	Cost: 12.07s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 7.5964	Cost: 12.47s
Train Epoch: 318 	Average Loss: 7.5742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9899

Learning rate: 9.975069398534559e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 7.9468	Cost: 42.98s
Train Epoch: 319 [20480/90000 (23%)]	Loss: 7.3930	Cost: 12.80s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 7.4770	Cost: 12.45s
Train Epoch: 319 [61440/90000 (68%)]	Loss: 7.5845	Cost: 8.28s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 7.5745	Cost: 6.08s
Train Epoch: 319 	Average Loss: 7.5527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9440

Saving model as e319_model.pt & e319_waveforms_supplementary.hdf5
Learning rate: 9.974912487222611e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 7.9774	Cost: 25.26s
Train Epoch: 320 [20480/90000 (23%)]	Loss: 7.4108	Cost: 11.98s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 7.6757	Cost: 7.92s
Train Epoch: 320 [61440/90000 (68%)]	Loss: 7.5013	Cost: 6.27s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 7.7283	Cost: 7.50s
Train Epoch: 320 	Average Loss: 7.5806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9870

Learning rate: 9.974755084906488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 7.9603	Cost: 20.02s
Train Epoch: 321 [20480/90000 (23%)]	Loss: 7.5114	Cost: 6.65s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 7.6190	Cost: 9.40s
Train Epoch: 321 [61440/90000 (68%)]	Loss: 7.4434	Cost: 8.69s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 7.5759	Cost: 8.40s
Train Epoch: 321 	Average Loss: 7.5310
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0011

Learning rate: 9.974597191601719e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 7.9773	Cost: 21.26s
Train Epoch: 322 [20480/90000 (23%)]	Loss: 7.4472	Cost: 7.72s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 7.4944	Cost: 8.91s
Train Epoch: 322 [61440/90000 (68%)]	Loss: 7.5321	Cost: 8.73s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 7.5759	Cost: 9.05s
Train Epoch: 322 	Average Loss: 7.5279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9721

Learning rate: 9.974438807323893e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 7.9698	Cost: 27.56s
Train Epoch: 323 [20480/90000 (23%)]	Loss: 7.3848	Cost: 10.07s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 7.4630	Cost: 9.29s
Train Epoch: 323 [61440/90000 (68%)]	Loss: 7.4874	Cost: 6.06s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 7.5804	Cost: 6.32s
Train Epoch: 323 	Average Loss: 7.5119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9843

Learning rate: 9.97427993208864e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 7.9024	Cost: 23.70s
Train Epoch: 324 [20480/90000 (23%)]	Loss: 7.4401	Cost: 10.00s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 7.5544	Cost: 11.61s
Train Epoch: 324 [61440/90000 (68%)]	Loss: 7.4625	Cost: 11.84s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 7.4125	Cost: 12.52s
Train Epoch: 324 	Average Loss: 7.5210
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9631

Learning rate: 9.97412056591164e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 8.0509	Cost: 26.24s
Train Epoch: 325 [20480/90000 (23%)]	Loss: 7.3597	Cost: 10.69s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 7.5544	Cost: 13.60s
Train Epoch: 325 [61440/90000 (68%)]	Loss: 7.5129	Cost: 12.37s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 7.4969	Cost: 12.39s
Train Epoch: 325 	Average Loss: 7.5085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9460

Learning rate: 9.973960708808621e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 7.9335	Cost: 29.55s
Train Epoch: 326 [20480/90000 (23%)]	Loss: 7.4240	Cost: 11.65s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 7.5640	Cost: 12.42s
Train Epoch: 326 [61440/90000 (68%)]	Loss: 7.4329	Cost: 12.00s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 7.6098	Cost: 8.44s
Train Epoch: 326 	Average Loss: 7.5101
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9189

Saving model as e326_model.pt & e326_waveforms_supplementary.hdf5
Learning rate: 9.97380036079536e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 7.9843	Cost: 24.94s
Train Epoch: 327 [20480/90000 (23%)]	Loss: 7.4033	Cost: 12.02s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 7.3551	Cost: 8.71s
Train Epoch: 327 [61440/90000 (68%)]	Loss: 7.3216	Cost: 6.29s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 7.5181	Cost: 7.62s
Train Epoch: 327 	Average Loss: 7.4696
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9134

Saving model as e327_model.pt & e327_waveforms_supplementary.hdf5
Learning rate: 9.973639521887684e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 7.8418	Cost: 27.07s
Train Epoch: 328 [20480/90000 (23%)]	Loss: 7.3901	Cost: 10.72s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 7.5825	Cost: 10.36s
Train Epoch: 328 [61440/90000 (68%)]	Loss: 7.3887	Cost: 9.15s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 7.5212	Cost: 8.74s
Train Epoch: 328 	Average Loss: 7.4628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0317

Learning rate: 9.973478192101466e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 7.9683	Cost: 21.50s
Train Epoch: 329 [20480/90000 (23%)]	Loss: 7.4628	Cost: 11.55s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 7.3925	Cost: 10.06s
Train Epoch: 329 [61440/90000 (68%)]	Loss: 7.4229	Cost: 9.03s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 7.4367	Cost: 8.85s
Train Epoch: 329 	Average Loss: 7.4776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8937

Saving model as e329_model.pt & e329_waveforms_supplementary.hdf5
Learning rate: 9.973316371452633e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 7.7897	Cost: 21.70s
Train Epoch: 330 [20480/90000 (23%)]	Loss: 7.3611	Cost: 8.50s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 7.4201	Cost: 9.13s
Train Epoch: 330 [61440/90000 (68%)]	Loss: 7.5296	Cost: 8.66s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 7.4867	Cost: 8.40s
Train Epoch: 330 	Average Loss: 7.4491
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8606

Saving model as e330_model.pt & e330_waveforms_supplementary.hdf5
Learning rate: 9.97315405995715e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 7.7357	Cost: 25.41s
Train Epoch: 331 [20480/90000 (23%)]	Loss: 7.3272	Cost: 8.76s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 7.4480	Cost: 8.89s
Train Epoch: 331 [61440/90000 (68%)]	Loss: 7.3544	Cost: 8.64s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 7.3893	Cost: 8.52s
Train Epoch: 331 	Average Loss: 7.4236
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7991

Saving model as e331_model.pt & e331_waveforms_supplementary.hdf5
Learning rate: 9.97299125763104e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 7.6903	Cost: 44.37s
Train Epoch: 332 [20480/90000 (23%)]	Loss: 7.3045	Cost: 12.88s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 7.4506	Cost: 13.32s
Train Epoch: 332 [61440/90000 (68%)]	Loss: 7.4612	Cost: 9.70s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 7.3450	Cost: 13.69s
Train Epoch: 332 	Average Loss: 7.4075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8420

Learning rate: 9.972827964490369e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 7.7299	Cost: 20.95s
Train Epoch: 333 [20480/90000 (23%)]	Loss: 7.3392	Cost: 7.36s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 7.3036	Cost: 12.70s
Train Epoch: 333 [61440/90000 (68%)]	Loss: 7.3594	Cost: 12.48s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 7.4762	Cost: 16.69s
Train Epoch: 333 	Average Loss: 7.4102
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8346

Learning rate: 9.972664180551254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 7.7175	Cost: 22.65s
Train Epoch: 334 [20480/90000 (23%)]	Loss: 7.3312	Cost: 12.89s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 7.4599	Cost: 14.53s
Train Epoch: 334 [61440/90000 (68%)]	Loss: 7.4437	Cost: 13.06s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 7.3793	Cost: 12.45s
Train Epoch: 334 	Average Loss: 7.4100
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8759

Learning rate: 9.972499905829862e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 7.7344	Cost: 25.56s
Train Epoch: 335 [20480/90000 (23%)]	Loss: 7.2657	Cost: 14.54s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 7.3506	Cost: 12.92s
Train Epoch: 335 [61440/90000 (68%)]	Loss: 7.4305	Cost: 12.11s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 7.3618	Cost: 7.75s
Train Epoch: 335 	Average Loss: 7.4042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8969

Learning rate: 9.972335140342403e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 7.8337	Cost: 38.13s
Train Epoch: 336 [20480/90000 (23%)]	Loss: 7.3302	Cost: 11.94s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 7.3480	Cost: 6.72s
Train Epoch: 336 [61440/90000 (68%)]	Loss: 7.3706	Cost: 6.28s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 7.3380	Cost: 7.82s
Train Epoch: 336 	Average Loss: 7.3685
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8664

Learning rate: 9.972169884105142e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 7.7051	Cost: 29.72s
Train Epoch: 337 [20480/90000 (23%)]	Loss: 7.2072	Cost: 6.43s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 7.3677	Cost: 10.96s
Train Epoch: 337 [61440/90000 (68%)]	Loss: 7.3040	Cost: 8.58s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 7.3915	Cost: 8.43s
Train Epoch: 337 	Average Loss: 7.3584
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8034

Learning rate: 9.972004137134385e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 7.7411	Cost: 24.20s
Train Epoch: 338 [20480/90000 (23%)]	Loss: 7.2537	Cost: 7.92s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 7.4396	Cost: 8.95s
Train Epoch: 338 [61440/90000 (68%)]	Loss: 7.3904	Cost: 9.11s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 7.3230	Cost: 8.86s
Train Epoch: 338 	Average Loss: 7.3554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8612

Learning rate: 9.971837899446494e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 7.9550	Cost: 24.10s
Train Epoch: 339 [20480/90000 (23%)]	Loss: 7.1670	Cost: 8.59s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 7.3578	Cost: 11.44s
Train Epoch: 339 [61440/90000 (68%)]	Loss: 7.5310	Cost: 9.50s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 7.3653	Cost: 13.48s
Train Epoch: 339 	Average Loss: 7.4072
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8497

Learning rate: 9.971671171057876e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 7.7820	Cost: 26.35s
Train Epoch: 340 [20480/90000 (23%)]	Loss: 7.3088	Cost: 10.80s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 7.5175	Cost: 15.12s
Train Epoch: 340 [61440/90000 (68%)]	Loss: 7.3280	Cost: 12.33s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 7.3577	Cost: 12.28s
Train Epoch: 340 	Average Loss: 7.4187
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8756

Learning rate: 9.971503951984984e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 7.7470	Cost: 29.26s
Train Epoch: 341 [20480/90000 (23%)]	Loss: 7.3601	Cost: 11.63s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 7.2925	Cost: 12.44s
Train Epoch: 341 [61440/90000 (68%)]	Loss: 7.3016	Cost: 12.19s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 7.3848	Cost: 8.56s
Train Epoch: 341 	Average Loss: 7.3427
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8839

Learning rate: 9.971336242244322e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 7.7250	Cost: 24.56s
Train Epoch: 342 [20480/90000 (23%)]	Loss: 7.3325	Cost: 10.44s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 7.1589	Cost: 9.98s
Train Epoch: 342 [61440/90000 (68%)]	Loss: 7.3398	Cost: 6.17s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 7.4690	Cost: 6.53s
Train Epoch: 342 	Average Loss: 7.3301
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7753

Saving model as e342_model.pt & e342_waveforms_supplementary.hdf5
Learning rate: 9.971168041852446e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 7.8222	Cost: 25.77s
Train Epoch: 343 [20480/90000 (23%)]	Loss: 7.1639	Cost: 11.10s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 7.3649	Cost: 9.51s
Train Epoch: 343 [61440/90000 (68%)]	Loss: 7.2472	Cost: 7.05s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 7.3456	Cost: 9.17s
Train Epoch: 343 	Average Loss: 7.3115
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8436

Learning rate: 9.970999350825954e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 7.8353	Cost: 19.32s
Train Epoch: 344 [20480/90000 (23%)]	Loss: 7.2395	Cost: 7.87s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 7.2383	Cost: 12.93s
Train Epoch: 344 [61440/90000 (68%)]	Loss: 7.1868	Cost: 9.12s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 7.3906	Cost: 8.86s
Train Epoch: 344 	Average Loss: 7.3047
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7494

Saving model as e344_model.pt & e344_waveforms_supplementary.hdf5
Learning rate: 9.970830169181494e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 7.6314	Cost: 23.72s
Train Epoch: 345 [20480/90000 (23%)]	Loss: 7.2297	Cost: 6.64s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 7.2510	Cost: 9.25s
Train Epoch: 345 [61440/90000 (68%)]	Loss: 7.2667	Cost: 10.63s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 7.1859	Cost: 12.73s
Train Epoch: 345 	Average Loss: 7.2905
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7631

Learning rate: 9.970660496935765e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 7.6965	Cost: 22.89s
Train Epoch: 346 [20480/90000 (23%)]	Loss: 7.2209	Cost: 10.02s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 7.2680	Cost: 13.24s
Train Epoch: 346 [61440/90000 (68%)]	Loss: 7.2628	Cost: 12.27s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 7.2513	Cost: 12.31s
Train Epoch: 346 	Average Loss: 7.2649
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7488

Saving model as e346_model.pt & e346_waveforms_supplementary.hdf5
Learning rate: 9.970490334105514e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 7.7927	Cost: 25.25s
Train Epoch: 347 [20480/90000 (23%)]	Loss: 7.1974	Cost: 13.70s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 7.2383	Cost: 14.04s
Train Epoch: 347 [61440/90000 (68%)]	Loss: 7.2900	Cost: 12.34s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 7.1746	Cost: 10.08s
Train Epoch: 347 	Average Loss: 7.2705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7843

Learning rate: 9.970319680707532e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 7.6714	Cost: 40.39s
Train Epoch: 348 [20480/90000 (23%)]	Loss: 7.1224	Cost: 13.26s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 7.3280	Cost: 12.26s
Train Epoch: 348 [61440/90000 (68%)]	Loss: 7.2534	Cost: 8.23s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 7.2567	Cost: 6.03s
Train Epoch: 348 	Average Loss: 7.2488
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7427

Saving model as e348_model.pt & e348_waveforms_supplementary.hdf5
Learning rate: 9.970148536758666e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 7.7230	Cost: 35.61s
Train Epoch: 349 [20480/90000 (23%)]	Loss: 7.0871	Cost: 8.15s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 7.1682	Cost: 6.55s
Train Epoch: 349 [61440/90000 (68%)]	Loss: 7.2458	Cost: 7.08s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 7.1074	Cost: 9.03s
Train Epoch: 349 	Average Loss: 7.2337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6862

Saving model as e349_model.pt & e349_waveforms_supplementary.hdf5
Learning rate: 9.969976902275804e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 7.7003	Cost: 19.80s
Train Epoch: 350 [20480/90000 (23%)]	Loss: 7.2044	Cost: 7.20s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 7.2900	Cost: 9.57s
Train Epoch: 350 [61440/90000 (68%)]	Loss: 7.1447	Cost: 8.73s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 7.1821	Cost: 9.15s
Train Epoch: 350 	Average Loss: 7.2278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6805

Saving model as e350_model.pt & e350_waveforms_supplementary.hdf5
Learning rate: 9.969804777275889e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 7.7044	Cost: 21.93s
Train Epoch: 351 [20480/90000 (23%)]	Loss: 7.2156	Cost: 9.12s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 7.2586	Cost: 8.97s
Train Epoch: 351 [61440/90000 (68%)]	Loss: 7.2786	Cost: 8.92s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 7.2565	Cost: 7.84s
Train Epoch: 351 	Average Loss: 7.2293
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7887

Learning rate: 9.969632161775905e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 7.8599	Cost: 23.73s
Train Epoch: 352 [20480/90000 (23%)]	Loss: 7.1067	Cost: 9.03s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 7.2452	Cost: 9.68s
Train Epoch: 352 [61440/90000 (68%)]	Loss: 7.1581	Cost: 11.59s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 7.1935	Cost: 12.53s
Train Epoch: 352 	Average Loss: 7.2161
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6999

Learning rate: 9.969459055792892e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 7.6614	Cost: 27.34s
Train Epoch: 353 [20480/90000 (23%)]	Loss: 7.0253	Cost: 10.71s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 7.2059	Cost: 12.80s
Train Epoch: 353 [61440/90000 (68%)]	Loss: 7.1096	Cost: 12.25s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 7.0549	Cost: 12.08s
Train Epoch: 353 	Average Loss: 7.1902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6857

Learning rate: 9.969285459343932e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 7.7238	Cost: 27.53s
Train Epoch: 354 [20480/90000 (23%)]	Loss: 7.1485	Cost: 11.88s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 7.1610	Cost: 12.63s
Train Epoch: 354 [61440/90000 (68%)]	Loss: 7.1376	Cost: 12.37s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 7.0752	Cost: 8.48s
Train Epoch: 354 	Average Loss: 7.1691
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6336

Saving model as e354_model.pt & e354_waveforms_supplementary.hdf5
Learning rate: 9.96911137244616e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 7.6205	Cost: 38.15s
Train Epoch: 355 [20480/90000 (23%)]	Loss: 7.0497	Cost: 13.90s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 7.1437	Cost: 11.51s
Train Epoch: 355 [61440/90000 (68%)]	Loss: 7.1021	Cost: 6.09s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 7.1506	Cost: 7.10s
Train Epoch: 355 	Average Loss: 7.1751
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6995

Learning rate: 9.968936795116758e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 7.6934	Cost: 25.02s
Train Epoch: 356 [20480/90000 (23%)]	Loss: 6.9230	Cost: 11.19s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 7.0840	Cost: 10.28s
Train Epoch: 356 [61440/90000 (68%)]	Loss: 7.1022	Cost: 9.40s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 7.1205	Cost: 8.64s
Train Epoch: 356 	Average Loss: 7.1759
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6248

Saving model as e356_model.pt & e356_waveforms_supplementary.hdf5
Learning rate: 9.968761727372955e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 7.6701	Cost: 24.41s
Train Epoch: 357 [20480/90000 (23%)]	Loss: 7.0541	Cost: 9.67s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 7.1124	Cost: 8.96s
Train Epoch: 357 [61440/90000 (68%)]	Loss: 7.1539	Cost: 8.92s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 7.1539	Cost: 6.38s
Train Epoch: 357 	Average Loss: 7.1517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7356

Learning rate: 9.96858616923203e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 7.6154	Cost: 19.93s
Train Epoch: 358 [20480/90000 (23%)]	Loss: 7.1233	Cost: 6.45s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 7.0874	Cost: 12.99s
Train Epoch: 358 [61440/90000 (68%)]	Loss: 7.1679	Cost: 11.92s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 7.1306	Cost: 11.76s
Train Epoch: 358 	Average Loss: 7.1585
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6947

Learning rate: 9.96841012071131e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 7.5521	Cost: 21.64s
Train Epoch: 359 [20480/90000 (23%)]	Loss: 7.0124	Cost: 9.53s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 7.0998	Cost: 10.82s
Train Epoch: 359 [61440/90000 (68%)]	Loss: 7.0898	Cost: 12.68s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 6.9346	Cost: 12.27s
Train Epoch: 359 	Average Loss: 7.1017
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6484

Learning rate: 9.968233581828168e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 7.6110	Cost: 26.28s
Train Epoch: 360 [20480/90000 (23%)]	Loss: 6.9514	Cost: 14.60s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 7.0417	Cost: 13.58s
Train Epoch: 360 [61440/90000 (68%)]	Loss: 7.0909	Cost: 12.33s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 7.1581	Cost: 10.00s
Train Epoch: 360 	Average Loss: 7.1070
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6198

Saving model as e360_model.pt & e360_waveforms_supplementary.hdf5
Learning rate: 9.968056552600032e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 7.6309	Cost: 41.01s
Train Epoch: 361 [20480/90000 (23%)]	Loss: 6.9960	Cost: 8.27s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 7.2104	Cost: 11.43s
Train Epoch: 361 [61440/90000 (68%)]	Loss: 7.0549	Cost: 6.15s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 6.9789	Cost: 6.07s
Train Epoch: 361 	Average Loss: 7.1030
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6758

Learning rate: 9.967879033044371e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 7.5140	Cost: 27.46s
Train Epoch: 362 [20480/90000 (23%)]	Loss: 6.9055	Cost: 11.15s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 7.1944	Cost: 12.50s
Train Epoch: 362 [61440/90000 (68%)]	Loss: 7.1599	Cost: 6.36s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 7.1039	Cost: 6.15s
Train Epoch: 362 	Average Loss: 7.0964
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6718

Learning rate: 9.967701023178707e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 7.7903	Cost: 34.65s
Train Epoch: 363 [20480/90000 (23%)]	Loss: 7.0640	Cost: 10.19s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 7.0781	Cost: 6.67s
Train Epoch: 363 [61440/90000 (68%)]	Loss: 7.1473	Cost: 6.57s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 7.1372	Cost: 8.78s
Train Epoch: 363 	Average Loss: 7.0885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6802

Learning rate: 9.967522523020609e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 7.5620	Cost: 19.43s
Train Epoch: 364 [20480/90000 (23%)]	Loss: 7.0066	Cost: 7.16s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 7.0198	Cost: 9.53s
Train Epoch: 364 [61440/90000 (68%)]	Loss: 6.9939	Cost: 8.71s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 7.1469	Cost: 8.89s
Train Epoch: 364 	Average Loss: 7.0729
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6714

Learning rate: 9.967343532587693e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 7.6561	Cost: 22.63s
Train Epoch: 365 [20480/90000 (23%)]	Loss: 6.9812	Cost: 7.50s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 7.0112	Cost: 9.14s
Train Epoch: 365 [61440/90000 (68%)]	Loss: 7.0471	Cost: 9.01s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 7.0350	Cost: 9.09s
Train Epoch: 365 	Average Loss: 7.0585
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6225

Learning rate: 9.967164051897624e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 7.5228	Cost: 29.96s
Train Epoch: 366 [20480/90000 (23%)]	Loss: 6.9890	Cost: 9.36s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 7.1570	Cost: 7.15s
Train Epoch: 366 [61440/90000 (68%)]	Loss: 7.0520	Cost: 6.78s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 6.9322	Cost: 6.64s
Train Epoch: 366 	Average Loss: 7.0639
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5980

Saving model as e366_model.pt & e366_waveforms_supplementary.hdf5
Learning rate: 9.966984080968118e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 7.5369	Cost: 38.10s
Train Epoch: 367 [20480/90000 (23%)]	Loss: 6.8545	Cost: 11.75s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 7.1195	Cost: 13.42s
Train Epoch: 367 [61440/90000 (68%)]	Loss: 6.9918	Cost: 12.23s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 7.0029	Cost: 12.18s
Train Epoch: 367 	Average Loss: 7.0375
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6423

Learning rate: 9.966803619816938e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 7.5624	Cost: 28.31s
Train Epoch: 368 [20480/90000 (23%)]	Loss: 6.9387	Cost: 11.92s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 7.0491	Cost: 12.78s
Train Epoch: 368 [61440/90000 (68%)]	Loss: 7.0920	Cost: 12.57s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 6.9799	Cost: 8.50s
Train Epoch: 368 	Average Loss: 7.0087
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5027

Saving model as e368_model.pt & e368_waveforms_supplementary.hdf5
Learning rate: 9.966622668461892e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 7.4121	Cost: 25.46s
Train Epoch: 369 [20480/90000 (23%)]	Loss: 6.8719	Cost: 12.34s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 6.9655	Cost: 12.58s
Train Epoch: 369 [61440/90000 (68%)]	Loss: 6.8582	Cost: 8.79s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 6.8730	Cost: 6.94s
Train Epoch: 369 	Average Loss: 6.9873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6056

Learning rate: 9.96644122692084e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 7.6581	Cost: 22.35s
Train Epoch: 370 [20480/90000 (23%)]	Loss: 7.0595	Cost: 11.81s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 6.8954	Cost: 9.55s
Train Epoch: 370 [61440/90000 (68%)]	Loss: 6.8261	Cost: 6.48s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 6.8300	Cost: 7.18s
Train Epoch: 370 	Average Loss: 7.0180
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4845

Saving model as e370_model.pt & e370_waveforms_supplementary.hdf5
Learning rate: 9.966259295211689e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 7.4374	Cost: 31.19s
Train Epoch: 371 [20480/90000 (23%)]	Loss: 6.9985	Cost: 10.33s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 6.9506	Cost: 8.90s
Train Epoch: 371 [61440/90000 (68%)]	Loss: 6.9417	Cost: 7.46s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 6.8060	Cost: 8.59s
Train Epoch: 371 	Average Loss: 6.9759
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5968

Learning rate: 9.966076873352397e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 7.5785	Cost: 28.23s
Train Epoch: 372 [20480/90000 (23%)]	Loss: 7.0038	Cost: 8.79s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 6.9743	Cost: 9.12s
Train Epoch: 372 [61440/90000 (68%)]	Loss: 6.9368	Cost: 8.57s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 6.9458	Cost: 8.59s
Train Epoch: 372 	Average Loss: 6.9697
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5671

Learning rate: 9.965893961360968e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 7.4304	Cost: 21.95s
Train Epoch: 373 [20480/90000 (23%)]	Loss: 7.0231	Cost: 8.81s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 6.8899	Cost: 8.93s
Train Epoch: 373 [61440/90000 (68%)]	Loss: 6.8260	Cost: 6.75s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 6.9629	Cost: 6.97s
Train Epoch: 373 	Average Loss: 6.9553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5907

Learning rate: 9.965710559255453e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 7.4817	Cost: 19.99s
Train Epoch: 374 [20480/90000 (23%)]	Loss: 6.8607	Cost: 8.02s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 6.9209	Cost: 9.50s
Train Epoch: 374 [61440/90000 (68%)]	Loss: 6.9118	Cost: 11.88s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 6.8111	Cost: 12.63s
Train Epoch: 374 	Average Loss: 6.9334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5906

Learning rate: 9.965526667053955e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 7.5778	Cost: 21.79s
Train Epoch: 375 [20480/90000 (23%)]	Loss: 6.7108	Cost: 10.41s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 6.9195	Cost: 14.72s
Train Epoch: 375 [61440/90000 (68%)]	Loss: 7.0344	Cost: 12.63s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 6.8788	Cost: 12.26s
Train Epoch: 375 	Average Loss: 6.9312
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5312

Learning rate: 9.965342284774624e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 7.4880	Cost: 41.51s
Train Epoch: 376 [20480/90000 (23%)]	Loss: 6.9109	Cost: 9.68s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 7.1296	Cost: 12.44s
Train Epoch: 376 [61440/90000 (68%)]	Loss: 6.8167	Cost: 12.23s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 6.9085	Cost: 7.60s
Train Epoch: 376 	Average Loss: 6.9493
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5752

Learning rate: 9.965157412435655e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 7.6324	Cost: 36.78s
Train Epoch: 377 [20480/90000 (23%)]	Loss: 6.7532	Cost: 9.41s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 6.8123	Cost: 6.55s
Train Epoch: 377 [61440/90000 (68%)]	Loss: 6.8558	Cost: 7.17s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 6.8210	Cost: 8.95s
Train Epoch: 377 	Average Loss: 6.9105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5288

Learning rate: 9.964972050055294e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 7.5053	Cost: 24.07s
Train Epoch: 378 [20480/90000 (23%)]	Loss: 6.7738	Cost: 10.52s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 6.9563	Cost: 11.07s
Train Epoch: 378 [61440/90000 (68%)]	Loss: 7.0512	Cost: 8.94s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 6.8500	Cost: 8.66s
Train Epoch: 378 	Average Loss: 6.9033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4935

Learning rate: 9.964786197651839e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 7.5382	Cost: 22.63s
Train Epoch: 379 [20480/90000 (23%)]	Loss: 6.8329	Cost: 10.96s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 6.9859	Cost: 10.32s
Train Epoch: 379 [61440/90000 (68%)]	Loss: 6.8505	Cost: 8.95s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 6.9385	Cost: 8.88s
Train Epoch: 379 	Average Loss: 6.8874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5481

Learning rate: 9.96459985524363e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 7.4861	Cost: 20.45s
Train Epoch: 380 [20480/90000 (23%)]	Loss: 6.7930	Cost: 8.87s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 6.8301	Cost: 8.75s
Train Epoch: 380 [61440/90000 (68%)]	Loss: 6.8874	Cost: 7.70s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 6.9450	Cost: 7.15s
Train Epoch: 380 	Average Loss: 6.8829
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5225

Learning rate: 9.96441302284906e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 7.3022	Cost: 19.85s
Train Epoch: 381 [20480/90000 (23%)]	Loss: 6.8773	Cost: 7.52s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 6.8906	Cost: 11.97s
Train Epoch: 381 [61440/90000 (68%)]	Loss: 6.8180	Cost: 13.90s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 6.8433	Cost: 16.01s
Train Epoch: 381 	Average Loss: 6.8597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5234

Learning rate: 9.964225700486566e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 7.4195	Cost: 29.32s
Train Epoch: 382 [20480/90000 (23%)]	Loss: 6.7560	Cost: 14.21s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 6.8016	Cost: 13.73s
Train Epoch: 382 [61440/90000 (68%)]	Loss: 6.7332	Cost: 11.99s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 6.8073	Cost: 12.14s
Train Epoch: 382 	Average Loss: 6.8582
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5128

Learning rate: 9.96403788817464e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 7.4140	Cost: 36.88s
Train Epoch: 383 [20480/90000 (23%)]	Loss: 6.7012	Cost: 12.06s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 6.8754	Cost: 7.37s
Train Epoch: 383 [61440/90000 (68%)]	Loss: 6.7207	Cost: 6.32s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 6.8378	Cost: 7.74s
Train Epoch: 383 	Average Loss: 6.8441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5563

Learning rate: 9.963849585931816e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 7.3812	Cost: 21.67s
Train Epoch: 384 [20480/90000 (23%)]	Loss: 6.8182	Cost: 8.61s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 6.9458	Cost: 8.96s
Train Epoch: 384 [61440/90000 (68%)]	Loss: 6.7896	Cost: 9.01s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 6.8387	Cost: 8.98s
Train Epoch: 384 	Average Loss: 6.8714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5150

Learning rate: 9.963660793776678e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 7.4421	Cost: 24.58s
Train Epoch: 385 [20480/90000 (23%)]	Loss: 6.8477	Cost: 9.94s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 6.7909	Cost: 6.77s
Train Epoch: 385 [61440/90000 (68%)]	Loss: 6.7354	Cost: 7.25s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 6.8950	Cost: 6.68s
Train Epoch: 385 	Average Loss: 6.8650
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5452

Learning rate: 9.963471511727859e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 7.4641	Cost: 28.79s
Train Epoch: 386 [20480/90000 (23%)]	Loss: 6.6512	Cost: 9.91s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 6.8995	Cost: 10.41s
Train Epoch: 386 [61440/90000 (68%)]	Loss: 6.7519	Cost: 13.10s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 6.9396	Cost: 12.72s
Train Epoch: 386 	Average Loss: 6.8420
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4686

Saving model as e386_model.pt & e386_waveforms_supplementary.hdf5
Learning rate: 9.963281739804043e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 7.3501	Cost: 29.66s
Train Epoch: 387 [20480/90000 (23%)]	Loss: 6.7320	Cost: 12.51s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 6.8219	Cost: 13.69s
Train Epoch: 387 [61440/90000 (68%)]	Loss: 6.7264	Cost: 12.23s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 6.7504	Cost: 12.16s
Train Epoch: 387 	Average Loss: 6.8153
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4859

Learning rate: 9.963091478023956e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 7.3245	Cost: 30.47s
Train Epoch: 388 [20480/90000 (23%)]	Loss: 6.8034	Cost: 11.18s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 6.7745	Cost: 12.71s
Train Epoch: 388 [61440/90000 (68%)]	Loss: 6.7702	Cost: 12.77s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 6.8875	Cost: 8.82s
Train Epoch: 388 	Average Loss: 6.8069
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4919

Learning rate: 9.962900726406379e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 7.5073	Cost: 25.43s
Train Epoch: 389 [20480/90000 (23%)]	Loss: 6.9161	Cost: 12.83s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 6.9081	Cost: 12.04s
Train Epoch: 389 [61440/90000 (68%)]	Loss: 6.8608	Cost: 6.44s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 6.8212	Cost: 6.86s
Train Epoch: 389 	Average Loss: 6.8352
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4568

Saving model as e389_model.pt & e389_waveforms_supplementary.hdf5
Learning rate: 9.962709484970139e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 7.5675	Cost: 19.36s
Train Epoch: 390 [20480/90000 (23%)]	Loss: 6.7152	Cost: 6.43s
Train Epoch: 390 [40960/90000 (45%)]	Loss: 6.7803	Cost: 10.95s
Train Epoch: 390 [61440/90000 (68%)]	Loss: 6.5778	Cost: 8.93s
Train Epoch: 390 [81920/90000 (91%)]	Loss: 6.7803	Cost: 8.74s
Train Epoch: 390 	Average Loss: 6.7614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4348

Saving model as e390_model.pt & e390_waveforms_supplementary.hdf5
Learning rate: 9.962517753734109e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 7.3798	Cost: 28.09s
Train Epoch: 391 [20480/90000 (23%)]	Loss: 6.7135	Cost: 8.81s
Train Epoch: 391 [40960/90000 (45%)]	Loss: 6.6377	Cost: 8.78s
Train Epoch: 391 [61440/90000 (68%)]	Loss: 6.7901	Cost: 5.95s
Train Epoch: 391 [81920/90000 (91%)]	Loss: 6.7840	Cost: 6.66s
Train Epoch: 391 	Average Loss: 6.7608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4347

Saving model as e391_model.pt & e391_waveforms_supplementary.hdf5
Learning rate: 9.962325532717212e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 7.2953	Cost: 29.53s
Train Epoch: 392 [20480/90000 (23%)]	Loss: 6.5947	Cost: 13.43s
Train Epoch: 392 [40960/90000 (45%)]	Loss: 6.7728	Cost: 15.78s
Train Epoch: 392 [61440/90000 (68%)]	Loss: 6.5544	Cost: 11.41s
Train Epoch: 392 [81920/90000 (91%)]	Loss: 6.5875	Cost: 18.65s
Train Epoch: 392 	Average Loss: 6.7266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3719

Saving model as e392_model.pt & e392_waveforms_supplementary.hdf5
Learning rate: 9.96213282193842e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 7.4866	Cost: 20.10s
Train Epoch: 393 [20480/90000 (23%)]	Loss: 6.7481	Cost: 8.23s
Train Epoch: 393 [40960/90000 (45%)]	Loss: 6.7922	Cost: 16.83s
Train Epoch: 393 [61440/90000 (68%)]	Loss: 6.6536	Cost: 12.49s
Train Epoch: 393 [81920/90000 (91%)]	Loss: 6.6177	Cost: 12.38s
Train Epoch: 393 	Average Loss: 6.7514
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3878

Learning rate: 9.961939621416751e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 7.3562	Cost: 31.65s
Train Epoch: 394 [20480/90000 (23%)]	Loss: 6.7523	Cost: 10.90s
Train Epoch: 394 [40960/90000 (45%)]	Loss: 6.8299	Cost: 12.07s
Train Epoch: 394 [61440/90000 (68%)]	Loss: 6.6964	Cost: 12.08s
Train Epoch: 394 [81920/90000 (91%)]	Loss: 6.6167	Cost: 9.12s
Train Epoch: 394 	Average Loss: 6.7311
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4438

Learning rate: 9.961745931171276e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 7.4190	Cost: 26.28s
Train Epoch: 395 [20480/90000 (23%)]	Loss: 6.7069	Cost: 12.87s
Train Epoch: 395 [40960/90000 (45%)]	Loss: 6.6105	Cost: 12.38s
Train Epoch: 395 [61440/90000 (68%)]	Loss: 6.6140	Cost: 7.82s
Train Epoch: 395 [81920/90000 (91%)]	Loss: 6.6477	Cost: 6.18s
Train Epoch: 395 	Average Loss: 6.7278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3907

Learning rate: 9.96155175122111e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 7.3965	Cost: 26.46s
Train Epoch: 396 [20480/90000 (23%)]	Loss: 6.8201	Cost: 12.06s
Train Epoch: 396 [40960/90000 (45%)]	Loss: 6.7401	Cost: 10.60s
Train Epoch: 396 [61440/90000 (68%)]	Loss: 6.6048	Cost: 6.29s
Train Epoch: 396 [81920/90000 (91%)]	Loss: 6.5876	Cost: 6.33s
Train Epoch: 396 	Average Loss: 6.6968
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4133

Learning rate: 9.96135708158542e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 7.2997	Cost: 37.55s
Train Epoch: 397 [20480/90000 (23%)]	Loss: 6.5784	Cost: 12.01s
Train Epoch: 397 [40960/90000 (45%)]	Loss: 6.6237	Cost: 8.90s
Train Epoch: 397 [61440/90000 (68%)]	Loss: 6.7121	Cost: 6.48s
Train Epoch: 397 [81920/90000 (91%)]	Loss: 6.6101	Cost: 8.51s
Train Epoch: 397 	Average Loss: 6.6591
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3275

Saving model as e397_model.pt & e397_waveforms_supplementary.hdf5
Learning rate: 9.961161922283415e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 7.2867	Cost: 23.60s
Train Epoch: 398 [20480/90000 (23%)]	Loss: 6.6215	Cost: 8.06s
Train Epoch: 398 [40960/90000 (45%)]	Loss: 6.7255	Cost: 10.42s
Train Epoch: 398 [61440/90000 (68%)]	Loss: 6.6842	Cost: 8.05s
Train Epoch: 398 [81920/90000 (91%)]	Loss: 6.6695	Cost: 8.71s
Train Epoch: 398 	Average Loss: 6.6768
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3178

Saving model as e398_model.pt & e398_waveforms_supplementary.hdf5
Learning rate: 9.960966273334359e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 7.2469	Cost: 24.12s
Train Epoch: 399 [20480/90000 (23%)]	Loss: 6.5145	Cost: 8.97s
Train Epoch: 399 [40960/90000 (45%)]	Loss: 6.5867	Cost: 9.03s
Train Epoch: 399 [61440/90000 (68%)]	Loss: 6.6925	Cost: 8.71s
Train Epoch: 399 [81920/90000 (91%)]	Loss: 6.6368	Cost: 8.78s
Train Epoch: 399 	Average Loss: 6.6575
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3797

Learning rate: 9.960770134757561e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 7.2509	Cost: 21.56s
Train Epoch: 400 [20480/90000 (23%)]	Loss: 6.5583	Cost: 6.93s
Train Epoch: 400 [40960/90000 (45%)]	Loss: 6.7107	Cost: 9.20s
Train Epoch: 400 [61440/90000 (68%)]	Loss: 6.6586	Cost: 13.15s
Train Epoch: 400 [81920/90000 (91%)]	Loss: 6.6023	Cost: 12.67s
Train Epoch: 400 	Average Loss: 6.6637
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3863

Learning rate: 9.96057350657238e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 401 [0/90000 (0%)]	Loss: 7.3920	Cost: 21.68s
Train Epoch: 401 [20480/90000 (23%)]	Loss: 6.5693	Cost: 12.50s
Train Epoch: 401 [40960/90000 (45%)]	Loss: 6.5555	Cost: 15.74s
Train Epoch: 401 [61440/90000 (68%)]	Loss: 6.7097	Cost: 12.38s
Train Epoch: 401 [81920/90000 (91%)]	Loss: 6.5553	Cost: 12.02s
Train Epoch: 401 	Average Loss: 6.6509
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3626

Learning rate: 9.960376388798222e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 402 [0/90000 (0%)]	Loss: 7.3749	Cost: 40.20s
Train Epoch: 402 [20480/90000 (23%)]	Loss: 6.4766	Cost: 11.97s
Train Epoch: 402 [40960/90000 (45%)]	Loss: 6.7023	Cost: 12.35s
Train Epoch: 402 [61440/90000 (68%)]	Loss: 6.5837	Cost: 11.33s
Train Epoch: 402 [81920/90000 (91%)]	Loss: 6.4912	Cost: 6.09s
Train Epoch: 402 	Average Loss: 6.6294
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3987

Learning rate: 9.960178781454541e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 403 [0/90000 (0%)]	Loss: 7.3692	Cost: 27.80s
Train Epoch: 403 [20480/90000 (23%)]	Loss: 6.5257	Cost: 12.80s
Train Epoch: 403 [40960/90000 (45%)]	Loss: 6.5159	Cost: 12.34s
Train Epoch: 403 [61440/90000 (68%)]	Loss: 6.6453	Cost: 7.62s
Train Epoch: 403 [81920/90000 (91%)]	Loss: 6.7619	Cost: 6.18s
Train Epoch: 403 	Average Loss: 6.6261
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2585

Saving model as e403_model.pt & e403_waveforms_supplementary.hdf5
Learning rate: 9.959980684560841e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 404 [0/90000 (0%)]	Loss: 7.2048	Cost: 27.92s
Train Epoch: 404 [20480/90000 (23%)]	Loss: 6.4440	Cost: 7.42s
Train Epoch: 404 [40960/90000 (45%)]	Loss: 6.5529	Cost: 9.44s
Train Epoch: 404 [61440/90000 (68%)]	Loss: 6.5148	Cost: 9.86s
Train Epoch: 404 [81920/90000 (91%)]	Loss: 6.6501	Cost: 9.09s
Train Epoch: 404 	Average Loss: 6.6002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3512

Learning rate: 9.959782098136674e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 405 [0/90000 (0%)]	Loss: 7.2071	Cost: 20.61s
Train Epoch: 405 [20480/90000 (23%)]	Loss: 6.5703	Cost: 10.14s
Train Epoch: 405 [40960/90000 (45%)]	Loss: 6.5662	Cost: 11.45s
Train Epoch: 405 [61440/90000 (68%)]	Loss: 6.5273	Cost: 8.93s
Train Epoch: 405 [81920/90000 (91%)]	Loss: 6.5866	Cost: 8.83s
Train Epoch: 405 	Average Loss: 6.5918
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3499

Learning rate: 9.959583022201639e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 406 [0/90000 (0%)]	Loss: 7.0840	Cost: 23.56s
Train Epoch: 406 [20480/90000 (23%)]	Loss: 6.4822	Cost: 9.24s
Train Epoch: 406 [40960/90000 (45%)]	Loss: 6.5672	Cost: 7.34s
Train Epoch: 406 [61440/90000 (68%)]	Loss: 6.4630	Cost: 5.97s
Train Epoch: 406 [81920/90000 (91%)]	Loss: 6.6282	Cost: 6.55s
Train Epoch: 406 	Average Loss: 6.5551
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3056

Learning rate: 9.959383456775382e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 407 [0/90000 (0%)]	Loss: 7.3364	Cost: 20.94s
Train Epoch: 407 [20480/90000 (23%)]	Loss: 6.3756	Cost: 7.17s
Train Epoch: 407 [40960/90000 (45%)]	Loss: 6.4755	Cost: 9.11s
Train Epoch: 407 [61440/90000 (68%)]	Loss: 6.5232	Cost: 12.44s
Train Epoch: 407 [81920/90000 (91%)]	Loss: 6.5446	Cost: 12.38s
Train Epoch: 407 	Average Loss: 6.5552
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2898

Learning rate: 9.959183401877603e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 408 [0/90000 (0%)]	Loss: 7.3188	Cost: 26.00s
Train Epoch: 408 [20480/90000 (23%)]	Loss: 6.4496	Cost: 12.33s
Train Epoch: 408 [40960/90000 (45%)]	Loss: 6.6253	Cost: 12.55s
Train Epoch: 408 [61440/90000 (68%)]	Loss: 6.5361	Cost: 12.39s
Train Epoch: 408 [81920/90000 (91%)]	Loss: 6.5506	Cost: 12.45s
Train Epoch: 408 	Average Loss: 6.5468
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2072

Saving model as e408_model.pt & e408_waveforms_supplementary.hdf5
Learning rate: 9.958982857528043e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 409 [0/90000 (0%)]	Loss: 7.0647	Cost: 29.93s
Train Epoch: 409 [20480/90000 (23%)]	Loss: 6.3619	Cost: 12.42s
Train Epoch: 409 [40960/90000 (45%)]	Loss: 6.5227	Cost: 14.22s
Train Epoch: 409 [61440/90000 (68%)]	Loss: 6.5350	Cost: 12.12s
Train Epoch: 409 [81920/90000 (91%)]	Loss: 6.3945	Cost: 9.48s
Train Epoch: 409 	Average Loss: 6.5454
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3044

Learning rate: 9.958781823746497e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 410 [0/90000 (0%)]	Loss: 7.2376	Cost: 31.65s
Train Epoch: 410 [20480/90000 (23%)]	Loss: 6.2934	Cost: 13.67s
Train Epoch: 410 [40960/90000 (45%)]	Loss: 6.5309	Cost: 11.89s
Train Epoch: 410 [61440/90000 (68%)]	Loss: 6.2323	Cost: 6.20s
Train Epoch: 410 [81920/90000 (91%)]	Loss: 6.5384	Cost: 6.04s
Train Epoch: 410 	Average Loss: 6.5250
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2326

Learning rate: 9.958580300552807e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 411 [0/90000 (0%)]	Loss: 7.2943	Cost: 26.96s
Train Epoch: 411 [20480/90000 (23%)]	Loss: 6.3812	Cost: 12.12s
Train Epoch: 411 [40960/90000 (45%)]	Loss: 6.4995	Cost: 6.78s
Train Epoch: 411 [61440/90000 (68%)]	Loss: 6.3443	Cost: 6.21s
Train Epoch: 411 [81920/90000 (91%)]	Loss: 6.5311	Cost: 8.40s
Train Epoch: 411 	Average Loss: 6.5098
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2420

Learning rate: 9.95837828796686e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 412 [0/90000 (0%)]	Loss: 7.2248	Cost: 27.92s
Train Epoch: 412 [20480/90000 (23%)]	Loss: 6.4548	Cost: 6.61s
Train Epoch: 412 [40960/90000 (45%)]	Loss: 6.4282	Cost: 9.08s
Train Epoch: 412 [61440/90000 (68%)]	Loss: 6.3708	Cost: 8.93s
Train Epoch: 412 [81920/90000 (91%)]	Loss: 6.4618	Cost: 8.60s
Train Epoch: 412 	Average Loss: 6.4734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2022

Saving model as e412_model.pt & e412_waveforms_supplementary.hdf5
Learning rate: 9.958175786008596e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 413 [0/90000 (0%)]	Loss: 7.1223	Cost: 22.53s
Train Epoch: 413 [20480/90000 (23%)]	Loss: 6.5151	Cost: 9.12s
Train Epoch: 413 [40960/90000 (45%)]	Loss: 6.3144	Cost: 8.48s
Train Epoch: 413 [61440/90000 (68%)]	Loss: 6.3802	Cost: 6.11s
Train Epoch: 413 [81920/90000 (91%)]	Loss: 6.3553	Cost: 6.48s
Train Epoch: 413 	Average Loss: 6.4851
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1974

Saving model as e413_model.pt & e413_waveforms_supplementary.hdf5
Learning rate: 9.957972794698001e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 414 [0/90000 (0%)]	Loss: 7.2067	Cost: 26.65s
Train Epoch: 414 [20480/90000 (23%)]	Loss: 6.4137	Cost: 10.80s
Train Epoch: 414 [40960/90000 (45%)]	Loss: 6.4896	Cost: 16.60s
Train Epoch: 414 [61440/90000 (68%)]	Loss: 6.3546	Cost: 13.15s
Train Epoch: 414 [81920/90000 (91%)]	Loss: 6.2689	Cost: 12.21s
Train Epoch: 414 	Average Loss: 6.4793
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2334

Learning rate: 9.957769314055109e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 415 [0/90000 (0%)]	Loss: 7.2497	Cost: 32.35s
Train Epoch: 415 [20480/90000 (23%)]	Loss: 6.4303	Cost: 14.57s
Train Epoch: 415 [40960/90000 (45%)]	Loss: 6.4435	Cost: 13.97s
Train Epoch: 415 [61440/90000 (68%)]	Loss: 6.3676	Cost: 12.08s
Train Epoch: 415 [81920/90000 (91%)]	Loss: 6.4059	Cost: 8.40s
Train Epoch: 415 	Average Loss: 6.4658
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1982

Learning rate: 9.957565344100001e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 416 [0/90000 (0%)]	Loss: 7.0977	Cost: 38.68s
Train Epoch: 416 [20480/90000 (23%)]	Loss: 6.4749	Cost: 12.58s
Train Epoch: 416 [40960/90000 (45%)]	Loss: 6.3999	Cost: 9.80s
Train Epoch: 416 [61440/90000 (68%)]	Loss: 6.5043	Cost: 6.12s
Train Epoch: 416 [81920/90000 (91%)]	Loss: 6.4105	Cost: 6.40s
Train Epoch: 416 	Average Loss: 6.4317
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1750

Saving model as e416_model.pt & e416_waveforms_supplementary.hdf5
Learning rate: 9.95736088485281e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 417 [0/90000 (0%)]	Loss: 7.1160	Cost: 25.62s
Train Epoch: 417 [20480/90000 (23%)]	Loss: 6.3703	Cost: 6.43s
Train Epoch: 417 [40960/90000 (45%)]	Loss: 6.4045	Cost: 9.55s
Train Epoch: 417 [61440/90000 (68%)]	Loss: 6.2240	Cost: 8.58s
Train Epoch: 417 [81920/90000 (91%)]	Loss: 6.5339	Cost: 8.39s
Train Epoch: 417 	Average Loss: 6.4449
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2387

Learning rate: 9.957155936333717e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 418 [0/90000 (0%)]	Loss: 7.2856	Cost: 21.15s
Train Epoch: 418 [20480/90000 (23%)]	Loss: 6.3138	Cost: 8.84s
Train Epoch: 418 [40960/90000 (45%)]	Loss: 6.3824	Cost: 8.79s
Train Epoch: 418 [61440/90000 (68%)]	Loss: 6.4210	Cost: 8.57s
Train Epoch: 418 [81920/90000 (91%)]	Loss: 6.5245	Cost: 7.70s
Train Epoch: 418 	Average Loss: 6.4367
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1686

Saving model as e418_model.pt & e418_waveforms_supplementary.hdf5
Learning rate: 9.956950498562945e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 419 [0/90000 (0%)]	Loss: 7.2624	Cost: 19.89s
Train Epoch: 419 [20480/90000 (23%)]	Loss: 6.4060	Cost: 8.04s
Train Epoch: 419 [40960/90000 (45%)]	Loss: 6.3860	Cost: 14.28s
Train Epoch: 419 [61440/90000 (68%)]	Loss: 6.4060	Cost: 11.99s
Train Epoch: 419 [81920/90000 (91%)]	Loss: 6.5487	Cost: 12.36s
Train Epoch: 419 	Average Loss: 6.4156
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2419

Learning rate: 9.956744571560774e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 420 [0/90000 (0%)]	Loss: 7.1691	Cost: 22.30s
Train Epoch: 420 [20480/90000 (23%)]	Loss: 6.3270	Cost: 8.67s
Train Epoch: 420 [40960/90000 (45%)]	Loss: 6.4239	Cost: 12.25s
Train Epoch: 420 [61440/90000 (68%)]	Loss: 6.2383	Cost: 8.42s
Train Epoch: 420 [81920/90000 (91%)]	Loss: 6.3445	Cost: 14.19s
Train Epoch: 420 	Average Loss: 6.3935
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2537

Learning rate: 9.956538155347526e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 421 [0/90000 (0%)]	Loss: 7.2329	Cost: 27.77s
Train Epoch: 421 [20480/90000 (23%)]	Loss: 6.2769	Cost: 12.60s
Train Epoch: 421 [40960/90000 (45%)]	Loss: 6.3132	Cost: 13.92s
Train Epoch: 421 [61440/90000 (68%)]	Loss: 6.2227	Cost: 12.38s
Train Epoch: 421 [81920/90000 (91%)]	Loss: 6.4006	Cost: 12.17s
Train Epoch: 421 	Average Loss: 6.3822
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1844

Learning rate: 9.956331249943575e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 422 [0/90000 (0%)]	Loss: 7.1596	Cost: 24.65s
Train Epoch: 422 [20480/90000 (23%)]	Loss: 6.3510	Cost: 12.20s
Train Epoch: 422 [40960/90000 (45%)]	Loss: 6.5395	Cost: 13.15s
Train Epoch: 422 [61440/90000 (68%)]	Loss: 6.3678	Cost: 12.60s
Train Epoch: 422 [81920/90000 (91%)]	Loss: 6.3326	Cost: 9.99s
Train Epoch: 422 	Average Loss: 6.4106
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1801

Learning rate: 9.956123855369338e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 423 [0/90000 (0%)]	Loss: 7.0829	Cost: 25.08s
Train Epoch: 423 [20480/90000 (23%)]	Loss: 6.3209	Cost: 11.56s
Train Epoch: 423 [40960/90000 (45%)]	Loss: 6.2354	Cost: 12.61s
Train Epoch: 423 [61440/90000 (68%)]	Loss: 6.2823	Cost: 12.59s
Train Epoch: 423 [81920/90000 (91%)]	Loss: 6.3509	Cost: 6.75s
Train Epoch: 423 	Average Loss: 6.3600
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2087

Learning rate: 9.95591597164529e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 424 [0/90000 (0%)]	Loss: 7.2309	Cost: 22.95s
Train Epoch: 424 [20480/90000 (23%)]	Loss: 6.1906	Cost: 12.71s
Train Epoch: 424 [40960/90000 (45%)]	Loss: 6.2242	Cost: 10.11s
Train Epoch: 424 [61440/90000 (68%)]	Loss: 6.2389	Cost: 6.34s
Train Epoch: 424 [81920/90000 (91%)]	Loss: 6.4366	Cost: 6.87s
Train Epoch: 424 	Average Loss: 6.3431
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1711

Learning rate: 9.955707598791946e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 425 [0/90000 (0%)]	Loss: 7.0622	Cost: 31.48s
Train Epoch: 425 [20480/90000 (23%)]	Loss: 6.2760	Cost: 8.70s
Train Epoch: 425 [40960/90000 (45%)]	Loss: 6.3891	Cost: 9.37s
Train Epoch: 425 [61440/90000 (68%)]	Loss: 6.3739	Cost: 7.70s
Train Epoch: 425 [81920/90000 (91%)]	Loss: 6.2304	Cost: 8.56s
Train Epoch: 425 	Average Loss: 6.3513
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1218

Saving model as e425_model.pt & e425_waveforms_supplementary.hdf5
Learning rate: 9.955498736829867e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 426 [0/90000 (0%)]	Loss: 7.1240	Cost: 23.15s
Train Epoch: 426 [20480/90000 (23%)]	Loss: 6.1907	Cost: 10.00s
Train Epoch: 426 [40960/90000 (45%)]	Loss: 6.2739	Cost: 10.55s
Train Epoch: 426 [61440/90000 (68%)]	Loss: 6.2044	Cost: 8.79s
Train Epoch: 426 [81920/90000 (91%)]	Loss: 6.3766	Cost: 8.75s
Train Epoch: 426 	Average Loss: 6.3171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0674

Saving model as e426_model.pt & e426_waveforms_supplementary.hdf5
Learning rate: 9.955289385779672e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 427 [0/90000 (0%)]	Loss: 6.9321	Cost: 19.50s
Train Epoch: 427 [20480/90000 (23%)]	Loss: 6.2947	Cost: 7.70s
Train Epoch: 427 [40960/90000 (45%)]	Loss: 6.3357	Cost: 7.35s
Train Epoch: 427 [61440/90000 (68%)]	Loss: 6.1798	Cost: 8.80s
Train Epoch: 427 [81920/90000 (91%)]	Loss: 6.3307	Cost: 10.07s
Train Epoch: 427 	Average Loss: 6.3138
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0960

Learning rate: 9.955079545662022e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 428 [0/90000 (0%)]	Loss: 6.9897	Cost: 19.40s
Train Epoch: 428 [20480/90000 (23%)]	Loss: 6.1555	Cost: 9.33s
Train Epoch: 428 [40960/90000 (45%)]	Loss: 6.3206	Cost: 13.27s
Train Epoch: 428 [61440/90000 (68%)]	Loss: 6.0280	Cost: 12.43s
Train Epoch: 428 [81920/90000 (91%)]	Loss: 6.1270	Cost: 12.54s
Train Epoch: 428 	Average Loss: 6.2913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0868

Learning rate: 9.954869216497627e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 429 [0/90000 (0%)]	Loss: 7.1616	Cost: 23.32s
Train Epoch: 429 [20480/90000 (23%)]	Loss: 6.2076	Cost: 14.46s
Train Epoch: 429 [40960/90000 (45%)]	Loss: 6.3538	Cost: 13.94s
Train Epoch: 429 [61440/90000 (68%)]	Loss: 6.1261	Cost: 12.21s
Train Epoch: 429 [81920/90000 (91%)]	Loss: 6.0715	Cost: 12.07s
Train Epoch: 429 	Average Loss: 6.2808
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0703

Learning rate: 9.954658398307247e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 430 [0/90000 (0%)]	Loss: 6.9088	Cost: 42.78s
Train Epoch: 430 [20480/90000 (23%)]	Loss: 6.1741	Cost: 12.16s
Train Epoch: 430 [40960/90000 (45%)]	Loss: 6.0512	Cost: 10.32s
Train Epoch: 430 [61440/90000 (68%)]	Loss: 6.2040	Cost: 6.10s
Train Epoch: 430 [81920/90000 (91%)]	Loss: 6.2685	Cost: 6.55s
Train Epoch: 430 	Average Loss: 6.2654
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0938

Learning rate: 9.954447091111686e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 431 [0/90000 (0%)]	Loss: 7.0090	Cost: 26.84s
Train Epoch: 431 [20480/90000 (23%)]	Loss: 6.1876	Cost: 11.08s
Train Epoch: 431 [40960/90000 (45%)]	Loss: 6.1668	Cost: 10.44s
Train Epoch: 431 [61440/90000 (68%)]	Loss: 6.1285	Cost: 6.26s
Train Epoch: 431 [81920/90000 (91%)]	Loss: 6.1675	Cost: 7.07s
Train Epoch: 431 	Average Loss: 6.2397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0540

Saving model as e431_model.pt & e431_waveforms_supplementary.hdf5
Learning rate: 9.954235294931802e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 432 [0/90000 (0%)]	Loss: 6.9464	Cost: 27.96s
Train Epoch: 432 [20480/90000 (23%)]	Loss: 6.0597	Cost: 6.64s
Train Epoch: 432 [40960/90000 (45%)]	Loss: 6.0378	Cost: 7.00s
Train Epoch: 432 [61440/90000 (68%)]	Loss: 6.2790	Cost: 8.30s
Train Epoch: 432 [81920/90000 (91%)]	Loss: 6.2002	Cost: 8.76s
Train Epoch: 432 	Average Loss: 6.2268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0348

Saving model as e432_model.pt & e432_waveforms_supplementary.hdf5
Learning rate: 9.954023009788497e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 433 [0/90000 (0%)]	Loss: 7.0155	Cost: 20.21s
Train Epoch: 433 [20480/90000 (23%)]	Loss: 6.0517	Cost: 8.33s
Train Epoch: 433 [40960/90000 (45%)]	Loss: 6.3627	Cost: 9.01s
Train Epoch: 433 [61440/90000 (68%)]	Loss: 6.1439	Cost: 8.52s
Train Epoch: 433 [81920/90000 (91%)]	Loss: 6.2945	Cost: 8.77s
Train Epoch: 433 	Average Loss: 6.2214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1039

Learning rate: 9.953810235702723e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 434 [0/90000 (0%)]	Loss: 7.0717	Cost: 22.38s
Train Epoch: 434 [20480/90000 (23%)]	Loss: 6.1139	Cost: 6.58s
Train Epoch: 434 [40960/90000 (45%)]	Loss: 6.2491	Cost: 12.26s
Train Epoch: 434 [61440/90000 (68%)]	Loss: 6.1788	Cost: 9.45s
Train Epoch: 434 [81920/90000 (91%)]	Loss: 6.1344	Cost: 13.03s
Train Epoch: 434 	Average Loss: 6.2229
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0670

Learning rate: 9.95359697269548e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 435 [0/90000 (0%)]	Loss: 7.1106	Cost: 22.33s
Train Epoch: 435 [20480/90000 (23%)]	Loss: 6.0888	Cost: 10.56s
Train Epoch: 435 [40960/90000 (45%)]	Loss: 6.2441	Cost: 12.20s
Train Epoch: 435 [61440/90000 (68%)]	Loss: 5.9926	Cost: 12.61s
Train Epoch: 435 [81920/90000 (91%)]	Loss: 6.1334	Cost: 12.38s
Train Epoch: 435 	Average Loss: 6.1930
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0320

Saving model as e435_model.pt & e435_waveforms_supplementary.hdf5
Learning rate: 9.953383220787815e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 436 [0/90000 (0%)]	Loss: 6.9465	Cost: 33.23s
Train Epoch: 436 [20480/90000 (23%)]	Loss: 6.0000	Cost: 13.94s
Train Epoch: 436 [40960/90000 (45%)]	Loss: 6.1677	Cost: 12.40s
Train Epoch: 436 [61440/90000 (68%)]	Loss: 6.0822	Cost: 12.18s
Train Epoch: 436 [81920/90000 (91%)]	Loss: 6.1609	Cost: 11.08s
Train Epoch: 436 	Average Loss: 6.1882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0826

Learning rate: 9.953168980000828e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 437 [0/90000 (0%)]	Loss: 6.9006	Cost: 27.42s
Train Epoch: 437 [20480/90000 (23%)]	Loss: 6.1796	Cost: 13.59s
Train Epoch: 437 [40960/90000 (45%)]	Loss: 6.2533	Cost: 14.22s
Train Epoch: 437 [61440/90000 (68%)]	Loss: 6.1855	Cost: 9.94s
Train Epoch: 437 [81920/90000 (91%)]	Loss: 6.0883	Cost: 6.58s
Train Epoch: 437 	Average Loss: 6.2006
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0891

Learning rate: 9.95295425035566e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 438 [0/90000 (0%)]	Loss: 7.0640	Cost: 25.38s
Train Epoch: 438 [20480/90000 (23%)]	Loss: 6.1017	Cost: 11.97s
Train Epoch: 438 [40960/90000 (45%)]	Loss: 6.2578	Cost: 12.06s
Train Epoch: 438 [61440/90000 (68%)]	Loss: 6.1279	Cost: 8.63s
Train Epoch: 438 [81920/90000 (91%)]	Loss: 6.2460	Cost: 7.73s
Train Epoch: 438 	Average Loss: 6.1771
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0086

Saving model as e438_model.pt & e438_waveforms_supplementary.hdf5
Learning rate: 9.952739031873505e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 439 [0/90000 (0%)]	Loss: 6.9020	Cost: 21.33s
Train Epoch: 439 [20480/90000 (23%)]	Loss: 5.9834	Cost: 8.62s
Train Epoch: 439 [40960/90000 (45%)]	Loss: 6.1907	Cost: 8.98s
Train Epoch: 439 [61440/90000 (68%)]	Loss: 6.0984	Cost: 8.94s
Train Epoch: 439 [81920/90000 (91%)]	Loss: 6.1186	Cost: 8.54s
Train Epoch: 439 	Average Loss: 6.1540
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9974

Saving model as e439_model.pt & e439_waveforms_supplementary.hdf5
Learning rate: 9.952523324575606e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 440 [0/90000 (0%)]	Loss: 6.8852	Cost: 29.18s
Train Epoch: 440 [20480/90000 (23%)]	Loss: 5.9238	Cost: 8.85s
Train Epoch: 440 [40960/90000 (45%)]	Loss: 6.0977	Cost: 8.83s
Train Epoch: 440 [61440/90000 (68%)]	Loss: 5.9491	Cost: 8.97s
Train Epoch: 440 [81920/90000 (91%)]	Loss: 6.0704	Cost: 8.22s
Train Epoch: 440 	Average Loss: 6.1215
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9625

Saving model as e440_model.pt & e440_waveforms_supplementary.hdf5
Learning rate: 9.952307128483249e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 441 [0/90000 (0%)]	Loss: 7.0857	Cost: 21.42s
Train Epoch: 441 [20480/90000 (23%)]	Loss: 6.0331	Cost: 7.59s
Train Epoch: 441 [40960/90000 (45%)]	Loss: 6.2582	Cost: 7.04s
Train Epoch: 441 [61440/90000 (68%)]	Loss: 6.1516	Cost: 6.62s
Train Epoch: 441 [81920/90000 (91%)]	Loss: 6.1321	Cost: 16.53s
Train Epoch: 441 	Average Loss: 6.1728
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0420

Learning rate: 9.952090443617776e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 442 [0/90000 (0%)]	Loss: 6.8929	Cost: 24.92s
Train Epoch: 442 [20480/90000 (23%)]	Loss: 6.0960	Cost: 10.63s
Train Epoch: 442 [40960/90000 (45%)]	Loss: 6.0197	Cost: 13.94s
Train Epoch: 442 [61440/90000 (68%)]	Loss: 6.2196	Cost: 14.40s
Train Epoch: 442 [81920/90000 (91%)]	Loss: 6.0815	Cost: 12.35s
Train Epoch: 442 	Average Loss: 6.1146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0158

Learning rate: 9.95187327000057e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 443 [0/90000 (0%)]	Loss: 6.7896	Cost: 24.46s
Train Epoch: 443 [20480/90000 (23%)]	Loss: 6.0550	Cost: 14.98s
Train Epoch: 443 [40960/90000 (45%)]	Loss: 6.0218	Cost: 14.88s
Train Epoch: 443 [61440/90000 (68%)]	Loss: 6.0640	Cost: 12.48s
Train Epoch: 443 [81920/90000 (91%)]	Loss: 6.0694	Cost: 11.94s
Train Epoch: 443 	Average Loss: 6.0821
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9520

Saving model as e443_model.pt & e443_waveforms_supplementary.hdf5
Learning rate: 9.951655607653065e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 444 [0/90000 (0%)]	Loss: 6.9243	Cost: 37.71s
Train Epoch: 444 [20480/90000 (23%)]	Loss: 5.9462	Cost: 12.24s
Train Epoch: 444 [40960/90000 (45%)]	Loss: 6.0241	Cost: 8.96s
Train Epoch: 444 [61440/90000 (68%)]	Loss: 6.0119	Cost: 6.07s
Train Epoch: 444 [81920/90000 (91%)]	Loss: 6.1405	Cost: 7.99s
Train Epoch: 444 	Average Loss: 6.0769
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9590

Learning rate: 9.951437456596745e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 445 [0/90000 (0%)]	Loss: 7.1749	Cost: 31.55s
Train Epoch: 445 [20480/90000 (23%)]	Loss: 5.9215	Cost: 9.93s
Train Epoch: 445 [40960/90000 (45%)]	Loss: 5.9936	Cost: 6.60s
Train Epoch: 445 [61440/90000 (68%)]	Loss: 5.8931	Cost: 6.84s
Train Epoch: 445 [81920/90000 (91%)]	Loss: 6.0584	Cost: 8.49s
Train Epoch: 445 	Average Loss: 6.0592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9680

Learning rate: 9.951218816853138e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 446 [0/90000 (0%)]	Loss: 6.9299	Cost: 24.37s
Train Epoch: 446 [20480/90000 (23%)]	Loss: 5.7967	Cost: 7.84s
Train Epoch: 446 [40960/90000 (45%)]	Loss: 5.9837	Cost: 9.57s
Train Epoch: 446 [61440/90000 (68%)]	Loss: 5.9040	Cost: 8.70s
Train Epoch: 446 [81920/90000 (91%)]	Loss: 6.0040	Cost: 8.49s
Train Epoch: 446 	Average Loss: 6.0344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9961

Learning rate: 9.950999688443825e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 447 [0/90000 (0%)]	Loss: 6.8143	Cost: 23.87s
Train Epoch: 447 [20480/90000 (23%)]	Loss: 5.9681	Cost: 12.02s
Train Epoch: 447 [40960/90000 (45%)]	Loss: 6.0723	Cost: 11.01s
Train Epoch: 447 [61440/90000 (68%)]	Loss: 6.0370	Cost: 7.65s
Train Epoch: 447 [81920/90000 (91%)]	Loss: 6.0062	Cost: 7.69s
Train Epoch: 447 	Average Loss: 6.0628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9588

Learning rate: 9.950780071390434e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 448 [0/90000 (0%)]	Loss: 6.7349	Cost: 20.17s
Train Epoch: 448 [20480/90000 (23%)]	Loss: 5.8780	Cost: 10.13s
Train Epoch: 448 [40960/90000 (45%)]	Loss: 5.9866	Cost: 12.82s
Train Epoch: 448 [61440/90000 (68%)]	Loss: 6.0403	Cost: 13.14s
Train Epoch: 448 [81920/90000 (91%)]	Loss: 5.9175	Cost: 12.12s
Train Epoch: 448 	Average Loss: 6.0076
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9448

Saving model as e448_model.pt & e448_waveforms_supplementary.hdf5
Learning rate: 9.95055996571464e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 449 [0/90000 (0%)]	Loss: 7.0067	Cost: 25.77s
Train Epoch: 449 [20480/90000 (23%)]	Loss: 5.8652	Cost: 13.51s
Train Epoch: 449 [40960/90000 (45%)]	Loss: 6.0162	Cost: 13.23s
Train Epoch: 449 [61440/90000 (68%)]	Loss: 5.8666	Cost: 12.27s
Train Epoch: 449 [81920/90000 (91%)]	Loss: 6.0437	Cost: 12.30s
Train Epoch: 449 	Average Loss: 6.0138
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9387

Saving model as e449_model.pt & e449_waveforms_supplementary.hdf5
Learning rate: 9.950339371438165e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 450 [0/90000 (0%)]	Loss: 6.9027	Cost: 21.79s
Train Epoch: 450 [20480/90000 (23%)]	Loss: 6.0033	Cost: 13.88s
Train Epoch: 450 [40960/90000 (45%)]	Loss: 6.0676	Cost: 12.35s
Train Epoch: 450 [61440/90000 (68%)]	Loss: 5.8324	Cost: 10.97s
Train Epoch: 450 [81920/90000 (91%)]	Loss: 6.1597	Cost: 6.27s
Train Epoch: 450 	Average Loss: 6.0448
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0109

Learning rate: 9.950118288582781e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 451 [0/90000 (0%)]	Loss: 6.9239	Cost: 27.83s
Train Epoch: 451 [20480/90000 (23%)]	Loss: 5.8673	Cost: 9.49s
Train Epoch: 451 [40960/90000 (45%)]	Loss: 6.0242	Cost: 6.42s
Train Epoch: 451 [61440/90000 (68%)]	Loss: 5.9243	Cost: 7.41s
Train Epoch: 451 [81920/90000 (91%)]	Loss: 5.8777	Cost: 9.06s
Train Epoch: 451 	Average Loss: 6.0171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9066

Saving model as e451_model.pt & e451_waveforms_supplementary.hdf5
Learning rate: 9.949896717170309e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 452 [0/90000 (0%)]	Loss: 6.8030	Cost: 26.29s
Train Epoch: 452 [20480/90000 (23%)]	Loss: 5.8000	Cost: 9.41s
Train Epoch: 452 [40960/90000 (45%)]	Loss: 5.9248	Cost: 9.51s
Train Epoch: 452 [61440/90000 (68%)]	Loss: 5.8968	Cost: 8.69s
Train Epoch: 452 [81920/90000 (91%)]	Loss: 6.0728	Cost: 8.55s
Train Epoch: 452 	Average Loss: 6.0046
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9275

Learning rate: 9.949674657222618e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 453 [0/90000 (0%)]	Loss: 6.8602	Cost: 31.51s
Train Epoch: 453 [20480/90000 (23%)]	Loss: 5.7798	Cost: 8.87s
Train Epoch: 453 [40960/90000 (45%)]	Loss: 5.9902	Cost: 9.13s
Train Epoch: 453 [61440/90000 (68%)]	Loss: 5.8807	Cost: 6.54s
Train Epoch: 453 [81920/90000 (91%)]	Loss: 5.8730	Cost: 6.93s
Train Epoch: 453 	Average Loss: 5.9661
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8503

Saving model as e453_model.pt & e453_waveforms_supplementary.hdf5
Learning rate: 9.949452108761622e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 454 [0/90000 (0%)]	Loss: 6.7550	Cost: 18.97s
Train Epoch: 454 [20480/90000 (23%)]	Loss: 5.9281	Cost: 8.53s
Train Epoch: 454 [40960/90000 (45%)]	Loss: 5.8023	Cost: 11.15s
Train Epoch: 454 [61440/90000 (68%)]	Loss: 5.8165	Cost: 12.83s
Train Epoch: 454 [81920/90000 (91%)]	Loss: 5.8913	Cost: 12.69s
Train Epoch: 454 	Average Loss: 5.9506
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8656

Learning rate: 9.949229071809287e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 455 [0/90000 (0%)]	Loss: 6.7400	Cost: 22.93s
Train Epoch: 455 [20480/90000 (23%)]	Loss: 5.8993	Cost: 12.15s
Train Epoch: 455 [40960/90000 (45%)]	Loss: 5.8617	Cost: 12.50s
Train Epoch: 455 [61440/90000 (68%)]	Loss: 5.9413	Cost: 12.45s
Train Epoch: 455 [81920/90000 (91%)]	Loss: 6.0272	Cost: 12.47s
Train Epoch: 455 	Average Loss: 5.9382
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8413

Saving model as e455_model.pt & e455_waveforms_supplementary.hdf5
Learning rate: 9.949005546387625e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 456 [0/90000 (0%)]	Loss: 6.5885	Cost: 23.61s
Train Epoch: 456 [20480/90000 (23%)]	Loss: 5.8427	Cost: 13.52s
Train Epoch: 456 [40960/90000 (45%)]	Loss: 5.8990	Cost: 12.48s
Train Epoch: 456 [61440/90000 (68%)]	Loss: 5.8807	Cost: 11.30s
Train Epoch: 456 [81920/90000 (91%)]	Loss: 5.9626	Cost: 5.99s
Train Epoch: 456 	Average Loss: 5.9319
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8883

Learning rate: 9.9487815325187e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 457 [0/90000 (0%)]	Loss: 6.8549	Cost: 31.61s
Train Epoch: 457 [20480/90000 (23%)]	Loss: 5.8716	Cost: 13.43s
Train Epoch: 457 [40960/90000 (45%)]	Loss: 5.7263	Cost: 9.21s
Train Epoch: 457 [61440/90000 (68%)]	Loss: 5.9152	Cost: 6.17s
Train Epoch: 457 [81920/90000 (91%)]	Loss: 5.8124	Cost: 7.74s
Train Epoch: 457 	Average Loss: 5.8997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8358

Saving model as e457_model.pt & e457_waveforms_supplementary.hdf5
Learning rate: 9.948557030224616e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 458 [0/90000 (0%)]	Loss: 6.9219	Cost: 25.36s
Train Epoch: 458 [20480/90000 (23%)]	Loss: 5.8180	Cost: 8.08s
Train Epoch: 458 [40960/90000 (45%)]	Loss: 5.7926	Cost: 8.27s
Train Epoch: 458 [61440/90000 (68%)]	Loss: 5.9250	Cost: 8.79s
Train Epoch: 458 [81920/90000 (91%)]	Loss: 5.8021	Cost: 8.71s
Train Epoch: 458 	Average Loss: 5.8937
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8448

Learning rate: 9.948332039527536e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 459 [0/90000 (0%)]	Loss: 6.7563	Cost: 22.07s
Train Epoch: 459 [20480/90000 (23%)]	Loss: 5.7691	Cost: 8.99s
Train Epoch: 459 [40960/90000 (45%)]	Loss: 5.8823	Cost: 9.23s
Train Epoch: 459 [61440/90000 (68%)]	Loss: 5.7880	Cost: 8.67s
Train Epoch: 459 [81920/90000 (91%)]	Loss: 5.8671	Cost: 8.74s
Train Epoch: 459 	Average Loss: 5.8937
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8563

Learning rate: 9.948106560449663e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 460 [0/90000 (0%)]	Loss: 6.7181	Cost: 21.23s
Train Epoch: 460 [20480/90000 (23%)]	Loss: 5.7743	Cost: 8.96s
Train Epoch: 460 [40960/90000 (45%)]	Loss: 5.8741	Cost: 9.11s
Train Epoch: 460 [61440/90000 (68%)]	Loss: 5.6836	Cost: 7.09s
Train Epoch: 460 [81920/90000 (91%)]	Loss: 5.8081	Cost: 7.69s
Train Epoch: 460 	Average Loss: 5.8597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8474

Learning rate: 9.947880593013248e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 461 [0/90000 (0%)]	Loss: 6.8828	Cost: 19.79s
Train Epoch: 461 [20480/90000 (23%)]	Loss: 5.8149	Cost: 9.34s
Train Epoch: 461 [40960/90000 (45%)]	Loss: 5.8209	Cost: 12.09s
Train Epoch: 461 [61440/90000 (68%)]	Loss: 5.9081	Cost: 13.09s
Train Epoch: 461 [81920/90000 (91%)]	Loss: 5.7804	Cost: 12.40s
Train Epoch: 461 	Average Loss: 5.8752
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8575

Learning rate: 9.9476541372406e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 462 [0/90000 (0%)]	Loss: 6.8521	Cost: 24.68s
Train Epoch: 462 [20480/90000 (23%)]	Loss: 5.6902	Cost: 10.75s
Train Epoch: 462 [40960/90000 (45%)]	Loss: 5.8132	Cost: 15.15s
Train Epoch: 462 [61440/90000 (68%)]	Loss: 5.8525	Cost: 12.67s
Train Epoch: 462 [81920/90000 (91%)]	Loss: 5.7269	Cost: 12.29s
Train Epoch: 462 	Average Loss: 5.8353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8260

Saving model as e462_model.pt & e462_waveforms_supplementary.hdf5
Learning rate: 9.947427193154066e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 463 [0/90000 (0%)]	Loss: 6.8944	Cost: 42.63s
Train Epoch: 463 [20480/90000 (23%)]	Loss: 5.7313	Cost: 12.67s
Train Epoch: 463 [40960/90000 (45%)]	Loss: 5.8301	Cost: 12.36s
Train Epoch: 463 [61440/90000 (68%)]	Loss: 5.7882	Cost: 9.93s
Train Epoch: 463 [81920/90000 (91%)]	Loss: 5.8036	Cost: 6.24s
Train Epoch: 463 	Average Loss: 5.8385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7959

Saving model as e463_model.pt & e463_waveforms_supplementary.hdf5
Learning rate: 9.947199760776042e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 464 [0/90000 (0%)]	Loss: 6.9326	Cost: 21.49s
Train Epoch: 464 [20480/90000 (23%)]	Loss: 5.7228	Cost: 9.01s
Train Epoch: 464 [40960/90000 (45%)]	Loss: 5.8463	Cost: 6.41s
Train Epoch: 464 [61440/90000 (68%)]	Loss: 5.7670	Cost: 7.28s
Train Epoch: 464 [81920/90000 (91%)]	Loss: 5.8812	Cost: 10.25s
Train Epoch: 464 	Average Loss: 5.8161
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7919

Saving model as e464_model.pt & e464_waveforms_supplementary.hdf5
Learning rate: 9.946971840128976e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 465 [0/90000 (0%)]	Loss: 6.6896	Cost: 21.58s
Train Epoch: 465 [20480/90000 (23%)]	Loss: 5.7323	Cost: 7.69s
Train Epoch: 465 [40960/90000 (45%)]	Loss: 5.7535	Cost: 9.46s
Train Epoch: 465 [61440/90000 (68%)]	Loss: 5.6168	Cost: 9.48s
Train Epoch: 465 [81920/90000 (91%)]	Loss: 5.8309	Cost: 9.07s
Train Epoch: 465 	Average Loss: 5.8013
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7771

Saving model as e465_model.pt & e465_waveforms_supplementary.hdf5
Learning rate: 9.946743431235365e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 466 [0/90000 (0%)]	Loss: 6.8445	Cost: 21.16s
Train Epoch: 466 [20480/90000 (23%)]	Loss: 5.6180	Cost: 8.23s
Train Epoch: 466 [40960/90000 (45%)]	Loss: 5.6934	Cost: 7.61s
Train Epoch: 466 [61440/90000 (68%)]	Loss: 5.5928	Cost: 9.79s
Train Epoch: 466 [81920/90000 (91%)]	Loss: 5.7247	Cost: 12.94s
Train Epoch: 466 	Average Loss: 5.7645
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8047

Learning rate: 9.94651453411775e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 467 [0/90000 (0%)]	Loss: 6.7700	Cost: 24.81s
Train Epoch: 467 [20480/90000 (23%)]	Loss: 5.6984	Cost: 8.19s
Train Epoch: 467 [40960/90000 (45%)]	Loss: 5.8475	Cost: 12.69s
Train Epoch: 467 [61440/90000 (68%)]	Loss: 5.7523	Cost: 12.50s
Train Epoch: 467 [81920/90000 (91%)]	Loss: 5.8323	Cost: 11.91s
Train Epoch: 467 	Average Loss: 5.7744
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7544

Saving model as e467_model.pt & e467_waveforms_supplementary.hdf5
Learning rate: 9.946285148798723e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 468 [0/90000 (0%)]	Loss: 6.6130	Cost: 26.03s
Train Epoch: 468 [20480/90000 (23%)]	Loss: 5.8378	Cost: 12.26s
Train Epoch: 468 [40960/90000 (45%)]	Loss: 5.7368	Cost: 12.42s
Train Epoch: 468 [61440/90000 (68%)]	Loss: 5.7290	Cost: 12.43s
Train Epoch: 468 [81920/90000 (91%)]	Loss: 5.6135	Cost: 7.84s
Train Epoch: 468 	Average Loss: 5.7579
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7963

Learning rate: 9.946055275300923e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 469 [0/90000 (0%)]	Loss: 6.6869	Cost: 29.65s
Train Epoch: 469 [20480/90000 (23%)]	Loss: 5.6222	Cost: 12.56s
Train Epoch: 469 [40960/90000 (45%)]	Loss: 5.6859	Cost: 13.64s
Train Epoch: 469 [61440/90000 (68%)]	Loss: 5.6525	Cost: 11.63s
Train Epoch: 469 [81920/90000 (91%)]	Loss: 5.8291	Cost: 6.22s
Train Epoch: 469 	Average Loss: 5.7740
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7555

Learning rate: 9.945824913647039e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 470 [0/90000 (0%)]	Loss: 6.5853	Cost: 25.13s
Train Epoch: 470 [20480/90000 (23%)]	Loss: 5.5714	Cost: 12.61s
Train Epoch: 470 [40960/90000 (45%)]	Loss: 5.7591	Cost: 12.97s
Train Epoch: 470 [61440/90000 (68%)]	Loss: 5.6809	Cost: 10.21s
Train Epoch: 470 [81920/90000 (91%)]	Loss: 5.6346	Cost: 8.20s
Train Epoch: 470 	Average Loss: 5.7289
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7667

Learning rate: 9.945594063859803e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 471 [0/90000 (0%)]	Loss: 6.6760	Cost: 24.26s
Train Epoch: 471 [20480/90000 (23%)]	Loss: 5.7059	Cost: 9.54s
Train Epoch: 471 [40960/90000 (45%)]	Loss: 5.5326	Cost: 7.18s
Train Epoch: 471 [61440/90000 (68%)]	Loss: 5.6310	Cost: 7.70s
Train Epoch: 471 [81920/90000 (91%)]	Loss: 5.7343	Cost: 8.81s
Train Epoch: 471 	Average Loss: 5.7027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6879

Saving model as e471_model.pt & e471_waveforms_supplementary.hdf5
Learning rate: 9.945362725962006e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 472 [0/90000 (0%)]	Loss: 6.6213	Cost: 24.67s
Train Epoch: 472 [20480/90000 (23%)]	Loss: 5.6213	Cost: 7.61s
Train Epoch: 472 [40960/90000 (45%)]	Loss: 5.7231	Cost: 9.46s
Train Epoch: 472 [61440/90000 (68%)]	Loss: 5.6300	Cost: 8.76s
Train Epoch: 472 [81920/90000 (91%)]	Loss: 5.6052	Cost: 8.58s
Train Epoch: 472 	Average Loss: 5.7111
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7380

Learning rate: 9.945130899976472e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 473 [0/90000 (0%)]	Loss: 6.8991	Cost: 28.74s
Train Epoch: 473 [20480/90000 (23%)]	Loss: 5.6022	Cost: 8.24s
Train Epoch: 473 [40960/90000 (45%)]	Loss: 5.6000	Cost: 8.92s
Train Epoch: 473 [61440/90000 (68%)]	Loss: 5.5187	Cost: 8.65s
Train Epoch: 473 [81920/90000 (91%)]	Loss: 5.7495	Cost: 8.64s
Train Epoch: 473 	Average Loss: 5.6844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7288

Learning rate: 9.944898585926086e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 474 [0/90000 (0%)]	Loss: 6.4995	Cost: 27.62s
Train Epoch: 474 [20480/90000 (23%)]	Loss: 5.5893	Cost: 6.55s
Train Epoch: 474 [40960/90000 (45%)]	Loss: 5.7039	Cost: 7.03s
Train Epoch: 474 [61440/90000 (68%)]	Loss: 5.6978	Cost: 8.65s
Train Epoch: 474 [81920/90000 (91%)]	Loss: 5.6199	Cost: 13.53s
Train Epoch: 474 	Average Loss: 5.7134
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6851

Saving model as e474_model.pt & e474_waveforms_supplementary.hdf5
Learning rate: 9.944665783833775e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 475 [0/90000 (0%)]	Loss: 6.4750	Cost: 21.52s
Train Epoch: 475 [20480/90000 (23%)]	Loss: 5.4580	Cost: 9.91s
Train Epoch: 475 [40960/90000 (45%)]	Loss: 5.6227	Cost: 12.68s
Train Epoch: 475 [61440/90000 (68%)]	Loss: 5.4918	Cost: 14.51s
Train Epoch: 475 [81920/90000 (91%)]	Loss: 5.8464	Cost: 12.96s
Train Epoch: 475 	Average Loss: 5.6422
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7481

Learning rate: 9.944432493722518e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 476 [0/90000 (0%)]	Loss: 6.5370	Cost: 27.95s
Train Epoch: 476 [20480/90000 (23%)]	Loss: 5.6971	Cost: 16.04s
Train Epoch: 476 [40960/90000 (45%)]	Loss: 5.6144	Cost: 14.62s
Train Epoch: 476 [61440/90000 (68%)]	Loss: 5.4760	Cost: 12.28s
Train Epoch: 476 [81920/90000 (91%)]	Loss: 5.5494	Cost: 12.26s
Train Epoch: 476 	Average Loss: 5.6517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6854

Learning rate: 9.944198715615337e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 477 [0/90000 (0%)]	Loss: 6.6196	Cost: 32.77s
Train Epoch: 477 [20480/90000 (23%)]	Loss: 5.4493	Cost: 10.73s
Train Epoch: 477 [40960/90000 (45%)]	Loss: 5.5791	Cost: 12.42s
Train Epoch: 477 [61440/90000 (68%)]	Loss: 5.5678	Cost: 12.30s
Train Epoch: 477 [81920/90000 (91%)]	Loss: 5.6452	Cost: 7.89s
Train Epoch: 477 	Average Loss: 5.6072
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6731

Saving model as e477_model.pt & e477_waveforms_supplementary.hdf5
Learning rate: 9.943964449535306e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 478 [0/90000 (0%)]	Loss: 6.5443	Cost: 23.38s
Train Epoch: 478 [20480/90000 (23%)]	Loss: 5.5038	Cost: 12.70s
Train Epoch: 478 [40960/90000 (45%)]	Loss: 5.6749	Cost: 6.85s
Train Epoch: 478 [61440/90000 (68%)]	Loss: 5.4660	Cost: 6.16s
Train Epoch: 478 [81920/90000 (91%)]	Loss: 5.4635	Cost: 8.51s
Train Epoch: 478 	Average Loss: 5.6026
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6899

Learning rate: 9.943729695505547e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 479 [0/90000 (0%)]	Loss: 6.5446	Cost: 19.72s
Train Epoch: 479 [20480/90000 (23%)]	Loss: 5.4535	Cost: 7.86s
Train Epoch: 479 [40960/90000 (45%)]	Loss: 5.5948	Cost: 9.04s
Train Epoch: 479 [61440/90000 (68%)]	Loss: 5.5316	Cost: 9.00s
Train Epoch: 479 [81920/90000 (91%)]	Loss: 5.5944	Cost: 8.72s
Train Epoch: 479 	Average Loss: 5.5658
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6346

Saving model as e479_model.pt & e479_waveforms_supplementary.hdf5
Learning rate: 9.943494453549226e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 480 [0/90000 (0%)]	Loss: 6.6346	Cost: 25.84s
Train Epoch: 480 [20480/90000 (23%)]	Loss: 5.3683	Cost: 8.93s
Train Epoch: 480 [40960/90000 (45%)]	Loss: 5.5238	Cost: 7.13s
Train Epoch: 480 [61440/90000 (68%)]	Loss: 5.3966	Cost: 6.34s
Train Epoch: 480 [81920/90000 (91%)]	Loss: 5.6255	Cost: 6.54s
Train Epoch: 480 	Average Loss: 5.5687
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7369

Learning rate: 9.943258723689565e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 481 [0/90000 (0%)]	Loss: 6.7641	Cost: 24.88s
Train Epoch: 481 [20480/90000 (23%)]	Loss: 5.6246	Cost: 8.17s
Train Epoch: 481 [40960/90000 (45%)]	Loss: 5.4889	Cost: 10.20s
Train Epoch: 481 [61440/90000 (68%)]	Loss: 5.5199	Cost: 12.82s
Train Epoch: 481 [81920/90000 (91%)]	Loss: 5.4171	Cost: 12.58s
Train Epoch: 481 	Average Loss: 5.6186
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6877

Learning rate: 9.943022505949827e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 482 [0/90000 (0%)]	Loss: 6.5593	Cost: 21.49s
Train Epoch: 482 [20480/90000 (23%)]	Loss: 5.3089	Cost: 7.65s
Train Epoch: 482 [40960/90000 (45%)]	Loss: 5.5545	Cost: 13.91s
Train Epoch: 482 [61440/90000 (68%)]	Loss: 5.4746	Cost: 12.59s
Train Epoch: 482 [81920/90000 (91%)]	Loss: 5.4103	Cost: 12.44s
Train Epoch: 482 	Average Loss: 5.5544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7079

Learning rate: 9.942785800353326e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 483 [0/90000 (0%)]	Loss: 6.7078	Cost: 33.80s
Train Epoch: 483 [20480/90000 (23%)]	Loss: 5.4959	Cost: 12.25s
Train Epoch: 483 [40960/90000 (45%)]	Loss: 5.5060	Cost: 12.32s
Train Epoch: 483 [61440/90000 (68%)]	Loss: 5.4540	Cost: 12.31s
Train Epoch: 483 [81920/90000 (91%)]	Loss: 5.5017	Cost: 7.13s
Train Epoch: 483 	Average Loss: 5.5497
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6284

Saving model as e483_model.pt & e483_waveforms_supplementary.hdf5
Learning rate: 9.942548606923424e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 484 [0/90000 (0%)]	Loss: 6.8635	Cost: 23.75s
Train Epoch: 484 [20480/90000 (23%)]	Loss: 5.5411	Cost: 12.16s
Train Epoch: 484 [40960/90000 (45%)]	Loss: 5.5359	Cost: 7.61s
Train Epoch: 484 [61440/90000 (68%)]	Loss: 5.3942	Cost: 6.35s
Train Epoch: 484 [81920/90000 (91%)]	Loss: 5.4992	Cost: 7.87s
Train Epoch: 484 	Average Loss: 5.5352
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6616

Learning rate: 9.942310925683532e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 485 [0/90000 (0%)]	Loss: 6.6079	Cost: 30.46s
Train Epoch: 485 [20480/90000 (23%)]	Loss: 5.4256	Cost: 9.48s
Train Epoch: 485 [40960/90000 (45%)]	Loss: 5.4245	Cost: 8.48s
Train Epoch: 485 [61440/90000 (68%)]	Loss: 5.4327	Cost: 8.59s
Train Epoch: 485 [81920/90000 (91%)]	Loss: 5.4930	Cost: 8.41s
Train Epoch: 485 	Average Loss: 5.5203
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5737

Saving model as e485_model.pt & e485_waveforms_supplementary.hdf5
Learning rate: 9.942072756657107e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 486 [0/90000 (0%)]	Loss: 6.5319	Cost: 27.09s
Train Epoch: 486 [20480/90000 (23%)]	Loss: 5.5152	Cost: 9.00s
Train Epoch: 486 [40960/90000 (45%)]	Loss: 5.4692	Cost: 9.07s
Train Epoch: 486 [61440/90000 (68%)]	Loss: 5.3385	Cost: 8.68s
Train Epoch: 486 [81920/90000 (91%)]	Loss: 5.4817	Cost: 7.94s
Train Epoch: 486 	Average Loss: 5.4915
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5181

Saving model as e486_model.pt & e486_waveforms_supplementary.hdf5
Learning rate: 9.941834099867654e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 487 [0/90000 (0%)]	Loss: 6.3630	Cost: 20.45s
Train Epoch: 487 [20480/90000 (23%)]	Loss: 5.4556	Cost: 8.27s
Train Epoch: 487 [40960/90000 (45%)]	Loss: 5.3156	Cost: 13.62s
Train Epoch: 487 [61440/90000 (68%)]	Loss: 5.3769	Cost: 13.08s
Train Epoch: 487 [81920/90000 (91%)]	Loss: 5.5406	Cost: 13.87s
Train Epoch: 487 	Average Loss: 5.4626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5892

Learning rate: 9.941594955338732e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 488 [0/90000 (0%)]	Loss: 6.4556	Cost: 23.13s
Train Epoch: 488 [20480/90000 (23%)]	Loss: 5.3123	Cost: 8.30s
Train Epoch: 488 [40960/90000 (45%)]	Loss: 5.5122	Cost: 14.44s
Train Epoch: 488 [61440/90000 (68%)]	Loss: 5.2956	Cost: 13.15s
Train Epoch: 488 [81920/90000 (91%)]	Loss: 5.6483	Cost: 12.22s
Train Epoch: 488 	Average Loss: 5.4625
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6340

Learning rate: 9.941355323093938e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 489 [0/90000 (0%)]	Loss: 6.6184	Cost: 43.58s
Train Epoch: 489 [20480/90000 (23%)]	Loss: 5.2894	Cost: 12.33s
Train Epoch: 489 [40960/90000 (45%)]	Loss: 5.3840	Cost: 12.18s
Train Epoch: 489 [61440/90000 (68%)]	Loss: 5.4319	Cost: 10.13s
Train Epoch: 489 [81920/90000 (91%)]	Loss: 5.5946	Cost: 6.43s
Train Epoch: 489 	Average Loss: 5.4790
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5542

Learning rate: 9.941115203156927e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 490 [0/90000 (0%)]	Loss: 6.5107	Cost: 29.43s
Train Epoch: 490 [20480/90000 (23%)]	Loss: 5.6625	Cost: 12.23s
Train Epoch: 490 [40960/90000 (45%)]	Loss: 5.4743	Cost: 6.47s
Train Epoch: 490 [61440/90000 (68%)]	Loss: 5.4998	Cost: 6.62s
Train Epoch: 490 [81920/90000 (91%)]	Loss: 5.3966	Cost: 8.37s
Train Epoch: 490 	Average Loss: 5.5072
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5361

Learning rate: 9.940874595551397e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 491 [0/90000 (0%)]	Loss: 6.7098	Cost: 22.88s
Train Epoch: 491 [20480/90000 (23%)]	Loss: 5.2926	Cost: 6.71s
Train Epoch: 491 [40960/90000 (45%)]	Loss: 5.2721	Cost: 10.14s
Train Epoch: 491 [61440/90000 (68%)]	Loss: 5.1835	Cost: 8.71s
Train Epoch: 491 [81920/90000 (91%)]	Loss: 5.4914	Cost: 8.52s
Train Epoch: 491 	Average Loss: 5.4370
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5976

Learning rate: 9.940633500301093e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 492 [0/90000 (0%)]	Loss: 6.3810	Cost: 21.82s
Train Epoch: 492 [20480/90000 (23%)]	Loss: 5.1960	Cost: 9.18s
Train Epoch: 492 [40960/90000 (45%)]	Loss: 5.3343	Cost: 8.64s
Train Epoch: 492 [61440/90000 (68%)]	Loss: 5.2073	Cost: 6.60s
Train Epoch: 492 [81920/90000 (91%)]	Loss: 5.5210	Cost: 7.93s
Train Epoch: 492 	Average Loss: 5.4056
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5282

Learning rate: 9.940391917429813e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 493 [0/90000 (0%)]	Loss: 6.4812	Cost: 23.14s
Train Epoch: 493 [20480/90000 (23%)]	Loss: 5.3322	Cost: 10.19s
Train Epoch: 493 [40960/90000 (45%)]	Loss: 5.5190	Cost: 12.48s
Train Epoch: 493 [61440/90000 (68%)]	Loss: 5.2681	Cost: 12.66s
Train Epoch: 493 [81920/90000 (91%)]	Loss: 5.3907	Cost: 12.15s
Train Epoch: 493 	Average Loss: 5.4276
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5489

Learning rate: 9.9401498469614e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 494 [0/90000 (0%)]	Loss: 6.5558	Cost: 28.32s
Train Epoch: 494 [20480/90000 (23%)]	Loss: 5.2793	Cost: 13.52s
Train Epoch: 494 [40960/90000 (45%)]	Loss: 5.4034	Cost: 13.85s
Train Epoch: 494 [61440/90000 (68%)]	Loss: 5.2370	Cost: 12.49s
Train Epoch: 494 [81920/90000 (91%)]	Loss: 5.3569	Cost: 12.26s
Train Epoch: 494 	Average Loss: 5.3892
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4767

Saving model as e494_model.pt & e494_waveforms_supplementary.hdf5
Learning rate: 9.93990728891974e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 495 [0/90000 (0%)]	Loss: 6.5111	Cost: 29.52s
Train Epoch: 495 [20480/90000 (23%)]	Loss: 5.2549	Cost: 12.63s
Train Epoch: 495 [40960/90000 (45%)]	Loss: 5.3997	Cost: 12.41s
Train Epoch: 495 [61440/90000 (68%)]	Loss: 5.2294	Cost: 9.90s
Train Epoch: 495 [81920/90000 (91%)]	Loss: 5.3930	Cost: 8.81s
Train Epoch: 495 	Average Loss: 5.3607
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4837

Learning rate: 9.939664243328781e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 496 [0/90000 (0%)]	Loss: 6.4676	Cost: 23.52s
Train Epoch: 496 [20480/90000 (23%)]	Loss: 5.3483	Cost: 6.62s
Train Epoch: 496 [40960/90000 (45%)]	Loss: 5.1763	Cost: 7.47s
Train Epoch: 496 [61440/90000 (68%)]	Loss: 5.1589	Cost: 8.40s
Train Epoch: 496 [81920/90000 (91%)]	Loss: 5.4462	Cost: 9.22s
Train Epoch: 496 	Average Loss: 5.3759
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5298

Learning rate: 9.939420710212505e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 497 [0/90000 (0%)]	Loss: 6.5987	Cost: 20.32s
Train Epoch: 497 [20480/90000 (23%)]	Loss: 5.4063	Cost: 8.96s
Train Epoch: 497 [40960/90000 (45%)]	Loss: 5.3286	Cost: 9.08s
Train Epoch: 497 [61440/90000 (68%)]	Loss: 5.1909	Cost: 8.79s
Train Epoch: 497 [81920/90000 (91%)]	Loss: 5.4233	Cost: 8.65s
Train Epoch: 497 	Average Loss: 5.3999
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5909

Learning rate: 9.939176689594949e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 498 [0/90000 (0%)]	Loss: 6.4429	Cost: 32.35s
Train Epoch: 498 [20480/90000 (23%)]	Loss: 5.2145	Cost: 8.83s
Train Epoch: 498 [40960/90000 (45%)]	Loss: 5.3236	Cost: 6.90s
Train Epoch: 498 [61440/90000 (68%)]	Loss: 5.2428	Cost: 6.55s
Train Epoch: 498 [81920/90000 (91%)]	Loss: 5.4054	Cost: 6.38s
Train Epoch: 498 	Average Loss: 5.3477
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5435

Learning rate: 9.938932181500198e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 499 [0/90000 (0%)]	Loss: 6.3613	Cost: 22.30s
Train Epoch: 499 [20480/90000 (23%)]	Loss: 5.3242	Cost: 7.22s
Train Epoch: 499 [40960/90000 (45%)]	Loss: 5.1946	Cost: 12.75s
Train Epoch: 499 [61440/90000 (68%)]	Loss: 5.2087	Cost: 11.57s
Train Epoch: 499 [81920/90000 (91%)]	Loss: 5.3625	Cost: 12.45s
Train Epoch: 499 	Average Loss: 5.3144
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4595

Saving model as e499_model.pt & e499_waveforms_supplementary.hdf5
Learning rate: 9.938687185952383e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 500 [0/90000 (0%)]	Loss: 6.3927	Cost: 21.44s
Train Epoch: 500 [20480/90000 (23%)]	Loss: 5.2439	Cost: 13.89s
Train Epoch: 500 [40960/90000 (45%)]	Loss: 5.1211	Cost: 13.88s
Train Epoch: 500 [61440/90000 (68%)]	Loss: 5.1281	Cost: 12.54s
Train Epoch: 500 [81920/90000 (91%)]	Loss: 5.2926	Cost: 12.41s
Train Epoch: 500 	Average Loss: 5.2884
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5409

Learning rate: 9.938441702975683e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 501 [0/90000 (0%)]	Loss: 6.2773	Cost: 24.20s
Train Epoch: 501 [20480/90000 (23%)]	Loss: 5.2195	Cost: 10.32s
Train Epoch: 501 [40960/90000 (45%)]	Loss: 5.2758	Cost: 12.60s
Train Epoch: 501 [61440/90000 (68%)]	Loss: 5.2017	Cost: 12.53s
Train Epoch: 501 [81920/90000 (91%)]	Loss: 5.2683	Cost: 7.52s
Train Epoch: 501 	Average Loss: 5.2955
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4430

Saving model as e501_model.pt & e501_waveforms_supplementary.hdf5
Learning rate: 9.938195732594328e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 502 [0/90000 (0%)]	Loss: 6.5000	Cost: 23.20s
Train Epoch: 502 [20480/90000 (23%)]	Loss: 5.3323	Cost: 12.06s
Train Epoch: 502 [40960/90000 (45%)]	Loss: 5.2923	Cost: 8.79s
Train Epoch: 502 [61440/90000 (68%)]	Loss: 5.1547	Cost: 6.41s
Train Epoch: 502 [81920/90000 (91%)]	Loss: 5.4467	Cost: 7.38s
Train Epoch: 502 	Average Loss: 5.3277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4243

Saving model as e502_model.pt & e502_waveforms_supplementary.hdf5
Learning rate: 9.937949274832593e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 503 [0/90000 (0%)]	Loss: 6.6284	Cost: 27.18s
Train Epoch: 503 [20480/90000 (23%)]	Loss: 5.2805	Cost: 11.96s
Train Epoch: 503 [40960/90000 (45%)]	Loss: 5.3080	Cost: 8.77s
Train Epoch: 503 [61440/90000 (68%)]	Loss: 4.9853	Cost: 6.35s
Train Epoch: 503 [81920/90000 (91%)]	Loss: 5.2594	Cost: 8.39s
Train Epoch: 503 	Average Loss: 5.2693
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4428

Learning rate: 9.937702329714805e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 504 [0/90000 (0%)]	Loss: 6.3178	Cost: 22.79s
Train Epoch: 504 [20480/90000 (23%)]	Loss: 5.1225	Cost: 11.96s
Train Epoch: 504 [40960/90000 (45%)]	Loss: 5.1946	Cost: 10.72s
Train Epoch: 504 [61440/90000 (68%)]	Loss: 5.3037	Cost: 7.28s
Train Epoch: 504 [81920/90000 (91%)]	Loss: 5.3902	Cost: 7.16s
Train Epoch: 504 	Average Loss: 5.2478
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4789

Learning rate: 9.937454897265332e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 505 [0/90000 (0%)]	Loss: 6.3209	Cost: 22.55s
Train Epoch: 505 [20480/90000 (23%)]	Loss: 5.0570	Cost: 8.63s
Train Epoch: 505 [40960/90000 (45%)]	Loss: 5.1613	Cost: 8.10s
Train Epoch: 505 [61440/90000 (68%)]	Loss: 5.1198	Cost: 8.69s
Train Epoch: 505 [81920/90000 (91%)]	Loss: 5.1221	Cost: 8.44s
Train Epoch: 505 	Average Loss: 5.2260
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4148

Saving model as e505_model.pt & e505_waveforms_supplementary.hdf5
Learning rate: 9.937206977508597e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 506 [0/90000 (0%)]	Loss: 6.3899	Cost: 27.02s
Train Epoch: 506 [20480/90000 (23%)]	Loss: 5.0701	Cost: 8.74s
Train Epoch: 506 [40960/90000 (45%)]	Loss: 5.1194	Cost: 8.87s
Train Epoch: 506 [61440/90000 (68%)]	Loss: 5.2163	Cost: 8.74s
Train Epoch: 506 [81920/90000 (91%)]	Loss: 5.0592	Cost: 8.64s
Train Epoch: 506 	Average Loss: 5.1824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4216

Learning rate: 9.936958570469071e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 507 [0/90000 (0%)]	Loss: 6.2899	Cost: 24.23s
Train Epoch: 507 [20480/90000 (23%)]	Loss: 5.1160	Cost: 8.81s
Train Epoch: 507 [40960/90000 (45%)]	Loss: 5.0586	Cost: 8.99s
Train Epoch: 507 [61440/90000 (68%)]	Loss: 5.1134	Cost: 8.55s
Train Epoch: 507 [81920/90000 (91%)]	Loss: 5.0966	Cost: 8.78s
Train Epoch: 507 	Average Loss: 5.2105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4071

Saving model as e507_model.pt & e507_waveforms_supplementary.hdf5
Learning rate: 9.936709676171268e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 508 [0/90000 (0%)]	Loss: 6.2912	Cost: 22.16s
Train Epoch: 508 [20480/90000 (23%)]	Loss: 5.0224	Cost: 10.35s
Train Epoch: 508 [40960/90000 (45%)]	Loss: 5.4035	Cost: 10.66s
Train Epoch: 508 [61440/90000 (68%)]	Loss: 5.2701	Cost: 11.98s
Train Epoch: 508 [81920/90000 (91%)]	Loss: 5.3129	Cost: 12.41s
Train Epoch: 508 	Average Loss: 5.3403
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4316

Learning rate: 9.936460294639754e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 509 [0/90000 (0%)]	Loss: 6.4131	Cost: 21.65s
Train Epoch: 509 [20480/90000 (23%)]	Loss: 5.1424	Cost: 10.34s
Train Epoch: 509 [40960/90000 (45%)]	Loss: 5.1929	Cost: 17.27s
Train Epoch: 509 [61440/90000 (68%)]	Loss: 5.1151	Cost: 14.11s
Train Epoch: 509 [81920/90000 (91%)]	Loss: 5.2032	Cost: 12.05s
Train Epoch: 509 	Average Loss: 5.2067
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3881

Saving model as e509_model.pt & e509_waveforms_supplementary.hdf5
Learning rate: 9.93621042589914e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 510 [0/90000 (0%)]	Loss: 6.2602	Cost: 35.82s
Train Epoch: 510 [20480/90000 (23%)]	Loss: 5.1439	Cost: 9.77s
Train Epoch: 510 [40960/90000 (45%)]	Loss: 5.2053	Cost: 12.35s
Train Epoch: 510 [61440/90000 (68%)]	Loss: 5.0414	Cost: 12.60s
Train Epoch: 510 [81920/90000 (91%)]	Loss: 5.2399	Cost: 7.71s
Train Epoch: 510 	Average Loss: 5.1701
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3552

Saving model as e510_model.pt & e510_waveforms_supplementary.hdf5
Learning rate: 9.935960069974091e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 511 [0/90000 (0%)]	Loss: 6.1043	Cost: 23.84s
Train Epoch: 511 [20480/90000 (23%)]	Loss: 5.1710	Cost: 10.27s
Train Epoch: 511 [40960/90000 (45%)]	Loss: 5.1147	Cost: 9.86s
Train Epoch: 511 [61440/90000 (68%)]	Loss: 5.0439	Cost: 6.03s
Train Epoch: 511 [81920/90000 (91%)]	Loss: 5.0961	Cost: 7.33s
Train Epoch: 511 	Average Loss: 5.1344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3575

Learning rate: 9.935709226889313e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 512 [0/90000 (0%)]	Loss: 6.7352	Cost: 25.94s
Train Epoch: 512 [20480/90000 (23%)]	Loss: 5.0280	Cost: 9.92s
Train Epoch: 512 [40960/90000 (45%)]	Loss: 5.0907	Cost: 11.47s
Train Epoch: 512 [61440/90000 (68%)]	Loss: 5.1482	Cost: 6.13s
Train Epoch: 512 [81920/90000 (91%)]	Loss: 5.2267	Cost: 7.01s
Train Epoch: 512 	Average Loss: 5.1444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4107

Learning rate: 9.935457896669563e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 513 [0/90000 (0%)]	Loss: 6.3334	Cost: 23.33s
Train Epoch: 513 [20480/90000 (23%)]	Loss: 5.0543	Cost: 8.26s
Train Epoch: 513 [40960/90000 (45%)]	Loss: 4.9822	Cost: 9.16s
Train Epoch: 513 [61440/90000 (68%)]	Loss: 4.9280	Cost: 9.47s
Train Epoch: 513 [81920/90000 (91%)]	Loss: 5.1616	Cost: 9.09s
Train Epoch: 513 	Average Loss: 5.1220
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3444

Saving model as e513_model.pt & e513_waveforms_supplementary.hdf5
Learning rate: 9.935206079339646e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 514 [0/90000 (0%)]	Loss: 6.4172	Cost: 21.06s
Train Epoch: 514 [20480/90000 (23%)]	Loss: 5.1511	Cost: 10.98s
Train Epoch: 514 [40960/90000 (45%)]	Loss: 5.0593	Cost: 10.54s
Train Epoch: 514 [61440/90000 (68%)]	Loss: 4.9299	Cost: 10.19s
Train Epoch: 514 [81920/90000 (91%)]	Loss: 4.9769	Cost: 12.76s
Train Epoch: 514 	Average Loss: 5.1415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3599

Learning rate: 9.934953774924418e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 515 [0/90000 (0%)]	Loss: 6.3820	Cost: 25.99s
Train Epoch: 515 [20480/90000 (23%)]	Loss: 5.0536	Cost: 10.41s
Train Epoch: 515 [40960/90000 (45%)]	Loss: 5.1900	Cost: 15.29s
Train Epoch: 515 [61440/90000 (68%)]	Loss: 5.0162	Cost: 12.27s
Train Epoch: 515 [81920/90000 (91%)]	Loss: 5.1067	Cost: 12.18s
Train Epoch: 515 	Average Loss: 5.1344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2739

Saving model as e515_model.pt & e515_waveforms_supplementary.hdf5
Learning rate: 9.93470098344878e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 516 [0/90000 (0%)]	Loss: 6.2099	Cost: 25.43s
Train Epoch: 516 [20480/90000 (23%)]	Loss: 5.1463	Cost: 10.85s
Train Epoch: 516 [40960/90000 (45%)]	Loss: 4.9724	Cost: 12.54s
Train Epoch: 516 [61440/90000 (68%)]	Loss: 4.9408	Cost: 12.06s
Train Epoch: 516 [81920/90000 (91%)]	Loss: 5.1060	Cost: 7.38s
Train Epoch: 516 	Average Loss: 5.1042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3227

Learning rate: 9.934447704937678e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 517 [0/90000 (0%)]	Loss: 6.3229	Cost: 25.02s
Train Epoch: 517 [20480/90000 (23%)]	Loss: 5.0470	Cost: 12.18s
Train Epoch: 517 [40960/90000 (45%)]	Loss: 5.0995	Cost: 10.29s
Train Epoch: 517 [61440/90000 (68%)]	Loss: 4.9177	Cost: 6.42s
Train Epoch: 517 [81920/90000 (91%)]	Loss: 5.0699	Cost: 7.22s
Train Epoch: 517 	Average Loss: 5.0760
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2935

Learning rate: 9.934193939416114e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 518 [0/90000 (0%)]	Loss: 6.1849	Cost: 22.63s
Train Epoch: 518 [20480/90000 (23%)]	Loss: 4.9457	Cost: 10.03s
Train Epoch: 518 [40960/90000 (45%)]	Loss: 5.0721	Cost: 10.55s
Train Epoch: 518 [61440/90000 (68%)]	Loss: 4.8538	Cost: 9.19s
Train Epoch: 518 [81920/90000 (91%)]	Loss: 4.9603	Cost: 8.95s
Train Epoch: 518 	Average Loss: 5.0327
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3221

Learning rate: 9.933939686909132e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 519 [0/90000 (0%)]	Loss: 6.0547	Cost: 22.11s
Train Epoch: 519 [20480/90000 (23%)]	Loss: 4.8473	Cost: 11.72s
Train Epoch: 519 [40960/90000 (45%)]	Loss: 4.8285	Cost: 12.33s
Train Epoch: 519 [61440/90000 (68%)]	Loss: 4.8392	Cost: 8.88s
Train Epoch: 519 [81920/90000 (91%)]	Loss: 4.9473	Cost: 7.60s
Train Epoch: 519 	Average Loss: 5.0223
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3391

Learning rate: 9.933684947441824e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 520 [0/90000 (0%)]	Loss: 6.2213	Cost: 22.84s
Train Epoch: 520 [20480/90000 (23%)]	Loss: 4.8697	Cost: 6.79s
Train Epoch: 520 [40960/90000 (45%)]	Loss: 4.9328	Cost: 10.20s
Train Epoch: 520 [61440/90000 (68%)]	Loss: 4.7959	Cost: 12.36s
Train Epoch: 520 [81920/90000 (91%)]	Loss: 4.9826	Cost: 12.63s
Train Epoch: 520 	Average Loss: 5.0265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1749

Saving model as e520_model.pt & e520_waveforms_supplementary.hdf5
Learning rate: 9.933429721039335e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 521 [0/90000 (0%)]	Loss: 6.1394	Cost: 27.09s
Train Epoch: 521 [20480/90000 (23%)]	Loss: 4.9462	Cost: 13.10s
Train Epoch: 521 [40960/90000 (45%)]	Loss: 4.9604	Cost: 12.42s
Train Epoch: 521 [61440/90000 (68%)]	Loss: 4.9034	Cost: 12.27s
Train Epoch: 521 [81920/90000 (91%)]	Loss: 4.9570	Cost: 11.15s
Train Epoch: 521 	Average Loss: 5.0147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2621

Learning rate: 9.933174007726853e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 522 [0/90000 (0%)]	Loss: 6.1121	Cost: 24.51s
Train Epoch: 522 [20480/90000 (23%)]	Loss: 4.8563	Cost: 12.63s
Train Epoch: 522 [40960/90000 (45%)]	Loss: 4.9496	Cost: 12.44s
Train Epoch: 522 [61440/90000 (68%)]	Loss: 4.8969	Cost: 9.69s
Train Epoch: 522 [81920/90000 (91%)]	Loss: 4.9559	Cost: 6.17s
Train Epoch: 522 	Average Loss: 4.9690
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1969

Learning rate: 9.932917807529615e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 523 [0/90000 (0%)]	Loss: 6.0244	Cost: 29.68s
Train Epoch: 523 [20480/90000 (23%)]	Loss: 4.9452	Cost: 11.32s
Train Epoch: 523 [40960/90000 (45%)]	Loss: 4.9589	Cost: 10.84s
Train Epoch: 523 [61440/90000 (68%)]	Loss: 4.8080	Cost: 6.18s
Train Epoch: 523 [81920/90000 (91%)]	Loss: 4.9428	Cost: 7.06s
Train Epoch: 523 	Average Loss: 4.9657
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2123

Learning rate: 9.93266112047291e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 524 [0/90000 (0%)]	Loss: 6.1259	Cost: 21.96s
Train Epoch: 524 [20480/90000 (23%)]	Loss: 4.8384	Cost: 13.30s
Train Epoch: 524 [40960/90000 (45%)]	Loss: 4.9583	Cost: 11.63s
Train Epoch: 524 [61440/90000 (68%)]	Loss: 4.8634	Cost: 7.93s
Train Epoch: 524 [81920/90000 (91%)]	Loss: 5.0669	Cost: 8.83s
Train Epoch: 524 	Average Loss: 4.9761
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2689

Learning rate: 9.932403946582067e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 525 [0/90000 (0%)]	Loss: 6.1132	Cost: 21.80s
Train Epoch: 525 [20480/90000 (23%)]	Loss: 4.9064	Cost: 7.94s
Train Epoch: 525 [40960/90000 (45%)]	Loss: 4.8395	Cost: 8.99s
Train Epoch: 525 [61440/90000 (68%)]	Loss: 4.9364	Cost: 8.91s
Train Epoch: 525 [81920/90000 (91%)]	Loss: 4.9346	Cost: 8.77s
Train Epoch: 525 	Average Loss: 4.9470
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1995

Learning rate: 9.932146285882473e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 526 [0/90000 (0%)]	Loss: 6.2370	Cost: 20.66s
Train Epoch: 526 [20480/90000 (23%)]	Loss: 4.7815	Cost: 9.09s
Train Epoch: 526 [40960/90000 (45%)]	Loss: 4.8753	Cost: 8.99s
Train Epoch: 526 [61440/90000 (68%)]	Loss: 4.6942	Cost: 6.98s
Train Epoch: 526 [81920/90000 (91%)]	Loss: 4.7912	Cost: 6.39s
Train Epoch: 526 	Average Loss: 4.9240
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2949

Learning rate: 9.931888138399556e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 527 [0/90000 (0%)]	Loss: 6.1721	Cost: 20.87s
Train Epoch: 527 [20480/90000 (23%)]	Loss: 4.8592	Cost: 7.16s
Train Epoch: 527 [40960/90000 (45%)]	Loss: 5.0226	Cost: 8.97s
Train Epoch: 527 [61440/90000 (68%)]	Loss: 4.8300	Cost: 12.28s
Train Epoch: 527 [81920/90000 (91%)]	Loss: 4.8113	Cost: 12.74s
Train Epoch: 527 	Average Loss: 4.9195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2221

Learning rate: 9.931629504158793e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 528 [0/90000 (0%)]	Loss: 6.0633	Cost: 32.76s
Train Epoch: 528 [20480/90000 (23%)]	Loss: 4.7113	Cost: 15.18s
Train Epoch: 528 [40960/90000 (45%)]	Loss: 4.8312	Cost: 14.81s
Train Epoch: 528 [61440/90000 (68%)]	Loss: 4.7316	Cost: 12.24s
Train Epoch: 528 [81920/90000 (91%)]	Loss: 4.9393	Cost: 12.03s
Train Epoch: 528 	Average Loss: 4.9027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2971

Learning rate: 9.931370383185712e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 529 [0/90000 (0%)]	Loss: 6.3451	Cost: 41.38s
Train Epoch: 529 [20480/90000 (23%)]	Loss: 4.7253	Cost: 12.34s
Train Epoch: 529 [40960/90000 (45%)]	Loss: 4.7252	Cost: 12.29s
Train Epoch: 529 [61440/90000 (68%)]	Loss: 4.6627	Cost: 10.02s
Train Epoch: 529 [81920/90000 (91%)]	Loss: 4.8861	Cost: 6.28s
Train Epoch: 529 	Average Loss: 4.8690
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1103

Saving model as e529_model.pt & e529_waveforms_supplementary.hdf5
Learning rate: 9.931110775505886e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 530 [0/90000 (0%)]	Loss: 5.9365	Cost: 26.00s
Train Epoch: 530 [20480/90000 (23%)]	Loss: 4.7668	Cost: 10.67s
Train Epoch: 530 [40960/90000 (45%)]	Loss: 4.7233	Cost: 6.25s
Train Epoch: 530 [61440/90000 (68%)]	Loss: 4.6829	Cost: 6.15s
Train Epoch: 530 [81920/90000 (91%)]	Loss: 4.8344	Cost: 8.77s
Train Epoch: 530 	Average Loss: 4.8284
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1723

Learning rate: 9.93085068114494e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 531 [0/90000 (0%)]	Loss: 6.2660	Cost: 22.15s
Train Epoch: 531 [20480/90000 (23%)]	Loss: 4.8032	Cost: 8.99s
Train Epoch: 531 [40960/90000 (45%)]	Loss: 4.8945	Cost: 9.03s
Train Epoch: 531 [61440/90000 (68%)]	Loss: 4.6575	Cost: 8.62s
Train Epoch: 531 [81920/90000 (91%)]	Loss: 4.7389	Cost: 8.80s
Train Epoch: 531 	Average Loss: 4.8421
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2043

Learning rate: 9.930590100128539e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 532 [0/90000 (0%)]	Loss: 6.0604	Cost: 19.40s
Train Epoch: 532 [20480/90000 (23%)]	Loss: 4.8148	Cost: 9.24s
Train Epoch: 532 [40960/90000 (45%)]	Loss: 4.7293	Cost: 12.32s
Train Epoch: 532 [61440/90000 (68%)]	Loss: 4.7038	Cost: 12.39s
Train Epoch: 532 [81920/90000 (91%)]	Loss: 4.7811	Cost: 12.29s
Train Epoch: 532 	Average Loss: 4.8098
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1616

Learning rate: 9.930329032482406e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 533 [0/90000 (0%)]	Loss: 6.0261	Cost: 40.19s
Train Epoch: 533 [20480/90000 (23%)]	Loss: 4.9148	Cost: 12.44s
Train Epoch: 533 [40960/90000 (45%)]	Loss: 4.6210	Cost: 12.36s
Train Epoch: 533 [61440/90000 (68%)]	Loss: 4.6231	Cost: 12.41s
Train Epoch: 533 [81920/90000 (91%)]	Loss: 4.8924	Cost: 11.84s
Train Epoch: 533 	Average Loss: 4.8127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1803

Learning rate: 9.930067478232305e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 534 [0/90000 (0%)]	Loss: 6.1194	Cost: 27.89s
Train Epoch: 534 [20480/90000 (23%)]	Loss: 4.8975	Cost: 13.24s
Train Epoch: 534 [40960/90000 (45%)]	Loss: 4.7400	Cost: 12.24s
Train Epoch: 534 [61440/90000 (68%)]	Loss: 4.8459	Cost: 11.31s
Train Epoch: 534 [81920/90000 (91%)]	Loss: 4.7198	Cost: 6.25s
Train Epoch: 534 	Average Loss: 4.8276
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1508

Learning rate: 9.929805437404053e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 535 [0/90000 (0%)]	Loss: 6.0517	Cost: 26.47s
Train Epoch: 535 [20480/90000 (23%)]	Loss: 4.6234	Cost: 12.83s
Train Epoch: 535 [40960/90000 (45%)]	Loss: 4.8629	Cost: 13.24s
Train Epoch: 535 [61440/90000 (68%)]	Loss: 4.6665	Cost: 8.87s
Train Epoch: 535 [81920/90000 (91%)]	Loss: 4.8292	Cost: 6.53s
Train Epoch: 535 	Average Loss: 4.8237
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1671

Learning rate: 9.92954291002351e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 536 [0/90000 (0%)]	Loss: 6.1048	Cost: 24.97s
Train Epoch: 536 [20480/90000 (23%)]	Loss: 4.7542	Cost: 11.27s
Train Epoch: 536 [40960/90000 (45%)]	Loss: 5.0400	Cost: 9.41s
Train Epoch: 536 [61440/90000 (68%)]	Loss: 4.8237	Cost: 6.40s
Train Epoch: 536 [81920/90000 (91%)]	Loss: 4.8827	Cost: 7.24s
Train Epoch: 536 	Average Loss: 4.8684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2476

Learning rate: 9.929279896116587e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 537 [0/90000 (0%)]	Loss: 5.9869	Cost: 19.68s
Train Epoch: 537 [20480/90000 (23%)]	Loss: 4.6290	Cost: 6.65s
Train Epoch: 537 [40960/90000 (45%)]	Loss: 4.5764	Cost: 10.58s
Train Epoch: 537 [61440/90000 (68%)]	Loss: 4.6827	Cost: 9.17s
Train Epoch: 537 [81920/90000 (91%)]	Loss: 4.8100	Cost: 8.80s
Train Epoch: 537 	Average Loss: 4.7754
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0743

Saving model as e537_model.pt & e537_waveforms_supplementary.hdf5
Learning rate: 9.929016395709243e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 538 [0/90000 (0%)]	Loss: 5.8249	Cost: 30.46s
Train Epoch: 538 [20480/90000 (23%)]	Loss: 4.5887	Cost: 8.85s
Train Epoch: 538 [40960/90000 (45%)]	Loss: 4.7779	Cost: 6.46s
Train Epoch: 538 [61440/90000 (68%)]	Loss: 4.6225	Cost: 6.52s
Train Epoch: 538 [81920/90000 (91%)]	Loss: 4.6423	Cost: 7.69s
Train Epoch: 538 	Average Loss: 4.7227
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0556

Saving model as e538_model.pt & e538_waveforms_supplementary.hdf5
Learning rate: 9.928752408827483e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 539 [0/90000 (0%)]	Loss: 6.0247	Cost: 33.08s
Train Epoch: 539 [20480/90000 (23%)]	Loss: 4.6440	Cost: 7.55s
Train Epoch: 539 [40960/90000 (45%)]	Loss: 4.6991	Cost: 13.34s
Train Epoch: 539 [61440/90000 (68%)]	Loss: 4.7623	Cost: 12.47s
Train Epoch: 539 [81920/90000 (91%)]	Loss: 4.8435	Cost: 12.16s
Train Epoch: 539 	Average Loss: 4.7906
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1567

Learning rate: 9.928487935497362e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 540 [0/90000 (0%)]	Loss: 6.0243	Cost: 28.32s
Train Epoch: 540 [20480/90000 (23%)]	Loss: 4.6771	Cost: 14.32s
Train Epoch: 540 [40960/90000 (45%)]	Loss: 4.6290	Cost: 12.99s
Train Epoch: 540 [61440/90000 (68%)]	Loss: 4.5305	Cost: 12.58s
Train Epoch: 540 [81920/90000 (91%)]	Loss: 4.9266	Cost: 9.96s
Train Epoch: 540 	Average Loss: 4.7404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1819

Learning rate: 9.928222975744984e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 541 [0/90000 (0%)]	Loss: 5.9747	Cost: 25.00s
Train Epoch: 541 [20480/90000 (23%)]	Loss: 4.8956	Cost: 10.55s
Train Epoch: 541 [40960/90000 (45%)]	Loss: 4.7438	Cost: 12.63s
Train Epoch: 541 [61440/90000 (68%)]	Loss: 4.7353	Cost: 12.46s
Train Epoch: 541 [81920/90000 (91%)]	Loss: 4.6959	Cost: 7.69s
Train Epoch: 541 	Average Loss: 4.8678
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1972

Learning rate: 9.927957529596498e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 542 [0/90000 (0%)]	Loss: 5.9778	Cost: 25.37s
Train Epoch: 542 [20480/90000 (23%)]	Loss: 4.6950	Cost: 12.80s
Train Epoch: 542 [40960/90000 (45%)]	Loss: 4.6740	Cost: 9.99s
Train Epoch: 542 [61440/90000 (68%)]	Loss: 4.5498	Cost: 6.32s
Train Epoch: 542 [81920/90000 (91%)]	Loss: 4.6141	Cost: 6.90s
Train Epoch: 542 	Average Loss: 4.7135
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0234

Saving model as e542_model.pt & e542_waveforms_supplementary.hdf5
Learning rate: 9.927691597078101e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 543 [0/90000 (0%)]	Loss: 6.2364	Cost: 33.71s
Train Epoch: 543 [20480/90000 (23%)]	Loss: 4.5581	Cost: 7.17s
Train Epoch: 543 [40960/90000 (45%)]	Loss: 4.5594	Cost: 9.31s
Train Epoch: 543 [61440/90000 (68%)]	Loss: 4.3224	Cost: 8.54s
Train Epoch: 543 [81920/90000 (91%)]	Loss: 4.6050	Cost: 8.43s
Train Epoch: 543 	Average Loss: 4.6391
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0291

Learning rate: 9.927425178216043e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 544 [0/90000 (0%)]	Loss: 6.0147	Cost: 28.12s
Train Epoch: 544 [20480/90000 (23%)]	Loss: 4.5189	Cost: 9.19s
Train Epoch: 544 [40960/90000 (45%)]	Loss: 4.6197	Cost: 9.00s
Train Epoch: 544 [61440/90000 (68%)]	Loss: 4.5692	Cost: 8.56s
Train Epoch: 544 [81920/90000 (91%)]	Loss: 4.6438	Cost: 8.38s
Train Epoch: 544 	Average Loss: 4.6411
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0098

Saving model as e544_model.pt & e544_waveforms_supplementary.hdf5
Learning rate: 9.927158273036618e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 545 [0/90000 (0%)]	Loss: 5.7636	Cost: 21.29s
Train Epoch: 545 [20480/90000 (23%)]	Loss: 4.4898	Cost: 6.37s
Train Epoch: 545 [40960/90000 (45%)]	Loss: 4.6234	Cost: 15.25s
Train Epoch: 545 [61440/90000 (68%)]	Loss: 4.4431	Cost: 12.52s
Train Epoch: 545 [81920/90000 (91%)]	Loss: 4.6570	Cost: 13.16s
Train Epoch: 545 	Average Loss: 4.6388
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0869

Learning rate: 9.926890881566166e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 546 [0/90000 (0%)]	Loss: 6.1684	Cost: 22.02s
Train Epoch: 546 [20480/90000 (23%)]	Loss: 4.5433	Cost: 6.87s
Train Epoch: 546 [40960/90000 (45%)]	Loss: 4.4237	Cost: 12.94s
Train Epoch: 546 [61440/90000 (68%)]	Loss: 4.4797	Cost: 13.84s
Train Epoch: 546 [81920/90000 (91%)]	Loss: 4.5420	Cost: 12.53s
Train Epoch: 546 	Average Loss: 4.6104
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9604

Saving model as e546_model.pt & e546_waveforms_supplementary.hdf5
Learning rate: 9.926623003831078e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 547 [0/90000 (0%)]	Loss: 5.9634	Cost: 30.01s
Train Epoch: 547 [20480/90000 (23%)]	Loss: 4.5630	Cost: 12.77s
Train Epoch: 547 [40960/90000 (45%)]	Loss: 4.5161	Cost: 13.88s
Train Epoch: 547 [61440/90000 (68%)]	Loss: 4.3409	Cost: 12.27s
Train Epoch: 547 [81920/90000 (91%)]	Loss: 4.6178	Cost: 7.07s
Train Epoch: 547 	Average Loss: 4.5896
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9402

Saving model as e547_model.pt & e547_waveforms_supplementary.hdf5
Learning rate: 9.926354639857796e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 548 [0/90000 (0%)]	Loss: 5.9128	Cost: 35.67s
Train Epoch: 548 [20480/90000 (23%)]	Loss: 4.4834	Cost: 10.50s
Train Epoch: 548 [40960/90000 (45%)]	Loss: 4.5855	Cost: 10.14s
Train Epoch: 548 [61440/90000 (68%)]	Loss: 4.4365	Cost: 6.04s
Train Epoch: 548 [81920/90000 (91%)]	Loss: 4.5982	Cost: 6.78s
Train Epoch: 548 	Average Loss: 4.5812
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9726

Learning rate: 9.926085789672802e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 549 [0/90000 (0%)]	Loss: 5.8331	Cost: 36.94s
Train Epoch: 549 [20480/90000 (23%)]	Loss: 4.4570	Cost: 9.39s
Train Epoch: 549 [40960/90000 (45%)]	Loss: 4.3910	Cost: 6.99s
Train Epoch: 549 [61440/90000 (68%)]	Loss: 4.6778	Cost: 7.39s
Train Epoch: 549 [81920/90000 (91%)]	Loss: 4.7804	Cost: 8.30s
Train Epoch: 549 	Average Loss: 4.5950
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0712

Learning rate: 9.92581645330263e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 550 [0/90000 (0%)]	Loss: 6.1218	Cost: 22.53s
Train Epoch: 550 [20480/90000 (23%)]	Loss: 4.4698	Cost: 8.24s
Train Epoch: 550 [40960/90000 (45%)]	Loss: 4.5356	Cost: 8.91s
Train Epoch: 550 [61440/90000 (68%)]	Loss: 4.4146	Cost: 9.40s
Train Epoch: 550 [81920/90000 (91%)]	Loss: 4.4538	Cost: 9.06s
Train Epoch: 550 	Average Loss: 4.6094
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9622

Learning rate: 9.925546630773865e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 551 [0/90000 (0%)]	Loss: 5.6910	Cost: 21.25s
Train Epoch: 551 [20480/90000 (23%)]	Loss: 4.4396	Cost: 11.33s
Train Epoch: 551 [40960/90000 (45%)]	Loss: 4.3616	Cost: 9.64s
Train Epoch: 551 [61440/90000 (68%)]	Loss: 4.3944	Cost: 8.83s
Train Epoch: 551 [81920/90000 (91%)]	Loss: 4.5111	Cost: 7.94s
Train Epoch: 551 	Average Loss: 4.5085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9711

Learning rate: 9.925276322113137e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 552 [0/90000 (0%)]	Loss: 5.8187	Cost: 26.47s
Train Epoch: 552 [20480/90000 (23%)]	Loss: 4.4341	Cost: 10.18s
Train Epoch: 552 [40960/90000 (45%)]	Loss: 4.4609	Cost: 11.22s
Train Epoch: 552 [61440/90000 (68%)]	Loss: 4.2280	Cost: 12.55s
Train Epoch: 552 [81920/90000 (91%)]	Loss: 4.4698	Cost: 12.43s
Train Epoch: 552 	Average Loss: 4.5056
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9108

Saving model as e552_model.pt & e552_waveforms_supplementary.hdf5
Learning rate: 9.925005527347125e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 553 [0/90000 (0%)]	Loss: 5.8482	Cost: 25.17s
Train Epoch: 553 [20480/90000 (23%)]	Loss: 4.5218	Cost: 13.98s
Train Epoch: 553 [40960/90000 (45%)]	Loss: 4.5729	Cost: 12.56s
Train Epoch: 553 [61440/90000 (68%)]	Loss: 4.4326	Cost: 12.06s
Train Epoch: 553 [81920/90000 (91%)]	Loss: 4.4411	Cost: 9.74s
Train Epoch: 553 	Average Loss: 4.5213
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9088

Saving model as e553_model.pt & e553_waveforms_supplementary.hdf5
Learning rate: 9.924734246502554e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 554 [0/90000 (0%)]	Loss: 5.9282	Cost: 27.13s
Train Epoch: 554 [20480/90000 (23%)]	Loss: 4.3933	Cost: 10.83s
Train Epoch: 554 [40960/90000 (45%)]	Loss: 4.5150	Cost: 9.31s
Train Epoch: 554 [61440/90000 (68%)]	Loss: 4.2336	Cost: 6.32s
Train Epoch: 554 [81920/90000 (91%)]	Loss: 4.4186	Cost: 7.24s
Train Epoch: 554 	Average Loss: 4.4753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8928

Saving model as e554_model.pt & e554_waveforms_supplementary.hdf5
Learning rate: 9.9244624796062e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 555 [0/90000 (0%)]	Loss: 5.7185	Cost: 23.29s
Train Epoch: 555 [20480/90000 (23%)]	Loss: 4.3319	Cost: 9.96s
Train Epoch: 555 [40960/90000 (45%)]	Loss: 4.4455	Cost: 9.68s
Train Epoch: 555 [61440/90000 (68%)]	Loss: 4.2475	Cost: 9.04s
Train Epoch: 555 [81920/90000 (91%)]	Loss: 4.6349	Cost: 8.72s
Train Epoch: 555 	Average Loss: 4.4529
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9645

Learning rate: 9.924190226684883e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 556 [0/90000 (0%)]	Loss: 5.8398	Cost: 19.50s
Train Epoch: 556 [20480/90000 (23%)]	Loss: 4.3765	Cost: 9.24s
Train Epoch: 556 [40960/90000 (45%)]	Loss: 4.4080	Cost: 13.30s
Train Epoch: 556 [61440/90000 (68%)]	Loss: 4.2971	Cost: 9.03s
Train Epoch: 556 [81920/90000 (91%)]	Loss: 4.4485	Cost: 8.91s
Train Epoch: 556 	Average Loss: 4.4411
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8911

Saving model as e556_model.pt & e556_waveforms_supplementary.hdf5
Learning rate: 9.923917487765477e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 557 [0/90000 (0%)]	Loss: 5.8533	Cost: 22.85s
Train Epoch: 557 [20480/90000 (23%)]	Loss: 4.5365	Cost: 8.70s
Train Epoch: 557 [40960/90000 (45%)]	Loss: 4.4833	Cost: 6.41s
Train Epoch: 557 [61440/90000 (68%)]	Loss: 4.2632	Cost: 7.41s
Train Epoch: 557 [81920/90000 (91%)]	Loss: 4.7727	Cost: 7.55s
Train Epoch: 557 	Average Loss: 4.6328
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1707

Learning rate: 9.923644262874898e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 558 [0/90000 (0%)]	Loss: 6.0199	Cost: 19.15s
Train Epoch: 558 [20480/90000 (23%)]	Loss: 4.6276	Cost: 7.65s
Train Epoch: 558 [40960/90000 (45%)]	Loss: 4.5797	Cost: 11.84s
Train Epoch: 558 [61440/90000 (68%)]	Loss: 4.4244	Cost: 12.47s
Train Epoch: 558 [81920/90000 (91%)]	Loss: 4.4658	Cost: 12.27s
Train Epoch: 558 	Average Loss: 4.5911
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9794

Learning rate: 9.92337055204011e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 559 [0/90000 (0%)]	Loss: 5.9751	Cost: 25.02s
Train Epoch: 559 [20480/90000 (23%)]	Loss: 4.4196	Cost: 10.72s
Train Epoch: 559 [40960/90000 (45%)]	Loss: 4.4964	Cost: 12.62s
Train Epoch: 559 [61440/90000 (68%)]	Loss: 4.2238	Cost: 12.57s
Train Epoch: 559 [81920/90000 (91%)]	Loss: 4.3258	Cost: 12.37s
Train Epoch: 559 	Average Loss: 4.4567
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8131

Saving model as e559_model.pt & e559_waveforms_supplementary.hdf5
Learning rate: 9.92309635528813e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 560 [0/90000 (0%)]	Loss: 5.7936	Cost: 40.43s
Train Epoch: 560 [20480/90000 (23%)]	Loss: 4.2812	Cost: 13.49s
Train Epoch: 560 [40960/90000 (45%)]	Loss: 4.3537	Cost: 12.29s
Train Epoch: 560 [61440/90000 (68%)]	Loss: 4.2326	Cost: 10.72s
Train Epoch: 560 [81920/90000 (91%)]	Loss: 4.3923	Cost: 6.04s
Train Epoch: 560 	Average Loss: 4.3981
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8311

Learning rate: 9.92282167264602e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 561 [0/90000 (0%)]	Loss: 5.6304	Cost: 41.68s
Train Epoch: 561 [20480/90000 (23%)]	Loss: 4.3079	Cost: 12.64s
Train Epoch: 561 [40960/90000 (45%)]	Loss: 4.4408	Cost: 9.13s
Train Epoch: 561 [61440/90000 (68%)]	Loss: 4.1784	Cost: 6.08s
Train Epoch: 561 [81920/90000 (91%)]	Loss: 4.2752	Cost: 7.34s
Train Epoch: 561 	Average Loss: 4.3925
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8741

Learning rate: 9.92254650414089e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 562 [0/90000 (0%)]	Loss: 6.1048	Cost: 26.56s
Train Epoch: 562 [20480/90000 (23%)]	Loss: 4.3153	Cost: 10.87s
Train Epoch: 562 [40960/90000 (45%)]	Loss: 4.4247	Cost: 10.24s
Train Epoch: 562 [61440/90000 (68%)]	Loss: 4.1902	Cost: 6.19s
Train Epoch: 562 [81920/90000 (91%)]	Loss: 4.4275	Cost: 7.24s
Train Epoch: 562 	Average Loss: 4.4079
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9515

Learning rate: 9.922270849799896e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 563 [0/90000 (0%)]	Loss: 5.6828	Cost: 19.49s
Train Epoch: 563 [20480/90000 (23%)]	Loss: 4.4225	Cost: 6.73s
Train Epoch: 563 [40960/90000 (45%)]	Loss: 4.4043	Cost: 10.04s
Train Epoch: 563 [61440/90000 (68%)]	Loss: 4.2248	Cost: 8.84s
Train Epoch: 563 [81920/90000 (91%)]	Loss: 4.3824	Cost: 8.53s
Train Epoch: 563 	Average Loss: 4.3965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8749

Learning rate: 9.921994709650246e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 564 [0/90000 (0%)]	Loss: 5.7477	Cost: 23.52s
Train Epoch: 564 [20480/90000 (23%)]	Loss: 4.1663	Cost: 8.99s
Train Epoch: 564 [40960/90000 (45%)]	Loss: 4.2796	Cost: 8.96s
Train Epoch: 564 [61440/90000 (68%)]	Loss: 4.1754	Cost: 9.25s
Train Epoch: 564 [81920/90000 (91%)]	Loss: 4.3578	Cost: 8.89s
Train Epoch: 564 	Average Loss: 4.3346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7918

Saving model as e564_model.pt & e564_waveforms_supplementary.hdf5
Learning rate: 9.921718083719194e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 565 [0/90000 (0%)]	Loss: 5.9466	Cost: 23.68s
Train Epoch: 565 [20480/90000 (23%)]	Loss: 4.2091	Cost: 9.70s
Train Epoch: 565 [40960/90000 (45%)]	Loss: 4.2658	Cost: 6.28s
Train Epoch: 565 [61440/90000 (68%)]	Loss: 4.2544	Cost: 7.13s
Train Epoch: 565 [81920/90000 (91%)]	Loss: 4.3484	Cost: 6.66s
Train Epoch: 565 	Average Loss: 4.3298
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7851

Saving model as e565_model.pt & e565_waveforms_supplementary.hdf5
Learning rate: 9.921440972034041e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 566 [0/90000 (0%)]	Loss: 5.6815	Cost: 24.92s
Train Epoch: 566 [20480/90000 (23%)]	Loss: 4.1809	Cost: 9.90s
Train Epoch: 566 [40960/90000 (45%)]	Loss: 4.2522	Cost: 13.93s
Train Epoch: 566 [61440/90000 (68%)]	Loss: 3.9644	Cost: 12.76s
Train Epoch: 566 [81920/90000 (91%)]	Loss: 4.2448	Cost: 12.43s
Train Epoch: 566 	Average Loss: 4.2810
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7072

Saving model as e566_model.pt & e566_waveforms_supplementary.hdf5
Learning rate: 9.921163374622138e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 567 [0/90000 (0%)]	Loss: 5.7853	Cost: 33.18s
Train Epoch: 567 [20480/90000 (23%)]	Loss: 4.1072	Cost: 12.83s
Train Epoch: 567 [40960/90000 (45%)]	Loss: 4.2679	Cost: 12.93s
Train Epoch: 567 [61440/90000 (68%)]	Loss: 4.1241	Cost: 12.26s
Train Epoch: 567 [81920/90000 (91%)]	Loss: 4.2917	Cost: 10.23s
Train Epoch: 567 	Average Loss: 4.2699
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9447

Learning rate: 9.920885291510881e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 568 [0/90000 (0%)]	Loss: 6.0136	Cost: 25.33s
Train Epoch: 568 [20480/90000 (23%)]	Loss: 4.2590	Cost: 12.52s
Train Epoch: 568 [40960/90000 (45%)]	Loss: 4.2222	Cost: 12.28s
Train Epoch: 568 [61440/90000 (68%)]	Loss: 4.2838	Cost: 10.37s
Train Epoch: 568 [81920/90000 (91%)]	Loss: 4.2434	Cost: 8.04s
Train Epoch: 568 	Average Loss: 4.3476
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7673

Learning rate: 9.920606722727717e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 569 [0/90000 (0%)]	Loss: 5.8848	Cost: 26.64s
Train Epoch: 569 [20480/90000 (23%)]	Loss: 4.2590	Cost: 11.55s
Train Epoch: 569 [40960/90000 (45%)]	Loss: 4.1494	Cost: 6.47s
Train Epoch: 569 [61440/90000 (68%)]	Loss: 4.1783	Cost: 6.20s
Train Epoch: 569 [81920/90000 (91%)]	Loss: 4.2199	Cost: 7.76s
Train Epoch: 569 	Average Loss: 4.2710
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8165

Learning rate: 9.920327668300141e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 570 [0/90000 (0%)]	Loss: 5.7699	Cost: 24.26s
Train Epoch: 570 [20480/90000 (23%)]	Loss: 4.1736	Cost: 11.09s
Train Epoch: 570 [40960/90000 (45%)]	Loss: 4.3600	Cost: 7.07s
Train Epoch: 570 [61440/90000 (68%)]	Loss: 4.1118	Cost: 6.63s
Train Epoch: 570 [81920/90000 (91%)]	Loss: 4.2891	Cost: 9.37s
Train Epoch: 570 	Average Loss: 4.2622
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8326

Learning rate: 9.920048128255691e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 571 [0/90000 (0%)]	Loss: 5.8289	Cost: 22.50s
Train Epoch: 571 [20480/90000 (23%)]	Loss: 4.2551	Cost: 9.80s
Train Epoch: 571 [40960/90000 (45%)]	Loss: 4.2463	Cost: 6.65s
Train Epoch: 571 [61440/90000 (68%)]	Loss: 4.2290	Cost: 8.13s
Train Epoch: 571 [81920/90000 (91%)]	Loss: 4.2279	Cost: 9.21s
Train Epoch: 571 	Average Loss: 4.2626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7371

Learning rate: 9.91976810262196e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 572 [0/90000 (0%)]	Loss: 5.4875	Cost: 21.39s
Train Epoch: 572 [20480/90000 (23%)]	Loss: 4.1703	Cost: 7.95s
Train Epoch: 572 [40960/90000 (45%)]	Loss: 4.2174	Cost: 10.71s
Train Epoch: 572 [61440/90000 (68%)]	Loss: 4.1916	Cost: 8.79s
Train Epoch: 572 [81920/90000 (91%)]	Loss: 4.2006	Cost: 8.50s
Train Epoch: 572 	Average Loss: 4.2279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7600

Learning rate: 9.919487591426583e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 573 [0/90000 (0%)]	Loss: 5.7881	Cost: 23.89s
Train Epoch: 573 [20480/90000 (23%)]	Loss: 4.0899	Cost: 9.00s
Train Epoch: 573 [40960/90000 (45%)]	Loss: 4.2578	Cost: 8.82s
Train Epoch: 573 [61440/90000 (68%)]	Loss: 3.9868	Cost: 7.26s
Train Epoch: 573 [81920/90000 (91%)]	Loss: 4.1868	Cost: 6.23s
Train Epoch: 573 	Average Loss: 4.1916
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7148

Learning rate: 9.919206594697245e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 574 [0/90000 (0%)]	Loss: 5.7005	Cost: 23.28s
Train Epoch: 574 [20480/90000 (23%)]	Loss: 4.1116	Cost: 7.73s
Train Epoch: 574 [40960/90000 (45%)]	Loss: 4.1384	Cost: 10.10s
Train Epoch: 574 [61440/90000 (68%)]	Loss: 4.1516	Cost: 11.89s
Train Epoch: 574 [81920/90000 (91%)]	Loss: 4.3471	Cost: 12.38s
Train Epoch: 574 	Average Loss: 4.3228
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7931

Learning rate: 9.918925112461682e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 575 [0/90000 (0%)]	Loss: 5.6393	Cost: 26.16s
Train Epoch: 575 [20480/90000 (23%)]	Loss: 4.1479	Cost: 12.90s
Train Epoch: 575 [40960/90000 (45%)]	Loss: 4.0360	Cost: 15.69s
Train Epoch: 575 [61440/90000 (68%)]	Loss: 3.9767	Cost: 12.86s
Train Epoch: 575 [81920/90000 (91%)]	Loss: 4.2314	Cost: 12.36s
Train Epoch: 575 	Average Loss: 4.1806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7689

Learning rate: 9.918643144747673e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 576 [0/90000 (0%)]	Loss: 5.5085	Cost: 23.85s
Train Epoch: 576 [20480/90000 (23%)]	Loss: 4.0977	Cost: 15.02s
Train Epoch: 576 [40960/90000 (45%)]	Loss: 4.0581	Cost: 13.69s
Train Epoch: 576 [61440/90000 (68%)]	Loss: 4.1974	Cost: 12.58s
Train Epoch: 576 [81920/90000 (91%)]	Loss: 4.2405	Cost: 7.11s
Train Epoch: 576 	Average Loss: 4.1944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7394

Learning rate: 9.918360691583047e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 577 [0/90000 (0%)]	Loss: 5.6018	Cost: 31.05s
Train Epoch: 577 [20480/90000 (23%)]	Loss: 4.1315	Cost: 12.54s
Train Epoch: 577 [40960/90000 (45%)]	Loss: 4.1692	Cost: 10.96s
Train Epoch: 577 [61440/90000 (68%)]	Loss: 4.0650	Cost: 6.24s
Train Epoch: 577 [81920/90000 (91%)]	Loss: 4.1164	Cost: 7.29s
Train Epoch: 577 	Average Loss: 4.1693
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6889

Saving model as e577_model.pt & e577_waveforms_supplementary.hdf5
Learning rate: 9.918077752995681e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 578 [0/90000 (0%)]	Loss: 5.6087	Cost: 26.74s
Train Epoch: 578 [20480/90000 (23%)]	Loss: 3.8939	Cost: 9.23s
Train Epoch: 578 [40960/90000 (45%)]	Loss: 4.0147	Cost: 6.46s
Train Epoch: 578 [61440/90000 (68%)]	Loss: 3.9532	Cost: 6.35s
Train Epoch: 578 [81920/90000 (91%)]	Loss: 4.0165	Cost: 8.87s
Train Epoch: 578 	Average Loss: 4.0916
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6429

Saving model as e578_model.pt & e578_waveforms_supplementary.hdf5
Learning rate: 9.917794329013504e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 579 [0/90000 (0%)]	Loss: 5.5958	Cost: 23.49s
Train Epoch: 579 [20480/90000 (23%)]	Loss: 3.9688	Cost: 7.30s
Train Epoch: 579 [40960/90000 (45%)]	Loss: 4.0095	Cost: 9.27s
Train Epoch: 579 [61440/90000 (68%)]	Loss: 4.0097	Cost: 8.94s
Train Epoch: 579 [81920/90000 (91%)]	Loss: 4.0355	Cost: 8.45s
Train Epoch: 579 	Average Loss: 4.0865
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6953

Learning rate: 9.917510419664483e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 580 [0/90000 (0%)]	Loss: 5.7832	Cost: 22.62s
Train Epoch: 580 [20480/90000 (23%)]	Loss: 4.0314	Cost: 9.43s
Train Epoch: 580 [40960/90000 (45%)]	Loss: 4.0459	Cost: 9.57s
Train Epoch: 580 [61440/90000 (68%)]	Loss: 3.8479	Cost: 9.50s
Train Epoch: 580 [81920/90000 (91%)]	Loss: 4.0894	Cost: 6.69s
Train Epoch: 580 	Average Loss: 4.0955
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6642

Learning rate: 9.91722602497664e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 581 [0/90000 (0%)]	Loss: 5.7382	Cost: 18.83s
Train Epoch: 581 [20480/90000 (23%)]	Loss: 4.1218	Cost: 7.20s
Train Epoch: 581 [40960/90000 (45%)]	Loss: 4.1384	Cost: 16.46s
Train Epoch: 581 [61440/90000 (68%)]	Loss: 3.9163	Cost: 12.95s
Train Epoch: 581 [81920/90000 (91%)]	Loss: 4.1682	Cost: 13.32s
Train Epoch: 581 	Average Loss: 4.1177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6441

Learning rate: 9.916941144978047e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 582 [0/90000 (0%)]	Loss: 5.7477	Cost: 24.70s
Train Epoch: 582 [20480/90000 (23%)]	Loss: 4.0391	Cost: 12.95s
Train Epoch: 582 [40960/90000 (45%)]	Loss: 3.8919	Cost: 14.27s
Train Epoch: 582 [61440/90000 (68%)]	Loss: 3.9025	Cost: 12.25s
Train Epoch: 582 [81920/90000 (91%)]	Loss: 3.9791	Cost: 12.17s
Train Epoch: 582 	Average Loss: 4.0677
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7597

Learning rate: 9.916655779696818e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 583 [0/90000 (0%)]	Loss: 5.9295	Cost: 29.75s
Train Epoch: 583 [20480/90000 (23%)]	Loss: 4.0439	Cost: 12.14s
Train Epoch: 583 [40960/90000 (45%)]	Loss: 3.8427	Cost: 12.10s
Train Epoch: 583 [61440/90000 (68%)]	Loss: 3.9147	Cost: 11.89s
Train Epoch: 583 [81920/90000 (91%)]	Loss: 4.0445	Cost: 6.17s
Train Epoch: 583 	Average Loss: 4.0949
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6819

Learning rate: 9.916369929161117e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 584 [0/90000 (0%)]	Loss: 5.8860	Cost: 26.24s
Train Epoch: 584 [20480/90000 (23%)]	Loss: 3.8617	Cost: 12.67s
Train Epoch: 584 [40960/90000 (45%)]	Loss: 3.9825	Cost: 12.32s
Train Epoch: 584 [61440/90000 (68%)]	Loss: 3.9240	Cost: 9.73s
Train Epoch: 584 [81920/90000 (91%)]	Loss: 4.0909	Cost: 6.30s
Train Epoch: 584 	Average Loss: 4.0468
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5875

Saving model as e584_model.pt & e584_waveforms_supplementary.hdf5
Learning rate: 9.916083593399158e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 585 [0/90000 (0%)]	Loss: 5.5791	Cost: 34.28s
Train Epoch: 585 [20480/90000 (23%)]	Loss: 3.8799	Cost: 10.68s
Train Epoch: 585 [40960/90000 (45%)]	Loss: 3.7841	Cost: 9.57s
Train Epoch: 585 [61440/90000 (68%)]	Loss: 3.8587	Cost: 8.21s
Train Epoch: 585 [81920/90000 (91%)]	Loss: 3.9860	Cost: 8.67s
Train Epoch: 585 	Average Loss: 3.9850
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5915

Learning rate: 9.9157967724392e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 586 [0/90000 (0%)]	Loss: 5.6627	Cost: 19.44s
Train Epoch: 586 [20480/90000 (23%)]	Loss: 3.8857	Cost: 8.54s
Train Epoch: 586 [40960/90000 (45%)]	Loss: 4.0530	Cost: 10.35s
Train Epoch: 586 [61440/90000 (68%)]	Loss: 3.8193	Cost: 10.01s
Train Epoch: 586 [81920/90000 (91%)]	Loss: 3.9297	Cost: 8.86s
Train Epoch: 586 	Average Loss: 3.9987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6158

Learning rate: 9.915509466309551e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 587 [0/90000 (0%)]	Loss: 5.6407	Cost: 25.04s
Train Epoch: 587 [20480/90000 (23%)]	Loss: 3.9103	Cost: 8.78s
Train Epoch: 587 [40960/90000 (45%)]	Loss: 3.8611	Cost: 7.10s
Train Epoch: 587 [61440/90000 (68%)]	Loss: 3.8529	Cost: 6.23s
Train Epoch: 587 [81920/90000 (91%)]	Loss: 3.9216	Cost: 6.74s
Train Epoch: 587 	Average Loss: 3.9767
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6707

Learning rate: 9.915221675038568e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 588 [0/90000 (0%)]	Loss: 5.5885	Cost: 20.62s
Train Epoch: 588 [20480/90000 (23%)]	Loss: 4.2074	Cost: 7.01s
Train Epoch: 588 [40960/90000 (45%)]	Loss: 3.9888	Cost: 9.51s
Train Epoch: 588 [61440/90000 (68%)]	Loss: 3.7015	Cost: 11.73s
Train Epoch: 588 [81920/90000 (91%)]	Loss: 3.9789	Cost: 12.40s
Train Epoch: 588 	Average Loss: 3.9965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6541

Learning rate: 9.914933398654654e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 589 [0/90000 (0%)]	Loss: 5.5797	Cost: 29.32s
Train Epoch: 589 [20480/90000 (23%)]	Loss: 3.9399	Cost: 9.59s
Train Epoch: 589 [40960/90000 (45%)]	Loss: 3.8437	Cost: 12.48s
Train Epoch: 589 [61440/90000 (68%)]	Loss: 3.8115	Cost: 12.48s
Train Epoch: 589 [81920/90000 (91%)]	Loss: 3.9182	Cost: 12.54s
Train Epoch: 589 	Average Loss: 3.9486
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5509

Saving model as e589_model.pt & e589_waveforms_supplementary.hdf5
Learning rate: 9.914644637186261e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 590 [0/90000 (0%)]	Loss: 5.2720	Cost: 33.54s
Train Epoch: 590 [20480/90000 (23%)]	Loss: 3.8827	Cost: 12.94s
Train Epoch: 590 [40960/90000 (45%)]	Loss: 3.9256	Cost: 13.45s
Train Epoch: 590 [61440/90000 (68%)]	Loss: 3.7103	Cost: 12.14s
Train Epoch: 590 [81920/90000 (91%)]	Loss: 3.8387	Cost: 8.38s
Train Epoch: 590 	Average Loss: 3.9180
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4551

Saving model as e590_model.pt & e590_waveforms_supplementary.hdf5
Learning rate: 9.914355390661888e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 591 [0/90000 (0%)]	Loss: 5.4329	Cost: 39.52s
Train Epoch: 591 [20480/90000 (23%)]	Loss: 3.8637	Cost: 11.93s
Train Epoch: 591 [40960/90000 (45%)]	Loss: 3.7410	Cost: 8.36s
Train Epoch: 591 [61440/90000 (68%)]	Loss: 3.8674	Cost: 6.30s
Train Epoch: 591 [81920/90000 (91%)]	Loss: 3.9535	Cost: 7.42s
Train Epoch: 591 	Average Loss: 3.8971
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5650

Learning rate: 9.914065659110084e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 592 [0/90000 (0%)]	Loss: 5.3291	Cost: 27.10s
Train Epoch: 592 [20480/90000 (23%)]	Loss: 3.7407	Cost: 12.68s
Train Epoch: 592 [40960/90000 (45%)]	Loss: 3.8965	Cost: 6.45s
Train Epoch: 592 [61440/90000 (68%)]	Loss: 3.6091	Cost: 6.25s
Train Epoch: 592 [81920/90000 (91%)]	Loss: 3.9847	Cost: 8.11s
Train Epoch: 592 	Average Loss: 3.9035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6920

Learning rate: 9.913775442559442e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 593 [0/90000 (0%)]	Loss: 5.4827	Cost: 19.80s
Train Epoch: 593 [20480/90000 (23%)]	Loss: 3.8966	Cost: 6.22s
Train Epoch: 593 [40960/90000 (45%)]	Loss: 3.8029	Cost: 10.27s
Train Epoch: 593 [61440/90000 (68%)]	Loss: 3.7648	Cost: 8.56s
Train Epoch: 593 [81920/90000 (91%)]	Loss: 3.7041	Cost: 8.39s
Train Epoch: 593 	Average Loss: 3.9108
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5387

Learning rate: 9.913484741038609e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 594 [0/90000 (0%)]	Loss: 5.3264	Cost: 20.72s
Train Epoch: 594 [20480/90000 (23%)]	Loss: 3.7139	Cost: 8.88s
Train Epoch: 594 [40960/90000 (45%)]	Loss: 3.6828	Cost: 9.19s
Train Epoch: 594 [61440/90000 (68%)]	Loss: 3.6879	Cost: 6.18s
Train Epoch: 594 [81920/90000 (91%)]	Loss: 3.9266	Cost: 6.45s
Train Epoch: 594 	Average Loss: 3.8864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5200

Learning rate: 9.913193554576272e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 595 [0/90000 (0%)]	Loss: 5.8377	Cost: 26.10s
Train Epoch: 595 [20480/90000 (23%)]	Loss: 3.7198	Cost: 10.65s
Train Epoch: 595 [40960/90000 (45%)]	Loss: 3.5900	Cost: 11.62s
Train Epoch: 595 [61440/90000 (68%)]	Loss: 3.6057	Cost: 12.82s
Train Epoch: 595 [81920/90000 (91%)]	Loss: 3.7884	Cost: 12.20s
Train Epoch: 595 	Average Loss: 3.8732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4753

Learning rate: 9.912901883201172e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 596 [0/90000 (0%)]	Loss: 5.1693	Cost: 34.41s
Train Epoch: 596 [20480/90000 (23%)]	Loss: 3.6736	Cost: 14.39s
Train Epoch: 596 [40960/90000 (45%)]	Loss: 3.7016	Cost: 13.04s
Train Epoch: 596 [61440/90000 (68%)]	Loss: 3.5796	Cost: 12.30s
Train Epoch: 596 [81920/90000 (91%)]	Loss: 3.7635	Cost: 12.12s
Train Epoch: 596 	Average Loss: 3.8085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5097

Learning rate: 9.912609726942096e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 597 [0/90000 (0%)]	Loss: 5.8086	Cost: 24.67s
Train Epoch: 597 [20480/90000 (23%)]	Loss: 3.7756	Cost: 10.65s
Train Epoch: 597 [40960/90000 (45%)]	Loss: 3.8214	Cost: 13.04s
Train Epoch: 597 [61440/90000 (68%)]	Loss: 3.7664	Cost: 12.29s
Train Epoch: 597 [81920/90000 (91%)]	Loss: 3.6440	Cost: 8.79s
Train Epoch: 597 	Average Loss: 3.8045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4417

Saving model as e597_model.pt & e597_waveforms_supplementary.hdf5
Learning rate: 9.912317085827877e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 598 [0/90000 (0%)]	Loss: 5.4137	Cost: 22.82s
Train Epoch: 598 [20480/90000 (23%)]	Loss: 3.6908	Cost: 9.20s
Train Epoch: 598 [40960/90000 (45%)]	Loss: 3.7817	Cost: 10.08s
Train Epoch: 598 [61440/90000 (68%)]	Loss: 3.5633	Cost: 6.47s
Train Epoch: 598 [81920/90000 (91%)]	Loss: 3.6366	Cost: 7.17s
Train Epoch: 598 	Average Loss: 3.8211
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4498

Learning rate: 9.9120239598874e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 599 [0/90000 (0%)]	Loss: 5.4738	Cost: 21.22s
Train Epoch: 599 [20480/90000 (23%)]	Loss: 3.7521	Cost: 6.61s
Train Epoch: 599 [40960/90000 (45%)]	Loss: 3.6600	Cost: 9.36s
Train Epoch: 599 [61440/90000 (68%)]	Loss: 3.6111	Cost: 9.32s
Train Epoch: 599 [81920/90000 (91%)]	Loss: 3.6925	Cost: 8.99s
Train Epoch: 599 	Average Loss: 3.7690
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5059

Learning rate: 9.911730349149594e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 600 [0/90000 (0%)]	Loss: 5.4596	Cost: 27.55s
Train Epoch: 600 [20480/90000 (23%)]	Loss: 3.6747	Cost: 8.87s
Train Epoch: 600 [40960/90000 (45%)]	Loss: 3.7050	Cost: 9.26s
Train Epoch: 600 [61440/90000 (68%)]	Loss: 3.6055	Cost: 7.68s
Train Epoch: 600 [81920/90000 (91%)]	Loss: 3.7710	Cost: 6.15s
Train Epoch: 600 	Average Loss: 3.7379
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4825

Learning rate: 9.911436253643436e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 601 [0/90000 (0%)]	Loss: 5.1872	Cost: 32.01s
Train Epoch: 601 [20480/90000 (23%)]	Loss: 3.8199	Cost: 6.72s
Train Epoch: 601 [40960/90000 (45%)]	Loss: 3.5212	Cost: 10.31s
Train Epoch: 601 [61440/90000 (68%)]	Loss: 3.6489	Cost: 10.65s
Train Epoch: 601 [81920/90000 (91%)]	Loss: 3.8316	Cost: 12.38s
Train Epoch: 601 	Average Loss: 3.7460
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4683

Learning rate: 9.911141673397953e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 602 [0/90000 (0%)]	Loss: 5.1545	Cost: 21.09s
Train Epoch: 602 [20480/90000 (23%)]	Loss: 3.5866	Cost: 11.46s
Train Epoch: 602 [40960/90000 (45%)]	Loss: 3.5788	Cost: 14.62s
Train Epoch: 602 [61440/90000 (68%)]	Loss: 3.4199	Cost: 12.58s
Train Epoch: 602 [81920/90000 (91%)]	Loss: 3.6012	Cost: 12.59s
Train Epoch: 602 	Average Loss: 3.6801
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4157

Saving model as e602_model.pt & e602_waveforms_supplementary.hdf5
Learning rate: 9.91084660844222e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 603 [0/90000 (0%)]	Loss: 5.5344	Cost: 22.88s
Train Epoch: 603 [20480/90000 (23%)]	Loss: 3.5249	Cost: 13.14s
Train Epoch: 603 [40960/90000 (45%)]	Loss: 3.6787	Cost: 12.83s
Train Epoch: 603 [61440/90000 (68%)]	Loss: 3.6621	Cost: 11.84s
Train Epoch: 603 [81920/90000 (91%)]	Loss: 3.6391	Cost: 6.58s
Train Epoch: 603 	Average Loss: 3.7166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4248

Learning rate: 9.910551058805357e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 604 [0/90000 (0%)]	Loss: 5.2336	Cost: 24.15s
Train Epoch: 604 [20480/90000 (23%)]	Loss: 3.6495	Cost: 10.93s
Train Epoch: 604 [40960/90000 (45%)]	Loss: 3.4770	Cost: 10.52s
Train Epoch: 604 [61440/90000 (68%)]	Loss: 3.5064	Cost: 6.15s
Train Epoch: 604 [81920/90000 (91%)]	Loss: 3.6285	Cost: 6.81s
Train Epoch: 604 	Average Loss: 3.6973
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4340

Learning rate: 9.910255024516536e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 605 [0/90000 (0%)]	Loss: 5.2072	Cost: 27.25s
Train Epoch: 605 [20480/90000 (23%)]	Loss: 3.7445	Cost: 12.49s
Train Epoch: 605 [40960/90000 (45%)]	Loss: 3.7057	Cost: 8.76s
Train Epoch: 605 [61440/90000 (68%)]	Loss: 3.5324	Cost: 7.00s
Train Epoch: 605 [81920/90000 (91%)]	Loss: 3.5612	Cost: 8.55s
Train Epoch: 605 	Average Loss: 3.6773
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3863

Saving model as e605_model.pt & e605_waveforms_supplementary.hdf5
Learning rate: 9.909958505604974e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 606 [0/90000 (0%)]	Loss: 5.3425	Cost: 38.39s
Train Epoch: 606 [20480/90000 (23%)]	Loss: 3.6032	Cost: 10.23s
Train Epoch: 606 [40960/90000 (45%)]	Loss: 3.6112	Cost: 10.18s
Train Epoch: 606 [61440/90000 (68%)]	Loss: 3.5121	Cost: 8.79s
Train Epoch: 606 [81920/90000 (91%)]	Loss: 3.7551	Cost: 8.81s
Train Epoch: 606 	Average Loss: 3.6919
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3426

Saving model as e606_model.pt & e606_waveforms_supplementary.hdf5
Learning rate: 9.909661502099934e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 607 [0/90000 (0%)]	Loss: 5.2132	Cost: 21.41s
Train Epoch: 607 [20480/90000 (23%)]	Loss: 3.4151	Cost: 9.18s
Train Epoch: 607 [40960/90000 (45%)]	Loss: 3.5852	Cost: 6.46s
Train Epoch: 607 [61440/90000 (68%)]	Loss: 3.3898	Cost: 7.84s
Train Epoch: 607 [81920/90000 (91%)]	Loss: 3.5527	Cost: 14.13s
Train Epoch: 607 	Average Loss: 3.6597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4187

Learning rate: 9.90936401403073e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 608 [0/90000 (0%)]	Loss: 5.3075	Cost: 21.43s
Train Epoch: 608 [20480/90000 (23%)]	Loss: 3.4468	Cost: 8.61s
Train Epoch: 608 [40960/90000 (45%)]	Loss: 3.4021	Cost: 12.99s
Train Epoch: 608 [61440/90000 (68%)]	Loss: 3.5022	Cost: 12.51s
Train Epoch: 608 [81920/90000 (91%)]	Loss: 3.5409	Cost: 12.26s
Train Epoch: 608 	Average Loss: 3.6483
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3958

Learning rate: 9.909066041426725e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 609 [0/90000 (0%)]	Loss: 5.4632	Cost: 28.92s
Train Epoch: 609 [20480/90000 (23%)]	Loss: 3.4905	Cost: 15.27s
Train Epoch: 609 [40960/90000 (45%)]	Loss: 3.4005	Cost: 13.38s
Train Epoch: 609 [61440/90000 (68%)]	Loss: 3.4028	Cost: 12.19s
Train Epoch: 609 [81920/90000 (91%)]	Loss: 3.6510	Cost: 8.24s
Train Epoch: 609 	Average Loss: 3.6218
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4918

Learning rate: 9.908767584317324e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 610 [0/90000 (0%)]	Loss: 5.4543	Cost: 43.52s
Train Epoch: 610 [20480/90000 (23%)]	Loss: 3.5247	Cost: 12.32s
Train Epoch: 610 [40960/90000 (45%)]	Loss: 3.5771	Cost: 10.98s
Train Epoch: 610 [61440/90000 (68%)]	Loss: 3.5105	Cost: 6.11s
Train Epoch: 610 [81920/90000 (91%)]	Loss: 3.6210	Cost: 6.86s
Train Epoch: 610 	Average Loss: 3.6664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3917

Learning rate: 9.908468642731985e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 611 [0/90000 (0%)]	Loss: 5.1175	Cost: 31.40s
Train Epoch: 611 [20480/90000 (23%)]	Loss: 3.5768	Cost: 6.38s
Train Epoch: 611 [40960/90000 (45%)]	Loss: 3.6324	Cost: 8.16s
Train Epoch: 611 [61440/90000 (68%)]	Loss: 3.5498	Cost: 8.49s
Train Epoch: 611 [81920/90000 (91%)]	Loss: 3.6082	Cost: 8.54s
Train Epoch: 611 	Average Loss: 3.6397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4590

Learning rate: 9.908169216700214e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 612 [0/90000 (0%)]	Loss: 5.4834	Cost: 18.27s
Train Epoch: 612 [20480/90000 (23%)]	Loss: 3.5247	Cost: 6.62s
Train Epoch: 612 [40960/90000 (45%)]	Loss: 3.6282	Cost: 10.71s
Train Epoch: 612 [61440/90000 (68%)]	Loss: 3.5279	Cost: 8.82s
Train Epoch: 612 [81920/90000 (91%)]	Loss: 3.7375	Cost: 9.62s
Train Epoch: 612 	Average Loss: 3.6650
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3514

Learning rate: 9.907869306251562e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 613 [0/90000 (0%)]	Loss: 5.3146	Cost: 18.60s
Train Epoch: 613 [20480/90000 (23%)]	Loss: 3.5405	Cost: 9.52s
Train Epoch: 613 [40960/90000 (45%)]	Loss: 3.4736	Cost: 7.42s
Train Epoch: 613 [61440/90000 (68%)]	Loss: 3.2988	Cost: 9.92s
Train Epoch: 613 [81920/90000 (91%)]	Loss: 3.5092	Cost: 10.74s
Train Epoch: 613 	Average Loss: 3.5788
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3234

Saving model as e613_model.pt & e613_waveforms_supplementary.hdf5
Learning rate: 9.907568911415629e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 614 [0/90000 (0%)]	Loss: 5.0256	Cost: 23.63s
Train Epoch: 614 [20480/90000 (23%)]	Loss: 3.4722	Cost: 11.09s
Train Epoch: 614 [40960/90000 (45%)]	Loss: 3.5931	Cost: 14.52s
Train Epoch: 614 [61440/90000 (68%)]	Loss: 3.4082	Cost: 12.36s
Train Epoch: 614 [81920/90000 (91%)]	Loss: 3.6582	Cost: 12.07s
Train Epoch: 614 	Average Loss: 3.5756
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3521

Learning rate: 9.907268032222063e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 615 [0/90000 (0%)]	Loss: 5.3062	Cost: 34.85s
Train Epoch: 615 [20480/90000 (23%)]	Loss: 3.4799	Cost: 12.52s
Train Epoch: 615 [40960/90000 (45%)]	Loss: 3.4061	Cost: 12.30s
Train Epoch: 615 [61440/90000 (68%)]	Loss: 3.4358	Cost: 10.66s
Train Epoch: 615 [81920/90000 (91%)]	Loss: 3.4120	Cost: 6.24s
Train Epoch: 615 	Average Loss: 3.5282
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2249

Saving model as e615_model.pt & e615_waveforms_supplementary.hdf5
Learning rate: 9.906966668700558e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 616 [0/90000 (0%)]	Loss: 5.1496	Cost: 29.13s
Train Epoch: 616 [20480/90000 (23%)]	Loss: 3.3056	Cost: 7.99s
Train Epoch: 616 [40960/90000 (45%)]	Loss: 3.4627	Cost: 6.79s
Train Epoch: 616 [61440/90000 (68%)]	Loss: 3.3687	Cost: 7.23s
Train Epoch: 616 [81920/90000 (91%)]	Loss: 3.4701	Cost: 9.05s
Train Epoch: 616 	Average Loss: 3.5037
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2460

Learning rate: 9.90666482088086e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 617 [0/90000 (0%)]	Loss: 5.1550	Cost: 23.40s
Train Epoch: 617 [20480/90000 (23%)]	Loss: 3.5752	Cost: 9.06s
Train Epoch: 617 [40960/90000 (45%)]	Loss: 3.5267	Cost: 10.76s
Train Epoch: 617 [61440/90000 (68%)]	Loss: 3.2707	Cost: 9.21s
Train Epoch: 617 [81920/90000 (91%)]	Loss: 3.4180	Cost: 8.87s
Train Epoch: 617 	Average Loss: 3.5087
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2117

Saving model as e617_model.pt & e617_waveforms_supplementary.hdf5
Learning rate: 9.906362488792757e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 618 [0/90000 (0%)]	Loss: 5.3112	Cost: 31.94s
Train Epoch: 618 [20480/90000 (23%)]	Loss: 3.3263	Cost: 9.47s
Train Epoch: 618 [40960/90000 (45%)]	Loss: 3.2283	Cost: 7.67s
Train Epoch: 618 [61440/90000 (68%)]	Loss: 3.2654	Cost: 6.82s
Train Epoch: 618 [81920/90000 (91%)]	Loss: 3.4712	Cost: 13.59s
Train Epoch: 618 	Average Loss: 3.4529
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2684

Learning rate: 9.906059672466091e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 619 [0/90000 (0%)]	Loss: 5.1655	Cost: 21.60s
Train Epoch: 619 [20480/90000 (23%)]	Loss: 3.3562	Cost: 7.92s
Train Epoch: 619 [40960/90000 (45%)]	Loss: 3.3465	Cost: 13.66s
Train Epoch: 619 [61440/90000 (68%)]	Loss: 3.1100	Cost: 12.77s
Train Epoch: 619 [81920/90000 (91%)]	Loss: 3.3224	Cost: 12.27s
Train Epoch: 619 	Average Loss: 3.4426
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2994

Learning rate: 9.905756371930748e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 620 [0/90000 (0%)]	Loss: 5.3199	Cost: 24.69s
Train Epoch: 620 [20480/90000 (23%)]	Loss: 3.3766	Cost: 14.36s
Train Epoch: 620 [40960/90000 (45%)]	Loss: 3.4089	Cost: 12.30s
Train Epoch: 620 [61440/90000 (68%)]	Loss: 3.4165	Cost: 12.21s
Train Epoch: 620 [81920/90000 (91%)]	Loss: 3.5274	Cost: 10.97s
Train Epoch: 620 	Average Loss: 3.5170
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3700

Learning rate: 9.905452587216662e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 621 [0/90000 (0%)]	Loss: 5.2030	Cost: 25.75s
Train Epoch: 621 [20480/90000 (23%)]	Loss: 3.4198	Cost: 12.51s
Train Epoch: 621 [40960/90000 (45%)]	Loss: 3.4249	Cost: 12.59s
Train Epoch: 621 [61440/90000 (68%)]	Loss: 3.2978	Cost: 6.85s
Train Epoch: 621 [81920/90000 (91%)]	Loss: 3.5955	Cost: 6.27s
Train Epoch: 621 	Average Loss: 3.4958
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2687

Learning rate: 9.905148318353815e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 622 [0/90000 (0%)]	Loss: 5.0819	Cost: 33.46s
Train Epoch: 622 [20480/90000 (23%)]	Loss: 3.3938	Cost: 11.58s
Train Epoch: 622 [40960/90000 (45%)]	Loss: 3.2728	Cost: 9.47s
Train Epoch: 622 [61440/90000 (68%)]	Loss: 3.3464	Cost: 7.63s
Train Epoch: 622 [81920/90000 (91%)]	Loss: 3.2115	Cost: 8.62s
Train Epoch: 622 	Average Loss: 3.4253
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2092

Saving model as e622_model.pt & e622_waveforms_supplementary.hdf5
Learning rate: 9.904843565372238e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 623 [0/90000 (0%)]	Loss: 5.0564	Cost: 22.38s
Train Epoch: 623 [20480/90000 (23%)]	Loss: 3.3468	Cost: 10.18s
Train Epoch: 623 [40960/90000 (45%)]	Loss: 3.1710	Cost: 11.98s
Train Epoch: 623 [61440/90000 (68%)]	Loss: 3.2906	Cost: 8.84s
Train Epoch: 623 [81920/90000 (91%)]	Loss: 3.3508	Cost: 8.73s
Train Epoch: 623 	Average Loss: 3.3703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2182

Learning rate: 9.904538328302008e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 624 [0/90000 (0%)]	Loss: 4.9296	Cost: 23.97s
Train Epoch: 624 [20480/90000 (23%)]	Loss: 3.2571	Cost: 9.02s
Train Epoch: 624 [40960/90000 (45%)]	Loss: 3.3673	Cost: 7.96s
Train Epoch: 624 [61440/90000 (68%)]	Loss: 3.2800	Cost: 7.18s
Train Epoch: 624 [81920/90000 (91%)]	Loss: 3.3208	Cost: 6.32s
Train Epoch: 624 	Average Loss: 3.3776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1641

Saving model as e624_model.pt & e624_waveforms_supplementary.hdf5
Learning rate: 9.904232607173254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 625 [0/90000 (0%)]	Loss: 5.1187	Cost: 19.62s
Train Epoch: 625 [20480/90000 (23%)]	Loss: 3.2892	Cost: 9.43s
Train Epoch: 625 [40960/90000 (45%)]	Loss: 3.2991	Cost: 10.65s
Train Epoch: 625 [61440/90000 (68%)]	Loss: 3.1937	Cost: 12.29s
Train Epoch: 625 [81920/90000 (91%)]	Loss: 3.2893	Cost: 12.30s
Train Epoch: 625 	Average Loss: 3.3282
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1580

Saving model as e625_model.pt & e625_waveforms_supplementary.hdf5
Learning rate: 9.903926402016143e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 626 [0/90000 (0%)]	Loss: 4.8970	Cost: 23.79s
Train Epoch: 626 [20480/90000 (23%)]	Loss: 3.1021	Cost: 12.37s
Train Epoch: 626 [40960/90000 (45%)]	Loss: 3.3711	Cost: 12.18s
Train Epoch: 626 [61440/90000 (68%)]	Loss: 3.2177	Cost: 12.58s
Train Epoch: 626 [81920/90000 (91%)]	Loss: 3.3402	Cost: 12.30s
Train Epoch: 626 	Average Loss: 3.3832
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3469

Learning rate: 9.903619712860903e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 627 [0/90000 (0%)]	Loss: 5.1340	Cost: 40.99s
Train Epoch: 627 [20480/90000 (23%)]	Loss: 3.2973	Cost: 12.63s
Train Epoch: 627 [40960/90000 (45%)]	Loss: 3.3721	Cost: 12.17s
Train Epoch: 627 [61440/90000 (68%)]	Loss: 3.2316	Cost: 9.97s
Train Epoch: 627 [81920/90000 (91%)]	Loss: 3.3377	Cost: 6.08s
Train Epoch: 627 	Average Loss: 3.4067
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2215

Learning rate: 9.903312539737797e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 628 [0/90000 (0%)]	Loss: 5.0891	Cost: 40.14s
Train Epoch: 628 [20480/90000 (23%)]	Loss: 3.1451	Cost: 10.72s
Train Epoch: 628 [40960/90000 (45%)]	Loss: 3.1690	Cost: 9.25s
Train Epoch: 628 [61440/90000 (68%)]	Loss: 3.2375	Cost: 6.38s
Train Epoch: 628 [81920/90000 (91%)]	Loss: 3.1305	Cost: 7.34s
Train Epoch: 628 	Average Loss: 3.2943
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1762

Learning rate: 9.903004882677146e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 629 [0/90000 (0%)]	Loss: 5.2214	Cost: 32.14s
Train Epoch: 629 [20480/90000 (23%)]	Loss: 3.2565	Cost: 11.53s
Train Epoch: 629 [40960/90000 (45%)]	Loss: 3.2889	Cost: 6.53s
Train Epoch: 629 [61440/90000 (68%)]	Loss: 3.2381	Cost: 6.32s
Train Epoch: 629 [81920/90000 (91%)]	Loss: 3.3122	Cost: 8.51s
Train Epoch: 629 	Average Loss: 3.3738
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1901

Learning rate: 9.902696741709314e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 630 [0/90000 (0%)]	Loss: 5.2469	Cost: 20.46s
Train Epoch: 630 [20480/90000 (23%)]	Loss: 3.3120	Cost: 8.57s
Train Epoch: 630 [40960/90000 (45%)]	Loss: 3.2851	Cost: 9.04s
Train Epoch: 630 [61440/90000 (68%)]	Loss: 3.1546	Cost: 8.68s
Train Epoch: 630 [81920/90000 (91%)]	Loss: 3.2876	Cost: 8.58s
Train Epoch: 630 	Average Loss: 3.2931
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1681

Learning rate: 9.902388116864713e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 631 [0/90000 (0%)]	Loss: 5.0874	Cost: 20.19s
Train Epoch: 631 [20480/90000 (23%)]	Loss: 3.0773	Cost: 10.04s
Train Epoch: 631 [40960/90000 (45%)]	Loss: 3.0080	Cost: 9.17s
Train Epoch: 631 [61440/90000 (68%)]	Loss: 2.9949	Cost: 6.31s
Train Epoch: 631 [81920/90000 (91%)]	Loss: 3.3740	Cost: 7.02s
Train Epoch: 631 	Average Loss: 3.2774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1254

Saving model as e631_model.pt & e631_waveforms_supplementary.hdf5
Learning rate: 9.902079008173801e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 632 [0/90000 (0%)]	Loss: 5.2236	Cost: 21.87s
Train Epoch: 632 [20480/90000 (23%)]	Loss: 3.0777	Cost: 8.62s
Train Epoch: 632 [40960/90000 (45%)]	Loss: 3.1152	Cost: 9.24s
Train Epoch: 632 [61440/90000 (68%)]	Loss: 3.0553	Cost: 7.28s
Train Epoch: 632 [81920/90000 (91%)]	Loss: 3.1331	Cost: 15.84s
Train Epoch: 632 	Average Loss: 3.2421
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1535

Learning rate: 9.90176941566709e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 633 [0/90000 (0%)]	Loss: 5.0678	Cost: 24.43s
Train Epoch: 633 [20480/90000 (23%)]	Loss: 3.2158	Cost: 10.75s
Train Epoch: 633 [40960/90000 (45%)]	Loss: 3.1055	Cost: 15.95s
Train Epoch: 633 [61440/90000 (68%)]	Loss: 3.0378	Cost: 12.58s
Train Epoch: 633 [81920/90000 (91%)]	Loss: 3.1487	Cost: 12.45s
Train Epoch: 633 	Average Loss: 3.2095
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0507

Saving model as e633_model.pt & e633_waveforms_supplementary.hdf5
Learning rate: 9.90145933937513e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 634 [0/90000 (0%)]	Loss: 5.1157	Cost: 26.38s
Train Epoch: 634 [20480/90000 (23%)]	Loss: 3.1384	Cost: 13.09s
Train Epoch: 634 [40960/90000 (45%)]	Loss: 3.4166	Cost: 13.23s
Train Epoch: 634 [61440/90000 (68%)]	Loss: 3.0870	Cost: 12.22s
Train Epoch: 634 [81920/90000 (91%)]	Loss: 3.2510	Cost: 9.28s
Train Epoch: 634 	Average Loss: 3.2543
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1323

Learning rate: 9.901148779328529e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 635 [0/90000 (0%)]	Loss: 5.2097	Cost: 25.20s
Train Epoch: 635 [20480/90000 (23%)]	Loss: 3.1291	Cost: 12.59s
Train Epoch: 635 [40960/90000 (45%)]	Loss: 2.9964	Cost: 10.76s
Train Epoch: 635 [61440/90000 (68%)]	Loss: 3.0386	Cost: 6.28s
Train Epoch: 635 [81920/90000 (91%)]	Loss: 3.1813	Cost: 6.84s
Train Epoch: 635 	Average Loss: 3.1919
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0617

Learning rate: 9.900837735557936e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 636 [0/90000 (0%)]	Loss: 5.1337	Cost: 25.01s
Train Epoch: 636 [20480/90000 (23%)]	Loss: 3.0144	Cost: 9.52s
Train Epoch: 636 [40960/90000 (45%)]	Loss: 3.1584	Cost: 11.05s
Train Epoch: 636 [61440/90000 (68%)]	Loss: 3.2555	Cost: 11.16s
Train Epoch: 636 [81920/90000 (91%)]	Loss: 3.2662	Cost: 10.27s
Train Epoch: 636 	Average Loss: 3.2073
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1409

Learning rate: 9.90052620809405e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 637 [0/90000 (0%)]	Loss: 4.9548	Cost: 24.26s
Train Epoch: 637 [20480/90000 (23%)]	Loss: 3.0303	Cost: 9.89s
Train Epoch: 637 [40960/90000 (45%)]	Loss: 3.0381	Cost: 10.45s
Train Epoch: 637 [61440/90000 (68%)]	Loss: 3.0519	Cost: 8.83s
Train Epoch: 637 [81920/90000 (91%)]	Loss: 3.1599	Cost: 8.64s
Train Epoch: 637 	Average Loss: 3.1925
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0668

Learning rate: 9.900214196967617e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 638 [0/90000 (0%)]	Loss: 4.9302	Cost: 32.25s
Train Epoch: 638 [20480/90000 (23%)]	Loss: 2.9645	Cost: 8.94s
Train Epoch: 638 [40960/90000 (45%)]	Loss: 3.1040	Cost: 6.59s
Train Epoch: 638 [61440/90000 (68%)]	Loss: 2.9749	Cost: 6.84s
Train Epoch: 638 [81920/90000 (91%)]	Loss: 3.0715	Cost: 12.16s
Train Epoch: 638 	Average Loss: 3.1314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0784

Learning rate: 9.899901702209434e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 639 [0/90000 (0%)]	Loss: 4.8959	Cost: 21.32s
Train Epoch: 639 [20480/90000 (23%)]	Loss: 2.9963	Cost: 8.58s
Train Epoch: 639 [40960/90000 (45%)]	Loss: 3.0008	Cost: 13.24s
Train Epoch: 639 [61440/90000 (68%)]	Loss: 2.9764	Cost: 12.83s
Train Epoch: 639 [81920/90000 (91%)]	Loss: 3.2550	Cost: 12.52s
Train Epoch: 639 	Average Loss: 3.1423
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0755

Learning rate: 9.899588723850338e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 640 [0/90000 (0%)]	Loss: 4.8267	Cost: 28.69s
Train Epoch: 640 [20480/90000 (23%)]	Loss: 3.0386	Cost: 13.00s
Train Epoch: 640 [40960/90000 (45%)]	Loss: 3.1334	Cost: 13.61s
Train Epoch: 640 [61440/90000 (68%)]	Loss: 3.0033	Cost: 12.57s
Train Epoch: 640 [81920/90000 (91%)]	Loss: 3.1660	Cost: 10.23s
Train Epoch: 640 	Average Loss: 3.2205
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0374

Saving model as e640_model.pt & e640_waveforms_supplementary.hdf5
Learning rate: 9.899275261921224e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 641 [0/90000 (0%)]	Loss: 5.0004	Cost: 28.36s
Train Epoch: 641 [20480/90000 (23%)]	Loss: 2.9849	Cost: 13.46s
Train Epoch: 641 [40960/90000 (45%)]	Loss: 3.0674	Cost: 12.11s
Train Epoch: 641 [61440/90000 (68%)]	Loss: 2.9141	Cost: 6.00s
Train Epoch: 641 [81920/90000 (91%)]	Loss: 3.1675	Cost: 6.98s
Train Epoch: 641 	Average Loss: 3.1236
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8714

Saving model as e641_model.pt & e641_waveforms_supplementary.hdf5
Learning rate: 9.898961316453026e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 642 [0/90000 (0%)]	Loss: 4.8154	Cost: 29.09s
Train Epoch: 642 [20480/90000 (23%)]	Loss: 3.0115	Cost: 6.55s
Train Epoch: 642 [40960/90000 (45%)]	Loss: 3.0436	Cost: 9.00s
Train Epoch: 642 [61440/90000 (68%)]	Loss: 3.0849	Cost: 8.69s
Train Epoch: 642 [81920/90000 (91%)]	Loss: 3.2012	Cost: 8.76s
Train Epoch: 642 	Average Loss: 3.1137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0777

Learning rate: 9.898646887476729e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 643 [0/90000 (0%)]	Loss: 5.0043	Cost: 22.50s
Train Epoch: 643 [20480/90000 (23%)]	Loss: 3.0575	Cost: 8.13s
Train Epoch: 643 [40960/90000 (45%)]	Loss: 2.9179	Cost: 8.93s
Train Epoch: 643 [61440/90000 (68%)]	Loss: 2.8079	Cost: 8.55s
Train Epoch: 643 [81920/90000 (91%)]	Loss: 3.1116	Cost: 8.39s
Train Epoch: 643 	Average Loss: 3.0809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0850

Learning rate: 9.898331975023371e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 644 [0/90000 (0%)]	Loss: 4.8119	Cost: 23.98s
Train Epoch: 644 [20480/90000 (23%)]	Loss: 3.0659	Cost: 11.27s
Train Epoch: 644 [40960/90000 (45%)]	Loss: 2.7978	Cost: 9.20s
Train Epoch: 644 [61440/90000 (68%)]	Loss: 2.9230	Cost: 6.76s
Train Epoch: 644 [81920/90000 (91%)]	Loss: 2.9857	Cost: 8.44s
Train Epoch: 644 	Average Loss: 3.0783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0284

Learning rate: 9.898016579124025e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 645 [0/90000 (0%)]	Loss: 4.9630	Cost: 19.89s
Train Epoch: 645 [20480/90000 (23%)]	Loss: 2.9242	Cost: 9.44s
Train Epoch: 645 [40960/90000 (45%)]	Loss: 2.8786	Cost: 17.52s
Train Epoch: 645 [61440/90000 (68%)]	Loss: 2.8795	Cost: 14.42s
Train Epoch: 645 [81920/90000 (91%)]	Loss: 3.0230	Cost: 12.12s
Train Epoch: 645 	Average Loss: 3.0404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0364

Learning rate: 9.897700699809825e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 646 [0/90000 (0%)]	Loss: 4.9970	Cost: 31.28s
Train Epoch: 646 [20480/90000 (23%)]	Loss: 2.8752	Cost: 14.83s
Train Epoch: 646 [40960/90000 (45%)]	Loss: 2.9136	Cost: 12.53s
Train Epoch: 646 [61440/90000 (68%)]	Loss: 2.8776	Cost: 12.17s
Train Epoch: 646 [81920/90000 (91%)]	Loss: 3.0733	Cost: 10.33s
Train Epoch: 646 	Average Loss: 3.0257
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9179

Learning rate: 9.897384337111944e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 647 [0/90000 (0%)]	Loss: 4.7644	Cost: 25.22s
Train Epoch: 647 [20480/90000 (23%)]	Loss: 2.8813	Cost: 10.03s
Train Epoch: 647 [40960/90000 (45%)]	Loss: 2.7554	Cost: 12.53s
Train Epoch: 647 [61440/90000 (68%)]	Loss: 2.7900	Cost: 12.31s
Train Epoch: 647 [81920/90000 (91%)]	Loss: 2.8062	Cost: 7.81s
Train Epoch: 647 	Average Loss: 2.9955
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8367

Saving model as e647_model.pt & e647_waveforms_supplementary.hdf5
Learning rate: 9.897067491061608e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 648 [0/90000 (0%)]	Loss: 4.8726	Cost: 29.77s
Train Epoch: 648 [20480/90000 (23%)]	Loss: 2.7842	Cost: 8.50s
Train Epoch: 648 [40960/90000 (45%)]	Loss: 2.8221	Cost: 6.53s
Train Epoch: 648 [61440/90000 (68%)]	Loss: 2.8248	Cost: 7.01s
Train Epoch: 648 [81920/90000 (91%)]	Loss: 2.8493	Cost: 9.08s
Train Epoch: 648 	Average Loss: 2.9468
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9180

Learning rate: 9.896750161690087e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 649 [0/90000 (0%)]	Loss: 4.9070	Cost: 21.31s
Train Epoch: 649 [20480/90000 (23%)]	Loss: 2.8235	Cost: 9.74s
Train Epoch: 649 [40960/90000 (45%)]	Loss: 2.8954	Cost: 10.11s
Train Epoch: 649 [61440/90000 (68%)]	Loss: 2.6870	Cost: 9.01s
Train Epoch: 649 [81920/90000 (91%)]	Loss: 2.9336	Cost: 8.71s
Train Epoch: 649 	Average Loss: 2.9334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9317

Learning rate: 9.8964323490287e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 650 [0/90000 (0%)]	Loss: 4.5745	Cost: 29.70s
Train Epoch: 650 [20480/90000 (23%)]	Loss: 2.8421	Cost: 11.82s
Train Epoch: 650 [40960/90000 (45%)]	Loss: 2.7275	Cost: 10.33s
Train Epoch: 650 [61440/90000 (68%)]	Loss: 2.6707	Cost: 6.30s
Train Epoch: 650 [81920/90000 (91%)]	Loss: 2.7822	Cost: 6.81s
Train Epoch: 650 	Average Loss: 2.9541
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9611

Learning rate: 9.896114053108814e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 651 [0/90000 (0%)]	Loss: 4.8764	Cost: 21.13s
Train Epoch: 651 [20480/90000 (23%)]	Loss: 2.7258	Cost: 6.92s
Train Epoch: 651 [40960/90000 (45%)]	Loss: 2.8496	Cost: 10.20s
Train Epoch: 651 [61440/90000 (68%)]	Loss: 2.6464	Cost: 10.92s
Train Epoch: 651 [81920/90000 (91%)]	Loss: 2.8798	Cost: 12.93s
Train Epoch: 651 	Average Loss: 2.9147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9368

Learning rate: 9.895795273961846e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 652 [0/90000 (0%)]	Loss: 5.0577	Cost: 24.03s
Train Epoch: 652 [20480/90000 (23%)]	Loss: 2.7248	Cost: 7.51s
Train Epoch: 652 [40960/90000 (45%)]	Loss: 2.7817	Cost: 13.07s
Train Epoch: 652 [61440/90000 (68%)]	Loss: 2.8870	Cost: 12.32s
Train Epoch: 652 [81920/90000 (91%)]	Loss: 3.0668	Cost: 12.13s
Train Epoch: 652 	Average Loss: 2.9956
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0145

Learning rate: 9.895476011619254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 653 [0/90000 (0%)]	Loss: 5.1188	Cost: 24.67s
Train Epoch: 653 [20480/90000 (23%)]	Loss: 2.9167	Cost: 13.00s
Train Epoch: 653 [40960/90000 (45%)]	Loss: 2.8070	Cost: 12.63s
Train Epoch: 653 [61440/90000 (68%)]	Loss: 2.7896	Cost: 12.41s
Train Epoch: 653 [81920/90000 (91%)]	Loss: 2.8978	Cost: 12.39s
Train Epoch: 653 	Average Loss: 3.0145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8837

Learning rate: 9.89515626611255e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 654 [0/90000 (0%)]	Loss: 4.7199	Cost: 24.65s
Train Epoch: 654 [20480/90000 (23%)]	Loss: 2.8699	Cost: 14.06s
Train Epoch: 654 [40960/90000 (45%)]	Loss: 2.9347	Cost: 12.17s
Train Epoch: 654 [61440/90000 (68%)]	Loss: 2.8017	Cost: 9.19s
Train Epoch: 654 [81920/90000 (91%)]	Loss: 2.7801	Cost: 6.12s
Train Epoch: 654 	Average Loss: 2.9005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7920

Saving model as e654_model.pt & e654_waveforms_supplementary.hdf5
Learning rate: 9.894836037473293e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 655 [0/90000 (0%)]	Loss: 4.5698	Cost: 34.07s
Train Epoch: 655 [20480/90000 (23%)]	Loss: 2.8229	Cost: 7.26s
Train Epoch: 655 [40960/90000 (45%)]	Loss: 2.6977	Cost: 8.76s
Train Epoch: 655 [61440/90000 (68%)]	Loss: 2.6681	Cost: 8.60s
Train Epoch: 655 [81920/90000 (91%)]	Loss: 2.7522	Cost: 8.43s
Train Epoch: 655 	Average Loss: 2.8207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8718

Learning rate: 9.894515325733087e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 656 [0/90000 (0%)]	Loss: 4.7652	Cost: 26.64s
Train Epoch: 656 [20480/90000 (23%)]	Loss: 2.6467	Cost: 7.89s
Train Epoch: 656 [40960/90000 (45%)]	Loss: 2.6942	Cost: 9.02s
Train Epoch: 656 [61440/90000 (68%)]	Loss: 2.6810	Cost: 8.76s
Train Epoch: 656 [81920/90000 (91%)]	Loss: 2.7835	Cost: 8.41s
Train Epoch: 656 	Average Loss: 2.8562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9013

Learning rate: 9.894194130923585e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 657 [0/90000 (0%)]	Loss: 5.1211	Cost: 22.46s
Train Epoch: 657 [20480/90000 (23%)]	Loss: 2.8237	Cost: 6.22s
Train Epoch: 657 [40960/90000 (45%)]	Loss: 3.1625	Cost: 12.07s
Train Epoch: 657 [61440/90000 (68%)]	Loss: 3.0186	Cost: 11.66s
Train Epoch: 657 [81920/90000 (91%)]	Loss: 2.9624	Cost: 13.93s
Train Epoch: 657 	Average Loss: 3.0756
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0275

Learning rate: 9.893872453076489e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 658 [0/90000 (0%)]	Loss: 4.6131	Cost: 21.75s
Train Epoch: 658 [20480/90000 (23%)]	Loss: 2.7733	Cost: 9.63s
Train Epoch: 658 [40960/90000 (45%)]	Loss: 2.9635	Cost: 14.89s
Train Epoch: 658 [61440/90000 (68%)]	Loss: 2.9925	Cost: 14.67s
Train Epoch: 658 [81920/90000 (91%)]	Loss: 3.2219	Cost: 12.47s
Train Epoch: 658 	Average Loss: 3.0975
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1661

Learning rate: 9.893550292223543e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 659 [0/90000 (0%)]	Loss: 5.1505	Cost: 27.49s
Train Epoch: 659 [20480/90000 (23%)]	Loss: 3.2277	Cost: 13.97s
Train Epoch: 659 [40960/90000 (45%)]	Loss: 3.0689	Cost: 12.90s
Train Epoch: 659 [61440/90000 (68%)]	Loss: 2.9348	Cost: 12.61s
Train Epoch: 659 [81920/90000 (91%)]	Loss: 2.9431	Cost: 7.89s
Train Epoch: 659 	Average Loss: 3.1825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8822

Learning rate: 9.893227648396548e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 660 [0/90000 (0%)]	Loss: 4.8930	Cost: 35.09s
Train Epoch: 660 [20480/90000 (23%)]	Loss: 2.6799	Cost: 10.32s
Train Epoch: 660 [40960/90000 (45%)]	Loss: 2.9261	Cost: 6.53s
Train Epoch: 660 [61440/90000 (68%)]	Loss: 2.8378	Cost: 6.29s
Train Epoch: 660 [81920/90000 (91%)]	Loss: 2.9362	Cost: 8.89s
Train Epoch: 660 	Average Loss: 2.9481
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9006

Learning rate: 9.892904521627345e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 661 [0/90000 (0%)]	Loss: 4.7699	Cost: 33.73s
Train Epoch: 661 [20480/90000 (23%)]	Loss: 2.8628	Cost: 6.45s
Train Epoch: 661 [40960/90000 (45%)]	Loss: 2.8675	Cost: 9.94s
Train Epoch: 661 [61440/90000 (68%)]	Loss: 2.7347	Cost: 8.56s
Train Epoch: 661 [81920/90000 (91%)]	Loss: 2.7105	Cost: 8.39s
Train Epoch: 661 	Average Loss: 2.9352
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9174

Learning rate: 9.892580911947826e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 662 [0/90000 (0%)]	Loss: 4.9527	Cost: 22.69s
Train Epoch: 662 [20480/90000 (23%)]	Loss: 2.9105	Cost: 12.26s
Train Epoch: 662 [40960/90000 (45%)]	Loss: 2.7583	Cost: 7.84s
Train Epoch: 662 [61440/90000 (68%)]	Loss: 2.5951	Cost: 9.21s
Train Epoch: 662 [81920/90000 (91%)]	Loss: 2.7185	Cost: 11.65s
Train Epoch: 662 	Average Loss: 2.8142
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6972

Saving model as e662_model.pt & e662_waveforms_supplementary.hdf5
Learning rate: 9.892256819389932e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 663 [0/90000 (0%)]	Loss: 4.6133	Cost: 22.80s
Train Epoch: 663 [20480/90000 (23%)]	Loss: 2.4892	Cost: 9.71s
Train Epoch: 663 [40960/90000 (45%)]	Loss: 2.7750	Cost: 14.18s
Train Epoch: 663 [61440/90000 (68%)]	Loss: 2.5059	Cost: 13.75s
Train Epoch: 663 [81920/90000 (91%)]	Loss: 2.6709	Cost: 12.19s
Train Epoch: 663 	Average Loss: 2.7054
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9209

Learning rate: 9.891932243985645e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 664 [0/90000 (0%)]	Loss: 5.0034	Cost: 30.14s
Train Epoch: 664 [20480/90000 (23%)]	Loss: 2.3702	Cost: 14.04s
Train Epoch: 664 [40960/90000 (45%)]	Loss: 2.5644	Cost: 12.58s
Train Epoch: 664 [61440/90000 (68%)]	Loss: 2.5300	Cost: 12.23s
Train Epoch: 664 [81920/90000 (91%)]	Loss: 2.5253	Cost: 12.36s
Train Epoch: 664 	Average Loss: 2.7402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7483

Learning rate: 9.891607185767004e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 665 [0/90000 (0%)]	Loss: 4.6571	Cost: 23.62s
Train Epoch: 665 [20480/90000 (23%)]	Loss: 2.6539	Cost: 12.81s
Train Epoch: 665 [40960/90000 (45%)]	Loss: 2.6491	Cost: 12.24s
Train Epoch: 665 [61440/90000 (68%)]	Loss: 2.5466	Cost: 11.77s
Train Epoch: 665 [81920/90000 (91%)]	Loss: 2.6580	Cost: 6.23s
Train Epoch: 665 	Average Loss: 2.7263
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8090

Learning rate: 9.891281644766087e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 666 [0/90000 (0%)]	Loss: 4.8672	Cost: 26.70s
Train Epoch: 666 [20480/90000 (23%)]	Loss: 2.5744	Cost: 11.14s
Train Epoch: 666 [40960/90000 (45%)]	Loss: 2.6426	Cost: 10.17s
Train Epoch: 666 [61440/90000 (68%)]	Loss: 2.5513	Cost: 6.36s
Train Epoch: 666 [81920/90000 (91%)]	Loss: 2.7364	Cost: 7.30s
Train Epoch: 666 	Average Loss: 2.7052
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7135

Learning rate: 9.890955621015026e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 667 [0/90000 (0%)]	Loss: 4.8463	Cost: 29.90s
Train Epoch: 667 [20480/90000 (23%)]	Loss: 2.6488	Cost: 6.55s
Train Epoch: 667 [40960/90000 (45%)]	Loss: 2.9379	Cost: 7.95s
Train Epoch: 667 [61440/90000 (68%)]	Loss: 2.6377	Cost: 9.48s
Train Epoch: 667 [81920/90000 (91%)]	Loss: 2.7336	Cost: 8.95s
Train Epoch: 667 	Average Loss: 2.8539
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8512

Learning rate: 9.890629114545997e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 668 [0/90000 (0%)]	Loss: 4.8140	Cost: 20.49s
Train Epoch: 668 [20480/90000 (23%)]	Loss: 2.6028	Cost: 9.65s
Train Epoch: 668 [40960/90000 (45%)]	Loss: 2.6174	Cost: 11.69s
Train Epoch: 668 [61440/90000 (68%)]	Loss: 2.5916	Cost: 9.91s
Train Epoch: 668 [81920/90000 (91%)]	Loss: 2.6473	Cost: 8.74s
Train Epoch: 668 	Average Loss: 2.7360
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7588

Learning rate: 9.890302125391226e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 669 [0/90000 (0%)]	Loss: 4.5577	Cost: 25.88s
Train Epoch: 669 [20480/90000 (23%)]	Loss: 2.7995	Cost: 9.08s
Train Epoch: 669 [40960/90000 (45%)]	Loss: 2.5969	Cost: 8.49s
Train Epoch: 669 [61440/90000 (68%)]	Loss: 2.6218	Cost: 6.72s
Train Epoch: 669 [81920/90000 (91%)]	Loss: 2.6106	Cost: 7.73s
Train Epoch: 669 	Average Loss: 2.7404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6698

Saving model as e669_model.pt & e669_waveforms_supplementary.hdf5
Learning rate: 9.889974653582986e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 670 [0/90000 (0%)]	Loss: 4.7282	Cost: 20.79s
Train Epoch: 670 [20480/90000 (23%)]	Loss: 2.5343	Cost: 8.11s
Train Epoch: 670 [40960/90000 (45%)]	Loss: 2.4998	Cost: 12.83s
Train Epoch: 670 [61440/90000 (68%)]	Loss: 2.5220	Cost: 12.60s
Train Epoch: 670 [81920/90000 (91%)]	Loss: 2.6258	Cost: 12.43s
Train Epoch: 670 	Average Loss: 2.6343
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7456

Learning rate: 9.889646699153596e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 671 [0/90000 (0%)]	Loss: 4.7255	Cost: 25.02s
Train Epoch: 671 [20480/90000 (23%)]	Loss: 2.4781	Cost: 12.85s
Train Epoch: 671 [40960/90000 (45%)]	Loss: 2.7600	Cost: 12.59s
Train Epoch: 671 [61440/90000 (68%)]	Loss: 2.4961	Cost: 12.34s
Train Epoch: 671 [81920/90000 (91%)]	Loss: 2.6528	Cost: 12.56s
Train Epoch: 671 	Average Loss: 2.7137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7966

Learning rate: 9.889318262135424e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 672 [0/90000 (0%)]	Loss: 4.3512	Cost: 23.98s
Train Epoch: 672 [20480/90000 (23%)]	Loss: 2.4928	Cost: 14.34s
Train Epoch: 672 [40960/90000 (45%)]	Loss: 2.6152	Cost: 12.14s
Train Epoch: 672 [61440/90000 (68%)]	Loss: 2.4185	Cost: 9.14s
Train Epoch: 672 [81920/90000 (91%)]	Loss: 2.6125	Cost: 6.13s
Train Epoch: 672 	Average Loss: 2.6572
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6402

Saving model as e672_model.pt & e672_waveforms_supplementary.hdf5
Learning rate: 9.888989342560885e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 673 [0/90000 (0%)]	Loss: 4.4462	Cost: 37.81s
Train Epoch: 673 [20480/90000 (23%)]	Loss: 2.4748	Cost: 6.95s
Train Epoch: 673 [40960/90000 (45%)]	Loss: 2.5581	Cost: 7.84s
Train Epoch: 673 [61440/90000 (68%)]	Loss: 2.3739	Cost: 7.82s
Train Epoch: 673 [81920/90000 (91%)]	Loss: 2.5143	Cost: 8.60s
Train Epoch: 673 	Average Loss: 2.6034
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6789

Learning rate: 9.888659940462443e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 674 [0/90000 (0%)]	Loss: 4.6438	Cost: 25.10s
Train Epoch: 674 [20480/90000 (23%)]	Loss: 2.4654	Cost: 8.36s
Train Epoch: 674 [40960/90000 (45%)]	Loss: 2.5127	Cost: 8.97s
Train Epoch: 674 [61440/90000 (68%)]	Loss: 3.4115	Cost: 8.62s
Train Epoch: 674 [81920/90000 (91%)]	Loss: 3.2401	Cost: 8.50s
Train Epoch: 674 	Average Loss: 2.8926
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2145

Learning rate: 9.88833005587261e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 675 [0/90000 (0%)]	Loss: 5.1753	Cost: 22.19s
Train Epoch: 675 [20480/90000 (23%)]	Loss: 3.0109	Cost: 9.08s
Train Epoch: 675 [40960/90000 (45%)]	Loss: 2.7659	Cost: 7.48s
Train Epoch: 675 [61440/90000 (68%)]	Loss: 2.6216	Cost: 10.08s
Train Epoch: 675 [81920/90000 (91%)]	Loss: 2.8635	Cost: 7.82s
Train Epoch: 675 	Average Loss: 2.9809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7708

Learning rate: 9.887999688823941e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 676 [0/90000 (0%)]	Loss: 4.5645	Cost: 19.97s
Train Epoch: 676 [20480/90000 (23%)]	Loss: 2.4894	Cost: 8.13s
Train Epoch: 676 [40960/90000 (45%)]	Loss: 2.6291	Cost: 13.17s
Train Epoch: 676 [61440/90000 (68%)]	Loss: 2.3150	Cost: 15.60s
Train Epoch: 676 [81920/90000 (91%)]	Loss: 2.5895	Cost: 13.59s
Train Epoch: 676 	Average Loss: 2.6761
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7525

Learning rate: 9.887668839349044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 677 [0/90000 (0%)]	Loss: 4.7243	Cost: 29.56s
Train Epoch: 677 [20480/90000 (23%)]	Loss: 2.6083	Cost: 13.95s
Train Epoch: 677 [40960/90000 (45%)]	Loss: 2.4738	Cost: 13.12s
Train Epoch: 677 [61440/90000 (68%)]	Loss: 2.4034	Cost: 12.10s
Train Epoch: 677 [81920/90000 (91%)]	Loss: 2.4586	Cost: 10.20s
Train Epoch: 677 	Average Loss: 2.6742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6031

Saving model as e677_model.pt & e677_waveforms_supplementary.hdf5
Learning rate: 9.887337507480573e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 678 [0/90000 (0%)]	Loss: 4.3839	Cost: 31.77s
Train Epoch: 678 [20480/90000 (23%)]	Loss: 2.4419	Cost: 11.37s
Train Epoch: 678 [40960/90000 (45%)]	Loss: 2.4187	Cost: 9.24s
Train Epoch: 678 [61440/90000 (68%)]	Loss: 2.2190	Cost: 6.12s
Train Epoch: 678 [81920/90000 (91%)]	Loss: 2.5092	Cost: 7.51s
Train Epoch: 678 	Average Loss: 2.5330
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6398

Learning rate: 9.887005693251226e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 679 [0/90000 (0%)]	Loss: 4.6219	Cost: 36.04s
Train Epoch: 679 [20480/90000 (23%)]	Loss: 2.4061	Cost: 12.01s
Train Epoch: 679 [40960/90000 (45%)]	Loss: 2.5119	Cost: 6.86s
Train Epoch: 679 [61440/90000 (68%)]	Loss: 2.2166	Cost: 6.48s
Train Epoch: 679 [81920/90000 (91%)]	Loss: 2.3664	Cost: 8.36s
Train Epoch: 679 	Average Loss: 2.5088
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6005

Saving model as e679_model.pt & e679_waveforms_supplementary.hdf5
Learning rate: 9.886673396693755e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 680 [0/90000 (0%)]	Loss: 4.6328	Cost: 22.17s
Train Epoch: 680 [20480/90000 (23%)]	Loss: 2.3726	Cost: 7.38s
Train Epoch: 680 [40960/90000 (45%)]	Loss: 2.2172	Cost: 8.58s
Train Epoch: 680 [61440/90000 (68%)]	Loss: 2.3723	Cost: 8.68s
Train Epoch: 680 [81920/90000 (91%)]	Loss: 2.6073	Cost: 8.45s
Train Epoch: 680 	Average Loss: 2.4909
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6227

Learning rate: 9.886340617840956e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 681 [0/90000 (0%)]	Loss: 4.4382	Cost: 25.42s
Train Epoch: 681 [20480/90000 (23%)]	Loss: 2.3925	Cost: 11.52s
Train Epoch: 681 [40960/90000 (45%)]	Loss: 2.4763	Cost: 11.02s
Train Epoch: 681 [61440/90000 (68%)]	Loss: 2.2820	Cost: 6.93s
Train Epoch: 681 [81920/90000 (91%)]	Loss: 2.3360	Cost: 7.91s
Train Epoch: 681 	Average Loss: 2.4922
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6276

Learning rate: 9.886007356725671e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 682 [0/90000 (0%)]	Loss: 4.2310	Cost: 20.97s
Train Epoch: 682 [20480/90000 (23%)]	Loss: 2.3541	Cost: 10.26s
Train Epoch: 682 [40960/90000 (45%)]	Loss: 2.5019	Cost: 10.10s
Train Epoch: 682 [61440/90000 (68%)]	Loss: 2.2158	Cost: 12.84s
Train Epoch: 682 [81920/90000 (91%)]	Loss: 2.2821	Cost: 12.52s
Train Epoch: 682 	Average Loss: 2.4746
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6183

Learning rate: 9.885673613380794e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 683 [0/90000 (0%)]	Loss: 4.4864	Cost: 30.34s
Train Epoch: 683 [20480/90000 (23%)]	Loss: 2.2487	Cost: 13.71s
Train Epoch: 683 [40960/90000 (45%)]	Loss: 2.4043	Cost: 12.66s
Train Epoch: 683 [61440/90000 (68%)]	Loss: 2.4046	Cost: 12.28s
Train Epoch: 683 [81920/90000 (91%)]	Loss: 2.3715	Cost: 12.07s
Train Epoch: 683 	Average Loss: 2.4909
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5530

Saving model as e683_model.pt & e683_waveforms_supplementary.hdf5
Learning rate: 9.885339387839263e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 684 [0/90000 (0%)]	Loss: 4.6128	Cost: 23.46s
Train Epoch: 684 [20480/90000 (23%)]	Loss: 2.3704	Cost: 13.40s
Train Epoch: 684 [40960/90000 (45%)]	Loss: 2.5717	Cost: 12.36s
Train Epoch: 684 [61440/90000 (68%)]	Loss: 2.3870	Cost: 10.73s
Train Epoch: 684 [81920/90000 (91%)]	Loss: 2.4700	Cost: 6.42s
Train Epoch: 684 	Average Loss: 2.4924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5623

Learning rate: 9.885004680134064e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 685 [0/90000 (0%)]	Loss: 4.3808	Cost: 26.60s
Train Epoch: 685 [20480/90000 (23%)]	Loss: 2.2797	Cost: 7.87s
Train Epoch: 685 [40960/90000 (45%)]	Loss: 2.3374	Cost: 12.43s
Train Epoch: 685 [61440/90000 (68%)]	Loss: 2.0721	Cost: 6.87s
Train Epoch: 685 [81920/90000 (91%)]	Loss: 2.2738	Cost: 6.28s
Train Epoch: 685 	Average Loss: 2.4132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5284

Saving model as e685_model.pt & e685_waveforms_supplementary.hdf5
Learning rate: 9.884669490298232e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 686 [0/90000 (0%)]	Loss: 4.6120	Cost: 27.63s
Train Epoch: 686 [20480/90000 (23%)]	Loss: 2.3236	Cost: 8.34s
Train Epoch: 686 [40960/90000 (45%)]	Loss: 2.4331	Cost: 10.27s
Train Epoch: 686 [61440/90000 (68%)]	Loss: 2.2043	Cost: 9.08s
Train Epoch: 686 [81920/90000 (91%)]	Loss: 2.3016	Cost: 8.79s
Train Epoch: 686 	Average Loss: 2.4048
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6515

Learning rate: 9.884333818364849e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 687 [0/90000 (0%)]	Loss: 4.3233	Cost: 25.95s
Train Epoch: 687 [20480/90000 (23%)]	Loss: 2.1774	Cost: 10.76s
Train Epoch: 687 [40960/90000 (45%)]	Loss: 2.2510	Cost: 10.84s
Train Epoch: 687 [61440/90000 (68%)]	Loss: 2.1815	Cost: 8.86s
Train Epoch: 687 [81920/90000 (91%)]	Loss: 2.3238	Cost: 6.59s
Train Epoch: 687 	Average Loss: 2.3684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4725

Saving model as e687_model.pt & e687_waveforms_supplementary.hdf5
Learning rate: 9.883997664367044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 688 [0/90000 (0%)]	Loss: 4.3264	Cost: 19.79s
Train Epoch: 688 [20480/90000 (23%)]	Loss: 2.4810	Cost: 7.47s
Train Epoch: 688 [40960/90000 (45%)]	Loss: 2.5080	Cost: 13.40s
Train Epoch: 688 [61440/90000 (68%)]	Loss: 2.1444	Cost: 12.78s
Train Epoch: 688 [81920/90000 (91%)]	Loss: 2.4466	Cost: 12.61s
Train Epoch: 688 	Average Loss: 2.4395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5774

Learning rate: 9.883661028337996e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 689 [0/90000 (0%)]	Loss: 4.4757	Cost: 24.59s
Train Epoch: 689 [20480/90000 (23%)]	Loss: 2.3166	Cost: 12.82s
Train Epoch: 689 [40960/90000 (45%)]	Loss: 2.1155	Cost: 12.39s
Train Epoch: 689 [61440/90000 (68%)]	Loss: 2.0860	Cost: 12.52s
Train Epoch: 689 [81920/90000 (91%)]	Loss: 2.5107	Cost: 12.20s
Train Epoch: 689 	Average Loss: 2.3827
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4687

Saving model as e689_model.pt & e689_waveforms_supplementary.hdf5
Learning rate: 9.883323910310927e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 690 [0/90000 (0%)]	Loss: 4.4395	Cost: 26.38s
Train Epoch: 690 [20480/90000 (23%)]	Loss: 2.2612	Cost: 12.31s
Train Epoch: 690 [40960/90000 (45%)]	Loss: 2.2307	Cost: 12.25s
Train Epoch: 690 [61440/90000 (68%)]	Loss: 2.0411	Cost: 6.16s
Train Epoch: 690 [81920/90000 (91%)]	Loss: 2.3784	Cost: 6.53s
Train Epoch: 690 	Average Loss: 2.3802
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5358

Learning rate: 9.88298631031911e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 691 [0/90000 (0%)]	Loss: 4.6703	Cost: 31.94s
Train Epoch: 691 [20480/90000 (23%)]	Loss: 2.1124	Cost: 6.92s
Train Epoch: 691 [40960/90000 (45%)]	Loss: 2.2679	Cost: 9.21s
Train Epoch: 691 [61440/90000 (68%)]	Loss: 2.1183	Cost: 8.86s
Train Epoch: 691 [81920/90000 (91%)]	Loss: 2.2108	Cost: 9.11s
Train Epoch: 691 	Average Loss: 2.3103
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4248

Saving model as e691_model.pt & e691_waveforms_supplementary.hdf5
Learning rate: 9.882648228395867e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 692 [0/90000 (0%)]	Loss: 4.6410	Cost: 23.60s
Train Epoch: 692 [20480/90000 (23%)]	Loss: 2.1484	Cost: 9.26s
Train Epoch: 692 [40960/90000 (45%)]	Loss: 2.2785	Cost: 8.91s
Train Epoch: 692 [61440/90000 (68%)]	Loss: 2.1024	Cost: 8.71s
Train Epoch: 692 [81920/90000 (91%)]	Loss: 2.1490	Cost: 8.51s
Train Epoch: 692 	Average Loss: 2.2658
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4460

Learning rate: 9.882309664574563e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 693 [0/90000 (0%)]	Loss: 4.2888	Cost: 21.14s
Train Epoch: 693 [20480/90000 (23%)]	Loss: 2.1326	Cost: 9.33s
Train Epoch: 693 [40960/90000 (45%)]	Loss: 1.9660	Cost: 7.70s
Train Epoch: 693 [61440/90000 (68%)]	Loss: 2.0558	Cost: 7.51s
Train Epoch: 693 [81920/90000 (91%)]	Loss: 2.2570	Cost: 9.74s
Train Epoch: 693 	Average Loss: 2.2651
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4379

Learning rate: 9.881970618888613e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 694 [0/90000 (0%)]	Loss: 4.6113	Cost: 19.33s
Train Epoch: 694 [20480/90000 (23%)]	Loss: 2.1159	Cost: 7.32s
Train Epoch: 694 [40960/90000 (45%)]	Loss: 2.0379	Cost: 12.29s
Train Epoch: 694 [61440/90000 (68%)]	Loss: 2.1106	Cost: 14.41s
Train Epoch: 694 [81920/90000 (91%)]	Loss: 2.2073	Cost: 13.70s
Train Epoch: 694 	Average Loss: 2.2592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3361

Saving model as e694_model.pt & e694_waveforms_supplementary.hdf5
Learning rate: 9.88163109137148e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 695 [0/90000 (0%)]	Loss: 4.1670	Cost: 24.77s
Train Epoch: 695 [20480/90000 (23%)]	Loss: 2.2536	Cost: 14.98s
Train Epoch: 695 [40960/90000 (45%)]	Loss: 2.3046	Cost: 13.72s
Train Epoch: 695 [61440/90000 (68%)]	Loss: 2.0425	Cost: 12.19s
Train Epoch: 695 [81920/90000 (91%)]	Loss: 2.2070	Cost: 10.55s
Train Epoch: 695 	Average Loss: 2.2546
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4570

Learning rate: 9.881291082056673e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 696 [0/90000 (0%)]	Loss: 4.1956	Cost: 42.24s
Train Epoch: 696 [20480/90000 (23%)]	Loss: 1.9879	Cost: 12.47s
Train Epoch: 696 [40960/90000 (45%)]	Loss: 2.1368	Cost: 12.27s
Train Epoch: 696 [61440/90000 (68%)]	Loss: 1.9075	Cost: 7.08s
Train Epoch: 696 [81920/90000 (91%)]	Loss: 2.1287	Cost: 6.11s
Train Epoch: 696 	Average Loss: 2.2680
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3631

Learning rate: 9.880950590977753e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 697 [0/90000 (0%)]	Loss: 4.3668	Cost: 35.73s
Train Epoch: 697 [20480/90000 (23%)]	Loss: 2.0950	Cost: 10.79s
Train Epoch: 697 [40960/90000 (45%)]	Loss: 2.1430	Cost: 6.81s
Train Epoch: 697 [61440/90000 (68%)]	Loss: 1.9498	Cost: 6.09s
Train Epoch: 697 [81920/90000 (91%)]	Loss: 2.1930	Cost: 7.90s
Train Epoch: 697 	Average Loss: 2.2526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4687

Learning rate: 9.88060961816832e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 698 [0/90000 (0%)]	Loss: 4.3885	Cost: 24.56s
Train Epoch: 698 [20480/90000 (23%)]	Loss: 2.0492	Cost: 7.12s
Train Epoch: 698 [40960/90000 (45%)]	Loss: 2.0404	Cost: 10.27s
Train Epoch: 698 [61440/90000 (68%)]	Loss: 1.8353	Cost: 8.85s
Train Epoch: 698 [81920/90000 (91%)]	Loss: 2.1149	Cost: 9.29s
Train Epoch: 698 	Average Loss: 2.1624
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3165

Saving model as e698_model.pt & e698_waveforms_supplementary.hdf5
Learning rate: 9.88026816366203e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 699 [0/90000 (0%)]	Loss: 4.4167	Cost: 20.09s
Train Epoch: 699 [20480/90000 (23%)]	Loss: 1.9783	Cost: 10.58s
Train Epoch: 699 [40960/90000 (45%)]	Loss: 2.1643	Cost: 10.98s
Train Epoch: 699 [61440/90000 (68%)]	Loss: 2.0337	Cost: 10.81s
Train Epoch: 699 [81920/90000 (91%)]	Loss: 2.1324	Cost: 14.47s
Train Epoch: 699 	Average Loss: 2.2029
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4273

Learning rate: 9.879926227492583e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 700 [0/90000 (0%)]	Loss: 4.3376	Cost: 28.72s
Train Epoch: 700 [20480/90000 (23%)]	Loss: 1.8870	Cost: 13.20s
Train Epoch: 700 [40960/90000 (45%)]	Loss: 2.1165	Cost: 13.63s
Train Epoch: 700 [61440/90000 (68%)]	Loss: 1.9680	Cost: 12.24s
Train Epoch: 700 [81920/90000 (91%)]	Loss: 2.0830	Cost: 12.39s
Train Epoch: 700 	Average Loss: 2.1866
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3995

Learning rate: 9.879583809693725e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 701 [0/90000 (0%)]	Loss: 4.4456	Cost: 29.05s
Train Epoch: 701 [20480/90000 (23%)]	Loss: 1.9593	Cost: 13.12s
Train Epoch: 701 [40960/90000 (45%)]	Loss: 2.1023	Cost: 12.10s
Train Epoch: 701 [61440/90000 (68%)]	Loss: 1.9937	Cost: 8.73s
Train Epoch: 701 [81920/90000 (91%)]	Loss: 1.9882	Cost: 6.05s
Train Epoch: 701 	Average Loss: 2.1617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3520

Learning rate: 9.879240910299253e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 702 [0/90000 (0%)]	Loss: 4.3817	Cost: 21.84s
Train Epoch: 702 [20480/90000 (23%)]	Loss: 2.3391	Cost: 6.83s
Train Epoch: 702 [40960/90000 (45%)]	Loss: 2.3022	Cost: 9.46s
Train Epoch: 702 [61440/90000 (68%)]	Loss: 2.1233	Cost: 9.08s
Train Epoch: 702 [81920/90000 (91%)]	Loss: 2.0060	Cost: 8.93s
Train Epoch: 702 	Average Loss: 2.2747
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5261

Learning rate: 9.87889752934301e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 703 [0/90000 (0%)]	Loss: 4.1760	Cost: 29.54s
Train Epoch: 703 [20480/90000 (23%)]	Loss: 2.0175	Cost: 8.87s
Train Epoch: 703 [40960/90000 (45%)]	Loss: 2.1019	Cost: 6.85s
Train Epoch: 703 [61440/90000 (68%)]	Loss: 1.9970	Cost: 6.71s
Train Epoch: 703 [81920/90000 (91%)]	Loss: 2.2635	Cost: 7.64s
Train Epoch: 703 	Average Loss: 2.2434
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4817

Learning rate: 9.878553666858885e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 704 [0/90000 (0%)]	Loss: 4.3043	Cost: 22.47s
Train Epoch: 704 [20480/90000 (23%)]	Loss: 2.2359	Cost: 10.19s
Train Epoch: 704 [40960/90000 (45%)]	Loss: 2.2220	Cost: 10.10s
Train Epoch: 704 [61440/90000 (68%)]	Loss: 1.9376	Cost: 7.50s
Train Epoch: 704 [81920/90000 (91%)]	Loss: 2.0929	Cost: 14.00s
Train Epoch: 704 	Average Loss: 2.2714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3945

Learning rate: 9.878209322880817e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 705 [0/90000 (0%)]	Loss: 4.5215	Cost: 21.54s
Train Epoch: 705 [20480/90000 (23%)]	Loss: 1.9708	Cost: 8.89s
Train Epoch: 705 [40960/90000 (45%)]	Loss: 1.7441	Cost: 12.51s
Train Epoch: 705 [61440/90000 (68%)]	Loss: 1.8673	Cost: 12.61s
Train Epoch: 705 [81920/90000 (91%)]	Loss: 2.0339	Cost: 12.43s
Train Epoch: 705 	Average Loss: 2.1050
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4441

Learning rate: 9.87786449744279e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 706 [0/90000 (0%)]	Loss: 3.9460	Cost: 23.13s
Train Epoch: 706 [20480/90000 (23%)]	Loss: 1.9868	Cost: 13.90s
Train Epoch: 706 [40960/90000 (45%)]	Loss: 1.9062	Cost: 12.46s
Train Epoch: 706 [61440/90000 (68%)]	Loss: 2.0381	Cost: 12.18s
Train Epoch: 706 [81920/90000 (91%)]	Loss: 2.0336	Cost: 12.50s
Train Epoch: 706 	Average Loss: 2.1805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4896

Learning rate: 9.87751919057884e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 707 [0/90000 (0%)]	Loss: 4.2881	Cost: 25.23s
Train Epoch: 707 [20480/90000 (23%)]	Loss: 2.1912	Cost: 13.57s
Train Epoch: 707 [40960/90000 (45%)]	Loss: 2.0764	Cost: 12.43s
Train Epoch: 707 [61440/90000 (68%)]	Loss: 2.1610	Cost: 10.25s
Train Epoch: 707 [81920/90000 (91%)]	Loss: 2.3979	Cost: 6.20s
Train Epoch: 707 	Average Loss: 2.2600
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6399

Learning rate: 9.877173402323044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 708 [0/90000 (0%)]	Loss: 4.8106	Cost: 40.96s
Train Epoch: 708 [20480/90000 (23%)]	Loss: 2.2167	Cost: 9.19s
Train Epoch: 708 [40960/90000 (45%)]	Loss: 2.2394	Cost: 6.78s
Train Epoch: 708 [61440/90000 (68%)]	Loss: 2.0422	Cost: 7.63s
Train Epoch: 708 [81920/90000 (91%)]	Loss: 2.1094	Cost: 8.53s
Train Epoch: 708 	Average Loss: 2.2542
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3785

Learning rate: 9.876827132709531e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 709 [0/90000 (0%)]	Loss: 4.2024	Cost: 23.97s
Train Epoch: 709 [20480/90000 (23%)]	Loss: 1.8137	Cost: 7.76s
Train Epoch: 709 [40960/90000 (45%)]	Loss: 1.9568	Cost: 9.38s
Train Epoch: 709 [61440/90000 (68%)]	Loss: 1.9799	Cost: 8.84s
Train Epoch: 709 [81920/90000 (91%)]	Loss: 2.1384	Cost: 8.49s
Train Epoch: 709 	Average Loss: 2.1129
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4492

Learning rate: 9.876480381772478e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 710 [0/90000 (0%)]	Loss: 4.5974	Cost: 20.46s
Train Epoch: 710 [20480/90000 (23%)]	Loss: 1.9362	Cost: 9.42s
Train Epoch: 710 [40960/90000 (45%)]	Loss: 2.1747	Cost: 8.86s
Train Epoch: 710 [61440/90000 (68%)]	Loss: 1.9966	Cost: 8.76s
Train Epoch: 710 [81920/90000 (91%)]	Loss: 2.2915	Cost: 9.79s
Train Epoch: 710 	Average Loss: 2.2914
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5691

Learning rate: 9.876133149546104e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 711 [0/90000 (0%)]	Loss: 4.3670	Cost: 20.15s
Train Epoch: 711 [20480/90000 (23%)]	Loss: 2.1250	Cost: 9.27s
Train Epoch: 711 [40960/90000 (45%)]	Loss: 2.0872	Cost: 9.29s
Train Epoch: 711 [61440/90000 (68%)]	Loss: 1.8178	Cost: 7.22s
Train Epoch: 711 [81920/90000 (91%)]	Loss: 1.9396	Cost: 6.24s
Train Epoch: 711 	Average Loss: 2.1788
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2459

Saving model as e711_model.pt & e711_waveforms_supplementary.hdf5
Learning rate: 9.875785436064683e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 712 [0/90000 (0%)]	Loss: 4.0196	Cost: 25.70s
Train Epoch: 712 [20480/90000 (23%)]	Loss: 1.9889	Cost: 12.02s
Train Epoch: 712 [40960/90000 (45%)]	Loss: 1.7862	Cost: 13.61s
Train Epoch: 712 [61440/90000 (68%)]	Loss: 1.9882	Cost: 12.40s
Train Epoch: 712 [81920/90000 (91%)]	Loss: 1.9416	Cost: 12.16s
Train Epoch: 712 	Average Loss: 2.0092
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2789

Learning rate: 9.875437241362533e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 713 [0/90000 (0%)]	Loss: 4.2685	Cost: 29.46s
Train Epoch: 713 [20480/90000 (23%)]	Loss: 1.7977	Cost: 12.49s
Train Epoch: 713 [40960/90000 (45%)]	Loss: 1.8992	Cost: 12.76s
Train Epoch: 713 [61440/90000 (68%)]	Loss: 1.7776	Cost: 12.11s
Train Epoch: 713 [81920/90000 (91%)]	Loss: 2.0019	Cost: 9.03s
Train Epoch: 713 	Average Loss: 2.0261
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3236

Learning rate: 9.875088565474018e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 714 [0/90000 (0%)]	Loss: 4.3625	Cost: 27.96s
Train Epoch: 714 [20480/90000 (23%)]	Loss: 1.8839	Cost: 10.01s
Train Epoch: 714 [40960/90000 (45%)]	Loss: 1.8645	Cost: 10.35s
Train Epoch: 714 [61440/90000 (68%)]	Loss: 1.7629	Cost: 6.59s
Train Epoch: 714 [81920/90000 (91%)]	Loss: 1.9242	Cost: 6.64s
Train Epoch: 714 	Average Loss: 2.0268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3450

Learning rate: 9.874739408433551e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 715 [0/90000 (0%)]	Loss: 4.2932	Cost: 25.24s
Train Epoch: 715 [20480/90000 (23%)]	Loss: 1.8016	Cost: 11.21s
Train Epoch: 715 [40960/90000 (45%)]	Loss: 1.7660	Cost: 10.80s
Train Epoch: 715 [61440/90000 (68%)]	Loss: 1.6508	Cost: 7.74s
Train Epoch: 715 [81920/90000 (91%)]	Loss: 1.8815	Cost: 8.96s
Train Epoch: 715 	Average Loss: 1.9706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2272

Saving model as e715_model.pt & e715_waveforms_supplementary.hdf5
Learning rate: 9.874389770275595e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 716 [0/90000 (0%)]	Loss: 4.0630	Cost: 19.44s
Train Epoch: 716 [20480/90000 (23%)]	Loss: 1.7321	Cost: 8.68s
Train Epoch: 716 [40960/90000 (45%)]	Loss: 1.6906	Cost: 10.97s
Train Epoch: 716 [61440/90000 (68%)]	Loss: 1.7053	Cost: 9.15s
Train Epoch: 716 [81920/90000 (91%)]	Loss: 1.7229	Cost: 8.89s
Train Epoch: 716 	Average Loss: 1.8526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1148

Saving model as e716_model.pt & e716_waveforms_supplementary.hdf5
Learning rate: 9.874039651034654e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 717 [0/90000 (0%)]	Loss: 4.2113	Cost: 26.68s
Train Epoch: 717 [20480/90000 (23%)]	Loss: 1.7183	Cost: 8.73s
Train Epoch: 717 [40960/90000 (45%)]	Loss: 1.7322	Cost: 8.92s
Train Epoch: 717 [61440/90000 (68%)]	Loss: 1.9074	Cost: 6.29s
Train Epoch: 717 [81920/90000 (91%)]	Loss: 1.8335	Cost: 7.32s
Train Epoch: 717 	Average Loss: 1.9039
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1627

Learning rate: 9.873689050745284e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 718 [0/90000 (0%)]	Loss: 4.2325	Cost: 18.52s
Train Epoch: 718 [20480/90000 (23%)]	Loss: 1.7232	Cost: 7.35s
Train Epoch: 718 [40960/90000 (45%)]	Loss: 1.7982	Cost: 11.19s
Train Epoch: 718 [61440/90000 (68%)]	Loss: 1.5989	Cost: 9.65s
Train Epoch: 718 [81920/90000 (91%)]	Loss: 1.8707	Cost: 12.41s
Train Epoch: 718 	Average Loss: 1.9563
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2736

Learning rate: 9.873337969442089e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 719 [0/90000 (0%)]	Loss: 4.2358	Cost: 24.10s
Train Epoch: 719 [20480/90000 (23%)]	Loss: 1.7982	Cost: 10.84s
Train Epoch: 719 [40960/90000 (45%)]	Loss: 1.6324	Cost: 12.69s
Train Epoch: 719 [61440/90000 (68%)]	Loss: 1.7253	Cost: 12.37s
Train Epoch: 719 [81920/90000 (91%)]	Loss: 1.8504	Cost: 12.48s
Train Epoch: 719 	Average Loss: 1.9166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1261

Learning rate: 9.87298640715972e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 720 [0/90000 (0%)]	Loss: 4.0915	Cost: 31.74s
Train Epoch: 720 [20480/90000 (23%)]	Loss: 1.6976	Cost: 13.99s
Train Epoch: 720 [40960/90000 (45%)]	Loss: 1.6528	Cost: 13.33s
Train Epoch: 720 [61440/90000 (68%)]	Loss: 1.4681	Cost: 12.31s
Train Epoch: 720 [81920/90000 (91%)]	Loss: 1.7720	Cost: 9.92s
Train Epoch: 720 	Average Loss: 1.8417
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0694

Saving model as e720_model.pt & e720_waveforms_supplementary.hdf5
Learning rate: 9.872634363932875e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 721 [0/90000 (0%)]	Loss: 3.9915	Cost: 28.72s
Train Epoch: 721 [20480/90000 (23%)]	Loss: 1.7450	Cost: 14.12s
Train Epoch: 721 [40960/90000 (45%)]	Loss: 1.6143	Cost: 13.40s
Train Epoch: 721 [61440/90000 (68%)]	Loss: 1.7208	Cost: 6.43s
Train Epoch: 721 [81920/90000 (91%)]	Loss: 1.8238	Cost: 6.17s
Train Epoch: 721 	Average Loss: 1.8612
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1628

Learning rate: 9.872281839796297e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 722 [0/90000 (0%)]	Loss: 4.1328	Cost: 24.20s
Train Epoch: 722 [20480/90000 (23%)]	Loss: 1.7404	Cost: 7.11s
Train Epoch: 722 [40960/90000 (45%)]	Loss: 1.6645	Cost: 9.65s
Train Epoch: 722 [61440/90000 (68%)]	Loss: 1.5823	Cost: 8.83s
Train Epoch: 722 [81920/90000 (91%)]	Loss: 1.9274	Cost: 8.64s
Train Epoch: 722 	Average Loss: 1.8681
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0985

Learning rate: 9.87192883478478e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 723 [0/90000 (0%)]	Loss: 3.7660	Cost: 19.73s
Train Epoch: 723 [20480/90000 (23%)]	Loss: 1.7844	Cost: 9.17s
Train Epoch: 723 [40960/90000 (45%)]	Loss: 1.6691	Cost: 9.01s
Train Epoch: 723 [61440/90000 (68%)]	Loss: 1.6415	Cost: 8.65s
Train Epoch: 723 [81920/90000 (91%)]	Loss: 1.6172	Cost: 6.29s
Train Epoch: 723 	Average Loss: 1.8104
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1325

Learning rate: 9.871575348933164e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 724 [0/90000 (0%)]	Loss: 3.8455	Cost: 21.43s
Train Epoch: 724 [20480/90000 (23%)]	Loss: 1.7073	Cost: 8.05s
Train Epoch: 724 [40960/90000 (45%)]	Loss: 1.6701	Cost: 7.07s
Train Epoch: 724 [61440/90000 (68%)]	Loss: 1.4247	Cost: 6.53s
Train Epoch: 724 [81920/90000 (91%)]	Loss: 1.6775	Cost: 12.16s
Train Epoch: 724 	Average Loss: 1.7782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1382

Learning rate: 9.871221382276338e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 725 [0/90000 (0%)]	Loss: 4.3364	Cost: 25.77s
Train Epoch: 725 [20480/90000 (23%)]	Loss: 1.6409	Cost: 10.80s
Train Epoch: 725 [40960/90000 (45%)]	Loss: 1.8425	Cost: 17.07s
Train Epoch: 725 [61440/90000 (68%)]	Loss: 1.7123	Cost: 14.92s
Train Epoch: 725 [81920/90000 (91%)]	Loss: 1.8695	Cost: 12.32s
Train Epoch: 725 	Average Loss: 1.8709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2080

Learning rate: 9.870866934849235e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 726 [0/90000 (0%)]	Loss: 4.3280	Cost: 38.81s
Train Epoch: 726 [20480/90000 (23%)]	Loss: 1.7571	Cost: 12.83s
Train Epoch: 726 [40960/90000 (45%)]	Loss: 1.9341	Cost: 12.91s
Train Epoch: 726 [61440/90000 (68%)]	Loss: 1.6272	Cost: 12.22s
Train Epoch: 726 [81920/90000 (91%)]	Loss: 1.7483	Cost: 7.62s
Train Epoch: 726 	Average Loss: 1.9101
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1879

Learning rate: 9.870512006686839e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 727 [0/90000 (0%)]	Loss: 4.2870	Cost: 28.75s
Train Epoch: 727 [20480/90000 (23%)]	Loss: 1.7064	Cost: 12.65s
Train Epoch: 727 [40960/90000 (45%)]	Loss: 1.8909	Cost: 12.57s
Train Epoch: 727 [61440/90000 (68%)]	Loss: 2.3684	Cost: 9.74s
Train Epoch: 727 [81920/90000 (91%)]	Loss: 2.3042	Cost: 6.36s
Train Epoch: 727 	Average Loss: 2.1894
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5852

Learning rate: 9.870156597824179e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 728 [0/90000 (0%)]	Loss: 4.1715	Cost: 27.41s
Train Epoch: 728 [20480/90000 (23%)]	Loss: 2.0004	Cost: 11.96s
Train Epoch: 728 [40960/90000 (45%)]	Loss: 1.7360	Cost: 6.50s
Train Epoch: 728 [61440/90000 (68%)]	Loss: 1.6751	Cost: 6.24s
Train Epoch: 728 [81920/90000 (91%)]	Loss: 1.8577	Cost: 8.30s
Train Epoch: 728 	Average Loss: 2.0747
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1770

Learning rate: 9.869800708296334e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 729 [0/90000 (0%)]	Loss: 3.9412	Cost: 22.59s
Train Epoch: 729 [20480/90000 (23%)]	Loss: 1.6705	Cost: 6.72s
Train Epoch: 729 [40960/90000 (45%)]	Loss: 1.6246	Cost: 8.58s
Train Epoch: 729 [61440/90000 (68%)]	Loss: 1.4788	Cost: 8.89s
Train Epoch: 729 [81920/90000 (91%)]	Loss: 1.6796	Cost: 9.07s
Train Epoch: 729 	Average Loss: 1.7871
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1115

Learning rate: 9.869444338138427e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 730 [0/90000 (0%)]	Loss: 4.0482	Cost: 24.86s
Train Epoch: 730 [20480/90000 (23%)]	Loss: 1.5560	Cost: 10.69s
Train Epoch: 730 [40960/90000 (45%)]	Loss: 1.6289	Cost: 9.22s
Train Epoch: 730 [61440/90000 (68%)]	Loss: 1.3200	Cost: 8.63s
Train Epoch: 730 [81920/90000 (91%)]	Loss: 1.5559	Cost: 6.50s
Train Epoch: 730 	Average Loss: 1.7266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0528

Saving model as e730_model.pt & e730_waveforms_supplementary.hdf5
Learning rate: 9.869087487385631e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 731 [0/90000 (0%)]	Loss: 4.2745	Cost: 23.93s
Train Epoch: 731 [20480/90000 (23%)]	Loss: 1.6050	Cost: 10.37s
Train Epoch: 731 [40960/90000 (45%)]	Loss: 1.4598	Cost: 7.97s
Train Epoch: 731 [61440/90000 (68%)]	Loss: 1.3328	Cost: 6.53s
Train Epoch: 731 [81920/90000 (91%)]	Loss: 1.4838	Cost: 6.75s
Train Epoch: 731 	Average Loss: 1.7294
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0503

Saving model as e731_model.pt & e731_waveforms_supplementary.hdf5
Learning rate: 9.868730156073167e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 732 [0/90000 (0%)]	Loss: 3.7299	Cost: 22.23s
Train Epoch: 732 [20480/90000 (23%)]	Loss: 1.6578	Cost: 8.98s
Train Epoch: 732 [40960/90000 (45%)]	Loss: 1.6305	Cost: 17.12s
Train Epoch: 732 [61440/90000 (68%)]	Loss: 1.5224	Cost: 12.71s
Train Epoch: 732 [81920/90000 (91%)]	Loss: 1.4847	Cost: 12.32s
Train Epoch: 732 	Average Loss: 1.6784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9473

Saving model as e732_model.pt & e732_waveforms_supplementary.hdf5
Learning rate: 9.8683723442363e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 733 [0/90000 (0%)]	Loss: 3.7403	Cost: 25.86s
Train Epoch: 733 [20480/90000 (23%)]	Loss: 1.6273	Cost: 13.80s
Train Epoch: 733 [40960/90000 (45%)]	Loss: 1.5425	Cost: 12.50s
Train Epoch: 733 [61440/90000 (68%)]	Loss: 1.5992	Cost: 12.57s
Train Epoch: 733 [81920/90000 (91%)]	Loss: 1.7323	Cost: 9.29s
Train Epoch: 733 	Average Loss: 1.7428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1847

Learning rate: 9.868014051910347e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 734 [0/90000 (0%)]	Loss: 4.0997	Cost: 25.46s
Train Epoch: 734 [20480/90000 (23%)]	Loss: 1.5621	Cost: 12.47s
Train Epoch: 734 [40960/90000 (45%)]	Loss: 1.5262	Cost: 12.33s
Train Epoch: 734 [61440/90000 (68%)]	Loss: 1.4402	Cost: 10.50s
Train Epoch: 734 [81920/90000 (91%)]	Loss: 1.4919	Cost: 6.61s
Train Epoch: 734 	Average Loss: 1.7004
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0077

Learning rate: 9.86765527913067e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 735 [0/90000 (0%)]	Loss: 3.9539	Cost: 24.28s
Train Epoch: 735 [20480/90000 (23%)]	Loss: 1.7768	Cost: 12.93s
Train Epoch: 735 [40960/90000 (45%)]	Loss: 1.8408	Cost: 8.35s
Train Epoch: 735 [61440/90000 (68%)]	Loss: 1.6605	Cost: 6.44s
Train Epoch: 735 [81920/90000 (91%)]	Loss: 1.7860	Cost: 7.40s
Train Epoch: 735 	Average Loss: 1.8824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2351

Learning rate: 9.867296025932675e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 736 [0/90000 (0%)]	Loss: 4.5377	Cost: 31.80s
Train Epoch: 736 [20480/90000 (23%)]	Loss: 1.6397	Cost: 8.50s
Train Epoch: 736 [40960/90000 (45%)]	Loss: 1.5961	Cost: 7.57s
Train Epoch: 736 [61440/90000 (68%)]	Loss: 1.3071	Cost: 8.81s
Train Epoch: 736 [81920/90000 (91%)]	Loss: 1.6788	Cost: 8.60s
Train Epoch: 736 	Average Loss: 1.7386
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0366

Learning rate: 9.866936292351822e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 737 [0/90000 (0%)]	Loss: 3.6381	Cost: 31.01s
Train Epoch: 737 [20480/90000 (23%)]	Loss: 1.5223	Cost: 8.79s
Train Epoch: 737 [40960/90000 (45%)]	Loss: 1.4862	Cost: 8.84s
Train Epoch: 737 [61440/90000 (68%)]	Loss: 1.3052	Cost: 8.67s
Train Epoch: 737 [81920/90000 (91%)]	Loss: 1.6047	Cost: 7.03s
Train Epoch: 737 	Average Loss: 1.5963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9247

Saving model as e737_model.pt & e737_waveforms_supplementary.hdf5
Learning rate: 9.866576078423615e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 738 [0/90000 (0%)]	Loss: 3.9255	Cost: 21.00s
Train Epoch: 738 [20480/90000 (23%)]	Loss: 1.3812	Cost: 8.07s
Train Epoch: 738 [40960/90000 (45%)]	Loss: 1.4252	Cost: 13.12s
Train Epoch: 738 [61440/90000 (68%)]	Loss: 1.2641	Cost: 12.52s
Train Epoch: 738 [81920/90000 (91%)]	Loss: 1.3982	Cost: 13.43s
Train Epoch: 738 	Average Loss: 1.5392
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9517

Learning rate: 9.866215384183606e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 739 [0/90000 (0%)]	Loss: 3.5917	Cost: 25.62s
Train Epoch: 739 [20480/90000 (23%)]	Loss: 1.4783	Cost: 12.51s
Train Epoch: 739 [40960/90000 (45%)]	Loss: 1.3115	Cost: 14.41s
Train Epoch: 739 [61440/90000 (68%)]	Loss: 1.1954	Cost: 12.49s
Train Epoch: 739 [81920/90000 (91%)]	Loss: 1.3777	Cost: 11.09s
Train Epoch: 739 	Average Loss: 1.5604
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9858

Learning rate: 9.865854209667392e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 740 [0/90000 (0%)]	Loss: 3.9083	Cost: 26.24s
Train Epoch: 740 [20480/90000 (23%)]	Loss: 1.6216	Cost: 14.26s
Train Epoch: 740 [40960/90000 (45%)]	Loss: 1.4590	Cost: 12.29s
Train Epoch: 740 [61440/90000 (68%)]	Loss: 1.3214	Cost: 8.76s
Train Epoch: 740 [81920/90000 (91%)]	Loss: 1.5740	Cost: 6.06s
Train Epoch: 740 	Average Loss: 1.6330
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9669

Learning rate: 9.865492554910621e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 741 [0/90000 (0%)]	Loss: 3.9929	Cost: 36.05s
Train Epoch: 741 [20480/90000 (23%)]	Loss: 1.6349	Cost: 6.32s
Train Epoch: 741 [40960/90000 (45%)]	Loss: 1.5337	Cost: 9.66s
Train Epoch: 741 [61440/90000 (68%)]	Loss: 1.1369	Cost: 8.75s
Train Epoch: 741 [81920/90000 (91%)]	Loss: 1.3296	Cost: 8.54s
Train Epoch: 741 	Average Loss: 1.5453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9225

Saving model as e741_model.pt & e741_waveforms_supplementary.hdf5
Learning rate: 9.865130419948984e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 742 [0/90000 (0%)]	Loss: 4.0727	Cost: 23.76s
Train Epoch: 742 [20480/90000 (23%)]	Loss: 1.2700	Cost: 9.07s
Train Epoch: 742 [40960/90000 (45%)]	Loss: 1.5372	Cost: 9.04s
Train Epoch: 742 [61440/90000 (68%)]	Loss: 1.2539	Cost: 8.67s
Train Epoch: 742 [81920/90000 (91%)]	Loss: 1.4716	Cost: 5.75s
Train Epoch: 742 	Average Loss: 1.5479
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8280

Saving model as e742_model.pt & e742_waveforms_supplementary.hdf5
Learning rate: 9.864767804818229e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 743 [0/90000 (0%)]	Loss: 3.9790	Cost: 20.39s
Train Epoch: 743 [20480/90000 (23%)]	Loss: 1.3318	Cost: 9.98s
Train Epoch: 743 [40960/90000 (45%)]	Loss: 1.3016	Cost: 9.54s
Train Epoch: 743 [61440/90000 (68%)]	Loss: 1.1636	Cost: 12.94s
Train Epoch: 743 [81920/90000 (91%)]	Loss: 1.3703	Cost: 14.53s
Train Epoch: 743 	Average Loss: 1.4475
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8512

Learning rate: 9.864404709554137e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 744 [0/90000 (0%)]	Loss: 3.7761	Cost: 23.86s
Train Epoch: 744 [20480/90000 (23%)]	Loss: 1.2691	Cost: 12.25s
Train Epoch: 744 [40960/90000 (45%)]	Loss: 1.2631	Cost: 13.28s
Train Epoch: 744 [61440/90000 (68%)]	Loss: 1.2051	Cost: 12.72s
Train Epoch: 744 [81920/90000 (91%)]	Loss: 1.1922	Cost: 12.47s
Train Epoch: 744 	Average Loss: 1.4399
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8806

Learning rate: 9.864041134192549e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 745 [0/90000 (0%)]	Loss: 3.5300	Cost: 27.73s
Train Epoch: 745 [20480/90000 (23%)]	Loss: 1.3104	Cost: 11.85s
Train Epoch: 745 [40960/90000 (45%)]	Loss: 1.3622	Cost: 12.99s
Train Epoch: 745 [61440/90000 (68%)]	Loss: 1.3180	Cost: 12.11s
Train Epoch: 745 [81920/90000 (91%)]	Loss: 1.4677	Cost: 8.12s
Train Epoch: 745 	Average Loss: 1.5241
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8315

Learning rate: 9.863677078769347e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 746 [0/90000 (0%)]	Loss: 3.8297	Cost: 39.07s
Train Epoch: 746 [20480/90000 (23%)]	Loss: 1.2906	Cost: 12.02s
Train Epoch: 746 [40960/90000 (45%)]	Loss: 1.3105	Cost: 11.41s
Train Epoch: 746 [61440/90000 (68%)]	Loss: 1.1281	Cost: 6.02s
Train Epoch: 746 [81920/90000 (91%)]	Loss: 1.3071	Cost: 6.56s
Train Epoch: 746 	Average Loss: 1.4138
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8440

Learning rate: 9.863312543320462e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 747 [0/90000 (0%)]	Loss: 4.0716	Cost: 38.03s
Train Epoch: 747 [20480/90000 (23%)]	Loss: 1.3944	Cost: 11.94s
Train Epoch: 747 [40960/90000 (45%)]	Loss: 1.3154	Cost: 7.93s
Train Epoch: 747 [61440/90000 (68%)]	Loss: 1.2706	Cost: 6.13s
Train Epoch: 747 [81920/90000 (91%)]	Loss: 1.4073	Cost: 7.64s
Train Epoch: 747 	Average Loss: 1.4697
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7001

Saving model as e747_model.pt & e747_waveforms_supplementary.hdf5
Learning rate: 9.862947527881872e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 748 [0/90000 (0%)]	Loss: 3.7169	Cost: 19.78s
Train Epoch: 748 [20480/90000 (23%)]	Loss: 1.2172	Cost: 6.60s
Train Epoch: 748 [40960/90000 (45%)]	Loss: 1.2578	Cost: 10.94s
Train Epoch: 748 [61440/90000 (68%)]	Loss: 0.9739	Cost: 8.83s
Train Epoch: 748 [81920/90000 (91%)]	Loss: 1.2929	Cost: 9.39s
Train Epoch: 748 	Average Loss: 1.3515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7905

Learning rate: 9.862582032489604e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 749 [0/90000 (0%)]	Loss: 3.7417	Cost: 21.18s
Train Epoch: 749 [20480/90000 (23%)]	Loss: 1.2647	Cost: 8.93s
Train Epoch: 749 [40960/90000 (45%)]	Loss: 1.3290	Cost: 9.13s
Train Epoch: 749 [61440/90000 (68%)]	Loss: 1.1154	Cost: 9.23s
Train Epoch: 749 [81920/90000 (91%)]	Loss: 1.2609	Cost: 6.79s
Train Epoch: 749 	Average Loss: 1.3826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8948

Learning rate: 9.862216057179729e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 750 [0/90000 (0%)]	Loss: 4.0083	Cost: 23.41s
Train Epoch: 750 [20480/90000 (23%)]	Loss: 1.3093	Cost: 10.41s
Train Epoch: 750 [40960/90000 (45%)]	Loss: 1.4171	Cost: 9.24s
Train Epoch: 750 [61440/90000 (68%)]	Loss: 1.2151	Cost: 10.92s
Train Epoch: 750 [81920/90000 (91%)]	Loss: 1.2789	Cost: 12.42s
Train Epoch: 750 	Average Loss: 1.4456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8782

Learning rate: 9.861849601988368e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 751 [0/90000 (0%)]	Loss: 4.0077	Cost: 30.88s
Train Epoch: 751 [20480/90000 (23%)]	Loss: 1.1884	Cost: 9.72s
Train Epoch: 751 [40960/90000 (45%)]	Loss: 1.4616	Cost: 12.40s
Train Epoch: 751 [61440/90000 (68%)]	Loss: 1.0859	Cost: 12.37s
Train Epoch: 751 [81920/90000 (91%)]	Loss: 1.2340	Cost: 12.10s
Train Epoch: 751 	Average Loss: 1.4015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8511

Learning rate: 9.86148266695169e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 752 [0/90000 (0%)]	Loss: 3.8104	Cost: 25.27s
Train Epoch: 752 [20480/90000 (23%)]	Loss: 1.1752	Cost: 12.30s
Train Epoch: 752 [40960/90000 (45%)]	Loss: 1.0829	Cost: 12.58s
Train Epoch: 752 [61440/90000 (68%)]	Loss: 1.2149	Cost: 12.49s
Train Epoch: 752 [81920/90000 (91%)]	Loss: 1.2340	Cost: 12.18s
Train Epoch: 752 	Average Loss: 1.3703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8090

Learning rate: 9.861115252105906e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 753 [0/90000 (0%)]	Loss: 3.5909	Cost: 39.00s
Train Epoch: 753 [20480/90000 (23%)]	Loss: 1.2326	Cost: 13.13s
Train Epoch: 753 [40960/90000 (45%)]	Loss: 1.2871	Cost: 12.40s
Train Epoch: 753 [61440/90000 (68%)]	Loss: 0.9967	Cost: 11.79s
Train Epoch: 753 [81920/90000 (91%)]	Loss: 1.2791	Cost: 6.02s
Train Epoch: 753 	Average Loss: 1.3376
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7649

Learning rate: 9.860747357487283e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 754 [0/90000 (0%)]	Loss: 3.7657	Cost: 31.41s
Train Epoch: 754 [20480/90000 (23%)]	Loss: 1.1858	Cost: 13.53s
Train Epoch: 754 [40960/90000 (45%)]	Loss: 1.1250	Cost: 13.10s
Train Epoch: 754 [61440/90000 (68%)]	Loss: 0.9109	Cost: 6.27s
Train Epoch: 754 [81920/90000 (91%)]	Loss: 1.3909	Cost: 6.14s
Train Epoch: 754 	Average Loss: 1.3308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9275

Learning rate: 9.860378983132128e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 755 [0/90000 (0%)]	Loss: 4.0229	Cost: 26.45s
Train Epoch: 755 [20480/90000 (23%)]	Loss: 1.2395	Cost: 10.43s
Train Epoch: 755 [40960/90000 (45%)]	Loss: 1.4007	Cost: 6.46s
Train Epoch: 755 [61440/90000 (68%)]	Loss: 1.1613	Cost: 6.33s
Train Epoch: 755 [81920/90000 (91%)]	Loss: 1.2657	Cost: 8.54s
Train Epoch: 755 	Average Loss: 1.5045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9630

Learning rate: 9.860010129076798e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 756 [0/90000 (0%)]	Loss: 3.9580	Cost: 24.87s
Train Epoch: 756 [20480/90000 (23%)]	Loss: 1.3145	Cost: 6.58s
Train Epoch: 756 [40960/90000 (45%)]	Loss: 1.3947	Cost: 9.35s
Train Epoch: 756 [61440/90000 (68%)]	Loss: 1.1281	Cost: 9.04s
Train Epoch: 756 [81920/90000 (91%)]	Loss: 1.4510	Cost: 8.91s
Train Epoch: 756 	Average Loss: 1.4430
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8152

Learning rate: 9.8596407953577e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 757 [0/90000 (0%)]	Loss: 3.7195	Cost: 23.03s
Train Epoch: 757 [20480/90000 (23%)]	Loss: 1.2416	Cost: 9.36s
Train Epoch: 757 [40960/90000 (45%)]	Loss: 1.2134	Cost: 8.89s
Train Epoch: 757 [61440/90000 (68%)]	Loss: 1.1124	Cost: 8.61s
Train Epoch: 757 [81920/90000 (91%)]	Loss: 1.1488	Cost: 8.43s
Train Epoch: 757 	Average Loss: 1.3609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7814

Learning rate: 9.859270982011284e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 758 [0/90000 (0%)]	Loss: 3.9582	Cost: 22.36s
Train Epoch: 758 [20480/90000 (23%)]	Loss: 1.0608	Cost: 7.49s
Train Epoch: 758 [40960/90000 (45%)]	Loss: 1.2101	Cost: 13.18s
Train Epoch: 758 [61440/90000 (68%)]	Loss: 1.0694	Cost: 9.72s
Train Epoch: 758 [81920/90000 (91%)]	Loss: 1.2565	Cost: 15.11s
Train Epoch: 758 	Average Loss: 1.3376
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7925

Learning rate: 9.858900689074049e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 759 [0/90000 (0%)]	Loss: 3.5612	Cost: 19.02s
Train Epoch: 759 [20480/90000 (23%)]	Loss: 1.1418	Cost: 6.40s
Train Epoch: 759 [40960/90000 (45%)]	Loss: 1.1389	Cost: 16.03s
Train Epoch: 759 [61440/90000 (68%)]	Loss: 1.0386	Cost: 13.70s
Train Epoch: 759 [81920/90000 (91%)]	Loss: 1.2064	Cost: 13.57s
Train Epoch: 759 	Average Loss: 1.2397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7881

Learning rate: 9.85852991658254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 760 [0/90000 (0%)]	Loss: 3.7186	Cost: 26.19s
Train Epoch: 760 [20480/90000 (23%)]	Loss: 1.1849	Cost: 15.44s
Train Epoch: 760 [40960/90000 (45%)]	Loss: 1.1358	Cost: 13.42s
Train Epoch: 760 [61440/90000 (68%)]	Loss: 1.1560	Cost: 11.62s
Train Epoch: 760 [81920/90000 (91%)]	Loss: 1.3486	Cost: 12.32s
Train Epoch: 760 	Average Loss: 1.3147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7456

Learning rate: 9.858158664573355e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 761 [0/90000 (0%)]	Loss: 3.9175	Cost: 29.71s
Train Epoch: 761 [20480/90000 (23%)]	Loss: 1.0600	Cost: 12.04s
Train Epoch: 761 [40960/90000 (45%)]	Loss: 1.1388	Cost: 12.42s
Train Epoch: 761 [61440/90000 (68%)]	Loss: 1.1351	Cost: 11.21s
Train Epoch: 761 [81920/90000 (91%)]	Loss: 1.1355	Cost: 6.00s
Train Epoch: 761 	Average Loss: 1.3137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6660

Saving model as e761_model.pt & e761_waveforms_supplementary.hdf5
Learning rate: 9.857786933083131e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 762 [0/90000 (0%)]	Loss: 3.4337	Cost: 23.82s
Train Epoch: 762 [20480/90000 (23%)]	Loss: 1.2649	Cost: 7.10s
Train Epoch: 762 [40960/90000 (45%)]	Loss: 0.9614	Cost: 6.85s
Train Epoch: 762 [61440/90000 (68%)]	Loss: 0.8751	Cost: 7.35s
Train Epoch: 762 [81920/90000 (91%)]	Loss: 0.9188	Cost: 8.92s
Train Epoch: 762 	Average Loss: 1.1753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5778

Saving model as e762_model.pt & e762_waveforms_supplementary.hdf5
Learning rate: 9.85741472214856e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 763 [0/90000 (0%)]	Loss: 3.7196	Cost: 23.49s
Train Epoch: 763 [20480/90000 (23%)]	Loss: 0.9252	Cost: 9.72s
Train Epoch: 763 [40960/90000 (45%)]	Loss: 0.9678	Cost: 9.24s
Train Epoch: 763 [61440/90000 (68%)]	Loss: 0.9778	Cost: 8.77s
Train Epoch: 763 [81920/90000 (91%)]	Loss: 0.9898	Cost: 8.65s
Train Epoch: 763 	Average Loss: 1.1243
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6481

Learning rate: 9.857042031806373e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 764 [0/90000 (0%)]	Loss: 3.4589	Cost: 25.52s
Train Epoch: 764 [20480/90000 (23%)]	Loss: 1.0023	Cost: 10.99s
Train Epoch: 764 [40960/90000 (45%)]	Loss: 0.9572	Cost: 9.12s
Train Epoch: 764 [61440/90000 (68%)]	Loss: 0.8839	Cost: 8.74s
Train Epoch: 764 [81920/90000 (91%)]	Loss: 1.1175	Cost: 6.88s
Train Epoch: 764 	Average Loss: 1.1554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6908

Learning rate: 9.856668862093358e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 765 [0/90000 (0%)]	Loss: 3.9576	Cost: 19.19s
Train Epoch: 765 [20480/90000 (23%)]	Loss: 0.9555	Cost: 7.35s
Train Epoch: 765 [40960/90000 (45%)]	Loss: 1.4314	Cost: 9.48s
Train Epoch: 765 [61440/90000 (68%)]	Loss: 1.2049	Cost: 8.62s
Train Epoch: 765 [81920/90000 (91%)]	Loss: 1.5230	Cost: 15.25s
Train Epoch: 765 	Average Loss: 1.3834
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0186

Learning rate: 9.856295213046343e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 766 [0/90000 (0%)]	Loss: 3.6041	Cost: 21.68s
Train Epoch: 766 [20480/90000 (23%)]	Loss: 1.1557	Cost: 9.34s
Train Epoch: 766 [40960/90000 (45%)]	Loss: 1.2601	Cost: 12.24s
Train Epoch: 766 [61440/90000 (68%)]	Loss: 1.0763	Cost: 12.37s
Train Epoch: 766 [81920/90000 (91%)]	Loss: 1.2938	Cost: 12.41s
Train Epoch: 766 	Average Loss: 1.3745
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7175

Learning rate: 9.855921084702205e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 767 [0/90000 (0%)]	Loss: 3.7043	Cost: 24.48s
Train Epoch: 767 [20480/90000 (23%)]	Loss: 1.1211	Cost: 14.32s
Train Epoch: 767 [40960/90000 (45%)]	Loss: 1.0753	Cost: 14.23s
Train Epoch: 767 [61440/90000 (68%)]	Loss: 0.9624	Cost: 12.29s
Train Epoch: 767 [81920/90000 (91%)]	Loss: 1.1281	Cost: 10.67s
Train Epoch: 767 	Average Loss: 1.2162
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6166

Learning rate: 9.85554647709787e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 768 [0/90000 (0%)]	Loss: 3.5972	Cost: 44.81s
Train Epoch: 768 [20480/90000 (23%)]	Loss: 1.4036	Cost: 11.35s
Train Epoch: 768 [40960/90000 (45%)]	Loss: 1.2724	Cost: 9.04s
Train Epoch: 768 [61440/90000 (68%)]	Loss: 1.1768	Cost: 6.29s
Train Epoch: 768 [81920/90000 (91%)]	Loss: 1.2533	Cost: 7.92s
Train Epoch: 768 	Average Loss: 1.4701
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7708

Learning rate: 9.85517139027031e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 769 [0/90000 (0%)]	Loss: 3.6860	Cost: 32.22s
Train Epoch: 769 [20480/90000 (23%)]	Loss: 1.0043	Cost: 6.55s
Train Epoch: 769 [40960/90000 (45%)]	Loss: 1.1717	Cost: 10.47s
Train Epoch: 769 [61440/90000 (68%)]	Loss: 0.8991	Cost: 8.85s
Train Epoch: 769 [81920/90000 (91%)]	Loss: 1.0294	Cost: 8.53s
Train Epoch: 769 	Average Loss: 1.2158
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6390

Learning rate: 9.854795824256546e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 770 [0/90000 (0%)]	Loss: 3.4359	Cost: 21.27s
Train Epoch: 770 [20480/90000 (23%)]	Loss: 1.0029	Cost: 9.60s
Train Epoch: 770 [40960/90000 (45%)]	Loss: 1.0821	Cost: 8.85s
Train Epoch: 770 [61440/90000 (68%)]	Loss: 1.0412	Cost: 8.76s
Train Epoch: 770 [81920/90000 (91%)]	Loss: 1.1534	Cost: 7.39s
Train Epoch: 770 	Average Loss: 1.1890
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5997

Learning rate: 9.854419779093642e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 771 [0/90000 (0%)]	Loss: 3.5619	Cost: 18.10s
Train Epoch: 771 [20480/90000 (23%)]	Loss: 0.9961	Cost: 7.24s
Train Epoch: 771 [40960/90000 (45%)]	Loss: 0.6882	Cost: 13.45s
Train Epoch: 771 [61440/90000 (68%)]	Loss: 0.8497	Cost: 14.52s
Train Epoch: 771 [81920/90000 (91%)]	Loss: 1.1173	Cost: 14.46s
Train Epoch: 771 	Average Loss: 1.1141
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5903

Learning rate: 9.854043254818714e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 772 [0/90000 (0%)]	Loss: 3.7254	Cost: 25.30s
Train Epoch: 772 [20480/90000 (23%)]	Loss: 0.9907	Cost: 15.28s
Train Epoch: 772 [40960/90000 (45%)]	Loss: 1.1588	Cost: 13.66s
Train Epoch: 772 [61440/90000 (68%)]	Loss: 0.9769	Cost: 11.91s
Train Epoch: 772 [81920/90000 (91%)]	Loss: 1.1341	Cost: 12.07s
Train Epoch: 772 	Average Loss: 1.1998
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5694

Saving model as e772_model.pt & e772_waveforms_supplementary.hdf5
Learning rate: 9.853666251468923e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 773 [0/90000 (0%)]	Loss: 3.6249	Cost: 32.06s
Train Epoch: 773 [20480/90000 (23%)]	Loss: 0.8568	Cost: 12.83s
Train Epoch: 773 [40960/90000 (45%)]	Loss: 0.8508	Cost: 12.16s
Train Epoch: 773 [61440/90000 (68%)]	Loss: 0.7161	Cost: 7.57s
Train Epoch: 773 [81920/90000 (91%)]	Loss: 0.9385	Cost: 5.98s
Train Epoch: 773 	Average Loss: 1.0441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6858

Learning rate: 9.853288769081479e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 774 [0/90000 (0%)]	Loss: 3.6009	Cost: 22.97s
Train Epoch: 774 [20480/90000 (23%)]	Loss: 0.9140	Cost: 6.64s
Train Epoch: 774 [40960/90000 (45%)]	Loss: 0.7936	Cost: 9.53s
Train Epoch: 774 [61440/90000 (68%)]	Loss: 0.8073	Cost: 8.70s
Train Epoch: 774 [81920/90000 (91%)]	Loss: 0.8920	Cost: 9.04s
Train Epoch: 774 	Average Loss: 1.0917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6134

Learning rate: 9.852910807693636e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 775 [0/90000 (0%)]	Loss: 3.6373	Cost: 28.88s
Train Epoch: 775 [20480/90000 (23%)]	Loss: 0.8973	Cost: 9.97s
Train Epoch: 775 [40960/90000 (45%)]	Loss: 0.8579	Cost: 8.95s
Train Epoch: 775 [61440/90000 (68%)]	Loss: 0.7990	Cost: 8.66s
Train Epoch: 775 [81920/90000 (91%)]	Loss: 0.9912	Cost: 7.95s
Train Epoch: 775 	Average Loss: 1.0640
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6532

Learning rate: 9.8525323673427e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 776 [0/90000 (0%)]	Loss: 3.6889	Cost: 33.24s
Train Epoch: 776 [20480/90000 (23%)]	Loss: 0.8937	Cost: 6.88s
Train Epoch: 776 [40960/90000 (45%)]	Loss: 0.7343	Cost: 11.04s
Train Epoch: 776 [61440/90000 (68%)]	Loss: 0.8261	Cost: 10.05s
Train Epoch: 776 [81920/90000 (91%)]	Loss: 0.8432	Cost: 12.42s
Train Epoch: 776 	Average Loss: 1.0296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6307

Learning rate: 9.85215344806602e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 777 [0/90000 (0%)]	Loss: 3.3858	Cost: 21.42s
Train Epoch: 777 [20480/90000 (23%)]	Loss: 0.8407	Cost: 10.09s
Train Epoch: 777 [40960/90000 (45%)]	Loss: 0.8045	Cost: 15.07s
Train Epoch: 777 [61440/90000 (68%)]	Loss: 0.7011	Cost: 12.82s
Train Epoch: 777 [81920/90000 (91%)]	Loss: 1.1954	Cost: 12.50s
Train Epoch: 777 	Average Loss: 1.0127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0039

Learning rate: 9.851774049900992e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 778 [0/90000 (0%)]	Loss: 3.9120	Cost: 27.59s
Train Epoch: 778 [20480/90000 (23%)]	Loss: 1.3692	Cost: 12.22s
Train Epoch: 778 [40960/90000 (45%)]	Loss: 1.1355	Cost: 14.26s
Train Epoch: 778 [61440/90000 (68%)]	Loss: 1.2019	Cost: 12.61s
Train Epoch: 778 [81920/90000 (91%)]	Loss: 1.4289	Cost: 8.78s
Train Epoch: 778 	Average Loss: 1.4429
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8198

Learning rate: 9.851394172885063e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 779 [0/90000 (0%)]	Loss: 3.7189	Cost: 25.64s
Train Epoch: 779 [20480/90000 (23%)]	Loss: 1.0521	Cost: 11.99s
Train Epoch: 779 [40960/90000 (45%)]	Loss: 1.0741	Cost: 11.29s
Train Epoch: 779 [61440/90000 (68%)]	Loss: 0.7939	Cost: 6.24s
Train Epoch: 779 [81920/90000 (91%)]	Loss: 0.8024	Cost: 6.54s
Train Epoch: 779 	Average Loss: 1.1296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4564

Saving model as e779_model.pt & e779_waveforms_supplementary.hdf5
Learning rate: 9.851013817055725e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 780 [0/90000 (0%)]	Loss: 3.1436	Cost: 26.60s
Train Epoch: 780 [20480/90000 (23%)]	Loss: 0.8801	Cost: 7.25s
Train Epoch: 780 [40960/90000 (45%)]	Loss: 0.7246	Cost: 9.80s
Train Epoch: 780 [61440/90000 (68%)]	Loss: 0.8417	Cost: 8.77s
Train Epoch: 780 [81920/90000 (91%)]	Loss: 0.9649	Cost: 8.52s
Train Epoch: 780 	Average Loss: 1.0499
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6484

Learning rate: 9.850632982450517e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 781 [0/90000 (0%)]	Loss: 3.4080	Cost: 31.21s
Train Epoch: 781 [20480/90000 (23%)]	Loss: 1.0078	Cost: 8.81s
Train Epoch: 781 [40960/90000 (45%)]	Loss: 0.8131	Cost: 8.90s
Train Epoch: 781 [61440/90000 (68%)]	Loss: 0.6960	Cost: 8.81s
Train Epoch: 781 [81920/90000 (91%)]	Loss: 0.8810	Cost: 6.39s
Train Epoch: 781 	Average Loss: 1.0378
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6430

Learning rate: 9.850251669107029e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 782 [0/90000 (0%)]	Loss: 3.5993	Cost: 22.11s
Train Epoch: 782 [20480/90000 (23%)]	Loss: 0.8484	Cost: 6.70s
Train Epoch: 782 [40960/90000 (45%)]	Loss: 0.8945	Cost: 8.77s
Train Epoch: 782 [61440/90000 (68%)]	Loss: 0.7559	Cost: 8.74s
Train Epoch: 782 [81920/90000 (91%)]	Loss: 0.9105	Cost: 13.04s
Train Epoch: 782 	Average Loss: 1.0332
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5864

Learning rate: 9.84986987706289e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 783 [0/90000 (0%)]	Loss: 3.2508	Cost: 22.44s
Train Epoch: 783 [20480/90000 (23%)]	Loss: 0.8378	Cost: 10.43s
Train Epoch: 783 [40960/90000 (45%)]	Loss: 0.7837	Cost: 14.17s
Train Epoch: 783 [61440/90000 (68%)]	Loss: 0.6307	Cost: 13.56s
Train Epoch: 783 [81920/90000 (91%)]	Loss: 0.7768	Cost: 12.47s
Train Epoch: 783 	Average Loss: 0.9416
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4383

Saving model as e783_model.pt & e783_waveforms_supplementary.hdf5
Learning rate: 9.849487606355786e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 784 [0/90000 (0%)]	Loss: 3.7071	Cost: 33.07s
Train Epoch: 784 [20480/90000 (23%)]	Loss: 0.7944	Cost: 14.73s
Train Epoch: 784 [40960/90000 (45%)]	Loss: 0.6202	Cost: 13.75s
Train Epoch: 784 [61440/90000 (68%)]	Loss: 0.6115	Cost: 12.35s
Train Epoch: 784 [81920/90000 (91%)]	Loss: 0.8126	Cost: 9.50s
Train Epoch: 784 	Average Loss: 0.8705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5377

Learning rate: 9.849104857023443e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 785 [0/90000 (0%)]	Loss: 3.3165	Cost: 31.27s
Train Epoch: 785 [20480/90000 (23%)]	Loss: 0.7516	Cost: 12.63s
Train Epoch: 785 [40960/90000 (45%)]	Loss: 0.6946	Cost: 12.31s
Train Epoch: 785 [61440/90000 (68%)]	Loss: 0.6153	Cost: 9.60s
Train Epoch: 785 [81920/90000 (91%)]	Loss: 0.8493	Cost: 6.32s
Train Epoch: 785 	Average Loss: 0.9217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6161

Learning rate: 9.848721629103637e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 786 [0/90000 (0%)]	Loss: 3.3600	Cost: 25.28s
Train Epoch: 786 [20480/90000 (23%)]	Loss: 0.8016	Cost: 11.28s
Train Epoch: 786 [40960/90000 (45%)]	Loss: 0.6064	Cost: 12.10s
Train Epoch: 786 [61440/90000 (68%)]	Loss: 0.6912	Cost: 5.97s
Train Epoch: 786 [81920/90000 (91%)]	Loss: 0.8469	Cost: 6.14s
Train Epoch: 786 	Average Loss: 0.9298
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4904

Learning rate: 9.848337922634192e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 787 [0/90000 (0%)]	Loss: 3.5308	Cost: 29.56s
Train Epoch: 787 [20480/90000 (23%)]	Loss: 0.8297	Cost: 8.70s
Train Epoch: 787 [40960/90000 (45%)]	Loss: 0.8387	Cost: 6.35s
Train Epoch: 787 [61440/90000 (68%)]	Loss: 0.5347	Cost: 7.02s
Train Epoch: 787 [81920/90000 (91%)]	Loss: 0.8203	Cost: 8.64s
Train Epoch: 787 	Average Loss: 0.8527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4005

Saving model as e787_model.pt & e787_waveforms_supplementary.hdf5
Learning rate: 9.847953737652978e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 788 [0/90000 (0%)]	Loss: 3.3173	Cost: 28.70s
Train Epoch: 788 [20480/90000 (23%)]	Loss: 0.6097	Cost: 12.51s
Train Epoch: 788 [40960/90000 (45%)]	Loss: 0.5973	Cost: 10.48s
Train Epoch: 788 [61440/90000 (68%)]	Loss: 0.5160	Cost: 8.87s
Train Epoch: 788 [81920/90000 (91%)]	Loss: 0.6923	Cost: 7.29s
Train Epoch: 788 	Average Loss: 0.8073
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3810

Saving model as e788_model.pt & e788_waveforms_supplementary.hdf5
Learning rate: 9.847569074197914e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 789 [0/90000 (0%)]	Loss: 3.3432	Cost: 23.62s
Train Epoch: 789 [20480/90000 (23%)]	Loss: 0.6793	Cost: 7.62s
Train Epoch: 789 [40960/90000 (45%)]	Loss: 0.9552	Cost: 13.29s
Train Epoch: 789 [61440/90000 (68%)]	Loss: 0.7791	Cost: 10.10s
Train Epoch: 789 [81920/90000 (91%)]	Loss: 0.8657	Cost: 12.47s
Train Epoch: 789 	Average Loss: 0.9478
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4662

Learning rate: 9.847183932306961e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 790 [0/90000 (0%)]	Loss: 3.4854	Cost: 22.69s
Train Epoch: 790 [20480/90000 (23%)]	Loss: 0.6070	Cost: 9.61s
Train Epoch: 790 [40960/90000 (45%)]	Loss: 0.8363	Cost: 11.27s
Train Epoch: 790 [61440/90000 (68%)]	Loss: 0.7099	Cost: 12.56s
Train Epoch: 790 [81920/90000 (91%)]	Loss: 0.8285	Cost: 12.06s
Train Epoch: 790 	Average Loss: 0.9610
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5437

Learning rate: 9.846798312018134e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 791 [0/90000 (0%)]	Loss: 3.4843	Cost: 23.46s
Train Epoch: 791 [20480/90000 (23%)]	Loss: 0.7010	Cost: 13.18s
Train Epoch: 791 [40960/90000 (45%)]	Loss: 0.7524	Cost: 12.65s
Train Epoch: 791 [61440/90000 (68%)]	Loss: 0.4514	Cost: 12.08s
Train Epoch: 791 [81920/90000 (91%)]	Loss: 0.7341	Cost: 12.19s
Train Epoch: 791 	Average Loss: 0.8589
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4772

Learning rate: 9.846412213369493e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 792 [0/90000 (0%)]	Loss: 3.4230	Cost: 25.76s
Train Epoch: 792 [20480/90000 (23%)]	Loss: 0.7479	Cost: 11.98s
Train Epoch: 792 [40960/90000 (45%)]	Loss: 0.6452	Cost: 12.80s
Train Epoch: 792 [61440/90000 (68%)]	Loss: 0.4969	Cost: 12.20s
Train Epoch: 792 [81920/90000 (91%)]	Loss: 0.5295	Cost: 6.75s
Train Epoch: 792 	Average Loss: 0.8580
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3750

Saving model as e792_model.pt & e792_waveforms_supplementary.hdf5
Learning rate: 9.84602563639914e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 793 [0/90000 (0%)]	Loss: 3.3494	Cost: 38.37s
Train Epoch: 793 [20480/90000 (23%)]	Loss: 0.7094	Cost: 12.71s
Train Epoch: 793 [40960/90000 (45%)]	Loss: 0.6448	Cost: 8.22s
Train Epoch: 793 [61440/90000 (68%)]	Loss: 0.5416	Cost: 6.14s
Train Epoch: 793 [81920/90000 (91%)]	Loss: 0.6341	Cost: 7.87s
Train Epoch: 793 	Average Loss: 0.7927
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4865

Learning rate: 9.845638581145233e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 794 [0/90000 (0%)]	Loss: 3.1179	Cost: 22.33s
Train Epoch: 794 [20480/90000 (23%)]	Loss: 0.4166	Cost: 10.97s
Train Epoch: 794 [40960/90000 (45%)]	Loss: 0.5940	Cost: 9.86s
Train Epoch: 794 [61440/90000 (68%)]	Loss: 0.5172	Cost: 9.31s
Train Epoch: 794 [81920/90000 (91%)]	Loss: 0.6024	Cost: 8.74s
Train Epoch: 794 	Average Loss: 0.7250
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3727

Saving model as e794_model.pt & e794_waveforms_supplementary.hdf5
Learning rate: 9.845251047645971e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 795 [0/90000 (0%)]	Loss: 3.2025	Cost: 23.71s
Train Epoch: 795 [20480/90000 (23%)]	Loss: 0.5687	Cost: 9.10s
Train Epoch: 795 [40960/90000 (45%)]	Loss: 0.5040	Cost: 8.96s
Train Epoch: 795 [61440/90000 (68%)]	Loss: 0.4614	Cost: 8.20s
Train Epoch: 795 [81920/90000 (91%)]	Loss: 0.6436	Cost: 6.54s
Train Epoch: 795 	Average Loss: 0.6523
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1608

Saving model as e795_model.pt & e795_waveforms_supplementary.hdf5
Learning rate: 9.844863035939603e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 796 [0/90000 (0%)]	Loss: 3.2539	Cost: 19.11s
Train Epoch: 796 [20480/90000 (23%)]	Loss: 0.3307	Cost: 8.03s
Train Epoch: 796 [40960/90000 (45%)]	Loss: 0.6406	Cost: 9.87s
Train Epoch: 796 [61440/90000 (68%)]	Loss: 0.3770	Cost: 11.11s
Train Epoch: 796 [81920/90000 (91%)]	Loss: 0.4819	Cost: 12.30s
Train Epoch: 796 	Average Loss: 0.6501
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3156

Learning rate: 9.844474546064422e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 797 [0/90000 (0%)]	Loss: 3.1320	Cost: 24.49s
Train Epoch: 797 [20480/90000 (23%)]	Loss: 0.5713	Cost: 12.39s
Train Epoch: 797 [40960/90000 (45%)]	Loss: 0.4960	Cost: 12.81s
Train Epoch: 797 [61440/90000 (68%)]	Loss: 0.2346	Cost: 12.38s
Train Epoch: 797 [81920/90000 (91%)]	Loss: 0.6080	Cost: 12.40s
Train Epoch: 797 	Average Loss: 0.6467
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2470

Learning rate: 9.844085578058772e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 798 [0/90000 (0%)]	Loss: 3.5718	Cost: 30.49s
Train Epoch: 798 [20480/90000 (23%)]	Loss: 0.7739	Cost: 14.24s
Train Epoch: 798 [40960/90000 (45%)]	Loss: 0.7040	Cost: 13.33s
Train Epoch: 798 [61440/90000 (68%)]	Loss: 0.6228	Cost: 12.05s
Train Epoch: 798 [81920/90000 (91%)]	Loss: 0.5325	Cost: 8.33s
Train Epoch: 798 	Average Loss: 0.8263
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4429

Learning rate: 9.843696131961044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 799 [0/90000 (0%)]	Loss: 3.3699	Cost: 38.83s
Train Epoch: 799 [20480/90000 (23%)]	Loss: 0.4030	Cost: 12.95s
Train Epoch: 799 [40960/90000 (45%)]	Loss: 0.3286	Cost: 11.12s
Train Epoch: 799 [61440/90000 (68%)]	Loss: 0.2954	Cost: 6.69s
Train Epoch: 799 [81920/90000 (91%)]	Loss: 0.6500	Cost: 7.41s
Train Epoch: 799 	Average Loss: 0.6737
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3015

Learning rate: 9.843306207809673e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 800 [0/90000 (0%)]	Loss: 2.9498	Cost: 31.97s
Train Epoch: 800 [20480/90000 (23%)]	Loss: 0.6783	Cost: 9.20s
Train Epoch: 800 [40960/90000 (45%)]	Loss: 1.0708	Cost: 6.52s
Train Epoch: 800 [61440/90000 (68%)]	Loss: 0.6868	Cost: 8.07s
Train Epoch: 800 [81920/90000 (91%)]	Loss: 0.8605	Cost: 8.68s
Train Epoch: 800 	Average Loss: 0.9592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4169

Learning rate: 9.842915805643143e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 801 [0/90000 (0%)]	Loss: 3.5423	Cost: 21.68s
Train Epoch: 801 [20480/90000 (23%)]	Loss: 0.6440	Cost: 6.75s
Train Epoch: 801 [40960/90000 (45%)]	Loss: 0.5660	Cost: 9.30s
Train Epoch: 801 [61440/90000 (68%)]	Loss: 0.6505	Cost: 8.89s
Train Epoch: 801 [81920/90000 (91%)]	Loss: 0.7204	Cost: 8.45s
Train Epoch: 801 	Average Loss: 0.7820
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3869

Learning rate: 9.842524925499985e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 802 [0/90000 (0%)]	Loss: 3.2107	Cost: 23.20s
Train Epoch: 802 [20480/90000 (23%)]	Loss: 0.5217	Cost: 8.24s
Train Epoch: 802 [40960/90000 (45%)]	Loss: 0.3314	Cost: 9.08s
Train Epoch: 802 [61440/90000 (68%)]	Loss: 0.5478	Cost: 8.72s
Train Epoch: 802 [81920/90000 (91%)]	Loss: 0.6789	Cost: 8.46s
Train Epoch: 802 	Average Loss: 0.6565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3114

Learning rate: 9.842133567418779e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 803 [0/90000 (0%)]	Loss: 3.2431	Cost: 23.59s
Train Epoch: 803 [20480/90000 (23%)]	Loss: 0.5468	Cost: 12.13s
Train Epoch: 803 [40960/90000 (45%)]	Loss: 0.5053	Cost: 9.73s
Train Epoch: 803 [61440/90000 (68%)]	Loss: 0.2001	Cost: 7.48s
Train Epoch: 803 [81920/90000 (91%)]	Loss: 0.5934	Cost: 8.37s
Train Epoch: 803 	Average Loss: 0.6156
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3430

Learning rate: 9.841741731438147e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 804 [0/90000 (0%)]	Loss: 3.1535	Cost: 19.98s
Train Epoch: 804 [20480/90000 (23%)]	Loss: 0.6452	Cost: 9.62s
Train Epoch: 804 [40960/90000 (45%)]	Loss: 0.5697	Cost: 14.88s
Train Epoch: 804 [61440/90000 (68%)]	Loss: 0.1424	Cost: 13.40s
Train Epoch: 804 [81920/90000 (91%)]	Loss: 0.5556	Cost: 12.41s
Train Epoch: 804 	Average Loss: 0.6627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2151

Learning rate: 9.841349417596765e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 805 [0/90000 (0%)]	Loss: 3.2420	Cost: 33.39s
Train Epoch: 805 [20480/90000 (23%)]	Loss: 0.2023	Cost: 13.47s
Train Epoch: 805 [40960/90000 (45%)]	Loss: 0.3396	Cost: 12.67s
Train Epoch: 805 [61440/90000 (68%)]	Loss: 0.3801	Cost: 12.34s
Train Epoch: 805 [81920/90000 (91%)]	Loss: 0.5254	Cost: 12.25s
Train Epoch: 805 	Average Loss: 0.5735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4881

Learning rate: 9.840956625933353e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 806 [0/90000 (0%)]	Loss: 3.6631	Cost: 23.46s
Train Epoch: 806 [20480/90000 (23%)]	Loss: 0.6604	Cost: 13.94s
Train Epoch: 806 [40960/90000 (45%)]	Loss: 0.7656	Cost: 12.30s
Train Epoch: 806 [61440/90000 (68%)]	Loss: 0.5398	Cost: 9.04s
Train Epoch: 806 [81920/90000 (91%)]	Loss: 0.4540	Cost: 6.44s
Train Epoch: 806 	Average Loss: 0.7361
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2956

Learning rate: 9.840563356486677e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 807 [0/90000 (0%)]	Loss: 3.2503	Cost: 23.65s
Train Epoch: 807 [20480/90000 (23%)]	Loss: 0.4682	Cost: 10.50s
Train Epoch: 807 [40960/90000 (45%)]	Loss: 0.2829	Cost: 6.42s
Train Epoch: 807 [61440/90000 (68%)]	Loss: 0.3005	Cost: 6.25s
Train Epoch: 807 [81920/90000 (91%)]	Loss: 0.4293	Cost: 8.95s
Train Epoch: 807 	Average Loss: 0.5304
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2123

Learning rate: 9.840169609295549e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 808 [0/90000 (0%)]	Loss: 3.4041	Cost: 21.65s
Train Epoch: 808 [20480/90000 (23%)]	Loss: 0.3115	Cost: 9.96s
Train Epoch: 808 [40960/90000 (45%)]	Loss: 0.2933	Cost: 11.27s
Train Epoch: 808 [61440/90000 (68%)]	Loss: 0.5492	Cost: 8.98s
Train Epoch: 808 [81920/90000 (91%)]	Loss: 0.5834	Cost: 8.74s
Train Epoch: 808 	Average Loss: 0.6433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4696

Learning rate: 9.839775384398833e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 809 [0/90000 (0%)]	Loss: 3.3746	Cost: 26.67s
Train Epoch: 809 [20480/90000 (23%)]	Loss: 0.3881	Cost: 11.29s
Train Epoch: 809 [40960/90000 (45%)]	Loss: 0.5326	Cost: 10.23s
Train Epoch: 809 [61440/90000 (68%)]	Loss: 0.3586	Cost: 8.69s
Train Epoch: 809 [81920/90000 (91%)]	Loss: 0.5871	Cost: 6.19s
Train Epoch: 809 	Average Loss: 0.7288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4128

Learning rate: 9.839380681835437e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 810 [0/90000 (0%)]	Loss: 3.4893	Cost: 21.34s
Train Epoch: 810 [20480/90000 (23%)]	Loss: 0.3152	Cost: 6.60s
Train Epoch: 810 [40960/90000 (45%)]	Loss: 0.4546	Cost: 7.94s
Train Epoch: 810 [61440/90000 (68%)]	Loss: 0.1346	Cost: 8.28s
Train Epoch: 810 [81920/90000 (91%)]	Loss: 0.4385	Cost: 16.05s
Train Epoch: 810 	Average Loss: 0.5628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2205

Learning rate: 9.838985501644315e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 811 [0/90000 (0%)]	Loss: 3.3411	Cost: 20.33s
Train Epoch: 811 [20480/90000 (23%)]	Loss: 0.2928	Cost: 9.77s
Train Epoch: 811 [40960/90000 (45%)]	Loss: 0.2357	Cost: 13.34s
Train Epoch: 811 [61440/90000 (68%)]	Loss: 0.0591	Cost: 12.27s
Train Epoch: 811 [81920/90000 (91%)]	Loss: 0.3458	Cost: 12.14s
Train Epoch: 811 	Average Loss: 0.4797
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0533

Saving model as e811_model.pt & e811_waveforms_supplementary.hdf5
Learning rate: 9.838589843864472e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 812 [0/90000 (0%)]	Loss: 3.1320	Cost: 23.41s
Train Epoch: 812 [20480/90000 (23%)]	Loss: 0.3188	Cost: 11.16s
Train Epoch: 812 [40960/90000 (45%)]	Loss: 0.4347	Cost: 13.98s
Train Epoch: 812 [61440/90000 (68%)]	Loss: 0.1283	Cost: 12.38s
Train Epoch: 812 [81920/90000 (91%)]	Loss: 0.3301	Cost: 7.79s
Train Epoch: 812 	Average Loss: 0.4690
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1597

Learning rate: 9.838193708534956e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 813 [0/90000 (0%)]	Loss: 3.2071	Cost: 30.83s
Train Epoch: 813 [20480/90000 (23%)]	Loss: 0.1906	Cost: 14.69s
Train Epoch: 813 [40960/90000 (45%)]	Loss: 0.2623	Cost: 12.56s
Train Epoch: 813 [61440/90000 (68%)]	Loss: 0.1148	Cost: 8.34s
Train Epoch: 813 [81920/90000 (91%)]	Loss: 0.6647	Cost: 6.07s
Train Epoch: 813 	Average Loss: 0.5049
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4759

Learning rate: 9.837797095694866e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 814 [0/90000 (0%)]	Loss: 3.4337	Cost: 25.44s
Train Epoch: 814 [20480/90000 (23%)]	Loss: 0.5580	Cost: 11.65s
Train Epoch: 814 [40960/90000 (45%)]	Loss: 0.3354	Cost: 11.05s
Train Epoch: 814 [61440/90000 (68%)]	Loss: 0.1284	Cost: 6.40s
Train Epoch: 814 [81920/90000 (91%)]	Loss: 0.4237	Cost: 6.41s
Train Epoch: 814 	Average Loss: 0.5708
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2387

Learning rate: 9.837400005383343e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 815 [0/90000 (0%)]	Loss: 3.0020	Cost: 23.33s
Train Epoch: 815 [20480/90000 (23%)]	Loss: 0.4109	Cost: 12.57s
Train Epoch: 815 [40960/90000 (45%)]	Loss: 0.2628	Cost: 8.26s
Train Epoch: 815 [61440/90000 (68%)]	Loss: 0.1142	Cost: 6.23s
Train Epoch: 815 [81920/90000 (91%)]	Loss: 0.5800	Cost: 8.36s
Train Epoch: 815 	Average Loss: 0.4566
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1410

Learning rate: 9.837002437639581e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 816 [0/90000 (0%)]	Loss: 3.0966	Cost: 28.42s
Train Epoch: 816 [20480/90000 (23%)]	Loss: 0.3450	Cost: 6.51s
Train Epoch: 816 [40960/90000 (45%)]	Loss: 0.1882	Cost: 9.42s
Train Epoch: 816 [61440/90000 (68%)]	Loss: 0.1718	Cost: 8.59s
Train Epoch: 816 [81920/90000 (91%)]	Loss: 0.3173	Cost: 8.80s
Train Epoch: 816 	Average Loss: 0.3839
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0942

Learning rate: 9.836604392502818e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 817 [0/90000 (0%)]	Loss: 3.2088	Cost: 26.10s
Train Epoch: 817 [20480/90000 (23%)]	Loss: 0.1656	Cost: 8.75s
Train Epoch: 817 [40960/90000 (45%)]	Loss: 0.3323	Cost: 8.98s
Train Epoch: 817 [61440/90000 (68%)]	Loss: 0.0674	Cost: 9.10s
Train Epoch: 817 [81920/90000 (91%)]	Loss: 0.1124	Cost: 8.99s
Train Epoch: 817 	Average Loss: 0.3603
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1602

Learning rate: 9.836205870012337e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 818 [0/90000 (0%)]	Loss: 3.0646	Cost: 24.29s
Train Epoch: 818 [20480/90000 (23%)]	Loss: 0.0872	Cost: 8.97s
Train Epoch: 818 [40960/90000 (45%)]	Loss: 0.1814	Cost: 13.40s
Train Epoch: 818 [61440/90000 (68%)]	Loss: -0.0614	Cost: 13.10s
Train Epoch: 818 [81920/90000 (91%)]	Loss: 0.2634	Cost: 12.58s
Train Epoch: 818 	Average Loss: 0.3503
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0742

Learning rate: 9.835806870207475e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 819 [0/90000 (0%)]	Loss: 3.4734	Cost: 21.48s
Train Epoch: 819 [20480/90000 (23%)]	Loss: 0.4266	Cost: 11.48s
Train Epoch: 819 [40960/90000 (45%)]	Loss: 0.1748	Cost: 15.00s
Train Epoch: 819 [61440/90000 (68%)]	Loss: 0.2274	Cost: 14.04s
Train Epoch: 819 [81920/90000 (91%)]	Loss: 0.2972	Cost: 12.46s
Train Epoch: 819 	Average Loss: 0.4293
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1544

Learning rate: 9.835407393127609e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 820 [0/90000 (0%)]	Loss: 3.2379	Cost: 34.26s
Train Epoch: 820 [20480/90000 (23%)]	Loss: 0.1521	Cost: 13.67s
Train Epoch: 820 [40960/90000 (45%)]	Loss: 0.1057	Cost: 12.44s
Train Epoch: 820 [61440/90000 (68%)]	Loss: 0.0112	Cost: 12.25s
Train Epoch: 820 [81920/90000 (91%)]	Loss: 0.1998	Cost: 9.71s
Train Epoch: 820 	Average Loss: 0.3561
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0828

Learning rate: 9.835007438812164e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 821 [0/90000 (0%)]	Loss: 3.0587	Cost: 26.11s
Train Epoch: 821 [20480/90000 (23%)]	Loss: 0.1674	Cost: 10.28s
Train Epoch: 821 [40960/90000 (45%)]	Loss: 0.1482	Cost: 9.83s
Train Epoch: 821 [61440/90000 (68%)]	Loss: 0.2244	Cost: 6.11s
Train Epoch: 821 [81920/90000 (91%)]	Loss: 0.1942	Cost: 7.06s
Train Epoch: 821 	Average Loss: 0.3650
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1473

Learning rate: 9.834607007300618e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 822 [0/90000 (0%)]	Loss: 3.1362	Cost: 29.48s
Train Epoch: 822 [20480/90000 (23%)]	Loss: 0.2716	Cost: 9.62s
Train Epoch: 822 [40960/90000 (45%)]	Loss: 0.1612	Cost: 6.42s
Train Epoch: 822 [61440/90000 (68%)]	Loss: 0.0564	Cost: 6.98s
Train Epoch: 822 [81920/90000 (91%)]	Loss: 0.3361	Cost: 8.54s
Train Epoch: 822 	Average Loss: 0.3998
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0885

Learning rate: 9.834206098632488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 823 [0/90000 (0%)]	Loss: 2.7847	Cost: 23.96s
Train Epoch: 823 [20480/90000 (23%)]	Loss: 0.3855	Cost: 8.59s
Train Epoch: 823 [40960/90000 (45%)]	Loss: 0.5173	Cost: 11.83s
Train Epoch: 823 [61440/90000 (68%)]	Loss: 0.2602	Cost: 9.02s
Train Epoch: 823 [81920/90000 (91%)]	Loss: 0.3015	Cost: 8.92s
Train Epoch: 823 	Average Loss: 0.4933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1163

Learning rate: 9.833804712847345e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 824 [0/90000 (0%)]	Loss: 3.3907	Cost: 27.32s
Train Epoch: 824 [20480/90000 (23%)]	Loss: 0.3179	Cost: 10.85s
Train Epoch: 824 [40960/90000 (45%)]	Loss: 0.2846	Cost: 9.69s
Train Epoch: 824 [61440/90000 (68%)]	Loss: 0.1023	Cost: 6.20s
Train Epoch: 824 [81920/90000 (91%)]	Loss: 0.2672	Cost: 6.71s
Train Epoch: 824 	Average Loss: 0.3957
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0380

Saving model as e824_model.pt & e824_waveforms_supplementary.hdf5
Learning rate: 9.833402849984804e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 825 [0/90000 (0%)]	Loss: 3.1139	Cost: 20.26s
Train Epoch: 825 [20480/90000 (23%)]	Loss: 0.0301	Cost: 7.74s
Train Epoch: 825 [40960/90000 (45%)]	Loss: 0.0797	Cost: 12.46s
Train Epoch: 825 [61440/90000 (68%)]	Loss: 0.0648	Cost: 13.65s
Train Epoch: 825 [81920/90000 (91%)]	Loss: 0.1484	Cost: 12.31s
Train Epoch: 825 	Average Loss: 0.2795
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0014

Saving model as e825_model.pt & e825_waveforms_supplementary.hdf5
Learning rate: 9.833000510084526e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 826 [0/90000 (0%)]	Loss: 2.9605	Cost: 24.74s
Train Epoch: 826 [20480/90000 (23%)]	Loss: 0.0416	Cost: 12.95s
Train Epoch: 826 [40960/90000 (45%)]	Loss: 0.0246	Cost: 12.34s
Train Epoch: 826 [61440/90000 (68%)]	Loss: -0.2444	Cost: 12.40s
Train Epoch: 826 [81920/90000 (91%)]	Loss: 0.1562	Cost: 10.37s
Train Epoch: 826 	Average Loss: 0.2437
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9367

Saving model as e826_model.pt & e826_waveforms_supplementary.hdf5
Learning rate: 9.832597693186221e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 827 [0/90000 (0%)]	Loss: 2.6873	Cost: 23.09s
Train Epoch: 827 [20480/90000 (23%)]	Loss: 0.0450	Cost: 10.37s
Train Epoch: 827 [40960/90000 (45%)]	Loss: 0.0363	Cost: 9.94s
Train Epoch: 827 [61440/90000 (68%)]	Loss: -0.0777	Cost: 6.47s
Train Epoch: 827 [81920/90000 (91%)]	Loss: 0.1024	Cost: 7.11s
Train Epoch: 827 	Average Loss: 0.1902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8812

Saving model as e827_model.pt & e827_waveforms_supplementary.hdf5
Learning rate: 9.832194399329644e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 828 [0/90000 (0%)]	Loss: 2.8065	Cost: 27.51s
Train Epoch: 828 [20480/90000 (23%)]	Loss: -0.0016	Cost: 12.49s
Train Epoch: 828 [40960/90000 (45%)]	Loss: 0.1772	Cost: 8.89s
Train Epoch: 828 [61440/90000 (68%)]	Loss: -0.0474	Cost: 6.50s
Train Epoch: 828 [81920/90000 (91%)]	Loss: 0.2205	Cost: 8.27s
Train Epoch: 828 	Average Loss: 0.2773
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9953

Learning rate: 9.831790628554601e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 829 [0/90000 (0%)]	Loss: 3.1162	Cost: 20.63s
Train Epoch: 829 [20480/90000 (23%)]	Loss: 0.0440	Cost: 9.90s
Train Epoch: 829 [40960/90000 (45%)]	Loss: 0.2699	Cost: 9.74s
Train Epoch: 829 [61440/90000 (68%)]	Loss: -0.0591	Cost: 9.08s
Train Epoch: 829 [81920/90000 (91%)]	Loss: 0.4101	Cost: 9.15s
Train Epoch: 829 	Average Loss: 0.3220
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1195

Learning rate: 9.831386380900942e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 830 [0/90000 (0%)]	Loss: 3.1232	Cost: 21.89s
Train Epoch: 830 [20480/90000 (23%)]	Loss: 0.1283	Cost: 8.38s
Train Epoch: 830 [40960/90000 (45%)]	Loss: -0.0517	Cost: 9.11s
Train Epoch: 830 [61440/90000 (68%)]	Loss: -0.1800	Cost: 8.70s
Train Epoch: 830 [81920/90000 (91%)]	Loss: 0.1033	Cost: 8.37s
Train Epoch: 830 	Average Loss: 0.2141
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9348

Learning rate: 9.830981656408563e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 831 [0/90000 (0%)]	Loss: 3.0485	Cost: 21.65s
Train Epoch: 831 [20480/90000 (23%)]	Loss: -0.0911	Cost: 9.14s
Train Epoch: 831 [40960/90000 (45%)]	Loss: -0.0433	Cost: 7.14s
Train Epoch: 831 [61440/90000 (68%)]	Loss: -0.0725	Cost: 6.41s
Train Epoch: 831 [81920/90000 (91%)]	Loss: 0.0272	Cost: 6.72s
Train Epoch: 831 	Average Loss: 0.1490
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0284

Learning rate: 9.830576455117411e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 832 [0/90000 (0%)]	Loss: 3.0825	Cost: 21.52s
Train Epoch: 832 [20480/90000 (23%)]	Loss: 0.0178	Cost: 9.23s
Train Epoch: 832 [40960/90000 (45%)]	Loss: -0.0769	Cost: 8.96s
Train Epoch: 832 [61440/90000 (68%)]	Loss: -0.1227	Cost: 11.57s
Train Epoch: 832 [81920/90000 (91%)]	Loss: -0.1793	Cost: 12.43s
Train Epoch: 832 	Average Loss: 0.1574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8646

Saving model as e832_model.pt & e832_waveforms_supplementary.hdf5
Learning rate: 9.830170777067474e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 833 [0/90000 (0%)]	Loss: 2.9682	Cost: 24.49s
Train Epoch: 833 [20480/90000 (23%)]	Loss: -0.1853	Cost: 12.12s
Train Epoch: 833 [40960/90000 (45%)]	Loss: -0.1223	Cost: 12.84s
Train Epoch: 833 [61440/90000 (68%)]	Loss: -0.0303	Cost: 12.83s
Train Epoch: 833 [81920/90000 (91%)]	Loss: 0.0650	Cost: 12.48s
Train Epoch: 833 	Average Loss: 0.1369
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9459

Learning rate: 9.829764622298796e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 834 [0/90000 (0%)]	Loss: 3.0385	Cost: 26.96s
Train Epoch: 834 [20480/90000 (23%)]	Loss: 0.0466	Cost: 10.19s
Train Epoch: 834 [40960/90000 (45%)]	Loss: -0.0802	Cost: 14.59s
Train Epoch: 834 [61440/90000 (68%)]	Loss: -0.1128	Cost: 12.61s
Train Epoch: 834 [81920/90000 (91%)]	Loss: 0.0343	Cost: 10.67s
Train Epoch: 834 	Average Loss: 0.1528
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9700

Learning rate: 9.829357990851458e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 835 [0/90000 (0%)]	Loss: 2.8794	Cost: 27.00s
Train Epoch: 835 [20480/90000 (23%)]	Loss: -0.1883	Cost: 10.87s
Train Epoch: 835 [40960/90000 (45%)]	Loss: -0.2457	Cost: 13.25s
Train Epoch: 835 [61440/90000 (68%)]	Loss: -0.1429	Cost: 12.15s
Train Epoch: 835 [81920/90000 (91%)]	Loss: -0.0313	Cost: 8.56s
Train Epoch: 835 	Average Loss: 0.0353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7817

Saving model as e835_model.pt & e835_waveforms_supplementary.hdf5
Learning rate: 9.828950882765597e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 836 [0/90000 (0%)]	Loss: 2.9856	Cost: 38.73s
Train Epoch: 836 [20480/90000 (23%)]	Loss: -0.0343	Cost: 11.38s
Train Epoch: 836 [40960/90000 (45%)]	Loss: -0.2521	Cost: 8.49s
Train Epoch: 836 [61440/90000 (68%)]	Loss: -0.1685	Cost: 6.26s
Train Epoch: 836 [81920/90000 (91%)]	Loss: 0.0358	Cost: 8.00s
Train Epoch: 836 	Average Loss: 0.0969
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3754

Learning rate: 9.82854329808139e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 837 [0/90000 (0%)]	Loss: 3.4807	Cost: 33.13s
Train Epoch: 837 [20480/90000 (23%)]	Loss: 0.4449	Cost: 6.43s
Train Epoch: 837 [40960/90000 (45%)]	Loss: 0.1714	Cost: 8.42s
Train Epoch: 837 [61440/90000 (68%)]	Loss: 0.2640	Cost: 8.87s
Train Epoch: 837 [81920/90000 (91%)]	Loss: 0.2070	Cost: 8.88s
Train Epoch: 837 	Average Loss: 0.5414
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1098

Learning rate: 9.828135236839064e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 838 [0/90000 (0%)]	Loss: 3.0200	Cost: 20.20s
Train Epoch: 838 [20480/90000 (23%)]	Loss: -0.0800	Cost: 9.31s
Train Epoch: 838 [40960/90000 (45%)]	Loss: -0.0952	Cost: 8.94s
Train Epoch: 838 [61440/90000 (68%)]	Loss: -0.1366	Cost: 8.71s
Train Epoch: 838 [81920/90000 (91%)]	Loss: -0.0042	Cost: 9.35s
Train Epoch: 838 	Average Loss: 0.1663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8025

Learning rate: 9.827726699078896e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 839 [0/90000 (0%)]	Loss: 2.4643	Cost: 19.11s
Train Epoch: 839 [20480/90000 (23%)]	Loss: -0.0290	Cost: 9.06s
Train Epoch: 839 [40960/90000 (45%)]	Loss: 0.0103	Cost: 11.16s
Train Epoch: 839 [61440/90000 (68%)]	Loss: -0.3158	Cost: 9.23s
Train Epoch: 839 [81920/90000 (91%)]	Loss: -0.0582	Cost: 6.61s
Train Epoch: 839 	Average Loss: 0.1097
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7991

Learning rate: 9.827317684841204e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 840 [0/90000 (0%)]	Loss: 3.0727	Cost: 22.17s
Train Epoch: 840 [20480/90000 (23%)]	Loss: -0.2360	Cost: 6.41s
Train Epoch: 840 [40960/90000 (45%)]	Loss: -0.0406	Cost: 11.55s
Train Epoch: 840 [61440/90000 (68%)]	Loss: -0.2109	Cost: 7.85s
Train Epoch: 840 [81920/90000 (91%)]	Loss: 0.1825	Cost: 12.62s
Train Epoch: 840 	Average Loss: 0.1066
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8850

Learning rate: 9.826908194166357e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 841 [0/90000 (0%)]	Loss: 2.9140	Cost: 34.05s
Train Epoch: 841 [20480/90000 (23%)]	Loss: -0.1064	Cost: 12.84s
Train Epoch: 841 [40960/90000 (45%)]	Loss: 0.0030	Cost: 12.82s
Train Epoch: 841 [61440/90000 (68%)]	Loss: 0.0192	Cost: 12.23s
Train Epoch: 841 [81920/90000 (91%)]	Loss: 0.4724	Cost: 12.12s
Train Epoch: 841 	Average Loss: 0.2428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0655

Learning rate: 9.826498227094772e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 842 [0/90000 (0%)]	Loss: 2.9185	Cost: 30.82s
Train Epoch: 842 [20480/90000 (23%)]	Loss: 0.0239	Cost: 12.30s
Train Epoch: 842 [40960/90000 (45%)]	Loss: 0.0033	Cost: 10.45s
Train Epoch: 842 [61440/90000 (68%)]	Loss: -0.2917	Cost: 6.32s
Train Epoch: 842 [81920/90000 (91%)]	Loss: -0.0603	Cost: 7.41s
Train Epoch: 842 	Average Loss: 0.0983
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7983

Learning rate: 9.826087783666908e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 843 [0/90000 (0%)]	Loss: 2.6679	Cost: 30.57s
Train Epoch: 843 [20480/90000 (23%)]	Loss: -0.3003	Cost: 7.39s
Train Epoch: 843 [40960/90000 (45%)]	Loss: -0.1830	Cost: 9.17s
Train Epoch: 843 [61440/90000 (68%)]	Loss: -0.3044	Cost: 8.50s
Train Epoch: 843 [81920/90000 (91%)]	Loss: -0.1363	Cost: 8.92s
Train Epoch: 843 	Average Loss: 0.0024
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7764

Saving model as e843_model.pt & e843_waveforms_supplementary.hdf5
Learning rate: 9.825676863923276e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 844 [0/90000 (0%)]	Loss: 3.0242	Cost: 20.35s
Train Epoch: 844 [20480/90000 (23%)]	Loss: -0.0777	Cost: 9.90s
Train Epoch: 844 [40960/90000 (45%)]	Loss: -0.0485	Cost: 13.30s
Train Epoch: 844 [61440/90000 (68%)]	Loss: -0.3491	Cost: 8.96s
Train Epoch: 844 [81920/90000 (91%)]	Loss: -0.1836	Cost: 8.71s
Train Epoch: 844 	Average Loss: -0.0080
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8111

Learning rate: 9.825265467904433e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 845 [0/90000 (0%)]	Loss: 2.9378	Cost: 21.86s
Train Epoch: 845 [20480/90000 (23%)]	Loss: -0.3451	Cost: 9.08s
Train Epoch: 845 [40960/90000 (45%)]	Loss: -0.3058	Cost: 6.49s
Train Epoch: 845 [61440/90000 (68%)]	Loss: -0.3109	Cost: 7.48s
Train Epoch: 845 [81920/90000 (91%)]	Loss: -0.0129	Cost: 6.91s
Train Epoch: 845 	Average Loss: -0.0577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7053

Saving model as e845_model.pt & e845_waveforms_supplementary.hdf5
Learning rate: 9.824853595650979e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 846 [0/90000 (0%)]	Loss: 2.6580	Cost: 19.40s
Train Epoch: 846 [20480/90000 (23%)]	Loss: -0.2970	Cost: 8.46s
Train Epoch: 846 [40960/90000 (45%)]	Loss: -0.3017	Cost: 13.69s
Train Epoch: 846 [61440/90000 (68%)]	Loss: -0.3580	Cost: 12.37s
Train Epoch: 846 [81920/90000 (91%)]	Loss: -0.1938	Cost: 12.28s
Train Epoch: 846 	Average Loss: -0.0543
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7949

Learning rate: 9.824441247203567e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 847 [0/90000 (0%)]	Loss: 2.7371	Cost: 24.32s
Train Epoch: 847 [20480/90000 (23%)]	Loss: -0.3014	Cost: 12.99s
Train Epoch: 847 [40960/90000 (45%)]	Loss: -0.2788	Cost: 13.30s
Train Epoch: 847 [61440/90000 (68%)]	Loss: -0.3841	Cost: 12.46s
Train Epoch: 847 [81920/90000 (91%)]	Loss: -0.2326	Cost: 12.24s
Train Epoch: 847 	Average Loss: -0.1084
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7248

Learning rate: 9.824028422602895e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 848 [0/90000 (0%)]	Loss: 2.8186	Cost: 40.63s
Train Epoch: 848 [20480/90000 (23%)]	Loss: -0.2672	Cost: 12.20s
Train Epoch: 848 [40960/90000 (45%)]	Loss: -0.1621	Cost: 12.06s
Train Epoch: 848 [61440/90000 (68%)]	Loss: -0.0519	Cost: 11.95s
Train Epoch: 848 [81920/90000 (91%)]	Loss: -0.1925	Cost: 6.16s
Train Epoch: 848 	Average Loss: 0.0631
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8353

Learning rate: 9.823615121889704e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 849 [0/90000 (0%)]	Loss: 3.0162	Cost: 34.25s
Train Epoch: 849 [20480/90000 (23%)]	Loss: -0.1437	Cost: 12.98s
Train Epoch: 849 [40960/90000 (45%)]	Loss: -0.1776	Cost: 12.46s
Train Epoch: 849 [61440/90000 (68%)]	Loss: -0.3093	Cost: 6.77s
Train Epoch: 849 [81920/90000 (91%)]	Loss: -0.1488	Cost: 6.08s
Train Epoch: 849 	Average Loss: -0.0253
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8457

Learning rate: 9.823201345104787e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 850 [0/90000 (0%)]	Loss: 2.6658	Cost: 30.02s
Train Epoch: 850 [20480/90000 (23%)]	Loss: -0.1607	Cost: 11.75s
Train Epoch: 850 [40960/90000 (45%)]	Loss: -0.3118	Cost: 6.39s
Train Epoch: 850 [61440/90000 (68%)]	Loss: -0.4470	Cost: 6.57s
Train Epoch: 850 [81920/90000 (91%)]	Loss: -0.3015	Cost: 8.18s
Train Epoch: 850 	Average Loss: -0.1333
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7578

Learning rate: 9.82278709228898e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 851 [0/90000 (0%)]	Loss: 2.7056	Cost: 20.25s
Train Epoch: 851 [20480/90000 (23%)]	Loss: -0.3749	Cost: 7.54s
Train Epoch: 851 [40960/90000 (45%)]	Loss: -0.5251	Cost: 8.92s
Train Epoch: 851 [61440/90000 (68%)]	Loss: -0.4973	Cost: 8.60s
Train Epoch: 851 [81920/90000 (91%)]	Loss: -0.2856	Cost: 8.87s
Train Epoch: 851 	Average Loss: -0.1653
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7083

Learning rate: 9.82237236348317e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 852 [0/90000 (0%)]	Loss: 2.6368	Cost: 18.96s
Train Epoch: 852 [20480/90000 (23%)]	Loss: -0.3493	Cost: 9.23s
Train Epoch: 852 [40960/90000 (45%)]	Loss: -0.4738	Cost: 7.08s
Train Epoch: 852 [61440/90000 (68%)]	Loss: -0.5744	Cost: 9.30s
Train Epoch: 852 [81920/90000 (91%)]	Loss: -0.2863	Cost: 11.23s
Train Epoch: 852 	Average Loss: -0.1676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6978

Saving model as e852_model.pt & e852_waveforms_supplementary.hdf5
Learning rate: 9.821957158728289e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 853 [0/90000 (0%)]	Loss: 2.4896	Cost: 27.90s
Train Epoch: 853 [20480/90000 (23%)]	Loss: -0.2740	Cost: 12.03s
Train Epoch: 853 [40960/90000 (45%)]	Loss: -0.1856	Cost: 14.42s
Train Epoch: 853 [61440/90000 (68%)]	Loss: -0.4420	Cost: 12.48s
Train Epoch: 853 [81920/90000 (91%)]	Loss: -0.1709	Cost: 11.83s
Train Epoch: 853 	Average Loss: -0.0994
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8248

Learning rate: 9.821541478065316e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 854 [0/90000 (0%)]	Loss: 2.6006	Cost: 41.57s
Train Epoch: 854 [20480/90000 (23%)]	Loss: -0.2327	Cost: 12.54s
Train Epoch: 854 [40960/90000 (45%)]	Loss: -0.5497	Cost: 12.59s
Train Epoch: 854 [61440/90000 (68%)]	Loss: -0.4633	Cost: 12.05s
Train Epoch: 854 [81920/90000 (91%)]	Loss: -0.1788	Cost: 6.47s
Train Epoch: 854 	Average Loss: -0.1385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7603

Learning rate: 9.821125321535279e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 855 [0/90000 (0%)]	Loss: 2.6066	Cost: 22.69s
Train Epoch: 855 [20480/90000 (23%)]	Loss: -0.4657	Cost: 10.09s
Train Epoch: 855 [40960/90000 (45%)]	Loss: -0.3558	Cost: 11.26s
Train Epoch: 855 [61440/90000 (68%)]	Loss: -0.6102	Cost: 6.22s
Train Epoch: 855 [81920/90000 (91%)]	Loss: -0.2136	Cost: 6.30s
Train Epoch: 855 	Average Loss: -0.1575
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7007

Learning rate: 9.820708689179247e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 856 [0/90000 (0%)]	Loss: 2.8229	Cost: 22.42s
Train Epoch: 856 [20480/90000 (23%)]	Loss: -0.3760	Cost: 7.18s
Train Epoch: 856 [40960/90000 (45%)]	Loss: -0.3104	Cost: 8.68s
Train Epoch: 856 [61440/90000 (68%)]	Loss: -0.5103	Cost: 9.15s
Train Epoch: 856 [81920/90000 (91%)]	Loss: -0.4590	Cost: 9.24s
Train Epoch: 856 	Average Loss: -0.2188
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6369

Saving model as e856_model.pt & e856_waveforms_supplementary.hdf5
Learning rate: 9.820291581038343e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 857 [0/90000 (0%)]	Loss: 2.4950	Cost: 21.97s
Train Epoch: 857 [20480/90000 (23%)]	Loss: -0.3540	Cost: 8.14s
Train Epoch: 857 [40960/90000 (45%)]	Loss: -0.3266	Cost: 8.98s
Train Epoch: 857 [61440/90000 (68%)]	Loss: -0.3943	Cost: 8.09s
Train Epoch: 857 [81920/90000 (91%)]	Loss: -0.2269	Cost: 13.17s
Train Epoch: 857 	Average Loss: -0.1760
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7067

Learning rate: 9.819873997153732e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 858 [0/90000 (0%)]	Loss: 2.5035	Cost: 25.77s
Train Epoch: 858 [20480/90000 (23%)]	Loss: -0.4067	Cost: 7.12s
Train Epoch: 858 [40960/90000 (45%)]	Loss: -0.2347	Cost: 12.76s
Train Epoch: 858 [61440/90000 (68%)]	Loss: -0.4754	Cost: 12.56s
Train Epoch: 858 [81920/90000 (91%)]	Loss: -0.1937	Cost: 12.19s
Train Epoch: 858 	Average Loss: -0.0769
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7393

Learning rate: 9.81945593756663e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 859 [0/90000 (0%)]	Loss: 2.8686	Cost: 26.04s
Train Epoch: 859 [20480/90000 (23%)]	Loss: -0.0077	Cost: 12.96s
Train Epoch: 859 [40960/90000 (45%)]	Loss: -0.2278	Cost: 12.56s
Train Epoch: 859 [61440/90000 (68%)]	Loss: -0.4346	Cost: 12.32s
Train Epoch: 859 [81920/90000 (91%)]	Loss: -0.1558	Cost: 12.35s
Train Epoch: 859 	Average Loss: -0.0145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7214

Learning rate: 9.819037402318296e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 860 [0/90000 (0%)]	Loss: 2.8218	Cost: 39.71s
Train Epoch: 860 [20480/90000 (23%)]	Loss: -0.2664	Cost: 13.78s
Train Epoch: 860 [40960/90000 (45%)]	Loss: -0.6484	Cost: 12.23s
Train Epoch: 860 [61440/90000 (68%)]	Loss: -0.5754	Cost: 10.01s
Train Epoch: 860 [81920/90000 (91%)]	Loss: -0.3006	Cost: 6.16s
Train Epoch: 860 	Average Loss: -0.2381
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7009

Learning rate: 9.818618391450038e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 861 [0/90000 (0%)]	Loss: 3.1776	Cost: 24.72s
Train Epoch: 861 [20480/90000 (23%)]	Loss: -0.3018	Cost: 13.08s
Train Epoch: 861 [40960/90000 (45%)]	Loss: -0.4844	Cost: 11.88s
Train Epoch: 861 [61440/90000 (68%)]	Loss: -0.6263	Cost: 6.29s
Train Epoch: 861 [81920/90000 (91%)]	Loss: -0.4966	Cost: 6.39s
Train Epoch: 861 	Average Loss: -0.2527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5517

Saving model as e861_model.pt & e861_waveforms_supplementary.hdf5
Learning rate: 9.81819890500321e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 862 [0/90000 (0%)]	Loss: 2.6124	Cost: 31.28s
Train Epoch: 862 [20480/90000 (23%)]	Loss: -0.4516	Cost: 6.52s
Train Epoch: 862 [40960/90000 (45%)]	Loss: -0.5876	Cost: 9.93s
Train Epoch: 862 [61440/90000 (68%)]	Loss: -0.5506	Cost: 8.62s
Train Epoch: 862 [81920/90000 (91%)]	Loss: -0.4825	Cost: 8.81s
Train Epoch: 862 	Average Loss: -0.3300
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5681

Learning rate: 9.817778943019216e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 863 [0/90000 (0%)]	Loss: 2.3661	Cost: 23.12s
Train Epoch: 863 [20480/90000 (23%)]	Loss: -0.5377	Cost: 7.65s
Train Epoch: 863 [40960/90000 (45%)]	Loss: -0.5206	Cost: 8.36s
Train Epoch: 863 [61440/90000 (68%)]	Loss: -0.5669	Cost: 8.88s
Train Epoch: 863 [81920/90000 (91%)]	Loss: -0.2945	Cost: 11.77s
Train Epoch: 863 	Average Loss: -0.3475
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5661

Learning rate: 9.817358505539504e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 864 [0/90000 (0%)]	Loss: 2.7626	Cost: 19.97s
Train Epoch: 864 [20480/90000 (23%)]	Loss: -0.3817	Cost: 9.39s
Train Epoch: 864 [40960/90000 (45%)]	Loss: -0.4266	Cost: 13.61s
Train Epoch: 864 [61440/90000 (68%)]	Loss: -0.6609	Cost: 13.49s
Train Epoch: 864 [81920/90000 (91%)]	Loss: -0.4711	Cost: 12.19s
Train Epoch: 864 	Average Loss: -0.2911
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7261

Learning rate: 9.816937592605568e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 865 [0/90000 (0%)]	Loss: 2.5193	Cost: 29.85s
Train Epoch: 865 [20480/90000 (23%)]	Loss: -0.4470	Cost: 8.46s
Train Epoch: 865 [40960/90000 (45%)]	Loss: -0.5069	Cost: 13.78s
Train Epoch: 865 [61440/90000 (68%)]	Loss: -0.6389	Cost: 12.50s
Train Epoch: 865 [81920/90000 (91%)]	Loss: -0.4427	Cost: 12.16s
Train Epoch: 865 	Average Loss: -0.3650
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5236

Saving model as e865_model.pt & e865_waveforms_supplementary.hdf5
Learning rate: 9.816516204258952e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 866 [0/90000 (0%)]	Loss: 2.5576	Cost: 27.47s
Train Epoch: 866 [20480/90000 (23%)]	Loss: -0.6093	Cost: 13.14s
Train Epoch: 866 [40960/90000 (45%)]	Loss: -0.3498	Cost: 12.49s
Train Epoch: 866 [61440/90000 (68%)]	Loss: -0.6470	Cost: 12.42s
Train Epoch: 866 [81920/90000 (91%)]	Loss: -0.4715	Cost: 10.91s
Train Epoch: 866 	Average Loss: -0.3174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5861

Learning rate: 9.816094340541243e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 867 [0/90000 (0%)]	Loss: 2.3488	Cost: 36.21s
Train Epoch: 867 [20480/90000 (23%)]	Loss: -0.5515	Cost: 14.03s
Train Epoch: 867 [40960/90000 (45%)]	Loss: -0.6220	Cost: 12.85s
Train Epoch: 867 [61440/90000 (68%)]	Loss: -0.7429	Cost: 6.64s
Train Epoch: 867 [81920/90000 (91%)]	Loss: -0.5563	Cost: 6.15s
Train Epoch: 867 	Average Loss: -0.3882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5054

Saving model as e867_model.pt & e867_waveforms_supplementary.hdf5
Learning rate: 9.815672001494079e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 868 [0/90000 (0%)]	Loss: 2.4047	Cost: 22.87s
Train Epoch: 868 [20480/90000 (23%)]	Loss: -0.5792	Cost: 12.74s
Train Epoch: 868 [40960/90000 (45%)]	Loss: -0.4835	Cost: 10.73s
Train Epoch: 868 [61440/90000 (68%)]	Loss: -0.6725	Cost: 7.82s
Train Epoch: 868 [81920/90000 (91%)]	Loss: -0.0125	Cost: 8.79s
Train Epoch: 868 	Average Loss: -0.2245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8294

Learning rate: 9.815249187159144e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 869 [0/90000 (0%)]	Loss: 3.2232	Cost: 21.53s
Train Epoch: 869 [20480/90000 (23%)]	Loss: -0.2608	Cost: 7.73s
Train Epoch: 869 [40960/90000 (45%)]	Loss: -0.4954	Cost: 8.74s
Train Epoch: 869 [61440/90000 (68%)]	Loss: -0.4697	Cost: 8.75s
Train Epoch: 869 [81920/90000 (91%)]	Loss: -0.3347	Cost: 8.52s
Train Epoch: 869 	Average Loss: -0.2106
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6999

Learning rate: 9.814825897578167e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 870 [0/90000 (0%)]	Loss: 2.8293	Cost: 21.98s
Train Epoch: 870 [20480/90000 (23%)]	Loss: -0.5505	Cost: 9.06s
Train Epoch: 870 [40960/90000 (45%)]	Loss: -0.6614	Cost: 9.04s
Train Epoch: 870 [61440/90000 (68%)]	Loss: -0.8417	Cost: 8.82s
Train Epoch: 870 [81920/90000 (91%)]	Loss: -0.6191	Cost: 8.43s
Train Epoch: 870 	Average Loss: -0.4253
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3772

Saving model as e870_model.pt & e870_waveforms_supplementary.hdf5
Learning rate: 9.814402132792926e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 871 [0/90000 (0%)]	Loss: 2.4355	Cost: 20.79s
Train Epoch: 871 [20480/90000 (23%)]	Loss: -0.6838	Cost: 6.78s
Train Epoch: 871 [40960/90000 (45%)]	Loss: -0.6824	Cost: 10.64s
Train Epoch: 871 [61440/90000 (68%)]	Loss: -0.8895	Cost: 9.55s
Train Epoch: 871 [81920/90000 (91%)]	Loss: -0.4683	Cost: 12.94s
Train Epoch: 871 	Average Loss: -0.5295
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4443

Learning rate: 9.813977892845244e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 872 [0/90000 (0%)]	Loss: 3.0445	Cost: 25.47s
Train Epoch: 872 [20480/90000 (23%)]	Loss: -0.7184	Cost: 10.18s
Train Epoch: 872 [40960/90000 (45%)]	Loss: -0.7188	Cost: 14.17s
Train Epoch: 872 [61440/90000 (68%)]	Loss: -0.7660	Cost: 13.45s
Train Epoch: 872 [81920/90000 (91%)]	Loss: -0.5609	Cost: 12.20s
Train Epoch: 872 	Average Loss: -0.4914
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3520

Saving model as e872_model.pt & e872_waveforms_supplementary.hdf5
Learning rate: 9.813553177776991e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 873 [0/90000 (0%)]	Loss: 2.4540	Cost: 39.37s
Train Epoch: 873 [20480/90000 (23%)]	Loss: -0.7968	Cost: 13.11s
Train Epoch: 873 [40960/90000 (45%)]	Loss: -0.8728	Cost: 12.13s
Train Epoch: 873 [61440/90000 (68%)]	Loss: -0.8237	Cost: 12.29s
Train Epoch: 873 [81920/90000 (91%)]	Loss: -0.4940	Cost: 7.12s
Train Epoch: 873 	Average Loss: -0.4878
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5485

Learning rate: 9.813127987630086e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 874 [0/90000 (0%)]	Loss: 2.1005	Cost: 31.95s
Train Epoch: 874 [20480/90000 (23%)]	Loss: -0.6041	Cost: 12.81s
Train Epoch: 874 [40960/90000 (45%)]	Loss: -0.8445	Cost: 12.31s
Train Epoch: 874 [61440/90000 (68%)]	Loss: -0.7488	Cost: 7.69s
Train Epoch: 874 [81920/90000 (91%)]	Loss: -0.5564	Cost: 6.39s
Train Epoch: 874 	Average Loss: -0.5216
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5310

Learning rate: 9.812702322446492e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 875 [0/90000 (0%)]	Loss: 2.4149	Cost: 26.79s
Train Epoch: 875 [20480/90000 (23%)]	Loss: -0.7345	Cost: 11.79s
Train Epoch: 875 [40960/90000 (45%)]	Loss: -0.5975	Cost: 6.44s
Train Epoch: 875 [61440/90000 (68%)]	Loss: -0.8005	Cost: 6.26s
Train Epoch: 875 [81920/90000 (91%)]	Loss: -0.5235	Cost: 8.63s
Train Epoch: 875 	Average Loss: -0.4261
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4629

Learning rate: 9.812276182268223e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 876 [0/90000 (0%)]	Loss: 2.5319	Cost: 23.54s
Train Epoch: 876 [20480/90000 (23%)]	Loss: -0.7886	Cost: 9.27s
Train Epoch: 876 [40960/90000 (45%)]	Loss: -0.7562	Cost: 9.15s
Train Epoch: 876 [61440/90000 (68%)]	Loss: -1.0170	Cost: 9.08s
Train Epoch: 876 [81920/90000 (91%)]	Loss: -0.7005	Cost: 6.68s
Train Epoch: 876 	Average Loss: -0.5496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3595

Learning rate: 9.811849567137337e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 877 [0/90000 (0%)]	Loss: 2.4323	Cost: 29.11s
Train Epoch: 877 [20480/90000 (23%)]	Loss: -0.6409	Cost: 6.49s
Train Epoch: 877 [40960/90000 (45%)]	Loss: -0.6878	Cost: 8.47s
Train Epoch: 877 [61440/90000 (68%)]	Loss: -0.8757	Cost: 6.93s
Train Epoch: 877 [81920/90000 (91%)]	Loss: -0.4999	Cost: 16.21s
Train Epoch: 877 	Average Loss: -0.5033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4799

Learning rate: 9.811422477095938e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 878 [0/90000 (0%)]	Loss: 2.7835	Cost: 27.78s
Train Epoch: 878 [20480/90000 (23%)]	Loss: -0.7545	Cost: 10.07s
Train Epoch: 878 [40960/90000 (45%)]	Loss: -0.8828	Cost: 15.59s
Train Epoch: 878 [61440/90000 (68%)]	Loss: -0.8740	Cost: 12.28s
Train Epoch: 878 [81920/90000 (91%)]	Loss: -0.7572	Cost: 12.32s
Train Epoch: 878 	Average Loss: -0.5755
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3598

Learning rate: 9.810994912186177e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 879 [0/90000 (0%)]	Loss: 2.8264	Cost: 28.06s
Train Epoch: 879 [20480/90000 (23%)]	Loss: -0.8526	Cost: 14.25s
Train Epoch: 879 [40960/90000 (45%)]	Loss: -0.9199	Cost: 13.39s
Train Epoch: 879 [61440/90000 (68%)]	Loss: -1.0461	Cost: 12.23s
Train Epoch: 879 [81920/90000 (91%)]	Loss: -0.6274	Cost: 8.88s
Train Epoch: 879 	Average Loss: -0.6114
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4044

Learning rate: 9.810566872450255e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 880 [0/90000 (0%)]	Loss: 2.4779	Cost: 25.42s
Train Epoch: 880 [20480/90000 (23%)]	Loss: -0.6338	Cost: 12.75s
Train Epoch: 880 [40960/90000 (45%)]	Loss: -0.8988	Cost: 10.96s
Train Epoch: 880 [61440/90000 (68%)]	Loss: -0.7934	Cost: 6.16s
Train Epoch: 880 [81920/90000 (91%)]	Loss: -0.6437	Cost: 7.96s
Train Epoch: 880 	Average Loss: -0.5526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4289

Learning rate: 9.810138357930416e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 881 [0/90000 (0%)]	Loss: 2.5311	Cost: 20.08s
Train Epoch: 881 [20480/90000 (23%)]	Loss: -0.4738	Cost: 7.51s
Train Epoch: 881 [40960/90000 (45%)]	Loss: -0.7308	Cost: 9.63s
Train Epoch: 881 [61440/90000 (68%)]	Loss: -1.0268	Cost: 8.85s
Train Epoch: 881 [81920/90000 (91%)]	Loss: -0.6315	Cost: 8.78s
Train Epoch: 881 	Average Loss: -0.4993
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4056

Learning rate: 9.809709368668956e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 882 [0/90000 (0%)]	Loss: 2.5643	Cost: 25.90s
Train Epoch: 882 [20480/90000 (23%)]	Loss: -0.7758	Cost: 8.98s
Train Epoch: 882 [40960/90000 (45%)]	Loss: -0.7699	Cost: 8.87s
Train Epoch: 882 [61440/90000 (68%)]	Loss: -0.9256	Cost: 5.92s
Train Epoch: 882 [81920/90000 (91%)]	Loss: -0.6364	Cost: 6.47s
Train Epoch: 882 	Average Loss: -0.5851
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4008

Learning rate: 9.80927990470821e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 883 [0/90000 (0%)]	Loss: 2.4359	Cost: 22.57s
Train Epoch: 883 [20480/90000 (23%)]	Loss: -0.7059	Cost: 7.22s
Train Epoch: 883 [40960/90000 (45%)]	Loss: -0.6542	Cost: 10.03s
Train Epoch: 883 [61440/90000 (68%)]	Loss: -0.6866	Cost: 11.86s
Train Epoch: 883 [81920/90000 (91%)]	Loss: -0.6085	Cost: 12.39s
Train Epoch: 883 	Average Loss: -0.4559
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4789

Learning rate: 9.80884996609057e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 884 [0/90000 (0%)]	Loss: 2.4536	Cost: 22.88s
Train Epoch: 884 [20480/90000 (23%)]	Loss: -0.7585	Cost: 10.00s
Train Epoch: 884 [40960/90000 (45%)]	Loss: -0.7402	Cost: 14.53s
Train Epoch: 884 [61440/90000 (68%)]	Loss: -0.8919	Cost: 12.11s
Train Epoch: 884 [81920/90000 (91%)]	Loss: -0.6038	Cost: 12.58s
Train Epoch: 884 	Average Loss: -0.5296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4341

Learning rate: 9.808419552858463e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 885 [0/90000 (0%)]	Loss: 2.5174	Cost: 27.09s
Train Epoch: 885 [20480/90000 (23%)]	Loss: -0.8238	Cost: 12.58s
Train Epoch: 885 [40960/90000 (45%)]	Loss: -0.8341	Cost: 12.74s
Train Epoch: 885 [61440/90000 (68%)]	Loss: -1.0766	Cost: 12.42s
Train Epoch: 885 [81920/90000 (91%)]	Loss: -0.7595	Cost: 8.23s
Train Epoch: 885 	Average Loss: -0.6760
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2985

Saving model as e885_model.pt & e885_waveforms_supplementary.hdf5
Learning rate: 9.807988665054374e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 886 [0/90000 (0%)]	Loss: 1.8134	Cost: 24.52s
Train Epoch: 886 [20480/90000 (23%)]	Loss: -0.7933	Cost: 11.62s
Train Epoch: 886 [40960/90000 (45%)]	Loss: -0.6965	Cost: 12.08s
Train Epoch: 886 [61440/90000 (68%)]	Loss: -1.1655	Cost: 6.16s
Train Epoch: 886 [81920/90000 (91%)]	Loss: -0.8005	Cost: 6.44s
Train Epoch: 886 	Average Loss: -0.6759
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3635

Learning rate: 9.807557302720827e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 887 [0/90000 (0%)]	Loss: 2.1938	Cost: 25.03s
Train Epoch: 887 [20480/90000 (23%)]	Loss: -0.9401	Cost: 9.30s
Train Epoch: 887 [40960/90000 (45%)]	Loss: -0.9189	Cost: 7.09s
Train Epoch: 887 [61440/90000 (68%)]	Loss: -0.9541	Cost: 8.89s
Train Epoch: 887 [81920/90000 (91%)]	Loss: -0.5404	Cost: 8.41s
Train Epoch: 887 	Average Loss: -0.6217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2995

Learning rate: 9.807125465900396e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 888 [0/90000 (0%)]	Loss: 2.4802	Cost: 23.36s
Train Epoch: 888 [20480/90000 (23%)]	Loss: -0.8598	Cost: 10.67s
Train Epoch: 888 [40960/90000 (45%)]	Loss: -0.8616	Cost: 9.43s
Train Epoch: 888 [61440/90000 (68%)]	Loss: -1.1168	Cost: 8.73s
Train Epoch: 888 [81920/90000 (91%)]	Loss: -0.7306	Cost: 8.69s
Train Epoch: 888 	Average Loss: -0.6735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2493

Saving model as e888_model.pt & e888_waveforms_supplementary.hdf5
Learning rate: 9.806693154635704e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 889 [0/90000 (0%)]	Loss: 2.4867	Cost: 18.70s
Train Epoch: 889 [20480/90000 (23%)]	Loss: -0.8698	Cost: 9.86s
Train Epoch: 889 [40960/90000 (45%)]	Loss: -0.7652	Cost: 7.82s
Train Epoch: 889 [61440/90000 (68%)]	Loss: -1.0701	Cost: 6.43s
Train Epoch: 889 [81920/90000 (91%)]	Loss: -0.6147	Cost: 6.81s
Train Epoch: 889 	Average Loss: -0.6767
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4181

Learning rate: 9.806260368969415e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 890 [0/90000 (0%)]	Loss: 1.9662	Cost: 22.81s
Train Epoch: 890 [20480/90000 (23%)]	Loss: -0.8132	Cost: 7.71s
Train Epoch: 890 [40960/90000 (45%)]	Loss: -0.9498	Cost: 11.74s
Train Epoch: 890 [61440/90000 (68%)]	Loss: -0.7971	Cost: 12.38s
Train Epoch: 890 [81920/90000 (91%)]	Loss: -0.6991	Cost: 12.52s
Train Epoch: 890 	Average Loss: -0.5717
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4035

Learning rate: 9.805827108944247e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 891 [0/90000 (0%)]	Loss: 2.1098	Cost: 23.74s
Train Epoch: 891 [20480/90000 (23%)]	Loss: -0.9255	Cost: 15.66s
Train Epoch: 891 [40960/90000 (45%)]	Loss: -0.9539	Cost: 13.83s
Train Epoch: 891 [61440/90000 (68%)]	Loss: -1.1109	Cost: 12.24s
Train Epoch: 891 [81920/90000 (91%)]	Loss: -0.8667	Cost: 11.34s
Train Epoch: 891 	Average Loss: -0.6719
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4525

Learning rate: 9.805393374602958e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 892 [0/90000 (0%)]	Loss: 2.2174	Cost: 35.21s
Train Epoch: 892 [20480/90000 (23%)]	Loss: -0.9250	Cost: 11.12s
Train Epoch: 892 [40960/90000 (45%)]	Loss: -0.8857	Cost: 12.38s
Train Epoch: 892 [61440/90000 (68%)]	Loss: -1.1417	Cost: 12.24s
Train Epoch: 892 [81920/90000 (91%)]	Loss: -0.8668	Cost: 7.04s
Train Epoch: 892 	Average Loss: -0.7693
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2680

Learning rate: 9.804959165988357e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 893 [0/90000 (0%)]	Loss: 2.1995	Cost: 40.95s
Train Epoch: 893 [20480/90000 (23%)]	Loss: -1.0113	Cost: 12.27s
Train Epoch: 893 [40960/90000 (45%)]	Loss: -1.0640	Cost: 12.05s
Train Epoch: 893 [61440/90000 (68%)]	Loss: -1.1506	Cost: 6.21s
Train Epoch: 893 [81920/90000 (91%)]	Loss: -0.8619	Cost: 6.72s
Train Epoch: 893 	Average Loss: -0.7715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3311

Learning rate: 9.804524483143299e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 894 [0/90000 (0%)]	Loss: 2.4347	Cost: 20.96s
Train Epoch: 894 [20480/90000 (23%)]	Loss: -1.0046	Cost: 6.96s
Train Epoch: 894 [40960/90000 (45%)]	Loss: -0.9998	Cost: 10.53s
Train Epoch: 894 [61440/90000 (68%)]	Loss: -0.9955	Cost: 8.93s
Train Epoch: 894 [81920/90000 (91%)]	Loss: -0.8531	Cost: 9.46s
Train Epoch: 894 	Average Loss: -0.7352
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2312

Saving model as e894_model.pt & e894_waveforms_supplementary.hdf5
Learning rate: 9.804089326110685e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 895 [0/90000 (0%)]	Loss: 2.5938	Cost: 19.86s
Train Epoch: 895 [20480/90000 (23%)]	Loss: -1.1057	Cost: 9.54s
Train Epoch: 895 [40960/90000 (45%)]	Loss: -0.9139	Cost: 10.63s
Train Epoch: 895 [61440/90000 (68%)]	Loss: -0.9586	Cost: 7.74s
Train Epoch: 895 [81920/90000 (91%)]	Loss: -0.8697	Cost: 9.45s
Train Epoch: 895 	Average Loss: -0.7113
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2524

Learning rate: 9.803653694933463e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 896 [0/90000 (0%)]	Loss: 2.5678	Cost: 21.01s
Train Epoch: 896 [20480/90000 (23%)]	Loss: -0.8969	Cost: 11.04s
Train Epoch: 896 [40960/90000 (45%)]	Loss: -1.0964	Cost: 11.49s
Train Epoch: 896 [61440/90000 (68%)]	Loss: -1.2420	Cost: 12.22s
Train Epoch: 896 [81920/90000 (91%)]	Loss: -1.0328	Cost: 12.36s
Train Epoch: 896 	Average Loss: -0.7901
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1624

Saving model as e896_model.pt & e896_waveforms_supplementary.hdf5
Learning rate: 9.803217589654627e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 897 [0/90000 (0%)]	Loss: 2.4241	Cost: 27.43s
Train Epoch: 897 [20480/90000 (23%)]	Loss: -0.6150	Cost: 12.86s
Train Epoch: 897 [40960/90000 (45%)]	Loss: -0.7722	Cost: 12.89s
Train Epoch: 897 [61440/90000 (68%)]	Loss: -0.8863	Cost: 12.26s
Train Epoch: 897 [81920/90000 (91%)]	Loss: -0.7289	Cost: 11.85s
Train Epoch: 897 	Average Loss: -0.5146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5213

Learning rate: 9.802781010317222e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 898 [0/90000 (0%)]	Loss: 2.7013	Cost: 26.14s
Train Epoch: 898 [20480/90000 (23%)]	Loss: -0.7523	Cost: 11.24s
Train Epoch: 898 [40960/90000 (45%)]	Loss: -0.9368	Cost: 13.00s
Train Epoch: 898 [61440/90000 (68%)]	Loss: -1.0473	Cost: 12.30s
Train Epoch: 898 [81920/90000 (91%)]	Loss: -0.8924	Cost: 6.59s
Train Epoch: 898 	Average Loss: -0.6288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3428

Learning rate: 9.802343956964335e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 899 [0/90000 (0%)]	Loss: 2.1049	Cost: 40.23s
Train Epoch: 899 [20480/90000 (23%)]	Loss: -1.1759	Cost: 12.98s
Train Epoch: 899 [40960/90000 (45%)]	Loss: -1.0166	Cost: 8.62s
Train Epoch: 899 [61440/90000 (68%)]	Loss: -1.1680	Cost: 6.38s
Train Epoch: 899 [81920/90000 (91%)]	Loss: -0.9425	Cost: 8.34s
Train Epoch: 899 	Average Loss: -0.8531
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2453

Learning rate: 9.8019064296391e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 900 [0/90000 (0%)]	Loss: 1.8215	Cost: 23.29s
Train Epoch: 900 [20480/90000 (23%)]	Loss: -0.9792	Cost: 12.10s
Train Epoch: 900 [40960/90000 (45%)]	Loss: -1.0080	Cost: 9.91s
Train Epoch: 900 [61440/90000 (68%)]	Loss: -1.0912	Cost: 7.55s
Train Epoch: 900 [81920/90000 (91%)]	Loss: -0.7959	Cost: 8.57s
Train Epoch: 900 	Average Loss: -0.7393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7125

Learning rate: 9.801468428384702e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 901 [0/90000 (0%)]	Loss: 2.3537	Cost: 22.31s
Train Epoch: 901 [20480/90000 (23%)]	Loss: -0.6058	Cost: 7.46s
Train Epoch: 901 [40960/90000 (45%)]	Loss: -0.8279	Cost: 9.25s
Train Epoch: 901 [61440/90000 (68%)]	Loss: -1.0150	Cost: 8.58s
Train Epoch: 901 [81920/90000 (91%)]	Loss: -0.8361	Cost: 8.67s
Train Epoch: 901 	Average Loss: -0.5577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3280

Learning rate: 9.80102995324437e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 902 [0/90000 (0%)]	Loss: 2.1861	Cost: 20.98s
Train Epoch: 902 [20480/90000 (23%)]	Loss: -0.9157	Cost: 9.28s
Train Epoch: 902 [40960/90000 (45%)]	Loss: -0.8095	Cost: 9.19s
Train Epoch: 902 [61440/90000 (68%)]	Loss: -0.9566	Cost: 8.60s
Train Epoch: 902 [81920/90000 (91%)]	Loss: -0.9985	Cost: 7.69s
Train Epoch: 902 	Average Loss: -0.6554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2823

Learning rate: 9.800591004261374e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 903 [0/90000 (0%)]	Loss: 2.3607	Cost: 19.53s
Train Epoch: 903 [20480/90000 (23%)]	Loss: -1.0054	Cost: 7.04s
Train Epoch: 903 [40960/90000 (45%)]	Loss: -1.0328	Cost: 10.70s
Train Epoch: 903 [61440/90000 (68%)]	Loss: -1.0912	Cost: 11.57s
Train Epoch: 903 [81920/90000 (91%)]	Loss: -0.9664	Cost: 13.09s
Train Epoch: 903 	Average Loss: -0.7554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3260

Learning rate: 9.800151581479044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 904 [0/90000 (0%)]	Loss: 2.1058	Cost: 25.63s
Train Epoch: 904 [20480/90000 (23%)]	Loss: -0.9860	Cost: 10.07s
Train Epoch: 904 [40960/90000 (45%)]	Loss: -1.0987	Cost: 12.42s
Train Epoch: 904 [61440/90000 (68%)]	Loss: -1.2604	Cost: 13.63s
Train Epoch: 904 [81920/90000 (91%)]	Loss: -1.0445	Cost: 12.38s
Train Epoch: 904 	Average Loss: -0.8753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0826

Saving model as e904_model.pt & e904_waveforms_supplementary.hdf5
Learning rate: 9.799711684940746e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 905 [0/90000 (0%)]	Loss: 2.2103	Cost: 39.25s
Train Epoch: 905 [20480/90000 (23%)]	Loss: -1.1350	Cost: 14.09s
Train Epoch: 905 [40960/90000 (45%)]	Loss: -1.1724	Cost: 12.58s
Train Epoch: 905 [61440/90000 (68%)]	Loss: -1.1977	Cost: 12.29s
Train Epoch: 905 [81920/90000 (91%)]	Loss: -1.0884	Cost: 7.65s
Train Epoch: 905 	Average Loss: -0.9031
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2041

Learning rate: 9.799271314689895e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 906 [0/90000 (0%)]	Loss: 2.0671	Cost: 27.51s
Train Epoch: 906 [20480/90000 (23%)]	Loss: -1.1569	Cost: 12.68s
Train Epoch: 906 [40960/90000 (45%)]	Loss: -1.0161	Cost: 12.70s
Train Epoch: 906 [61440/90000 (68%)]	Loss: -1.2772	Cost: 8.44s
Train Epoch: 906 [81920/90000 (91%)]	Loss: -0.9679	Cost: 6.17s
Train Epoch: 906 	Average Loss: -0.8626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1282

Learning rate: 9.798830470769955e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 907 [0/90000 (0%)]	Loss: 2.3097	Cost: 22.89s
Train Epoch: 907 [20480/90000 (23%)]	Loss: -1.1826	Cost: 11.88s
Train Epoch: 907 [40960/90000 (45%)]	Loss: -1.1698	Cost: 6.73s
Train Epoch: 907 [61440/90000 (68%)]	Loss: -1.2209	Cost: 6.20s
Train Epoch: 907 [81920/90000 (91%)]	Loss: -1.0260	Cost: 9.00s
Train Epoch: 907 	Average Loss: -0.9817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1671

Learning rate: 9.798389153224436e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 908 [0/90000 (0%)]	Loss: 2.0160	Cost: 21.51s
Train Epoch: 908 [20480/90000 (23%)]	Loss: -1.0043	Cost: 7.28s
Train Epoch: 908 [40960/90000 (45%)]	Loss: -1.1796	Cost: 9.19s
Train Epoch: 908 [61440/90000 (68%)]	Loss: -1.3976	Cost: 9.42s
Train Epoch: 908 [81920/90000 (91%)]	Loss: -1.1585	Cost: 8.92s
Train Epoch: 908 	Average Loss: -0.9673
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0087

Saving model as e908_model.pt & e908_waveforms_supplementary.hdf5
Learning rate: 9.797947362096895e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 909 [0/90000 (0%)]	Loss: 2.2989	Cost: 31.86s
Train Epoch: 909 [20480/90000 (23%)]	Loss: -1.1209	Cost: 6.68s
Train Epoch: 909 [40960/90000 (45%)]	Loss: -1.1633	Cost: 8.20s
Train Epoch: 909 [61440/90000 (68%)]	Loss: -1.2170	Cost: 6.68s
Train Epoch: 909 [81920/90000 (91%)]	Loss: -1.0399	Cost: 14.83s
Train Epoch: 909 	Average Loss: -0.9130
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1716

Learning rate: 9.797505097430932e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 910 [0/90000 (0%)]	Loss: 2.0758	Cost: 38.15s
Train Epoch: 910 [20480/90000 (23%)]	Loss: -0.9677	Cost: 12.84s
Train Epoch: 910 [40960/90000 (45%)]	Loss: -1.0789	Cost: 12.89s
Train Epoch: 910 [61440/90000 (68%)]	Loss: -1.2209	Cost: 12.29s
Train Epoch: 910 [81920/90000 (91%)]	Loss: -1.2044	Cost: 12.07s
Train Epoch: 910 	Average Loss: -0.9216
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9952

Saving model as e910_model.pt & e910_waveforms_supplementary.hdf5
Learning rate: 9.797062359270201e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 911 [0/90000 (0%)]	Loss: 2.1377	Cost: 27.45s
Train Epoch: 911 [20480/90000 (23%)]	Loss: -1.2732	Cost: 13.99s
Train Epoch: 911 [40960/90000 (45%)]	Loss: -1.2087	Cost: 12.50s
Train Epoch: 911 [61440/90000 (68%)]	Loss: -1.0367	Cost: 8.77s
Train Epoch: 911 [81920/90000 (91%)]	Loss: -1.0311	Cost: 6.74s
Train Epoch: 911 	Average Loss: -0.9560
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1153

Learning rate: 9.796619147658394e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 912 [0/90000 (0%)]	Loss: 2.6885	Cost: 24.42s
Train Epoch: 912 [20480/90000 (23%)]	Loss: -1.2017	Cost: 11.22s
Train Epoch: 912 [40960/90000 (45%)]	Loss: -1.2376	Cost: 6.80s
Train Epoch: 912 [61440/90000 (68%)]	Loss: -1.4422	Cost: 6.68s
Train Epoch: 912 [81920/90000 (91%)]	Loss: -1.2996	Cost: 9.02s
Train Epoch: 912 	Average Loss: -1.0059
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0391

Learning rate: 9.796175462639258e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 913 [0/90000 (0%)]	Loss: 2.2339	Cost: 21.16s
Train Epoch: 913 [20480/90000 (23%)]	Loss: -1.3824	Cost: 9.26s
Train Epoch: 913 [40960/90000 (45%)]	Loss: -0.9464	Cost: 9.08s
Train Epoch: 913 [61440/90000 (68%)]	Loss: -1.2083	Cost: 8.74s
Train Epoch: 913 [81920/90000 (91%)]	Loss: -1.0141	Cost: 8.57s
Train Epoch: 913 	Average Loss: -0.9836
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1141

Learning rate: 9.79573130425658e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 914 [0/90000 (0%)]	Loss: 2.3904	Cost: 28.39s
Train Epoch: 914 [20480/90000 (23%)]	Loss: -1.2267	Cost: 8.68s
Train Epoch: 914 [40960/90000 (45%)]	Loss: -1.5148	Cost: 8.04s
Train Epoch: 914 [61440/90000 (68%)]	Loss: -1.4606	Cost: 6.18s
Train Epoch: 914 [81920/90000 (91%)]	Loss: -1.2263	Cost: 7.01s
Train Epoch: 914 	Average Loss: -1.0446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0274

Learning rate: 9.795286672554198e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 915 [0/90000 (0%)]	Loss: 2.1874	Cost: 22.12s
Train Epoch: 915 [20480/90000 (23%)]	Loss: -1.2716	Cost: 9.70s
Train Epoch: 915 [40960/90000 (45%)]	Loss: -1.2704	Cost: 9.65s
Train Epoch: 915 [61440/90000 (68%)]	Loss: -1.2668	Cost: 12.11s
Train Epoch: 915 [81920/90000 (91%)]	Loss: -1.1796	Cost: 12.40s
Train Epoch: 915 	Average Loss: -0.9770
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0859

Learning rate: 9.794841567575996e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 916 [0/90000 (0%)]	Loss: 2.3368	Cost: 24.02s
Train Epoch: 916 [20480/90000 (23%)]	Loss: -0.9118	Cost: 13.79s
Train Epoch: 916 [40960/90000 (45%)]	Loss: -1.0622	Cost: 13.53s
Train Epoch: 916 [61440/90000 (68%)]	Loss: -1.1931	Cost: 12.57s
Train Epoch: 916 [81920/90000 (91%)]	Loss: -0.9814	Cost: 12.55s
Train Epoch: 916 	Average Loss: -0.9288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1127

Learning rate: 9.794395989365903e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 917 [0/90000 (0%)]	Loss: 1.9321	Cost: 23.31s
Train Epoch: 917 [20480/90000 (23%)]	Loss: -1.2818	Cost: 11.35s
Train Epoch: 917 [40960/90000 (45%)]	Loss: -0.9459	Cost: 13.56s
Train Epoch: 917 [61440/90000 (68%)]	Loss: -1.1172	Cost: 12.61s
Train Epoch: 917 [81920/90000 (91%)]	Loss: -1.0286	Cost: 7.55s
Train Epoch: 917 	Average Loss: -0.8748
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1616

Learning rate: 9.793949937967896e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 918 [0/90000 (0%)]	Loss: 2.4077	Cost: 25.66s
Train Epoch: 918 [20480/90000 (23%)]	Loss: -1.1806	Cost: 12.55s
Train Epoch: 918 [40960/90000 (45%)]	Loss: -1.2306	Cost: 11.36s
Train Epoch: 918 [61440/90000 (68%)]	Loss: -1.2596	Cost: 6.19s
Train Epoch: 918 [81920/90000 (91%)]	Loss: -0.9749	Cost: 6.73s
Train Epoch: 918 	Average Loss: -0.9362
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2047

Learning rate: 9.793503413425998e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 919 [0/90000 (0%)]	Loss: 2.2585	Cost: 34.57s
Train Epoch: 919 [20480/90000 (23%)]	Loss: -1.2918	Cost: 6.52s
Train Epoch: 919 [40960/90000 (45%)]	Loss: -1.2374	Cost: 9.62s
Train Epoch: 919 [61440/90000 (68%)]	Loss: -1.3477	Cost: 8.62s
Train Epoch: 919 [81920/90000 (91%)]	Loss: -1.0780	Cost: 8.65s
Train Epoch: 919 	Average Loss: -1.0463
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0801

Learning rate: 9.793056415784282e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 920 [0/90000 (0%)]	Loss: 1.9847	Cost: 25.88s
Train Epoch: 920 [20480/90000 (23%)]	Loss: -1.3150	Cost: 9.14s
Train Epoch: 920 [40960/90000 (45%)]	Loss: -1.3695	Cost: 9.44s
Train Epoch: 920 [61440/90000 (68%)]	Loss: -1.3197	Cost: 9.02s
Train Epoch: 920 [81920/90000 (91%)]	Loss: -1.1897	Cost: 7.64s
Train Epoch: 920 	Average Loss: -1.0808
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9816

Saving model as e920_model.pt & e920_waveforms_supplementary.hdf5
Learning rate: 9.792608945086863e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 921 [0/90000 (0%)]	Loss: 1.9685	Cost: 22.75s
Train Epoch: 921 [20480/90000 (23%)]	Loss: -1.3150	Cost: 10.11s
Train Epoch: 921 [40960/90000 (45%)]	Loss: -1.4796	Cost: 15.57s
Train Epoch: 921 [61440/90000 (68%)]	Loss: -1.3648	Cost: 13.94s
Train Epoch: 921 [81920/90000 (91%)]	Loss: -1.2642	Cost: 11.96s
Train Epoch: 921 	Average Loss: -1.1596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0572

Learning rate: 9.792161001377905e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 922 [0/90000 (0%)]	Loss: 2.3937	Cost: 22.27s
Train Epoch: 922 [20480/90000 (23%)]	Loss: -1.3980	Cost: 13.52s
Train Epoch: 922 [40960/90000 (45%)]	Loss: -1.3509	Cost: 14.86s
Train Epoch: 922 [61440/90000 (68%)]	Loss: -1.7192	Cost: 12.84s
Train Epoch: 922 [81920/90000 (91%)]	Loss: -1.3269	Cost: 12.42s
Train Epoch: 922 	Average Loss: -1.1526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9033

Saving model as e922_model.pt & e922_waveforms_supplementary.hdf5
Learning rate: 9.791712584701618e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 923 [0/90000 (0%)]	Loss: 2.0341	Cost: 29.15s
Train Epoch: 923 [20480/90000 (23%)]	Loss: -1.5929	Cost: 13.30s
Train Epoch: 923 [40960/90000 (45%)]	Loss: -1.6572	Cost: 12.45s
Train Epoch: 923 [61440/90000 (68%)]	Loss: -1.5864	Cost: 12.21s
Train Epoch: 923 [81920/90000 (91%)]	Loss: -1.3338	Cost: 7.90s
Train Epoch: 923 	Average Loss: -1.2610
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9745

Learning rate: 9.791263695102257e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 924 [0/90000 (0%)]	Loss: 2.3673	Cost: 28.96s
Train Epoch: 924 [20480/90000 (23%)]	Loss: -1.2972	Cost: 12.72s
Train Epoch: 924 [40960/90000 (45%)]	Loss: -1.4914	Cost: 12.24s
Train Epoch: 924 [61440/90000 (68%)]	Loss: -1.5490	Cost: 9.45s
Train Epoch: 924 [81920/90000 (91%)]	Loss: -1.4308	Cost: 6.03s
Train Epoch: 924 	Average Loss: -1.2142
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9674

Learning rate: 9.790814332624128e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 925 [0/90000 (0%)]	Loss: 1.9358	Cost: 26.01s
Train Epoch: 925 [20480/90000 (23%)]	Loss: -1.5279	Cost: 8.85s
Train Epoch: 925 [40960/90000 (45%)]	Loss: -1.6716	Cost: 10.89s
Train Epoch: 925 [61440/90000 (68%)]	Loss: -0.7102	Cost: 6.09s
Train Epoch: 925 [81920/90000 (91%)]	Loss: -0.6576	Cost: 6.88s
Train Epoch: 925 	Average Loss: -0.8656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9016

Learning rate: 9.790364497311582e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 926 [0/90000 (0%)]	Loss: 2.7260	Cost: 24.83s
Train Epoch: 926 [20480/90000 (23%)]	Loss: -0.2755	Cost: 7.59s
Train Epoch: 926 [40960/90000 (45%)]	Loss: -0.5406	Cost: 11.15s
Train Epoch: 926 [61440/90000 (68%)]	Loss: -0.9567	Cost: 9.23s
Train Epoch: 926 [81920/90000 (91%)]	Loss: -0.9327	Cost: 8.92s
Train Epoch: 926 	Average Loss: -0.4290
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1505

Learning rate: 9.789914189209014e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 927 [0/90000 (0%)]	Loss: 2.3117	Cost: 21.48s
Train Epoch: 927 [20480/90000 (23%)]	Loss: -1.0782	Cost: 11.51s
Train Epoch: 927 [40960/90000 (45%)]	Loss: -1.3041	Cost: 9.60s
Train Epoch: 927 [61440/90000 (68%)]	Loss: -1.2735	Cost: 9.57s
Train Epoch: 927 [81920/90000 (91%)]	Loss: -0.9937	Cost: 7.60s
Train Epoch: 927 	Average Loss: -0.9530
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0254

Learning rate: 9.789463408360868e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 928 [0/90000 (0%)]	Loss: 2.0087	Cost: 26.07s
Train Epoch: 928 [20480/90000 (23%)]	Loss: -1.3698	Cost: 10.70s
Train Epoch: 928 [40960/90000 (45%)]	Loss: -1.4854	Cost: 11.23s
Train Epoch: 928 [61440/90000 (68%)]	Loss: -1.5820	Cost: 12.67s
Train Epoch: 928 [81920/90000 (91%)]	Loss: -1.3911	Cost: 12.38s
Train Epoch: 928 	Average Loss: -1.2326
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8423

Saving model as e928_model.pt & e928_waveforms_supplementary.hdf5
Learning rate: 9.789012154811634e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 929 [0/90000 (0%)]	Loss: 1.6694	Cost: 23.10s
Train Epoch: 929 [20480/90000 (23%)]	Loss: -1.4648	Cost: 13.87s
Train Epoch: 929 [40960/90000 (45%)]	Loss: -1.5548	Cost: 12.36s
Train Epoch: 929 [61440/90000 (68%)]	Loss: -1.7038	Cost: 12.07s
Train Epoch: 929 [81920/90000 (91%)]	Loss: -1.3526	Cost: 11.10s
Train Epoch: 929 	Average Loss: -1.2759
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9371

Learning rate: 9.788560428605849e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 930 [0/90000 (0%)]	Loss: 1.9465	Cost: 27.43s
Train Epoch: 930 [20480/90000 (23%)]	Loss: -1.5597	Cost: 12.44s
Train Epoch: 930 [40960/90000 (45%)]	Loss: -1.5143	Cost: 12.61s
Train Epoch: 930 [61440/90000 (68%)]	Loss: -1.6192	Cost: 9.22s
Train Epoch: 930 [81920/90000 (91%)]	Loss: -1.2492	Cost: 6.31s
Train Epoch: 930 	Average Loss: -1.1698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9476

Learning rate: 9.788108229788097e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 931 [0/90000 (0%)]	Loss: 1.9947	Cost: 27.27s
Train Epoch: 931 [20480/90000 (23%)]	Loss: -1.2014	Cost: 11.36s
Train Epoch: 931 [40960/90000 (45%)]	Loss: -1.5645	Cost: 10.72s
Train Epoch: 931 [61440/90000 (68%)]	Loss: -1.5732	Cost: 9.64s
Train Epoch: 931 [81920/90000 (91%)]	Loss: -0.9534	Cost: 6.19s
Train Epoch: 931 	Average Loss: -1.1308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1086

Learning rate: 9.78765555840301e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 932 [0/90000 (0%)]	Loss: 2.3861	Cost: 23.72s
Train Epoch: 932 [20480/90000 (23%)]	Loss: -1.2964	Cost: 9.93s
Train Epoch: 932 [40960/90000 (45%)]	Loss: -1.5408	Cost: 11.49s
Train Epoch: 932 [61440/90000 (68%)]	Loss: -1.4674	Cost: 8.62s
Train Epoch: 932 [81920/90000 (91%)]	Loss: -1.4121	Cost: 7.99s
Train Epoch: 932 	Average Loss: -1.1310
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9223

Learning rate: 9.787202414495261e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 933 [0/90000 (0%)]	Loss: 2.0566	Cost: 21.77s
Train Epoch: 933 [20480/90000 (23%)]	Loss: -1.4744	Cost: 9.60s
Train Epoch: 933 [40960/90000 (45%)]	Loss: -1.4512	Cost: 6.76s
Train Epoch: 933 [61440/90000 (68%)]	Loss: -1.6066	Cost: 7.37s
Train Epoch: 933 [81920/90000 (91%)]	Loss: -1.2912	Cost: 8.87s
Train Epoch: 933 	Average Loss: -1.2024
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8861

Learning rate: 9.786748798109577e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 934 [0/90000 (0%)]	Loss: 1.8367	Cost: 22.89s
Train Epoch: 934 [20480/90000 (23%)]	Loss: -1.1347	Cost: 9.78s
Train Epoch: 934 [40960/90000 (45%)]	Loss: -1.2178	Cost: 10.75s
Train Epoch: 934 [61440/90000 (68%)]	Loss: -1.4358	Cost: 8.91s
Train Epoch: 934 [81920/90000 (91%)]	Loss: -1.2322	Cost: 8.67s
Train Epoch: 934 	Average Loss: -1.0084
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9164

Learning rate: 9.786294709290727e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 935 [0/90000 (0%)]	Loss: 2.5339	Cost: 25.68s
Train Epoch: 935 [20480/90000 (23%)]	Loss: -1.5368	Cost: 9.95s
Train Epoch: 935 [40960/90000 (45%)]	Loss: -1.5498	Cost: 9.86s
Train Epoch: 935 [61440/90000 (68%)]	Loss: -1.7256	Cost: 8.70s
Train Epoch: 935 [81920/90000 (91%)]	Loss: -1.4541	Cost: 8.63s
Train Epoch: 935 	Average Loss: -1.3139
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8410

Saving model as e935_model.pt & e935_waveforms_supplementary.hdf5
Learning rate: 9.785840148083527e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 936 [0/90000 (0%)]	Loss: 2.1230	Cost: 20.05s
Train Epoch: 936 [20480/90000 (23%)]	Loss: -1.3456	Cost: 8.24s
Train Epoch: 936 [40960/90000 (45%)]	Loss: -1.3860	Cost: 7.25s
Train Epoch: 936 [61440/90000 (68%)]	Loss: -1.5687	Cost: 8.64s
Train Epoch: 936 [81920/90000 (91%)]	Loss: -1.3870	Cost: 8.97s
Train Epoch: 936 	Average Loss: -1.2232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8560

Learning rate: 9.785385114532841e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 937 [0/90000 (0%)]	Loss: 1.9832	Cost: 21.27s
Train Epoch: 937 [20480/90000 (23%)]	Loss: -1.5101	Cost: 8.17s
Train Epoch: 937 [40960/90000 (45%)]	Loss: -1.4317	Cost: 12.10s
Train Epoch: 937 [61440/90000 (68%)]	Loss: -1.4653	Cost: 12.38s
Train Epoch: 937 [81920/90000 (91%)]	Loss: -1.3444	Cost: 12.58s
Train Epoch: 937 	Average Loss: -1.2014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8788

Learning rate: 9.78492960868358e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 938 [0/90000 (0%)]	Loss: 1.9113	Cost: 23.73s
Train Epoch: 938 [20480/90000 (23%)]	Loss: -1.6097	Cost: 15.56s
Train Epoch: 938 [40960/90000 (45%)]	Loss: -1.4073	Cost: 14.08s
Train Epoch: 938 [61440/90000 (68%)]	Loss: -1.6522	Cost: 12.25s
Train Epoch: 938 [81920/90000 (91%)]	Loss: -1.6344	Cost: 10.61s
Train Epoch: 938 	Average Loss: -1.3391
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7616

Saving model as e938_model.pt & e938_waveforms_supplementary.hdf5
Learning rate: 9.784473630580698e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 939 [0/90000 (0%)]	Loss: 1.6001	Cost: 42.33s
Train Epoch: 939 [20480/90000 (23%)]	Loss: -1.6013	Cost: 12.33s
Train Epoch: 939 [40960/90000 (45%)]	Loss: -1.6586	Cost: 7.32s
Train Epoch: 939 [61440/90000 (68%)]	Loss: -1.7424	Cost: 6.31s
Train Epoch: 939 [81920/90000 (91%)]	Loss: -1.6038	Cost: 7.93s
Train Epoch: 939 	Average Loss: -1.4503
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7391

Saving model as e939_model.pt & e939_waveforms_supplementary.hdf5
Learning rate: 9.784017180269201e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 940 [0/90000 (0%)]	Loss: 1.7167	Cost: 30.00s
Train Epoch: 940 [20480/90000 (23%)]	Loss: -1.3938	Cost: 6.50s
Train Epoch: 940 [40960/90000 (45%)]	Loss: -1.4143	Cost: 9.45s
Train Epoch: 940 [61440/90000 (68%)]	Loss: -1.4374	Cost: 8.81s
Train Epoch: 940 [81920/90000 (91%)]	Loss: -1.4067	Cost: 8.58s
Train Epoch: 940 	Average Loss: -1.2424
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0537

Learning rate: 9.783560257794138e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 941 [0/90000 (0%)]	Loss: 1.9212	Cost: 21.10s
Train Epoch: 941 [20480/90000 (23%)]	Loss: -1.5224	Cost: 9.53s
Train Epoch: 941 [40960/90000 (45%)]	Loss: -1.7082	Cost: 8.86s
Train Epoch: 941 [61440/90000 (68%)]	Loss: -1.6421	Cost: 9.12s
Train Epoch: 941 [81920/90000 (91%)]	Loss: -1.4352	Cost: 8.98s
Train Epoch: 941 	Average Loss: -1.2527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8349

Learning rate: 9.783102863200605e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 942 [0/90000 (0%)]	Loss: 1.7178	Cost: 19.73s
Train Epoch: 942 [20480/90000 (23%)]	Loss: -1.5509	Cost: 7.22s
Train Epoch: 942 [40960/90000 (45%)]	Loss: -1.5084	Cost: 12.21s
Train Epoch: 942 [61440/90000 (68%)]	Loss: -1.5817	Cost: 11.32s
Train Epoch: 942 [81920/90000 (91%)]	Loss: -1.6096	Cost: 12.68s
Train Epoch: 942 	Average Loss: -1.3018
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8174

Learning rate: 9.782644996533745e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 943 [0/90000 (0%)]	Loss: 2.0500	Cost: 26.79s
Train Epoch: 943 [20480/90000 (23%)]	Loss: -1.5608	Cost: 11.63s
Train Epoch: 943 [40960/90000 (45%)]	Loss: -1.6557	Cost: 14.21s
Train Epoch: 943 [61440/90000 (68%)]	Loss: -1.8159	Cost: 12.19s
Train Epoch: 943 [81920/90000 (91%)]	Loss: -1.5796	Cost: 11.90s
Train Epoch: 943 	Average Loss: -1.3823
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8314

Learning rate: 9.782186657838747e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 944 [0/90000 (0%)]	Loss: 1.6796	Cost: 35.23s
Train Epoch: 944 [20480/90000 (23%)]	Loss: -1.7073	Cost: 10.59s
Train Epoch: 944 [40960/90000 (45%)]	Loss: -1.7586	Cost: 12.51s
Train Epoch: 944 [61440/90000 (68%)]	Loss: -1.8692	Cost: 12.09s
Train Epoch: 944 [81920/90000 (91%)]	Loss: -1.4095	Cost: 7.34s
Train Epoch: 944 	Average Loss: -1.4055
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8286

Learning rate: 9.781727847160849e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 945 [0/90000 (0%)]	Loss: 1.9908	Cost: 25.15s
Train Epoch: 945 [20480/90000 (23%)]	Loss: -1.7359	Cost: 12.49s
Train Epoch: 945 [40960/90000 (45%)]	Loss: -1.8327	Cost: 12.00s
Train Epoch: 945 [61440/90000 (68%)]	Loss: -1.8063	Cost: 6.14s
Train Epoch: 945 [81920/90000 (91%)]	Loss: -1.5179	Cost: 6.40s
Train Epoch: 945 	Average Loss: -1.4296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6800

Saving model as e945_model.pt & e945_waveforms_supplementary.hdf5
Learning rate: 9.781268564545331e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 946 [0/90000 (0%)]	Loss: 1.4577	Cost: 24.30s
Train Epoch: 946 [20480/90000 (23%)]	Loss: -1.6328	Cost: 7.44s
Train Epoch: 946 [40960/90000 (45%)]	Loss: -1.9008	Cost: 10.80s
Train Epoch: 946 [61440/90000 (68%)]	Loss: -1.9620	Cost: 9.85s
Train Epoch: 946 [81920/90000 (91%)]	Loss: -1.1063	Cost: 9.05s
Train Epoch: 946 	Average Loss: -1.4298
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9869

Learning rate: 9.780808810037527e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 947 [0/90000 (0%)]	Loss: 2.1099	Cost: 23.09s
Train Epoch: 947 [20480/90000 (23%)]	Loss: -1.3583	Cost: 11.17s
Train Epoch: 947 [40960/90000 (45%)]	Loss: -1.5046	Cost: 10.92s
Train Epoch: 947 [61440/90000 (68%)]	Loss: -1.1815	Cost: 6.78s
Train Epoch: 947 [81920/90000 (91%)]	Loss: -1.1563	Cost: 7.23s
Train Epoch: 947 	Average Loss: -1.1014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9673

Learning rate: 9.780348583682808e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 948 [0/90000 (0%)]	Loss: 2.3150	Cost: 21.17s
Train Epoch: 948 [20480/90000 (23%)]	Loss: -1.4136	Cost: 8.92s
Train Epoch: 948 [40960/90000 (45%)]	Loss: -1.6251	Cost: 10.27s
Train Epoch: 948 [61440/90000 (68%)]	Loss: -1.7433	Cost: 12.59s
Train Epoch: 948 [81920/90000 (91%)]	Loss: -1.5445	Cost: 12.50s
Train Epoch: 948 	Average Loss: -1.3096
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7641

Learning rate: 9.779887885526599e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 949 [0/90000 (0%)]	Loss: 1.8532	Cost: 23.43s
Train Epoch: 949 [20480/90000 (23%)]	Loss: -1.7589	Cost: 13.98s
Train Epoch: 949 [40960/90000 (45%)]	Loss: -2.0082	Cost: 12.55s
Train Epoch: 949 [61440/90000 (68%)]	Loss: -1.8199	Cost: 12.14s
Train Epoch: 949 [81920/90000 (91%)]	Loss: -1.5616	Cost: 12.47s
Train Epoch: 949 	Average Loss: -1.4932
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7579

Learning rate: 9.77942671561437e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 950 [0/90000 (0%)]	Loss: 1.8626	Cost: 25.39s
Train Epoch: 950 [20480/90000 (23%)]	Loss: -1.8029	Cost: 12.69s
Train Epoch: 950 [40960/90000 (45%)]	Loss: -1.8425	Cost: 12.58s
Train Epoch: 950 [61440/90000 (68%)]	Loss: -2.0706	Cost: 9.01s
Train Epoch: 950 [81920/90000 (91%)]	Loss: -1.6746	Cost: 6.25s
Train Epoch: 950 	Average Loss: -1.5375
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6124

Saving model as e950_model.pt & e950_waveforms_supplementary.hdf5
Learning rate: 9.778965073991635e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 951 [0/90000 (0%)]	Loss: 1.5707	Cost: 34.98s
Train Epoch: 951 [20480/90000 (23%)]	Loss: -1.7589	Cost: 11.12s
Train Epoch: 951 [40960/90000 (45%)]	Loss: -1.8446	Cost: 9.66s
Train Epoch: 951 [61440/90000 (68%)]	Loss: -1.8193	Cost: 7.05s
Train Epoch: 951 [81920/90000 (91%)]	Loss: -1.6389	Cost: 8.58s
Train Epoch: 951 	Average Loss: -1.5177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7518

Learning rate: 9.778502960703957e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 952 [0/90000 (0%)]	Loss: 1.5372	Cost: 20.83s
Train Epoch: 952 [20480/90000 (23%)]	Loss: -1.7153	Cost: 8.79s
Train Epoch: 952 [40960/90000 (45%)]	Loss: -1.7741	Cost: 9.53s
Train Epoch: 952 [61440/90000 (68%)]	Loss: -2.0209	Cost: 8.89s
Train Epoch: 952 [81920/90000 (91%)]	Loss: -1.7055	Cost: 9.06s
Train Epoch: 952 	Average Loss: -1.5195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7359

Learning rate: 9.778040375796944e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 953 [0/90000 (0%)]	Loss: 1.7354	Cost: 24.55s
Train Epoch: 953 [20480/90000 (23%)]	Loss: -1.7154	Cost: 7.65s
Train Epoch: 953 [40960/90000 (45%)]	Loss: -1.9137	Cost: 8.90s
Train Epoch: 953 [61440/90000 (68%)]	Loss: -1.9600	Cost: 8.66s
Train Epoch: 953 [81920/90000 (91%)]	Loss: -1.6801	Cost: 8.41s
Train Epoch: 953 	Average Loss: -1.5716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6561

Learning rate: 9.777577319316251e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 954 [0/90000 (0%)]	Loss: 1.9706	Cost: 27.17s
Train Epoch: 954 [20480/90000 (23%)]	Loss: -1.9197	Cost: 8.67s
Train Epoch: 954 [40960/90000 (45%)]	Loss: -1.9150	Cost: 8.83s
Train Epoch: 954 [61440/90000 (68%)]	Loss: -2.1326	Cost: 6.23s
Train Epoch: 954 [81920/90000 (91%)]	Loss: -1.8041	Cost: 6.35s
Train Epoch: 954 	Average Loss: -1.6844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7466

Learning rate: 9.777113791307581e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 955 [0/90000 (0%)]	Loss: 2.0276	Cost: 22.58s
Train Epoch: 955 [20480/90000 (23%)]	Loss: -1.6709	Cost: 8.01s
Train Epoch: 955 [40960/90000 (45%)]	Loss: -1.6156	Cost: 8.81s
Train Epoch: 955 [61440/90000 (68%)]	Loss: -1.8964	Cost: 12.21s
Train Epoch: 955 [81920/90000 (91%)]	Loss: -1.7451	Cost: 12.73s
Train Epoch: 955 	Average Loss: -1.5133
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6423

Learning rate: 9.776649791816682e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 956 [0/90000 (0%)]	Loss: 1.8088	Cost: 30.11s
Train Epoch: 956 [20480/90000 (23%)]	Loss: -1.7391	Cost: 15.50s
Train Epoch: 956 [40960/90000 (45%)]	Loss: -1.8523	Cost: 14.43s
Train Epoch: 956 [61440/90000 (68%)]	Loss: -1.9775	Cost: 12.59s
Train Epoch: 956 [81920/90000 (91%)]	Loss: -1.8510	Cost: 12.16s
Train Epoch: 956 	Average Loss: -1.5910
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7312

Learning rate: 9.776185320889348e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 957 [0/90000 (0%)]	Loss: 1.6150	Cost: 31.04s
Train Epoch: 957 [20480/90000 (23%)]	Loss: -1.0945	Cost: 13.74s
Train Epoch: 957 [40960/90000 (45%)]	Loss: -1.4315	Cost: 13.93s
Train Epoch: 957 [61440/90000 (68%)]	Loss: -1.4868	Cost: 12.15s
Train Epoch: 957 [81920/90000 (91%)]	Loss: -1.2114	Cost: 6.60s
Train Epoch: 957 	Average Loss: -1.1270
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9414

Learning rate: 9.775720378571423e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 958 [0/90000 (0%)]	Loss: 1.8153	Cost: 34.02s
Train Epoch: 958 [20480/90000 (23%)]	Loss: -1.5736	Cost: 12.04s
Train Epoch: 958 [40960/90000 (45%)]	Loss: -1.6127	Cost: 10.07s
Train Epoch: 958 [61440/90000 (68%)]	Loss: -1.8384	Cost: 6.22s
Train Epoch: 958 [81920/90000 (91%)]	Loss: -1.5357	Cost: 7.42s
Train Epoch: 958 	Average Loss: -1.4467
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6597

Learning rate: 9.775254964908792e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 959 [0/90000 (0%)]	Loss: 1.4217	Cost: 30.35s
Train Epoch: 959 [20480/90000 (23%)]	Loss: -1.6086	Cost: 10.24s
Train Epoch: 959 [40960/90000 (45%)]	Loss: -1.8834	Cost: 9.73s
Train Epoch: 959 [61440/90000 (68%)]	Loss: -1.8754	Cost: 6.28s
Train Epoch: 959 [81920/90000 (91%)]	Loss: -1.7529	Cost: 6.99s
Train Epoch: 959 	Average Loss: -1.5784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5966

Saving model as e959_model.pt & e959_waveforms_supplementary.hdf5
Learning rate: 9.774789079947391e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 960 [0/90000 (0%)]	Loss: 1.7524	Cost: 28.34s
Train Epoch: 960 [20480/90000 (23%)]	Loss: -2.0643	Cost: 7.05s
Train Epoch: 960 [40960/90000 (45%)]	Loss: -2.1376	Cost: 10.14s
Train Epoch: 960 [61440/90000 (68%)]	Loss: -2.1189	Cost: 8.64s
Train Epoch: 960 [81920/90000 (91%)]	Loss: -1.7745	Cost: 8.39s
Train Epoch: 960 	Average Loss: -1.6715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5758

Saving model as e960_model.pt & e960_waveforms_supplementary.hdf5
Learning rate: 9.774322723733201e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 961 [0/90000 (0%)]	Loss: 1.4267	Cost: 25.31s
Train Epoch: 961 [20480/90000 (23%)]	Loss: -2.1540	Cost: 9.19s
Train Epoch: 961 [40960/90000 (45%)]	Loss: -2.0333	Cost: 10.96s
Train Epoch: 961 [61440/90000 (68%)]	Loss: -2.1671	Cost: 6.81s
Train Epoch: 961 [81920/90000 (91%)]	Loss: -1.9351	Cost: 9.49s
Train Epoch: 961 	Average Loss: -1.7826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5696

Saving model as e961_model.pt & e961_waveforms_supplementary.hdf5
Learning rate: 9.773855896312248e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 962 [0/90000 (0%)]	Loss: 1.7306	Cost: 19.75s
Train Epoch: 962 [20480/90000 (23%)]	Loss: -1.8733	Cost: 10.70s
Train Epoch: 962 [40960/90000 (45%)]	Loss: -1.9854	Cost: 14.51s
Train Epoch: 962 [61440/90000 (68%)]	Loss: -2.0283	Cost: 14.49s
Train Epoch: 962 [81920/90000 (91%)]	Loss: -1.8263	Cost: 13.19s
Train Epoch: 962 	Average Loss: -1.6479
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5258

Saving model as e962_model.pt & e962_waveforms_supplementary.hdf5
Learning rate: 9.773388597730608e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 963 [0/90000 (0%)]	Loss: 1.6934	Cost: 28.30s
Train Epoch: 963 [20480/90000 (23%)]	Loss: -1.9013	Cost: 15.34s
Train Epoch: 963 [40960/90000 (45%)]	Loss: -1.7627	Cost: 12.73s
Train Epoch: 963 [61440/90000 (68%)]	Loss: -2.0256	Cost: 12.32s
Train Epoch: 963 [81920/90000 (91%)]	Loss: -1.9140	Cost: 11.28s
Train Epoch: 963 	Average Loss: -1.6617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5237

Saving model as e963_model.pt & e963_waveforms_supplementary.hdf5
Learning rate: 9.772920828034401e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 964 [0/90000 (0%)]	Loss: 1.8274	Cost: 24.65s
Train Epoch: 964 [20480/90000 (23%)]	Loss: -1.7957	Cost: 13.29s
Train Epoch: 964 [40960/90000 (45%)]	Loss: -1.9001	Cost: 10.26s
Train Epoch: 964 [61440/90000 (68%)]	Loss: -2.0815	Cost: 6.06s
Train Epoch: 964 [81920/90000 (91%)]	Loss: -1.6216	Cost: 7.49s
Train Epoch: 964 	Average Loss: -1.6214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7623

Learning rate: 9.772452587269794e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 965 [0/90000 (0%)]	Loss: 2.3754	Cost: 24.63s
Train Epoch: 965 [20480/90000 (23%)]	Loss: -1.7672	Cost: 6.50s
Train Epoch: 965 [40960/90000 (45%)]	Loss: -1.9171	Cost: 7.92s
Train Epoch: 965 [61440/90000 (68%)]	Loss: -2.0389	Cost: 9.01s
Train Epoch: 965 [81920/90000 (91%)]	Loss: -1.8427	Cost: 9.04s
Train Epoch: 965 	Average Loss: -1.5759
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5317

Learning rate: 9.771983875482999e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 966 [0/90000 (0%)]	Loss: 1.4701	Cost: 26.30s
Train Epoch: 966 [20480/90000 (23%)]	Loss: -1.7601	Cost: 10.67s
Train Epoch: 966 [40960/90000 (45%)]	Loss: -0.4485	Cost: 10.27s
Train Epoch: 966 [61440/90000 (68%)]	Loss: -0.9162	Cost: 8.71s
Train Epoch: 966 [81920/90000 (91%)]	Loss: -0.8631	Cost: 8.08s
Train Epoch: 966 	Average Loss: -0.8493
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1853

Learning rate: 9.771514692720278e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 967 [0/90000 (0%)]	Loss: 1.8694	Cost: 30.69s
Train Epoch: 967 [20480/90000 (23%)]	Loss: -1.4028	Cost: 8.58s
Train Epoch: 967 [40960/90000 (45%)]	Loss: -1.6869	Cost: 6.48s
Train Epoch: 967 [61440/90000 (68%)]	Loss: -1.5921	Cost: 7.29s
Train Epoch: 967 [81920/90000 (91%)]	Loss: -1.5354	Cost: 8.28s
Train Epoch: 967 	Average Loss: -1.3181
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6800

Learning rate: 9.771045039027936e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 968 [0/90000 (0%)]	Loss: 1.9869	Cost: 20.41s
Train Epoch: 968 [20480/90000 (23%)]	Loss: -1.9230	Cost: 7.13s
Train Epoch: 968 [40960/90000 (45%)]	Loss: -1.9345	Cost: 14.23s
Train Epoch: 968 [61440/90000 (68%)]	Loss: -2.0479	Cost: 13.04s
Train Epoch: 968 [81920/90000 (91%)]	Loss: -1.6757	Cost: 12.61s
Train Epoch: 968 	Average Loss: -1.6978
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6033

Learning rate: 9.770574914452328e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 969 [0/90000 (0%)]	Loss: 1.8530	Cost: 25.03s
Train Epoch: 969 [20480/90000 (23%)]	Loss: -2.0677	Cost: 12.65s
Train Epoch: 969 [40960/90000 (45%)]	Loss: -2.0548	Cost: 12.47s
Train Epoch: 969 [61440/90000 (68%)]	Loss: -2.2212	Cost: 12.44s
Train Epoch: 969 [81920/90000 (91%)]	Loss: -1.7675	Cost: 12.53s
Train Epoch: 969 	Average Loss: -1.7329
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6263

Learning rate: 9.770104319039851e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 970 [0/90000 (0%)]	Loss: 1.9614	Cost: 23.24s
Train Epoch: 970 [20480/90000 (23%)]	Loss: -1.8564	Cost: 13.71s
Train Epoch: 970 [40960/90000 (45%)]	Loss: -1.7530	Cost: 12.43s
Train Epoch: 970 [61440/90000 (68%)]	Loss: -1.8888	Cost: 6.79s
Train Epoch: 970 [81920/90000 (91%)]	Loss: -1.9330	Cost: 6.17s
Train Epoch: 970 	Average Loss: -1.6069
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5340

Learning rate: 9.769633252836953e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 971 [0/90000 (0%)]	Loss: 1.5413	Cost: 34.82s
Train Epoch: 971 [20480/90000 (23%)]	Loss: -1.7733	Cost: 8.75s
Train Epoch: 971 [40960/90000 (45%)]	Loss: -2.0418	Cost: 7.41s
Train Epoch: 971 [61440/90000 (68%)]	Loss: -2.0897	Cost: 7.24s
Train Epoch: 971 [81920/90000 (91%)]	Loss: -1.9339	Cost: 8.61s
Train Epoch: 971 	Average Loss: -1.7498
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4246

Saving model as e971_model.pt & e971_waveforms_supplementary.hdf5
Learning rate: 9.769161715890125e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 972 [0/90000 (0%)]	Loss: 1.6172	Cost: 25.17s
Train Epoch: 972 [20480/90000 (23%)]	Loss: -2.1115	Cost: 8.65s
Train Epoch: 972 [40960/90000 (45%)]	Loss: -1.6680	Cost: 9.18s
Train Epoch: 972 [61440/90000 (68%)]	Loss: -1.5141	Cost: 8.79s
Train Epoch: 972 [81920/90000 (91%)]	Loss: -1.2626	Cost: 8.58s
Train Epoch: 972 	Average Loss: -1.4875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9230

Learning rate: 9.768689708245906e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 973 [0/90000 (0%)]	Loss: 2.2301	Cost: 20.13s
Train Epoch: 973 [20480/90000 (23%)]	Loss: -1.5580	Cost: 9.43s
Train Epoch: 973 [40960/90000 (45%)]	Loss: -1.8671	Cost: 8.90s
Train Epoch: 973 [61440/90000 (68%)]	Loss: -2.0447	Cost: 9.15s
Train Epoch: 973 [81920/90000 (91%)]	Loss: -1.8018	Cost: 6.53s
Train Epoch: 973 	Average Loss: -1.5266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6081

Learning rate: 9.768217229950883e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 974 [0/90000 (0%)]	Loss: 1.4215	Cost: 20.68s
Train Epoch: 974 [20480/90000 (23%)]	Loss: -2.0884	Cost: 8.13s
Train Epoch: 974 [40960/90000 (45%)]	Loss: -2.1452	Cost: 9.50s
Train Epoch: 974 [61440/90000 (68%)]	Loss: -2.2206	Cost: 10.21s
Train Epoch: 974 [81920/90000 (91%)]	Loss: -2.1019	Cost: 14.01s
Train Epoch: 974 	Average Loss: -1.8232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3487

Saving model as e974_model.pt & e974_waveforms_supplementary.hdf5
Learning rate: 9.767744281051684e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 975 [0/90000 (0%)]	Loss: 1.5214	Cost: 22.22s
Train Epoch: 975 [20480/90000 (23%)]	Loss: -2.1163	Cost: 12.20s
Train Epoch: 975 [40960/90000 (45%)]	Loss: -2.2259	Cost: 14.25s
Train Epoch: 975 [61440/90000 (68%)]	Loss: -2.2077	Cost: 12.09s
Train Epoch: 975 [81920/90000 (91%)]	Loss: -2.0176	Cost: 12.07s
Train Epoch: 975 	Average Loss: -1.8227
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5264

Learning rate: 9.767270861594989e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 976 [0/90000 (0%)]	Loss: 1.4200	Cost: 33.96s
Train Epoch: 976 [20480/90000 (23%)]	Loss: -1.8377	Cost: 11.22s
Train Epoch: 976 [40960/90000 (45%)]	Loss: -2.0383	Cost: 12.51s
Train Epoch: 976 [61440/90000 (68%)]	Loss: -2.1491	Cost: 12.09s
Train Epoch: 976 [81920/90000 (91%)]	Loss: -1.9377	Cost: 7.73s
Train Epoch: 976 	Average Loss: -1.7847
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6633

Learning rate: 9.766796971627527e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 977 [0/90000 (0%)]	Loss: 1.6350	Cost: 30.67s
Train Epoch: 977 [20480/90000 (23%)]	Loss: -1.9782	Cost: 12.57s
Train Epoch: 977 [40960/90000 (45%)]	Loss: -2.1905	Cost: 10.82s
Train Epoch: 977 [61440/90000 (68%)]	Loss: -2.2308	Cost: 6.34s
Train Epoch: 977 [81920/90000 (91%)]	Loss: -2.0158	Cost: 6.25s
Train Epoch: 977 	Average Loss: -1.8577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4281

Learning rate: 9.766322611196063e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 978 [0/90000 (0%)]	Loss: 1.4575	Cost: 28.13s
Train Epoch: 978 [20480/90000 (23%)]	Loss: -2.1589	Cost: 7.11s
Train Epoch: 978 [40960/90000 (45%)]	Loss: -2.0358	Cost: 10.59s
Train Epoch: 978 [61440/90000 (68%)]	Loss: -2.2188	Cost: 9.12s
Train Epoch: 978 [81920/90000 (91%)]	Loss: -2.1779	Cost: 8.91s
Train Epoch: 978 	Average Loss: -1.8852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5519

Learning rate: 9.765847780347416e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 979 [0/90000 (0%)]	Loss: 1.6771	Cost: 21.82s
Train Epoch: 979 [20480/90000 (23%)]	Loss: -1.9612	Cost: 9.71s
Train Epoch: 979 [40960/90000 (45%)]	Loss: -2.2743	Cost: 12.14s
Train Epoch: 979 [61440/90000 (68%)]	Loss: -2.0217	Cost: 9.05s
Train Epoch: 979 [81920/90000 (91%)]	Loss: -1.8060	Cost: 8.70s
Train Epoch: 979 	Average Loss: -1.8217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5527

Learning rate: 9.765372479128451e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 980 [0/90000 (0%)]	Loss: 1.4847	Cost: 21.94s
Train Epoch: 980 [20480/90000 (23%)]	Loss: -2.2247	Cost: 6.54s
Train Epoch: 980 [40960/90000 (45%)]	Loss: -2.2099	Cost: 7.42s
Train Epoch: 980 [61440/90000 (68%)]	Loss: -2.3421	Cost: 8.26s
Train Epoch: 980 [81920/90000 (91%)]	Loss: -2.1712	Cost: 15.62s
Train Epoch: 980 	Average Loss: -1.9297
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2178

Saving model as e980_model.pt & e980_waveforms_supplementary.hdf5
Learning rate: 9.764896707586078e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 981 [0/90000 (0%)]	Loss: 1.2305	Cost: 21.48s
Train Epoch: 981 [20480/90000 (23%)]	Loss: -2.3021	Cost: 12.99s
Train Epoch: 981 [40960/90000 (45%)]	Loss: -2.2223	Cost: 12.96s
Train Epoch: 981 [61440/90000 (68%)]	Loss: -2.3974	Cost: 12.20s
Train Epoch: 981 [81920/90000 (91%)]	Loss: -2.1083	Cost: 12.37s
Train Epoch: 981 	Average Loss: -2.0410
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3794

Learning rate: 9.764420465767253e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 982 [0/90000 (0%)]	Loss: 1.1656	Cost: 27.09s
Train Epoch: 982 [20480/90000 (23%)]	Loss: -2.0588	Cost: 13.13s
Train Epoch: 982 [40960/90000 (45%)]	Loss: -2.2330	Cost: 13.00s
Train Epoch: 982 [61440/90000 (68%)]	Loss: -2.2691	Cost: 12.21s
Train Epoch: 982 [81920/90000 (91%)]	Loss: -2.2039	Cost: 6.51s
Train Epoch: 982 	Average Loss: -1.9903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4320

Learning rate: 9.76394375371898e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 983 [0/90000 (0%)]	Loss: 1.1886	Cost: 33.53s
Train Epoch: 983 [20480/90000 (23%)]	Loss: -2.1794	Cost: 14.15s
Train Epoch: 983 [40960/90000 (45%)]	Loss: -2.3198	Cost: 12.72s
Train Epoch: 983 [61440/90000 (68%)]	Loss: -2.1244	Cost: 9.41s
Train Epoch: 983 [81920/90000 (91%)]	Loss: -2.2412	Cost: 6.34s
Train Epoch: 983 	Average Loss: -1.9836
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4279

Learning rate: 9.76346657148831e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 984 [0/90000 (0%)]	Loss: 1.2237	Cost: 27.84s
Train Epoch: 984 [20480/90000 (23%)]	Loss: -2.3606	Cost: 12.60s
Train Epoch: 984 [40960/90000 (45%)]	Loss: -2.3865	Cost: 9.47s
Train Epoch: 984 [61440/90000 (68%)]	Loss: -2.5215	Cost: 6.25s
Train Epoch: 984 [81920/90000 (91%)]	Loss: -2.3072	Cost: 7.16s
Train Epoch: 984 	Average Loss: -2.1037
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3114

Learning rate: 9.762988919122336e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 985 [0/90000 (0%)]	Loss: 1.3637	Cost: 27.23s
Train Epoch: 985 [20480/90000 (23%)]	Loss: -2.2563	Cost: 6.76s
Train Epoch: 985 [40960/90000 (45%)]	Loss: -2.3806	Cost: 10.16s
Train Epoch: 985 [61440/90000 (68%)]	Loss: -2.2640	Cost: 8.66s
Train Epoch: 985 [81920/90000 (91%)]	Loss: -2.1547	Cost: 9.08s
Train Epoch: 985 	Average Loss: -2.0021
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4709

Learning rate: 9.762510796668202e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 986 [0/90000 (0%)]	Loss: 1.2975	Cost: 19.99s
Train Epoch: 986 [20480/90000 (23%)]	Loss: -1.8018	Cost: 9.11s
Train Epoch: 986 [40960/90000 (45%)]	Loss: -1.8778	Cost: 9.05s
Train Epoch: 986 [61440/90000 (68%)]	Loss: -2.2758	Cost: 8.06s
Train Epoch: 986 [81920/90000 (91%)]	Loss: -2.0765	Cost: 5.99s
Train Epoch: 986 	Average Loss: -1.7693
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3607

Learning rate: 9.762032204173097e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 987 [0/90000 (0%)]	Loss: 1.3762	Cost: 22.22s
Train Epoch: 987 [20480/90000 (23%)]	Loss: -1.8733	Cost: 7.13s
Train Epoch: 987 [40960/90000 (45%)]	Loss: -1.9271	Cost: 10.92s
Train Epoch: 987 [61440/90000 (68%)]	Loss: -2.3198	Cost: 12.74s
Train Epoch: 987 [81920/90000 (91%)]	Loss: -2.1300	Cost: 12.54s
Train Epoch: 987 	Average Loss: -1.8681
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4490

Learning rate: 9.761553141684257e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 988 [0/90000 (0%)]	Loss: 1.4996	Cost: 30.93s
Train Epoch: 988 [20480/90000 (23%)]	Loss: -2.1317	Cost: 14.44s
Train Epoch: 988 [40960/90000 (45%)]	Loss: -2.5072	Cost: 14.93s
Train Epoch: 988 [61440/90000 (68%)]	Loss: -1.9105	Cost: 12.39s
Train Epoch: 988 [81920/90000 (91%)]	Loss: -1.8781	Cost: 11.91s
Train Epoch: 988 	Average Loss: -1.9188
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6083

Learning rate: 9.761073609248962e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 989 [0/90000 (0%)]	Loss: 1.4548	Cost: 40.32s
Train Epoch: 989 [20480/90000 (23%)]	Loss: -2.1222	Cost: 13.52s
Train Epoch: 989 [40960/90000 (45%)]	Loss: -2.1623	Cost: 12.61s
Train Epoch: 989 [61440/90000 (68%)]	Loss: -2.4016	Cost: 10.70s
Train Epoch: 989 [81920/90000 (91%)]	Loss: -2.1065	Cost: 6.17s
Train Epoch: 989 	Average Loss: -1.9089
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2790

Learning rate: 9.76059360691454e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 990 [0/90000 (0%)]	Loss: 1.1082	Cost: 30.79s
Train Epoch: 990 [20480/90000 (23%)]	Loss: -2.2613	Cost: 12.81s
Train Epoch: 990 [40960/90000 (45%)]	Loss: -2.2962	Cost: 12.38s
Train Epoch: 990 [61440/90000 (68%)]	Loss: -2.3606	Cost: 7.57s
Train Epoch: 990 [81920/90000 (91%)]	Loss: -2.0517	Cost: 6.33s
Train Epoch: 990 	Average Loss: -2.0872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4330

Learning rate: 9.760113134728365e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 991 [0/90000 (0%)]	Loss: 1.5293	Cost: 28.32s
Train Epoch: 991 [20480/90000 (23%)]	Loss: -2.3272	Cost: 9.34s
Train Epoch: 991 [40960/90000 (45%)]	Loss: -2.2110	Cost: 6.57s
Train Epoch: 991 [61440/90000 (68%)]	Loss: -2.3967	Cost: 6.93s
Train Epoch: 991 [81920/90000 (91%)]	Loss: -2.1210	Cost: 8.40s
Train Epoch: 991 	Average Loss: -1.9575
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3121

Learning rate: 9.759632192737859e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 992 [0/90000 (0%)]	Loss: 1.4235	Cost: 23.33s
Train Epoch: 992 [20480/90000 (23%)]	Loss: -2.2015	Cost: 6.93s
Train Epoch: 992 [40960/90000 (45%)]	Loss: -2.2915	Cost: 9.72s
Train Epoch: 992 [61440/90000 (68%)]	Loss: -2.6373	Cost: 8.60s
Train Epoch: 992 [81920/90000 (91%)]	Loss: -2.2826	Cost: 8.66s
Train Epoch: 992 	Average Loss: -2.1160
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1338

Saving model as e992_model.pt & e992_waveforms_supplementary.hdf5
Learning rate: 9.759150780990488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 993 [0/90000 (0%)]	Loss: 1.4979	Cost: 29.32s
Train Epoch: 993 [20480/90000 (23%)]	Loss: -2.1244	Cost: 10.52s
Train Epoch: 993 [40960/90000 (45%)]	Loss: -1.8055	Cost: 6.93s
Train Epoch: 993 [61440/90000 (68%)]	Loss: -1.7108	Cost: 7.27s
Train Epoch: 993 [81920/90000 (91%)]	Loss: -1.7186	Cost: 7.86s
Train Epoch: 993 	Average Loss: -1.6750
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6585

Learning rate: 9.758668899533768e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 994 [0/90000 (0%)]	Loss: 1.3745	Cost: 22.86s
Train Epoch: 994 [20480/90000 (23%)]	Loss: -1.9789	Cost: 10.18s
Train Epoch: 994 [40960/90000 (45%)]	Loss: -2.1627	Cost: 9.38s
Train Epoch: 994 [61440/90000 (68%)]	Loss: -2.5144	Cost: 13.27s
Train Epoch: 994 [81920/90000 (91%)]	Loss: -2.3713	Cost: 12.49s
Train Epoch: 994 	Average Loss: -1.9654
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1460

Learning rate: 9.758186548415257e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 995 [0/90000 (0%)]	Loss: 1.0529	Cost: 28.75s
Train Epoch: 995 [20480/90000 (23%)]	Loss: -2.3464	Cost: 10.98s
Train Epoch: 995 [40960/90000 (45%)]	Loss: -2.4524	Cost: 12.73s
Train Epoch: 995 [61440/90000 (68%)]	Loss: -2.5073	Cost: 12.38s
Train Epoch: 995 [81920/90000 (91%)]	Loss: -1.8549	Cost: 12.29s
Train Epoch: 995 	Average Loss: -2.0318
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6390

Learning rate: 9.757703727682558e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 996 [0/90000 (0%)]	Loss: 2.2715	Cost: 24.63s
Train Epoch: 996 [20480/90000 (23%)]	Loss: -1.9891	Cost: 13.78s
Train Epoch: 996 [40960/90000 (45%)]	Loss: -1.9757	Cost: 12.37s
Train Epoch: 996 [61440/90000 (68%)]	Loss: -2.2150	Cost: 12.23s
Train Epoch: 996 [81920/90000 (91%)]	Loss: -2.1527	Cost: 10.95s
Train Epoch: 996 	Average Loss: -1.8898
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2978

Learning rate: 9.757220437383328e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 997 [0/90000 (0%)]	Loss: 1.0917	Cost: 24.85s
Train Epoch: 997 [20480/90000 (23%)]	Loss: -2.4994	Cost: 13.00s
Train Epoch: 997 [40960/90000 (45%)]	Loss: -2.3737	Cost: 12.66s
Train Epoch: 997 [61440/90000 (68%)]	Loss: -2.6193	Cost: 7.24s
Train Epoch: 997 [81920/90000 (91%)]	Loss: -2.2249	Cost: 6.16s
Train Epoch: 997 	Average Loss: -2.1791
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3102

Learning rate: 9.756736677565264e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 998 [0/90000 (0%)]	Loss: 1.0040	Cost: 37.37s
Train Epoch: 998 [20480/90000 (23%)]	Loss: -2.1934	Cost: 9.46s
Train Epoch: 998 [40960/90000 (45%)]	Loss: -2.3915	Cost: 9.46s
Train Epoch: 998 [61440/90000 (68%)]	Loss: -2.4180	Cost: 7.77s
Train Epoch: 998 [81920/90000 (91%)]	Loss: -2.1470	Cost: 8.55s
Train Epoch: 998 	Average Loss: -2.0970
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4084

Learning rate: 9.756252448276111e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 999 [0/90000 (0%)]	Loss: 1.2233	Cost: 22.59s
Train Epoch: 999 [20480/90000 (23%)]	Loss: -2.2649	Cost: 8.59s
Train Epoch: 999 [40960/90000 (45%)]	Loss: -2.6537	Cost: 9.07s
Train Epoch: 999 [61440/90000 (68%)]	Loss: -2.6446	Cost: 8.64s
Train Epoch: 999 [81920/90000 (91%)]	Loss: -2.2860	Cost: 8.80s
Train Epoch: 999 	Average Loss: -2.1520
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2244

Learning rate: 9.755767749563662e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1000 [0/90000 (0%)]	Loss: 1.3163	Cost: 22.42s
Train Epoch: 1000 [20480/90000 (23%)]	Loss: -2.3731	Cost: 7.28s
Train Epoch: 1000 [40960/90000 (45%)]	Loss: -2.5171	Cost: 10.62s
Train Epoch: 1000 [61440/90000 (68%)]	Loss: -2.4698	Cost: 8.62s
Train Epoch: 1000 [81920/90000 (91%)]	Loss: -2.4224	Cost: 8.76s
Train Epoch: 1000 	Average Loss: -2.2447
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0532

Saving model as e1000_model.pt & e1000_waveforms_supplementary.hdf5
Learning rate: 9.755282581475752e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1001 [0/90000 (0%)]	Loss: 1.1205	Cost: 20.50s
Train Epoch: 1001 [20480/90000 (23%)]	Loss: -2.4580	Cost: 9.01s
Train Epoch: 1001 [40960/90000 (45%)]	Loss: -2.5849	Cost: 9.17s
Train Epoch: 1001 [61440/90000 (68%)]	Loss: -2.7519	Cost: 5.86s
Train Epoch: 1001 [81920/90000 (91%)]	Loss: -2.2886	Cost: 6.27s
Train Epoch: 1001 	Average Loss: -2.2774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3644

Learning rate: 9.754796944060267e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1002 [0/90000 (0%)]	Loss: 1.3023	Cost: 21.58s
Train Epoch: 1002 [20480/90000 (23%)]	Loss: -2.1793	Cost: 6.56s
Train Epoch: 1002 [40960/90000 (45%)]	Loss: -2.3624	Cost: 11.88s
Train Epoch: 1002 [61440/90000 (68%)]	Loss: -2.6195	Cost: 13.57s
Train Epoch: 1002 [81920/90000 (91%)]	Loss: -2.3975	Cost: 12.52s
Train Epoch: 1002 	Average Loss: -2.1526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1361

Learning rate: 9.754310837365139e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1003 [0/90000 (0%)]	Loss: 1.1421	Cost: 31.05s
Train Epoch: 1003 [20480/90000 (23%)]	Loss: -2.6193	Cost: 13.43s
Train Epoch: 1003 [40960/90000 (45%)]	Loss: -2.5643	Cost: 14.28s
Train Epoch: 1003 [61440/90000 (68%)]	Loss: -2.9006	Cost: 12.32s
Train Epoch: 1003 [81920/90000 (91%)]	Loss: -2.5237	Cost: 12.33s
Train Epoch: 1003 	Average Loss: -2.3225
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0847

Learning rate: 9.753824261438342e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1004 [0/90000 (0%)]	Loss: 0.9246	Cost: 42.94s
Train Epoch: 1004 [20480/90000 (23%)]	Loss: -2.5159	Cost: 12.32s
Train Epoch: 1004 [40960/90000 (45%)]	Loss: -2.7951	Cost: 12.25s
Train Epoch: 1004 [61440/90000 (68%)]	Loss: -2.7420	Cost: 10.03s
Train Epoch: 1004 [81920/90000 (91%)]	Loss: -2.5637	Cost: 6.06s
Train Epoch: 1004 	Average Loss: -2.3238
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1118

Learning rate: 9.753337216327901e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1005 [0/90000 (0%)]	Loss: 0.6480	Cost: 22.86s
Train Epoch: 1005 [20480/90000 (23%)]	Loss: -2.7805	Cost: 11.21s
Train Epoch: 1005 [40960/90000 (45%)]	Loss: -2.8084	Cost: 7.59s
Train Epoch: 1005 [61440/90000 (68%)]	Loss: -2.8119	Cost: 6.17s
Train Epoch: 1005 [81920/90000 (91%)]	Loss: -2.4296	Cost: 8.73s
Train Epoch: 1005 	Average Loss: -2.3571
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1479

Learning rate: 9.752849702081885e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1006 [0/90000 (0%)]	Loss: 0.8995	Cost: 21.46s
Train Epoch: 1006 [20480/90000 (23%)]	Loss: -2.4244	Cost: 7.38s
Train Epoch: 1006 [40960/90000 (45%)]	Loss: -2.4409	Cost: 8.88s
Train Epoch: 1006 [61440/90000 (68%)]	Loss: -2.5971	Cost: 9.08s
Train Epoch: 1006 [81920/90000 (91%)]	Loss: -2.4642	Cost: 9.58s
Train Epoch: 1006 	Average Loss: -2.2845
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1004

Learning rate: 9.752361718748408e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1007 [0/90000 (0%)]	Loss: 1.1090	Cost: 24.43s
Train Epoch: 1007 [20480/90000 (23%)]	Loss: -2.5271	Cost: 9.11s
Train Epoch: 1007 [40960/90000 (45%)]	Loss: -2.6388	Cost: 6.49s
Train Epoch: 1007 [61440/90000 (68%)]	Loss: -2.7522	Cost: 7.19s
Train Epoch: 1007 [81920/90000 (91%)]	Loss: -2.5886	Cost: 7.46s
Train Epoch: 1007 	Average Loss: -2.3172
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1062

Learning rate: 9.751873266375635e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1008 [0/90000 (0%)]	Loss: 1.0285	Cost: 35.31s
Train Epoch: 1008 [20480/90000 (23%)]	Loss: -2.4178	Cost: 11.34s
Train Epoch: 1008 [40960/90000 (45%)]	Loss: -2.6379	Cost: 12.65s
Train Epoch: 1008 [61440/90000 (68%)]	Loss: -2.8576	Cost: 12.36s
Train Epoch: 1008 [81920/90000 (91%)]	Loss: -2.5419	Cost: 12.07s
Train Epoch: 1008 	Average Loss: -2.3587
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0439

Saving model as e1008_model.pt & e1008_waveforms_supplementary.hdf5
Learning rate: 9.751384345011772e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1009 [0/90000 (0%)]	Loss: 0.9898	Cost: 26.52s
Train Epoch: 1009 [20480/90000 (23%)]	Loss: -2.6550	Cost: 12.30s
Train Epoch: 1009 [40960/90000 (45%)]	Loss: -2.7031	Cost: 12.28s
Train Epoch: 1009 [61440/90000 (68%)]	Loss: -2.7954	Cost: 12.34s
Train Epoch: 1009 [81920/90000 (91%)]	Loss: -2.6677	Cost: 8.63s
Train Epoch: 1009 	Average Loss: -2.4482
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2009

Learning rate: 9.750894954705075e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1010 [0/90000 (0%)]	Loss: 1.2835	Cost: 33.91s
Train Epoch: 1010 [20480/90000 (23%)]	Loss: -2.2564	Cost: 12.66s
Train Epoch: 1010 [40960/90000 (45%)]	Loss: -2.4883	Cost: 12.82s
Train Epoch: 1010 [61440/90000 (68%)]	Loss: -2.7663	Cost: 8.21s
Train Epoch: 1010 [81920/90000 (91%)]	Loss: -2.5042	Cost: 6.28s
Train Epoch: 1010 	Average Loss: -2.3076
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9773

Saving model as e1010_model.pt & e1010_waveforms_supplementary.hdf5
Learning rate: 9.750405095503843e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1011 [0/90000 (0%)]	Loss: 0.5928	Cost: 22.86s
Train Epoch: 1011 [20480/90000 (23%)]	Loss: -2.7194	Cost: 10.87s
Train Epoch: 1011 [40960/90000 (45%)]	Loss: -2.7988	Cost: 10.92s
Train Epoch: 1011 [61440/90000 (68%)]	Loss: -2.7062	Cost: 7.93s
Train Epoch: 1011 [81920/90000 (91%)]	Loss: -2.4903	Cost: 8.02s
Train Epoch: 1011 	Average Loss: -2.4194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1149

Learning rate: 9.749914767456425e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1012 [0/90000 (0%)]	Loss: 1.5734	Cost: 20.65s
Train Epoch: 1012 [20480/90000 (23%)]	Loss: -2.3372	Cost: 8.32s
Train Epoch: 1012 [40960/90000 (45%)]	Loss: -2.4204	Cost: 9.50s
Train Epoch: 1012 [61440/90000 (68%)]	Loss: -2.1755	Cost: 8.96s
Train Epoch: 1012 [81920/90000 (91%)]	Loss: -2.1064	Cost: 8.63s
Train Epoch: 1012 	Average Loss: -2.0590
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3420

Learning rate: 9.749423970611215e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1013 [0/90000 (0%)]	Loss: 1.6066	Cost: 22.40s
Train Epoch: 1013 [20480/90000 (23%)]	Loss: -2.5109	Cost: 8.83s
Train Epoch: 1013 [40960/90000 (45%)]	Loss: -2.5745	Cost: 8.49s
Train Epoch: 1013 [61440/90000 (68%)]	Loss: -2.8298	Cost: 8.68s
Train Epoch: 1013 [81920/90000 (91%)]	Loss: -2.6596	Cost: 8.40s
Train Epoch: 1013 	Average Loss: -2.3109
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0404

Learning rate: 9.74893270501665e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1014 [0/90000 (0%)]	Loss: 0.8342	Cost: 33.83s
Train Epoch: 1014 [20480/90000 (23%)]	Loss: -2.4464	Cost: 8.82s
Train Epoch: 1014 [40960/90000 (45%)]	Loss: -2.7818	Cost: 8.93s
Train Epoch: 1014 [61440/90000 (68%)]	Loss: -2.7169	Cost: 6.63s
Train Epoch: 1014 [81920/90000 (91%)]	Loss: -2.5944	Cost: 6.42s
Train Epoch: 1014 	Average Loss: -2.4242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1168

Learning rate: 9.748440970721218e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1015 [0/90000 (0%)]	Loss: 1.3544	Cost: 18.82s
Train Epoch: 1015 [20480/90000 (23%)]	Loss: -2.8558	Cost: 8.57s
Train Epoch: 1015 [40960/90000 (45%)]	Loss: -2.7708	Cost: 13.77s
Train Epoch: 1015 [61440/90000 (68%)]	Loss: -2.5619	Cost: 13.12s
Train Epoch: 1015 [81920/90000 (91%)]	Loss: -2.4597	Cost: 13.31s
Train Epoch: 1015 	Average Loss: -2.3745
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1513

Learning rate: 9.747948767773452e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1016 [0/90000 (0%)]	Loss: 1.3255	Cost: 26.52s
Train Epoch: 1016 [20480/90000 (23%)]	Loss: -2.7492	Cost: 12.39s
Train Epoch: 1016 [40960/90000 (45%)]	Loss: -2.7873	Cost: 13.42s
Train Epoch: 1016 [61440/90000 (68%)]	Loss: -2.6936	Cost: 12.38s
Train Epoch: 1016 [81920/90000 (91%)]	Loss: -2.5130	Cost: 12.49s
Train Epoch: 1016 	Average Loss: -2.4367
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9740

Saving model as e1016_model.pt & e1016_waveforms_supplementary.hdf5
Learning rate: 9.747456096221927e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1017 [0/90000 (0%)]	Loss: 0.6370	Cost: 25.75s
Train Epoch: 1017 [20480/90000 (23%)]	Loss: -2.7019	Cost: 13.05s
Train Epoch: 1017 [40960/90000 (45%)]	Loss: -2.9895	Cost: 12.32s
Train Epoch: 1017 [61440/90000 (68%)]	Loss: -3.0641	Cost: 11.27s
Train Epoch: 1017 [81920/90000 (91%)]	Loss: -2.6350	Cost: 6.11s
Train Epoch: 1017 	Average Loss: -2.5438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9197

Saving model as e1017_model.pt & e1017_waveforms_supplementary.hdf5
Learning rate: 9.746962956115272e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1018 [0/90000 (0%)]	Loss: 0.9886	Cost: 33.04s
Train Epoch: 1018 [20480/90000 (23%)]	Loss: -2.6861	Cost: 6.65s
Train Epoch: 1018 [40960/90000 (45%)]	Loss: -2.9250	Cost: 8.86s
Train Epoch: 1018 [61440/90000 (68%)]	Loss: -2.8208	Cost: 9.01s
Train Epoch: 1018 [81920/90000 (91%)]	Loss: -2.5886	Cost: 8.69s
Train Epoch: 1018 	Average Loss: -2.4431
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0591

Learning rate: 9.746469347502156e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1019 [0/90000 (0%)]	Loss: 1.0708	Cost: 22.94s
Train Epoch: 1019 [20480/90000 (23%)]	Loss: -2.6998	Cost: 7.63s
Train Epoch: 1019 [40960/90000 (45%)]	Loss: -2.8793	Cost: 8.60s
Train Epoch: 1019 [61440/90000 (68%)]	Loss: -2.7178	Cost: 8.65s
Train Epoch: 1019 [81920/90000 (91%)]	Loss: -2.6300	Cost: 8.44s
Train Epoch: 1019 	Average Loss: -2.4338
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0954

Learning rate: 9.745975270431296e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1020 [0/90000 (0%)]	Loss: 1.2024	Cost: 28.22s
Train Epoch: 1020 [20480/90000 (23%)]	Loss: -2.7171	Cost: 11.15s
Train Epoch: 1020 [40960/90000 (45%)]	Loss: -2.7327	Cost: 9.66s
Train Epoch: 1020 [61440/90000 (68%)]	Loss: -2.9086	Cost: 6.60s
Train Epoch: 1020 [81920/90000 (91%)]	Loss: -2.6330	Cost: 6.74s
Train Epoch: 1020 	Average Loss: -2.4657
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8730

Saving model as e1020_model.pt & e1020_waveforms_supplementary.hdf5
Learning rate: 9.745480724951455e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1021 [0/90000 (0%)]	Loss: 0.9766	Cost: 21.62s
Train Epoch: 1021 [20480/90000 (23%)]	Loss: -2.7101	Cost: 10.48s
Train Epoch: 1021 [40960/90000 (45%)]	Loss: -2.9404	Cost: 16.52s
Train Epoch: 1021 [61440/90000 (68%)]	Loss: -2.9714	Cost: 13.32s
Train Epoch: 1021 [81920/90000 (91%)]	Loss: -2.5677	Cost: 12.35s
Train Epoch: 1021 	Average Loss: -2.5678
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9973

Learning rate: 9.744985711111445e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1022 [0/90000 (0%)]	Loss: 1.2197	Cost: 32.00s
Train Epoch: 1022 [20480/90000 (23%)]	Loss: -2.7219	Cost: 12.57s
Train Epoch: 1022 [40960/90000 (45%)]	Loss: -2.8543	Cost: 12.70s
Train Epoch: 1022 [61440/90000 (68%)]	Loss: -3.1195	Cost: 12.34s
Train Epoch: 1022 [81920/90000 (91%)]	Loss: -2.7227	Cost: 12.34s
Train Epoch: 1022 	Average Loss: -2.5093
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0291

Learning rate: 9.744490228960119e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1023 [0/90000 (0%)]	Loss: 1.3739	Cost: 25.59s
Train Epoch: 1023 [20480/90000 (23%)]	Loss: -2.9533	Cost: 12.55s
Train Epoch: 1023 [40960/90000 (45%)]	Loss: -3.1359	Cost: 12.20s
Train Epoch: 1023 [61440/90000 (68%)]	Loss: -2.9975	Cost: 7.06s
Train Epoch: 1023 [81920/90000 (91%)]	Loss: -2.7257	Cost: 7.05s
Train Epoch: 1023 	Average Loss: -2.6314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9229

Learning rate: 9.743994278546379e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1024 [0/90000 (0%)]	Loss: 0.7589	Cost: 21.19s
Train Epoch: 1024 [20480/90000 (23%)]	Loss: -2.7014	Cost: 6.80s
Train Epoch: 1024 [40960/90000 (45%)]	Loss: -2.7725	Cost: 9.41s
Train Epoch: 1024 [61440/90000 (68%)]	Loss: -2.8704	Cost: 9.14s
Train Epoch: 1024 [81920/90000 (91%)]	Loss: -2.5545	Cost: 8.91s
Train Epoch: 1024 	Average Loss: -2.5015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9851

Learning rate: 9.743497859919177e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1025 [0/90000 (0%)]	Loss: 0.8954	Cost: 28.77s
Train Epoch: 1025 [20480/90000 (23%)]	Loss: -2.8412	Cost: 8.86s
Train Epoch: 1025 [40960/90000 (45%)]	Loss: -2.8617	Cost: 7.70s
Train Epoch: 1025 [61440/90000 (68%)]	Loss: -2.8918	Cost: 6.08s
Train Epoch: 1025 [81920/90000 (91%)]	Loss: -2.4258	Cost: 6.64s
Train Epoch: 1025 	Average Loss: -2.5064
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1963

Learning rate: 9.743000973127504e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1026 [0/90000 (0%)]	Loss: 1.6912	Cost: 22.36s
Train Epoch: 1026 [20480/90000 (23%)]	Loss: -2.0154	Cost: 9.50s
Train Epoch: 1026 [40960/90000 (45%)]	Loss: -2.1534	Cost: 11.81s
Train Epoch: 1026 [61440/90000 (68%)]	Loss: -1.9767	Cost: 11.63s
Train Epoch: 1026 [81920/90000 (91%)]	Loss: -2.0144	Cost: 12.36s
Train Epoch: 1026 	Average Loss: -1.8762
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4736

Learning rate: 9.742503618220404e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1027 [0/90000 (0%)]	Loss: 1.3326	Cost: 23.62s
Train Epoch: 1027 [20480/90000 (23%)]	Loss: -2.3741	Cost: 8.90s
Train Epoch: 1027 [40960/90000 (45%)]	Loss: -2.4352	Cost: 14.10s
Train Epoch: 1027 [61440/90000 (68%)]	Loss: -2.7596	Cost: 12.70s
Train Epoch: 1027 [81920/90000 (91%)]	Loss: -2.2761	Cost: 12.20s
Train Epoch: 1027 	Average Loss: -2.1885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0696

Learning rate: 9.742005795246962e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1028 [0/90000 (0%)]	Loss: 1.2855	Cost: 30.79s
Train Epoch: 1028 [20480/90000 (23%)]	Loss: -2.6448	Cost: 12.39s
Train Epoch: 1028 [40960/90000 (45%)]	Loss: -2.8227	Cost: 13.35s
Train Epoch: 1028 [61440/90000 (68%)]	Loss: -2.9345	Cost: 12.56s
Train Epoch: 1028 [81920/90000 (91%)]	Loss: -2.6466	Cost: 7.64s
Train Epoch: 1028 	Average Loss: -2.4526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8279

Saving model as e1028_model.pt & e1028_waveforms_supplementary.hdf5
Learning rate: 9.74150750425631e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1029 [0/90000 (0%)]	Loss: 1.2188	Cost: 25.72s
Train Epoch: 1029 [20480/90000 (23%)]	Loss: -2.9586	Cost: 9.44s
Train Epoch: 1029 [40960/90000 (45%)]	Loss: -3.0265	Cost: 11.06s
Train Epoch: 1029 [61440/90000 (68%)]	Loss: -2.8926	Cost: 6.22s
Train Epoch: 1029 [81920/90000 (91%)]	Loss: -2.7503	Cost: 6.46s
Train Epoch: 1029 	Average Loss: -2.5693
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9119

Learning rate: 9.741008745297627e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1030 [0/90000 (0%)]	Loss: 1.1142	Cost: 21.90s
Train Epoch: 1030 [20480/90000 (23%)]	Loss: -2.8105	Cost: 8.69s
Train Epoch: 1030 [40960/90000 (45%)]	Loss: -2.9480	Cost: 9.38s
Train Epoch: 1030 [61440/90000 (68%)]	Loss: -3.0748	Cost: 8.80s
Train Epoch: 1030 [81920/90000 (91%)]	Loss: -2.6816	Cost: 8.76s
Train Epoch: 1030 	Average Loss: -2.6499
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8818

Learning rate: 9.740509518420142e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1031 [0/90000 (0%)]	Loss: 0.8060	Cost: 26.69s
Train Epoch: 1031 [20480/90000 (23%)]	Loss: -2.9837	Cost: 7.67s
Train Epoch: 1031 [40960/90000 (45%)]	Loss: -3.1117	Cost: 8.89s
Train Epoch: 1031 [61440/90000 (68%)]	Loss: -3.1380	Cost: 8.55s
Train Epoch: 1031 [81920/90000 (91%)]	Loss: -3.0312	Cost: 8.60s
Train Epoch: 1031 	Average Loss: -2.7326
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7799

Saving model as e1031_model.pt & e1031_waveforms_supplementary.hdf5
Learning rate: 9.740009823673125e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1032 [0/90000 (0%)]	Loss: 1.2575	Cost: 23.50s
Train Epoch: 1032 [20480/90000 (23%)]	Loss: -3.1839	Cost: 9.19s
Train Epoch: 1032 [40960/90000 (45%)]	Loss: -2.9776	Cost: 6.53s
Train Epoch: 1032 [61440/90000 (68%)]	Loss: -2.7325	Cost: 6.57s
Train Epoch: 1032 [81920/90000 (91%)]	Loss: -2.5662	Cost: 7.70s
Train Epoch: 1032 	Average Loss: -2.5839
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0046

Learning rate: 9.739509661105893e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1033 [0/90000 (0%)]	Loss: 1.1511	Cost: 21.67s
Train Epoch: 1033 [20480/90000 (23%)]	Loss: -2.6917	Cost: 9.28s
Train Epoch: 1033 [40960/90000 (45%)]	Loss: -2.7572	Cost: 18.31s
Train Epoch: 1033 [61440/90000 (68%)]	Loss: -2.9031	Cost: 13.89s
Train Epoch: 1033 [81920/90000 (91%)]	Loss: -2.7483	Cost: 12.62s
Train Epoch: 1033 	Average Loss: -2.5476
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8086

Learning rate: 9.739009030767811e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1034 [0/90000 (0%)]	Loss: 1.1970	Cost: 24.33s
Train Epoch: 1034 [20480/90000 (23%)]	Loss: -2.8716	Cost: 14.26s
Train Epoch: 1034 [40960/90000 (45%)]	Loss: -3.0099	Cost: 13.79s
Train Epoch: 1034 [61440/90000 (68%)]	Loss: -3.0922	Cost: 12.48s
Train Epoch: 1034 [81920/90000 (91%)]	Loss: -3.0098	Cost: 8.43s
Train Epoch: 1034 	Average Loss: -2.6859
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8163

Learning rate: 9.73850793270829e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1035 [0/90000 (0%)]	Loss: 0.7351	Cost: 29.85s
Train Epoch: 1035 [20480/90000 (23%)]	Loss: -2.5631	Cost: 13.28s
Train Epoch: 1035 [40960/90000 (45%)]	Loss: -2.3585	Cost: 10.88s
Train Epoch: 1035 [61440/90000 (68%)]	Loss: -2.5787	Cost: 6.10s
Train Epoch: 1035 [81920/90000 (91%)]	Loss: -2.3789	Cost: 7.54s
Train Epoch: 1035 	Average Loss: -2.3316
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0169

Learning rate: 9.738006366976783e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1036 [0/90000 (0%)]	Loss: 0.5531	Cost: 28.67s
Train Epoch: 1036 [20480/90000 (23%)]	Loss: -2.6760	Cost: 6.47s
Train Epoch: 1036 [40960/90000 (45%)]	Loss: -2.6766	Cost: 9.90s
Train Epoch: 1036 [61440/90000 (68%)]	Loss: -2.9885	Cost: 8.83s
Train Epoch: 1036 [81920/90000 (91%)]	Loss: -2.8017	Cost: 8.81s
Train Epoch: 1036 	Average Loss: -2.5205
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9329

Learning rate: 9.737504333622795e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1037 [0/90000 (0%)]	Loss: 0.8228	Cost: 24.40s
Train Epoch: 1037 [20480/90000 (23%)]	Loss: -2.9520	Cost: 7.19s
Train Epoch: 1037 [40960/90000 (45%)]	Loss: -2.8903	Cost: 9.04s
Train Epoch: 1037 [61440/90000 (68%)]	Loss: -2.9677	Cost: 8.57s
Train Epoch: 1037 [81920/90000 (91%)]	Loss: -2.6719	Cost: 8.41s
Train Epoch: 1037 	Average Loss: -2.6818
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0008

Learning rate: 9.737001832695876e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1038 [0/90000 (0%)]	Loss: 1.5152	Cost: 23.14s
Train Epoch: 1038 [20480/90000 (23%)]	Loss: -2.8812	Cost: 11.06s
Train Epoch: 1038 [40960/90000 (45%)]	Loss: -2.9660	Cost: 10.90s
Train Epoch: 1038 [61440/90000 (68%)]	Loss: -2.9277	Cost: 6.87s
Train Epoch: 1038 [81920/90000 (91%)]	Loss: -2.8774	Cost: 9.06s
Train Epoch: 1038 	Average Loss: -2.5978
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7609

Saving model as e1038_model.pt & e1038_waveforms_supplementary.hdf5
Learning rate: 9.73649886424562e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1039 [0/90000 (0%)]	Loss: 1.4372	Cost: 20.95s
Train Epoch: 1039 [20480/90000 (23%)]	Loss: -3.2268	Cost: 10.30s
Train Epoch: 1039 [40960/90000 (45%)]	Loss: -3.2734	Cost: 16.37s
Train Epoch: 1039 [61440/90000 (68%)]	Loss: -3.0766	Cost: 13.93s
Train Epoch: 1039 [81920/90000 (91%)]	Loss: -2.8831	Cost: 12.41s
Train Epoch: 1039 	Average Loss: -2.8166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7523

Saving model as e1039_model.pt & e1039_waveforms_supplementary.hdf5
Learning rate: 9.735995428321667e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1040 [0/90000 (0%)]	Loss: 0.5764	Cost: 31.81s
Train Epoch: 1040 [20480/90000 (23%)]	Loss: -3.1135	Cost: 12.58s
Train Epoch: 1040 [40960/90000 (45%)]	Loss: -3.0567	Cost: 12.58s
Train Epoch: 1040 [61440/90000 (68%)]	Loss: -3.0584	Cost: 12.35s
Train Epoch: 1040 [81920/90000 (91%)]	Loss: -2.9954	Cost: 10.49s
Train Epoch: 1040 	Average Loss: -2.7819
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6967

Saving model as e1040_model.pt & e1040_waveforms_supplementary.hdf5
Learning rate: 9.735491524973705e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1041 [0/90000 (0%)]	Loss: 0.4626	Cost: 23.40s
Train Epoch: 1041 [20480/90000 (23%)]	Loss: -2.9981	Cost: 9.00s
Train Epoch: 1041 [40960/90000 (45%)]	Loss: -2.9589	Cost: 11.21s
Train Epoch: 1041 [61440/90000 (68%)]	Loss: -3.1178	Cost: 6.62s
Train Epoch: 1041 [81920/90000 (91%)]	Loss: -2.8436	Cost: 6.59s
Train Epoch: 1041 	Average Loss: -2.7392
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8716

Learning rate: 9.734987154251465e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1042 [0/90000 (0%)]	Loss: 0.4420	Cost: 23.14s
Train Epoch: 1042 [20480/90000 (23%)]	Loss: -3.0598	Cost: 6.63s
Train Epoch: 1042 [40960/90000 (45%)]	Loss: -3.1748	Cost: 10.47s
Train Epoch: 1042 [61440/90000 (68%)]	Loss: -3.3141	Cost: 9.13s
Train Epoch: 1042 [81920/90000 (91%)]	Loss: -2.9136	Cost: 8.86s
Train Epoch: 1042 	Average Loss: -2.8445
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8211

Learning rate: 9.73448231620473e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1043 [0/90000 (0%)]	Loss: 1.5967	Cost: 33.14s
Train Epoch: 1043 [20480/90000 (23%)]	Loss: -2.9310	Cost: 8.84s
Train Epoch: 1043 [40960/90000 (45%)]	Loss: -3.3495	Cost: 8.97s
Train Epoch: 1043 [61440/90000 (68%)]	Loss: -3.0943	Cost: 7.88s
Train Epoch: 1043 [81920/90000 (91%)]	Loss: -2.8518	Cost: 5.99s
Train Epoch: 1043 	Average Loss: -2.7353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8203

Learning rate: 9.733977010883324e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1044 [0/90000 (0%)]	Loss: 1.0868	Cost: 31.51s
Train Epoch: 1044 [20480/90000 (23%)]	Loss: -3.0684	Cost: 6.89s
Train Epoch: 1044 [40960/90000 (45%)]	Loss: -3.0509	Cost: 12.72s
Train Epoch: 1044 [61440/90000 (68%)]	Loss: -3.1191	Cost: 12.56s
Train Epoch: 1044 [81920/90000 (91%)]	Loss: -2.9024	Cost: 12.35s
Train Epoch: 1044 	Average Loss: -2.7604
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7122

Learning rate: 9.733471238337118e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1045 [0/90000 (0%)]	Loss: 0.5673	Cost: 23.90s
Train Epoch: 1045 [20480/90000 (23%)]	Loss: -3.1266	Cost: 13.87s
Train Epoch: 1045 [40960/90000 (45%)]	Loss: -3.1255	Cost: 13.65s
Train Epoch: 1045 [61440/90000 (68%)]	Loss: -3.2375	Cost: 12.74s
Train Epoch: 1045 [81920/90000 (91%)]	Loss: -2.9494	Cost: 12.46s
Train Epoch: 1045 	Average Loss: -2.8192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8139

Learning rate: 9.732964998616029e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1046 [0/90000 (0%)]	Loss: 0.7038	Cost: 23.19s
Train Epoch: 1046 [20480/90000 (23%)]	Loss: -3.1402	Cost: 13.08s
Train Epoch: 1046 [40960/90000 (45%)]	Loss: -3.2331	Cost: 13.87s
Train Epoch: 1046 [61440/90000 (68%)]	Loss: -3.0992	Cost: 12.11s
Train Epoch: 1046 [81920/90000 (91%)]	Loss: -2.8653	Cost: 6.40s
Train Epoch: 1046 	Average Loss: -2.7958
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8394

Learning rate: 9.732458291770023e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1047 [0/90000 (0%)]	Loss: 0.7331	Cost: 28.12s
Train Epoch: 1047 [20480/90000 (23%)]	Loss: -3.0336	Cost: 9.51s
Train Epoch: 1047 [40960/90000 (45%)]	Loss: -3.0186	Cost: 11.24s
Train Epoch: 1047 [61440/90000 (68%)]	Loss: -3.3040	Cost: 6.23s
Train Epoch: 1047 [81920/90000 (91%)]	Loss: -2.8509	Cost: 6.90s
Train Epoch: 1047 	Average Loss: -2.8645
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7517

Learning rate: 9.731951117849109e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1048 [0/90000 (0%)]	Loss: 0.5071	Cost: 25.85s
Train Epoch: 1048 [20480/90000 (23%)]	Loss: -3.2556	Cost: 12.55s
Train Epoch: 1048 [40960/90000 (45%)]	Loss: -3.0852	Cost: 7.52s
Train Epoch: 1048 [61440/90000 (68%)]	Loss: -3.1205	Cost: 6.39s
Train Epoch: 1048 [81920/90000 (91%)]	Loss: -3.0775	Cost: 7.99s
Train Epoch: 1048 	Average Loss: -2.8538
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6241

Saving model as e1048_model.pt & e1048_waveforms_supplementary.hdf5
Learning rate: 9.731443476903343e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1049 [0/90000 (0%)]	Loss: 1.1785	Cost: 23.25s
Train Epoch: 1049 [20480/90000 (23%)]	Loss: -2.9940	Cost: 11.49s
Train Epoch: 1049 [40960/90000 (45%)]	Loss: -3.2602	Cost: 9.50s
Train Epoch: 1049 [61440/90000 (68%)]	Loss: -3.3712	Cost: 8.73s
Train Epoch: 1049 [81920/90000 (91%)]	Loss: -3.1340	Cost: 8.80s
Train Epoch: 1049 	Average Loss: -2.9076
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5620

Saving model as e1049_model.pt & e1049_waveforms_supplementary.hdf5
Learning rate: 9.730935368982828e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1050 [0/90000 (0%)]	Loss: 0.3875	Cost: 21.11s
Train Epoch: 1050 [20480/90000 (23%)]	Loss: -3.0465	Cost: 8.98s
Train Epoch: 1050 [40960/90000 (45%)]	Loss: -3.0316	Cost: 8.92s
Train Epoch: 1050 [61440/90000 (68%)]	Loss: -2.9807	Cost: 8.28s
Train Epoch: 1050 [81920/90000 (91%)]	Loss: -2.9836	Cost: 6.10s
Train Epoch: 1050 	Average Loss: -2.8623
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6973

Learning rate: 9.730426794137711e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1051 [0/90000 (0%)]	Loss: 0.6449	Cost: 21.46s
Train Epoch: 1051 [20480/90000 (23%)]	Loss: -2.7376	Cost: 7.41s
Train Epoch: 1051 [40960/90000 (45%)]	Loss: -2.9280	Cost: 10.40s
Train Epoch: 1051 [61440/90000 (68%)]	Loss: -3.1195	Cost: 12.91s
Train Epoch: 1051 [81920/90000 (91%)]	Loss: -2.9753	Cost: 13.48s
Train Epoch: 1051 	Average Loss: -2.7775
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6205

Learning rate: 9.729917752418187e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1052 [0/90000 (0%)]	Loss: 0.8834	Cost: 22.83s
Train Epoch: 1052 [20480/90000 (23%)]	Loss: -3.2311	Cost: 14.93s
Train Epoch: 1052 [40960/90000 (45%)]	Loss: -3.3535	Cost: 14.03s
Train Epoch: 1052 [61440/90000 (68%)]	Loss: -3.3473	Cost: 12.22s
Train Epoch: 1052 [81920/90000 (91%)]	Loss: -2.7491	Cost: 12.19s
Train Epoch: 1052 	Average Loss: -2.9011
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0026

Learning rate: 9.729408243874495e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1053 [0/90000 (0%)]	Loss: 1.0855	Cost: 40.66s
Train Epoch: 1053 [20480/90000 (23%)]	Loss: -2.7759	Cost: 12.21s
Train Epoch: 1053 [40960/90000 (45%)]	Loss: -3.1448	Cost: 8.41s
Train Epoch: 1053 [61440/90000 (68%)]	Loss: -3.2686	Cost: 6.31s
Train Epoch: 1053 [81920/90000 (91%)]	Loss: -3.1073	Cost: 7.28s
Train Epoch: 1053 	Average Loss: -2.6903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6280

Learning rate: 9.728898268556922e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1054 [0/90000 (0%)]	Loss: 0.3988	Cost: 27.31s
Train Epoch: 1054 [20480/90000 (23%)]	Loss: -3.2413	Cost: 12.73s
Train Epoch: 1054 [40960/90000 (45%)]	Loss: -3.3585	Cost: 7.18s
Train Epoch: 1054 [61440/90000 (68%)]	Loss: -3.2847	Cost: 6.33s
Train Epoch: 1054 [81920/90000 (91%)]	Loss: -3.2359	Cost: 7.68s
Train Epoch: 1054 	Average Loss: -2.9807
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5421

Saving model as e1054_model.pt & e1054_waveforms_supplementary.hdf5
Learning rate: 9.728387826515802e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1055 [0/90000 (0%)]	Loss: 1.1219	Cost: 28.35s
Train Epoch: 1055 [20480/90000 (23%)]	Loss: -3.2536	Cost: 6.47s
Train Epoch: 1055 [40960/90000 (45%)]	Loss: -3.1879	Cost: 8.49s
Train Epoch: 1055 [61440/90000 (68%)]	Loss: -3.3308	Cost: 8.97s
Train Epoch: 1055 [81920/90000 (91%)]	Loss: -3.2553	Cost: 8.74s
Train Epoch: 1055 	Average Loss: -2.9742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5250

Saving model as e1055_model.pt & e1055_waveforms_supplementary.hdf5
Learning rate: 9.727876917801514e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1056 [0/90000 (0%)]	Loss: 0.7067	Cost: 22.44s
Train Epoch: 1056 [20480/90000 (23%)]	Loss: -3.3773	Cost: 8.92s
Train Epoch: 1056 [40960/90000 (45%)]	Loss: -3.5624	Cost: 6.35s
Train Epoch: 1056 [61440/90000 (68%)]	Loss: -3.5137	Cost: 7.68s
Train Epoch: 1056 [81920/90000 (91%)]	Loss: -3.1407	Cost: 7.73s
Train Epoch: 1056 	Average Loss: -3.0781
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5699

Learning rate: 9.727365542464482e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1057 [0/90000 (0%)]	Loss: 1.0293	Cost: 18.73s
Train Epoch: 1057 [20480/90000 (23%)]	Loss: -3.3480	Cost: 7.69s
Train Epoch: 1057 [40960/90000 (45%)]	Loss: -3.3480	Cost: 13.44s
Train Epoch: 1057 [61440/90000 (68%)]	Loss: -3.3953	Cost: 13.68s
Train Epoch: 1057 [81920/90000 (91%)]	Loss: -3.2918	Cost: 12.35s
Train Epoch: 1057 	Average Loss: -3.0132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7109

Learning rate: 9.726853700555175e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1058 [0/90000 (0%)]	Loss: 0.9732	Cost: 44.86s
Train Epoch: 1058 [20480/90000 (23%)]	Loss: -3.3283	Cost: 12.82s
Train Epoch: 1058 [40960/90000 (45%)]	Loss: -3.3479	Cost: 12.50s
Train Epoch: 1058 [61440/90000 (68%)]	Loss: -3.5050	Cost: 12.32s
Train Epoch: 1058 [81920/90000 (91%)]	Loss: -3.2340	Cost: 6.38s
Train Epoch: 1058 	Average Loss: -3.0589
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6023

Learning rate: 9.726341392124111e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1059 [0/90000 (0%)]	Loss: 0.7585	Cost: 29.26s
Train Epoch: 1059 [20480/90000 (23%)]	Loss: -3.2274	Cost: 12.57s
Train Epoch: 1059 [40960/90000 (45%)]	Loss: -3.5434	Cost: 7.38s
Train Epoch: 1059 [61440/90000 (68%)]	Loss: -3.5775	Cost: 6.28s
Train Epoch: 1059 [81920/90000 (91%)]	Loss: -3.2343	Cost: 7.69s
Train Epoch: 1059 	Average Loss: -3.0869
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4538

Saving model as e1059_model.pt & e1059_waveforms_supplementary.hdf5
Learning rate: 9.725828617221853e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1060 [0/90000 (0%)]	Loss: 0.7309	Cost: 22.30s
Train Epoch: 1060 [20480/90000 (23%)]	Loss: -3.3420	Cost: 8.10s
Train Epoch: 1060 [40960/90000 (45%)]	Loss: -3.2630	Cost: 8.90s
Train Epoch: 1060 [61440/90000 (68%)]	Loss: -3.4445	Cost: 9.40s
Train Epoch: 1060 [81920/90000 (91%)]	Loss: -3.1146	Cost: 9.07s
Train Epoch: 1060 	Average Loss: -3.0398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5937

Learning rate: 9.725315375899009e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1061 [0/90000 (0%)]	Loss: 0.9960	Cost: 22.18s
Train Epoch: 1061 [20480/90000 (23%)]	Loss: -3.2898	Cost: 11.39s
Train Epoch: 1061 [40960/90000 (45%)]	Loss: -3.3414	Cost: 12.33s
Train Epoch: 1061 [61440/90000 (68%)]	Loss: -3.5346	Cost: 13.16s
Train Epoch: 1061 [81920/90000 (91%)]	Loss: -3.1568	Cost: 12.55s
Train Epoch: 1061 	Average Loss: -2.9934
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6093

Learning rate: 9.724801668206235e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1062 [0/90000 (0%)]	Loss: 0.7484	Cost: 35.03s
Train Epoch: 1062 [20480/90000 (23%)]	Loss: -3.4629	Cost: 13.40s
Train Epoch: 1062 [40960/90000 (45%)]	Loss: -3.4274	Cost: 12.59s
Train Epoch: 1062 [61440/90000 (68%)]	Loss: -3.3556	Cost: 12.13s
Train Epoch: 1062 [81920/90000 (91%)]	Loss: -3.1817	Cost: 12.29s
Train Epoch: 1062 	Average Loss: -3.0679
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5087

Learning rate: 9.72428749419423e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1063 [0/90000 (0%)]	Loss: 0.8490	Cost: 22.98s
Train Epoch: 1063 [20480/90000 (23%)]	Loss: -3.3488	Cost: 13.50s
Train Epoch: 1063 [40960/90000 (45%)]	Loss: -3.5542	Cost: 12.31s
Train Epoch: 1063 [61440/90000 (68%)]	Loss: -3.5573	Cost: 11.43s
Train Epoch: 1063 [81920/90000 (91%)]	Loss: -3.2407	Cost: 6.35s
Train Epoch: 1063 	Average Loss: -3.1435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5356

Learning rate: 9.723772853913744e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1064 [0/90000 (0%)]	Loss: 1.1525	Cost: 27.32s
Train Epoch: 1064 [20480/90000 (23%)]	Loss: -3.1399	Cost: 11.50s
Train Epoch: 1064 [40960/90000 (45%)]	Loss: -3.2811	Cost: 6.63s
Train Epoch: 1064 [61440/90000 (68%)]	Loss: -3.4897	Cost: 6.86s
Train Epoch: 1064 [81920/90000 (91%)]	Loss: -3.1678	Cost: 8.28s
Train Epoch: 1064 	Average Loss: -3.0380
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5093

Learning rate: 9.723257747415567e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1065 [0/90000 (0%)]	Loss: 0.6058	Cost: 26.45s
Train Epoch: 1065 [20480/90000 (23%)]	Loss: -3.5505	Cost: 10.05s
Train Epoch: 1065 [40960/90000 (45%)]	Loss: -3.6060	Cost: 10.56s
Train Epoch: 1065 [61440/90000 (68%)]	Loss: -3.4589	Cost: 8.97s
Train Epoch: 1065 [81920/90000 (91%)]	Loss: -3.3634	Cost: 8.67s
Train Epoch: 1065 	Average Loss: -3.1974
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4842

Learning rate: 9.722742174750542e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1066 [0/90000 (0%)]	Loss: 0.1844	Cost: 23.61s
Train Epoch: 1066 [20480/90000 (23%)]	Loss: -3.4971	Cost: 12.18s
Train Epoch: 1066 [40960/90000 (45%)]	Loss: -3.5259	Cost: 12.24s
Train Epoch: 1066 [61440/90000 (68%)]	Loss: -3.1732	Cost: 8.90s
Train Epoch: 1066 [81920/90000 (91%)]	Loss: -2.8291	Cost: 6.43s
Train Epoch: 1066 	Average Loss: -2.9734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8876

Learning rate: 9.722226135969548e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1067 [0/90000 (0%)]	Loss: 0.7031	Cost: 22.42s
Train Epoch: 1067 [20480/90000 (23%)]	Loss: -2.9267	Cost: 6.49s
Train Epoch: 1067 [40960/90000 (45%)]	Loss: -3.1757	Cost: 10.69s
Train Epoch: 1067 [61440/90000 (68%)]	Loss: -3.1763	Cost: 12.27s
Train Epoch: 1067 [81920/90000 (91%)]	Loss: -3.0941	Cost: 12.46s
Train Epoch: 1067 	Average Loss: -2.7721
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7257

Learning rate: 9.72170963112352e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1068 [0/90000 (0%)]	Loss: 1.0141	Cost: 23.60s
Train Epoch: 1068 [20480/90000 (23%)]	Loss: -3.3579	Cost: 10.98s
Train Epoch: 1068 [40960/90000 (45%)]	Loss: -3.3413	Cost: 12.61s
Train Epoch: 1068 [61440/90000 (68%)]	Loss: -3.5400	Cost: 12.23s
Train Epoch: 1068 [81920/90000 (91%)]	Loss: -3.2316	Cost: 12.29s
Train Epoch: 1068 	Average Loss: -3.0515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4985

Learning rate: 9.721192660263436e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1069 [0/90000 (0%)]	Loss: 0.6316	Cost: 28.71s
Train Epoch: 1069 [20480/90000 (23%)]	Loss: -3.3350	Cost: 14.17s
Train Epoch: 1069 [40960/90000 (45%)]	Loss: -3.3622	Cost: 13.27s
Train Epoch: 1069 [61440/90000 (68%)]	Loss: -3.6288	Cost: 12.26s
Train Epoch: 1069 [81920/90000 (91%)]	Loss: -3.4133	Cost: 8.36s
Train Epoch: 1069 	Average Loss: -3.1388
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4281

Saving model as e1069_model.pt & e1069_waveforms_supplementary.hdf5
Learning rate: 9.720675223440316e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1070 [0/90000 (0%)]	Loss: 0.0520	Cost: 39.71s
Train Epoch: 1070 [20480/90000 (23%)]	Loss: -3.3204	Cost: 12.07s
Train Epoch: 1070 [40960/90000 (45%)]	Loss: -3.3532	Cost: 6.84s
Train Epoch: 1070 [61440/90000 (68%)]	Loss: -3.4986	Cost: 6.37s
Train Epoch: 1070 [81920/90000 (91%)]	Loss: -3.3027	Cost: 8.20s
Train Epoch: 1070 	Average Loss: -3.1599
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5852

Learning rate: 9.720157320705232e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1071 [0/90000 (0%)]	Loss: 0.9054	Cost: 32.42s
Train Epoch: 1071 [20480/90000 (23%)]	Loss: -3.3234	Cost: 9.23s
Train Epoch: 1071 [40960/90000 (45%)]	Loss: -3.5474	Cost: 6.86s
Train Epoch: 1071 [61440/90000 (68%)]	Loss: -3.5797	Cost: 8.17s
Train Epoch: 1071 [81920/90000 (91%)]	Loss: -3.3703	Cost: 8.81s
Train Epoch: 1071 	Average Loss: -3.1894
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4137

Saving model as e1071_model.pt & e1071_waveforms_supplementary.hdf5
Learning rate: 9.719638952109295e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1072 [0/90000 (0%)]	Loss: 0.6624	Cost: 23.17s
Train Epoch: 1072 [20480/90000 (23%)]	Loss: -3.6239	Cost: 8.93s
Train Epoch: 1072 [40960/90000 (45%)]	Loss: -3.4065	Cost: 9.14s
Train Epoch: 1072 [61440/90000 (68%)]	Loss: -3.8006	Cost: 8.74s
Train Epoch: 1072 [81920/90000 (91%)]	Loss: -3.2688	Cost: 9.21s
Train Epoch: 1072 	Average Loss: -3.2140
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5081

Learning rate: 9.719120117703668e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1073 [0/90000 (0%)]	Loss: 0.9730	Cost: 20.47s
Train Epoch: 1073 [20480/90000 (23%)]	Loss: -3.2374	Cost: 8.17s
Train Epoch: 1073 [40960/90000 (45%)]	Loss: -3.2649	Cost: 7.89s
Train Epoch: 1073 [61440/90000 (68%)]	Loss: -3.3492	Cost: 10.66s
Train Epoch: 1073 [81920/90000 (91%)]	Loss: -3.3595	Cost: 12.40s
Train Epoch: 1073 	Average Loss: -3.0076
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4234

Learning rate: 9.71860081753956e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1074 [0/90000 (0%)]	Loss: 0.7264	Cost: 22.95s
Train Epoch: 1074 [20480/90000 (23%)]	Loss: -3.2734	Cost: 9.04s
Train Epoch: 1074 [40960/90000 (45%)]	Loss: -3.4159	Cost: 15.32s
Train Epoch: 1074 [61440/90000 (68%)]	Loss: -3.6426	Cost: 12.77s
Train Epoch: 1074 [81920/90000 (91%)]	Loss: -3.2984	Cost: 12.14s
Train Epoch: 1074 	Average Loss: -3.1244
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4559

Learning rate: 9.71808105166822e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1075 [0/90000 (0%)]	Loss: 0.5526	Cost: 39.00s
Train Epoch: 1075 [20480/90000 (23%)]	Loss: -3.5187	Cost: 11.19s
Train Epoch: 1075 [40960/90000 (45%)]	Loss: -3.4860	Cost: 12.24s
Train Epoch: 1075 [61440/90000 (68%)]	Loss: -3.5057	Cost: 11.74s
Train Epoch: 1075 [81920/90000 (91%)]	Loss: -3.2814	Cost: 7.23s
Train Epoch: 1075 	Average Loss: -3.1930
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7054

Learning rate: 9.71756082014095e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1076 [0/90000 (0%)]	Loss: 0.7440	Cost: 25.38s
Train Epoch: 1076 [20480/90000 (23%)]	Loss: -3.1765	Cost: 12.43s
Train Epoch: 1076 [40960/90000 (45%)]	Loss: -3.0951	Cost: 10.87s
Train Epoch: 1076 [61440/90000 (68%)]	Loss: -3.5488	Cost: 6.15s
Train Epoch: 1076 [81920/90000 (91%)]	Loss: -3.3279	Cost: 6.72s
Train Epoch: 1076 	Average Loss: -2.9522
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4577

Learning rate: 9.717040123009093e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1077 [0/90000 (0%)]	Loss: 0.5100	Cost: 27.42s
Train Epoch: 1077 [20480/90000 (23%)]	Loss: -3.3750	Cost: 6.90s
Train Epoch: 1077 [40960/90000 (45%)]	Loss: -3.4241	Cost: 10.98s
Train Epoch: 1077 [61440/90000 (68%)]	Loss: -3.7187	Cost: 9.31s
Train Epoch: 1077 [81920/90000 (91%)]	Loss: -3.5780	Cost: 9.00s
Train Epoch: 1077 	Average Loss: -3.2098
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2203

Saving model as e1077_model.pt & e1077_waveforms_supplementary.hdf5
Learning rate: 9.716518960324041e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1078 [0/90000 (0%)]	Loss: 0.1039	Cost: 33.63s
Train Epoch: 1078 [20480/90000 (23%)]	Loss: -3.6039	Cost: 8.88s
Train Epoch: 1078 [40960/90000 (45%)]	Loss: -3.5357	Cost: 9.45s
Train Epoch: 1078 [61440/90000 (68%)]	Loss: -3.8617	Cost: 9.28s
Train Epoch: 1078 [81920/90000 (91%)]	Loss: -3.4952	Cost: 12.62s
Train Epoch: 1078 	Average Loss: -3.3297
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3684

Learning rate: 9.71599733213723e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1079 [0/90000 (0%)]	Loss: 0.7480	Cost: 22.10s
Train Epoch: 1079 [20480/90000 (23%)]	Loss: -3.5776	Cost: 10.09s
Train Epoch: 1079 [40960/90000 (45%)]	Loss: -3.8080	Cost: 12.44s
Train Epoch: 1079 [61440/90000 (68%)]	Loss: -3.7759	Cost: 12.55s
Train Epoch: 1079 [81920/90000 (91%)]	Loss: -3.6649	Cost: 12.44s
Train Epoch: 1079 	Average Loss: -3.3680
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2270

Learning rate: 9.71547523850014e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1080 [0/90000 (0%)]	Loss: 0.2725	Cost: 24.08s
Train Epoch: 1080 [20480/90000 (23%)]	Loss: -3.6809	Cost: 13.55s
Train Epoch: 1080 [40960/90000 (45%)]	Loss: -3.7503	Cost: 12.50s
Train Epoch: 1080 [61440/90000 (68%)]	Loss: -3.9642	Cost: 12.10s
Train Epoch: 1080 [81920/90000 (91%)]	Loss: -3.3352	Cost: 11.13s
Train Epoch: 1080 	Average Loss: -3.3575
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5620

Learning rate: 9.714952679464304e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1081 [0/90000 (0%)]	Loss: 0.8851	Cost: 27.07s
Train Epoch: 1081 [20480/90000 (23%)]	Loss: -3.2431	Cost: 11.25s
Train Epoch: 1081 [40960/90000 (45%)]	Loss: -3.3643	Cost: 7.01s
Train Epoch: 1081 [61440/90000 (68%)]	Loss: -3.3233	Cost: 6.44s
Train Epoch: 1081 [81920/90000 (91%)]	Loss: -3.1925	Cost: 8.79s
Train Epoch: 1081 	Average Loss: -2.9901
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6749

Learning rate: 9.714429655081295e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1082 [0/90000 (0%)]	Loss: 0.8051	Cost: 22.92s
Train Epoch: 1082 [20480/90000 (23%)]	Loss: -3.3836	Cost: 9.07s
Train Epoch: 1082 [40960/90000 (45%)]	Loss: -3.7475	Cost: 8.16s
Train Epoch: 1082 [61440/90000 (68%)]	Loss: -3.7505	Cost: 8.88s
Train Epoch: 1082 [81920/90000 (91%)]	Loss: -3.5029	Cost: 8.78s
Train Epoch: 1082 	Average Loss: -3.2414
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4196

Learning rate: 9.713906165402731e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1083 [0/90000 (0%)]	Loss: 0.1335	Cost: 24.98s
Train Epoch: 1083 [20480/90000 (23%)]	Loss: -3.5163	Cost: 8.87s
Train Epoch: 1083 [40960/90000 (45%)]	Loss: -3.6855	Cost: 12.11s
Train Epoch: 1083 [61440/90000 (68%)]	Loss: -3.8888	Cost: 8.88s
Train Epoch: 1083 [81920/90000 (91%)]	Loss: -3.5020	Cost: 8.50s
Train Epoch: 1083 	Average Loss: -3.2443
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2881

Learning rate: 9.713382210480282e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1084 [0/90000 (0%)]	Loss: 0.3323	Cost: 21.90s
Train Epoch: 1084 [20480/90000 (23%)]	Loss: -3.6179	Cost: 9.06s
Train Epoch: 1084 [40960/90000 (45%)]	Loss: -3.5772	Cost: 6.65s
Train Epoch: 1084 [61440/90000 (68%)]	Loss: -3.7769	Cost: 7.80s
Train Epoch: 1084 [81920/90000 (91%)]	Loss: -3.5223	Cost: 6.95s
Train Epoch: 1084 	Average Loss: -3.3375
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3521

Learning rate: 9.712857790365659e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1085 [0/90000 (0%)]	Loss: 0.1360	Cost: 18.49s
Train Epoch: 1085 [20480/90000 (23%)]	Loss: -3.7513	Cost: 7.60s
Train Epoch: 1085 [40960/90000 (45%)]	Loss: -3.8908	Cost: 13.57s
Train Epoch: 1085 [61440/90000 (68%)]	Loss: -3.6610	Cost: 12.56s
Train Epoch: 1085 [81920/90000 (91%)]	Loss: -3.5972	Cost: 12.44s
Train Epoch: 1085 	Average Loss: -3.3659
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3637

Learning rate: 9.712332905110621e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1086 [0/90000 (0%)]	Loss: 0.2503	Cost: 26.47s
Train Epoch: 1086 [20480/90000 (23%)]	Loss: -3.6899	Cost: 12.58s
Train Epoch: 1086 [40960/90000 (45%)]	Loss: -3.7679	Cost: 13.64s
Train Epoch: 1086 [61440/90000 (68%)]	Loss: -3.6770	Cost: 12.26s
Train Epoch: 1086 [81920/90000 (91%)]	Loss: -3.4845	Cost: 12.31s
Train Epoch: 1086 	Average Loss: -3.3958
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3026

Learning rate: 9.711807554766971e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1087 [0/90000 (0%)]	Loss: 0.1797	Cost: 40.83s
Train Epoch: 1087 [20480/90000 (23%)]	Loss: -3.7165	Cost: 13.53s
Train Epoch: 1087 [40960/90000 (45%)]	Loss: -3.6685	Cost: 12.06s
Train Epoch: 1087 [61440/90000 (68%)]	Loss: -3.8749	Cost: 9.45s
Train Epoch: 1087 [81920/90000 (91%)]	Loss: -3.5339	Cost: 6.18s
Train Epoch: 1087 	Average Loss: -3.4663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2840

Learning rate: 9.711281739386558e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1088 [0/90000 (0%)]	Loss: 0.4010	Cost: 29.73s
Train Epoch: 1088 [20480/90000 (23%)]	Loss: -3.5818	Cost: 12.02s
Train Epoch: 1088 [40960/90000 (45%)]	Loss: -3.6878	Cost: 10.27s
Train Epoch: 1088 [61440/90000 (68%)]	Loss: -3.8299	Cost: 6.24s
Train Epoch: 1088 [81920/90000 (91%)]	Loss: -3.4259	Cost: 7.29s
Train Epoch: 1088 	Average Loss: -3.4076
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3943

Learning rate: 9.710755459021279e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1089 [0/90000 (0%)]	Loss: 0.7481	Cost: 32.86s
Train Epoch: 1089 [20480/90000 (23%)]	Loss: -3.4836	Cost: 8.86s
Train Epoch: 1089 [40960/90000 (45%)]	Loss: -3.7567	Cost: 6.38s
Train Epoch: 1089 [61440/90000 (68%)]	Loss: -3.8269	Cost: 6.90s
Train Epoch: 1089 [81920/90000 (91%)]	Loss: -3.6811	Cost: 8.75s
Train Epoch: 1089 	Average Loss: -3.4093
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1848

Saving model as e1089_model.pt & e1089_waveforms_supplementary.hdf5
Learning rate: 9.710228713723075e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1090 [0/90000 (0%)]	Loss: 0.3494	Cost: 21.77s
Train Epoch: 1090 [20480/90000 (23%)]	Loss: -3.7155	Cost: 9.19s
Train Epoch: 1090 [40960/90000 (45%)]	Loss: -3.8126	Cost: 8.94s
Train Epoch: 1090 [61440/90000 (68%)]	Loss: -3.9896	Cost: 8.53s
Train Epoch: 1090 [81920/90000 (91%)]	Loss: -3.5508	Cost: 8.40s
Train Epoch: 1090 	Average Loss: -3.5034
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2103

Learning rate: 9.709701503543935e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1091 [0/90000 (0%)]	Loss: 0.8294	Cost: 22.37s
Train Epoch: 1091 [20480/90000 (23%)]	Loss: -3.8346	Cost: 9.08s
Train Epoch: 1091 [40960/90000 (45%)]	Loss: -3.7862	Cost: 9.24s
Train Epoch: 1091 [61440/90000 (68%)]	Loss: -3.6786	Cost: 8.07s
Train Epoch: 1091 [81920/90000 (91%)]	Loss: -3.5129	Cost: 6.38s
Train Epoch: 1091 	Average Loss: -3.3703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3837

Learning rate: 9.709173828535892e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1092 [0/90000 (0%)]	Loss: 0.5161	Cost: 22.36s
Train Epoch: 1092 [20480/90000 (23%)]	Loss: -3.6096	Cost: 10.37s
Train Epoch: 1092 [40960/90000 (45%)]	Loss: -3.7710	Cost: 10.45s
Train Epoch: 1092 [61440/90000 (68%)]	Loss: -4.0309	Cost: 11.80s
Train Epoch: 1092 [81920/90000 (91%)]	Loss: -3.7095	Cost: 12.25s
Train Epoch: 1092 	Average Loss: -3.4145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2492

Learning rate: 9.708645688751025e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1093 [0/90000 (0%)]	Loss: 0.3404	Cost: 25.07s
Train Epoch: 1093 [20480/90000 (23%)]	Loss: -3.8205	Cost: 10.19s
Train Epoch: 1093 [40960/90000 (45%)]	Loss: -3.8545	Cost: 17.35s
Train Epoch: 1093 [61440/90000 (68%)]	Loss: -3.9351	Cost: 13.60s
Train Epoch: 1093 [81920/90000 (91%)]	Loss: -3.6390	Cost: 12.17s
Train Epoch: 1093 	Average Loss: -3.4818
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2699

Learning rate: 9.70811708424146e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1094 [0/90000 (0%)]	Loss: 0.3536	Cost: 39.33s
Train Epoch: 1094 [20480/90000 (23%)]	Loss: -3.8226	Cost: 10.71s
Train Epoch: 1094 [40960/90000 (45%)]	Loss: -3.7027	Cost: 12.50s
Train Epoch: 1094 [61440/90000 (68%)]	Loss: -3.9141	Cost: 12.10s
Train Epoch: 1094 [81920/90000 (91%)]	Loss: -3.7301	Cost: 7.80s
Train Epoch: 1094 	Average Loss: -3.4611
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2222

Learning rate: 9.707588015059367e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1095 [0/90000 (0%)]	Loss: 0.4579	Cost: 24.91s
Train Epoch: 1095 [20480/90000 (23%)]	Loss: -3.8756	Cost: 12.53s
Train Epoch: 1095 [40960/90000 (45%)]	Loss: -3.8475	Cost: 12.39s
Train Epoch: 1095 [61440/90000 (68%)]	Loss: -3.9500	Cost: 9.36s
Train Epoch: 1095 [81920/90000 (91%)]	Loss: -3.6861	Cost: 7.92s
Train Epoch: 1095 	Average Loss: -3.4607
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1745

Saving model as e1095_model.pt & e1095_waveforms_supplementary.hdf5
Learning rate: 9.707058481256966e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1096 [0/90000 (0%)]	Loss: -0.1483	Cost: 22.19s
Train Epoch: 1096 [20480/90000 (23%)]	Loss: -3.7114	Cost: 6.67s
Train Epoch: 1096 [40960/90000 (45%)]	Loss: -4.0436	Cost: 9.33s
Train Epoch: 1096 [61440/90000 (68%)]	Loss: -3.9596	Cost: 9.22s
Train Epoch: 1096 [81920/90000 (91%)]	Loss: -2.9441	Cost: 8.87s
Train Epoch: 1096 	Average Loss: -3.4875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8238

Learning rate: 9.706528482886516e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1097 [0/90000 (0%)]	Loss: 0.7023	Cost: 21.51s
Train Epoch: 1097 [20480/90000 (23%)]	Loss: -3.1912	Cost: 10.06s
Train Epoch: 1097 [40960/90000 (45%)]	Loss: -3.2581	Cost: 7.17s
Train Epoch: 1097 [61440/90000 (68%)]	Loss: -3.6428	Cost: 7.25s
Train Epoch: 1097 [81920/90000 (91%)]	Loss: -3.5533	Cost: 6.45s
Train Epoch: 1097 	Average Loss: -3.0881
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2908

Learning rate: 9.705998020000328e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1098 [0/90000 (0%)]	Loss: 0.3489	Cost: 23.28s
Train Epoch: 1098 [20480/90000 (23%)]	Loss: -3.4782	Cost: 10.04s
Train Epoch: 1098 [40960/90000 (45%)]	Loss: -3.3837	Cost: 10.52s
Train Epoch: 1098 [61440/90000 (68%)]	Loss: -3.4445	Cost: 12.42s
Train Epoch: 1098 [81920/90000 (91%)]	Loss: -3.3449	Cost: 12.47s
Train Epoch: 1098 	Average Loss: -3.1681
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4742

Learning rate: 9.705467092650757e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1099 [0/90000 (0%)]	Loss: 0.4020	Cost: 40.06s
Train Epoch: 1099 [20480/90000 (23%)]	Loss: -3.5882	Cost: 13.52s
Train Epoch: 1099 [40960/90000 (45%)]	Loss: -3.9082	Cost: 12.48s
Train Epoch: 1099 [61440/90000 (68%)]	Loss: -3.8056	Cost: 12.17s
Train Epoch: 1099 [81920/90000 (91%)]	Loss: -3.5620	Cost: 10.89s
Train Epoch: 1099 	Average Loss: -3.4380
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2999

Learning rate: 9.704935700890203e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1100 [0/90000 (0%)]	Loss: 0.8363	Cost: 26.34s
Train Epoch: 1100 [20480/90000 (23%)]	Loss: -3.7002	Cost: 13.35s
Train Epoch: 1100 [40960/90000 (45%)]	Loss: -3.8338	Cost: 12.62s
Train Epoch: 1100 [61440/90000 (68%)]	Loss: -3.9325	Cost: 9.24s
Train Epoch: 1100 [81920/90000 (91%)]	Loss: -3.6155	Cost: 6.87s
Train Epoch: 1100 	Average Loss: -3.4595
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0417

Saving model as e1100_model.pt & e1100_waveforms_supplementary.hdf5
Learning rate: 9.70440384477111e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1101 [0/90000 (0%)]	Loss: 0.1900	Cost: 23.70s
Train Epoch: 1101 [20480/90000 (23%)]	Loss: -4.1042	Cost: 10.15s
Train Epoch: 1101 [40960/90000 (45%)]	Loss: -3.6628	Cost: 9.80s
Train Epoch: 1101 [61440/90000 (68%)]	Loss: -3.8265	Cost: 8.25s
Train Epoch: 1101 [81920/90000 (91%)]	Loss: -3.6917	Cost: 8.79s
Train Epoch: 1101 	Average Loss: -3.4544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1578

Learning rate: 9.703871524345972e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1102 [0/90000 (0%)]	Loss: 0.6044	Cost: 19.82s
Train Epoch: 1102 [20480/90000 (23%)]	Loss: -3.9037	Cost: 7.53s
Train Epoch: 1102 [40960/90000 (45%)]	Loss: -4.0315	Cost: 9.85s
Train Epoch: 1102 [61440/90000 (68%)]	Loss: -4.1573	Cost: 8.82s
Train Epoch: 1102 [81920/90000 (91%)]	Loss: -3.9385	Cost: 8.73s
Train Epoch: 1102 	Average Loss: -3.6208
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1220

Learning rate: 9.703338739667327e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1103 [0/90000 (0%)]	Loss: 0.3698	Cost: 23.73s
Train Epoch: 1103 [20480/90000 (23%)]	Loss: -3.3847	Cost: 8.85s
Train Epoch: 1103 [40960/90000 (45%)]	Loss: -3.6250	Cost: 8.98s
Train Epoch: 1103 [61440/90000 (68%)]	Loss: -3.7608	Cost: 8.70s
Train Epoch: 1103 [81920/90000 (91%)]	Loss: -3.6445	Cost: 8.64s
Train Epoch: 1103 	Average Loss: -3.3785
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1579

Learning rate: 9.70280549078776e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1104 [0/90000 (0%)]	Loss: 0.4072	Cost: 28.98s
Train Epoch: 1104 [20480/90000 (23%)]	Loss: -3.7140	Cost: 8.25s
Train Epoch: 1104 [40960/90000 (45%)]	Loss: -3.8860	Cost: 6.93s
Train Epoch: 1104 [61440/90000 (68%)]	Loss: -3.9252	Cost: 6.80s
Train Epoch: 1104 [81920/90000 (91%)]	Loss: -3.4748	Cost: 9.74s
Train Epoch: 1104 	Average Loss: -3.5071
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2527

Learning rate: 9.702271777759897e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1105 [0/90000 (0%)]	Loss: 0.4580	Cost: 20.99s
Train Epoch: 1105 [20480/90000 (23%)]	Loss: -3.7440	Cost: 9.29s
Train Epoch: 1105 [40960/90000 (45%)]	Loss: -4.0395	Cost: 16.45s
Train Epoch: 1105 [61440/90000 (68%)]	Loss: -3.9909	Cost: 12.71s
Train Epoch: 1105 [81920/90000 (91%)]	Loss: -3.7394	Cost: 12.58s
Train Epoch: 1105 	Average Loss: -3.5848
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1235

Learning rate: 9.701737600636417e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1106 [0/90000 (0%)]	Loss: -0.0379	Cost: 25.01s
Train Epoch: 1106 [20480/90000 (23%)]	Loss: -3.9904	Cost: 12.96s
Train Epoch: 1106 [40960/90000 (45%)]	Loss: -3.9009	Cost: 13.97s
Train Epoch: 1106 [61440/90000 (68%)]	Loss: -3.9605	Cost: 12.65s
Train Epoch: 1106 [81920/90000 (91%)]	Loss: -3.8400	Cost: 9.15s
Train Epoch: 1106 	Average Loss: -3.6559
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0182

Saving model as e1106_model.pt & e1106_waveforms_supplementary.hdf5
Learning rate: 9.701202959470039e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1107 [0/90000 (0%)]	Loss: 0.2773	Cost: 27.05s
Train Epoch: 1107 [20480/90000 (23%)]	Loss: -4.0740	Cost: 10.32s
Train Epoch: 1107 [40960/90000 (45%)]	Loss: -4.1534	Cost: 12.24s
Train Epoch: 1107 [61440/90000 (68%)]	Loss: -4.1270	Cost: 7.28s
Train Epoch: 1107 [81920/90000 (91%)]	Loss: -3.6589	Cost: 6.11s
Train Epoch: 1107 	Average Loss: -3.7022
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1042

Learning rate: 9.700667854313532e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1108 [0/90000 (0%)]	Loss: 0.1830	Cost: 27.01s
Train Epoch: 1108 [20480/90000 (23%)]	Loss: -3.6972	Cost: 11.35s
Train Epoch: 1108 [40960/90000 (45%)]	Loss: -3.9798	Cost: 6.75s
Train Epoch: 1108 [61440/90000 (68%)]	Loss: -4.0714	Cost: 6.21s
Train Epoch: 1108 [81920/90000 (91%)]	Loss: -3.9481	Cost: 8.40s
Train Epoch: 1108 	Average Loss: -3.6176
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0037

Saving model as e1108_model.pt & e1108_waveforms_supplementary.hdf5
Learning rate: 9.700132285219706e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1109 [0/90000 (0%)]	Loss: 0.2412	Cost: 34.03s
Train Epoch: 1109 [20480/90000 (23%)]	Loss: -3.9374	Cost: 6.46s
Train Epoch: 1109 [40960/90000 (45%)]	Loss: -3.8962	Cost: 9.64s
Train Epoch: 1109 [61440/90000 (68%)]	Loss: -4.0145	Cost: 8.56s
Train Epoch: 1109 [81920/90000 (91%)]	Loss: -3.7818	Cost: 8.71s
Train Epoch: 1109 	Average Loss: -3.6453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1798

Learning rate: 9.69959625224142e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1110 [0/90000 (0%)]	Loss: 0.0701	Cost: 24.94s
Train Epoch: 1110 [20480/90000 (23%)]	Loss: -3.8697	Cost: 9.08s
Train Epoch: 1110 [40960/90000 (45%)]	Loss: -4.1264	Cost: 7.44s
Train Epoch: 1110 [61440/90000 (68%)]	Loss: -4.0937	Cost: 6.67s
Train Epoch: 1110 [81920/90000 (91%)]	Loss: -4.0101	Cost: 6.60s
Train Epoch: 1110 	Average Loss: -3.6169
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1229

Learning rate: 9.699059755431581e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1111 [0/90000 (0%)]	Loss: -0.2288	Cost: 20.10s
Train Epoch: 1111 [20480/90000 (23%)]	Loss: -3.9370	Cost: 9.80s
Train Epoch: 1111 [40960/90000 (45%)]	Loss: -4.1636	Cost: 16.06s
Train Epoch: 1111 [61440/90000 (68%)]	Loss: -4.0262	Cost: 14.39s
Train Epoch: 1111 [81920/90000 (91%)]	Loss: -3.8445	Cost: 12.66s
Train Epoch: 1111 	Average Loss: -3.6761
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2522

Learning rate: 9.698522794843136e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1112 [0/90000 (0%)]	Loss: 0.4461	Cost: 24.06s
Train Epoch: 1112 [20480/90000 (23%)]	Loss: -3.8715	Cost: 14.64s
Train Epoch: 1112 [40960/90000 (45%)]	Loss: -3.4830	Cost: 14.21s
Train Epoch: 1112 [61440/90000 (68%)]	Loss: -3.6763	Cost: 12.55s
Train Epoch: 1112 [81920/90000 (91%)]	Loss: -3.5283	Cost: 12.21s
Train Epoch: 1112 	Average Loss: -3.3635
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3102

Learning rate: 9.697985370529083e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1113 [0/90000 (0%)]	Loss: 0.4814	Cost: 39.03s
Train Epoch: 1113 [20480/90000 (23%)]	Loss: -3.7796	Cost: 12.32s
Train Epoch: 1113 [40960/90000 (45%)]	Loss: -4.0471	Cost: 12.27s
Train Epoch: 1113 [61440/90000 (68%)]	Loss: -4.0575	Cost: 9.70s
Train Epoch: 1113 [81920/90000 (91%)]	Loss: -3.3308	Cost: 6.41s
Train Epoch: 1113 	Average Loss: -3.5553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3664

Learning rate: 9.697447482542464e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1114 [0/90000 (0%)]	Loss: 1.0672	Cost: 20.93s
Train Epoch: 1114 [20480/90000 (23%)]	Loss: -3.8339	Cost: 8.08s
Train Epoch: 1114 [40960/90000 (45%)]	Loss: -3.9639	Cost: 6.41s
Train Epoch: 1114 [61440/90000 (68%)]	Loss: -4.1209	Cost: 7.41s
Train Epoch: 1114 [81920/90000 (91%)]	Loss: -3.6853	Cost: 8.62s
Train Epoch: 1114 	Average Loss: -3.5234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1717

Learning rate: 9.696909130936366e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1115 [0/90000 (0%)]	Loss: -0.1237	Cost: 21.89s
Train Epoch: 1115 [20480/90000 (23%)]	Loss: -3.7701	Cost: 7.11s
Train Epoch: 1115 [40960/90000 (45%)]	Loss: -3.8352	Cost: 8.91s
Train Epoch: 1115 [61440/90000 (68%)]	Loss: -3.5242	Cost: 9.06s
Train Epoch: 1115 [81920/90000 (91%)]	Loss: -3.5967	Cost: 9.02s
Train Epoch: 1115 	Average Loss: -3.4163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3207

Learning rate: 9.69637031576392e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1116 [0/90000 (0%)]	Loss: 0.5720	Cost: 28.79s
Train Epoch: 1116 [20480/90000 (23%)]	Loss: -3.6870	Cost: 8.93s
Train Epoch: 1116 [40960/90000 (45%)]	Loss: -4.0163	Cost: 8.90s
Train Epoch: 1116 [61440/90000 (68%)]	Loss: -4.1732	Cost: 8.50s
Train Epoch: 1116 [81920/90000 (91%)]	Loss: -4.0141	Cost: 6.32s
Train Epoch: 1116 	Average Loss: -3.6354
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0653

Learning rate: 9.695831037078306e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1117 [0/90000 (0%)]	Loss: 1.0556	Cost: 26.49s
Train Epoch: 1117 [20480/90000 (23%)]	Loss: -4.0283	Cost: 8.89s
Train Epoch: 1117 [40960/90000 (45%)]	Loss: -4.1679	Cost: 7.64s
Train Epoch: 1117 [61440/90000 (68%)]	Loss: -4.2635	Cost: 6.65s
Train Epoch: 1117 [81920/90000 (91%)]	Loss: -4.0893	Cost: 6.74s
Train Epoch: 1117 	Average Loss: -3.8132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2322

Saving model as e1117_model.pt & e1117_waveforms_supplementary.hdf5
Learning rate: 9.695291294932748e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1118 [0/90000 (0%)]	Loss: 0.2601	Cost: 19.96s
Train Epoch: 1118 [20480/90000 (23%)]	Loss: -4.0515	Cost: 7.23s
Train Epoch: 1118 [40960/90000 (45%)]	Loss: -4.1551	Cost: 17.14s
Train Epoch: 1118 [61440/90000 (68%)]	Loss: -4.0547	Cost: 12.89s
Train Epoch: 1118 [81920/90000 (91%)]	Loss: -3.8363	Cost: 12.44s
Train Epoch: 1118 	Average Loss: -3.7744
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0765

Learning rate: 9.69475108938052e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1119 [0/90000 (0%)]	Loss: 0.3958	Cost: 24.92s
Train Epoch: 1119 [20480/90000 (23%)]	Loss: -3.9302	Cost: 12.66s
Train Epoch: 1119 [40960/90000 (45%)]	Loss: -4.0944	Cost: 12.48s
Train Epoch: 1119 [61440/90000 (68%)]	Loss: -4.3135	Cost: 12.96s
Train Epoch: 1119 [81920/90000 (91%)]	Loss: -3.8326	Cost: 12.15s
Train Epoch: 1119 	Average Loss: -3.7628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0234

Learning rate: 9.694210420474934e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1120 [0/90000 (0%)]	Loss: 0.2828	Cost: 26.44s
Train Epoch: 1120 [20480/90000 (23%)]	Loss: -4.0839	Cost: 13.40s
Train Epoch: 1120 [40960/90000 (45%)]	Loss: -4.1545	Cost: 12.33s
Train Epoch: 1120 [61440/90000 (68%)]	Loss: -4.2925	Cost: 7.07s
Train Epoch: 1120 [81920/90000 (91%)]	Loss: -4.0982	Cost: 6.19s
Train Epoch: 1120 	Average Loss: -3.7851
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0285

Learning rate: 9.693669288269356e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1121 [0/90000 (0%)]	Loss: 0.5720	Cost: 34.25s
Train Epoch: 1121 [20480/90000 (23%)]	Loss: -3.8394	Cost: 11.28s
Train Epoch: 1121 [40960/90000 (45%)]	Loss: -4.1283	Cost: 6.81s
Train Epoch: 1121 [61440/90000 (68%)]	Loss: -4.3630	Cost: 6.24s
Train Epoch: 1121 [81920/90000 (91%)]	Loss: -4.0314	Cost: 8.47s
Train Epoch: 1121 	Average Loss: -3.7434
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0229

Learning rate: 9.693127692817188e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1122 [0/90000 (0%)]	Loss: -0.3199	Cost: 29.93s
Train Epoch: 1122 [20480/90000 (23%)]	Loss: -4.1666	Cost: 10.84s
Train Epoch: 1122 [40960/90000 (45%)]	Loss: -4.3341	Cost: 10.16s
Train Epoch: 1122 [61440/90000 (68%)]	Loss: -4.1561	Cost: 8.75s
Train Epoch: 1122 [81920/90000 (91%)]	Loss: -3.9155	Cost: 8.70s
Train Epoch: 1122 	Average Loss: -3.8164
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0547

Learning rate: 9.692585634171887e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1123 [0/90000 (0%)]	Loss: -0.0196	Cost: 21.24s
Train Epoch: 1123 [20480/90000 (23%)]	Loss: -4.1744	Cost: 9.05s
Train Epoch: 1123 [40960/90000 (45%)]	Loss: -4.1969	Cost: 8.97s
Train Epoch: 1123 [61440/90000 (68%)]	Loss: -4.4823	Cost: 6.26s
Train Epoch: 1123 [81920/90000 (91%)]	Loss: -4.0264	Cost: 6.21s
Train Epoch: 1123 	Average Loss: -3.8968
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1344

Learning rate: 9.692043112386951e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1124 [0/90000 (0%)]	Loss: 0.2627	Cost: 20.80s
Train Epoch: 1124 [20480/90000 (23%)]	Loss: -4.2373	Cost: 8.21s
Train Epoch: 1124 [40960/90000 (45%)]	Loss: -4.2843	Cost: 14.13s
Train Epoch: 1124 [61440/90000 (68%)]	Loss: -4.4448	Cost: 12.44s
Train Epoch: 1124 [81920/90000 (91%)]	Loss: -4.3880	Cost: 12.19s
Train Epoch: 1124 	Average Loss: -3.9405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1480

Learning rate: 9.691500127515926e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1125 [0/90000 (0%)]	Loss: -0.1561	Cost: 23.62s
Train Epoch: 1125 [20480/90000 (23%)]	Loss: -4.2847	Cost: 14.51s
Train Epoch: 1125 [40960/90000 (45%)]	Loss: -4.3482	Cost: 13.52s
Train Epoch: 1125 [61440/90000 (68%)]	Loss: -4.2825	Cost: 12.16s
Train Epoch: 1125 [81920/90000 (91%)]	Loss: -4.2101	Cost: 9.36s
Train Epoch: 1125 	Average Loss: -3.9489
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0839

Learning rate: 9.690956679612404e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1126 [0/90000 (0%)]	Loss: -0.0394	Cost: 37.64s
Train Epoch: 1126 [20480/90000 (23%)]	Loss: -4.2427	Cost: 12.57s
Train Epoch: 1126 [40960/90000 (45%)]	Loss: -4.2233	Cost: 12.12s
Train Epoch: 1126 [61440/90000 (68%)]	Loss: -4.3272	Cost: 6.10s
Train Epoch: 1126 [81920/90000 (91%)]	Loss: -4.1217	Cost: 6.39s
Train Epoch: 1126 	Average Loss: -3.9299
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1505

Learning rate: 9.690412768730017e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1127 [0/90000 (0%)]	Loss: -0.2027	Cost: 24.79s
Train Epoch: 1127 [20480/90000 (23%)]	Loss: -4.4020	Cost: 6.89s
Train Epoch: 1127 [40960/90000 (45%)]	Loss: -4.3674	Cost: 10.14s
Train Epoch: 1127 [61440/90000 (68%)]	Loss: -4.4784	Cost: 8.66s
Train Epoch: 1127 [81920/90000 (91%)]	Loss: -4.0031	Cost: 8.75s
Train Epoch: 1127 	Average Loss: -4.0252
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1634

Learning rate: 9.689868394922449e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1128 [0/90000 (0%)]	Loss: -0.0230	Cost: 22.15s
Train Epoch: 1128 [20480/90000 (23%)]	Loss: -4.4290	Cost: 12.12s
Train Epoch: 1128 [40960/90000 (45%)]	Loss: -4.2068	Cost: 10.46s
Train Epoch: 1128 [61440/90000 (68%)]	Loss: -4.2137	Cost: 7.99s
Train Epoch: 1128 [81920/90000 (91%)]	Loss: -3.9913	Cost: 8.74s
Train Epoch: 1128 	Average Loss: -3.8980
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0646

Learning rate: 9.689323558243428e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1129 [0/90000 (0%)]	Loss: 0.2665	Cost: 21.49s
Train Epoch: 1129 [20480/90000 (23%)]	Loss: -4.3726	Cost: 9.75s
Train Epoch: 1129 [40960/90000 (45%)]	Loss: -4.2362	Cost: 17.60s
Train Epoch: 1129 [61440/90000 (68%)]	Loss: -4.3104	Cost: 14.14s
Train Epoch: 1129 [81920/90000 (91%)]	Loss: -3.8828	Cost: 12.36s
Train Epoch: 1129 	Average Loss: -3.9471
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0703

Learning rate: 9.688778258746725e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1130 [0/90000 (0%)]	Loss: 0.4033	Cost: 33.01s
Train Epoch: 1130 [20480/90000 (23%)]	Loss: -4.2316	Cost: 13.39s
Train Epoch: 1130 [40960/90000 (45%)]	Loss: -4.3447	Cost: 12.50s
Train Epoch: 1130 [61440/90000 (68%)]	Loss: -4.3162	Cost: 12.36s
Train Epoch: 1130 [81920/90000 (91%)]	Loss: -3.9789	Cost: 12.23s
Train Epoch: 1130 	Average Loss: -3.9190
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0669

Learning rate: 9.68823249648616e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1131 [0/90000 (0%)]	Loss: -0.1623	Cost: 24.63s
Train Epoch: 1131 [20480/90000 (23%)]	Loss: -4.1097	Cost: 13.23s
Train Epoch: 1131 [40960/90000 (45%)]	Loss: -4.2353	Cost: 12.30s
Train Epoch: 1131 [61440/90000 (68%)]	Loss: -4.3789	Cost: 8.78s
Train Epoch: 1131 [81920/90000 (91%)]	Loss: -4.1393	Cost: 6.07s
Train Epoch: 1131 	Average Loss: -3.9445
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1572

Learning rate: 9.6876862715156e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1132 [0/90000 (0%)]	Loss: 0.2236	Cost: 24.66s
Train Epoch: 1132 [20480/90000 (23%)]	Loss: -4.1604	Cost: 10.30s
Train Epoch: 1132 [40960/90000 (45%)]	Loss: -4.0433	Cost: 9.89s
Train Epoch: 1132 [61440/90000 (68%)]	Loss: -4.2662	Cost: 6.22s
Train Epoch: 1132 [81920/90000 (91%)]	Loss: -3.9976	Cost: 7.49s
Train Epoch: 1132 	Average Loss: -3.9370
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1492

Learning rate: 9.687139583888953e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1133 [0/90000 (0%)]	Loss: 0.5911	Cost: 24.21s
Train Epoch: 1133 [20480/90000 (23%)]	Loss: -3.8580	Cost: 6.76s
Train Epoch: 1133 [40960/90000 (45%)]	Loss: -4.0176	Cost: 10.02s
Train Epoch: 1133 [61440/90000 (68%)]	Loss: -4.0859	Cost: 8.66s
Train Epoch: 1133 [81920/90000 (91%)]	Loss: -3.7581	Cost: 9.11s
Train Epoch: 1133 	Average Loss: -3.7543
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1156

Learning rate: 9.686592433660174e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1134 [0/90000 (0%)]	Loss: 0.6435	Cost: 27.27s
Train Epoch: 1134 [20480/90000 (23%)]	Loss: -4.3625	Cost: 10.27s
Train Epoch: 1134 [40960/90000 (45%)]	Loss: -4.4194	Cost: 9.27s
Train Epoch: 1134 [61440/90000 (68%)]	Loss: -4.3303	Cost: 7.62s
Train Epoch: 1134 [81920/90000 (91%)]	Loss: -3.9981	Cost: 5.70s
Train Epoch: 1134 	Average Loss: -3.9822
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2310

Learning rate: 9.686044820883267e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1135 [0/90000 (0%)]	Loss: -0.0062	Cost: 24.73s
Train Epoch: 1135 [20480/90000 (23%)]	Loss: -4.3526	Cost: 10.08s
Train Epoch: 1135 [40960/90000 (45%)]	Loss: -4.4653	Cost: 8.07s
Train Epoch: 1135 [61440/90000 (68%)]	Loss: -4.5380	Cost: 6.54s
Train Epoch: 1135 [81920/90000 (91%)]	Loss: -4.4190	Cost: 6.80s
Train Epoch: 1135 	Average Loss: -4.0672
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2325

Saving model as e1135_model.pt & e1135_waveforms_supplementary.hdf5
Learning rate: 9.685496745612277e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1136 [0/90000 (0%)]	Loss: -0.2271	Cost: 20.01s
Train Epoch: 1136 [20480/90000 (23%)]	Loss: -4.3108	Cost: 7.04s
Train Epoch: 1136 [40960/90000 (45%)]	Loss: -4.4813	Cost: 11.62s
Train Epoch: 1136 [61440/90000 (68%)]	Loss: -4.5320	Cost: 13.51s
Train Epoch: 1136 [81920/90000 (91%)]	Loss: -4.3702	Cost: 12.47s
Train Epoch: 1136 	Average Loss: -4.0547
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1049

Learning rate: 9.684948207901299e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1137 [0/90000 (0%)]	Loss: 0.0499	Cost: 24.19s
Train Epoch: 1137 [20480/90000 (23%)]	Loss: -4.3554	Cost: 13.46s
Train Epoch: 1137 [40960/90000 (45%)]	Loss: -4.3825	Cost: 12.45s
Train Epoch: 1137 [61440/90000 (68%)]	Loss: -4.5157	Cost: 12.31s
Train Epoch: 1137 [81920/90000 (91%)]	Loss: -4.1689	Cost: 12.65s
Train Epoch: 1137 	Average Loss: -4.0573
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2447

Saving model as e1137_model.pt & e1137_waveforms_supplementary.hdf5
Learning rate: 9.68439920780447e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1138 [0/90000 (0%)]	Loss: -0.1804	Cost: 24.02s
Train Epoch: 1138 [20480/90000 (23%)]	Loss: -4.4132	Cost: 14.04s
Train Epoch: 1138 [40960/90000 (45%)]	Loss: -4.4790	Cost: 12.24s
Train Epoch: 1138 [61440/90000 (68%)]	Loss: -4.4617	Cost: 7.22s
Train Epoch: 1138 [81920/90000 (91%)]	Loss: -4.2320	Cost: 6.10s
Train Epoch: 1138 	Average Loss: -4.1031
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2113

Learning rate: 9.683849745375974e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1139 [0/90000 (0%)]	Loss: -0.3535	Cost: 33.89s
Train Epoch: 1139 [20480/90000 (23%)]	Loss: -4.3383	Cost: 6.65s
Train Epoch: 1139 [40960/90000 (45%)]	Loss: -4.5053	Cost: 9.83s
Train Epoch: 1139 [61440/90000 (68%)]	Loss: -4.6645	Cost: 8.66s
Train Epoch: 1139 [81920/90000 (91%)]	Loss: -4.3869	Cost: 8.56s
Train Epoch: 1139 	Average Loss: -4.0570
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1122

Learning rate: 9.68329982067004e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1140 [0/90000 (0%)]	Loss: -0.2965	Cost: 23.46s
Train Epoch: 1140 [20480/90000 (23%)]	Loss: -4.4008	Cost: 7.91s
Train Epoch: 1140 [40960/90000 (45%)]	Loss: -4.0875	Cost: 9.26s
Train Epoch: 1140 [61440/90000 (68%)]	Loss: -4.1191	Cost: 8.74s
Train Epoch: 1140 [81920/90000 (91%)]	Loss: -3.8155	Cost: 8.46s
Train Epoch: 1140 	Average Loss: -3.8164
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0312

Learning rate: 9.682749433740945e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1141 [0/90000 (0%)]	Loss: 0.1233	Cost: 24.30s
Train Epoch: 1141 [20480/90000 (23%)]	Loss: -3.8789	Cost: 7.30s
Train Epoch: 1141 [40960/90000 (45%)]	Loss: -3.8584	Cost: 13.51s
Train Epoch: 1141 [61440/90000 (68%)]	Loss: -4.3058	Cost: 10.73s
Train Epoch: 1141 [81920/90000 (91%)]	Loss: -4.2864	Cost: 13.15s
Train Epoch: 1141 	Average Loss: -3.8089
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1619

Learning rate: 9.682198584643011e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1142 [0/90000 (0%)]	Loss: -0.1983	Cost: 19.96s
Train Epoch: 1142 [20480/90000 (23%)]	Loss: -4.4096	Cost: 7.89s
Train Epoch: 1142 [40960/90000 (45%)]	Loss: -4.4496	Cost: 16.93s
Train Epoch: 1142 [61440/90000 (68%)]	Loss: -4.3446	Cost: 14.77s
Train Epoch: 1142 [81920/90000 (91%)]	Loss: -4.1666	Cost: 12.78s
Train Epoch: 1142 	Average Loss: -4.0724
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2775

Saving model as e1142_model.pt & e1142_waveforms_supplementary.hdf5
Learning rate: 9.681647273430602e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1143 [0/90000 (0%)]	Loss: 0.0433	Cost: 30.45s
Train Epoch: 1143 [20480/90000 (23%)]	Loss: -4.4099	Cost: 13.65s
Train Epoch: 1143 [40960/90000 (45%)]	Loss: -4.2338	Cost: 12.64s
Train Epoch: 1143 [61440/90000 (68%)]	Loss: -4.3698	Cost: 12.11s
Train Epoch: 1143 [81920/90000 (91%)]	Loss: -4.1614	Cost: 10.32s
Train Epoch: 1143 	Average Loss: -4.0545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0659

Learning rate: 9.681095500158132e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1144 [0/90000 (0%)]	Loss: 0.2213	Cost: 29.47s
Train Epoch: 1144 [20480/90000 (23%)]	Loss: -4.1929	Cost: 11.40s
Train Epoch: 1144 [40960/90000 (45%)]	Loss: -4.4404	Cost: 8.49s
Train Epoch: 1144 [61440/90000 (68%)]	Loss: -4.3977	Cost: 6.26s
Train Epoch: 1144 [81920/90000 (91%)]	Loss: -4.1593	Cost: 7.69s
Train Epoch: 1144 	Average Loss: -3.9417
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0992

Learning rate: 9.68054326488006e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1145 [0/90000 (0%)]	Loss: 0.2561	Cost: 21.69s
Train Epoch: 1145 [20480/90000 (23%)]	Loss: -4.2926	Cost: 7.80s
Train Epoch: 1145 [40960/90000 (45%)]	Loss: -4.3972	Cost: 8.90s
Train Epoch: 1145 [61440/90000 (68%)]	Loss: -4.6656	Cost: 8.80s
Train Epoch: 1145 [81920/90000 (91%)]	Loss: -4.3218	Cost: 8.96s
Train Epoch: 1145 	Average Loss: -4.0670
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4911

Saving model as e1145_model.pt & e1145_waveforms_supplementary.hdf5
Learning rate: 9.679990567650885e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1146 [0/90000 (0%)]	Loss: -0.2784	Cost: 24.64s
Train Epoch: 1146 [20480/90000 (23%)]	Loss: -4.6197	Cost: 10.12s
Train Epoch: 1146 [40960/90000 (45%)]	Loss: -4.6519	Cost: 8.79s
Train Epoch: 1146 [61440/90000 (68%)]	Loss: -4.4029	Cost: 6.31s
Train Epoch: 1146 [81920/90000 (91%)]	Loss: -4.2077	Cost: 6.45s
Train Epoch: 1146 	Average Loss: -4.1375
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2080

Learning rate: 9.67943740852516e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1147 [0/90000 (0%)]	Loss: -0.2238	Cost: 34.56s
Train Epoch: 1147 [20480/90000 (23%)]	Loss: -4.3344	Cost: 12.16s
Train Epoch: 1147 [40960/90000 (45%)]	Loss: -4.3348	Cost: 11.25s
Train Epoch: 1147 [61440/90000 (68%)]	Loss: -4.3466	Cost: 12.41s
Train Epoch: 1147 [81920/90000 (91%)]	Loss: -4.3530	Cost: 12.30s
Train Epoch: 1147 	Average Loss: -4.0976
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2513

Learning rate: 9.678883787557477e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1148 [0/90000 (0%)]	Loss: -0.0619	Cost: 22.08s
Train Epoch: 1148 [20480/90000 (23%)]	Loss: -4.5831	Cost: 8.51s
Train Epoch: 1148 [40960/90000 (45%)]	Loss: -4.6768	Cost: 13.10s
Train Epoch: 1148 [61440/90000 (68%)]	Loss: -4.5631	Cost: 13.02s
Train Epoch: 1148 [81920/90000 (91%)]	Loss: -4.5512	Cost: 12.27s
Train Epoch: 1148 	Average Loss: -4.2571
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1979

Learning rate: 9.67832970480248e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1149 [0/90000 (0%)]	Loss: -0.2228	Cost: 26.12s
Train Epoch: 1149 [20480/90000 (23%)]	Loss: -4.5986	Cost: 12.70s
Train Epoch: 1149 [40960/90000 (45%)]	Loss: -4.5713	Cost: 12.43s
Train Epoch: 1149 [61440/90000 (68%)]	Loss: -4.6610	Cost: 12.45s
Train Epoch: 1149 [81920/90000 (91%)]	Loss: -4.4961	Cost: 11.64s
Train Epoch: 1149 	Average Loss: -4.2539
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3436

Learning rate: 9.67777516031485e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1150 [0/90000 (0%)]	Loss: 0.0643	Cost: 24.93s
Train Epoch: 1150 [20480/90000 (23%)]	Loss: -3.8403	Cost: 12.74s
Train Epoch: 1150 [40960/90000 (45%)]	Loss: -3.9187	Cost: 12.39s
Train Epoch: 1150 [61440/90000 (68%)]	Loss: -4.1445	Cost: 6.34s
Train Epoch: 1150 [81920/90000 (91%)]	Loss: -4.0641	Cost: 6.25s
Train Epoch: 1150 	Average Loss: -3.7973
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0884

Learning rate: 9.677220154149323e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1151 [0/90000 (0%)]	Loss: -0.3719	Cost: 23.57s
Train Epoch: 1151 [20480/90000 (23%)]	Loss: -4.5755	Cost: 11.89s
Train Epoch: 1151 [40960/90000 (45%)]	Loss: -4.5868	Cost: 7.47s
Train Epoch: 1151 [61440/90000 (68%)]	Loss: -4.6706	Cost: 6.17s
Train Epoch: 1151 [81920/90000 (91%)]	Loss: -4.2892	Cost: 7.10s
Train Epoch: 1151 	Average Loss: -4.1840
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2565

Learning rate: 9.676664686360671e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1152 [0/90000 (0%)]	Loss: 0.0171	Cost: 23.53s
Train Epoch: 1152 [20480/90000 (23%)]	Loss: -4.6375	Cost: 13.70s
Train Epoch: 1152 [40960/90000 (45%)]	Loss: -4.6542	Cost: 11.23s
Train Epoch: 1152 [61440/90000 (68%)]	Loss: -4.5395	Cost: 9.38s
Train Epoch: 1152 [81920/90000 (91%)]	Loss: -4.4204	Cost: 8.78s
Train Epoch: 1152 	Average Loss: -4.1759
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2027

Learning rate: 9.67610875700372e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1153 [0/90000 (0%)]	Loss: -0.3198	Cost: 22.15s
Train Epoch: 1153 [20480/90000 (23%)]	Loss: -4.5930	Cost: 8.43s
Train Epoch: 1153 [40960/90000 (45%)]	Loss: -4.4913	Cost: 8.84s
Train Epoch: 1153 [61440/90000 (68%)]	Loss: -4.7140	Cost: 8.89s
Train Epoch: 1153 [81920/90000 (91%)]	Loss: -4.0075	Cost: 8.71s
Train Epoch: 1153 	Average Loss: -4.1621
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1395

Learning rate: 9.675552366133338e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1154 [0/90000 (0%)]	Loss: 0.3447	Cost: 28.26s
Train Epoch: 1154 [20480/90000 (23%)]	Loss: -4.1681	Cost: 7.62s
Train Epoch: 1154 [40960/90000 (45%)]	Loss: -4.5172	Cost: 7.02s
Train Epoch: 1154 [61440/90000 (68%)]	Loss: -4.4915	Cost: 7.05s
Train Epoch: 1154 [81920/90000 (91%)]	Loss: -4.5598	Cost: 9.83s
Train Epoch: 1154 	Average Loss: -4.0193
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3581

Learning rate: 9.674995513804436e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1155 [0/90000 (0%)]	Loss: -0.2548	Cost: 20.28s
Train Epoch: 1155 [20480/90000 (23%)]	Loss: -4.5852	Cost: 7.07s
Train Epoch: 1155 [40960/90000 (45%)]	Loss: -4.5702	Cost: 13.17s
Train Epoch: 1155 [61440/90000 (68%)]	Loss: -4.7293	Cost: 12.54s
Train Epoch: 1155 [81920/90000 (91%)]	Loss: -4.5565	Cost: 12.32s
Train Epoch: 1155 	Average Loss: -4.3354
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4510

Learning rate: 9.674438200071975e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1156 [0/90000 (0%)]	Loss: -0.2501	Cost: 28.01s
Train Epoch: 1156 [20480/90000 (23%)]	Loss: -4.5580	Cost: 12.44s
Train Epoch: 1156 [40960/90000 (45%)]	Loss: -4.9462	Cost: 13.75s
Train Epoch: 1156 [61440/90000 (68%)]	Loss: -4.7905	Cost: 12.51s
Train Epoch: 1156 [81920/90000 (91%)]	Loss: -4.5640	Cost: 12.29s
Train Epoch: 1156 	Average Loss: -4.3232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4114

Learning rate: 9.673880424990961e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1157 [0/90000 (0%)]	Loss: -0.1398	Cost: 37.22s
Train Epoch: 1157 [20480/90000 (23%)]	Loss: -4.8148	Cost: 12.60s
Train Epoch: 1157 [40960/90000 (45%)]	Loss: -4.6756	Cost: 12.31s
Train Epoch: 1157 [61440/90000 (68%)]	Loss: -4.4981	Cost: 8.40s
Train Epoch: 1157 [81920/90000 (91%)]	Loss: -4.5824	Cost: 6.10s
Train Epoch: 1157 	Average Loss: -4.2727
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2995

Learning rate: 9.673322188616441e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1158 [0/90000 (0%)]	Loss: 0.0239	Cost: 33.58s
Train Epoch: 1158 [20480/90000 (23%)]	Loss: -4.5030	Cost: 9.78s
Train Epoch: 1158 [40960/90000 (45%)]	Loss: -4.7188	Cost: 9.98s
Train Epoch: 1158 [61440/90000 (68%)]	Loss: -4.9149	Cost: 6.40s
Train Epoch: 1158 [81920/90000 (91%)]	Loss: -4.5757	Cost: 7.26s
Train Epoch: 1158 	Average Loss: -4.3100
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3933

Learning rate: 9.672763491003515e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1159 [0/90000 (0%)]	Loss: -0.6340	Cost: 29.59s
Train Epoch: 1159 [20480/90000 (23%)]	Loss: -4.7577	Cost: 11.27s
Train Epoch: 1159 [40960/90000 (45%)]	Loss: -4.7432	Cost: 8.77s
Train Epoch: 1159 [61440/90000 (68%)]	Loss: -4.8966	Cost: 6.47s
Train Epoch: 1159 [81920/90000 (91%)]	Loss: -4.4423	Cost: 7.63s
Train Epoch: 1159 	Average Loss: -4.4218
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4641

Learning rate: 9.67220433220732e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1160 [0/90000 (0%)]	Loss: -0.2002	Cost: 18.92s
Train Epoch: 1160 [20480/90000 (23%)]	Loss: -4.7655	Cost: 6.59s
Train Epoch: 1160 [40960/90000 (45%)]	Loss: -4.9466	Cost: 8.46s
Train Epoch: 1160 [61440/90000 (68%)]	Loss: -4.8191	Cost: 9.00s
Train Epoch: 1160 [81920/90000 (91%)]	Loss: -4.5965	Cost: 8.67s
Train Epoch: 1160 	Average Loss: -4.3890
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5882

Saving model as e1160_model.pt & e1160_waveforms_supplementary.hdf5
Learning rate: 9.671644712283045e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1161 [0/90000 (0%)]	Loss: -0.6344	Cost: 20.14s
Train Epoch: 1161 [20480/90000 (23%)]	Loss: -4.6275	Cost: 8.99s
Train Epoch: 1161 [40960/90000 (45%)]	Loss: -4.6598	Cost: 7.21s
Train Epoch: 1161 [61440/90000 (68%)]	Loss: -4.7132	Cost: 7.67s
Train Epoch: 1161 [81920/90000 (91%)]	Loss: -4.2338	Cost: 7.47s
Train Epoch: 1161 	Average Loss: -4.3213
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4213

Learning rate: 9.67108463128592e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1162 [0/90000 (0%)]	Loss: 0.6077	Cost: 22.92s
Train Epoch: 1162 [20480/90000 (23%)]	Loss: -4.5436	Cost: 9.89s
Train Epoch: 1162 [40960/90000 (45%)]	Loss: -4.7432	Cost: 16.50s
Train Epoch: 1162 [61440/90000 (68%)]	Loss: -4.8295	Cost: 13.67s
Train Epoch: 1162 [81920/90000 (91%)]	Loss: -4.5879	Cost: 12.23s
Train Epoch: 1162 	Average Loss: -4.3165
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5224

Learning rate: 9.670524089271225e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1163 [0/90000 (0%)]	Loss: -0.2858	Cost: 34.53s
Train Epoch: 1163 [20480/90000 (23%)]	Loss: -4.7932	Cost: 14.53s
Train Epoch: 1163 [40960/90000 (45%)]	Loss: -4.8728	Cost: 14.13s
Train Epoch: 1163 [61440/90000 (68%)]	Loss: -4.7361	Cost: 12.23s
Train Epoch: 1163 [81920/90000 (91%)]	Loss: -4.5243	Cost: 11.32s
Train Epoch: 1163 	Average Loss: -4.4536
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3926

Learning rate: 9.669963086294282e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1164 [0/90000 (0%)]	Loss: 0.0231	Cost: 29.30s
Train Epoch: 1164 [20480/90000 (23%)]	Loss: -4.7416	Cost: 11.63s
Train Epoch: 1164 [40960/90000 (45%)]	Loss: -4.6263	Cost: 11.93s
Train Epoch: 1164 [61440/90000 (68%)]	Loss: -4.8957	Cost: 12.27s
Train Epoch: 1164 [81920/90000 (91%)]	Loss: -4.5751	Cost: 6.98s
Train Epoch: 1164 	Average Loss: -4.3678
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4773

Learning rate: 9.669401622410463e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1165 [0/90000 (0%)]	Loss: 0.1336	Cost: 29.10s
Train Epoch: 1165 [20480/90000 (23%)]	Loss: -4.7557	Cost: 12.41s
Train Epoch: 1165 [40960/90000 (45%)]	Loss: -4.7701	Cost: 9.31s
Train Epoch: 1165 [61440/90000 (68%)]	Loss: -4.6424	Cost: 6.18s
Train Epoch: 1165 [81920/90000 (91%)]	Loss: -4.4567	Cost: 8.42s
Train Epoch: 1165 	Average Loss: -4.3777
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3446

Learning rate: 9.668839697675178e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1166 [0/90000 (0%)]	Loss: -0.2804	Cost: 20.68s
Train Epoch: 1166 [20480/90000 (23%)]	Loss: -4.5658	Cost: 6.70s
Train Epoch: 1166 [40960/90000 (45%)]	Loss: -4.7198	Cost: 9.19s
Train Epoch: 1166 [61440/90000 (68%)]	Loss: -4.8008	Cost: 9.17s
Train Epoch: 1166 [81920/90000 (91%)]	Loss: -4.6467	Cost: 8.96s
Train Epoch: 1166 	Average Loss: -4.4062
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6371

Saving model as e1166_model.pt & e1166_waveforms_supplementary.hdf5
Learning rate: 9.668277312143889e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1167 [0/90000 (0%)]	Loss: -0.0538	Cost: 30.49s
Train Epoch: 1167 [20480/90000 (23%)]	Loss: -4.7871	Cost: 8.92s
Train Epoch: 1167 [40960/90000 (45%)]	Loss: -4.9258	Cost: 7.54s
Train Epoch: 1167 [61440/90000 (68%)]	Loss: -4.8176	Cost: 6.21s
Train Epoch: 1167 [81920/90000 (91%)]	Loss: -4.6571	Cost: 6.47s
Train Epoch: 1167 	Average Loss: -4.4550
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5502

Learning rate: 9.667714465872102e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1168 [0/90000 (0%)]	Loss: -0.3768	Cost: 23.66s
Train Epoch: 1168 [20480/90000 (23%)]	Loss: -4.9443	Cost: 9.64s
Train Epoch: 1168 [40960/90000 (45%)]	Loss: -4.5948	Cost: 11.90s
Train Epoch: 1168 [61440/90000 (68%)]	Loss: -4.5081	Cost: 10.45s
Train Epoch: 1168 [81920/90000 (91%)]	Loss: -4.3933	Cost: 13.88s
Train Epoch: 1168 	Average Loss: -4.2421
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2324

Learning rate: 9.667151158915365e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1169 [0/90000 (0%)]	Loss: 0.0269	Cost: 23.31s
Train Epoch: 1169 [20480/90000 (23%)]	Loss: -4.4052	Cost: 10.46s
Train Epoch: 1169 [40960/90000 (45%)]	Loss: -4.2188	Cost: 12.90s
Train Epoch: 1169 [61440/90000 (68%)]	Loss: -4.6757	Cost: 12.82s
Train Epoch: 1169 [81920/90000 (91%)]	Loss: -4.5155	Cost: 12.38s
Train Epoch: 1169 	Average Loss: -4.1364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4479

Learning rate: 9.666587391329276e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1170 [0/90000 (0%)]	Loss: 0.0926	Cost: 31.38s
Train Epoch: 1170 [20480/90000 (23%)]	Loss: -4.8605	Cost: 12.58s
Train Epoch: 1170 [40960/90000 (45%)]	Loss: -4.8358	Cost: 12.47s
Train Epoch: 1170 [61440/90000 (68%)]	Loss: -4.8178	Cost: 12.53s
Train Epoch: 1170 [81920/90000 (91%)]	Loss: -4.6558	Cost: 9.90s
Train Epoch: 1170 	Average Loss: -4.3950
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4595

Learning rate: 9.666023163169475e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1171 [0/90000 (0%)]	Loss: -0.2867	Cost: 25.80s
Train Epoch: 1171 [20480/90000 (23%)]	Loss: -4.7883	Cost: 11.03s
Train Epoch: 1171 [40960/90000 (45%)]	Loss: -4.9309	Cost: 9.88s
Train Epoch: 1171 [61440/90000 (68%)]	Loss: -5.0392	Cost: 6.37s
Train Epoch: 1171 [81920/90000 (91%)]	Loss: -4.6366	Cost: 6.97s
Train Epoch: 1171 	Average Loss: -4.4742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4592

Learning rate: 9.665458474491652e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1172 [0/90000 (0%)]	Loss: -0.5875	Cost: 25.14s
Train Epoch: 1172 [20480/90000 (23%)]	Loss: -4.7820	Cost: 6.84s
Train Epoch: 1172 [40960/90000 (45%)]	Loss: -4.6483	Cost: 8.75s
Train Epoch: 1172 [61440/90000 (68%)]	Loss: -5.0411	Cost: 9.04s
Train Epoch: 1172 [81920/90000 (91%)]	Loss: -4.4614	Cost: 8.72s
Train Epoch: 1172 	Average Loss: -4.4128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3387

Learning rate: 9.664893325351537e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1173 [0/90000 (0%)]	Loss: 0.0944	Cost: 34.01s
Train Epoch: 1173 [20480/90000 (23%)]	Loss: -4.7068	Cost: 9.07s
Train Epoch: 1173 [40960/90000 (45%)]	Loss: -4.8497	Cost: 8.97s
Train Epoch: 1173 [61440/90000 (68%)]	Loss: -4.9905	Cost: 8.47s
Train Epoch: 1173 [81920/90000 (91%)]	Loss: -4.6785	Cost: 8.45s
Train Epoch: 1173 	Average Loss: -4.4808
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4671

Learning rate: 9.664327715804909e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1174 [0/90000 (0%)]	Loss: -0.4991	Cost: 22.65s
Train Epoch: 1174 [20480/90000 (23%)]	Loss: -4.6386	Cost: 8.64s
Train Epoch: 1174 [40960/90000 (45%)]	Loss: -4.8023	Cost: 9.56s
Train Epoch: 1174 [61440/90000 (68%)]	Loss: -4.6437	Cost: 8.45s
Train Epoch: 1174 [81920/90000 (91%)]	Loss: -4.3897	Cost: 13.00s
Train Epoch: 1174 	Average Loss: -4.4013
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3493

Learning rate: 9.663761645907591e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1175 [0/90000 (0%)]	Loss: -0.6473	Cost: 22.44s
Train Epoch: 1175 [20480/90000 (23%)]	Loss: -4.6331	Cost: 12.01s
Train Epoch: 1175 [40960/90000 (45%)]	Loss: -4.7526	Cost: 15.39s
Train Epoch: 1175 [61440/90000 (68%)]	Loss: -4.8824	Cost: 14.50s
Train Epoch: 1175 [81920/90000 (91%)]	Loss: -4.4294	Cost: 12.48s
Train Epoch: 1175 	Average Loss: -4.4020
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5701

Learning rate: 9.663195115715452e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1176 [0/90000 (0%)]	Loss: -0.5646	Cost: 26.09s
Train Epoch: 1176 [20480/90000 (23%)]	Loss: -4.8607	Cost: 14.63s
Train Epoch: 1176 [40960/90000 (45%)]	Loss: -4.6876	Cost: 14.38s
Train Epoch: 1176 [61440/90000 (68%)]	Loss: -4.8110	Cost: 12.42s
Train Epoch: 1176 [81920/90000 (91%)]	Loss: -4.4956	Cost: 9.33s
Train Epoch: 1176 	Average Loss: -4.3936
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3695

Learning rate: 9.662628125284406e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1177 [0/90000 (0%)]	Loss: -0.4628	Cost: 26.79s
Train Epoch: 1177 [20480/90000 (23%)]	Loss: -4.6851	Cost: 14.04s
Train Epoch: 1177 [40960/90000 (45%)]	Loss: -4.9182	Cost: 12.32s
Train Epoch: 1177 [61440/90000 (68%)]	Loss: -4.9533	Cost: 7.65s
Train Epoch: 1177 [81920/90000 (91%)]	Loss: -4.8717	Cost: 6.19s
Train Epoch: 1177 	Average Loss: -4.5247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5824

Learning rate: 9.662060674670414e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1178 [0/90000 (0%)]	Loss: -0.2307	Cost: 34.25s
Train Epoch: 1178 [20480/90000 (23%)]	Loss: -4.8194	Cost: 6.38s
Train Epoch: 1178 [40960/90000 (45%)]	Loss: -5.0262	Cost: 8.13s
Train Epoch: 1178 [61440/90000 (68%)]	Loss: -4.9686	Cost: 8.81s
Train Epoch: 1178 [81920/90000 (91%)]	Loss: -4.7286	Cost: 8.83s
Train Epoch: 1178 	Average Loss: -4.5981
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5102

Learning rate: 9.66149276392948e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1179 [0/90000 (0%)]	Loss: -0.6283	Cost: 22.53s
Train Epoch: 1179 [20480/90000 (23%)]	Loss: -4.9104	Cost: 7.75s
Train Epoch: 1179 [40960/90000 (45%)]	Loss: -4.8471	Cost: 9.83s
Train Epoch: 1179 [61440/90000 (68%)]	Loss: -4.8824	Cost: 8.60s
Train Epoch: 1179 [81920/90000 (91%)]	Loss: -4.5990	Cost: 8.41s
Train Epoch: 1179 	Average Loss: -4.5416
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5585

Learning rate: 9.660924393117656e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1180 [0/90000 (0%)]	Loss: 0.1334	Cost: 23.71s
Train Epoch: 1180 [20480/90000 (23%)]	Loss: -2.4361	Cost: 9.50s
Train Epoch: 1180 [40960/90000 (45%)]	Loss: -3.0830	Cost: 10.84s
Train Epoch: 1180 [61440/90000 (68%)]	Loss: -3.6222	Cost: 8.98s
Train Epoch: 1180 [81920/90000 (91%)]	Loss: -3.6403	Cost: 11.19s
Train Epoch: 1180 	Average Loss: -3.0097
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2200

Learning rate: 9.660355562291035e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1181 [0/90000 (0%)]	Loss: 0.5727	Cost: 19.99s
Train Epoch: 1181 [20480/90000 (23%)]	Loss: -3.9863	Cost: 9.31s
Train Epoch: 1181 [40960/90000 (45%)]	Loss: -4.2995	Cost: 14.58s
Train Epoch: 1181 [61440/90000 (68%)]	Loss: -4.7076	Cost: 14.49s
Train Epoch: 1181 [81920/90000 (91%)]	Loss: -4.6025	Cost: 12.47s
Train Epoch: 1181 	Average Loss: -3.9741
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5315

Learning rate: 9.659786271505762e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1182 [0/90000 (0%)]	Loss: 0.0950	Cost: 30.39s
Train Epoch: 1182 [20480/90000 (23%)]	Loss: -4.8449	Cost: 14.69s
Train Epoch: 1182 [40960/90000 (45%)]	Loss: -4.7532	Cost: 12.65s
Train Epoch: 1182 [61440/90000 (68%)]	Loss: -4.9714	Cost: 12.17s
Train Epoch: 1182 [81920/90000 (91%)]	Loss: -4.4702	Cost: 12.30s
Train Epoch: 1182 	Average Loss: -4.4803
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4560

Learning rate: 9.65921652081802e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1183 [0/90000 (0%)]	Loss: -0.4258	Cost: 27.02s
Train Epoch: 1183 [20480/90000 (23%)]	Loss: -4.6242	Cost: 12.38s
Train Epoch: 1183 [40960/90000 (45%)]	Loss: -4.7321	Cost: 12.53s
Train Epoch: 1183 [61440/90000 (68%)]	Loss: -4.9667	Cost: 10.62s
Train Epoch: 1183 [81920/90000 (91%)]	Loss: -4.8444	Cost: 6.11s
Train Epoch: 1183 	Average Loss: -4.4851
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6019

Learning rate: 9.658646310284045e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1184 [0/90000 (0%)]	Loss: -0.4806	Cost: 26.72s
Train Epoch: 1184 [20480/90000 (23%)]	Loss: -4.7835	Cost: 7.28s
Train Epoch: 1184 [40960/90000 (45%)]	Loss: -5.0080	Cost: 7.78s
Train Epoch: 1184 [61440/90000 (68%)]	Loss: -5.1952	Cost: 8.51s
Train Epoch: 1184 [81920/90000 (91%)]	Loss: -4.8721	Cost: 8.50s
Train Epoch: 1184 	Average Loss: -4.5679
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5357

Learning rate: 9.65807563996011e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1185 [0/90000 (0%)]	Loss: 0.0711	Cost: 21.96s
Train Epoch: 1185 [20480/90000 (23%)]	Loss: -4.8946	Cost: 8.50s
Train Epoch: 1185 [40960/90000 (45%)]	Loss: -4.9685	Cost: 9.09s
Train Epoch: 1185 [61440/90000 (68%)]	Loss: -4.9132	Cost: 9.14s
Train Epoch: 1185 [81920/90000 (91%)]	Loss: -4.7389	Cost: 9.08s
Train Epoch: 1185 	Average Loss: -4.5430
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6540

Saving model as e1185_model.pt & e1185_waveforms_supplementary.hdf5
Learning rate: 9.657504509902543e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1186 [0/90000 (0%)]	Loss: -0.7723	Cost: 25.84s
Train Epoch: 1186 [20480/90000 (23%)]	Loss: -5.0091	Cost: 8.89s
Train Epoch: 1186 [40960/90000 (45%)]	Loss: -5.0463	Cost: 8.46s
Train Epoch: 1186 [61440/90000 (68%)]	Loss: -5.1910	Cost: 5.99s
Train Epoch: 1186 [81920/90000 (91%)]	Loss: -4.8326	Cost: 6.63s
Train Epoch: 1186 	Average Loss: -4.6839
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7851

Saving model as e1186_model.pt & e1186_waveforms_supplementary.hdf5
Learning rate: 9.656932920167708e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1187 [0/90000 (0%)]	Loss: -0.4829	Cost: 34.99s
Train Epoch: 1187 [20480/90000 (23%)]	Loss: -5.1322	Cost: 7.62s
Train Epoch: 1187 [40960/90000 (45%)]	Loss: -5.0788	Cost: 14.31s
Train Epoch: 1187 [61440/90000 (68%)]	Loss: -5.0816	Cost: 12.41s
Train Epoch: 1187 [81920/90000 (91%)]	Loss: -4.9981	Cost: 12.26s
Train Epoch: 1187 	Average Loss: -4.7296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6346

Learning rate: 9.656360870812022e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1188 [0/90000 (0%)]	Loss: -0.1458	Cost: 28.07s
Train Epoch: 1188 [20480/90000 (23%)]	Loss: -4.9448	Cost: 13.66s
Train Epoch: 1188 [40960/90000 (45%)]	Loss: -4.9078	Cost: 14.05s
Train Epoch: 1188 [61440/90000 (68%)]	Loss: -5.1263	Cost: 12.47s
Train Epoch: 1188 [81920/90000 (91%)]	Loss: -4.7780	Cost: 12.30s
Train Epoch: 1188 	Average Loss: -4.6574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7720

Learning rate: 9.655788361891943e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1189 [0/90000 (0%)]	Loss: -0.4060	Cost: 22.29s
Train Epoch: 1189 [20480/90000 (23%)]	Loss: -4.9069	Cost: 13.21s
Train Epoch: 1189 [40960/90000 (45%)]	Loss: -5.0377	Cost: 13.78s
Train Epoch: 1189 [61440/90000 (68%)]	Loss: -5.0606	Cost: 12.51s
Train Epoch: 1189 [81920/90000 (91%)]	Loss: -4.9625	Cost: 7.65s
Train Epoch: 1189 	Average Loss: -4.7507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7692

Learning rate: 9.655215393463971e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1190 [0/90000 (0%)]	Loss: -0.5996	Cost: 26.44s
Train Epoch: 1190 [20480/90000 (23%)]	Loss: -4.9592	Cost: 12.89s
Train Epoch: 1190 [40960/90000 (45%)]	Loss: -5.2973	Cost: 9.14s
Train Epoch: 1190 [61440/90000 (68%)]	Loss: -5.1433	Cost: 6.17s
Train Epoch: 1190 [81920/90000 (91%)]	Loss: -4.7399	Cost: 7.28s
Train Epoch: 1190 	Average Loss: -4.7004
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6120

Learning rate: 9.65464196558466e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1191 [0/90000 (0%)]	Loss: -0.4924	Cost: 23.94s
Train Epoch: 1191 [20480/90000 (23%)]	Loss: -5.0746	Cost: 8.39s
Train Epoch: 1191 [40960/90000 (45%)]	Loss: -5.2292	Cost: 9.69s
Train Epoch: 1191 [61440/90000 (68%)]	Loss: -5.0361	Cost: 8.86s
Train Epoch: 1191 [81920/90000 (91%)]	Loss: -4.8901	Cost: 8.49s
Train Epoch: 1191 	Average Loss: -4.7138
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6670

Learning rate: 9.654068078310607e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1192 [0/90000 (0%)]	Loss: -0.1915	Cost: 26.91s
Train Epoch: 1192 [20480/90000 (23%)]	Loss: -5.0491	Cost: 7.24s
Train Epoch: 1192 [40960/90000 (45%)]	Loss: -5.2945	Cost: 9.10s
Train Epoch: 1192 [61440/90000 (68%)]	Loss: -5.2657	Cost: 8.81s
Train Epoch: 1192 [81920/90000 (91%)]	Loss: -5.0310	Cost: 8.58s
Train Epoch: 1192 	Average Loss: -4.7639
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7024

Learning rate: 9.653493731698448e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1193 [0/90000 (0%)]	Loss: -0.7445	Cost: 20.20s
Train Epoch: 1193 [20480/90000 (23%)]	Loss: -5.0632	Cost: 8.91s
Train Epoch: 1193 [40960/90000 (45%)]	Loss: -5.1928	Cost: 8.91s
Train Epoch: 1193 [61440/90000 (68%)]	Loss: -5.1091	Cost: 8.67s
Train Epoch: 1193 [81920/90000 (91%)]	Loss: -4.8681	Cost: 9.05s
Train Epoch: 1193 	Average Loss: -4.7757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8042

Saving model as e1193_model.pt & e1193_waveforms_supplementary.hdf5
Learning rate: 9.652918925804872e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1194 [0/90000 (0%)]	Loss: -1.0445	Cost: 18.46s
Train Epoch: 1194 [20480/90000 (23%)]	Loss: -5.1706	Cost: 7.71s
Train Epoch: 1194 [40960/90000 (45%)]	Loss: -5.0919	Cost: 10.36s
Train Epoch: 1194 [61440/90000 (68%)]	Loss: -5.2512	Cost: 10.53s
Train Epoch: 1194 [81920/90000 (91%)]	Loss: -4.9839	Cost: 18.74s
Train Epoch: 1194 	Average Loss: -4.8428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6693

Learning rate: 9.652343660686608e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1195 [0/90000 (0%)]	Loss: -0.8189	Cost: 19.23s
Train Epoch: 1195 [20480/90000 (23%)]	Loss: -5.1052	Cost: 9.48s
Train Epoch: 1195 [40960/90000 (45%)]	Loss: -5.3248	Cost: 17.31s
Train Epoch: 1195 [61440/90000 (68%)]	Loss: -5.3160	Cost: 12.80s
Train Epoch: 1195 [81920/90000 (91%)]	Loss: -4.9701	Cost: 12.17s
Train Epoch: 1195 	Average Loss: -4.8196
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5783

Learning rate: 9.651767936400433e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1196 [0/90000 (0%)]	Loss: -0.5368	Cost: 30.66s
Train Epoch: 1196 [20480/90000 (23%)]	Loss: -5.0800	Cost: 12.71s
Train Epoch: 1196 [40960/90000 (45%)]	Loss: -5.3314	Cost: 12.55s
Train Epoch: 1196 [61440/90000 (68%)]	Loss: -5.3026	Cost: 12.33s
Train Epoch: 1196 [81920/90000 (91%)]	Loss: -5.1089	Cost: 11.84s
Train Epoch: 1196 	Average Loss: -4.7929
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8533

Saving model as e1196_model.pt & e1196_waveforms_supplementary.hdf5
Learning rate: 9.651191753003167e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1197 [0/90000 (0%)]	Loss: -0.9043	Cost: 27.00s
Train Epoch: 1197 [20480/90000 (23%)]	Loss: -5.3370	Cost: 12.55s
Train Epoch: 1197 [40960/90000 (45%)]	Loss: -5.2831	Cost: 12.42s
Train Epoch: 1197 [61440/90000 (68%)]	Loss: -5.3846	Cost: 9.72s
Train Epoch: 1197 [81920/90000 (91%)]	Loss: -5.1479	Cost: 6.45s
Train Epoch: 1197 	Average Loss: -4.9105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7748

Learning rate: 9.650615110551681e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1198 [0/90000 (0%)]	Loss: -0.9108	Cost: 26.45s
Train Epoch: 1198 [20480/90000 (23%)]	Loss: -5.1778	Cost: 12.78s
Train Epoch: 1198 [40960/90000 (45%)]	Loss: -5.1950	Cost: 13.11s
Train Epoch: 1198 [61440/90000 (68%)]	Loss: -5.3321	Cost: 6.51s
Train Epoch: 1198 [81920/90000 (91%)]	Loss: -4.7860	Cost: 6.93s
Train Epoch: 1198 	Average Loss: -4.8201
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6506

Learning rate: 9.650038009102886e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1199 [0/90000 (0%)]	Loss: -0.2693	Cost: 26.28s
Train Epoch: 1199 [20480/90000 (23%)]	Loss: -5.1823	Cost: 12.54s
Train Epoch: 1199 [40960/90000 (45%)]	Loss: -4.7421	Cost: 7.06s
Train Epoch: 1199 [61440/90000 (68%)]	Loss: -4.8223	Cost: 7.58s
Train Epoch: 1199 [81920/90000 (91%)]	Loss: -4.9181	Cost: 8.38s
Train Epoch: 1199 	Average Loss: -4.6186
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6863

Learning rate: 9.649460448713736e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1200 [0/90000 (0%)]	Loss: -0.7004	Cost: 19.60s
Train Epoch: 1200 [20480/90000 (23%)]	Loss: -4.7895	Cost: 6.58s
Train Epoch: 1200 [40960/90000 (45%)]	Loss: -5.0118	Cost: 10.57s
Train Epoch: 1200 [61440/90000 (68%)]	Loss: -4.9950	Cost: 9.42s
Train Epoch: 1200 [81920/90000 (91%)]	Loss: -4.8293	Cost: 8.83s
Train Epoch: 1200 	Average Loss: -4.6056
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6296

Learning rate: 9.648882429441238e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1201 [0/90000 (0%)]	Loss: -0.5169	Cost: 21.19s
Train Epoch: 1201 [20480/90000 (23%)]	Loss: -4.9054	Cost: 9.34s
Train Epoch: 1201 [40960/90000 (45%)]	Loss: -4.6831	Cost: 9.68s
Train Epoch: 1201 [61440/90000 (68%)]	Loss: -4.5098	Cost: 8.72s
Train Epoch: 1201 [81920/90000 (91%)]	Loss: -4.5215	Cost: 8.53s
Train Epoch: 1201 	Average Loss: -4.3828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3760

Learning rate: 9.64830395134244e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1202 [0/90000 (0%)]	Loss: -0.4742	Cost: 21.16s
Train Epoch: 1202 [20480/90000 (23%)]	Loss: -4.8561	Cost: 11.94s
Train Epoch: 1202 [40960/90000 (45%)]	Loss: -5.0549	Cost: 11.04s
Train Epoch: 1202 [61440/90000 (68%)]	Loss: -5.3502	Cost: 8.72s
Train Epoch: 1202 [81920/90000 (91%)]	Loss: -4.9845	Cost: 8.93s
Train Epoch: 1202 	Average Loss: -4.7094
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6917

Learning rate: 9.647725014474433e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1203 [0/90000 (0%)]	Loss: -0.4533	Cost: 22.20s
Train Epoch: 1203 [20480/90000 (23%)]	Loss: -5.1146	Cost: 8.91s
Train Epoch: 1203 [40960/90000 (45%)]	Loss: -5.1669	Cost: 9.10s
Train Epoch: 1203 [61440/90000 (68%)]	Loss: -5.4572	Cost: 6.58s
Train Epoch: 1203 [81920/90000 (91%)]	Loss: -5.0379	Cost: 6.47s
Train Epoch: 1203 	Average Loss: -4.8705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7813

Learning rate: 9.647145618894359e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1204 [0/90000 (0%)]	Loss: -0.1184	Cost: 21.10s
Train Epoch: 1204 [20480/90000 (23%)]	Loss: -5.3214	Cost: 7.28s
Train Epoch: 1204 [40960/90000 (45%)]	Loss: -5.2567	Cost: 12.65s
Train Epoch: 1204 [61440/90000 (68%)]	Loss: -5.3042	Cost: 12.69s
Train Epoch: 1204 [81920/90000 (91%)]	Loss: -5.1769	Cost: 12.59s
Train Epoch: 1204 	Average Loss: -4.9364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9808

Saving model as e1204_model.pt & e1204_waveforms_supplementary.hdf5
Learning rate: 9.646565764659398e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1205 [0/90000 (0%)]	Loss: -0.6212	Cost: 26.28s
Train Epoch: 1205 [20480/90000 (23%)]	Loss: -5.3286	Cost: 15.18s
Train Epoch: 1205 [40960/90000 (45%)]	Loss: -5.2595	Cost: 13.35s
Train Epoch: 1205 [61440/90000 (68%)]	Loss: -5.1926	Cost: 12.03s
Train Epoch: 1205 [81920/90000 (91%)]	Loss: -5.1382	Cost: 8.16s
Train Epoch: 1205 	Average Loss: -4.9346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6544

Learning rate: 9.645985451826784e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1206 [0/90000 (0%)]	Loss: -0.3253	Cost: 43.00s
Train Epoch: 1206 [20480/90000 (23%)]	Loss: -4.9735	Cost: 12.13s
Train Epoch: 1206 [40960/90000 (45%)]	Loss: -5.2216	Cost: 8.24s
Train Epoch: 1206 [61440/90000 (68%)]	Loss: -5.3816	Cost: 6.07s
Train Epoch: 1206 [81920/90000 (91%)]	Loss: -5.0092	Cost: 7.07s
Train Epoch: 1206 	Average Loss: -4.7876
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7718

Learning rate: 9.645404680453786e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1207 [0/90000 (0%)]	Loss: -0.3335	Cost: 37.67s
Train Epoch: 1207 [20480/90000 (23%)]	Loss: -5.3289	Cost: 9.46s
Train Epoch: 1207 [40960/90000 (45%)]	Loss: -5.1348	Cost: 6.66s
Train Epoch: 1207 [61440/90000 (68%)]	Loss: -5.5433	Cost: 6.19s
Train Epoch: 1207 [81920/90000 (91%)]	Loss: -4.8551	Cost: 8.69s
Train Epoch: 1207 	Average Loss: -4.9022
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5677

Learning rate: 9.64482345059773e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1208 [0/90000 (0%)]	Loss: -0.5328	Cost: 20.91s
Train Epoch: 1208 [20480/90000 (23%)]	Loss: -5.0113	Cost: 6.79s
Train Epoch: 1208 [40960/90000 (45%)]	Loss: -5.2559	Cost: 9.19s
Train Epoch: 1208 [61440/90000 (68%)]	Loss: -5.4796	Cost: 8.83s
Train Epoch: 1208 [81920/90000 (91%)]	Loss: -4.9460	Cost: 9.08s
Train Epoch: 1208 	Average Loss: -4.8384
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8270

Learning rate: 9.644241762315976e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1209 [0/90000 (0%)]	Loss: -0.1828	Cost: 22.46s
Train Epoch: 1209 [20480/90000 (23%)]	Loss: -5.1802	Cost: 9.01s
Train Epoch: 1209 [40960/90000 (45%)]	Loss: -5.2623	Cost: 9.25s
Train Epoch: 1209 [61440/90000 (68%)]	Loss: -5.4598	Cost: 9.24s
Train Epoch: 1209 [81920/90000 (91%)]	Loss: -5.1646	Cost: 7.22s
Train Epoch: 1209 	Average Loss: -5.0056
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9301

Learning rate: 9.643659615665937e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1210 [0/90000 (0%)]	Loss: -0.8264	Cost: 22.00s
Train Epoch: 1210 [20480/90000 (23%)]	Loss: -5.2466	Cost: 9.33s
Train Epoch: 1210 [40960/90000 (45%)]	Loss: -5.3266	Cost: 12.46s
Train Epoch: 1210 [61440/90000 (68%)]	Loss: -5.4447	Cost: 12.46s
Train Epoch: 1210 [81920/90000 (91%)]	Loss: -5.2486	Cost: 12.45s
Train Epoch: 1210 	Average Loss: -4.9923
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9228

Learning rate: 9.643077010705068e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1211 [0/90000 (0%)]	Loss: -0.8322	Cost: 25.78s
Train Epoch: 1211 [20480/90000 (23%)]	Loss: -5.4201	Cost: 12.28s
Train Epoch: 1211 [40960/90000 (45%)]	Loss: -5.3850	Cost: 12.78s
Train Epoch: 1211 [61440/90000 (68%)]	Loss: -5.6805	Cost: 12.18s
Train Epoch: 1211 [81920/90000 (91%)]	Loss: -5.2643	Cost: 12.36s
Train Epoch: 1211 	Average Loss: -5.0086
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9566

Learning rate: 9.64249394749087e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1212 [0/90000 (0%)]	Loss: -0.5461	Cost: 28.70s
Train Epoch: 1212 [20480/90000 (23%)]	Loss: -5.4776	Cost: 12.34s
Train Epoch: 1212 [40960/90000 (45%)]	Loss: -5.5101	Cost: 12.88s
Train Epoch: 1212 [61440/90000 (68%)]	Loss: -5.5579	Cost: 11.07s
Train Epoch: 1212 [81920/90000 (91%)]	Loss: -5.2702	Cost: 6.19s
Train Epoch: 1212 	Average Loss: -5.0489
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9861

Saving model as e1212_model.pt & e1212_waveforms_supplementary.hdf5
Learning rate: 9.641910426080889e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1213 [0/90000 (0%)]	Loss: -0.7765	Cost: 33.67s
Train Epoch: 1213 [20480/90000 (23%)]	Loss: -5.4102	Cost: 11.43s
Train Epoch: 1213 [40960/90000 (45%)]	Loss: -5.2550	Cost: 9.37s
Train Epoch: 1213 [61440/90000 (68%)]	Loss: -5.3609	Cost: 6.39s
Train Epoch: 1213 [81920/90000 (91%)]	Loss: -4.9377	Cost: 7.03s
Train Epoch: 1213 	Average Loss: -4.9721
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7126

Learning rate: 9.641326446532716e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1214 [0/90000 (0%)]	Loss: -0.0830	Cost: 21.34s
Train Epoch: 1214 [20480/90000 (23%)]	Loss: -5.1675	Cost: 11.33s
Train Epoch: 1214 [40960/90000 (45%)]	Loss: -5.6275	Cost: 11.31s
Train Epoch: 1214 [61440/90000 (68%)]	Loss: -5.6237	Cost: 7.25s
Train Epoch: 1214 [81920/90000 (91%)]	Loss: -5.0436	Cost: 7.19s
Train Epoch: 1214 	Average Loss: -4.9653
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0324

Saving model as e1214_model.pt & e1214_waveforms_supplementary.hdf5
Learning rate: 9.640742008903988e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1215 [0/90000 (0%)]	Loss: -1.2833	Cost: 21.79s
Train Epoch: 1215 [20480/90000 (23%)]	Loss: -5.4512	Cost: 8.33s
Train Epoch: 1215 [40960/90000 (45%)]	Loss: -5.3774	Cost: 8.21s
Train Epoch: 1215 [61440/90000 (68%)]	Loss: -5.4567	Cost: 8.84s
Train Epoch: 1215 [81920/90000 (91%)]	Loss: -5.1138	Cost: 8.52s
Train Epoch: 1215 	Average Loss: -5.0587
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7930

Learning rate: 9.640157113252386e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1216 [0/90000 (0%)]	Loss: -0.6454	Cost: 28.73s
Train Epoch: 1216 [20480/90000 (23%)]	Loss: -5.4303	Cost: 7.48s
Train Epoch: 1216 [40960/90000 (45%)]	Loss: -5.4773	Cost: 9.03s
Train Epoch: 1216 [61440/90000 (68%)]	Loss: -5.2749	Cost: 8.90s
Train Epoch: 1216 [81920/90000 (91%)]	Loss: -5.1242	Cost: 8.71s
Train Epoch: 1216 	Average Loss: -5.0009
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8019

Learning rate: 9.639571759635636e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1217 [0/90000 (0%)]	Loss: -0.4305	Cost: 22.95s
Train Epoch: 1217 [20480/90000 (23%)]	Loss: -5.2324	Cost: 9.19s
Train Epoch: 1217 [40960/90000 (45%)]	Loss: -5.0517	Cost: 7.25s
Train Epoch: 1217 [61440/90000 (68%)]	Loss: -5.3863	Cost: 6.49s
Train Epoch: 1217 [81920/90000 (91%)]	Loss: -5.2464	Cost: 6.44s
Train Epoch: 1217 	Average Loss: -4.9224
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8774

Learning rate: 9.638985948111512e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1218 [0/90000 (0%)]	Loss: -0.3993	Cost: 22.40s
Train Epoch: 1218 [20480/90000 (23%)]	Loss: -5.2666	Cost: 9.59s
Train Epoch: 1218 [40960/90000 (45%)]	Loss: -5.1644	Cost: 18.66s
Train Epoch: 1218 [61440/90000 (68%)]	Loss: -5.3589	Cost: 13.37s
Train Epoch: 1218 [81920/90000 (91%)]	Loss: -5.2293	Cost: 12.36s
Train Epoch: 1218 	Average Loss: -4.9658
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1088

Saving model as e1218_model.pt & e1218_waveforms_supplementary.hdf5
Learning rate: 9.638399678737831e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1219 [0/90000 (0%)]	Loss: -1.1009	Cost: 24.68s
Train Epoch: 1219 [20480/90000 (23%)]	Loss: -5.3054	Cost: 15.22s
Train Epoch: 1219 [40960/90000 (45%)]	Loss: -5.6593	Cost: 14.28s
Train Epoch: 1219 [61440/90000 (68%)]	Loss: -5.4686	Cost: 12.36s
Train Epoch: 1219 [81920/90000 (91%)]	Loss: -5.1528	Cost: 9.59s
Train Epoch: 1219 	Average Loss: -5.0904
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8478

Learning rate: 9.637812951572454e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1220 [0/90000 (0%)]	Loss: -0.9018	Cost: 35.10s
Train Epoch: 1220 [20480/90000 (23%)]	Loss: -5.3781	Cost: 12.71s
Train Epoch: 1220 [40960/90000 (45%)]	Loss: -5.3921	Cost: 10.87s
Train Epoch: 1220 [61440/90000 (68%)]	Loss: -5.3559	Cost: 6.05s
Train Epoch: 1220 [81920/90000 (91%)]	Loss: -5.0465	Cost: 6.93s
Train Epoch: 1220 	Average Loss: -4.9311
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7207

Learning rate: 9.63722576667329e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1221 [0/90000 (0%)]	Loss: -0.6007	Cost: 33.44s
Train Epoch: 1221 [20480/90000 (23%)]	Loss: -5.0910	Cost: 6.28s
Train Epoch: 1221 [40960/90000 (45%)]	Loss: -5.0576	Cost: 7.40s
Train Epoch: 1221 [61440/90000 (68%)]	Loss: -5.3079	Cost: 8.91s
Train Epoch: 1221 [81920/90000 (91%)]	Loss: -5.3857	Cost: 8.87s
Train Epoch: 1221 	Average Loss: -4.8226
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9274

Learning rate: 9.636638124098291e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1222 [0/90000 (0%)]	Loss: -0.9518	Cost: 23.03s
Train Epoch: 1222 [20480/90000 (23%)]	Loss: -5.1976	Cost: 6.81s
Train Epoch: 1222 [40960/90000 (45%)]	Loss: -5.1515	Cost: 9.94s
Train Epoch: 1222 [61440/90000 (68%)]	Loss: -5.6535	Cost: 8.85s
Train Epoch: 1222 [81920/90000 (91%)]	Loss: -5.0946	Cost: 8.77s
Train Epoch: 1222 	Average Loss: -4.9944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9139

Learning rate: 9.636050023905454e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1223 [0/90000 (0%)]	Loss: -0.6257	Cost: 25.36s
Train Epoch: 1223 [20480/90000 (23%)]	Loss: -5.2152	Cost: 9.54s
Train Epoch: 1223 [40960/90000 (45%)]	Loss: -5.3468	Cost: 10.06s
Train Epoch: 1223 [61440/90000 (68%)]	Loss: -5.6197	Cost: 9.59s
Train Epoch: 1223 [81920/90000 (91%)]	Loss: -5.2848	Cost: 12.66s
Train Epoch: 1223 	Average Loss: -5.0262
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8944

Learning rate: 9.635461466152825e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1224 [0/90000 (0%)]	Loss: -0.8069	Cost: 18.99s
Train Epoch: 1224 [20480/90000 (23%)]	Loss: -4.6452	Cost: 7.02s
Train Epoch: 1224 [40960/90000 (45%)]	Loss: -4.7496	Cost: 13.18s
Train Epoch: 1224 [61440/90000 (68%)]	Loss: -4.2420	Cost: 14.57s
Train Epoch: 1224 [81920/90000 (91%)]	Loss: -4.3337	Cost: 13.80s
Train Epoch: 1224 	Average Loss: -4.3203
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1662

Learning rate: 9.634872450898492e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1225 [0/90000 (0%)]	Loss: -0.0015	Cost: 21.33s
Train Epoch: 1225 [20480/90000 (23%)]	Loss: -4.5666	Cost: 12.53s
Train Epoch: 1225 [40960/90000 (45%)]	Loss: -4.8375	Cost: 15.51s
Train Epoch: 1225 [61440/90000 (68%)]	Loss: -5.2430	Cost: 12.43s
Train Epoch: 1225 [81920/90000 (91%)]	Loss: -5.1238	Cost: 12.09s
Train Epoch: 1225 	Average Loss: -4.5667
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8696

Learning rate: 9.634282978200585e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1226 [0/90000 (0%)]	Loss: -0.1576	Cost: 37.63s
Train Epoch: 1226 [20480/90000 (23%)]	Loss: -5.1278	Cost: 10.87s
Train Epoch: 1226 [40960/90000 (45%)]	Loss: -5.4684	Cost: 12.59s
Train Epoch: 1226 [61440/90000 (68%)]	Loss: -5.4981	Cost: 12.11s
Train Epoch: 1226 [81920/90000 (91%)]	Loss: -5.2941	Cost: 6.93s
Train Epoch: 1226 	Average Loss: -5.0364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9922

Learning rate: 9.633693048117287e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1227 [0/90000 (0%)]	Loss: -1.2461	Cost: 28.90s
Train Epoch: 1227 [20480/90000 (23%)]	Loss: -5.5085	Cost: 11.63s
Train Epoch: 1227 [40960/90000 (45%)]	Loss: -5.5065	Cost: 9.05s
Train Epoch: 1227 [61440/90000 (68%)]	Loss: -5.6777	Cost: 7.03s
Train Epoch: 1227 [81920/90000 (91%)]	Loss: -5.3386	Cost: 7.42s
Train Epoch: 1227 	Average Loss: -5.2470
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1103

Saving model as e1227_model.pt & e1227_waveforms_supplementary.hdf5
Learning rate: 9.63310266070682e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1228 [0/90000 (0%)]	Loss: -0.3315	Cost: 25.64s
Train Epoch: 1228 [20480/90000 (23%)]	Loss: -5.3851	Cost: 8.79s
Train Epoch: 1228 [40960/90000 (45%)]	Loss: -5.2842	Cost: 8.78s
Train Epoch: 1228 [61440/90000 (68%)]	Loss: -5.2515	Cost: 8.88s
Train Epoch: 1228 [81920/90000 (91%)]	Loss: -5.2125	Cost: 8.73s
Train Epoch: 1228 	Average Loss: -4.9868
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8665

Learning rate: 9.632511816027452e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1229 [0/90000 (0%)]	Loss: -0.8104	Cost: 33.49s
Train Epoch: 1229 [20480/90000 (23%)]	Loss: -5.3363	Cost: 8.20s
Train Epoch: 1229 [40960/90000 (45%)]	Loss: -5.5077	Cost: 9.91s
Train Epoch: 1229 [61440/90000 (68%)]	Loss: -5.5466	Cost: 7.55s
Train Epoch: 1229 [81920/90000 (91%)]	Loss: -5.3314	Cost: 14.35s
Train Epoch: 1229 	Average Loss: -5.1088
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1022

Learning rate: 9.631920514137498e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1230 [0/90000 (0%)]	Loss: -0.3045	Cost: 22.34s
Train Epoch: 1230 [20480/90000 (23%)]	Loss: -5.3195	Cost: 8.14s
Train Epoch: 1230 [40960/90000 (45%)]	Loss: -5.5481	Cost: 12.46s
Train Epoch: 1230 [61440/90000 (68%)]	Loss: -5.6370	Cost: 12.95s
Train Epoch: 1230 [81920/90000 (91%)]	Loss: -5.4401	Cost: 12.19s
Train Epoch: 1230 	Average Loss: -5.1509
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1603

Saving model as e1230_model.pt & e1230_waveforms_supplementary.hdf5
Learning rate: 9.631328755095315e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1231 [0/90000 (0%)]	Loss: -0.6873	Cost: 24.17s
Train Epoch: 1231 [20480/90000 (23%)]	Loss: -5.3014	Cost: 13.33s
Train Epoch: 1231 [40960/90000 (45%)]	Loss: -5.3857	Cost: 12.34s
Train Epoch: 1231 [61440/90000 (68%)]	Loss: -5.4565	Cost: 12.21s
Train Epoch: 1231 [81920/90000 (91%)]	Loss: -5.2139	Cost: 9.19s
Train Epoch: 1231 	Average Loss: -5.0379
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9043

Learning rate: 9.630736538959309e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1232 [0/90000 (0%)]	Loss: -1.0025	Cost: 24.16s
Train Epoch: 1232 [20480/90000 (23%)]	Loss: -5.3165	Cost: 11.99s
Train Epoch: 1232 [40960/90000 (45%)]	Loss: -5.4105	Cost: 9.97s
Train Epoch: 1232 [61440/90000 (68%)]	Loss: -5.4325	Cost: 6.59s
Train Epoch: 1232 [81920/90000 (91%)]	Loss: -5.3142	Cost: 7.18s
Train Epoch: 1232 	Average Loss: -5.0385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9753

Learning rate: 9.630143865787932e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1233 [0/90000 (0%)]	Loss: -0.8647	Cost: 34.68s
Train Epoch: 1233 [20480/90000 (23%)]	Loss: -5.4500	Cost: 10.50s
Train Epoch: 1233 [40960/90000 (45%)]	Loss: -5.6620	Cost: 8.15s
Train Epoch: 1233 [61440/90000 (68%)]	Loss: -5.8103	Cost: 6.42s
Train Epoch: 1233 [81920/90000 (91%)]	Loss: -5.5550	Cost: 8.67s
Train Epoch: 1233 	Average Loss: -5.2947
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1273

Learning rate: 9.629550735639675e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1234 [0/90000 (0%)]	Loss: -0.8997	Cost: 21.00s
Train Epoch: 1234 [20480/90000 (23%)]	Loss: -5.5597	Cost: 10.56s
Train Epoch: 1234 [40960/90000 (45%)]	Loss: -5.6564	Cost: 10.45s
Train Epoch: 1234 [61440/90000 (68%)]	Loss: -5.6581	Cost: 9.65s
Train Epoch: 1234 [81920/90000 (91%)]	Loss: -5.1177	Cost: 8.95s
Train Epoch: 1234 	Average Loss: -5.2056
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0144

Learning rate: 9.628957148573078e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1235 [0/90000 (0%)]	Loss: -0.6182	Cost: 25.40s
Train Epoch: 1235 [20480/90000 (23%)]	Loss: -5.5249	Cost: 8.84s
Train Epoch: 1235 [40960/90000 (45%)]	Loss: -5.6806	Cost: 8.95s
Train Epoch: 1235 [61440/90000 (68%)]	Loss: -5.6470	Cost: 8.64s
Train Epoch: 1235 [81920/90000 (91%)]	Loss: -5.3556	Cost: 7.27s
Train Epoch: 1235 	Average Loss: -5.2013
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9769

Learning rate: 9.628363104646728e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1236 [0/90000 (0%)]	Loss: -0.9738	Cost: 20.39s
Train Epoch: 1236 [20480/90000 (23%)]	Loss: -4.3507	Cost: 9.13s
Train Epoch: 1236 [40960/90000 (45%)]	Loss: -4.3153	Cost: 6.47s
Train Epoch: 1236 [61440/90000 (68%)]	Loss: -4.7574	Cost: 6.56s
Train Epoch: 1236 [81920/90000 (91%)]	Loss: -4.8352	Cost: 11.02s
Train Epoch: 1236 	Average Loss: -4.4342
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6687

Learning rate: 9.627768603919251e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1237 [0/90000 (0%)]	Loss: -0.3393	Cost: 22.26s
Train Epoch: 1237 [20480/90000 (23%)]	Loss: -5.1394	Cost: 7.93s
Train Epoch: 1237 [40960/90000 (45%)]	Loss: -5.2552	Cost: 12.78s
Train Epoch: 1237 [61440/90000 (68%)]	Loss: -5.5234	Cost: 12.55s
Train Epoch: 1237 [81920/90000 (91%)]	Loss: -5.3863	Cost: 12.67s
Train Epoch: 1237 	Average Loss: -4.9679
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0328

Learning rate: 9.627173646449324e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1238 [0/90000 (0%)]	Loss: -0.8328	Cost: 26.95s
Train Epoch: 1238 [20480/90000 (23%)]	Loss: -5.5282	Cost: 15.33s
Train Epoch: 1238 [40960/90000 (45%)]	Loss: -5.6493	Cost: 14.42s
Train Epoch: 1238 [61440/90000 (68%)]	Loss: -5.7660	Cost: 12.40s
Train Epoch: 1238 [81920/90000 (91%)]	Loss: -5.3654	Cost: 12.23s
Train Epoch: 1238 	Average Loss: -5.2175
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0537

Learning rate: 9.626578232295669e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1239 [0/90000 (0%)]	Loss: -0.7416	Cost: 30.75s
Train Epoch: 1239 [20480/90000 (23%)]	Loss: -5.4973	Cost: 13.30s
Train Epoch: 1239 [40960/90000 (45%)]	Loss: -5.5072	Cost: 13.57s
Train Epoch: 1239 [61440/90000 (68%)]	Loss: -5.5816	Cost: 12.21s
Train Epoch: 1239 [81920/90000 (91%)]	Loss: -5.3816	Cost: 6.98s
Train Epoch: 1239 	Average Loss: -5.1831
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1105

Learning rate: 9.625982361517048e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1240 [0/90000 (0%)]	Loss: -0.8114	Cost: 30.81s
Train Epoch: 1240 [20480/90000 (23%)]	Loss: -5.6152	Cost: 12.48s
Train Epoch: 1240 [40960/90000 (45%)]	Loss: -5.5254	Cost: 8.50s
Train Epoch: 1240 [61440/90000 (68%)]	Loss: -5.7404	Cost: 6.06s
Train Epoch: 1240 [81920/90000 (91%)]	Loss: -5.5931	Cost: 7.67s
Train Epoch: 1240 	Average Loss: -5.2587
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1438

Learning rate: 9.625386034172271e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1241 [0/90000 (0%)]	Loss: -0.8307	Cost: 26.21s
Train Epoch: 1241 [20480/90000 (23%)]	Loss: -5.5471	Cost: 6.63s
Train Epoch: 1241 [40960/90000 (45%)]	Loss: -5.7025	Cost: 8.69s
Train Epoch: 1241 [61440/90000 (68%)]	Loss: -5.5763	Cost: 8.91s
Train Epoch: 1241 [81920/90000 (91%)]	Loss: -5.3859	Cost: 8.71s
Train Epoch: 1241 	Average Loss: -5.1932
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1011

Learning rate: 9.624789250320195e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1242 [0/90000 (0%)]	Loss: -0.7378	Cost: 24.30s
Train Epoch: 1242 [20480/90000 (23%)]	Loss: -5.4967	Cost: 6.74s
Train Epoch: 1242 [40960/90000 (45%)]	Loss: -5.6303	Cost: 10.55s
Train Epoch: 1242 [61440/90000 (68%)]	Loss: -5.6803	Cost: 8.71s
Train Epoch: 1242 [81920/90000 (91%)]	Loss: -5.6872	Cost: 8.54s
Train Epoch: 1242 	Average Loss: -5.2249
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1890

Saving model as e1242_model.pt & e1242_waveforms_supplementary.hdf5
Learning rate: 9.62419201001972e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1243 [0/90000 (0%)]	Loss: -0.6669	Cost: 22.73s
Train Epoch: 1243 [20480/90000 (23%)]	Loss: -5.6218	Cost: 8.94s
Train Epoch: 1243 [40960/90000 (45%)]	Loss: -5.8276	Cost: 11.22s
Train Epoch: 1243 [61440/90000 (68%)]	Loss: -5.9896	Cost: 12.36s
Train Epoch: 1243 [81920/90000 (91%)]	Loss: -5.6696	Cost: 12.68s
Train Epoch: 1243 	Average Loss: -5.3643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2941

Saving model as e1243_model.pt & e1243_waveforms_supplementary.hdf5
Learning rate: 9.62359431332979e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1244 [0/90000 (0%)]	Loss: -1.2165	Cost: 20.95s
Train Epoch: 1244 [20480/90000 (23%)]	Loss: -5.7240	Cost: 10.41s
Train Epoch: 1244 [40960/90000 (45%)]	Loss: -5.8486	Cost: 16.71s
Train Epoch: 1244 [61440/90000 (68%)]	Loss: -5.9005	Cost: 14.06s
Train Epoch: 1244 [81920/90000 (91%)]	Loss: -5.5387	Cost: 12.11s
Train Epoch: 1244 	Average Loss: -5.4672
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3556

Saving model as e1244_model.pt & e1244_waveforms_supplementary.hdf5
Learning rate: 9.622996160309395e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1245 [0/90000 (0%)]	Loss: -1.0765	Cost: 32.27s
Train Epoch: 1245 [20480/90000 (23%)]	Loss: -5.9338	Cost: 10.52s
Train Epoch: 1245 [40960/90000 (45%)]	Loss: -5.7354	Cost: 12.59s
Train Epoch: 1245 [61440/90000 (68%)]	Loss: -5.9771	Cost: 12.29s
Train Epoch: 1245 [81920/90000 (91%)]	Loss: -5.6469	Cost: 8.58s
Train Epoch: 1245 	Average Loss: -5.4079
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1910

Learning rate: 9.622397551017573e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1246 [0/90000 (0%)]	Loss: -1.0494	Cost: 24.67s
Train Epoch: 1246 [20480/90000 (23%)]	Loss: -5.6894	Cost: 10.88s
Train Epoch: 1246 [40960/90000 (45%)]	Loss: -5.3342	Cost: 9.43s
Train Epoch: 1246 [61440/90000 (68%)]	Loss: -5.6597	Cost: 6.16s
Train Epoch: 1246 [81920/90000 (91%)]	Loss: -5.3051	Cost: 7.47s
Train Epoch: 1246 	Average Loss: -5.2002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1390

Learning rate: 9.621798485513401e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1247 [0/90000 (0%)]	Loss: -0.8540	Cost: 20.91s
Train Epoch: 1247 [20480/90000 (23%)]	Loss: -5.5323	Cost: 9.10s
Train Epoch: 1247 [40960/90000 (45%)]	Loss: -5.5198	Cost: 9.39s
Train Epoch: 1247 [61440/90000 (68%)]	Loss: -5.5138	Cost: 8.96s
Train Epoch: 1247 [81920/90000 (91%)]	Loss: -5.5809	Cost: 8.71s
Train Epoch: 1247 	Average Loss: -5.1197
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1456

Learning rate: 9.621198963856007e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1248 [0/90000 (0%)]	Loss: -0.7944	Cost: 26.82s
Train Epoch: 1248 [20480/90000 (23%)]	Loss: -5.7851	Cost: 8.88s
Train Epoch: 1248 [40960/90000 (45%)]	Loss: -5.7329	Cost: 6.65s
Train Epoch: 1248 [61440/90000 (68%)]	Loss: -5.8923	Cost: 6.27s
Train Epoch: 1248 [81920/90000 (91%)]	Loss: -5.6441	Cost: 6.33s
Train Epoch: 1248 	Average Loss: -5.4280
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3130

Learning rate: 9.620598986104559e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1249 [0/90000 (0%)]	Loss: -0.7006	Cost: 31.39s
Train Epoch: 1249 [20480/90000 (23%)]	Loss: -6.0888	Cost: 8.97s
Train Epoch: 1249 [40960/90000 (45%)]	Loss: -5.9051	Cost: 12.68s
Train Epoch: 1249 [61440/90000 (68%)]	Loss: -5.8299	Cost: 12.82s
Train Epoch: 1249 [81920/90000 (91%)]	Loss: -5.6992	Cost: 12.20s
Train Epoch: 1249 	Average Loss: -5.5159
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1129

Learning rate: 9.619998552318275e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1250 [0/90000 (0%)]	Loss: -1.1424	Cost: 26.00s
Train Epoch: 1250 [20480/90000 (23%)]	Loss: -5.9332	Cost: 14.12s
Train Epoch: 1250 [40960/90000 (45%)]	Loss: -5.8981	Cost: 13.36s
Train Epoch: 1250 [61440/90000 (68%)]	Loss: -5.8187	Cost: 12.50s
Train Epoch: 1250 [81920/90000 (91%)]	Loss: -5.6435	Cost: 10.17s
Train Epoch: 1250 	Average Loss: -5.5274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2826

Learning rate: 9.619397662556414e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1251 [0/90000 (0%)]	Loss: -0.6103	Cost: 27.50s
Train Epoch: 1251 [20480/90000 (23%)]	Loss: -5.9197	Cost: 12.89s
Train Epoch: 1251 [40960/90000 (45%)]	Loss: -5.9733	Cost: 12.68s
Train Epoch: 1251 [61440/90000 (68%)]	Loss: -6.0290	Cost: 9.45s
Train Epoch: 1251 [81920/90000 (91%)]	Loss: -5.6829	Cost: 6.42s
Train Epoch: 1251 	Average Loss: -5.5494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2796

Learning rate: 9.618796316878283e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1252 [0/90000 (0%)]	Loss: -1.1181	Cost: 22.92s
Train Epoch: 1252 [20480/90000 (23%)]	Loss: -5.6227	Cost: 12.41s
Train Epoch: 1252 [40960/90000 (45%)]	Loss: -5.7340	Cost: 9.04s
Train Epoch: 1252 [61440/90000 (68%)]	Loss: -5.7642	Cost: 6.41s
Train Epoch: 1252 [81920/90000 (91%)]	Loss: -5.4526	Cost: 7.62s
Train Epoch: 1252 	Average Loss: -5.3205
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0040

Learning rate: 9.618194515343229e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1253 [0/90000 (0%)]	Loss: -1.0338	Cost: 31.23s
Train Epoch: 1253 [20480/90000 (23%)]	Loss: -5.5936	Cost: 12.53s
Train Epoch: 1253 [40960/90000 (45%)]	Loss: -5.7099	Cost: 8.88s
Train Epoch: 1253 [61440/90000 (68%)]	Loss: -5.9579	Cost: 6.33s
Train Epoch: 1253 [81920/90000 (91%)]	Loss: -5.7602	Cost: 8.61s
Train Epoch: 1253 	Average Loss: -5.3377
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1677

Learning rate: 9.61759225801065e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1254 [0/90000 (0%)]	Loss: -1.0369	Cost: 22.21s
Train Epoch: 1254 [20480/90000 (23%)]	Loss: -5.3721	Cost: 10.24s
Train Epoch: 1254 [40960/90000 (45%)]	Loss: -5.7288	Cost: 10.52s
Train Epoch: 1254 [61440/90000 (68%)]	Loss: -5.6871	Cost: 8.03s
Train Epoch: 1254 [81920/90000 (91%)]	Loss: -5.5918	Cost: 8.85s
Train Epoch: 1254 	Average Loss: -5.2620
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1496

Learning rate: 9.616989544939987e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1255 [0/90000 (0%)]	Loss: -0.4151	Cost: 24.70s
Train Epoch: 1255 [20480/90000 (23%)]	Loss: -5.6869	Cost: 7.70s
Train Epoch: 1255 [40960/90000 (45%)]	Loss: -5.7918	Cost: 8.94s
Train Epoch: 1255 [61440/90000 (68%)]	Loss: -6.0359	Cost: 8.82s
Train Epoch: 1255 [81920/90000 (91%)]	Loss: -5.7993	Cost: 8.83s
Train Epoch: 1255 	Average Loss: -5.4631
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2901

Learning rate: 9.616386376190724e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1256 [0/90000 (0%)]	Loss: -0.7208	Cost: 20.47s
Train Epoch: 1256 [20480/90000 (23%)]	Loss: -5.7703	Cost: 8.99s
Train Epoch: 1256 [40960/90000 (45%)]	Loss: -6.1111	Cost: 8.90s
Train Epoch: 1256 [61440/90000 (68%)]	Loss: -5.9180	Cost: 8.50s
Train Epoch: 1256 [81920/90000 (91%)]	Loss: -5.7425	Cost: 6.54s
Train Epoch: 1256 	Average Loss: -5.6145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2739

Learning rate: 9.615782751822392e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1257 [0/90000 (0%)]	Loss: -0.8354	Cost: 20.95s
Train Epoch: 1257 [20480/90000 (23%)]	Loss: -5.8711	Cost: 6.78s
Train Epoch: 1257 [40960/90000 (45%)]	Loss: -6.1087	Cost: 9.17s
Train Epoch: 1257 [61440/90000 (68%)]	Loss: -6.1721	Cost: 10.41s
Train Epoch: 1257 [81920/90000 (91%)]	Loss: -5.5842	Cost: 13.74s
Train Epoch: 1257 	Average Loss: -5.6067
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3066

Learning rate: 9.615178671894565e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1258 [0/90000 (0%)]	Loss: -1.4614	Cost: 21.91s
Train Epoch: 1258 [20480/90000 (23%)]	Loss: -5.8166	Cost: 10.28s
Train Epoch: 1258 [40960/90000 (45%)]	Loss: -6.0341	Cost: 12.48s
Train Epoch: 1258 [61440/90000 (68%)]	Loss: -6.0324	Cost: 14.33s
Train Epoch: 1258 [81920/90000 (91%)]	Loss: -5.7522	Cost: 12.36s
Train Epoch: 1258 	Average Loss: -5.5210
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3243

Learning rate: 9.614574136466867e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1259 [0/90000 (0%)]	Loss: -1.4793	Cost: 22.93s
Train Epoch: 1259 [20480/90000 (23%)]	Loss: -5.9922	Cost: 11.36s
Train Epoch: 1259 [40960/90000 (45%)]	Loss: -6.0439	Cost: 15.35s
Train Epoch: 1259 [61440/90000 (68%)]	Loss: -6.2531	Cost: 13.20s
Train Epoch: 1259 [81920/90000 (91%)]	Loss: -5.8611	Cost: 12.22s
Train Epoch: 1259 	Average Loss: -5.6575
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4967

Saving model as e1259_model.pt & e1259_waveforms_supplementary.hdf5
Learning rate: 9.613969145598959e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1260 [0/90000 (0%)]	Loss: -1.1356	Cost: 43.62s
Train Epoch: 1260 [20480/90000 (23%)]	Loss: -6.1169	Cost: 11.96s
Train Epoch: 1260 [40960/90000 (45%)]	Loss: -5.8647	Cost: 12.58s
Train Epoch: 1260 [61440/90000 (68%)]	Loss: -5.9911	Cost: 7.94s
Train Epoch: 1260 [81920/90000 (91%)]	Loss: -4.8093	Cost: 6.38s
Train Epoch: 1260 	Average Loss: -5.4066
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5616

Learning rate: 9.613363699350553e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1261 [0/90000 (0%)]	Loss: -0.4652	Cost: 24.37s
Train Epoch: 1261 [20480/90000 (23%)]	Loss: -5.0095	Cost: 9.80s
Train Epoch: 1261 [40960/90000 (45%)]	Loss: -5.5280	Cost: 6.41s
Train Epoch: 1261 [61440/90000 (68%)]	Loss: -5.4930	Cost: 6.51s
Train Epoch: 1261 [81920/90000 (91%)]	Loss: -5.2807	Cost: 8.59s
Train Epoch: 1261 	Average Loss: -4.9595
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9441

Learning rate: 9.612757797781404e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1262 [0/90000 (0%)]	Loss: -0.2083	Cost: 25.97s
Train Epoch: 1262 [20480/90000 (23%)]	Loss: -5.4846	Cost: 6.67s
Train Epoch: 1262 [40960/90000 (45%)]	Loss: -5.4979	Cost: 10.33s
Train Epoch: 1262 [61440/90000 (68%)]	Loss: -5.7375	Cost: 8.60s
Train Epoch: 1262 [81920/90000 (91%)]	Loss: -5.5491	Cost: 8.50s
Train Epoch: 1262 	Average Loss: -5.1939
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1134

Learning rate: 9.612151440951311e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1263 [0/90000 (0%)]	Loss: -1.1017	Cost: 21.78s
Train Epoch: 1263 [20480/90000 (23%)]	Loss: -5.5794	Cost: 9.06s
Train Epoch: 1263 [40960/90000 (45%)]	Loss: -5.7877	Cost: 7.44s
Train Epoch: 1263 [61440/90000 (68%)]	Loss: -5.8885	Cost: 6.34s
Train Epoch: 1263 [81920/90000 (91%)]	Loss: -5.5978	Cost: 6.54s
Train Epoch: 1263 	Average Loss: -5.2850
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1586

Learning rate: 9.611544628920122e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1264 [0/90000 (0%)]	Loss: -0.9187	Cost: 20.42s
Train Epoch: 1264 [20480/90000 (23%)]	Loss: -6.0037	Cost: 9.98s
Train Epoch: 1264 [40960/90000 (45%)]	Loss: -5.9640	Cost: 10.64s
Train Epoch: 1264 [61440/90000 (68%)]	Loss: -5.8194	Cost: 13.21s
Train Epoch: 1264 [81920/90000 (91%)]	Loss: -5.6194	Cost: 12.06s
Train Epoch: 1264 	Average Loss: -5.4856
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1950

Learning rate: 9.610937361747725e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1265 [0/90000 (0%)]	Loss: -0.4301	Cost: 25.85s
Train Epoch: 1265 [20480/90000 (23%)]	Loss: -5.7291	Cost: 12.06s
Train Epoch: 1265 [40960/90000 (45%)]	Loss: -5.9112	Cost: 15.84s
Train Epoch: 1265 [61440/90000 (68%)]	Loss: -6.1247	Cost: 13.14s
Train Epoch: 1265 [81920/90000 (91%)]	Loss: -5.7592	Cost: 12.21s
Train Epoch: 1265 	Average Loss: -5.4864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9791

Learning rate: 9.610329639494054e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1266 [0/90000 (0%)]	Loss: -0.4248	Cost: 37.89s
Train Epoch: 1266 [20480/90000 (23%)]	Loss: -5.1268	Cost: 12.02s
Train Epoch: 1266 [40960/90000 (45%)]	Loss: -4.9679	Cost: 12.39s
Train Epoch: 1266 [61440/90000 (68%)]	Loss: -5.5374	Cost: 10.88s
Train Epoch: 1266 [81920/90000 (91%)]	Loss: -5.2480	Cost: 6.21s
Train Epoch: 1266 	Average Loss: -4.9342
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9731

Learning rate: 9.60972146221909e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1267 [0/90000 (0%)]	Loss: -0.6319	Cost: 23.40s
Train Epoch: 1267 [20480/90000 (23%)]	Loss: -5.5277	Cost: 11.15s
Train Epoch: 1267 [40960/90000 (45%)]	Loss: -5.9659	Cost: 9.22s
Train Epoch: 1267 [61440/90000 (68%)]	Loss: -5.8058	Cost: 6.26s
Train Epoch: 1267 [81920/90000 (91%)]	Loss: -5.6220	Cost: 7.79s
Train Epoch: 1267 	Average Loss: -5.4683
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3542

Learning rate: 9.609112829982858e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1268 [0/90000 (0%)]	Loss: -1.5741	Cost: 21.46s
Train Epoch: 1268 [20480/90000 (23%)]	Loss: -5.9273	Cost: 6.58s
Train Epoch: 1268 [40960/90000 (45%)]	Loss: -6.1831	Cost: 9.28s
Train Epoch: 1268 [61440/90000 (68%)]	Loss: -6.0556	Cost: 9.33s
Train Epoch: 1268 [81920/90000 (91%)]	Loss: -5.7794	Cost: 8.92s
Train Epoch: 1268 	Average Loss: -5.6620
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3612

Learning rate: 9.608503742845427e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1269 [0/90000 (0%)]	Loss: -1.1692	Cost: 36.07s
Train Epoch: 1269 [20480/90000 (23%)]	Loss: -6.1241	Cost: 7.37s
Train Epoch: 1269 [40960/90000 (45%)]	Loss: -6.2137	Cost: 7.34s
Train Epoch: 1269 [61440/90000 (68%)]	Loss: -6.2402	Cost: 6.83s
Train Epoch: 1269 [81920/90000 (91%)]	Loss: -5.8400	Cost: 16.54s
Train Epoch: 1269 	Average Loss: -5.7029
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2991

Learning rate: 9.607894200866912e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1270 [0/90000 (0%)]	Loss: -0.8511	Cost: 36.40s
Train Epoch: 1270 [20480/90000 (23%)]	Loss: -5.8193	Cost: 9.96s
Train Epoch: 1270 [40960/90000 (45%)]	Loss: -5.7265	Cost: 13.59s
Train Epoch: 1270 [61440/90000 (68%)]	Loss: -5.8824	Cost: 12.52s
Train Epoch: 1270 [81920/90000 (91%)]	Loss: -5.7605	Cost: 12.15s
Train Epoch: 1270 	Average Loss: -5.4734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3404

Learning rate: 9.607284204107471e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1271 [0/90000 (0%)]	Loss: -0.8111	Cost: 30.17s
Train Epoch: 1271 [20480/90000 (23%)]	Loss: -6.0204	Cost: 13.21s
Train Epoch: 1271 [40960/90000 (45%)]	Loss: -6.0551	Cost: 13.27s
Train Epoch: 1271 [61440/90000 (68%)]	Loss: -6.1377	Cost: 12.51s
Train Epoch: 1271 [81920/90000 (91%)]	Loss: -5.8519	Cost: 9.98s
Train Epoch: 1271 	Average Loss: -5.6366
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5177

Saving model as e1271_model.pt & e1271_waveforms_supplementary.hdf5
Learning rate: 9.606673752627308e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1272 [0/90000 (0%)]	Loss: -1.6293	Cost: 24.90s
Train Epoch: 1272 [20480/90000 (23%)]	Loss: -6.1326	Cost: 12.84s
Train Epoch: 1272 [40960/90000 (45%)]	Loss: -6.2525	Cost: 12.05s
Train Epoch: 1272 [61440/90000 (68%)]	Loss: -6.0345	Cost: 6.53s
Train Epoch: 1272 [81920/90000 (91%)]	Loss: -5.8936	Cost: 6.58s
Train Epoch: 1272 	Average Loss: -5.7579
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5116

Learning rate: 9.606062846486675e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1273 [0/90000 (0%)]	Loss: -1.4519	Cost: 24.30s
Train Epoch: 1273 [20480/90000 (23%)]	Loss: -5.9247	Cost: 8.56s
Train Epoch: 1273 [40960/90000 (45%)]	Loss: -5.9021	Cost: 7.99s
Train Epoch: 1273 [61440/90000 (68%)]	Loss: -6.2385	Cost: 8.70s
Train Epoch: 1273 [81920/90000 (91%)]	Loss: -5.9770	Cost: 8.74s
Train Epoch: 1273 	Average Loss: -5.7136
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5152

Learning rate: 9.605451485745864e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1274 [0/90000 (0%)]	Loss: -1.0583	Cost: 27.87s
Train Epoch: 1274 [20480/90000 (23%)]	Loss: -6.0619	Cost: 6.49s
Train Epoch: 1274 [40960/90000 (45%)]	Loss: -6.1039	Cost: 8.80s
Train Epoch: 1274 [61440/90000 (68%)]	Loss: -6.1506	Cost: 8.75s
Train Epoch: 1274 [81920/90000 (91%)]	Loss: -5.8844	Cost: 8.76s
Train Epoch: 1274 	Average Loss: -5.7500
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5104

Learning rate: 9.604839670465215e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1275 [0/90000 (0%)]	Loss: -1.5951	Cost: 24.06s
Train Epoch: 1275 [20480/90000 (23%)]	Loss: -6.1616	Cost: 8.99s
Train Epoch: 1275 [40960/90000 (45%)]	Loss: -6.0161	Cost: 8.94s
Train Epoch: 1275 [61440/90000 (68%)]	Loss: -5.9188	Cost: 8.62s
Train Epoch: 1275 [81920/90000 (91%)]	Loss: -5.9162	Cost: 6.28s
Train Epoch: 1275 	Average Loss: -5.6816
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4035

Learning rate: 9.604227400705111e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1276 [0/90000 (0%)]	Loss: -0.6410	Cost: 21.25s
Train Epoch: 1276 [20480/90000 (23%)]	Loss: -6.0781	Cost: 8.64s
Train Epoch: 1276 [40960/90000 (45%)]	Loss: -6.3366	Cost: 10.48s
Train Epoch: 1276 [61440/90000 (68%)]	Loss: -6.1962	Cost: 12.90s
Train Epoch: 1276 [81920/90000 (91%)]	Loss: -5.8734	Cost: 13.44s
Train Epoch: 1276 	Average Loss: -5.7533
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4336

Learning rate: 9.603614676525979e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1277 [0/90000 (0%)]	Loss: -1.5619	Cost: 20.26s
Train Epoch: 1277 [20480/90000 (23%)]	Loss: -6.0706	Cost: 10.45s
Train Epoch: 1277 [40960/90000 (45%)]	Loss: -6.0057	Cost: 15.42s
Train Epoch: 1277 [61440/90000 (68%)]	Loss: -6.1475	Cost: 14.38s
Train Epoch: 1277 [81920/90000 (91%)]	Loss: -5.4614	Cost: 12.49s
Train Epoch: 1277 	Average Loss: -5.5754
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1724

Learning rate: 9.603001497988294e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1278 [0/90000 (0%)]	Loss: -0.7473	Cost: 34.15s
Train Epoch: 1278 [20480/90000 (23%)]	Loss: -5.7641	Cost: 14.21s
Train Epoch: 1278 [40960/90000 (45%)]	Loss: -5.7621	Cost: 12.35s
Train Epoch: 1278 [61440/90000 (68%)]	Loss: -6.1354	Cost: 12.38s
Train Epoch: 1278 [81920/90000 (91%)]	Loss: -5.7612	Cost: 8.10s
Train Epoch: 1278 	Average Loss: -5.4944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3469

Learning rate: 9.602387865152576e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1279 [0/90000 (0%)]	Loss: -0.7624	Cost: 25.53s
Train Epoch: 1279 [20480/90000 (23%)]	Loss: -5.5179	Cost: 9.52s
Train Epoch: 1279 [40960/90000 (45%)]	Loss: -5.7003	Cost: 10.24s
Train Epoch: 1279 [61440/90000 (68%)]	Loss: -5.9565	Cost: 6.18s
Train Epoch: 1279 [81920/90000 (91%)]	Loss: -5.6572	Cost: 6.90s
Train Epoch: 1279 	Average Loss: -5.4130
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4781

Learning rate: 9.601773778079384e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1280 [0/90000 (0%)]	Loss: -1.3546	Cost: 27.22s
Train Epoch: 1280 [20480/90000 (23%)]	Loss: -6.1577	Cost: 10.82s
Train Epoch: 1280 [40960/90000 (45%)]	Loss: -6.2836	Cost: 6.64s
Train Epoch: 1280 [61440/90000 (68%)]	Loss: -6.4792	Cost: 6.34s
Train Epoch: 1280 [81920/90000 (91%)]	Loss: -5.8579	Cost: 8.33s
Train Epoch: 1280 	Average Loss: -5.8001
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4469

Learning rate: 9.60115923682933e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1281 [0/90000 (0%)]	Loss: -1.7734	Cost: 23.84s
Train Epoch: 1281 [20480/90000 (23%)]	Loss: -6.1717	Cost: 8.76s
Train Epoch: 1281 [40960/90000 (45%)]	Loss: -6.1311	Cost: 11.83s
Train Epoch: 1281 [61440/90000 (68%)]	Loss: -6.3648	Cost: 9.14s
Train Epoch: 1281 [81920/90000 (91%)]	Loss: -6.0495	Cost: 8.91s
Train Epoch: 1281 	Average Loss: -5.7662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4926

Learning rate: 9.600544241463066e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1282 [0/90000 (0%)]	Loss: -1.2824	Cost: 28.67s
Train Epoch: 1282 [20480/90000 (23%)]	Loss: -6.3054	Cost: 10.34s
Train Epoch: 1282 [40960/90000 (45%)]	Loss: -6.3166	Cost: 7.14s
Train Epoch: 1282 [61440/90000 (68%)]	Loss: -6.3698	Cost: 7.33s
Train Epoch: 1282 [81920/90000 (91%)]	Loss: -6.1674	Cost: 6.68s
Train Epoch: 1282 	Average Loss: -5.8591
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5009

Learning rate: 9.599928792041287e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1283 [0/90000 (0%)]	Loss: -0.8918	Cost: 20.88s
Train Epoch: 1283 [20480/90000 (23%)]	Loss: -6.3546	Cost: 6.94s
Train Epoch: 1283 [40960/90000 (45%)]	Loss: -6.1154	Cost: 8.60s
Train Epoch: 1283 [61440/90000 (68%)]	Loss: -6.2060	Cost: 11.02s
Train Epoch: 1283 [81920/90000 (91%)]	Loss: -6.1392	Cost: 12.38s
Train Epoch: 1283 	Average Loss: -5.8800
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4693

Learning rate: 9.599312888624739e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1284 [0/90000 (0%)]	Loss: -1.2462	Cost: 21.60s
Train Epoch: 1284 [20480/90000 (23%)]	Loss: -6.2139	Cost: 9.32s
Train Epoch: 1284 [40960/90000 (45%)]	Loss: -6.2318	Cost: 13.94s
Train Epoch: 1284 [61440/90000 (68%)]	Loss: -6.2697	Cost: 12.34s
Train Epoch: 1284 [81920/90000 (91%)]	Loss: -5.9105	Cost: 12.06s
Train Epoch: 1284 	Average Loss: -5.8538
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5226

Saving model as e1284_model.pt & e1284_waveforms_supplementary.hdf5
Learning rate: 9.598696531274207e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1285 [0/90000 (0%)]	Loss: -1.1146	Cost: 34.13s
Train Epoch: 1285 [20480/90000 (23%)]	Loss: -5.9139	Cost: 12.74s
Train Epoch: 1285 [40960/90000 (45%)]	Loss: -5.3486	Cost: 12.45s
Train Epoch: 1285 [61440/90000 (68%)]	Loss: -5.4922	Cost: 7.86s
Train Epoch: 1285 [81920/90000 (91%)]	Loss: -5.7336	Cost: 6.14s
Train Epoch: 1285 	Average Loss: -5.3055
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3003

Learning rate: 9.598079720050523e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1286 [0/90000 (0%)]	Loss: -1.1815	Cost: 35.71s
Train Epoch: 1286 [20480/90000 (23%)]	Loss: -5.9083	Cost: 8.85s
Train Epoch: 1286 [40960/90000 (45%)]	Loss: -6.0949	Cost: 12.15s
Train Epoch: 1286 [61440/90000 (68%)]	Loss: -6.0348	Cost: 6.53s
Train Epoch: 1286 [81920/90000 (91%)]	Loss: -5.8750	Cost: 6.70s
Train Epoch: 1286 	Average Loss: -5.6754
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4222

Learning rate: 9.597462455014565e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1287 [0/90000 (0%)]	Loss: -1.3173	Cost: 23.37s
Train Epoch: 1287 [20480/90000 (23%)]	Loss: -6.1842	Cost: 12.05s
Train Epoch: 1287 [40960/90000 (45%)]	Loss: -6.3234	Cost: 11.02s
Train Epoch: 1287 [61440/90000 (68%)]	Loss: -6.4584	Cost: 7.01s
Train Epoch: 1287 [81920/90000 (91%)]	Loss: -6.1099	Cost: 7.74s
Train Epoch: 1287 	Average Loss: -5.8803
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4851

Learning rate: 9.596844736227252e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1288 [0/90000 (0%)]	Loss: -1.1989	Cost: 22.14s
Train Epoch: 1288 [20480/90000 (23%)]	Loss: -6.0180	Cost: 7.72s
Train Epoch: 1288 [40960/90000 (45%)]	Loss: -5.7562	Cost: 9.24s
Train Epoch: 1288 [61440/90000 (68%)]	Loss: -6.1370	Cost: 8.68s
Train Epoch: 1288 [81920/90000 (91%)]	Loss: -5.8698	Cost: 8.60s
Train Epoch: 1288 	Average Loss: -5.6715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4331

Learning rate: 9.596226563749555e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1289 [0/90000 (0%)]	Loss: -0.9858	Cost: 20.60s
Train Epoch: 1289 [20480/90000 (23%)]	Loss: -6.1031	Cost: 8.48s
Train Epoch: 1289 [40960/90000 (45%)]	Loss: -6.4103	Cost: 8.98s
Train Epoch: 1289 [61440/90000 (68%)]	Loss: -6.3587	Cost: 8.78s
Train Epoch: 1289 [81920/90000 (91%)]	Loss: -6.2246	Cost: 8.36s
Train Epoch: 1289 	Average Loss: -5.8948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6982

Saving model as e1289_model.pt & e1289_waveforms_supplementary.hdf5
Learning rate: 9.595607937642481e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1290 [0/90000 (0%)]	Loss: -1.4464	Cost: 20.28s
Train Epoch: 1290 [20480/90000 (23%)]	Loss: -6.2668	Cost: 8.75s
Train Epoch: 1290 [40960/90000 (45%)]	Loss: -6.1943	Cost: 7.40s
Train Epoch: 1290 [61440/90000 (68%)]	Loss: -6.2318	Cost: 6.80s
Train Epoch: 1290 [81920/90000 (91%)]	Loss: -6.0390	Cost: 6.37s
Train Epoch: 1290 	Average Loss: -5.9603
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5095

Learning rate: 9.594988857967086e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1291 [0/90000 (0%)]	Loss: -1.0316	Cost: 20.84s
Train Epoch: 1291 [20480/90000 (23%)]	Loss: -6.2729	Cost: 9.01s
Train Epoch: 1291 [40960/90000 (45%)]	Loss: -6.1368	Cost: 11.96s
Train Epoch: 1291 [61440/90000 (68%)]	Loss: -6.4071	Cost: 11.22s
Train Epoch: 1291 [81920/90000 (91%)]	Loss: -6.0642	Cost: 12.62s
Train Epoch: 1291 	Average Loss: -5.8903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5796

Learning rate: 9.594369324784475e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1292 [0/90000 (0%)]	Loss: -1.0777	Cost: 21.55s
Train Epoch: 1292 [20480/90000 (23%)]	Loss: -6.2262	Cost: 10.85s
Train Epoch: 1292 [40960/90000 (45%)]	Loss: -6.4069	Cost: 13.02s
Train Epoch: 1292 [61440/90000 (68%)]	Loss: -6.6179	Cost: 13.96s
Train Epoch: 1292 [81920/90000 (91%)]	Loss: -6.1457	Cost: 12.33s
Train Epoch: 1292 	Average Loss: -5.9526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6170

Learning rate: 9.593749338155789e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1293 [0/90000 (0%)]	Loss: -1.5957	Cost: 38.75s
Train Epoch: 1293 [20480/90000 (23%)]	Loss: -6.2562	Cost: 12.47s
Train Epoch: 1293 [40960/90000 (45%)]	Loss: -6.2849	Cost: 12.28s
Train Epoch: 1293 [61440/90000 (68%)]	Loss: -5.8276	Cost: 12.27s
Train Epoch: 1293 [81920/90000 (91%)]	Loss: -5.9244	Cost: 8.37s
Train Epoch: 1293 	Average Loss: -5.7462
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4842

Learning rate: 9.59312889814222e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1294 [0/90000 (0%)]	Loss: -0.5527	Cost: 23.45s
Train Epoch: 1294 [20480/90000 (23%)]	Loss: -6.1125	Cost: 13.56s
Train Epoch: 1294 [40960/90000 (45%)]	Loss: -6.1332	Cost: 12.31s
Train Epoch: 1294 [61440/90000 (68%)]	Loss: -6.3224	Cost: 9.21s
Train Epoch: 1294 [81920/90000 (91%)]	Loss: -6.1380	Cost: 6.27s
Train Epoch: 1294 	Average Loss: -5.7905
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5717

Learning rate: 9.592508004805003e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1295 [0/90000 (0%)]	Loss: -1.1810	Cost: 27.22s
Train Epoch: 1295 [20480/90000 (23%)]	Loss: -6.0495	Cost: 6.37s
Train Epoch: 1295 [40960/90000 (45%)]	Loss: -6.3094	Cost: 7.66s
Train Epoch: 1295 [61440/90000 (68%)]	Loss: -6.2923	Cost: 8.99s
Train Epoch: 1295 [81920/90000 (91%)]	Loss: -6.2466	Cost: 9.05s
Train Epoch: 1295 	Average Loss: -5.8986
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7647

Saving model as e1295_model.pt & e1295_waveforms_supplementary.hdf5
Learning rate: 9.591886658205417e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1296 [0/90000 (0%)]	Loss: -0.8626	Cost: 25.74s
Train Epoch: 1296 [20480/90000 (23%)]	Loss: -6.5015	Cost: 10.87s
Train Epoch: 1296 [40960/90000 (45%)]	Loss: -6.2546	Cost: 9.74s
Train Epoch: 1296 [61440/90000 (68%)]	Loss: -6.1715	Cost: 8.63s
Train Epoch: 1296 [81920/90000 (91%)]	Loss: -5.9302	Cost: 8.10s
Train Epoch: 1296 	Average Loss: -5.8653
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3460

Learning rate: 9.591264858404789e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1297 [0/90000 (0%)]	Loss: -1.0868	Cost: 29.05s
Train Epoch: 1297 [20480/90000 (23%)]	Loss: -6.2156	Cost: 8.89s
Train Epoch: 1297 [40960/90000 (45%)]	Loss: -6.4222	Cost: 6.68s
Train Epoch: 1297 [61440/90000 (68%)]	Loss: -6.2728	Cost: 6.86s
Train Epoch: 1297 [81920/90000 (91%)]	Loss: -6.3431	Cost: 6.63s
Train Epoch: 1297 	Average Loss: -5.8940
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5807

Learning rate: 9.590642605464485e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1298 [0/90000 (0%)]	Loss: -0.7095	Cost: 19.22s
Train Epoch: 1298 [20480/90000 (23%)]	Loss: -6.2301	Cost: 7.52s
Train Epoch: 1298 [40960/90000 (45%)]	Loss: -6.3534	Cost: 9.50s
Train Epoch: 1298 [61440/90000 (68%)]	Loss: -6.4869	Cost: 11.57s
Train Epoch: 1298 [81920/90000 (91%)]	Loss: -6.2252	Cost: 12.40s
Train Epoch: 1298 	Average Loss: -5.9366
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6856

Learning rate: 9.59001989944592e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1299 [0/90000 (0%)]	Loss: -1.5563	Cost: 21.66s
Train Epoch: 1299 [20480/90000 (23%)]	Loss: -6.3995	Cost: 13.18s
Train Epoch: 1299 [40960/90000 (45%)]	Loss: -6.4315	Cost: 12.64s
Train Epoch: 1299 [61440/90000 (68%)]	Loss: -6.7315	Cost: 12.34s
Train Epoch: 1299 [81920/90000 (91%)]	Loss: -6.0836	Cost: 12.51s
Train Epoch: 1299 	Average Loss: -6.0655
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5949

Learning rate: 9.589396740410552e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1300 [0/90000 (0%)]	Loss: -1.0780	Cost: 24.56s
Train Epoch: 1300 [20480/90000 (23%)]	Loss: -6.2005	Cost: 13.58s
Train Epoch: 1300 [40960/90000 (45%)]	Loss: -6.3248	Cost: 12.91s
Train Epoch: 1300 [61440/90000 (68%)]	Loss: -6.5180	Cost: 11.69s
Train Epoch: 1300 [81920/90000 (91%)]	Loss: -6.2315	Cost: 5.98s
Train Epoch: 1300 	Average Loss: -6.0076
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7118

Learning rate: 9.588773128419886e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1301 [0/90000 (0%)]	Loss: -1.5546	Cost: 38.66s
Train Epoch: 1301 [20480/90000 (23%)]	Loss: -6.2104	Cost: 12.48s
Train Epoch: 1301 [40960/90000 (45%)]	Loss: -6.3758	Cost: 8.56s
Train Epoch: 1301 [61440/90000 (68%)]	Loss: -6.4117	Cost: 6.09s
Train Epoch: 1301 [81920/90000 (91%)]	Loss: -6.4135	Cost: 8.20s
Train Epoch: 1301 	Average Loss: -5.9781
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6869

Learning rate: 9.588149063535469e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1302 [0/90000 (0%)]	Loss: -1.5486	Cost: 27.36s
Train Epoch: 1302 [20480/90000 (23%)]	Loss: -6.4261	Cost: 10.69s
Train Epoch: 1302 [40960/90000 (45%)]	Loss: -6.5051	Cost: 7.15s
Train Epoch: 1302 [61440/90000 (68%)]	Loss: -6.4400	Cost: 8.04s
Train Epoch: 1302 [81920/90000 (91%)]	Loss: -6.3144	Cost: 8.78s
Train Epoch: 1302 	Average Loss: -6.0940
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7080

Learning rate: 9.587524545818893e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1303 [0/90000 (0%)]	Loss: -1.5378	Cost: 22.05s
Train Epoch: 1303 [20480/90000 (23%)]	Loss: -6.4416	Cost: 7.07s
Train Epoch: 1303 [40960/90000 (45%)]	Loss: -6.4923	Cost: 9.02s
Train Epoch: 1303 [61440/90000 (68%)]	Loss: -6.3116	Cost: 8.83s
Train Epoch: 1303 [81920/90000 (91%)]	Loss: -6.1959	Cost: 8.92s
Train Epoch: 1303 	Average Loss: -6.0276
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6779

Learning rate: 9.586899575331797e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1304 [0/90000 (0%)]	Loss: -0.9687	Cost: 21.86s
Train Epoch: 1304 [20480/90000 (23%)]	Loss: -6.4396	Cost: 8.58s
Train Epoch: 1304 [40960/90000 (45%)]	Loss: -6.2643	Cost: 6.89s
Train Epoch: 1304 [61440/90000 (68%)]	Loss: -6.6071	Cost: 8.25s
Train Epoch: 1304 [81920/90000 (91%)]	Loss: -6.2968	Cost: 8.32s
Train Epoch: 1304 	Average Loss: -6.0645
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8086

Saving model as e1304_model.pt & e1304_waveforms_supplementary.hdf5
Learning rate: 9.586274152135862e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1305 [0/90000 (0%)]	Loss: -1.7066	Cost: 21.14s
Train Epoch: 1305 [20480/90000 (23%)]	Loss: -6.4754	Cost: 10.40s
Train Epoch: 1305 [40960/90000 (45%)]	Loss: -6.6062	Cost: 14.78s
Train Epoch: 1305 [61440/90000 (68%)]	Loss: -6.5973	Cost: 12.80s
Train Epoch: 1305 [81920/90000 (91%)]	Loss: -6.3132	Cost: 12.08s
Train Epoch: 1305 	Average Loss: -6.1326
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7699

Learning rate: 9.585648276292814e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1306 [0/90000 (0%)]	Loss: -1.9792	Cost: 37.42s
Train Epoch: 1306 [20480/90000 (23%)]	Loss: -6.4241	Cost: 12.58s
Train Epoch: 1306 [40960/90000 (45%)]	Loss: -6.6867	Cost: 12.49s
Train Epoch: 1306 [61440/90000 (68%)]	Loss: -6.6736	Cost: 12.29s
Train Epoch: 1306 [81920/90000 (91%)]	Loss: -6.2094	Cost: 10.57s
Train Epoch: 1306 	Average Loss: -6.1574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6497

Learning rate: 9.585021947864428e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1307 [0/90000 (0%)]	Loss: -1.3647	Cost: 26.72s
Train Epoch: 1307 [20480/90000 (23%)]	Loss: -6.6563	Cost: 13.21s
Train Epoch: 1307 [40960/90000 (45%)]	Loss: -6.3587	Cost: 12.45s
Train Epoch: 1307 [61440/90000 (68%)]	Loss: -6.5543	Cost: 11.36s
Train Epoch: 1307 [81920/90000 (91%)]	Loss: -6.5494	Cost: 6.92s
Train Epoch: 1307 	Average Loss: -6.1310
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7652

Learning rate: 9.584395166912516e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1308 [0/90000 (0%)]	Loss: -1.5964	Cost: 31.25s
Train Epoch: 1308 [20480/90000 (23%)]	Loss: -6.6186	Cost: 9.15s
Train Epoch: 1308 [40960/90000 (45%)]	Loss: -6.5656	Cost: 12.45s
Train Epoch: 1308 [61440/90000 (68%)]	Loss: -6.5160	Cost: 6.66s
Train Epoch: 1308 [81920/90000 (91%)]	Loss: -6.3639	Cost: 6.57s
Train Epoch: 1308 	Average Loss: -6.1683
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6570

Learning rate: 9.583767933498941e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1309 [0/90000 (0%)]	Loss: -1.7725	Cost: 24.66s
Train Epoch: 1309 [20480/90000 (23%)]	Loss: -6.3921	Cost: 12.29s
Train Epoch: 1309 [40960/90000 (45%)]	Loss: -6.3999	Cost: 7.54s
Train Epoch: 1309 [61440/90000 (68%)]	Loss: -6.4271	Cost: 6.85s
Train Epoch: 1309 [81920/90000 (91%)]	Loss: -6.2314	Cost: 8.52s
Train Epoch: 1309 	Average Loss: -6.0375
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7337

Learning rate: 9.58314024768561e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1310 [0/90000 (0%)]	Loss: -1.4083	Cost: 19.15s
Train Epoch: 1310 [20480/90000 (23%)]	Loss: -6.3926	Cost: 6.80s
Train Epoch: 1310 [40960/90000 (45%)]	Loss: -6.5099	Cost: 10.37s
Train Epoch: 1310 [61440/90000 (68%)]	Loss: -6.6547	Cost: 8.90s
Train Epoch: 1310 [81920/90000 (91%)]	Loss: -6.5339	Cost: 8.73s
Train Epoch: 1310 	Average Loss: -6.1673
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9178

Saving model as e1310_model.pt & e1310_waveforms_supplementary.hdf5
Learning rate: 9.582512109534469e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1311 [0/90000 (0%)]	Loss: -1.4185	Cost: 33.85s
Train Epoch: 1311 [20480/90000 (23%)]	Loss: -6.5049	Cost: 8.83s
Train Epoch: 1311 [40960/90000 (45%)]	Loss: -6.4551	Cost: 8.26s
Train Epoch: 1311 [61440/90000 (68%)]	Loss: -6.3789	Cost: 5.94s
Train Epoch: 1311 [81920/90000 (91%)]	Loss: -6.1026	Cost: 6.48s
Train Epoch: 1311 	Average Loss: -6.0254
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5805

Learning rate: 9.581883519107515e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1312 [0/90000 (0%)]	Loss: -1.6622	Cost: 26.76s
Train Epoch: 1312 [20480/90000 (23%)]	Loss: -6.4418	Cost: 7.66s
Train Epoch: 1312 [40960/90000 (45%)]	Loss: -6.5575	Cost: 10.68s
Train Epoch: 1312 [61440/90000 (68%)]	Loss: -6.6690	Cost: 9.89s
Train Epoch: 1312 [81920/90000 (91%)]	Loss: -6.3408	Cost: 12.14s
Train Epoch: 1312 	Average Loss: -6.1027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6137

Learning rate: 9.581254476466788e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1313 [0/90000 (0%)]	Loss: -1.4433	Cost: 21.99s
Train Epoch: 1313 [20480/90000 (23%)]	Loss: -6.3152	Cost: 7.00s
Train Epoch: 1313 [40960/90000 (45%)]	Loss: -6.3532	Cost: 13.18s
Train Epoch: 1313 [61440/90000 (68%)]	Loss: -6.6086	Cost: 13.14s
Train Epoch: 1313 [81920/90000 (91%)]	Loss: -6.4146	Cost: 12.28s
Train Epoch: 1313 	Average Loss: -6.1062
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6092

Learning rate: 9.58062498167437e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1314 [0/90000 (0%)]	Loss: -1.0993	Cost: 27.85s
Train Epoch: 1314 [20480/90000 (23%)]	Loss: -6.2532	Cost: 12.75s
Train Epoch: 1314 [40960/90000 (45%)]	Loss: -6.6156	Cost: 12.39s
Train Epoch: 1314 [61440/90000 (68%)]	Loss: -6.7288	Cost: 12.47s
Train Epoch: 1314 [81920/90000 (91%)]	Loss: -6.3385	Cost: 9.28s
Train Epoch: 1314 	Average Loss: -6.1504
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5928

Learning rate: 9.579995034792391e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1315 [0/90000 (0%)]	Loss: -1.4309	Cost: 24.59s
Train Epoch: 1315 [20480/90000 (23%)]	Loss: -6.3352	Cost: 12.33s
Train Epoch: 1315 [40960/90000 (45%)]	Loss: -6.1596	Cost: 12.57s
Train Epoch: 1315 [61440/90000 (68%)]	Loss: -6.5222	Cost: 11.46s
Train Epoch: 1315 [81920/90000 (91%)]	Loss: -6.3429	Cost: 6.45s
Train Epoch: 1315 	Average Loss: -6.0223
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8208

Learning rate: 9.579364635883025e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1316 [0/90000 (0%)]	Loss: -1.2395	Cost: 29.01s
Train Epoch: 1316 [20480/90000 (23%)]	Loss: -6.6564	Cost: 13.22s
Train Epoch: 1316 [40960/90000 (45%)]	Loss: -6.7262	Cost: 12.19s
Train Epoch: 1316 [61440/90000 (68%)]	Loss: -6.8463	Cost: 6.59s
Train Epoch: 1316 [81920/90000 (91%)]	Loss: -6.5192	Cost: 6.23s
Train Epoch: 1316 	Average Loss: -6.2767
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8166

Learning rate: 9.57873378500849e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1317 [0/90000 (0%)]	Loss: -1.6818	Cost: 22.81s
Train Epoch: 1317 [20480/90000 (23%)]	Loss: -6.5449	Cost: 11.66s
Train Epoch: 1317 [40960/90000 (45%)]	Loss: -6.7669	Cost: 13.22s
Train Epoch: 1317 [61440/90000 (68%)]	Loss: -6.5321	Cost: 9.04s
Train Epoch: 1317 [81920/90000 (91%)]	Loss: -6.3984	Cost: 7.78s
Train Epoch: 1317 	Average Loss: -6.1451
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6894

Learning rate: 9.578102482231046e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1318 [0/90000 (0%)]	Loss: -1.0724	Cost: 22.82s
Train Epoch: 1318 [20480/90000 (23%)]	Loss: -6.3146	Cost: 8.41s
Train Epoch: 1318 [40960/90000 (45%)]	Loss: -6.3748	Cost: 8.54s
Train Epoch: 1318 [61440/90000 (68%)]	Loss: -6.4482	Cost: 8.75s
Train Epoch: 1318 [81920/90000 (91%)]	Loss: -6.4858	Cost: 8.45s
Train Epoch: 1318 	Average Loss: -6.0384
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7780

Learning rate: 9.577470727613003e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1319 [0/90000 (0%)]	Loss: -1.5481	Cost: 22.93s
Train Epoch: 1319 [20480/90000 (23%)]	Loss: -6.5216	Cost: 9.05s
Train Epoch: 1319 [40960/90000 (45%)]	Loss: -6.8178	Cost: 9.04s
Train Epoch: 1319 [61440/90000 (68%)]	Loss: -6.7490	Cost: 8.45s
Train Epoch: 1319 [81920/90000 (91%)]	Loss: -6.4560	Cost: 5.70s
Train Epoch: 1319 	Average Loss: -6.2240
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8882

Learning rate: 9.576838521216712e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1320 [0/90000 (0%)]	Loss: -1.3193	Cost: 22.50s
Train Epoch: 1320 [20480/90000 (23%)]	Loss: -6.6829	Cost: 7.42s
Train Epoch: 1320 [40960/90000 (45%)]	Loss: -6.9481	Cost: 6.91s
Train Epoch: 1320 [61440/90000 (68%)]	Loss: -6.6288	Cost: 7.09s
Train Epoch: 1320 [81920/90000 (91%)]	Loss: -6.3889	Cost: 16.48s
Train Epoch: 1320 	Average Loss: -6.2255
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7648

Learning rate: 9.576205863104567e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1321 [0/90000 (0%)]	Loss: -1.2559	Cost: 25.01s
Train Epoch: 1321 [20480/90000 (23%)]	Loss: -6.2594	Cost: 9.70s
Train Epoch: 1321 [40960/90000 (45%)]	Loss: -6.5157	Cost: 14.24s
Train Epoch: 1321 [61440/90000 (68%)]	Loss: -6.5986	Cost: 12.79s
Train Epoch: 1321 [81920/90000 (91%)]	Loss: -6.6623	Cost: 12.33s
Train Epoch: 1321 	Average Loss: -6.1476
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8991

Learning rate: 9.575572753339011e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1322 [0/90000 (0%)]	Loss: -1.3503	Cost: 29.35s
Train Epoch: 1322 [20480/90000 (23%)]	Loss: -6.7901	Cost: 15.50s
Train Epoch: 1322 [40960/90000 (45%)]	Loss: -6.5649	Cost: 15.48s
Train Epoch: 1322 [61440/90000 (68%)]	Loss: -6.7209	Cost: 12.00s
Train Epoch: 1322 [81920/90000 (91%)]	Loss: -6.6783	Cost: 10.20s
Train Epoch: 1322 	Average Loss: -6.3009
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8523

Learning rate: 9.574939191982527e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1323 [0/90000 (0%)]	Loss: -1.7107	Cost: 36.43s
Train Epoch: 1323 [20480/90000 (23%)]	Loss: -6.7675	Cost: 12.61s
Train Epoch: 1323 [40960/90000 (45%)]	Loss: -6.8441	Cost: 12.25s
Train Epoch: 1323 [61440/90000 (68%)]	Loss: -6.6338	Cost: 10.41s
Train Epoch: 1323 [81920/90000 (91%)]	Loss: -6.5144	Cost: 6.39s
Train Epoch: 1323 	Average Loss: -6.3360
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8003

Learning rate: 9.574305179097649e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1324 [0/90000 (0%)]	Loss: -2.1379	Cost: 24.16s
Train Epoch: 1324 [20480/90000 (23%)]	Loss: -6.7731	Cost: 12.69s
Train Epoch: 1324 [40960/90000 (45%)]	Loss: -6.6451	Cost: 7.48s
Train Epoch: 1324 [61440/90000 (68%)]	Loss: -6.8031	Cost: 6.21s
Train Epoch: 1324 [81920/90000 (91%)]	Loss: -6.4787	Cost: 8.09s
Train Epoch: 1324 	Average Loss: -6.2703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7644

Learning rate: 9.573670714746948e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1325 [0/90000 (0%)]	Loss: -1.8973	Cost: 26.10s
Train Epoch: 1325 [20480/90000 (23%)]	Loss: -6.3530	Cost: 13.63s
Train Epoch: 1325 [40960/90000 (45%)]	Loss: -6.5951	Cost: 12.31s
Train Epoch: 1325 [61440/90000 (68%)]	Loss: -6.7140	Cost: 8.32s
Train Epoch: 1325 [81920/90000 (91%)]	Loss: -6.5013	Cost: 6.10s
Train Epoch: 1325 	Average Loss: -6.2448
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8989

Learning rate: 9.573035798993046e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1326 [0/90000 (0%)]	Loss: -1.6872	Cost: 26.14s
Train Epoch: 1326 [20480/90000 (23%)]	Loss: -6.6723	Cost: 10.66s
Train Epoch: 1326 [40960/90000 (45%)]	Loss: -6.6640	Cost: 7.98s
Train Epoch: 1326 [61440/90000 (68%)]	Loss: -6.7737	Cost: 7.05s
Train Epoch: 1326 [81920/90000 (91%)]	Loss: -6.4215	Cost: 8.62s
Train Epoch: 1326 	Average Loss: -6.2632
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9224

Saving model as e1326_model.pt & e1326_waveforms_supplementary.hdf5
Learning rate: 9.572400431898604e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1327 [0/90000 (0%)]	Loss: -1.2565	Cost: 20.47s
Train Epoch: 1327 [20480/90000 (23%)]	Loss: -6.6733	Cost: 7.53s
Train Epoch: 1327 [40960/90000 (45%)]	Loss: -5.9519	Cost: 9.31s
Train Epoch: 1327 [61440/90000 (68%)]	Loss: -6.1560	Cost: 9.08s
Train Epoch: 1327 [81920/90000 (91%)]	Loss: -6.1542	Cost: 9.19s
Train Epoch: 1327 	Average Loss: -5.9981
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5621

Learning rate: 9.571764613526331e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1328 [0/90000 (0%)]	Loss: -1.7048	Cost: 19.25s
Train Epoch: 1328 [20480/90000 (23%)]	Loss: -6.1812	Cost: 8.99s
Train Epoch: 1328 [40960/90000 (45%)]	Loss: -6.2260	Cost: 9.10s
Train Epoch: 1328 [61440/90000 (68%)]	Loss: -6.7267	Cost: 8.05s
Train Epoch: 1328 [81920/90000 (91%)]	Loss: -6.2907	Cost: 9.29s
Train Epoch: 1328 	Average Loss: -6.0396
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7477

Learning rate: 9.571128343938982e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1329 [0/90000 (0%)]	Loss: -1.4269	Cost: 21.47s
Train Epoch: 1329 [20480/90000 (23%)]	Loss: -6.5748	Cost: 10.41s
Train Epoch: 1329 [40960/90000 (45%)]	Loss: -6.5889	Cost: 16.68s
Train Epoch: 1329 [61440/90000 (68%)]	Loss: -6.3891	Cost: 12.48s
Train Epoch: 1329 [81920/90000 (91%)]	Loss: -6.2366	Cost: 12.22s
Train Epoch: 1329 	Average Loss: -6.1146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8400

Learning rate: 9.570491623199352e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1330 [0/90000 (0%)]	Loss: -1.3539	Cost: 30.30s
Train Epoch: 1330 [20480/90000 (23%)]	Loss: -6.3995	Cost: 12.96s
Train Epoch: 1330 [40960/90000 (45%)]	Loss: -6.6045	Cost: 12.89s
Train Epoch: 1330 [61440/90000 (68%)]	Loss: -6.7379	Cost: 12.06s
Train Epoch: 1330 [81920/90000 (91%)]	Loss: -6.5566	Cost: 8.82s
Train Epoch: 1330 	Average Loss: -6.2187
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8240

Learning rate: 9.569854451370282e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1331 [0/90000 (0%)]	Loss: -1.6810	Cost: 26.15s
Train Epoch: 1331 [20480/90000 (23%)]	Loss: -6.3213	Cost: 12.35s
Train Epoch: 1331 [40960/90000 (45%)]	Loss: -6.3952	Cost: 12.42s
Train Epoch: 1331 [61440/90000 (68%)]	Loss: -6.6771	Cost: 8.54s
Train Epoch: 1331 [81920/90000 (91%)]	Loss: -6.5273	Cost: 6.23s
Train Epoch: 1331 	Average Loss: -6.0276
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7189

Learning rate: 9.569216828514662e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1332 [0/90000 (0%)]	Loss: -1.6970	Cost: 30.13s
Train Epoch: 1332 [20480/90000 (23%)]	Loss: -6.6602	Cost: 12.24s
Train Epoch: 1332 [40960/90000 (45%)]	Loss: -6.7778	Cost: 7.73s
Train Epoch: 1332 [61440/90000 (68%)]	Loss: -6.3556	Cost: 7.80s
Train Epoch: 1332 [81920/90000 (91%)]	Loss: -6.1749	Cost: 8.93s
Train Epoch: 1332 	Average Loss: -6.1214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5966

Learning rate: 9.56857875469542e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1333 [0/90000 (0%)]	Loss: -1.7511	Cost: 18.56s
Train Epoch: 1333 [20480/90000 (23%)]	Loss: -6.4731	Cost: 6.50s
Train Epoch: 1333 [40960/90000 (45%)]	Loss: -6.6244	Cost: 9.32s
Train Epoch: 1333 [61440/90000 (68%)]	Loss: -6.6355	Cost: 10.82s
Train Epoch: 1333 [81920/90000 (91%)]	Loss: -6.3918	Cost: 9.19s
Train Epoch: 1333 	Average Loss: -6.1444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8363

Learning rate: 9.567940229975531e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1334 [0/90000 (0%)]	Loss: -1.1018	Cost: 22.74s
Train Epoch: 1334 [20480/90000 (23%)]	Loss: -6.7097	Cost: 9.91s
Train Epoch: 1334 [40960/90000 (45%)]	Loss: -6.8717	Cost: 9.19s
Train Epoch: 1334 [61440/90000 (68%)]	Loss: -7.0231	Cost: 6.27s
Train Epoch: 1334 [81920/90000 (91%)]	Loss: -6.7899	Cost: 6.47s
Train Epoch: 1334 	Average Loss: -6.4226
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9687

Saving model as e1334_model.pt & e1334_waveforms_supplementary.hdf5
Learning rate: 9.567301254418016e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1335 [0/90000 (0%)]	Loss: -1.6464	Cost: 25.57s
Train Epoch: 1335 [20480/90000 (23%)]	Loss: -6.8922	Cost: 7.26s
Train Epoch: 1335 [40960/90000 (45%)]	Loss: -6.9890	Cost: 13.60s
Train Epoch: 1335 [61440/90000 (68%)]	Loss: -6.9702	Cost: 12.43s
Train Epoch: 1335 [81920/90000 (91%)]	Loss: -6.7553	Cost: 12.40s
Train Epoch: 1335 	Average Loss: -6.4402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0662

Saving model as e1335_model.pt & e1335_waveforms_supplementary.hdf5
Learning rate: 9.566661828085939e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1336 [0/90000 (0%)]	Loss: -1.1228	Cost: 28.05s
Train Epoch: 1336 [20480/90000 (23%)]	Loss: -6.4663	Cost: 13.40s
Train Epoch: 1336 [40960/90000 (45%)]	Loss: -6.8317	Cost: 12.54s
Train Epoch: 1336 [61440/90000 (68%)]	Loss: -6.8373	Cost: 12.38s
Train Epoch: 1336 [81920/90000 (91%)]	Loss: -6.4488	Cost: 11.43s
Train Epoch: 1336 	Average Loss: -6.2714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7267

Learning rate: 9.56602195104241e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1337 [0/90000 (0%)]	Loss: -1.4518	Cost: 37.80s
Train Epoch: 1337 [20480/90000 (23%)]	Loss: -6.5290	Cost: 13.11s
Train Epoch: 1337 [40960/90000 (45%)]	Loss: -6.7745	Cost: 12.41s
Train Epoch: 1337 [61440/90000 (68%)]	Loss: -6.8479	Cost: 10.00s
Train Epoch: 1337 [81920/90000 (91%)]	Loss: -6.5206	Cost: 5.95s
Train Epoch: 1337 	Average Loss: -6.2921
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9000

Learning rate: 9.56538162335058e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1338 [0/90000 (0%)]	Loss: -1.4044	Cost: 30.01s
Train Epoch: 1338 [20480/90000 (23%)]	Loss: -6.7357	Cost: 12.83s
Train Epoch: 1338 [40960/90000 (45%)]	Loss: -6.7699	Cost: 10.67s
Train Epoch: 1338 [61440/90000 (68%)]	Loss: -6.8069	Cost: 6.81s
Train Epoch: 1338 [81920/90000 (91%)]	Loss: -6.4507	Cost: 6.98s
Train Epoch: 1338 	Average Loss: -6.4037
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9145

Learning rate: 9.564740845073646e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1339 [0/90000 (0%)]	Loss: -1.1255	Cost: 29.14s
Train Epoch: 1339 [20480/90000 (23%)]	Loss: -6.9424	Cost: 7.55s
Train Epoch: 1339 [40960/90000 (45%)]	Loss: -6.7770	Cost: 9.11s
Train Epoch: 1339 [61440/90000 (68%)]	Loss: -6.9063	Cost: 8.61s
Train Epoch: 1339 [81920/90000 (91%)]	Loss: -6.6292	Cost: 8.59s
Train Epoch: 1339 	Average Loss: -6.4120
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0090

Learning rate: 9.564099616274855e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1340 [0/90000 (0%)]	Loss: -1.5865	Cost: 21.23s
Train Epoch: 1340 [20480/90000 (23%)]	Loss: -6.8585	Cost: 9.05s
Train Epoch: 1340 [40960/90000 (45%)]	Loss: -6.9594	Cost: 9.05s
Train Epoch: 1340 [61440/90000 (68%)]	Loss: -6.4902	Cost: 8.79s
Train Epoch: 1340 [81920/90000 (91%)]	Loss: -6.1266	Cost: 7.86s
Train Epoch: 1340 	Average Loss: -6.2827
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6693

Learning rate: 9.563457937017491e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1341 [0/90000 (0%)]	Loss: -1.5003	Cost: 20.00s
Train Epoch: 1341 [20480/90000 (23%)]	Loss: -6.4673	Cost: 7.59s
Train Epoch: 1341 [40960/90000 (45%)]	Loss: -6.6493	Cost: 6.59s
Train Epoch: 1341 [61440/90000 (68%)]	Loss: -6.7795	Cost: 7.98s
Train Epoch: 1341 [81920/90000 (91%)]	Loss: -6.4256	Cost: 14.37s
Train Epoch: 1341 	Average Loss: -6.1776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8608

Learning rate: 9.562815807364884e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1342 [0/90000 (0%)]	Loss: -1.5794	Cost: 21.62s
Train Epoch: 1342 [20480/90000 (23%)]	Loss: -6.7961	Cost: 10.44s
Train Epoch: 1342 [40960/90000 (45%)]	Loss: -6.9264	Cost: 15.93s
Train Epoch: 1342 [61440/90000 (68%)]	Loss: -7.0168	Cost: 13.98s
Train Epoch: 1342 [81920/90000 (91%)]	Loss: -6.9313	Cost: 12.28s
Train Epoch: 1342 	Average Loss: -6.4930
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1679

Saving model as e1342_model.pt & e1342_waveforms_supplementary.hdf5
Learning rate: 9.562173227380412e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1343 [0/90000 (0%)]	Loss: -1.8981	Cost: 27.36s
Train Epoch: 1343 [20480/90000 (23%)]	Loss: -6.7522	Cost: 14.91s
Train Epoch: 1343 [40960/90000 (45%)]	Loss: -6.7464	Cost: 14.72s
Train Epoch: 1343 [61440/90000 (68%)]	Loss: -7.0151	Cost: 12.20s
Train Epoch: 1343 [81920/90000 (91%)]	Loss: -6.8283	Cost: 12.17s
Train Epoch: 1343 	Average Loss: -6.4623
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0959

Learning rate: 9.561530197127494e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1344 [0/90000 (0%)]	Loss: -1.5069	Cost: 32.73s
Train Epoch: 1344 [20480/90000 (23%)]	Loss: -7.0192	Cost: 10.41s
Train Epoch: 1344 [40960/90000 (45%)]	Loss: -7.1239	Cost: 12.04s
Train Epoch: 1344 [61440/90000 (68%)]	Loss: -7.0836	Cost: 12.33s
Train Epoch: 1344 [81920/90000 (91%)]	Loss: -6.8178	Cost: 8.99s
Train Epoch: 1344 	Average Loss: -6.6273
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0195

Learning rate: 9.560886716669594e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1345 [0/90000 (0%)]	Loss: -2.1638	Cost: 24.12s
Train Epoch: 1345 [20480/90000 (23%)]	Loss: -7.0446	Cost: 12.87s
Train Epoch: 1345 [40960/90000 (45%)]	Loss: -7.0509	Cost: 11.41s
Train Epoch: 1345 [61440/90000 (68%)]	Loss: -6.6603	Cost: 6.07s
Train Epoch: 1345 [81920/90000 (91%)]	Loss: -6.5025	Cost: 6.84s
Train Epoch: 1345 	Average Loss: -6.4211
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0498

Learning rate: 9.560242786070223e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1346 [0/90000 (0%)]	Loss: -1.3452	Cost: 21.67s
Train Epoch: 1346 [20480/90000 (23%)]	Loss: -6.9040	Cost: 6.70s
Train Epoch: 1346 [40960/90000 (45%)]	Loss: -6.7177	Cost: 9.80s
Train Epoch: 1346 [61440/90000 (68%)]	Loss: -6.7337	Cost: 8.81s
Train Epoch: 1346 [81920/90000 (91%)]	Loss: -6.4814	Cost: 9.04s
Train Epoch: 1346 	Average Loss: -6.3592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0475

Learning rate: 9.559598405392933e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1347 [0/90000 (0%)]	Loss: -1.5800	Cost: 22.42s
Train Epoch: 1347 [20480/90000 (23%)]	Loss: -6.8027	Cost: 9.83s
Train Epoch: 1347 [40960/90000 (45%)]	Loss: -6.8136	Cost: 8.95s
Train Epoch: 1347 [61440/90000 (68%)]	Loss: -6.9829	Cost: 8.79s
Train Epoch: 1347 [81920/90000 (91%)]	Loss: -6.6894	Cost: 6.30s
Train Epoch: 1347 	Average Loss: -6.4028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9919

Learning rate: 9.55895357470132e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1348 [0/90000 (0%)]	Loss: -1.3622	Cost: 33.75s
Train Epoch: 1348 [20480/90000 (23%)]	Loss: -6.9993	Cost: 8.55s
Train Epoch: 1348 [40960/90000 (45%)]	Loss: -6.9960	Cost: 11.24s
Train Epoch: 1348 [61440/90000 (68%)]	Loss: -7.0920	Cost: 12.85s
Train Epoch: 1348 [81920/90000 (91%)]	Loss: -6.7286	Cost: 12.29s
Train Epoch: 1348 	Average Loss: -6.5353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1054

Learning rate: 9.55830829405903e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1349 [0/90000 (0%)]	Loss: -1.4530	Cost: 21.58s
Train Epoch: 1349 [20480/90000 (23%)]	Loss: -6.9837	Cost: 13.41s
Train Epoch: 1349 [40960/90000 (45%)]	Loss: -7.1563	Cost: 14.08s
Train Epoch: 1349 [61440/90000 (68%)]	Loss: -7.3215	Cost: 12.30s
Train Epoch: 1349 [81920/90000 (91%)]	Loss: -6.7841	Cost: 12.46s
Train Epoch: 1349 	Average Loss: -6.6809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1302

Learning rate: 9.557662563529747e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1350 [0/90000 (0%)]	Loss: -1.7200	Cost: 23.93s
Train Epoch: 1350 [20480/90000 (23%)]	Loss: -6.9539	Cost: 12.34s
Train Epoch: 1350 [40960/90000 (45%)]	Loss: -6.9415	Cost: 12.67s
Train Epoch: 1350 [61440/90000 (68%)]	Loss: -6.8801	Cost: 12.68s
Train Epoch: 1350 [81920/90000 (91%)]	Loss: -6.5088	Cost: 9.05s
Train Epoch: 1350 	Average Loss: -6.4635
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9268

Learning rate: 9.557016383177202e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1351 [0/90000 (0%)]	Loss: -1.1063	Cost: 24.27s
Train Epoch: 1351 [20480/90000 (23%)]	Loss: -6.3883	Cost: 12.85s
Train Epoch: 1351 [40960/90000 (45%)]	Loss: -6.8164	Cost: 9.92s
Train Epoch: 1351 [61440/90000 (68%)]	Loss: -6.9480	Cost: 6.30s
Train Epoch: 1351 [81920/90000 (91%)]	Loss: -6.6574	Cost: 6.96s
Train Epoch: 1351 	Average Loss: -6.2496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9343

Learning rate: 9.556369753065172e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1352 [0/90000 (0%)]	Loss: -1.2165	Cost: 30.74s
Train Epoch: 1352 [20480/90000 (23%)]	Loss: -6.9672	Cost: 9.22s
Train Epoch: 1352 [40960/90000 (45%)]	Loss: -6.8825	Cost: 7.06s
Train Epoch: 1352 [61440/90000 (68%)]	Loss: -7.0125	Cost: 6.71s
Train Epoch: 1352 [81920/90000 (91%)]	Loss: -6.6378	Cost: 8.51s
Train Epoch: 1352 	Average Loss: -6.4802
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0312

Learning rate: 9.555722673257475e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1353 [0/90000 (0%)]	Loss: -1.5588	Cost: 22.34s
Train Epoch: 1353 [20480/90000 (23%)]	Loss: -6.6378	Cost: 10.36s
Train Epoch: 1353 [40960/90000 (45%)]	Loss: -6.9351	Cost: 10.92s
Train Epoch: 1353 [61440/90000 (68%)]	Loss: -7.1083	Cost: 9.37s
Train Epoch: 1353 [81920/90000 (91%)]	Loss: -6.7105	Cost: 8.65s
Train Epoch: 1353 	Average Loss: -6.5576
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0294

Learning rate: 9.555075143817977e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1354 [0/90000 (0%)]	Loss: -1.3824	Cost: 24.66s
Train Epoch: 1354 [20480/90000 (23%)]	Loss: -6.9505	Cost: 8.92s
Train Epoch: 1354 [40960/90000 (45%)]	Loss: -7.1507	Cost: 9.09s
Train Epoch: 1354 [61440/90000 (68%)]	Loss: -7.0892	Cost: 8.02s
Train Epoch: 1354 [81920/90000 (91%)]	Loss: -7.1332	Cost: 6.61s
Train Epoch: 1354 	Average Loss: -6.6221
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1527

Learning rate: 9.554427164810586e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1355 [0/90000 (0%)]	Loss: -1.7358	Cost: 19.85s
Train Epoch: 1355 [20480/90000 (23%)]	Loss: -7.1235	Cost: 7.46s
Train Epoch: 1355 [40960/90000 (45%)]	Loss: -6.9575	Cost: 12.68s
Train Epoch: 1355 [61440/90000 (68%)]	Loss: -7.1277	Cost: 12.95s
Train Epoch: 1355 [81920/90000 (91%)]	Loss: -6.7839	Cost: 13.94s
Train Epoch: 1355 	Average Loss: -6.6044
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2233

Saving model as e1355_model.pt & e1355_waveforms_supplementary.hdf5
Learning rate: 9.553778736299254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1356 [0/90000 (0%)]	Loss: -2.7856	Cost: 26.44s
Train Epoch: 1356 [20480/90000 (23%)]	Loss: -7.0961	Cost: 14.99s
Train Epoch: 1356 [40960/90000 (45%)]	Loss: -7.0968	Cost: 13.12s
Train Epoch: 1356 [61440/90000 (68%)]	Loss: -7.0951	Cost: 12.20s
Train Epoch: 1356 [81920/90000 (91%)]	Loss: -7.0677	Cost: 8.80s
Train Epoch: 1356 	Average Loss: -6.6711
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1943

Learning rate: 9.55312985834798e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1357 [0/90000 (0%)]	Loss: -0.6297	Cost: 37.53s
Train Epoch: 1357 [20480/90000 (23%)]	Loss: -6.8452	Cost: 11.42s
Train Epoch: 1357 [40960/90000 (45%)]	Loss: -7.0249	Cost: 6.49s
Train Epoch: 1357 [61440/90000 (68%)]	Loss: -7.0858	Cost: 6.32s
Train Epoch: 1357 [81920/90000 (91%)]	Loss: -6.8310	Cost: 8.41s
Train Epoch: 1357 	Average Loss: -6.5879
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0890

Learning rate: 9.552480531020806e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1358 [0/90000 (0%)]	Loss: -1.6367	Cost: 24.51s
Train Epoch: 1358 [20480/90000 (23%)]	Loss: -7.1914	Cost: 11.08s
Train Epoch: 1358 [40960/90000 (45%)]	Loss: -7.1129	Cost: 11.63s
Train Epoch: 1358 [61440/90000 (68%)]	Loss: -7.0827	Cost: 6.47s
Train Epoch: 1358 [81920/90000 (91%)]	Loss: -6.8556	Cost: 6.59s
Train Epoch: 1358 	Average Loss: -6.7453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1273

Learning rate: 9.551830754381815e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1359 [0/90000 (0%)]	Loss: -1.9340	Cost: 35.70s
Train Epoch: 1359 [20480/90000 (23%)]	Loss: -7.1619	Cost: 8.93s
Train Epoch: 1359 [40960/90000 (45%)]	Loss: -7.1102	Cost: 6.68s
Train Epoch: 1359 [61440/90000 (68%)]	Loss: -7.2836	Cost: 7.13s
Train Epoch: 1359 [81920/90000 (91%)]	Loss: -6.7939	Cost: 9.00s
Train Epoch: 1359 	Average Loss: -6.7379
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1124

Learning rate: 9.55118052849514e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1360 [0/90000 (0%)]	Loss: -1.9017	Cost: 21.51s
Train Epoch: 1360 [20480/90000 (23%)]	Loss: -7.1152	Cost: 7.13s
Train Epoch: 1360 [40960/90000 (45%)]	Loss: -7.1273	Cost: 9.09s
Train Epoch: 1360 [61440/90000 (68%)]	Loss: -7.3753	Cost: 8.77s
Train Epoch: 1360 [81920/90000 (91%)]	Loss: -6.9496	Cost: 8.57s
Train Epoch: 1360 	Average Loss: -6.6945
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0795

Learning rate: 9.550529853424953e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1361 [0/90000 (0%)]	Loss: -1.9814	Cost: 23.22s
Train Epoch: 1361 [20480/90000 (23%)]	Loss: -6.8419	Cost: 8.74s
Train Epoch: 1361 [40960/90000 (45%)]	Loss: -6.9385	Cost: 8.89s
Train Epoch: 1361 [61440/90000 (68%)]	Loss: -7.1003	Cost: 8.98s
Train Epoch: 1361 [81920/90000 (91%)]	Loss: -6.9077	Cost: 9.00s
Train Epoch: 1361 	Average Loss: -6.6037
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2545

Saving model as e1361_model.pt & e1361_waveforms_supplementary.hdf5
Learning rate: 9.549878729235476e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1362 [0/90000 (0%)]	Loss: -1.4055	Cost: 26.63s
Train Epoch: 1362 [20480/90000 (23%)]	Loss: -7.0801	Cost: 9.38s
Train Epoch: 1362 [40960/90000 (45%)]	Loss: -7.1132	Cost: 6.22s
Train Epoch: 1362 [61440/90000 (68%)]	Loss: -7.1320	Cost: 6.94s
Train Epoch: 1362 [81920/90000 (91%)]	Loss: -6.9295	Cost: 10.14s
Train Epoch: 1362 	Average Loss: -6.6189
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1450

Learning rate: 9.549227155990973e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1363 [0/90000 (0%)]	Loss: -1.8629	Cost: 35.03s
Train Epoch: 1363 [20480/90000 (23%)]	Loss: -6.9922	Cost: 10.58s
Train Epoch: 1363 [40960/90000 (45%)]	Loss: -7.2209	Cost: 13.09s
Train Epoch: 1363 [61440/90000 (68%)]	Loss: -6.9711	Cost: 12.55s
Train Epoch: 1363 [81920/90000 (91%)]	Loss: -6.8689	Cost: 12.19s
Train Epoch: 1363 	Average Loss: -6.6487
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1655

Learning rate: 9.54857513375575e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1364 [0/90000 (0%)]	Loss: -1.0469	Cost: 23.43s
Train Epoch: 1364 [20480/90000 (23%)]	Loss: -7.1639	Cost: 14.73s
Train Epoch: 1364 [40960/90000 (45%)]	Loss: -7.3429	Cost: 11.88s
Train Epoch: 1364 [61440/90000 (68%)]	Loss: -7.3642	Cost: 12.45s
Train Epoch: 1364 [81920/90000 (91%)]	Loss: -7.0943	Cost: 12.52s
Train Epoch: 1364 	Average Loss: -6.7233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2834

Saving model as e1364_model.pt & e1364_waveforms_supplementary.hdf5
Learning rate: 9.547922662594159e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1365 [0/90000 (0%)]	Loss: -2.2322	Cost: 26.81s
Train Epoch: 1365 [20480/90000 (23%)]	Loss: -7.0170	Cost: 10.58s
Train Epoch: 1365 [40960/90000 (45%)]	Loss: -7.4039	Cost: 12.14s
Train Epoch: 1365 [61440/90000 (68%)]	Loss: -7.2638	Cost: 7.10s
Train Epoch: 1365 [81920/90000 (91%)]	Loss: -7.0159	Cost: 7.51s
Train Epoch: 1365 	Average Loss: -6.7928
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1949

Learning rate: 9.547269742570596e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1366 [0/90000 (0%)]	Loss: -1.9275	Cost: 21.30s
Train Epoch: 1366 [20480/90000 (23%)]	Loss: -6.7637	Cost: 7.94s
Train Epoch: 1366 [40960/90000 (45%)]	Loss: -6.7561	Cost: 7.42s
Train Epoch: 1366 [61440/90000 (68%)]	Loss: -6.8024	Cost: 8.73s
Train Epoch: 1366 [81920/90000 (91%)]	Loss: -6.6443	Cost: 8.76s
Train Epoch: 1366 	Average Loss: -6.4704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8447

Learning rate: 9.546616373749502e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1367 [0/90000 (0%)]	Loss: -2.2126	Cost: 25.42s
Train Epoch: 1367 [20480/90000 (23%)]	Loss: -6.5950	Cost: 9.11s
Train Epoch: 1367 [40960/90000 (45%)]	Loss: -6.7790	Cost: 9.71s
Train Epoch: 1367 [61440/90000 (68%)]	Loss: -7.0201	Cost: 8.69s
Train Epoch: 1367 [81920/90000 (91%)]	Loss: -6.8486	Cost: 8.42s
Train Epoch: 1367 	Average Loss: -6.4253
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1838

Learning rate: 9.545962556195362e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1368 [0/90000 (0%)]	Loss: -1.6143	Cost: 33.93s
Train Epoch: 1368 [20480/90000 (23%)]	Loss: -7.0201	Cost: 9.15s
Train Epoch: 1368 [40960/90000 (45%)]	Loss: -7.2325	Cost: 9.32s
Train Epoch: 1368 [61440/90000 (68%)]	Loss: -7.2920	Cost: 8.67s
Train Epoch: 1368 [81920/90000 (91%)]	Loss: -6.6886	Cost: 6.62s
Train Epoch: 1368 	Average Loss: -6.6212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1261

Learning rate: 9.545308289972705e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1369 [0/90000 (0%)]	Loss: -2.0035	Cost: 20.20s
Train Epoch: 1369 [20480/90000 (23%)]	Loss: -6.7664	Cost: 6.54s
Train Epoch: 1369 [40960/90000 (45%)]	Loss: -6.9933	Cost: 10.39s
Train Epoch: 1369 [61440/90000 (68%)]	Loss: -7.2513	Cost: 9.57s
Train Epoch: 1369 [81920/90000 (91%)]	Loss: -7.0401	Cost: 13.96s
Train Epoch: 1369 	Average Loss: -6.7002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2962

Saving model as e1369_model.pt & e1369_waveforms_supplementary.hdf5
Learning rate: 9.544653575146105e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1370 [0/90000 (0%)]	Loss: -1.8689	Cost: 24.90s
Train Epoch: 1370 [20480/90000 (23%)]	Loss: -7.2932	Cost: 11.19s
Train Epoch: 1370 [40960/90000 (45%)]	Loss: -7.5084	Cost: 12.50s
Train Epoch: 1370 [61440/90000 (68%)]	Loss: -7.2872	Cost: 12.39s
Train Epoch: 1370 [81920/90000 (91%)]	Loss: -6.9999	Cost: 12.65s
Train Epoch: 1370 	Average Loss: -6.8448
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3111

Saving model as e1370_model.pt & e1370_waveforms_supplementary.hdf5
Learning rate: 9.54399841178018e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1371 [0/90000 (0%)]	Loss: -1.2229	Cost: 24.75s
Train Epoch: 1371 [20480/90000 (23%)]	Loss: -7.3440	Cost: 14.13s
Train Epoch: 1371 [40960/90000 (45%)]	Loss: -7.2992	Cost: 12.62s
Train Epoch: 1371 [61440/90000 (68%)]	Loss: -7.3628	Cost: 11.35s
Train Epoch: 1371 [81920/90000 (91%)]	Loss: -7.0455	Cost: 6.12s
Train Epoch: 1371 	Average Loss: -6.8014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3006

Learning rate: 9.54334279993959e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1372 [0/90000 (0%)]	Loss: -1.7621	Cost: 40.28s
Train Epoch: 1372 [20480/90000 (23%)]	Loss: -6.9986	Cost: 11.93s
Train Epoch: 1372 [40960/90000 (45%)]	Loss: -7.0240	Cost: 7.52s
Train Epoch: 1372 [61440/90000 (68%)]	Loss: -7.3130	Cost: 6.31s
Train Epoch: 1372 [81920/90000 (91%)]	Loss: -6.9275	Cost: 8.30s
Train Epoch: 1372 	Average Loss: -6.7047
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2157

Learning rate: 9.542686739689042e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1373 [0/90000 (0%)]	Loss: -1.8444	Cost: 34.44s
Train Epoch: 1373 [20480/90000 (23%)]	Loss: -7.1957	Cost: 6.44s
Train Epoch: 1373 [40960/90000 (45%)]	Loss: -7.3919	Cost: 10.20s
Train Epoch: 1373 [61440/90000 (68%)]	Loss: -7.4247	Cost: 8.77s
Train Epoch: 1373 [81920/90000 (91%)]	Loss: -6.9724	Cost: 8.48s
Train Epoch: 1373 	Average Loss: -6.8041
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2860

Learning rate: 9.542030231093288e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1374 [0/90000 (0%)]	Loss: -1.9164	Cost: 20.53s
Train Epoch: 1374 [20480/90000 (23%)]	Loss: -7.2230	Cost: 7.66s
Train Epoch: 1374 [40960/90000 (45%)]	Loss: -7.2557	Cost: 8.88s
Train Epoch: 1374 [61440/90000 (68%)]	Loss: -7.2424	Cost: 9.45s
Train Epoch: 1374 [81920/90000 (91%)]	Loss: -7.1049	Cost: 9.65s
Train Epoch: 1374 	Average Loss: -6.8126
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2406

Learning rate: 9.541373274217122e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1375 [0/90000 (0%)]	Loss: -2.0759	Cost: 19.77s
Train Epoch: 1375 [20480/90000 (23%)]	Loss: -7.2091	Cost: 10.16s
Train Epoch: 1375 [40960/90000 (45%)]	Loss: -7.1333	Cost: 10.22s
Train Epoch: 1375 [61440/90000 (68%)]	Loss: -7.2945	Cost: 8.78s
Train Epoch: 1375 [81920/90000 (91%)]	Loss: -7.0607	Cost: 10.35s
Train Epoch: 1375 	Average Loss: -6.7664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1419

Learning rate: 9.540715869125385e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1376 [0/90000 (0%)]	Loss: -1.7488	Cost: 22.59s
Train Epoch: 1376 [20480/90000 (23%)]	Loss: -7.3297	Cost: 10.73s
Train Epoch: 1376 [40960/90000 (45%)]	Loss: -7.3189	Cost: 9.00s
Train Epoch: 1376 [61440/90000 (68%)]	Loss: -7.3411	Cost: 13.09s
Train Epoch: 1376 [81920/90000 (91%)]	Loss: -6.8699	Cost: 12.24s
Train Epoch: 1376 	Average Loss: -6.8133
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2505

Learning rate: 9.540058015882956e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1377 [0/90000 (0%)]	Loss: -1.9017	Cost: 33.36s
Train Epoch: 1377 [20480/90000 (23%)]	Loss: -7.1468	Cost: 12.79s
Train Epoch: 1377 [40960/90000 (45%)]	Loss: -7.2195	Cost: 12.56s
Train Epoch: 1377 [61440/90000 (68%)]	Loss: -7.5035	Cost: 12.33s
Train Epoch: 1377 [81920/90000 (91%)]	Loss: -6.9305	Cost: 12.53s
Train Epoch: 1377 	Average Loss: -6.8259
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0956

Learning rate: 9.539399714554766e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1378 [0/90000 (0%)]	Loss: -1.8568	Cost: 26.41s
Train Epoch: 1378 [20480/90000 (23%)]	Loss: -7.1905	Cost: 9.41s
Train Epoch: 1378 [40960/90000 (45%)]	Loss: -7.4053	Cost: 12.52s
Train Epoch: 1378 [61440/90000 (68%)]	Loss: -7.5790	Cost: 12.39s
Train Epoch: 1378 [81920/90000 (91%)]	Loss: -7.1167	Cost: 7.96s
Train Epoch: 1378 	Average Loss: -6.9010
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2492

Learning rate: 9.538740965205785e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1379 [0/90000 (0%)]	Loss: -2.3162	Cost: 30.60s
Train Epoch: 1379 [20480/90000 (23%)]	Loss: -7.3356	Cost: 13.05s
Train Epoch: 1379 [40960/90000 (45%)]	Loss: -7.5081	Cost: 12.05s
Train Epoch: 1379 [61440/90000 (68%)]	Loss: -7.6452	Cost: 6.55s
Train Epoch: 1379 [81920/90000 (91%)]	Loss: -7.0138	Cost: 7.14s
Train Epoch: 1379 	Average Loss: -6.9146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3640

Saving model as e1379_model.pt & e1379_waveforms_supplementary.hdf5
Learning rate: 9.538081767901031e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1380 [0/90000 (0%)]	Loss: -2.4526	Cost: 23.24s
Train Epoch: 1380 [20480/90000 (23%)]	Loss: -7.3591	Cost: 12.19s
Train Epoch: 1380 [40960/90000 (45%)]	Loss: -7.4693	Cost: 7.44s
Train Epoch: 1380 [61440/90000 (68%)]	Loss: -7.3406	Cost: 8.46s
Train Epoch: 1380 [81920/90000 (91%)]	Loss: -6.9949	Cost: 9.07s
Train Epoch: 1380 	Average Loss: -6.9719
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2866

Learning rate: 9.537422122705562e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1381 [0/90000 (0%)]	Loss: -1.9600	Cost: 20.96s
Train Epoch: 1381 [20480/90000 (23%)]	Loss: -7.1428	Cost: 8.22s
Train Epoch: 1381 [40960/90000 (45%)]	Loss: -7.0848	Cost: 8.75s
Train Epoch: 1381 [61440/90000 (68%)]	Loss: -6.6466	Cost: 8.80s
Train Epoch: 1381 [81920/90000 (91%)]	Loss: -6.3725	Cost: 8.50s
Train Epoch: 1381 	Average Loss: -6.4604
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6980

Learning rate: 9.536762029684484e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1382 [0/90000 (0%)]	Loss: -1.4778	Cost: 25.62s
Train Epoch: 1382 [20480/90000 (23%)]	Loss: -6.8590	Cost: 8.62s
Train Epoch: 1382 [40960/90000 (45%)]	Loss: -7.1306	Cost: 8.89s
Train Epoch: 1382 [61440/90000 (68%)]	Loss: -7.4139	Cost: 8.61s
Train Epoch: 1382 [81920/90000 (91%)]	Loss: -6.6732	Cost: 8.85s
Train Epoch: 1382 	Average Loss: -6.6469
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0328

Learning rate: 9.536101488902943e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1383 [0/90000 (0%)]	Loss: -1.9697	Cost: 22.92s
Train Epoch: 1383 [20480/90000 (23%)]	Loss: -6.9938	Cost: 9.39s
Train Epoch: 1383 [40960/90000 (45%)]	Loss: -7.2176	Cost: 6.85s
Train Epoch: 1383 [61440/90000 (68%)]	Loss: -7.2960	Cost: 6.45s
Train Epoch: 1383 [81920/90000 (91%)]	Loss: -7.1934	Cost: 6.43s
Train Epoch: 1383 	Average Loss: -6.7324
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3239

Learning rate: 9.535440500426135e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1384 [0/90000 (0%)]	Loss: -1.6743	Cost: 24.09s
Train Epoch: 1384 [20480/90000 (23%)]	Loss: -7.2872	Cost: 9.55s
Train Epoch: 1384 [40960/90000 (45%)]	Loss: -7.0079	Cost: 16.45s
Train Epoch: 1384 [61440/90000 (68%)]	Loss: -7.2054	Cost: 13.96s
Train Epoch: 1384 [81920/90000 (91%)]	Loss: -6.3648	Cost: 12.39s
Train Epoch: 1384 	Average Loss: -6.6091
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9021

Learning rate: 9.534779064319296e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1385 [0/90000 (0%)]	Loss: -1.2846	Cost: 24.17s
Train Epoch: 1385 [20480/90000 (23%)]	Loss: -6.9590	Cost: 15.26s
Train Epoch: 1385 [40960/90000 (45%)]	Loss: -7.0376	Cost: 14.81s
Train Epoch: 1385 [61440/90000 (68%)]	Loss: -7.2070	Cost: 12.35s
Train Epoch: 1385 [81920/90000 (91%)]	Loss: -7.0932	Cost: 12.36s
Train Epoch: 1385 	Average Loss: -6.7026
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3554

Learning rate: 9.534117180647705e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1386 [0/90000 (0%)]	Loss: -1.7317	Cost: 44.22s
Train Epoch: 1386 [20480/90000 (23%)]	Loss: -7.3280	Cost: 11.78s
Train Epoch: 1386 [40960/90000 (45%)]	Loss: -7.1904	Cost: 10.80s
Train Epoch: 1386 [61440/90000 (68%)]	Loss: -7.3864	Cost: 6.46s
Train Epoch: 1386 [81920/90000 (91%)]	Loss: -6.7185	Cost: 6.30s
Train Epoch: 1386 	Average Loss: -6.7174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0774

Learning rate: 9.533454849476689e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1387 [0/90000 (0%)]	Loss: -2.2750	Cost: 19.29s
Train Epoch: 1387 [20480/90000 (23%)]	Loss: -7.0395	Cost: 6.55s
Train Epoch: 1387 [40960/90000 (45%)]	Loss: -7.1155	Cost: 10.10s
Train Epoch: 1387 [61440/90000 (68%)]	Loss: -6.9601	Cost: 8.65s
Train Epoch: 1387 [81920/90000 (91%)]	Loss: -6.9954	Cost: 8.86s
Train Epoch: 1387 	Average Loss: -6.5773
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1014

Learning rate: 9.53279207087162e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1388 [0/90000 (0%)]	Loss: -1.3345	Cost: 20.94s
Train Epoch: 1388 [20480/90000 (23%)]	Loss: -7.0317	Cost: 9.10s
Train Epoch: 1388 [40960/90000 (45%)]	Loss: -7.3313	Cost: 9.18s
Train Epoch: 1388 [61440/90000 (68%)]	Loss: -7.5586	Cost: 8.96s
Train Epoch: 1388 [81920/90000 (91%)]	Loss: -7.3063	Cost: 8.72s
Train Epoch: 1388 	Average Loss: -6.8442
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4177

Saving model as e1388_model.pt & e1388_waveforms_supplementary.hdf5
Learning rate: 9.532128844897905e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1389 [0/90000 (0%)]	Loss: -1.5614	Cost: 26.39s
Train Epoch: 1389 [20480/90000 (23%)]	Loss: -7.5309	Cost: 7.38s
Train Epoch: 1389 [40960/90000 (45%)]	Loss: -7.6273	Cost: 6.67s
Train Epoch: 1389 [61440/90000 (68%)]	Loss: -7.3877	Cost: 6.76s
Train Epoch: 1389 [81920/90000 (91%)]	Loss: -6.9862	Cost: 11.80s
Train Epoch: 1389 	Average Loss: -6.9920
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1810

Learning rate: 9.531465171621007e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1390 [0/90000 (0%)]	Loss: -2.4270	Cost: 22.88s
Train Epoch: 1390 [20480/90000 (23%)]	Loss: -7.1503	Cost: 9.16s
Train Epoch: 1390 [40960/90000 (45%)]	Loss: -7.4348	Cost: 13.07s
Train Epoch: 1390 [61440/90000 (68%)]	Loss: -7.4684	Cost: 12.79s
Train Epoch: 1390 [81920/90000 (91%)]	Loss: -7.0405	Cost: 12.20s
Train Epoch: 1390 	Average Loss: -6.8749
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3119

Learning rate: 9.530801051106427e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1391 [0/90000 (0%)]	Loss: -2.0625	Cost: 25.09s
Train Epoch: 1391 [20480/90000 (23%)]	Loss: -7.2868	Cost: 14.17s
Train Epoch: 1391 [40960/90000 (45%)]	Loss: -6.8654	Cost: 13.22s
Train Epoch: 1391 [61440/90000 (68%)]	Loss: -7.2819	Cost: 12.53s
Train Epoch: 1391 [81920/90000 (91%)]	Loss: -6.8952	Cost: 11.72s
Train Epoch: 1391 	Average Loss: -6.7949
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2010

Learning rate: 9.53013648341971e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1392 [0/90000 (0%)]	Loss: -1.6672	Cost: 24.57s
Train Epoch: 1392 [20480/90000 (23%)]	Loss: -7.0059	Cost: 12.12s
Train Epoch: 1392 [40960/90000 (45%)]	Loss: -7.1078	Cost: 13.56s
Train Epoch: 1392 [61440/90000 (68%)]	Loss: -7.2818	Cost: 12.34s
Train Epoch: 1392 [81920/90000 (91%)]	Loss: -7.0158	Cost: 6.54s
Train Epoch: 1392 	Average Loss: -6.7776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4127

Learning rate: 9.529471468626449e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1393 [0/90000 (0%)]	Loss: -1.6635	Cost: 23.68s
Train Epoch: 1393 [20480/90000 (23%)]	Loss: -7.3710	Cost: 12.06s
Train Epoch: 1393 [40960/90000 (45%)]	Loss: -7.5775	Cost: 12.51s
Train Epoch: 1393 [61440/90000 (68%)]	Loss: -7.4610	Cost: 7.30s
Train Epoch: 1393 [81920/90000 (91%)]	Loss: -7.1880	Cost: 6.25s
Train Epoch: 1393 	Average Loss: -6.9930
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2557

Learning rate: 9.528806006792274e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1394 [0/90000 (0%)]	Loss: -1.6195	Cost: 27.04s
Train Epoch: 1394 [20480/90000 (23%)]	Loss: -7.3009	Cost: 11.58s
Train Epoch: 1394 [40960/90000 (45%)]	Loss: -7.6431	Cost: 12.48s
Train Epoch: 1394 [61440/90000 (68%)]	Loss: -7.5934	Cost: 6.24s
Train Epoch: 1394 [81920/90000 (91%)]	Loss: -7.4259	Cost: 6.16s
Train Epoch: 1394 	Average Loss: -7.0407
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3968

Learning rate: 9.528140097982867e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1395 [0/90000 (0%)]	Loss: -2.1906	Cost: 22.45s
Train Epoch: 1395 [20480/90000 (23%)]	Loss: -7.4783	Cost: 9.42s
Train Epoch: 1395 [40960/90000 (45%)]	Loss: -7.4023	Cost: 12.29s
Train Epoch: 1395 [61440/90000 (68%)]	Loss: -7.4750	Cost: 7.14s
Train Epoch: 1395 [81920/90000 (91%)]	Loss: -7.2500	Cost: 7.10s
Train Epoch: 1395 	Average Loss: -7.0416
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4071

Learning rate: 9.52747374226395e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1396 [0/90000 (0%)]	Loss: -1.4370	Cost: 22.24s
Train Epoch: 1396 [20480/90000 (23%)]	Loss: -7.6408	Cost: 7.52s
Train Epoch: 1396 [40960/90000 (45%)]	Loss: -7.6834	Cost: 8.11s
Train Epoch: 1396 [61440/90000 (68%)]	Loss: -7.6116	Cost: 8.86s
Train Epoch: 1396 [81920/90000 (91%)]	Loss: -7.3512	Cost: 8.76s
Train Epoch: 1396 	Average Loss: -7.0308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4586

Saving model as e1396_model.pt & e1396_waveforms_supplementary.hdf5
Learning rate: 9.526806939701286e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1397 [0/90000 (0%)]	Loss: -1.5693	Cost: 23.48s
Train Epoch: 1397 [20480/90000 (23%)]	Loss: -7.3323	Cost: 8.41s
Train Epoch: 1397 [40960/90000 (45%)]	Loss: -7.6135	Cost: 9.18s
Train Epoch: 1397 [61440/90000 (68%)]	Loss: -7.6031	Cost: 8.70s
Train Epoch: 1397 [81920/90000 (91%)]	Loss: -7.4558	Cost: 8.55s
Train Epoch: 1397 	Average Loss: -7.0598
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4946

Saving model as e1397_model.pt & e1397_waveforms_supplementary.hdf5
Learning rate: 9.526139690360691e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1398 [0/90000 (0%)]	Loss: -2.0154	Cost: 23.96s
Train Epoch: 1398 [20480/90000 (23%)]	Loss: -7.4185	Cost: 9.03s
Train Epoch: 1398 [40960/90000 (45%)]	Loss: -7.2471	Cost: 6.34s
Train Epoch: 1398 [61440/90000 (68%)]	Loss: -7.3153	Cost: 6.62s
Train Epoch: 1398 [81920/90000 (91%)]	Loss: -6.8930	Cost: 7.43s
Train Epoch: 1398 	Average Loss: -6.9248
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0656

Learning rate: 9.525471994308019e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1399 [0/90000 (0%)]	Loss: -1.5208	Cost: 27.37s
Train Epoch: 1399 [20480/90000 (23%)]	Loss: -7.1887	Cost: 9.56s
Train Epoch: 1399 [40960/90000 (45%)]	Loss: -7.3532	Cost: 13.68s
Train Epoch: 1399 [61440/90000 (68%)]	Loss: -7.5987	Cost: 12.60s
Train Epoch: 1399 [81920/90000 (91%)]	Loss: -7.2736	Cost: 12.36s
Train Epoch: 1399 	Average Loss: -6.9018
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4238

Learning rate: 9.524803851609165e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1400 [0/90000 (0%)]	Loss: -2.3263	Cost: 40.83s
Train Epoch: 1400 [20480/90000 (23%)]	Loss: -7.5449	Cost: 13.45s
Train Epoch: 1400 [40960/90000 (45%)]	Loss: -7.5652	Cost: 13.24s
Train Epoch: 1400 [61440/90000 (68%)]	Loss: -7.5657	Cost: 12.19s
Train Epoch: 1400 [81920/90000 (91%)]	Loss: -7.4745	Cost: 7.33s
Train Epoch: 1400 	Average Loss: -7.1046
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4637

Learning rate: 9.524135262330076e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1401 [0/90000 (0%)]	Loss: -1.5357	Cost: 29.26s
Train Epoch: 1401 [20480/90000 (23%)]	Loss: -7.5807	Cost: 14.06s
Train Epoch: 1401 [40960/90000 (45%)]	Loss: -7.6950	Cost: 10.79s
Train Epoch: 1401 [61440/90000 (68%)]	Loss: -7.5264	Cost: 6.24s
Train Epoch: 1401 [81920/90000 (91%)]	Loss: -7.1205	Cost: 6.83s
Train Epoch: 1401 	Average Loss: -7.0729
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5589

Saving model as e1401_model.pt & e1401_waveforms_supplementary.hdf5
Learning rate: 9.523466226536737e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1402 [0/90000 (0%)]	Loss: -2.5497	Cost: 26.87s
Train Epoch: 1402 [20480/90000 (23%)]	Loss: -7.1908	Cost: 10.79s
Train Epoch: 1402 [40960/90000 (45%)]	Loss: -7.4744	Cost: 6.49s
Train Epoch: 1402 [61440/90000 (68%)]	Loss: -7.5614	Cost: 6.17s
Train Epoch: 1402 [81920/90000 (91%)]	Loss: -7.3986	Cost: 8.48s
Train Epoch: 1402 	Average Loss: -6.9571
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3793

Learning rate: 9.52279674429518e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1403 [0/90000 (0%)]	Loss: -2.3659	Cost: 27.13s
Train Epoch: 1403 [20480/90000 (23%)]	Loss: -7.3736	Cost: 6.69s
Train Epoch: 1403 [40960/90000 (45%)]	Loss: -7.6288	Cost: 8.38s
Train Epoch: 1403 [61440/90000 (68%)]	Loss: -7.6376	Cost: 8.78s
Train Epoch: 1403 [81920/90000 (91%)]	Loss: -7.3785	Cost: 8.79s
Train Epoch: 1403 	Average Loss: -7.0253
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2473

Learning rate: 9.522126815671481e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1404 [0/90000 (0%)]	Loss: -1.6501	Cost: 29.55s
Train Epoch: 1404 [20480/90000 (23%)]	Loss: -7.3590	Cost: 8.93s
Train Epoch: 1404 [40960/90000 (45%)]	Loss: -7.4305	Cost: 9.07s
Train Epoch: 1404 [61440/90000 (68%)]	Loss: -7.5330	Cost: 7.98s
Train Epoch: 1404 [81920/90000 (91%)]	Loss: -7.3334	Cost: 5.91s
Train Epoch: 1404 	Average Loss: -6.9816
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5870

Saving model as e1404_model.pt & e1404_waveforms_supplementary.hdf5
Learning rate: 9.521456440731758e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1405 [0/90000 (0%)]	Loss: -2.3949	Cost: 21.52s
Train Epoch: 1405 [20480/90000 (23%)]	Loss: -7.7585	Cost: 8.00s
Train Epoch: 1405 [40960/90000 (45%)]	Loss: -7.6296	Cost: 11.37s
Train Epoch: 1405 [61440/90000 (68%)]	Loss: -7.7289	Cost: 13.72s
Train Epoch: 1405 [81920/90000 (91%)]	Loss: -7.2516	Cost: 12.36s
Train Epoch: 1405 	Average Loss: -7.1991
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3212

Learning rate: 9.520785619542176e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1406 [0/90000 (0%)]	Loss: -1.9900	Cost: 26.85s
Train Epoch: 1406 [20480/90000 (23%)]	Loss: -7.3253	Cost: 7.19s
Train Epoch: 1406 [40960/90000 (45%)]	Loss: -7.6376	Cost: 20.35s
Train Epoch: 1406 [61440/90000 (68%)]	Loss: -7.5685	Cost: 12.45s
Train Epoch: 1406 [81920/90000 (91%)]	Loss: -7.3558	Cost: 12.10s
Train Epoch: 1406 	Average Loss: -7.0139
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6623

Saving model as e1406_model.pt & e1406_waveforms_supplementary.hdf5
Learning rate: 9.520114352168938e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1407 [0/90000 (0%)]	Loss: -2.3057	Cost: 41.16s
Train Epoch: 1407 [20480/90000 (23%)]	Loss: -7.6106	Cost: 12.58s
Train Epoch: 1407 [40960/90000 (45%)]	Loss: -7.7073	Cost: 12.15s
Train Epoch: 1407 [61440/90000 (68%)]	Loss: -7.4507	Cost: 9.04s
Train Epoch: 1407 [81920/90000 (91%)]	Loss: -7.2647	Cost: 6.09s
Train Epoch: 1407 	Average Loss: -7.1164
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2753

Learning rate: 9.519442638678302e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1408 [0/90000 (0%)]	Loss: -1.8042	Cost: 22.53s
Train Epoch: 1408 [20480/90000 (23%)]	Loss: -7.5133	Cost: 9.78s
Train Epoch: 1408 [40960/90000 (45%)]	Loss: -7.4365	Cost: 6.65s
Train Epoch: 1408 [61440/90000 (68%)]	Loss: -7.5140	Cost: 7.00s
Train Epoch: 1408 [81920/90000 (91%)]	Loss: -7.2692	Cost: 9.17s
Train Epoch: 1408 	Average Loss: -7.0770
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3309

Learning rate: 9.518770479136558e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1409 [0/90000 (0%)]	Loss: -1.9918	Cost: 22.70s
Train Epoch: 1409 [20480/90000 (23%)]	Loss: -7.3649	Cost: 8.27s
Train Epoch: 1409 [40960/90000 (45%)]	Loss: -7.1123	Cost: 9.20s
Train Epoch: 1409 [61440/90000 (68%)]	Loss: -7.1917	Cost: 9.04s
Train Epoch: 1409 [81920/90000 (91%)]	Loss: -7.1680	Cost: 9.04s
Train Epoch: 1409 	Average Loss: -6.9266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3334

Learning rate: 9.518097873610047e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1410 [0/90000 (0%)]	Loss: -2.0078	Cost: 22.40s
Train Epoch: 1410 [20480/90000 (23%)]	Loss: -7.3784	Cost: 9.33s
Train Epoch: 1410 [40960/90000 (45%)]	Loss: -7.4777	Cost: 8.89s
Train Epoch: 1410 [61440/90000 (68%)]	Loss: -7.5249	Cost: 8.48s
Train Epoch: 1410 [81920/90000 (91%)]	Loss: -7.4828	Cost: 5.69s
Train Epoch: 1410 	Average Loss: -7.1331
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6522

Learning rate: 9.517424822165155e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1411 [0/90000 (0%)]	Loss: -2.5240	Cost: 23.04s
Train Epoch: 1411 [20480/90000 (23%)]	Loss: -7.8877	Cost: 6.83s
Train Epoch: 1411 [40960/90000 (45%)]	Loss: -7.6906	Cost: 8.00s
Train Epoch: 1411 [61440/90000 (68%)]	Loss: -7.6282	Cost: 8.51s
Train Epoch: 1411 [81920/90000 (91%)]	Loss: -7.1099	Cost: 15.41s
Train Epoch: 1411 	Average Loss: -7.1649
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2334

Learning rate: 9.516751324868306e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1412 [0/90000 (0%)]	Loss: -1.3285	Cost: 28.05s
Train Epoch: 1412 [20480/90000 (23%)]	Loss: -6.9967	Cost: 11.18s
Train Epoch: 1412 [40960/90000 (45%)]	Loss: -7.2709	Cost: 12.66s
Train Epoch: 1412 [61440/90000 (68%)]	Loss: -7.4889	Cost: 12.44s
Train Epoch: 1412 [81920/90000 (91%)]	Loss: -7.2330	Cost: 12.57s
Train Epoch: 1412 	Average Loss: -6.8870
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3100

Learning rate: 9.516077381785973e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1413 [0/90000 (0%)]	Loss: -2.4484	Cost: 38.66s
Train Epoch: 1413 [20480/90000 (23%)]	Loss: -7.7081	Cost: 13.77s
Train Epoch: 1413 [40960/90000 (45%)]	Loss: -7.7533	Cost: 12.69s
Train Epoch: 1413 [61440/90000 (68%)]	Loss: -7.7783	Cost: 11.72s
Train Epoch: 1413 [81920/90000 (91%)]	Loss: -7.5583	Cost: 6.19s
Train Epoch: 1413 	Average Loss: -7.2885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6952

Saving model as e1413_model.pt & e1413_waveforms_supplementary.hdf5
Learning rate: 9.515402992984673e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1414 [0/90000 (0%)]	Loss: -2.5711	Cost: 31.77s
Train Epoch: 1414 [20480/90000 (23%)]	Loss: -7.7941	Cost: 11.98s
Train Epoch: 1414 [40960/90000 (45%)]	Loss: -7.8666	Cost: 11.87s
Train Epoch: 1414 [61440/90000 (68%)]	Loss: -7.6425	Cost: 6.10s
Train Epoch: 1414 [81920/90000 (91%)]	Loss: -7.5669	Cost: 6.20s
Train Epoch: 1414 	Average Loss: -7.2793
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5828

Learning rate: 9.514728158530964e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1415 [0/90000 (0%)]	Loss: -1.9030	Cost: 31.73s
Train Epoch: 1415 [20480/90000 (23%)]	Loss: -7.6501	Cost: 12.09s
Train Epoch: 1415 [40960/90000 (45%)]	Loss: -7.6833	Cost: 7.35s
Train Epoch: 1415 [61440/90000 (68%)]	Loss: -7.9408	Cost: 6.31s
Train Epoch: 1415 [81920/90000 (91%)]	Loss: -7.5834	Cost: 7.99s
Train Epoch: 1415 	Average Loss: -7.3080
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3046

Learning rate: 9.514052878491448e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1416 [0/90000 (0%)]	Loss: -2.0501	Cost: 21.12s
Train Epoch: 1416 [20480/90000 (23%)]	Loss: -6.7102	Cost: 6.79s
Train Epoch: 1416 [40960/90000 (45%)]	Loss: -7.0333	Cost: 9.07s
Train Epoch: 1416 [61440/90000 (68%)]	Loss: -7.1345	Cost: 8.86s
Train Epoch: 1416 [81920/90000 (91%)]	Loss: -6.9919	Cost: 8.44s
Train Epoch: 1416 	Average Loss: -6.5883
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3520

Learning rate: 9.513377152932777e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1417 [0/90000 (0%)]	Loss: -1.4954	Cost: 21.42s
Train Epoch: 1417 [20480/90000 (23%)]	Loss: -7.5090	Cost: 6.92s
Train Epoch: 1417 [40960/90000 (45%)]	Loss: -7.5456	Cost: 9.34s
Train Epoch: 1417 [61440/90000 (68%)]	Loss: -7.6326	Cost: 8.61s
Train Epoch: 1417 [81920/90000 (91%)]	Loss: -7.5097	Cost: 8.53s
Train Epoch: 1417 	Average Loss: -7.1570
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4733

Learning rate: 9.512700981921638e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1418 [0/90000 (0%)]	Loss: -1.7502	Cost: 23.80s
Train Epoch: 1418 [20480/90000 (23%)]	Loss: -7.6516	Cost: 8.78s
Train Epoch: 1418 [40960/90000 (45%)]	Loss: -7.6320	Cost: 9.08s
Train Epoch: 1418 [61440/90000 (68%)]	Loss: -7.6730	Cost: 9.04s
Train Epoch: 1418 [81920/90000 (91%)]	Loss: -7.4871	Cost: 6.46s
Train Epoch: 1418 	Average Loss: -7.2048
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5449

Learning rate: 9.512024365524768e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1419 [0/90000 (0%)]	Loss: -2.5268	Cost: 19.61s
Train Epoch: 1419 [20480/90000 (23%)]	Loss: -7.4559	Cost: 7.58s
Train Epoch: 1419 [40960/90000 (45%)]	Loss: -7.6337	Cost: 15.77s
Train Epoch: 1419 [61440/90000 (68%)]	Loss: -7.7057	Cost: 12.84s
Train Epoch: 1419 [81920/90000 (91%)]	Loss: -7.5863	Cost: 13.22s
Train Epoch: 1419 	Average Loss: -7.2194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5561

Learning rate: 9.511347303808946e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1420 [0/90000 (0%)]	Loss: -2.8280	Cost: 26.55s
Train Epoch: 1420 [20480/90000 (23%)]	Loss: -7.8680	Cost: 12.47s
Train Epoch: 1420 [40960/90000 (45%)]	Loss: -7.7830	Cost: 13.49s
Train Epoch: 1420 [61440/90000 (68%)]	Loss: -7.8410	Cost: 12.26s
Train Epoch: 1420 [81920/90000 (91%)]	Loss: -6.4843	Cost: 12.19s
Train Epoch: 1420 	Average Loss: -7.1271
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9660

Learning rate: 9.510669796840995e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1421 [0/90000 (0%)]	Loss: -2.0354	Cost: 29.70s
Train Epoch: 1421 [20480/90000 (23%)]	Loss: -7.2478	Cost: 11.16s
Train Epoch: 1421 [40960/90000 (45%)]	Loss: -7.2600	Cost: 12.59s
Train Epoch: 1421 [61440/90000 (68%)]	Loss: -7.5484	Cost: 12.14s
Train Epoch: 1421 [81920/90000 (91%)]	Loss: -7.3856	Cost: 7.35s
Train Epoch: 1421 	Average Loss: -6.9337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5478

Learning rate: 9.509991844687784e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1422 [0/90000 (0%)]	Loss: -2.3165	Cost: 24.50s
Train Epoch: 1422 [20480/90000 (23%)]	Loss: -7.6321	Cost: 9.96s
Train Epoch: 1422 [40960/90000 (45%)]	Loss: -7.9523	Cost: 10.50s
Train Epoch: 1422 [61440/90000 (68%)]	Loss: -7.7651	Cost: 6.18s
Train Epoch: 1422 [81920/90000 (91%)]	Loss: -7.3613	Cost: 6.41s
Train Epoch: 1422 	Average Loss: -7.2717
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6587

Learning rate: 9.509313447416221e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1423 [0/90000 (0%)]	Loss: -2.3933	Cost: 25.76s
Train Epoch: 1423 [20480/90000 (23%)]	Loss: -7.7598	Cost: 14.01s
Train Epoch: 1423 [40960/90000 (45%)]	Loss: -7.8755	Cost: 9.32s
Train Epoch: 1423 [61440/90000 (68%)]	Loss: -7.5069	Cost: 7.24s
Train Epoch: 1423 [81920/90000 (91%)]	Loss: -7.3660	Cost: 8.48s
Train Epoch: 1423 	Average Loss: -7.3089
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5927

Learning rate: 9.508634605093264e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1424 [0/90000 (0%)]	Loss: -2.1511	Cost: 21.68s
Train Epoch: 1424 [20480/90000 (23%)]	Loss: -7.8130	Cost: 12.31s
Train Epoch: 1424 [40960/90000 (45%)]	Loss: -7.7235	Cost: 9.22s
Train Epoch: 1424 [61440/90000 (68%)]	Loss: -7.7010	Cost: 8.95s
Train Epoch: 1424 [81920/90000 (91%)]	Loss: -7.1154	Cost: 8.62s
Train Epoch: 1424 	Average Loss: -7.1801
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4744

Learning rate: 9.507955317785911e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1425 [0/90000 (0%)]	Loss: -1.2801	Cost: 20.71s
Train Epoch: 1425 [20480/90000 (23%)]	Loss: -7.5117	Cost: 8.41s
Train Epoch: 1425 [40960/90000 (45%)]	Loss: -7.9129	Cost: 7.33s
Train Epoch: 1425 [61440/90000 (68%)]	Loss: -7.8514	Cost: 8.99s
Train Epoch: 1425 [81920/90000 (91%)]	Loss: -7.4225	Cost: 8.66s
Train Epoch: 1425 	Average Loss: -7.2044
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5028

Learning rate: 9.507275585561206e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1426 [0/90000 (0%)]	Loss: -2.1475	Cost: 35.47s
Train Epoch: 1426 [20480/90000 (23%)]	Loss: -7.9034	Cost: 8.91s
Train Epoch: 1426 [40960/90000 (45%)]	Loss: -7.7306	Cost: 8.93s
Train Epoch: 1426 [61440/90000 (68%)]	Loss: -7.8196	Cost: 8.59s
Train Epoch: 1426 [81920/90000 (91%)]	Loss: -7.6150	Cost: 8.21s
Train Epoch: 1426 	Average Loss: -7.4064
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6793

Learning rate: 9.506595408486236e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1427 [0/90000 (0%)]	Loss: -2.1886	Cost: 22.56s
Train Epoch: 1427 [20480/90000 (23%)]	Loss: -7.7961	Cost: 8.30s
Train Epoch: 1427 [40960/90000 (45%)]	Loss: -7.6758	Cost: 6.96s
Train Epoch: 1427 [61440/90000 (68%)]	Loss: -7.7344	Cost: 6.51s
Train Epoch: 1427 [81920/90000 (91%)]	Loss: -7.4128	Cost: 11.31s
Train Epoch: 1427 	Average Loss: -7.3093
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2737

Learning rate: 9.505914786628128e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1428 [0/90000 (0%)]	Loss: -1.8265	Cost: 21.35s
Train Epoch: 1428 [20480/90000 (23%)]	Loss: -7.4369	Cost: 9.99s
Train Epoch: 1428 [40960/90000 (45%)]	Loss: -7.3814	Cost: 11.84s
Train Epoch: 1428 [61440/90000 (68%)]	Loss: -7.5195	Cost: 13.50s
Train Epoch: 1428 [81920/90000 (91%)]	Loss: -7.5506	Cost: 13.31s
Train Epoch: 1428 	Average Loss: -7.0630
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7260

Saving model as e1428_model.pt & e1428_waveforms_supplementary.hdf5
Learning rate: 9.505233720054063e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1429 [0/90000 (0%)]	Loss: -2.5651	Cost: 24.64s
Train Epoch: 1429 [20480/90000 (23%)]	Loss: -7.9555	Cost: 14.37s
Train Epoch: 1429 [40960/90000 (45%)]	Loss: -7.8033	Cost: 14.53s
Train Epoch: 1429 [61440/90000 (68%)]	Loss: -7.7853	Cost: 12.34s
Train Epoch: 1429 [81920/90000 (91%)]	Loss: -7.6259	Cost: 8.50s
Train Epoch: 1429 	Average Loss: -7.3824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6964

Learning rate: 9.504552208831255e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1430 [0/90000 (0%)]	Loss: -2.8791	Cost: 27.51s
Train Epoch: 1430 [20480/90000 (23%)]	Loss: -7.9356	Cost: 13.10s
Train Epoch: 1430 [40960/90000 (45%)]	Loss: -7.9071	Cost: 11.47s
Train Epoch: 1430 [61440/90000 (68%)]	Loss: -7.8976	Cost: 6.09s
Train Epoch: 1430 [81920/90000 (91%)]	Loss: -7.8430	Cost: 6.97s
Train Epoch: 1430 	Average Loss: -7.4197
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9066

Saving model as e1430_model.pt & e1430_waveforms_supplementary.hdf5
Learning rate: 9.503870253026966e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1431 [0/90000 (0%)]	Loss: -1.9311	Cost: 27.68s
Train Epoch: 1431 [20480/90000 (23%)]	Loss: -7.9400	Cost: 7.05s
Train Epoch: 1431 [40960/90000 (45%)]	Loss: -7.9935	Cost: 6.78s
Train Epoch: 1431 [61440/90000 (68%)]	Loss: -7.7548	Cost: 7.69s
Train Epoch: 1431 [81920/90000 (91%)]	Loss: -7.3894	Cost: 8.90s
Train Epoch: 1431 	Average Loss: -7.3714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6845

Learning rate: 9.503187852708506e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1432 [0/90000 (0%)]	Loss: -2.1650	Cost: 24.57s
Train Epoch: 1432 [20480/90000 (23%)]	Loss: -7.6964	Cost: 7.79s
Train Epoch: 1432 [40960/90000 (45%)]	Loss: -7.8561	Cost: 9.28s
Train Epoch: 1432 [61440/90000 (68%)]	Loss: -7.9230	Cost: 8.70s
Train Epoch: 1432 [81920/90000 (91%)]	Loss: -7.4676	Cost: 8.38s
Train Epoch: 1432 	Average Loss: -7.3846
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6708

Learning rate: 9.502505007943222e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1433 [0/90000 (0%)]	Loss: -2.6486	Cost: 21.86s
Train Epoch: 1433 [20480/90000 (23%)]	Loss: -7.6143	Cost: 9.32s
Train Epoch: 1433 [40960/90000 (45%)]	Loss: -7.7841	Cost: 9.40s
Train Epoch: 1433 [61440/90000 (68%)]	Loss: -7.8205	Cost: 8.68s
Train Epoch: 1433 [81920/90000 (91%)]	Loss: -7.8843	Cost: 10.45s
Train Epoch: 1433 	Average Loss: -7.3627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7345

Learning rate: 9.50182171879851e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1434 [0/90000 (0%)]	Loss: -2.6120	Cost: 19.10s
Train Epoch: 1434 [20480/90000 (23%)]	Loss: -7.7836	Cost: 9.80s
Train Epoch: 1434 [40960/90000 (45%)]	Loss: -7.5715	Cost: 17.70s
Train Epoch: 1434 [61440/90000 (68%)]	Loss: -7.5776	Cost: 14.53s
Train Epoch: 1434 [81920/90000 (91%)]	Loss: -7.3144	Cost: 13.04s
Train Epoch: 1434 	Average Loss: -7.2596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6056

Learning rate: 9.501137985341808e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1435 [0/90000 (0%)]	Loss: -2.7001	Cost: 23.99s
Train Epoch: 1435 [20480/90000 (23%)]	Loss: -7.6473	Cost: 14.96s
Train Epoch: 1435 [40960/90000 (45%)]	Loss: -7.7112	Cost: 13.32s
Train Epoch: 1435 [61440/90000 (68%)]	Loss: -7.6268	Cost: 12.04s
Train Epoch: 1435 [81920/90000 (91%)]	Loss: -7.6048	Cost: 12.13s
Train Epoch: 1435 	Average Loss: -7.2614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6923

Learning rate: 9.500453807640594e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1436 [0/90000 (0%)]	Loss: -2.2707	Cost: 28.63s
Train Epoch: 1436 [20480/90000 (23%)]	Loss: -7.7638	Cost: 11.69s
Train Epoch: 1436 [40960/90000 (45%)]	Loss: -7.6040	Cost: 12.61s
Train Epoch: 1436 [61440/90000 (68%)]	Loss: -7.7497	Cost: 11.89s
Train Epoch: 1436 [81920/90000 (91%)]	Loss: -7.4013	Cost: 6.33s
Train Epoch: 1436 	Average Loss: -7.1750
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2806

Learning rate: 9.4997691857624e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1437 [0/90000 (0%)]	Loss: -2.2287	Cost: 25.51s
Train Epoch: 1437 [20480/90000 (23%)]	Loss: -7.3332	Cost: 10.79s
Train Epoch: 1437 [40960/90000 (45%)]	Loss: -7.5446	Cost: 6.97s
Train Epoch: 1437 [61440/90000 (68%)]	Loss: -7.5592	Cost: 6.21s
Train Epoch: 1437 [81920/90000 (91%)]	Loss: -7.3849	Cost: 8.87s
Train Epoch: 1437 	Average Loss: -6.9996
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5959

Learning rate: 9.49908411977479e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1438 [0/90000 (0%)]	Loss: -1.7929	Cost: 23.03s
Train Epoch: 1438 [20480/90000 (23%)]	Loss: -7.1986	Cost: 8.31s
Train Epoch: 1438 [40960/90000 (45%)]	Loss: -7.3223	Cost: 11.41s
Train Epoch: 1438 [61440/90000 (68%)]	Loss: -7.6595	Cost: 9.16s
Train Epoch: 1438 [81920/90000 (91%)]	Loss: -7.3434	Cost: 8.74s
Train Epoch: 1438 	Average Loss: -6.9891
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3051

Learning rate: 9.49839860974538e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1439 [0/90000 (0%)]	Loss: -1.4743	Cost: 24.09s
Train Epoch: 1439 [20480/90000 (23%)]	Loss: -7.1568	Cost: 11.95s
Train Epoch: 1439 [40960/90000 (45%)]	Loss: -7.2915	Cost: 9.70s
Train Epoch: 1439 [61440/90000 (68%)]	Loss: -7.6809	Cost: 8.55s
Train Epoch: 1439 [81920/90000 (91%)]	Loss: -7.4597	Cost: 10.55s
Train Epoch: 1439 	Average Loss: -6.9005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3367

Learning rate: 9.497712655741827e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1440 [0/90000 (0%)]	Loss: -1.1549	Cost: 21.42s
Train Epoch: 1440 [20480/90000 (23%)]	Loss: -7.5050	Cost: 10.06s
Train Epoch: 1440 [40960/90000 (45%)]	Loss: -7.8499	Cost: 14.17s
Train Epoch: 1440 [61440/90000 (68%)]	Loss: -7.8114	Cost: 12.48s
Train Epoch: 1440 [81920/90000 (91%)]	Loss: -7.5534	Cost: 12.38s
Train Epoch: 1440 	Average Loss: -7.2482
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6499

Learning rate: 9.497026257831831e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1441 [0/90000 (0%)]	Loss: -2.5892	Cost: 27.98s
Train Epoch: 1441 [20480/90000 (23%)]	Loss: -7.8376	Cost: 13.46s
Train Epoch: 1441 [40960/90000 (45%)]	Loss: -7.9492	Cost: 12.44s
Train Epoch: 1441 [61440/90000 (68%)]	Loss: -8.0207	Cost: 11.99s
Train Epoch: 1441 [81920/90000 (91%)]	Loss: -7.7301	Cost: 9.95s
Train Epoch: 1441 	Average Loss: -7.5043
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7901

Learning rate: 9.496339416083137e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1442 [0/90000 (0%)]	Loss: -2.2232	Cost: 26.09s
Train Epoch: 1442 [20480/90000 (23%)]	Loss: -8.0081	Cost: 12.63s
Train Epoch: 1442 [40960/90000 (45%)]	Loss: -8.2559	Cost: 12.43s
Train Epoch: 1442 [61440/90000 (68%)]	Loss: -8.1604	Cost: 6.60s
Train Epoch: 1442 [81920/90000 (91%)]	Loss: -7.8631	Cost: 6.39s
Train Epoch: 1442 	Average Loss: -7.5531
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8112

Learning rate: 9.495652130563534e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1443 [0/90000 (0%)]	Loss: -2.3502	Cost: 28.44s
Train Epoch: 1443 [20480/90000 (23%)]	Loss: -7.9908	Cost: 11.23s
Train Epoch: 1443 [40960/90000 (45%)]	Loss: -8.0006	Cost: 10.94s
Train Epoch: 1443 [61440/90000 (68%)]	Loss: -7.9784	Cost: 6.62s
Train Epoch: 1443 [81920/90000 (91%)]	Loss: -7.5181	Cost: 8.13s
Train Epoch: 1443 	Average Loss: -7.5088
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6188

Learning rate: 9.494964401340855e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1444 [0/90000 (0%)]	Loss: -2.4481	Cost: 22.70s
Train Epoch: 1444 [20480/90000 (23%)]	Loss: -7.8400	Cost: 7.38s
Train Epoch: 1444 [40960/90000 (45%)]	Loss: -8.0647	Cost: 6.88s
Train Epoch: 1444 [61440/90000 (68%)]	Loss: -8.0155	Cost: 8.90s
Train Epoch: 1444 [81920/90000 (91%)]	Loss: -7.9806	Cost: 9.07s
Train Epoch: 1444 	Average Loss: -7.4819
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7585

Learning rate: 9.494276228482974e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1445 [0/90000 (0%)]	Loss: -2.2712	Cost: 21.61s
Train Epoch: 1445 [20480/90000 (23%)]	Loss: -8.0806	Cost: 9.32s
Train Epoch: 1445 [40960/90000 (45%)]	Loss: -7.8896	Cost: 9.07s
Train Epoch: 1445 [61440/90000 (68%)]	Loss: -7.8346	Cost: 8.55s
Train Epoch: 1445 [81920/90000 (91%)]	Loss: -7.6637	Cost: 8.48s
Train Epoch: 1445 	Average Loss: -7.4227
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5975

Learning rate: 9.493587612057813e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1446 [0/90000 (0%)]	Loss: -2.1839	Cost: 21.32s
Train Epoch: 1446 [20480/90000 (23%)]	Loss: -7.9427	Cost: 8.95s
Train Epoch: 1446 [40960/90000 (45%)]	Loss: -7.9934	Cost: 7.75s
Train Epoch: 1446 [61440/90000 (68%)]	Loss: -8.1296	Cost: 6.49s
Train Epoch: 1446 [81920/90000 (91%)]	Loss: -7.6905	Cost: 6.48s
Train Epoch: 1446 	Average Loss: -7.4412
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6262

Learning rate: 9.492898552133333e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1447 [0/90000 (0%)]	Loss: -2.7056	Cost: 21.41s
Train Epoch: 1447 [20480/90000 (23%)]	Loss: -7.8678	Cost: 9.92s
Train Epoch: 1447 [40960/90000 (45%)]	Loss: -7.8956	Cost: 9.46s
Train Epoch: 1447 [61440/90000 (68%)]	Loss: -8.1350	Cost: 10.41s
Train Epoch: 1447 [81920/90000 (91%)]	Loss: -7.6901	Cost: 12.62s
Train Epoch: 1447 	Average Loss: -7.4706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6249

Learning rate: 9.492209048777545e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1448 [0/90000 (0%)]	Loss: -2.7202	Cost: 23.11s
Train Epoch: 1448 [20480/90000 (23%)]	Loss: -7.8545	Cost: 10.56s
Train Epoch: 1448 [40960/90000 (45%)]	Loss: -7.0071	Cost: 14.07s
Train Epoch: 1448 [61440/90000 (68%)]	Loss: -7.1377	Cost: 13.30s
Train Epoch: 1448 [81920/90000 (91%)]	Loss: -7.0939	Cost: 12.40s
Train Epoch: 1448 	Average Loss: -6.9130
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2031

Learning rate: 9.491519102058499e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1449 [0/90000 (0%)]	Loss: -1.8682	Cost: 24.55s
Train Epoch: 1449 [20480/90000 (23%)]	Loss: -7.4477	Cost: 14.03s
Train Epoch: 1449 [40960/90000 (45%)]	Loss: -7.7602	Cost: 13.89s
Train Epoch: 1449 [61440/90000 (68%)]	Loss: -7.6828	Cost: 12.36s
Train Epoch: 1449 [81920/90000 (91%)]	Loss: -7.3997	Cost: 12.02s
Train Epoch: 1449 	Average Loss: -7.1588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4856

Learning rate: 9.490828712044288e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1450 [0/90000 (0%)]	Loss: -1.6663	Cost: 32.14s
Train Epoch: 1450 [20480/90000 (23%)]	Loss: -7.8074	Cost: 13.17s
Train Epoch: 1450 [40960/90000 (45%)]	Loss: -7.9375	Cost: 12.35s
Train Epoch: 1450 [61440/90000 (68%)]	Loss: -8.0148	Cost: 8.68s
Train Epoch: 1450 [81920/90000 (91%)]	Loss: -7.7799	Cost: 6.25s
Train Epoch: 1450 	Average Loss: -7.3675
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8156

Learning rate: 9.490137878803053e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1451 [0/90000 (0%)]	Loss: -1.7795	Cost: 33.67s
Train Epoch: 1451 [20480/90000 (23%)]	Loss: -7.6317	Cost: 6.44s
Train Epoch: 1451 [40960/90000 (45%)]	Loss: -7.5967	Cost: 9.14s
Train Epoch: 1451 [61440/90000 (68%)]	Loss: -7.7976	Cost: 9.00s
Train Epoch: 1451 [81920/90000 (91%)]	Loss: -7.7863	Cost: 8.88s
Train Epoch: 1451 	Average Loss: -7.3450
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7498

Learning rate: 9.489446602402978e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1452 [0/90000 (0%)]	Loss: -2.3300	Cost: 23.11s
Train Epoch: 1452 [20480/90000 (23%)]	Loss: -7.9412	Cost: 8.64s
Train Epoch: 1452 [40960/90000 (45%)]	Loss: -7.9551	Cost: 9.19s
Train Epoch: 1452 [61440/90000 (68%)]	Loss: -8.1021	Cost: 8.57s
Train Epoch: 1452 [81920/90000 (91%)]	Loss: -7.5513	Cost: 8.64s
Train Epoch: 1452 	Average Loss: -7.4643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3732

Learning rate: 9.488754882912286e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1453 [0/90000 (0%)]	Loss: -2.0973	Cost: 22.07s
Train Epoch: 1453 [20480/90000 (23%)]	Loss: -7.3956	Cost: 10.51s
Train Epoch: 1453 [40960/90000 (45%)]	Loss: -7.8824	Cost: 9.71s
Train Epoch: 1453 [61440/90000 (68%)]	Loss: -7.8135	Cost: 10.43s
Train Epoch: 1453 [81920/90000 (91%)]	Loss: -7.8171	Cost: 13.55s
Train Epoch: 1453 	Average Loss: -7.2704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9560

Saving model as e1453_model.pt & e1453_waveforms_supplementary.hdf5
Learning rate: 9.488062720399246e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1454 [0/90000 (0%)]	Loss: -2.1354	Cost: 21.85s
Train Epoch: 1454 [20480/90000 (23%)]	Loss: -8.2003	Cost: 10.17s
Train Epoch: 1454 [40960/90000 (45%)]	Loss: -8.1579	Cost: 14.30s
Train Epoch: 1454 [61440/90000 (68%)]	Loss: -8.2996	Cost: 14.15s
Train Epoch: 1454 [81920/90000 (91%)]	Loss: -7.8484	Cost: 12.69s
Train Epoch: 1454 	Average Loss: -7.6564
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9441

Learning rate: 9.487370114932177e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1455 [0/90000 (0%)]	Loss: -2.8827	Cost: 35.16s
Train Epoch: 1455 [20480/90000 (23%)]	Loss: -8.0260	Cost: 13.29s
Train Epoch: 1455 [40960/90000 (45%)]	Loss: -8.1356	Cost: 12.62s
Train Epoch: 1455 [61440/90000 (68%)]	Loss: -7.9762	Cost: 12.07s
Train Epoch: 1455 [81920/90000 (91%)]	Loss: -7.7505	Cost: 10.38s
Train Epoch: 1455 	Average Loss: -7.6251
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8984

Learning rate: 9.486677066579433e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1456 [0/90000 (0%)]	Loss: -2.0368	Cost: 31.26s
Train Epoch: 1456 [20480/90000 (23%)]	Loss: -7.8715	Cost: 11.68s
Train Epoch: 1456 [40960/90000 (45%)]	Loss: -8.0792	Cost: 6.49s
Train Epoch: 1456 [61440/90000 (68%)]	Loss: -8.0812	Cost: 6.24s
Train Epoch: 1456 [81920/90000 (91%)]	Loss: -7.9361	Cost: 9.02s
Train Epoch: 1456 	Average Loss: -7.5154
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9224

Learning rate: 9.485983575409414e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1457 [0/90000 (0%)]	Loss: -2.7699	Cost: 21.56s
Train Epoch: 1457 [20480/90000 (23%)]	Loss: -8.2779	Cost: 8.92s
Train Epoch: 1457 [40960/90000 (45%)]	Loss: -8.1725	Cost: 9.27s
Train Epoch: 1457 [61440/90000 (68%)]	Loss: -8.3432	Cost: 8.98s
Train Epoch: 1457 [81920/90000 (91%)]	Loss: -8.1069	Cost: 8.28s
Train Epoch: 1457 	Average Loss: -7.7828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0444

Saving model as e1457_model.pt & e1457_waveforms_supplementary.hdf5
Learning rate: 9.485289641490566e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1458 [0/90000 (0%)]	Loss: -2.9257	Cost: 23.28s
Train Epoch: 1458 [20480/90000 (23%)]	Loss: -8.2906	Cost: 8.91s
Train Epoch: 1458 [40960/90000 (45%)]	Loss: -8.3051	Cost: 6.80s
Train Epoch: 1458 [61440/90000 (68%)]	Loss: -8.3729	Cost: 6.35s
Train Epoch: 1458 [81920/90000 (91%)]	Loss: -7.9185	Cost: 6.65s
Train Epoch: 1458 	Average Loss: -7.7742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8972

Learning rate: 9.484595264891378e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1459 [0/90000 (0%)]	Loss: -2.3909	Cost: 31.98s
Train Epoch: 1459 [20480/90000 (23%)]	Loss: -8.2951	Cost: 9.87s
Train Epoch: 1459 [40960/90000 (45%)]	Loss: -8.0016	Cost: 14.69s
Train Epoch: 1459 [61440/90000 (68%)]	Loss: -8.2600	Cost: 12.31s
Train Epoch: 1459 [81920/90000 (91%)]	Loss: -7.9660	Cost: 12.29s
Train Epoch: 1459 	Average Loss: -7.7382
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0421

Learning rate: 9.483900445680383e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1460 [0/90000 (0%)]	Loss: -2.3377	Cost: 25.79s
Train Epoch: 1460 [20480/90000 (23%)]	Loss: -8.1982	Cost: 14.39s
Train Epoch: 1460 [40960/90000 (45%)]	Loss: -8.3715	Cost: 13.86s
Train Epoch: 1460 [61440/90000 (68%)]	Loss: -8.2513	Cost: 12.49s
Train Epoch: 1460 [81920/90000 (91%)]	Loss: -7.9910	Cost: 9.97s
Train Epoch: 1460 	Average Loss: -7.6954
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0573

Saving model as e1460_model.pt & e1460_waveforms_supplementary.hdf5
Learning rate: 9.483205183926155e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1461 [0/90000 (0%)]	Loss: -2.5484	Cost: 25.05s
Train Epoch: 1461 [20480/90000 (23%)]	Loss: -8.1513	Cost: 10.13s
Train Epoch: 1461 [40960/90000 (45%)]	Loss: -8.3850	Cost: 10.19s
Train Epoch: 1461 [61440/90000 (68%)]	Loss: -8.2237	Cost: 6.30s
Train Epoch: 1461 [81920/90000 (91%)]	Loss: -7.9590	Cost: 7.55s
Train Epoch: 1461 	Average Loss: -7.7630
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1047

Saving model as e1461_model.pt & e1461_waveforms_supplementary.hdf5
Learning rate: 9.482509479697314e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1462 [0/90000 (0%)]	Loss: -2.6072	Cost: 27.38s
Train Epoch: 1462 [20480/90000 (23%)]	Loss: -8.2998	Cost: 12.16s
Train Epoch: 1462 [40960/90000 (45%)]	Loss: -8.1231	Cost: 12.34s
Train Epoch: 1462 [61440/90000 (68%)]	Loss: -8.1645	Cost: 6.57s
Train Epoch: 1462 [81920/90000 (91%)]	Loss: -8.0578	Cost: 6.19s
Train Epoch: 1462 	Average Loss: -7.7611
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9607

Learning rate: 9.481813333062525e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1463 [0/90000 (0%)]	Loss: -1.9029	Cost: 28.66s
Train Epoch: 1463 [20480/90000 (23%)]	Loss: -7.9236	Cost: 9.58s
Train Epoch: 1463 [40960/90000 (45%)]	Loss: -8.2604	Cost: 9.70s
Train Epoch: 1463 [61440/90000 (68%)]	Loss: -8.0432	Cost: 8.27s
Train Epoch: 1463 [81920/90000 (91%)]	Loss: -7.9154	Cost: 8.69s
Train Epoch: 1463 	Average Loss: -7.7163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9299

Learning rate: 9.481116744090494e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1464 [0/90000 (0%)]	Loss: -1.7012	Cost: 18.80s
Train Epoch: 1464 [20480/90000 (23%)]	Loss: -8.1196	Cost: 8.30s
Train Epoch: 1464 [40960/90000 (45%)]	Loss: -8.0545	Cost: 9.56s
Train Epoch: 1464 [61440/90000 (68%)]	Loss: -8.2563	Cost: 9.90s
Train Epoch: 1464 [81920/90000 (91%)]	Loss: -7.9108	Cost: 8.96s
Train Epoch: 1464 	Average Loss: -7.6912
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9018

Learning rate: 9.48041971284997e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1465 [0/90000 (0%)]	Loss: -2.1492	Cost: 23.61s
Train Epoch: 1465 [20480/90000 (23%)]	Loss: -7.2696	Cost: 8.99s
Train Epoch: 1465 [40960/90000 (45%)]	Loss: -7.6591	Cost: 8.91s
Train Epoch: 1465 [61440/90000 (68%)]	Loss: -7.8025	Cost: 8.44s
Train Epoch: 1465 [81920/90000 (91%)]	Loss: -6.4444	Cost: 8.66s
Train Epoch: 1465 	Average Loss: -6.9289
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7071

Learning rate: 9.479722239409749e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1466 [0/90000 (0%)]	Loss: -1.0374	Cost: 18.58s
Train Epoch: 1466 [20480/90000 (23%)]	Loss: -6.7141	Cost: 9.14s
Train Epoch: 1466 [40960/90000 (45%)]	Loss: -7.2449	Cost: 9.11s
Train Epoch: 1466 [61440/90000 (68%)]	Loss: -7.4743	Cost: 6.31s
Train Epoch: 1466 [81920/90000 (91%)]	Loss: -7.3997	Cost: 6.41s
Train Epoch: 1466 	Average Loss: -6.7282
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3613

Learning rate: 9.479024323838667e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1467 [0/90000 (0%)]	Loss: -2.3006	Cost: 21.17s
Train Epoch: 1467 [20480/90000 (23%)]	Loss: -7.6513	Cost: 7.76s
Train Epoch: 1467 [40960/90000 (45%)]	Loss: -7.9047	Cost: 12.58s
Train Epoch: 1467 [61440/90000 (68%)]	Loss: -8.1209	Cost: 12.60s
Train Epoch: 1467 [81920/90000 (91%)]	Loss: -7.6557	Cost: 12.70s
Train Epoch: 1467 	Average Loss: -7.3909
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8399

Learning rate: 9.478325966205609e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1468 [0/90000 (0%)]	Loss: -2.4816	Cost: 26.62s
Train Epoch: 1468 [20480/90000 (23%)]	Loss: -8.0853	Cost: 13.85s
Train Epoch: 1468 [40960/90000 (45%)]	Loss: -8.2008	Cost: 14.95s
Train Epoch: 1468 [61440/90000 (68%)]	Loss: -8.2419	Cost: 12.37s
Train Epoch: 1468 [81920/90000 (91%)]	Loss: -8.1531	Cost: 12.11s
Train Epoch: 1468 	Average Loss: -7.7287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0608

Learning rate: 9.477627166579498e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1469 [0/90000 (0%)]	Loss: -2.5047	Cost: 41.76s
Train Epoch: 1469 [20480/90000 (23%)]	Loss: -8.1149	Cost: 13.73s
Train Epoch: 1469 [40960/90000 (45%)]	Loss: -8.2284	Cost: 12.35s
Train Epoch: 1469 [61440/90000 (68%)]	Loss: -8.2567	Cost: 11.47s
Train Epoch: 1469 [81920/90000 (91%)]	Loss: -8.1264	Cost: 6.12s
Train Epoch: 1469 	Average Loss: -7.8426
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0181

Learning rate: 9.4769279250293e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1470 [0/90000 (0%)]	Loss: -2.8031	Cost: 36.18s
Train Epoch: 1470 [20480/90000 (23%)]	Loss: -8.2500	Cost: 9.97s
Train Epoch: 1470 [40960/90000 (45%)]	Loss: -8.3849	Cost: 10.73s
Train Epoch: 1470 [61440/90000 (68%)]	Loss: -8.0680	Cost: 6.05s
Train Epoch: 1470 [81920/90000 (91%)]	Loss: -7.6868	Cost: 6.07s
Train Epoch: 1470 	Average Loss: -7.7641
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7627

Learning rate: 9.476228241624034e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1471 [0/90000 (0%)]	Loss: -2.9796	Cost: 20.61s
Train Epoch: 1471 [20480/90000 (23%)]	Loss: -8.0956	Cost: 9.88s
Train Epoch: 1471 [40960/90000 (45%)]	Loss: -8.2804	Cost: 6.38s
Train Epoch: 1471 [61440/90000 (68%)]	Loss: -8.0388	Cost: 7.23s
Train Epoch: 1471 [81920/90000 (91%)]	Loss: -7.9920	Cost: 8.42s
Train Epoch: 1471 	Average Loss: -7.6908
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8612

Learning rate: 9.47552811643275e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1472 [0/90000 (0%)]	Loss: -2.4770	Cost: 31.41s
Train Epoch: 1472 [20480/90000 (23%)]	Loss: -7.9627	Cost: 10.05s
Train Epoch: 1472 [40960/90000 (45%)]	Loss: -8.1313	Cost: 9.82s
Train Epoch: 1472 [61440/90000 (68%)]	Loss: -8.2715	Cost: 6.18s
Train Epoch: 1472 [81920/90000 (91%)]	Loss: -8.2763	Cost: 7.56s
Train Epoch: 1472 	Average Loss: -7.7169
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0084

Learning rate: 9.47482754952455e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1473 [0/90000 (0%)]	Loss: -2.7812	Cost: 20.06s
Train Epoch: 1473 [20480/90000 (23%)]	Loss: -8.3629	Cost: 8.67s
Train Epoch: 1473 [40960/90000 (45%)]	Loss: -8.1309	Cost: 8.93s
Train Epoch: 1473 [61440/90000 (68%)]	Loss: -8.4427	Cost: 9.23s
Train Epoch: 1473 [81920/90000 (91%)]	Loss: -8.1854	Cost: 9.09s
Train Epoch: 1473 	Average Loss: -7.8499
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1018

Learning rate: 9.474126540968577e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1474 [0/90000 (0%)]	Loss: -3.1458	Cost: 21.10s
Train Epoch: 1474 [20480/90000 (23%)]	Loss: -8.3396	Cost: 9.37s
Train Epoch: 1474 [40960/90000 (45%)]	Loss: -8.4121	Cost: 10.93s
Train Epoch: 1474 [61440/90000 (68%)]	Loss: -8.0612	Cost: 10.53s
Train Epoch: 1474 [81920/90000 (91%)]	Loss: -7.7436	Cost: 13.10s
Train Epoch: 1474 	Average Loss: -7.6853
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7475

Learning rate: 9.473425090834017e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1475 [0/90000 (0%)]	Loss: -2.7336	Cost: 23.60s
Train Epoch: 1475 [20480/90000 (23%)]	Loss: -7.8834	Cost: 10.26s
Train Epoch: 1475 [40960/90000 (45%)]	Loss: -8.0101	Cost: 14.79s
Train Epoch: 1475 [61440/90000 (68%)]	Loss: -8.2774	Cost: 12.29s
Train Epoch: 1475 [81920/90000 (91%)]	Loss: -8.1254	Cost: 12.20s
Train Epoch: 1475 	Average Loss: -7.7471
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1012

Learning rate: 9.472723199190101e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1476 [0/90000 (0%)]	Loss: -2.1409	Cost: 35.73s
Train Epoch: 1476 [20480/90000 (23%)]	Loss: -8.2138	Cost: 12.60s
Train Epoch: 1476 [40960/90000 (45%)]	Loss: -8.1873	Cost: 12.32s
Train Epoch: 1476 [61440/90000 (68%)]	Loss: -8.3835	Cost: 11.82s
Train Epoch: 1476 [81920/90000 (91%)]	Loss: -8.0749	Cost: 6.06s
Train Epoch: 1476 	Average Loss: -7.8112
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0433

Learning rate: 9.472020866106103e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1477 [0/90000 (0%)]	Loss: -2.3897	Cost: 23.74s
Train Epoch: 1477 [20480/90000 (23%)]	Loss: -8.1645	Cost: 12.25s
Train Epoch: 1477 [40960/90000 (45%)]	Loss: -8.1042	Cost: 9.77s
Train Epoch: 1477 [61440/90000 (68%)]	Loss: -8.1929	Cost: 6.14s
Train Epoch: 1477 [81920/90000 (91%)]	Loss: -7.6741	Cost: 7.35s
Train Epoch: 1477 	Average Loss: -7.6274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7401

Learning rate: 9.471318091651342e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1478 [0/90000 (0%)]	Loss: -2.3216	Cost: 24.58s
Train Epoch: 1478 [20480/90000 (23%)]	Loss: -8.0071	Cost: 6.93s
Train Epoch: 1478 [40960/90000 (45%)]	Loss: -8.3285	Cost: 9.59s
Train Epoch: 1478 [61440/90000 (68%)]	Loss: -8.4430	Cost: 9.13s
Train Epoch: 1478 [81920/90000 (91%)]	Loss: -8.1936	Cost: 8.80s
Train Epoch: 1478 	Average Loss: -7.7678
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1516

Saving model as e1478_model.pt & e1478_waveforms_supplementary.hdf5
Learning rate: 9.470614875895176e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1479 [0/90000 (0%)]	Loss: -2.4346	Cost: 25.11s
Train Epoch: 1479 [20480/90000 (23%)]	Loss: -8.3171	Cost: 11.24s
Train Epoch: 1479 [40960/90000 (45%)]	Loss: -8.3577	Cost: 9.91s
Train Epoch: 1479 [61440/90000 (68%)]	Loss: -8.4506	Cost: 8.16s
Train Epoch: 1479 [81920/90000 (91%)]	Loss: -8.3062	Cost: 6.27s
Train Epoch: 1479 	Average Loss: -7.9312
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9865

Learning rate: 9.46991121890701e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1480 [0/90000 (0%)]	Loss: -2.8524	Cost: 22.59s
Train Epoch: 1480 [20480/90000 (23%)]	Loss: -8.3072	Cost: 7.99s
Train Epoch: 1480 [40960/90000 (45%)]	Loss: -8.2984	Cost: 7.89s
Train Epoch: 1480 [61440/90000 (68%)]	Loss: -8.5891	Cost: 9.23s
Train Epoch: 1480 [81920/90000 (91%)]	Loss: -8.3250	Cost: 9.89s
Train Epoch: 1480 	Average Loss: -8.0012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1425

Learning rate: 9.469207120756294e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1481 [0/90000 (0%)]	Loss: -2.9724	Cost: 21.58s
Train Epoch: 1481 [20480/90000 (23%)]	Loss: -8.4818	Cost: 7.51s
Train Epoch: 1481 [40960/90000 (45%)]	Loss: -8.3832	Cost: 11.27s
Train Epoch: 1481 [61440/90000 (68%)]	Loss: -8.4147	Cost: 12.59s
Train Epoch: 1481 [81920/90000 (91%)]	Loss: -8.1841	Cost: 12.39s
Train Epoch: 1481 	Average Loss: -7.8838
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9744

Learning rate: 9.468502581512518e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1482 [0/90000 (0%)]	Loss: -2.5388	Cost: 24.41s
Train Epoch: 1482 [20480/90000 (23%)]	Loss: -8.2550	Cost: 13.31s
Train Epoch: 1482 [40960/90000 (45%)]	Loss: -8.3335	Cost: 12.53s
Train Epoch: 1482 [61440/90000 (68%)]	Loss: -8.3819	Cost: 12.25s
Train Epoch: 1482 [81920/90000 (91%)]	Loss: -8.2788	Cost: 12.37s
Train Epoch: 1482 	Average Loss: -7.8849
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1284

Learning rate: 9.46779760124522e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1483 [0/90000 (0%)]	Loss: -2.4271	Cost: 24.66s
Train Epoch: 1483 [20480/90000 (23%)]	Loss: -8.3625	Cost: 13.33s
Train Epoch: 1483 [40960/90000 (45%)]	Loss: -8.3800	Cost: 12.79s
Train Epoch: 1483 [61440/90000 (68%)]	Loss: -8.5725	Cost: 12.06s
Train Epoch: 1483 [81920/90000 (91%)]	Loss: -8.3359	Cost: 6.19s
Train Epoch: 1483 	Average Loss: -7.9599
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1393

Learning rate: 9.467092180023976e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1484 [0/90000 (0%)]	Loss: -2.7325	Cost: 39.85s
Train Epoch: 1484 [20480/90000 (23%)]	Loss: -8.3647	Cost: 12.25s
Train Epoch: 1484 [40960/90000 (45%)]	Loss: -8.2916	Cost: 6.60s
Train Epoch: 1484 [61440/90000 (68%)]	Loss: -8.4817	Cost: 6.60s
Train Epoch: 1484 [81920/90000 (91%)]	Loss: -8.3762	Cost: 8.01s
Train Epoch: 1484 	Average Loss: -7.9224
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1408

Learning rate: 9.46638631791841e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1485 [0/90000 (0%)]	Loss: -2.9646	Cost: 23.82s
Train Epoch: 1485 [20480/90000 (23%)]	Loss: -8.4134	Cost: 8.46s
Train Epoch: 1485 [40960/90000 (45%)]	Loss: -8.5731	Cost: 7.94s
Train Epoch: 1485 [61440/90000 (68%)]	Loss: -8.4440	Cost: 8.99s
Train Epoch: 1485 [81920/90000 (91%)]	Loss: -8.3422	Cost: 8.87s
Train Epoch: 1485 	Average Loss: -8.0734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2062

Saving model as e1485_model.pt & e1485_waveforms_supplementary.hdf5
Learning rate: 9.465680014998187e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1486 [0/90000 (0%)]	Loss: -2.8616	Cost: 21.26s
Train Epoch: 1486 [20480/90000 (23%)]	Loss: -8.4108	Cost: 9.05s
Train Epoch: 1486 [40960/90000 (45%)]	Loss: -7.9071	Cost: 9.22s
Train Epoch: 1486 [61440/90000 (68%)]	Loss: -7.8938	Cost: 8.69s
Train Epoch: 1486 [81920/90000 (91%)]	Loss: -7.9057	Cost: 6.76s
Train Epoch: 1486 	Average Loss: -7.6857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0606

Learning rate: 9.464973271333016e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1487 [0/90000 (0%)]	Loss: -1.4235	Cost: 21.22s
Train Epoch: 1487 [20480/90000 (23%)]	Loss: -7.9057	Cost: 6.55s
Train Epoch: 1487 [40960/90000 (45%)]	Loss: -8.3457	Cost: 10.65s
Train Epoch: 1487 [61440/90000 (68%)]	Loss: -8.5437	Cost: 12.34s
Train Epoch: 1487 [81920/90000 (91%)]	Loss: -8.3075	Cost: 14.58s
Train Epoch: 1487 	Average Loss: -7.8162
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0928

Learning rate: 9.464266086992651e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1488 [0/90000 (0%)]	Loss: -2.9308	Cost: 23.27s
Train Epoch: 1488 [20480/90000 (23%)]	Loss: -8.2830	Cost: 14.53s
Train Epoch: 1488 [40960/90000 (45%)]	Loss: -8.5858	Cost: 14.84s
Train Epoch: 1488 [61440/90000 (68%)]	Loss: -8.6492	Cost: 12.57s
Train Epoch: 1488 [81920/90000 (91%)]	Loss: -8.3552	Cost: 12.10s
Train Epoch: 1488 	Average Loss: -8.0645
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1627

Learning rate: 9.463558462046886e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1489 [0/90000 (0%)]	Loss: -2.8493	Cost: 33.80s
Train Epoch: 1489 [20480/90000 (23%)]	Loss: -8.2654	Cost: 11.84s
Train Epoch: 1489 [40960/90000 (45%)]	Loss: -8.4107	Cost: 12.20s
Train Epoch: 1489 [61440/90000 (68%)]	Loss: -8.5264	Cost: 6.07s
Train Epoch: 1489 [81920/90000 (91%)]	Loss: -7.9767	Cost: 6.23s
Train Epoch: 1489 	Average Loss: -7.9455
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0292

Learning rate: 9.462850396565563e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1490 [0/90000 (0%)]	Loss: -2.9739	Cost: 23.65s
Train Epoch: 1490 [20480/90000 (23%)]	Loss: -8.4019	Cost: 6.92s
Train Epoch: 1490 [40960/90000 (45%)]	Loss: -8.2768	Cost: 9.73s
Train Epoch: 1490 [61440/90000 (68%)]	Loss: -8.2427	Cost: 8.72s
Train Epoch: 1490 [81920/90000 (91%)]	Loss: -7.9412	Cost: 8.59s
Train Epoch: 1490 	Average Loss: -7.7944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0041

Learning rate: 9.462141890618565e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1491 [0/90000 (0%)]	Loss: -3.2158	Cost: 23.45s
Train Epoch: 1491 [20480/90000 (23%)]	Loss: -8.4374	Cost: 8.62s
Train Epoch: 1491 [40960/90000 (45%)]	Loss: -8.5363	Cost: 11.42s
Train Epoch: 1491 [61440/90000 (68%)]	Loss: -8.6287	Cost: 8.85s
Train Epoch: 1491 [81920/90000 (91%)]	Loss: -8.5218	Cost: 8.70s
Train Epoch: 1491 	Average Loss: -8.0485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2079

Saving model as e1491_model.pt & e1491_waveforms_supplementary.hdf5
Learning rate: 9.461432944275817e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1492 [0/90000 (0%)]	Loss: -2.7438	Cost: 24.98s
Train Epoch: 1492 [20480/90000 (23%)]	Loss: -8.6326	Cost: 8.37s
Train Epoch: 1492 [40960/90000 (45%)]	Loss: -8.7380	Cost: 11.19s
Train Epoch: 1492 [61440/90000 (68%)]	Loss: -8.5252	Cost: 11.64s
Train Epoch: 1492 [81920/90000 (91%)]	Loss: -8.1905	Cost: 12.44s
Train Epoch: 1492 	Average Loss: -8.1078
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0156

Learning rate: 9.46072355760729e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1493 [0/90000 (0%)]	Loss: -2.4362	Cost: 22.27s
Train Epoch: 1493 [20480/90000 (23%)]	Loss: -8.2037	Cost: 9.14s
Train Epoch: 1493 [40960/90000 (45%)]	Loss: -8.6016	Cost: 13.21s
Train Epoch: 1493 [61440/90000 (68%)]	Loss: -8.4872	Cost: 13.39s
Train Epoch: 1493 [81920/90000 (91%)]	Loss: -8.1530	Cost: 12.35s
Train Epoch: 1493 	Average Loss: -7.8571
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0111

Learning rate: 9.460013730682999e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1494 [0/90000 (0%)]	Loss: -2.5665	Cost: 25.91s
Train Epoch: 1494 [20480/90000 (23%)]	Loss: -8.4950	Cost: 13.44s
Train Epoch: 1494 [40960/90000 (45%)]	Loss: -8.4384	Cost: 13.39s
Train Epoch: 1494 [61440/90000 (68%)]	Loss: -8.6153	Cost: 12.37s
Train Epoch: 1494 [81920/90000 (91%)]	Loss: -8.5028	Cost: 12.31s
Train Epoch: 1494 	Average Loss: -8.0556
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1704

Learning rate: 9.459303463572999e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1495 [0/90000 (0%)]	Loss: -2.8370	Cost: 24.81s
Train Epoch: 1495 [20480/90000 (23%)]	Loss: -8.4180	Cost: 12.76s
Train Epoch: 1495 [40960/90000 (45%)]	Loss: -8.4383	Cost: 12.54s
Train Epoch: 1495 [61440/90000 (68%)]	Loss: -8.4047	Cost: 6.84s
Train Epoch: 1495 [81920/90000 (91%)]	Loss: -8.2501	Cost: 6.28s
Train Epoch: 1495 	Average Loss: -7.9091
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9982

Learning rate: 9.458592756347392e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1496 [0/90000 (0%)]	Loss: -2.6060	Cost: 22.87s
Train Epoch: 1496 [20480/90000 (23%)]	Loss: -8.3701	Cost: 6.60s
Train Epoch: 1496 [40960/90000 (45%)]	Loss: -8.2785	Cost: 8.89s
Train Epoch: 1496 [61440/90000 (68%)]	Loss: -8.3756	Cost: 9.45s
Train Epoch: 1496 [81920/90000 (91%)]	Loss: -8.4067	Cost: 8.96s
Train Epoch: 1496 	Average Loss: -7.9910
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0869

Learning rate: 9.457881609076323e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1497 [0/90000 (0%)]	Loss: -2.8268	Cost: 22.66s
Train Epoch: 1497 [20480/90000 (23%)]	Loss: -8.1278	Cost: 10.34s
Train Epoch: 1497 [40960/90000 (45%)]	Loss: -8.1699	Cost: 10.36s
Train Epoch: 1497 [61440/90000 (68%)]	Loss: -8.2004	Cost: 8.66s
Train Epoch: 1497 [81920/90000 (91%)]	Loss: -8.0545	Cost: 8.42s
Train Epoch: 1497 	Average Loss: -7.8607
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1122

Learning rate: 9.457170021829978e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1498 [0/90000 (0%)]	Loss: -2.7058	Cost: 24.20s
Train Epoch: 1498 [20480/90000 (23%)]	Loss: -8.2338	Cost: 10.96s
Train Epoch: 1498 [40960/90000 (45%)]	Loss: -8.4145	Cost: 9.36s
Train Epoch: 1498 [61440/90000 (68%)]	Loss: -8.5177	Cost: 8.85s
Train Epoch: 1498 [81920/90000 (91%)]	Loss: -8.4049	Cost: 8.78s
Train Epoch: 1498 	Average Loss: -8.0242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1014

Learning rate: 9.456457994678588e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1499 [0/90000 (0%)]	Loss: -2.3984	Cost: 19.58s
Train Epoch: 1499 [20480/90000 (23%)]	Loss: -8.4881	Cost: 9.29s
Train Epoch: 1499 [40960/90000 (45%)]	Loss: -8.4752	Cost: 6.87s
Train Epoch: 1499 [61440/90000 (68%)]	Loss: -8.5026	Cost: 7.39s
Train Epoch: 1499 [81920/90000 (91%)]	Loss: -8.3329	Cost: 6.39s
Train Epoch: 1499 	Average Loss: -8.0302
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1656

Learning rate: 9.455745527692427e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1500 [0/90000 (0%)]	Loss: -1.5729	Cost: 20.81s
Train Epoch: 1500 [20480/90000 (23%)]	Loss: -8.3140	Cost: 7.63s
Train Epoch: 1500 [40960/90000 (45%)]	Loss: -8.4301	Cost: 11.68s
Train Epoch: 1500 [61440/90000 (68%)]	Loss: -8.5743	Cost: 12.21s
Train Epoch: 1500 [81920/90000 (91%)]	Loss: -8.3231	Cost: 12.27s
Train Epoch: 1500 	Average Loss: -8.0011
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2858

Saving model as e1500_model.pt & e1500_waveforms_supplementary.hdf5
Learning rate: 9.455032620941813e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1501 [0/90000 (0%)]	Loss: -2.6388	Cost: 24.38s
Train Epoch: 1501 [20480/90000 (23%)]	Loss: -8.4552	Cost: 14.43s
Train Epoch: 1501 [40960/90000 (45%)]	Loss: -8.4911	Cost: 13.95s
Train Epoch: 1501 [61440/90000 (68%)]	Loss: -8.7284	Cost: 12.26s
Train Epoch: 1501 [81920/90000 (91%)]	Loss: -8.2834	Cost: 10.04s
Train Epoch: 1501 	Average Loss: -8.1090
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1750

Learning rate: 9.454319274497107e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1502 [0/90000 (0%)]	Loss: -2.9137	Cost: 36.43s
Train Epoch: 1502 [20480/90000 (23%)]	Loss: -8.4760	Cost: 12.89s
Train Epoch: 1502 [40960/90000 (45%)]	Loss: -8.6521	Cost: 12.02s
Train Epoch: 1502 [61440/90000 (68%)]	Loss: -8.6084	Cost: 6.14s
Train Epoch: 1502 [81920/90000 (91%)]	Loss: -8.6004	Cost: 6.85s
Train Epoch: 1502 	Average Loss: -8.0930
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2406

Learning rate: 9.453605488428713e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1503 [0/90000 (0%)]	Loss: -3.1741	Cost: 36.52s
Train Epoch: 1503 [20480/90000 (23%)]	Loss: -8.3917	Cost: 8.83s
Train Epoch: 1503 [40960/90000 (45%)]	Loss: -8.1359	Cost: 6.61s
Train Epoch: 1503 [61440/90000 (68%)]	Loss: -8.3093	Cost: 7.25s
Train Epoch: 1503 [81920/90000 (91%)]	Loss: -8.3979	Cost: 9.48s
Train Epoch: 1503 	Average Loss: -7.9559
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0476

Learning rate: 9.452891262807079e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1504 [0/90000 (0%)]	Loss: -1.9297	Cost: 20.28s
Train Epoch: 1504 [20480/90000 (23%)]	Loss: -8.3533	Cost: 6.95s
Train Epoch: 1504 [40960/90000 (45%)]	Loss: -8.5044	Cost: 9.41s
Train Epoch: 1504 [61440/90000 (68%)]	Loss: -8.6627	Cost: 9.02s
Train Epoch: 1504 [81920/90000 (91%)]	Loss: -8.4960	Cost: 8.76s
Train Epoch: 1504 	Average Loss: -8.0033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2443

Learning rate: 9.452176597702696e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1505 [0/90000 (0%)]	Loss: -2.6219	Cost: 22.18s
Train Epoch: 1505 [20480/90000 (23%)]	Loss: -8.7648	Cost: 8.77s
Train Epoch: 1505 [40960/90000 (45%)]	Loss: -8.8078	Cost: 7.53s
Train Epoch: 1505 [61440/90000 (68%)]	Loss: -8.8135	Cost: 8.17s
Train Epoch: 1505 [81920/90000 (91%)]	Loss: -8.4426	Cost: 10.97s
Train Epoch: 1505 	Average Loss: -8.1887
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2135

Learning rate: 9.4514614931861e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1506 [0/90000 (0%)]	Loss: -2.6909	Cost: 20.74s
Train Epoch: 1506 [20480/90000 (23%)]	Loss: -8.4885	Cost: 9.90s
Train Epoch: 1506 [40960/90000 (45%)]	Loss: -8.7738	Cost: 18.17s
Train Epoch: 1506 [61440/90000 (68%)]	Loss: -8.6082	Cost: 12.28s
Train Epoch: 1506 [81920/90000 (91%)]	Loss: -8.2713	Cost: 12.12s
Train Epoch: 1506 	Average Loss: -8.1299
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1336

Learning rate: 9.450745949327868e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1507 [0/90000 (0%)]	Loss: -3.2373	Cost: 40.38s
Train Epoch: 1507 [20480/90000 (23%)]	Loss: -8.5342	Cost: 11.45s
Train Epoch: 1507 [40960/90000 (45%)]	Loss: -8.7835	Cost: 12.19s
Train Epoch: 1507 [61440/90000 (68%)]	Loss: -8.6575	Cost: 12.10s
Train Epoch: 1507 [81920/90000 (91%)]	Loss: -8.2208	Cost: 5.90s
Train Epoch: 1507 	Average Loss: -8.1638
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2041

Learning rate: 9.450029966198623e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1508 [0/90000 (0%)]	Loss: -3.0243	Cost: 28.32s
Train Epoch: 1508 [20480/90000 (23%)]	Loss: -8.5793	Cost: 12.39s
Train Epoch: 1508 [40960/90000 (45%)]	Loss: -8.6242	Cost: 9.04s
Train Epoch: 1508 [61440/90000 (68%)]	Loss: -8.4783	Cost: 6.23s
Train Epoch: 1508 [81920/90000 (91%)]	Loss: -8.2038	Cost: 7.59s
Train Epoch: 1508 	Average Loss: -8.0889
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2346

Learning rate: 9.449313543869027e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1509 [0/90000 (0%)]	Loss: -2.3858	Cost: 24.38s
Train Epoch: 1509 [20480/90000 (23%)]	Loss: -8.5985	Cost: 7.53s
Train Epoch: 1509 [40960/90000 (45%)]	Loss: -8.6586	Cost: 10.24s
Train Epoch: 1509 [61440/90000 (68%)]	Loss: -8.7828	Cost: 9.03s
Train Epoch: 1509 [81920/90000 (91%)]	Loss: -8.3379	Cost: 8.88s
Train Epoch: 1509 	Average Loss: -8.1318
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1312

Learning rate: 9.448596682409789e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1510 [0/90000 (0%)]	Loss: -2.8236	Cost: 28.06s
Train Epoch: 1510 [20480/90000 (23%)]	Loss: -8.5236	Cost: 11.53s
Train Epoch: 1510 [40960/90000 (45%)]	Loss: -8.7044	Cost: 10.38s
Train Epoch: 1510 [61440/90000 (68%)]	Loss: -8.7447	Cost: 8.22s
Train Epoch: 1510 [81920/90000 (91%)]	Loss: -8.4123	Cost: 6.34s
Train Epoch: 1510 	Average Loss: -8.1398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1855

Learning rate: 9.447879381891662e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1511 [0/90000 (0%)]	Loss: -2.3917	Cost: 21.52s
Train Epoch: 1511 [20480/90000 (23%)]	Loss: -8.5456	Cost: 6.47s
Train Epoch: 1511 [40960/90000 (45%)]	Loss: -8.5969	Cost: 8.86s
Train Epoch: 1511 [61440/90000 (68%)]	Loss: -8.5537	Cost: 10.31s
Train Epoch: 1511 [81920/90000 (91%)]	Loss: -8.4761	Cost: 12.38s
Train Epoch: 1511 	Average Loss: -8.0578
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3350

Saving model as e1511_model.pt & e1511_waveforms_supplementary.hdf5
Learning rate: 9.447161642385438e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1512 [0/90000 (0%)]	Loss: -2.7471	Cost: 21.75s
Train Epoch: 1512 [20480/90000 (23%)]	Loss: -8.6398	Cost: 12.51s
Train Epoch: 1512 [40960/90000 (45%)]	Loss: -8.8797	Cost: 12.58s
Train Epoch: 1512 [61440/90000 (68%)]	Loss: -8.5965	Cost: 12.30s
Train Epoch: 1512 [81920/90000 (91%)]	Loss: -8.1888	Cost: 12.20s
Train Epoch: 1512 	Average Loss: -8.2361
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1550

Learning rate: 9.446443463961957e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1513 [0/90000 (0%)]	Loss: -2.8727	Cost: 27.18s
Train Epoch: 1513 [20480/90000 (23%)]	Loss: -8.6324	Cost: 12.55s
Train Epoch: 1513 [40960/90000 (45%)]	Loss: -8.7995	Cost: 13.18s
Train Epoch: 1513 [61440/90000 (68%)]	Loss: -8.8002	Cost: 12.29s
Train Epoch: 1513 [81920/90000 (91%)]	Loss: -8.4451	Cost: 8.21s
Train Epoch: 1513 	Average Loss: -8.1699
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2005

Learning rate: 9.4457248466921e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1514 [0/90000 (0%)]	Loss: -3.6081	Cost: 38.47s
Train Epoch: 1514 [20480/90000 (23%)]	Loss: -8.7066	Cost: 12.53s
Train Epoch: 1514 [40960/90000 (45%)]	Loss: -8.8433	Cost: 8.59s
Train Epoch: 1514 [61440/90000 (68%)]	Loss: -8.9361	Cost: 5.98s
Train Epoch: 1514 [81920/90000 (91%)]	Loss: -8.2998	Cost: 7.78s
Train Epoch: 1514 	Average Loss: -8.3177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0406

Learning rate: 9.44500579064679e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1515 [0/90000 (0%)]	Loss: -2.8507	Cost: 27.67s
Train Epoch: 1515 [20480/90000 (23%)]	Loss: -8.5339	Cost: 9.27s
Train Epoch: 1515 [40960/90000 (45%)]	Loss: -8.6085	Cost: 8.78s
Train Epoch: 1515 [61440/90000 (68%)]	Loss: -8.5637	Cost: 8.48s
Train Epoch: 1515 [81920/90000 (91%)]	Loss: -8.3451	Cost: 8.59s
Train Epoch: 1515 	Average Loss: -8.0407
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2864

Learning rate: 9.444286295896998e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1516 [0/90000 (0%)]	Loss: -2.6293	Cost: 22.80s
Train Epoch: 1516 [20480/90000 (23%)]	Loss: -8.8420	Cost: 8.40s
Train Epoch: 1516 [40960/90000 (45%)]	Loss: -8.7831	Cost: 9.72s
Train Epoch: 1516 [61440/90000 (68%)]	Loss: -8.6133	Cost: 9.12s
Train Epoch: 1516 [81920/90000 (91%)]	Loss: -8.6528	Cost: 8.67s
Train Epoch: 1516 	Average Loss: -8.2841
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3566

Saving model as e1516_model.pt & e1516_waveforms_supplementary.hdf5
Learning rate: 9.443566362513733e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1517 [0/90000 (0%)]	Loss: -3.3968	Cost: 19.57s
Train Epoch: 1517 [20480/90000 (23%)]	Loss: -8.7582	Cost: 6.59s
Train Epoch: 1517 [40960/90000 (45%)]	Loss: -8.8496	Cost: 7.76s
Train Epoch: 1517 [61440/90000 (68%)]	Loss: -8.7690	Cost: 10.75s
Train Epoch: 1517 [81920/90000 (91%)]	Loss: -8.5212	Cost: 14.67s
Train Epoch: 1517 	Average Loss: -8.3286
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4127

Saving model as e1517_model.pt & e1517_waveforms_supplementary.hdf5
Learning rate: 9.442845990568051e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1518 [0/90000 (0%)]	Loss: -2.9751	Cost: 21.48s
Train Epoch: 1518 [20480/90000 (23%)]	Loss: -8.5369	Cost: 11.85s
Train Epoch: 1518 [40960/90000 (45%)]	Loss: -8.6510	Cost: 15.02s
Train Epoch: 1518 [61440/90000 (68%)]	Loss: -8.6997	Cost: 12.58s
Train Epoch: 1518 [81920/90000 (91%)]	Loss: -8.3324	Cost: 12.16s
Train Epoch: 1518 	Average Loss: -8.2036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3558

Learning rate: 9.442125180131048e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1519 [0/90000 (0%)]	Loss: -3.5112	Cost: 33.24s
Train Epoch: 1519 [20480/90000 (23%)]	Loss: -8.5759	Cost: 10.41s
Train Epoch: 1519 [40960/90000 (45%)]	Loss: -8.5962	Cost: 12.35s
Train Epoch: 1519 [61440/90000 (68%)]	Loss: -8.5580	Cost: 12.29s
Train Epoch: 1519 [81920/90000 (91%)]	Loss: -8.2561	Cost: 8.95s
Train Epoch: 1519 	Average Loss: -8.2050
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1377

Learning rate: 9.441403931273867e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1520 [0/90000 (0%)]	Loss: -2.3511	Cost: 40.11s
Train Epoch: 1520 [20480/90000 (23%)]	Loss: -8.6277	Cost: 12.31s
Train Epoch: 1520 [40960/90000 (45%)]	Loss: -8.8136	Cost: 11.96s
Train Epoch: 1520 [61440/90000 (68%)]	Loss: -8.7827	Cost: 6.72s
Train Epoch: 1520 [81920/90000 (91%)]	Loss: -8.4032	Cost: 7.53s
Train Epoch: 1520 	Average Loss: -8.1068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3709

Learning rate: 9.440682244067694e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1521 [0/90000 (0%)]	Loss: -3.6855	Cost: 25.33s
Train Epoch: 1521 [20480/90000 (23%)]	Loss: -8.7018	Cost: 8.31s
Train Epoch: 1521 [40960/90000 (45%)]	Loss: -8.7464	Cost: 11.54s
Train Epoch: 1521 [61440/90000 (68%)]	Loss: -8.5007	Cost: 9.07s
Train Epoch: 1521 [81920/90000 (91%)]	Loss: -8.1783	Cost: 8.83s
Train Epoch: 1521 	Average Loss: -8.2089
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1217

Learning rate: 9.439960118583752e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1522 [0/90000 (0%)]	Loss: -2.0888	Cost: 34.56s
Train Epoch: 1522 [20480/90000 (23%)]	Loss: -8.3323	Cost: 6.94s
Train Epoch: 1522 [40960/90000 (45%)]	Loss: -8.6091	Cost: 10.76s
Train Epoch: 1522 [61440/90000 (68%)]	Loss: -8.6489	Cost: 8.66s
Train Epoch: 1522 [81920/90000 (91%)]	Loss: -8.3400	Cost: 14.35s
Train Epoch: 1522 	Average Loss: -8.1123
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4656

Saving model as e1522_model.pt & e1522_waveforms_supplementary.hdf5
Learning rate: 9.439237554893315e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1523 [0/90000 (0%)]	Loss: -3.4012	Cost: 22.87s
Train Epoch: 1523 [20480/90000 (23%)]	Loss: -8.8120	Cost: 9.38s
Train Epoch: 1523 [40960/90000 (45%)]	Loss: -8.7356	Cost: 13.76s
Train Epoch: 1523 [61440/90000 (68%)]	Loss: -8.6142	Cost: 12.53s
Train Epoch: 1523 [81920/90000 (91%)]	Loss: -8.2672	Cost: 12.37s
Train Epoch: 1523 	Average Loss: -8.2529
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2371

Learning rate: 9.438514553067697e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1524 [0/90000 (0%)]	Loss: -3.1927	Cost: 27.81s
Train Epoch: 1524 [20480/90000 (23%)]	Loss: -8.5534	Cost: 12.71s
Train Epoch: 1524 [40960/90000 (45%)]	Loss: -8.5875	Cost: 12.40s
Train Epoch: 1524 [61440/90000 (68%)]	Loss: -8.4925	Cost: 12.65s
Train Epoch: 1524 [81920/90000 (91%)]	Loss: -8.3999	Cost: 7.98s
Train Epoch: 1524 	Average Loss: -8.1526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3020

Learning rate: 9.437791113178254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1525 [0/90000 (0%)]	Loss: -2.1170	Cost: 25.14s
Train Epoch: 1525 [20480/90000 (23%)]	Loss: -8.5085	Cost: 12.50s
Train Epoch: 1525 [40960/90000 (45%)]	Loss: -8.7166	Cost: 12.49s
Train Epoch: 1525 [61440/90000 (68%)]	Loss: -8.7084	Cost: 6.66s
Train Epoch: 1525 [81920/90000 (91%)]	Loss: -8.4424	Cost: 6.18s
Train Epoch: 1525 	Average Loss: -8.2412
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3454

Learning rate: 9.437067235296389e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1526 [0/90000 (0%)]	Loss: -2.8293	Cost: 29.43s
Train Epoch: 1526 [20480/90000 (23%)]	Loss: -8.7402	Cost: 13.53s
Train Epoch: 1526 [40960/90000 (45%)]	Loss: -8.9093	Cost: 11.89s
Train Epoch: 1526 [61440/90000 (68%)]	Loss: -8.3024	Cost: 8.88s
Train Epoch: 1526 [81920/90000 (91%)]	Loss: -7.9827	Cost: 6.07s
Train Epoch: 1526 	Average Loss: -8.1887
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8814

Learning rate: 9.436342919493543e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1527 [0/90000 (0%)]	Loss: -3.0889	Cost: 23.43s
Train Epoch: 1527 [20480/90000 (23%)]	Loss: -8.0477	Cost: 13.22s
Train Epoch: 1527 [40960/90000 (45%)]	Loss: -8.0337	Cost: 11.31s
Train Epoch: 1527 [61440/90000 (68%)]	Loss: -8.2840	Cost: 7.54s
Train Epoch: 1527 [81920/90000 (91%)]	Loss: -8.2459	Cost: 7.39s
Train Epoch: 1527 	Average Loss: -7.7627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1392

Learning rate: 9.435618165841206e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1528 [0/90000 (0%)]	Loss: -3.0251	Cost: 23.67s
Train Epoch: 1528 [20480/90000 (23%)]	Loss: -8.5004	Cost: 8.13s
Train Epoch: 1528 [40960/90000 (45%)]	Loss: -8.6626	Cost: 10.11s
Train Epoch: 1528 [61440/90000 (68%)]	Loss: -8.7806	Cost: 8.60s
Train Epoch: 1528 [81920/90000 (91%)]	Loss: -8.4233	Cost: 8.36s
Train Epoch: 1528 	Average Loss: -8.1944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3542

Learning rate: 9.434892974410905e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1529 [0/90000 (0%)]	Loss: -3.2282	Cost: 22.58s
Train Epoch: 1529 [20480/90000 (23%)]	Loss: -8.7874	Cost: 9.05s
Train Epoch: 1529 [40960/90000 (45%)]	Loss: -8.7780	Cost: 9.12s
Train Epoch: 1529 [61440/90000 (68%)]	Loss: -8.7339	Cost: 8.06s
Train Epoch: 1529 [81920/90000 (91%)]	Loss: -8.6211	Cost: 5.96s
Train Epoch: 1529 	Average Loss: -8.4075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4978

Saving model as e1529_model.pt & e1529_waveforms_supplementary.hdf5
Learning rate: 9.434167345274215e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1530 [0/90000 (0%)]	Loss: -3.4767	Cost: 21.14s
Train Epoch: 1530 [20480/90000 (23%)]	Loss: -8.8410	Cost: 7.05s
Train Epoch: 1530 [40960/90000 (45%)]	Loss: -8.9141	Cost: 8.48s
Train Epoch: 1530 [61440/90000 (68%)]	Loss: -8.7942	Cost: 10.59s
Train Epoch: 1530 [81920/90000 (91%)]	Loss: -8.7255	Cost: 12.76s
Train Epoch: 1530 	Average Loss: -8.4590
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4371

Learning rate: 9.433441278502756e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1531 [0/90000 (0%)]	Loss: -2.7910	Cost: 28.06s
Train Epoch: 1531 [20480/90000 (23%)]	Loss: -8.8069	Cost: 12.47s
Train Epoch: 1531 [40960/90000 (45%)]	Loss: -9.1101	Cost: 14.30s
Train Epoch: 1531 [61440/90000 (68%)]	Loss: -8.7290	Cost: 12.69s
Train Epoch: 1531 [81920/90000 (91%)]	Loss: -8.6796	Cost: 12.41s
Train Epoch: 1531 	Average Loss: -8.4590
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4902

Learning rate: 9.432714774168182e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1532 [0/90000 (0%)]	Loss: -2.8237	Cost: 24.74s
Train Epoch: 1532 [20480/90000 (23%)]	Loss: -8.5713	Cost: 15.50s
Train Epoch: 1532 [40960/90000 (45%)]	Loss: -7.7487	Cost: 15.23s
Train Epoch: 1532 [61440/90000 (68%)]	Loss: -7.9833	Cost: 12.30s
Train Epoch: 1532 [81920/90000 (91%)]	Loss: -7.8225	Cost: 12.21s
Train Epoch: 1532 	Average Loss: -7.7560
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9536

Learning rate: 9.431987832342201e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1533 [0/90000 (0%)]	Loss: -2.2454	Cost: 30.73s
Train Epoch: 1533 [20480/90000 (23%)]	Loss: -8.1941	Cost: 12.19s
Train Epoch: 1533 [40960/90000 (45%)]	Loss: -8.6672	Cost: 12.55s
Train Epoch: 1533 [61440/90000 (68%)]	Loss: -8.6470	Cost: 12.25s
Train Epoch: 1533 [81920/90000 (91%)]	Loss: -8.4635	Cost: 9.04s
Train Epoch: 1533 	Average Loss: -8.0557
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3608

Learning rate: 9.431260453096557e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1534 [0/90000 (0%)]	Loss: -3.1906	Cost: 23.91s
Train Epoch: 1534 [20480/90000 (23%)]	Loss: -8.7405	Cost: 10.41s
Train Epoch: 1534 [40960/90000 (45%)]	Loss: -9.0023	Cost: 12.45s
Train Epoch: 1534 [61440/90000 (68%)]	Loss: -8.6765	Cost: 6.45s
Train Epoch: 1534 [81920/90000 (91%)]	Loss: -8.5326	Cost: 6.44s
Train Epoch: 1534 	Average Loss: -8.3574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5094

Saving model as e1534_model.pt & e1534_waveforms_supplementary.hdf5
Learning rate: 9.43053263650304e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1535 [0/90000 (0%)]	Loss: -3.1071	Cost: 21.12s
Train Epoch: 1535 [20480/90000 (23%)]	Loss: -8.8296	Cost: 8.62s
Train Epoch: 1535 [40960/90000 (45%)]	Loss: -8.8921	Cost: 10.05s
Train Epoch: 1535 [61440/90000 (68%)]	Loss: -8.9711	Cost: 8.99s
Train Epoch: 1535 [81920/90000 (91%)]	Loss: -8.7590	Cost: 8.92s
Train Epoch: 1535 	Average Loss: -8.4536
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4736

Learning rate: 9.429804382633482e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1536 [0/90000 (0%)]	Loss: -3.0218	Cost: 30.49s
Train Epoch: 1536 [20480/90000 (23%)]	Loss: -8.9349	Cost: 7.03s
Train Epoch: 1536 [40960/90000 (45%)]	Loss: -8.9155	Cost: 9.29s
Train Epoch: 1536 [61440/90000 (68%)]	Loss: -8.8332	Cost: 11.57s
Train Epoch: 1536 [81920/90000 (91%)]	Loss: -8.8372	Cost: 12.58s
Train Epoch: 1536 	Average Loss: -8.4674
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6284

Saving model as e1536_model.pt & e1536_waveforms_supplementary.hdf5
Learning rate: 9.429075691559762e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1537 [0/90000 (0%)]	Loss: -3.2947	Cost: 27.56s
Train Epoch: 1537 [20480/90000 (23%)]	Loss: -8.8190	Cost: 9.06s
Train Epoch: 1537 [40960/90000 (45%)]	Loss: -8.8136	Cost: 11.76s
Train Epoch: 1537 [61440/90000 (68%)]	Loss: -8.7416	Cost: 12.76s
Train Epoch: 1537 [81920/90000 (91%)]	Loss: -8.3525	Cost: 12.27s
Train Epoch: 1537 	Average Loss: -8.4432
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3280

Learning rate: 9.428346563353793e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1538 [0/90000 (0%)]	Loss: -3.1512	Cost: 29.95s
Train Epoch: 1538 [20480/90000 (23%)]	Loss: -8.7522	Cost: 13.90s
Train Epoch: 1538 [40960/90000 (45%)]	Loss: -8.7257	Cost: 12.62s
Train Epoch: 1538 [61440/90000 (68%)]	Loss: -8.9001	Cost: 12.27s
Train Epoch: 1538 [81920/90000 (91%)]	Loss: -8.6674	Cost: 12.39s
Train Epoch: 1538 	Average Loss: -8.4174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4529

Learning rate: 9.427616998087541e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1539 [0/90000 (0%)]	Loss: -2.9727	Cost: 26.26s
Train Epoch: 1539 [20480/90000 (23%)]	Loss: -8.9448	Cost: 11.55s
Train Epoch: 1539 [40960/90000 (45%)]	Loss: -9.0328	Cost: 14.97s
Train Epoch: 1539 [61440/90000 (68%)]	Loss: -8.8441	Cost: 12.37s
Train Epoch: 1539 [81920/90000 (91%)]	Loss: -8.7765	Cost: 10.19s
Train Epoch: 1539 	Average Loss: -8.5174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4657

Learning rate: 9.426886995833012e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1540 [0/90000 (0%)]	Loss: -2.7609	Cost: 25.95s
Train Epoch: 1540 [20480/90000 (23%)]	Loss: -8.9805	Cost: 13.87s
Train Epoch: 1540 [40960/90000 (45%)]	Loss: -8.7986	Cost: 12.58s
Train Epoch: 1540 [61440/90000 (68%)]	Loss: -8.9285	Cost: 10.64s
Train Epoch: 1540 [81920/90000 (91%)]	Loss: -8.6931	Cost: 6.32s
Train Epoch: 1540 	Average Loss: -8.3827
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4004

Learning rate: 9.426156556662252e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1541 [0/90000 (0%)]	Loss: -3.0708	Cost: 36.02s
Train Epoch: 1541 [20480/90000 (23%)]	Loss: -9.1149	Cost: 12.07s
Train Epoch: 1541 [40960/90000 (45%)]	Loss: -9.1891	Cost: 6.46s
Train Epoch: 1541 [61440/90000 (68%)]	Loss: -9.2157	Cost: 6.57s
Train Epoch: 1541 [81920/90000 (91%)]	Loss: -9.0609	Cost: 8.73s
Train Epoch: 1541 	Average Loss: -8.5752
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5697

Learning rate: 9.425425680647353e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1542 [0/90000 (0%)]	Loss: -2.7234	Cost: 32.65s
Train Epoch: 1542 [20480/90000 (23%)]	Loss: -9.0964	Cost: 6.32s
Train Epoch: 1542 [40960/90000 (45%)]	Loss: -9.1068	Cost: 10.14s
Train Epoch: 1542 [61440/90000 (68%)]	Loss: -9.1281	Cost: 8.78s
Train Epoch: 1542 [81920/90000 (91%)]	Loss: -8.8227	Cost: 8.49s
Train Epoch: 1542 	Average Loss: -8.5904
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5800

Learning rate: 9.42469436786045e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1543 [0/90000 (0%)]	Loss: -2.8112	Cost: 20.83s
Train Epoch: 1543 [20480/90000 (23%)]	Loss: -8.8113	Cost: 9.95s
Train Epoch: 1543 [40960/90000 (45%)]	Loss: -8.8824	Cost: 8.92s
Train Epoch: 1543 [61440/90000 (68%)]	Loss: -9.1416	Cost: 8.71s
Train Epoch: 1543 [81920/90000 (91%)]	Loss: -8.6595	Cost: 9.13s
Train Epoch: 1543 	Average Loss: -8.4393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5380

Learning rate: 9.42396261837372e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1544 [0/90000 (0%)]	Loss: -2.9516	Cost: 18.51s
Train Epoch: 1544 [20480/90000 (23%)]	Loss: -8.9800	Cost: 7.13s
Train Epoch: 1544 [40960/90000 (45%)]	Loss: -8.9516	Cost: 14.17s
Train Epoch: 1544 [61440/90000 (68%)]	Loss: -9.0244	Cost: 11.16s
Train Epoch: 1544 [81920/90000 (91%)]	Loss: -8.8521	Cost: 16.57s
Train Epoch: 1544 	Average Loss: -8.5422
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4188

Learning rate: 9.423230432259386e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1545 [0/90000 (0%)]	Loss: -3.1858	Cost: 19.12s
Train Epoch: 1545 [20480/90000 (23%)]	Loss: -8.8943	Cost: 8.97s
Train Epoch: 1545 [40960/90000 (45%)]	Loss: -9.0082	Cost: 14.19s
Train Epoch: 1545 [61440/90000 (68%)]	Loss: -9.0950	Cost: 13.16s
Train Epoch: 1545 [81920/90000 (91%)]	Loss: -8.9498	Cost: 12.26s
Train Epoch: 1545 	Average Loss: -8.5376
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5844

Learning rate: 9.422497809589708e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1546 [0/90000 (0%)]	Loss: -3.0267	Cost: 39.40s
Train Epoch: 1546 [20480/90000 (23%)]	Loss: -8.9948	Cost: 12.83s
Train Epoch: 1546 [40960/90000 (45%)]	Loss: -9.1857	Cost: 12.46s
Train Epoch: 1546 [61440/90000 (68%)]	Loss: -8.9587	Cost: 12.32s
Train Epoch: 1546 [81920/90000 (91%)]	Loss: -8.7635	Cost: 10.62s
Train Epoch: 1546 	Average Loss: -8.5909
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5255

Learning rate: 9.421764750436996e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1547 [0/90000 (0%)]	Loss: -3.0279	Cost: 31.88s
Train Epoch: 1547 [20480/90000 (23%)]	Loss: -8.8797	Cost: 13.47s
Train Epoch: 1547 [40960/90000 (45%)]	Loss: -8.8887	Cost: 12.25s
Train Epoch: 1547 [61440/90000 (68%)]	Loss: -8.9328	Cost: 10.67s
Train Epoch: 1547 [81920/90000 (91%)]	Loss: -8.8041	Cost: 6.05s
Train Epoch: 1547 	Average Loss: -8.4818
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5805

Learning rate: 9.421031254873599e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1548 [0/90000 (0%)]	Loss: -3.8179	Cost: 30.12s
Train Epoch: 1548 [20480/90000 (23%)]	Loss: -8.8726	Cost: 10.32s
Train Epoch: 1548 [40960/90000 (45%)]	Loss: -9.0198	Cost: 9.76s
Train Epoch: 1548 [61440/90000 (68%)]	Loss: -9.1559	Cost: 6.67s
Train Epoch: 1548 [81920/90000 (91%)]	Loss: -8.6950	Cost: 6.32s
Train Epoch: 1548 	Average Loss: -8.4814
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5136

Learning rate: 9.42029732297191e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1549 [0/90000 (0%)]	Loss: -3.2270	Cost: 20.79s
Train Epoch: 1549 [20480/90000 (23%)]	Loss: -8.8689	Cost: 6.41s
Train Epoch: 1549 [40960/90000 (45%)]	Loss: -8.9216	Cost: 8.26s
Train Epoch: 1549 [61440/90000 (68%)]	Loss: -9.0248	Cost: 9.08s
Train Epoch: 1549 [81920/90000 (91%)]	Loss: -8.9373	Cost: 9.30s
Train Epoch: 1549 	Average Loss: -8.5655
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5834

Learning rate: 9.419562954804365e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1550 [0/90000 (0%)]	Loss: -2.8690	Cost: 21.81s
Train Epoch: 1550 [20480/90000 (23%)]	Loss: -8.9382	Cost: 9.22s
Train Epoch: 1550 [40960/90000 (45%)]	Loss: -8.9708	Cost: 8.85s
Train Epoch: 1550 [61440/90000 (68%)]	Loss: -9.0054	Cost: 8.68s
Train Epoch: 1550 [81920/90000 (91%)]	Loss: -8.8863	Cost: 8.44s
Train Epoch: 1550 	Average Loss: -8.6122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6695

Saving model as e1550_model.pt & e1550_waveforms_supplementary.hdf5
Learning rate: 9.418828150443444e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1551 [0/90000 (0%)]	Loss: -2.7804	Cost: 21.82s
Train Epoch: 1551 [20480/90000 (23%)]	Loss: -8.8785	Cost: 6.50s
Train Epoch: 1551 [40960/90000 (45%)]	Loss: -9.0383	Cost: 8.56s
Train Epoch: 1551 [61440/90000 (68%)]	Loss: -9.0740	Cost: 8.25s
Train Epoch: 1551 [81920/90000 (91%)]	Loss: -8.8049	Cost: 14.45s
Train Epoch: 1551 	Average Loss: -8.5175
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6134

Learning rate: 9.41809290996167e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1552 [0/90000 (0%)]	Loss: -3.1859	Cost: 22.79s
Train Epoch: 1552 [20480/90000 (23%)]	Loss: -8.9268	Cost: 10.46s
Train Epoch: 1552 [40960/90000 (45%)]	Loss: -9.0267	Cost: 13.08s
Train Epoch: 1552 [61440/90000 (68%)]	Loss: -8.9422	Cost: 12.50s
Train Epoch: 1552 [81920/90000 (91%)]	Loss: -8.7607	Cost: 12.35s
Train Epoch: 1552 	Average Loss: -8.4890
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5018

Learning rate: 9.417357233431606e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1553 [0/90000 (0%)]	Loss: -3.7465	Cost: 39.96s
Train Epoch: 1553 [20480/90000 (23%)]	Loss: -8.8978	Cost: 13.87s
Train Epoch: 1553 [40960/90000 (45%)]	Loss: -8.9833	Cost: 13.25s
Train Epoch: 1553 [61440/90000 (68%)]	Loss: -9.2410	Cost: 12.10s
Train Epoch: 1553 [81920/90000 (91%)]	Loss: -8.7965	Cost: 6.44s
Train Epoch: 1553 	Average Loss: -8.5609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5091

Learning rate: 9.416621120925861e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1554 [0/90000 (0%)]	Loss: -3.0240	Cost: 25.17s
Train Epoch: 1554 [20480/90000 (23%)]	Loss: -9.1424	Cost: 13.19s
Train Epoch: 1554 [40960/90000 (45%)]	Loss: -9.2631	Cost: 12.55s
Train Epoch: 1554 [61440/90000 (68%)]	Loss: -9.4842	Cost: 6.39s
Train Epoch: 1554 [81920/90000 (91%)]	Loss: -8.4866	Cost: 6.30s
Train Epoch: 1554 	Average Loss: -8.6200
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4302

Learning rate: 9.415884572517089e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1555 [0/90000 (0%)]	Loss: -2.7124	Cost: 30.22s
Train Epoch: 1555 [20480/90000 (23%)]	Loss: -8.7922	Cost: 6.87s
Train Epoch: 1555 [40960/90000 (45%)]	Loss: -9.0282	Cost: 9.70s
Train Epoch: 1555 [61440/90000 (68%)]	Loss: -9.2033	Cost: 8.56s
Train Epoch: 1555 [81920/90000 (91%)]	Loss: -8.8669	Cost: 8.80s
Train Epoch: 1555 	Average Loss: -8.5207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7419

Saving model as e1555_model.pt & e1555_waveforms_supplementary.hdf5
Learning rate: 9.415147588277982e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1556 [0/90000 (0%)]	Loss: -2.7836	Cost: 19.57s
Train Epoch: 1556 [20480/90000 (23%)]	Loss: -9.3348	Cost: 9.05s
Train Epoch: 1556 [40960/90000 (45%)]	Loss: -9.3154	Cost: 8.36s
Train Epoch: 1556 [61440/90000 (68%)]	Loss: -9.1967	Cost: 6.05s
Train Epoch: 1556 [81920/90000 (91%)]	Loss: -9.0077	Cost: 6.38s
Train Epoch: 1556 	Average Loss: -8.6827
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7395

Learning rate: 9.414410168281278e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1557 [0/90000 (0%)]	Loss: -3.2696	Cost: 20.73s
Train Epoch: 1557 [20480/90000 (23%)]	Loss: -9.0870	Cost: 7.87s
Train Epoch: 1557 [40960/90000 (45%)]	Loss: -9.1757	Cost: 10.06s
Train Epoch: 1557 [61440/90000 (68%)]	Loss: -9.2263	Cost: 12.71s
Train Epoch: 1557 [81920/90000 (91%)]	Loss: -8.8490	Cost: 12.48s
Train Epoch: 1557 	Average Loss: -8.7065
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7715

Saving model as e1557_model.pt & e1557_waveforms_supplementary.hdf5
Learning rate: 9.413672312599757e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1558 [0/90000 (0%)]	Loss: -2.7961	Cost: 38.99s
Train Epoch: 1558 [20480/90000 (23%)]	Loss: -8.8520	Cost: 14.46s
Train Epoch: 1558 [40960/90000 (45%)]	Loss: -8.9128	Cost: 13.19s
Train Epoch: 1558 [61440/90000 (68%)]	Loss: -9.0589	Cost: 12.16s
Train Epoch: 1558 [81920/90000 (91%)]	Loss: -8.8000	Cost: 8.81s
Train Epoch: 1558 	Average Loss: -8.5231
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6465

Learning rate: 9.412934021306243e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1559 [0/90000 (0%)]	Loss: -2.8468	Cost: 39.86s
Train Epoch: 1559 [20480/90000 (23%)]	Loss: -8.8968	Cost: 13.50s
Train Epoch: 1559 [40960/90000 (45%)]	Loss: -9.0251	Cost: 12.09s
Train Epoch: 1559 [61440/90000 (68%)]	Loss: -9.0494	Cost: 6.06s
Train Epoch: 1559 [81920/90000 (91%)]	Loss: -8.8125	Cost: 6.24s
Train Epoch: 1559 	Average Loss: -8.5641
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6946

Learning rate: 9.412195294473602e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1560 [0/90000 (0%)]	Loss: -3.3180	Cost: 30.19s
Train Epoch: 1560 [20480/90000 (23%)]	Loss: -8.9606	Cost: 12.31s
Train Epoch: 1560 [40960/90000 (45%)]	Loss: -9.2828	Cost: 9.61s
Train Epoch: 1560 [61440/90000 (68%)]	Loss: -9.2871	Cost: 6.09s
Train Epoch: 1560 [81920/90000 (91%)]	Loss: -8.8767	Cost: 7.72s
Train Epoch: 1560 	Average Loss: -8.6848
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6309

Learning rate: 9.411456132174745e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1561 [0/90000 (0%)]	Loss: -3.0162	Cost: 21.45s
Train Epoch: 1561 [20480/90000 (23%)]	Loss: -9.1735	Cost: 7.36s
Train Epoch: 1561 [40960/90000 (45%)]	Loss: -9.2146	Cost: 9.74s
Train Epoch: 1561 [61440/90000 (68%)]	Loss: -9.0912	Cost: 8.49s
Train Epoch: 1561 [81920/90000 (91%)]	Loss: -9.1580	Cost: 8.40s
Train Epoch: 1561 	Average Loss: -8.6652
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7858

Saving model as e1561_model.pt & e1561_waveforms_supplementary.hdf5
Learning rate: 9.410716534482622e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1562 [0/90000 (0%)]	Loss: -3.0055	Cost: 21.73s
Train Epoch: 1562 [20480/90000 (23%)]	Loss: -9.3132	Cost: 9.25s
Train Epoch: 1562 [40960/90000 (45%)]	Loss: -9.3085	Cost: 8.85s
Train Epoch: 1562 [61440/90000 (68%)]	Loss: -9.1516	Cost: 9.03s
Train Epoch: 1562 [81920/90000 (91%)]	Loss: -8.9779	Cost: 9.14s
Train Epoch: 1562 	Average Loss: -8.7464
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8833

Saving model as e1562_model.pt & e1562_waveforms_supplementary.hdf5
Learning rate: 9.409976501470228e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1563 [0/90000 (0%)]	Loss: -3.5684	Cost: 22.46s
Train Epoch: 1563 [20480/90000 (23%)]	Loss: -9.0065	Cost: 9.82s
Train Epoch: 1563 [40960/90000 (45%)]	Loss: -9.2502	Cost: 10.84s
Train Epoch: 1563 [61440/90000 (68%)]	Loss: -9.2933	Cost: 12.76s
Train Epoch: 1563 [81920/90000 (91%)]	Loss: -9.0407	Cost: 12.45s
Train Epoch: 1563 	Average Loss: -8.6826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7199

Learning rate: 9.409236033210605e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1564 [0/90000 (0%)]	Loss: -3.0184	Cost: 27.99s
Train Epoch: 1564 [20480/90000 (23%)]	Loss: -9.0264	Cost: 12.82s
Train Epoch: 1564 [40960/90000 (45%)]	Loss: -9.3079	Cost: 14.73s
Train Epoch: 1564 [61440/90000 (68%)]	Loss: -9.1779	Cost: 12.31s
Train Epoch: 1564 [81920/90000 (91%)]	Loss: -8.8948	Cost: 12.26s
Train Epoch: 1564 	Average Loss: -8.7134
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7257

Learning rate: 9.40849512977683e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1565 [0/90000 (0%)]	Loss: -3.3053	Cost: 26.55s
Train Epoch: 1565 [20480/90000 (23%)]	Loss: -9.1762	Cost: 13.65s
Train Epoch: 1565 [40960/90000 (45%)]	Loss: -9.1523	Cost: 13.13s
Train Epoch: 1565 [61440/90000 (68%)]	Loss: -9.1716	Cost: 12.25s
Train Epoch: 1565 [81920/90000 (91%)]	Loss: -8.9952	Cost: 8.84s
Train Epoch: 1565 	Average Loss: -8.6836
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6631

Learning rate: 9.40775379124203e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1566 [0/90000 (0%)]	Loss: -3.3313	Cost: 24.17s
Train Epoch: 1566 [20480/90000 (23%)]	Loss: -9.0450	Cost: 12.44s
Train Epoch: 1566 [40960/90000 (45%)]	Loss: -8.9904	Cost: 11.40s
Train Epoch: 1566 [61440/90000 (68%)]	Loss: -8.7874	Cost: 6.45s
Train Epoch: 1566 [81920/90000 (91%)]	Loss: -8.7576	Cost: 6.69s
Train Epoch: 1566 	Average Loss: -8.5215
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6081

Learning rate: 9.407012017679371e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1567 [0/90000 (0%)]	Loss: -3.1982	Cost: 21.34s
Train Epoch: 1567 [20480/90000 (23%)]	Loss: -8.9420	Cost: 6.79s
Train Epoch: 1567 [40960/90000 (45%)]	Loss: -9.1982	Cost: 9.29s
Train Epoch: 1567 [61440/90000 (68%)]	Loss: -9.2239	Cost: 9.28s
Train Epoch: 1567 [81920/90000 (91%)]	Loss: -8.9358	Cost: 8.84s
Train Epoch: 1567 	Average Loss: -8.6544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7717

Learning rate: 9.406269809162065e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1568 [0/90000 (0%)]	Loss: -2.9718	Cost: 27.44s
Train Epoch: 1568 [20480/90000 (23%)]	Loss: -9.2908	Cost: 10.25s
Train Epoch: 1568 [40960/90000 (45%)]	Loss: -9.2591	Cost: 8.81s
Train Epoch: 1568 [61440/90000 (68%)]	Loss: -9.2786	Cost: 8.58s
Train Epoch: 1568 [81920/90000 (91%)]	Loss: -9.1404	Cost: 8.83s
Train Epoch: 1568 	Average Loss: -8.7949
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6193

Learning rate: 9.405527165763362e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1569 [0/90000 (0%)]	Loss: -3.2193	Cost: 24.08s
Train Epoch: 1569 [20480/90000 (23%)]	Loss: -9.1868	Cost: 8.95s
Train Epoch: 1569 [40960/90000 (45%)]	Loss: -9.4021	Cost: 9.06s
Train Epoch: 1569 [61440/90000 (68%)]	Loss: -9.4040	Cost: 6.62s
Train Epoch: 1569 [81920/90000 (91%)]	Loss: -9.0064	Cost: 6.40s
Train Epoch: 1569 	Average Loss: -8.8273
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6003

Learning rate: 9.40478408755656e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1570 [0/90000 (0%)]	Loss: -3.2284	Cost: 17.87s
Train Epoch: 1570 [20480/90000 (23%)]	Loss: -9.2883	Cost: 7.37s
Train Epoch: 1570 [40960/90000 (45%)]	Loss: -9.3682	Cost: 10.51s
Train Epoch: 1570 [61440/90000 (68%)]	Loss: -9.2594	Cost: 9.28s
Train Epoch: 1570 [81920/90000 (91%)]	Loss: -9.2910	Cost: 13.12s
Train Epoch: 1570 	Average Loss: -8.8574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8866

Saving model as e1570_model.pt & e1570_waveforms_supplementary.hdf5
Learning rate: 9.404040574614996e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1571 [0/90000 (0%)]	Loss: -3.5325	Cost: 24.19s
Train Epoch: 1571 [20480/90000 (23%)]	Loss: -9.2797	Cost: 10.70s
Train Epoch: 1571 [40960/90000 (45%)]	Loss: -9.2798	Cost: 12.57s
Train Epoch: 1571 [61440/90000 (68%)]	Loss: -9.4066	Cost: 12.25s
Train Epoch: 1571 [81920/90000 (91%)]	Loss: -9.2047	Cost: 12.62s
Train Epoch: 1571 	Average Loss: -8.7919
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8517

Learning rate: 9.403296627012055e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1572 [0/90000 (0%)]	Loss: -4.0797	Cost: 24.36s
Train Epoch: 1572 [20480/90000 (23%)]	Loss: -9.2904	Cost: 14.99s
Train Epoch: 1572 [40960/90000 (45%)]	Loss: -9.3520	Cost: 13.14s
Train Epoch: 1572 [61440/90000 (68%)]	Loss: -8.4557	Cost: 12.11s
Train Epoch: 1572 [81920/90000 (91%)]	Loss: -8.6322	Cost: 8.31s
Train Epoch: 1572 	Average Loss: -8.5620
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3886

Learning rate: 9.402552244821159e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1573 [0/90000 (0%)]	Loss: -2.7761	Cost: 38.99s
Train Epoch: 1573 [20480/90000 (23%)]	Loss: -8.9269	Cost: 10.04s
Train Epoch: 1573 [40960/90000 (45%)]	Loss: -9.1628	Cost: 10.22s
Train Epoch: 1573 [61440/90000 (68%)]	Loss: -9.2749	Cost: 6.39s
Train Epoch: 1573 [81920/90000 (91%)]	Loss: -9.0560	Cost: 6.98s
Train Epoch: 1573 	Average Loss: -8.6262
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7582

Learning rate: 9.401807428115777e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1574 [0/90000 (0%)]	Loss: -3.4668	Cost: 35.45s
Train Epoch: 1574 [20480/90000 (23%)]	Loss: -9.2824	Cost: 10.70s
Train Epoch: 1574 [40960/90000 (45%)]	Loss: -9.4432	Cost: 6.80s
Train Epoch: 1574 [61440/90000 (68%)]	Loss: -9.1987	Cost: 6.36s
Train Epoch: 1574 [81920/90000 (91%)]	Loss: -9.1136	Cost: 8.46s
Train Epoch: 1574 	Average Loss: -8.8401
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8126

Learning rate: 9.40106217696942e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1575 [0/90000 (0%)]	Loss: -2.9150	Cost: 25.48s
Train Epoch: 1575 [20480/90000 (23%)]	Loss: -9.3903	Cost: 6.95s
Train Epoch: 1575 [40960/90000 (45%)]	Loss: -9.1985	Cost: 7.52s
Train Epoch: 1575 [61440/90000 (68%)]	Loss: -9.4499	Cost: 8.25s
Train Epoch: 1575 [81920/90000 (91%)]	Loss: -8.9495	Cost: 8.76s
Train Epoch: 1575 	Average Loss: -8.8497
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7121

Learning rate: 9.40031649145564e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1576 [0/90000 (0%)]	Loss: -3.4166	Cost: 19.48s
Train Epoch: 1576 [20480/90000 (23%)]	Loss: -9.1409	Cost: 6.74s
Train Epoch: 1576 [40960/90000 (45%)]	Loss: -9.2496	Cost: 9.84s
Train Epoch: 1576 [61440/90000 (68%)]	Loss: -9.2988	Cost: 8.67s
Train Epoch: 1576 [81920/90000 (91%)]	Loss: -9.0028	Cost: 8.75s
Train Epoch: 1576 	Average Loss: -8.7465
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9507

Saving model as e1576_model.pt & e1576_waveforms_supplementary.hdf5
Learning rate: 9.399570371648032e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1577 [0/90000 (0%)]	Loss: -3.2833	Cost: 20.74s
Train Epoch: 1577 [20480/90000 (23%)]	Loss: -9.3458	Cost: 8.93s
Train Epoch: 1577 [40960/90000 (45%)]	Loss: -9.5957	Cost: 9.65s
Train Epoch: 1577 [61440/90000 (68%)]	Loss: -9.4010	Cost: 9.14s
Train Epoch: 1577 [81920/90000 (91%)]	Loss: -9.2464	Cost: 6.55s
Train Epoch: 1577 	Average Loss: -8.9769
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9140

Learning rate: 9.398823817620238e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1578 [0/90000 (0%)]	Loss: -3.3173	Cost: 27.35s
Train Epoch: 1578 [20480/90000 (23%)]	Loss: -9.3756	Cost: 8.64s
Train Epoch: 1578 [40960/90000 (45%)]	Loss: -9.4581	Cost: 7.08s
Train Epoch: 1578 [61440/90000 (68%)]	Loss: -9.5725	Cost: 7.72s
Train Epoch: 1578 [81920/90000 (91%)]	Loss: -9.0459	Cost: 13.33s
Train Epoch: 1578 	Average Loss: -8.8665
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6716

Learning rate: 9.398076829445937e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1579 [0/90000 (0%)]	Loss: -3.1463	Cost: 23.61s
Train Epoch: 1579 [20480/90000 (23%)]	Loss: -9.3945	Cost: 10.79s
Train Epoch: 1579 [40960/90000 (45%)]	Loss: -9.3690	Cost: 15.93s
Train Epoch: 1579 [61440/90000 (68%)]	Loss: -9.5283	Cost: 13.06s
Train Epoch: 1579 [81920/90000 (91%)]	Loss: -9.2359	Cost: 12.26s
Train Epoch: 1579 	Average Loss: -8.8843
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7665

Learning rate: 9.397329407198858e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1580 [0/90000 (0%)]	Loss: -3.8215	Cost: 28.54s
Train Epoch: 1580 [20480/90000 (23%)]	Loss: -9.2804	Cost: 12.76s
Train Epoch: 1580 [40960/90000 (45%)]	Loss: -9.1759	Cost: 13.05s
Train Epoch: 1580 [61440/90000 (68%)]	Loss: -9.3819	Cost: 12.28s
Train Epoch: 1580 [81920/90000 (91%)]	Loss: -9.1696	Cost: 12.31s
Train Epoch: 1580 	Average Loss: -8.9068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8924

Learning rate: 9.396581550952764e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1581 [0/90000 (0%)]	Loss: -2.9909	Cost: 24.41s
Train Epoch: 1581 [20480/90000 (23%)]	Loss: -9.4031	Cost: 10.31s
Train Epoch: 1581 [40960/90000 (45%)]	Loss: -9.2782	Cost: 12.45s
Train Epoch: 1581 [61440/90000 (68%)]	Loss: -8.7556	Cost: 12.16s
Train Epoch: 1581 [81920/90000 (91%)]	Loss: -8.4840	Cost: 8.20s
Train Epoch: 1581 	Average Loss: -8.6066
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4550

Learning rate: 9.395833260781467e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1582 [0/90000 (0%)]	Loss: -3.2189	Cost: 26.67s
Train Epoch: 1582 [20480/90000 (23%)]	Loss: -8.8633	Cost: 11.68s
Train Epoch: 1582 [40960/90000 (45%)]	Loss: -9.0257	Cost: 8.62s
Train Epoch: 1582 [61440/90000 (68%)]	Loss: -9.1785	Cost: 6.48s
Train Epoch: 1582 [81920/90000 (91%)]	Loss: -8.9189	Cost: 7.42s
Train Epoch: 1582 	Average Loss: -8.5140
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7288

Learning rate: 9.395084536758821e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1583 [0/90000 (0%)]	Loss: -3.4840	Cost: 23.56s
Train Epoch: 1583 [20480/90000 (23%)]	Loss: -9.1493	Cost: 13.49s
Train Epoch: 1583 [40960/90000 (45%)]	Loss: -9.3641	Cost: 9.98s
Train Epoch: 1583 [61440/90000 (68%)]	Loss: -9.2649	Cost: 7.03s
Train Epoch: 1583 [81920/90000 (91%)]	Loss: -9.2352	Cost: 8.08s
Train Epoch: 1583 	Average Loss: -8.8077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8715

Learning rate: 9.39433537895872e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1584 [0/90000 (0%)]	Loss: -3.3774	Cost: 23.94s
Train Epoch: 1584 [20480/90000 (23%)]	Loss: -9.2323	Cost: 12.56s
Train Epoch: 1584 [40960/90000 (45%)]	Loss: -9.4181	Cost: 6.52s
Train Epoch: 1584 [61440/90000 (68%)]	Loss: -9.3737	Cost: 8.84s
Train Epoch: 1584 [81920/90000 (91%)]	Loss: -9.1515	Cost: 8.53s
Train Epoch: 1584 	Average Loss: -8.9439
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5164

Learning rate: 9.393585787455106e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1585 [0/90000 (0%)]	Loss: -3.5053	Cost: 22.20s
Train Epoch: 1585 [20480/90000 (23%)]	Loss: -9.3870	Cost: 9.15s
Train Epoch: 1585 [40960/90000 (45%)]	Loss: -8.9331	Cost: 9.03s
Train Epoch: 1585 [61440/90000 (68%)]	Loss: -8.8718	Cost: 8.73s
Train Epoch: 1585 [81920/90000 (91%)]	Loss: -8.6885	Cost: 8.56s
Train Epoch: 1585 	Average Loss: -8.5997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5609

Learning rate: 9.39283576232196e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1586 [0/90000 (0%)]	Loss: -2.9804	Cost: 23.79s
Train Epoch: 1586 [20480/90000 (23%)]	Loss: -8.9700	Cost: 8.90s
Train Epoch: 1586 [40960/90000 (45%)]	Loss: -9.2805	Cost: 7.02s
Train Epoch: 1586 [61440/90000 (68%)]	Loss: -9.5472	Cost: 6.57s
Train Epoch: 1586 [81920/90000 (91%)]	Loss: -9.0298	Cost: 6.45s
Train Epoch: 1586 	Average Loss: -8.7206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7886

Learning rate: 9.392085303633305e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1587 [0/90000 (0%)]	Loss: -3.6668	Cost: 21.71s
Train Epoch: 1587 [20480/90000 (23%)]	Loss: -9.2796	Cost: 9.22s
Train Epoch: 1587 [40960/90000 (45%)]	Loss: -9.1594	Cost: 8.83s
Train Epoch: 1587 [61440/90000 (68%)]	Loss: -8.0879	Cost: 11.80s
Train Epoch: 1587 [81920/90000 (91%)]	Loss: -7.9924	Cost: 12.32s
Train Epoch: 1587 	Average Loss: -8.3645
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0661

Learning rate: 9.39133441146321e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1588 [0/90000 (0%)]	Loss: -2.9726	Cost: 23.37s
Train Epoch: 1588 [20480/90000 (23%)]	Loss: -8.5505	Cost: 11.54s
Train Epoch: 1588 [40960/90000 (45%)]	Loss: -9.1289	Cost: 14.66s
Train Epoch: 1588 [61440/90000 (68%)]	Loss: -9.2232	Cost: 13.60s
Train Epoch: 1588 [81920/90000 (91%)]	Loss: -9.0655	Cost: 12.45s
Train Epoch: 1588 	Average Loss: -8.4989
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7761

Learning rate: 9.390583085885783e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1589 [0/90000 (0%)]	Loss: -3.1692	Cost: 27.12s
Train Epoch: 1589 [20480/90000 (23%)]	Loss: -9.2944	Cost: 14.39s
Train Epoch: 1589 [40960/90000 (45%)]	Loss: -9.1696	Cost: 13.99s
Train Epoch: 1589 [61440/90000 (68%)]	Loss: -9.1023	Cost: 12.31s
Train Epoch: 1589 [81920/90000 (91%)]	Loss: -8.8485	Cost: 7.22s
Train Epoch: 1589 	Average Loss: -8.7073
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6722

Learning rate: 9.389831326975179e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1590 [0/90000 (0%)]	Loss: -3.2931	Cost: 30.69s
Train Epoch: 1590 [20480/90000 (23%)]	Loss: -9.1789	Cost: 12.48s
Train Epoch: 1590 [40960/90000 (45%)]	Loss: -9.3777	Cost: 9.27s
Train Epoch: 1590 [61440/90000 (68%)]	Loss: -9.4665	Cost: 6.06s
Train Epoch: 1590 [81920/90000 (91%)]	Loss: -9.3298	Cost: 7.43s
Train Epoch: 1590 	Average Loss: -8.8624
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9165

Learning rate: 9.389079134805592e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1591 [0/90000 (0%)]	Loss: -3.8228	Cost: 31.74s
Train Epoch: 1591 [20480/90000 (23%)]	Loss: -9.4482	Cost: 6.40s
Train Epoch: 1591 [40960/90000 (45%)]	Loss: -9.6244	Cost: 8.82s
Train Epoch: 1591 [61440/90000 (68%)]	Loss: -9.5719	Cost: 8.75s
Train Epoch: 1591 [81920/90000 (91%)]	Loss: -9.2381	Cost: 8.90s
Train Epoch: 1591 	Average Loss: -9.0481
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7911

Learning rate: 9.388326509451261e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1592 [0/90000 (0%)]	Loss: -2.7726	Cost: 24.34s
Train Epoch: 1592 [20480/90000 (23%)]	Loss: -9.4400	Cost: 6.94s
Train Epoch: 1592 [40960/90000 (45%)]	Loss: -9.5765	Cost: 9.25s
Train Epoch: 1592 [61440/90000 (68%)]	Loss: -9.6402	Cost: 8.92s
Train Epoch: 1592 [81920/90000 (91%)]	Loss: -9.3285	Cost: 8.65s
Train Epoch: 1592 	Average Loss: -9.0430
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9135

Learning rate: 9.387573450986467e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1593 [0/90000 (0%)]	Loss: -3.1249	Cost: 24.47s
Train Epoch: 1593 [20480/90000 (23%)]	Loss: -9.3500	Cost: 9.85s
Train Epoch: 1593 [40960/90000 (45%)]	Loss: -9.4988	Cost: 16.41s
Train Epoch: 1593 [61440/90000 (68%)]	Loss: -9.6365	Cost: 13.88s
Train Epoch: 1593 [81920/90000 (91%)]	Loss: -9.3081	Cost: 12.28s
Train Epoch: 1593 	Average Loss: -8.9816
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8796

Learning rate: 9.386819959485536e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1594 [0/90000 (0%)]	Loss: -2.9545	Cost: 24.66s
Train Epoch: 1594 [20480/90000 (23%)]	Loss: -9.2774	Cost: 11.58s
Train Epoch: 1594 [40960/90000 (45%)]	Loss: -9.5200	Cost: 15.87s
Train Epoch: 1594 [61440/90000 (68%)]	Loss: -9.3723	Cost: 13.32s
Train Epoch: 1594 [81920/90000 (91%)]	Loss: -9.4984	Cost: 12.32s
Train Epoch: 1594 	Average Loss: -9.0732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1808

Saving model as e1594_model.pt & e1594_waveforms_supplementary.hdf5
Learning rate: 9.386066035022831e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1595 [0/90000 (0%)]	Loss: -4.3114	Cost: 36.23s
Train Epoch: 1595 [20480/90000 (23%)]	Loss: -9.6015	Cost: 12.38s
Train Epoch: 1595 [40960/90000 (45%)]	Loss: -9.7744	Cost: 12.44s
Train Epoch: 1595 [61440/90000 (68%)]	Loss: -9.4921	Cost: 10.84s
Train Epoch: 1595 [81920/90000 (91%)]	Loss: -9.4194	Cost: 6.26s
Train Epoch: 1595 	Average Loss: -9.1285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0010

Learning rate: 9.385311677672765e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1596 [0/90000 (0%)]	Loss: -3.9077	Cost: 22.98s
Train Epoch: 1596 [20480/90000 (23%)]	Loss: -9.5205	Cost: 12.42s
Train Epoch: 1596 [40960/90000 (45%)]	Loss: -9.5512	Cost: 6.47s
Train Epoch: 1596 [61440/90000 (68%)]	Loss: -9.5417	Cost: 6.12s
Train Epoch: 1596 [81920/90000 (91%)]	Loss: -9.2246	Cost: 8.20s
Train Epoch: 1596 	Average Loss: -9.0336
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1311

Learning rate: 9.384556887509786e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1597 [0/90000 (0%)]	Loss: -2.3328	Cost: 22.15s
Train Epoch: 1597 [20480/90000 (23%)]	Loss: -9.4868	Cost: 9.07s
Train Epoch: 1597 [40960/90000 (45%)]	Loss: -9.6544	Cost: 9.39s
Train Epoch: 1597 [61440/90000 (68%)]	Loss: -9.4756	Cost: 9.02s
Train Epoch: 1597 [81920/90000 (91%)]	Loss: -9.1160	Cost: 8.18s
Train Epoch: 1597 	Average Loss: -8.9871
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9389

Learning rate: 9.383801664608392e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1598 [0/90000 (0%)]	Loss: -2.9974	Cost: 21.31s
Train Epoch: 1598 [20480/90000 (23%)]	Loss: -9.5283	Cost: 8.12s
Train Epoch: 1598 [40960/90000 (45%)]	Loss: -9.4959	Cost: 13.39s
Train Epoch: 1598 [61440/90000 (68%)]	Loss: -9.4562	Cost: 10.06s
Train Epoch: 1598 [81920/90000 (91%)]	Loss: -9.2221	Cost: 12.92s
Train Epoch: 1598 	Average Loss: -9.0253
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7872

Learning rate: 9.38304600904312e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1599 [0/90000 (0%)]	Loss: -3.4466	Cost: 35.81s
Train Epoch: 1599 [20480/90000 (23%)]	Loss: -9.5939	Cost: 10.56s
Train Epoch: 1599 [40960/90000 (45%)]	Loss: -9.4160	Cost: 12.63s
Train Epoch: 1599 [61440/90000 (68%)]	Loss: -9.4703	Cost: 12.34s
Train Epoch: 1599 [81920/90000 (91%)]	Loss: -9.2336	Cost: 12.31s
Train Epoch: 1599 	Average Loss: -9.0383
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9543

Learning rate: 9.382289920888548e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1600 [0/90000 (0%)]	Loss: -4.1690	Cost: 31.28s
Train Epoch: 1600 [20480/90000 (23%)]	Loss: -9.3033	Cost: 11.27s
Train Epoch: 1600 [40960/90000 (45%)]	Loss: -9.5535	Cost: 12.67s
Train Epoch: 1600 [61440/90000 (68%)]	Loss: -9.4354	Cost: 12.33s
Train Epoch: 1600 [81920/90000 (91%)]	Loss: -9.3192	Cost: 7.95s
Train Epoch: 1600 	Average Loss: -9.0662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9387

Learning rate: 9.3815334002193e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1601 [0/90000 (0%)]	Loss: -3.8659	Cost: 37.99s
Train Epoch: 1601 [20480/90000 (23%)]	Loss: -9.4351	Cost: 12.72s
Train Epoch: 1601 [40960/90000 (45%)]	Loss: -9.5402	Cost: 12.44s
Train Epoch: 1601 [61440/90000 (68%)]	Loss: -9.6639	Cost: 7.73s
Train Epoch: 1601 [81920/90000 (91%)]	Loss: -9.5195	Cost: 6.44s
Train Epoch: 1601 	Average Loss: -9.1490
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1215

Learning rate: 9.380776447110046e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1602 [0/90000 (0%)]	Loss: -4.2428	Cost: 26.20s
Train Epoch: 1602 [20480/90000 (23%)]	Loss: -9.6155	Cost: 12.43s
Train Epoch: 1602 [40960/90000 (45%)]	Loss: -9.5873	Cost: 8.38s
Train Epoch: 1602 [61440/90000 (68%)]	Loss: -9.4575	Cost: 7.41s
Train Epoch: 1602 [81920/90000 (91%)]	Loss: -9.3407	Cost: 7.48s
Train Epoch: 1602 	Average Loss: -9.0672
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7984

Learning rate: 9.380019061635488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1603 [0/90000 (0%)]	Loss: -3.0047	Cost: 24.57s
Train Epoch: 1603 [20480/90000 (23%)]	Loss: -9.4415	Cost: 9.70s
Train Epoch: 1603 [40960/90000 (45%)]	Loss: -9.7273	Cost: 6.98s
Train Epoch: 1603 [61440/90000 (68%)]	Loss: -9.8498	Cost: 7.55s
Train Epoch: 1603 [81920/90000 (91%)]	Loss: -9.4160	Cost: 8.49s
Train Epoch: 1603 	Average Loss: -9.0837
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1283

Learning rate: 9.37926124387038e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1604 [0/90000 (0%)]	Loss: -3.5277	Cost: 25.76s
Train Epoch: 1604 [20480/90000 (23%)]	Loss: -9.6630	Cost: 7.11s
Train Epoch: 1604 [40960/90000 (45%)]	Loss: -9.7772	Cost: 8.95s
Train Epoch: 1604 [61440/90000 (68%)]	Loss: -9.7334	Cost: 8.76s
Train Epoch: 1604 [81920/90000 (91%)]	Loss: -9.4602	Cost: 8.74s
Train Epoch: 1604 	Average Loss: -9.2320
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9677

Learning rate: 9.378502993889515e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1605 [0/90000 (0%)]	Loss: -3.0692	Cost: 26.94s
Train Epoch: 1605 [20480/90000 (23%)]	Loss: -9.4181	Cost: 9.00s
Train Epoch: 1605 [40960/90000 (45%)]	Loss: -9.5661	Cost: 8.98s
Train Epoch: 1605 [61440/90000 (68%)]	Loss: -9.5312	Cost: 8.61s
Train Epoch: 1605 [81920/90000 (91%)]	Loss: -9.2979	Cost: 6.21s
Train Epoch: 1605 	Average Loss: -9.1082
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0055

Learning rate: 9.377744311767728e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1606 [0/90000 (0%)]	Loss: -3.5295	Cost: 22.08s
Train Epoch: 1606 [20480/90000 (23%)]	Loss: -9.4534	Cost: 8.76s
Train Epoch: 1606 [40960/90000 (45%)]	Loss: -9.6064	Cost: 15.95s
Train Epoch: 1606 [61440/90000 (68%)]	Loss: -9.7787	Cost: 13.93s
Train Epoch: 1606 [81920/90000 (91%)]	Loss: -9.6827	Cost: 12.43s
Train Epoch: 1606 	Average Loss: -9.2017
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9955

Learning rate: 9.376985197579901e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1607 [0/90000 (0%)]	Loss: -3.7839	Cost: 22.15s
Train Epoch: 1607 [20480/90000 (23%)]	Loss: -9.5883	Cost: 11.65s
Train Epoch: 1607 [40960/90000 (45%)]	Loss: -9.5523	Cost: 15.27s
Train Epoch: 1607 [61440/90000 (68%)]	Loss: -9.6384	Cost: 13.92s
Train Epoch: 1607 [81920/90000 (91%)]	Loss: -9.3644	Cost: 12.36s
Train Epoch: 1607 	Average Loss: -9.1535
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0063

Learning rate: 9.376225651400952e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1608 [0/90000 (0%)]	Loss: -3.8592	Cost: 28.63s
Train Epoch: 1608 [20480/90000 (23%)]	Loss: -9.4682	Cost: 14.27s
Train Epoch: 1608 [40960/90000 (45%)]	Loss: -9.7162	Cost: 12.41s
Train Epoch: 1608 [61440/90000 (68%)]	Loss: -9.8232	Cost: 12.19s
Train Epoch: 1608 [81920/90000 (91%)]	Loss: -9.4049	Cost: 10.15s
Train Epoch: 1608 	Average Loss: -9.2047
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1097

Learning rate: 9.375465673305849e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1609 [0/90000 (0%)]	Loss: -3.7726	Cost: 27.47s
Train Epoch: 1609 [20480/90000 (23%)]	Loss: -9.4608	Cost: 11.68s
Train Epoch: 1609 [40960/90000 (45%)]	Loss: -9.7132	Cost: 12.51s
Train Epoch: 1609 [61440/90000 (68%)]	Loss: -9.6767	Cost: 11.22s
Train Epoch: 1609 [81920/90000 (91%)]	Loss: -9.4420	Cost: 6.11s
Train Epoch: 1609 	Average Loss: -9.2077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0703

Learning rate: 9.374705263369597e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1610 [0/90000 (0%)]	Loss: -3.0319	Cost: 24.44s
Train Epoch: 1610 [20480/90000 (23%)]	Loss: -9.4509	Cost: 11.54s
Train Epoch: 1610 [40960/90000 (45%)]	Loss: -9.4331	Cost: 6.44s
Train Epoch: 1610 [61440/90000 (68%)]	Loss: -9.5976	Cost: 6.52s
Train Epoch: 1610 [81920/90000 (91%)]	Loss: -9.3352	Cost: 9.20s
Train Epoch: 1610 	Average Loss: -9.0653
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1239

Learning rate: 9.373944421667244e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1611 [0/90000 (0%)]	Loss: -3.9983	Cost: 24.47s
Train Epoch: 1611 [20480/90000 (23%)]	Loss: -9.6753	Cost: 9.74s
Train Epoch: 1611 [40960/90000 (45%)]	Loss: -9.4018	Cost: 11.08s
Train Epoch: 1611 [61440/90000 (68%)]	Loss: -9.6575	Cost: 8.99s
Train Epoch: 1611 [81920/90000 (91%)]	Loss: -9.2551	Cost: 8.78s
Train Epoch: 1611 	Average Loss: -9.0345
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9956

Learning rate: 9.373183148273885e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1612 [0/90000 (0%)]	Loss: -2.6902	Cost: 26.82s
Train Epoch: 1612 [20480/90000 (23%)]	Loss: -9.4657	Cost: 11.22s
Train Epoch: 1612 [40960/90000 (45%)]	Loss: -9.5961	Cost: 9.46s
Train Epoch: 1612 [61440/90000 (68%)]	Loss: -9.6369	Cost: 6.17s
Train Epoch: 1612 [81920/90000 (91%)]	Loss: -9.5649	Cost: 6.48s
Train Epoch: 1612 	Average Loss: -9.1170
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0613

Learning rate: 9.372421443264651e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1613 [0/90000 (0%)]	Loss: -3.1188	Cost: 20.46s
Train Epoch: 1613 [20480/90000 (23%)]	Loss: -9.3799	Cost: 6.82s
Train Epoch: 1613 [40960/90000 (45%)]	Loss: -9.3179	Cost: 8.36s
Train Epoch: 1613 [61440/90000 (68%)]	Loss: -9.4032	Cost: 12.13s
Train Epoch: 1613 [81920/90000 (91%)]	Loss: -9.4384	Cost: 12.53s
Train Epoch: 1613 	Average Loss: -9.0650
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2142

Saving model as e1613_model.pt & e1613_waveforms_supplementary.hdf5
Learning rate: 9.371659306714724e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1614 [0/90000 (0%)]	Loss: -3.8477	Cost: 20.97s
Train Epoch: 1614 [20480/90000 (23%)]	Loss: -9.5834	Cost: 12.58s
Train Epoch: 1614 [40960/90000 (45%)]	Loss: -9.7296	Cost: 12.71s
Train Epoch: 1614 [61440/90000 (68%)]	Loss: -9.7967	Cost: 12.08s
Train Epoch: 1614 [81920/90000 (91%)]	Loss: -9.3894	Cost: 12.47s
Train Epoch: 1614 	Average Loss: -9.1995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1181

Learning rate: 9.37089673869932e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1615 [0/90000 (0%)]	Loss: -4.0127	Cost: 26.85s
Train Epoch: 1615 [20480/90000 (23%)]	Loss: -9.7884	Cost: 13.14s
Train Epoch: 1615 [40960/90000 (45%)]	Loss: -9.8227	Cost: 12.70s
Train Epoch: 1615 [61440/90000 (68%)]	Loss: -9.8824	Cost: 12.38s
Train Epoch: 1615 [81920/90000 (91%)]	Loss: -9.5556	Cost: 7.84s
Train Epoch: 1615 	Average Loss: -9.2754
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1118

Learning rate: 9.370133739293702e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1616 [0/90000 (0%)]	Loss: -3.5638	Cost: 29.99s
Train Epoch: 1616 [20480/90000 (23%)]	Loss: -9.5541	Cost: 13.79s
Train Epoch: 1616 [40960/90000 (45%)]	Loss: -9.9717	Cost: 12.43s
Train Epoch: 1616 [61440/90000 (68%)]	Loss: -9.7904	Cost: 9.74s
Train Epoch: 1616 [81920/90000 (91%)]	Loss: -9.6374	Cost: 6.14s
Train Epoch: 1616 	Average Loss: -9.2354
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0936

Learning rate: 9.369370308573176e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1617 [0/90000 (0%)]	Loss: -2.4207	Cost: 23.49s
Train Epoch: 1617 [20480/90000 (23%)]	Loss: -9.6441	Cost: 12.51s
Train Epoch: 1617 [40960/90000 (45%)]	Loss: -9.8271	Cost: 11.85s
Train Epoch: 1617 [61440/90000 (68%)]	Loss: -9.5430	Cost: 7.23s
Train Epoch: 1617 [81920/90000 (91%)]	Loss: -9.4590	Cost: 6.67s
Train Epoch: 1617 	Average Loss: -9.1213
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0359

Learning rate: 9.36860644661309e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1618 [0/90000 (0%)]	Loss: -3.5177	Cost: 22.29s
Train Epoch: 1618 [20480/90000 (23%)]	Loss: -9.6051	Cost: 8.33s
Train Epoch: 1618 [40960/90000 (45%)]	Loss: -9.8174	Cost: 10.96s
Train Epoch: 1618 [61440/90000 (68%)]	Loss: -9.6845	Cost: 8.78s
Train Epoch: 1618 [81920/90000 (91%)]	Loss: -9.2994	Cost: 8.46s
Train Epoch: 1618 	Average Loss: -9.1505
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0413

Learning rate: 9.367842153488833e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1619 [0/90000 (0%)]	Loss: -2.9502	Cost: 27.74s
Train Epoch: 1619 [20480/90000 (23%)]	Loss: -9.5215	Cost: 8.43s
Train Epoch: 1619 [40960/90000 (45%)]	Loss: -9.4837	Cost: 8.87s
Train Epoch: 1619 [61440/90000 (68%)]	Loss: -9.6611	Cost: 8.84s
Train Epoch: 1619 [81920/90000 (91%)]	Loss: -9.4972	Cost: 8.62s
Train Epoch: 1619 	Average Loss: -9.1585
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2331

Saving model as e1619_model.pt & e1619_waveforms_supplementary.hdf5
Learning rate: 9.367077429275838e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1620 [0/90000 (0%)]	Loss: -4.1175	Cost: 21.88s
Train Epoch: 1620 [20480/90000 (23%)]	Loss: -9.5712	Cost: 9.09s
Train Epoch: 1620 [40960/90000 (45%)]	Loss: -9.6498	Cost: 6.63s
Train Epoch: 1620 [61440/90000 (68%)]	Loss: -9.7824	Cost: 6.89s
Train Epoch: 1620 [81920/90000 (91%)]	Loss: -9.5643	Cost: 6.87s
Train Epoch: 1620 	Average Loss: -9.2071
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2778

Saving model as e1620_model.pt & e1620_waveforms_supplementary.hdf5
Learning rate: 9.366312274049581e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1621 [0/90000 (0%)]	Loss: -3.5708	Cost: 28.55s
Train Epoch: 1621 [20480/90000 (23%)]	Loss: -9.6969	Cost: 9.80s
Train Epoch: 1621 [40960/90000 (45%)]	Loss: -9.7727	Cost: 19.55s
Train Epoch: 1621 [61440/90000 (68%)]	Loss: -9.8426	Cost: 12.85s
Train Epoch: 1621 [81920/90000 (91%)]	Loss: -9.6537	Cost: 12.26s
Train Epoch: 1621 	Average Loss: -9.2978
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0579

Learning rate: 9.365546687885579e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1622 [0/90000 (0%)]	Loss: -3.3573	Cost: 29.45s
Train Epoch: 1622 [20480/90000 (23%)]	Loss: -9.5837	Cost: 12.16s
Train Epoch: 1622 [40960/90000 (45%)]	Loss: -9.8666	Cost: 11.55s
Train Epoch: 1622 [61440/90000 (68%)]	Loss: -9.5257	Cost: 12.51s
Train Epoch: 1622 [81920/90000 (91%)]	Loss: -9.2576	Cost: 10.69s
Train Epoch: 1622 	Average Loss: -9.1897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0168

Learning rate: 9.364780670859392e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1623 [0/90000 (0%)]	Loss: -3.7866	Cost: 40.41s
Train Epoch: 1623 [20480/90000 (23%)]	Loss: -9.6844	Cost: 12.52s
Train Epoch: 1623 [40960/90000 (45%)]	Loss: -9.9713	Cost: 12.16s
Train Epoch: 1623 [61440/90000 (68%)]	Loss: -9.9952	Cost: 6.24s
Train Epoch: 1623 [81920/90000 (91%)]	Loss: -9.4654	Cost: 6.25s
Train Epoch: 1623 	Average Loss: -9.3116
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1443

Learning rate: 9.364014223046625e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1624 [0/90000 (0%)]	Loss: -3.6265	Cost: 23.73s
Train Epoch: 1624 [20480/90000 (23%)]	Loss: -9.1958	Cost: 6.58s
Train Epoch: 1624 [40960/90000 (45%)]	Loss: -9.5162	Cost: 10.27s
Train Epoch: 1624 [61440/90000 (68%)]	Loss: -9.9013	Cost: 8.60s
Train Epoch: 1624 [81920/90000 (91%)]	Loss: -9.4393	Cost: 8.59s
Train Epoch: 1624 	Average Loss: -9.1225
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0820

Learning rate: 9.363247344522919e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1625 [0/90000 (0%)]	Loss: -3.4729	Cost: 21.49s
Train Epoch: 1625 [20480/90000 (23%)]	Loss: -9.5767	Cost: 8.62s
Train Epoch: 1625 [40960/90000 (45%)]	Loss: -9.4759	Cost: 6.58s
Train Epoch: 1625 [61440/90000 (68%)]	Loss: -9.7136	Cost: 7.70s
Train Epoch: 1625 [81920/90000 (91%)]	Loss: -9.6105	Cost: 7.01s
Train Epoch: 1625 	Average Loss: -9.2146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2147

Learning rate: 9.362480035363967e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1626 [0/90000 (0%)]	Loss: -3.4006	Cost: 21.80s
Train Epoch: 1626 [20480/90000 (23%)]	Loss: -9.8880	Cost: 10.03s
Train Epoch: 1626 [40960/90000 (45%)]	Loss: -10.0117	Cost: 13.79s
Train Epoch: 1626 [61440/90000 (68%)]	Loss: -9.8993	Cost: 14.07s
Train Epoch: 1626 [81920/90000 (91%)]	Loss: -9.7119	Cost: 12.36s
Train Epoch: 1626 	Average Loss: -9.3822
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2594

Learning rate: 9.361712295645495e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1627 [0/90000 (0%)]	Loss: -4.0292	Cost: 21.02s
Train Epoch: 1627 [20480/90000 (23%)]	Loss: -9.7575	Cost: 10.15s
Train Epoch: 1627 [40960/90000 (45%)]	Loss: -10.0688	Cost: 12.95s
Train Epoch: 1627 [61440/90000 (68%)]	Loss: -10.0994	Cost: 14.68s
Train Epoch: 1627 [81920/90000 (91%)]	Loss: -9.8681	Cost: 12.36s
Train Epoch: 1627 	Average Loss: -9.4818
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3149

Saving model as e1627_model.pt & e1627_waveforms_supplementary.hdf5
Learning rate: 9.360944125443278e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1628 [0/90000 (0%)]	Loss: -3.3106	Cost: 33.24s
Train Epoch: 1628 [20480/90000 (23%)]	Loss: -9.9393	Cost: 12.76s
Train Epoch: 1628 [40960/90000 (45%)]	Loss: -9.8134	Cost: 12.47s
Train Epoch: 1628 [61440/90000 (68%)]	Loss: -9.9162	Cost: 12.43s
Train Epoch: 1628 [81920/90000 (91%)]	Loss: -9.6494	Cost: 9.05s
Train Epoch: 1628 	Average Loss: -9.3961
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2537

Learning rate: 9.360175524833132e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1629 [0/90000 (0%)]	Loss: -4.2224	Cost: 25.86s
Train Epoch: 1629 [20480/90000 (23%)]	Loss: -9.6406	Cost: 11.53s
Train Epoch: 1629 [40960/90000 (45%)]	Loss: -9.7436	Cost: 12.11s
Train Epoch: 1629 [61440/90000 (68%)]	Loss: -9.9863	Cost: 6.43s
Train Epoch: 1629 [81920/90000 (91%)]	Loss: -9.5401	Cost: 5.98s
Train Epoch: 1629 	Average Loss: -9.3830
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2017

Learning rate: 9.359406493890915e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1630 [0/90000 (0%)]	Loss: -3.8723	Cost: 23.00s
Train Epoch: 1630 [20480/90000 (23%)]	Loss: -9.6262	Cost: 11.51s
Train Epoch: 1630 [40960/90000 (45%)]	Loss: -9.6642	Cost: 8.02s
Train Epoch: 1630 [61440/90000 (68%)]	Loss: -9.7091	Cost: 6.36s
Train Epoch: 1630 [81920/90000 (91%)]	Loss: -9.3321	Cost: 8.07s
Train Epoch: 1630 	Average Loss: -9.3096
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9772

Learning rate: 9.358637032692525e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1631 [0/90000 (0%)]	Loss: -3.7270	Cost: 23.93s
Train Epoch: 1631 [20480/90000 (23%)]	Loss: -9.1938	Cost: 6.50s
Train Epoch: 1631 [40960/90000 (45%)]	Loss: -9.4232	Cost: 12.68s
Train Epoch: 1631 [61440/90000 (68%)]	Loss: -9.8470	Cost: 9.12s
Train Epoch: 1631 [81920/90000 (91%)]	Loss: -9.4982	Cost: 8.79s
Train Epoch: 1631 	Average Loss: -9.1388
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1480

Learning rate: 9.357867141313905e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1632 [0/90000 (0%)]	Loss: -2.8047	Cost: 22.73s
Train Epoch: 1632 [20480/90000 (23%)]	Loss: -9.7795	Cost: 11.85s
Train Epoch: 1632 [40960/90000 (45%)]	Loss: -9.6362	Cost: 10.84s
Train Epoch: 1632 [61440/90000 (68%)]	Loss: -9.6845	Cost: 8.90s
Train Epoch: 1632 [81920/90000 (91%)]	Loss: -9.6035	Cost: 6.55s
Train Epoch: 1632 	Average Loss: -9.2793
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2656

Learning rate: 9.357096819831042e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1633 [0/90000 (0%)]	Loss: -3.6234	Cost: 23.26s
Train Epoch: 1633 [20480/90000 (23%)]	Loss: -9.8632	Cost: 6.64s
Train Epoch: 1633 [40960/90000 (45%)]	Loss: -9.8952	Cost: 8.49s
Train Epoch: 1633 [61440/90000 (68%)]	Loss: -10.1458	Cost: 10.64s
Train Epoch: 1633 [81920/90000 (91%)]	Loss: -9.6736	Cost: 13.58s
Train Epoch: 1633 	Average Loss: -9.4137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3049

Learning rate: 9.356326068319965e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1634 [0/90000 (0%)]	Loss: -3.1357	Cost: 23.97s
Train Epoch: 1634 [20480/90000 (23%)]	Loss: -9.6948	Cost: 10.21s
Train Epoch: 1634 [40960/90000 (45%)]	Loss: -10.1348	Cost: 12.87s
Train Epoch: 1634 [61440/90000 (68%)]	Loss: -10.1419	Cost: 12.38s
Train Epoch: 1634 [81920/90000 (91%)]	Loss: -9.4642	Cost: 12.15s
Train Epoch: 1634 	Average Loss: -9.3895
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2365

Learning rate: 9.355554886856741e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1635 [0/90000 (0%)]	Loss: -3.9590	Cost: 24.55s
Train Epoch: 1635 [20480/90000 (23%)]	Loss: -9.6217	Cost: 12.67s
Train Epoch: 1635 [40960/90000 (45%)]	Loss: -9.8506	Cost: 13.06s
Train Epoch: 1635 [61440/90000 (68%)]	Loss: -9.6684	Cost: 12.36s
Train Epoch: 1635 [81920/90000 (91%)]	Loss: -9.3534	Cost: 12.36s
Train Epoch: 1635 	Average Loss: -9.2166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0854

Learning rate: 9.354783275517484e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1636 [0/90000 (0%)]	Loss: -3.3412	Cost: 30.99s
Train Epoch: 1636 [20480/90000 (23%)]	Loss: -9.6094	Cost: 14.74s
Train Epoch: 1636 [40960/90000 (45%)]	Loss: -9.2132	Cost: 13.58s
Train Epoch: 1636 [61440/90000 (68%)]	Loss: -9.4967	Cost: 12.02s
Train Epoch: 1636 [81920/90000 (91%)]	Loss: -9.2455	Cost: 8.80s
Train Epoch: 1636 	Average Loss: -8.9241
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0046

Learning rate: 9.354011234378349e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1637 [0/90000 (0%)]	Loss: -4.0387	Cost: 33.95s
Train Epoch: 1637 [20480/90000 (23%)]	Loss: -9.5845	Cost: 14.00s
Train Epoch: 1637 [40960/90000 (45%)]	Loss: -9.7897	Cost: 12.72s
Train Epoch: 1637 [61440/90000 (68%)]	Loss: -9.9198	Cost: 8.04s
Train Epoch: 1637 [81920/90000 (91%)]	Loss: -9.7781	Cost: 6.41s
Train Epoch: 1637 	Average Loss: -9.2528
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1665

Learning rate: 9.353238763515532e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1638 [0/90000 (0%)]	Loss: -3.0501	Cost: 35.45s
Train Epoch: 1638 [20480/90000 (23%)]	Loss: -9.7903	Cost: 10.40s
Train Epoch: 1638 [40960/90000 (45%)]	Loss: -9.7242	Cost: 6.45s
Train Epoch: 1638 [61440/90000 (68%)]	Loss: -9.8020	Cost: 6.27s
Train Epoch: 1638 [81920/90000 (91%)]	Loss: -10.0110	Cost: 9.08s
Train Epoch: 1638 	Average Loss: -9.3420
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2588

Learning rate: 9.352465863005275e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1639 [0/90000 (0%)]	Loss: -3.4028	Cost: 22.99s
Train Epoch: 1639 [20480/90000 (23%)]	Loss: -9.8763	Cost: 6.65s
Train Epoch: 1639 [40960/90000 (45%)]	Loss: -9.8657	Cost: 9.47s
Train Epoch: 1639 [61440/90000 (68%)]	Loss: -9.9563	Cost: 9.03s
Train Epoch: 1639 [81920/90000 (91%)]	Loss: -9.7634	Cost: 9.00s
Train Epoch: 1639 	Average Loss: -9.4153
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2584

Learning rate: 9.35169253292386e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1640 [0/90000 (0%)]	Loss: -4.0135	Cost: 24.08s
Train Epoch: 1640 [20480/90000 (23%)]	Loss: -9.7116	Cost: 8.81s
Train Epoch: 1640 [40960/90000 (45%)]	Loss: -10.0931	Cost: 8.83s
Train Epoch: 1640 [61440/90000 (68%)]	Loss: -10.0017	Cost: 9.15s
Train Epoch: 1640 [81920/90000 (91%)]	Loss: -9.6880	Cost: 9.19s
Train Epoch: 1640 	Average Loss: -9.4794
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3264

Saving model as e1640_model.pt & e1640_waveforms_supplementary.hdf5
Learning rate: 9.350918773347609e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1641 [0/90000 (0%)]	Loss: -3.8786	Cost: 28.16s
Train Epoch: 1641 [20480/90000 (23%)]	Loss: -9.7661	Cost: 9.17s
Train Epoch: 1641 [40960/90000 (45%)]	Loss: -9.7604	Cost: 9.41s
Train Epoch: 1641 [61440/90000 (68%)]	Loss: -9.8613	Cost: 11.54s
Train Epoch: 1641 [81920/90000 (91%)]	Loss: -9.7599	Cost: 12.43s
Train Epoch: 1641 	Average Loss: -9.3552
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1459

Learning rate: 9.350144584352891e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1642 [0/90000 (0%)]	Loss: -3.7517	Cost: 36.67s
Train Epoch: 1642 [20480/90000 (23%)]	Loss: -9.7499	Cost: 11.74s
Train Epoch: 1642 [40960/90000 (45%)]	Loss: -9.9608	Cost: 13.26s
Train Epoch: 1642 [61440/90000 (68%)]	Loss: -9.9961	Cost: 12.36s
Train Epoch: 1642 [81920/90000 (91%)]	Loss: -9.8070	Cost: 12.11s
Train Epoch: 1642 	Average Loss: -9.4243
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2300

Learning rate: 9.349369966016114e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1643 [0/90000 (0%)]	Loss: -3.0809	Cost: 29.75s
Train Epoch: 1643 [20480/90000 (23%)]	Loss: -9.9605	Cost: 10.18s
Train Epoch: 1643 [40960/90000 (45%)]	Loss: -9.9443	Cost: 13.42s
Train Epoch: 1643 [61440/90000 (68%)]	Loss: -9.9892	Cost: 12.12s
Train Epoch: 1643 [81920/90000 (91%)]	Loss: -9.6899	Cost: 11.46s
Train Epoch: 1643 	Average Loss: -9.4532
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3338

Saving model as e1643_model.pt & e1643_waveforms_supplementary.hdf5
Learning rate: 9.348594918413733e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1644 [0/90000 (0%)]	Loss: -3.9483	Cost: 22.70s
Train Epoch: 1644 [20480/90000 (23%)]	Loss: -9.8474	Cost: 13.57s
Train Epoch: 1644 [40960/90000 (45%)]	Loss: -9.6782	Cost: 14.09s
Train Epoch: 1644 [61440/90000 (68%)]	Loss: -9.9738	Cost: 9.67s
Train Epoch: 1644 [81920/90000 (91%)]	Loss: -9.6367	Cost: 6.67s
Train Epoch: 1644 	Average Loss: -9.3854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2562

Learning rate: 9.34781944162224e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1645 [0/90000 (0%)]	Loss: -4.1217	Cost: 24.26s
Train Epoch: 1645 [20480/90000 (23%)]	Loss: -9.7309	Cost: 11.92s
Train Epoch: 1645 [40960/90000 (45%)]	Loss: -9.9249	Cost: 6.47s
Train Epoch: 1645 [61440/90000 (68%)]	Loss: -10.2575	Cost: 6.38s
Train Epoch: 1645 [81920/90000 (91%)]	Loss: -9.8954	Cost: 8.31s
Train Epoch: 1645 	Average Loss: -9.5102
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2963

Learning rate: 9.34704353571817e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1646 [0/90000 (0%)]	Loss: -2.9475	Cost: 31.67s
Train Epoch: 1646 [20480/90000 (23%)]	Loss: -9.9304	Cost: 8.93s
Train Epoch: 1646 [40960/90000 (45%)]	Loss: -9.9413	Cost: 8.09s
Train Epoch: 1646 [61440/90000 (68%)]	Loss: -10.0657	Cost: 8.67s
Train Epoch: 1646 [81920/90000 (91%)]	Loss: -9.8829	Cost: 9.02s
Train Epoch: 1646 	Average Loss: -9.4821
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4254

Saving model as e1646_model.pt & e1646_waveforms_supplementary.hdf5
Learning rate: 9.346267200778104e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1647 [0/90000 (0%)]	Loss: -3.3592	Cost: 32.41s
Train Epoch: 1647 [20480/90000 (23%)]	Loss: -9.8901	Cost: 8.82s
Train Epoch: 1647 [40960/90000 (45%)]	Loss: -9.9943	Cost: 8.81s
Train Epoch: 1647 [61440/90000 (68%)]	Loss: -10.1877	Cost: 5.90s
Train Epoch: 1647 [81920/90000 (91%)]	Loss: -10.0337	Cost: 6.38s
Train Epoch: 1647 	Average Loss: -9.6132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3863

Learning rate: 9.345490436878664e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1648 [0/90000 (0%)]	Loss: -3.9201	Cost: 19.15s
Train Epoch: 1648 [20480/90000 (23%)]	Loss: -9.8040	Cost: 8.97s
Train Epoch: 1648 [40960/90000 (45%)]	Loss: -10.0125	Cost: 11.77s
Train Epoch: 1648 [61440/90000 (68%)]	Loss: -9.8993	Cost: 11.95s
Train Epoch: 1648 [81920/90000 (91%)]	Loss: -9.9073	Cost: 13.72s
Train Epoch: 1648 	Average Loss: -9.5004
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3800

Learning rate: 9.344713244096511e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1649 [0/90000 (0%)]	Loss: -3.8176	Cost: 23.84s
Train Epoch: 1649 [20480/90000 (23%)]	Loss: -9.8668	Cost: 12.36s
Train Epoch: 1649 [40960/90000 (45%)]	Loss: -10.0805	Cost: 12.90s
Train Epoch: 1649 [61440/90000 (68%)]	Loss: -10.0979	Cost: 12.75s
Train Epoch: 1649 [81920/90000 (91%)]	Loss: -9.7956	Cost: 12.29s
Train Epoch: 1649 	Average Loss: -9.4880
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4149

Learning rate: 9.343935622508351e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1650 [0/90000 (0%)]	Loss: -3.7240	Cost: 26.81s
Train Epoch: 1650 [20480/90000 (23%)]	Loss: -9.7907	Cost: 13.75s
Train Epoch: 1650 [40960/90000 (45%)]	Loss: -9.9750	Cost: 12.07s
Train Epoch: 1650 [61440/90000 (68%)]	Loss: -10.1604	Cost: 12.14s
Train Epoch: 1650 [81920/90000 (91%)]	Loss: -9.8044	Cost: 6.43s
Train Epoch: 1650 	Average Loss: -9.4903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2821

Learning rate: 9.343157572190936e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1651 [0/90000 (0%)]	Loss: -3.9283	Cost: 39.73s
Train Epoch: 1651 [20480/90000 (23%)]	Loss: -9.6393	Cost: 9.01s
Train Epoch: 1651 [40960/90000 (45%)]	Loss: -9.7826	Cost: 6.65s
Train Epoch: 1651 [61440/90000 (68%)]	Loss: -9.8079	Cost: 7.15s
Train Epoch: 1651 [81920/90000 (91%)]	Loss: -9.7625	Cost: 8.52s
Train Epoch: 1651 	Average Loss: -9.3431
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2892

Learning rate: 9.34237909322105e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1652 [0/90000 (0%)]	Loss: -4.2240	Cost: 26.56s
Train Epoch: 1652 [20480/90000 (23%)]	Loss: -9.8667	Cost: 10.12s
Train Epoch: 1652 [40960/90000 (45%)]	Loss: -10.0096	Cost: 6.81s
Train Epoch: 1652 [61440/90000 (68%)]	Loss: -10.0802	Cost: 7.05s
Train Epoch: 1652 [81920/90000 (91%)]	Loss: -9.7622	Cost: 8.70s
Train Epoch: 1652 	Average Loss: -9.4534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3689

Learning rate: 9.341600185675532e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1653 [0/90000 (0%)]	Loss: -3.5377	Cost: 27.67s
Train Epoch: 1653 [20480/90000 (23%)]	Loss: -10.0722	Cost: 6.50s
Train Epoch: 1653 [40960/90000 (45%)]	Loss: -9.8660	Cost: 9.06s
Train Epoch: 1653 [61440/90000 (68%)]	Loss: -10.0756	Cost: 8.83s
Train Epoch: 1653 [81920/90000 (91%)]	Loss: -9.8555	Cost: 8.74s
Train Epoch: 1653 	Average Loss: -9.4347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3443

Learning rate: 9.340820849631254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1654 [0/90000 (0%)]	Loss: -3.3621	Cost: 21.54s
Train Epoch: 1654 [20480/90000 (23%)]	Loss: -9.7622	Cost: 8.83s
Train Epoch: 1654 [40960/90000 (45%)]	Loss: -9.8249	Cost: 9.15s
Train Epoch: 1654 [61440/90000 (68%)]	Loss: -8.2330	Cost: 8.72s
Train Epoch: 1654 [81920/90000 (91%)]	Loss: -8.0141	Cost: 9.13s
Train Epoch: 1654 	Average Loss: -8.8595
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2116

Learning rate: 9.340041085165135e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1655 [0/90000 (0%)]	Loss: -1.9723	Cost: 20.41s
Train Epoch: 1655 [20480/90000 (23%)]	Loss: -8.9070	Cost: 9.54s
Train Epoch: 1655 [40960/90000 (45%)]	Loss: -9.3145	Cost: 8.49s
Train Epoch: 1655 [61440/90000 (68%)]	Loss: -9.5255	Cost: 6.97s
Train Epoch: 1655 [81920/90000 (91%)]	Loss: -9.4000	Cost: 6.91s
Train Epoch: 1655 	Average Loss: -8.7247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1290

Learning rate: 9.339260892354131e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1656 [0/90000 (0%)]	Loss: -4.1003	Cost: 22.18s
Train Epoch: 1656 [20480/90000 (23%)]	Loss: -9.9239	Cost: 8.64s
Train Epoch: 1656 [40960/90000 (45%)]	Loss: -9.9790	Cost: 11.14s
Train Epoch: 1656 [61440/90000 (68%)]	Loss: -10.0427	Cost: 9.14s
Train Epoch: 1656 [81920/90000 (91%)]	Loss: -9.8990	Cost: 15.05s
Train Epoch: 1656 	Average Loss: -9.4559
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5484

Saving model as e1656_model.pt & e1656_waveforms_supplementary.hdf5
Learning rate: 9.338480271275247e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1657 [0/90000 (0%)]	Loss: -3.6069	Cost: 28.94s
Train Epoch: 1657 [20480/90000 (23%)]	Loss: -10.0770	Cost: 13.68s
Train Epoch: 1657 [40960/90000 (45%)]	Loss: -10.2615	Cost: 12.65s
Train Epoch: 1657 [61440/90000 (68%)]	Loss: -10.0309	Cost: 11.93s
Train Epoch: 1657 [81920/90000 (91%)]	Loss: -9.7840	Cost: 12.19s
Train Epoch: 1657 	Average Loss: -9.4704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2895

Learning rate: 9.337699222005527e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1658 [0/90000 (0%)]	Loss: -4.2094	Cost: 29.66s
Train Epoch: 1658 [20480/90000 (23%)]	Loss: -9.8611	Cost: 12.63s
Train Epoch: 1658 [40960/90000 (45%)]	Loss: -9.9834	Cost: 11.97s
Train Epoch: 1658 [61440/90000 (68%)]	Loss: -9.8663	Cost: 12.42s
Train Epoch: 1658 [81920/90000 (91%)]	Loss: -9.5300	Cost: 9.54s
Train Epoch: 1658 	Average Loss: -9.3808
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1801

Learning rate: 9.336917744622058e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1659 [0/90000 (0%)]	Loss: -3.0987	Cost: 25.34s
Train Epoch: 1659 [20480/90000 (23%)]	Loss: -9.8797	Cost: 12.16s
Train Epoch: 1659 [40960/90000 (45%)]	Loss: -9.8282	Cost: 12.03s
Train Epoch: 1659 [61440/90000 (68%)]	Loss: -9.6010	Cost: 6.38s
Train Epoch: 1659 [81920/90000 (91%)]	Loss: -9.5566	Cost: 8.35s
Train Epoch: 1659 	Average Loss: -9.3205
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1195

Learning rate: 9.336135839201968e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1660 [0/90000 (0%)]	Loss: -3.2592	Cost: 22.78s
Train Epoch: 1660 [20480/90000 (23%)]	Loss: -10.0007	Cost: 10.12s
Train Epoch: 1660 [40960/90000 (45%)]	Loss: -10.0386	Cost: 6.64s
Train Epoch: 1660 [61440/90000 (68%)]	Loss: -10.0796	Cost: 7.17s
Train Epoch: 1660 [81920/90000 (91%)]	Loss: -9.7315	Cost: 8.73s
Train Epoch: 1660 	Average Loss: -9.4592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1444

Learning rate: 9.335353505822426e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1661 [0/90000 (0%)]	Loss: -3.4012	Cost: 21.19s
Train Epoch: 1661 [20480/90000 (23%)]	Loss: -10.0048	Cost: 6.64s
Train Epoch: 1661 [40960/90000 (45%)]	Loss: -10.0860	Cost: 9.23s
Train Epoch: 1661 [61440/90000 (68%)]	Loss: -10.1468	Cost: 9.09s
Train Epoch: 1661 [81920/90000 (91%)]	Loss: -9.8565	Cost: 8.87s
Train Epoch: 1661 	Average Loss: -9.5884
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4228

Learning rate: 9.334570744560649e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1662 [0/90000 (0%)]	Loss: -4.0204	Cost: 24.22s
Train Epoch: 1662 [20480/90000 (23%)]	Loss: -10.1089	Cost: 10.49s
Train Epoch: 1662 [40960/90000 (45%)]	Loss: -9.8883	Cost: 9.25s
Train Epoch: 1662 [61440/90000 (68%)]	Loss: -10.2629	Cost: 8.76s
Train Epoch: 1662 [81920/90000 (91%)]	Loss: -9.9309	Cost: 8.71s
Train Epoch: 1662 	Average Loss: -9.6684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4169

Learning rate: 9.33378755549389e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1663 [0/90000 (0%)]	Loss: -3.6200	Cost: 29.53s
Train Epoch: 1663 [20480/90000 (23%)]	Loss: -10.0817	Cost: 8.79s
Train Epoch: 1663 [40960/90000 (45%)]	Loss: -9.8584	Cost: 7.85s
Train Epoch: 1663 [61440/90000 (68%)]	Loss: -10.1113	Cost: 6.09s
Train Epoch: 1663 [81920/90000 (91%)]	Loss: -9.6684	Cost: 6.55s
Train Epoch: 1663 	Average Loss: -9.4854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2335

Learning rate: 9.333003938699447e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1664 [0/90000 (0%)]	Loss: -3.9246	Cost: 18.39s
Train Epoch: 1664 [20480/90000 (23%)]	Loss: -9.9811	Cost: 8.42s
Train Epoch: 1664 [40960/90000 (45%)]	Loss: -10.0621	Cost: 10.21s
Train Epoch: 1664 [61440/90000 (68%)]	Loss: -10.0869	Cost: 11.05s
Train Epoch: 1664 [81920/90000 (91%)]	Loss: -9.8824	Cost: 12.99s
Train Epoch: 1664 	Average Loss: -9.5474
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4207

Learning rate: 9.332219894254661e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1665 [0/90000 (0%)]	Loss: -3.6158	Cost: 24.88s
Train Epoch: 1665 [20480/90000 (23%)]	Loss: -10.1411	Cost: 11.86s
Train Epoch: 1665 [40960/90000 (45%)]	Loss: -10.1605	Cost: 12.48s
Train Epoch: 1665 [61440/90000 (68%)]	Loss: -10.1550	Cost: 12.57s
Train Epoch: 1665 [81920/90000 (91%)]	Loss: -9.8184	Cost: 12.46s
Train Epoch: 1665 	Average Loss: -9.5886
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2773

Learning rate: 9.331435422236914e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1666 [0/90000 (0%)]	Loss: -3.3672	Cost: 28.21s
Train Epoch: 1666 [20480/90000 (23%)]	Loss: -9.8325	Cost: 12.58s
Train Epoch: 1666 [40960/90000 (45%)]	Loss: -10.0456	Cost: 12.70s
Train Epoch: 1666 [61440/90000 (68%)]	Loss: -9.9049	Cost: 12.22s
Train Epoch: 1666 [81920/90000 (91%)]	Loss: -9.7456	Cost: 7.51s
Train Epoch: 1666 	Average Loss: -9.4878
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4085

Learning rate: 9.330650522723627e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1667 [0/90000 (0%)]	Loss: -4.0810	Cost: 37.03s
Train Epoch: 1667 [20480/90000 (23%)]	Loss: -10.0219	Cost: 10.12s
Train Epoch: 1667 [40960/90000 (45%)]	Loss: -10.1488	Cost: 10.86s
Train Epoch: 1667 [61440/90000 (68%)]	Loss: -10.1788	Cost: 6.31s
Train Epoch: 1667 [81920/90000 (91%)]	Loss: -9.5815	Cost: 6.65s
Train Epoch: 1667 	Average Loss: -9.5404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2530

Learning rate: 9.329865195792271e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1668 [0/90000 (0%)]	Loss: -3.7829	Cost: 30.94s
Train Epoch: 1668 [20480/90000 (23%)]	Loss: -10.1025	Cost: 9.63s
Train Epoch: 1668 [40960/90000 (45%)]	Loss: -9.9807	Cost: 11.60s
Train Epoch: 1668 [61440/90000 (68%)]	Loss: -10.3072	Cost: 6.19s
Train Epoch: 1668 [81920/90000 (91%)]	Loss: -9.7655	Cost: 6.24s
Train Epoch: 1668 	Average Loss: -9.5757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5303

Learning rate: 9.329079441520351e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1669 [0/90000 (0%)]	Loss: -3.7041	Cost: 29.92s
Train Epoch: 1669 [20480/90000 (23%)]	Loss: -10.1339	Cost: 11.22s
Train Epoch: 1669 [40960/90000 (45%)]	Loss: -10.3236	Cost: 10.18s
Train Epoch: 1669 [61440/90000 (68%)]	Loss: -10.1323	Cost: 6.22s
Train Epoch: 1669 [81920/90000 (91%)]	Loss: -9.9366	Cost: 7.05s
Train Epoch: 1669 	Average Loss: -9.6931
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3283

Learning rate: 9.328293259985419e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1670 [0/90000 (0%)]	Loss: -3.7814	Cost: 23.75s
Train Epoch: 1670 [20480/90000 (23%)]	Loss: -10.1835	Cost: 6.67s
Train Epoch: 1670 [40960/90000 (45%)]	Loss: -10.1296	Cost: 8.57s
Train Epoch: 1670 [61440/90000 (68%)]	Loss: -10.1301	Cost: 8.88s
Train Epoch: 1670 [81920/90000 (91%)]	Loss: -9.8913	Cost: 8.91s
Train Epoch: 1670 	Average Loss: -9.6409
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4194

Learning rate: 9.32750665126507e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1671 [0/90000 (0%)]	Loss: -3.1823	Cost: 22.64s
Train Epoch: 1671 [20480/90000 (23%)]	Loss: -10.1764	Cost: 8.97s
Train Epoch: 1671 [40960/90000 (45%)]	Loss: -10.1535	Cost: 8.92s
Train Epoch: 1671 [61440/90000 (68%)]	Loss: -10.0394	Cost: 9.00s
Train Epoch: 1671 [81920/90000 (91%)]	Loss: -10.1095	Cost: 9.00s
Train Epoch: 1671 	Average Loss: -9.6875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5890

Saving model as e1671_model.pt & e1671_waveforms_supplementary.hdf5
Learning rate: 9.326719615436937e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1672 [0/90000 (0%)]	Loss: -3.8883	Cost: 36.08s
Train Epoch: 1672 [20480/90000 (23%)]	Loss: -10.4296	Cost: 7.95s
Train Epoch: 1672 [40960/90000 (45%)]	Loss: -10.1019	Cost: 12.50s
Train Epoch: 1672 [61440/90000 (68%)]	Loss: -10.2992	Cost: 12.49s
Train Epoch: 1672 [81920/90000 (91%)]	Loss: -10.0959	Cost: 12.23s
Train Epoch: 1672 	Average Loss: -9.8199
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5537

Learning rate: 9.325932152578697e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1673 [0/90000 (0%)]	Loss: -3.6924	Cost: 37.48s
Train Epoch: 1673 [20480/90000 (23%)]	Loss: -10.1097	Cost: 12.11s
Train Epoch: 1673 [40960/90000 (45%)]	Loss: -10.1999	Cost: 12.19s
Train Epoch: 1673 [61440/90000 (68%)]	Loss: -10.0721	Cost: 12.40s
Train Epoch: 1673 [81920/90000 (91%)]	Loss: -9.4875	Cost: 8.50s
Train Epoch: 1673 	Average Loss: -9.6335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4503

Learning rate: 9.325144262768072e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1674 [0/90000 (0%)]	Loss: -3.8798	Cost: 31.07s
Train Epoch: 1674 [20480/90000 (23%)]	Loss: -9.9860	Cost: 13.10s
Train Epoch: 1674 [40960/90000 (45%)]	Loss: -10.0602	Cost: 13.18s
Train Epoch: 1674 [61440/90000 (68%)]	Loss: -10.1603	Cost: 8.55s
Train Epoch: 1674 [81920/90000 (91%)]	Loss: -9.9247	Cost: 6.20s
Train Epoch: 1674 	Average Loss: -9.6411
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4571

Learning rate: 9.324355946082821e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1675 [0/90000 (0%)]	Loss: -3.5549	Cost: 23.31s
Train Epoch: 1675 [20480/90000 (23%)]	Loss: -9.8153	Cost: 11.50s
Train Epoch: 1675 [40960/90000 (45%)]	Loss: -9.2181	Cost: 13.94s
Train Epoch: 1675 [61440/90000 (68%)]	Loss: -9.5163	Cost: 7.85s
Train Epoch: 1675 [81920/90000 (91%)]	Loss: -9.6133	Cost: 7.70s
Train Epoch: 1675 	Average Loss: -9.1773
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2644

Learning rate: 9.32356720260075e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1676 [0/90000 (0%)]	Loss: -3.3699	Cost: 24.84s
Train Epoch: 1676 [20480/90000 (23%)]	Loss: -9.8781	Cost: 11.16s
Train Epoch: 1676 [40960/90000 (45%)]	Loss: -10.1153	Cost: 6.86s
Train Epoch: 1676 [61440/90000 (68%)]	Loss: -9.9260	Cost: 6.66s
Train Epoch: 1676 [81920/90000 (91%)]	Loss: -9.7473	Cost: 8.59s
Train Epoch: 1676 	Average Loss: -9.3800
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2082

Learning rate: 9.322778032399702e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1677 [0/90000 (0%)]	Loss: -3.5455	Cost: 26.13s
Train Epoch: 1677 [20480/90000 (23%)]	Loss: -9.8833	Cost: 6.54s
Train Epoch: 1677 [40960/90000 (45%)]	Loss: -10.1384	Cost: 9.18s
Train Epoch: 1677 [61440/90000 (68%)]	Loss: -10.2635	Cost: 8.59s
Train Epoch: 1677 [81920/90000 (91%)]	Loss: -9.9138	Cost: 8.75s
Train Epoch: 1677 	Average Loss: -9.5724
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3954

Learning rate: 9.321988435557567e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1678 [0/90000 (0%)]	Loss: -3.9459	Cost: 24.79s
Train Epoch: 1678 [20480/90000 (23%)]	Loss: -9.7556	Cost: 9.10s
Train Epoch: 1678 [40960/90000 (45%)]	Loss: -10.0401	Cost: 9.26s
Train Epoch: 1678 [61440/90000 (68%)]	Loss: -10.0263	Cost: 8.88s
Train Epoch: 1678 [81920/90000 (91%)]	Loss: -9.8390	Cost: 6.93s
Train Epoch: 1678 	Average Loss: -9.5343
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4858

Learning rate: 9.321198412152276e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1679 [0/90000 (0%)]	Loss: -3.2082	Cost: 21.73s
Train Epoch: 1679 [20480/90000 (23%)]	Loss: -10.2228	Cost: 7.88s
Train Epoch: 1679 [40960/90000 (45%)]	Loss: -10.1365	Cost: 12.40s
Train Epoch: 1679 [61440/90000 (68%)]	Loss: -8.8681	Cost: 11.73s
Train Epoch: 1679 [81920/90000 (91%)]	Loss: -8.7131	Cost: 14.05s
Train Epoch: 1679 	Average Loss: -9.0307
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7811

Learning rate: 9.3204079622618e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1680 [0/90000 (0%)]	Loss: -3.1926	Cost: 21.68s
Train Epoch: 1680 [20480/90000 (23%)]	Loss: -9.4287	Cost: 7.16s
Train Epoch: 1680 [40960/90000 (45%)]	Loss: -9.5211	Cost: 16.76s
Train Epoch: 1680 [61440/90000 (68%)]	Loss: -9.9010	Cost: 13.91s
Train Epoch: 1680 [81920/90000 (91%)]	Loss: -9.3557	Cost: 12.62s
Train Epoch: 1680 	Average Loss: -9.0652
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6878

Learning rate: 9.31961708596415e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1681 [0/90000 (0%)]	Loss: -3.4244	Cost: 31.49s
Train Epoch: 1681 [20480/90000 (23%)]	Loss: -9.3255	Cost: 14.61s
Train Epoch: 1681 [40960/90000 (45%)]	Loss: -9.4297	Cost: 12.71s
Train Epoch: 1681 [61440/90000 (68%)]	Loss: -9.5500	Cost: 12.23s
Train Epoch: 1681 [81920/90000 (91%)]	Loss: -9.5555	Cost: 10.27s
Train Epoch: 1681 	Average Loss: -9.0514
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4024

Learning rate: 9.318825783337389e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1682 [0/90000 (0%)]	Loss: -3.1892	Cost: 28.33s
Train Epoch: 1682 [20480/90000 (23%)]	Loss: -9.7549	Cost: 12.89s
Train Epoch: 1682 [40960/90000 (45%)]	Loss: -9.9517	Cost: 12.37s
Train Epoch: 1682 [61440/90000 (68%)]	Loss: -10.0612	Cost: 7.75s
Train Epoch: 1682 [81920/90000 (91%)]	Loss: -9.7032	Cost: 6.18s
Train Epoch: 1682 	Average Loss: -9.4913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4504

Learning rate: 9.318034054459612e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1683 [0/90000 (0%)]	Loss: -3.8994	Cost: 27.69s
Train Epoch: 1683 [20480/90000 (23%)]	Loss: -10.0833	Cost: 6.49s
Train Epoch: 1683 [40960/90000 (45%)]	Loss: -10.0264	Cost: 9.66s
Train Epoch: 1683 [61440/90000 (68%)]	Loss: -10.0859	Cost: 8.60s
Train Epoch: 1683 [81920/90000 (91%)]	Loss: -9.9649	Cost: 8.52s
Train Epoch: 1683 	Average Loss: -9.5879
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3824

Learning rate: 9.317241899408957e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1684 [0/90000 (0%)]	Loss: -3.8676	Cost: 21.89s
Train Epoch: 1684 [20480/90000 (23%)]	Loss: -10.1663	Cost: 9.11s
Train Epoch: 1684 [40960/90000 (45%)]	Loss: -10.2225	Cost: 9.62s
Train Epoch: 1684 [61440/90000 (68%)]	Loss: -10.1552	Cost: 8.99s
Train Epoch: 1684 [81920/90000 (91%)]	Loss: -9.9253	Cost: 7.41s
Train Epoch: 1684 	Average Loss: -9.6671
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4920

Learning rate: 9.31644931826361e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1685 [0/90000 (0%)]	Loss: -3.4910	Cost: 29.81s
Train Epoch: 1685 [20480/90000 (23%)]	Loss: -9.9397	Cost: 8.77s
Train Epoch: 1685 [40960/90000 (45%)]	Loss: -10.1658	Cost: 6.60s
Train Epoch: 1685 [61440/90000 (68%)]	Loss: -9.9369	Cost: 6.63s
Train Epoch: 1685 [81920/90000 (91%)]	Loss: -9.6722	Cost: 7.66s
Train Epoch: 1685 	Average Loss: -9.5080
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3018

Learning rate: 9.315656311101795e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1686 [0/90000 (0%)]	Loss: -4.1619	Cost: 30.83s
Train Epoch: 1686 [20480/90000 (23%)]	Loss: -10.0984	Cost: 8.07s
Train Epoch: 1686 [40960/90000 (45%)]	Loss: -9.8525	Cost: 14.15s
Train Epoch: 1686 [61440/90000 (68%)]	Loss: -10.3736	Cost: 12.51s
Train Epoch: 1686 [81920/90000 (91%)]	Loss: -10.0342	Cost: 12.44s
Train Epoch: 1686 	Average Loss: -9.5971
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4804

Learning rate: 9.314862878001778e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1687 [0/90000 (0%)]	Loss: -4.3166	Cost: 27.48s
Train Epoch: 1687 [20480/90000 (23%)]	Loss: -10.3912	Cost: 14.12s
Train Epoch: 1687 [40960/90000 (45%)]	Loss: -10.2832	Cost: 13.43s
Train Epoch: 1687 [61440/90000 (68%)]	Loss: -10.0945	Cost: 12.62s
Train Epoch: 1687 [81920/90000 (91%)]	Loss: -9.9518	Cost: 12.41s
Train Epoch: 1687 	Average Loss: -9.7934
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4457

Learning rate: 9.314069019041867e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1688 [0/90000 (0%)]	Loss: -4.0141	Cost: 23.81s
Train Epoch: 1688 [20480/90000 (23%)]	Loss: -10.2404	Cost: 14.62s
Train Epoch: 1688 [40960/90000 (45%)]	Loss: -10.3497	Cost: 14.09s
Train Epoch: 1688 [61440/90000 (68%)]	Loss: -10.3383	Cost: 12.52s
Train Epoch: 1688 [81920/90000 (91%)]	Loss: -9.9988	Cost: 7.45s
Train Epoch: 1688 	Average Loss: -9.7529
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5118

Learning rate: 9.313274734300415e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1689 [0/90000 (0%)]	Loss: -4.0088	Cost: 28.40s
Train Epoch: 1689 [20480/90000 (23%)]	Loss: -10.3331	Cost: 12.39s
Train Epoch: 1689 [40960/90000 (45%)]	Loss: -10.3049	Cost: 10.47s
Train Epoch: 1689 [61440/90000 (68%)]	Loss: -9.9977	Cost: 6.15s
Train Epoch: 1689 [81920/90000 (91%)]	Loss: -9.7330	Cost: 6.77s
Train Epoch: 1689 	Average Loss: -9.7022
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3893

Learning rate: 9.312480023855812e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1690 [0/90000 (0%)]	Loss: -3.8896	Cost: 27.21s
Train Epoch: 1690 [20480/90000 (23%)]	Loss: -10.1959	Cost: 7.19s
Train Epoch: 1690 [40960/90000 (45%)]	Loss: -10.2873	Cost: 8.98s
Train Epoch: 1690 [61440/90000 (68%)]	Loss: -10.1903	Cost: 8.68s
Train Epoch: 1690 [81920/90000 (91%)]	Loss: -9.9652	Cost: 8.88s
Train Epoch: 1690 	Average Loss: -9.6928
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5776

Learning rate: 9.311684887786495e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1691 [0/90000 (0%)]	Loss: -3.4117	Cost: 29.15s
Train Epoch: 1691 [20480/90000 (23%)]	Loss: -10.3837	Cost: 6.40s
Train Epoch: 1691 [40960/90000 (45%)]	Loss: -10.2807	Cost: 9.71s
Train Epoch: 1691 [61440/90000 (68%)]	Loss: -10.6166	Cost: 8.76s
Train Epoch: 1691 [81920/90000 (91%)]	Loss: -9.9777	Cost: 8.55s
Train Epoch: 1691 	Average Loss: -9.8076
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6109

Saving model as e1691_model.pt & e1691_waveforms_supplementary.hdf5
Learning rate: 9.310889326170941e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1692 [0/90000 (0%)]	Loss: -4.6371	Cost: 21.05s
Train Epoch: 1692 [20480/90000 (23%)]	Loss: -10.2426	Cost: 9.49s
Train Epoch: 1692 [40960/90000 (45%)]	Loss: -10.0787	Cost: 8.85s
Train Epoch: 1692 [61440/90000 (68%)]	Loss: -9.3134	Cost: 7.93s
Train Epoch: 1692 [81920/90000 (91%)]	Loss: -9.1974	Cost: 8.61s
Train Epoch: 1692 	Average Loss: -9.3739
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1508

Learning rate: 9.310093339087666e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1693 [0/90000 (0%)]	Loss: -4.1224	Cost: 18.46s
Train Epoch: 1693 [20480/90000 (23%)]	Loss: -9.8806	Cost: 7.02s
Train Epoch: 1693 [40960/90000 (45%)]	Loss: -9.9784	Cost: 9.85s
Train Epoch: 1693 [61440/90000 (68%)]	Loss: -10.1361	Cost: 13.13s
Train Epoch: 1693 [81920/90000 (91%)]	Loss: -10.0270	Cost: 14.23s
Train Epoch: 1693 	Average Loss: -9.5164
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4541

Learning rate: 9.309296926615233e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1694 [0/90000 (0%)]	Loss: -3.7031	Cost: 23.63s
Train Epoch: 1694 [20480/90000 (23%)]	Loss: -10.1537	Cost: 11.79s
Train Epoch: 1694 [40960/90000 (45%)]	Loss: -9.9096	Cost: 14.39s
Train Epoch: 1694 [61440/90000 (68%)]	Loss: -10.0900	Cost: 12.36s
Train Epoch: 1694 [81920/90000 (91%)]	Loss: -10.1292	Cost: 12.10s
Train Epoch: 1694 	Average Loss: -9.6521
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3394

Learning rate: 9.308500088832246e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1695 [0/90000 (0%)]	Loss: -4.1755	Cost: 32.53s
Train Epoch: 1695 [20480/90000 (23%)]	Loss: -10.1975	Cost: 12.86s
Train Epoch: 1695 [40960/90000 (45%)]	Loss: -10.4169	Cost: 12.66s
Train Epoch: 1695 [61440/90000 (68%)]	Loss: -10.5296	Cost: 12.10s
Train Epoch: 1695 [81920/90000 (91%)]	Loss: -10.1648	Cost: 8.81s
Train Epoch: 1695 	Average Loss: -9.7959
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5917

Learning rate: 9.307702825817347e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1696 [0/90000 (0%)]	Loss: -4.4793	Cost: 28.58s
Train Epoch: 1696 [20480/90000 (23%)]	Loss: -10.3409	Cost: 12.72s
Train Epoch: 1696 [40960/90000 (45%)]	Loss: -10.2851	Cost: 12.26s
Train Epoch: 1696 [61440/90000 (68%)]	Loss: -10.3858	Cost: 8.01s
Train Epoch: 1696 [81920/90000 (91%)]	Loss: -10.1049	Cost: 6.34s
Train Epoch: 1696 	Average Loss: -9.8389
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5636

Learning rate: 9.306905137649225e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1697 [0/90000 (0%)]	Loss: -4.0636	Cost: 22.69s
Train Epoch: 1697 [20480/90000 (23%)]	Loss: -10.1191	Cost: 8.45s
Train Epoch: 1697 [40960/90000 (45%)]	Loss: -10.2418	Cost: 9.88s
Train Epoch: 1697 [61440/90000 (68%)]	Loss: -10.6262	Cost: 9.06s
Train Epoch: 1697 [81920/90000 (91%)]	Loss: -10.1448	Cost: 9.06s
Train Epoch: 1697 	Average Loss: -9.8763
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5927

Learning rate: 9.306107024406607e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1698 [0/90000 (0%)]	Loss: -4.3355	Cost: 21.67s
Train Epoch: 1698 [20480/90000 (23%)]	Loss: -10.3356	Cost: 11.15s
Train Epoch: 1698 [40960/90000 (45%)]	Loss: -10.4614	Cost: 10.57s
Train Epoch: 1698 [61440/90000 (68%)]	Loss: -10.4331	Cost: 6.86s
Train Epoch: 1698 [81920/90000 (91%)]	Loss: -10.2384	Cost: 7.73s
Train Epoch: 1698 	Average Loss: -9.9534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7095

Saving model as e1698_model.pt & e1698_waveforms_supplementary.hdf5
Learning rate: 9.305308486168263e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1699 [0/90000 (0%)]	Loss: -4.0985	Cost: 23.96s
Train Epoch: 1699 [20480/90000 (23%)]	Loss: -10.5696	Cost: 8.94s
Train Epoch: 1699 [40960/90000 (45%)]	Loss: -10.6290	Cost: 12.31s
Train Epoch: 1699 [61440/90000 (68%)]	Loss: -10.5757	Cost: 12.88s
Train Epoch: 1699 [81920/90000 (91%)]	Loss: -10.3759	Cost: 12.14s
Train Epoch: 1699 	Average Loss: -10.0369
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5440

Learning rate: 9.304509523013007e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1700 [0/90000 (0%)]	Loss: -3.6497	Cost: 25.14s
Train Epoch: 1700 [20480/90000 (23%)]	Loss: -10.6513	Cost: 13.30s
Train Epoch: 1700 [40960/90000 (45%)]	Loss: -10.3813	Cost: 12.48s
Train Epoch: 1700 [61440/90000 (68%)]	Loss: -10.6003	Cost: 12.08s
Train Epoch: 1700 [81920/90000 (91%)]	Loss: -10.3241	Cost: 11.86s
Train Epoch: 1700 	Average Loss: -9.9896
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6425

Learning rate: 9.303710135019694e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1701 [0/90000 (0%)]	Loss: -3.7017	Cost: 27.72s
Train Epoch: 1701 [20480/90000 (23%)]	Loss: -10.4508	Cost: 12.58s
Train Epoch: 1701 [40960/90000 (45%)]	Loss: -10.4549	Cost: 12.69s
Train Epoch: 1701 [61440/90000 (68%)]	Loss: -10.4806	Cost: 6.72s
Train Epoch: 1701 [81920/90000 (91%)]	Loss: -10.3563	Cost: 6.30s
Train Epoch: 1701 	Average Loss: -9.9731
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6414

Learning rate: 9.30291032226722e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1702 [0/90000 (0%)]	Loss: -4.4133	Cost: 37.45s
Train Epoch: 1702 [20480/90000 (23%)]	Loss: -10.5200	Cost: 10.01s
Train Epoch: 1702 [40960/90000 (45%)]	Loss: -10.3318	Cost: 9.93s
Train Epoch: 1702 [61440/90000 (68%)]	Loss: -10.2909	Cost: 6.56s
Train Epoch: 1702 [81920/90000 (91%)]	Loss: -10.1639	Cost: 7.36s
Train Epoch: 1702 	Average Loss: -9.9359
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5581

Learning rate: 9.302110084834521e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1703 [0/90000 (0%)]	Loss: -3.3933	Cost: 24.87s
Train Epoch: 1703 [20480/90000 (23%)]	Loss: -10.2043	Cost: 11.18s
Train Epoch: 1703 [40960/90000 (45%)]	Loss: -10.4005	Cost: 6.28s
Train Epoch: 1703 [61440/90000 (68%)]	Loss: -10.6480	Cost: 7.38s
Train Epoch: 1703 [81920/90000 (91%)]	Loss: -10.2508	Cost: 8.28s
Train Epoch: 1703 	Average Loss: -9.8694
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6119

Learning rate: 9.30130942280058e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1704 [0/90000 (0%)]	Loss: -4.2392	Cost: 24.87s
Train Epoch: 1704 [20480/90000 (23%)]	Loss: -10.1078	Cost: 7.65s
Train Epoch: 1704 [40960/90000 (45%)]	Loss: -10.3937	Cost: 9.00s
Train Epoch: 1704 [61440/90000 (68%)]	Loss: -10.3593	Cost: 8.78s
Train Epoch: 1704 [81920/90000 (91%)]	Loss: -10.0703	Cost: 8.38s
Train Epoch: 1704 	Average Loss: -9.8496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6341

Learning rate: 9.300508336244418e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1705 [0/90000 (0%)]	Loss: -4.1367	Cost: 24.35s
Train Epoch: 1705 [20480/90000 (23%)]	Loss: -10.4359	Cost: 8.88s
Train Epoch: 1705 [40960/90000 (45%)]	Loss: -10.6330	Cost: 9.11s
Train Epoch: 1705 [61440/90000 (68%)]	Loss: -10.5168	Cost: 7.98s
Train Epoch: 1705 [81920/90000 (91%)]	Loss: -10.2262	Cost: 5.83s
Train Epoch: 1705 	Average Loss: -10.0276
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7874

Saving model as e1705_model.pt & e1705_waveforms_supplementary.hdf5
Learning rate: 9.2997068252451e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1706 [0/90000 (0%)]	Loss: -3.8610	Cost: 20.84s
Train Epoch: 1706 [20480/90000 (23%)]	Loss: -10.4863	Cost: 7.20s
Train Epoch: 1706 [40960/90000 (45%)]	Loss: -10.5487	Cost: 12.14s
Train Epoch: 1706 [61440/90000 (68%)]	Loss: -10.5999	Cost: 13.02s
Train Epoch: 1706 [81920/90000 (91%)]	Loss: -10.4814	Cost: 12.36s
Train Epoch: 1706 	Average Loss: -9.9874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8298

Saving model as e1706_model.pt & e1706_waveforms_supplementary.hdf5
Learning rate: 9.298904889881731e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1707 [0/90000 (0%)]	Loss: -4.6831	Cost: 26.79s
Train Epoch: 1707 [20480/90000 (23%)]	Loss: -10.5065	Cost: 15.15s
Train Epoch: 1707 [40960/90000 (45%)]	Loss: -10.6628	Cost: 15.80s
Train Epoch: 1707 [61440/90000 (68%)]	Loss: -10.8164	Cost: 12.31s
Train Epoch: 1707 [81920/90000 (91%)]	Loss: -10.5314	Cost: 12.01s
Train Epoch: 1707 	Average Loss: -10.1271
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6878

Learning rate: 9.29810253023346e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1708 [0/90000 (0%)]	Loss: -4.2631	Cost: 41.13s
Train Epoch: 1708 [20480/90000 (23%)]	Loss: -10.4521	Cost: 13.26s
Train Epoch: 1708 [40960/90000 (45%)]	Loss: -10.5757	Cost: 12.40s
Train Epoch: 1708 [61440/90000 (68%)]	Loss: -10.5789	Cost: 11.46s
Train Epoch: 1708 [81920/90000 (91%)]	Loss: -10.1416	Cost: 6.20s
Train Epoch: 1708 	Average Loss: -10.0255
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6860

Learning rate: 9.297299746379476e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1709 [0/90000 (0%)]	Loss: -4.0077	Cost: 29.06s
Train Epoch: 1709 [20480/90000 (23%)]	Loss: -10.1361	Cost: 12.58s
Train Epoch: 1709 [40960/90000 (45%)]	Loss: -10.3812	Cost: 12.29s
Train Epoch: 1709 [61440/90000 (68%)]	Loss: -10.6632	Cost: 7.56s
Train Epoch: 1709 [81920/90000 (91%)]	Loss: -10.1907	Cost: 6.49s
Train Epoch: 1709 	Average Loss: -9.9212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5921

Learning rate: 9.29649653839901e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1710 [0/90000 (0%)]	Loss: -2.5381	Cost: 29.91s
Train Epoch: 1710 [20480/90000 (23%)]	Loss: -10.3854	Cost: 12.49s
Train Epoch: 1710 [40960/90000 (45%)]	Loss: -10.4427	Cost: 7.26s
Train Epoch: 1710 [61440/90000 (68%)]	Loss: -10.4808	Cost: 6.32s
Train Epoch: 1710 [81920/90000 (91%)]	Loss: -10.2586	Cost: 7.57s
Train Epoch: 1710 	Average Loss: -9.9654
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8043

Learning rate: 9.295692906371338e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1711 [0/90000 (0%)]	Loss: -3.8567	Cost: 22.52s
Train Epoch: 1711 [20480/90000 (23%)]	Loss: -10.4014	Cost: 6.84s
Train Epoch: 1711 [40960/90000 (45%)]	Loss: -10.3667	Cost: 8.90s
Train Epoch: 1711 [61440/90000 (68%)]	Loss: -10.8120	Cost: 8.67s
Train Epoch: 1711 [81920/90000 (91%)]	Loss: -10.1047	Cost: 8.75s
Train Epoch: 1711 	Average Loss: -9.9613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3747

Learning rate: 9.294888850375771e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1712 [0/90000 (0%)]	Loss: -3.1377	Cost: 25.89s
Train Epoch: 1712 [20480/90000 (23%)]	Loss: -10.3807	Cost: 10.16s
Train Epoch: 1712 [40960/90000 (45%)]	Loss: -10.4379	Cost: 9.96s
Train Epoch: 1712 [61440/90000 (68%)]	Loss: -10.6765	Cost: 6.16s
Train Epoch: 1712 [81920/90000 (91%)]	Loss: -10.2574	Cost: 6.59s
Train Epoch: 1712 	Average Loss: -9.8989
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7618

Learning rate: 9.29408437049167e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1713 [0/90000 (0%)]	Loss: -4.3454	Cost: 25.24s
Train Epoch: 1713 [20480/90000 (23%)]	Loss: -10.3356	Cost: 9.68s
Train Epoch: 1713 [40960/90000 (45%)]	Loss: -10.6833	Cost: 10.98s
Train Epoch: 1713 [61440/90000 (68%)]	Loss: -10.7864	Cost: 10.18s
Train Epoch: 1713 [81920/90000 (91%)]	Loss: -10.3246	Cost: 13.14s
Train Epoch: 1713 	Average Loss: -10.0320
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5672

Learning rate: 9.293279466798431e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1714 [0/90000 (0%)]	Loss: -3.7765	Cost: 25.89s
Train Epoch: 1714 [20480/90000 (23%)]	Loss: -10.2890	Cost: 10.66s
Train Epoch: 1714 [40960/90000 (45%)]	Loss: -10.5124	Cost: 12.09s
Train Epoch: 1714 [61440/90000 (68%)]	Loss: -10.6543	Cost: 12.76s
Train Epoch: 1714 [81920/90000 (91%)]	Loss: -10.3640	Cost: 12.38s
Train Epoch: 1714 	Average Loss: -10.0016
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8167

Learning rate: 9.292474139375496e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1715 [0/90000 (0%)]	Loss: -4.7663	Cost: 25.51s
Train Epoch: 1715 [20480/90000 (23%)]	Loss: -10.3207	Cost: 11.17s
Train Epoch: 1715 [40960/90000 (45%)]	Loss: -10.7064	Cost: 12.65s
Train Epoch: 1715 [61440/90000 (68%)]	Loss: -10.7969	Cost: 12.10s
Train Epoch: 1715 [81920/90000 (91%)]	Loss: -10.3413	Cost: 10.86s
Train Epoch: 1715 	Average Loss: -10.1420
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7801

Learning rate: 9.291668388302348e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1716 [0/90000 (0%)]	Loss: -3.8525	Cost: 27.05s
Train Epoch: 1716 [20480/90000 (23%)]	Loss: -10.3981	Cost: 12.14s
Train Epoch: 1716 [40960/90000 (45%)]	Loss: -10.4475	Cost: 10.47s
Train Epoch: 1716 [61440/90000 (68%)]	Loss: -10.6265	Cost: 6.36s
Train Epoch: 1716 [81920/90000 (91%)]	Loss: -10.2105	Cost: 7.04s
Train Epoch: 1716 	Average Loss: -9.9574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6243

Learning rate: 9.290862213658514e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1717 [0/90000 (0%)]	Loss: -4.2999	Cost: 34.27s
Train Epoch: 1717 [20480/90000 (23%)]	Loss: -10.5916	Cost: 11.64s
Train Epoch: 1717 [40960/90000 (45%)]	Loss: -10.1726	Cost: 9.45s
Train Epoch: 1717 [61440/90000 (68%)]	Loss: -10.7338	Cost: 7.48s
Train Epoch: 1717 [81920/90000 (91%)]	Loss: -10.4005	Cost: 8.55s
Train Epoch: 1717 	Average Loss: -9.9641
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9131

Saving model as e1717_model.pt & e1717_waveforms_supplementary.hdf5
Learning rate: 9.290055615523555e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1718 [0/90000 (0%)]	Loss: -4.8099	Cost: 20.91s
Train Epoch: 1718 [20480/90000 (23%)]	Loss: -10.6583	Cost: 10.12s
Train Epoch: 1718 [40960/90000 (45%)]	Loss: -10.6167	Cost: 7.61s
Train Epoch: 1718 [61440/90000 (68%)]	Loss: -10.6969	Cost: 9.16s
Train Epoch: 1718 [81920/90000 (91%)]	Loss: -10.1131	Cost: 9.29s
Train Epoch: 1718 	Average Loss: -10.1548
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6046

Learning rate: 9.289248593977082e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1719 [0/90000 (0%)]	Loss: -4.1157	Cost: 20.84s
Train Epoch: 1719 [20480/90000 (23%)]	Loss: -10.3112	Cost: 8.69s
Train Epoch: 1719 [40960/90000 (45%)]	Loss: -10.5405	Cost: 8.88s
Train Epoch: 1719 [61440/90000 (68%)]	Loss: -10.3394	Cost: 8.70s
Train Epoch: 1719 [81920/90000 (91%)]	Loss: -10.3406	Cost: 8.45s
Train Epoch: 1719 	Average Loss: -9.9170
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6791

Learning rate: 9.288441149098744e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1720 [0/90000 (0%)]	Loss: -3.5643	Cost: 28.24s
Train Epoch: 1720 [20480/90000 (23%)]	Loss: -10.4142	Cost: 8.86s
Train Epoch: 1720 [40960/90000 (45%)]	Loss: -10.6710	Cost: 6.79s
Train Epoch: 1720 [61440/90000 (68%)]	Loss: -10.6396	Cost: 6.61s
Train Epoch: 1720 [81920/90000 (91%)]	Loss: -10.2071	Cost: 6.57s
Train Epoch: 1720 	Average Loss: -10.0840
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6704

Learning rate: 9.287633280968234e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1721 [0/90000 (0%)]	Loss: -3.3529	Cost: 21.74s
Train Epoch: 1721 [20480/90000 (23%)]	Loss: -10.3490	Cost: 9.59s
Train Epoch: 1721 [40960/90000 (45%)]	Loss: -10.3650	Cost: 11.82s
Train Epoch: 1721 [61440/90000 (68%)]	Loss: -10.5679	Cost: 12.49s
Train Epoch: 1721 [81920/90000 (91%)]	Loss: -10.1827	Cost: 12.79s
Train Epoch: 1721 	Average Loss: -9.9842
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8403

Learning rate: 9.286824989665286e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1722 [0/90000 (0%)]	Loss: -3.4173	Cost: 26.41s
Train Epoch: 1722 [20480/90000 (23%)]	Loss: -10.4223	Cost: 12.90s
Train Epoch: 1722 [40960/90000 (45%)]	Loss: -10.6242	Cost: 13.37s
Train Epoch: 1722 [61440/90000 (68%)]	Loss: -10.4896	Cost: 12.83s
Train Epoch: 1722 [81920/90000 (91%)]	Loss: -9.8208	Cost: 12.39s
Train Epoch: 1722 	Average Loss: -9.9382
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4291

Learning rate: 9.286016275269671e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1723 [0/90000 (0%)]	Loss: -3.8046	Cost: 29.70s
Train Epoch: 1723 [20480/90000 (23%)]	Loss: -10.3173	Cost: 13.86s
Train Epoch: 1723 [40960/90000 (45%)]	Loss: -10.2904	Cost: 14.13s
Train Epoch: 1723 [61440/90000 (68%)]	Loss: -10.5353	Cost: 12.47s
Train Epoch: 1723 [81920/90000 (91%)]	Loss: -10.1114	Cost: 7.07s
Train Epoch: 1723 	Average Loss: -9.8465
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6012

Learning rate: 9.28520713786121e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1724 [0/90000 (0%)]	Loss: -4.2029	Cost: 28.76s
Train Epoch: 1724 [20480/90000 (23%)]	Loss: -10.4537	Cost: 13.02s
Train Epoch: 1724 [40960/90000 (45%)]	Loss: -10.5352	Cost: 10.92s
Train Epoch: 1724 [61440/90000 (68%)]	Loss: -10.5513	Cost: 5.99s
Train Epoch: 1724 [81920/90000 (91%)]	Loss: -10.2302	Cost: 7.01s
Train Epoch: 1724 	Average Loss: -9.9900
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7205

Learning rate: 9.28439757751976e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1725 [0/90000 (0%)]	Loss: -4.2556	Cost: 34.37s
Train Epoch: 1725 [20480/90000 (23%)]	Loss: -10.3949	Cost: 6.44s
Train Epoch: 1725 [40960/90000 (45%)]	Loss: -10.5939	Cost: 9.93s
Train Epoch: 1725 [61440/90000 (68%)]	Loss: -10.7558	Cost: 8.96s
Train Epoch: 1725 [81920/90000 (91%)]	Loss: -10.3214	Cost: 8.82s
Train Epoch: 1725 	Average Loss: -10.0495
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7248

Learning rate: 9.283587594325222e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1726 [0/90000 (0%)]	Loss: -4.2536	Cost: 24.79s
Train Epoch: 1726 [20480/90000 (23%)]	Loss: -10.4551	Cost: 6.75s
Train Epoch: 1726 [40960/90000 (45%)]	Loss: -10.5086	Cost: 9.61s
Train Epoch: 1726 [61440/90000 (68%)]	Loss: -10.6750	Cost: 8.63s
Train Epoch: 1726 [81920/90000 (91%)]	Loss: -10.2022	Cost: 8.41s
Train Epoch: 1726 	Average Loss: -10.0418
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7396

Learning rate: 9.282777188357535e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1727 [0/90000 (0%)]	Loss: -4.1542	Cost: 22.11s
Train Epoch: 1727 [20480/90000 (23%)]	Loss: -10.5051	Cost: 9.34s
Train Epoch: 1727 [40960/90000 (45%)]	Loss: -10.4080	Cost: 7.91s
Train Epoch: 1727 [61440/90000 (68%)]	Loss: -10.9519	Cost: 9.73s
Train Epoch: 1727 [81920/90000 (91%)]	Loss: -10.4380	Cost: 14.33s
Train Epoch: 1727 	Average Loss: -10.0869
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9001

Learning rate: 9.281966359696688e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1728 [0/90000 (0%)]	Loss: -4.8619	Cost: 18.74s
Train Epoch: 1728 [20480/90000 (23%)]	Loss: -10.6477	Cost: 7.02s
Train Epoch: 1728 [40960/90000 (45%)]	Loss: -10.9311	Cost: 14.30s
Train Epoch: 1728 [61440/90000 (68%)]	Loss: -10.7817	Cost: 13.55s
Train Epoch: 1728 [81920/90000 (91%)]	Loss: -10.7553	Cost: 12.67s
Train Epoch: 1728 	Average Loss: -10.2919
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7852

Learning rate: 9.281155108422703e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1729 [0/90000 (0%)]	Loss: -4.3082	Cost: 27.11s
Train Epoch: 1729 [20480/90000 (23%)]	Loss: -10.2368	Cost: 15.46s
Train Epoch: 1729 [40960/90000 (45%)]	Loss: -10.3670	Cost: 13.18s
Train Epoch: 1729 [61440/90000 (68%)]	Loss: -10.7162	Cost: 12.18s
Train Epoch: 1729 [81920/90000 (91%)]	Loss: -10.2203	Cost: 9.30s
Train Epoch: 1729 	Average Loss: -10.0068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7997

Learning rate: 9.28034343461565e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1730 [0/90000 (0%)]	Loss: -3.6943	Cost: 36.73s
Train Epoch: 1730 [20480/90000 (23%)]	Loss: -10.3931	Cost: 12.75s
Train Epoch: 1730 [40960/90000 (45%)]	Loss: -10.1929	Cost: 12.27s
Train Epoch: 1730 [61440/90000 (68%)]	Loss: -10.3901	Cost: 7.11s
Train Epoch: 1730 [81920/90000 (91%)]	Loss: -10.1001	Cost: 6.11s
Train Epoch: 1730 	Average Loss: -9.9069
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7074

Learning rate: 9.279531338355635e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1731 [0/90000 (0%)]	Loss: -2.6932	Cost: 40.22s
Train Epoch: 1731 [20480/90000 (23%)]	Loss: -10.5234	Cost: 8.65s
Train Epoch: 1731 [40960/90000 (45%)]	Loss: -10.6893	Cost: 6.66s
Train Epoch: 1731 [61440/90000 (68%)]	Loss: -10.8396	Cost: 7.18s
Train Epoch: 1731 [81920/90000 (91%)]	Loss: -10.3980	Cost: 9.91s
Train Epoch: 1731 	Average Loss: -10.0640
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8034

Learning rate: 9.278718819722811e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1732 [0/90000 (0%)]	Loss: -4.2773	Cost: 21.41s
Train Epoch: 1732 [20480/90000 (23%)]	Loss: -10.7737	Cost: 6.65s
Train Epoch: 1732 [40960/90000 (45%)]	Loss: -10.7189	Cost: 9.11s
Train Epoch: 1732 [61440/90000 (68%)]	Loss: -10.7785	Cost: 9.37s
Train Epoch: 1732 [81920/90000 (91%)]	Loss: -10.6109	Cost: 8.74s
Train Epoch: 1732 	Average Loss: -10.2307
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8330

Learning rate: 9.27790587879737e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1733 [0/90000 (0%)]	Loss: -3.9375	Cost: 19.20s
Train Epoch: 1733 [20480/90000 (23%)]	Loss: -10.6214	Cost: 6.72s
Train Epoch: 1733 [40960/90000 (45%)]	Loss: -10.5772	Cost: 10.43s
Train Epoch: 1733 [61440/90000 (68%)]	Loss: -10.7513	Cost: 8.55s
Train Epoch: 1733 [81920/90000 (91%)]	Loss: -10.3881	Cost: 8.53s
Train Epoch: 1733 	Average Loss: -10.1458
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8371

Learning rate: 9.277092515659545e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1734 [0/90000 (0%)]	Loss: -3.2541	Cost: 21.56s
Train Epoch: 1734 [20480/90000 (23%)]	Loss: -10.7456	Cost: 9.05s
Train Epoch: 1734 [40960/90000 (45%)]	Loss: -10.7141	Cost: 9.18s
Train Epoch: 1734 [61440/90000 (68%)]	Loss: -10.7932	Cost: 9.14s
Train Epoch: 1734 [81920/90000 (91%)]	Loss: -10.4256	Cost: 7.68s
Train Epoch: 1734 	Average Loss: -10.2470
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8921

Learning rate: 9.276278730389611e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1735 [0/90000 (0%)]	Loss: -4.4607	Cost: 21.01s
Train Epoch: 1735 [20480/90000 (23%)]	Loss: -10.7121	Cost: 8.70s
Train Epoch: 1735 [40960/90000 (45%)]	Loss: -10.7203	Cost: 10.99s
Train Epoch: 1735 [61440/90000 (68%)]	Loss: -10.7111	Cost: 13.16s
Train Epoch: 1735 [81920/90000 (91%)]	Loss: -10.4420	Cost: 12.54s
Train Epoch: 1735 	Average Loss: -10.2090
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9393

Saving model as e1735_model.pt & e1735_waveforms_supplementary.hdf5
Learning rate: 9.275464523067889e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1736 [0/90000 (0%)]	Loss: -3.8908	Cost: 30.06s
Train Epoch: 1736 [20480/90000 (23%)]	Loss: -10.7157	Cost: 13.56s
Train Epoch: 1736 [40960/90000 (45%)]	Loss: -10.6098	Cost: 13.29s
Train Epoch: 1736 [61440/90000 (68%)]	Loss: -10.8014	Cost: 12.33s
Train Epoch: 1736 [81920/90000 (91%)]	Loss: -10.5087	Cost: 12.20s
Train Epoch: 1736 	Average Loss: -10.2340
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7657

Learning rate: 9.274649893774736e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1737 [0/90000 (0%)]	Loss: -4.0099	Cost: 42.67s
Train Epoch: 1737 [20480/90000 (23%)]	Loss: -10.4906	Cost: 12.56s
Train Epoch: 1737 [40960/90000 (45%)]	Loss: -10.7659	Cost: 12.25s
Train Epoch: 1737 [61440/90000 (68%)]	Loss: -10.8657	Cost: 9.53s
Train Epoch: 1737 [81920/90000 (91%)]	Loss: -10.3989	Cost: 6.18s
Train Epoch: 1737 	Average Loss: -10.1256
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8015

Learning rate: 9.27383484259055e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1738 [0/90000 (0%)]	Loss: -4.2394	Cost: 28.21s
Train Epoch: 1738 [20480/90000 (23%)]	Loss: -10.5188	Cost: 11.64s
Train Epoch: 1738 [40960/90000 (45%)]	Loss: -10.6075	Cost: 11.54s
Train Epoch: 1738 [61440/90000 (68%)]	Loss: -10.7551	Cost: 6.76s
Train Epoch: 1738 [81920/90000 (91%)]	Loss: -10.4654	Cost: 7.43s
Train Epoch: 1738 	Average Loss: -10.1598
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8781

Learning rate: 9.273019369595777e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1739 [0/90000 (0%)]	Loss: -3.4966	Cost: 22.80s
Train Epoch: 1739 [20480/90000 (23%)]	Loss: -10.5319	Cost: 9.19s
Train Epoch: 1739 [40960/90000 (45%)]	Loss: -10.6858	Cost: 7.44s
Train Epoch: 1739 [61440/90000 (68%)]	Loss: -10.9486	Cost: 7.51s
Train Epoch: 1739 [81920/90000 (91%)]	Loss: -10.3878	Cost: 9.47s
Train Epoch: 1739 	Average Loss: -10.2243
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9757

Saving model as e1739_model.pt & e1739_waveforms_supplementary.hdf5
Learning rate: 9.2722034748709e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1740 [0/90000 (0%)]	Loss: -3.9472	Cost: 24.43s
Train Epoch: 1740 [20480/90000 (23%)]	Loss: -10.5425	Cost: 9.05s
Train Epoch: 1740 [40960/90000 (45%)]	Loss: -10.5174	Cost: 9.43s
Train Epoch: 1740 [61440/90000 (68%)]	Loss: -10.5928	Cost: 8.56s
Train Epoch: 1740 [81920/90000 (91%)]	Loss: -10.3684	Cost: 8.21s
Train Epoch: 1740 	Average Loss: -10.2062
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8449

Learning rate: 9.271387158496444e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1741 [0/90000 (0%)]	Loss: -4.8204	Cost: 22.03s
Train Epoch: 1741 [20480/90000 (23%)]	Loss: -10.4963	Cost: 8.86s
Train Epoch: 1741 [40960/90000 (45%)]	Loss: -10.8559	Cost: 6.42s
Train Epoch: 1741 [61440/90000 (68%)]	Loss: -10.6555	Cost: 6.88s
Train Epoch: 1741 [81920/90000 (91%)]	Loss: -10.3910	Cost: 7.62s
Train Epoch: 1741 	Average Loss: -10.1551
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9874

Saving model as e1741_model.pt & e1741_waveforms_supplementary.hdf5
Learning rate: 9.270570420552977e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1742 [0/90000 (0%)]	Loss: -4.6451	Cost: 22.23s
Train Epoch: 1742 [20480/90000 (23%)]	Loss: -10.8150	Cost: 10.52s
Train Epoch: 1742 [40960/90000 (45%)]	Loss: -10.8815	Cost: 11.56s
Train Epoch: 1742 [61440/90000 (68%)]	Loss: -10.6128	Cost: 12.40s
Train Epoch: 1742 [81920/90000 (91%)]	Loss: -10.4147	Cost: 12.47s
Train Epoch: 1742 	Average Loss: -10.2109
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9402

Learning rate: 9.269753261121107e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1743 [0/90000 (0%)]	Loss: -4.0426	Cost: 25.99s
Train Epoch: 1743 [20480/90000 (23%)]	Loss: -10.5207	Cost: 13.96s
Train Epoch: 1743 [40960/90000 (45%)]	Loss: -10.5768	Cost: 13.98s
Train Epoch: 1743 [61440/90000 (68%)]	Loss: -10.7641	Cost: 12.32s
Train Epoch: 1743 [81920/90000 (91%)]	Loss: -10.4617	Cost: 12.31s
Train Epoch: 1743 	Average Loss: -10.1583
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9015

Learning rate: 9.268935680281485e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1744 [0/90000 (0%)]	Loss: -4.7837	Cost: 24.23s
Train Epoch: 1744 [20480/90000 (23%)]	Loss: -10.6354	Cost: 13.98s
Train Epoch: 1744 [40960/90000 (45%)]	Loss: -10.6529	Cost: 14.19s
Train Epoch: 1744 [61440/90000 (68%)]	Loss: -10.7506	Cost: 12.32s
Train Epoch: 1744 [81920/90000 (91%)]	Loss: -10.4840	Cost: 9.01s
Train Epoch: 1744 	Average Loss: -10.1986
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8939

Learning rate: 9.268117678114803e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1745 [0/90000 (0%)]	Loss: -4.3567	Cost: 28.34s
Train Epoch: 1745 [20480/90000 (23%)]	Loss: -10.4315	Cost: 13.88s
Train Epoch: 1745 [40960/90000 (45%)]	Loss: -10.6620	Cost: 12.29s
Train Epoch: 1745 [61440/90000 (68%)]	Loss: -10.6157	Cost: 7.59s
Train Epoch: 1745 [81920/90000 (91%)]	Loss: -10.4548	Cost: 6.27s
Train Epoch: 1745 	Average Loss: -10.1921
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8549

Learning rate: 9.267299254701793e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1746 [0/90000 (0%)]	Loss: -4.0379	Cost: 25.31s
Train Epoch: 1746 [20480/90000 (23%)]	Loss: -10.6387	Cost: 6.64s
Train Epoch: 1746 [40960/90000 (45%)]	Loss: -10.7471	Cost: 8.31s
Train Epoch: 1746 [61440/90000 (68%)]	Loss: -10.9150	Cost: 8.85s
Train Epoch: 1746 [81920/90000 (91%)]	Loss: -10.4076	Cost: 8.75s
Train Epoch: 1746 	Average Loss: -10.2809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8210

Learning rate: 9.266480410123233e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1747 [0/90000 (0%)]	Loss: -3.8478	Cost: 25.39s
Train Epoch: 1747 [20480/90000 (23%)]	Loss: -10.5895	Cost: 6.56s
Train Epoch: 1747 [40960/90000 (45%)]	Loss: -10.4820	Cost: 10.84s
Train Epoch: 1747 [61440/90000 (68%)]	Loss: -10.7953	Cost: 8.55s
Train Epoch: 1747 [81920/90000 (91%)]	Loss: -10.4705	Cost: 8.41s
Train Epoch: 1747 	Average Loss: -10.1027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8331

Learning rate: 9.265661144459937e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1748 [0/90000 (0%)]	Loss: -4.6003	Cost: 25.68s
Train Epoch: 1748 [20480/90000 (23%)]	Loss: -10.7246	Cost: 9.69s
Train Epoch: 1748 [40960/90000 (45%)]	Loss: -10.5957	Cost: 9.63s
Train Epoch: 1748 [61440/90000 (68%)]	Loss: -10.8560	Cost: 8.86s
Train Epoch: 1748 [81920/90000 (91%)]	Loss: -10.4168	Cost: 9.22s
Train Epoch: 1748 	Average Loss: -10.2289
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9511

Learning rate: 9.264841457792765e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1749 [0/90000 (0%)]	Loss: -4.8055	Cost: 17.97s
Train Epoch: 1749 [20480/90000 (23%)]	Loss: -10.6903	Cost: 7.24s
Train Epoch: 1749 [40960/90000 (45%)]	Loss: -10.8074	Cost: 11.46s
Train Epoch: 1749 [61440/90000 (68%)]	Loss: -10.7022	Cost: 14.12s
Train Epoch: 1749 [81920/90000 (91%)]	Loss: -10.6066	Cost: 13.82s
Train Epoch: 1749 	Average Loss: -10.2839
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6236

Learning rate: 9.264021350202617e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1750 [0/90000 (0%)]	Loss: -4.0628	Cost: 21.19s
Train Epoch: 1750 [20480/90000 (23%)]	Loss: -10.2536	Cost: 11.06s
Train Epoch: 1750 [40960/90000 (45%)]	Loss: -10.4162	Cost: 14.95s
Train Epoch: 1750 [61440/90000 (68%)]	Loss: -10.6092	Cost: 12.53s
Train Epoch: 1750 [81920/90000 (91%)]	Loss: -10.3680	Cost: 12.15s
Train Epoch: 1750 	Average Loss: -9.9189
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9365

Learning rate: 9.263200821770431e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1751 [0/90000 (0%)]	Loss: -3.5673	Cost: 38.20s
Train Epoch: 1751 [20480/90000 (23%)]	Loss: -10.7098	Cost: 9.90s
Train Epoch: 1751 [40960/90000 (45%)]	Loss: -10.5085	Cost: 12.47s
Train Epoch: 1751 [61440/90000 (68%)]	Loss: -10.9413	Cost: 12.30s
Train Epoch: 1751 [81920/90000 (91%)]	Loss: -10.5972	Cost: 7.17s
Train Epoch: 1751 	Average Loss: -10.1960
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9206

Learning rate: 9.262379872577195e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1752 [0/90000 (0%)]	Loss: -3.9703	Cost: 27.58s
Train Epoch: 1752 [20480/90000 (23%)]	Loss: -10.8994	Cost: 13.52s
Train Epoch: 1752 [40960/90000 (45%)]	Loss: -10.8538	Cost: 9.77s
Train Epoch: 1752 [61440/90000 (68%)]	Loss: -10.9205	Cost: 6.12s
Train Epoch: 1752 [81920/90000 (91%)]	Loss: -10.3960	Cost: 7.53s
Train Epoch: 1752 	Average Loss: -10.1942
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7441

Learning rate: 9.26155850270393e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1753 [0/90000 (0%)]	Loss: -4.1956	Cost: 24.69s
Train Epoch: 1753 [20480/90000 (23%)]	Loss: -10.7133	Cost: 7.83s
Train Epoch: 1753 [40960/90000 (45%)]	Loss: -10.8545	Cost: 11.08s
Train Epoch: 1753 [61440/90000 (68%)]	Loss: -11.0620	Cost: 9.13s
Train Epoch: 1753 [81920/90000 (91%)]	Loss: -10.7069	Cost: 8.94s
Train Epoch: 1753 	Average Loss: -10.2789
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0559

Saving model as e1753_model.pt & e1753_waveforms_supplementary.hdf5
Learning rate: 9.260736712231702e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1754 [0/90000 (0%)]	Loss: -4.6292	Cost: 22.54s
Train Epoch: 1754 [20480/90000 (23%)]	Loss: -10.6316	Cost: 10.71s
Train Epoch: 1754 [40960/90000 (45%)]	Loss: -10.9967	Cost: 10.45s
Train Epoch: 1754 [61440/90000 (68%)]	Loss: -10.7398	Cost: 8.33s
Train Epoch: 1754 [81920/90000 (91%)]	Loss: -10.4880	Cost: 10.18s
Train Epoch: 1754 	Average Loss: -10.2793
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8840

Learning rate: 9.25991450124162e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1755 [0/90000 (0%)]	Loss: -4.4017	Cost: 25.06s
Train Epoch: 1755 [20480/90000 (23%)]	Loss: -10.6202	Cost: 10.59s
Train Epoch: 1755 [40960/90000 (45%)]	Loss: -10.7241	Cost: 12.11s
Train Epoch: 1755 [61440/90000 (68%)]	Loss: -10.7675	Cost: 12.60s
Train Epoch: 1755 [81920/90000 (91%)]	Loss: -10.4035	Cost: 12.40s
Train Epoch: 1755 	Average Loss: -10.1588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6328

Learning rate: 9.259091869814832e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1756 [0/90000 (0%)]	Loss: -3.3174	Cost: 25.14s
Train Epoch: 1756 [20480/90000 (23%)]	Loss: -10.4633	Cost: 13.43s
Train Epoch: 1756 [40960/90000 (45%)]	Loss: -10.5259	Cost: 12.54s
Train Epoch: 1756 [61440/90000 (68%)]	Loss: -10.8638	Cost: 12.06s
Train Epoch: 1756 [81920/90000 (91%)]	Loss: -10.4036	Cost: 10.53s
Train Epoch: 1756 	Average Loss: -10.0456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8901

Learning rate: 9.25826881803253e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1757 [0/90000 (0%)]	Loss: -4.0129	Cost: 25.36s
Train Epoch: 1757 [20480/90000 (23%)]	Loss: -10.5758	Cost: 12.24s
Train Epoch: 1757 [40960/90000 (45%)]	Loss: -10.3575	Cost: 12.57s
Train Epoch: 1757 [61440/90000 (68%)]	Loss: -10.5687	Cost: 11.22s
Train Epoch: 1757 [81920/90000 (91%)]	Loss: -10.3079	Cost: 6.47s
Train Epoch: 1757 	Average Loss: -10.1182
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8001

Learning rate: 9.257445345975943e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1758 [0/90000 (0%)]	Loss: -4.5205	Cost: 27.56s
Train Epoch: 1758 [20480/90000 (23%)]	Loss: -10.6124	Cost: 15.32s
Train Epoch: 1758 [40960/90000 (45%)]	Loss: -10.4677	Cost: 13.27s
Train Epoch: 1758 [61440/90000 (68%)]	Loss: -10.8254	Cost: 6.45s
Train Epoch: 1758 [81920/90000 (91%)]	Loss: -10.6427	Cost: 6.28s
Train Epoch: 1758 	Average Loss: -10.2535
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9038

Learning rate: 9.256621453726348e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1759 [0/90000 (0%)]	Loss: -4.1746	Cost: 23.67s
Train Epoch: 1759 [20480/90000 (23%)]	Loss: -10.8229	Cost: 9.83s
Train Epoch: 1759 [40960/90000 (45%)]	Loss: -10.7937	Cost: 11.42s
Train Epoch: 1759 [61440/90000 (68%)]	Loss: -10.9521	Cost: 8.78s
Train Epoch: 1759 [81920/90000 (91%)]	Loss: -10.2309	Cost: 7.13s
Train Epoch: 1759 	Average Loss: -10.2595
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4860

Learning rate: 9.255797141365057e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1760 [0/90000 (0%)]	Loss: -3.9018	Cost: 21.32s
Train Epoch: 1760 [20480/90000 (23%)]	Loss: -10.5035	Cost: 8.40s
Train Epoch: 1760 [40960/90000 (45%)]	Loss: -10.6246	Cost: 7.66s
Train Epoch: 1760 [61440/90000 (68%)]	Loss: -10.7367	Cost: 8.92s
Train Epoch: 1760 [81920/90000 (91%)]	Loss: -9.9980	Cost: 8.79s
Train Epoch: 1760 	Average Loss: -10.0050
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4628

Learning rate: 9.254972408973427e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1761 [0/90000 (0%)]	Loss: -3.5474	Cost: 23.33s
Train Epoch: 1761 [20480/90000 (23%)]	Loss: -10.4164	Cost: 9.76s
Train Epoch: 1761 [40960/90000 (45%)]	Loss: -10.3488	Cost: 9.80s
Train Epoch: 1761 [61440/90000 (68%)]	Loss: -10.5024	Cost: 8.71s
Train Epoch: 1761 [81920/90000 (91%)]	Loss: -10.0743	Cost: 8.45s
Train Epoch: 1761 	Average Loss: -9.7780
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7496

Learning rate: 9.254147256632858e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1762 [0/90000 (0%)]	Loss: -3.9231	Cost: 23.01s
Train Epoch: 1762 [20480/90000 (23%)]	Loss: -10.3657	Cost: 10.43s
Train Epoch: 1762 [40960/90000 (45%)]	Loss: -10.4823	Cost: 9.79s
Train Epoch: 1762 [61440/90000 (68%)]	Loss: -10.5760	Cost: 8.77s
Train Epoch: 1762 [81920/90000 (91%)]	Loss: -10.4200	Cost: 8.78s
Train Epoch: 1762 	Average Loss: -10.0315
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8549

Learning rate: 9.253321684424786e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1763 [0/90000 (0%)]	Loss: -4.8341	Cost: 21.47s
Train Epoch: 1763 [20480/90000 (23%)]	Loss: -10.6999	Cost: 8.77s
Train Epoch: 1763 [40960/90000 (45%)]	Loss: -10.8198	Cost: 8.91s
Train Epoch: 1763 [61440/90000 (68%)]	Loss: -10.8388	Cost: 6.40s
Train Epoch: 1763 [81920/90000 (91%)]	Loss: -10.6408	Cost: 6.31s
Train Epoch: 1763 	Average Loss: -10.2914
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8254

Learning rate: 9.252495692430695e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1764 [0/90000 (0%)]	Loss: -4.1301	Cost: 19.96s
Train Epoch: 1764 [20480/90000 (23%)]	Loss: -10.8791	Cost: 7.27s
Train Epoch: 1764 [40960/90000 (45%)]	Loss: -10.6565	Cost: 8.75s
Train Epoch: 1764 [61440/90000 (68%)]	Loss: -10.7198	Cost: 11.64s
Train Epoch: 1764 [81920/90000 (91%)]	Loss: -10.4349	Cost: 13.15s
Train Epoch: 1764 	Average Loss: -10.1728
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8173

Learning rate: 9.251669280732104e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1765 [0/90000 (0%)]	Loss: -3.7043	Cost: 21.48s
Train Epoch: 1765 [20480/90000 (23%)]	Loss: -10.7446	Cost: 9.18s
Train Epoch: 1765 [40960/90000 (45%)]	Loss: -10.6610	Cost: 13.06s
Train Epoch: 1765 [61440/90000 (68%)]	Loss: -10.7665	Cost: 12.69s
Train Epoch: 1765 [81920/90000 (91%)]	Loss: -10.4171	Cost: 12.33s
Train Epoch: 1765 	Average Loss: -10.1880
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6748

Learning rate: 9.250842449410579e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1766 [0/90000 (0%)]	Loss: -3.6051	Cost: 39.98s
Train Epoch: 1766 [20480/90000 (23%)]	Loss: -10.5713	Cost: 12.41s
Train Epoch: 1766 [40960/90000 (45%)]	Loss: -10.7217	Cost: 12.68s
Train Epoch: 1766 [61440/90000 (68%)]	Loss: -10.7492	Cost: 12.22s
Train Epoch: 1766 [81920/90000 (91%)]	Loss: -10.5572	Cost: 7.80s
Train Epoch: 1766 	Average Loss: -10.2525
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8477

Learning rate: 9.250015198547725e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1767 [0/90000 (0%)]	Loss: -3.5167	Cost: 27.41s
Train Epoch: 1767 [20480/90000 (23%)]	Loss: -10.8333	Cost: 11.84s
Train Epoch: 1767 [40960/90000 (45%)]	Loss: -10.6864	Cost: 12.54s
Train Epoch: 1767 [61440/90000 (68%)]	Loss: -10.8316	Cost: 12.32s
Train Epoch: 1767 [81920/90000 (91%)]	Loss: -10.5977	Cost: 8.23s
Train Epoch: 1767 	Average Loss: -10.2578
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9700

Learning rate: 9.249187528225185e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1768 [0/90000 (0%)]	Loss: -3.4661	Cost: 25.11s
Train Epoch: 1768 [20480/90000 (23%)]	Loss: -10.6569	Cost: 11.04s
Train Epoch: 1768 [40960/90000 (45%)]	Loss: -10.9207	Cost: 12.36s
Train Epoch: 1768 [61440/90000 (68%)]	Loss: -10.8042	Cost: 6.43s
Train Epoch: 1768 [81920/90000 (91%)]	Loss: -9.7640	Cost: 6.16s
Train Epoch: 1768 	Average Loss: -10.0206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3930

Learning rate: 9.248359438524651e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1769 [0/90000 (0%)]	Loss: -3.8241	Cost: 22.13s
Train Epoch: 1769 [20480/90000 (23%)]	Loss: -10.3445	Cost: 6.63s
Train Epoch: 1769 [40960/90000 (45%)]	Loss: -10.6974	Cost: 9.06s
Train Epoch: 1769 [61440/90000 (68%)]	Loss: -10.7316	Cost: 8.73s
Train Epoch: 1769 [81920/90000 (91%)]	Loss: -10.3862	Cost: 9.15s
Train Epoch: 1769 	Average Loss: -10.0255
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7229

Learning rate: 9.247530929527849e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1770 [0/90000 (0%)]	Loss: -3.9172	Cost: 21.56s
Train Epoch: 1770 [20480/90000 (23%)]	Loss: -10.1081	Cost: 9.67s
Train Epoch: 1770 [40960/90000 (45%)]	Loss: -10.6044	Cost: 8.99s
Train Epoch: 1770 [61440/90000 (68%)]	Loss: -10.6272	Cost: 7.84s
Train Epoch: 1770 [81920/90000 (91%)]	Loss: -10.4511	Cost: 6.08s
Train Epoch: 1770 	Average Loss: -9.9644
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7106

Learning rate: 9.24670200131655e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1771 [0/90000 (0%)]	Loss: -3.9121	Cost: 23.22s
Train Epoch: 1771 [20480/90000 (23%)]	Loss: -10.3750	Cost: 7.73s
Train Epoch: 1771 [40960/90000 (45%)]	Loss: -10.9216	Cost: 6.28s
Train Epoch: 1771 [61440/90000 (68%)]	Loss: -10.7764	Cost: 6.82s
Train Epoch: 1771 [81920/90000 (91%)]	Loss: -10.6746	Cost: 13.71s
Train Epoch: 1771 	Average Loss: -10.1937
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9392

Learning rate: 9.24587265397257e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1772 [0/90000 (0%)]	Loss: -4.6832	Cost: 39.61s
Train Epoch: 1772 [20480/90000 (23%)]	Loss: -10.6591	Cost: 13.44s
Train Epoch: 1772 [40960/90000 (45%)]	Loss: -10.7138	Cost: 13.37s
Train Epoch: 1772 [61440/90000 (68%)]	Loss: -10.7461	Cost: 12.12s
Train Epoch: 1772 [81920/90000 (91%)]	Loss: -10.2719	Cost: 12.35s
Train Epoch: 1772 	Average Loss: -10.2355
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7963

Learning rate: 9.245042887577755e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1773 [0/90000 (0%)]	Loss: -4.3867	Cost: 28.80s
Train Epoch: 1773 [20480/90000 (23%)]	Loss: -10.4459	Cost: 13.29s
Train Epoch: 1773 [40960/90000 (45%)]	Loss: -10.7756	Cost: 12.48s
Train Epoch: 1773 [61440/90000 (68%)]	Loss: -11.0081	Cost: 10.04s
Train Epoch: 1773 [81920/90000 (91%)]	Loss: -10.6765	Cost: 7.71s
Train Epoch: 1773 	Average Loss: -10.2407
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9903

Learning rate: 9.244212702214006e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1774 [0/90000 (0%)]	Loss: -4.6529	Cost: 24.86s
Train Epoch: 1774 [20480/90000 (23%)]	Loss: -10.9490	Cost: 9.42s
Train Epoch: 1774 [40960/90000 (45%)]	Loss: -10.8381	Cost: 11.63s
Train Epoch: 1774 [61440/90000 (68%)]	Loss: -10.9868	Cost: 6.45s
Train Epoch: 1774 [81920/90000 (91%)]	Loss: -10.9632	Cost: 7.94s
Train Epoch: 1774 	Average Loss: -10.4513
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1791

Saving model as e1774_model.pt & e1774_waveforms_supplementary.hdf5
Learning rate: 9.243382097963258e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1775 [0/90000 (0%)]	Loss: -4.7152	Cost: 21.45s
Train Epoch: 1775 [20480/90000 (23%)]	Loss: -11.0087	Cost: 7.80s
Train Epoch: 1775 [40960/90000 (45%)]	Loss: -11.2436	Cost: 8.33s
Train Epoch: 1775 [61440/90000 (68%)]	Loss: -11.1774	Cost: 8.77s
Train Epoch: 1775 [81920/90000 (91%)]	Loss: -10.8641	Cost: 8.43s
Train Epoch: 1775 	Average Loss: -10.5605
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1016

Learning rate: 9.242551074907487e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1776 [0/90000 (0%)]	Loss: -4.4630	Cost: 26.22s
Train Epoch: 1776 [20480/90000 (23%)]	Loss: -10.8329	Cost: 7.82s
Train Epoch: 1776 [40960/90000 (45%)]	Loss: -10.8706	Cost: 8.89s
Train Epoch: 1776 [61440/90000 (68%)]	Loss: -11.0297	Cost: 8.83s
Train Epoch: 1776 [81920/90000 (91%)]	Loss: -10.6562	Cost: 8.76s
Train Epoch: 1776 	Average Loss: -10.3979
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9960

Learning rate: 9.241719633128709e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1777 [0/90000 (0%)]	Loss: -4.6632	Cost: 21.73s
Train Epoch: 1777 [20480/90000 (23%)]	Loss: -10.8357	Cost: 9.33s
Train Epoch: 1777 [40960/90000 (45%)]	Loss: -11.2748	Cost: 8.06s
Train Epoch: 1777 [61440/90000 (68%)]	Loss: -11.0896	Cost: 6.36s
Train Epoch: 1777 [81920/90000 (91%)]	Loss: -10.8551	Cost: 6.41s
Train Epoch: 1777 	Average Loss: -10.5107
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1109

Learning rate: 9.240887772708989e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1778 [0/90000 (0%)]	Loss: -3.7923	Cost: 21.96s
Train Epoch: 1778 [20480/90000 (23%)]	Loss: -10.8430	Cost: 9.72s
Train Epoch: 1778 [40960/90000 (45%)]	Loss: -10.8089	Cost: 13.41s
Train Epoch: 1778 [61440/90000 (68%)]	Loss: -10.9595	Cost: 13.99s
Train Epoch: 1778 [81920/90000 (91%)]	Loss: -10.9160	Cost: 12.44s
Train Epoch: 1778 	Average Loss: -10.4671
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1268

Learning rate: 9.240055493730426e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1779 [0/90000 (0%)]	Loss: -3.9734	Cost: 24.50s
Train Epoch: 1779 [20480/90000 (23%)]	Loss: -10.6425	Cost: 14.63s
Train Epoch: 1779 [40960/90000 (45%)]	Loss: -10.8787	Cost: 15.33s
Train Epoch: 1779 [61440/90000 (68%)]	Loss: -11.0796	Cost: 12.24s
Train Epoch: 1779 [81920/90000 (91%)]	Loss: -10.9081	Cost: 9.95s
Train Epoch: 1779 	Average Loss: -10.4968
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0913

Learning rate: 9.239222796275163e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1780 [0/90000 (0%)]	Loss: -4.5568	Cost: 27.37s
Train Epoch: 1780 [20480/90000 (23%)]	Loss: -10.9334	Cost: 13.87s
Train Epoch: 1780 [40960/90000 (45%)]	Loss: -11.0710	Cost: 12.36s
Train Epoch: 1780 [61440/90000 (68%)]	Loss: -11.2669	Cost: 11.26s
Train Epoch: 1780 [81920/90000 (91%)]	Loss: -10.6923	Cost: 6.04s
Train Epoch: 1780 	Average Loss: -10.4761
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1028

Learning rate: 9.238389680425384e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1781 [0/90000 (0%)]	Loss: -4.4505	Cost: 30.02s
Train Epoch: 1781 [20480/90000 (23%)]	Loss: -10.8854	Cost: 12.84s
Train Epoch: 1781 [40960/90000 (45%)]	Loss: -10.9366	Cost: 12.28s
Train Epoch: 1781 [61440/90000 (68%)]	Loss: -11.1362	Cost: 7.09s
Train Epoch: 1781 [81920/90000 (91%)]	Loss: -10.7552	Cost: 6.05s
Train Epoch: 1781 	Average Loss: -10.5195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9436

Learning rate: 9.237556146263314e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1782 [0/90000 (0%)]	Loss: -3.9085	Cost: 32.97s
Train Epoch: 1782 [20480/90000 (23%)]	Loss: -10.6889	Cost: 10.64s
Train Epoch: 1782 [40960/90000 (45%)]	Loss: -11.0216	Cost: 10.98s
Train Epoch: 1782 [61440/90000 (68%)]	Loss: -11.0550	Cost: 6.26s
Train Epoch: 1782 [81920/90000 (91%)]	Loss: -10.8357	Cost: 6.85s
Train Epoch: 1782 	Average Loss: -10.4496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1599

Learning rate: 9.236722193871219e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1783 [0/90000 (0%)]	Loss: -4.6922	Cost: 33.48s
Train Epoch: 1783 [20480/90000 (23%)]	Loss: -10.9102	Cost: 11.61s
Train Epoch: 1783 [40960/90000 (45%)]	Loss: -10.9933	Cost: 6.45s
Train Epoch: 1783 [61440/90000 (68%)]	Loss: -10.9526	Cost: 6.31s
Train Epoch: 1783 [81920/90000 (91%)]	Loss: -9.8697	Cost: 8.79s
Train Epoch: 1783 	Average Loss: -10.3046
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4909

Learning rate: 9.235887823331407e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1784 [0/90000 (0%)]	Loss: -4.5826	Cost: 20.09s
Train Epoch: 1784 [20480/90000 (23%)]	Loss: -10.3582	Cost: 6.68s
Train Epoch: 1784 [40960/90000 (45%)]	Loss: -10.6593	Cost: 8.89s
Train Epoch: 1784 [61440/90000 (68%)]	Loss: -10.5465	Cost: 8.89s
Train Epoch: 1784 [81920/90000 (91%)]	Loss: -10.3268	Cost: 8.44s
Train Epoch: 1784 	Average Loss: -10.0217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8727

Learning rate: 9.235053034726228e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1785 [0/90000 (0%)]	Loss: -3.7459	Cost: 22.54s
Train Epoch: 1785 [20480/90000 (23%)]	Loss: -10.6382	Cost: 8.21s
Train Epoch: 1785 [40960/90000 (45%)]	Loss: -10.9288	Cost: 8.86s
Train Epoch: 1785 [61440/90000 (68%)]	Loss: -11.1751	Cost: 8.79s
Train Epoch: 1785 [81920/90000 (91%)]	Loss: -10.8357	Cost: 9.15s
Train Epoch: 1785 	Average Loss: -10.3935
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2806

Saving model as e1785_model.pt & e1785_waveforms_supplementary.hdf5
Learning rate: 9.234217828138071e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1786 [0/90000 (0%)]	Loss: -4.5499	Cost: 27.96s
Train Epoch: 1786 [20480/90000 (23%)]	Loss: -10.9061	Cost: 9.00s
Train Epoch: 1786 [40960/90000 (45%)]	Loss: -11.0608	Cost: 7.34s
Train Epoch: 1786 [61440/90000 (68%)]	Loss: -11.1919	Cost: 6.39s
Train Epoch: 1786 [81920/90000 (91%)]	Loss: -10.9471	Cost: 6.53s
Train Epoch: 1786 	Average Loss: -10.6022
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1120

Learning rate: 9.23338220364937e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1787 [0/90000 (0%)]	Loss: -4.4955	Cost: 31.16s
Train Epoch: 1787 [20480/90000 (23%)]	Loss: -10.5493	Cost: 9.83s
Train Epoch: 1787 [40960/90000 (45%)]	Loss: -10.9908	Cost: 14.96s
Train Epoch: 1787 [61440/90000 (68%)]	Loss: -10.9121	Cost: 13.02s
Train Epoch: 1787 [81920/90000 (91%)]	Loss: -10.8122	Cost: 12.43s
Train Epoch: 1787 	Average Loss: -10.4743
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1573

Learning rate: 9.232546161342596e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1788 [0/90000 (0%)]	Loss: -5.1700	Cost: 26.02s
Train Epoch: 1788 [20480/90000 (23%)]	Loss: -11.0099	Cost: 13.31s
Train Epoch: 1788 [40960/90000 (45%)]	Loss: -11.0514	Cost: 13.21s
Train Epoch: 1788 [61440/90000 (68%)]	Loss: -11.1437	Cost: 12.34s
Train Epoch: 1788 [81920/90000 (91%)]	Loss: -10.8711	Cost: 12.30s
Train Epoch: 1788 	Average Loss: -10.5997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1983

Learning rate: 9.231709701300262e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1789 [0/90000 (0%)]	Loss: -4.8122	Cost: 30.97s
Train Epoch: 1789 [20480/90000 (23%)]	Loss: -10.9715	Cost: 12.49s
Train Epoch: 1789 [40960/90000 (45%)]	Loss: -10.6966	Cost: 11.66s
Train Epoch: 1789 [61440/90000 (68%)]	Loss: -11.2573	Cost: 8.30s
Train Epoch: 1789 [81920/90000 (91%)]	Loss: -10.6571	Cost: 7.78s
Train Epoch: 1789 	Average Loss: -10.5252
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0933

Learning rate: 9.230872823604925e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1790 [0/90000 (0%)]	Loss: -4.9042	Cost: 20.09s
Train Epoch: 1790 [20480/90000 (23%)]	Loss: -10.8681	Cost: 7.88s
Train Epoch: 1790 [40960/90000 (45%)]	Loss: -11.3284	Cost: 10.49s
Train Epoch: 1790 [61440/90000 (68%)]	Loss: -11.2713	Cost: 8.86s
Train Epoch: 1790 [81920/90000 (91%)]	Loss: -10.8529	Cost: 8.69s
Train Epoch: 1790 	Average Loss: -10.5573
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1471

Learning rate: 9.23003552833918e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1791 [0/90000 (0%)]	Loss: -4.6464	Cost: 23.76s
Train Epoch: 1791 [20480/90000 (23%)]	Loss: -11.2436	Cost: 8.94s
Train Epoch: 1791 [40960/90000 (45%)]	Loss: -11.2832	Cost: 8.43s
Train Epoch: 1791 [61440/90000 (68%)]	Loss: -11.2163	Cost: 9.12s
Train Epoch: 1791 [81920/90000 (91%)]	Loss: -11.0600	Cost: 8.51s
Train Epoch: 1791 	Average Loss: -10.6776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1901

Learning rate: 9.229197815585665e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1792 [0/90000 (0%)]	Loss: -5.0333	Cost: 24.61s
Train Epoch: 1792 [20480/90000 (23%)]	Loss: -10.7959	Cost: 8.75s
Train Epoch: 1792 [40960/90000 (45%)]	Loss: -11.1598	Cost: 8.86s
Train Epoch: 1792 [61440/90000 (68%)]	Loss: -11.0869	Cost: 8.67s
Train Epoch: 1792 [81920/90000 (91%)]	Loss: -10.6509	Cost: 8.46s
Train Epoch: 1792 	Average Loss: -10.5550
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2056

Learning rate: 9.228359685427062e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1793 [0/90000 (0%)]	Loss: -4.6532	Cost: 20.68s
Train Epoch: 1793 [20480/90000 (23%)]	Loss: -11.2446	Cost: 9.16s
Train Epoch: 1793 [40960/90000 (45%)]	Loss: -11.2928	Cost: 8.85s
Train Epoch: 1793 [61440/90000 (68%)]	Loss: -11.2258	Cost: 8.93s
Train Epoch: 1793 [81920/90000 (91%)]	Loss: -10.9258	Cost: 7.04s
Train Epoch: 1793 	Average Loss: -10.6404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1884

Learning rate: 9.227521137946087e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1794 [0/90000 (0%)]	Loss: -5.0493	Cost: 18.85s
Train Epoch: 1794 [20480/90000 (23%)]	Loss: -11.0638	Cost: 6.84s
Train Epoch: 1794 [40960/90000 (45%)]	Loss: -11.4924	Cost: 11.08s
Train Epoch: 1794 [61440/90000 (68%)]	Loss: -11.4281	Cost: 13.63s
Train Epoch: 1794 [81920/90000 (91%)]	Loss: -10.8369	Cost: 14.63s
Train Epoch: 1794 	Average Loss: -10.7604
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1600

Learning rate: 9.226682173225505e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1795 [0/90000 (0%)]	Loss: -4.8435	Cost: 20.81s
Train Epoch: 1795 [20480/90000 (23%)]	Loss: -10.9973	Cost: 8.20s
Train Epoch: 1795 [40960/90000 (45%)]	Loss: -11.1506	Cost: 15.90s
Train Epoch: 1795 [61440/90000 (68%)]	Loss: -11.3820	Cost: 13.13s
Train Epoch: 1795 [81920/90000 (91%)]	Loss: -10.9856	Cost: 12.36s
Train Epoch: 1795 	Average Loss: -10.6106
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3070

Saving model as e1795_model.pt & e1795_waveforms_supplementary.hdf5
Learning rate: 9.225842791348115e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1796 [0/90000 (0%)]	Loss: -4.0242	Cost: 39.84s
Train Epoch: 1796 [20480/90000 (23%)]	Loss: -11.1272	Cost: 12.53s
Train Epoch: 1796 [40960/90000 (45%)]	Loss: -11.2580	Cost: 12.40s
Train Epoch: 1796 [61440/90000 (68%)]	Loss: -11.0923	Cost: 10.81s
Train Epoch: 1796 [81920/90000 (91%)]	Loss: -10.9902	Cost: 6.10s
Train Epoch: 1796 	Average Loss: -10.6296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2020

Learning rate: 9.225002992396763e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1797 [0/90000 (0%)]	Loss: -4.8475	Cost: 29.61s
Train Epoch: 1797 [20480/90000 (23%)]	Loss: -11.1908	Cost: 12.34s
Train Epoch: 1797 [40960/90000 (45%)]	Loss: -11.3245	Cost: 6.81s
Train Epoch: 1797 [61440/90000 (68%)]	Loss: -11.4132	Cost: 6.34s
Train Epoch: 1797 [81920/90000 (91%)]	Loss: -10.9374	Cost: 8.62s
Train Epoch: 1797 	Average Loss: -10.7123
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4350

Saving model as e1797_model.pt & e1797_waveforms_supplementary.hdf5
Learning rate: 9.224162776454334e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1798 [0/90000 (0%)]	Loss: -4.6957	Cost: 24.19s
Train Epoch: 1798 [20480/90000 (23%)]	Loss: -11.1364	Cost: 10.10s
Train Epoch: 1798 [40960/90000 (45%)]	Loss: -11.4163	Cost: 9.48s
Train Epoch: 1798 [61440/90000 (68%)]	Loss: -11.4207	Cost: 8.92s
Train Epoch: 1798 [81920/90000 (91%)]	Loss: -11.1705	Cost: 8.76s
Train Epoch: 1798 	Average Loss: -10.7455
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2696

Learning rate: 9.223322143603753e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1799 [0/90000 (0%)]	Loss: -4.5563	Cost: 31.14s
Train Epoch: 1799 [20480/90000 (23%)]	Loss: -11.1544	Cost: 7.49s
Train Epoch: 1799 [40960/90000 (45%)]	Loss: -11.4891	Cost: 8.55s
Train Epoch: 1799 [61440/90000 (68%)]	Loss: -11.3407	Cost: 7.42s
Train Epoch: 1799 [81920/90000 (91%)]	Loss: -11.0275	Cost: 15.82s
Train Epoch: 1799 	Average Loss: -10.7884
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2770

Learning rate: 9.222481093927987e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1800 [0/90000 (0%)]	Loss: -4.2331	Cost: 21.60s
Train Epoch: 1800 [20480/90000 (23%)]	Loss: -11.1261	Cost: 7.30s
Train Epoch: 1800 [40960/90000 (45%)]	Loss: -11.4148	Cost: 12.80s
Train Epoch: 1800 [61440/90000 (68%)]	Loss: -11.3738	Cost: 12.71s
Train Epoch: 1800 [81920/90000 (91%)]	Loss: -11.2011	Cost: 12.35s
Train Epoch: 1800 	Average Loss: -10.8457
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3246

Learning rate: 9.221639627510043e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1801 [0/90000 (0%)]	Loss: -5.0707	Cost: 25.52s
Train Epoch: 1801 [20480/90000 (23%)]	Loss: -11.2005	Cost: 13.07s
Train Epoch: 1801 [40960/90000 (45%)]	Loss: -11.3134	Cost: 12.46s
Train Epoch: 1801 [61440/90000 (68%)]	Loss: -11.3949	Cost: 12.15s
Train Epoch: 1801 [81920/90000 (91%)]	Loss: -10.9643	Cost: 10.96s
Train Epoch: 1801 	Average Loss: -10.7255
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2496

Learning rate: 9.220797744432973e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1802 [0/90000 (0%)]	Loss: -5.0717	Cost: 23.49s
Train Epoch: 1802 [20480/90000 (23%)]	Loss: -10.9797	Cost: 13.33s
Train Epoch: 1802 [40960/90000 (45%)]	Loss: -11.1822	Cost: 11.12s
Train Epoch: 1802 [61440/90000 (68%)]	Loss: -11.2325	Cost: 6.33s
Train Epoch: 1802 [81920/90000 (91%)]	Loss: -11.1536	Cost: 6.52s
Train Epoch: 1802 	Average Loss: -10.7451
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5487

Saving model as e1802_model.pt & e1802_waveforms_supplementary.hdf5
Learning rate: 9.219955444779867e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1803 [0/90000 (0%)]	Loss: -5.3395	Cost: 35.40s
Train Epoch: 1803 [20480/90000 (23%)]	Loss: -11.4824	Cost: 10.46s
Train Epoch: 1803 [40960/90000 (45%)]	Loss: -11.4875	Cost: 9.10s
Train Epoch: 1803 [61440/90000 (68%)]	Loss: -11.4011	Cost: 8.69s
Train Epoch: 1803 [81920/90000 (91%)]	Loss: -11.0813	Cost: 8.61s
Train Epoch: 1803 	Average Loss: -10.8921
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4098

Learning rate: 9.219112728633856e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1804 [0/90000 (0%)]	Loss: -4.9110	Cost: 33.16s
Train Epoch: 1804 [20480/90000 (23%)]	Loss: -11.4671	Cost: 8.77s
Train Epoch: 1804 [40960/90000 (45%)]	Loss: -11.5099	Cost: 8.87s
Train Epoch: 1804 [61440/90000 (68%)]	Loss: -11.4581	Cost: 6.19s
Train Epoch: 1804 [81920/90000 (91%)]	Loss: -11.1465	Cost: 6.67s
Train Epoch: 1804 	Average Loss: -10.8963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3844

Learning rate: 9.218269596078113e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1805 [0/90000 (0%)]	Loss: -4.2769	Cost: 18.58s
Train Epoch: 1805 [20480/90000 (23%)]	Loss: -10.9720	Cost: 8.06s
Train Epoch: 1805 [40960/90000 (45%)]	Loss: -11.0247	Cost: 12.41s
Train Epoch: 1805 [61440/90000 (68%)]	Loss: -11.1762	Cost: 11.90s
Train Epoch: 1805 [81920/90000 (91%)]	Loss: -10.9609	Cost: 12.93s
Train Epoch: 1805 	Average Loss: -10.5682
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3436

Learning rate: 9.217426047195853e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1806 [0/90000 (0%)]	Loss: -4.8389	Cost: 22.95s
Train Epoch: 1806 [20480/90000 (23%)]	Loss: -11.1966	Cost: 10.21s
Train Epoch: 1806 [40960/90000 (45%)]	Loss: -11.3315	Cost: 12.53s
Train Epoch: 1806 [61440/90000 (68%)]	Loss: -11.4674	Cost: 12.40s
Train Epoch: 1806 [81920/90000 (91%)]	Loss: -11.2637	Cost: 12.63s
Train Epoch: 1806 	Average Loss: -10.8063
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4143

Learning rate: 9.216582082070327e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1807 [0/90000 (0%)]	Loss: -4.6339	Cost: 24.13s
Train Epoch: 1807 [20480/90000 (23%)]	Loss: -11.0792	Cost: 14.88s
Train Epoch: 1807 [40960/90000 (45%)]	Loss: -11.3698	Cost: 13.19s
Train Epoch: 1807 [61440/90000 (68%)]	Loss: -11.5179	Cost: 12.15s
Train Epoch: 1807 [81920/90000 (91%)]	Loss: -11.1838	Cost: 8.33s
Train Epoch: 1807 	Average Loss: -10.8091
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3984

Learning rate: 9.215737700784834e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1808 [0/90000 (0%)]	Loss: -4.4232	Cost: 34.70s
Train Epoch: 1808 [20480/90000 (23%)]	Loss: -11.0182	Cost: 13.09s
Train Epoch: 1808 [40960/90000 (45%)]	Loss: -10.9761	Cost: 12.42s
Train Epoch: 1808 [61440/90000 (68%)]	Loss: -10.9140	Cost: 6.67s
Train Epoch: 1808 [81920/90000 (91%)]	Loss: -11.0049	Cost: 6.16s
Train Epoch: 1808 	Average Loss: -10.5194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3797

Learning rate: 9.214892903422712e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1809 [0/90000 (0%)]	Loss: -4.3651	Cost: 37.92s
Train Epoch: 1809 [20480/90000 (23%)]	Loss: -10.8608	Cost: 11.62s
Train Epoch: 1809 [40960/90000 (45%)]	Loss: -11.0125	Cost: 6.98s
Train Epoch: 1809 [61440/90000 (68%)]	Loss: -11.3376	Cost: 7.03s
Train Epoch: 1809 [81920/90000 (91%)]	Loss: -11.1959	Cost: 8.80s
Train Epoch: 1809 	Average Loss: -10.6872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4744

Learning rate: 9.214047690067338e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1810 [0/90000 (0%)]	Loss: -4.3293	Cost: 26.75s
Train Epoch: 1810 [20480/90000 (23%)]	Loss: -11.2217	Cost: 6.53s
Train Epoch: 1810 [40960/90000 (45%)]	Loss: -11.2214	Cost: 9.35s
Train Epoch: 1810 [61440/90000 (68%)]	Loss: -10.3472	Cost: 8.85s
Train Epoch: 1810 [81920/90000 (91%)]	Loss: -10.0295	Cost: 8.99s
Train Epoch: 1810 	Average Loss: -10.4586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7456

Learning rate: 9.213202060802132e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1811 [0/90000 (0%)]	Loss: -4.7941	Cost: 20.49s
Train Epoch: 1811 [20480/90000 (23%)]	Loss: -10.6588	Cost: 7.87s
Train Epoch: 1811 [40960/90000 (45%)]	Loss: -11.1900	Cost: 9.11s
Train Epoch: 1811 [61440/90000 (68%)]	Loss: -11.0783	Cost: 8.70s
Train Epoch: 1811 [81920/90000 (91%)]	Loss: -10.8828	Cost: 8.57s
Train Epoch: 1811 	Average Loss: -10.4938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5288

Learning rate: 9.212356015710551e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1812 [0/90000 (0%)]	Loss: -5.0893	Cost: 21.23s
Train Epoch: 1812 [20480/90000 (23%)]	Loss: -11.2647	Cost: 9.15s
Train Epoch: 1812 [40960/90000 (45%)]	Loss: -11.3340	Cost: 9.12s
Train Epoch: 1812 [61440/90000 (68%)]	Loss: -11.3836	Cost: 8.68s
Train Epoch: 1812 [81920/90000 (91%)]	Loss: -10.9500	Cost: 6.59s
Train Epoch: 1812 	Average Loss: -10.7902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2777

Learning rate: 9.2115095548761e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1813 [0/90000 (0%)]	Loss: -4.9508	Cost: 21.73s
Train Epoch: 1813 [20480/90000 (23%)]	Loss: -11.3532	Cost: 10.50s
Train Epoch: 1813 [40960/90000 (45%)]	Loss: -11.3127	Cost: 13.14s
Train Epoch: 1813 [61440/90000 (68%)]	Loss: -11.3072	Cost: 12.68s
Train Epoch: 1813 [81920/90000 (91%)]	Loss: -11.1938	Cost: 12.37s
Train Epoch: 1813 	Average Loss: -10.8137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4360

Learning rate: 9.210662678382321e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1814 [0/90000 (0%)]	Loss: -5.3233	Cost: 25.14s
Train Epoch: 1814 [20480/90000 (23%)]	Loss: -11.6376	Cost: 12.13s
Train Epoch: 1814 [40960/90000 (45%)]	Loss: -11.5806	Cost: 15.13s
Train Epoch: 1814 [61440/90000 (68%)]	Loss: -11.4530	Cost: 12.76s
Train Epoch: 1814 [81920/90000 (91%)]	Loss: -10.7650	Cost: 12.31s
Train Epoch: 1814 	Average Loss: -10.8607
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2796

Learning rate: 9.209815386312794e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1815 [0/90000 (0%)]	Loss: -5.4072	Cost: 29.57s
Train Epoch: 1815 [20480/90000 (23%)]	Loss: -11.3179	Cost: 13.14s
Train Epoch: 1815 [40960/90000 (45%)]	Loss: -11.5060	Cost: 13.63s
Train Epoch: 1815 [61440/90000 (68%)]	Loss: -11.6472	Cost: 12.25s
Train Epoch: 1815 [81920/90000 (91%)]	Loss: -11.3888	Cost: 10.18s
Train Epoch: 1815 	Average Loss: -10.8857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6389

Saving model as e1815_model.pt & e1815_waveforms_supplementary.hdf5
Learning rate: 9.208967678751147e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1816 [0/90000 (0%)]	Loss: -5.2828	Cost: 25.81s
Train Epoch: 1816 [20480/90000 (23%)]	Loss: -11.3271	Cost: 11.38s
Train Epoch: 1816 [40960/90000 (45%)]	Loss: -11.4218	Cost: 8.42s
Train Epoch: 1816 [61440/90000 (68%)]	Loss: -11.4389	Cost: 7.12s
Train Epoch: 1816 [81920/90000 (91%)]	Loss: -11.3485	Cost: 8.92s
Train Epoch: 1816 	Average Loss: -10.9507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4043

Learning rate: 9.208119555781044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1817 [0/90000 (0%)]	Loss: -5.3176	Cost: 20.77s
Train Epoch: 1817 [20480/90000 (23%)]	Loss: -11.4475	Cost: 7.43s
Train Epoch: 1817 [40960/90000 (45%)]	Loss: -11.4639	Cost: 9.44s
Train Epoch: 1817 [61440/90000 (68%)]	Loss: -11.3232	Cost: 8.88s
Train Epoch: 1817 [81920/90000 (91%)]	Loss: -11.0638	Cost: 8.76s
Train Epoch: 1817 	Average Loss: -10.9008
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2937

Learning rate: 9.20727101748619e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1818 [0/90000 (0%)]	Loss: -4.5419	Cost: 24.73s
Train Epoch: 1818 [20480/90000 (23%)]	Loss: -11.1916	Cost: 7.65s
Train Epoch: 1818 [40960/90000 (45%)]	Loss: -11.6070	Cost: 10.81s
Train Epoch: 1818 [61440/90000 (68%)]	Loss: -11.6609	Cost: 8.53s
Train Epoch: 1818 [81920/90000 (91%)]	Loss: -11.3849	Cost: 13.09s
Train Epoch: 1818 	Average Loss: -10.9460
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4177

Learning rate: 9.206422063950336e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1819 [0/90000 (0%)]	Loss: -5.3227	Cost: 23.10s
Train Epoch: 1819 [20480/90000 (23%)]	Loss: -11.4314	Cost: 7.55s
Train Epoch: 1819 [40960/90000 (45%)]	Loss: -11.2106	Cost: 12.19s
Train Epoch: 1819 [61440/90000 (68%)]	Loss: -11.3749	Cost: 12.51s
Train Epoch: 1819 [81920/90000 (91%)]	Loss: -10.9480	Cost: 12.46s
Train Epoch: 1819 	Average Loss: -10.7838
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1025

Learning rate: 9.205572695257268e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1820 [0/90000 (0%)]	Loss: -3.9377	Cost: 30.67s
Train Epoch: 1820 [20480/90000 (23%)]	Loss: -11.0596	Cost: 13.09s
Train Epoch: 1820 [40960/90000 (45%)]	Loss: -11.3060	Cost: 12.58s
Train Epoch: 1820 [61440/90000 (68%)]	Loss: -11.6335	Cost: 12.30s
Train Epoch: 1820 [81920/90000 (91%)]	Loss: -11.3417	Cost: 12.41s
Train Epoch: 1820 	Average Loss: -10.7415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5999

Learning rate: 9.204722911490815e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1821 [0/90000 (0%)]	Loss: -4.6773	Cost: 29.17s
Train Epoch: 1821 [20480/90000 (23%)]	Loss: -11.2545	Cost: 10.96s
Train Epoch: 1821 [40960/90000 (45%)]	Loss: -11.4640	Cost: 14.65s
Train Epoch: 1821 [61440/90000 (68%)]	Loss: -11.3868	Cost: 12.45s
Train Epoch: 1821 [81920/90000 (91%)]	Loss: -11.0856	Cost: 11.28s
Train Epoch: 1821 	Average Loss: -10.8463
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5008

Learning rate: 9.203872712734849e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1822 [0/90000 (0%)]	Loss: -4.8564	Cost: 23.91s
Train Epoch: 1822 [20480/90000 (23%)]	Loss: -11.3205	Cost: 12.78s
Train Epoch: 1822 [40960/90000 (45%)]	Loss: -11.2988	Cost: 15.16s
Train Epoch: 1822 [61440/90000 (68%)]	Loss: -11.2755	Cost: 12.57s
Train Epoch: 1822 [81920/90000 (91%)]	Loss: -10.6061	Cost: 6.55s
Train Epoch: 1822 	Average Loss: -10.6974
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0146

Learning rate: 9.203022099073279e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1823 [0/90000 (0%)]	Loss: -4.3123	Cost: 28.15s
Train Epoch: 1823 [20480/90000 (23%)]	Loss: -10.8735	Cost: 12.32s
Train Epoch: 1823 [40960/90000 (45%)]	Loss: -11.3908	Cost: 6.87s
Train Epoch: 1823 [61440/90000 (68%)]	Loss: -11.4936	Cost: 6.36s
Train Epoch: 1823 [81920/90000 (91%)]	Loss: -11.0374	Cost: 8.29s
Train Epoch: 1823 	Average Loss: -10.7229
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3252

Learning rate: 9.202171070590059e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1824 [0/90000 (0%)]	Loss: -4.2154	Cost: 29.08s
Train Epoch: 1824 [20480/90000 (23%)]	Loss: -11.3072	Cost: 6.44s
Train Epoch: 1824 [40960/90000 (45%)]	Loss: -11.4346	Cost: 9.41s
Train Epoch: 1824 [61440/90000 (68%)]	Loss: -11.3346	Cost: 8.69s
Train Epoch: 1824 [81920/90000 (91%)]	Loss: -11.1343	Cost: 8.82s
Train Epoch: 1824 	Average Loss: -10.7918
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4909

Learning rate: 9.201319627369181e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1825 [0/90000 (0%)]	Loss: -4.3264	Cost: 22.72s
Train Epoch: 1825 [20480/90000 (23%)]	Loss: -11.4701	Cost: 7.88s
Train Epoch: 1825 [40960/90000 (45%)]	Loss: -11.5322	Cost: 9.04s
Train Epoch: 1825 [61440/90000 (68%)]	Loss: -11.2997	Cost: 8.63s
Train Epoch: 1825 [81920/90000 (91%)]	Loss: -11.1192	Cost: 8.44s
Train Epoch: 1825 	Average Loss: -10.8935
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3517

Learning rate: 9.20046776949468e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1826 [0/90000 (0%)]	Loss: -4.6278	Cost: 25.04s
Train Epoch: 1826 [20480/90000 (23%)]	Loss: -11.4170	Cost: 9.80s
Train Epoch: 1826 [40960/90000 (45%)]	Loss: -11.6726	Cost: 10.94s
Train Epoch: 1826 [61440/90000 (68%)]	Loss: -11.5701	Cost: 6.64s
Train Epoch: 1826 [81920/90000 (91%)]	Loss: -11.2641	Cost: 9.56s
Train Epoch: 1826 	Average Loss: -10.9653
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5671

Learning rate: 9.199615497050631e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1827 [0/90000 (0%)]	Loss: -4.0689	Cost: 18.14s
Train Epoch: 1827 [20480/90000 (23%)]	Loss: -11.4643	Cost: 8.73s
Train Epoch: 1827 [40960/90000 (45%)]	Loss: -11.3990	Cost: 9.87s
Train Epoch: 1827 [61440/90000 (68%)]	Loss: -11.4571	Cost: 13.92s
Train Epoch: 1827 [81920/90000 (91%)]	Loss: -10.9724	Cost: 14.16s
Train Epoch: 1827 	Average Loss: -10.8725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2209

Learning rate: 9.198762810121149e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1828 [0/90000 (0%)]	Loss: -4.1878	Cost: 22.18s
Train Epoch: 1828 [20480/90000 (23%)]	Loss: -11.4579	Cost: 14.02s
Train Epoch: 1828 [40960/90000 (45%)]	Loss: -11.1770	Cost: 14.62s
Train Epoch: 1828 [61440/90000 (68%)]	Loss: -11.2229	Cost: 12.18s
Train Epoch: 1828 [81920/90000 (91%)]	Loss: -11.1656	Cost: 12.14s
Train Epoch: 1828 	Average Loss: -10.7343
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3043

Learning rate: 9.19790970879039e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1829 [0/90000 (0%)]	Loss: -4.9921	Cost: 37.28s
Train Epoch: 1829 [20480/90000 (23%)]	Loss: -11.4358	Cost: 11.57s
Train Epoch: 1829 [40960/90000 (45%)]	Loss: -11.4369	Cost: 12.41s
Train Epoch: 1829 [61440/90000 (68%)]	Loss: -11.1328	Cost: 11.89s
Train Epoch: 1829 [81920/90000 (91%)]	Loss: -10.9142	Cost: 6.35s
Train Epoch: 1829 	Average Loss: -10.8171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2216

Learning rate: 9.197056193142553e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1830 [0/90000 (0%)]	Loss: -3.7964	Cost: 26.68s
Train Epoch: 1830 [20480/90000 (23%)]	Loss: -11.2482	Cost: 12.18s
Train Epoch: 1830 [40960/90000 (45%)]	Loss: -11.3258	Cost: 6.89s
Train Epoch: 1830 [61440/90000 (68%)]	Loss: -11.6131	Cost: 6.26s
Train Epoch: 1830 [81920/90000 (91%)]	Loss: -11.3471	Cost: 8.37s
Train Epoch: 1830 	Average Loss: -10.9392
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4715

Learning rate: 9.196202263261877e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1831 [0/90000 (0%)]	Loss: -4.5849	Cost: 21.31s
Train Epoch: 1831 [20480/90000 (23%)]	Loss: -11.3242	Cost: 7.76s
Train Epoch: 1831 [40960/90000 (45%)]	Loss: -11.4271	Cost: 11.32s
Train Epoch: 1831 [61440/90000 (68%)]	Loss: -11.3550	Cost: 8.97s
Train Epoch: 1831 [81920/90000 (91%)]	Loss: -11.2432	Cost: 8.77s
Train Epoch: 1831 	Average Loss: -10.9400
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4985

Learning rate: 9.195347919232642e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1832 [0/90000 (0%)]	Loss: -5.2732	Cost: 22.93s
Train Epoch: 1832 [20480/90000 (23%)]	Loss: -11.5127	Cost: 11.86s
Train Epoch: 1832 [40960/90000 (45%)]	Loss: -11.5390	Cost: 10.60s
Train Epoch: 1832 [61440/90000 (68%)]	Loss: -11.5669	Cost: 8.84s
Train Epoch: 1832 [81920/90000 (91%)]	Loss: -11.1599	Cost: 6.90s
Train Epoch: 1832 	Average Loss: -11.0585
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4432

Learning rate: 9.19449316113917e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1833 [0/90000 (0%)]	Loss: -5.1797	Cost: 21.22s
Train Epoch: 1833 [20480/90000 (23%)]	Loss: -11.6664	Cost: 6.51s
Train Epoch: 1833 [40960/90000 (45%)]	Loss: -11.5524	Cost: 14.07s
Train Epoch: 1833 [61440/90000 (68%)]	Loss: -11.5758	Cost: 10.61s
Train Epoch: 1833 [81920/90000 (91%)]	Loss: -11.3148	Cost: 12.34s
Train Epoch: 1833 	Average Loss: -11.0364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4309

Learning rate: 9.193637989065816e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1834 [0/90000 (0%)]	Loss: -4.8163	Cost: 22.35s
Train Epoch: 1834 [20480/90000 (23%)]	Loss: -11.1095	Cost: 7.09s
Train Epoch: 1834 [40960/90000 (45%)]	Loss: -11.2898	Cost: 12.00s
Train Epoch: 1834 [61440/90000 (68%)]	Loss: -11.3962	Cost: 12.85s
Train Epoch: 1834 [81920/90000 (91%)]	Loss: -11.3896	Cost: 12.42s
Train Epoch: 1834 	Average Loss: -10.8978
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5784

Learning rate: 9.192782403096989e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1835 [0/90000 (0%)]	Loss: -5.2165	Cost: 29.01s
Train Epoch: 1835 [20480/90000 (23%)]	Loss: -11.4051	Cost: 12.58s
Train Epoch: 1835 [40960/90000 (45%)]	Loss: -11.4491	Cost: 12.36s
Train Epoch: 1835 [61440/90000 (68%)]	Loss: -11.5109	Cost: 12.31s
Train Epoch: 1835 [81920/90000 (91%)]	Loss: -11.2476	Cost: 8.86s
Train Epoch: 1835 	Average Loss: -10.9654
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5568

Learning rate: 9.191926403317126e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1836 [0/90000 (0%)]	Loss: -4.8143	Cost: 23.65s
Train Epoch: 1836 [20480/90000 (23%)]	Loss: -11.3167	Cost: 13.27s
Train Epoch: 1836 [40960/90000 (45%)]	Loss: -11.4665	Cost: 11.10s
Train Epoch: 1836 [61440/90000 (68%)]	Loss: -11.6097	Cost: 6.32s
Train Epoch: 1836 [81920/90000 (91%)]	Loss: -11.3904	Cost: 6.26s
Train Epoch: 1836 	Average Loss: -10.9463
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5614

Learning rate: 9.191069989810715e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1837 [0/90000 (0%)]	Loss: -5.0800	Cost: 28.28s
Train Epoch: 1837 [20480/90000 (23%)]	Loss: -11.1830	Cost: 12.29s
Train Epoch: 1837 [40960/90000 (45%)]	Loss: -11.2277	Cost: 11.51s
Train Epoch: 1837 [61440/90000 (68%)]	Loss: -11.3255	Cost: 7.49s
Train Epoch: 1837 [81920/90000 (91%)]	Loss: -11.3447	Cost: 6.22s
Train Epoch: 1837 	Average Loss: -10.8297
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4124

Learning rate: 9.190213162662278e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1838 [0/90000 (0%)]	Loss: -4.8943	Cost: 23.59s
Train Epoch: 1838 [20480/90000 (23%)]	Loss: -11.5474	Cost: 12.10s
Train Epoch: 1838 [40960/90000 (45%)]	Loss: -11.3943	Cost: 12.65s
Train Epoch: 1838 [61440/90000 (68%)]	Loss: -11.7594	Cost: 6.73s
Train Epoch: 1838 [81920/90000 (91%)]	Loss: -11.6926	Cost: 6.46s
Train Epoch: 1838 	Average Loss: -11.1334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7324

Saving model as e1838_model.pt & e1838_waveforms_supplementary.hdf5
Learning rate: 9.189355921956384e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1839 [0/90000 (0%)]	Loss: -4.9597	Cost: 21.79s
Train Epoch: 1839 [20480/90000 (23%)]	Loss: -11.6896	Cost: 8.62s
Train Epoch: 1839 [40960/90000 (45%)]	Loss: -11.6472	Cost: 10.66s
Train Epoch: 1839 [61440/90000 (68%)]	Loss: -11.9360	Cost: 8.83s
Train Epoch: 1839 [81920/90000 (91%)]	Loss: -11.4564	Cost: 8.49s
Train Epoch: 1839 	Average Loss: -11.1922
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7425

Saving model as e1839_model.pt & e1839_waveforms_supplementary.hdf5
Learning rate: 9.188498267777634e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1840 [0/90000 (0%)]	Loss: -5.0787	Cost: 29.21s
Train Epoch: 1840 [20480/90000 (23%)]	Loss: -11.5366	Cost: 9.32s
Train Epoch: 1840 [40960/90000 (45%)]	Loss: -11.6951	Cost: 8.99s
Train Epoch: 1840 [61440/90000 (68%)]	Loss: -11.7062	Cost: 7.36s
Train Epoch: 1840 [81920/90000 (91%)]	Loss: -11.2531	Cost: 6.26s
Train Epoch: 1840 	Average Loss: -11.1097
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5310

Learning rate: 9.187640200210681e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1841 [0/90000 (0%)]	Loss: -4.1253	Cost: 22.93s
Train Epoch: 1841 [20480/90000 (23%)]	Loss: -11.5347	Cost: 6.76s
Train Epoch: 1841 [40960/90000 (45%)]	Loss: -11.5548	Cost: 11.15s
Train Epoch: 1841 [61440/90000 (68%)]	Loss: -11.6093	Cost: 11.35s
Train Epoch: 1841 [81920/90000 (91%)]	Loss: -11.4646	Cost: 12.56s
Train Epoch: 1841 	Average Loss: -11.0490
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5393

Learning rate: 9.186781719340208e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1842 [0/90000 (0%)]	Loss: -5.0827	Cost: 31.18s
Train Epoch: 1842 [20480/90000 (23%)]	Loss: -11.6924	Cost: 13.55s
Train Epoch: 1842 [40960/90000 (45%)]	Loss: -11.7593	Cost: 14.94s
Train Epoch: 1842 [61440/90000 (68%)]	Loss: -11.8868	Cost: 12.45s
Train Epoch: 1842 [81920/90000 (91%)]	Loss: -11.3453	Cost: 12.24s
Train Epoch: 1842 	Average Loss: -11.1957
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6528

Learning rate: 9.185922825250947e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1843 [0/90000 (0%)]	Loss: -5.3819	Cost: 23.04s
Train Epoch: 1843 [20480/90000 (23%)]	Loss: -11.6328	Cost: 13.75s
Train Epoch: 1843 [40960/90000 (45%)]	Loss: -11.5007	Cost: 14.29s
Train Epoch: 1843 [61440/90000 (68%)]	Loss: -11.8835	Cost: 12.51s
Train Epoch: 1843 [81920/90000 (91%)]	Loss: -11.1989	Cost: 7.14s
Train Epoch: 1843 	Average Loss: -11.1005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6248

Learning rate: 9.185063518027664e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1844 [0/90000 (0%)]	Loss: -4.6913	Cost: 26.59s
Train Epoch: 1844 [20480/90000 (23%)]	Loss: -11.5670	Cost: 9.92s
Train Epoch: 1844 [40960/90000 (45%)]	Loss: -11.4017	Cost: 10.80s
Train Epoch: 1844 [61440/90000 (68%)]	Loss: -11.6364	Cost: 6.24s
Train Epoch: 1844 [81920/90000 (91%)]	Loss: -11.3437	Cost: 7.06s
Train Epoch: 1844 	Average Loss: -11.0674
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4633

Learning rate: 9.184203797755172e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1845 [0/90000 (0%)]	Loss: -4.5400	Cost: 35.35s
Train Epoch: 1845 [20480/90000 (23%)]	Loss: -11.4982	Cost: 7.40s
Train Epoch: 1845 [40960/90000 (45%)]	Loss: -11.6386	Cost: 9.03s
Train Epoch: 1845 [61440/90000 (68%)]	Loss: -11.7656	Cost: 8.92s
Train Epoch: 1845 [81920/90000 (91%)]	Loss: -11.2386	Cost: 8.59s
Train Epoch: 1845 	Average Loss: -11.0742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6305

Learning rate: 9.183343664518321e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1846 [0/90000 (0%)]	Loss: -4.5340	Cost: 28.34s
Train Epoch: 1846 [20480/90000 (23%)]	Loss: -11.2920	Cost: 8.91s
Train Epoch: 1846 [40960/90000 (45%)]	Loss: -11.6361	Cost: 8.92s
Train Epoch: 1846 [61440/90000 (68%)]	Loss: -11.6766	Cost: 6.37s
Train Epoch: 1846 [81920/90000 (91%)]	Loss: -11.4771	Cost: 6.18s
Train Epoch: 1846 	Average Loss: -11.0623
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7078

Learning rate: 9.182483118402004e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1847 [0/90000 (0%)]	Loss: -4.8545	Cost: 21.22s
Train Epoch: 1847 [20480/90000 (23%)]	Loss: -11.7185	Cost: 9.17s
Train Epoch: 1847 [40960/90000 (45%)]	Loss: -11.8742	Cost: 14.06s
Train Epoch: 1847 [61440/90000 (68%)]	Loss: -11.6598	Cost: 14.69s
Train Epoch: 1847 [81920/90000 (91%)]	Loss: -11.3536	Cost: 13.72s
Train Epoch: 1847 	Average Loss: -11.1189
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4466

Learning rate: 9.181622159491152e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1848 [0/90000 (0%)]	Loss: -4.7207	Cost: 23.04s
Train Epoch: 1848 [20480/90000 (23%)]	Loss: -11.4504	Cost: 13.77s
Train Epoch: 1848 [40960/90000 (45%)]	Loss: -11.5661	Cost: 15.13s
Train Epoch: 1848 [61440/90000 (68%)]	Loss: -11.6548	Cost: 12.75s
Train Epoch: 1848 [81920/90000 (91%)]	Loss: -11.4060	Cost: 12.25s
Train Epoch: 1848 	Average Loss: -11.1103
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6732

Learning rate: 9.180760787870738e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1849 [0/90000 (0%)]	Loss: -5.0433	Cost: 30.36s
Train Epoch: 1849 [20480/90000 (23%)]	Loss: -11.7788	Cost: 11.72s
Train Epoch: 1849 [40960/90000 (45%)]	Loss: -11.8226	Cost: 12.37s
Train Epoch: 1849 [61440/90000 (68%)]	Loss: -11.8726	Cost: 12.04s
Train Epoch: 1849 [81920/90000 (91%)]	Loss: -11.4958	Cost: 8.56s
Train Epoch: 1849 	Average Loss: -11.2452
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6115

Learning rate: 9.179899003625777e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1850 [0/90000 (0%)]	Loss: -4.7202	Cost: 30.73s
Train Epoch: 1850 [20480/90000 (23%)]	Loss: -11.3312	Cost: 12.30s
Train Epoch: 1850 [40960/90000 (45%)]	Loss: -11.0463	Cost: 12.26s
Train Epoch: 1850 [61440/90000 (68%)]	Loss: -11.4065	Cost: 11.32s
Train Epoch: 1850 [81920/90000 (91%)]	Loss: -11.1864	Cost: 6.01s
Train Epoch: 1850 	Average Loss: -10.7794
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4616

Learning rate: 9.179036806841325e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1851 [0/90000 (0%)]	Loss: -5.8334	Cost: 28.01s
Train Epoch: 1851 [20480/90000 (23%)]	Loss: -11.6873	Cost: 13.25s
Train Epoch: 1851 [40960/90000 (45%)]	Loss: -11.7468	Cost: 12.29s
Train Epoch: 1851 [61440/90000 (68%)]	Loss: -11.8363	Cost: 6.37s
Train Epoch: 1851 [81920/90000 (91%)]	Loss: -11.3675	Cost: 6.26s
Train Epoch: 1851 	Average Loss: -11.1444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5806

Learning rate: 9.178174197602472e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1852 [0/90000 (0%)]	Loss: -4.7686	Cost: 23.51s
Train Epoch: 1852 [20480/90000 (23%)]	Loss: -11.3114	Cost: 7.70s
Train Epoch: 1852 [40960/90000 (45%)]	Loss: -11.4246	Cost: 11.55s
Train Epoch: 1852 [61440/90000 (68%)]	Loss: -11.6637	Cost: 9.34s
Train Epoch: 1852 [81920/90000 (91%)]	Loss: -11.5305	Cost: 9.02s
Train Epoch: 1852 	Average Loss: -11.0347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5607

Learning rate: 9.177311175994362e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1853 [0/90000 (0%)]	Loss: -4.5142	Cost: 25.80s
Train Epoch: 1853 [20480/90000 (23%)]	Loss: -11.6061	Cost: 11.65s
Train Epoch: 1853 [40960/90000 (45%)]	Loss: -11.5526	Cost: 9.75s
Train Epoch: 1853 [61440/90000 (68%)]	Loss: -11.7494	Cost: 6.29s
Train Epoch: 1853 [81920/90000 (91%)]	Loss: -11.6233	Cost: 6.83s
Train Epoch: 1853 	Average Loss: -11.1205
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6757

Learning rate: 9.176447742102165e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1854 [0/90000 (0%)]	Loss: -5.5422	Cost: 20.98s
Train Epoch: 1854 [20480/90000 (23%)]	Loss: -11.7251	Cost: 7.57s
Train Epoch: 1854 [40960/90000 (45%)]	Loss: -11.2284	Cost: 8.12s
Train Epoch: 1854 [61440/90000 (68%)]	Loss: -11.5229	Cost: 11.28s
Train Epoch: 1854 [81920/90000 (91%)]	Loss: -11.2387	Cost: 12.93s
Train Epoch: 1854 	Average Loss: -11.0613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6111

Learning rate: 9.175583896011101e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1855 [0/90000 (0%)]	Loss: -4.6993	Cost: 21.55s
Train Epoch: 1855 [20480/90000 (23%)]	Loss: -11.4386	Cost: 10.11s
Train Epoch: 1855 [40960/90000 (45%)]	Loss: -11.6768	Cost: 13.11s
Train Epoch: 1855 [61440/90000 (68%)]	Loss: -11.8583	Cost: 12.36s
Train Epoch: 1855 [81920/90000 (91%)]	Loss: -11.5614	Cost: 12.07s
Train Epoch: 1855 	Average Loss: -11.1564
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7745

Saving model as e1855_model.pt & e1855_waveforms_supplementary.hdf5
Learning rate: 9.17471963780643e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1856 [0/90000 (0%)]	Loss: -5.2914	Cost: 25.73s
Train Epoch: 1856 [20480/90000 (23%)]	Loss: -11.6958	Cost: 11.17s
Train Epoch: 1856 [40960/90000 (45%)]	Loss: -11.8039	Cost: 12.33s
Train Epoch: 1856 [61440/90000 (68%)]	Loss: -11.9639	Cost: 12.53s
Train Epoch: 1856 [81920/90000 (91%)]	Loss: -11.5191	Cost: 6.84s
Train Epoch: 1856 	Average Loss: -11.2597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6493

Learning rate: 9.173854967573448e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1857 [0/90000 (0%)]	Loss: -5.1718	Cost: 27.34s
Train Epoch: 1857 [20480/90000 (23%)]	Loss: -11.6429	Cost: 13.17s
Train Epoch: 1857 [40960/90000 (45%)]	Loss: -11.8197	Cost: 13.48s
Train Epoch: 1857 [61440/90000 (68%)]	Loss: -11.9153	Cost: 7.19s
Train Epoch: 1857 [81920/90000 (91%)]	Loss: -11.6065	Cost: 6.45s
Train Epoch: 1857 	Average Loss: -11.2441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7874

Saving model as e1857_model.pt & e1857_waveforms_supplementary.hdf5
Learning rate: 9.172989885397498e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1858 [0/90000 (0%)]	Loss: -5.2383	Cost: 21.68s
Train Epoch: 1858 [20480/90000 (23%)]	Loss: -11.9416	Cost: 10.68s
Train Epoch: 1858 [40960/90000 (45%)]	Loss: -11.2298	Cost: 11.26s
Train Epoch: 1858 [61440/90000 (68%)]	Loss: -11.5971	Cost: 8.25s
Train Epoch: 1858 [81920/90000 (91%)]	Loss: -11.2692	Cost: 8.11s
Train Epoch: 1858 	Average Loss: -11.0444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7178

Learning rate: 9.172124391363957e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1859 [0/90000 (0%)]	Loss: -4.9155	Cost: 21.47s
Train Epoch: 1859 [20480/90000 (23%)]	Loss: -11.5479	Cost: 8.28s
Train Epoch: 1859 [40960/90000 (45%)]	Loss: -11.7023	Cost: 9.32s
Train Epoch: 1859 [61440/90000 (68%)]	Loss: -11.8761	Cost: 8.81s
Train Epoch: 1859 [81920/90000 (91%)]	Loss: -11.6202	Cost: 8.62s
Train Epoch: 1859 	Average Loss: -11.2162
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8380

Saving model as e1859_model.pt & e1859_waveforms_supplementary.hdf5
Learning rate: 9.171258485558245e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1860 [0/90000 (0%)]	Loss: -5.2275	Cost: 29.87s
Train Epoch: 1860 [20480/90000 (23%)]	Loss: -11.6897	Cost: 6.82s
Train Epoch: 1860 [40960/90000 (45%)]	Loss: -11.8008	Cost: 6.98s
Train Epoch: 1860 [61440/90000 (68%)]	Loss: -11.8937	Cost: 6.65s
Train Epoch: 1860 [81920/90000 (91%)]	Loss: -11.7254	Cost: 11.00s
Train Epoch: 1860 	Average Loss: -11.3831
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8937

Saving model as e1860_model.pt & e1860_waveforms_supplementary.hdf5
Learning rate: 9.170392168065828e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1861 [0/90000 (0%)]	Loss: -5.6109	Cost: 22.90s
Train Epoch: 1861 [20480/90000 (23%)]	Loss: -11.8878	Cost: 10.52s
Train Epoch: 1861 [40960/90000 (45%)]	Loss: -11.8083	Cost: 9.74s
Train Epoch: 1861 [61440/90000 (68%)]	Loss: -12.1160	Cost: 12.84s
Train Epoch: 1861 [81920/90000 (91%)]	Loss: -11.6168	Cost: 12.32s
Train Epoch: 1861 	Average Loss: -11.3369
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7695

Learning rate: 9.169525438972204e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1862 [0/90000 (0%)]	Loss: -5.0822	Cost: 25.31s
Train Epoch: 1862 [20480/90000 (23%)]	Loss: -11.6339	Cost: 13.84s
Train Epoch: 1862 [40960/90000 (45%)]	Loss: -11.8750	Cost: 15.00s
Train Epoch: 1862 [61440/90000 (68%)]	Loss: -11.8607	Cost: 12.85s
Train Epoch: 1862 [81920/90000 (91%)]	Loss: -11.5175	Cost: 12.35s
Train Epoch: 1862 	Average Loss: -11.1945
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9082

Saving model as e1862_model.pt & e1862_waveforms_supplementary.hdf5
Learning rate: 9.168658298362917e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1863 [0/90000 (0%)]	Loss: -5.5140	Cost: 30.48s
Train Epoch: 1863 [20480/90000 (23%)]	Loss: -11.6998	Cost: 13.43s
Train Epoch: 1863 [40960/90000 (45%)]	Loss: -11.9710	Cost: 13.83s
Train Epoch: 1863 [61440/90000 (68%)]	Loss: -11.8226	Cost: 10.90s
Train Epoch: 1863 [81920/90000 (91%)]	Loss: -11.6273	Cost: 6.29s
Train Epoch: 1863 	Average Loss: -11.2551
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7140

Learning rate: 9.16779074632355e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1864 [0/90000 (0%)]	Loss: -5.1407	Cost: 30.16s
Train Epoch: 1864 [20480/90000 (23%)]	Loss: -11.8693	Cost: 13.84s
Train Epoch: 1864 [40960/90000 (45%)]	Loss: -11.8697	Cost: 12.32s
Train Epoch: 1864 [61440/90000 (68%)]	Loss: -11.9219	Cost: 7.59s
Train Epoch: 1864 [81920/90000 (91%)]	Loss: -11.4871	Cost: 6.10s
Train Epoch: 1864 	Average Loss: -11.2849
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7564

Learning rate: 9.166922782939728e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1865 [0/90000 (0%)]	Loss: -3.8827	Cost: 32.69s
Train Epoch: 1865 [20480/90000 (23%)]	Loss: -11.6301	Cost: 12.75s
Train Epoch: 1865 [40960/90000 (45%)]	Loss: -11.8912	Cost: 6.96s
Train Epoch: 1865 [61440/90000 (68%)]	Loss: -11.9155	Cost: 6.18s
Train Epoch: 1865 [81920/90000 (91%)]	Loss: -11.5928	Cost: 8.57s
Train Epoch: 1865 	Average Loss: -11.1967
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6272

Learning rate: 9.166054408297117e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1866 [0/90000 (0%)]	Loss: -4.7306	Cost: 27.11s
Train Epoch: 1866 [20480/90000 (23%)]	Loss: -11.6538	Cost: 12.13s
Train Epoch: 1866 [40960/90000 (45%)]	Loss: -11.9061	Cost: 8.09s
Train Epoch: 1866 [61440/90000 (68%)]	Loss: -11.9244	Cost: 6.21s
Train Epoch: 1866 [81920/90000 (91%)]	Loss: -11.4245	Cost: 7.33s
Train Epoch: 1866 	Average Loss: -11.3406
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6940

Learning rate: 9.165185622481417e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1867 [0/90000 (0%)]	Loss: -4.2375	Cost: 24.52s
Train Epoch: 1867 [20480/90000 (23%)]	Loss: -11.8294	Cost: 8.59s
Train Epoch: 1867 [40960/90000 (45%)]	Loss: -11.8288	Cost: 6.92s
Train Epoch: 1867 [61440/90000 (68%)]	Loss: -11.8773	Cost: 7.47s
Train Epoch: 1867 [81920/90000 (91%)]	Loss: -11.5929	Cost: 8.87s
Train Epoch: 1867 	Average Loss: -11.3477
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8334

Learning rate: 9.16431642557838e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1868 [0/90000 (0%)]	Loss: -5.2566	Cost: 22.63s
Train Epoch: 1868 [20480/90000 (23%)]	Loss: -11.5189	Cost: 8.97s
Train Epoch: 1868 [40960/90000 (45%)]	Loss: -11.8897	Cost: 9.01s
Train Epoch: 1868 [61440/90000 (68%)]	Loss: -11.8479	Cost: 9.09s
Train Epoch: 1868 [81920/90000 (91%)]	Loss: -11.5415	Cost: 9.29s
Train Epoch: 1868 	Average Loss: -11.2946
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7605

Learning rate: 9.163446817673787e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1869 [0/90000 (0%)]	Loss: -5.3677	Cost: 22.92s
Train Epoch: 1869 [20480/90000 (23%)]	Loss: -11.7182	Cost: 8.10s
Train Epoch: 1869 [40960/90000 (45%)]	Loss: -11.9699	Cost: 14.18s
Train Epoch: 1869 [61440/90000 (68%)]	Loss: -12.0468	Cost: 12.06s
Train Epoch: 1869 [81920/90000 (91%)]	Loss: -11.3230	Cost: 12.41s
Train Epoch: 1869 	Average Loss: -11.3016
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4997

Learning rate: 9.162576798853468e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1870 [0/90000 (0%)]	Loss: -4.7031	Cost: 30.25s
Train Epoch: 1870 [20480/90000 (23%)]	Loss: -11.6144	Cost: 12.57s
Train Epoch: 1870 [40960/90000 (45%)]	Loss: -11.8230	Cost: 12.77s
Train Epoch: 1870 [61440/90000 (68%)]	Loss: -11.8596	Cost: 12.10s
Train Epoch: 1870 [81920/90000 (91%)]	Loss: -11.6791	Cost: 12.18s
Train Epoch: 1870 	Average Loss: -11.1883
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8096

Learning rate: 9.161706369203289e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1871 [0/90000 (0%)]	Loss: -4.5076	Cost: 26.72s
Train Epoch: 1871 [20480/90000 (23%)]	Loss: -11.7284	Cost: 9.89s
Train Epoch: 1871 [40960/90000 (45%)]	Loss: -11.9968	Cost: 12.68s
Train Epoch: 1871 [61440/90000 (68%)]	Loss: -12.0538	Cost: 12.36s
Train Epoch: 1871 [81920/90000 (91%)]	Loss: -11.6120	Cost: 9.75s
Train Epoch: 1871 	Average Loss: -11.3645
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7317

Learning rate: 9.160835528809158e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1872 [0/90000 (0%)]	Loss: -5.3413	Cost: 26.83s
Train Epoch: 1872 [20480/90000 (23%)]	Loss: -11.7734	Cost: 11.83s
Train Epoch: 1872 [40960/90000 (45%)]	Loss: -11.9753	Cost: 12.69s
Train Epoch: 1872 [61440/90000 (68%)]	Loss: -11.9156	Cost: 12.68s
Train Epoch: 1872 [81920/90000 (91%)]	Loss: -11.8186	Cost: 7.79s
Train Epoch: 1872 	Average Loss: -11.4062
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0028

Saving model as e1872_model.pt & e1872_waveforms_supplementary.hdf5
Learning rate: 9.159964277757025e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1873 [0/90000 (0%)]	Loss: -4.2456	Cost: 25.51s
Train Epoch: 1873 [20480/90000 (23%)]	Loss: -11.8185	Cost: 13.26s
Train Epoch: 1873 [40960/90000 (45%)]	Loss: -11.9640	Cost: 10.54s
Train Epoch: 1873 [61440/90000 (68%)]	Loss: -12.1701	Cost: 9.03s
Train Epoch: 1873 [81920/90000 (91%)]	Loss: -11.6805	Cost: 7.35s
Train Epoch: 1873 	Average Loss: -11.4298
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7545

Learning rate: 9.159092616132876e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1874 [0/90000 (0%)]	Loss: -6.0504	Cost: 23.12s
Train Epoch: 1874 [20480/90000 (23%)]	Loss: -11.7916	Cost: 9.83s
Train Epoch: 1874 [40960/90000 (45%)]	Loss: -11.8720	Cost: 7.60s
Train Epoch: 1874 [61440/90000 (68%)]	Loss: -11.8318	Cost: 7.53s
Train Epoch: 1874 [81920/90000 (91%)]	Loss: -11.6405	Cost: 8.63s
Train Epoch: 1874 	Average Loss: -11.3703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7702

Learning rate: 9.158220544022744e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1875 [0/90000 (0%)]	Loss: -5.6092	Cost: 26.83s
Train Epoch: 1875 [20480/90000 (23%)]	Loss: -11.9412	Cost: 8.52s
Train Epoch: 1875 [40960/90000 (45%)]	Loss: -12.1340	Cost: 8.98s
Train Epoch: 1875 [61440/90000 (68%)]	Loss: -12.1517	Cost: 9.05s
Train Epoch: 1875 [81920/90000 (91%)]	Loss: -11.7042	Cost: 8.57s
Train Epoch: 1875 	Average Loss: -11.4301
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7745

Learning rate: 9.157348061512699e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1876 [0/90000 (0%)]	Loss: -4.0210	Cost: 19.80s
Train Epoch: 1876 [20480/90000 (23%)]	Loss: -11.7053	Cost: 8.97s
Train Epoch: 1876 [40960/90000 (45%)]	Loss: -11.7150	Cost: 8.47s
Train Epoch: 1876 [61440/90000 (68%)]	Loss: -11.9239	Cost: 6.57s
Train Epoch: 1876 [81920/90000 (91%)]	Loss: -11.7012	Cost: 6.41s
Train Epoch: 1876 	Average Loss: -11.3141
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9895

Learning rate: 9.156475168688847e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1877 [0/90000 (0%)]	Loss: -4.5032	Cost: 21.59s
Train Epoch: 1877 [20480/90000 (23%)]	Loss: -11.8878	Cost: 7.49s
Train Epoch: 1877 [40960/90000 (45%)]	Loss: -11.7154	Cost: 12.61s
Train Epoch: 1877 [61440/90000 (68%)]	Loss: -11.7590	Cost: 13.02s
Train Epoch: 1877 [81920/90000 (91%)]	Loss: -11.6582	Cost: 12.49s
Train Epoch: 1877 	Average Loss: -11.3032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7250

Learning rate: 9.155601865637345e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1878 [0/90000 (0%)]	Loss: -4.9564	Cost: 26.38s
Train Epoch: 1878 [20480/90000 (23%)]	Loss: -11.8519	Cost: 11.84s
Train Epoch: 1878 [40960/90000 (45%)]	Loss: -11.8144	Cost: 15.05s
Train Epoch: 1878 [61440/90000 (68%)]	Loss: -11.9621	Cost: 12.59s
Train Epoch: 1878 [81920/90000 (91%)]	Loss: -11.5206	Cost: 12.07s
Train Epoch: 1878 	Average Loss: -11.2854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8790

Learning rate: 9.154728152444381e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1879 [0/90000 (0%)]	Loss: -4.4607	Cost: 41.21s
Train Epoch: 1879 [20480/90000 (23%)]	Loss: -11.6408	Cost: 12.21s
Train Epoch: 1879 [40960/90000 (45%)]	Loss: -11.8128	Cost: 12.28s
Train Epoch: 1879 [61440/90000 (68%)]	Loss: -11.8724	Cost: 11.71s
Train Epoch: 1879 [81920/90000 (91%)]	Loss: -11.5650	Cost: 7.62s
Train Epoch: 1879 	Average Loss: -11.2790
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8482

Learning rate: 9.153854029196186e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1880 [0/90000 (0%)]	Loss: -3.8093	Cost: 27.81s
Train Epoch: 1880 [20480/90000 (23%)]	Loss: -11.7293	Cost: 9.94s
Train Epoch: 1880 [40960/90000 (45%)]	Loss: -11.7878	Cost: 12.31s
Train Epoch: 1880 [61440/90000 (68%)]	Loss: -11.9239	Cost: 7.76s
Train Epoch: 1880 [81920/90000 (91%)]	Loss: -11.4859	Cost: 6.96s
Train Epoch: 1880 	Average Loss: -11.2578
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7629

Learning rate: 9.152979495979036e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1881 [0/90000 (0%)]	Loss: -4.0459	Cost: 24.33s
Train Epoch: 1881 [20480/90000 (23%)]	Loss: -11.8826	Cost: 12.25s
Train Epoch: 1881 [40960/90000 (45%)]	Loss: -12.0175	Cost: 8.56s
Train Epoch: 1881 [61440/90000 (68%)]	Loss: -12.1005	Cost: 6.26s
Train Epoch: 1881 [81920/90000 (91%)]	Loss: -11.6466	Cost: 8.74s
Train Epoch: 1881 	Average Loss: -11.4265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7999

Learning rate: 9.152104552879241e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1882 [0/90000 (0%)]	Loss: -4.0490	Cost: 20.02s
Train Epoch: 1882 [20480/90000 (23%)]	Loss: -12.1128	Cost: 8.81s
Train Epoch: 1882 [40960/90000 (45%)]	Loss: -12.1255	Cost: 9.01s
Train Epoch: 1882 [61440/90000 (68%)]	Loss: -12.0723	Cost: 8.81s
Train Epoch: 1882 [81920/90000 (91%)]	Loss: -11.7488	Cost: 8.66s
Train Epoch: 1882 	Average Loss: -11.5059
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9072

Learning rate: 9.151229199983157e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1883 [0/90000 (0%)]	Loss: -5.1684	Cost: 25.74s
Train Epoch: 1883 [20480/90000 (23%)]	Loss: -11.9891	Cost: 8.91s
Train Epoch: 1883 [40960/90000 (45%)]	Loss: -10.8813	Cost: 8.84s
Train Epoch: 1883 [61440/90000 (68%)]	Loss: -11.2185	Cost: 8.84s
Train Epoch: 1883 [81920/90000 (91%)]	Loss: -11.0155	Cost: 7.73s
Train Epoch: 1883 	Average Loss: -10.8918
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4623

Learning rate: 9.150353437377176e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1884 [0/90000 (0%)]	Loss: -5.0434	Cost: 24.02s
Train Epoch: 1884 [20480/90000 (23%)]	Loss: -11.5152	Cost: 6.73s
Train Epoch: 1884 [40960/90000 (45%)]	Loss: -11.6633	Cost: 9.42s
Train Epoch: 1884 [61440/90000 (68%)]	Loss: -11.8809	Cost: 9.77s
Train Epoch: 1884 [81920/90000 (91%)]	Loss: -11.4313	Cost: 13.43s
Train Epoch: 1884 	Average Loss: -11.1246
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9314

Learning rate: 9.149477265147733e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1885 [0/90000 (0%)]	Loss: -4.3942	Cost: 22.77s
Train Epoch: 1885 [20480/90000 (23%)]	Loss: -11.6642	Cost: 9.93s
Train Epoch: 1885 [40960/90000 (45%)]	Loss: -11.8509	Cost: 17.40s
Train Epoch: 1885 [61440/90000 (68%)]	Loss: -11.8424	Cost: 13.59s
Train Epoch: 1885 [81920/90000 (91%)]	Loss: -11.5490	Cost: 12.37s
Train Epoch: 1885 	Average Loss: -11.3511
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7305

Learning rate: 9.148600683381301e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1886 [0/90000 (0%)]	Loss: -4.4399	Cost: 26.96s
Train Epoch: 1886 [20480/90000 (23%)]	Loss: -11.6554	Cost: 14.09s
Train Epoch: 1886 [40960/90000 (45%)]	Loss: -11.8638	Cost: 14.17s
Train Epoch: 1886 [61440/90000 (68%)]	Loss: -11.4526	Cost: 12.35s
Train Epoch: 1886 [81920/90000 (91%)]	Loss: -11.1408	Cost: 8.82s
Train Epoch: 1886 	Average Loss: -11.0842
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3657

Learning rate: 9.147723692164398e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1887 [0/90000 (0%)]	Loss: -4.7590	Cost: 31.84s
Train Epoch: 1887 [20480/90000 (23%)]	Loss: -11.6591	Cost: 12.62s
Train Epoch: 1887 [40960/90000 (45%)]	Loss: -11.5341	Cost: 12.11s
Train Epoch: 1887 [61440/90000 (68%)]	Loss: -11.9303	Cost: 8.30s
Train Epoch: 1887 [81920/90000 (91%)]	Loss: -11.5138	Cost: 6.14s
Train Epoch: 1887 	Average Loss: -11.1804
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8240

Learning rate: 9.146846291583579e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1888 [0/90000 (0%)]	Loss: -4.6531	Cost: 23.56s
Train Epoch: 1888 [20480/90000 (23%)]	Loss: -11.7457	Cost: 6.63s
Train Epoch: 1888 [40960/90000 (45%)]	Loss: -12.0751	Cost: 9.59s
Train Epoch: 1888 [61440/90000 (68%)]	Loss: -12.0529	Cost: 8.95s
Train Epoch: 1888 [81920/90000 (91%)]	Loss: -11.7450	Cost: 8.83s
Train Epoch: 1888 	Average Loss: -11.4229
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0362

Saving model as e1888_model.pt & e1888_waveforms_supplementary.hdf5
Learning rate: 9.145968481725437e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1889 [0/90000 (0%)]	Loss: -4.9222	Cost: 23.08s
Train Epoch: 1889 [20480/90000 (23%)]	Loss: -12.0772	Cost: 8.96s
Train Epoch: 1889 [40960/90000 (45%)]	Loss: -12.0956	Cost: 8.93s
Train Epoch: 1889 [61440/90000 (68%)]	Loss: -12.0089	Cost: 8.47s
Train Epoch: 1889 [81920/90000 (91%)]	Loss: -11.8018	Cost: 8.52s
Train Epoch: 1889 	Average Loss: -11.4334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8339

Learning rate: 9.145090262676614e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1890 [0/90000 (0%)]	Loss: -4.3856	Cost: 21.65s
Train Epoch: 1890 [20480/90000 (23%)]	Loss: -11.7771	Cost: 9.14s
Train Epoch: 1890 [40960/90000 (45%)]	Loss: -11.7180	Cost: 9.85s
Train Epoch: 1890 [61440/90000 (68%)]	Loss: -11.7898	Cost: 9.49s
Train Epoch: 1890 [81920/90000 (91%)]	Loss: -11.7018	Cost: 12.20s
Train Epoch: 1890 	Average Loss: -11.3077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7130

Learning rate: 9.144211634523782e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1891 [0/90000 (0%)]	Loss: -4.1647	Cost: 18.94s
Train Epoch: 1891 [20480/90000 (23%)]	Loss: -11.7257	Cost: 9.46s
Train Epoch: 1891 [40960/90000 (45%)]	Loss: -12.0299	Cost: 17.56s
Train Epoch: 1891 [61440/90000 (68%)]	Loss: -11.9125	Cost: 14.23s
Train Epoch: 1891 [81920/90000 (91%)]	Loss: -11.5365	Cost: 13.37s
Train Epoch: 1891 	Average Loss: -11.2248
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7836

Learning rate: 9.143332597353658e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1892 [0/90000 (0%)]	Loss: -4.2692	Cost: 31.22s
Train Epoch: 1892 [20480/90000 (23%)]	Loss: -11.7602	Cost: 13.76s
Train Epoch: 1892 [40960/90000 (45%)]	Loss: -11.9588	Cost: 12.32s
Train Epoch: 1892 [61440/90000 (68%)]	Loss: -12.0258	Cost: 12.18s
Train Epoch: 1892 [81920/90000 (91%)]	Loss: -11.8718	Cost: 11.48s
Train Epoch: 1892 	Average Loss: -11.4054
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9362

Learning rate: 9.142453151253003e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1893 [0/90000 (0%)]	Loss: -5.1686	Cost: 27.41s
Train Epoch: 1893 [20480/90000 (23%)]	Loss: -12.0527	Cost: 12.46s
Train Epoch: 1893 [40960/90000 (45%)]	Loss: -12.3024	Cost: 9.77s
Train Epoch: 1893 [61440/90000 (68%)]	Loss: -12.0781	Cost: 6.27s
Train Epoch: 1893 [81920/90000 (91%)]	Loss: -11.9155	Cost: 7.64s
Train Epoch: 1893 	Average Loss: -11.5217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8616

Learning rate: 9.141573296308612e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1894 [0/90000 (0%)]	Loss: -5.0990	Cost: 23.93s
Train Epoch: 1894 [20480/90000 (23%)]	Loss: -12.0209	Cost: 6.71s
Train Epoch: 1894 [40960/90000 (45%)]	Loss: -12.2931	Cost: 8.66s
Train Epoch: 1894 [61440/90000 (68%)]	Loss: -11.9941	Cost: 8.85s
Train Epoch: 1894 [81920/90000 (91%)]	Loss: -11.7533	Cost: 9.05s
Train Epoch: 1894 	Average Loss: -11.5384
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9887

Learning rate: 9.140693032607324e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1895 [0/90000 (0%)]	Loss: -5.2272	Cost: 22.30s
Train Epoch: 1895 [20480/90000 (23%)]	Loss: -11.9523	Cost: 10.83s
Train Epoch: 1895 [40960/90000 (45%)]	Loss: -12.1045	Cost: 10.92s
Train Epoch: 1895 [61440/90000 (68%)]	Loss: -12.3613	Cost: 8.89s
Train Epoch: 1895 [81920/90000 (91%)]	Loss: -11.6990	Cost: 8.75s
Train Epoch: 1895 	Average Loss: -11.5716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8175

Learning rate: 9.139812360236018e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1896 [0/90000 (0%)]	Loss: -5.3286	Cost: 34.04s
Train Epoch: 1896 [20480/90000 (23%)]	Loss: -11.6612	Cost: 9.14s
Train Epoch: 1896 [40960/90000 (45%)]	Loss: -11.9372	Cost: 6.65s
Train Epoch: 1896 [61440/90000 (68%)]	Loss: -12.1982	Cost: 7.14s
Train Epoch: 1896 [81920/90000 (91%)]	Loss: -11.9133	Cost: 6.78s
Train Epoch: 1896 	Average Loss: -11.4943
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0443

Saving model as e1896_model.pt & e1896_waveforms_supplementary.hdf5
Learning rate: 9.13893127928161e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1897 [0/90000 (0%)]	Loss: -4.6441	Cost: 21.30s
Train Epoch: 1897 [20480/90000 (23%)]	Loss: -11.9949	Cost: 7.15s
Train Epoch: 1897 [40960/90000 (45%)]	Loss: -12.1281	Cost: 12.51s
Train Epoch: 1897 [61440/90000 (68%)]	Loss: -12.1510	Cost: 13.06s
Train Epoch: 1897 [81920/90000 (91%)]	Loss: -11.7521	Cost: 12.36s
Train Epoch: 1897 	Average Loss: -11.5015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9709

Learning rate: 9.138049789831064e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1898 [0/90000 (0%)]	Loss: -5.1190	Cost: 27.42s
Train Epoch: 1898 [20480/90000 (23%)]	Loss: -11.7068	Cost: 12.96s
Train Epoch: 1898 [40960/90000 (45%)]	Loss: -11.8011	Cost: 12.29s
Train Epoch: 1898 [61440/90000 (68%)]	Loss: -11.7767	Cost: 12.36s
Train Epoch: 1898 [81920/90000 (91%)]	Loss: -11.6277	Cost: 11.78s
Train Epoch: 1898 	Average Loss: -11.3100
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8211

Learning rate: 9.137167891971379e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1899 [0/90000 (0%)]	Loss: -5.1450	Cost: 24.52s
Train Epoch: 1899 [20480/90000 (23%)]	Loss: -11.9431	Cost: 13.84s
Train Epoch: 1899 [40960/90000 (45%)]	Loss: -12.0019	Cost: 12.50s
Train Epoch: 1899 [61440/90000 (68%)]	Loss: -11.9131	Cost: 7.12s
Train Epoch: 1899 [81920/90000 (91%)]	Loss: -11.6595	Cost: 6.59s
Train Epoch: 1899 	Average Loss: -11.3747
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8950

Learning rate: 9.13628558578959e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1900 [0/90000 (0%)]	Loss: -5.5035	Cost: 37.41s
Train Epoch: 1900 [20480/90000 (23%)]	Loss: -11.8466	Cost: 9.53s
Train Epoch: 1900 [40960/90000 (45%)]	Loss: -12.2127	Cost: 7.00s
Train Epoch: 1900 [61440/90000 (68%)]	Loss: -12.0510	Cost: 7.99s
Train Epoch: 1900 [81920/90000 (91%)]	Loss: -11.7463	Cost: 8.59s
Train Epoch: 1900 	Average Loss: -11.5596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9252

Learning rate: 9.13540287137278e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1901 [0/90000 (0%)]	Loss: -5.5308	Cost: 25.41s
Train Epoch: 1901 [20480/90000 (23%)]	Loss: -11.9832	Cost: 8.36s
Train Epoch: 1901 [40960/90000 (45%)]	Loss: -12.0296	Cost: 9.15s
Train Epoch: 1901 [61440/90000 (68%)]	Loss: -12.2308	Cost: 8.88s
Train Epoch: 1901 [81920/90000 (91%)]	Loss: -11.8779	Cost: 8.50s
Train Epoch: 1901 	Average Loss: -11.6169
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9564

Learning rate: 9.134519748808071e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1902 [0/90000 (0%)]	Loss: -4.6150	Cost: 20.85s
Train Epoch: 1902 [20480/90000 (23%)]	Loss: -11.8554	Cost: 9.71s
Train Epoch: 1902 [40960/90000 (45%)]	Loss: -12.1154	Cost: 8.89s
Train Epoch: 1902 [61440/90000 (68%)]	Loss: -12.2761	Cost: 7.92s
Train Epoch: 1902 [81920/90000 (91%)]	Loss: -12.0065	Cost: 7.51s
Train Epoch: 1902 	Average Loss: -11.4947
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9914

Learning rate: 9.133636218182622e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1903 [0/90000 (0%)]	Loss: -5.9505	Cost: 19.38s
Train Epoch: 1903 [20480/90000 (23%)]	Loss: -12.0423	Cost: 6.61s
Train Epoch: 1903 [40960/90000 (45%)]	Loss: -11.9320	Cost: 9.66s
Train Epoch: 1903 [61440/90000 (68%)]	Loss: -12.2178	Cost: 11.50s
Train Epoch: 1903 [81920/90000 (91%)]	Loss: -11.8158	Cost: 14.32s
Train Epoch: 1903 	Average Loss: -11.5490
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8026

Learning rate: 9.132752279583634e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1904 [0/90000 (0%)]	Loss: -4.5603	Cost: 21.19s
Train Epoch: 1904 [20480/90000 (23%)]	Loss: -12.1245	Cost: 9.58s
Train Epoch: 1904 [40960/90000 (45%)]	Loss: -12.3000	Cost: 15.11s
Train Epoch: 1904 [61440/90000 (68%)]	Loss: -12.1692	Cost: 12.89s
Train Epoch: 1904 [81920/90000 (91%)]	Loss: -11.7223	Cost: 12.20s
Train Epoch: 1904 	Average Loss: -11.5987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0241

Learning rate: 9.13186793309835e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1905 [0/90000 (0%)]	Loss: -5.0421	Cost: 40.22s
Train Epoch: 1905 [20480/90000 (23%)]	Loss: -12.0312	Cost: 12.58s
Train Epoch: 1905 [40960/90000 (45%)]	Loss: -12.0409	Cost: 12.49s
Train Epoch: 1905 [61440/90000 (68%)]	Loss: -12.2077	Cost: 12.22s
Train Epoch: 1905 [81920/90000 (91%)]	Loss: -11.8932	Cost: 6.41s
Train Epoch: 1905 	Average Loss: -11.5680
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9772

Learning rate: 9.130983178814048e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1906 [0/90000 (0%)]	Loss: -5.4827	Cost: 27.61s
Train Epoch: 1906 [20480/90000 (23%)]	Loss: -12.0341	Cost: 9.59s
Train Epoch: 1906 [40960/90000 (45%)]	Loss: -12.1448	Cost: 8.54s
Train Epoch: 1906 [61440/90000 (68%)]	Loss: -12.1754	Cost: 6.31s
Train Epoch: 1906 [81920/90000 (91%)]	Loss: -11.8914	Cost: 7.66s
Train Epoch: 1906 	Average Loss: -11.6816
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0645

Saving model as e1906_model.pt & e1906_waveforms_supplementary.hdf5
Learning rate: 9.130098016818053e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1907 [0/90000 (0%)]	Loss: -4.9976	Cost: 24.60s
Train Epoch: 1907 [20480/90000 (23%)]	Loss: -11.9925	Cost: 8.63s
Train Epoch: 1907 [40960/90000 (45%)]	Loss: -12.0060	Cost: 10.58s
Train Epoch: 1907 [61440/90000 (68%)]	Loss: -11.8980	Cost: 9.11s
Train Epoch: 1907 [81920/90000 (91%)]	Loss: -11.6770	Cost: 9.08s
Train Epoch: 1907 	Average Loss: -11.4823
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8784

Learning rate: 9.129212447197726e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1908 [0/90000 (0%)]	Loss: -4.7315	Cost: 31.06s
Train Epoch: 1908 [20480/90000 (23%)]	Loss: -11.8130	Cost: 10.16s
Train Epoch: 1908 [40960/90000 (45%)]	Loss: -12.0666	Cost: 12.14s
Train Epoch: 1908 [61440/90000 (68%)]	Loss: -12.1786	Cost: 10.74s
Train Epoch: 1908 [81920/90000 (91%)]	Loss: -11.9991	Cost: 12.39s
Train Epoch: 1908 	Average Loss: -11.5249
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1030

Saving model as e1908_model.pt & e1908_waveforms_supplementary.hdf5
Learning rate: 9.128326470040468e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1909 [0/90000 (0%)]	Loss: -5.5948	Cost: 26.79s
Train Epoch: 1909 [20480/90000 (23%)]	Loss: -11.9861	Cost: 7.17s
Train Epoch: 1909 [40960/90000 (45%)]	Loss: -12.1176	Cost: 12.99s
Train Epoch: 1909 [61440/90000 (68%)]	Loss: -12.2210	Cost: 12.65s
Train Epoch: 1909 [81920/90000 (91%)]	Loss: -11.9329	Cost: 12.37s
Train Epoch: 1909 	Average Loss: -11.5813
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9552

Learning rate: 9.127440085433723e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1910 [0/90000 (0%)]	Loss: -5.7389	Cost: 25.09s
Train Epoch: 1910 [20480/90000 (23%)]	Loss: -11.9137	Cost: 13.71s
Train Epoch: 1910 [40960/90000 (45%)]	Loss: -11.9326	Cost: 12.29s
Train Epoch: 1910 [61440/90000 (68%)]	Loss: -12.1525	Cost: 12.14s
Train Epoch: 1910 [81920/90000 (91%)]	Loss: -11.8790	Cost: 10.12s
Train Epoch: 1910 	Average Loss: -11.5965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0381

Learning rate: 9.126553293464973e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1911 [0/90000 (0%)]	Loss: -4.0294	Cost: 24.48s
Train Epoch: 1911 [20480/90000 (23%)]	Loss: -8.9755	Cost: 12.34s
Train Epoch: 1911 [40960/90000 (45%)]	Loss: -9.9072	Cost: 11.71s
Train Epoch: 1911 [61440/90000 (68%)]	Loss: -10.2200	Cost: 6.27s
Train Epoch: 1911 [81920/90000 (91%)]	Loss: -10.5737	Cost: 6.51s
Train Epoch: 1911 	Average Loss: -9.4116
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9939

Learning rate: 9.125666094221739e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1912 [0/90000 (0%)]	Loss: -5.0975	Cost: 29.74s
Train Epoch: 1912 [20480/90000 (23%)]	Loss: -11.3511	Cost: 13.08s
Train Epoch: 1912 [40960/90000 (45%)]	Loss: -11.5175	Cost: 10.45s
Train Epoch: 1912 [61440/90000 (68%)]	Loss: -11.7643	Cost: 7.17s
Train Epoch: 1912 [81920/90000 (91%)]	Loss: -11.5332	Cost: 8.69s
Train Epoch: 1912 	Average Loss: -10.9546
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7536

Learning rate: 9.124778487791588e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1913 [0/90000 (0%)]	Loss: -4.5514	Cost: 20.58s
Train Epoch: 1913 [20480/90000 (23%)]	Loss: -11.5222	Cost: 10.27s
Train Epoch: 1913 [40960/90000 (45%)]	Loss: -11.6148	Cost: 10.44s
Train Epoch: 1913 [61440/90000 (68%)]	Loss: -11.7278	Cost: 8.21s
Train Epoch: 1913 [81920/90000 (91%)]	Loss: -11.6478	Cost: 8.85s
Train Epoch: 1913 	Average Loss: -11.2253
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8262

Learning rate: 9.12389047426212e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1914 [0/90000 (0%)]	Loss: -4.2115	Cost: 21.90s
Train Epoch: 1914 [20480/90000 (23%)]	Loss: -12.0312	Cost: 8.84s
Train Epoch: 1914 [40960/90000 (45%)]	Loss: -12.0288	Cost: 7.70s
Train Epoch: 1914 [61440/90000 (68%)]	Loss: -12.0988	Cost: 8.74s
Train Epoch: 1914 [81920/90000 (91%)]	Loss: -11.8483	Cost: 8.36s
Train Epoch: 1914 	Average Loss: -11.4397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8921

Learning rate: 9.12300205372098e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1915 [0/90000 (0%)]	Loss: -4.5634	Cost: 25.78s
Train Epoch: 1915 [20480/90000 (23%)]	Loss: -10.8448	Cost: 8.92s
Train Epoch: 1915 [40960/90000 (45%)]	Loss: -11.2045	Cost: 8.96s
Train Epoch: 1915 [61440/90000 (68%)]	Loss: -11.5008	Cost: 8.85s
Train Epoch: 1915 [81920/90000 (91%)]	Loss: -11.3726	Cost: 6.79s
Train Epoch: 1915 	Average Loss: -10.7228
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5833

Learning rate: 9.12211322625585e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1916 [0/90000 (0%)]	Loss: -5.2287	Cost: 22.07s
Train Epoch: 1916 [20480/90000 (23%)]	Loss: -11.6059	Cost: 7.56s
Train Epoch: 1916 [40960/90000 (45%)]	Loss: -11.7503	Cost: 6.80s
Train Epoch: 1916 [61440/90000 (68%)]	Loss: -11.7994	Cost: 6.62s
Train Epoch: 1916 [81920/90000 (91%)]	Loss: -11.1952	Cost: 16.29s
Train Epoch: 1916 	Average Loss: -11.0768
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5901

Learning rate: 9.121223991954458e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1917 [0/90000 (0%)]	Loss: -4.4696	Cost: 26.93s
Train Epoch: 1917 [20480/90000 (23%)]	Loss: -11.5390	Cost: 12.89s
Train Epoch: 1917 [40960/90000 (45%)]	Loss: -11.8772	Cost: 15.66s
Train Epoch: 1917 [61440/90000 (68%)]	Loss: -12.1105	Cost: 12.87s
Train Epoch: 1917 [81920/90000 (91%)]	Loss: -11.9181	Cost: 12.35s
Train Epoch: 1917 	Average Loss: -11.2967
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9250

Learning rate: 9.120334350904563e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1918 [0/90000 (0%)]	Loss: -5.0926	Cost: 25.46s
Train Epoch: 1918 [20480/90000 (23%)]	Loss: -11.9376	Cost: 15.46s
Train Epoch: 1918 [40960/90000 (45%)]	Loss: -12.0644	Cost: 14.39s
Train Epoch: 1918 [61440/90000 (68%)]	Loss: -12.0061	Cost: 12.41s
Train Epoch: 1918 [81920/90000 (91%)]	Loss: -11.8448	Cost: 10.13s
Train Epoch: 1918 	Average Loss: -11.4651
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8888

Learning rate: 9.11944430319397e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1919 [0/90000 (0%)]	Loss: -5.7478	Cost: 33.68s
Train Epoch: 1919 [20480/90000 (23%)]	Loss: -12.0808	Cost: 13.03s
Train Epoch: 1919 [40960/90000 (45%)]	Loss: -12.3171	Cost: 12.53s
Train Epoch: 1919 [61440/90000 (68%)]	Loss: -12.3113	Cost: 6.81s
Train Epoch: 1919 [81920/90000 (91%)]	Loss: -11.9996	Cost: 6.22s
Train Epoch: 1919 	Average Loss: -11.7098
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9784

Learning rate: 9.118553848910525e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1920 [0/90000 (0%)]	Loss: -4.1394	Cost: 26.24s
Train Epoch: 1920 [20480/90000 (23%)]	Loss: -12.1653	Cost: 6.58s
Train Epoch: 1920 [40960/90000 (45%)]	Loss: -12.1748	Cost: 8.98s
Train Epoch: 1920 [61440/90000 (68%)]	Loss: -12.0026	Cost: 8.92s
Train Epoch: 1920 [81920/90000 (91%)]	Loss: -12.0003	Cost: 8.69s
Train Epoch: 1920 	Average Loss: -11.6125
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1464

Saving model as e1920_model.pt & e1920_waveforms_supplementary.hdf5
Learning rate: 9.11766298814211e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1921 [0/90000 (0%)]	Loss: -5.6223	Cost: 25.52s
Train Epoch: 1921 [20480/90000 (23%)]	Loss: -11.9141	Cost: 8.41s
Train Epoch: 1921 [40960/90000 (45%)]	Loss: -12.0616	Cost: 8.94s
Train Epoch: 1921 [61440/90000 (68%)]	Loss: -12.0668	Cost: 8.54s
Train Epoch: 1921 [81920/90000 (91%)]	Loss: -11.9566	Cost: 8.42s
Train Epoch: 1921 	Average Loss: -11.5663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0551

Learning rate: 9.116771720976654e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1922 [0/90000 (0%)]	Loss: -5.1757	Cost: 22.84s
Train Epoch: 1922 [20480/90000 (23%)]	Loss: -12.1411	Cost: 8.99s
Train Epoch: 1922 [40960/90000 (45%)]	Loss: -12.1847	Cost: 8.97s
Train Epoch: 1922 [61440/90000 (68%)]	Loss: -12.3307	Cost: 7.91s
Train Epoch: 1922 [81920/90000 (91%)]	Loss: -12.0922	Cost: 8.31s
Train Epoch: 1922 	Average Loss: -11.7160
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2066

Saving model as e1922_model.pt & e1922_waveforms_supplementary.hdf5
Learning rate: 9.115880047502117e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1923 [0/90000 (0%)]	Loss: -4.4999	Cost: 20.69s
Train Epoch: 1923 [20480/90000 (23%)]	Loss: -12.2485	Cost: 10.05s
Train Epoch: 1923 [40960/90000 (45%)]	Loss: -12.2402	Cost: 17.12s
Train Epoch: 1923 [61440/90000 (68%)]	Loss: -12.1243	Cost: 14.21s
Train Epoch: 1923 [81920/90000 (91%)]	Loss: -11.9979	Cost: 12.55s
Train Epoch: 1923 	Average Loss: -11.6238
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9453

Learning rate: 9.114987967806504e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1924 [0/90000 (0%)]	Loss: -5.0999	Cost: 38.10s
Train Epoch: 1924 [20480/90000 (23%)]	Loss: -12.0623	Cost: 12.41s
Train Epoch: 1924 [40960/90000 (45%)]	Loss: -12.2716	Cost: 12.61s
Train Epoch: 1924 [61440/90000 (68%)]	Loss: -12.3449	Cost: 12.22s
Train Epoch: 1924 [81920/90000 (91%)]	Loss: -11.8798	Cost: 9.02s
Train Epoch: 1924 	Average Loss: -11.6578
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9374

Learning rate: 9.114095481977862e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1925 [0/90000 (0%)]	Loss: -4.6426	Cost: 27.19s
Train Epoch: 1925 [20480/90000 (23%)]	Loss: -12.0478	Cost: 13.13s
Train Epoch: 1925 [40960/90000 (45%)]	Loss: -12.2120	Cost: 9.69s
Train Epoch: 1925 [61440/90000 (68%)]	Loss: -12.1818	Cost: 6.06s
Train Epoch: 1925 [81920/90000 (91%)]	Loss: -12.1517	Cost: 7.50s
Train Epoch: 1925 	Average Loss: -11.6539
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1230

Learning rate: 9.113202590104274e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1926 [0/90000 (0%)]	Loss: -5.4661	Cost: 21.59s
Train Epoch: 1926 [20480/90000 (23%)]	Loss: -12.1413	Cost: 6.76s
Train Epoch: 1926 [40960/90000 (45%)]	Loss: -12.1855	Cost: 8.19s
Train Epoch: 1926 [61440/90000 (68%)]	Loss: -12.2501	Cost: 9.17s
Train Epoch: 1926 [81920/90000 (91%)]	Loss: -12.0370	Cost: 8.86s
Train Epoch: 1926 	Average Loss: -11.7109
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0544

Learning rate: 9.112309292273865e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1927 [0/90000 (0%)]	Loss: -5.2448	Cost: 22.32s
Train Epoch: 1927 [20480/90000 (23%)]	Loss: -12.4263	Cost: 9.09s
Train Epoch: 1927 [40960/90000 (45%)]	Loss: -12.3093	Cost: 9.43s
Train Epoch: 1927 [61440/90000 (68%)]	Loss: -12.1905	Cost: 8.45s
Train Epoch: 1927 [81920/90000 (91%)]	Loss: -11.9567	Cost: 6.84s
Train Epoch: 1927 	Average Loss: -11.6951
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0106

Learning rate: 9.111415588574802e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1928 [0/90000 (0%)]	Loss: -5.0776	Cost: 24.08s
Train Epoch: 1928 [20480/90000 (23%)]	Loss: -12.1606	Cost: 8.93s
Train Epoch: 1928 [40960/90000 (45%)]	Loss: -12.2522	Cost: 10.71s
Train Epoch: 1928 [61440/90000 (68%)]	Loss: -12.2099	Cost: 9.16s
Train Epoch: 1928 [81920/90000 (91%)]	Loss: -11.9427	Cost: 13.73s
Train Epoch: 1928 	Average Loss: -11.6268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9966

Learning rate: 9.110521479095288e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1929 [0/90000 (0%)]	Loss: -5.5182	Cost: 26.15s
Train Epoch: 1929 [20480/90000 (23%)]	Loss: -12.2542	Cost: 10.95s
Train Epoch: 1929 [40960/90000 (45%)]	Loss: -12.2437	Cost: 14.33s
Train Epoch: 1929 [61440/90000 (68%)]	Loss: -12.0952	Cost: 12.50s
Train Epoch: 1929 [81920/90000 (91%)]	Loss: -11.7522	Cost: 12.44s
Train Epoch: 1929 	Average Loss: -11.5960
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9596

Learning rate: 9.109626963923566e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1930 [0/90000 (0%)]	Loss: -5.1855	Cost: 28.52s
Train Epoch: 1930 [20480/90000 (23%)]	Loss: -12.1879	Cost: 12.82s
Train Epoch: 1930 [40960/90000 (45%)]	Loss: -12.1911	Cost: 12.91s
Train Epoch: 1930 [61440/90000 (68%)]	Loss: -12.2872	Cost: 12.40s
Train Epoch: 1930 [81920/90000 (91%)]	Loss: -11.7992	Cost: 9.63s
Train Epoch: 1930 	Average Loss: -11.6275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0386

Learning rate: 9.108732043147926e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1931 [0/90000 (0%)]	Loss: -5.2387	Cost: 24.47s
Train Epoch: 1931 [20480/90000 (23%)]	Loss: -12.2044	Cost: 12.50s
Train Epoch: 1931 [40960/90000 (45%)]	Loss: -12.3034	Cost: 12.36s
Train Epoch: 1931 [61440/90000 (68%)]	Loss: -12.3693	Cost: 7.95s
Train Epoch: 1931 [81920/90000 (91%)]	Loss: -11.8572	Cost: 6.72s
Train Epoch: 1931 	Average Loss: -11.6749
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6873

Learning rate: 9.10783671685669e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1932 [0/90000 (0%)]	Loss: -4.9073	Cost: 23.22s
Train Epoch: 1932 [20480/90000 (23%)]	Loss: -12.0503	Cost: 6.43s
Train Epoch: 1932 [40960/90000 (45%)]	Loss: -12.0095	Cost: 8.36s
Train Epoch: 1932 [61440/90000 (68%)]	Loss: -12.2898	Cost: 8.98s
Train Epoch: 1932 [81920/90000 (91%)]	Loss: -11.9543	Cost: 9.07s
Train Epoch: 1932 	Average Loss: -11.5395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9975

Learning rate: 9.106940985138223e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1933 [0/90000 (0%)]	Loss: -5.3290	Cost: 27.54s
Train Epoch: 1933 [20480/90000 (23%)]	Loss: -12.1006	Cost: 9.08s
Train Epoch: 1933 [40960/90000 (45%)]	Loss: -12.1204	Cost: 10.61s
Train Epoch: 1933 [61440/90000 (68%)]	Loss: -12.1519	Cost: 9.20s
Train Epoch: 1933 [81920/90000 (91%)]	Loss: -12.0425	Cost: 8.63s
Train Epoch: 1933 	Average Loss: -11.6296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9467

Learning rate: 9.106044848080932e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1934 [0/90000 (0%)]	Loss: -5.2171	Cost: 32.47s
Train Epoch: 1934 [20480/90000 (23%)]	Loss: -12.1852	Cost: 8.74s
Train Epoch: 1934 [40960/90000 (45%)]	Loss: -12.0188	Cost: 8.61s
Train Epoch: 1934 [61440/90000 (68%)]	Loss: -12.3778	Cost: 6.09s
Train Epoch: 1934 [81920/90000 (91%)]	Loss: -11.8660	Cost: 6.92s
Train Epoch: 1934 	Average Loss: -11.7101
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2022

Learning rate: 9.105148305773263e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1935 [0/90000 (0%)]	Loss: -5.6489	Cost: 18.33s
Train Epoch: 1935 [20480/90000 (23%)]	Loss: -12.2052	Cost: 8.77s
Train Epoch: 1935 [40960/90000 (45%)]	Loss: -12.3556	Cost: 10.95s
Train Epoch: 1935 [61440/90000 (68%)]	Loss: -12.4182	Cost: 12.64s
Train Epoch: 1935 [81920/90000 (91%)]	Loss: -11.9819	Cost: 12.73s
Train Epoch: 1935 	Average Loss: -11.8264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1895

Learning rate: 9.104251358303697e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1936 [0/90000 (0%)]	Loss: -5.9948	Cost: 25.54s
Train Epoch: 1936 [20480/90000 (23%)]	Loss: -12.2290	Cost: 13.04s
Train Epoch: 1936 [40960/90000 (45%)]	Loss: -12.3726	Cost: 12.39s
Train Epoch: 1936 [61440/90000 (68%)]	Loss: -12.2685	Cost: 12.36s
Train Epoch: 1936 [81920/90000 (91%)]	Loss: -11.8393	Cost: 12.41s
Train Epoch: 1936 	Average Loss: -11.7149
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1397

Learning rate: 9.103354005760764e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1937 [0/90000 (0%)]	Loss: -5.1884	Cost: 25.26s
Train Epoch: 1937 [20480/90000 (23%)]	Loss: -12.1130	Cost: 14.05s
Train Epoch: 1937 [40960/90000 (45%)]	Loss: -12.1581	Cost: 12.53s
Train Epoch: 1937 [61440/90000 (68%)]	Loss: -12.2306	Cost: 11.98s
Train Epoch: 1937 [81920/90000 (91%)]	Loss: -11.6811	Cost: 6.04s
Train Epoch: 1937 	Average Loss: -11.6471
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7741

Learning rate: 9.102456248233025e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1938 [0/90000 (0%)]	Loss: -5.3305	Cost: 33.71s
Train Epoch: 1938 [20480/90000 (23%)]	Loss: -11.8478	Cost: 9.90s
Train Epoch: 1938 [40960/90000 (45%)]	Loss: -11.9154	Cost: 6.46s
Train Epoch: 1938 [61440/90000 (68%)]	Loss: -12.0625	Cost: 6.28s
Train Epoch: 1938 [81920/90000 (91%)]	Loss: -11.9256	Cost: 8.82s
Train Epoch: 1938 	Average Loss: -11.4557
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9978

Learning rate: 9.101558085809087e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1939 [0/90000 (0%)]	Loss: -5.9062	Cost: 25.35s
Train Epoch: 1939 [20480/90000 (23%)]	Loss: -12.3320	Cost: 6.71s
Train Epoch: 1939 [40960/90000 (45%)]	Loss: -12.2202	Cost: 9.37s
Train Epoch: 1939 [61440/90000 (68%)]	Loss: -12.3751	Cost: 8.69s
Train Epoch: 1939 [81920/90000 (91%)]	Loss: -12.1188	Cost: 8.36s
Train Epoch: 1939 	Average Loss: -11.7502
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0805

Learning rate: 9.100659518577597e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1940 [0/90000 (0%)]	Loss: -4.0781	Cost: 24.14s
Train Epoch: 1940 [20480/90000 (23%)]	Loss: -12.1746	Cost: 10.13s
Train Epoch: 1940 [40960/90000 (45%)]	Loss: -12.2073	Cost: 10.06s
Train Epoch: 1940 [61440/90000 (68%)]	Loss: -12.3183	Cost: 9.38s
Train Epoch: 1940 [81920/90000 (91%)]	Loss: -12.0291	Cost: 10.65s
Train Epoch: 1940 	Average Loss: -11.6873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0926

Learning rate: 9.099760546627236e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1941 [0/90000 (0%)]	Loss: -5.3631	Cost: 18.96s
Train Epoch: 1941 [20480/90000 (23%)]	Loss: -12.2995	Cost: 9.69s
Train Epoch: 1941 [40960/90000 (45%)]	Loss: -12.2514	Cost: 10.23s
Train Epoch: 1941 [61440/90000 (68%)]	Loss: -12.0000	Cost: 13.78s
Train Epoch: 1941 [81920/90000 (91%)]	Loss: -12.0473	Cost: 13.95s
Train Epoch: 1941 	Average Loss: -11.6826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9940

Learning rate: 9.09886117004673e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1942 [0/90000 (0%)]	Loss: -5.0537	Cost: 21.37s
Train Epoch: 1942 [20480/90000 (23%)]	Loss: -12.2382	Cost: 10.63s
Train Epoch: 1942 [40960/90000 (45%)]	Loss: -12.3824	Cost: 15.03s
Train Epoch: 1942 [61440/90000 (68%)]	Loss: -12.3109	Cost: 12.52s
Train Epoch: 1942 [81920/90000 (91%)]	Loss: -11.9477	Cost: 12.06s
Train Epoch: 1942 	Average Loss: -11.7302
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0141

Learning rate: 9.097961388924847e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1943 [0/90000 (0%)]	Loss: -5.5428	Cost: 38.77s
Train Epoch: 1943 [20480/90000 (23%)]	Loss: -12.0006	Cost: 12.60s
Train Epoch: 1943 [40960/90000 (45%)]	Loss: -12.2038	Cost: 12.32s
Train Epoch: 1943 [61440/90000 (68%)]	Loss: -12.4826	Cost: 12.29s
Train Epoch: 1943 [81920/90000 (91%)]	Loss: -11.9742	Cost: 8.28s
Train Epoch: 1943 	Average Loss: -11.6528
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9217

Learning rate: 9.09706120335039e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1944 [0/90000 (0%)]	Loss: -5.0467	Cost: 34.80s
Train Epoch: 1944 [20480/90000 (23%)]	Loss: -12.4052	Cost: 12.17s
Train Epoch: 1944 [40960/90000 (45%)]	Loss: -12.4390	Cost: 12.33s
Train Epoch: 1944 [61440/90000 (68%)]	Loss: -12.3499	Cost: 6.36s
Train Epoch: 1944 [81920/90000 (91%)]	Loss: -12.3751	Cost: 6.08s
Train Epoch: 1944 	Average Loss: -11.8429
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2945

Saving model as e1944_model.pt & e1944_waveforms_supplementary.hdf5
Learning rate: 9.096160613412202e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1945 [0/90000 (0%)]	Loss: -4.9625	Cost: 26.80s
Train Epoch: 1945 [20480/90000 (23%)]	Loss: -12.4945	Cost: 7.28s
Train Epoch: 1945 [40960/90000 (45%)]	Loss: -12.3864	Cost: 11.86s
Train Epoch: 1945 [61440/90000 (68%)]	Loss: -12.3357	Cost: 9.02s
Train Epoch: 1945 [81920/90000 (91%)]	Loss: -12.1981	Cost: 9.16s
Train Epoch: 1945 	Average Loss: -11.8450
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1323

Learning rate: 9.095259619199171e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1946 [0/90000 (0%)]	Loss: -4.8465	Cost: 26.43s
Train Epoch: 1946 [20480/90000 (23%)]	Loss: -12.2826	Cost: 10.88s
Train Epoch: 1946 [40960/90000 (45%)]	Loss: -12.3782	Cost: 8.78s
Train Epoch: 1946 [61440/90000 (68%)]	Loss: -12.6953	Cost: 6.72s
Train Epoch: 1946 [81920/90000 (91%)]	Loss: -12.1151	Cost: 6.69s
Train Epoch: 1946 	Average Loss: -11.8498
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2437

Learning rate: 9.094358220800217e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1947 [0/90000 (0%)]	Loss: -5.4976	Cost: 21.19s
Train Epoch: 1947 [20480/90000 (23%)]	Loss: -12.2971	Cost: 8.06s
Train Epoch: 1947 [40960/90000 (45%)]	Loss: -12.5598	Cost: 11.73s
Train Epoch: 1947 [61440/90000 (68%)]	Loss: -12.3426	Cost: 12.89s
Train Epoch: 1947 [81920/90000 (91%)]	Loss: -12.3040	Cost: 12.42s
Train Epoch: 1947 	Average Loss: -11.9047
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2370

Learning rate: 9.09345641830431e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1948 [0/90000 (0%)]	Loss: -5.0618	Cost: 23.08s
Train Epoch: 1948 [20480/90000 (23%)]	Loss: -12.4684	Cost: 13.56s
Train Epoch: 1948 [40960/90000 (45%)]	Loss: -12.4470	Cost: 12.52s
Train Epoch: 1948 [61440/90000 (68%)]	Loss: -12.4079	Cost: 12.19s
Train Epoch: 1948 [81920/90000 (91%)]	Loss: -12.3873	Cost: 12.52s
Train Epoch: 1948 	Average Loss: -11.9273
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3119

Saving model as e1948_model.pt & e1948_waveforms_supplementary.hdf5
Learning rate: 9.09255421180045e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1949 [0/90000 (0%)]	Loss: -5.5773	Cost: 23.48s
Train Epoch: 1949 [20480/90000 (23%)]	Loss: -12.3531	Cost: 14.02s
Train Epoch: 1949 [40960/90000 (45%)]	Loss: -12.4492	Cost: 12.51s
Train Epoch: 1949 [61440/90000 (68%)]	Loss: -12.3741	Cost: 7.83s
Train Epoch: 1949 [81920/90000 (91%)]	Loss: -12.3663	Cost: 6.23s
Train Epoch: 1949 	Average Loss: -11.8448
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2810

Learning rate: 9.091651601377684e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1950 [0/90000 (0%)]	Loss: -4.5278	Cost: 31.92s
Train Epoch: 1950 [20480/90000 (23%)]	Loss: -12.4486	Cost: 13.31s
Train Epoch: 1950 [40960/90000 (45%)]	Loss: -12.5346	Cost: 8.41s
Train Epoch: 1950 [61440/90000 (68%)]	Loss: -12.5325	Cost: 6.61s
Train Epoch: 1950 [81920/90000 (91%)]	Loss: -12.2426	Cost: 8.55s
Train Epoch: 1950 	Average Loss: -11.9172
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3211

Saving model as e1950_model.pt & e1950_waveforms_supplementary.hdf5
Learning rate: 9.090748587125094e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1951 [0/90000 (0%)]	Loss: -4.6617	Cost: 23.40s
Train Epoch: 1951 [20480/90000 (23%)]	Loss: -12.3974	Cost: 10.91s
Train Epoch: 1951 [40960/90000 (45%)]	Loss: -12.3226	Cost: 10.37s
Train Epoch: 1951 [61440/90000 (68%)]	Loss: -12.6261	Cost: 8.82s
Train Epoch: 1951 [81920/90000 (91%)]	Loss: -12.2758	Cost: 8.74s
Train Epoch: 1951 	Average Loss: -11.8550
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2983

Learning rate: 9.089845169131804e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1952 [0/90000 (0%)]	Loss: -5.7395	Cost: 22.97s
Train Epoch: 1952 [20480/90000 (23%)]	Loss: -12.3042	Cost: 8.95s
Train Epoch: 1952 [40960/90000 (45%)]	Loss: -12.4194	Cost: 8.97s
Train Epoch: 1952 [61440/90000 (68%)]	Loss: -12.3172	Cost: 8.84s
Train Epoch: 1952 [81920/90000 (91%)]	Loss: -11.8752	Cost: 8.72s
Train Epoch: 1952 	Average Loss: -11.8626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9591

Learning rate: 9.08894134748698e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1953 [0/90000 (0%)]	Loss: -4.5519	Cost: 22.44s
Train Epoch: 1953 [20480/90000 (23%)]	Loss: -12.0152	Cost: 9.22s
Train Epoch: 1953 [40960/90000 (45%)]	Loss: -12.3253	Cost: 7.17s
Train Epoch: 1953 [61440/90000 (68%)]	Loss: -12.2336	Cost: 6.46s
Train Epoch: 1953 [81920/90000 (91%)]	Loss: -12.1885	Cost: 6.57s
Train Epoch: 1953 	Average Loss: -11.6705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1249

Learning rate: 9.088037122279823e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1954 [0/90000 (0%)]	Loss: -4.7095	Cost: 22.31s
Train Epoch: 1954 [20480/90000 (23%)]	Loss: -12.2770	Cost: 7.02s
Train Epoch: 1954 [40960/90000 (45%)]	Loss: -12.5475	Cost: 13.55s
Train Epoch: 1954 [61440/90000 (68%)]	Loss: -12.4608	Cost: 13.02s
Train Epoch: 1954 [81920/90000 (91%)]	Loss: -12.1768	Cost: 12.36s
Train Epoch: 1954 	Average Loss: -11.8656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0001

Learning rate: 9.087132493599577e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1955 [0/90000 (0%)]	Loss: -3.3842	Cost: 37.73s
Train Epoch: 1955 [20480/90000 (23%)]	Loss: -12.0866	Cost: 14.92s
Train Epoch: 1955 [40960/90000 (45%)]	Loss: -12.3301	Cost: 12.53s
Train Epoch: 1955 [61440/90000 (68%)]	Loss: -12.2624	Cost: 12.03s
Train Epoch: 1955 [81920/90000 (91%)]	Loss: -12.2738	Cost: 9.32s
Train Epoch: 1955 	Average Loss: -11.6651
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2412

Learning rate: 9.086227461535529e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1956 [0/90000 (0%)]	Loss: -5.8032	Cost: 39.50s
Train Epoch: 1956 [20480/90000 (23%)]	Loss: -12.3120	Cost: 12.38s
Train Epoch: 1956 [40960/90000 (45%)]	Loss: -12.5756	Cost: 10.31s
Train Epoch: 1956 [61440/90000 (68%)]	Loss: -12.2114	Cost: 6.16s
Train Epoch: 1956 [81920/90000 (91%)]	Loss: -12.1920	Cost: 7.30s
Train Epoch: 1956 	Average Loss: -11.9086
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0910

Learning rate: 9.085322026176996e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1957 [0/90000 (0%)]	Loss: -4.4183	Cost: 21.07s
Train Epoch: 1957 [20480/90000 (23%)]	Loss: -12.2981	Cost: 7.53s
Train Epoch: 1957 [40960/90000 (45%)]	Loss: -12.4174	Cost: 6.97s
Train Epoch: 1957 [61440/90000 (68%)]	Loss: -12.4346	Cost: 7.65s
Train Epoch: 1957 [81920/90000 (91%)]	Loss: -12.1417	Cost: 8.96s
Train Epoch: 1957 	Average Loss: -11.8448
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2691

Learning rate: 9.084416187613343e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1958 [0/90000 (0%)]	Loss: -5.7770	Cost: 22.13s
Train Epoch: 1958 [20480/90000 (23%)]	Loss: -12.3825	Cost: 8.97s
Train Epoch: 1958 [40960/90000 (45%)]	Loss: -12.4685	Cost: 8.99s
Train Epoch: 1958 [61440/90000 (68%)]	Loss: -12.5113	Cost: 9.00s
Train Epoch: 1958 [81920/90000 (91%)]	Loss: -11.9995	Cost: 8.01s
Train Epoch: 1958 	Average Loss: -11.8198
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9823

Learning rate: 9.083509945933975e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1959 [0/90000 (0%)]	Loss: -5.6677	Cost: 23.13s
Train Epoch: 1959 [20480/90000 (23%)]	Loss: -12.4319	Cost: 8.08s
Train Epoch: 1959 [40960/90000 (45%)]	Loss: -12.4813	Cost: 13.94s
Train Epoch: 1959 [61440/90000 (68%)]	Loss: -12.3582	Cost: 12.63s
Train Epoch: 1959 [81920/90000 (91%)]	Loss: -12.2196	Cost: 12.33s
Train Epoch: 1959 	Average Loss: -11.8209
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2121

Learning rate: 9.082603301228332e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1960 [0/90000 (0%)]	Loss: -5.6326	Cost: 25.24s
Train Epoch: 1960 [20480/90000 (23%)]	Loss: -12.4051	Cost: 13.02s
Train Epoch: 1960 [40960/90000 (45%)]	Loss: -12.1826	Cost: 12.63s
Train Epoch: 1960 [61440/90000 (68%)]	Loss: -12.4198	Cost: 12.30s
Train Epoch: 1960 [81920/90000 (91%)]	Loss: -12.2029	Cost: 12.39s
Train Epoch: 1960 	Average Loss: -11.8398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2664

Learning rate: 9.081696253585899e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1961 [0/90000 (0%)]	Loss: -5.8182	Cost: 26.80s
Train Epoch: 1961 [20480/90000 (23%)]	Loss: -12.2644	Cost: 12.20s
Train Epoch: 1961 [40960/90000 (45%)]	Loss: -12.6791	Cost: 12.63s
Train Epoch: 1961 [61440/90000 (68%)]	Loss: -12.5629	Cost: 11.78s
Train Epoch: 1961 [81920/90000 (91%)]	Loss: -12.3524	Cost: 6.24s
Train Epoch: 1961 	Average Loss: -11.9177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2020

Learning rate: 9.080788803096196e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1962 [0/90000 (0%)]	Loss: -4.6827	Cost: 34.57s
Train Epoch: 1962 [20480/90000 (23%)]	Loss: -12.3789	Cost: 12.31s
Train Epoch: 1962 [40960/90000 (45%)]	Loss: -12.3096	Cost: 11.29s
Train Epoch: 1962 [61440/90000 (68%)]	Loss: -12.3696	Cost: 6.44s
Train Epoch: 1962 [81920/90000 (91%)]	Loss: -12.2205	Cost: 6.58s
Train Epoch: 1962 	Average Loss: -11.8288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2368

Learning rate: 9.079880949848785e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1963 [0/90000 (0%)]	Loss: -5.4574	Cost: 24.07s
Train Epoch: 1963 [20480/90000 (23%)]	Loss: -12.2797	Cost: 12.13s
Train Epoch: 1963 [40960/90000 (45%)]	Loss: -12.4888	Cost: 9.40s
Train Epoch: 1963 [61440/90000 (68%)]	Loss: -12.5669	Cost: 8.49s
Train Epoch: 1963 [81920/90000 (91%)]	Loss: -12.2217	Cost: 8.47s
Train Epoch: 1963 	Average Loss: -11.9349
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0349

Learning rate: 9.078972693933266e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1964 [0/90000 (0%)]	Loss: -5.0732	Cost: 21.63s
Train Epoch: 1964 [20480/90000 (23%)]	Loss: -12.2576	Cost: 8.20s
Train Epoch: 1964 [40960/90000 (45%)]	Loss: -12.2887	Cost: 10.43s
Train Epoch: 1964 [61440/90000 (68%)]	Loss: -12.3762	Cost: 8.84s
Train Epoch: 1964 [81920/90000 (91%)]	Loss: -12.3092	Cost: 8.61s
Train Epoch: 1964 	Average Loss: -11.7598
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1928

Learning rate: 9.078064035439282e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1965 [0/90000 (0%)]	Loss: -5.1746	Cost: 29.82s
Train Epoch: 1965 [20480/90000 (23%)]	Loss: -12.2779	Cost: 7.97s
Train Epoch: 1965 [40960/90000 (45%)]	Loss: -12.4847	Cost: 8.99s
Train Epoch: 1965 [61440/90000 (68%)]	Loss: -12.4793	Cost: 8.74s
Train Epoch: 1965 [81920/90000 (91%)]	Loss: -12.2647	Cost: 8.69s
Train Epoch: 1965 	Average Loss: -11.8949
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2491

Learning rate: 9.077154974456515e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1966 [0/90000 (0%)]	Loss: -5.4062	Cost: 28.46s
Train Epoch: 1966 [20480/90000 (23%)]	Loss: -12.1709	Cost: 8.55s
Train Epoch: 1966 [40960/90000 (45%)]	Loss: -12.3534	Cost: 6.25s
Train Epoch: 1966 [61440/90000 (68%)]	Loss: -12.4939	Cost: 6.50s
Train Epoch: 1966 [81920/90000 (91%)]	Loss: -12.3308	Cost: 11.93s
Train Epoch: 1966 	Average Loss: -11.9561
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2109

Learning rate: 9.076245511074684e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1967 [0/90000 (0%)]	Loss: -4.7295	Cost: 20.86s
Train Epoch: 1967 [20480/90000 (23%)]	Loss: -12.3679	Cost: 9.68s
Train Epoch: 1967 [40960/90000 (45%)]	Loss: -12.5532	Cost: 15.90s
Train Epoch: 1967 [61440/90000 (68%)]	Loss: -12.4468	Cost: 13.18s
Train Epoch: 1967 [81920/90000 (91%)]	Loss: -12.1712	Cost: 12.70s
Train Epoch: 1967 	Average Loss: -11.9249
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2385

Learning rate: 9.07533564538355e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1968 [0/90000 (0%)]	Loss: -5.6518	Cost: 26.10s
Train Epoch: 1968 [20480/90000 (23%)]	Loss: -12.4077	Cost: 13.87s
Train Epoch: 1968 [40960/90000 (45%)]	Loss: -12.6004	Cost: 14.00s
Train Epoch: 1968 [61440/90000 (68%)]	Loss: -12.7862	Cost: 12.68s
Train Epoch: 1968 [81920/90000 (91%)]	Loss: -12.3500	Cost: 9.22s
Train Epoch: 1968 	Average Loss: -12.0674
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3395

Saving model as e1968_model.pt & e1968_waveforms_supplementary.hdf5
Learning rate: 9.074425377472912e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1969 [0/90000 (0%)]	Loss: -5.8812	Cost: 30.75s
Train Epoch: 1969 [20480/90000 (23%)]	Loss: -12.1664	Cost: 12.57s
Train Epoch: 1969 [40960/90000 (45%)]	Loss: -12.1242	Cost: 8.16s
Train Epoch: 1969 [61440/90000 (68%)]	Loss: -12.2552	Cost: 6.16s
Train Epoch: 1969 [81920/90000 (91%)]	Loss: -12.0637	Cost: 7.80s
Train Epoch: 1969 	Average Loss: -11.7824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3361

Learning rate: 9.073514707432611e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1970 [0/90000 (0%)]	Loss: -4.2920	Cost: 29.46s
Train Epoch: 1970 [20480/90000 (23%)]	Loss: -12.4391	Cost: 6.66s
Train Epoch: 1970 [40960/90000 (45%)]	Loss: -12.2986	Cost: 10.06s
Train Epoch: 1970 [61440/90000 (68%)]	Loss: -12.4496	Cost: 8.87s
Train Epoch: 1970 [81920/90000 (91%)]	Loss: -12.2633	Cost: 8.75s
Train Epoch: 1970 	Average Loss: -11.8332
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2354

Learning rate: 9.072603635352528e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1971 [0/90000 (0%)]	Loss: -4.6847	Cost: 25.98s
Train Epoch: 1971 [20480/90000 (23%)]	Loss: -12.3276	Cost: 9.21s
Train Epoch: 1971 [40960/90000 (45%)]	Loss: -12.6243	Cost: 8.99s
Train Epoch: 1971 [61440/90000 (68%)]	Loss: -12.6158	Cost: 8.45s
Train Epoch: 1971 [81920/90000 (91%)]	Loss: -12.2854	Cost: 7.04s
Train Epoch: 1971 	Average Loss: -11.9476
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1464

Learning rate: 9.071692161322579e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1972 [0/90000 (0%)]	Loss: -5.9922	Cost: 21.97s
Train Epoch: 1972 [20480/90000 (23%)]	Loss: -12.3976	Cost: 9.37s
Train Epoch: 1972 [40960/90000 (45%)]	Loss: -12.4956	Cost: 11.34s
Train Epoch: 1972 [61440/90000 (68%)]	Loss: -12.3894	Cost: 13.88s
Train Epoch: 1972 [81920/90000 (91%)]	Loss: -12.2108	Cost: 13.29s
Train Epoch: 1972 	Average Loss: -11.9144
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2285

Learning rate: 9.070780285432725e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1973 [0/90000 (0%)]	Loss: -5.8196	Cost: 21.07s
Train Epoch: 1973 [20480/90000 (23%)]	Loss: -12.5615	Cost: 10.90s
Train Epoch: 1973 [40960/90000 (45%)]	Loss: -12.5524	Cost: 15.16s
Train Epoch: 1973 [61440/90000 (68%)]	Loss: -12.2120	Cost: 14.29s
Train Epoch: 1973 [81920/90000 (91%)]	Loss: -12.1723	Cost: 12.27s
Train Epoch: 1973 	Average Loss: -11.9165
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1557

Learning rate: 9.069868007772965e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1974 [0/90000 (0%)]	Loss: -5.2726	Cost: 38.47s
Train Epoch: 1974 [20480/90000 (23%)]	Loss: -12.1656	Cost: 12.58s
Train Epoch: 1974 [40960/90000 (45%)]	Loss: -12.4491	Cost: 12.47s
Train Epoch: 1974 [61440/90000 (68%)]	Loss: -12.3145	Cost: 12.23s
Train Epoch: 1974 [81920/90000 (91%)]	Loss: -12.0363	Cost: 9.71s
Train Epoch: 1974 	Average Loss: -11.8088
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2137

Learning rate: 9.068955328433336e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1975 [0/90000 (0%)]	Loss: -5.1806	Cost: 24.09s
Train Epoch: 1975 [20480/90000 (23%)]	Loss: -12.2513	Cost: 9.30s
Train Epoch: 1975 [40960/90000 (45%)]	Loss: -12.5769	Cost: 10.71s
Train Epoch: 1975 [61440/90000 (68%)]	Loss: -12.4334	Cost: 6.11s
Train Epoch: 1975 [81920/90000 (91%)]	Loss: -12.1460	Cost: 7.57s
Train Epoch: 1975 	Average Loss: -11.8668
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1494

Learning rate: 9.068042247503917e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1976 [0/90000 (0%)]	Loss: -5.3730	Cost: 19.73s
Train Epoch: 1976 [20480/90000 (23%)]	Loss: -12.4618	Cost: 8.56s
Train Epoch: 1976 [40960/90000 (45%)]	Loss: -12.7408	Cost: 9.86s
Train Epoch: 1976 [61440/90000 (68%)]	Loss: -12.4155	Cost: 8.89s
Train Epoch: 1976 [81920/90000 (91%)]	Loss: -12.0010	Cost: 8.78s
Train Epoch: 1976 	Average Loss: -11.9278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2878

Learning rate: 9.067128765074822e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1977 [0/90000 (0%)]	Loss: -4.9195	Cost: 23.52s
Train Epoch: 1977 [20480/90000 (23%)]	Loss: -12.4671	Cost: 9.27s
Train Epoch: 1977 [40960/90000 (45%)]	Loss: -12.7253	Cost: 8.97s
Train Epoch: 1977 [61440/90000 (68%)]	Loss: -12.6680	Cost: 8.54s
Train Epoch: 1977 [81920/90000 (91%)]	Loss: -12.1884	Cost: 6.13s
Train Epoch: 1977 	Average Loss: -11.9737
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2913

Learning rate: 9.066214881236213e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1978 [0/90000 (0%)]	Loss: -5.3901	Cost: 24.68s
Train Epoch: 1978 [20480/90000 (23%)]	Loss: -12.5185	Cost: 7.18s
Train Epoch: 1978 [40960/90000 (45%)]	Loss: -12.6487	Cost: 7.51s
Train Epoch: 1978 [61440/90000 (68%)]	Loss: -12.5215	Cost: 7.13s
Train Epoch: 1978 [81920/90000 (91%)]	Loss: -12.1855	Cost: 13.49s
Train Epoch: 1978 	Average Loss: -12.0149
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2449

Learning rate: 9.065300596078284e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1979 [0/90000 (0%)]	Loss: -5.3563	Cost: 19.89s
Train Epoch: 1979 [20480/90000 (23%)]	Loss: -12.4820	Cost: 9.44s
Train Epoch: 1979 [40960/90000 (45%)]	Loss: -11.7205	Cost: 16.80s
Train Epoch: 1979 [61440/90000 (68%)]	Loss: -11.8673	Cost: 13.04s
Train Epoch: 1979 [81920/90000 (91%)]	Loss: -11.7981	Cost: 12.22s
Train Epoch: 1979 	Average Loss: -11.5615
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1396

Learning rate: 9.064385909691271e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1980 [0/90000 (0%)]	Loss: -3.8074	Cost: 25.08s
Train Epoch: 1980 [20480/90000 (23%)]	Loss: -12.0621	Cost: 12.37s
Train Epoch: 1980 [40960/90000 (45%)]	Loss: -12.3943	Cost: 12.83s
Train Epoch: 1980 [61440/90000 (68%)]	Loss: -12.5528	Cost: 12.61s
Train Epoch: 1980 [81920/90000 (91%)]	Loss: -12.1734	Cost: 11.22s
Train Epoch: 1980 	Average Loss: -11.6973
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3298

Learning rate: 9.06347082216545e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1981 [0/90000 (0%)]	Loss: -5.3965	Cost: 24.13s
Train Epoch: 1981 [20480/90000 (23%)]	Loss: -12.3788	Cost: 13.51s
Train Epoch: 1981 [40960/90000 (45%)]	Loss: -12.5540	Cost: 12.47s
Train Epoch: 1981 [61440/90000 (68%)]	Loss: -12.5292	Cost: 11.98s
Train Epoch: 1981 [81920/90000 (91%)]	Loss: -12.3149	Cost: 5.97s
Train Epoch: 1981 	Average Loss: -11.9875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3327

Learning rate: 9.062555333591139e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1982 [0/90000 (0%)]	Loss: -5.5402	Cost: 40.79s
Train Epoch: 1982 [20480/90000 (23%)]	Loss: -12.6042	Cost: 10.33s
Train Epoch: 1982 [40960/90000 (45%)]	Loss: -12.8557	Cost: 6.56s
Train Epoch: 1982 [61440/90000 (68%)]	Loss: -12.7007	Cost: 6.67s
Train Epoch: 1982 [81920/90000 (91%)]	Loss: -12.2411	Cost: 8.71s
Train Epoch: 1982 	Average Loss: -12.1054
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3279

Learning rate: 9.06163944405869e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1983 [0/90000 (0%)]	Loss: -4.4940	Cost: 31.13s
Train Epoch: 1983 [20480/90000 (23%)]	Loss: -12.4705	Cost: 6.94s
Train Epoch: 1983 [40960/90000 (45%)]	Loss: -12.5712	Cost: 10.10s
Train Epoch: 1983 [61440/90000 (68%)]	Loss: -12.3213	Cost: 8.94s
Train Epoch: 1983 [81920/90000 (91%)]	Loss: -11.9362	Cost: 8.70s
Train Epoch: 1983 	Average Loss: -11.8440
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2206

Learning rate: 9.0607231536585e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1984 [0/90000 (0%)]	Loss: -4.4505	Cost: 21.03s
Train Epoch: 1984 [20480/90000 (23%)]	Loss: -12.3418	Cost: 9.08s
Train Epoch: 1984 [40960/90000 (45%)]	Loss: -12.5185	Cost: 8.98s
Train Epoch: 1984 [61440/90000 (68%)]	Loss: -12.4483	Cost: 8.78s
Train Epoch: 1984 [81920/90000 (91%)]	Loss: -12.2943	Cost: 7.57s
Train Epoch: 1984 	Average Loss: -11.7711
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2644

Learning rate: 9.059806462481002e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1985 [0/90000 (0%)]	Loss: -5.5124	Cost: 21.19s
Train Epoch: 1985 [20480/90000 (23%)]	Loss: -12.4554	Cost: 9.18s
Train Epoch: 1985 [40960/90000 (45%)]	Loss: -12.6167	Cost: 8.14s
Train Epoch: 1985 [61440/90000 (68%)]	Loss: -12.7581	Cost: 6.31s
Train Epoch: 1985 [81920/90000 (91%)]	Loss: -12.3591	Cost: 7.83s
Train Epoch: 1985 	Average Loss: -12.0627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4766

Saving model as e1985_model.pt & e1985_waveforms_supplementary.hdf5
Learning rate: 9.05888937061667e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1986 [0/90000 (0%)]	Loss: -5.1077	Cost: 19.51s
Train Epoch: 1986 [20480/90000 (23%)]	Loss: -12.2700	Cost: 10.36s
Train Epoch: 1986 [40960/90000 (45%)]	Loss: -12.4417	Cost: 14.76s
Train Epoch: 1986 [61440/90000 (68%)]	Loss: -12.6706	Cost: 12.56s
Train Epoch: 1986 [81920/90000 (91%)]	Loss: -12.0019	Cost: 12.17s
Train Epoch: 1986 	Average Loss: -11.8752
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2280

Learning rate: 9.057971878156017e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1987 [0/90000 (0%)]	Loss: -5.4738	Cost: 31.56s
Train Epoch: 1987 [20480/90000 (23%)]	Loss: -12.1565	Cost: 11.29s
Train Epoch: 1987 [40960/90000 (45%)]	Loss: -12.2764	Cost: 12.55s
Train Epoch: 1987 [61440/90000 (68%)]	Loss: -12.5000	Cost: 12.38s
Train Epoch: 1987 [81920/90000 (91%)]	Loss: -12.2478	Cost: 12.02s
Train Epoch: 1987 	Average Loss: -11.8647
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3297

Learning rate: 9.057053985189597e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1988 [0/90000 (0%)]	Loss: -6.0706	Cost: 30.12s
Train Epoch: 1988 [20480/90000 (23%)]	Loss: -12.5082	Cost: 9.65s
Train Epoch: 1988 [40960/90000 (45%)]	Loss: -12.6289	Cost: 12.14s
Train Epoch: 1988 [61440/90000 (68%)]	Loss: -12.4729	Cost: 12.50s
Train Epoch: 1988 [81920/90000 (91%)]	Loss: -11.5965	Cost: 9.66s
Train Epoch: 1988 	Average Loss: -11.8886
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8886

Learning rate: 9.056135691808e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1989 [0/90000 (0%)]	Loss: -5.1242	Cost: 37.85s
Train Epoch: 1989 [20480/90000 (23%)]	Loss: -12.0061	Cost: 13.93s
Train Epoch: 1989 [40960/90000 (45%)]	Loss: -12.3217	Cost: 12.72s
Train Epoch: 1989 [61440/90000 (68%)]	Loss: -12.2260	Cost: 10.76s
Train Epoch: 1989 [81920/90000 (91%)]	Loss: -12.0981	Cost: 6.11s
Train Epoch: 1989 	Average Loss: -11.6349
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3438

Learning rate: 9.05521699810186e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1990 [0/90000 (0%)]	Loss: -5.7897	Cost: 25.31s
Train Epoch: 1990 [20480/90000 (23%)]	Loss: -12.6672	Cost: 13.50s
Train Epoch: 1990 [40960/90000 (45%)]	Loss: -12.4769	Cost: 10.67s
Train Epoch: 1990 [61440/90000 (68%)]	Loss: -12.6773	Cost: 6.47s
Train Epoch: 1990 [81920/90000 (91%)]	Loss: -12.0691	Cost: 6.89s
Train Epoch: 1990 	Average Loss: -12.0110
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2438

Learning rate: 9.054297904161849e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1991 [0/90000 (0%)]	Loss: -5.4635	Cost: 31.17s
Train Epoch: 1991 [20480/90000 (23%)]	Loss: -12.4710	Cost: 6.35s
Train Epoch: 1991 [40960/90000 (45%)]	Loss: -12.4077	Cost: 10.21s
Train Epoch: 1991 [61440/90000 (68%)]	Loss: -12.5127	Cost: 8.70s
Train Epoch: 1991 [81920/90000 (91%)]	Loss: -12.2933	Cost: 8.63s
Train Epoch: 1991 	Average Loss: -11.9393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4383

Learning rate: 9.053378410078676e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1992 [0/90000 (0%)]	Loss: -4.7753	Cost: 19.55s
Train Epoch: 1992 [20480/90000 (23%)]	Loss: -12.3568	Cost: 8.39s
Train Epoch: 1992 [40960/90000 (45%)]	Loss: -12.4905	Cost: 9.14s
Train Epoch: 1992 [61440/90000 (68%)]	Loss: -12.6990	Cost: 8.53s
Train Epoch: 1992 [81920/90000 (91%)]	Loss: -12.2037	Cost: 8.52s
Train Epoch: 1992 	Average Loss: -12.0138
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5086

Saving model as e1992_model.pt & e1992_waveforms_supplementary.hdf5
Learning rate: 9.052458515943094e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1993 [0/90000 (0%)]	Loss: -5.6457	Cost: 19.51s
Train Epoch: 1993 [20480/90000 (23%)]	Loss: -12.3805	Cost: 6.54s
Train Epoch: 1993 [40960/90000 (45%)]	Loss: -12.2321	Cost: 14.43s
Train Epoch: 1993 [61440/90000 (68%)]	Loss: -12.6237	Cost: 12.07s
Train Epoch: 1993 [81920/90000 (91%)]	Loss: -12.4427	Cost: 12.25s
Train Epoch: 1993 	Average Loss: -11.9158
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4598

Learning rate: 9.051538221845889e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1994 [0/90000 (0%)]	Loss: -4.6137	Cost: 25.49s
Train Epoch: 1994 [20480/90000 (23%)]	Loss: -12.2947	Cost: 11.04s
Train Epoch: 1994 [40960/90000 (45%)]	Loss: -12.6753	Cost: 16.95s
Train Epoch: 1994 [61440/90000 (68%)]	Loss: -12.7447	Cost: 12.47s
Train Epoch: 1994 [81920/90000 (91%)]	Loss: -12.2775	Cost: 12.00s
Train Epoch: 1994 	Average Loss: -11.9649
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3966

Learning rate: 9.050617527877894e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1995 [0/90000 (0%)]	Loss: -6.1078	Cost: 39.41s
Train Epoch: 1995 [20480/90000 (23%)]	Loss: -12.3941	Cost: 13.47s
Train Epoch: 1995 [40960/90000 (45%)]	Loss: -12.3886	Cost: 12.34s
Train Epoch: 1995 [61440/90000 (68%)]	Loss: -12.4319	Cost: 12.10s
Train Epoch: 1995 [81920/90000 (91%)]	Loss: -12.3316	Cost: 6.46s
Train Epoch: 1995 	Average Loss: -11.9345
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4331

Learning rate: 9.049696434129976e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1996 [0/90000 (0%)]	Loss: -5.3335	Cost: 26.01s
Train Epoch: 1996 [20480/90000 (23%)]	Loss: -12.2315	Cost: 10.74s
Train Epoch: 1996 [40960/90000 (45%)]	Loss: -12.4872	Cost: 11.84s
Train Epoch: 1996 [61440/90000 (68%)]	Loss: -12.7186	Cost: 8.05s
Train Epoch: 1996 [81920/90000 (91%)]	Loss: -12.1700	Cost: 6.76s
Train Epoch: 1996 	Average Loss: -11.8723
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3125

Learning rate: 9.048774940693044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1997 [0/90000 (0%)]	Loss: -6.0170	Cost: 22.40s
Train Epoch: 1997 [20480/90000 (23%)]	Loss: -12.4070	Cost: 6.59s
Train Epoch: 1997 [40960/90000 (45%)]	Loss: -12.5657	Cost: 10.26s
Train Epoch: 1997 [61440/90000 (68%)]	Loss: -12.6260	Cost: 9.25s
Train Epoch: 1997 [81920/90000 (91%)]	Loss: -12.4154	Cost: 9.17s
Train Epoch: 1997 	Average Loss: -12.0074
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4360

Learning rate: 9.047853047658045e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1998 [0/90000 (0%)]	Loss: -5.9716	Cost: 26.23s
Train Epoch: 1998 [20480/90000 (23%)]	Loss: -12.6467	Cost: 8.87s
Train Epoch: 1998 [40960/90000 (45%)]	Loss: -12.4020	Cost: 8.88s
Train Epoch: 1998 [61440/90000 (68%)]	Loss: -12.5117	Cost: 6.41s
Train Epoch: 1998 [81920/90000 (91%)]	Loss: -12.3681	Cost: 6.61s
Train Epoch: 1998 	Average Loss: -11.9733
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3256

Learning rate: 9.046930755115967e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1999 [0/90000 (0%)]	Loss: -3.2957	Cost: 22.46s
Train Epoch: 1999 [20480/90000 (23%)]	Loss: -12.5138	Cost: 7.11s
Train Epoch: 1999 [40960/90000 (45%)]	Loss: -12.7090	Cost: 9.21s
Train Epoch: 1999 [61440/90000 (68%)]	Loss: -12.6790	Cost: 12.45s
Train Epoch: 1999 [81920/90000 (91%)]	Loss: -12.5630	Cost: 12.32s
Train Epoch: 1999 	Average Loss: -11.9740
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4582

Learning rate: 9.046008063157837e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2000 [0/90000 (0%)]	Loss: -6.3479	Cost: 23.02s
Train Epoch: 2000 [20480/90000 (23%)]	Loss: -12.6405	Cost: 10.05s
Train Epoch: 2000 [40960/90000 (45%)]	Loss: -12.8143	Cost: 13.09s
Train Epoch: 2000 [61440/90000 (68%)]	Loss: -12.7536	Cost: 12.35s
Train Epoch: 2000 [81920/90000 (91%)]	Loss: -12.3358	Cost: 12.30s
Train Epoch: 2000 	Average Loss: -12.1979
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3628

Learning rate: 9.04508497187472e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2001 [0/90000 (0%)]	Loss: -5.9266	Cost: 27.17s
Train Epoch: 2001 [20480/90000 (23%)]	Loss: -12.3824	Cost: 15.62s
Train Epoch: 2001 [40960/90000 (45%)]	Loss: -12.4779	Cost: 14.80s
Train Epoch: 2001 [61440/90000 (68%)]	Loss: -12.6967	Cost: 12.51s
Train Epoch: 2001 [81920/90000 (91%)]	Loss: -12.4535	Cost: 12.17s
Train Epoch: 2001 	Average Loss: -12.0855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4351

Learning rate: 9.044161481357723e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2002 [0/90000 (0%)]	Loss: -5.2129	Cost: 30.94s
Train Epoch: 2002 [20480/90000 (23%)]	Loss: -12.5748	Cost: 12.38s
Train Epoch: 2002 [40960/90000 (45%)]	Loss: -12.6358	Cost: 13.89s
Train Epoch: 2002 [61440/90000 (68%)]	Loss: -12.6073	Cost: 12.34s
Train Epoch: 2002 [81920/90000 (91%)]	Loss: -12.4376	Cost: 8.40s
Train Epoch: 2002 	Average Loss: -11.9901
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3846

Learning rate: 9.043237591697987e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2003 [0/90000 (0%)]	Loss: -6.0993	Cost: 33.76s
Train Epoch: 2003 [20480/90000 (23%)]	Loss: -12.5853	Cost: 12.68s
Train Epoch: 2003 [40960/90000 (45%)]	Loss: -12.8208	Cost: 12.25s
Train Epoch: 2003 [61440/90000 (68%)]	Loss: -12.6067	Cost: 10.93s
Train Epoch: 2003 [81920/90000 (91%)]	Loss: -12.5604	Cost: 6.36s
Train Epoch: 2003 	Average Loss: -12.0991
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3459

Learning rate: 9.0423133029867e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2004 [0/90000 (0%)]	Loss: -5.9807	Cost: 32.08s
Train Epoch: 2004 [20480/90000 (23%)]	Loss: -12.3910	Cost: 12.23s
Train Epoch: 2004 [40960/90000 (45%)]	Loss: -12.6031	Cost: 10.13s
Train Epoch: 2004 [61440/90000 (68%)]	Loss: -12.8000	Cost: 6.14s
Train Epoch: 2004 [81920/90000 (91%)]	Loss: -12.4515	Cost: 6.95s
Train Epoch: 2004 	Average Loss: -12.0888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2018

Learning rate: 9.041388615315085e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2005 [0/90000 (0%)]	Loss: -5.6037	Cost: 25.71s
Train Epoch: 2005 [20480/90000 (23%)]	Loss: -12.4047	Cost: 7.07s
Train Epoch: 2005 [40960/90000 (45%)]	Loss: -12.7249	Cost: 9.94s
Train Epoch: 2005 [61440/90000 (68%)]	Loss: -12.8563	Cost: 8.65s
Train Epoch: 2005 [81920/90000 (91%)]	Loss: -12.4679	Cost: 8.52s
Train Epoch: 2005 	Average Loss: -12.0968
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5022

Learning rate: 9.040463528774405e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2006 [0/90000 (0%)]	Loss: -5.2218	Cost: 24.45s
Train Epoch: 2006 [20480/90000 (23%)]	Loss: -12.7614	Cost: 9.60s
Train Epoch: 2006 [40960/90000 (45%)]	Loss: -12.7544	Cost: 10.40s
Train Epoch: 2006 [61440/90000 (68%)]	Loss: -12.7074	Cost: 9.00s
Train Epoch: 2006 [81920/90000 (91%)]	Loss: -12.5149	Cost: 8.12s
Train Epoch: 2006 	Average Loss: -12.1893
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3780

Learning rate: 9.039538043455962e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2007 [0/90000 (0%)]	Loss: -5.8433	Cost: 22.74s
Train Epoch: 2007 [20480/90000 (23%)]	Loss: -12.6865	Cost: 10.35s
Train Epoch: 2007 [40960/90000 (45%)]	Loss: -12.8302	Cost: 10.38s
Train Epoch: 2007 [61440/90000 (68%)]	Loss: -12.8680	Cost: 11.74s
Train Epoch: 2007 [81920/90000 (91%)]	Loss: -12.7654	Cost: 12.61s
Train Epoch: 2007 	Average Loss: -12.3171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5160

Saving model as e2007_model.pt & e2007_waveforms_supplementary.hdf5
Learning rate: 9.038612159451097e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2008 [0/90000 (0%)]	Loss: -6.5008	Cost: 29.90s
Train Epoch: 2008 [20480/90000 (23%)]	Loss: -12.6264	Cost: 13.56s
Train Epoch: 2008 [40960/90000 (45%)]	Loss: -12.7957	Cost: 12.58s
Train Epoch: 2008 [61440/90000 (68%)]	Loss: -12.7203	Cost: 12.24s
Train Epoch: 2008 [81920/90000 (91%)]	Loss: -12.5086	Cost: 12.21s
Train Epoch: 2008 	Average Loss: -12.1879
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2782

Learning rate: 9.037685876851193e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2009 [0/90000 (0%)]	Loss: -4.3811	Cost: 24.13s
Train Epoch: 2009 [20480/90000 (23%)]	Loss: -12.6398	Cost: 13.72s
Train Epoch: 2009 [40960/90000 (45%)]	Loss: -12.7345	Cost: 12.40s
Train Epoch: 2009 [61440/90000 (68%)]	Loss: -12.6986	Cost: 7.91s
Train Epoch: 2009 [81920/90000 (91%)]	Loss: -12.5467	Cost: 6.51s
Train Epoch: 2009 	Average Loss: -12.0908
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2198

Learning rate: 9.036759195747669e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2010 [0/90000 (0%)]	Loss: -5.4011	Cost: 23.14s
Train Epoch: 2010 [20480/90000 (23%)]	Loss: -12.6269	Cost: 6.89s
Train Epoch: 2010 [40960/90000 (45%)]	Loss: -12.7645	Cost: 7.25s
Train Epoch: 2010 [61440/90000 (68%)]	Loss: -12.8324	Cost: 8.24s
Train Epoch: 2010 [81920/90000 (91%)]	Loss: -12.6143	Cost: 9.06s
Train Epoch: 2010 	Average Loss: -12.2045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0061

Learning rate: 9.035832116231983e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2011 [0/90000 (0%)]	Loss: -5.7984	Cost: 25.70s
Train Epoch: 2011 [20480/90000 (23%)]	Loss: -12.0681	Cost: 9.77s
Train Epoch: 2011 [40960/90000 (45%)]	Loss: -12.5790	Cost: 10.09s
Train Epoch: 2011 [61440/90000 (68%)]	Loss: -12.4494	Cost: 8.85s
Train Epoch: 2011 [81920/90000 (91%)]	Loss: -12.2063	Cost: 8.66s
Train Epoch: 2011 	Average Loss: -11.7796
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2758

Learning rate: 9.034904638395638e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2012 [0/90000 (0%)]	Loss: -5.6971	Cost: 29.03s
Train Epoch: 2012 [20480/90000 (23%)]	Loss: -12.6660	Cost: 9.13s
Train Epoch: 2012 [40960/90000 (45%)]	Loss: -12.5805	Cost: 8.61s
Train Epoch: 2012 [61440/90000 (68%)]	Loss: -12.7545	Cost: 6.29s
Train Epoch: 2012 [81920/90000 (91%)]	Loss: -12.6088	Cost: 6.60s
Train Epoch: 2012 	Average Loss: -12.1630
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4392

Learning rate: 9.033976762330172e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2013 [0/90000 (0%)]	Loss: -5.4772	Cost: 21.30s
Train Epoch: 2013 [20480/90000 (23%)]	Loss: -12.7068	Cost: 6.86s
Train Epoch: 2013 [40960/90000 (45%)]	Loss: -12.9805	Cost: 10.29s
Train Epoch: 2013 [61440/90000 (68%)]	Loss: -12.7381	Cost: 12.99s
Train Epoch: 2013 [81920/90000 (91%)]	Loss: -12.3885	Cost: 12.27s
Train Epoch: 2013 	Average Loss: -12.1619
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2071

Learning rate: 9.033048488127158e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2014 [0/90000 (0%)]	Loss: -3.7510	Cost: 21.81s
Train Epoch: 2014 [20480/90000 (23%)]	Loss: -12.4634	Cost: 10.88s
Train Epoch: 2014 [40960/90000 (45%)]	Loss: -12.8149	Cost: 12.66s
Train Epoch: 2014 [61440/90000 (68%)]	Loss: -12.8083	Cost: 12.39s
Train Epoch: 2014 [81920/90000 (91%)]	Loss: -12.5896	Cost: 12.51s
Train Epoch: 2014 	Average Loss: -12.1262
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3216

Learning rate: 9.032119815878218e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2015 [0/90000 (0%)]	Loss: -5.5556	Cost: 24.48s
Train Epoch: 2015 [20480/90000 (23%)]	Loss: -12.5352	Cost: 15.00s
Train Epoch: 2015 [40960/90000 (45%)]	Loss: -12.9295	Cost: 13.78s
Train Epoch: 2015 [61440/90000 (68%)]	Loss: -12.9814	Cost: 12.16s
Train Epoch: 2015 [81920/90000 (91%)]	Loss: -12.5250	Cost: 8.97s
Train Epoch: 2015 	Average Loss: -12.2302
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4322

Learning rate: 9.031190745675007e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2016 [0/90000 (0%)]	Loss: -5.9725	Cost: 41.09s
Train Epoch: 2016 [20480/90000 (23%)]	Loss: -12.6031	Cost: 9.84s
Train Epoch: 2016 [40960/90000 (45%)]	Loss: -12.9244	Cost: 8.13s
Train Epoch: 2016 [61440/90000 (68%)]	Loss: -12.9741	Cost: 6.30s
Train Epoch: 2016 [81920/90000 (91%)]	Loss: -12.4643	Cost: 7.98s
Train Epoch: 2016 	Average Loss: -12.2432
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3426

Learning rate: 9.030261277609217e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2017 [0/90000 (0%)]	Loss: -5.5786	Cost: 37.43s
Train Epoch: 2017 [20480/90000 (23%)]	Loss: -12.7533	Cost: 7.65s
Train Epoch: 2017 [40960/90000 (45%)]	Loss: -12.5782	Cost: 7.45s
Train Epoch: 2017 [61440/90000 (68%)]	Loss: -12.7759	Cost: 8.29s
Train Epoch: 2017 [81920/90000 (91%)]	Loss: -12.4891	Cost: 8.64s
Train Epoch: 2017 	Average Loss: -12.1986
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4962

Learning rate: 9.02933141177259e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2018 [0/90000 (0%)]	Loss: -5.5089	Cost: 22.73s
Train Epoch: 2018 [20480/90000 (23%)]	Loss: -12.8441	Cost: 6.91s
Train Epoch: 2018 [40960/90000 (45%)]	Loss: -12.9979	Cost: 9.47s
Train Epoch: 2018 [61440/90000 (68%)]	Loss: -12.6301	Cost: 8.93s
Train Epoch: 2018 [81920/90000 (91%)]	Loss: -12.5748	Cost: 8.73s
Train Epoch: 2018 	Average Loss: -12.2331
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3929

Learning rate: 9.028401148256893e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2019 [0/90000 (0%)]	Loss: -5.9286	Cost: 22.43s
Train Epoch: 2019 [20480/90000 (23%)]	Loss: -12.6918	Cost: 9.00s
Train Epoch: 2019 [40960/90000 (45%)]	Loss: -12.6821	Cost: 9.15s
Train Epoch: 2019 [61440/90000 (68%)]	Loss: -12.7064	Cost: 8.25s
Train Epoch: 2019 [81920/90000 (91%)]	Loss: -12.2761	Cost: 7.92s
Train Epoch: 2019 	Average Loss: -12.1441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2216

Learning rate: 9.027470487153944e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2020 [0/90000 (0%)]	Loss: -5.9777	Cost: 18.51s
Train Epoch: 2020 [20480/90000 (23%)]	Loss: -12.4771	Cost: 9.73s
Train Epoch: 2020 [40960/90000 (45%)]	Loss: -12.5659	Cost: 13.61s
Train Epoch: 2020 [61440/90000 (68%)]	Loss: -12.6395	Cost: 13.27s
Train Epoch: 2020 [81920/90000 (91%)]	Loss: -12.5265	Cost: 12.41s
Train Epoch: 2020 	Average Loss: -12.0872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3526

Learning rate: 9.026539428555592e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2021 [0/90000 (0%)]	Loss: -6.0732	Cost: 31.12s
Train Epoch: 2021 [20480/90000 (23%)]	Loss: -12.3834	Cost: 11.30s
Train Epoch: 2021 [40960/90000 (45%)]	Loss: -12.6310	Cost: 13.80s
Train Epoch: 2021 [61440/90000 (68%)]	Loss: -12.7958	Cost: 12.48s
Train Epoch: 2021 [81920/90000 (91%)]	Loss: -12.7628	Cost: 12.17s
Train Epoch: 2021 	Average Loss: -12.1145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5292

Saving model as e2021_model.pt & e2021_waveforms_supplementary.hdf5
Learning rate: 9.025607972553731e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2022 [0/90000 (0%)]	Loss: -3.7215	Cost: 29.26s
Train Epoch: 2022 [20480/90000 (23%)]	Loss: -12.6174	Cost: 11.97s
Train Epoch: 2022 [40960/90000 (45%)]	Loss: -12.9146	Cost: 12.14s
Train Epoch: 2022 [61440/90000 (68%)]	Loss: -12.6174	Cost: 12.17s
Train Epoch: 2022 [81920/90000 (91%)]	Loss: -12.5270	Cost: 9.05s
Train Epoch: 2022 	Average Loss: -12.1529
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4055

Learning rate: 9.024676119240294e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2023 [0/90000 (0%)]	Loss: -5.0911	Cost: 29.93s
Train Epoch: 2023 [20480/90000 (23%)]	Loss: -12.6168	Cost: 13.47s
Train Epoch: 2023 [40960/90000 (45%)]	Loss: -12.6053	Cost: 12.66s
Train Epoch: 2023 [61440/90000 (68%)]	Loss: -12.6407	Cost: 9.23s
Train Epoch: 2023 [81920/90000 (91%)]	Loss: -12.4865	Cost: 6.39s
Train Epoch: 2023 	Average Loss: -12.1099
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4100

Learning rate: 9.023743868707245e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2024 [0/90000 (0%)]	Loss: -5.4066	Cost: 25.05s
Train Epoch: 2024 [20480/90000 (23%)]	Loss: -12.6508	Cost: 10.04s
Train Epoch: 2024 [40960/90000 (45%)]	Loss: -12.5135	Cost: 11.38s
Train Epoch: 2024 [61440/90000 (68%)]	Loss: -12.6588	Cost: 8.18s
Train Epoch: 2024 [81920/90000 (91%)]	Loss: -12.2233	Cost: 8.00s
Train Epoch: 2024 	Average Loss: -12.0817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3553

Learning rate: 9.0228112210466e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2025 [0/90000 (0%)]	Loss: -5.8243	Cost: 20.53s
Train Epoch: 2025 [20480/90000 (23%)]	Loss: -12.6459	Cost: 6.49s
Train Epoch: 2025 [40960/90000 (45%)]	Loss: -12.6960	Cost: 8.22s
Train Epoch: 2025 [61440/90000 (68%)]	Loss: -12.6855	Cost: 8.42s
Train Epoch: 2025 [81920/90000 (91%)]	Loss: -12.6375	Cost: 8.81s
Train Epoch: 2025 	Average Loss: -12.1961
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3108

Learning rate: 9.021878176350403e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2026 [0/90000 (0%)]	Loss: -4.8984	Cost: 21.16s
Train Epoch: 2026 [20480/90000 (23%)]	Loss: -12.6526	Cost: 9.67s
Train Epoch: 2026 [40960/90000 (45%)]	Loss: -12.8570	Cost: 10.45s
Train Epoch: 2026 [61440/90000 (68%)]	Loss: -11.9508	Cost: 8.74s
Train Epoch: 2026 [81920/90000 (91%)]	Loss: -11.9124	Cost: 8.47s
Train Epoch: 2026 	Average Loss: -11.9887
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0834

Learning rate: 9.020944734710745e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2027 [0/90000 (0%)]	Loss: -4.9104	Cost: 32.44s
Train Epoch: 2027 [20480/90000 (23%)]	Loss: -12.3495	Cost: 10.10s
Train Epoch: 2027 [40960/90000 (45%)]	Loss: -12.1571	Cost: 9.61s
Train Epoch: 2027 [61440/90000 (68%)]	Loss: -12.4019	Cost: 8.77s
Train Epoch: 2027 [81920/90000 (91%)]	Loss: -12.2515	Cost: 6.96s
Train Epoch: 2027 	Average Loss: -11.7550
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2756

Learning rate: 9.020010896219752e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2028 [0/90000 (0%)]	Loss: -5.6273	Cost: 19.77s
Train Epoch: 2028 [20480/90000 (23%)]	Loss: -12.4163	Cost: 6.68s
Train Epoch: 2028 [40960/90000 (45%)]	Loss: -12.6307	Cost: 11.18s
Train Epoch: 2028 [61440/90000 (68%)]	Loss: -12.6769	Cost: 10.34s
Train Epoch: 2028 [81920/90000 (91%)]	Loss: -12.2917	Cost: 14.63s
Train Epoch: 2028 	Average Loss: -12.0496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5285

Learning rate: 9.019076660969589e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2029 [0/90000 (0%)]	Loss: -5.6234	Cost: 24.49s
Train Epoch: 2029 [20480/90000 (23%)]	Loss: -12.6111	Cost: 12.19s
Train Epoch: 2029 [40960/90000 (45%)]	Loss: -12.7948	Cost: 12.53s
Train Epoch: 2029 [61440/90000 (68%)]	Loss: -12.6901	Cost: 12.53s
Train Epoch: 2029 [81920/90000 (91%)]	Loss: -12.4724	Cost: 12.48s
Train Epoch: 2029 	Average Loss: -12.1279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3363

Learning rate: 9.018142029052463e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2030 [0/90000 (0%)]	Loss: -5.3827	Cost: 23.07s
Train Epoch: 2030 [20480/90000 (23%)]	Loss: -12.6903	Cost: 12.27s
Train Epoch: 2030 [40960/90000 (45%)]	Loss: -12.7794	Cost: 13.75s
Train Epoch: 2030 [61440/90000 (68%)]	Loss: -12.7924	Cost: 11.96s
Train Epoch: 2030 [81920/90000 (91%)]	Loss: -12.5718	Cost: 9.52s
Train Epoch: 2030 	Average Loss: -12.2392
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2717

Learning rate: 9.017207000560619e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2031 [0/90000 (0%)]	Loss: -5.8780	Cost: 40.97s
Train Epoch: 2031 [20480/90000 (23%)]	Loss: -12.4458	Cost: 12.49s
Train Epoch: 2031 [40960/90000 (45%)]	Loss: -12.8306	Cost: 9.69s
Train Epoch: 2031 [61440/90000 (68%)]	Loss: -12.9386	Cost: 6.03s
Train Epoch: 2031 [81920/90000 (91%)]	Loss: -12.3854	Cost: 6.95s
Train Epoch: 2031 	Average Loss: -12.2076
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4195

Learning rate: 9.016271575586336e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2032 [0/90000 (0%)]	Loss: -4.9554	Cost: 38.33s
Train Epoch: 2032 [20480/90000 (23%)]	Loss: -12.5844	Cost: 10.37s
Train Epoch: 2032 [40960/90000 (45%)]	Loss: -12.8445	Cost: 6.54s
Train Epoch: 2032 [61440/90000 (68%)]	Loss: -12.8239	Cost: 6.85s
Train Epoch: 2032 [81920/90000 (91%)]	Loss: -12.4786	Cost: 8.95s
Train Epoch: 2032 	Average Loss: -12.1835
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3817

Learning rate: 9.015335754221943e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2033 [0/90000 (0%)]	Loss: -6.1741	Cost: 30.14s
Train Epoch: 2033 [20480/90000 (23%)]	Loss: -12.7174	Cost: 6.41s
Train Epoch: 2033 [40960/90000 (45%)]	Loss: -13.1473	Cost: 8.46s
Train Epoch: 2033 [61440/90000 (68%)]	Loss: -12.9101	Cost: 8.92s
Train Epoch: 2033 [81920/90000 (91%)]	Loss: -12.5541	Cost: 8.80s
Train Epoch: 2033 	Average Loss: -12.2982
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4952

Learning rate: 9.014399536559798e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2034 [0/90000 (0%)]	Loss: -4.6199	Cost: 21.64s
Train Epoch: 2034 [20480/90000 (23%)]	Loss: -12.5005	Cost: 9.15s
Train Epoch: 2034 [40960/90000 (45%)]	Loss: -12.6850	Cost: 8.89s
Train Epoch: 2034 [61440/90000 (68%)]	Loss: -12.4916	Cost: 8.35s
Train Epoch: 2034 [81920/90000 (91%)]	Loss: -12.4535	Cost: 6.52s
Train Epoch: 2034 	Average Loss: -11.9454
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4068

Learning rate: 9.013462922692302e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2035 [0/90000 (0%)]	Loss: -6.0106	Cost: 18.96s
Train Epoch: 2035 [20480/90000 (23%)]	Loss: -12.5449	Cost: 9.71s
Train Epoch: 2035 [40960/90000 (45%)]	Loss: -12.9311	Cost: 15.61s
Train Epoch: 2035 [61440/90000 (68%)]	Loss: -12.7631	Cost: 12.53s
Train Epoch: 2035 [81920/90000 (91%)]	Loss: -12.6116	Cost: 12.27s
Train Epoch: 2035 	Average Loss: -12.2608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4211

Learning rate: 9.012525912711897e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2036 [0/90000 (0%)]	Loss: -6.4569	Cost: 27.59s
Train Epoch: 2036 [20480/90000 (23%)]	Loss: -12.6124	Cost: 9.11s
Train Epoch: 2036 [40960/90000 (45%)]	Loss: -12.8240	Cost: 14.55s
Train Epoch: 2036 [61440/90000 (68%)]	Loss: -12.8647	Cost: 12.47s
Train Epoch: 2036 [81920/90000 (91%)]	Loss: -12.2515	Cost: 12.28s
Train Epoch: 2036 	Average Loss: -12.1579
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3165

Learning rate: 9.011588506711062e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2037 [0/90000 (0%)]	Loss: -4.8892	Cost: 30.35s
Train Epoch: 2037 [20480/90000 (23%)]	Loss: -12.3420	Cost: 12.71s
Train Epoch: 2037 [40960/90000 (45%)]	Loss: -12.5796	Cost: 12.41s
Train Epoch: 2037 [61440/90000 (68%)]	Loss: -12.8528	Cost: 12.45s
Train Epoch: 2037 [81920/90000 (91%)]	Loss: -12.6356	Cost: 11.49s
Train Epoch: 2037 	Average Loss: -12.1637
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5091

Learning rate: 9.010650704782314e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2038 [0/90000 (0%)]	Loss: -6.1635	Cost: 41.10s
Train Epoch: 2038 [20480/90000 (23%)]	Loss: -12.5907	Cost: 14.18s
Train Epoch: 2038 [40960/90000 (45%)]	Loss: -12.5888	Cost: 12.56s
Train Epoch: 2038 [61440/90000 (68%)]	Loss: -12.7682	Cost: 8.23s
Train Epoch: 2038 [81920/90000 (91%)]	Loss: -12.3806	Cost: 6.24s
Train Epoch: 2038 	Average Loss: -12.1701
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4231

Learning rate: 9.00971250701821e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2039 [0/90000 (0%)]	Loss: -5.1158	Cost: 25.03s
Train Epoch: 2039 [20480/90000 (23%)]	Loss: -12.5570	Cost: 13.39s
Train Epoch: 2039 [40960/90000 (45%)]	Loss: -12.8227	Cost: 9.37s
Train Epoch: 2039 [61440/90000 (68%)]	Loss: -13.0299	Cost: 6.43s
Train Epoch: 2039 [81920/90000 (91%)]	Loss: -12.8071	Cost: 8.18s
Train Epoch: 2039 	Average Loss: -12.2924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6637

Saving model as e2039_model.pt & e2039_waveforms_supplementary.hdf5
Learning rate: 9.008773913511349e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2040 [0/90000 (0%)]	Loss: -5.7888	Cost: 21.44s
Train Epoch: 2040 [20480/90000 (23%)]	Loss: -12.7073	Cost: 7.12s
Train Epoch: 2040 [40960/90000 (45%)]	Loss: -12.7030	Cost: 9.19s
Train Epoch: 2040 [61440/90000 (68%)]	Loss: -12.8343	Cost: 8.65s
Train Epoch: 2040 [81920/90000 (91%)]	Loss: -12.4866	Cost: 8.81s
Train Epoch: 2040 	Average Loss: -12.2831
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6074

Learning rate: 9.007834924354363e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2041 [0/90000 (0%)]	Loss: -5.3596	Cost: 19.98s
Train Epoch: 2041 [20480/90000 (23%)]	Loss: -12.7790	Cost: 9.24s
Train Epoch: 2041 [40960/90000 (45%)]	Loss: -12.6535	Cost: 9.09s
Train Epoch: 2041 [61440/90000 (68%)]	Loss: -12.3180	Cost: 8.65s
Train Epoch: 2041 [81920/90000 (91%)]	Loss: -12.5019	Cost: 7.99s
Train Epoch: 2041 	Average Loss: -12.0714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4447

Learning rate: 9.006895539639927e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2042 [0/90000 (0%)]	Loss: -6.0153	Cost: 21.81s
Train Epoch: 2042 [20480/90000 (23%)]	Loss: -12.5852	Cost: 6.55s
Train Epoch: 2042 [40960/90000 (45%)]	Loss: -12.6042	Cost: 8.09s
Train Epoch: 2042 [61440/90000 (68%)]	Loss: -12.5012	Cost: 6.75s
Train Epoch: 2042 [81920/90000 (91%)]	Loss: -12.4632	Cost: 14.86s
Train Epoch: 2042 	Average Loss: -12.1507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5591

Learning rate: 9.005955759460758e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2043 [0/90000 (0%)]	Loss: -5.8404	Cost: 26.93s
Train Epoch: 2043 [20480/90000 (23%)]	Loss: -12.7982	Cost: 10.77s
Train Epoch: 2043 [40960/90000 (45%)]	Loss: -12.8759	Cost: 14.94s
Train Epoch: 2043 [61440/90000 (68%)]	Loss: -12.8238	Cost: 13.89s
Train Epoch: 2043 [81920/90000 (91%)]	Loss: -12.5968	Cost: 12.34s
Train Epoch: 2043 	Average Loss: -12.4045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6528

Learning rate: 9.005015583909606e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2044 [0/90000 (0%)]	Loss: -5.5400	Cost: 26.89s
Train Epoch: 2044 [20480/90000 (23%)]	Loss: -12.9303	Cost: 15.05s
Train Epoch: 2044 [40960/90000 (45%)]	Loss: -13.2125	Cost: 14.22s
Train Epoch: 2044 [61440/90000 (68%)]	Loss: -12.9513	Cost: 12.29s
Train Epoch: 2044 [81920/90000 (91%)]	Loss: -12.8039	Cost: 10.12s
Train Epoch: 2044 	Average Loss: -12.4551
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6923

Saving model as e2044_model.pt & e2044_waveforms_supplementary.hdf5
Learning rate: 9.004075013079262e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2045 [0/90000 (0%)]	Loss: -5.4369	Cost: 27.74s
Train Epoch: 2045 [20480/90000 (23%)]	Loss: -12.8065	Cost: 13.25s
Train Epoch: 2045 [40960/90000 (45%)]	Loss: -12.6184	Cost: 12.21s
Train Epoch: 2045 [61440/90000 (68%)]	Loss: -12.8792	Cost: 9.62s
Train Epoch: 2045 [81920/90000 (91%)]	Loss: -12.4438	Cost: 6.34s
Train Epoch: 2045 	Average Loss: -12.2251
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5536

Learning rate: 9.003134047062559e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2046 [0/90000 (0%)]	Loss: -5.9314	Cost: 20.82s
Train Epoch: 2046 [20480/90000 (23%)]	Loss: -12.7582	Cost: 6.77s
Train Epoch: 2046 [40960/90000 (45%)]	Loss: -12.8278	Cost: 10.52s
Train Epoch: 2046 [61440/90000 (68%)]	Loss: -12.9567	Cost: 8.69s
Train Epoch: 2046 [81920/90000 (91%)]	Loss: -12.5444	Cost: 8.51s
Train Epoch: 2046 	Average Loss: -12.3468
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5972

Learning rate: 9.002192685952364e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2047 [0/90000 (0%)]	Loss: -5.7304	Cost: 23.26s
Train Epoch: 2047 [20480/90000 (23%)]	Loss: -12.7813	Cost: 9.03s
Train Epoch: 2047 [40960/90000 (45%)]	Loss: -13.0357	Cost: 8.90s
Train Epoch: 2047 [61440/90000 (68%)]	Loss: -12.8948	Cost: 8.99s
Train Epoch: 2047 [81920/90000 (91%)]	Loss: -12.8573	Cost: 9.24s
Train Epoch: 2047 	Average Loss: -12.3294
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5566

Learning rate: 9.001250929841586e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2048 [0/90000 (0%)]	Loss: -5.4739	Cost: 27.25s
Train Epoch: 2048 [20480/90000 (23%)]	Loss: -12.6563	Cost: 9.00s
Train Epoch: 2048 [40960/90000 (45%)]	Loss: -12.7340	Cost: 12.80s
Train Epoch: 2048 [61440/90000 (68%)]	Loss: -12.9823	Cost: 11.57s
Train Epoch: 2048 [81920/90000 (91%)]	Loss: -12.7571	Cost: 12.42s
Train Epoch: 2048 	Average Loss: -12.2749
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6571

Learning rate: 9.000308778823175e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2049 [0/90000 (0%)]	Loss: -4.9587	Cost: 41.56s
Train Epoch: 2049 [20480/90000 (23%)]	Loss: -12.8592	Cost: 13.96s
Train Epoch: 2049 [40960/90000 (45%)]	Loss: -12.9367	Cost: 12.57s
Train Epoch: 2049 [61440/90000 (68%)]	Loss: -13.0809	Cost: 12.05s
Train Epoch: 2049 [81920/90000 (91%)]	Loss: -12.8841	Cost: 10.80s
Train Epoch: 2049 	Average Loss: -12.4112
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5684

Learning rate: 8.999366232990115e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2050 [0/90000 (0%)]	Loss: -6.2193	Cost: 30.31s
Train Epoch: 2050 [20480/90000 (23%)]	Loss: -12.8546	Cost: 13.42s
Train Epoch: 2050 [40960/90000 (45%)]	Loss: -13.0908	Cost: 12.34s
Train Epoch: 2050 [61440/90000 (68%)]	Loss: -12.7683	Cost: 8.42s
Train Epoch: 2050 [81920/90000 (91%)]	Loss: -12.6642	Cost: 6.38s
Train Epoch: 2050 	Average Loss: -12.3505
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6067

Learning rate: 8.998423292435434e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2051 [0/90000 (0%)]	Loss: -5.6530	Cost: 23.81s
Train Epoch: 2051 [20480/90000 (23%)]	Loss: -12.7702	Cost: 9.41s
Train Epoch: 2051 [40960/90000 (45%)]	Loss: -12.5486	Cost: 6.37s
Train Epoch: 2051 [61440/90000 (68%)]	Loss: -12.8022	Cost: 6.74s
Train Epoch: 2051 [81920/90000 (91%)]	Loss: -12.6002	Cost: 10.14s
Train Epoch: 2051 	Average Loss: -12.2336
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5486

Learning rate: 8.997479957252192e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2052 [0/90000 (0%)]	Loss: -6.0965	Cost: 20.63s
Train Epoch: 2052 [20480/90000 (23%)]	Loss: -12.9505	Cost: 7.81s
Train Epoch: 2052 [40960/90000 (45%)]	Loss: -13.0738	Cost: 9.24s
Train Epoch: 2052 [61440/90000 (68%)]	Loss: -13.1237	Cost: 8.98s
Train Epoch: 2052 [81920/90000 (91%)]	Loss: -12.9227	Cost: 8.73s
Train Epoch: 2052 	Average Loss: -12.4524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7113

Saving model as e2052_model.pt & e2052_waveforms_supplementary.hdf5
Learning rate: 8.996536227533499e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2053 [0/90000 (0%)]	Loss: -6.2682	Cost: 26.15s
Train Epoch: 2053 [20480/90000 (23%)]	Loss: -12.9400	Cost: 7.30s
Train Epoch: 2053 [40960/90000 (45%)]	Loss: -13.1519	Cost: 7.15s
Train Epoch: 2053 [61440/90000 (68%)]	Loss: -12.9859	Cost: 6.77s
Train Epoch: 2053 [81920/90000 (91%)]	Loss: -12.9601	Cost: 13.38s
Train Epoch: 2053 	Average Loss: -12.6306
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6422

Learning rate: 8.99559210337249e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2054 [0/90000 (0%)]	Loss: -6.2572	Cost: 27.66s
Train Epoch: 2054 [20480/90000 (23%)]	Loss: -12.8371	Cost: 7.67s
Train Epoch: 2054 [40960/90000 (45%)]	Loss: -12.6794	Cost: 11.22s
Train Epoch: 2054 [61440/90000 (68%)]	Loss: -13.0025	Cost: 12.21s
Train Epoch: 2054 [81920/90000 (91%)]	Loss: -12.4385	Cost: 12.45s
Train Epoch: 2054 	Average Loss: -12.3915
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6655

Learning rate: 8.994647584862352e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2055 [0/90000 (0%)]	Loss: -5.9425	Cost: 25.14s
Train Epoch: 2055 [20480/90000 (23%)]	Loss: -12.8388	Cost: 10.02s
Train Epoch: 2055 [40960/90000 (45%)]	Loss: -12.9727	Cost: 15.03s
Train Epoch: 2055 [61440/90000 (68%)]	Loss: -12.9011	Cost: 12.41s
Train Epoch: 2055 [81920/90000 (91%)]	Loss: -12.8009	Cost: 11.95s
Train Epoch: 2055 	Average Loss: -12.4721
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6599

Learning rate: 8.993702672096304e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2056 [0/90000 (0%)]	Loss: -4.8060	Cost: 35.34s
Train Epoch: 2056 [20480/90000 (23%)]	Loss: -12.7626	Cost: 10.23s
Train Epoch: 2056 [40960/90000 (45%)]	Loss: -12.7294	Cost: 13.26s
Train Epoch: 2056 [61440/90000 (68%)]	Loss: -12.7623	Cost: 12.39s
Train Epoch: 2056 [81920/90000 (91%)]	Loss: -12.3692	Cost: 10.35s
Train Epoch: 2056 	Average Loss: -12.1546
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5589

Learning rate: 8.992757365167604e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2057 [0/90000 (0%)]	Loss: -5.7533	Cost: 23.91s
Train Epoch: 2057 [20480/90000 (23%)]	Loss: -12.8221	Cost: 9.71s
Train Epoch: 2057 [40960/90000 (45%)]	Loss: -13.0144	Cost: 13.25s
Train Epoch: 2057 [61440/90000 (68%)]	Loss: -13.0690	Cost: 12.52s
Train Epoch: 2057 [81920/90000 (91%)]	Loss: -12.6745	Cost: 8.53s
Train Epoch: 2057 	Average Loss: -12.4548
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7857

Saving model as e2057_model.pt & e2057_waveforms_supplementary.hdf5
Learning rate: 8.99181166416955e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2058 [0/90000 (0%)]	Loss: -6.1522	Cost: 27.36s
Train Epoch: 2058 [20480/90000 (23%)]	Loss: -12.8661	Cost: 9.61s
Train Epoch: 2058 [40960/90000 (45%)]	Loss: -12.7108	Cost: 11.71s
Train Epoch: 2058 [61440/90000 (68%)]	Loss: -12.7906	Cost: 6.11s
Train Epoch: 2058 [81920/90000 (91%)]	Loss: -12.5070	Cost: 6.81s
Train Epoch: 2058 	Average Loss: -12.2723
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3960

Learning rate: 8.99086556919548e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2059 [0/90000 (0%)]	Loss: -5.0048	Cost: 35.35s
Train Epoch: 2059 [20480/90000 (23%)]	Loss: -12.4436	Cost: 7.30s
Train Epoch: 2059 [40960/90000 (45%)]	Loss: -12.9703	Cost: 7.20s
Train Epoch: 2059 [61440/90000 (68%)]	Loss: -13.0430	Cost: 8.22s
Train Epoch: 2059 [81920/90000 (91%)]	Loss: -12.8509	Cost: 8.57s
Train Epoch: 2059 	Average Loss: -12.3140
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7808

Learning rate: 8.98991908033877e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2060 [0/90000 (0%)]	Loss: -6.2031	Cost: 26.28s
Train Epoch: 2060 [20480/90000 (23%)]	Loss: -12.9765	Cost: 7.64s
Train Epoch: 2060 [40960/90000 (45%)]	Loss: -12.8934	Cost: 9.06s
Train Epoch: 2060 [61440/90000 (68%)]	Loss: -13.1688	Cost: 8.78s
Train Epoch: 2060 [81920/90000 (91%)]	Loss: -12.8582	Cost: 8.57s
Train Epoch: 2060 	Average Loss: -12.5009
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7914

Saving model as e2060_model.pt & e2060_waveforms_supplementary.hdf5
Learning rate: 8.988972197692833e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2061 [0/90000 (0%)]	Loss: -6.1113	Cost: 21.34s
Train Epoch: 2061 [20480/90000 (23%)]	Loss: -12.8263	Cost: 9.25s
Train Epoch: 2061 [40960/90000 (45%)]	Loss: -13.0433	Cost: 9.63s
Train Epoch: 2061 [61440/90000 (68%)]	Loss: -12.9076	Cost: 7.16s
Train Epoch: 2061 [81920/90000 (91%)]	Loss: -12.8478	Cost: 9.80s
Train Epoch: 2061 	Average Loss: -12.4159
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8303

Saving model as e2061_model.pt & e2061_waveforms_supplementary.hdf5
Learning rate: 8.988024921351125e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2062 [0/90000 (0%)]	Loss: -6.0505	Cost: 20.40s
Train Epoch: 2062 [20480/90000 (23%)]	Loss: -12.5730	Cost: 7.46s
Train Epoch: 2062 [40960/90000 (45%)]	Loss: -12.6754	Cost: 14.07s
Train Epoch: 2062 [61440/90000 (68%)]	Loss: -12.8388	Cost: 14.20s
Train Epoch: 2062 [81920/90000 (91%)]	Loss: -12.6473	Cost: 13.20s
Train Epoch: 2062 	Average Loss: -12.2850
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5835

Learning rate: 8.987077251407137e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2063 [0/90000 (0%)]	Loss: -5.5750	Cost: 30.08s
Train Epoch: 2063 [20480/90000 (23%)]	Loss: -12.6799	Cost: 15.06s
Train Epoch: 2063 [40960/90000 (45%)]	Loss: -12.8059	Cost: 13.89s
Train Epoch: 2063 [61440/90000 (68%)]	Loss: -12.8680	Cost: 12.41s
Train Epoch: 2063 [81920/90000 (91%)]	Loss: -12.6734	Cost: 7.65s
Train Epoch: 2063 	Average Loss: -12.2643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7466

Learning rate: 8.9861291879544e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2064 [0/90000 (0%)]	Loss: -6.0274	Cost: 38.59s
Train Epoch: 2064 [20480/90000 (23%)]	Loss: -13.0375	Cost: 11.85s
Train Epoch: 2064 [40960/90000 (45%)]	Loss: -13.2402	Cost: 8.48s
Train Epoch: 2064 [61440/90000 (68%)]	Loss: -13.1660	Cost: 6.08s
Train Epoch: 2064 [81920/90000 (91%)]	Loss: -12.8535	Cost: 7.46s
Train Epoch: 2064 	Average Loss: -12.5491
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7731

Learning rate: 8.985180731086484e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2065 [0/90000 (0%)]	Loss: -4.9902	Cost: 23.50s
Train Epoch: 2065 [20480/90000 (23%)]	Loss: -13.2001	Cost: 8.24s
Train Epoch: 2065 [40960/90000 (45%)]	Loss: -13.2190	Cost: 7.82s
Train Epoch: 2065 [61440/90000 (68%)]	Loss: -13.0202	Cost: 8.11s
Train Epoch: 2065 [81920/90000 (91%)]	Loss: -12.8549	Cost: 8.40s
Train Epoch: 2065 	Average Loss: -12.4950
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6741

Learning rate: 8.984231880896998e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2066 [0/90000 (0%)]	Loss: -5.9710	Cost: 21.91s
Train Epoch: 2066 [20480/90000 (23%)]	Loss: -13.0967	Cost: 8.52s
Train Epoch: 2066 [40960/90000 (45%)]	Loss: -13.0615	Cost: 12.60s
Train Epoch: 2066 [61440/90000 (68%)]	Loss: -13.1316	Cost: 9.07s
Train Epoch: 2066 [81920/90000 (91%)]	Loss: -12.6220	Cost: 9.01s
Train Epoch: 2066 	Average Loss: -12.5520
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8130

Learning rate: 8.983282637479591e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2067 [0/90000 (0%)]	Loss: -6.2481	Cost: 24.84s
Train Epoch: 2067 [20480/90000 (23%)]	Loss: -13.1156	Cost: 9.61s
Train Epoch: 2067 [40960/90000 (45%)]	Loss: -13.2451	Cost: 10.12s
Train Epoch: 2067 [61440/90000 (68%)]	Loss: -13.2233	Cost: 8.94s
Train Epoch: 2067 [81920/90000 (91%)]	Loss: -12.9051	Cost: 11.36s
Train Epoch: 2067 	Average Loss: -12.6555
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9762

Saving model as e2067_model.pt & e2067_waveforms_supplementary.hdf5
Learning rate: 8.982333000927949e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2068 [0/90000 (0%)]	Loss: -6.3724	Cost: 24.20s
Train Epoch: 2068 [20480/90000 (23%)]	Loss: -13.1074	Cost: 10.15s
Train Epoch: 2068 [40960/90000 (45%)]	Loss: -12.9982	Cost: 11.17s
Train Epoch: 2068 [61440/90000 (68%)]	Loss: -13.0746	Cost: 12.55s
Train Epoch: 2068 [81920/90000 (91%)]	Loss: -12.8962	Cost: 12.56s
Train Epoch: 2068 	Average Loss: -12.5660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7024

Learning rate: 8.981382971335796e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2069 [0/90000 (0%)]	Loss: -6.1351	Cost: 24.38s
Train Epoch: 2069 [20480/90000 (23%)]	Loss: -13.2403	Cost: 13.75s
Train Epoch: 2069 [40960/90000 (45%)]	Loss: -13.0820	Cost: 12.53s
Train Epoch: 2069 [61440/90000 (68%)]	Loss: -13.0651	Cost: 12.11s
Train Epoch: 2069 [81920/90000 (91%)]	Loss: -12.8436	Cost: 10.95s
Train Epoch: 2069 	Average Loss: -12.5374
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7278

Learning rate: 8.980432548796897e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2070 [0/90000 (0%)]	Loss: -5.7746	Cost: 28.46s
Train Epoch: 2070 [20480/90000 (23%)]	Loss: -12.8760	Cost: 12.09s
Train Epoch: 2070 [40960/90000 (45%)]	Loss: -12.0858	Cost: 12.53s
Train Epoch: 2070 [61440/90000 (68%)]	Loss: -12.5452	Cost: 6.25s
Train Epoch: 2070 [81920/90000 (91%)]	Loss: -12.5358	Cost: 6.33s
Train Epoch: 2070 	Average Loss: -12.1247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6387

Learning rate: 8.979481733405057e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2071 [0/90000 (0%)]	Loss: -5.7796	Cost: 37.19s
Train Epoch: 2071 [20480/90000 (23%)]	Loss: -13.0301	Cost: 8.67s
Train Epoch: 2071 [40960/90000 (45%)]	Loss: -13.1411	Cost: 11.23s
Train Epoch: 2071 [61440/90000 (68%)]	Loss: -13.2273	Cost: 8.56s
Train Epoch: 2071 [81920/90000 (91%)]	Loss: -12.8062	Cost: 8.72s
Train Epoch: 2071 	Average Loss: -12.5147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8156

Learning rate: 8.978530525254115e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2072 [0/90000 (0%)]	Loss: -5.3775	Cost: 19.86s
Train Epoch: 2072 [20480/90000 (23%)]	Loss: -12.8934	Cost: 8.16s
Train Epoch: 2072 [40960/90000 (45%)]	Loss: -13.2577	Cost: 10.17s
Train Epoch: 2072 [61440/90000 (68%)]	Loss: -13.3282	Cost: 9.57s
Train Epoch: 2072 [81920/90000 (91%)]	Loss: -12.8641	Cost: 8.92s
Train Epoch: 2072 	Average Loss: -12.6128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6948

Learning rate: 8.977578924437951e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2073 [0/90000 (0%)]	Loss: -5.8289	Cost: 25.14s
Train Epoch: 2073 [20480/90000 (23%)]	Loss: -12.7126	Cost: 9.30s
Train Epoch: 2073 [40960/90000 (45%)]	Loss: -13.0250	Cost: 9.11s
Train Epoch: 2073 [61440/90000 (68%)]	Loss: -13.1788	Cost: 8.52s
Train Epoch: 2073 [81920/90000 (91%)]	Loss: -12.8749	Cost: 8.65s
Train Epoch: 2073 	Average Loss: -12.4850
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9179

Learning rate: 8.976626931050488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2074 [0/90000 (0%)]	Loss: -5.9626	Cost: 20.96s
Train Epoch: 2074 [20480/90000 (23%)]	Loss: -12.9657	Cost: 9.00s
Train Epoch: 2074 [40960/90000 (45%)]	Loss: -13.3279	Cost: 8.92s
Train Epoch: 2074 [61440/90000 (68%)]	Loss: -13.4248	Cost: 6.40s
Train Epoch: 2074 [81920/90000 (91%)]	Loss: -13.1346	Cost: 6.49s
Train Epoch: 2074 	Average Loss: -12.6761
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9414

Learning rate: 8.97567454518568e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2075 [0/90000 (0%)]	Loss: -6.2392	Cost: 21.54s
Train Epoch: 2075 [20480/90000 (23%)]	Loss: -13.2127	Cost: 7.11s
Train Epoch: 2075 [40960/90000 (45%)]	Loss: -13.3679	Cost: 11.54s
Train Epoch: 2075 [61440/90000 (68%)]	Loss: -13.2671	Cost: 12.54s
Train Epoch: 2075 [81920/90000 (91%)]	Loss: -12.8458	Cost: 12.56s
Train Epoch: 2075 	Average Loss: -12.6789
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9439

Learning rate: 8.974721766937527e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2076 [0/90000 (0%)]	Loss: -5.9149	Cost: 24.27s
Train Epoch: 2076 [20480/90000 (23%)]	Loss: -13.0992	Cost: 12.12s
Train Epoch: 2076 [40960/90000 (45%)]	Loss: -13.1743	Cost: 15.53s
Train Epoch: 2076 [61440/90000 (68%)]	Loss: -13.3416	Cost: 13.46s
Train Epoch: 2076 [81920/90000 (91%)]	Loss: -12.8211	Cost: 12.24s
Train Epoch: 2076 	Average Loss: -12.6278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8685

Learning rate: 8.973768596400062e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2077 [0/90000 (0%)]	Loss: -6.3242	Cost: 28.69s
Train Epoch: 2077 [20480/90000 (23%)]	Loss: -12.9710	Cost: 12.86s
Train Epoch: 2077 [40960/90000 (45%)]	Loss: -13.0636	Cost: 14.60s
Train Epoch: 2077 [61440/90000 (68%)]	Loss: -13.2531	Cost: 12.35s
Train Epoch: 2077 [81920/90000 (91%)]	Loss: -13.0432	Cost: 9.80s
Train Epoch: 2077 	Average Loss: -12.6073
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9766

Saving model as e2077_model.pt & e2077_waveforms_supplementary.hdf5
Learning rate: 8.97281503366736e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2078 [0/90000 (0%)]	Loss: -6.6413	Cost: 31.33s
Train Epoch: 2078 [20480/90000 (23%)]	Loss: -13.1686	Cost: 12.84s
Train Epoch: 2078 [40960/90000 (45%)]	Loss: -13.2011	Cost: 12.08s
Train Epoch: 2078 [61440/90000 (68%)]	Loss: -13.3408	Cost: 6.50s
Train Epoch: 2078 [81920/90000 (91%)]	Loss: -13.1157	Cost: 6.59s
Train Epoch: 2078 	Average Loss: -12.6849
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9605

Learning rate: 8.971861078833534e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2079 [0/90000 (0%)]	Loss: -6.1618	Cost: 27.08s
Train Epoch: 2079 [20480/90000 (23%)]	Loss: -13.2054	Cost: 12.35s
Train Epoch: 2079 [40960/90000 (45%)]	Loss: -13.2621	Cost: 8.93s
Train Epoch: 2079 [61440/90000 (68%)]	Loss: -13.2660	Cost: 6.08s
Train Epoch: 2079 [81920/90000 (91%)]	Loss: -12.8943	Cost: 7.07s
Train Epoch: 2079 	Average Loss: -12.7172
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6758

Learning rate: 8.970906731992736e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2080 [0/90000 (0%)]	Loss: -6.2779	Cost: 38.16s
Train Epoch: 2080 [20480/90000 (23%)]	Loss: -12.6155	Cost: 8.46s
Train Epoch: 2080 [40960/90000 (45%)]	Loss: -12.5927	Cost: 7.06s
Train Epoch: 2080 [61440/90000 (68%)]	Loss: -12.6602	Cost: 7.37s
Train Epoch: 2080 [81920/90000 (91%)]	Loss: -12.4848	Cost: 8.76s
Train Epoch: 2080 	Average Loss: -12.1740
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5936

Learning rate: 8.969951993239156e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2081 [0/90000 (0%)]	Loss: -6.0061	Cost: 21.56s
Train Epoch: 2081 [20480/90000 (23%)]	Loss: -12.8659	Cost: 6.70s
Train Epoch: 2081 [40960/90000 (45%)]	Loss: -13.2294	Cost: 9.97s
Train Epoch: 2081 [61440/90000 (68%)]	Loss: -13.3439	Cost: 9.47s
Train Epoch: 2081 [81920/90000 (91%)]	Loss: -12.9507	Cost: 8.75s
Train Epoch: 2081 	Average Loss: -12.6603
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8624

Learning rate: 8.968996862667021e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2082 [0/90000 (0%)]	Loss: -5.9679	Cost: 21.06s
Train Epoch: 2082 [20480/90000 (23%)]	Loss: -13.3315	Cost: 9.12s
Train Epoch: 2082 [40960/90000 (45%)]	Loss: -13.4189	Cost: 8.87s
Train Epoch: 2082 [61440/90000 (68%)]	Loss: -13.5197	Cost: 9.02s
Train Epoch: 2082 [81920/90000 (91%)]	Loss: -13.2481	Cost: 9.20s
Train Epoch: 2082 	Average Loss: -12.8386
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8650

Learning rate: 8.9680413403706e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2083 [0/90000 (0%)]	Loss: -6.4397	Cost: 21.16s
Train Epoch: 2083 [20480/90000 (23%)]	Loss: -13.1629	Cost: 9.56s
Train Epoch: 2083 [40960/90000 (45%)]	Loss: -13.0243	Cost: 7.34s
Train Epoch: 2083 [61440/90000 (68%)]	Loss: -13.2541	Cost: 7.38s
Train Epoch: 2083 [81920/90000 (91%)]	Loss: -12.9339	Cost: 6.47s
Train Epoch: 2083 	Average Loss: -12.6912
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9280

Learning rate: 8.9670854264442e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2084 [0/90000 (0%)]	Loss: -6.5028	Cost: 32.29s
Train Epoch: 2084 [20480/90000 (23%)]	Loss: -13.0526	Cost: 7.29s
Train Epoch: 2084 [40960/90000 (45%)]	Loss: -13.3161	Cost: 13.06s
Train Epoch: 2084 [61440/90000 (68%)]	Loss: -13.2240	Cost: 12.48s
Train Epoch: 2084 [81920/90000 (91%)]	Loss: -13.1036	Cost: 12.27s
Train Epoch: 2084 	Average Loss: -12.7657
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1389

Saving model as e2084_model.pt & e2084_waveforms_supplementary.hdf5
Learning rate: 8.966129120982165e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2085 [0/90000 (0%)]	Loss: -5.5210	Cost: 34.68s
Train Epoch: 2085 [20480/90000 (23%)]	Loss: -13.2823	Cost: 13.27s
Train Epoch: 2085 [40960/90000 (45%)]	Loss: -13.2977	Cost: 12.66s
Train Epoch: 2085 [61440/90000 (68%)]	Loss: -13.3932	Cost: 12.04s
Train Epoch: 2085 [81920/90000 (91%)]	Loss: -13.2491	Cost: 12.27s
Train Epoch: 2085 	Average Loss: -12.8399
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1129

Learning rate: 8.965172424078879e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2086 [0/90000 (0%)]	Loss: -6.0855	Cost: 29.68s
Train Epoch: 2086 [20480/90000 (23%)]	Loss: -13.3462	Cost: 12.33s
Train Epoch: 2086 [40960/90000 (45%)]	Loss: -13.2559	Cost: 12.83s
Train Epoch: 2086 [61440/90000 (68%)]	Loss: -13.3875	Cost: 12.32s
Train Epoch: 2086 [81920/90000 (91%)]	Loss: -13.0648	Cost: 6.74s
Train Epoch: 2086 	Average Loss: -12.7950
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9502

Learning rate: 8.964215335828765e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2087 [0/90000 (0%)]	Loss: -5.9354	Cost: 27.51s
Train Epoch: 2087 [20480/90000 (23%)]	Loss: -13.1335	Cost: 14.21s
Train Epoch: 2087 [40960/90000 (45%)]	Loss: -13.5164	Cost: 13.55s
Train Epoch: 2087 [61440/90000 (68%)]	Loss: -13.4491	Cost: 6.46s
Train Epoch: 2087 [81920/90000 (91%)]	Loss: -13.1896	Cost: 6.34s
Train Epoch: 2087 	Average Loss: -12.8823
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1255

Learning rate: 8.963257856326281e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2088 [0/90000 (0%)]	Loss: -5.9418	Cost: 24.93s
Train Epoch: 2088 [20480/90000 (23%)]	Loss: -13.2117	Cost: 9.89s
Train Epoch: 2088 [40960/90000 (45%)]	Loss: -13.5053	Cost: 10.43s
Train Epoch: 2088 [61440/90000 (68%)]	Loss: -13.4125	Cost: 6.18s
Train Epoch: 2088 [81920/90000 (91%)]	Loss: -12.9595	Cost: 7.00s
Train Epoch: 2088 	Average Loss: -12.7035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9571

Learning rate: 8.962299985665932e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2089 [0/90000 (0%)]	Loss: -6.3223	Cost: 26.48s
Train Epoch: 2089 [20480/90000 (23%)]	Loss: -13.2223	Cost: 6.88s
Train Epoch: 2089 [40960/90000 (45%)]	Loss: -13.3915	Cost: 8.84s
Train Epoch: 2089 [61440/90000 (68%)]	Loss: -13.4921	Cost: 8.77s
Train Epoch: 2089 [81920/90000 (91%)]	Loss: -12.9620	Cost: 8.68s
Train Epoch: 2089 	Average Loss: -12.7768
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8585

Learning rate: 8.96134172394225e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2090 [0/90000 (0%)]	Loss: -5.5434	Cost: 22.94s
Train Epoch: 2090 [20480/90000 (23%)]	Loss: -12.8723	Cost: 7.12s
Train Epoch: 2090 [40960/90000 (45%)]	Loss: -13.0370	Cost: 9.19s
Train Epoch: 2090 [61440/90000 (68%)]	Loss: -13.3133	Cost: 9.13s
Train Epoch: 2090 [81920/90000 (91%)]	Loss: -13.1328	Cost: 8.59s
Train Epoch: 2090 	Average Loss: -12.6178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0605

Learning rate: 8.960383071249814e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2091 [0/90000 (0%)]	Loss: -5.6929	Cost: 24.23s
Train Epoch: 2091 [20480/90000 (23%)]	Loss: -13.0743	Cost: 7.69s
Train Epoch: 2091 [40960/90000 (45%)]	Loss: -13.3278	Cost: 8.43s
Train Epoch: 2091 [61440/90000 (68%)]	Loss: -13.1809	Cost: 9.24s
Train Epoch: 2091 [81920/90000 (91%)]	Loss: -13.1686	Cost: 13.77s
Train Epoch: 2091 	Average Loss: -12.7104
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9124

Learning rate: 8.959424027683239e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2092 [0/90000 (0%)]	Loss: -6.3218	Cost: 22.48s
Train Epoch: 2092 [20480/90000 (23%)]	Loss: -13.2377	Cost: 8.00s
Train Epoch: 2092 [40960/90000 (45%)]	Loss: -13.7325	Cost: 12.42s
Train Epoch: 2092 [61440/90000 (68%)]	Loss: -13.4649	Cost: 13.64s
Train Epoch: 2092 [81920/90000 (91%)]	Loss: -12.9448	Cost: 12.65s
Train Epoch: 2092 	Average Loss: -12.8261
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9586

Learning rate: 8.958464593337179e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2093 [0/90000 (0%)]	Loss: -6.6878	Cost: 24.64s
Train Epoch: 2093 [20480/90000 (23%)]	Loss: -13.2677	Cost: 15.41s
Train Epoch: 2093 [40960/90000 (45%)]	Loss: -13.4472	Cost: 13.46s
Train Epoch: 2093 [61440/90000 (68%)]	Loss: -13.3354	Cost: 12.21s
Train Epoch: 2093 [81920/90000 (91%)]	Loss: -13.2962	Cost: 10.02s
Train Epoch: 2093 	Average Loss: -12.8303
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0792

Learning rate: 8.957504768306328e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2094 [0/90000 (0%)]	Loss: -6.3557	Cost: 40.19s
Train Epoch: 2094 [20480/90000 (23%)]	Loss: -12.8629	Cost: 10.25s
Train Epoch: 2094 [40960/90000 (45%)]	Loss: -13.2267	Cost: 9.88s
Train Epoch: 2094 [61440/90000 (68%)]	Loss: -13.1104	Cost: 6.14s
Train Epoch: 2094 [81920/90000 (91%)]	Loss: -13.1445	Cost: 7.21s
Train Epoch: 2094 	Average Loss: -12.6412
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9903

Learning rate: 8.956544552685414e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2095 [0/90000 (0%)]	Loss: -6.1693	Cost: 39.59s
Train Epoch: 2095 [20480/90000 (23%)]	Loss: -13.2149	Cost: 9.81s
Train Epoch: 2095 [40960/90000 (45%)]	Loss: -13.3783	Cost: 6.53s
Train Epoch: 2095 [61440/90000 (68%)]	Loss: -13.3401	Cost: 6.80s
Train Epoch: 2095 [81920/90000 (91%)]	Loss: -13.1410	Cost: 8.78s
Train Epoch: 2095 	Average Loss: -12.8231
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9239

Learning rate: 8.955583946569207e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2096 [0/90000 (0%)]	Loss: -5.1994	Cost: 24.68s
Train Epoch: 2096 [20480/90000 (23%)]	Loss: -13.1127	Cost: 6.61s
Train Epoch: 2096 [40960/90000 (45%)]	Loss: -13.0925	Cost: 9.44s
Train Epoch: 2096 [61440/90000 (68%)]	Loss: -13.5842	Cost: 8.96s
Train Epoch: 2096 [81920/90000 (91%)]	Loss: -13.2186	Cost: 8.96s
Train Epoch: 2096 	Average Loss: -12.7156
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0459

Learning rate: 8.954622950052518e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2097 [0/90000 (0%)]	Loss: -6.6306	Cost: 21.75s
Train Epoch: 2097 [20480/90000 (23%)]	Loss: -13.2792	Cost: 8.88s
Train Epoch: 2097 [40960/90000 (45%)]	Loss: -13.5176	Cost: 8.99s
Train Epoch: 2097 [61440/90000 (68%)]	Loss: -13.4808	Cost: 6.19s
Train Epoch: 2097 [81920/90000 (91%)]	Loss: -13.3262	Cost: 6.31s
Train Epoch: 2097 	Average Loss: -12.8544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9771

Learning rate: 8.953661563230191e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2098 [0/90000 (0%)]	Loss: -6.9309	Cost: 19.78s
Train Epoch: 2098 [20480/90000 (23%)]	Loss: -13.3986	Cost: 7.53s
Train Epoch: 2098 [40960/90000 (45%)]	Loss: -13.6031	Cost: 8.76s
Train Epoch: 2098 [61440/90000 (68%)]	Loss: -13.5003	Cost: 14.37s
Train Epoch: 2098 [81920/90000 (91%)]	Loss: -13.1335	Cost: 12.49s
Train Epoch: 2098 	Average Loss: -12.9446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0702

Learning rate: 8.952699786197111e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2099 [0/90000 (0%)]	Loss: -5.7157	Cost: 24.39s
Train Epoch: 2099 [20480/90000 (23%)]	Loss: -13.2802	Cost: 11.07s
Train Epoch: 2099 [40960/90000 (45%)]	Loss: -13.2895	Cost: 15.58s
Train Epoch: 2099 [61440/90000 (68%)]	Loss: -13.3942	Cost: 13.33s
Train Epoch: 2099 [81920/90000 (91%)]	Loss: -13.0888	Cost: 12.30s
Train Epoch: 2099 	Average Loss: -12.7717
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0178

Learning rate: 8.951737619048204e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2100 [0/90000 (0%)]	Loss: -6.1949	Cost: 43.74s
Train Epoch: 2100 [20480/90000 (23%)]	Loss: -13.4147	Cost: 13.22s
Train Epoch: 2100 [40960/90000 (45%)]	Loss: -13.3635	Cost: 12.36s
Train Epoch: 2100 [61440/90000 (68%)]	Loss: -13.5193	Cost: 11.39s
Train Epoch: 2100 [81920/90000 (91%)]	Loss: -13.2364	Cost: 6.14s
Train Epoch: 2100 	Average Loss: -12.8717
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9800

Learning rate: 8.950775061878426e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2101 [0/90000 (0%)]	Loss: -5.4451	Cost: 31.71s
Train Epoch: 2101 [20480/90000 (23%)]	Loss: -13.2767	Cost: 12.38s
Train Epoch: 2101 [40960/90000 (45%)]	Loss: -13.3447	Cost: 12.10s
Train Epoch: 2101 [61440/90000 (68%)]	Loss: -13.4167	Cost: 6.28s
Train Epoch: 2101 [81920/90000 (91%)]	Loss: -13.1495	Cost: 6.27s
Train Epoch: 2101 	Average Loss: -12.8758
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1879

Saving model as e2101_model.pt & e2101_waveforms_supplementary.hdf5
Learning rate: 8.949812114782787e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2102 [0/90000 (0%)]	Loss: -6.4508	Cost: 21.60s
Train Epoch: 2102 [20480/90000 (23%)]	Loss: -13.1746	Cost: 8.71s
Train Epoch: 2102 [40960/90000 (45%)]	Loss: -13.2019	Cost: 8.94s
Train Epoch: 2102 [61440/90000 (68%)]	Loss: -13.3920	Cost: 9.16s
Train Epoch: 2102 [81920/90000 (91%)]	Loss: -13.0271	Cost: 9.24s
Train Epoch: 2102 	Average Loss: -12.7598
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7899

Learning rate: 8.948848777856318e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2103 [0/90000 (0%)]	Loss: -4.7022	Cost: 21.78s
Train Epoch: 2103 [20480/90000 (23%)]	Loss: -12.9357	Cost: 7.84s
Train Epoch: 2103 [40960/90000 (45%)]	Loss: -13.2552	Cost: 11.56s
Train Epoch: 2103 [61440/90000 (68%)]	Loss: -13.1517	Cost: 10.87s
Train Epoch: 2103 [81920/90000 (91%)]	Loss: -12.8115	Cost: 12.49s
Train Epoch: 2103 	Average Loss: -12.5159
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7521

Learning rate: 8.9478850511941e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2104 [0/90000 (0%)]	Loss: -5.2590	Cost: 23.42s
Train Epoch: 2104 [20480/90000 (23%)]	Loss: -13.2412	Cost: 11.90s
Train Epoch: 2104 [40960/90000 (45%)]	Loss: -13.3670	Cost: 13.35s
Train Epoch: 2104 [61440/90000 (68%)]	Loss: -13.2111	Cost: 12.85s
Train Epoch: 2104 [81920/90000 (91%)]	Loss: -12.7062	Cost: 11.90s
Train Epoch: 2104 	Average Loss: -12.5841
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7836

Learning rate: 8.94692093489125e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2105 [0/90000 (0%)]	Loss: -6.1864	Cost: 37.04s
Train Epoch: 2105 [20480/90000 (23%)]	Loss: -12.9282	Cost: 10.54s
Train Epoch: 2105 [40960/90000 (45%)]	Loss: -13.2031	Cost: 12.23s
Train Epoch: 2105 [61440/90000 (68%)]	Loss: -13.2854	Cost: 12.11s
Train Epoch: 2105 [81920/90000 (91%)]	Loss: -13.2088	Cost: 7.99s
Train Epoch: 2105 	Average Loss: -12.5993
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1140

Learning rate: 8.945956429042919e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2106 [0/90000 (0%)]	Loss: -6.3730	Cost: 27.76s
Train Epoch: 2106 [20480/90000 (23%)]	Loss: -13.3328	Cost: 13.39s
Train Epoch: 2106 [40960/90000 (45%)]	Loss: -13.4900	Cost: 12.47s
Train Epoch: 2106 [61440/90000 (68%)]	Loss: -13.4935	Cost: 9.28s
Train Epoch: 2106 [81920/90000 (91%)]	Loss: -13.1681	Cost: 6.42s
Train Epoch: 2106 	Average Loss: -12.8462
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1119

Learning rate: 8.944991533744303e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2107 [0/90000 (0%)]	Loss: -6.1351	Cost: 31.14s
Train Epoch: 2107 [20480/90000 (23%)]	Loss: -13.3295	Cost: 13.30s
Train Epoch: 2107 [40960/90000 (45%)]	Loss: -13.4252	Cost: 11.03s
Train Epoch: 2107 [61440/90000 (68%)]	Loss: -13.5047	Cost: 6.63s
Train Epoch: 2107 [81920/90000 (91%)]	Loss: -13.0975	Cost: 6.88s
Train Epoch: 2107 	Average Loss: -12.8066
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9554

Learning rate: 8.944026249090629e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2108 [0/90000 (0%)]	Loss: -6.7549	Cost: 23.59s
Train Epoch: 2108 [20480/90000 (23%)]	Loss: -12.8263	Cost: 10.87s
Train Epoch: 2108 [40960/90000 (45%)]	Loss: -13.2124	Cost: 9.40s
Train Epoch: 2108 [61440/90000 (68%)]	Loss: -13.4966	Cost: 8.77s
Train Epoch: 2108 [81920/90000 (91%)]	Loss: -13.2936	Cost: 8.49s
Train Epoch: 2108 	Average Loss: -12.7067
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0213

Learning rate: 8.943060575177173e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2109 [0/90000 (0%)]	Loss: -7.0679	Cost: 21.10s
Train Epoch: 2109 [20480/90000 (23%)]	Loss: -12.6449	Cost: 8.82s
Train Epoch: 2109 [40960/90000 (45%)]	Loss: -12.8898	Cost: 8.53s
Train Epoch: 2109 [61440/90000 (68%)]	Loss: -13.0738	Cost: 8.65s
Train Epoch: 2109 [81920/90000 (91%)]	Loss: -13.0183	Cost: 8.58s
Train Epoch: 2109 	Average Loss: -12.5075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7466

Learning rate: 8.94209451209924e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2110 [0/90000 (0%)]	Loss: -5.7466	Cost: 24.36s
Train Epoch: 2110 [20480/90000 (23%)]	Loss: -13.2930	Cost: 7.69s
Train Epoch: 2110 [40960/90000 (45%)]	Loss: -13.4274	Cost: 8.81s
Train Epoch: 2110 [61440/90000 (68%)]	Loss: -13.4878	Cost: 8.75s
Train Epoch: 2110 [81920/90000 (91%)]	Loss: -13.3003	Cost: 8.89s
Train Epoch: 2110 	Average Loss: -12.8351
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0093

Learning rate: 8.941128059952176e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2111 [0/90000 (0%)]	Loss: -5.5086	Cost: 25.71s
Train Epoch: 2111 [20480/90000 (23%)]	Loss: -13.2835	Cost: 8.91s
Train Epoch: 2111 [40960/90000 (45%)]	Loss: -13.6904	Cost: 9.00s
Train Epoch: 2111 [61440/90000 (68%)]	Loss: -13.6929	Cost: 6.64s
Train Epoch: 2111 [81920/90000 (91%)]	Loss: -13.3202	Cost: 6.57s
Train Epoch: 2111 	Average Loss: -12.9708
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0638

Learning rate: 8.940161218831365e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2112 [0/90000 (0%)]	Loss: -5.3221	Cost: 22.37s
Train Epoch: 2112 [20480/90000 (23%)]	Loss: -13.3497	Cost: 10.33s
Train Epoch: 2112 [40960/90000 (45%)]	Loss: -13.5797	Cost: 18.17s
Train Epoch: 2112 [61440/90000 (68%)]	Loss: -13.8193	Cost: 13.87s
Train Epoch: 2112 [81920/90000 (91%)]	Loss: -13.2622	Cost: 11.89s
Train Epoch: 2112 	Average Loss: -12.9660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1685

Learning rate: 8.939193988832235e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2113 [0/90000 (0%)]	Loss: -6.2104	Cost: 28.27s
Train Epoch: 2113 [20480/90000 (23%)]	Loss: -13.3166	Cost: 15.25s
Train Epoch: 2113 [40960/90000 (45%)]	Loss: -13.6046	Cost: 14.66s
Train Epoch: 2113 [61440/90000 (68%)]	Loss: -13.3730	Cost: 12.32s
Train Epoch: 2113 [81920/90000 (91%)]	Loss: -12.7078	Cost: 12.13s
Train Epoch: 2113 	Average Loss: -12.7665
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5851

Learning rate: 8.938226370050244e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2114 [0/90000 (0%)]	Loss: -6.8086	Cost: 30.28s
Train Epoch: 2114 [20480/90000 (23%)]	Loss: -12.9641	Cost: 13.22s
Train Epoch: 2114 [40960/90000 (45%)]	Loss: -13.1210	Cost: 12.42s
Train Epoch: 2114 [61440/90000 (68%)]	Loss: -13.2323	Cost: 12.33s
Train Epoch: 2114 [81920/90000 (91%)]	Loss: -13.1217	Cost: 9.62s
Train Epoch: 2114 	Average Loss: -12.6356
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1072

Learning rate: 8.937258362580892e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2115 [0/90000 (0%)]	Loss: -6.6141	Cost: 22.75s
Train Epoch: 2115 [20480/90000 (23%)]	Loss: -13.4895	Cost: 9.73s
Train Epoch: 2115 [40960/90000 (45%)]	Loss: -13.3455	Cost: 11.27s
Train Epoch: 2115 [61440/90000 (68%)]	Loss: -13.4938	Cost: 6.14s
Train Epoch: 2115 [81920/90000 (91%)]	Loss: -13.2605	Cost: 7.33s
Train Epoch: 2115 	Average Loss: -12.8652
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2185

Saving model as e2115_model.pt & e2115_waveforms_supplementary.hdf5
Learning rate: 8.93628996651972e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2116 [0/90000 (0%)]	Loss: -6.9476	Cost: 20.19s
Train Epoch: 2116 [20480/90000 (23%)]	Loss: -13.4847	Cost: 9.36s
Train Epoch: 2116 [40960/90000 (45%)]	Loss: -13.5800	Cost: 9.28s
Train Epoch: 2116 [61440/90000 (68%)]	Loss: -13.7405	Cost: 8.90s
Train Epoch: 2116 [81920/90000 (91%)]	Loss: -13.1467	Cost: 7.31s
Train Epoch: 2116 	Average Loss: -13.0356
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2136

Learning rate: 8.935321181962305e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2117 [0/90000 (0%)]	Loss: -5.8020	Cost: 24.17s
Train Epoch: 2117 [20480/90000 (23%)]	Loss: -13.2103	Cost: 9.77s
Train Epoch: 2117 [40960/90000 (45%)]	Loss: -12.6879	Cost: 9.08s
Train Epoch: 2117 [61440/90000 (68%)]	Loss: -13.0803	Cost: 6.46s
Train Epoch: 2117 [81920/90000 (91%)]	Loss: -12.3969	Cost: 6.19s
Train Epoch: 2117 	Average Loss: -12.3717
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6184

Learning rate: 8.934352009004257e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2118 [0/90000 (0%)]	Loss: -4.7117	Cost: 26.07s
Train Epoch: 2118 [20480/90000 (23%)]	Loss: -12.6539	Cost: 7.37s
Train Epoch: 2118 [40960/90000 (45%)]	Loss: -13.0835	Cost: 12.48s
Train Epoch: 2118 [61440/90000 (68%)]	Loss: -13.1445	Cost: 10.97s
Train Epoch: 2118 [81920/90000 (91%)]	Loss: -12.7908	Cost: 12.33s
Train Epoch: 2118 	Average Loss: -12.4299
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7340

Learning rate: 8.933382447741235e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2119 [0/90000 (0%)]	Loss: -5.7685	Cost: 20.42s
Train Epoch: 2119 [20480/90000 (23%)]	Loss: -13.3053	Cost: 10.87s
Train Epoch: 2119 [40960/90000 (45%)]	Loss: -13.5754	Cost: 14.26s
Train Epoch: 2119 [61440/90000 (68%)]	Loss: -13.5907	Cost: 12.58s
Train Epoch: 2119 [81920/90000 (91%)]	Loss: -13.2808	Cost: 12.63s
Train Epoch: 2119 	Average Loss: -12.8584
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2154

Learning rate: 8.932412498268929e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2120 [0/90000 (0%)]	Loss: -7.1947	Cost: 26.67s
Train Epoch: 2120 [20480/90000 (23%)]	Loss: -13.6128	Cost: 13.20s
Train Epoch: 2120 [40960/90000 (45%)]	Loss: -13.6944	Cost: 14.05s
Train Epoch: 2120 [61440/90000 (68%)]	Loss: -13.7154	Cost: 12.56s
Train Epoch: 2120 [81920/90000 (91%)]	Loss: -13.4907	Cost: 8.62s
Train Epoch: 2120 	Average Loss: -13.1203
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3583

Saving model as e2120_model.pt & e2120_waveforms_supplementary.hdf5
Learning rate: 8.931442160683068e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2121 [0/90000 (0%)]	Loss: -7.0310	Cost: 25.97s
Train Epoch: 2121 [20480/90000 (23%)]	Loss: -13.5286	Cost: 10.48s
Train Epoch: 2121 [40960/90000 (45%)]	Loss: -13.5694	Cost: 11.64s
Train Epoch: 2121 [61440/90000 (68%)]	Loss: -13.7398	Cost: 6.14s
Train Epoch: 2121 [81920/90000 (91%)]	Loss: -13.3455	Cost: 6.50s
Train Epoch: 2121 	Average Loss: -13.0876
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3183

Learning rate: 8.930471435079425e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2122 [0/90000 (0%)]	Loss: -6.1475	Cost: 33.19s
Train Epoch: 2122 [20480/90000 (23%)]	Loss: -13.5373	Cost: 7.06s
Train Epoch: 2122 [40960/90000 (45%)]	Loss: -13.7467	Cost: 9.14s
Train Epoch: 2122 [61440/90000 (68%)]	Loss: -13.9258	Cost: 8.92s
Train Epoch: 2122 [81920/90000 (91%)]	Loss: -13.6359	Cost: 8.41s
Train Epoch: 2122 	Average Loss: -13.0937
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2978

Learning rate: 8.9295003215538e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2123 [0/90000 (0%)]	Loss: -6.4275	Cost: 30.90s
Train Epoch: 2123 [20480/90000 (23%)]	Loss: -13.4188	Cost: 8.94s
Train Epoch: 2123 [40960/90000 (45%)]	Loss: -13.2347	Cost: 8.99s
Train Epoch: 2123 [61440/90000 (68%)]	Loss: -13.6071	Cost: 8.72s
Train Epoch: 2123 [81920/90000 (91%)]	Loss: -13.2595	Cost: 8.18s
Train Epoch: 2123 	Average Loss: -12.8540
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0822

Learning rate: 8.928528820202045e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2124 [0/90000 (0%)]	Loss: -5.6880	Cost: 21.07s
Train Epoch: 2124 [20480/90000 (23%)]	Loss: -13.5590	Cost: 7.62s
Train Epoch: 2124 [40960/90000 (45%)]	Loss: -13.4086	Cost: 10.88s
Train Epoch: 2124 [61440/90000 (68%)]	Loss: -13.6496	Cost: 9.67s
Train Epoch: 2124 [81920/90000 (91%)]	Loss: -13.2448	Cost: 17.70s
Train Epoch: 2124 	Average Loss: -12.8905
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0949

Learning rate: 8.927556931120037e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2125 [0/90000 (0%)]	Loss: -6.8098	Cost: 23.35s
Train Epoch: 2125 [20480/90000 (23%)]	Loss: -13.3972	Cost: 9.60s
Train Epoch: 2125 [40960/90000 (45%)]	Loss: -13.5117	Cost: 13.59s
Train Epoch: 2125 [61440/90000 (68%)]	Loss: -13.5226	Cost: 14.01s
Train Epoch: 2125 [81920/90000 (91%)]	Loss: -13.2888	Cost: 12.69s
Train Epoch: 2125 	Average Loss: -12.9393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1768

Learning rate: 8.926584654403701e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2126 [0/90000 (0%)]	Loss: -5.9501	Cost: 24.27s
Train Epoch: 2126 [20480/90000 (23%)]	Loss: -13.2937	Cost: 14.88s
Train Epoch: 2126 [40960/90000 (45%)]	Loss: -13.3617	Cost: 13.20s
Train Epoch: 2126 [61440/90000 (68%)]	Loss: -13.3367	Cost: 12.19s
Train Epoch: 2126 [81920/90000 (91%)]	Loss: -13.1526	Cost: 8.20s
Train Epoch: 2126 	Average Loss: -12.8575
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1493

Learning rate: 8.925611990148997e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2127 [0/90000 (0%)]	Loss: -7.2019	Cost: 35.78s
Train Epoch: 2127 [20480/90000 (23%)]	Loss: -13.3975	Cost: 12.10s
Train Epoch: 2127 [40960/90000 (45%)]	Loss: -13.5963	Cost: 7.95s
Train Epoch: 2127 [61440/90000 (68%)]	Loss: -13.7589	Cost: 6.27s
Train Epoch: 2127 [81920/90000 (91%)]	Loss: -13.2798	Cost: 8.07s
Train Epoch: 2127 	Average Loss: -13.0719
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0708

Learning rate: 8.924638938451922e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2128 [0/90000 (0%)]	Loss: -6.0786	Cost: 35.84s
Train Epoch: 2128 [20480/90000 (23%)]	Loss: -13.5245	Cost: 6.45s
Train Epoch: 2128 [40960/90000 (45%)]	Loss: -13.7144	Cost: 8.60s
Train Epoch: 2128 [61440/90000 (68%)]	Loss: -13.6150	Cost: 8.98s
Train Epoch: 2128 [81920/90000 (91%)]	Loss: -13.5488	Cost: 8.75s
Train Epoch: 2128 	Average Loss: -13.0947
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1173

Learning rate: 8.923665499408512e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2129 [0/90000 (0%)]	Loss: -7.2643	Cost: 20.22s
Train Epoch: 2129 [20480/90000 (23%)]	Loss: -13.7204	Cost: 7.33s
Train Epoch: 2129 [40960/90000 (45%)]	Loss: -13.7429	Cost: 9.41s
Train Epoch: 2129 [61440/90000 (68%)]	Loss: -13.5517	Cost: 8.84s
Train Epoch: 2129 [81920/90000 (91%)]	Loss: -13.3904	Cost: 8.98s
Train Epoch: 2129 	Average Loss: -13.1185
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2209

Learning rate: 8.922691673114843e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2130 [0/90000 (0%)]	Loss: -4.9394	Cost: 21.78s
Train Epoch: 2130 [20480/90000 (23%)]	Loss: -13.2797	Cost: 9.05s
Train Epoch: 2130 [40960/90000 (45%)]	Loss: -13.6799	Cost: 9.08s
Train Epoch: 2130 [61440/90000 (68%)]	Loss: -13.6782	Cost: 7.85s
Train Epoch: 2130 [81920/90000 (91%)]	Loss: -13.4395	Cost: 8.20s
Train Epoch: 2130 	Average Loss: -12.9519
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1468

Learning rate: 8.921717459667027e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2131 [0/90000 (0%)]	Loss: -6.4022	Cost: 20.26s
Train Epoch: 2131 [20480/90000 (23%)]	Loss: -13.1864	Cost: 9.60s
Train Epoch: 2131 [40960/90000 (45%)]	Loss: -13.1060	Cost: 10.61s
Train Epoch: 2131 [61440/90000 (68%)]	Loss: -13.4307	Cost: 13.01s
Train Epoch: 2131 [81920/90000 (91%)]	Loss: -13.2708	Cost: 12.30s
Train Epoch: 2131 	Average Loss: -12.8191
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1715

Learning rate: 8.920742859161217e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2132 [0/90000 (0%)]	Loss: -5.4054	Cost: 28.31s
Train Epoch: 2132 [20480/90000 (23%)]	Loss: -13.4731	Cost: 13.28s
Train Epoch: 2132 [40960/90000 (45%)]	Loss: -13.8585	Cost: 13.72s
Train Epoch: 2132 [61440/90000 (68%)]	Loss: -13.7511	Cost: 12.43s
Train Epoch: 2132 [81920/90000 (91%)]	Loss: -13.6205	Cost: 12.31s
Train Epoch: 2132 	Average Loss: -13.0619
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3563

Learning rate: 8.919767871693597e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2133 [0/90000 (0%)]	Loss: -6.4849	Cost: 34.96s
Train Epoch: 2133 [20480/90000 (23%)]	Loss: -13.6506	Cost: 12.83s
Train Epoch: 2133 [40960/90000 (45%)]	Loss: -13.7209	Cost: 12.36s
Train Epoch: 2133 [61440/90000 (68%)]	Loss: -13.6642	Cost: 12.18s
Train Epoch: 2133 [81920/90000 (91%)]	Loss: -13.4664	Cost: 8.98s
Train Epoch: 2133 	Average Loss: -13.1100
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1479

Learning rate: 8.9187924973604e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2134 [0/90000 (0%)]	Loss: -5.4503	Cost: 34.54s
Train Epoch: 2134 [20480/90000 (23%)]	Loss: -13.3672	Cost: 13.06s
Train Epoch: 2134 [40960/90000 (45%)]	Loss: -13.7138	Cost: 11.55s
Train Epoch: 2134 [61440/90000 (68%)]	Loss: -13.6686	Cost: 6.62s
Train Epoch: 2134 [81920/90000 (91%)]	Loss: -13.3599	Cost: 6.56s
Train Epoch: 2134 	Average Loss: -13.0721
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1878

Learning rate: 8.917816736257888e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2135 [0/90000 (0%)]	Loss: -5.3748	Cost: 23.29s
Train Epoch: 2135 [20480/90000 (23%)]	Loss: -13.4283	Cost: 9.58s
Train Epoch: 2135 [40960/90000 (45%)]	Loss: -13.7659	Cost: 8.39s
Train Epoch: 2135 [61440/90000 (68%)]	Loss: -13.8309	Cost: 7.21s
Train Epoch: 2135 [81920/90000 (91%)]	Loss: -13.5021	Cost: 8.51s
Train Epoch: 2135 	Average Loss: -13.0591
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2503

Learning rate: 8.916840588482369e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2136 [0/90000 (0%)]	Loss: -5.7077	Cost: 20.55s
Train Epoch: 2136 [20480/90000 (23%)]	Loss: -13.6365	Cost: 8.69s
Train Epoch: 2136 [40960/90000 (45%)]	Loss: -13.6336	Cost: 9.63s
Train Epoch: 2136 [61440/90000 (68%)]	Loss: -13.6541	Cost: 8.78s
Train Epoch: 2136 [81920/90000 (91%)]	Loss: -13.5234	Cost: 8.64s
Train Epoch: 2136 	Average Loss: -13.0751
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3132

Learning rate: 8.91586405413018e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2137 [0/90000 (0%)]	Loss: -5.8832	Cost: 32.87s
Train Epoch: 2137 [20480/90000 (23%)]	Loss: -13.6304	Cost: 8.85s
Train Epoch: 2137 [40960/90000 (45%)]	Loss: -13.6806	Cost: 8.83s
Train Epoch: 2137 [61440/90000 (68%)]	Loss: -13.6672	Cost: 8.63s
Train Epoch: 2137 [81920/90000 (91%)]	Loss: -13.2937	Cost: 7.52s
Train Epoch: 2137 	Average Loss: -13.0683
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1174

Learning rate: 8.914887133297702e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2138 [0/90000 (0%)]	Loss: -6.3572	Cost: 22.27s
Train Epoch: 2138 [20480/90000 (23%)]	Loss: -13.4112	Cost: 6.89s
Train Epoch: 2138 [40960/90000 (45%)]	Loss: -13.6149	Cost: 9.80s
Train Epoch: 2138 [61440/90000 (68%)]	Loss: -13.6748	Cost: 7.92s
Train Epoch: 2138 [81920/90000 (91%)]	Loss: -13.5855	Cost: 14.81s
Train Epoch: 2138 	Average Loss: -13.0795
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2543

Learning rate: 8.913909826081356e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2139 [0/90000 (0%)]	Loss: -4.7210	Cost: 28.60s
Train Epoch: 2139 [20480/90000 (23%)]	Loss: -13.6670	Cost: 12.18s
Train Epoch: 2139 [40960/90000 (45%)]	Loss: -13.6669	Cost: 14.51s
Train Epoch: 2139 [61440/90000 (68%)]	Loss: -13.9533	Cost: 12.47s
Train Epoch: 2139 [81920/90000 (91%)]	Loss: -13.5359	Cost: 12.39s
Train Epoch: 2139 	Average Loss: -13.1065
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0981

Learning rate: 8.912932132577597e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2140 [0/90000 (0%)]	Loss: -6.7364	Cost: 26.40s
Train Epoch: 2140 [20480/90000 (23%)]	Loss: -13.5282	Cost: 15.11s
Train Epoch: 2140 [40960/90000 (45%)]	Loss: -13.4886	Cost: 13.98s
Train Epoch: 2140 [61440/90000 (68%)]	Loss: -13.6055	Cost: 12.17s
Train Epoch: 2140 [81920/90000 (91%)]	Loss: -13.4705	Cost: 9.20s
Train Epoch: 2140 	Average Loss: -13.0090
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3771

Saving model as e2140_model.pt & e2140_waveforms_supplementary.hdf5
Learning rate: 8.911954052882919e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2141 [0/90000 (0%)]	Loss: -6.3440	Cost: 27.44s
Train Epoch: 2141 [20480/90000 (23%)]	Loss: -13.3509	Cost: 13.53s
Train Epoch: 2141 [40960/90000 (45%)]	Loss: -13.6627	Cost: 12.40s
Train Epoch: 2141 [61440/90000 (68%)]	Loss: -13.6257	Cost: 11.35s
Train Epoch: 2141 [81920/90000 (91%)]	Loss: -13.5101	Cost: 6.30s
Train Epoch: 2141 	Average Loss: -13.0672
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2816

Learning rate: 8.910975587093856e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2142 [0/90000 (0%)]	Loss: -6.6941	Cost: 33.66s
Train Epoch: 2142 [20480/90000 (23%)]	Loss: -13.6183	Cost: 11.18s
Train Epoch: 2142 [40960/90000 (45%)]	Loss: -13.4800	Cost: 8.22s
Train Epoch: 2142 [61440/90000 (68%)]	Loss: -13.8662	Cost: 6.13s
Train Epoch: 2142 [81920/90000 (91%)]	Loss: -13.6534	Cost: 7.52s
Train Epoch: 2142 	Average Loss: -13.1009
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2767

Learning rate: 8.909996735306974e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2143 [0/90000 (0%)]	Loss: -5.1490	Cost: 25.78s
Train Epoch: 2143 [20480/90000 (23%)]	Loss: -13.5501	Cost: 7.33s
Train Epoch: 2143 [40960/90000 (45%)]	Loss: -13.7511	Cost: 10.06s
Train Epoch: 2143 [61440/90000 (68%)]	Loss: -13.8890	Cost: 8.47s
Train Epoch: 2143 [81920/90000 (91%)]	Loss: -13.6349	Cost: 8.44s
Train Epoch: 2143 	Average Loss: -13.0572
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1969

Learning rate: 8.909017497618888e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2144 [0/90000 (0%)]	Loss: -5.7448	Cost: 23.67s
Train Epoch: 2144 [20480/90000 (23%)]	Loss: -13.6857	Cost: 11.61s
Train Epoch: 2144 [40960/90000 (45%)]	Loss: -13.6174	Cost: 9.19s
Train Epoch: 2144 [61440/90000 (68%)]	Loss: -13.7381	Cost: 9.58s
Train Epoch: 2144 [81920/90000 (91%)]	Loss: -13.2513	Cost: 11.43s
Train Epoch: 2144 	Average Loss: -13.0134
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9711

Learning rate: 8.908037874126241e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2145 [0/90000 (0%)]	Loss: -6.3186	Cost: 19.60s
Train Epoch: 2145 [20480/90000 (23%)]	Loss: -13.2856	Cost: 10.81s
Train Epoch: 2145 [40960/90000 (45%)]	Loss: -13.5909	Cost: 15.44s
Train Epoch: 2145 [61440/90000 (68%)]	Loss: -13.7923	Cost: 14.25s
Train Epoch: 2145 [81920/90000 (91%)]	Loss: -13.4926	Cost: 12.68s
Train Epoch: 2145 	Average Loss: -12.9306
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3439

Learning rate: 8.90705786492572e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2146 [0/90000 (0%)]	Loss: -6.1084	Cost: 27.23s
Train Epoch: 2146 [20480/90000 (23%)]	Loss: -13.4865	Cost: 14.23s
Train Epoch: 2146 [40960/90000 (45%)]	Loss: -13.6401	Cost: 12.83s
Train Epoch: 2146 [61440/90000 (68%)]	Loss: -13.8583	Cost: 12.25s
Train Epoch: 2146 [81920/90000 (91%)]	Loss: -13.3465	Cost: 12.30s
Train Epoch: 2146 	Average Loss: -13.0658
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1815

Learning rate: 8.906077470114047e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2147 [0/90000 (0%)]	Loss: -6.7379	Cost: 24.66s
Train Epoch: 2147 [20480/90000 (23%)]	Loss: -13.7199	Cost: 11.69s
Train Epoch: 2147 [40960/90000 (45%)]	Loss: -13.7786	Cost: 12.59s
Train Epoch: 2147 [61440/90000 (68%)]	Loss: -13.9160	Cost: 12.07s
Train Epoch: 2147 [81920/90000 (91%)]	Loss: -13.5788	Cost: 8.49s
Train Epoch: 2147 	Average Loss: -13.2290
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2731

Learning rate: 8.905096689787983e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2148 [0/90000 (0%)]	Loss: -7.6554	Cost: 29.36s
Train Epoch: 2148 [20480/90000 (23%)]	Loss: -13.8302	Cost: 11.93s
Train Epoch: 2148 [40960/90000 (45%)]	Loss: -13.9346	Cost: 8.95s
Train Epoch: 2148 [61440/90000 (68%)]	Loss: -13.8846	Cost: 6.33s
Train Epoch: 2148 [81920/90000 (91%)]	Loss: -13.7049	Cost: 7.21s
Train Epoch: 2148 	Average Loss: -13.2643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2430

Learning rate: 8.904115524044328e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2149 [0/90000 (0%)]	Loss: -5.9013	Cost: 31.38s
Train Epoch: 2149 [20480/90000 (23%)]	Loss: -13.5491	Cost: 9.53s
Train Epoch: 2149 [40960/90000 (45%)]	Loss: -13.6617	Cost: 9.15s
Train Epoch: 2149 [61440/90000 (68%)]	Loss: -13.8350	Cost: 8.71s
Train Epoch: 2149 [81920/90000 (91%)]	Loss: -13.5261	Cost: 8.68s
Train Epoch: 2149 	Average Loss: -13.0782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3653

Learning rate: 8.903133972979917e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2150 [0/90000 (0%)]	Loss: -5.7366	Cost: 20.75s
Train Epoch: 2150 [20480/90000 (23%)]	Loss: -13.6759	Cost: 8.48s
Train Epoch: 2150 [40960/90000 (45%)]	Loss: -13.8176	Cost: 12.98s
Train Epoch: 2150 [61440/90000 (68%)]	Loss: -13.5379	Cost: 9.12s
Train Epoch: 2150 [81920/90000 (91%)]	Loss: -13.6298	Cost: 8.70s
Train Epoch: 2150 	Average Loss: -13.1344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2073

Learning rate: 8.902152036691628e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2151 [0/90000 (0%)]	Loss: -6.8594	Cost: 22.10s
Train Epoch: 2151 [20480/90000 (23%)]	Loss: -13.6621	Cost: 7.18s
Train Epoch: 2151 [40960/90000 (45%)]	Loss: -13.7487	Cost: 7.43s
Train Epoch: 2151 [61440/90000 (68%)]	Loss: -13.8707	Cost: 7.11s
Train Epoch: 2151 [81920/90000 (91%)]	Loss: -13.5599	Cost: 15.20s
Train Epoch: 2151 	Average Loss: -13.2157
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3952

Saving model as e2151_model.pt & e2151_waveforms_supplementary.hdf5
Learning rate: 8.901169715276373e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2152 [0/90000 (0%)]	Loss: -6.0269	Cost: 21.23s
Train Epoch: 2152 [20480/90000 (23%)]	Loss: -13.7248	Cost: 11.14s
Train Epoch: 2152 [40960/90000 (45%)]	Loss: -13.8199	Cost: 12.75s
Train Epoch: 2152 [61440/90000 (68%)]	Loss: -13.7166	Cost: 12.21s
Train Epoch: 2152 [81920/90000 (91%)]	Loss: -13.5422	Cost: 12.58s
Train Epoch: 2152 	Average Loss: -13.1896
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2355

Learning rate: 8.900187008831104e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2153 [0/90000 (0%)]	Loss: -6.4085	Cost: 26.60s
Train Epoch: 2153 [20480/90000 (23%)]	Loss: -13.4033	Cost: 14.59s
Train Epoch: 2153 [40960/90000 (45%)]	Loss: -13.4398	Cost: 13.05s
Train Epoch: 2153 [61440/90000 (68%)]	Loss: -13.5915	Cost: 12.18s
Train Epoch: 2153 [81920/90000 (91%)]	Loss: -13.6005	Cost: 8.78s
Train Epoch: 2153 	Average Loss: -12.9738
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0970

Learning rate: 8.899203917452807e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2154 [0/90000 (0%)]	Loss: -6.0205	Cost: 40.18s
Train Epoch: 2154 [20480/90000 (23%)]	Loss: -12.8963	Cost: 12.48s
Train Epoch: 2154 [40960/90000 (45%)]	Loss: -13.5151	Cost: 9.59s
Train Epoch: 2154 [61440/90000 (68%)]	Loss: -13.4742	Cost: 6.48s
Train Epoch: 2154 [81920/90000 (91%)]	Loss: -13.2208	Cost: 7.32s
Train Epoch: 2154 	Average Loss: -12.7851
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1227

Learning rate: 8.898220441238513e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2155 [0/90000 (0%)]	Loss: -7.0509	Cost: 36.67s
Train Epoch: 2155 [20480/90000 (23%)]	Loss: -13.7207	Cost: 8.18s
Train Epoch: 2155 [40960/90000 (45%)]	Loss: -13.8403	Cost: 6.99s
Train Epoch: 2155 [61440/90000 (68%)]	Loss: -13.9844	Cost: 7.65s
Train Epoch: 2155 [81920/90000 (91%)]	Loss: -13.7683	Cost: 8.53s
Train Epoch: 2155 	Average Loss: -13.1719
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3368

Learning rate: 8.897236580285288e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2156 [0/90000 (0%)]	Loss: -6.4715	Cost: 25.53s
Train Epoch: 2156 [20480/90000 (23%)]	Loss: -13.6863	Cost: 6.57s
Train Epoch: 2156 [40960/90000 (45%)]	Loss: -13.6913	Cost: 9.85s
Train Epoch: 2156 [61440/90000 (68%)]	Loss: -13.8527	Cost: 9.01s
Train Epoch: 2156 [81920/90000 (91%)]	Loss: -13.5536	Cost: 8.91s
Train Epoch: 2156 	Average Loss: -13.0962
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1627

Learning rate: 8.89625233469023e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2157 [0/90000 (0%)]	Loss: -6.5605	Cost: 22.73s
Train Epoch: 2157 [20480/90000 (23%)]	Loss: -13.5359	Cost: 8.96s
Train Epoch: 2157 [40960/90000 (45%)]	Loss: -13.8371	Cost: 8.80s
Train Epoch: 2157 [61440/90000 (68%)]	Loss: -13.9367	Cost: 8.76s
Train Epoch: 2157 [81920/90000 (91%)]	Loss: -13.7165	Cost: 7.62s
Train Epoch: 2157 	Average Loss: -13.2093
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2746

Learning rate: 8.895267704550484e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2158 [0/90000 (0%)]	Loss: -6.9655	Cost: 20.14s
Train Epoch: 2158 [20480/90000 (23%)]	Loss: -13.5458	Cost: 10.02s
Train Epoch: 2158 [40960/90000 (45%)]	Loss: -13.8702	Cost: 16.66s
Train Epoch: 2158 [61440/90000 (68%)]	Loss: -13.7493	Cost: 12.69s
Train Epoch: 2158 [81920/90000 (91%)]	Loss: -13.5978	Cost: 12.18s
Train Epoch: 2158 	Average Loss: -13.1049
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2116

Learning rate: 8.89428268996323e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2159 [0/90000 (0%)]	Loss: -6.3492	Cost: 33.00s
Train Epoch: 2159 [20480/90000 (23%)]	Loss: -13.4195	Cost: 12.57s
Train Epoch: 2159 [40960/90000 (45%)]	Loss: -13.4382	Cost: 12.60s
Train Epoch: 2159 [61440/90000 (68%)]	Loss: -13.7224	Cost: 12.22s
Train Epoch: 2159 [81920/90000 (91%)]	Loss: -13.5390	Cost: 12.13s
Train Epoch: 2159 	Average Loss: -13.0223
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3726

Learning rate: 8.89329729102568e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2160 [0/90000 (0%)]	Loss: -6.7281	Cost: 27.77s
Train Epoch: 2160 [20480/90000 (23%)]	Loss: -13.5684	Cost: 11.80s
Train Epoch: 2160 [40960/90000 (45%)]	Loss: -13.8607	Cost: 12.38s
Train Epoch: 2160 [61440/90000 (68%)]	Loss: -13.9562	Cost: 12.43s
Train Epoch: 2160 [81920/90000 (91%)]	Loss: -13.6546	Cost: 7.29s
Train Epoch: 2160 	Average Loss: -13.2898
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2258

Learning rate: 8.892311507835096e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2161 [0/90000 (0%)]	Loss: -6.4652	Cost: 35.49s
Train Epoch: 2161 [20480/90000 (23%)]	Loss: -13.4170	Cost: 13.07s
Train Epoch: 2161 [40960/90000 (45%)]	Loss: -13.6101	Cost: 12.40s
Train Epoch: 2161 [61440/90000 (68%)]	Loss: -13.8329	Cost: 6.41s
Train Epoch: 2161 [81920/90000 (91%)]	Loss: -13.6188	Cost: 6.24s
Train Epoch: 2161 	Average Loss: -13.1730
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4412

Saving model as e2161_model.pt & e2161_waveforms_supplementary.hdf5
Learning rate: 8.891325340488766e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2162 [0/90000 (0%)]	Loss: -5.8241	Cost: 21.56s
Train Epoch: 2162 [20480/90000 (23%)]	Loss: -13.7160	Cost: 10.18s
Train Epoch: 2162 [40960/90000 (45%)]	Loss: -13.7491	Cost: 11.59s
Train Epoch: 2162 [61440/90000 (68%)]	Loss: -13.7166	Cost: 7.60s
Train Epoch: 2162 [81920/90000 (91%)]	Loss: -13.2901	Cost: 8.41s
Train Epoch: 2162 	Average Loss: -13.1333
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9710

Learning rate: 8.89033878908402e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2163 [0/90000 (0%)]	Loss: -6.2670	Cost: 21.48s
Train Epoch: 2163 [20480/90000 (23%)]	Loss: -13.3944	Cost: 9.75s
Train Epoch: 2163 [40960/90000 (45%)]	Loss: -13.3796	Cost: 6.45s
Train Epoch: 2163 [61440/90000 (68%)]	Loss: -13.7608	Cost: 6.95s
Train Epoch: 2163 [81920/90000 (91%)]	Loss: -13.3660	Cost: 8.81s
Train Epoch: 2163 	Average Loss: -12.9996
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0499

Learning rate: 8.889351853718233e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2164 [0/90000 (0%)]	Loss: -6.2205	Cost: 23.25s
Train Epoch: 2164 [20480/90000 (23%)]	Loss: -13.0720	Cost: 9.59s
Train Epoch: 2164 [40960/90000 (45%)]	Loss: -13.5115	Cost: 10.45s
Train Epoch: 2164 [61440/90000 (68%)]	Loss: -13.5924	Cost: 8.63s
Train Epoch: 2164 [81920/90000 (91%)]	Loss: -13.4254	Cost: 8.65s
Train Epoch: 2164 	Average Loss: -12.9576
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1442

Learning rate: 8.888364534488804e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2165 [0/90000 (0%)]	Loss: -6.5541	Cost: 20.79s
Train Epoch: 2165 [20480/90000 (23%)]	Loss: -13.4752	Cost: 8.84s
Train Epoch: 2165 [40960/90000 (45%)]	Loss: -13.5626	Cost: 11.37s
Train Epoch: 2165 [61440/90000 (68%)]	Loss: -13.7215	Cost: 9.12s
Train Epoch: 2165 [81920/90000 (91%)]	Loss: -13.4343	Cost: 9.02s
Train Epoch: 2165 	Average Loss: -12.9991
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1656

Learning rate: 8.887376831493182e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2166 [0/90000 (0%)]	Loss: -6.6158	Cost: 26.77s
Train Epoch: 2166 [20480/90000 (23%)]	Loss: -13.4644	Cost: 8.63s
Train Epoch: 2166 [40960/90000 (45%)]	Loss: -13.5822	Cost: 8.83s
Train Epoch: 2166 [61440/90000 (68%)]	Loss: -13.8341	Cost: 8.60s
Train Epoch: 2166 [81920/90000 (91%)]	Loss: -13.5293	Cost: 8.73s
Train Epoch: 2166 	Average Loss: -13.1569
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3589

Learning rate: 8.886388744828849e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2167 [0/90000 (0%)]	Loss: -5.5584	Cost: 20.70s
Train Epoch: 2167 [20480/90000 (23%)]	Loss: -13.5300	Cost: 8.96s
Train Epoch: 2167 [40960/90000 (45%)]	Loss: -13.6396	Cost: 8.94s
Train Epoch: 2167 [61440/90000 (68%)]	Loss: -13.9366	Cost: 5.94s
Train Epoch: 2167 [81920/90000 (91%)]	Loss: -13.5958	Cost: 6.38s
Train Epoch: 2167 	Average Loss: -13.1078
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3568

Learning rate: 8.885400274593324e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2168 [0/90000 (0%)]	Loss: -6.6961	Cost: 21.72s
Train Epoch: 2168 [20480/90000 (23%)]	Loss: -13.7980	Cost: 7.04s
Train Epoch: 2168 [40960/90000 (45%)]	Loss: -13.5622	Cost: 11.45s
Train Epoch: 2168 [61440/90000 (68%)]	Loss: -13.5779	Cost: 12.64s
Train Epoch: 2168 [81920/90000 (91%)]	Loss: -13.2249	Cost: 12.71s
Train Epoch: 2168 	Average Loss: -13.1246
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0816

Learning rate: 8.884411420884166e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2169 [0/90000 (0%)]	Loss: -5.5135	Cost: 38.52s
Train Epoch: 2169 [20480/90000 (23%)]	Loss: -13.4653	Cost: 15.03s
Train Epoch: 2169 [40960/90000 (45%)]	Loss: -13.7113	Cost: 13.85s
Train Epoch: 2169 [61440/90000 (68%)]	Loss: -13.8634	Cost: 12.19s
Train Epoch: 2169 [81920/90000 (91%)]	Loss: -13.7649	Cost: 10.63s
Train Epoch: 2169 	Average Loss: -13.1053
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3514

Learning rate: 8.883422183798969e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2170 [0/90000 (0%)]	Loss: -6.9206	Cost: 32.23s
Train Epoch: 2170 [20480/90000 (23%)]	Loss: -13.6721	Cost: 14.69s
Train Epoch: 2170 [40960/90000 (45%)]	Loss: -13.9503	Cost: 12.50s
Train Epoch: 2170 [61440/90000 (68%)]	Loss: -14.1353	Cost: 10.85s
Train Epoch: 2170 [81920/90000 (91%)]	Loss: -13.7147	Cost: 6.21s
Train Epoch: 2170 	Average Loss: -13.3417
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2206

Learning rate: 8.88243256343537e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2171 [0/90000 (0%)]	Loss: -5.9952	Cost: 30.44s
Train Epoch: 2171 [20480/90000 (23%)]	Loss: -13.6305	Cost: 12.87s
Train Epoch: 2171 [40960/90000 (45%)]	Loss: -13.8106	Cost: 10.32s
Train Epoch: 2171 [61440/90000 (68%)]	Loss: -14.0440	Cost: 6.17s
Train Epoch: 2171 [81920/90000 (91%)]	Loss: -13.7277	Cost: 7.28s
Train Epoch: 2171 	Average Loss: -13.2550
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3931

Learning rate: 8.881442559891038e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2172 [0/90000 (0%)]	Loss: -6.5764	Cost: 18.80s
Train Epoch: 2172 [20480/90000 (23%)]	Loss: -13.6149	Cost: 6.59s
Train Epoch: 2172 [40960/90000 (45%)]	Loss: -14.1323	Cost: 10.01s
Train Epoch: 2172 [61440/90000 (68%)]	Loss: -13.9267	Cost: 8.78s
Train Epoch: 2172 [81920/90000 (91%)]	Loss: -13.5997	Cost: 8.59s
Train Epoch: 2172 	Average Loss: -13.3944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3740

Learning rate: 8.880452173263684e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2173 [0/90000 (0%)]	Loss: -5.9212	Cost: 22.76s
Train Epoch: 2173 [20480/90000 (23%)]	Loss: -13.6818	Cost: 9.03s
Train Epoch: 2173 [40960/90000 (45%)]	Loss: -13.7675	Cost: 9.09s
Train Epoch: 2173 [61440/90000 (68%)]	Loss: -13.6693	Cost: 8.94s
Train Epoch: 2173 [81920/90000 (91%)]	Loss: -13.4027	Cost: 8.25s
Train Epoch: 2173 	Average Loss: -13.1772
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2837

Learning rate: 8.879461403651055e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2174 [0/90000 (0%)]	Loss: -6.9002	Cost: 22.15s
Train Epoch: 2174 [20480/90000 (23%)]	Loss: -13.6839	Cost: 9.06s
Train Epoch: 2174 [40960/90000 (45%)]	Loss: -13.8258	Cost: 9.38s
Train Epoch: 2174 [61440/90000 (68%)]	Loss: -13.8950	Cost: 8.98s
Train Epoch: 2174 [81920/90000 (91%)]	Loss: -13.8983	Cost: 12.41s
Train Epoch: 2174 	Average Loss: -13.2318
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4854

Saving model as e2174_model.pt & e2174_waveforms_supplementary.hdf5
Learning rate: 8.878470251150936e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2175 [0/90000 (0%)]	Loss: -6.3350	Cost: 27.01s
Train Epoch: 2175 [20480/90000 (23%)]	Loss: -13.7990	Cost: 9.89s
Train Epoch: 2175 [40960/90000 (45%)]	Loss: -13.9948	Cost: 16.08s
Train Epoch: 2175 [61440/90000 (68%)]	Loss: -13.9956	Cost: 12.50s
Train Epoch: 2175 [81920/90000 (91%)]	Loss: -13.6685	Cost: 12.25s
Train Epoch: 2175 	Average Loss: -13.3501
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4165

Learning rate: 8.877478715861149e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2176 [0/90000 (0%)]	Loss: -6.3448	Cost: 28.67s
Train Epoch: 2176 [20480/90000 (23%)]	Loss: -13.6507	Cost: 12.83s
Train Epoch: 2176 [40960/90000 (45%)]	Loss: -13.7490	Cost: 13.50s
Train Epoch: 2176 [61440/90000 (68%)]	Loss: -13.7427	Cost: 12.29s
Train Epoch: 2176 [81920/90000 (91%)]	Loss: -13.3314	Cost: 9.94s
Train Epoch: 2176 	Average Loss: -13.1806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1048

Learning rate: 8.876486797879555e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2177 [0/90000 (0%)]	Loss: -5.1246	Cost: 24.99s
Train Epoch: 2177 [20480/90000 (23%)]	Loss: -13.3451	Cost: 12.60s
Train Epoch: 2177 [40960/90000 (45%)]	Loss: -13.6091	Cost: 11.97s
Train Epoch: 2177 [61440/90000 (68%)]	Loss: -13.7101	Cost: 6.29s
Train Epoch: 2177 [81920/90000 (91%)]	Loss: -13.6021	Cost: 7.09s
Train Epoch: 2177 	Average Loss: -12.9716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3137

Learning rate: 8.875494497304053e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2178 [0/90000 (0%)]	Loss: -6.3385	Cost: 20.47s
Train Epoch: 2178 [20480/90000 (23%)]	Loss: -13.5395	Cost: 6.70s
Train Epoch: 2178 [40960/90000 (45%)]	Loss: -13.8458	Cost: 10.21s
Train Epoch: 2178 [61440/90000 (68%)]	Loss: -14.1253	Cost: 9.48s
Train Epoch: 2178 [81920/90000 (91%)]	Loss: -13.8039	Cost: 8.91s
Train Epoch: 2178 	Average Loss: -13.2432
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2271

Learning rate: 8.874501814232578e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2179 [0/90000 (0%)]	Loss: -5.7658	Cost: 31.34s
Train Epoch: 2179 [20480/90000 (23%)]	Loss: -13.7214	Cost: 8.72s
Train Epoch: 2179 [40960/90000 (45%)]	Loss: -14.0725	Cost: 6.39s
Train Epoch: 2179 [61440/90000 (68%)]	Loss: -14.0669	Cost: 6.59s
Train Epoch: 2179 [81920/90000 (91%)]	Loss: -13.7381	Cost: 8.41s
Train Epoch: 2179 	Average Loss: -13.3634
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4690

Learning rate: 8.873508748763104e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2180 [0/90000 (0%)]	Loss: -5.8474	Cost: 28.42s
Train Epoch: 2180 [20480/90000 (23%)]	Loss: -13.7121	Cost: 9.57s
Train Epoch: 2180 [40960/90000 (45%)]	Loss: -13.8483	Cost: 12.26s
Train Epoch: 2180 [61440/90000 (68%)]	Loss: -13.8317	Cost: 12.93s
Train Epoch: 2180 [81920/90000 (91%)]	Loss: -13.5752	Cost: 12.31s
Train Epoch: 2180 	Average Loss: -13.2455
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2379

Learning rate: 8.872515300993643e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2181 [0/90000 (0%)]	Loss: -6.0692	Cost: 23.64s
Train Epoch: 2181 [20480/90000 (23%)]	Loss: -13.5974	Cost: 13.12s
Train Epoch: 2181 [40960/90000 (45%)]	Loss: -14.0177	Cost: 13.60s
Train Epoch: 2181 [61440/90000 (68%)]	Loss: -14.0678	Cost: 12.49s
Train Epoch: 2181 [81920/90000 (91%)]	Loss: -13.7288	Cost: 12.44s
Train Epoch: 2181 	Average Loss: -13.2553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3590

Learning rate: 8.871521471022245e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2182 [0/90000 (0%)]	Loss: -5.8208	Cost: 23.12s
Train Epoch: 2182 [20480/90000 (23%)]	Loss: -13.7481	Cost: 12.93s
Train Epoch: 2182 [40960/90000 (45%)]	Loss: -13.9005	Cost: 13.55s
Train Epoch: 2182 [61440/90000 (68%)]	Loss: -13.6841	Cost: 12.50s
Train Epoch: 2182 [81920/90000 (91%)]	Loss: -13.6669	Cost: 6.80s
Train Epoch: 2182 	Average Loss: -13.1991
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4005

Learning rate: 8.870527258946998e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2183 [0/90000 (0%)]	Loss: -6.3267	Cost: 24.76s
Train Epoch: 2183 [20480/90000 (23%)]	Loss: -13.8584	Cost: 13.36s
Train Epoch: 2183 [40960/90000 (45%)]	Loss: -13.9817	Cost: 12.45s
Train Epoch: 2183 [61440/90000 (68%)]	Loss: -14.1179	Cost: 7.14s
Train Epoch: 2183 [81920/90000 (91%)]	Loss: -13.6858	Cost: 6.11s
Train Epoch: 2183 	Average Loss: -13.3634
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4825

Learning rate: 8.869532664866025e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2184 [0/90000 (0%)]	Loss: -6.0335	Cost: 26.50s
Train Epoch: 2184 [20480/90000 (23%)]	Loss: -13.7370	Cost: 8.46s
Train Epoch: 2184 [40960/90000 (45%)]	Loss: -13.9062	Cost: 7.05s
Train Epoch: 2184 [61440/90000 (68%)]	Loss: -13.9796	Cost: 7.64s
Train Epoch: 2184 [81920/90000 (91%)]	Loss: -13.4430	Cost: 8.59s
Train Epoch: 2184 	Average Loss: -13.2907
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1334

Learning rate: 8.868537688877489e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2185 [0/90000 (0%)]	Loss: -6.9788	Cost: 25.21s
Train Epoch: 2185 [20480/90000 (23%)]	Loss: -13.6918	Cost: 10.14s
Train Epoch: 2185 [40960/90000 (45%)]	Loss: -14.0053	Cost: 9.17s
Train Epoch: 2185 [61440/90000 (68%)]	Loss: -14.1887	Cost: 8.73s
Train Epoch: 2185 [81920/90000 (91%)]	Loss: -13.8629	Cost: 8.81s
Train Epoch: 2185 	Average Loss: -13.4024
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4083

Learning rate: 8.867542331079591e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2186 [0/90000 (0%)]	Loss: -6.2530	Cost: 21.25s
Train Epoch: 2186 [20480/90000 (23%)]	Loss: -13.7013	Cost: 8.99s
Train Epoch: 2186 [40960/90000 (45%)]	Loss: -13.8614	Cost: 9.21s
Train Epoch: 2186 [61440/90000 (68%)]	Loss: -14.0077	Cost: 8.78s
Train Epoch: 2186 [81920/90000 (91%)]	Loss: -13.6025	Cost: 6.57s
Train Epoch: 2186 	Average Loss: -13.3010
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3637

Learning rate: 8.866546591570567e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2187 [0/90000 (0%)]	Loss: -5.9517	Cost: 22.50s
Train Epoch: 2187 [20480/90000 (23%)]	Loss: -13.8038	Cost: 7.37s
Train Epoch: 2187 [40960/90000 (45%)]	Loss: -13.9974	Cost: 6.92s
Train Epoch: 2187 [61440/90000 (68%)]	Loss: -13.9966	Cost: 8.23s
Train Epoch: 2187 [81920/90000 (91%)]	Loss: -13.6144	Cost: 11.36s
Train Epoch: 2187 	Average Loss: -13.1655
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2210

Learning rate: 8.865550470448694e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2188 [0/90000 (0%)]	Loss: -6.8661	Cost: 20.51s
Train Epoch: 2188 [20480/90000 (23%)]	Loss: -13.7513	Cost: 6.95s
Train Epoch: 2188 [40960/90000 (45%)]	Loss: -14.0171	Cost: 13.44s
Train Epoch: 2188 [61440/90000 (68%)]	Loss: -13.9090	Cost: 13.22s
Train Epoch: 2188 [81920/90000 (91%)]	Loss: -13.5890	Cost: 12.34s
Train Epoch: 2188 	Average Loss: -13.2709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3874

Learning rate: 8.864553967812284e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2189 [0/90000 (0%)]	Loss: -6.9134	Cost: 36.24s
Train Epoch: 2189 [20480/90000 (23%)]	Loss: -13.5313	Cost: 14.80s
Train Epoch: 2189 [40960/90000 (45%)]	Loss: -13.7533	Cost: 13.03s
Train Epoch: 2189 [61440/90000 (68%)]	Loss: -13.9004	Cost: 12.19s
Train Epoch: 2189 [81920/90000 (91%)]	Loss: -13.4476	Cost: 11.80s
Train Epoch: 2189 	Average Loss: -13.1694
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2955

Learning rate: 8.863557083759689e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2190 [0/90000 (0%)]	Loss: -5.5560	Cost: 30.09s
Train Epoch: 2190 [20480/90000 (23%)]	Loss: -13.6495	Cost: 9.40s
Train Epoch: 2190 [40960/90000 (45%)]	Loss: -13.8382	Cost: 13.21s
Train Epoch: 2190 [61440/90000 (68%)]	Loss: -13.7882	Cost: 11.86s
Train Epoch: 2190 [81920/90000 (91%)]	Loss: -13.8276	Cost: 10.26s
Train Epoch: 2190 	Average Loss: -13.1679
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3948

Learning rate: 8.862559818389296e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2191 [0/90000 (0%)]	Loss: -6.0239	Cost: 23.69s
Train Epoch: 2191 [20480/90000 (23%)]	Loss: -13.6700	Cost: 14.01s
Train Epoch: 2191 [40960/90000 (45%)]	Loss: -14.1609	Cost: 12.54s
Train Epoch: 2191 [61440/90000 (68%)]	Loss: -13.8898	Cost: 9.52s
Train Epoch: 2191 [81920/90000 (91%)]	Loss: -13.8251	Cost: 7.00s
Train Epoch: 2191 	Average Loss: -13.3790
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4861

Saving model as e2191_model.pt & e2191_waveforms_supplementary.hdf5
Learning rate: 8.861562171799534e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2192 [0/90000 (0%)]	Loss: -5.9583	Cost: 24.11s
Train Epoch: 2192 [20480/90000 (23%)]	Loss: -13.8593	Cost: 11.84s
Train Epoch: 2192 [40960/90000 (45%)]	Loss: -13.8516	Cost: 6.39s
Train Epoch: 2192 [61440/90000 (68%)]	Loss: -13.8975	Cost: 6.48s
Train Epoch: 2192 [81920/90000 (91%)]	Loss: -13.5548	Cost: 8.74s
Train Epoch: 2192 	Average Loss: -13.2383
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2941

Learning rate: 8.860564144088865e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2193 [0/90000 (0%)]	Loss: -6.5873	Cost: 20.02s
Train Epoch: 2193 [20480/90000 (23%)]	Loss: -13.9252	Cost: 6.67s
Train Epoch: 2193 [40960/90000 (45%)]	Loss: -13.7844	Cost: 9.70s
Train Epoch: 2193 [61440/90000 (68%)]	Loss: -13.2060	Cost: 9.11s
Train Epoch: 2193 [81920/90000 (91%)]	Loss: -13.0848	Cost: 8.92s
Train Epoch: 2193 	Average Loss: -13.0218
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9608

Learning rate: 8.85956573535579e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2194 [0/90000 (0%)]	Loss: -5.0222	Cost: 30.51s
Train Epoch: 2194 [20480/90000 (23%)]	Loss: -13.4210	Cost: 8.89s
Train Epoch: 2194 [40960/90000 (45%)]	Loss: -13.7995	Cost: 8.88s
Train Epoch: 2194 [61440/90000 (68%)]	Loss: -13.7146	Cost: 5.71s
Train Epoch: 2194 [81920/90000 (91%)]	Loss: -13.4598	Cost: 6.45s
Train Epoch: 2194 	Average Loss: -12.9153
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2295

Learning rate: 8.858566945698848e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2195 [0/90000 (0%)]	Loss: -6.1475	Cost: 26.27s
Train Epoch: 2195 [20480/90000 (23%)]	Loss: -13.4301	Cost: 8.97s
Train Epoch: 2195 [40960/90000 (45%)]	Loss: -13.8317	Cost: 6.61s
Train Epoch: 2195 [61440/90000 (68%)]	Loss: -13.9165	Cost: 7.53s
Train Epoch: 2195 [81920/90000 (91%)]	Loss: -13.6073	Cost: 8.84s
Train Epoch: 2195 	Average Loss: -13.2330
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3736

Learning rate: 8.857567775216616e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2196 [0/90000 (0%)]	Loss: -6.0595	Cost: 22.36s
Train Epoch: 2196 [20480/90000 (23%)]	Loss: -13.6710	Cost: 7.01s
Train Epoch: 2196 [40960/90000 (45%)]	Loss: -13.9203	Cost: 14.57s
Train Epoch: 2196 [61440/90000 (68%)]	Loss: -13.9236	Cost: 13.31s
Train Epoch: 2196 [81920/90000 (91%)]	Loss: -13.5332	Cost: 12.31s
Train Epoch: 2196 	Average Loss: -13.2410
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3553

Learning rate: 8.856568224007708e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2197 [0/90000 (0%)]	Loss: -6.1973	Cost: 24.94s
Train Epoch: 2197 [20480/90000 (23%)]	Loss: -13.7262	Cost: 13.04s
Train Epoch: 2197 [40960/90000 (45%)]	Loss: -13.8676	Cost: 12.47s
Train Epoch: 2197 [61440/90000 (68%)]	Loss: -13.8158	Cost: 12.37s
Train Epoch: 2197 [81920/90000 (91%)]	Loss: -13.7828	Cost: 12.17s
Train Epoch: 2197 	Average Loss: -13.3059
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2930

Learning rate: 8.855568292170777e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2198 [0/90000 (0%)]	Loss: -6.3843	Cost: 25.43s
Train Epoch: 2198 [20480/90000 (23%)]	Loss: -13.8450	Cost: 11.78s
Train Epoch: 2198 [40960/90000 (45%)]	Loss: -14.1103	Cost: 12.67s
Train Epoch: 2198 [61440/90000 (68%)]	Loss: -13.8042	Cost: 12.31s
Train Epoch: 2198 [81920/90000 (91%)]	Loss: -13.6973	Cost: 7.18s
Train Epoch: 2198 	Average Loss: -13.3841
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3360

Learning rate: 8.854567979804511e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2199 [0/90000 (0%)]	Loss: -7.6291	Cost: 30.17s
Train Epoch: 2199 [20480/90000 (23%)]	Loss: -13.7891	Cost: 13.52s
Train Epoch: 2199 [40960/90000 (45%)]	Loss: -14.1477	Cost: 10.89s
Train Epoch: 2199 [61440/90000 (68%)]	Loss: -13.8417	Cost: 6.14s
Train Epoch: 2199 [81920/90000 (91%)]	Loss: -13.6256	Cost: 7.26s
Train Epoch: 2199 	Average Loss: -13.3887
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1170

Learning rate: 8.853567287007638e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2200 [0/90000 (0%)]	Loss: -5.7504	Cost: 32.24s
Train Epoch: 2200 [20480/90000 (23%)]	Loss: -13.5646	Cost: 10.40s
Train Epoch: 2200 [40960/90000 (45%)]	Loss: -13.7194	Cost: 9.26s
Train Epoch: 2200 [61440/90000 (68%)]	Loss: -13.7964	Cost: 8.52s
Train Epoch: 2200 [81920/90000 (91%)]	Loss: -13.6072	Cost: 8.63s
Train Epoch: 2200 	Average Loss: -13.1774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3604

Learning rate: 8.85256621387892e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2201 [0/90000 (0%)]	Loss: -5.1590	Cost: 22.81s
Train Epoch: 2201 [20480/90000 (23%)]	Loss: -13.8213	Cost: 8.47s
Train Epoch: 2201 [40960/90000 (45%)]	Loss: -13.9311	Cost: 9.31s
Train Epoch: 2201 [61440/90000 (68%)]	Loss: -14.1119	Cost: 9.03s
Train Epoch: 2201 [81920/90000 (91%)]	Loss: -13.9423	Cost: 8.70s
Train Epoch: 2201 	Average Loss: -13.3459
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4891

Saving model as e2201_model.pt & e2201_waveforms_supplementary.hdf5
Learning rate: 8.851564760517161e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2202 [0/90000 (0%)]	Loss: -6.6460	Cost: 19.96s
Train Epoch: 2202 [20480/90000 (23%)]	Loss: -13.9714	Cost: 6.57s
Train Epoch: 2202 [40960/90000 (45%)]	Loss: -14.1801	Cost: 7.83s
Train Epoch: 2202 [61440/90000 (68%)]	Loss: -13.9202	Cost: 9.26s
Train Epoch: 2202 [81920/90000 (91%)]	Loss: -13.7693	Cost: 17.08s
Train Epoch: 2202 	Average Loss: -13.3776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3393

Learning rate: 8.8505629270212e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2203 [0/90000 (0%)]	Loss: -5.2734	Cost: 21.78s
Train Epoch: 2203 [20480/90000 (23%)]	Loss: -13.7442	Cost: 9.71s
Train Epoch: 2203 [40960/90000 (45%)]	Loss: -13.8747	Cost: 13.21s
Train Epoch: 2203 [61440/90000 (68%)]	Loss: -14.1173	Cost: 12.51s
Train Epoch: 2203 [81920/90000 (91%)]	Loss: -13.6629	Cost: 12.13s
Train Epoch: 2203 	Average Loss: -13.2701
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4249

Learning rate: 8.849560713489914e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2204 [0/90000 (0%)]	Loss: -6.5433	Cost: 31.56s
Train Epoch: 2204 [20480/90000 (23%)]	Loss: -13.8271	Cost: 14.61s
Train Epoch: 2204 [40960/90000 (45%)]	Loss: -13.9356	Cost: 11.62s
Train Epoch: 2204 [61440/90000 (68%)]	Loss: -14.0510	Cost: 12.14s
Train Epoch: 2204 [81920/90000 (91%)]	Loss: -13.6143	Cost: 10.84s
Train Epoch: 2204 	Average Loss: -13.3284
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4131

Learning rate: 8.848558120022219e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2205 [0/90000 (0%)]	Loss: -5.9958	Cost: 43.09s
Train Epoch: 2205 [20480/90000 (23%)]	Loss: -13.7506	Cost: 12.50s
Train Epoch: 2205 [40960/90000 (45%)]	Loss: -14.1225	Cost: 12.33s
Train Epoch: 2205 [61440/90000 (68%)]	Loss: -14.0488	Cost: 8.88s
Train Epoch: 2205 [81920/90000 (91%)]	Loss: -13.8292	Cost: 6.05s
Train Epoch: 2205 	Average Loss: -13.3394
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4654

Learning rate: 8.847555146717063e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2206 [0/90000 (0%)]	Loss: -7.1129	Cost: 23.39s
Train Epoch: 2206 [20480/90000 (23%)]	Loss: -13.7340	Cost: 7.91s
Train Epoch: 2206 [40960/90000 (45%)]	Loss: -13.8537	Cost: 8.73s
Train Epoch: 2206 [61440/90000 (68%)]	Loss: -13.9365	Cost: 8.98s
Train Epoch: 2206 [81920/90000 (91%)]	Loss: -13.6257	Cost: 9.20s
Train Epoch: 2206 	Average Loss: -13.2750
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3346

Learning rate: 8.84655179367344e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2207 [0/90000 (0%)]	Loss: -6.6342	Cost: 19.39s
Train Epoch: 2207 [20480/90000 (23%)]	Loss: -13.7762	Cost: 12.40s
Train Epoch: 2207 [40960/90000 (45%)]	Loss: -13.9157	Cost: 11.83s
Train Epoch: 2207 [61440/90000 (68%)]	Loss: -13.9127	Cost: 8.43s
Train Epoch: 2207 [81920/90000 (91%)]	Loss: -13.6478	Cost: 6.38s
Train Epoch: 2207 	Average Loss: -13.3171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3620

Learning rate: 8.845548060990374e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2208 [0/90000 (0%)]	Loss: -6.0289	Cost: 22.70s
Train Epoch: 2208 [20480/90000 (23%)]	Loss: -13.8083	Cost: 7.61s
Train Epoch: 2208 [40960/90000 (45%)]	Loss: -13.8303	Cost: 10.12s
Train Epoch: 2208 [61440/90000 (68%)]	Loss: -13.5950	Cost: 11.76s
Train Epoch: 2208 [81920/90000 (91%)]	Loss: -13.4647	Cost: 12.74s
Train Epoch: 2208 	Average Loss: -13.2227
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2943

Learning rate: 8.844543948766932e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2209 [0/90000 (0%)]	Loss: -6.9189	Cost: 21.72s
Train Epoch: 2209 [20480/90000 (23%)]	Loss: -13.7381	Cost: 9.36s
Train Epoch: 2209 [40960/90000 (45%)]	Loss: -13.8835	Cost: 13.04s
Train Epoch: 2209 [61440/90000 (68%)]	Loss: -13.8858	Cost: 12.56s
Train Epoch: 2209 [81920/90000 (91%)]	Loss: -13.7444	Cost: 12.10s
Train Epoch: 2209 	Average Loss: -13.2339
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2371

Learning rate: 8.843539457102213e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2210 [0/90000 (0%)]	Loss: -5.9746	Cost: 25.65s
Train Epoch: 2210 [20480/90000 (23%)]	Loss: -13.7973	Cost: 13.02s
Train Epoch: 2210 [40960/90000 (45%)]	Loss: -14.1654	Cost: 12.96s
Train Epoch: 2210 [61440/90000 (68%)]	Loss: -14.0328	Cost: 12.56s
Train Epoch: 2210 [81920/90000 (91%)]	Loss: -13.6612	Cost: 10.82s
Train Epoch: 2210 	Average Loss: -13.3224
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2689

Learning rate: 8.842534586095357e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2211 [0/90000 (0%)]	Loss: -5.9652	Cost: 36.07s
Train Epoch: 2211 [20480/90000 (23%)]	Loss: -13.7118	Cost: 14.43s
Train Epoch: 2211 [40960/90000 (45%)]	Loss: -14.0195	Cost: 12.70s
Train Epoch: 2211 [61440/90000 (68%)]	Loss: -13.7390	Cost: 10.62s
Train Epoch: 2211 [81920/90000 (91%)]	Loss: -13.1753	Cost: 6.08s
Train Epoch: 2211 	Average Loss: -13.1590
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0547

Learning rate: 8.841529335845542e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2212 [0/90000 (0%)]	Loss: -6.1506	Cost: 38.75s
Train Epoch: 2212 [20480/90000 (23%)]	Loss: -13.6628	Cost: 11.42s
Train Epoch: 2212 [40960/90000 (45%)]	Loss: -13.6180	Cost: 6.52s
Train Epoch: 2212 [61440/90000 (68%)]	Loss: -13.9324	Cost: 6.39s
Train Epoch: 2212 [81920/90000 (91%)]	Loss: -13.3125	Cost: 8.62s
Train Epoch: 2212 	Average Loss: -13.0832
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2947

Learning rate: 8.840523706451982e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2213 [0/90000 (0%)]	Loss: -6.4143	Cost: 27.08s
Train Epoch: 2213 [20480/90000 (23%)]	Loss: -13.7322	Cost: 6.62s
Train Epoch: 2213 [40960/90000 (45%)]	Loss: -13.7203	Cost: 9.33s
Train Epoch: 2213 [61440/90000 (68%)]	Loss: -13.9014	Cost: 8.74s
Train Epoch: 2213 [81920/90000 (91%)]	Loss: -13.4207	Cost: 8.92s
Train Epoch: 2213 	Average Loss: -13.1874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2063

Learning rate: 8.839517698013928e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2214 [0/90000 (0%)]	Loss: -6.4378	Cost: 21.23s
Train Epoch: 2214 [20480/90000 (23%)]	Loss: -13.3041	Cost: 9.23s
Train Epoch: 2214 [40960/90000 (45%)]	Loss: -13.5072	Cost: 9.11s
Train Epoch: 2214 [61440/90000 (68%)]	Loss: -13.8151	Cost: 8.55s
Train Epoch: 2214 [81920/90000 (91%)]	Loss: -13.6741	Cost: 6.61s
Train Epoch: 2214 	Average Loss: -13.1664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3781

Learning rate: 8.83851131063067e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2215 [0/90000 (0%)]	Loss: -6.3550	Cost: 21.73s
Train Epoch: 2215 [20480/90000 (23%)]	Loss: -13.6109	Cost: 8.15s
Train Epoch: 2215 [40960/90000 (45%)]	Loss: -13.4984	Cost: 6.47s
Train Epoch: 2215 [61440/90000 (68%)]	Loss: -13.6080	Cost: 6.79s
Train Epoch: 2215 [81920/90000 (91%)]	Loss: -13.1344	Cost: 11.68s
Train Epoch: 2215 	Average Loss: -13.0505
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2052

Learning rate: 8.837504544401532e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2216 [0/90000 (0%)]	Loss: -6.4193	Cost: 25.17s
Train Epoch: 2216 [20480/90000 (23%)]	Loss: -13.5049	Cost: 10.39s
Train Epoch: 2216 [40960/90000 (45%)]	Loss: -13.7445	Cost: 17.87s
Train Epoch: 2216 [61440/90000 (68%)]	Loss: -13.4074	Cost: 14.24s
Train Epoch: 2216 [81920/90000 (91%)]	Loss: -13.3772	Cost: 12.26s
Train Epoch: 2216 	Average Loss: -12.9870
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1110

Learning rate: 8.836497399425883e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2217 [0/90000 (0%)]	Loss: -6.3032	Cost: 33.15s
Train Epoch: 2217 [20480/90000 (23%)]	Loss: -13.3620	Cost: 14.85s
Train Epoch: 2217 [40960/90000 (45%)]	Loss: -13.5645	Cost: 13.60s
Train Epoch: 2217 [61440/90000 (68%)]	Loss: -13.7741	Cost: 12.06s
Train Epoch: 2217 [81920/90000 (91%)]	Loss: -13.4311	Cost: 10.82s
Train Epoch: 2217 	Average Loss: -12.9679
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1036

Learning rate: 8.835489875803119e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2218 [0/90000 (0%)]	Loss: -6.4893	Cost: 32.56s
Train Epoch: 2218 [20480/90000 (23%)]	Loss: -13.6606	Cost: 11.08s
Train Epoch: 2218 [40960/90000 (45%)]	Loss: -13.5306	Cost: 12.40s
Train Epoch: 2218 [61440/90000 (68%)]	Loss: -14.0871	Cost: 12.09s
Train Epoch: 2218 [81920/90000 (91%)]	Loss: -13.7732	Cost: 6.42s
Train Epoch: 2218 	Average Loss: -13.2200
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3882

Learning rate: 8.834481973632681e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2219 [0/90000 (0%)]	Loss: -6.5398	Cost: 24.55s
Train Epoch: 2219 [20480/90000 (23%)]	Loss: -13.5219	Cost: 11.61s
Train Epoch: 2219 [40960/90000 (45%)]	Loss: -13.8875	Cost: 8.71s
Train Epoch: 2219 [61440/90000 (68%)]	Loss: -13.9289	Cost: 6.12s
Train Epoch: 2219 [81920/90000 (91%)]	Loss: -13.8598	Cost: 7.50s
Train Epoch: 2219 	Average Loss: -13.2760
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4542

Learning rate: 8.833473693014044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2220 [0/90000 (0%)]	Loss: -6.2896	Cost: 22.12s
Train Epoch: 2220 [20480/90000 (23%)]	Loss: -13.7813	Cost: 6.79s
Train Epoch: 2220 [40960/90000 (45%)]	Loss: -13.9486	Cost: 9.44s
Train Epoch: 2220 [61440/90000 (68%)]	Loss: -13.9376	Cost: 8.78s
Train Epoch: 2220 [81920/90000 (91%)]	Loss: -13.8676	Cost: 8.76s
Train Epoch: 2220 	Average Loss: -13.3613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2862

Learning rate: 8.832465034046723e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2221 [0/90000 (0%)]	Loss: -6.1190	Cost: 25.10s
Train Epoch: 2221 [20480/90000 (23%)]	Loss: -13.7152	Cost: 9.68s
Train Epoch: 2221 [40960/90000 (45%)]	Loss: -13.0784	Cost: 8.88s
Train Epoch: 2221 [61440/90000 (68%)]	Loss: -13.4659	Cost: 7.37s
Train Epoch: 2221 [81920/90000 (91%)]	Loss: -13.2784	Cost: 6.36s
Train Epoch: 2221 	Average Loss: -12.9147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1190

Learning rate: 8.831455996830268e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2222 [0/90000 (0%)]	Loss: -5.6087	Cost: 26.31s
Train Epoch: 2222 [20480/90000 (23%)]	Loss: -13.4327	Cost: 9.98s
Train Epoch: 2222 [40960/90000 (45%)]	Loss: -13.5581	Cost: 7.11s
Train Epoch: 2222 [61440/90000 (68%)]	Loss: -13.6160	Cost: 7.41s
Train Epoch: 2222 [81920/90000 (91%)]	Loss: -13.4698	Cost: 7.95s
Train Epoch: 2222 	Average Loss: -12.9482
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2627

Learning rate: 8.830446581464264e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2223 [0/90000 (0%)]	Loss: -7.2296	Cost: 22.30s
Train Epoch: 2223 [20480/90000 (23%)]	Loss: -13.2162	Cost: 9.70s
Train Epoch: 2223 [40960/90000 (45%)]	Loss: -13.4263	Cost: 11.02s
Train Epoch: 2223 [61440/90000 (68%)]	Loss: -13.6169	Cost: 13.55s
Train Epoch: 2223 [81920/90000 (91%)]	Loss: -13.5788	Cost: 12.48s
Train Epoch: 2223 	Average Loss: -13.0262
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4052

Learning rate: 8.82943678804834e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2224 [0/90000 (0%)]	Loss: -7.2620	Cost: 24.33s
Train Epoch: 2224 [20480/90000 (23%)]	Loss: -13.7047	Cost: 7.70s
Train Epoch: 2224 [40960/90000 (45%)]	Loss: -13.8880	Cost: 11.99s
Train Epoch: 2224 [61440/90000 (68%)]	Loss: -13.7675	Cost: 12.53s
Train Epoch: 2224 [81920/90000 (91%)]	Loss: -13.5983	Cost: 12.44s
Train Epoch: 2224 	Average Loss: -13.2760
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3467

Learning rate: 8.828426616682159e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2225 [0/90000 (0%)]	Loss: -6.5781	Cost: 24.12s
Train Epoch: 2225 [20480/90000 (23%)]	Loss: -13.6462	Cost: 13.97s
Train Epoch: 2225 [40960/90000 (45%)]	Loss: -13.8137	Cost: 12.31s
Train Epoch: 2225 [61440/90000 (68%)]	Loss: -14.0371	Cost: 12.30s
Train Epoch: 2225 [81920/90000 (91%)]	Loss: -13.8715	Cost: 12.34s
Train Epoch: 2225 	Average Loss: -13.3487
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5058

Saving model as e2225_model.pt & e2225_waveforms_supplementary.hdf5
Learning rate: 8.827416067465417e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2226 [0/90000 (0%)]	Loss: -7.2985	Cost: 24.06s
Train Epoch: 2226 [20480/90000 (23%)]	Loss: -13.7281	Cost: 13.38s
Train Epoch: 2226 [40960/90000 (45%)]	Loss: -13.9343	Cost: 11.98s
Train Epoch: 2226 [61440/90000 (68%)]	Loss: -13.9133	Cost: 6.57s
Train Epoch: 2226 [81920/90000 (91%)]	Loss: -13.8313	Cost: 6.14s
Train Epoch: 2226 	Average Loss: -13.4337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4902

Learning rate: 8.826405140497852e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2227 [0/90000 (0%)]	Loss: -6.6141	Cost: 33.58s
Train Epoch: 2227 [20480/90000 (23%)]	Loss: -13.6751	Cost: 11.43s
Train Epoch: 2227 [40960/90000 (45%)]	Loss: -14.2440	Cost: 6.51s
Train Epoch: 2227 [61440/90000 (68%)]	Loss: -14.1905	Cost: 6.36s
Train Epoch: 2227 [81920/90000 (91%)]	Loss: -13.6897	Cost: 8.57s
Train Epoch: 2227 	Average Loss: -13.5146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4424

Learning rate: 8.825393835879243e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2228 [0/90000 (0%)]	Loss: -6.6266	Cost: 21.22s
Train Epoch: 2228 [20480/90000 (23%)]	Loss: -13.8438	Cost: 10.24s
Train Epoch: 2228 [40960/90000 (45%)]	Loss: -13.9512	Cost: 10.19s
Train Epoch: 2228 [61440/90000 (68%)]	Loss: -14.0931	Cost: 8.86s
Train Epoch: 2228 [81920/90000 (91%)]	Loss: -13.9175	Cost: 8.80s
Train Epoch: 2228 	Average Loss: -13.4150
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3805

Learning rate: 8.824382153709396e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2229 [0/90000 (0%)]	Loss: -6.5119	Cost: 23.08s
Train Epoch: 2229 [20480/90000 (23%)]	Loss: -13.9171	Cost: 8.94s
Train Epoch: 2229 [40960/90000 (45%)]	Loss: -14.0639	Cost: 8.99s
Train Epoch: 2229 [61440/90000 (68%)]	Loss: -14.0033	Cost: 9.02s
Train Epoch: 2229 [81920/90000 (91%)]	Loss: -13.9191	Cost: 7.01s
Train Epoch: 2229 	Average Loss: -13.4317
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4491

Learning rate: 8.823370094088164e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2230 [0/90000 (0%)]	Loss: -6.3917	Cost: 20.31s
Train Epoch: 2230 [20480/90000 (23%)]	Loss: -13.8142	Cost: 6.53s
Train Epoch: 2230 [40960/90000 (45%)]	Loss: -13.9746	Cost: 9.14s
Train Epoch: 2230 [61440/90000 (68%)]	Loss: -13.9492	Cost: 9.72s
Train Epoch: 2230 [81920/90000 (91%)]	Loss: -13.7584	Cost: 14.16s
Train Epoch: 2230 	Average Loss: -13.3811
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3533

Learning rate: 8.822357657115432e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2231 [0/90000 (0%)]	Loss: -6.5188	Cost: 22.89s
Train Epoch: 2231 [20480/90000 (23%)]	Loss: -13.9034	Cost: 10.01s
Train Epoch: 2231 [40960/90000 (45%)]	Loss: -14.0669	Cost: 13.11s
Train Epoch: 2231 [61440/90000 (68%)]	Loss: -14.2982	Cost: 12.48s
Train Epoch: 2231 [81920/90000 (91%)]	Loss: -14.0600	Cost: 12.30s
Train Epoch: 2231 	Average Loss: -13.4596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4638

Learning rate: 8.821344842891124e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2232 [0/90000 (0%)]	Loss: -6.8558	Cost: 41.73s
Train Epoch: 2232 [20480/90000 (23%)]	Loss: -13.8765	Cost: 11.63s
Train Epoch: 2232 [40960/90000 (45%)]	Loss: -14.1689	Cost: 12.37s
Train Epoch: 2232 [61440/90000 (68%)]	Loss: -14.0746	Cost: 12.03s
Train Epoch: 2232 [81920/90000 (91%)]	Loss: -13.8946	Cost: 6.26s
Train Epoch: 2232 	Average Loss: -13.5154
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4445

Learning rate: 8.820331651515199e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2233 [0/90000 (0%)]	Loss: -6.0986	Cost: 38.54s
Train Epoch: 2233 [20480/90000 (23%)]	Loss: -14.0512	Cost: 12.03s
Train Epoch: 2233 [40960/90000 (45%)]	Loss: -14.2404	Cost: 9.10s
Train Epoch: 2233 [61440/90000 (68%)]	Loss: -13.9915	Cost: 6.22s
Train Epoch: 2233 [81920/90000 (91%)]	Loss: -13.7074	Cost: 7.38s
Train Epoch: 2233 	Average Loss: -13.4580
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2922

Learning rate: 8.819318083087657e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2234 [0/90000 (0%)]	Loss: -6.9916	Cost: 25.82s
Train Epoch: 2234 [20480/90000 (23%)]	Loss: -13.9676	Cost: 8.87s
Train Epoch: 2234 [40960/90000 (45%)]	Loss: -14.0685	Cost: 6.48s
Train Epoch: 2234 [61440/90000 (68%)]	Loss: -14.1668	Cost: 6.92s
Train Epoch: 2234 [81920/90000 (91%)]	Loss: -13.8929	Cost: 8.66s
Train Epoch: 2234 	Average Loss: -13.5674
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5138

Saving model as e2234_model.pt & e2234_waveforms_supplementary.hdf5
Learning rate: 8.818304137708534e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2235 [0/90000 (0%)]	Loss: -6.4297	Cost: 19.84s
Train Epoch: 2235 [20480/90000 (23%)]	Loss: -14.1113	Cost: 6.52s
Train Epoch: 2235 [40960/90000 (45%)]	Loss: -14.1052	Cost: 9.36s
Train Epoch: 2235 [61440/90000 (68%)]	Loss: -14.1905	Cost: 8.67s
Train Epoch: 2235 [81920/90000 (91%)]	Loss: -13.8876	Cost: 8.47s
Train Epoch: 2235 	Average Loss: -13.5430
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5832

Saving model as e2235_model.pt & e2235_waveforms_supplementary.hdf5
Learning rate: 8.8172898154779e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2236 [0/90000 (0%)]	Loss: -4.8771	Cost: 21.63s
Train Epoch: 2236 [20480/90000 (23%)]	Loss: -13.9822	Cost: 8.96s
Train Epoch: 2236 [40960/90000 (45%)]	Loss: -14.2162	Cost: 9.25s
Train Epoch: 2236 [61440/90000 (68%)]	Loss: -14.1740	Cost: 9.05s
Train Epoch: 2236 [81920/90000 (91%)]	Loss: -13.8244	Cost: 8.24s
Train Epoch: 2236 	Average Loss: -13.4650
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3497

Learning rate: 8.816275116495864e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2237 [0/90000 (0%)]	Loss: -6.9046	Cost: 24.07s
Train Epoch: 2237 [20480/90000 (23%)]	Loss: -14.1349	Cost: 10.05s
Train Epoch: 2237 [40960/90000 (45%)]	Loss: -14.2280	Cost: 9.04s
Train Epoch: 2237 [61440/90000 (68%)]	Loss: -14.0667	Cost: 5.88s
Train Epoch: 2237 [81920/90000 (91%)]	Loss: -13.7925	Cost: 6.48s
Train Epoch: 2237 	Average Loss: -13.5550
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4425

Learning rate: 8.815260040862576e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2238 [0/90000 (0%)]	Loss: -6.8455	Cost: 22.23s
Train Epoch: 2238 [20480/90000 (23%)]	Loss: -13.8939	Cost: 9.29s
Train Epoch: 2238 [40960/90000 (45%)]	Loss: -13.9993	Cost: 11.92s
Train Epoch: 2238 [61440/90000 (68%)]	Loss: -13.9813	Cost: 10.23s
Train Epoch: 2238 [81920/90000 (91%)]	Loss: -13.6226	Cost: 12.43s
Train Epoch: 2238 	Average Loss: -13.3337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3145

Learning rate: 8.814244588678218e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2239 [0/90000 (0%)]	Loss: -7.4185	Cost: 25.98s
Train Epoch: 2239 [20480/90000 (23%)]	Loss: -13.8335	Cost: 9.37s
Train Epoch: 2239 [40960/90000 (45%)]	Loss: -14.2618	Cost: 13.77s
Train Epoch: 2239 [61440/90000 (68%)]	Loss: -14.1739	Cost: 12.77s
Train Epoch: 2239 [81920/90000 (91%)]	Loss: -13.9976	Cost: 12.02s
Train Epoch: 2239 	Average Loss: -13.4780
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5901

Saving model as e2239_model.pt & e2239_waveforms_supplementary.hdf5
Learning rate: 8.813228760043011e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2240 [0/90000 (0%)]	Loss: -6.0062	Cost: 23.56s
Train Epoch: 2240 [20480/90000 (23%)]	Loss: -13.9834	Cost: 11.03s
Train Epoch: 2240 [40960/90000 (45%)]	Loss: -14.1761	Cost: 12.50s
Train Epoch: 2240 [61440/90000 (68%)]	Loss: -14.2641	Cost: 12.18s
Train Epoch: 2240 [81920/90000 (91%)]	Loss: -13.9727	Cost: 9.15s
Train Epoch: 2240 	Average Loss: -13.6045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6337

Saving model as e2240_model.pt & e2240_waveforms_supplementary.hdf5
Learning rate: 8.812212555057214e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2241 [0/90000 (0%)]	Loss: -7.0347	Cost: 23.92s
Train Epoch: 2241 [20480/90000 (23%)]	Loss: -13.9787	Cost: 10.71s
Train Epoch: 2241 [40960/90000 (45%)]	Loss: -14.2090	Cost: 7.27s
Train Epoch: 2241 [61440/90000 (68%)]	Loss: -14.2103	Cost: 6.41s
Train Epoch: 2241 [81920/90000 (91%)]	Loss: -13.9066	Cost: 8.85s
Train Epoch: 2241 	Average Loss: -13.5568
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4448

Learning rate: 8.811195973821122e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2242 [0/90000 (0%)]	Loss: -5.9076	Cost: 30.83s
Train Epoch: 2242 [20480/90000 (23%)]	Loss: -14.0832	Cost: 7.95s
Train Epoch: 2242 [40960/90000 (45%)]	Loss: -14.4061	Cost: 10.31s
Train Epoch: 2242 [61440/90000 (68%)]	Loss: -14.1528	Cost: 8.83s
Train Epoch: 2242 [81920/90000 (91%)]	Loss: -14.0040	Cost: 8.62s
Train Epoch: 2242 	Average Loss: -13.6075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6443

Saving model as e2242_model.pt & e2242_waveforms_supplementary.hdf5
Learning rate: 8.810179016435067e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2243 [0/90000 (0%)]	Loss: -6.7404	Cost: 29.78s
Train Epoch: 2243 [20480/90000 (23%)]	Loss: -14.0962	Cost: 9.18s
Train Epoch: 2243 [40960/90000 (45%)]	Loss: -14.1733	Cost: 9.02s
Train Epoch: 2243 [61440/90000 (68%)]	Loss: -14.0195	Cost: 7.71s
Train Epoch: 2243 [81920/90000 (91%)]	Loss: -13.6986	Cost: 6.20s
Train Epoch: 2243 	Average Loss: -13.4705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4474

Learning rate: 8.809161682999421e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2244 [0/90000 (0%)]	Loss: -6.3134	Cost: 22.16s
Train Epoch: 2244 [20480/90000 (23%)]	Loss: -13.9019	Cost: 7.26s
Train Epoch: 2244 [40960/90000 (45%)]	Loss: -14.0449	Cost: 9.73s
Train Epoch: 2244 [61440/90000 (68%)]	Loss: -13.9849	Cost: 12.87s
Train Epoch: 2244 [81920/90000 (91%)]	Loss: -13.6117	Cost: 12.50s
Train Epoch: 2244 	Average Loss: -13.4525
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2349

Learning rate: 8.808143973614587e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2245 [0/90000 (0%)]	Loss: -6.9235	Cost: 22.57s
Train Epoch: 2245 [20480/90000 (23%)]	Loss: -13.9710	Cost: 13.16s
Train Epoch: 2245 [40960/90000 (45%)]	Loss: -14.0709	Cost: 12.49s
Train Epoch: 2245 [61440/90000 (68%)]	Loss: -14.0907	Cost: 12.16s
Train Epoch: 2245 [81920/90000 (91%)]	Loss: -13.8404	Cost: 12.54s
Train Epoch: 2245 	Average Loss: -13.4599
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5102

Learning rate: 8.80712588838101e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2246 [0/90000 (0%)]	Loss: -6.0367	Cost: 24.96s
Train Epoch: 2246 [20480/90000 (23%)]	Loss: -13.9032	Cost: 14.43s
Train Epoch: 2246 [40960/90000 (45%)]	Loss: -14.1056	Cost: 13.27s
Train Epoch: 2246 [61440/90000 (68%)]	Loss: -14.1845	Cost: 12.04s
Train Epoch: 2246 [81920/90000 (91%)]	Loss: -14.0165	Cost: 8.79s
Train Epoch: 2246 	Average Loss: -13.5714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5601

Learning rate: 8.806107427399172e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2247 [0/90000 (0%)]	Loss: -6.9567	Cost: 38.22s
Train Epoch: 2247 [20480/90000 (23%)]	Loss: -14.0455	Cost: 11.30s
Train Epoch: 2247 [40960/90000 (45%)]	Loss: -14.2093	Cost: 9.10s
Train Epoch: 2247 [61440/90000 (68%)]	Loss: -14.5507	Cost: 6.22s
Train Epoch: 2247 [81920/90000 (91%)]	Loss: -14.1223	Cost: 7.81s
Train Epoch: 2247 	Average Loss: -13.6979
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7129

Saving model as e2247_model.pt & e2247_waveforms_supplementary.hdf5
Learning rate: 8.805088590769593e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2248 [0/90000 (0%)]	Loss: -6.7497	Cost: 28.97s
Train Epoch: 2248 [20480/90000 (23%)]	Loss: -14.1948	Cost: 8.74s
Train Epoch: 2248 [40960/90000 (45%)]	Loss: -14.4701	Cost: 7.23s
Train Epoch: 2248 [61440/90000 (68%)]	Loss: -14.3602	Cost: 9.20s
Train Epoch: 2248 [81920/90000 (91%)]	Loss: -14.2098	Cost: 8.79s
Train Epoch: 2248 	Average Loss: -13.8282
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7104

Learning rate: 8.804069378592826e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2249 [0/90000 (0%)]	Loss: -6.9825	Cost: 22.53s
Train Epoch: 2249 [20480/90000 (23%)]	Loss: -14.2488	Cost: 8.89s
Train Epoch: 2249 [40960/90000 (45%)]	Loss: -14.3072	Cost: 9.72s
Train Epoch: 2249 [61440/90000 (68%)]	Loss: -14.3649	Cost: 8.84s
Train Epoch: 2249 [81920/90000 (91%)]	Loss: -14.1271	Cost: 8.66s
Train Epoch: 2249 	Average Loss: -13.6779
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8487

Saving model as e2249_model.pt & e2249_waveforms_supplementary.hdf5
Learning rate: 8.803049790969462e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2250 [0/90000 (0%)]	Loss: -6.8149	Cost: 18.22s
Train Epoch: 2250 [20480/90000 (23%)]	Loss: -14.3259	Cost: 6.95s
Train Epoch: 2250 [40960/90000 (45%)]	Loss: -14.1260	Cost: 8.36s
Train Epoch: 2250 [61440/90000 (68%)]	Loss: -14.3328	Cost: 11.16s
Train Epoch: 2250 [81920/90000 (91%)]	Loss: -13.7907	Cost: 17.33s
Train Epoch: 2250 	Average Loss: -13.5790
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4357

Learning rate: 8.802029828000131e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2251 [0/90000 (0%)]	Loss: -6.1871	Cost: 24.57s
Train Epoch: 2251 [20480/90000 (23%)]	Loss: -14.1159	Cost: 12.96s
Train Epoch: 2251 [40960/90000 (45%)]	Loss: -14.2789	Cost: 15.19s
Train Epoch: 2251 [61440/90000 (68%)]	Loss: -14.1886	Cost: 12.02s
Train Epoch: 2251 [81920/90000 (91%)]	Loss: -13.8977	Cost: 12.19s
Train Epoch: 2251 	Average Loss: -13.5122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5147

Learning rate: 8.801009489785502e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2252 [0/90000 (0%)]	Loss: -6.7602	Cost: 27.50s
Train Epoch: 2252 [20480/90000 (23%)]	Loss: -14.1985	Cost: 14.51s
Train Epoch: 2252 [40960/90000 (45%)]	Loss: -14.3606	Cost: 12.55s
Train Epoch: 2252 [61440/90000 (68%)]	Loss: -14.4753	Cost: 10.65s
Train Epoch: 2252 [81920/90000 (91%)]	Loss: -13.9750	Cost: 6.78s
Train Epoch: 2252 	Average Loss: -13.6592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6708

Learning rate: 8.799988776426275e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2253 [0/90000 (0%)]	Loss: -5.9244	Cost: 40.45s
Train Epoch: 2253 [20480/90000 (23%)]	Loss: -14.0455	Cost: 10.58s
Train Epoch: 2253 [40960/90000 (45%)]	Loss: -14.1454	Cost: 9.53s
Train Epoch: 2253 [61440/90000 (68%)]	Loss: -14.2072	Cost: 6.26s
Train Epoch: 2253 [81920/90000 (91%)]	Loss: -13.9726	Cost: 6.89s
Train Epoch: 2253 	Average Loss: -13.5274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5442

Learning rate: 8.79896768802319e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2254 [0/90000 (0%)]	Loss: -6.3109	Cost: 36.34s
Train Epoch: 2254 [20480/90000 (23%)]	Loss: -13.9916	Cost: 11.28s
Train Epoch: 2254 [40960/90000 (45%)]	Loss: -14.0914	Cost: 6.45s
Train Epoch: 2254 [61440/90000 (68%)]	Loss: -14.4867	Cost: 6.26s
Train Epoch: 2254 [81920/90000 (91%)]	Loss: -14.0031	Cost: 8.67s
Train Epoch: 2254 	Average Loss: -13.6590
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6619

Learning rate: 8.797946224677029e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2255 [0/90000 (0%)]	Loss: -7.5264	Cost: 22.63s
Train Epoch: 2255 [20480/90000 (23%)]	Loss: -14.0471	Cost: 8.54s
Train Epoch: 2255 [40960/90000 (45%)]	Loss: -14.3244	Cost: 10.93s
Train Epoch: 2255 [61440/90000 (68%)]	Loss: -14.3862	Cost: 9.28s
Train Epoch: 2255 [81920/90000 (91%)]	Loss: -13.9574	Cost: 9.22s
Train Epoch: 2255 	Average Loss: -13.7616
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6531

Learning rate: 8.7969243864886e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2256 [0/90000 (0%)]	Loss: -5.5537	Cost: 22.77s
Train Epoch: 2256 [20480/90000 (23%)]	Loss: -14.1706	Cost: 10.75s
Train Epoch: 2256 [40960/90000 (45%)]	Loss: -14.4029	Cost: 9.82s
Train Epoch: 2256 [61440/90000 (68%)]	Loss: -14.3402	Cost: 8.77s
Train Epoch: 2256 [81920/90000 (91%)]	Loss: -13.8796	Cost: 11.01s
Train Epoch: 2256 	Average Loss: -13.6947
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4948

Learning rate: 8.79590217355876e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2257 [0/90000 (0%)]	Loss: -7.0076	Cost: 22.72s
Train Epoch: 2257 [20480/90000 (23%)]	Loss: -14.0027	Cost: 10.69s
Train Epoch: 2257 [40960/90000 (45%)]	Loss: -14.2134	Cost: 11.55s
Train Epoch: 2257 [61440/90000 (68%)]	Loss: -14.2954	Cost: 12.53s
Train Epoch: 2257 [81920/90000 (91%)]	Loss: -13.9212	Cost: 12.44s
Train Epoch: 2257 	Average Loss: -13.7159
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8208

Learning rate: 8.794879585988396e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2258 [0/90000 (0%)]	Loss: -6.5003	Cost: 24.30s
Train Epoch: 2258 [20480/90000 (23%)]	Loss: -14.0620	Cost: 13.97s
Train Epoch: 2258 [40960/90000 (45%)]	Loss: -14.4707	Cost: 12.56s
Train Epoch: 2258 [61440/90000 (68%)]	Loss: -14.3090	Cost: 12.07s
Train Epoch: 2258 [81920/90000 (91%)]	Loss: -13.7889	Cost: 11.42s
Train Epoch: 2258 	Average Loss: -13.6032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5716

Learning rate: 8.79385662387843e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2259 [0/90000 (0%)]	Loss: -6.6970	Cost: 32.41s
Train Epoch: 2259 [20480/90000 (23%)]	Loss: -13.9231	Cost: 13.05s
Train Epoch: 2259 [40960/90000 (45%)]	Loss: -14.0950	Cost: 10.49s
Train Epoch: 2259 [61440/90000 (68%)]	Loss: -14.1287	Cost: 6.24s
Train Epoch: 2259 [81920/90000 (91%)]	Loss: -13.9828	Cost: 6.92s
Train Epoch: 2259 	Average Loss: -13.5774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6536

Learning rate: 8.792833287329828e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2260 [0/90000 (0%)]	Loss: -6.5096	Cost: 35.97s
Train Epoch: 2260 [20480/90000 (23%)]	Loss: -10.2443	Cost: 8.84s
Train Epoch: 2260 [40960/90000 (45%)]	Loss: -11.0621	Cost: 8.72s
Train Epoch: 2260 [61440/90000 (68%)]	Loss: -11.7638	Cost: 8.38s
Train Epoch: 2260 [81920/90000 (91%)]	Loss: -11.6152	Cost: 8.72s
Train Epoch: 2260 	Average Loss: -11.2045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1962

Learning rate: 8.791809576443587e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2261 [0/90000 (0%)]	Loss: -6.0389	Cost: 34.78s
Train Epoch: 2261 [20480/90000 (23%)]	Loss: -12.1023	Cost: 8.95s
Train Epoch: 2261 [40960/90000 (45%)]	Loss: -13.1153	Cost: 8.97s
Train Epoch: 2261 [61440/90000 (68%)]	Loss: -13.5480	Cost: 8.91s
Train Epoch: 2261 [81920/90000 (91%)]	Loss: -13.3645	Cost: 7.91s
Train Epoch: 2261 	Average Loss: -12.4723
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2694

Learning rate: 8.790785491320744e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2262 [0/90000 (0%)]	Loss: -4.3101	Cost: 18.84s
Train Epoch: 2262 [20480/90000 (23%)]	Loss: -13.4581	Cost: 8.64s
Train Epoch: 2262 [40960/90000 (45%)]	Loss: -14.0735	Cost: 7.90s
Train Epoch: 2262 [61440/90000 (68%)]	Loss: -13.9850	Cost: 8.27s
Train Epoch: 2262 [81920/90000 (91%)]	Loss: -13.8535	Cost: 13.07s
Train Epoch: 2262 	Average Loss: -13.3357
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4950

Learning rate: 8.789761032062373e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2263 [0/90000 (0%)]	Loss: -6.5870	Cost: 21.37s
Train Epoch: 2263 [20480/90000 (23%)]	Loss: -13.8343	Cost: 8.15s
Train Epoch: 2263 [40960/90000 (45%)]	Loss: -14.0365	Cost: 11.87s
Train Epoch: 2263 [61440/90000 (68%)]	Loss: -14.1358	Cost: 12.33s
Train Epoch: 2263 [81920/90000 (91%)]	Loss: -13.8571	Cost: 12.46s
Train Epoch: 2263 	Average Loss: -13.4688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5845

Learning rate: 8.788736198769582e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2264 [0/90000 (0%)]	Loss: -6.4500	Cost: 25.52s
Train Epoch: 2264 [20480/90000 (23%)]	Loss: -14.0286	Cost: 14.51s
Train Epoch: 2264 [40960/90000 (45%)]	Loss: -14.5089	Cost: 13.81s
Train Epoch: 2264 [61440/90000 (68%)]	Loss: -14.4173	Cost: 12.41s
Train Epoch: 2264 [81920/90000 (91%)]	Loss: -14.0249	Cost: 9.39s
Train Epoch: 2264 	Average Loss: -13.6685
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7637

Learning rate: 8.787710991543522e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2265 [0/90000 (0%)]	Loss: -7.0176	Cost: 39.92s
Train Epoch: 2265 [20480/90000 (23%)]	Loss: -14.0558	Cost: 10.39s
Train Epoch: 2265 [40960/90000 (45%)]	Loss: -14.3168	Cost: 9.68s
Train Epoch: 2265 [61440/90000 (68%)]	Loss: -14.3372	Cost: 6.70s
Train Epoch: 2265 [81920/90000 (91%)]	Loss: -14.1546	Cost: 7.67s
Train Epoch: 2265 	Average Loss: -13.7846
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8262

Learning rate: 8.786685410485373e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2266 [0/90000 (0%)]	Loss: -7.4258	Cost: 35.21s
Train Epoch: 2266 [20480/90000 (23%)]	Loss: -14.1217	Cost: 11.42s
Train Epoch: 2266 [40960/90000 (45%)]	Loss: -14.3588	Cost: 6.73s
Train Epoch: 2266 [61440/90000 (68%)]	Loss: -14.3913	Cost: 7.23s
Train Epoch: 2266 [81920/90000 (91%)]	Loss: -14.0742	Cost: 8.76s
Train Epoch: 2266 	Average Loss: -13.7095
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8043

Learning rate: 8.785659455696358e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2267 [0/90000 (0%)]	Loss: -5.9989	Cost: 21.40s
Train Epoch: 2267 [20480/90000 (23%)]	Loss: -14.0046	Cost: 6.79s
Train Epoch: 2267 [40960/90000 (45%)]	Loss: -14.1906	Cost: 8.79s
Train Epoch: 2267 [61440/90000 (68%)]	Loss: -14.0180	Cost: 9.04s
Train Epoch: 2267 [81920/90000 (91%)]	Loss: -13.8520	Cost: 8.91s
Train Epoch: 2267 	Average Loss: -13.5004
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7734

Learning rate: 8.784633127277734e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2268 [0/90000 (0%)]	Loss: -6.5519	Cost: 21.92s
Train Epoch: 2268 [20480/90000 (23%)]	Loss: -14.0499	Cost: 8.97s
Train Epoch: 2268 [40960/90000 (45%)]	Loss: -14.5060	Cost: 8.84s
Train Epoch: 2268 [61440/90000 (68%)]	Loss: -14.2486	Cost: 6.13s
Train Epoch: 2268 [81920/90000 (91%)]	Loss: -13.7690	Cost: 6.39s
Train Epoch: 2268 	Average Loss: -13.6479
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7765

Learning rate: 8.783606425330793e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2269 [0/90000 (0%)]	Loss: -5.7035	Cost: 19.01s
Train Epoch: 2269 [20480/90000 (23%)]	Loss: -13.9048	Cost: 7.19s
Train Epoch: 2269 [40960/90000 (45%)]	Loss: -14.3295	Cost: 9.41s
Train Epoch: 2269 [61440/90000 (68%)]	Loss: -14.5661	Cost: 13.21s
Train Epoch: 2269 [81920/90000 (91%)]	Loss: -14.0015	Cost: 12.34s
Train Epoch: 2269 	Average Loss: -13.6864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5912

Learning rate: 8.782579349956871e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2270 [0/90000 (0%)]	Loss: -6.1087	Cost: 25.62s
Train Epoch: 2270 [20480/90000 (23%)]	Loss: -14.0207	Cost: 11.12s
Train Epoch: 2270 [40960/90000 (45%)]	Loss: -14.4852	Cost: 14.74s
Train Epoch: 2270 [61440/90000 (68%)]	Loss: -14.4818	Cost: 12.98s
Train Epoch: 2270 [81920/90000 (91%)]	Loss: -14.0668	Cost: 12.01s
Train Epoch: 2270 	Average Loss: -13.7773
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8855

Saving model as e2270_model.pt & e2270_waveforms_supplementary.hdf5
Learning rate: 8.781551901257334e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2271 [0/90000 (0%)]	Loss: -6.6572	Cost: 40.73s
Train Epoch: 2271 [20480/90000 (23%)]	Loss: -14.2493	Cost: 12.91s
Train Epoch: 2271 [40960/90000 (45%)]	Loss: -14.4531	Cost: 12.52s
Train Epoch: 2271 [61440/90000 (68%)]	Loss: -14.5622	Cost: 12.35s
Train Epoch: 2271 [81920/90000 (91%)]	Loss: -14.2945	Cost: 6.56s
Train Epoch: 2271 	Average Loss: -13.8567
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8459

Learning rate: 8.780524079333586e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2272 [0/90000 (0%)]	Loss: -7.0025	Cost: 32.41s
Train Epoch: 2272 [20480/90000 (23%)]	Loss: -14.3055	Cost: 11.37s
Train Epoch: 2272 [40960/90000 (45%)]	Loss: -14.4025	Cost: 8.94s
Train Epoch: 2272 [61440/90000 (68%)]	Loss: -14.4347	Cost: 6.41s
Train Epoch: 2272 [81920/90000 (91%)]	Loss: -14.1867	Cost: 7.47s
Train Epoch: 2272 	Average Loss: -13.8486
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7024

Learning rate: 8.779495884287072e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2273 [0/90000 (0%)]	Loss: -6.9132	Cost: 21.48s
Train Epoch: 2273 [20480/90000 (23%)]	Loss: -14.1975	Cost: 6.62s
Train Epoch: 2273 [40960/90000 (45%)]	Loss: -14.2928	Cost: 8.83s
Train Epoch: 2273 [61440/90000 (68%)]	Loss: -14.6317	Cost: 8.56s
Train Epoch: 2273 [81920/90000 (91%)]	Loss: -14.2672	Cost: 8.83s
Train Epoch: 2273 	Average Loss: -13.7657
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8120

Learning rate: 8.778467316219268e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2274 [0/90000 (0%)]	Loss: -6.9707	Cost: 20.97s
Train Epoch: 2274 [20480/90000 (23%)]	Loss: -14.2682	Cost: 6.54s
Train Epoch: 2274 [40960/90000 (45%)]	Loss: -14.3970	Cost: 12.64s
Train Epoch: 2274 [61440/90000 (68%)]	Loss: -14.5371	Cost: 10.18s
Train Epoch: 2274 [81920/90000 (91%)]	Loss: -14.0174	Cost: 13.14s
Train Epoch: 2274 	Average Loss: -13.7796
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7134

Learning rate: 8.77743837523169e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2275 [0/90000 (0%)]	Loss: -7.1490	Cost: 25.87s
Train Epoch: 2275 [20480/90000 (23%)]	Loss: -14.1436	Cost: 9.69s
Train Epoch: 2275 [40960/90000 (45%)]	Loss: -14.4840	Cost: 15.16s
Train Epoch: 2275 [61440/90000 (68%)]	Loss: -14.6250	Cost: 12.68s
Train Epoch: 2275 [81920/90000 (91%)]	Loss: -14.2095	Cost: 12.18s
Train Epoch: 2275 	Average Loss: -13.7574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7188

Learning rate: 8.776409061425892e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2276 [0/90000 (0%)]	Loss: -6.1651	Cost: 31.08s
Train Epoch: 2276 [20480/90000 (23%)]	Loss: -14.1212	Cost: 13.22s
Train Epoch: 2276 [40960/90000 (45%)]	Loss: -14.6358	Cost: 12.44s
Train Epoch: 2276 [61440/90000 (68%)]	Loss: -14.5252	Cost: 12.16s
Train Epoch: 2276 [81920/90000 (91%)]	Loss: -14.4186	Cost: 12.13s
Train Epoch: 2276 	Average Loss: -13.8982
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9166

Saving model as e2276_model.pt & e2276_waveforms_supplementary.hdf5
Learning rate: 8.77537937490346e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2277 [0/90000 (0%)]	Loss: -7.0413	Cost: 42.97s
Train Epoch: 2277 [20480/90000 (23%)]	Loss: -14.4421	Cost: 12.63s
Train Epoch: 2277 [40960/90000 (45%)]	Loss: -14.5032	Cost: 9.04s
Train Epoch: 2277 [61440/90000 (68%)]	Loss: -14.4649	Cost: 6.14s
Train Epoch: 2277 [81920/90000 (91%)]	Loss: -14.1786	Cost: 7.27s
Train Epoch: 2277 	Average Loss: -13.8536
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0096

Saving model as e2277_model.pt & e2277_waveforms_supplementary.hdf5
Learning rate: 8.774349315766026e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2278 [0/90000 (0%)]	Loss: -6.2979	Cost: 27.97s
Train Epoch: 2278 [20480/90000 (23%)]	Loss: -14.1013	Cost: 6.81s
Train Epoch: 2278 [40960/90000 (45%)]	Loss: -14.6157	Cost: 12.71s
Train Epoch: 2278 [61440/90000 (68%)]	Loss: -14.4442	Cost: 8.88s
Train Epoch: 2278 [81920/90000 (91%)]	Loss: -14.3731	Cost: 8.59s
Train Epoch: 2278 	Average Loss: -13.8299
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8024

Learning rate: 8.773318884115247e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2279 [0/90000 (0%)]	Loss: -6.1421	Cost: 23.75s
Train Epoch: 2279 [20480/90000 (23%)]	Loss: -13.8495	Cost: 8.92s
Train Epoch: 2279 [40960/90000 (45%)]	Loss: -14.3715	Cost: 9.15s
Train Epoch: 2279 [61440/90000 (68%)]	Loss: -14.2762	Cost: 8.80s
Train Epoch: 2279 [81920/90000 (91%)]	Loss: -14.0615	Cost: 6.26s
Train Epoch: 2279 	Average Loss: -13.6712
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6577

Learning rate: 8.772288080052823e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2280 [0/90000 (0%)]	Loss: -6.5314	Cost: 20.18s
Train Epoch: 2280 [20480/90000 (23%)]	Loss: -14.1385	Cost: 7.01s
Train Epoch: 2280 [40960/90000 (45%)]	Loss: -14.4504	Cost: 9.81s
Train Epoch: 2280 [61440/90000 (68%)]	Loss: -14.3337	Cost: 11.53s
Train Epoch: 2280 [81920/90000 (91%)]	Loss: -13.8588	Cost: 13.47s
Train Epoch: 2280 	Average Loss: -13.7139
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6097

Learning rate: 8.771256903680493e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2281 [0/90000 (0%)]	Loss: -7.2569	Cost: 22.39s
Train Epoch: 2281 [20480/90000 (23%)]	Loss: -14.1401	Cost: 11.32s
Train Epoch: 2281 [40960/90000 (45%)]	Loss: -14.3712	Cost: 12.72s
Train Epoch: 2281 [61440/90000 (68%)]	Loss: -14.3542	Cost: 12.63s
Train Epoch: 2281 [81920/90000 (91%)]	Loss: -14.1522	Cost: 12.29s
Train Epoch: 2281 	Average Loss: -13.7589
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7041

Learning rate: 8.770225355100029e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2282 [0/90000 (0%)]	Loss: -7.6396	Cost: 36.17s
Train Epoch: 2282 [20480/90000 (23%)]	Loss: -14.2837	Cost: 14.26s
Train Epoch: 2282 [40960/90000 (45%)]	Loss: -14.6770	Cost: 12.53s
Train Epoch: 2282 [61440/90000 (68%)]	Loss: -14.6533	Cost: 12.15s
Train Epoch: 2282 [81920/90000 (91%)]	Loss: -14.1846	Cost: 8.45s
Train Epoch: 2282 	Average Loss: -13.8995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6860

Learning rate: 8.769193434413239e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2283 [0/90000 (0%)]	Loss: -7.5497	Cost: 36.13s
Train Epoch: 2283 [20480/90000 (23%)]	Loss: -14.1517	Cost: 12.48s
Train Epoch: 2283 [40960/90000 (45%)]	Loss: -14.3999	Cost: 11.62s
Train Epoch: 2283 [61440/90000 (68%)]	Loss: -14.3832	Cost: 6.05s
Train Epoch: 2283 [81920/90000 (91%)]	Loss: -14.3113	Cost: 6.74s
Train Epoch: 2283 	Average Loss: -13.8494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8732

Learning rate: 8.768161141721973e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2284 [0/90000 (0%)]	Loss: -7.0314	Cost: 23.75s
Train Epoch: 2284 [20480/90000 (23%)]	Loss: -14.2975	Cost: 7.80s
Train Epoch: 2284 [40960/90000 (45%)]	Loss: -14.5098	Cost: 9.15s
Train Epoch: 2284 [61440/90000 (68%)]	Loss: -14.5859	Cost: 8.75s
Train Epoch: 2284 [81920/90000 (91%)]	Loss: -14.3750	Cost: 8.71s
Train Epoch: 2284 	Average Loss: -13.9388
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9674

Learning rate: 8.767128477128111e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2285 [0/90000 (0%)]	Loss: -7.3797	Cost: 19.78s
Train Epoch: 2285 [20480/90000 (23%)]	Loss: -14.4098	Cost: 11.87s
Train Epoch: 2285 [40960/90000 (45%)]	Loss: -14.6298	Cost: 12.66s
Train Epoch: 2285 [61440/90000 (68%)]	Loss: -14.6619	Cost: 8.56s
Train Epoch: 2285 [81920/90000 (91%)]	Loss: -14.1886	Cost: 7.16s
Train Epoch: 2285 	Average Loss: -13.8661
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9277

Learning rate: 8.766095440733574e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2286 [0/90000 (0%)]	Loss: -7.1314	Cost: 21.58s
Train Epoch: 2286 [20480/90000 (23%)]	Loss: -14.4264	Cost: 9.17s
Train Epoch: 2286 [40960/90000 (45%)]	Loss: -14.4985	Cost: 12.17s
Train Epoch: 2286 [61440/90000 (68%)]	Loss: -14.4543	Cost: 12.92s
Train Epoch: 2286 [81920/90000 (91%)]	Loss: -13.9616	Cost: 12.61s
Train Epoch: 2286 	Average Loss: -13.8373
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7825

Learning rate: 8.765062032640319e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2287 [0/90000 (0%)]	Loss: -5.2643	Cost: 26.72s
Train Epoch: 2287 [20480/90000 (23%)]	Loss: -14.0186	Cost: 10.44s
Train Epoch: 2287 [40960/90000 (45%)]	Loss: -14.4122	Cost: 12.85s
Train Epoch: 2287 [61440/90000 (68%)]	Loss: -14.3882	Cost: 12.22s
Train Epoch: 2287 [81920/90000 (91%)]	Loss: -14.0314	Cost: 12.57s
Train Epoch: 2287 	Average Loss: -13.7007
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9474

Learning rate: 8.764028252950338e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2288 [0/90000 (0%)]	Loss: -7.5956	Cost: 27.11s
Train Epoch: 2288 [20480/90000 (23%)]	Loss: -14.2563	Cost: 12.74s
Train Epoch: 2288 [40960/90000 (45%)]	Loss: -14.6004	Cost: 12.56s
Train Epoch: 2288 [61440/90000 (68%)]	Loss: -14.6891	Cost: 11.48s
Train Epoch: 2288 [81920/90000 (91%)]	Loss: -14.3552	Cost: 6.88s
Train Epoch: 2288 	Average Loss: -13.9634
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9533

Learning rate: 8.762994101765663e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2289 [0/90000 (0%)]	Loss: -7.6684	Cost: 24.32s
Train Epoch: 2289 [20480/90000 (23%)]	Loss: -14.3956	Cost: 11.65s
Train Epoch: 2289 [40960/90000 (45%)]	Loss: -14.4631	Cost: 8.68s
Train Epoch: 2289 [61440/90000 (68%)]	Loss: -14.2872	Cost: 6.52s
Train Epoch: 2289 [81920/90000 (91%)]	Loss: -13.9791	Cost: 7.79s
Train Epoch: 2289 	Average Loss: -13.8635
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7301

Learning rate: 8.761959579188359e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2290 [0/90000 (0%)]	Loss: -6.8747	Cost: 26.26s
Train Epoch: 2290 [20480/90000 (23%)]	Loss: -14.0845	Cost: 13.17s
Train Epoch: 2290 [40960/90000 (45%)]	Loss: -14.5331	Cost: 10.34s
Train Epoch: 2290 [61440/90000 (68%)]	Loss: -14.3119	Cost: 8.06s
Train Epoch: 2290 [81920/90000 (91%)]	Loss: -13.6646	Cost: 8.63s
Train Epoch: 2290 	Average Loss: -13.6450
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7121

Learning rate: 8.76092468532053e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2291 [0/90000 (0%)]	Loss: -6.3783	Cost: 22.50s
Train Epoch: 2291 [20480/90000 (23%)]	Loss: -14.0072	Cost: 10.35s
Train Epoch: 2291 [40960/90000 (45%)]	Loss: -14.2660	Cost: 8.80s
Train Epoch: 2291 [61440/90000 (68%)]	Loss: -14.2870	Cost: 7.60s
Train Epoch: 2291 [81920/90000 (91%)]	Loss: -14.1055	Cost: 8.68s
Train Epoch: 2291 	Average Loss: -13.6821
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8120

Learning rate: 8.759889420264316e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2292 [0/90000 (0%)]	Loss: -7.0240	Cost: 22.85s
Train Epoch: 2292 [20480/90000 (23%)]	Loss: -14.1720	Cost: 8.45s
Train Epoch: 2292 [40960/90000 (45%)]	Loss: -14.1935	Cost: 10.31s
Train Epoch: 2292 [61440/90000 (68%)]	Loss: -14.1535	Cost: 8.55s
Train Epoch: 2292 [81920/90000 (91%)]	Loss: -14.0843	Cost: 8.62s
Train Epoch: 2292 	Average Loss: -13.6690
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7984

Learning rate: 8.758853784121894e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2293 [0/90000 (0%)]	Loss: -6.4886	Cost: 21.55s
Train Epoch: 2293 [20480/90000 (23%)]	Loss: -14.0797	Cost: 8.97s
Train Epoch: 2293 [40960/90000 (45%)]	Loss: -14.4854	Cost: 9.18s
Train Epoch: 2293 [61440/90000 (68%)]	Loss: -14.2399	Cost: 7.02s
Train Epoch: 2293 [81920/90000 (91%)]	Loss: -14.2276	Cost: 6.26s
Train Epoch: 2293 	Average Loss: -13.7541
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9200

Learning rate: 8.757817776995476e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2294 [0/90000 (0%)]	Loss: -6.7353	Cost: 20.66s
Train Epoch: 2294 [20480/90000 (23%)]	Loss: -14.3365	Cost: 7.10s
Train Epoch: 2294 [40960/90000 (45%)]	Loss: -14.1360	Cost: 10.31s
Train Epoch: 2294 [61440/90000 (68%)]	Loss: -14.2674	Cost: 12.07s
Train Epoch: 2294 [81920/90000 (91%)]	Loss: -14.0452	Cost: 12.59s
Train Epoch: 2294 	Average Loss: -13.7078
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7893

Learning rate: 8.756781398987313e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2295 [0/90000 (0%)]	Loss: -7.2176	Cost: 34.66s
Train Epoch: 2295 [20480/90000 (23%)]	Loss: -14.3379	Cost: 14.72s
Train Epoch: 2295 [40960/90000 (45%)]	Loss: -14.5408	Cost: 14.38s
Train Epoch: 2295 [61440/90000 (68%)]	Loss: -14.6067	Cost: 12.31s
Train Epoch: 2295 [81920/90000 (91%)]	Loss: -14.3172	Cost: 11.91s
Train Epoch: 2295 	Average Loss: -13.9454
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8698

Learning rate: 8.75574465019969e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2296 [0/90000 (0%)]	Loss: -6.3600	Cost: 33.45s
Train Epoch: 2296 [20480/90000 (23%)]	Loss: -14.1109	Cost: 13.44s
Train Epoch: 2296 [40960/90000 (45%)]	Loss: -14.4856	Cost: 12.98s
Train Epoch: 2296 [61440/90000 (68%)]	Loss: -14.5751	Cost: 12.15s
Train Epoch: 2296 [81920/90000 (91%)]	Loss: -14.1767	Cost: 7.07s
Train Epoch: 2296 	Average Loss: -13.7508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8757

Learning rate: 8.754707530734931e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2297 [0/90000 (0%)]	Loss: -7.2618	Cost: 40.06s
Train Epoch: 2297 [20480/90000 (23%)]	Loss: -14.3743	Cost: 12.31s
Train Epoch: 2297 [40960/90000 (45%)]	Loss: -14.3169	Cost: 11.99s
Train Epoch: 2297 [61440/90000 (68%)]	Loss: -14.5170	Cost: 6.05s
Train Epoch: 2297 [81920/90000 (91%)]	Loss: -14.3726	Cost: 6.09s
Train Epoch: 2297 	Average Loss: -13.9308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8083

Learning rate: 8.753670040695395e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2298 [0/90000 (0%)]	Loss: -5.4447	Cost: 22.87s
Train Epoch: 2298 [20480/90000 (23%)]	Loss: -13.9901	Cost: 9.74s
Train Epoch: 2298 [40960/90000 (45%)]	Loss: -14.1810	Cost: 10.33s
Train Epoch: 2298 [61440/90000 (68%)]	Loss: -14.3032	Cost: 6.14s
Train Epoch: 2298 [81920/90000 (91%)]	Loss: -14.0554	Cost: 7.16s
Train Epoch: 2298 	Average Loss: -13.6976
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6523

Learning rate: 8.752632180183477e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2299 [0/90000 (0%)]	Loss: -7.1944	Cost: 22.04s
Train Epoch: 2299 [20480/90000 (23%)]	Loss: -14.2263	Cost: 6.64s
Train Epoch: 2299 [40960/90000 (45%)]	Loss: -14.2284	Cost: 8.98s
Train Epoch: 2299 [61440/90000 (68%)]	Loss: -14.3959	Cost: 9.37s
Train Epoch: 2299 [81920/90000 (91%)]	Loss: -14.0040	Cost: 8.98s
Train Epoch: 2299 	Average Loss: -13.7784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6723

Learning rate: 8.751593949301614e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2300 [0/90000 (0%)]	Loss: -6.4427	Cost: 25.66s
Train Epoch: 2300 [20480/90000 (23%)]	Loss: -14.2165	Cost: 9.84s
Train Epoch: 2300 [40960/90000 (45%)]	Loss: -14.4053	Cost: 9.05s
Train Epoch: 2300 [61440/90000 (68%)]	Loss: -14.1849	Cost: 7.91s
Train Epoch: 2300 [81920/90000 (91%)]	Loss: -13.9906	Cost: 6.32s
Train Epoch: 2300 	Average Loss: -13.6831
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7489

Learning rate: 8.750555348152272e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2301 [0/90000 (0%)]	Loss: -6.2865	Cost: 29.24s
Train Epoch: 2301 [20480/90000 (23%)]	Loss: -14.2364	Cost: 6.52s
Train Epoch: 2301 [40960/90000 (45%)]	Loss: -14.6557	Cost: 12.13s
Train Epoch: 2301 [61440/90000 (68%)]	Loss: -14.4379	Cost: 10.41s
Train Epoch: 2301 [81920/90000 (91%)]	Loss: -14.2851	Cost: 12.44s
Train Epoch: 2301 	Average Loss: -13.8467
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9073

Learning rate: 8.749516376837957e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2302 [0/90000 (0%)]	Loss: -7.0492	Cost: 20.76s
Train Epoch: 2302 [20480/90000 (23%)]	Loss: -14.3126	Cost: 11.73s
Train Epoch: 2302 [40960/90000 (45%)]	Loss: -14.3844	Cost: 14.25s
Train Epoch: 2302 [61440/90000 (68%)]	Loss: -14.3269	Cost: 12.45s
Train Epoch: 2302 [81920/90000 (91%)]	Loss: -13.8203	Cost: 12.60s
Train Epoch: 2302 	Average Loss: -13.7290
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7232

Learning rate: 8.748477035461212e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2303 [0/90000 (0%)]	Loss: -5.9919	Cost: 25.69s
Train Epoch: 2303 [20480/90000 (23%)]	Loss: -14.1936	Cost: 11.58s
Train Epoch: 2303 [40960/90000 (45%)]	Loss: -14.6333	Cost: 14.57s
Train Epoch: 2303 [61440/90000 (68%)]	Loss: -14.6071	Cost: 12.54s
Train Epoch: 2303 [81920/90000 (91%)]	Loss: -14.3160	Cost: 8.82s
Train Epoch: 2303 	Average Loss: -13.8595
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8518

Learning rate: 8.747437324124616e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2304 [0/90000 (0%)]	Loss: -7.1174	Cost: 23.41s
Train Epoch: 2304 [20480/90000 (23%)]	Loss: -14.4625	Cost: 12.56s
Train Epoch: 2304 [40960/90000 (45%)]	Loss: -14.7680	Cost: 9.46s
Train Epoch: 2304 [61440/90000 (68%)]	Loss: -14.5235	Cost: 6.26s
Train Epoch: 2304 [81920/90000 (91%)]	Loss: -14.1393	Cost: 7.13s
Train Epoch: 2304 	Average Loss: -13.9053
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9902

Learning rate: 8.746397242930784e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2305 [0/90000 (0%)]	Loss: -6.8947	Cost: 36.81s
Train Epoch: 2305 [20480/90000 (23%)]	Loss: -14.1984	Cost: 10.41s
Train Epoch: 2305 [40960/90000 (45%)]	Loss: -14.8083	Cost: 7.17s
Train Epoch: 2305 [61440/90000 (68%)]	Loss: -14.9614	Cost: 7.27s
Train Epoch: 2305 [81920/90000 (91%)]	Loss: -14.4551	Cost: 9.02s
Train Epoch: 2305 	Average Loss: -14.0524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1032

Saving model as e2305_model.pt & e2305_waveforms_supplementary.hdf5
Learning rate: 8.745356791982367e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2306 [0/90000 (0%)]	Loss: -5.8548	Cost: 28.03s
Train Epoch: 2306 [20480/90000 (23%)]	Loss: -14.5649	Cost: 8.36s
Train Epoch: 2306 [40960/90000 (45%)]	Loss: -14.5415	Cost: 8.92s
Train Epoch: 2306 [61440/90000 (68%)]	Loss: -14.5108	Cost: 8.81s
Train Epoch: 2306 [81920/90000 (91%)]	Loss: -13.9411	Cost: 8.67s
Train Epoch: 2306 	Average Loss: -13.8092
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6664

Learning rate: 8.744315971382053e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2307 [0/90000 (0%)]	Loss: -5.9315	Cost: 21.25s
Train Epoch: 2307 [20480/90000 (23%)]	Loss: -14.1709	Cost: 9.41s
Train Epoch: 2307 [40960/90000 (45%)]	Loss: -14.5044	Cost: 9.05s
Train Epoch: 2307 [61440/90000 (68%)]	Loss: -14.5385	Cost: 8.22s
Train Epoch: 2307 [81920/90000 (91%)]	Loss: -14.2050	Cost: 6.91s
Train Epoch: 2307 	Average Loss: -13.7690
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7830

Learning rate: 8.74327478123257e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2308 [0/90000 (0%)]	Loss: -7.1762	Cost: 20.80s
Train Epoch: 2308 [20480/90000 (23%)]	Loss: -14.6144	Cost: 7.21s
Train Epoch: 2308 [40960/90000 (45%)]	Loss: -14.6264	Cost: 9.11s
Train Epoch: 2308 [61440/90000 (68%)]	Loss: -14.6556	Cost: 13.67s
Train Epoch: 2308 [81920/90000 (91%)]	Loss: -14.1868	Cost: 14.22s
Train Epoch: 2308 	Average Loss: -14.0006
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7735

Learning rate: 8.742233221636677e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2309 [0/90000 (0%)]	Loss: -6.9878	Cost: 21.68s
Train Epoch: 2309 [20480/90000 (23%)]	Loss: -14.0171	Cost: 12.79s
Train Epoch: 2309 [40960/90000 (45%)]	Loss: -14.6488	Cost: 14.50s
Train Epoch: 2309 [61440/90000 (68%)]	Loss: -14.8062	Cost: 12.52s
Train Epoch: 2309 [81920/90000 (91%)]	Loss: -14.4737	Cost: 12.10s
Train Epoch: 2309 	Average Loss: -13.9403
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0961

Learning rate: 8.741191292697172e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2310 [0/90000 (0%)]	Loss: -8.1685	Cost: 41.48s
Train Epoch: 2310 [20480/90000 (23%)]	Loss: -14.6155	Cost: 11.53s
Train Epoch: 2310 [40960/90000 (45%)]	Loss: -14.7946	Cost: 12.37s
Train Epoch: 2310 [61440/90000 (68%)]	Loss: -14.7546	Cost: 12.04s
Train Epoch: 2310 [81920/90000 (91%)]	Loss: -14.2912	Cost: 6.21s
Train Epoch: 2310 	Average Loss: -14.0754
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9560

Learning rate: 8.74014899451689e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2311 [0/90000 (0%)]	Loss: -6.3378	Cost: 32.69s
Train Epoch: 2311 [20480/90000 (23%)]	Loss: -14.4281	Cost: 12.17s
Train Epoch: 2311 [40960/90000 (45%)]	Loss: -14.7710	Cost: 11.54s
Train Epoch: 2311 [61440/90000 (68%)]	Loss: -14.7413	Cost: 6.03s
Train Epoch: 2311 [81920/90000 (91%)]	Loss: -14.2468	Cost: 7.04s
Train Epoch: 2311 	Average Loss: -13.9665
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7676

Learning rate: 8.739106327198702e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2312 [0/90000 (0%)]	Loss: -7.1755	Cost: 25.39s
Train Epoch: 2312 [20480/90000 (23%)]	Loss: -14.3967	Cost: 9.18s
Train Epoch: 2312 [40960/90000 (45%)]	Loss: -14.5366	Cost: 10.91s
Train Epoch: 2312 [61440/90000 (68%)]	Loss: -14.3286	Cost: 8.96s
Train Epoch: 2312 [81920/90000 (91%)]	Loss: -14.2511	Cost: 8.86s
Train Epoch: 2312 	Average Loss: -13.8273
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9727

Learning rate: 8.738063290845513e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2313 [0/90000 (0%)]	Loss: -6.5769	Cost: 22.54s
Train Epoch: 2313 [20480/90000 (23%)]	Loss: -14.3833	Cost: 11.39s
Train Epoch: 2313 [40960/90000 (45%)]	Loss: -14.4945	Cost: 10.15s
Train Epoch: 2313 [61440/90000 (68%)]	Loss: -14.4410	Cost: 7.55s
Train Epoch: 2313 [81920/90000 (91%)]	Loss: -14.0109	Cost: 6.11s
Train Epoch: 2313 	Average Loss: -13.8865
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8056

Learning rate: 8.737019885560269e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2314 [0/90000 (0%)]	Loss: -5.8759	Cost: 20.58s
Train Epoch: 2314 [20480/90000 (23%)]	Loss: -14.3026	Cost: 6.56s
Train Epoch: 2314 [40960/90000 (45%)]	Loss: -14.4945	Cost: 8.20s
Train Epoch: 2314 [61440/90000 (68%)]	Loss: -14.8235	Cost: 7.60s
Train Epoch: 2314 [81920/90000 (91%)]	Loss: -14.1608	Cost: 15.83s
Train Epoch: 2314 	Average Loss: -13.8468
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9092

Learning rate: 8.735976111445948e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2315 [0/90000 (0%)]	Loss: -7.4832	Cost: 21.30s
Train Epoch: 2315 [20480/90000 (23%)]	Loss: -14.3966	Cost: 11.14s
Train Epoch: 2315 [40960/90000 (45%)]	Loss: -14.5541	Cost: 12.70s
Train Epoch: 2315 [61440/90000 (68%)]	Loss: -14.7294	Cost: 12.27s
Train Epoch: 2315 [81920/90000 (91%)]	Loss: -14.2905	Cost: 12.51s
Train Epoch: 2315 	Average Loss: -13.9352
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0334

Learning rate: 8.734931968605567e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2316 [0/90000 (0%)]	Loss: -7.6678	Cost: 22.72s
Train Epoch: 2316 [20480/90000 (23%)]	Loss: -14.5745	Cost: 13.85s
Train Epoch: 2316 [40960/90000 (45%)]	Loss: -14.9749	Cost: 13.30s
Train Epoch: 2316 [61440/90000 (68%)]	Loss: -14.8042	Cost: 12.35s
Train Epoch: 2316 [81920/90000 (91%)]	Loss: -14.5687	Cost: 8.57s
Train Epoch: 2316 	Average Loss: -14.1346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9971

Learning rate: 8.733887457142179e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2317 [0/90000 (0%)]	Loss: -7.5944	Cost: 39.53s
Train Epoch: 2317 [20480/90000 (23%)]	Loss: -14.2984	Cost: 11.90s
Train Epoch: 2317 [40960/90000 (45%)]	Loss: -14.7150	Cost: 8.21s
Train Epoch: 2317 [61440/90000 (68%)]	Loss: -14.8091	Cost: 6.28s
Train Epoch: 2317 [81920/90000 (91%)]	Loss: -14.3486	Cost: 8.41s
Train Epoch: 2317 	Average Loss: -14.0334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0343

Learning rate: 8.732842577158875e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2318 [0/90000 (0%)]	Loss: -6.7783	Cost: 30.55s
Train Epoch: 2318 [20480/90000 (23%)]	Loss: -14.4783	Cost: 9.04s
Train Epoch: 2318 [40960/90000 (45%)]	Loss: -14.7039	Cost: 7.06s
Train Epoch: 2318 [61440/90000 (68%)]	Loss: -14.8640	Cost: 8.91s
Train Epoch: 2318 [81920/90000 (91%)]	Loss: -14.4039	Cost: 8.74s
Train Epoch: 2318 	Average Loss: -14.0553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1412

Saving model as e2318_model.pt & e2318_waveforms_supplementary.hdf5
Learning rate: 8.731797328758776e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2319 [0/90000 (0%)]	Loss: -7.4226	Cost: 23.57s
Train Epoch: 2319 [20480/90000 (23%)]	Loss: -14.5928	Cost: 9.08s
Train Epoch: 2319 [40960/90000 (45%)]	Loss: -14.6764	Cost: 9.49s
Train Epoch: 2319 [61440/90000 (68%)]	Loss: -14.6825	Cost: 8.96s
Train Epoch: 2319 [81920/90000 (91%)]	Loss: -14.4634	Cost: 8.88s
Train Epoch: 2319 	Average Loss: -14.0041
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0760

Learning rate: 8.730751712045047e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2320 [0/90000 (0%)]	Loss: -6.6030	Cost: 20.78s
Train Epoch: 2320 [20480/90000 (23%)]	Loss: -14.4704	Cost: 6.70s
Train Epoch: 2320 [40960/90000 (45%)]	Loss: -14.6639	Cost: 8.34s
Train Epoch: 2320 [61440/90000 (68%)]	Loss: -14.8104	Cost: 9.12s
Train Epoch: 2320 [81920/90000 (91%)]	Loss: -14.3799	Cost: 18.38s
Train Epoch: 2320 	Average Loss: -14.0698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0327

Learning rate: 8.729705727120888e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2321 [0/90000 (0%)]	Loss: -7.8169	Cost: 22.35s
Train Epoch: 2321 [20480/90000 (23%)]	Loss: -14.3417	Cost: 14.11s
Train Epoch: 2321 [40960/90000 (45%)]	Loss: -14.6113	Cost: 14.10s
Train Epoch: 2321 [61440/90000 (68%)]	Loss: -14.6504	Cost: 12.41s
Train Epoch: 2321 [81920/90000 (91%)]	Loss: -14.3756	Cost: 12.14s
Train Epoch: 2321 	Average Loss: -14.0653
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9413

Learning rate: 8.728659374089531e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2322 [0/90000 (0%)]	Loss: -7.4762	Cost: 40.72s
Train Epoch: 2322 [20480/90000 (23%)]	Loss: -14.5907	Cost: 12.41s
Train Epoch: 2322 [40960/90000 (45%)]	Loss: -14.5516	Cost: 12.37s
Train Epoch: 2322 [61440/90000 (68%)]	Loss: -14.6786	Cost: 9.32s
Train Epoch: 2322 [81920/90000 (91%)]	Loss: -14.3457	Cost: 6.22s
Train Epoch: 2322 	Average Loss: -14.0524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1875

Saving model as e2322_model.pt & e2322_waveforms_supplementary.hdf5
Learning rate: 8.727612653054245e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2323 [0/90000 (0%)]	Loss: -6.8388	Cost: 25.43s
Train Epoch: 2323 [20480/90000 (23%)]	Loss: -14.2449	Cost: 8.41s
Train Epoch: 2323 [40960/90000 (45%)]	Loss: -14.2059	Cost: 6.53s
Train Epoch: 2323 [61440/90000 (68%)]	Loss: -14.0574	Cost: 6.78s
Train Epoch: 2323 [81920/90000 (91%)]	Loss: -13.7402	Cost: 8.77s
Train Epoch: 2323 	Average Loss: -13.6333
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5530

Learning rate: 8.72656556411834e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2324 [0/90000 (0%)]	Loss: -6.7326	Cost: 23.97s
Train Epoch: 2324 [20480/90000 (23%)]	Loss: -14.1390	Cost: 8.07s
Train Epoch: 2324 [40960/90000 (45%)]	Loss: -14.4867	Cost: 12.04s
Train Epoch: 2324 [61440/90000 (68%)]	Loss: -14.6200	Cost: 9.06s
Train Epoch: 2324 [81920/90000 (91%)]	Loss: -14.3529	Cost: 8.82s
Train Epoch: 2324 	Average Loss: -13.8622
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0740

Learning rate: 8.725518107385162e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2325 [0/90000 (0%)]	Loss: -7.5125	Cost: 22.85s
Train Epoch: 2325 [20480/90000 (23%)]	Loss: -14.5504	Cost: 11.24s
Train Epoch: 2325 [40960/90000 (45%)]	Loss: -14.6561	Cost: 9.10s
Train Epoch: 2325 [61440/90000 (68%)]	Loss: -14.6036	Cost: 6.62s
Train Epoch: 2325 [81920/90000 (91%)]	Loss: -14.2834	Cost: 6.83s
Train Epoch: 2325 	Average Loss: -14.1176
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0789

Learning rate: 8.724470282958085e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2326 [0/90000 (0%)]	Loss: -6.6274	Cost: 21.65s
Train Epoch: 2326 [20480/90000 (23%)]	Loss: -14.6199	Cost: 7.89s
Train Epoch: 2326 [40960/90000 (45%)]	Loss: -14.9390	Cost: 9.76s
Train Epoch: 2326 [61440/90000 (68%)]	Loss: -14.9224	Cost: 12.70s
Train Epoch: 2326 [81920/90000 (91%)]	Loss: -14.6332	Cost: 12.44s
Train Epoch: 2326 	Average Loss: -14.1348
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2115

Saving model as e2326_model.pt & e2326_waveforms_supplementary.hdf5
Learning rate: 8.72342209094053e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2327 [0/90000 (0%)]	Loss: -6.9741	Cost: 21.80s
Train Epoch: 2327 [20480/90000 (23%)]	Loss: -14.3631	Cost: 14.04s
Train Epoch: 2327 [40960/90000 (45%)]	Loss: -14.7100	Cost: 12.59s
Train Epoch: 2327 [61440/90000 (68%)]	Loss: -14.7651	Cost: 12.17s
Train Epoch: 2327 [81920/90000 (91%)]	Loss: -14.3747	Cost: 12.59s
Train Epoch: 2327 	Average Loss: -14.0919
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0443

Learning rate: 8.722373531435948e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2328 [0/90000 (0%)]	Loss: -8.1497	Cost: 22.84s
Train Epoch: 2328 [20480/90000 (23%)]	Loss: -14.5535	Cost: 11.51s
Train Epoch: 2328 [40960/90000 (45%)]	Loss: -14.5625	Cost: 13.27s
Train Epoch: 2328 [61440/90000 (68%)]	Loss: -14.4766	Cost: 12.14s
Train Epoch: 2328 [81920/90000 (91%)]	Loss: -14.1119	Cost: 6.56s
Train Epoch: 2328 	Average Loss: -14.0712
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8222

Learning rate: 8.721324604547826e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2329 [0/90000 (0%)]	Loss: -6.9611	Cost: 35.75s
Train Epoch: 2329 [20480/90000 (23%)]	Loss: -14.3214	Cost: 14.38s
Train Epoch: 2329 [40960/90000 (45%)]	Loss: -14.3918	Cost: 12.39s
Train Epoch: 2329 [61440/90000 (68%)]	Loss: -14.4736	Cost: 5.99s
Train Epoch: 2329 [81920/90000 (91%)]	Loss: -13.9614	Cost: 6.48s
Train Epoch: 2329 	Average Loss: -13.8386
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7758

Learning rate: 8.720275310379689e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2330 [0/90000 (0%)]	Loss: -7.7712	Cost: 27.06s
Train Epoch: 2330 [20480/90000 (23%)]	Loss: -14.2567	Cost: 10.18s
Train Epoch: 2330 [40960/90000 (45%)]	Loss: -14.4795	Cost: 8.56s
Train Epoch: 2330 [61440/90000 (68%)]	Loss: -14.2526	Cost: 8.74s
Train Epoch: 2330 [81920/90000 (91%)]	Loss: -13.9331	Cost: 8.69s
Train Epoch: 2330 	Average Loss: -13.7535
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7985

Learning rate: 8.7192256490351e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2331 [0/90000 (0%)]	Loss: -6.2602	Cost: 21.45s
Train Epoch: 2331 [20480/90000 (23%)]	Loss: -14.3721	Cost: 8.16s
Train Epoch: 2331 [40960/90000 (45%)]	Loss: -14.6743	Cost: 8.95s
Train Epoch: 2331 [61440/90000 (68%)]	Loss: -14.6489	Cost: 8.89s
Train Epoch: 2331 [81920/90000 (91%)]	Loss: -14.2479	Cost: 8.69s
Train Epoch: 2331 	Average Loss: -13.8943
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7868

Learning rate: 8.718175620617655e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2332 [0/90000 (0%)]	Loss: -6.6699	Cost: 21.72s
Train Epoch: 2332 [20480/90000 (23%)]	Loss: -14.3192	Cost: 8.98s
Train Epoch: 2332 [40960/90000 (45%)]	Loss: -14.4989	Cost: 6.68s
Train Epoch: 2332 [61440/90000 (68%)]	Loss: -14.6238	Cost: 6.69s
Train Epoch: 2332 [81920/90000 (91%)]	Loss: -14.2864	Cost: 6.61s
Train Epoch: 2332 	Average Loss: -13.9433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0307

Learning rate: 8.717125225230991e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2333 [0/90000 (0%)]	Loss: -6.9478	Cost: 19.53s
Train Epoch: 2333 [20480/90000 (23%)]	Loss: -14.4687	Cost: 7.72s
Train Epoch: 2333 [40960/90000 (45%)]	Loss: -14.8902	Cost: 11.06s
Train Epoch: 2333 [61440/90000 (68%)]	Loss: -14.8583	Cost: 13.36s
Train Epoch: 2333 [81920/90000 (91%)]	Loss: -14.5199	Cost: 12.53s
Train Epoch: 2333 	Average Loss: -14.1328
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0513

Learning rate: 8.716074462978773e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2334 [0/90000 (0%)]	Loss: -7.7223	Cost: 22.13s
Train Epoch: 2334 [20480/90000 (23%)]	Loss: -14.6327	Cost: 10.07s
Train Epoch: 2334 [40960/90000 (45%)]	Loss: -14.5314	Cost: 14.64s
Train Epoch: 2334 [61440/90000 (68%)]	Loss: -14.4784	Cost: 13.86s
Train Epoch: 2334 [81920/90000 (91%)]	Loss: -14.2370	Cost: 12.01s
Train Epoch: 2334 	Average Loss: -13.9409
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8681

Learning rate: 8.715023333964711e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2335 [0/90000 (0%)]	Loss: -7.7584	Cost: 35.52s
Train Epoch: 2335 [20480/90000 (23%)]	Loss: -14.3064	Cost: 14.81s
Train Epoch: 2335 [40960/90000 (45%)]	Loss: -14.4815	Cost: 13.43s
Train Epoch: 2335 [61440/90000 (68%)]	Loss: -14.4500	Cost: 12.26s
Train Epoch: 2335 [81920/90000 (91%)]	Loss: -14.1014	Cost: 10.75s
Train Epoch: 2335 	Average Loss: -13.8828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9970

Learning rate: 8.713971838292545e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2336 [0/90000 (0%)]	Loss: -7.8394	Cost: 33.43s
Train Epoch: 2336 [20480/90000 (23%)]	Loss: -14.5025	Cost: 11.76s
Train Epoch: 2336 [40960/90000 (45%)]	Loss: -14.8287	Cost: 12.25s
Train Epoch: 2336 [61440/90000 (68%)]	Loss: -14.8061	Cost: 12.04s
Train Epoch: 2336 [81920/90000 (91%)]	Loss: -14.4102	Cost: 6.09s
Train Epoch: 2336 	Average Loss: -14.1308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8778

Learning rate: 8.712919976066054e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2337 [0/90000 (0%)]	Loss: -7.4443	Cost: 23.14s
Train Epoch: 2337 [20480/90000 (23%)]	Loss: -14.5181	Cost: 10.97s
Train Epoch: 2337 [40960/90000 (45%)]	Loss: -14.9994	Cost: 9.05s
Train Epoch: 2337 [61440/90000 (68%)]	Loss: -14.7516	Cost: 6.03s
Train Epoch: 2337 [81920/90000 (91%)]	Loss: -14.4783	Cost: 8.13s
Train Epoch: 2337 	Average Loss: -14.1370
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9916

Learning rate: 8.71186774738905e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2338 [0/90000 (0%)]	Loss: -7.8238	Cost: 20.08s
Train Epoch: 2338 [20480/90000 (23%)]	Loss: -14.6509	Cost: 6.76s
Train Epoch: 2338 [40960/90000 (45%)]	Loss: -14.7301	Cost: 10.39s
Train Epoch: 2338 [61440/90000 (68%)]	Loss: -14.7519	Cost: 9.25s
Train Epoch: 2338 [81920/90000 (91%)]	Loss: -14.3268	Cost: 8.85s
Train Epoch: 2338 	Average Loss: -14.1627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9548

Learning rate: 8.71081515236539e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2339 [0/90000 (0%)]	Loss: -6.8542	Cost: 23.42s
Train Epoch: 2339 [20480/90000 (23%)]	Loss: -14.1699	Cost: 10.05s
Train Epoch: 2339 [40960/90000 (45%)]	Loss: -14.4844	Cost: 9.11s
Train Epoch: 2339 [61440/90000 (68%)]	Loss: -14.7602	Cost: 8.56s
Train Epoch: 2339 [81920/90000 (91%)]	Loss: -14.4636	Cost: 7.31s
Train Epoch: 2339 	Average Loss: -13.9699
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1014

Learning rate: 8.709762191098955e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2340 [0/90000 (0%)]	Loss: -5.0737	Cost: 26.12s
Train Epoch: 2340 [20480/90000 (23%)]	Loss: -14.5979	Cost: 8.95s
Train Epoch: 2340 [40960/90000 (45%)]	Loss: -14.7385	Cost: 8.86s
Train Epoch: 2340 [61440/90000 (68%)]	Loss: -14.9493	Cost: 6.12s
Train Epoch: 2340 [81920/90000 (91%)]	Loss: -14.5095	Cost: 6.70s
Train Epoch: 2340 	Average Loss: -14.1005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2430

Saving model as e2340_model.pt & e2340_waveforms_supplementary.hdf5
Learning rate: 8.708708863693671e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2341 [0/90000 (0%)]	Loss: -6.9341	Cost: 18.27s
Train Epoch: 2341 [20480/90000 (23%)]	Loss: -14.7481	Cost: 7.68s
Train Epoch: 2341 [40960/90000 (45%)]	Loss: -14.7464	Cost: 15.17s
Train Epoch: 2341 [61440/90000 (68%)]	Loss: -14.7882	Cost: 13.00s
Train Epoch: 2341 [81920/90000 (91%)]	Loss: -14.5956	Cost: 12.32s
Train Epoch: 2341 	Average Loss: -14.2217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0602

Learning rate: 8.707655170253498e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2342 [0/90000 (0%)]	Loss: -7.1629	Cost: 25.53s
Train Epoch: 2342 [20480/90000 (23%)]	Loss: -14.7607	Cost: 12.84s
Train Epoch: 2342 [40960/90000 (45%)]	Loss: -15.1202	Cost: 12.53s
Train Epoch: 2342 [61440/90000 (68%)]	Loss: -14.9771	Cost: 12.31s
Train Epoch: 2342 [81920/90000 (91%)]	Loss: -14.6012	Cost: 12.61s
Train Epoch: 2342 	Average Loss: -14.3052
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3086

Saving model as e2342_model.pt & e2342_waveforms_supplementary.hdf5
Learning rate: 8.70660111088243e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2343 [0/90000 (0%)]	Loss: -7.3264	Cost: 24.53s
Train Epoch: 2343 [20480/90000 (23%)]	Loss: -14.6737	Cost: 13.51s
Train Epoch: 2343 [40960/90000 (45%)]	Loss: -15.0758	Cost: 12.41s
Train Epoch: 2343 [61440/90000 (68%)]	Loss: -15.0564	Cost: 7.78s
Train Epoch: 2343 [81920/90000 (91%)]	Loss: -14.6628	Cost: 6.19s
Train Epoch: 2343 	Average Loss: -14.2930
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0760

Learning rate: 8.705546685684498e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2344 [0/90000 (0%)]	Loss: -6.0699	Cost: 29.32s
Train Epoch: 2344 [20480/90000 (23%)]	Loss: -14.6995	Cost: 6.81s
Train Epoch: 2344 [40960/90000 (45%)]	Loss: -14.8378	Cost: 9.48s
Train Epoch: 2344 [61440/90000 (68%)]	Loss: -14.9351	Cost: 8.73s
Train Epoch: 2344 [81920/90000 (91%)]	Loss: -14.4266	Cost: 8.70s
Train Epoch: 2344 	Average Loss: -14.2503
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1476

Learning rate: 8.70449189476377e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2345 [0/90000 (0%)]	Loss: -7.5030	Cost: 23.07s
Train Epoch: 2345 [20480/90000 (23%)]	Loss: -14.6522	Cost: 7.58s
Train Epoch: 2345 [40960/90000 (45%)]	Loss: -14.8343	Cost: 9.12s
Train Epoch: 2345 [61440/90000 (68%)]	Loss: -14.9255	Cost: 8.55s
Train Epoch: 2345 [81920/90000 (91%)]	Loss: -14.4740	Cost: 8.49s
Train Epoch: 2345 	Average Loss: -14.1919
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1006

Learning rate: 8.703436738224352e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2346 [0/90000 (0%)]	Loss: -7.0666	Cost: 26.24s
Train Epoch: 2346 [20480/90000 (23%)]	Loss: -14.7762	Cost: 8.76s
Train Epoch: 2346 [40960/90000 (45%)]	Loss: -14.7699	Cost: 7.50s
Train Epoch: 2346 [61440/90000 (68%)]	Loss: -15.0261	Cost: 6.29s
Train Epoch: 2346 [81920/90000 (91%)]	Loss: -14.5386	Cost: 7.57s
Train Epoch: 2346 	Average Loss: -14.2292
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2255

Learning rate: 8.70238121617038e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2347 [0/90000 (0%)]	Loss: -6.3565	Cost: 19.72s
Train Epoch: 2347 [20480/90000 (23%)]	Loss: -14.6935	Cost: 8.38s
Train Epoch: 2347 [40960/90000 (45%)]	Loss: -14.9295	Cost: 10.09s
Train Epoch: 2347 [61440/90000 (68%)]	Loss: -14.9178	Cost: 14.64s
Train Epoch: 2347 [81920/90000 (91%)]	Loss: -14.5471	Cost: 14.29s
Train Epoch: 2347 	Average Loss: -14.2736
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2812

Learning rate: 8.70132532870603e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2348 [0/90000 (0%)]	Loss: -7.7835	Cost: 25.08s
Train Epoch: 2348 [20480/90000 (23%)]	Loss: -14.5629	Cost: 13.14s
Train Epoch: 2348 [40960/90000 (45%)]	Loss: -14.7613	Cost: 13.88s
Train Epoch: 2348 [61440/90000 (68%)]	Loss: -15.0115	Cost: 12.51s
Train Epoch: 2348 [81920/90000 (91%)]	Loss: -14.4051	Cost: 12.42s
Train Epoch: 2348 	Average Loss: -14.2028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9840

Learning rate: 8.700269075935517e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2349 [0/90000 (0%)]	Loss: -6.3387	Cost: 25.56s
Train Epoch: 2349 [20480/90000 (23%)]	Loss: -14.5156	Cost: 14.41s
Train Epoch: 2349 [40960/90000 (45%)]	Loss: -15.0090	Cost: 12.61s
Train Epoch: 2349 [61440/90000 (68%)]	Loss: -14.8843	Cost: 10.66s
Train Epoch: 2349 [81920/90000 (91%)]	Loss: -14.7620	Cost: 6.30s
Train Epoch: 2349 	Average Loss: -14.2509
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2304

Learning rate: 8.699212457963087e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2350 [0/90000 (0%)]	Loss: -7.2507	Cost: 34.82s
Train Epoch: 2350 [20480/90000 (23%)]	Loss: -14.4524	Cost: 10.89s
Train Epoch: 2350 [40960/90000 (45%)]	Loss: -14.8153	Cost: 6.39s
Train Epoch: 2350 [61440/90000 (68%)]	Loss: -14.8692	Cost: 6.30s
Train Epoch: 2350 [81920/90000 (91%)]	Loss: -14.4466	Cost: 8.98s
Train Epoch: 2350 	Average Loss: -14.1290
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8480

Learning rate: 8.698155474893025e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2351 [0/90000 (0%)]	Loss: -7.3408	Cost: 26.49s
Train Epoch: 2351 [20480/90000 (23%)]	Loss: -14.4569	Cost: 7.10s
Train Epoch: 2351 [40960/90000 (45%)]	Loss: -14.5876	Cost: 10.00s
Train Epoch: 2351 [61440/90000 (68%)]	Loss: -14.8167	Cost: 8.59s
Train Epoch: 2351 [81920/90000 (91%)]	Loss: -14.4281	Cost: 8.42s
Train Epoch: 2351 	Average Loss: -14.0866
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0236

Learning rate: 8.69709812682965e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2352 [0/90000 (0%)]	Loss: -6.0640	Cost: 24.39s
Train Epoch: 2352 [20480/90000 (23%)]	Loss: -14.6936	Cost: 10.67s
Train Epoch: 2352 [40960/90000 (45%)]	Loss: -14.8099	Cost: 10.27s
Train Epoch: 2352 [61440/90000 (68%)]	Loss: -14.7808	Cost: 6.88s
Train Epoch: 2352 [81920/90000 (91%)]	Loss: -14.4713	Cost: 8.79s
Train Epoch: 2352 	Average Loss: -14.1406
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9591

Learning rate: 8.696040413877318e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2353 [0/90000 (0%)]	Loss: -6.3103	Cost: 18.27s
Train Epoch: 2353 [20480/90000 (23%)]	Loss: -14.2833	Cost: 9.01s
Train Epoch: 2353 [40960/90000 (45%)]	Loss: -14.7461	Cost: 17.29s
Train Epoch: 2353 [61440/90000 (68%)]	Loss: -14.8588	Cost: 14.46s
Train Epoch: 2353 [81920/90000 (91%)]	Loss: -14.4413	Cost: 12.86s
Train Epoch: 2353 	Average Loss: -14.1080
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1158

Learning rate: 8.694982336140423e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2354 [0/90000 (0%)]	Loss: -6.5860	Cost: 29.32s
Train Epoch: 2354 [20480/90000 (23%)]	Loss: -14.5781	Cost: 11.91s
Train Epoch: 2354 [40960/90000 (45%)]	Loss: -14.6854	Cost: 12.27s
Train Epoch: 2354 [61440/90000 (68%)]	Loss: -15.0833	Cost: 12.23s
Train Epoch: 2354 [81920/90000 (91%)]	Loss: -14.7800	Cost: 12.25s
Train Epoch: 2354 	Average Loss: -14.2325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2568

Learning rate: 8.693923893723392e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2355 [0/90000 (0%)]	Loss: -7.0328	Cost: 26.69s
Train Epoch: 2355 [20480/90000 (23%)]	Loss: -14.6829	Cost: 14.31s
Train Epoch: 2355 [40960/90000 (45%)]	Loss: -14.8699	Cost: 12.47s
Train Epoch: 2355 [61440/90000 (68%)]	Loss: -14.8486	Cost: 12.02s
Train Epoch: 2355 [81920/90000 (91%)]	Loss: -14.6331	Cost: 7.79s
Train Epoch: 2355 	Average Loss: -14.2195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0579

Learning rate: 8.692865086730689e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2356 [0/90000 (0%)]	Loss: -6.5835	Cost: 25.19s
Train Epoch: 2356 [20480/90000 (23%)]	Loss: -14.4803	Cost: 12.73s
Train Epoch: 2356 [40960/90000 (45%)]	Loss: -14.6468	Cost: 12.38s
Train Epoch: 2356 [61440/90000 (68%)]	Loss: -14.8135	Cost: 6.64s
Train Epoch: 2356 [81920/90000 (91%)]	Loss: -14.6170	Cost: 6.30s
Train Epoch: 2356 	Average Loss: -14.0849
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3317

Saving model as e2356_model.pt & e2356_waveforms_supplementary.hdf5
Learning rate: 8.691805915266811e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2357 [0/90000 (0%)]	Loss: -8.0594	Cost: 30.70s
Train Epoch: 2357 [20480/90000 (23%)]	Loss: -14.7173	Cost: 7.07s
Train Epoch: 2357 [40960/90000 (45%)]	Loss: -14.6262	Cost: 9.84s
Train Epoch: 2357 [61440/90000 (68%)]	Loss: -14.8365	Cost: 9.13s
Train Epoch: 2357 [81920/90000 (91%)]	Loss: -14.1114	Cost: 8.71s
Train Epoch: 2357 	Average Loss: -14.1586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8688

Learning rate: 8.6907463794363e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2358 [0/90000 (0%)]	Loss: -7.0052	Cost: 24.40s
Train Epoch: 2358 [20480/90000 (23%)]	Loss: -14.4448	Cost: 10.39s
Train Epoch: 2358 [40960/90000 (45%)]	Loss: -14.8461	Cost: 11.32s
Train Epoch: 2358 [61440/90000 (68%)]	Loss: -14.7568	Cost: 9.18s
Train Epoch: 2358 [81920/90000 (91%)]	Loss: -14.5392	Cost: 8.61s
Train Epoch: 2358 	Average Loss: -14.1158
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2564

Learning rate: 8.689686479343725e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2359 [0/90000 (0%)]	Loss: -7.0013	Cost: 23.71s
Train Epoch: 2359 [20480/90000 (23%)]	Loss: -14.3931	Cost: 6.47s
Train Epoch: 2359 [40960/90000 (45%)]	Loss: -14.5837	Cost: 7.51s
Train Epoch: 2359 [61440/90000 (68%)]	Loss: -14.4157	Cost: 6.74s
Train Epoch: 2359 [81920/90000 (91%)]	Loss: -14.4046	Cost: 15.47s
Train Epoch: 2359 	Average Loss: -13.9876
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0454

Learning rate: 8.688626215093691e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2360 [0/90000 (0%)]	Loss: -6.0223	Cost: 22.27s
Train Epoch: 2360 [20480/90000 (23%)]	Loss: -14.5527	Cost: 10.60s
Train Epoch: 2360 [40960/90000 (45%)]	Loss: -14.8184	Cost: 13.56s
Train Epoch: 2360 [61440/90000 (68%)]	Loss: -14.7721	Cost: 12.40s
Train Epoch: 2360 [81920/90000 (91%)]	Loss: -14.0695	Cost: 12.02s
Train Epoch: 2360 	Average Loss: -13.9660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8395

Learning rate: 8.687565586790846e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2361 [0/90000 (0%)]	Loss: -7.3043	Cost: 26.52s
Train Epoch: 2361 [20480/90000 (23%)]	Loss: -14.3151	Cost: 13.94s
Train Epoch: 2361 [40960/90000 (45%)]	Loss: -15.0682	Cost: 13.83s
Train Epoch: 2361 [61440/90000 (68%)]	Loss: -14.9108	Cost: 12.32s
Train Epoch: 2361 [81920/90000 (91%)]	Loss: -14.6696	Cost: 9.61s
Train Epoch: 2361 	Average Loss: -14.1731
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0359

Learning rate: 8.686504594539869e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2362 [0/90000 (0%)]	Loss: -6.8024	Cost: 35.09s
Train Epoch: 2362 [20480/90000 (23%)]	Loss: -14.5656	Cost: 13.73s
Train Epoch: 2362 [40960/90000 (45%)]	Loss: -14.7309	Cost: 10.23s
Train Epoch: 2362 [61440/90000 (68%)]	Loss: -15.1621	Cost: 6.06s
Train Epoch: 2362 [81920/90000 (91%)]	Loss: -14.7134	Cost: 6.94s
Train Epoch: 2362 	Average Loss: -14.2278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2578

Learning rate: 8.685443238445476e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2363 [0/90000 (0%)]	Loss: -6.2192	Cost: 27.25s
Train Epoch: 2363 [20480/90000 (23%)]	Loss: -14.6132	Cost: 11.34s
Train Epoch: 2363 [40960/90000 (45%)]	Loss: -14.8813	Cost: 9.86s
Train Epoch: 2363 [61440/90000 (68%)]	Loss: -14.8776	Cost: 7.84s
Train Epoch: 2363 [81920/90000 (91%)]	Loss: -14.6692	Cost: 9.06s
Train Epoch: 2363 	Average Loss: -14.2520
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1608

Learning rate: 8.684381518612416e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2364 [0/90000 (0%)]	Loss: -7.2282	Cost: 26.09s
Train Epoch: 2364 [20480/90000 (23%)]	Loss: -14.6436	Cost: 8.92s
Train Epoch: 2364 [40960/90000 (45%)]	Loss: -15.0578	Cost: 9.08s
Train Epoch: 2364 [61440/90000 (68%)]	Loss: -14.9548	Cost: 8.83s
Train Epoch: 2364 [81920/90000 (91%)]	Loss: -14.7142	Cost: 7.95s
Train Epoch: 2364 	Average Loss: -14.3457
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1621

Learning rate: 8.68331943514548e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2365 [0/90000 (0%)]	Loss: -6.0437	Cost: 21.92s
Train Epoch: 2365 [20480/90000 (23%)]	Loss: -14.7872	Cost: 6.91s
Train Epoch: 2365 [40960/90000 (45%)]	Loss: -14.6976	Cost: 7.10s
Train Epoch: 2365 [61440/90000 (68%)]	Loss: -14.8334	Cost: 8.69s
Train Epoch: 2365 [81920/90000 (91%)]	Loss: -14.4717	Cost: 15.68s
Train Epoch: 2365 	Average Loss: -14.0945
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2255

Learning rate: 8.68225698814949e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2366 [0/90000 (0%)]	Loss: -7.0725	Cost: 21.15s
Train Epoch: 2366 [20480/90000 (23%)]	Loss: -14.5842	Cost: 12.03s
Train Epoch: 2366 [40960/90000 (45%)]	Loss: -14.7825	Cost: 15.04s
Train Epoch: 2366 [61440/90000 (68%)]	Loss: -14.9409	Cost: 12.60s
Train Epoch: 2366 [81920/90000 (91%)]	Loss: -14.5622	Cost: 12.13s
Train Epoch: 2366 	Average Loss: -14.2685
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0849

Learning rate: 8.681194177729305e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2367 [0/90000 (0%)]	Loss: -6.5750	Cost: 39.47s
Train Epoch: 2367 [20480/90000 (23%)]	Loss: -14.7106	Cost: 12.36s
Train Epoch: 2367 [40960/90000 (45%)]	Loss: -15.0469	Cost: 12.29s
Train Epoch: 2367 [61440/90000 (68%)]	Loss: -15.0864	Cost: 8.35s
Train Epoch: 2367 [81920/90000 (91%)]	Loss: -14.7450	Cost: 6.18s
Train Epoch: 2367 	Average Loss: -14.3592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3810

Saving model as e2367_model.pt & e2367_waveforms_supplementary.hdf5
Learning rate: 8.680131003989819e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2368 [0/90000 (0%)]	Loss: -6.8160	Cost: 32.94s
Train Epoch: 2368 [20480/90000 (23%)]	Loss: -14.7529	Cost: 8.89s
Train Epoch: 2368 [40960/90000 (45%)]	Loss: -15.1052	Cost: 6.76s
Train Epoch: 2368 [61440/90000 (68%)]	Loss: -15.1138	Cost: 7.20s
Train Epoch: 2368 [81920/90000 (91%)]	Loss: -14.5359	Cost: 8.42s
Train Epoch: 2368 	Average Loss: -14.3091
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2234

Learning rate: 8.679067467035965e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2369 [0/90000 (0%)]	Loss: -6.6733	Cost: 20.46s
Train Epoch: 2369 [20480/90000 (23%)]	Loss: -14.6814	Cost: 8.32s
Train Epoch: 2369 [40960/90000 (45%)]	Loss: -15.0688	Cost: 9.94s
Train Epoch: 2369 [61440/90000 (68%)]	Loss: -14.9704	Cost: 9.22s
Train Epoch: 2369 [81920/90000 (91%)]	Loss: -14.6046	Cost: 9.06s
Train Epoch: 2369 	Average Loss: -14.2662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1297

Learning rate: 8.67800356697271e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2370 [0/90000 (0%)]	Loss: -7.1305	Cost: 20.22s
Train Epoch: 2370 [20480/90000 (23%)]	Loss: -14.7043	Cost: 11.14s
Train Epoch: 2370 [40960/90000 (45%)]	Loss: -14.9015	Cost: 9.83s
Train Epoch: 2370 [61440/90000 (68%)]	Loss: -14.5132	Cost: 9.08s
Train Epoch: 2370 [81920/90000 (91%)]	Loss: -14.1558	Cost: 6.90s
Train Epoch: 2370 	Average Loss: -14.0798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8800

Learning rate: 8.676939303905056e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2371 [0/90000 (0%)]	Loss: -7.0715	Cost: 23.08s
Train Epoch: 2371 [20480/90000 (23%)]	Loss: -14.3136	Cost: 10.76s
Train Epoch: 2371 [40960/90000 (45%)]	Loss: -14.5760	Cost: 15.19s
Train Epoch: 2371 [61440/90000 (68%)]	Loss: -13.7472	Cost: 12.24s
Train Epoch: 2371 [81920/90000 (91%)]	Loss: -13.4168	Cost: 12.37s
Train Epoch: 2371 	Average Loss: -13.5602
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3814

Learning rate: 8.675874677938041e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2372 [0/90000 (0%)]	Loss: -6.4683	Cost: 26.56s
Train Epoch: 2372 [20480/90000 (23%)]	Loss: -13.4757	Cost: 12.87s
Train Epoch: 2372 [40960/90000 (45%)]	Loss: -14.0888	Cost: 12.70s
Train Epoch: 2372 [61440/90000 (68%)]	Loss: -14.4044	Cost: 12.10s
Train Epoch: 2372 [81920/90000 (91%)]	Loss: -14.2624	Cost: 11.18s
Train Epoch: 2372 	Average Loss: -13.4884
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9125

Learning rate: 8.674809689176741e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2373 [0/90000 (0%)]	Loss: -7.1913	Cost: 30.47s
Train Epoch: 2373 [20480/90000 (23%)]	Loss: -14.3178	Cost: 12.17s
Train Epoch: 2373 [40960/90000 (45%)]	Loss: -14.7977	Cost: 12.47s
Train Epoch: 2373 [61440/90000 (68%)]	Loss: -14.9155	Cost: 7.29s
Train Epoch: 2373 [81920/90000 (91%)]	Loss: -14.4690	Cost: 6.42s
Train Epoch: 2373 	Average Loss: -14.1247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3030

Learning rate: 8.673744337726265e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2374 [0/90000 (0%)]	Loss: -7.0892	Cost: 31.82s
Train Epoch: 2374 [20480/90000 (23%)]	Loss: -14.7841	Cost: 12.67s
Train Epoch: 2374 [40960/90000 (45%)]	Loss: -14.8968	Cost: 9.27s
Train Epoch: 2374 [61440/90000 (68%)]	Loss: -14.8858	Cost: 6.90s
Train Epoch: 2374 [81920/90000 (91%)]	Loss: -14.7100	Cost: 8.76s
Train Epoch: 2374 	Average Loss: -14.2749
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2285

Learning rate: 8.67267862369176e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2375 [0/90000 (0%)]	Loss: -6.5900	Cost: 22.40s
Train Epoch: 2375 [20480/90000 (23%)]	Loss: -14.7581	Cost: 10.44s
Train Epoch: 2375 [40960/90000 (45%)]	Loss: -15.0235	Cost: 8.02s
Train Epoch: 2375 [61440/90000 (68%)]	Loss: -14.7147	Cost: 8.18s
Train Epoch: 2375 [81920/90000 (91%)]	Loss: -14.2180	Cost: 9.13s
Train Epoch: 2375 	Average Loss: -14.1790
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9950

Learning rate: 8.671612547178406e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2376 [0/90000 (0%)]	Loss: -6.6397	Cost: 21.61s
Train Epoch: 2376 [20480/90000 (23%)]	Loss: -14.5739	Cost: 8.12s
Train Epoch: 2376 [40960/90000 (45%)]	Loss: -14.8139	Cost: 10.73s
Train Epoch: 2376 [61440/90000 (68%)]	Loss: -15.0609	Cost: 8.77s
Train Epoch: 2376 [81920/90000 (91%)]	Loss: -14.7118	Cost: 8.51s
Train Epoch: 2376 	Average Loss: -14.2337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2954

Learning rate: 8.67054610829142e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2377 [0/90000 (0%)]	Loss: -7.5081	Cost: 25.55s
Train Epoch: 2377 [20480/90000 (23%)]	Loss: -14.5664	Cost: 8.93s
Train Epoch: 2377 [40960/90000 (45%)]	Loss: -14.8818	Cost: 8.94s
Train Epoch: 2377 [61440/90000 (68%)]	Loss: -14.8577	Cost: 8.75s
Train Epoch: 2377 [81920/90000 (91%)]	Loss: -14.7738	Cost: 6.10s
Train Epoch: 2377 	Average Loss: -14.2866
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2579

Learning rate: 8.669479307136058e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2378 [0/90000 (0%)]	Loss: -7.0451	Cost: 26.89s
Train Epoch: 2378 [20480/90000 (23%)]	Loss: -14.7629	Cost: 7.27s
Train Epoch: 2378 [40960/90000 (45%)]	Loss: -14.9889	Cost: 9.48s
Train Epoch: 2378 [61440/90000 (68%)]	Loss: -15.0338	Cost: 9.94s
Train Epoch: 2378 [81920/90000 (91%)]	Loss: -14.7481	Cost: 13.06s
Train Epoch: 2378 	Average Loss: -14.3490
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3127

Learning rate: 8.668412143817608e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2379 [0/90000 (0%)]	Loss: -7.9622	Cost: 27.34s
Train Epoch: 2379 [20480/90000 (23%)]	Loss: -14.6961	Cost: 11.75s
Train Epoch: 2379 [40960/90000 (45%)]	Loss: -15.0055	Cost: 14.30s
Train Epoch: 2379 [61440/90000 (68%)]	Loss: -14.8354	Cost: 12.71s
Train Epoch: 2379 [81920/90000 (91%)]	Loss: -14.4559	Cost: 12.25s
Train Epoch: 2379 	Average Loss: -14.2228
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1173

Learning rate: 8.667344618441395e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2380 [0/90000 (0%)]	Loss: -6.9990	Cost: 23.69s
Train Epoch: 2380 [20480/90000 (23%)]	Loss: -14.6329	Cost: 13.04s
Train Epoch: 2380 [40960/90000 (45%)]	Loss: -14.8875	Cost: 14.59s
Train Epoch: 2380 [61440/90000 (68%)]	Loss: -15.0763	Cost: 12.31s
Train Epoch: 2380 [81920/90000 (91%)]	Loss: -14.1557	Cost: 9.03s
Train Epoch: 2380 	Average Loss: -14.0999
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6879

Learning rate: 8.66627673111278e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2381 [0/90000 (0%)]	Loss: -6.7624	Cost: 27.00s
Train Epoch: 2381 [20480/90000 (23%)]	Loss: -14.2893	Cost: 15.06s
Train Epoch: 2381 [40960/90000 (45%)]	Loss: -14.3220	Cost: 12.64s
Train Epoch: 2381 [61440/90000 (68%)]	Loss: -14.9988	Cost: 10.27s
Train Epoch: 2381 [81920/90000 (91%)]	Loss: -14.4644	Cost: 6.30s
Train Epoch: 2381 	Average Loss: -13.9601
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0013

Learning rate: 8.665208481937155e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2382 [0/90000 (0%)]	Loss: -6.8514	Cost: 29.57s
Train Epoch: 2382 [20480/90000 (23%)]	Loss: -14.9575	Cost: 6.55s
Train Epoch: 2382 [40960/90000 (45%)]	Loss: -14.9598	Cost: 9.86s
Train Epoch: 2382 [61440/90000 (68%)]	Loss: -15.0787	Cost: 8.90s
Train Epoch: 2382 [81920/90000 (91%)]	Loss: -14.7575	Cost: 8.72s
Train Epoch: 2382 	Average Loss: -14.3271
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2195

Learning rate: 8.664139871019957e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2383 [0/90000 (0%)]	Loss: -6.1921	Cost: 26.48s
Train Epoch: 2383 [20480/90000 (23%)]	Loss: -14.3570	Cost: 6.58s
Train Epoch: 2383 [40960/90000 (45%)]	Loss: -14.4095	Cost: 9.78s
Train Epoch: 2383 [61440/90000 (68%)]	Loss: -14.8617	Cost: 8.82s
Train Epoch: 2383 [81920/90000 (91%)]	Loss: -14.3404	Cost: 8.47s
Train Epoch: 2383 	Average Loss: -13.9829
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7577

Learning rate: 8.663070898466652e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2384 [0/90000 (0%)]	Loss: -5.9571	Cost: 21.95s
Train Epoch: 2384 [20480/90000 (23%)]	Loss: -14.1935	Cost: 9.28s
Train Epoch: 2384 [40960/90000 (45%)]	Loss: -14.6765	Cost: 9.80s
Train Epoch: 2384 [61440/90000 (68%)]	Loss: -14.7010	Cost: 7.18s
Train Epoch: 2384 [81920/90000 (91%)]	Loss: -14.2197	Cost: 9.10s
Train Epoch: 2384 	Average Loss: -13.9613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8824

Learning rate: 8.662001564382745e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2385 [0/90000 (0%)]	Loss: -7.2123	Cost: 18.35s
Train Epoch: 2385 [20480/90000 (23%)]	Loss: -14.3812	Cost: 7.07s
Train Epoch: 2385 [40960/90000 (45%)]	Loss: -14.6228	Cost: 14.11s
Train Epoch: 2385 [61440/90000 (68%)]	Loss: -14.8062	Cost: 12.47s
Train Epoch: 2385 [81920/90000 (91%)]	Loss: -14.2792	Cost: 14.32s
Train Epoch: 2385 	Average Loss: -14.0311
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9075

Learning rate: 8.660931868873772e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2386 [0/90000 (0%)]	Loss: -7.9854	Cost: 23.24s
Train Epoch: 2386 [20480/90000 (23%)]	Loss: -14.6000	Cost: 12.36s
Train Epoch: 2386 [40960/90000 (45%)]	Loss: -14.9513	Cost: 14.93s
Train Epoch: 2386 [61440/90000 (68%)]	Loss: -15.0240	Cost: 12.15s
Train Epoch: 2386 [81920/90000 (91%)]	Loss: -14.7231	Cost: 12.03s
Train Epoch: 2386 	Average Loss: -14.3071
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0327

Learning rate: 8.65986181204531e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2387 [0/90000 (0%)]	Loss: -6.1270	Cost: 40.14s
Train Epoch: 2387 [20480/90000 (23%)]	Loss: -14.8656	Cost: 11.80s
Train Epoch: 2387 [40960/90000 (45%)]	Loss: -14.8452	Cost: 12.44s
Train Epoch: 2387 [61440/90000 (68%)]	Loss: -15.0866	Cost: 11.78s
Train Epoch: 2387 [81920/90000 (91%)]	Loss: -14.7288	Cost: 5.99s
Train Epoch: 2387 	Average Loss: -14.2928
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1981

Learning rate: 8.658791394002967e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2388 [0/90000 (0%)]	Loss: -6.9889	Cost: 26.45s
Train Epoch: 2388 [20480/90000 (23%)]	Loss: -14.6044	Cost: 10.74s
Train Epoch: 2388 [40960/90000 (45%)]	Loss: -14.8364	Cost: 8.61s
Train Epoch: 2388 [61440/90000 (68%)]	Loss: -15.0332	Cost: 6.26s
Train Epoch: 2388 [81920/90000 (91%)]	Loss: -14.6630	Cost: 8.01s
Train Epoch: 2388 	Average Loss: -14.2698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3235

Learning rate: 8.65772061485239e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2389 [0/90000 (0%)]	Loss: -7.7042	Cost: 25.65s
Train Epoch: 2389 [20480/90000 (23%)]	Loss: -14.7539	Cost: 8.16s
Train Epoch: 2389 [40960/90000 (45%)]	Loss: -14.6869	Cost: 11.30s
Train Epoch: 2389 [61440/90000 (68%)]	Loss: -15.0063	Cost: 9.10s
Train Epoch: 2389 [81920/90000 (91%)]	Loss: -14.7584	Cost: 9.21s
Train Epoch: 2389 	Average Loss: -14.2912
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2307

Learning rate: 8.656649474699263e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2390 [0/90000 (0%)]	Loss: -6.2516	Cost: 23.56s
Train Epoch: 2390 [20480/90000 (23%)]	Loss: -14.6663	Cost: 12.02s
Train Epoch: 2390 [40960/90000 (45%)]	Loss: -14.8454	Cost: 9.98s
Train Epoch: 2390 [61440/90000 (68%)]	Loss: -14.8633	Cost: 6.88s
Train Epoch: 2390 [81920/90000 (91%)]	Loss: -14.4438	Cost: 6.46s
Train Epoch: 2390 	Average Loss: -14.1550
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0656

Learning rate: 8.6555779736493e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2391 [0/90000 (0%)]	Loss: -6.2677	Cost: 22.68s
Train Epoch: 2391 [20480/90000 (23%)]	Loss: -13.8927	Cost: 6.81s
Train Epoch: 2391 [40960/90000 (45%)]	Loss: -14.2218	Cost: 8.34s
Train Epoch: 2391 [61440/90000 (68%)]	Loss: -14.4765	Cost: 10.37s
Train Epoch: 2391 [81920/90000 (91%)]	Loss: -14.3555	Cost: 13.74s
Train Epoch: 2391 	Average Loss: -13.7146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9152

Learning rate: 8.654506111808257e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2392 [0/90000 (0%)]	Loss: -6.4682	Cost: 21.80s
Train Epoch: 2392 [20480/90000 (23%)]	Loss: -14.5524	Cost: 8.64s
Train Epoch: 2392 [40960/90000 (45%)]	Loss: -14.6327	Cost: 15.19s
Train Epoch: 2392 [61440/90000 (68%)]	Loss: -14.7851	Cost: 12.27s
Train Epoch: 2392 [81920/90000 (91%)]	Loss: -14.6355	Cost: 12.25s
Train Epoch: 2392 	Average Loss: -14.1857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1979

Learning rate: 8.65343388928192e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2393 [0/90000 (0%)]	Loss: -6.7726	Cost: 30.18s
Train Epoch: 2393 [20480/90000 (23%)]	Loss: -14.8271	Cost: 10.95s
Train Epoch: 2393 [40960/90000 (45%)]	Loss: -14.9898	Cost: 13.81s
Train Epoch: 2393 [61440/90000 (68%)]	Loss: -14.9876	Cost: 12.32s
Train Epoch: 2393 [81920/90000 (91%)]	Loss: -14.8800	Cost: 7.79s
Train Epoch: 2393 	Average Loss: -14.3838
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2549

Learning rate: 8.652361306176113e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2394 [0/90000 (0%)]	Loss: -7.5930	Cost: 33.63s
Train Epoch: 2394 [20480/90000 (23%)]	Loss: -14.6869	Cost: 13.56s
Train Epoch: 2394 [40960/90000 (45%)]	Loss: -14.8630	Cost: 11.91s
Train Epoch: 2394 [61440/90000 (68%)]	Loss: -15.0681	Cost: 6.58s
Train Epoch: 2394 [81920/90000 (91%)]	Loss: -14.4414	Cost: 6.20s
Train Epoch: 2394 	Average Loss: -14.3106
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0204

Learning rate: 8.651288362596698e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2395 [0/90000 (0%)]	Loss: -6.9933	Cost: 27.74s
Train Epoch: 2395 [20480/90000 (23%)]	Loss: -14.4762	Cost: 11.06s
Train Epoch: 2395 [40960/90000 (45%)]	Loss: -14.7471	Cost: 9.62s
Train Epoch: 2395 [61440/90000 (68%)]	Loss: -15.0035	Cost: 8.77s
Train Epoch: 2395 [81920/90000 (91%)]	Loss: -14.8711	Cost: 8.85s
Train Epoch: 2395 	Average Loss: -14.2143
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2892

Learning rate: 8.650215058649567e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2396 [0/90000 (0%)]	Loss: -6.5947	Cost: 22.73s
Train Epoch: 2396 [20480/90000 (23%)]	Loss: -14.7367	Cost: 8.36s
Train Epoch: 2396 [40960/90000 (45%)]	Loss: -14.7596	Cost: 8.99s
Train Epoch: 2396 [61440/90000 (68%)]	Loss: -15.0103	Cost: 8.70s
Train Epoch: 2396 [81920/90000 (91%)]	Loss: -14.7276	Cost: 9.05s
Train Epoch: 2396 	Average Loss: -14.2633
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2810

Learning rate: 8.649141394440657e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2397 [0/90000 (0%)]	Loss: -7.7960	Cost: 21.52s
Train Epoch: 2397 [20480/90000 (23%)]	Loss: -14.8096	Cost: 9.17s
Train Epoch: 2397 [40960/90000 (45%)]	Loss: -14.9038	Cost: 8.95s
Train Epoch: 2397 [61440/90000 (68%)]	Loss: -14.8923	Cost: 7.94s
Train Epoch: 2397 [81920/90000 (91%)]	Loss: -14.7036	Cost: 6.39s
Train Epoch: 2397 	Average Loss: -14.2809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9635

Learning rate: 8.648067370075927e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2398 [0/90000 (0%)]	Loss: -6.5005	Cost: 18.22s
Train Epoch: 2398 [20480/90000 (23%)]	Loss: -14.5041	Cost: 7.54s
Train Epoch: 2398 [40960/90000 (45%)]	Loss: -14.6985	Cost: 11.24s
Train Epoch: 2398 [61440/90000 (68%)]	Loss: -14.8041	Cost: 12.22s
Train Epoch: 2398 [81920/90000 (91%)]	Loss: -14.4931	Cost: 12.38s
Train Epoch: 2398 	Average Loss: -14.1204
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1482

Learning rate: 8.646992985661383e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2399 [0/90000 (0%)]	Loss: -7.8161	Cost: 21.38s
Train Epoch: 2399 [20480/90000 (23%)]	Loss: -14.7585	Cost: 9.68s
Train Epoch: 2399 [40960/90000 (45%)]	Loss: -14.8389	Cost: 9.94s
Train Epoch: 2399 [61440/90000 (68%)]	Loss: -15.0846	Cost: 14.77s
Train Epoch: 2399 [81920/90000 (91%)]	Loss: -14.7138	Cost: 12.47s
Train Epoch: 2399 	Average Loss: -14.3404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9940

Learning rate: 8.645918241303062e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2400 [0/90000 (0%)]	Loss: -6.8814	Cost: 20.99s
Train Epoch: 2400 [20480/90000 (23%)]	Loss: -14.7128	Cost: 12.60s
Train Epoch: 2400 [40960/90000 (45%)]	Loss: -14.5137	Cost: 15.37s
Train Epoch: 2400 [61440/90000 (68%)]	Loss: -14.9156	Cost: 11.95s
Train Epoch: 2400 [81920/90000 (91%)]	Loss: -14.5627	Cost: 12.00s
Train Epoch: 2400 	Average Loss: -14.2008
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0325

Learning rate: 8.644843137107037e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2401 [0/90000 (0%)]	Loss: -6.9610	Cost: 33.73s
Train Epoch: 2401 [20480/90000 (23%)]	Loss: -14.8401	Cost: 14.04s
Train Epoch: 2401 [40960/90000 (45%)]	Loss: -14.8844	Cost: 12.73s
Train Epoch: 2401 [61440/90000 (68%)]	Loss: -14.7841	Cost: 12.14s
Train Epoch: 2401 [81920/90000 (91%)]	Loss: -14.6015	Cost: 10.96s
Train Epoch: 2401 	Average Loss: -14.2526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1502

Learning rate: 8.643767673179416e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2402 [0/90000 (0%)]	Loss: -7.5152	Cost: 29.65s
Train Epoch: 2402 [20480/90000 (23%)]	Loss: -14.8014	Cost: 10.61s
Train Epoch: 2402 [40960/90000 (45%)]	Loss: -14.9843	Cost: 12.10s
Train Epoch: 2402 [61440/90000 (68%)]	Loss: -15.1650	Cost: 6.34s
Train Epoch: 2402 [81920/90000 (91%)]	Loss: -14.7965	Cost: 6.22s
Train Epoch: 2402 	Average Loss: -14.3766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0818

Learning rate: 8.642691849626344e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2403 [0/90000 (0%)]	Loss: -7.8330	Cost: 20.59s
Train Epoch: 2403 [20480/90000 (23%)]	Loss: -14.7884	Cost: 7.51s
Train Epoch: 2403 [40960/90000 (45%)]	Loss: -14.9878	Cost: 9.07s
Train Epoch: 2403 [61440/90000 (68%)]	Loss: -14.7997	Cost: 9.25s
Train Epoch: 2403 [81920/90000 (91%)]	Loss: -14.9244	Cost: 8.86s
Train Epoch: 2403 	Average Loss: -14.4345
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1371

Learning rate: 8.641615666553999e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2404 [0/90000 (0%)]	Loss: -7.5935	Cost: 27.42s
Train Epoch: 2404 [20480/90000 (23%)]	Loss: -14.7653	Cost: 9.07s
Train Epoch: 2404 [40960/90000 (45%)]	Loss: -14.9511	Cost: 8.90s
Train Epoch: 2404 [61440/90000 (68%)]	Loss: -14.9102	Cost: 8.63s
Train Epoch: 2404 [81920/90000 (91%)]	Loss: -14.7163	Cost: 6.34s
Train Epoch: 2404 	Average Loss: -14.3293
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2054

Learning rate: 8.640539124068596e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2405 [0/90000 (0%)]	Loss: -7.2989	Cost: 27.34s
Train Epoch: 2405 [20480/90000 (23%)]	Loss: -14.6912	Cost: 8.80s
Train Epoch: 2405 [40960/90000 (45%)]	Loss: -14.9682	Cost: 6.37s
Train Epoch: 2405 [61440/90000 (68%)]	Loss: -15.0365	Cost: 6.49s
Train Epoch: 2405 [81920/90000 (91%)]	Loss: -14.6953	Cost: 10.79s
Train Epoch: 2405 	Average Loss: -14.3224
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2377

Learning rate: 8.639462222276387e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2406 [0/90000 (0%)]	Loss: -7.5372	Cost: 21.35s
Train Epoch: 2406 [20480/90000 (23%)]	Loss: -14.7418	Cost: 9.23s
Train Epoch: 2406 [40960/90000 (45%)]	Loss: -14.9187	Cost: 9.31s
Train Epoch: 2406 [61440/90000 (68%)]	Loss: -14.9870	Cost: 10.87s
Train Epoch: 2406 [81920/90000 (91%)]	Loss: -14.7383	Cost: 12.43s
Train Epoch: 2406 	Average Loss: -14.3203
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1176

Learning rate: 8.638384961283658e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2407 [0/90000 (0%)]	Loss: -5.4053	Cost: 21.57s
Train Epoch: 2407 [20480/90000 (23%)]	Loss: -14.6349	Cost: 8.11s
Train Epoch: 2407 [40960/90000 (45%)]	Loss: -14.5373	Cost: 11.17s
Train Epoch: 2407 [61440/90000 (68%)]	Loss: -14.6207	Cost: 12.46s
Train Epoch: 2407 [81920/90000 (91%)]	Loss: -14.1868	Cost: 12.47s
Train Epoch: 2407 	Average Loss: -14.0622
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9688

Learning rate: 8.63730734119673e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2408 [0/90000 (0%)]	Loss: -7.3845	Cost: 22.62s
Train Epoch: 2408 [20480/90000 (23%)]	Loss: -14.5648	Cost: 14.29s
Train Epoch: 2408 [40960/90000 (45%)]	Loss: -14.7418	Cost: 12.56s
Train Epoch: 2408 [61440/90000 (68%)]	Loss: -14.8235	Cost: 12.14s
Train Epoch: 2408 [81920/90000 (91%)]	Loss: -14.5924	Cost: 12.53s
Train Epoch: 2408 	Average Loss: -14.1903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1899

Learning rate: 8.636229362121958e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2409 [0/90000 (0%)]	Loss: -7.5844	Cost: 24.99s
Train Epoch: 2409 [20480/90000 (23%)]	Loss: -14.7575	Cost: 12.99s
Train Epoch: 2409 [40960/90000 (45%)]	Loss: -14.9473	Cost: 12.38s
Train Epoch: 2409 [61440/90000 (68%)]	Loss: -14.9586	Cost: 6.83s
Train Epoch: 2409 [81920/90000 (91%)]	Loss: -14.4309	Cost: 6.36s
Train Epoch: 2409 	Average Loss: -14.2665
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9738

Learning rate: 8.635151024165737e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2410 [0/90000 (0%)]	Loss: -7.5392	Cost: 32.21s
Train Epoch: 2410 [20480/90000 (23%)]	Loss: -14.5811	Cost: 11.33s
Train Epoch: 2410 [40960/90000 (45%)]	Loss: -14.6637	Cost: 12.08s
Train Epoch: 2410 [61440/90000 (68%)]	Loss: -14.6252	Cost: 6.45s
Train Epoch: 2410 [81920/90000 (91%)]	Loss: -14.5121	Cost: 6.39s
Train Epoch: 2410 	Average Loss: -14.1842
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3226

Learning rate: 8.634072327434493e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2411 [0/90000 (0%)]	Loss: -7.7444	Cost: 23.50s
Train Epoch: 2411 [20480/90000 (23%)]	Loss: -14.7051	Cost: 10.06s
Train Epoch: 2411 [40960/90000 (45%)]	Loss: -14.8434	Cost: 12.15s
Train Epoch: 2411 [61440/90000 (68%)]	Loss: -14.8947	Cost: 7.51s
Train Epoch: 2411 [81920/90000 (91%)]	Loss: -14.6343	Cost: 6.45s
Train Epoch: 2411 	Average Loss: -14.3140
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3241

Learning rate: 8.63299327203469e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2412 [0/90000 (0%)]	Loss: -7.7824	Cost: 22.78s
Train Epoch: 2412 [20480/90000 (23%)]	Loss: -15.0726	Cost: 8.01s
Train Epoch: 2412 [40960/90000 (45%)]	Loss: -15.0900	Cost: 8.34s
Train Epoch: 2412 [61440/90000 (68%)]	Loss: -14.8631	Cost: 7.89s
Train Epoch: 2412 [81920/90000 (91%)]	Loss: -14.6500	Cost: 8.64s
Train Epoch: 2412 	Average Loss: -14.3385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1255

Learning rate: 8.631913858072824e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2413 [0/90000 (0%)]	Loss: -7.1574	Cost: 28.66s
Train Epoch: 2413 [20480/90000 (23%)]	Loss: -14.7536	Cost: 6.81s
Train Epoch: 2413 [40960/90000 (45%)]	Loss: -14.7123	Cost: 9.23s
Train Epoch: 2413 [61440/90000 (68%)]	Loss: -14.7755	Cost: 8.57s
Train Epoch: 2413 [81920/90000 (91%)]	Loss: -14.2691	Cost: 8.49s
Train Epoch: 2413 	Average Loss: -14.1519
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1719

Learning rate: 8.630834085655434e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2414 [0/90000 (0%)]	Loss: -7.2665	Cost: 29.26s
Train Epoch: 2414 [20480/90000 (23%)]	Loss: -14.5833	Cost: 8.81s
Train Epoch: 2414 [40960/90000 (45%)]	Loss: -14.6233	Cost: 8.86s
Train Epoch: 2414 [61440/90000 (68%)]	Loss: -14.7383	Cost: 8.41s
Train Epoch: 2414 [81920/90000 (91%)]	Loss: -14.3108	Cost: 8.35s
Train Epoch: 2414 	Average Loss: -14.1917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0821

Learning rate: 8.629753954889085e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2415 [0/90000 (0%)]	Loss: -7.2574	Cost: 26.50s
Train Epoch: 2415 [20480/90000 (23%)]	Loss: -14.8522	Cost: 7.39s
Train Epoch: 2415 [40960/90000 (45%)]	Loss: -14.8692	Cost: 10.81s
Train Epoch: 2415 [61440/90000 (68%)]	Loss: -14.7531	Cost: 11.60s
Train Epoch: 2415 [81920/90000 (91%)]	Loss: -14.5878	Cost: 13.25s
Train Epoch: 2415 	Average Loss: -14.2389
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2139

Learning rate: 8.628673465880384e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2416 [0/90000 (0%)]	Loss: -6.8996	Cost: 20.00s
Train Epoch: 2416 [20480/90000 (23%)]	Loss: -14.8815	Cost: 7.03s
Train Epoch: 2416 [40960/90000 (45%)]	Loss: -15.2190	Cost: 14.47s
Train Epoch: 2416 [61440/90000 (68%)]	Loss: -15.0173	Cost: 14.22s
Train Epoch: 2416 [81920/90000 (91%)]	Loss: -14.6925	Cost: 13.37s
Train Epoch: 2416 	Average Loss: -14.4249
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2003

Learning rate: 8.627592618735969e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2417 [0/90000 (0%)]	Loss: -6.7864	Cost: 28.64s
Train Epoch: 2417 [20480/90000 (23%)]	Loss: -14.6437	Cost: 15.21s
Train Epoch: 2417 [40960/90000 (45%)]	Loss: -14.7760	Cost: 13.32s
Train Epoch: 2417 [61440/90000 (68%)]	Loss: -14.6942	Cost: 12.20s
Train Epoch: 2417 [81920/90000 (91%)]	Loss: -14.4578	Cost: 8.29s
Train Epoch: 2417 	Average Loss: -14.0954
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0510

Learning rate: 8.626511413562516e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2418 [0/90000 (0%)]	Loss: -7.1946	Cost: 35.99s
Train Epoch: 2418 [20480/90000 (23%)]	Loss: -14.7159	Cost: 11.97s
Train Epoch: 2418 [40960/90000 (45%)]	Loss: -14.6622	Cost: 10.88s
Train Epoch: 2418 [61440/90000 (68%)]	Loss: -14.6941	Cost: 6.31s
Train Epoch: 2418 [81920/90000 (91%)]	Loss: -14.4197	Cost: 6.97s
Train Epoch: 2418 	Average Loss: -14.1171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9087

Learning rate: 8.625429850466735e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2419 [0/90000 (0%)]	Loss: -7.6084	Cost: 23.14s
Train Epoch: 2419 [20480/90000 (23%)]	Loss: -14.6801	Cost: 7.67s
Train Epoch: 2419 [40960/90000 (45%)]	Loss: -14.8587	Cost: 8.79s
Train Epoch: 2419 [61440/90000 (68%)]	Loss: -14.7949	Cost: 8.63s
Train Epoch: 2419 [81920/90000 (91%)]	Loss: -14.5466	Cost: 8.67s
Train Epoch: 2419 	Average Loss: -14.2086
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1879

Learning rate: 8.624347929555375e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2420 [0/90000 (0%)]	Loss: -7.2636	Cost: 23.68s
Train Epoch: 2420 [20480/90000 (23%)]	Loss: -14.8089	Cost: 11.20s
Train Epoch: 2420 [40960/90000 (45%)]	Loss: -14.9996	Cost: 9.04s
Train Epoch: 2420 [61440/90000 (68%)]	Loss: -14.2501	Cost: 8.71s
Train Epoch: 2420 [81920/90000 (91%)]	Loss: -13.8233	Cost: 10.06s
Train Epoch: 2420 	Average Loss: -14.0498
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5971

Learning rate: 8.623265650935214e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2421 [0/90000 (0%)]	Loss: -7.2718	Cost: 19.05s
Train Epoch: 2421 [20480/90000 (23%)]	Loss: -14.1190	Cost: 9.03s
Train Epoch: 2421 [40960/90000 (45%)]	Loss: -14.7609	Cost: 18.77s
Train Epoch: 2421 [61440/90000 (68%)]	Loss: -14.6675	Cost: 14.27s
Train Epoch: 2421 [81920/90000 (91%)]	Loss: -14.1266	Cost: 12.74s
Train Epoch: 2421 	Average Loss: -13.8641
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9162

Learning rate: 8.62218301471307e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2422 [0/90000 (0%)]	Loss: -7.3794	Cost: 27.14s
Train Epoch: 2422 [20480/90000 (23%)]	Loss: -14.5698	Cost: 14.30s
Train Epoch: 2422 [40960/90000 (45%)]	Loss: -14.9016	Cost: 12.54s
Train Epoch: 2422 [61440/90000 (68%)]	Loss: -14.9533	Cost: 12.41s
Train Epoch: 2422 [81920/90000 (91%)]	Loss: -14.4827	Cost: 12.57s
Train Epoch: 2422 	Average Loss: -14.2330
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2156

Learning rate: 8.621100020995792e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2423 [0/90000 (0%)]	Loss: -7.5981	Cost: 24.22s
Train Epoch: 2423 [20480/90000 (23%)]	Loss: -14.6514	Cost: 10.89s
Train Epoch: 2423 [40960/90000 (45%)]	Loss: -14.9545	Cost: 12.57s
Train Epoch: 2423 [61440/90000 (68%)]	Loss: -14.9544	Cost: 12.05s
Train Epoch: 2423 [81920/90000 (91%)]	Loss: -14.2661	Cost: 7.88s
Train Epoch: 2423 	Average Loss: -14.2698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0716

Learning rate: 8.620016669890272e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2424 [0/90000 (0%)]	Loss: -7.0926	Cost: 29.10s
Train Epoch: 2424 [20480/90000 (23%)]	Loss: -14.6923	Cost: 12.21s
Train Epoch: 2424 [40960/90000 (45%)]	Loss: -15.0676	Cost: 10.94s
Train Epoch: 2424 [61440/90000 (68%)]	Loss: -14.9126	Cost: 6.39s
Train Epoch: 2424 [81920/90000 (91%)]	Loss: -14.5794	Cost: 6.32s
Train Epoch: 2424 	Average Loss: -14.3202
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2698

Learning rate: 8.618932961503431e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2425 [0/90000 (0%)]	Loss: -7.2380	Cost: 25.13s
Train Epoch: 2425 [20480/90000 (23%)]	Loss: -15.0185	Cost: 7.79s
Train Epoch: 2425 [40960/90000 (45%)]	Loss: -15.2864	Cost: 11.41s
Train Epoch: 2425 [61440/90000 (68%)]	Loss: -15.1724	Cost: 9.15s
Train Epoch: 2425 [81920/90000 (91%)]	Loss: -14.3952	Cost: 8.86s
Train Epoch: 2425 	Average Loss: -14.4154
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2202

Learning rate: 8.617848895942225e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2426 [0/90000 (0%)]	Loss: -6.9609	Cost: 25.88s
Train Epoch: 2426 [20480/90000 (23%)]	Loss: -14.8642	Cost: 11.91s
Train Epoch: 2426 [40960/90000 (45%)]	Loss: -14.9647	Cost: 10.52s
Train Epoch: 2426 [61440/90000 (68%)]	Loss: -15.0433	Cost: 8.79s
Train Epoch: 2426 [81920/90000 (91%)]	Loss: -14.6361	Cost: 7.51s
Train Epoch: 2426 	Average Loss: -14.3616
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2695

Learning rate: 8.61676447331365e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2427 [0/90000 (0%)]	Loss: -7.5737	Cost: 21.95s
Train Epoch: 2427 [20480/90000 (23%)]	Loss: -14.8300	Cost: 6.73s
Train Epoch: 2427 [40960/90000 (45%)]	Loss: -15.1738	Cost: 9.05s
Train Epoch: 2427 [61440/90000 (68%)]	Loss: -15.1441	Cost: 10.60s
Train Epoch: 2427 [81920/90000 (91%)]	Loss: -14.7975	Cost: 12.31s
Train Epoch: 2427 	Average Loss: -14.5405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4048

Saving model as e2427_model.pt & e2427_waveforms_supplementary.hdf5
Learning rate: 8.61567969372473e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2428 [0/90000 (0%)]	Loss: -7.4985	Cost: 23.91s
Train Epoch: 2428 [20480/90000 (23%)]	Loss: -14.8542	Cost: 13.48s
Train Epoch: 2428 [40960/90000 (45%)]	Loss: -15.0467	Cost: 12.45s
Train Epoch: 2428 [61440/90000 (68%)]	Loss: -15.1259	Cost: 12.40s
Train Epoch: 2428 [81920/90000 (91%)]	Loss: -15.0746	Cost: 12.72s
Train Epoch: 2428 	Average Loss: -14.5427
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3448

Learning rate: 8.614594557282532e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2429 [0/90000 (0%)]	Loss: -7.2506	Cost: 25.95s
Train Epoch: 2429 [20480/90000 (23%)]	Loss: -15.2539	Cost: 14.31s
Train Epoch: 2429 [40960/90000 (45%)]	Loss: -15.2662	Cost: 12.34s
Train Epoch: 2429 [61440/90000 (68%)]	Loss: -15.2102	Cost: 7.87s
Train Epoch: 2429 [81920/90000 (91%)]	Loss: -14.8952	Cost: 6.11s
Train Epoch: 2429 	Average Loss: -14.5789
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4442

Saving model as e2429_model.pt & e2429_waveforms_supplementary.hdf5
Learning rate: 8.613509064094152e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2430 [0/90000 (0%)]	Loss: -6.5753	Cost: 33.21s
Train Epoch: 2430 [20480/90000 (23%)]	Loss: -14.8873	Cost: 8.58s
Train Epoch: 2430 [40960/90000 (45%)]	Loss: -15.2144	Cost: 6.66s
Train Epoch: 2430 [61440/90000 (68%)]	Loss: -15.1728	Cost: 8.51s
Train Epoch: 2430 [81920/90000 (91%)]	Loss: -14.8763	Cost: 8.54s
Train Epoch: 2430 	Average Loss: -14.4955
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2855

Learning rate: 8.612423214266726e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2431 [0/90000 (0%)]	Loss: -7.6357	Cost: 24.31s
Train Epoch: 2431 [20480/90000 (23%)]	Loss: -14.9845	Cost: 8.30s
Train Epoch: 2431 [40960/90000 (45%)]	Loss: -15.4995	Cost: 9.02s
Train Epoch: 2431 [61440/90000 (68%)]	Loss: -15.2529	Cost: 8.80s
Train Epoch: 2431 [81920/90000 (91%)]	Loss: -14.8320	Cost: 8.57s
Train Epoch: 2431 	Average Loss: -14.5055
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3895

Learning rate: 8.611337007907424e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2432 [0/90000 (0%)]	Loss: -6.5578	Cost: 20.94s
Train Epoch: 2432 [20480/90000 (23%)]	Loss: -15.1510	Cost: 9.77s
Train Epoch: 2432 [40960/90000 (45%)]	Loss: -14.7245	Cost: 8.89s
Train Epoch: 2432 [61440/90000 (68%)]	Loss: -14.9877	Cost: 8.71s
Train Epoch: 2432 [81920/90000 (91%)]	Loss: -14.7210	Cost: 7.16s
Train Epoch: 2432 	Average Loss: -14.4049
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1595

Learning rate: 8.610250445123448e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2433 [0/90000 (0%)]	Loss: -6.7589	Cost: 19.00s
Train Epoch: 2433 [20480/90000 (23%)]	Loss: -14.6994	Cost: 6.88s
Train Epoch: 2433 [40960/90000 (45%)]	Loss: -15.0633	Cost: 11.21s
Train Epoch: 2433 [61440/90000 (68%)]	Loss: -15.1664	Cost: 14.94s
Train Epoch: 2433 [81920/90000 (91%)]	Loss: -14.8763	Cost: 14.20s
Train Epoch: 2433 	Average Loss: -14.4265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4362

Learning rate: 8.609163526022036e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2434 [0/90000 (0%)]	Loss: -7.7714	Cost: 24.11s
Train Epoch: 2434 [20480/90000 (23%)]	Loss: -15.1938	Cost: 15.11s
Train Epoch: 2434 [40960/90000 (45%)]	Loss: -15.2112	Cost: 13.76s
Train Epoch: 2434 [61440/90000 (68%)]	Loss: -15.0999	Cost: 12.21s
Train Epoch: 2434 [81920/90000 (91%)]	Loss: -14.6210	Cost: 12.12s
Train Epoch: 2434 	Average Loss: -14.5086
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3386

Learning rate: 8.608076250710467e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2435 [0/90000 (0%)]	Loss: -6.6703	Cost: 33.17s
Train Epoch: 2435 [20480/90000 (23%)]	Loss: -15.1281	Cost: 11.11s
Train Epoch: 2435 [40960/90000 (45%)]	Loss: -15.2138	Cost: 12.71s
Train Epoch: 2435 [61440/90000 (68%)]	Loss: -15.1838	Cost: 11.95s
Train Epoch: 2435 [81920/90000 (91%)]	Loss: -14.8544	Cost: 6.01s
Train Epoch: 2435 	Average Loss: -14.4951
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3783

Learning rate: 8.606988619296048e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2436 [0/90000 (0%)]	Loss: -7.8804	Cost: 25.72s
Train Epoch: 2436 [20480/90000 (23%)]	Loss: -14.9145	Cost: 9.25s
Train Epoch: 2436 [40960/90000 (45%)]	Loss: -14.9942	Cost: 6.62s
Train Epoch: 2436 [61440/90000 (68%)]	Loss: -15.1303	Cost: 7.22s
Train Epoch: 2436 [81920/90000 (91%)]	Loss: -14.6525	Cost: 8.74s
Train Epoch: 2436 	Average Loss: -14.4231
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3384

Learning rate: 8.605900631886124e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2437 [0/90000 (0%)]	Loss: -6.9040	Cost: 21.89s
Train Epoch: 2437 [20480/90000 (23%)]	Loss: -14.7661	Cost: 7.53s
Train Epoch: 2437 [40960/90000 (45%)]	Loss: -15.3208	Cost: 11.32s
Train Epoch: 2437 [61440/90000 (68%)]	Loss: -15.2237	Cost: 9.03s
Train Epoch: 2437 [81920/90000 (91%)]	Loss: -14.9198	Cost: 8.78s
Train Epoch: 2437 	Average Loss: -14.5305
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3143

Learning rate: 8.604812288588077e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2438 [0/90000 (0%)]	Loss: -8.1345	Cost: 23.43s
Train Epoch: 2438 [20480/90000 (23%)]	Loss: -15.1894	Cost: 11.59s
Train Epoch: 2438 [40960/90000 (45%)]	Loss: -15.3052	Cost: 10.43s
Train Epoch: 2438 [61440/90000 (68%)]	Loss: -15.3019	Cost: 7.72s
Train Epoch: 2438 [81920/90000 (91%)]	Loss: -14.9220	Cost: 6.56s
Train Epoch: 2438 	Average Loss: -14.6614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4673

Saving model as e2438_model.pt & e2438_waveforms_supplementary.hdf5
Learning rate: 8.60372358950932e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2439 [0/90000 (0%)]	Loss: -7.6510	Cost: 22.03s
Train Epoch: 2439 [20480/90000 (23%)]	Loss: -15.2130	Cost: 9.05s
Train Epoch: 2439 [40960/90000 (45%)]	Loss: -15.4357	Cost: 12.59s
Train Epoch: 2439 [61440/90000 (68%)]	Loss: -14.9842	Cost: 12.48s
Train Epoch: 2439 [81920/90000 (91%)]	Loss: -14.7840	Cost: 12.50s
Train Epoch: 2439 	Average Loss: -14.5989
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4680

Saving model as e2439_model.pt & e2439_waveforms_supplementary.hdf5
Learning rate: 8.602634534757304e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2440 [0/90000 (0%)]	Loss: -7.1808	Cost: 23.50s
Train Epoch: 2440 [20480/90000 (23%)]	Loss: -14.9294	Cost: 10.16s
Train Epoch: 2440 [40960/90000 (45%)]	Loss: -15.2719	Cost: 13.82s
Train Epoch: 2440 [61440/90000 (68%)]	Loss: -15.2070	Cost: 12.14s
Train Epoch: 2440 [81920/90000 (91%)]	Loss: -14.8730	Cost: 12.39s
Train Epoch: 2440 	Average Loss: -14.5526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5475

Saving model as e2440_model.pt & e2440_waveforms_supplementary.hdf5
Learning rate: 8.601545124439513e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2441 [0/90000 (0%)]	Loss: -6.9103	Cost: 26.80s
Train Epoch: 2441 [20480/90000 (23%)]	Loss: -15.0388	Cost: 12.52s
Train Epoch: 2441 [40960/90000 (45%)]	Loss: -15.2181	Cost: 12.70s
Train Epoch: 2441 [61440/90000 (68%)]	Loss: -15.3002	Cost: 11.13s
Train Epoch: 2441 [81920/90000 (91%)]	Loss: -15.0178	Cost: 7.27s
Train Epoch: 2441 	Average Loss: -14.6826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5936

Saving model as e2441_model.pt & e2441_waveforms_supplementary.hdf5
Learning rate: 8.60045535866347e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2442 [0/90000 (0%)]	Loss: -7.3220	Cost: 22.92s
Train Epoch: 2442 [20480/90000 (23%)]	Loss: -15.2343	Cost: 13.06s
Train Epoch: 2442 [40960/90000 (45%)]	Loss: -15.2041	Cost: 7.21s
Train Epoch: 2442 [61440/90000 (68%)]	Loss: -15.4466	Cost: 6.38s
Train Epoch: 2442 [81920/90000 (91%)]	Loss: -14.9456	Cost: 8.28s
Train Epoch: 2442 	Average Loss: -14.7017
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4285

Learning rate: 8.599365237536731e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2443 [0/90000 (0%)]	Loss: -7.6668	Cost: 32.52s
Train Epoch: 2443 [20480/90000 (23%)]	Loss: -15.1592	Cost: 9.91s
Train Epoch: 2443 [40960/90000 (45%)]	Loss: -15.4006	Cost: 9.19s
Train Epoch: 2443 [61440/90000 (68%)]	Loss: -15.5054	Cost: 7.94s
Train Epoch: 2443 [81920/90000 (91%)]	Loss: -14.8959	Cost: 8.61s
Train Epoch: 2443 	Average Loss: -14.7512
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4758

Learning rate: 8.598274761166882e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2444 [0/90000 (0%)]	Loss: -7.6355	Cost: 22.01s
Train Epoch: 2444 [20480/90000 (23%)]	Loss: -15.2372	Cost: 10.45s
Train Epoch: 2444 [40960/90000 (45%)]	Loss: -15.2313	Cost: 10.36s
Train Epoch: 2444 [61440/90000 (68%)]	Loss: -15.6185	Cost: 9.66s
Train Epoch: 2444 [81920/90000 (91%)]	Loss: -15.0244	Cost: 8.83s
Train Epoch: 2444 	Average Loss: -14.7715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5977

Saving model as e2444_model.pt & e2444_waveforms_supplementary.hdf5
Learning rate: 8.597183929661553e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2445 [0/90000 (0%)]	Loss: -7.6999	Cost: 25.33s
Train Epoch: 2445 [20480/90000 (23%)]	Loss: -15.3629	Cost: 8.95s
Train Epoch: 2445 [40960/90000 (45%)]	Loss: -15.1558	Cost: 8.81s
Train Epoch: 2445 [61440/90000 (68%)]	Loss: -15.3203	Cost: 9.04s
Train Epoch: 2445 [81920/90000 (91%)]	Loss: -14.8376	Cost: 7.52s
Train Epoch: 2445 	Average Loss: -14.6848
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5603

Learning rate: 8.596092743128403e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2446 [0/90000 (0%)]	Loss: -7.1657	Cost: 20.71s
Train Epoch: 2446 [20480/90000 (23%)]	Loss: -15.2300	Cost: 7.20s
Train Epoch: 2446 [40960/90000 (45%)]	Loss: -15.3415	Cost: 9.82s
Train Epoch: 2446 [61440/90000 (68%)]	Loss: -15.4411	Cost: 12.47s
Train Epoch: 2446 [81920/90000 (91%)]	Loss: -15.0417	Cost: 12.81s
Train Epoch: 2446 	Average Loss: -14.7099
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5733

Learning rate: 8.595001201675128e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2447 [0/90000 (0%)]	Loss: -7.9419	Cost: 22.91s
Train Epoch: 2447 [20480/90000 (23%)]	Loss: -15.2382	Cost: 12.71s
Train Epoch: 2447 [40960/90000 (45%)]	Loss: -15.2833	Cost: 13.10s
Train Epoch: 2447 [61440/90000 (68%)]	Loss: -15.4438	Cost: 12.21s
Train Epoch: 2447 [81920/90000 (91%)]	Loss: -14.9712	Cost: 12.27s
Train Epoch: 2447 	Average Loss: -14.6745
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4882

Learning rate: 8.59390930540946e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2448 [0/90000 (0%)]	Loss: -7.1484	Cost: 43.00s
Train Epoch: 2448 [20480/90000 (23%)]	Loss: -15.1173	Cost: 11.66s
Train Epoch: 2448 [40960/90000 (45%)]	Loss: -15.3224	Cost: 12.38s
Train Epoch: 2448 [61440/90000 (68%)]	Loss: -15.3609	Cost: 12.01s
Train Epoch: 2448 [81920/90000 (91%)]	Loss: -15.1710	Cost: 5.94s
Train Epoch: 2448 	Average Loss: -14.6954
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.6816

Saving model as e2448_model.pt & e2448_waveforms_supplementary.hdf5
Learning rate: 8.592817054439163e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2449 [0/90000 (0%)]	Loss: -7.8753	Cost: 41.20s
Train Epoch: 2449 [20480/90000 (23%)]	Loss: -15.2502	Cost: 12.32s
Train Epoch: 2449 [40960/90000 (45%)]	Loss: -14.9410	Cost: 6.65s
Train Epoch: 2449 [61440/90000 (68%)]	Loss: -15.0002	Cost: 6.60s
Train Epoch: 2449 [81920/90000 (91%)]	Loss: -14.8396	Cost: 8.56s
Train Epoch: 2449 	Average Loss: -14.4831
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
