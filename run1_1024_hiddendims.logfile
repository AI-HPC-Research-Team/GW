Nestedspace(activation='elu', apply_unconditional_transform=False, base_transform_type='rq-coupling', basis_dir='data/GW150914_sample_prior_basis/', batch_norm=True, batch_size=2048, bw_dstar=None, cuda=True, data_dir='data/GW150914_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, dropout_probability=0.0, epochs=3000, flow_lr=None, hidden_dims=1024, kl_annealing=True, lr=0.0002, lr_anneal_method='cosine', lr_annealing=True, mode='train', model_dir='models/GW150914_sample_uniform_100basis_all_posterior_prior_1024hiddendims/', model_source='new', model_type='nde', nbins=8, nflows=15, nsample=100000, nsamples_target_event=2000, num_transform_blocks=10, output_freq=10, sampling_from='posterior', save=True, save_aux_filename='waveforms_supplementary.hdf5', save_model_name='model.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, tail_bound=1.0, truncate_basis=200)
Waveform directory data/GW150914_sample_prior_basis/
Model directory models/GW150914_sample_uniform_100basis_all_posterior_prior_1024hiddendims/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from posterior prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 200 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Detectors: ['H1', 'L1']

Constructing model of type nde

Initial learning rate 0.0002
Using cosine LR annealing.

Model hyperparameters:
input_dim 	 15
num_flow_steps 	 15
context_dim 	 800
base_transform_kwargs
	 hidden_dim 	 1024
	 num_transform_blocks 	 10
	 activation 	 elu
	 dropout_probability 	 0.0
	 batch_norm 	 True
	 num_bins 	 8
	 tail_bound 	 1.0
	 apply_unconditional_transform 	 False
	 base_transform_type 	 rq-coupling

Training for 3000 epochs
Starting timer
Learning rate: 0.0002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 28.2695	Cost: 29.65s
Train Epoch: 1 [20480/90000 (23%)]	Loss: 21.9955	Cost: 9.70s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 21.2504	Cost: 9.75s
Train Epoch: 1 [61440/90000 (68%)]	Loss: 20.9040	Cost: 9.46s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 20.7193	Cost: 9.19s
Train Epoch: 1 	Average Loss: 21.5777
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.4060

Learning rate: 0.00019999994516886946
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 20.2828	Cost: 28.51s
Train Epoch: 2 [20480/90000 (23%)]	Loss: 20.2706	Cost: 9.87s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 19.7378	Cost: 10.21s
Train Epoch: 2 [61440/90000 (68%)]	Loss: 19.4521	Cost: 9.42s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 19.4760	Cost: 9.22s
Train Epoch: 2 	Average Loss: 19.7630
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 19.3009

Learning rate: 0.00019999978067553796
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 19.1468	Cost: 28.36s
Train Epoch: 3 [20480/90000 (23%)]	Loss: 19.0098	Cost: 9.61s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 18.7874	Cost: 10.53s
Train Epoch: 3 [61440/90000 (68%)]	Loss: 18.5587	Cost: 9.41s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 18.5278	Cost: 9.20s
Train Epoch: 3 	Average Loss: 18.7207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.3899

Learning rate: 0.00019999950652018584
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 18.2873	Cost: 29.38s
Train Epoch: 4 [20480/90000 (23%)]	Loss: 18.2262	Cost: 9.61s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 18.0854	Cost: 10.48s
Train Epoch: 4 [61440/90000 (68%)]	Loss: 17.7015	Cost: 9.40s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 17.8254	Cost: 9.21s
Train Epoch: 4 	Average Loss: 17.9864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.7613

Learning rate: 0.00019999912270311375
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 17.6808	Cost: 28.33s
Train Epoch: 5 [20480/90000 (23%)]	Loss: 17.6786	Cost: 9.66s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 17.3869	Cost: 10.52s
Train Epoch: 5 [61440/90000 (68%)]	Loss: 17.4231	Cost: 9.42s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 17.2223	Cost: 9.64s
Train Epoch: 5 	Average Loss: 17.3858
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 17.3044

Learning rate: 0.00019999862922474268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 16.9860	Cost: 29.06s
Train Epoch: 6 [20480/90000 (23%)]	Loss: 17.1606	Cost: 9.67s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 17.0188	Cost: 10.39s
Train Epoch: 6 [61440/90000 (68%)]	Loss: 16.5960	Cost: 9.60s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 16.7516	Cost: 9.22s
Train Epoch: 6 	Average Loss: 16.8577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6410

Learning rate: 0.0001999980260856137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 16.5829	Cost: 28.89s
Train Epoch: 7 [20480/90000 (23%)]	Loss: 16.6257	Cost: 9.56s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 16.2728	Cost: 10.83s
Train Epoch: 7 [61440/90000 (68%)]	Loss: 16.2085	Cost: 9.34s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 16.2160	Cost: 9.22s
Train Epoch: 7 	Average Loss: 16.3476
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 16.6281

Learning rate: 0.0001999973132863883
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 16.2529	Cost: 29.01s
Train Epoch: 8 [20480/90000 (23%)]	Loss: 16.2523	Cost: 9.63s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 16.1438	Cost: 10.46s
Train Epoch: 8 [61440/90000 (68%)]	Loss: 15.9182	Cost: 9.57s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 15.8273	Cost: 9.47s
Train Epoch: 8 	Average Loss: 15.9910
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6846

Learning rate: 0.0001999964908278481
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 15.5867	Cost: 29.15s
Train Epoch: 9 [20480/90000 (23%)]	Loss: 15.6994	Cost: 9.62s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 15.6980	Cost: 10.77s
Train Epoch: 9 [61440/90000 (68%)]	Loss: 15.5389	Cost: 9.38s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 15.6050	Cost: 9.21s
Train Epoch: 9 	Average Loss: 15.6023
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.6082

Learning rate: 0.000199995558710895
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 15.5079	Cost: 28.84s
Train Epoch: 10 [20480/90000 (23%)]	Loss: 15.3810	Cost: 9.61s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 15.2540	Cost: 10.86s
Train Epoch: 10 [61440/90000 (68%)]	Loss: 15.1141	Cost: 9.37s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 15.2163	Cost: 9.46s
Train Epoch: 10 	Average Loss: 15.3222
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.2326

Learning rate: 0.00019999451693655123
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 15.1380	Cost: 28.57s
Train Epoch: 11 [20480/90000 (23%)]	Loss: 15.1169	Cost: 9.66s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 14.8587	Cost: 10.84s
Train Epoch: 11 [61440/90000 (68%)]	Loss: 14.8546	Cost: 9.37s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 14.9076	Cost: 9.19s
Train Epoch: 11 	Average Loss: 14.9330
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.7100

Learning rate: 0.0001999933655059592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 14.8891	Cost: 29.24s
Train Epoch: 12 [20480/90000 (23%)]	Loss: 14.8353	Cost: 9.62s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 14.6666	Cost: 10.68s
Train Epoch: 12 [61440/90000 (68%)]	Loss: 14.7496	Cost: 9.40s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 14.6619	Cost: 9.21s
Train Epoch: 12 	Average Loss: 14.6939
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.6410

Learning rate: 0.00019999210442038162
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 14.5832	Cost: 29.03s
Train Epoch: 13 [20480/90000 (23%)]	Loss: 14.6790	Cost: 9.57s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 14.6083	Cost: 10.74s
Train Epoch: 13 [61440/90000 (68%)]	Loss: 14.4904	Cost: 9.39s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 14.3559	Cost: 9.25s
Train Epoch: 13 	Average Loss: 14.4989
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.3791

Learning rate: 0.0001999907336812014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 14.5458	Cost: 29.06s
Train Epoch: 14 [20480/90000 (23%)]	Loss: 14.3848	Cost: 9.62s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 14.1260	Cost: 10.60s
Train Epoch: 14 [61440/90000 (68%)]	Loss: 14.3274	Cost: 9.46s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 14.1086	Cost: 9.20s
Train Epoch: 14 	Average Loss: 14.2364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.0490

Learning rate: 0.00019998925328992175
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 14.1309	Cost: 29.15s
Train Epoch: 15 [20480/90000 (23%)]	Loss: 14.2192	Cost: 9.63s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 14.0852	Cost: 10.54s
Train Epoch: 15 [61440/90000 (68%)]	Loss: 14.0949	Cost: 9.36s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 13.9454	Cost: 9.79s
Train Epoch: 15 	Average Loss: 14.0166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.9653

Learning rate: 0.00019998766324816607
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 13.8994	Cost: 29.32s
Train Epoch: 16 [20480/90000 (23%)]	Loss: 13.8607	Cost: 9.60s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 13.8536	Cost: 10.58s
Train Epoch: 16 [61440/90000 (68%)]	Loss: 13.6533	Cost: 9.36s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 13.7005	Cost: 9.20s
Train Epoch: 16 	Average Loss: 13.8021
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.6241

Learning rate: 0.00019998596355767805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 13.7592	Cost: 28.34s
Train Epoch: 17 [20480/90000 (23%)]	Loss: 13.7520	Cost: 9.65s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 13.5251	Cost: 10.67s
Train Epoch: 17 [61440/90000 (68%)]	Loss: 13.3747	Cost: 9.41s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 13.4870	Cost: 9.37s
Train Epoch: 17 	Average Loss: 13.6108
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.4958

Learning rate: 0.00019998415422032163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 13.3995	Cost: 29.29s
Train Epoch: 18 [20480/90000 (23%)]	Loss: 13.5537	Cost: 9.64s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 13.3941	Cost: 11.14s
Train Epoch: 18 [61440/90000 (68%)]	Loss: 13.4789	Cost: 9.38s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 13.4546	Cost: 9.37s
Train Epoch: 18 	Average Loss: 13.3987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.3532

Learning rate: 0.0001999822352380809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 13.2617	Cost: 29.35s
Train Epoch: 19 [20480/90000 (23%)]	Loss: 13.4352	Cost: 9.58s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 13.3404	Cost: 10.70s
Train Epoch: 19 [61440/90000 (68%)]	Loss: 13.2194	Cost: 9.38s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 13.2583	Cost: 9.24s
Train Epoch: 19 	Average Loss: 13.2557
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1992

Learning rate: 0.00019998020661306037
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 13.2403	Cost: 28.60s
Train Epoch: 20 [20480/90000 (23%)]	Loss: 13.3183	Cost: 9.65s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 13.1377	Cost: 10.88s
Train Epoch: 20 [61440/90000 (68%)]	Loss: 12.8617	Cost: 9.36s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 13.0106	Cost: 9.39s
Train Epoch: 20 	Average Loss: 13.0750
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9546

Learning rate: 0.00019997806834748456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 12.8476	Cost: 28.57s
Train Epoch: 21 [20480/90000 (23%)]	Loss: 12.9958	Cost: 9.57s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 12.9916	Cost: 10.92s
Train Epoch: 21 [61440/90000 (68%)]	Loss: 12.8536	Cost: 9.40s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 12.9286	Cost: 9.22s
Train Epoch: 21 	Average Loss: 12.9392
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.7712

Learning rate: 0.0001999758204436984
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 12.8287	Cost: 29.28s
Train Epoch: 22 [20480/90000 (23%)]	Loss: 12.9028	Cost: 9.66s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 12.8500	Cost: 10.83s
Train Epoch: 22 [61440/90000 (68%)]	Loss: 12.7491	Cost: 9.36s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 13.0219	Cost: 9.65s
Train Epoch: 22 	Average Loss: 12.7969
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.9758

Learning rate: 0.000199973462904167
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 12.6888	Cost: 29.28s
Train Epoch: 23 [20480/90000 (23%)]	Loss: 12.8443	Cost: 9.72s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 12.7380	Cost: 10.56s
Train Epoch: 23 [61440/90000 (68%)]	Loss: 12.6717	Cost: 9.36s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 12.7239	Cost: 9.30s
Train Epoch: 23 	Average Loss: 12.7255
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6589

Learning rate: 0.0001999709957314757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 12.6388	Cost: 29.26s
Train Epoch: 24 [20480/90000 (23%)]	Loss: 12.6837	Cost: 9.60s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 12.4378	Cost: 10.60s
Train Epoch: 24 [61440/90000 (68%)]	Loss: 12.6047	Cost: 9.40s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 12.4405	Cost: 9.31s
Train Epoch: 24 	Average Loss: 12.5256
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4310

Learning rate: 0.00019996841892833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 12.4801	Cost: 29.09s
Train Epoch: 25 [20480/90000 (23%)]	Loss: 12.5221	Cost: 9.65s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 12.4220	Cost: 10.65s
Train Epoch: 25 [61440/90000 (68%)]	Loss: 12.3935	Cost: 9.46s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 12.4223	Cost: 9.22s
Train Epoch: 25 	Average Loss: 12.4083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.5140

Learning rate: 0.00019996573249755575
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 12.5087	Cost: 29.09s
Train Epoch: 26 [20480/90000 (23%)]	Loss: 12.4547	Cost: 9.67s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 12.2550	Cost: 10.62s
Train Epoch: 26 [61440/90000 (68%)]	Loss: 12.2036	Cost: 9.46s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 12.2034	Cost: 9.22s
Train Epoch: 26 	Average Loss: 12.2907
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1240

Learning rate: 0.0001999629364420989
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 12.0722	Cost: 29.08s
Train Epoch: 27 [20480/90000 (23%)]	Loss: 12.2481	Cost: 9.63s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 12.1819	Cost: 10.65s
Train Epoch: 27 [61440/90000 (68%)]	Loss: 12.1437	Cost: 9.38s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 12.2007	Cost: 9.28s
Train Epoch: 27 	Average Loss: 12.1844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.2213

Learning rate: 0.00019996003076502568
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 12.0363	Cost: 29.84s
Train Epoch: 28 [20480/90000 (23%)]	Loss: 12.1754	Cost: 9.65s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 12.0434	Cost: 10.52s
Train Epoch: 28 [61440/90000 (68%)]	Loss: 12.0503	Cost: 9.36s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 12.0454	Cost: 9.23s
Train Epoch: 28 	Average Loss: 12.0629
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0127

Learning rate: 0.00019995701546952254
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 12.0193	Cost: 29.67s
Train Epoch: 29 [20480/90000 (23%)]	Loss: 12.0208	Cost: 9.63s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 12.0111	Cost: 10.79s
Train Epoch: 29 [61440/90000 (68%)]	Loss: 12.0370	Cost: 9.51s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 12.0227	Cost: 9.21s
Train Epoch: 29 	Average Loss: 12.0017
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9611

Learning rate: 0.0001999538905588961
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 12.1234	Cost: 28.59s
Train Epoch: 30 [20480/90000 (23%)]	Loss: 11.9304	Cost: 9.62s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 11.8378	Cost: 10.60s
Train Epoch: 30 [61440/90000 (68%)]	Loss: 11.8975	Cost: 9.40s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 11.9827	Cost: 9.20s
Train Epoch: 30 	Average Loss: 11.8706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.8841

Learning rate: 0.00019995065603657322
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 11.9633	Cost: 29.09s
Train Epoch: 31 [20480/90000 (23%)]	Loss: 11.8814	Cost: 9.69s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 11.7198	Cost: 10.54s
Train Epoch: 31 [61440/90000 (68%)]	Loss: 11.7123	Cost: 9.38s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 11.8884	Cost: 9.34s
Train Epoch: 31 	Average Loss: 11.8147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7421

Learning rate: 0.00019994731190610092
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 11.7233	Cost: 29.26s
Train Epoch: 32 [20480/90000 (23%)]	Loss: 11.7763	Cost: 9.72s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 11.8149	Cost: 10.50s
Train Epoch: 32 [61440/90000 (68%)]	Loss: 11.6034	Cost: 9.47s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 11.8741	Cost: 9.20s
Train Epoch: 32 	Average Loss: 11.7182
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7218

Learning rate: 0.0001999438581711465
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 11.7480	Cost: 29.10s
Train Epoch: 33 [20480/90000 (23%)]	Loss: 11.8293	Cost: 9.61s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 11.6108	Cost: 10.65s
Train Epoch: 33 [61440/90000 (68%)]	Loss: 11.7397	Cost: 9.41s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 11.7709	Cost: 9.18s
Train Epoch: 33 	Average Loss: 11.6276
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.6711

Learning rate: 0.00019994029483549737
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 11.4486	Cost: 29.46s
Train Epoch: 34 [20480/90000 (23%)]	Loss: 11.5923	Cost: 9.65s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 11.5030	Cost: 10.89s
Train Epoch: 34 [61440/90000 (68%)]	Loss: 11.5546	Cost: 9.36s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 11.6450	Cost: 9.20s
Train Epoch: 34 	Average Loss: 11.5376
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5841

Learning rate: 0.00019993662190306114
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 11.6534	Cost: 29.44s
Train Epoch: 35 [20480/90000 (23%)]	Loss: 11.6229	Cost: 9.63s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 11.5132	Cost: 10.78s
Train Epoch: 35 [61440/90000 (68%)]	Loss: 11.3674	Cost: 9.75s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 11.4471	Cost: 9.24s
Train Epoch: 35 	Average Loss: 11.4602
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4807

Learning rate: 0.00019993283937786568
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 11.3662	Cost: 28.70s
Train Epoch: 36 [20480/90000 (23%)]	Loss: 11.5567	Cost: 9.64s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 11.4719	Cost: 10.61s
Train Epoch: 36 [61440/90000 (68%)]	Loss: 11.4622	Cost: 9.38s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 11.3514	Cost: 9.30s
Train Epoch: 36 	Average Loss: 11.3999
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4152

Learning rate: 0.00019992894726405898
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 11.5201	Cost: 29.53s
Train Epoch: 37 [20480/90000 (23%)]	Loss: 11.3919	Cost: 9.60s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 11.5484	Cost: 10.74s
Train Epoch: 37 [61440/90000 (68%)]	Loss: 11.4393	Cost: 10.06s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 11.3233	Cost: 9.48s
Train Epoch: 37 	Average Loss: 11.4021
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3324

Learning rate: 0.00019992494556590921
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 11.3238	Cost: 29.56s
Train Epoch: 38 [20480/90000 (23%)]	Loss: 11.3993	Cost: 9.62s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 11.3816	Cost: 10.83s
Train Epoch: 38 [61440/90000 (68%)]	Loss: 11.3323	Cost: 9.40s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 11.3016	Cost: 9.21s
Train Epoch: 38 	Average Loss: 11.3201
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2902

Learning rate: 0.00019992083428780474
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 11.3315	Cost: 29.54s
Train Epoch: 39 [20480/90000 (23%)]	Loss: 11.3125	Cost: 9.59s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 11.2002	Cost: 10.79s
Train Epoch: 39 [61440/90000 (68%)]	Loss: 11.1841	Cost: 9.51s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 11.4172	Cost: 9.34s
Train Epoch: 39 	Average Loss: 11.2058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.1527

Learning rate: 0.00019991661343425406
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 11.2233	Cost: 29.52s
Train Epoch: 40 [20480/90000 (23%)]	Loss: 11.2060	Cost: 9.61s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 11.1908	Cost: 10.72s
Train Epoch: 40 [61440/90000 (68%)]	Loss: 11.1447	Cost: 9.37s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 11.1719	Cost: 9.19s
Train Epoch: 40 	Average Loss: 11.1491
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0725

Learning rate: 0.0001999122830098859
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 11.1618	Cost: 29.32s
Train Epoch: 41 [20480/90000 (23%)]	Loss: 11.0653	Cost: 9.65s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 11.1441	Cost: 10.75s
Train Epoch: 41 [61440/90000 (68%)]	Loss: 11.0499	Cost: 9.52s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 11.0447	Cost: 9.28s
Train Epoch: 41 	Average Loss: 11.0542
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0237

Learning rate: 0.00019990784301944904
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 11.0128	Cost: 29.34s
Train Epoch: 42 [20480/90000 (23%)]	Loss: 11.0627	Cost: 9.63s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 10.8826	Cost: 10.49s
Train Epoch: 42 [61440/90000 (68%)]	Loss: 11.0554	Cost: 9.39s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 10.9652	Cost: 9.21s
Train Epoch: 42 	Average Loss: 10.9778
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9601

Learning rate: 0.00019990329346781252
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 10.9623	Cost: 28.89s
Train Epoch: 43 [20480/90000 (23%)]	Loss: 11.0310	Cost: 9.74s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 10.8387	Cost: 10.89s
Train Epoch: 43 [61440/90000 (68%)]	Loss: 10.8888	Cost: 9.45s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 10.8452	Cost: 9.37s
Train Epoch: 43 	Average Loss: 10.9259
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9202

Learning rate: 0.00019989863435996547
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 10.9973	Cost: 28.93s
Train Epoch: 44 [20480/90000 (23%)]	Loss: 11.0281	Cost: 9.66s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 11.0272	Cost: 10.71s
Train Epoch: 44 [61440/90000 (68%)]	Loss: 10.8601	Cost: 9.40s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 10.8274	Cost: 9.27s
Train Epoch: 44 	Average Loss: 10.9302
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9248

Learning rate: 0.00019989386570101717
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 10.9048	Cost: 29.28s
Train Epoch: 45 [20480/90000 (23%)]	Loss: 10.9156	Cost: 9.62s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 10.8676	Cost: 10.79s
Train Epoch: 45 [61440/90000 (68%)]	Loss: 10.7749	Cost: 9.37s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 11.0321	Cost: 9.18s
Train Epoch: 45 	Average Loss: 10.8341
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.7603

Learning rate: 0.00019988898749619704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 10.5874	Cost: 29.21s
Train Epoch: 46 [20480/90000 (23%)]	Loss: 10.7468	Cost: 10.29s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 10.5738	Cost: 10.03s
Train Epoch: 46 [61440/90000 (68%)]	Loss: 10.7982	Cost: 9.38s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 10.8835	Cost: 9.27s
Train Epoch: 46 	Average Loss: 10.7077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8285

Learning rate: 0.00019988399975085462
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 10.7370	Cost: 29.26s
Train Epoch: 47 [20480/90000 (23%)]	Loss: 10.7183	Cost: 9.60s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 10.5600	Cost: 10.54s
Train Epoch: 47 [61440/90000 (68%)]	Loss: 10.6181	Cost: 9.45s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 10.7212	Cost: 9.23s
Train Epoch: 47 	Average Loss: 10.6558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6683

Learning rate: 0.0001998789024704596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 10.6669	Cost: 28.50s
Train Epoch: 48 [20480/90000 (23%)]	Loss: 10.6562	Cost: 9.67s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 10.5510	Cost: 10.73s
Train Epoch: 48 [61440/90000 (68%)]	Loss: 10.5908	Cost: 9.53s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 10.6220	Cost: 9.31s
Train Epoch: 48 	Average Loss: 10.6003
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6282

Learning rate: 0.0001998736956606018
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 10.6659	Cost: 29.38s
Train Epoch: 49 [20480/90000 (23%)]	Loss: 10.6119	Cost: 9.67s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 10.5418	Cost: 10.74s
Train Epoch: 49 [61440/90000 (68%)]	Loss: 10.6012	Cost: 9.39s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 10.4269	Cost: 9.24s
Train Epoch: 49 	Average Loss: 10.5670
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5819

Learning rate: 0.00019986837932699106
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 10.5267	Cost: 28.79s
Train Epoch: 50 [20480/90000 (23%)]	Loss: 10.6714	Cost: 9.63s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 10.6441	Cost: 10.71s
Train Epoch: 50 [61440/90000 (68%)]	Loss: 10.5406	Cost: 9.40s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 10.5419	Cost: 9.25s
Train Epoch: 50 	Average Loss: 10.5303
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5345

Saving model as model.pt_e50 & waveforms_supplementary.hdf5_e50
Learning rate: 0.00019986295347545742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 10.5301	Cost: 28.75s
Train Epoch: 51 [20480/90000 (23%)]	Loss: 10.5903	Cost: 9.63s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 10.5050	Cost: 10.34s
Train Epoch: 51 [61440/90000 (68%)]	Loss: 10.5353	Cost: 9.42s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 10.5554	Cost: 9.20s
Train Epoch: 51 	Average Loss: 10.4689
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.4600

Learning rate: 0.00019985741811195102
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 10.4230	Cost: 29.06s
Train Epoch: 52 [20480/90000 (23%)]	Loss: 10.6634	Cost: 9.64s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 10.4605	Cost: 10.41s
Train Epoch: 52 [61440/90000 (68%)]	Loss: 10.4502	Cost: 9.42s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 10.4726	Cost: 9.25s
Train Epoch: 52 	Average Loss: 10.4522
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.4224

Learning rate: 0.00019985177324254207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 10.3643	Cost: 29.15s
Train Epoch: 53 [20480/90000 (23%)]	Loss: 10.4401	Cost: 9.71s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 10.3146	Cost: 10.48s
Train Epoch: 53 [61440/90000 (68%)]	Loss: 10.3475	Cost: 9.56s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 10.4064	Cost: 9.20s
Train Epoch: 53 	Average Loss: 10.3633
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3468

Learning rate: 0.00019984601887342078
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 10.2819	Cost: 28.86s
Train Epoch: 54 [20480/90000 (23%)]	Loss: 10.3452	Cost: 9.62s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 10.3220	Cost: 10.79s
Train Epoch: 54 [61440/90000 (68%)]	Loss: 10.4870	Cost: 9.36s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 10.5677	Cost: 9.25s
Train Epoch: 54 	Average Loss: 10.3744
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.4032

Learning rate: 0.0001998401550108976
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 10.3788	Cost: 28.92s
Train Epoch: 55 [20480/90000 (23%)]	Loss: 10.3499	Cost: 9.66s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 10.4946	Cost: 10.88s
Train Epoch: 55 [61440/90000 (68%)]	Loss: 10.3361	Cost: 9.61s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 10.3385	Cost: 9.23s
Train Epoch: 55 	Average Loss: 10.3046
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2484

Learning rate: 0.0001998341816614029
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 10.2417	Cost: 28.94s
Train Epoch: 56 [20480/90000 (23%)]	Loss: 10.3255	Cost: 9.61s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 10.2823	Cost: 10.50s
Train Epoch: 56 [61440/90000 (68%)]	Loss: 10.3593	Cost: 9.36s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 10.2852	Cost: 9.20s
Train Epoch: 56 	Average Loss: 10.2662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2611

Learning rate: 0.00019982809883148728
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 10.1967	Cost: 29.11s
Train Epoch: 57 [20480/90000 (23%)]	Loss: 10.4711	Cost: 9.56s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 10.2668	Cost: 11.08s
Train Epoch: 57 [61440/90000 (68%)]	Loss: 10.2300	Cost: 9.40s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 10.0689	Cost: 9.39s
Train Epoch: 57 	Average Loss: 10.1849
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2239

Learning rate: 0.00019982190652782127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 10.2464	Cost: 28.95s
Train Epoch: 58 [20480/90000 (23%)]	Loss: 10.3014	Cost: 9.59s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 10.2163	Cost: 10.69s
Train Epoch: 58 [61440/90000 (68%)]	Loss: 10.2030	Cost: 9.37s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 10.1819	Cost: 9.22s
Train Epoch: 58 	Average Loss: 10.1483
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1641

Learning rate: 0.00019981560475719546
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 10.1800	Cost: 29.09s
Train Epoch: 59 [20480/90000 (23%)]	Loss: 10.1398	Cost: 9.63s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 10.1488	Cost: 10.35s
Train Epoch: 59 [61440/90000 (68%)]	Loss: 10.2748	Cost: 9.40s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 10.1548	Cost: 9.38s
Train Epoch: 59 	Average Loss: 10.1442
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2191

Learning rate: 0.00019980919352652056
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 10.1687	Cost: 29.67s
Train Epoch: 60 [20480/90000 (23%)]	Loss: 10.2582	Cost: 9.69s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 10.2805	Cost: 10.42s
Train Epoch: 60 [61440/90000 (68%)]	Loss: 10.1623	Cost: 9.42s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 10.1835	Cost: 9.17s
Train Epoch: 60 	Average Loss: 10.1477
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1695

Learning rate: 0.00019980267284282725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 10.1349	Cost: 29.30s
Train Epoch: 61 [20480/90000 (23%)]	Loss: 10.1373	Cost: 9.57s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 10.1095	Cost: 10.63s
Train Epoch: 61 [61440/90000 (68%)]	Loss: 10.0992	Cost: 9.33s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 10.1330	Cost: 9.41s
Train Epoch: 61 	Average Loss: 10.0504
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0614

Learning rate: 0.00019979604271326627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 10.0674	Cost: 29.27s
Train Epoch: 62 [20480/90000 (23%)]	Loss: 10.0256	Cost: 9.65s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 10.0523	Cost: 10.64s
Train Epoch: 62 [61440/90000 (68%)]	Loss: 9.9982	Cost: 9.55s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 10.0861	Cost: 9.23s
Train Epoch: 62 	Average Loss: 9.9859
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0286

Learning rate: 0.00019978930314510835
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 10.0483	Cost: 29.03s
Train Epoch: 63 [20480/90000 (23%)]	Loss: 10.0613	Cost: 9.61s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 10.0689	Cost: 10.45s
Train Epoch: 63 [61440/90000 (68%)]	Loss: 10.0276	Cost: 9.37s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 10.0115	Cost: 9.23s
Train Epoch: 63 	Average Loss: 9.9873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9624

Learning rate: 0.00019978245414574428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 9.9082	Cost: 29.24s
Train Epoch: 64 [20480/90000 (23%)]	Loss: 9.9691	Cost: 9.67s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 10.0076	Cost: 10.41s
Train Epoch: 64 [61440/90000 (68%)]	Loss: 9.8961	Cost: 9.41s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 10.0423	Cost: 9.70s
Train Epoch: 64 	Average Loss: 9.9293
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9239

Learning rate: 0.0001997754957226848
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 10.0284	Cost: 28.58s
Train Epoch: 65 [20480/90000 (23%)]	Loss: 9.8883	Cost: 9.67s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 9.9485	Cost: 10.81s
Train Epoch: 65 [61440/90000 (68%)]	Loss: 9.8280	Cost: 9.36s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 9.7759	Cost: 9.40s
Train Epoch: 65 	Average Loss: 9.8781
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8887

Learning rate: 0.00019976842788356066
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 9.8641	Cost: 29.94s
Train Epoch: 66 [20480/90000 (23%)]	Loss: 9.9010	Cost: 9.63s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 9.8154	Cost: 10.41s
Train Epoch: 66 [61440/90000 (68%)]	Loss: 9.9483	Cost: 9.41s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 9.8217	Cost: 9.22s
Train Epoch: 66 	Average Loss: 9.8544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8704

Learning rate: 0.00019976125063612266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 9.7489	Cost: 29.13s
Train Epoch: 67 [20480/90000 (23%)]	Loss: 9.7806	Cost: 9.57s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 9.8831	Cost: 10.52s
Train Epoch: 67 [61440/90000 (68%)]	Loss: 9.9300	Cost: 9.38s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 9.9056	Cost: 9.21s
Train Epoch: 67 	Average Loss: 9.7993
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8228

Learning rate: 0.0001997539639882415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 9.8035	Cost: 28.69s
Train Epoch: 68 [20480/90000 (23%)]	Loss: 9.9617	Cost: 9.79s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 9.8454	Cost: 10.66s
Train Epoch: 68 [61440/90000 (68%)]	Loss: 9.8266	Cost: 9.46s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 9.8246	Cost: 9.28s
Train Epoch: 68 	Average Loss: 9.8081
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8457

Learning rate: 0.00019974656794790788
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 9.8720	Cost: 29.29s
Train Epoch: 69 [20480/90000 (23%)]	Loss: 9.7975	Cost: 9.71s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 9.8012	Cost: 10.81s
Train Epoch: 69 [61440/90000 (68%)]	Loss: 9.6860	Cost: 9.41s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 9.8221	Cost: 9.20s
Train Epoch: 69 	Average Loss: 9.7774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8125

Learning rate: 0.0001997390625232325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 9.8499	Cost: 28.87s
Train Epoch: 70 [20480/90000 (23%)]	Loss: 9.6475	Cost: 9.65s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 9.6816	Cost: 10.67s
Train Epoch: 70 [61440/90000 (68%)]	Loss: 9.8824	Cost: 9.42s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 9.8711	Cost: 9.23s
Train Epoch: 70 	Average Loss: 9.7343
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.8806

Learning rate: 0.00019973144772244593
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 9.8902	Cost: 29.01s
Train Epoch: 71 [20480/90000 (23%)]	Loss: 9.6876	Cost: 9.73s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 9.6097	Cost: 10.95s
Train Epoch: 71 [61440/90000 (68%)]	Loss: 9.7484	Cost: 9.56s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 9.6602	Cost: 9.43s
Train Epoch: 71 	Average Loss: 9.6944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7081

Learning rate: 0.0001997237235538988
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 9.7885	Cost: 29.01s
Train Epoch: 72 [20480/90000 (23%)]	Loss: 9.6405	Cost: 9.60s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 9.8013	Cost: 10.86s
Train Epoch: 72 [61440/90000 (68%)]	Loss: 9.7172	Cost: 9.40s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 9.7282	Cost: 9.22s
Train Epoch: 72 	Average Loss: 9.6559
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6962

Learning rate: 0.0001997158900260615
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 9.7125	Cost: 29.68s
Train Epoch: 73 [20480/90000 (23%)]	Loss: 9.6778	Cost: 9.69s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 9.7842	Cost: 10.68s
Train Epoch: 73 [61440/90000 (68%)]	Loss: 9.6531	Cost: 9.43s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 9.5458	Cost: 9.37s
Train Epoch: 73 	Average Loss: 9.6205
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6091

Learning rate: 0.00019970794714752456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 9.5342	Cost: 28.91s
Train Epoch: 74 [20480/90000 (23%)]	Loss: 9.6932	Cost: 9.70s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 9.6506	Cost: 10.68s
Train Epoch: 74 [61440/90000 (68%)]	Loss: 9.6751	Cost: 9.52s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 9.7741	Cost: 9.50s
Train Epoch: 74 	Average Loss: 9.5929
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5597

Learning rate: 0.0001996998949269983
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 9.6416	Cost: 29.10s
Train Epoch: 75 [20480/90000 (23%)]	Loss: 9.5263	Cost: 9.62s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 9.4966	Cost: 10.67s
Train Epoch: 75 [61440/90000 (68%)]	Loss: 9.5567	Cost: 9.45s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 9.5892	Cost: 9.39s
Train Epoch: 75 	Average Loss: 9.5596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5941

Learning rate: 0.00019969173337331292
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 9.4615	Cost: 28.43s
Train Epoch: 76 [20480/90000 (23%)]	Loss: 9.6210	Cost: 9.74s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 9.6049	Cost: 10.69s
Train Epoch: 76 [61440/90000 (68%)]	Loss: 9.5697	Cost: 9.47s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 9.5023	Cost: 9.07s
Train Epoch: 76 	Average Loss: 9.5708
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6129

Learning rate: 0.00019968346249541857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 9.5628	Cost: 28.48s
Train Epoch: 77 [20480/90000 (23%)]	Loss: 9.6358	Cost: 9.74s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 9.4223	Cost: 10.38s
Train Epoch: 77 [61440/90000 (68%)]	Loss: 9.3900	Cost: 9.39s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 9.4891	Cost: 9.35s
Train Epoch: 77 	Average Loss: 9.5346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5651

Learning rate: 0.00019967508230238533
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 9.5917	Cost: 29.04s
Train Epoch: 78 [20480/90000 (23%)]	Loss: 9.4529	Cost: 9.70s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 9.4272	Cost: 10.58s
Train Epoch: 78 [61440/90000 (68%)]	Loss: 9.5874	Cost: 9.41s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 9.6544	Cost: 9.27s
Train Epoch: 78 	Average Loss: 9.4773
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4948

Learning rate: 0.00019966659280340308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 9.6936	Cost: 28.93s
Train Epoch: 79 [20480/90000 (23%)]	Loss: 9.5738	Cost: 9.67s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 9.3447	Cost: 10.85s
Train Epoch: 79 [61440/90000 (68%)]	Loss: 9.4085	Cost: 9.44s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 9.3673	Cost: 9.30s
Train Epoch: 79 	Average Loss: 9.4520
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4511

Learning rate: 0.00019965799400778163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 9.3705	Cost: 29.05s
Train Epoch: 80 [20480/90000 (23%)]	Loss: 9.4495	Cost: 9.77s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 9.4294	Cost: 10.38s
Train Epoch: 80 [61440/90000 (68%)]	Loss: 9.5805	Cost: 9.42s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 9.4709	Cost: 9.22s
Train Epoch: 80 	Average Loss: 9.3969
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4763

Learning rate: 0.00019964928592495053
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 9.4720	Cost: 29.22s
Train Epoch: 81 [20480/90000 (23%)]	Loss: 9.4104	Cost: 9.65s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 9.4136	Cost: 10.88s
Train Epoch: 81 [61440/90000 (68%)]	Loss: 9.3580	Cost: 9.48s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 9.3662	Cost: 9.36s
Train Epoch: 81 	Average Loss: 9.3687
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4005

Learning rate: 0.00019964046856445932
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 9.3832	Cost: 29.35s
Train Epoch: 82 [20480/90000 (23%)]	Loss: 9.3946	Cost: 9.73s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 9.3759	Cost: 10.45s
Train Epoch: 82 [61440/90000 (68%)]	Loss: 9.5120	Cost: 9.61s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 9.5101	Cost: 9.24s
Train Epoch: 82 	Average Loss: 9.3648
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3177

Learning rate: 0.00019963154193597735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 9.3712	Cost: 28.86s
Train Epoch: 83 [20480/90000 (23%)]	Loss: 9.3571	Cost: 9.68s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 9.2405	Cost: 10.70s
Train Epoch: 83 [61440/90000 (68%)]	Loss: 9.4131	Cost: 9.41s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 9.4247	Cost: 9.37s
Train Epoch: 83 	Average Loss: 9.3384
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3817

Learning rate: 0.0001996225060492937
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 9.4249	Cost: 29.33s
Train Epoch: 84 [20480/90000 (23%)]	Loss: 9.3488	Cost: 9.59s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 9.2738	Cost: 10.54s
Train Epoch: 84 [61440/90000 (68%)]	Loss: 9.4444	Cost: 9.41s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 9.4202	Cost: 9.24s
Train Epoch: 84 	Average Loss: 9.3033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4482

Learning rate: 0.00019961336091431733
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 9.5301	Cost: 29.33s
Train Epoch: 85 [20480/90000 (23%)]	Loss: 9.5331	Cost: 9.59s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 9.2825	Cost: 10.60s
Train Epoch: 85 [61440/90000 (68%)]	Loss: 9.3227	Cost: 9.38s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 9.3128	Cost: 9.21s
Train Epoch: 85 	Average Loss: 9.3113
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3410

Learning rate: 0.00019960410654107705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 9.3828	Cost: 29.41s
Train Epoch: 86 [20480/90000 (23%)]	Loss: 9.2981	Cost: 9.67s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 9.1473	Cost: 10.32s
Train Epoch: 86 [61440/90000 (68%)]	Loss: 9.2518	Cost: 9.41s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 9.1946	Cost: 9.19s
Train Epoch: 86 	Average Loss: 9.2253
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3408

Learning rate: 0.00019959474293972137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 9.3205	Cost: 29.21s
Train Epoch: 87 [20480/90000 (23%)]	Loss: 9.2303	Cost: 9.62s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 9.1453	Cost: 10.62s
Train Epoch: 87 [61440/90000 (68%)]	Loss: 9.2873	Cost: 9.42s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 9.2640	Cost: 9.77s
Train Epoch: 87 	Average Loss: 9.2007
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2742

Learning rate: 0.00019958527012051865
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 9.2633	Cost: 29.09s
Train Epoch: 88 [20480/90000 (23%)]	Loss: 9.2319	Cost: 9.61s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 9.2323	Cost: 10.73s
Train Epoch: 88 [61440/90000 (68%)]	Loss: 9.1625	Cost: 9.51s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 9.0786	Cost: 9.68s
Train Epoch: 88 	Average Loss: 9.2021
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2910

Learning rate: 0.000199575688093857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 9.3883	Cost: 28.94s
Train Epoch: 89 [20480/90000 (23%)]	Loss: 9.0560	Cost: 9.59s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 9.0716	Cost: 10.60s
Train Epoch: 89 [61440/90000 (68%)]	Loss: 9.1107	Cost: 9.44s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 9.1491	Cost: 9.22s
Train Epoch: 89 	Average Loss: 9.1565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2624

Learning rate: 0.00019956599687024425
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 9.4787	Cost: 29.47s
Train Epoch: 90 [20480/90000 (23%)]	Loss: 9.1712	Cost: 9.71s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 9.1611	Cost: 10.43s
Train Epoch: 90 [61440/90000 (68%)]	Loss: 9.1629	Cost: 9.43s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 9.3586	Cost: 9.15s
Train Epoch: 90 	Average Loss: 9.1854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2517

Learning rate: 0.00019955619646030805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 9.2320	Cost: 28.68s
Train Epoch: 91 [20480/90000 (23%)]	Loss: 9.1747	Cost: 9.70s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 9.1143	Cost: 10.31s
Train Epoch: 91 [61440/90000 (68%)]	Loss: 9.0430	Cost: 9.42s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 9.1380	Cost: 9.24s
Train Epoch: 91 	Average Loss: 9.1128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1979

Learning rate: 0.00019954628687479575
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 9.1870	Cost: 30.01s
Train Epoch: 92 [20480/90000 (23%)]	Loss: 9.2034	Cost: 9.63s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 9.1564	Cost: 10.54s
Train Epoch: 92 [61440/90000 (68%)]	Loss: 9.0977	Cost: 9.38s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 9.1925	Cost: 9.19s
Train Epoch: 92 	Average Loss: 9.0803
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2976

Learning rate: 0.00019953626812457446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 9.3000	Cost: 29.53s
Train Epoch: 93 [20480/90000 (23%)]	Loss: 9.0331	Cost: 9.77s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 9.0704	Cost: 10.19s
Train Epoch: 93 [61440/90000 (68%)]	Loss: 9.2524	Cost: 9.97s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 9.0157	Cost: 9.28s
Train Epoch: 93 	Average Loss: 9.0590
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2037

Learning rate: 0.0001995261402206309
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 9.1402	Cost: 28.36s
Train Epoch: 94 [20480/90000 (23%)]	Loss: 9.0845	Cost: 9.75s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 9.0321	Cost: 10.67s
Train Epoch: 94 [61440/90000 (68%)]	Loss: 8.9951	Cost: 9.44s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 8.9583	Cost: 9.23s
Train Epoch: 94 	Average Loss: 9.0279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.1367

Learning rate: 0.00019951590317407155
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 9.0931	Cost: 29.40s
Train Epoch: 95 [20480/90000 (23%)]	Loss: 9.1339	Cost: 9.73s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 9.0089	Cost: 10.66s
Train Epoch: 95 [61440/90000 (68%)]	Loss: 9.0284	Cost: 9.45s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 8.9422	Cost: 9.21s
Train Epoch: 95 	Average Loss: 9.0341
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0970

Learning rate: 0.0001995055569961227
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 9.0618	Cost: 29.36s
Train Epoch: 96 [20480/90000 (23%)]	Loss: 8.9464	Cost: 9.70s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 9.0166	Cost: 10.73s
Train Epoch: 96 [61440/90000 (68%)]	Loss: 9.0127	Cost: 10.07s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 8.9623	Cost: 9.36s
Train Epoch: 96 	Average Loss: 8.9926
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0511

Learning rate: 0.0001994951016981301
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 9.0865	Cost: 29.27s
Train Epoch: 97 [20480/90000 (23%)]	Loss: 9.0989	Cost: 9.82s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 8.8647	Cost: 10.64s
Train Epoch: 97 [61440/90000 (68%)]	Loss: 9.2042	Cost: 9.45s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 8.9705	Cost: 9.76s
Train Epoch: 97 	Average Loss: 8.9699
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0741

Learning rate: 0.00019948453729155924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 9.0263	Cost: 28.82s
Train Epoch: 98 [20480/90000 (23%)]	Loss: 8.9794	Cost: 9.69s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 8.9666	Cost: 10.42s
Train Epoch: 98 [61440/90000 (68%)]	Loss: 8.9220	Cost: 9.38s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 8.8993	Cost: 9.40s
Train Epoch: 98 	Average Loss: 8.9207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0280

Learning rate: 0.00019947386378799537
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 8.8994	Cost: 28.67s
Train Epoch: 99 [20480/90000 (23%)]	Loss: 9.0571	Cost: 9.64s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 9.0103	Cost: 10.65s
Train Epoch: 99 [61440/90000 (68%)]	Loss: 8.8160	Cost: 9.35s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 8.8902	Cost: 9.20s
Train Epoch: 99 	Average Loss: 8.9200
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9670

Learning rate: 0.00019946308119914329
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 8.9934	Cost: 28.82s
Train Epoch: 100 [20480/90000 (23%)]	Loss: 8.8909	Cost: 9.70s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 8.9183	Cost: 10.77s
Train Epoch: 100 [61440/90000 (68%)]	Loss: 8.9246	Cost: 9.42s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 9.0165	Cost: 9.21s
Train Epoch: 100 	Average Loss: 8.8730
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9882

Saving model as model.pt_e100 & waveforms_supplementary.hdf5_e100
Learning rate: 0.0001994521895368274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 9.0127	Cost: 28.97s
Train Epoch: 101 [20480/90000 (23%)]	Loss: 8.8997	Cost: 9.70s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 8.9235	Cost: 10.50s
Train Epoch: 101 [61440/90000 (68%)]	Loss: 8.8790	Cost: 9.88s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 8.8954	Cost: 9.44s
Train Epoch: 101 	Average Loss: 8.8765
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9967

Learning rate: 0.00019944118881299173
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 8.9841	Cost: 29.69s
Train Epoch: 102 [20480/90000 (23%)]	Loss: 8.9291	Cost: 9.77s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 8.9048	Cost: 10.65s
Train Epoch: 102 [61440/90000 (68%)]	Loss: 8.8903	Cost: 9.44s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 8.7609	Cost: 9.34s
Train Epoch: 102 	Average Loss: 8.8192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9263

Learning rate: 0.00019943007903969995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 8.9343	Cost: 29.07s
Train Epoch: 103 [20480/90000 (23%)]	Loss: 8.9823	Cost: 9.80s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 8.8786	Cost: 10.27s
Train Epoch: 103 [61440/90000 (68%)]	Loss: 8.9310	Cost: 9.42s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 8.7433	Cost: 9.21s
Train Epoch: 103 	Average Loss: 8.8292
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9087

Learning rate: 0.00019941886022913527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 8.8404	Cost: 29.29s
Train Epoch: 104 [20480/90000 (23%)]	Loss: 8.7740	Cost: 9.73s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 8.8493	Cost: 10.53s
Train Epoch: 104 [61440/90000 (68%)]	Loss: 8.7620	Cost: 9.40s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 8.7514	Cost: 9.14s
Train Epoch: 104 	Average Loss: 8.7730
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9319

Learning rate: 0.00019940753239360053
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 8.8696	Cost: 29.33s
Train Epoch: 105 [20480/90000 (23%)]	Loss: 8.7232	Cost: 9.65s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 8.7374	Cost: 10.43s
Train Epoch: 105 [61440/90000 (68%)]	Loss: 8.7841	Cost: 9.37s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 8.7092	Cost: 9.20s
Train Epoch: 105 	Average Loss: 8.7362
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8666

Learning rate: 0.00019939609554551804
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 8.9060	Cost: 29.09s
Train Epoch: 106 [20480/90000 (23%)]	Loss: 8.6820	Cost: 9.71s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 8.7255	Cost: 10.32s
Train Epoch: 106 [61440/90000 (68%)]	Loss: 8.8068	Cost: 9.67s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 8.6546	Cost: 9.20s
Train Epoch: 106 	Average Loss: 8.7329
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8052

Learning rate: 0.00019938454969742973
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 8.8479	Cost: 29.90s
Train Epoch: 107 [20480/90000 (23%)]	Loss: 8.6898	Cost: 9.75s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 8.7585	Cost: 10.70s
Train Epoch: 107 [61440/90000 (68%)]	Loss: 8.6533	Cost: 9.45s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 8.6634	Cost: 9.31s
Train Epoch: 107 	Average Loss: 8.6832
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8007

Learning rate: 0.00019937289486199702
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 8.7689	Cost: 29.04s
Train Epoch: 108 [20480/90000 (23%)]	Loss: 8.7121	Cost: 9.80s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 8.7400	Cost: 10.52s
Train Epoch: 108 [61440/90000 (68%)]	Loss: 8.8234	Cost: 9.50s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 8.7270	Cost: 9.37s
Train Epoch: 108 	Average Loss: 8.6748
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7580

Learning rate: 0.00019936113105200088
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 8.7784	Cost: 29.08s
Train Epoch: 109 [20480/90000 (23%)]	Loss: 8.6114	Cost: 9.80s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 8.7151	Cost: 10.75s
Train Epoch: 109 [61440/90000 (68%)]	Loss: 8.6732	Cost: 9.41s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 8.7226	Cost: 9.24s
Train Epoch: 109 	Average Loss: 8.6604
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8683

Learning rate: 0.00019934925828034178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 8.9234	Cost: 28.56s
Train Epoch: 110 [20480/90000 (23%)]	Loss: 8.6424	Cost: 9.71s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 8.6291	Cost: 10.70s
Train Epoch: 110 [61440/90000 (68%)]	Loss: 8.6644	Cost: 9.39s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 8.6421	Cost: 9.22s
Train Epoch: 110 	Average Loss: 8.6403
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8530

Learning rate: 0.00019933727656003969
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 8.9075	Cost: 28.96s
Train Epoch: 111 [20480/90000 (23%)]	Loss: 8.5585	Cost: 9.63s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 8.4965	Cost: 10.63s
Train Epoch: 111 [61440/90000 (68%)]	Loss: 8.5855	Cost: 9.42s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 8.5630	Cost: 9.22s
Train Epoch: 111 	Average Loss: 8.6015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7134

Learning rate: 0.000199325185904234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 8.7657	Cost: 29.58s
Train Epoch: 112 [20480/90000 (23%)]	Loss: 8.6028	Cost: 9.72s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 8.6058	Cost: 9.91s
Train Epoch: 112 [61440/90000 (68%)]	Loss: 8.6235	Cost: 9.41s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 8.6776	Cost: 9.26s
Train Epoch: 112 	Average Loss: 8.5885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7130

Learning rate: 0.0001993129863261836
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 8.8055	Cost: 29.68s
Train Epoch: 113 [20480/90000 (23%)]	Loss: 8.4448	Cost: 9.68s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 8.5017	Cost: 10.71s
Train Epoch: 113 [61440/90000 (68%)]	Loss: 8.5415	Cost: 9.37s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 8.5871	Cost: 9.20s
Train Epoch: 113 	Average Loss: 8.5878
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8233

Learning rate: 0.00019930067783926678
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 8.9528	Cost: 30.18s
Train Epoch: 114 [20480/90000 (23%)]	Loss: 8.6483	Cost: 9.64s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 8.6688	Cost: 10.49s
Train Epoch: 114 [61440/90000 (68%)]	Loss: 8.5338	Cost: 9.42s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 8.5454	Cost: 9.19s
Train Epoch: 114 	Average Loss: 8.5739
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6926

Learning rate: 0.0001992882604569814
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 8.5723	Cost: 28.89s
Train Epoch: 115 [20480/90000 (23%)]	Loss: 8.4992	Cost: 9.70s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 8.3812	Cost: 10.63s
Train Epoch: 115 [61440/90000 (68%)]	Loss: 8.4111	Cost: 9.42s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 8.4636	Cost: 9.25s
Train Epoch: 115 	Average Loss: 8.4950
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6323

Learning rate: 0.00019927573419294456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 8.5133	Cost: 29.05s
Train Epoch: 116 [20480/90000 (23%)]	Loss: 8.4436	Cost: 9.83s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 8.5958	Cost: 10.34s
Train Epoch: 116 [61440/90000 (68%)]	Loss: 8.4249	Cost: 9.62s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 8.4480	Cost: 9.27s
Train Epoch: 116 	Average Loss: 8.4604
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6299

Learning rate: 0.0001992630990608929
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 8.5887	Cost: 29.24s
Train Epoch: 117 [20480/90000 (23%)]	Loss: 8.5558	Cost: 9.64s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 8.3443	Cost: 10.58s
Train Epoch: 117 [61440/90000 (68%)]	Loss: 8.4907	Cost: 9.41s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 8.5403	Cost: 9.29s
Train Epoch: 117 	Average Loss: 8.4585
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6442

Learning rate: 0.0001992503550746824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 8.7233	Cost: 28.60s
Train Epoch: 118 [20480/90000 (23%)]	Loss: 8.3984	Cost: 9.88s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 8.3251	Cost: 10.65s
Train Epoch: 118 [61440/90000 (68%)]	Loss: 8.4457	Cost: 9.51s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 8.5508	Cost: 9.12s
Train Epoch: 118 	Average Loss: 8.4264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7180

Learning rate: 0.00019923750224828832
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 8.5939	Cost: 29.41s
Train Epoch: 119 [20480/90000 (23%)]	Loss: 8.3183	Cost: 9.70s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 8.4619	Cost: 10.01s
Train Epoch: 119 [61440/90000 (68%)]	Loss: 8.3712	Cost: 9.44s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 8.4060	Cost: 9.25s
Train Epoch: 119 	Average Loss: 8.4012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6744

Learning rate: 0.00019922454059580544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 8.6912	Cost: 28.75s
Train Epoch: 120 [20480/90000 (23%)]	Loss: 8.4211	Cost: 9.96s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 8.2863	Cost: 10.46s
Train Epoch: 120 [61440/90000 (68%)]	Loss: 8.3575	Cost: 9.46s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 8.4655	Cost: 9.20s
Train Epoch: 120 	Average Loss: 8.3863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5899

Learning rate: 0.00019921147013144782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 8.7281	Cost: 29.66s
Train Epoch: 121 [20480/90000 (23%)]	Loss: 8.3048	Cost: 9.73s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 8.3231	Cost: 10.73s
Train Epoch: 121 [61440/90000 (68%)]	Loss: 8.4360	Cost: 9.50s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 8.3730	Cost: 9.29s
Train Epoch: 121 	Average Loss: 8.3533
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5141

Learning rate: 0.00019919829086954873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 8.6822	Cost: 28.39s
Train Epoch: 122 [20480/90000 (23%)]	Loss: 8.3414	Cost: 9.78s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 8.3854	Cost: 10.67s
Train Epoch: 122 [61440/90000 (68%)]	Loss: 8.4504	Cost: 9.93s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 8.3419	Cost: 9.45s
Train Epoch: 122 	Average Loss: 8.3301
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6050

Learning rate: 0.00019918500282456092
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 8.6309	Cost: 29.21s
Train Epoch: 123 [20480/90000 (23%)]	Loss: 8.3656	Cost: 9.75s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 8.4377	Cost: 10.39s
Train Epoch: 123 [61440/90000 (68%)]	Loss: 8.3867	Cost: 9.53s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 8.3830	Cost: 9.30s
Train Epoch: 123 	Average Loss: 8.3466
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5760

Learning rate: 0.00019917160601105635
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 8.5426	Cost: 28.93s
Train Epoch: 124 [20480/90000 (23%)]	Loss: 8.3341	Cost: 9.70s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 8.2397	Cost: 10.78s
Train Epoch: 124 [61440/90000 (68%)]	Loss: 8.3023	Cost: 9.45s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 8.2818	Cost: 9.21s
Train Epoch: 124 	Average Loss: 8.2957
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4963

Learning rate: 0.00019915810044372623
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 8.6574	Cost: 29.12s
Train Epoch: 125 [20480/90000 (23%)]	Loss: 8.1980	Cost: 9.62s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 8.3255	Cost: 10.87s
Train Epoch: 125 [61440/90000 (68%)]	Loss: 8.2590	Cost: 9.56s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 8.3167	Cost: 9.24s
Train Epoch: 125 	Average Loss: 8.2783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5292

Learning rate: 0.0001991444861373811
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 8.5375	Cost: 29.24s
Train Epoch: 126 [20480/90000 (23%)]	Loss: 8.4539	Cost: 9.67s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 8.2807	Cost: 10.69s
Train Epoch: 126 [61440/90000 (68%)]	Loss: 8.3567	Cost: 9.38s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 8.4297	Cost: 9.31s
Train Epoch: 126 	Average Loss: 8.2775
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5314

Learning rate: 0.00019913076310695073
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 8.5108	Cost: 29.38s
Train Epoch: 127 [20480/90000 (23%)]	Loss: 8.2488	Cost: 9.64s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 8.2051	Cost: 10.42s
Train Epoch: 127 [61440/90000 (68%)]	Loss: 8.2519	Cost: 9.41s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 8.2995	Cost: 9.20s
Train Epoch: 127 	Average Loss: 8.2181
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4456

Learning rate: 0.00019911693136748408
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 8.4900	Cost: 29.59s
Train Epoch: 128 [20480/90000 (23%)]	Loss: 8.2077	Cost: 9.61s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 8.2422	Cost: 10.56s
Train Epoch: 128 [61440/90000 (68%)]	Loss: 8.1076	Cost: 9.40s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 8.2031	Cost: 9.25s
Train Epoch: 128 	Average Loss: 8.1699
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3686

Learning rate: 0.00019910299093414934
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 8.4347	Cost: 28.90s
Train Epoch: 129 [20480/90000 (23%)]	Loss: 8.1868	Cost: 9.60s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 8.1206	Cost: 10.51s
Train Epoch: 129 [61440/90000 (68%)]	Loss: 8.1871	Cost: 9.41s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 8.1050	Cost: 9.31s
Train Epoch: 129 	Average Loss: 8.1744
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4108

Learning rate: 0.00019908894182223393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 8.5008	Cost: 28.86s
Train Epoch: 130 [20480/90000 (23%)]	Loss: 8.1295	Cost: 9.71s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 8.0843	Cost: 10.72s
Train Epoch: 130 [61440/90000 (68%)]	Loss: 8.0978	Cost: 9.43s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 8.0956	Cost: 9.18s
Train Epoch: 130 	Average Loss: 8.1332
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4194

Learning rate: 0.00019907478404714441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 8.4542	Cost: 29.35s
Train Epoch: 131 [20480/90000 (23%)]	Loss: 8.0071	Cost: 9.72s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 8.2275	Cost: 10.89s
Train Epoch: 131 [61440/90000 (68%)]	Loss: 8.1289	Cost: 9.50s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 8.0921	Cost: 9.16s
Train Epoch: 131 	Average Loss: 8.1096
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3596

Learning rate: 0.00019906051762440656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 8.3739	Cost: 29.65s
Train Epoch: 132 [20480/90000 (23%)]	Loss: 7.9964	Cost: 9.82s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 8.0365	Cost: 9.89s
Train Epoch: 132 [61440/90000 (68%)]	Loss: 8.0937	Cost: 9.39s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 8.0737	Cost: 9.70s
Train Epoch: 132 	Average Loss: 8.0638
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3518

Learning rate: 0.0001990461425696652
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 8.3434	Cost: 28.78s
Train Epoch: 133 [20480/90000 (23%)]	Loss: 8.0483	Cost: 9.81s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 8.0194	Cost: 10.53s
Train Epoch: 133 [61440/90000 (68%)]	Loss: 8.1337	Cost: 9.42s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 8.2298	Cost: 9.20s
Train Epoch: 133 	Average Loss: 8.0544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3468

Learning rate: 0.00019903165889868438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 8.4307	Cost: 29.53s
Train Epoch: 134 [20480/90000 (23%)]	Loss: 7.9633	Cost: 9.67s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 8.0560	Cost: 10.48s
Train Epoch: 134 [61440/90000 (68%)]	Loss: 7.9986	Cost: 9.43s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 8.0113	Cost: 9.21s
Train Epoch: 134 	Average Loss: 8.0179
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3125

Learning rate: 0.0001990170666273472
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 8.3901	Cost: 29.00s
Train Epoch: 135 [20480/90000 (23%)]	Loss: 8.0831	Cost: 9.62s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 8.0559	Cost: 10.45s
Train Epoch: 135 [61440/90000 (68%)]	Loss: 8.0235	Cost: 9.53s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 8.0529	Cost: 9.26s
Train Epoch: 135 	Average Loss: 8.0073
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3291

Learning rate: 0.00019900236577165585
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 8.2523	Cost: 28.76s
Train Epoch: 136 [20480/90000 (23%)]	Loss: 8.0563	Cost: 9.67s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 7.9203	Cost: 10.80s
Train Epoch: 136 [61440/90000 (68%)]	Loss: 7.9638	Cost: 9.42s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 8.1150	Cost: 9.35s
Train Epoch: 136 	Average Loss: 7.9786
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2359

Learning rate: 0.00019898755634773166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 8.1311	Cost: 29.24s
Train Epoch: 137 [20480/90000 (23%)]	Loss: 7.9842	Cost: 9.64s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 7.9517	Cost: 10.62s
Train Epoch: 137 [61440/90000 (68%)]	Loss: 8.0574	Cost: 9.44s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 7.9418	Cost: 9.23s
Train Epoch: 137 	Average Loss: 7.9392
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2941

Learning rate: 0.00019897263837181497
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 8.1744	Cost: 29.83s
Train Epoch: 138 [20480/90000 (23%)]	Loss: 7.9000	Cost: 9.63s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 7.8723	Cost: 11.01s
Train Epoch: 138 [61440/90000 (68%)]	Loss: 8.0297	Cost: 9.40s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 7.9398	Cost: 9.37s
Train Epoch: 138 	Average Loss: 7.9343
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2266

Learning rate: 0.00019895761186026516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 8.1487	Cost: 29.42s
Train Epoch: 139 [20480/90000 (23%)]	Loss: 7.9076	Cost: 9.60s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 7.6968	Cost: 10.56s
Train Epoch: 139 [61440/90000 (68%)]	Loss: 7.9475	Cost: 9.49s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 7.8363	Cost: 9.19s
Train Epoch: 139 	Average Loss: 7.8837
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2506

Learning rate: 0.0001989424768295607
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 8.2354	Cost: 29.12s
Train Epoch: 140 [20480/90000 (23%)]	Loss: 7.9532	Cost: 9.57s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 7.8598	Cost: 11.13s
Train Epoch: 140 [61440/90000 (68%)]	Loss: 7.9800	Cost: 9.54s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 7.9443	Cost: 9.39s
Train Epoch: 140 	Average Loss: 7.8730
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1784

Learning rate: 0.00019892723329629892
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 8.4052	Cost: 29.44s
Train Epoch: 141 [20480/90000 (23%)]	Loss: 7.8186	Cost: 9.64s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 7.7188	Cost: 10.73s
Train Epoch: 141 [61440/90000 (68%)]	Loss: 8.0172	Cost: 9.40s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 7.8447	Cost: 9.19s
Train Epoch: 141 	Average Loss: 7.8594
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3157

Learning rate: 0.00019891188127719623
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 8.3634	Cost: 29.78s
Train Epoch: 142 [20480/90000 (23%)]	Loss: 7.7864	Cost: 9.60s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 7.8814	Cost: 10.84s
Train Epoch: 142 [61440/90000 (68%)]	Loss: 7.9393	Cost: 9.35s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 7.9672	Cost: 9.59s
Train Epoch: 142 	Average Loss: 7.8605
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2940

Learning rate: 0.0001988964207890881
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 8.3428	Cost: 29.22s
Train Epoch: 143 [20480/90000 (23%)]	Loss: 7.8141	Cost: 9.84s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 7.8062	Cost: 10.33s
Train Epoch: 143 [61440/90000 (68%)]	Loss: 7.9240	Cost: 9.42s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 7.7965	Cost: 9.18s
Train Epoch: 143 	Average Loss: 7.8163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1970

Learning rate: 0.00019888085184892874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 8.2379	Cost: 29.24s
Train Epoch: 144 [20480/90000 (23%)]	Loss: 7.7659	Cost: 9.73s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 7.7668	Cost: 10.27s
Train Epoch: 144 [61440/90000 (68%)]	Loss: 7.7260	Cost: 9.50s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 7.7898	Cost: 9.32s
Train Epoch: 144 	Average Loss: 7.7595
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2020

Learning rate: 0.00019886517447379145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 8.3019	Cost: 29.42s
Train Epoch: 145 [20480/90000 (23%)]	Loss: 7.7589	Cost: 9.76s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 7.6482	Cost: 10.32s
Train Epoch: 145 [61440/90000 (68%)]	Loss: 7.9098	Cost: 9.58s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 7.6819	Cost: 9.36s
Train Epoch: 145 	Average Loss: 7.7443
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1374

Learning rate: 0.0001988493886808684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 7.9977	Cost: 29.54s
Train Epoch: 146 [20480/90000 (23%)]	Loss: 7.5981	Cost: 9.75s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 7.7432	Cost: 10.65s
Train Epoch: 146 [61440/90000 (68%)]	Loss: 7.7941	Cost: 9.57s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 7.8619	Cost: 9.40s
Train Epoch: 146 	Average Loss: 7.7184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1435

Learning rate: 0.00019883349448747068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 8.0429	Cost: 29.39s
Train Epoch: 147 [20480/90000 (23%)]	Loss: 7.5830	Cost: 9.82s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 7.6706	Cost: 10.71s
Train Epoch: 147 [61440/90000 (68%)]	Loss: 7.8232	Cost: 9.49s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 7.6787	Cost: 9.14s
Train Epoch: 147 	Average Loss: 7.6688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0521

Learning rate: 0.00019881749191102814
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 8.0505	Cost: 29.31s
Train Epoch: 148 [20480/90000 (23%)]	Loss: 7.5348	Cost: 9.89s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 7.6661	Cost: 10.61s
Train Epoch: 148 [61440/90000 (68%)]	Loss: 7.7132	Cost: 9.42s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 7.6068	Cost: 9.39s
Train Epoch: 148 	Average Loss: 7.6512
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0588

Learning rate: 0.00019880138096908958
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 8.0333	Cost: 28.57s
Train Epoch: 149 [20480/90000 (23%)]	Loss: 7.5709	Cost: 9.77s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 7.5630	Cost: 10.67s
Train Epoch: 149 [61440/90000 (68%)]	Loss: 7.6154	Cost: 9.57s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 7.5299	Cost: 9.15s
Train Epoch: 149 	Average Loss: 7.6045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9432

Learning rate: 0.00019878516167932264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 8.0268	Cost: 29.18s
Train Epoch: 150 [20480/90000 (23%)]	Loss: 7.4934	Cost: 9.77s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 7.5509	Cost: 10.45s
Train Epoch: 150 [61440/90000 (68%)]	Loss: 7.6012	Cost: 9.43s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 7.5366	Cost: 9.41s
Train Epoch: 150 	Average Loss: 7.5796
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9793

Saving model as model.pt_e150 & waveforms_supplementary.hdf5_e150
Learning rate: 0.00019876883405951383
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 7.9115	Cost: 29.48s
Train Epoch: 151 [20480/90000 (23%)]	Loss: 7.5656	Cost: 9.81s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 7.5401	Cost: 10.28s
Train Epoch: 151 [61440/90000 (68%)]	Loss: 7.6315	Cost: 9.42s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 7.5217	Cost: 9.18s
Train Epoch: 151 	Average Loss: 7.5675
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0477

Learning rate: 0.0001987523981275683
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 7.9946	Cost: 29.95s
Train Epoch: 152 [20480/90000 (23%)]	Loss: 7.5071	Cost: 9.62s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 7.4588	Cost: 10.77s
Train Epoch: 152 [61440/90000 (68%)]	Loss: 7.5334	Cost: 9.87s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 7.4488	Cost: 9.87s
Train Epoch: 152 	Average Loss: 7.5222
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9867

Learning rate: 0.00019873585390151012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 8.1597	Cost: 29.08s
Train Epoch: 153 [20480/90000 (23%)]	Loss: 7.4836	Cost: 9.68s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 7.3636	Cost: 10.75s
Train Epoch: 153 [61440/90000 (68%)]	Loss: 7.5862	Cost: 9.40s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 7.5784	Cost: 9.30s
Train Epoch: 153 	Average Loss: 7.4896
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9333

Learning rate: 0.00019871920139948198
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 7.9189	Cost: 29.61s
Train Epoch: 154 [20480/90000 (23%)]	Loss: 7.4244	Cost: 9.69s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 7.4665	Cost: 10.67s
Train Epoch: 154 [61440/90000 (68%)]	Loss: 7.4591	Cost: 9.43s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 7.4150	Cost: 9.22s
Train Epoch: 154 	Average Loss: 7.4510
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9056

Learning rate: 0.00019870244063974546
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 7.8412	Cost: 29.85s
Train Epoch: 155 [20480/90000 (23%)]	Loss: 7.3587	Cost: 9.73s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 7.3412	Cost: 10.60s
Train Epoch: 155 [61440/90000 (68%)]	Loss: 7.4156	Cost: 9.42s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 7.3828	Cost: 9.22s
Train Epoch: 155 	Average Loss: 7.4094
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9540

Learning rate: 0.00019868557164068077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 7.9268	Cost: 29.33s
Train Epoch: 156 [20480/90000 (23%)]	Loss: 7.5033	Cost: 9.76s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 7.3925	Cost: 10.23s
Train Epoch: 156 [61440/90000 (68%)]	Loss: 7.3680	Cost: 9.45s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 7.3948	Cost: 9.17s
Train Epoch: 156 	Average Loss: 7.4233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9102

Learning rate: 0.00019866859442078683
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 7.9417	Cost: 29.36s
Train Epoch: 157 [20480/90000 (23%)]	Loss: 7.2890	Cost: 9.87s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 7.3220	Cost: 10.50s
Train Epoch: 157 [61440/90000 (68%)]	Loss: 7.3832	Cost: 9.45s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 7.2641	Cost: 9.19s
Train Epoch: 157 	Average Loss: 7.3540
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8576

Learning rate: 0.0001986515089986813
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 7.7121	Cost: 28.78s
Train Epoch: 158 [20480/90000 (23%)]	Loss: 7.3675	Cost: 10.07s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 7.2673	Cost: 10.58s
Train Epoch: 158 [61440/90000 (68%)]	Loss: 7.2086	Cost: 9.70s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 7.4521	Cost: 9.38s
Train Epoch: 158 	Average Loss: 7.3514
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8266

Learning rate: 0.00019863431539310036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 7.8762	Cost: 29.70s
Train Epoch: 159 [20480/90000 (23%)]	Loss: 7.3580	Cost: 9.63s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 7.2559	Cost: 10.70s
Train Epoch: 159 [61440/90000 (68%)]	Loss: 7.1999	Cost: 9.43s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 7.4148	Cost: 9.20s
Train Epoch: 159 	Average Loss: 7.3124
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7918

Learning rate: 0.00019861701362289895
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 7.8743	Cost: 29.18s
Train Epoch: 160 [20480/90000 (23%)]	Loss: 7.3051	Cost: 9.69s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 7.1638	Cost: 10.21s
Train Epoch: 160 [61440/90000 (68%)]	Loss: 7.3557	Cost: 9.38s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 7.4146	Cost: 9.22s
Train Epoch: 160 	Average Loss: 7.2838
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7779

Learning rate: 0.00019859960370705056
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 7.8843	Cost: 29.43s
Train Epoch: 161 [20480/90000 (23%)]	Loss: 7.0990	Cost: 9.62s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 7.1874	Cost: 10.68s
Train Epoch: 161 [61440/90000 (68%)]	Loss: 7.2378	Cost: 9.38s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 7.3083	Cost: 9.20s
Train Epoch: 161 	Average Loss: 7.2244
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7058

Learning rate: 0.0001985820856646473
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 7.6160	Cost: 29.65s
Train Epoch: 162 [20480/90000 (23%)]	Loss: 7.2206	Cost: 9.60s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 7.1211	Cost: 10.76s
Train Epoch: 162 [61440/90000 (68%)]	Loss: 7.2924	Cost: 9.42s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 7.1494	Cost: 9.22s
Train Epoch: 162 	Average Loss: 7.1997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7462

Learning rate: 0.00019856445951489985
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 7.7736	Cost: 29.02s
Train Epoch: 163 [20480/90000 (23%)]	Loss: 7.0864	Cost: 9.67s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 6.9687	Cost: 10.49s
Train Epoch: 163 [61440/90000 (68%)]	Loss: 7.2065	Cost: 9.59s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 7.0900	Cost: 9.26s
Train Epoch: 163 	Average Loss: 7.1560
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7205

Learning rate: 0.0001985467252771375
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 7.7186	Cost: 29.70s
Train Epoch: 164 [20480/90000 (23%)]	Loss: 7.0486	Cost: 9.69s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 7.1060	Cost: 10.73s
Train Epoch: 164 [61440/90000 (68%)]	Loss: 7.1307	Cost: 9.42s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 7.0555	Cost: 9.22s
Train Epoch: 164 	Average Loss: 7.1435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6650

Learning rate: 0.0001985288829708079
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 7.6261	Cost: 29.37s
Train Epoch: 165 [20480/90000 (23%)]	Loss: 6.9553	Cost: 9.67s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 6.9717	Cost: 10.65s
Train Epoch: 165 [61440/90000 (68%)]	Loss: 7.1957	Cost: 9.43s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 7.0866	Cost: 9.81s
Train Epoch: 165 	Average Loss: 7.1203
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6906

Learning rate: 0.00019851093261547743
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 7.7290	Cost: 29.05s
Train Epoch: 166 [20480/90000 (23%)]	Loss: 6.9519	Cost: 9.64s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 7.0092	Cost: 10.46s
Train Epoch: 166 [61440/90000 (68%)]	Loss: 7.1989	Cost: 9.37s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 7.0936	Cost: 9.73s
Train Epoch: 166 	Average Loss: 7.1339
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7462

Learning rate: 0.00019849287423083083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 7.6001	Cost: 28.93s
Train Epoch: 167 [20480/90000 (23%)]	Loss: 6.9720	Cost: 9.63s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 7.0445	Cost: 10.73s
Train Epoch: 167 [61440/90000 (68%)]	Loss: 7.0549	Cost: 9.42s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 6.9875	Cost: 9.21s
Train Epoch: 167 	Average Loss: 7.0601
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6613

Learning rate: 0.00019847470783667133
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 7.6318	Cost: 28.66s
Train Epoch: 168 [20480/90000 (23%)]	Loss: 6.9239	Cost: 9.68s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 6.9302	Cost: 10.45s
Train Epoch: 168 [61440/90000 (68%)]	Loss: 6.9904	Cost: 9.45s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 6.9673	Cost: 9.21s
Train Epoch: 168 	Average Loss: 6.9913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6800

Learning rate: 0.0001984564334529206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 7.6178	Cost: 29.15s
Train Epoch: 169 [20480/90000 (23%)]	Loss: 6.7959	Cost: 9.63s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 6.8811	Cost: 10.65s
Train Epoch: 169 [61440/90000 (68%)]	Loss: 6.8714	Cost: 9.42s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 7.0852	Cost: 9.17s
Train Epoch: 169 	Average Loss: 6.9844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6404

Learning rate: 0.00019843805109961873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 7.5899	Cost: 28.86s
Train Epoch: 170 [20480/90000 (23%)]	Loss: 6.8726	Cost: 9.63s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 6.8976	Cost: 10.76s
Train Epoch: 170 [61440/90000 (68%)]	Loss: 7.0572	Cost: 9.43s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 6.9395	Cost: 9.81s
Train Epoch: 170 	Average Loss: 6.9543
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6831

Learning rate: 0.00019841956079692422
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 7.7450	Cost: 29.91s
Train Epoch: 171 [20480/90000 (23%)]	Loss: 6.8674	Cost: 9.62s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 6.7809	Cost: 10.49s
Train Epoch: 171 [61440/90000 (68%)]	Loss: 6.9632	Cost: 9.39s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 7.0043	Cost: 9.19s
Train Epoch: 171 	Average Loss: 6.9543
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5818

Learning rate: 0.000198400962565114
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 7.7020	Cost: 29.17s
Train Epoch: 172 [20480/90000 (23%)]	Loss: 6.9623	Cost: 9.65s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 6.8817	Cost: 10.75s
Train Epoch: 172 [61440/90000 (68%)]	Loss: 6.8823	Cost: 9.38s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 6.9155	Cost: 9.16s
Train Epoch: 172 	Average Loss: 6.9269
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5666

Learning rate: 0.0001983822564245833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 7.5482	Cost: 29.87s
Train Epoch: 173 [20480/90000 (23%)]	Loss: 6.9772	Cost: 9.67s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 6.8511	Cost: 10.63s
Train Epoch: 173 [61440/90000 (68%)]	Loss: 6.8233	Cost: 9.42s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 6.8624	Cost: 9.24s
Train Epoch: 173 	Average Loss: 6.8497
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5224

Learning rate: 0.00019836344239584564
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 7.5156	Cost: 29.22s
Train Epoch: 174 [20480/90000 (23%)]	Loss: 6.7638	Cost: 9.63s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 6.6477	Cost: 10.67s
Train Epoch: 174 [61440/90000 (68%)]	Loss: 6.7470	Cost: 9.43s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 6.7816	Cost: 9.57s
Train Epoch: 174 	Average Loss: 6.7944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4820

Learning rate: 0.00019834452049953297
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 7.3033	Cost: 30.43s
Train Epoch: 175 [20480/90000 (23%)]	Loss: 6.5607	Cost: 9.63s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 6.7261	Cost: 10.45s
Train Epoch: 175 [61440/90000 (68%)]	Loss: 6.7760	Cost: 9.37s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 6.7917	Cost: 9.21s
Train Epoch: 175 	Average Loss: 6.7534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4738

Learning rate: 0.00019832549075639546
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 7.4923	Cost: 29.47s
Train Epoch: 176 [20480/90000 (23%)]	Loss: 6.6923	Cost: 9.58s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 6.7096	Cost: 10.78s
Train Epoch: 176 [61440/90000 (68%)]	Loss: 6.8170	Cost: 9.47s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 6.7915	Cost: 9.31s
Train Epoch: 176 	Average Loss: 6.7465
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4322

Learning rate: 0.00019830635318730154
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 7.2339	Cost: 28.76s
Train Epoch: 177 [20480/90000 (23%)]	Loss: 6.5985	Cost: 9.62s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 6.5453	Cost: 10.66s
Train Epoch: 177 [61440/90000 (68%)]	Loss: 6.7619	Cost: 9.38s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 6.7013	Cost: 9.18s
Train Epoch: 177 	Average Loss: 6.7002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4569

Learning rate: 0.0001982871078132379
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 7.3650	Cost: 29.27s
Train Epoch: 178 [20480/90000 (23%)]	Loss: 6.6226	Cost: 9.60s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 6.7042	Cost: 10.61s
Train Epoch: 178 [61440/90000 (68%)]	Loss: 6.7808	Cost: 9.41s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 6.6866	Cost: 9.19s
Train Epoch: 178 	Average Loss: 6.6864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3189

Learning rate: 0.00019826775465530948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 7.2639	Cost: 28.49s
Train Epoch: 179 [20480/90000 (23%)]	Loss: 6.5937	Cost: 9.77s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 6.5363	Cost: 10.72s
Train Epoch: 179 [61440/90000 (68%)]	Loss: 6.6673	Cost: 9.39s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 6.6900	Cost: 9.31s
Train Epoch: 179 	Average Loss: 6.6212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3406

Learning rate: 0.00019824829373473938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 7.2058	Cost: 28.97s
Train Epoch: 180 [20480/90000 (23%)]	Loss: 6.5806	Cost: 9.76s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 6.5711	Cost: 10.28s
Train Epoch: 180 [61440/90000 (68%)]	Loss: 6.6932	Cost: 9.46s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 6.6024	Cost: 9.16s
Train Epoch: 180 	Average Loss: 6.6379
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3766

Learning rate: 0.00019822872507286885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 7.4253	Cost: 28.67s
Train Epoch: 181 [20480/90000 (23%)]	Loss: 6.4891	Cost: 9.73s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 6.5813	Cost: 10.95s
Train Epoch: 181 [61440/90000 (68%)]	Loss: 6.5471	Cost: 9.53s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 6.5731	Cost: 9.08s
Train Epoch: 181 	Average Loss: 6.5916
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3707

Learning rate: 0.00019820904869115736
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 7.4674	Cost: 28.72s
Train Epoch: 182 [20480/90000 (23%)]	Loss: 6.4841	Cost: 9.82s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 6.3715	Cost: 10.42s
Train Epoch: 182 [61440/90000 (68%)]	Loss: 6.5275	Cost: 9.38s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 6.4996	Cost: 9.22s
Train Epoch: 182 	Average Loss: 6.5311
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2966

Learning rate: 0.0001981892646111825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 7.2322	Cost: 29.45s
Train Epoch: 183 [20480/90000 (23%)]	Loss: 6.3676	Cost: 10.10s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 6.3390	Cost: 10.00s
Train Epoch: 183 [61440/90000 (68%)]	Loss: 6.5792	Cost: 9.65s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 6.5244	Cost: 9.26s
Train Epoch: 183 	Average Loss: 6.5078
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2669

Learning rate: 0.00019816937285463987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 7.1473	Cost: 29.59s
Train Epoch: 184 [20480/90000 (23%)]	Loss: 6.2877	Cost: 9.72s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 6.3038	Cost: 10.67s
Train Epoch: 184 [61440/90000 (68%)]	Loss: 6.5081	Cost: 9.48s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 6.4498	Cost: 9.13s
Train Epoch: 184 	Average Loss: 6.4610
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2884

Learning rate: 0.00019814937344334328
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 7.1786	Cost: 29.12s
Train Epoch: 185 [20480/90000 (23%)]	Loss: 6.4465	Cost: 9.78s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 6.1312	Cost: 10.46s
Train Epoch: 185 [61440/90000 (68%)]	Loss: 6.4806	Cost: 9.55s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 6.4572	Cost: 9.22s
Train Epoch: 185 	Average Loss: 6.4238
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2618

Learning rate: 0.0001981292663992245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 7.2799	Cost: 29.22s
Train Epoch: 186 [20480/90000 (23%)]	Loss: 6.2301	Cost: 9.63s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 6.2281	Cost: 10.51s
Train Epoch: 186 [61440/90000 (68%)]	Loss: 6.3540	Cost: 9.41s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 6.3310	Cost: 9.21s
Train Epoch: 186 	Average Loss: 6.3679
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2273

Learning rate: 0.0001981090517443334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 7.1655	Cost: 29.13s
Train Epoch: 187 [20480/90000 (23%)]	Loss: 6.2909	Cost: 9.62s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 6.3202	Cost: 10.64s
Train Epoch: 187 [61440/90000 (68%)]	Loss: 6.2914	Cost: 9.41s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 6.3554	Cost: 9.18s
Train Epoch: 187 	Average Loss: 6.3738
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2161

Learning rate: 0.00019808872950083782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 7.1976	Cost: 29.34s
Train Epoch: 188 [20480/90000 (23%)]	Loss: 6.2040	Cost: 9.66s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 6.2898	Cost: 10.60s
Train Epoch: 188 [61440/90000 (68%)]	Loss: 6.3118	Cost: 9.45s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 6.3486	Cost: 9.80s
Train Epoch: 188 	Average Loss: 6.3361
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1026

Learning rate: 0.00019806829969102355
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 7.1244	Cost: 29.77s
Train Epoch: 189 [20480/90000 (23%)]	Loss: 6.1412	Cost: 10.28s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 6.2703	Cost: 9.85s
Train Epoch: 189 [61440/90000 (68%)]	Loss: 6.3620	Cost: 9.43s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 6.2454	Cost: 9.20s
Train Epoch: 189 	Average Loss: 6.2979
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1105

Learning rate: 0.00019804776233729444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 7.1065	Cost: 29.22s
Train Epoch: 190 [20480/90000 (23%)]	Loss: 6.0108	Cost: 9.58s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 6.0760	Cost: 10.76s
Train Epoch: 190 [61440/90000 (68%)]	Loss: 6.2146	Cost: 9.39s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 6.2758	Cost: 9.23s
Train Epoch: 190 	Average Loss: 6.2675
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1902

Learning rate: 0.00019802711746217218
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 7.0453	Cost: 29.94s
Train Epoch: 191 [20480/90000 (23%)]	Loss: 6.0823	Cost: 9.68s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 6.1286	Cost: 10.51s
Train Epoch: 191 [61440/90000 (68%)]	Loss: 6.2607	Cost: 9.41s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 6.2035	Cost: 9.18s
Train Epoch: 191 	Average Loss: 6.2119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1220

Learning rate: 0.00019800636508829643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 7.0248	Cost: 29.54s
Train Epoch: 192 [20480/90000 (23%)]	Loss: 5.9668	Cost: 9.59s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 6.2045	Cost: 10.63s
Train Epoch: 192 [61440/90000 (68%)]	Loss: 6.3793	Cost: 9.40s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 6.2310	Cost: 9.21s
Train Epoch: 192 	Average Loss: 6.2396
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1163

Learning rate: 0.0001979855052384247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 6.9022	Cost: 29.21s
Train Epoch: 193 [20480/90000 (23%)]	Loss: 6.1747	Cost: 9.69s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 6.2066	Cost: 10.62s
Train Epoch: 193 [61440/90000 (68%)]	Loss: 6.1119	Cost: 9.59s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 6.3122	Cost: 9.44s
Train Epoch: 193 	Average Loss: 6.1947
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0405

Learning rate: 0.00019796453793543238
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 6.9930	Cost: 28.74s
Train Epoch: 194 [20480/90000 (23%)]	Loss: 6.0870	Cost: 9.75s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 6.1282	Cost: 10.57s
Train Epoch: 194 [61440/90000 (68%)]	Loss: 6.1616	Cost: 9.43s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 6.1265	Cost: 9.23s
Train Epoch: 194 	Average Loss: 6.1250
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9841

Learning rate: 0.00019794346320231267
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 6.9886	Cost: 29.28s
Train Epoch: 195 [20480/90000 (23%)]	Loss: 5.8814	Cost: 9.63s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 6.0881	Cost: 10.63s
Train Epoch: 195 [61440/90000 (68%)]	Loss: 6.0469	Cost: 9.42s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 6.1993	Cost: 9.20s
Train Epoch: 195 	Average Loss: 6.1288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0893

Learning rate: 0.0001979222810621766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 6.9852	Cost: 28.55s
Train Epoch: 196 [20480/90000 (23%)]	Loss: 5.9840	Cost: 9.61s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 6.0435	Cost: 10.52s
Train Epoch: 196 [61440/90000 (68%)]	Loss: 6.1385	Cost: 9.43s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 6.0219	Cost: 9.14s
Train Epoch: 196 	Average Loss: 6.0944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8653

Learning rate: 0.00019790099153825302
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 6.8615	Cost: 29.64s
Train Epoch: 197 [20480/90000 (23%)]	Loss: 5.9067	Cost: 9.67s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 5.8601	Cost: 10.44s
Train Epoch: 197 [61440/90000 (68%)]	Loss: 6.0376	Cost: 9.40s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 5.9127	Cost: 9.23s
Train Epoch: 197 	Average Loss: 6.0041
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9257

Learning rate: 0.00019787959465388845
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 6.9729	Cost: 28.76s
Train Epoch: 198 [20480/90000 (23%)]	Loss: 5.8324	Cost: 9.68s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 5.8428	Cost: 10.86s
Train Epoch: 198 [61440/90000 (68%)]	Loss: 6.0626	Cost: 9.39s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 5.8898	Cost: 9.21s
Train Epoch: 198 	Average Loss: 5.9689
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9764

Learning rate: 0.00019785809043254722
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 6.9725	Cost: 29.50s
Train Epoch: 199 [20480/90000 (23%)]	Loss: 5.8927	Cost: 9.77s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 5.8924	Cost: 10.25s
Train Epoch: 199 [61440/90000 (68%)]	Loss: 5.8831	Cost: 9.42s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 5.8775	Cost: 9.24s
Train Epoch: 199 	Average Loss: 5.9669
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9183

Learning rate: 0.00019783647889781136
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 6.8335	Cost: 29.26s
Train Epoch: 200 [20480/90000 (23%)]	Loss: 5.7676	Cost: 9.65s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 5.6838	Cost: 10.62s
Train Epoch: 200 [61440/90000 (68%)]	Loss: 5.8085	Cost: 9.39s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 5.8360	Cost: 9.21s
Train Epoch: 200 	Average Loss: 5.8710
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8049

Saving model as model.pt_e200 & waveforms_supplementary.hdf5_e200
Learning rate: 0.00019781476007338058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 6.7611	Cost: 29.28s
Train Epoch: 201 [20480/90000 (23%)]	Loss: 5.7293	Cost: 9.59s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 5.6947	Cost: 10.74s
Train Epoch: 201 [61440/90000 (68%)]	Loss: 5.9635	Cost: 9.55s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 5.8562	Cost: 9.21s
Train Epoch: 201 	Average Loss: 5.8441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8199

Learning rate: 0.0001977929339830722
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 6.7909	Cost: 28.95s
Train Epoch: 202 [20480/90000 (23%)]	Loss: 5.7630	Cost: 9.65s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 5.7202	Cost: 10.81s
Train Epoch: 202 [61440/90000 (68%)]	Loss: 5.7718	Cost: 9.40s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 5.7029	Cost: 9.22s
Train Epoch: 202 	Average Loss: 5.7952
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7723

Learning rate: 0.0001977710006508212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 6.6941	Cost: 30.19s
Train Epoch: 203 [20480/90000 (23%)]	Loss: 5.7280	Cost: 9.67s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 5.7307	Cost: 10.36s
Train Epoch: 203 [61440/90000 (68%)]	Loss: 5.8389	Cost: 9.42s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 5.8180	Cost: 9.23s
Train Epoch: 203 	Average Loss: 5.8263
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8330

Learning rate: 0.00019774896010068022
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 6.6537	Cost: 28.85s
Train Epoch: 204 [20480/90000 (23%)]	Loss: 5.7464	Cost: 9.66s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 5.5817	Cost: 10.53s
Train Epoch: 204 [61440/90000 (68%)]	Loss: 5.7839	Cost: 9.44s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 5.7200	Cost: 9.23s
Train Epoch: 204 	Average Loss: 5.7875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8188

Learning rate: 0.00019772681235681938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 6.5782	Cost: 29.07s
Train Epoch: 205 [20480/90000 (23%)]	Loss: 5.5738	Cost: 9.71s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 5.5484	Cost: 10.79s
Train Epoch: 205 [61440/90000 (68%)]	Loss: 5.7514	Cost: 9.43s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 5.8092	Cost: 9.33s
Train Epoch: 205 	Average Loss: 5.7258
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7056

Learning rate: 0.00019770455744352641
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 6.5368	Cost: 28.57s
Train Epoch: 206 [20480/90000 (23%)]	Loss: 5.6012	Cost: 9.75s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 5.4235	Cost: 10.70s
Train Epoch: 206 [61440/90000 (68%)]	Loss: 5.5295	Cost: 9.41s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 5.6447	Cost: 9.20s
Train Epoch: 206 	Average Loss: 5.6717
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7541

Learning rate: 0.00019768219538520652
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 6.6057	Cost: 29.29s
Train Epoch: 207 [20480/90000 (23%)]	Loss: 5.7027	Cost: 9.79s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 5.5673	Cost: 10.63s
Train Epoch: 207 [61440/90000 (68%)]	Loss: 5.5292	Cost: 9.56s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 5.6118	Cost: 9.18s
Train Epoch: 207 	Average Loss: 5.6671
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6504

Learning rate: 0.00019765972620638248
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 6.6566	Cost: 29.43s
Train Epoch: 208 [20480/90000 (23%)]	Loss: 5.5303	Cost: 9.65s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 5.4163	Cost: 10.04s
Train Epoch: 208 [61440/90000 (68%)]	Loss: 5.6063	Cost: 9.41s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 5.7771	Cost: 9.16s
Train Epoch: 208 	Average Loss: 5.6084
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6683

Learning rate: 0.00019763714993169452
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 6.5406	Cost: 28.56s
Train Epoch: 209 [20480/90000 (23%)]	Loss: 5.5610	Cost: 9.80s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 5.4458	Cost: 10.71s
Train Epoch: 209 [61440/90000 (68%)]	Loss: 5.6500	Cost: 9.39s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 5.5985	Cost: 9.37s
Train Epoch: 209 	Average Loss: 5.6171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6607

Learning rate: 0.00019761446658590024
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 6.7255	Cost: 29.20s
Train Epoch: 210 [20480/90000 (23%)]	Loss: 5.4658	Cost: 9.58s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 5.4141	Cost: 10.83s
Train Epoch: 210 [61440/90000 (68%)]	Loss: 5.4836	Cost: 9.40s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 5.5652	Cost: 9.25s
Train Epoch: 210 	Average Loss: 5.5696
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5702

Learning rate: 0.00019759167619387476
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 6.4571	Cost: 28.26s
Train Epoch: 211 [20480/90000 (23%)]	Loss: 5.2985	Cost: 9.74s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 5.4220	Cost: 10.61s
Train Epoch: 211 [61440/90000 (68%)]	Loss: 5.4955	Cost: 9.38s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 5.5175	Cost: 9.32s
Train Epoch: 211 	Average Loss: 5.5095
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5697

Learning rate: 0.00019756877878061052
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 6.6665	Cost: 29.58s
Train Epoch: 212 [20480/90000 (23%)]	Loss: 5.4224	Cost: 9.73s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 5.2748	Cost: 10.78s
Train Epoch: 212 [61440/90000 (68%)]	Loss: 5.3761	Cost: 9.46s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 5.4524	Cost: 9.29s
Train Epoch: 212 	Average Loss: 5.4991
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5400

Learning rate: 0.00019754577437121733
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 6.4089	Cost: 28.48s
Train Epoch: 213 [20480/90000 (23%)]	Loss: 5.3351	Cost: 9.70s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 5.2529	Cost: 10.74s
Train Epoch: 213 [61440/90000 (68%)]	Loss: 5.4100	Cost: 9.42s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 5.3760	Cost: 9.28s
Train Epoch: 213 	Average Loss: 5.3972
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4736

Learning rate: 0.00019752266299092233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 6.5089	Cost: 30.21s
Train Epoch: 214 [20480/90000 (23%)]	Loss: 5.3133	Cost: 9.84s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 5.1774	Cost: 10.43s
Train Epoch: 214 [61440/90000 (68%)]	Loss: 5.3514	Cost: 9.47s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 5.3947	Cost: 9.20s
Train Epoch: 214 	Average Loss: 5.3685
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6089

Learning rate: 0.00019749944466507005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 6.3259	Cost: 28.85s
Train Epoch: 215 [20480/90000 (23%)]	Loss: 5.2839	Cost: 9.64s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 5.2823	Cost: 10.33s
Train Epoch: 215 [61440/90000 (68%)]	Loss: 5.2221	Cost: 9.43s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 5.3705	Cost: 9.20s
Train Epoch: 215 	Average Loss: 5.3731
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5109

Learning rate: 0.00019747611941912217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 6.6240	Cost: 29.17s
Train Epoch: 216 [20480/90000 (23%)]	Loss: 5.1832	Cost: 9.60s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 5.1847	Cost: 10.87s
Train Epoch: 216 [61440/90000 (68%)]	Loss: 5.2558	Cost: 9.36s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 5.2078	Cost: 9.25s
Train Epoch: 216 	Average Loss: 5.2905
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4791

Learning rate: 0.0001974526872786577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 6.4002	Cost: 29.39s
Train Epoch: 217 [20480/90000 (23%)]	Loss: 5.1235	Cost: 9.72s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 5.1086	Cost: 10.54s
Train Epoch: 217 [61440/90000 (68%)]	Loss: 5.2740	Cost: 9.37s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 5.1847	Cost: 9.37s
Train Epoch: 217 	Average Loss: 5.2647
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5169

Learning rate: 0.00019742914826937285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 6.4222	Cost: 28.95s
Train Epoch: 218 [20480/90000 (23%)]	Loss: 5.0262	Cost: 9.70s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 5.0868	Cost: 10.63s
Train Epoch: 218 [61440/90000 (68%)]	Loss: 5.1262	Cost: 9.46s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 5.2700	Cost: 9.22s
Train Epoch: 218 	Average Loss: 5.2338
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4764

Learning rate: 0.00019740550241708105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 6.2542	Cost: 28.62s
Train Epoch: 219 [20480/90000 (23%)]	Loss: 5.1190	Cost: 9.67s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 5.0330	Cost: 10.67s
Train Epoch: 219 [61440/90000 (68%)]	Loss: 5.1674	Cost: 9.38s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 5.1295	Cost: 9.77s
Train Epoch: 219 	Average Loss: 5.2046
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3294

Learning rate: 0.00019738174974771286
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 6.4125	Cost: 29.85s
Train Epoch: 220 [20480/90000 (23%)]	Loss: 5.0559	Cost: 9.61s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 5.0382	Cost: 10.46s
Train Epoch: 220 [61440/90000 (68%)]	Loss: 5.1633	Cost: 9.38s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 4.9945	Cost: 9.21s
Train Epoch: 220 	Average Loss: 5.1732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3939

Learning rate: 0.000197357890287316
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 6.2897	Cost: 68.95s
Train Epoch: 221 [20480/90000 (23%)]	Loss: 4.8700	Cost: 12.90s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 4.8975	Cost: 23.07s
Train Epoch: 221 [61440/90000 (68%)]	Loss: 5.1244	Cost: 12.43s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 5.0640	Cost: 27.16s
Train Epoch: 221 	Average Loss: 5.1180
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3121

Learning rate: 0.00019733392406205528
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 6.1609	Cost: 78.44s
Train Epoch: 222 [20480/90000 (23%)]	Loss: 4.9820	Cost: 12.72s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 4.8759	Cost: 22.87s
Train Epoch: 222 [61440/90000 (68%)]	Loss: 5.0917	Cost: 12.77s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 5.0714	Cost: 23.53s
Train Epoch: 222 	Average Loss: 5.0691
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3508

Learning rate: 0.00019730985109821266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 6.2193	Cost: 74.20s
Train Epoch: 223 [20480/90000 (23%)]	Loss: 4.8795	Cost: 13.13s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 4.8047	Cost: 22.95s
Train Epoch: 223 [61440/90000 (68%)]	Loss: 5.0480	Cost: 12.30s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 5.0498	Cost: 17.22s
Train Epoch: 223 	Average Loss: 5.0546
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2640

Learning rate: 0.00019728567142218703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 6.2075	Cost: 28.71s
Train Epoch: 224 [20480/90000 (23%)]	Loss: 4.8648	Cost: 9.67s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 4.9048	Cost: 10.22s
Train Epoch: 224 [61440/90000 (68%)]	Loss: 5.0963	Cost: 9.46s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 5.0502	Cost: 9.38s
Train Epoch: 224 	Average Loss: 5.0648
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2656

Learning rate: 0.00019726138506049435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 6.3295	Cost: 28.73s
Train Epoch: 225 [20480/90000 (23%)]	Loss: 4.8476	Cost: 9.72s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 4.9280	Cost: 10.58s
Train Epoch: 225 [61440/90000 (68%)]	Loss: 4.8827	Cost: 9.49s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 5.0306	Cost: 9.22s
Train Epoch: 225 	Average Loss: 5.0253
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2663

Learning rate: 0.00019723699203976766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 6.0765	Cost: 29.93s
Train Epoch: 226 [20480/90000 (23%)]	Loss: 4.8283	Cost: 9.65s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 4.6866	Cost: 10.37s
Train Epoch: 226 [61440/90000 (68%)]	Loss: 4.8110	Cost: 9.40s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 4.7870	Cost: 9.27s
Train Epoch: 226 	Average Loss: 4.9518
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2127

Learning rate: 0.00019721249238675688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 6.1725	Cost: 28.94s
Train Epoch: 227 [20480/90000 (23%)]	Loss: 4.7167	Cost: 9.69s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 4.7270	Cost: 10.34s
Train Epoch: 227 [61440/90000 (68%)]	Loss: 4.8176	Cost: 9.40s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 4.7949	Cost: 9.21s
Train Epoch: 227 	Average Loss: 4.8920
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1889

Learning rate: 0.00019718788612832884
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 6.0707	Cost: 28.91s
Train Epoch: 228 [20480/90000 (23%)]	Loss: 4.6735	Cost: 9.61s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 4.8039	Cost: 11.05s
Train Epoch: 228 [61440/90000 (68%)]	Loss: 4.8474	Cost: 9.38s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 4.6945	Cost: 9.38s
Train Epoch: 228 	Average Loss: 4.8432
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1542

Learning rate: 0.0001971631732914674
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 6.2187	Cost: 29.27s
Train Epoch: 229 [20480/90000 (23%)]	Loss: 4.6628	Cost: 13.18s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 4.5311	Cost: 19.34s
Train Epoch: 229 [61440/90000 (68%)]	Loss: 4.7415	Cost: 13.00s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 4.7708	Cost: 25.43s
Train Epoch: 229 	Average Loss: 4.8418
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0844

Learning rate: 0.00019713835390327314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 6.0260	Cost: 78.91s
Train Epoch: 230 [20480/90000 (23%)]	Loss: 4.6717	Cost: 12.55s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 4.5378	Cost: 24.04s
Train Epoch: 230 [61440/90000 (68%)]	Loss: 4.6158	Cost: 13.54s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 4.7418	Cost: 14.74s
Train Epoch: 230 	Average Loss: 4.7549
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1348

Learning rate: 0.0001971134279909636
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 6.1666	Cost: 79.75s
Train Epoch: 231 [20480/90000 (23%)]	Loss: 4.5870	Cost: 12.50s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 4.4030	Cost: 24.42s
Train Epoch: 231 [61440/90000 (68%)]	Loss: 4.5277	Cost: 11.16s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 4.6640	Cost: 27.05s
Train Epoch: 231 	Average Loss: 4.7203
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0146

Learning rate: 0.00019708839558187308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 5.9101	Cost: 28.96s
Train Epoch: 232 [20480/90000 (23%)]	Loss: 4.5747	Cost: 9.76s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 4.4805	Cost: 11.10s
Train Epoch: 232 [61440/90000 (68%)]	Loss: 4.5261	Cost: 9.40s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 4.7754	Cost: 9.20s
Train Epoch: 232 	Average Loss: 4.7352
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2021

Learning rate: 0.0001970632567034527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 6.0146	Cost: 28.36s
Train Epoch: 233 [20480/90000 (23%)]	Loss: 4.6607	Cost: 9.71s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 4.4623	Cost: 10.86s
Train Epoch: 233 [61440/90000 (68%)]	Loss: 4.6220	Cost: 9.47s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 4.6633	Cost: 9.33s
Train Epoch: 233 	Average Loss: 4.7910
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1314

Learning rate: 0.00019703801138327035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 6.0941	Cost: 29.33s
Train Epoch: 234 [20480/90000 (23%)]	Loss: 4.3998	Cost: 9.67s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 4.3810	Cost: 10.41s
Train Epoch: 234 [61440/90000 (68%)]	Loss: 4.6918	Cost: 9.55s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 4.7573	Cost: 9.12s
Train Epoch: 234 	Average Loss: 4.6718
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9795

Learning rate: 0.00019701265964901054
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 6.0308	Cost: 29.32s
Train Epoch: 235 [20480/90000 (23%)]	Loss: 4.4278	Cost: 9.66s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 4.3896	Cost: 10.46s
Train Epoch: 235 [61440/90000 (68%)]	Loss: 4.5672	Cost: 9.44s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 4.6175	Cost: 9.15s
Train Epoch: 235 	Average Loss: 4.6230
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9925

Learning rate: 0.00019698720152847463
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 5.8637	Cost: 29.17s
Train Epoch: 236 [20480/90000 (23%)]	Loss: 4.4759	Cost: 9.72s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 4.5410	Cost: 10.56s
Train Epoch: 236 [61440/90000 (68%)]	Loss: 4.5408	Cost: 9.41s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 4.3965	Cost: 9.31s
Train Epoch: 236 	Average Loss: 4.6032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9972

Learning rate: 0.00019696163704958054
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 5.8002	Cost: 29.07s
Train Epoch: 237 [20480/90000 (23%)]	Loss: 4.5578	Cost: 9.74s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 4.3169	Cost: 10.69s
Train Epoch: 237 [61440/90000 (68%)]	Loss: 4.4098	Cost: 9.43s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 4.4679	Cost: 9.15s
Train Epoch: 237 	Average Loss: 4.5844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0075

Learning rate: 0.0001969359662403629
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 5.9266	Cost: 29.45s
Train Epoch: 238 [20480/90000 (23%)]	Loss: 4.3614	Cost: 9.63s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 4.2456	Cost: 10.40s
Train Epoch: 238 [61440/90000 (68%)]	Loss: 4.5086	Cost: 9.40s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 4.4640	Cost: 9.28s
Train Epoch: 238 	Average Loss: 4.5071
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9586

Learning rate: 0.00019691018912897283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 5.7769	Cost: 29.36s
Train Epoch: 239 [20480/90000 (23%)]	Loss: 4.3607	Cost: 9.75s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 4.2603	Cost: 10.46s
Train Epoch: 239 [61440/90000 (68%)]	Loss: 4.4423	Cost: 9.58s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 4.3191	Cost: 9.23s
Train Epoch: 239 	Average Loss: 4.4882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9120

Learning rate: 0.00019688430574367816
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 5.7856	Cost: 29.62s
Train Epoch: 240 [20480/90000 (23%)]	Loss: 4.2428	Cost: 9.78s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 4.0220	Cost: 10.09s
Train Epoch: 240 [61440/90000 (68%)]	Loss: 4.2928	Cost: 9.41s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 4.2696	Cost: 9.36s
Train Epoch: 240 	Average Loss: 4.4004
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8389

Learning rate: 0.0001968583161128631
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 5.7100	Cost: 29.58s
Train Epoch: 241 [20480/90000 (23%)]	Loss: 4.1927	Cost: 9.68s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 4.1903	Cost: 10.82s
Train Epoch: 241 [61440/90000 (68%)]	Loss: 4.3381	Cost: 9.48s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 4.2682	Cost: 9.26s
Train Epoch: 241 	Average Loss: 4.3595
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8822

Learning rate: 0.00019683222026502855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 5.6709	Cost: 28.71s
Train Epoch: 242 [20480/90000 (23%)]	Loss: 4.2750	Cost: 9.69s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 4.0730	Cost: 10.73s
Train Epoch: 242 [61440/90000 (68%)]	Loss: 4.2425	Cost: 9.45s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 4.2343	Cost: 9.24s
Train Epoch: 242 	Average Loss: 4.3194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8533

Learning rate: 0.0001968060182287918
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 5.7899	Cost: 28.67s
Train Epoch: 243 [20480/90000 (23%)]	Loss: 4.0457	Cost: 9.87s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 4.2757	Cost: 10.36s
Train Epoch: 243 [61440/90000 (68%)]	Loss: 4.4053	Cost: 9.38s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 4.5161	Cost: 9.22s
Train Epoch: 243 	Average Loss: 4.3793
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7972

Learning rate: 0.00019677971003288655
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 5.6143	Cost: 28.80s
Train Epoch: 244 [20480/90000 (23%)]	Loss: 4.2030	Cost: 9.82s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 4.0875	Cost: 10.61s
Train Epoch: 244 [61440/90000 (68%)]	Loss: 4.1898	Cost: 9.44s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 4.1914	Cost: 9.21s
Train Epoch: 244 	Average Loss: 4.3137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7634

Learning rate: 0.00019675329570616298
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 5.7240	Cost: 29.26s
Train Epoch: 245 [20480/90000 (23%)]	Loss: 4.1082	Cost: 9.85s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 4.0132	Cost: 10.38s
Train Epoch: 245 [61440/90000 (68%)]	Loss: 4.0685	Cost: 9.61s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 4.0223	Cost: 9.21s
Train Epoch: 245 	Average Loss: 4.2154
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6577

Learning rate: 0.0001967267752775877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 5.8447	Cost: 28.77s
Train Epoch: 246 [20480/90000 (23%)]	Loss: 4.1153	Cost: 9.76s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 4.1199	Cost: 10.67s
Train Epoch: 246 [61440/90000 (68%)]	Loss: 4.1918	Cost: 9.39s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 4.1203	Cost: 9.20s
Train Epoch: 246 	Average Loss: 4.2069
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6421

Learning rate: 0.0001967001487762435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 5.4760	Cost: 28.85s
Train Epoch: 247 [20480/90000 (23%)]	Loss: 3.9821	Cost: 9.77s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 3.8653	Cost: 10.53s
Train Epoch: 247 [61440/90000 (68%)]	Loss: 3.9951	Cost: 9.43s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 3.9921	Cost: 9.39s
Train Epoch: 247 	Average Loss: 4.1021
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6650

Learning rate: 0.00019667341623132967
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 5.4221	Cost: 29.19s
Train Epoch: 248 [20480/90000 (23%)]	Loss: 3.9867	Cost: 9.65s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 3.8891	Cost: 10.76s
Train Epoch: 248 [61440/90000 (68%)]	Loss: 4.0517	Cost: 9.37s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 3.9948	Cost: 9.22s
Train Epoch: 248 	Average Loss: 4.0911
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5895

Learning rate: 0.00019664657767216176
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 5.5189	Cost: 29.03s
Train Epoch: 249 [20480/90000 (23%)]	Loss: 3.8698	Cost: 9.76s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 3.9337	Cost: 10.41s
Train Epoch: 249 [61440/90000 (68%)]	Loss: 4.0933	Cost: 9.55s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 4.0495	Cost: 9.23s
Train Epoch: 249 	Average Loss: 4.0873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5735

Learning rate: 0.00019661963312817148
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 5.4341	Cost: 28.54s
Train Epoch: 250 [20480/90000 (23%)]	Loss: 3.9226	Cost: 9.71s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 3.8990	Cost: 10.77s
Train Epoch: 250 [61440/90000 (68%)]	Loss: 3.9393	Cost: 9.46s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 3.9910	Cost: 9.53s
Train Epoch: 250 	Average Loss: 4.0612
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6211

Saving model as model.pt_e250 & waveforms_supplementary.hdf5_e250
Learning rate: 0.0001965925826289068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 5.2924	Cost: 28.72s
Train Epoch: 251 [20480/90000 (23%)]	Loss: 3.8132	Cost: 9.75s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 3.7564	Cost: 10.65s
Train Epoch: 251 [61440/90000 (68%)]	Loss: 3.9385	Cost: 9.38s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 3.9816	Cost: 9.75s
Train Epoch: 251 	Average Loss: 4.0335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5908

Learning rate: 0.000196565426204032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 5.6569	Cost: 29.62s
Train Epoch: 252 [20480/90000 (23%)]	Loss: 4.0355	Cost: 9.76s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 3.8599	Cost: 10.59s
Train Epoch: 252 [61440/90000 (68%)]	Loss: 3.9720	Cost: 9.42s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 3.9572	Cost: 9.20s
Train Epoch: 252 	Average Loss: 4.0621
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5396

Learning rate: 0.00019653816388332735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 5.2646	Cost: 29.84s
Train Epoch: 253 [20480/90000 (23%)]	Loss: 3.7841	Cost: 9.80s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 3.5646	Cost: 10.18s
Train Epoch: 253 [61440/90000 (68%)]	Loss: 3.9678	Cost: 9.43s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 3.9384	Cost: 9.19s
Train Epoch: 253 	Average Loss: 3.9493
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5705

Learning rate: 0.0001965107956966894
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 5.4142	Cost: 29.75s
Train Epoch: 254 [20480/90000 (23%)]	Loss: 4.0503	Cost: 9.69s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 3.8885	Cost: 10.75s
Train Epoch: 254 [61440/90000 (68%)]	Loss: 3.9789	Cost: 9.41s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 3.9995	Cost: 9.17s
Train Epoch: 254 	Average Loss: 4.1026
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5115

Learning rate: 0.00019648332167413062
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 5.3714	Cost: 29.05s
Train Epoch: 255 [20480/90000 (23%)]	Loss: 3.8148	Cost: 9.79s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 3.6983	Cost: 10.88s
Train Epoch: 255 [61440/90000 (68%)]	Loss: 3.7142	Cost: 9.38s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 3.7686	Cost: 9.20s
Train Epoch: 255 	Average Loss: 3.8778
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5047

Learning rate: 0.00019645574184577974
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 5.2597	Cost: 28.93s
Train Epoch: 256 [20480/90000 (23%)]	Loss: 3.6788	Cost: 9.82s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 3.6218	Cost: 10.34s
Train Epoch: 256 [61440/90000 (68%)]	Loss: 3.7170	Cost: 9.45s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 3.7247	Cost: 9.27s
Train Epoch: 256 	Average Loss: 3.8200
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4464

Learning rate: 0.00019642805624188142
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 5.1769	Cost: 29.20s
Train Epoch: 257 [20480/90000 (23%)]	Loss: 3.5483	Cost: 9.77s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 3.5728	Cost: 10.64s
Train Epoch: 257 [61440/90000 (68%)]	Loss: 3.8027	Cost: 9.73s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 3.8469	Cost: 9.13s
Train Epoch: 257 	Average Loss: 3.8048
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4376

Learning rate: 0.00019640026489279626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 5.3693	Cost: 28.79s
Train Epoch: 258 [20480/90000 (23%)]	Loss: 3.6547	Cost: 9.74s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 3.4895	Cost: 10.98s
Train Epoch: 258 [61440/90000 (68%)]	Loss: 3.6185	Cost: 9.41s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 3.6521	Cost: 9.20s
Train Epoch: 258 	Average Loss: 3.7865
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4119

Learning rate: 0.00019637236782900092
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 5.2713	Cost: 29.97s
Train Epoch: 259 [20480/90000 (23%)]	Loss: 3.5112	Cost: 9.86s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 3.4422	Cost: 10.47s
Train Epoch: 259 [61440/90000 (68%)]	Loss: 3.5026	Cost: 9.43s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 3.6291	Cost: 9.43s
Train Epoch: 259 	Average Loss: 3.6703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3805

Learning rate: 0.00019634436508108794
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 5.1245	Cost: 29.58s
Train Epoch: 260 [20480/90000 (23%)]	Loss: 3.4752	Cost: 9.70s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 3.4107	Cost: 10.48s
Train Epoch: 260 [61440/90000 (68%)]	Loss: 3.4750	Cost: 9.43s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 3.6504	Cost: 9.25s
Train Epoch: 260 	Average Loss: 3.6396
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4063

Learning rate: 0.00019631625667976578
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 5.2571	Cost: 29.08s
Train Epoch: 261 [20480/90000 (23%)]	Loss: 3.5563	Cost: 9.77s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 3.4130	Cost: 10.73s
Train Epoch: 261 [61440/90000 (68%)]	Loss: 3.4612	Cost: 9.38s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 3.5942	Cost: 9.25s
Train Epoch: 261 	Average Loss: 3.6740
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3033

Learning rate: 0.00019628804265585872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 5.2261	Cost: 28.98s
Train Epoch: 262 [20480/90000 (23%)]	Loss: 3.4420	Cost: 9.81s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 3.3456	Cost: 10.37s
Train Epoch: 262 [61440/90000 (68%)]	Loss: 3.6007	Cost: 9.42s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 3.6807	Cost: 9.22s
Train Epoch: 262 	Average Loss: 3.6232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4513

Learning rate: 0.0001962597230403069
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 5.4694	Cost: 28.84s
Train Epoch: 263 [20480/90000 (23%)]	Loss: 3.4619	Cost: 9.83s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 3.3426	Cost: 10.37s
Train Epoch: 263 [61440/90000 (68%)]	Loss: 3.5638	Cost: 9.46s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 3.5978	Cost: 9.14s
Train Epoch: 263 	Average Loss: 3.6309
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2394

Learning rate: 0.00019623129786416627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 5.2018	Cost: 29.00s
Train Epoch: 264 [20480/90000 (23%)]	Loss: 3.4002	Cost: 9.73s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 3.3725	Cost: 10.62s
Train Epoch: 264 [61440/90000 (68%)]	Loss: 3.4570	Cost: 9.51s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 3.5033	Cost: 9.18s
Train Epoch: 264 	Average Loss: 3.5630
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2459

Learning rate: 0.0001962027671586085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 5.1207	Cost: 29.22s
Train Epoch: 265 [20480/90000 (23%)]	Loss: 3.3087	Cost: 9.81s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 3.3464	Cost: 10.54s
Train Epoch: 265 [61440/90000 (68%)]	Loss: 3.3771	Cost: 9.42s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 3.2972	Cost: 9.22s
Train Epoch: 265 	Average Loss: 3.4986
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1668

Learning rate: 0.00019617413095492106
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 5.0013	Cost: 29.39s
Train Epoch: 266 [20480/90000 (23%)]	Loss: 3.2111	Cost: 9.88s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 3.1194	Cost: 10.49s
Train Epoch: 266 [61440/90000 (68%)]	Loss: 3.6147	Cost: 9.51s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 3.7599	Cost: 9.38s
Train Epoch: 266 	Average Loss: 3.4869
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3350

Learning rate: 0.000196145389284507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 5.3466	Cost: 28.90s
Train Epoch: 267 [20480/90000 (23%)]	Loss: 3.5876	Cost: 9.82s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 3.3790	Cost: 10.01s
Train Epoch: 267 [61440/90000 (68%)]	Loss: 3.6823	Cost: 9.42s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 3.4572	Cost: 9.25s
Train Epoch: 267 	Average Loss: 3.5643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1090

Learning rate: 0.0001961165421788851
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 5.1189	Cost: 29.11s
Train Epoch: 268 [20480/90000 (23%)]	Loss: 3.3139	Cost: 9.86s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 3.1111	Cost: 10.39s
Train Epoch: 268 [61440/90000 (68%)]	Loss: 3.3566	Cost: 9.60s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 3.3013	Cost: 9.23s
Train Epoch: 268 	Average Loss: 3.4474
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0443

Learning rate: 0.00019608758966968977
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 4.9484	Cost: 29.58s
Train Epoch: 269 [20480/90000 (23%)]	Loss: 3.1501	Cost: 9.78s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 2.9324	Cost: 9.92s
Train Epoch: 269 [61440/90000 (68%)]	Loss: 3.1747	Cost: 9.42s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 3.3112	Cost: 9.27s
Train Epoch: 269 	Average Loss: 3.3209
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9819

Learning rate: 0.00019605853178867095
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 5.1200	Cost: 29.55s
Train Epoch: 270 [20480/90000 (23%)]	Loss: 3.0959	Cost: 9.67s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 3.0289	Cost: 10.82s
Train Epoch: 270 [61440/90000 (68%)]	Loss: 3.5137	Cost: 9.42s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 3.2932	Cost: 9.30s
Train Epoch: 270 	Average Loss: 3.3692
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1625

Learning rate: 0.0001960293685676942
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 4.9441	Cost: 29.34s
Train Epoch: 271 [20480/90000 (23%)]	Loss: 3.3583	Cost: 10.32s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 3.0737	Cost: 9.65s
Train Epoch: 271 [61440/90000 (68%)]	Loss: 3.2456	Cost: 9.42s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 3.1682	Cost: 9.28s
Train Epoch: 271 	Average Loss: 3.4233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0862

Learning rate: 0.00019600010003874058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 4.9555	Cost: 29.78s
Train Epoch: 272 [20480/90000 (23%)]	Loss: 3.0796	Cost: 9.74s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 3.0216	Cost: 10.29s
Train Epoch: 272 [61440/90000 (68%)]	Loss: 3.1150	Cost: 9.60s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 3.0868	Cost: 9.12s
Train Epoch: 272 	Average Loss: 3.2324
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0705

Learning rate: 0.0001959707262339066
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 4.8336	Cost: 28.93s
Train Epoch: 273 [20480/90000 (23%)]	Loss: 3.0918	Cost: 9.71s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 2.8119	Cost: 10.55s
Train Epoch: 273 [61440/90000 (68%)]	Loss: 3.1866	Cost: 9.48s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 3.1113	Cost: 9.21s
Train Epoch: 273 	Average Loss: 3.1905
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9646

Learning rate: 0.0001959412471854042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 5.1380	Cost: 29.66s
Train Epoch: 274 [20480/90000 (23%)]	Loss: 3.0021	Cost: 9.63s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 2.8720	Cost: 10.75s
Train Epoch: 274 [61440/90000 (68%)]	Loss: 2.9537	Cost: 9.41s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 2.9363	Cost: 9.21s
Train Epoch: 274 	Average Loss: 3.1218
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8508

Learning rate: 0.00019591166292556083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 5.0234	Cost: 30.00s
Train Epoch: 275 [20480/90000 (23%)]	Loss: 2.8243	Cost: 9.63s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 2.7609	Cost: 10.53s
Train Epoch: 275 [61440/90000 (68%)]	Loss: 2.9100	Cost: 9.39s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 2.9772	Cost: 9.20s
Train Epoch: 275 	Average Loss: 3.0350
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8367

Learning rate: 0.00019588197348681922
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 4.7910	Cost: 29.33s
Train Epoch: 276 [20480/90000 (23%)]	Loss: 2.7345	Cost: 9.66s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 2.6626	Cost: 10.57s
Train Epoch: 276 [61440/90000 (68%)]	Loss: 3.0209	Cost: 9.42s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 3.0943	Cost: 9.21s
Train Epoch: 276 	Average Loss: 3.0466
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7921

Learning rate: 0.0001958521789017375
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 4.8251	Cost: 28.92s
Train Epoch: 277 [20480/90000 (23%)]	Loss: 2.9241	Cost: 9.60s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 2.7767	Cost: 10.66s
Train Epoch: 277 [61440/90000 (68%)]	Loss: 2.8113	Cost: 9.41s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 2.9867	Cost: 9.27s
Train Epoch: 277 	Average Loss: 3.0395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8853

Learning rate: 0.00019582227920298905
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 4.8114	Cost: 29.50s
Train Epoch: 278 [20480/90000 (23%)]	Loss: 3.0141	Cost: 9.67s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 2.8392	Cost: 10.42s
Train Epoch: 278 [61440/90000 (68%)]	Loss: 3.0192	Cost: 9.50s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 3.0198	Cost: 9.18s
Train Epoch: 278 	Average Loss: 3.1142
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9815

Learning rate: 0.00019579227442336267
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 4.8468	Cost: 28.58s
Train Epoch: 279 [20480/90000 (23%)]	Loss: 2.7282	Cost: 9.85s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 2.6075	Cost: 10.50s
Train Epoch: 279 [61440/90000 (68%)]	Loss: 2.8746	Cost: 9.52s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 2.9384	Cost: 9.35s
Train Epoch: 279 	Average Loss: 2.9614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8179

Learning rate: 0.0001957621645957621
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 4.8622	Cost: 28.97s
Train Epoch: 280 [20480/90000 (23%)]	Loss: 2.5759	Cost: 9.69s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 2.4825	Cost: 10.71s
Train Epoch: 280 [61440/90000 (68%)]	Loss: 2.8318	Cost: 9.43s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 2.7082	Cost: 9.12s
Train Epoch: 280 	Average Loss: 2.8489
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7415

Learning rate: 0.00019573194975320662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 4.6707	Cost: 29.23s
Train Epoch: 281 [20480/90000 (23%)]	Loss: 2.5856	Cost: 9.71s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 2.6088	Cost: 10.73s
Train Epoch: 281 [61440/90000 (68%)]	Loss: 2.7606	Cost: 9.43s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 2.6725	Cost: 9.22s
Train Epoch: 281 	Average Loss: 2.8372
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8013

Learning rate: 0.00019570162992883045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 4.5661	Cost: 28.99s
Train Epoch: 282 [20480/90000 (23%)]	Loss: 2.6796	Cost: 9.76s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 2.4817	Cost: 10.58s
Train Epoch: 282 [61440/90000 (68%)]	Loss: 2.9069	Cost: 9.41s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 2.6998	Cost: 9.22s
Train Epoch: 282 	Average Loss: 2.8260
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8618

Learning rate: 0.00019567120515588297
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 4.8541	Cost: 28.94s
Train Epoch: 283 [20480/90000 (23%)]	Loss: 3.0504	Cost: 9.85s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 2.8000	Cost: 10.69s
Train Epoch: 283 [61440/90000 (68%)]	Loss: 2.9032	Cost: 9.42s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 2.7368	Cost: 9.26s
Train Epoch: 283 	Average Loss: 2.9957
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7762

Learning rate: 0.00019564067546772867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 4.7131	Cost: 28.42s
Train Epoch: 284 [20480/90000 (23%)]	Loss: 2.5332	Cost: 9.79s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 2.5625	Cost: 10.65s
Train Epoch: 284 [61440/90000 (68%)]	Loss: 2.8400	Cost: 9.47s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 2.7953	Cost: 9.25s
Train Epoch: 284 	Average Loss: 2.8458
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7721

Learning rate: 0.00019561004089784715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 4.4930	Cost: 29.23s
Train Epoch: 285 [20480/90000 (23%)]	Loss: 2.4397	Cost: 9.78s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 2.3721	Cost: 10.06s
Train Epoch: 285 [61440/90000 (68%)]	Loss: 2.6023	Cost: 9.42s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 2.7480	Cost: 9.18s
Train Epoch: 285 	Average Loss: 2.7379
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6794

Learning rate: 0.0001955793014798329
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 4.6215	Cost: 28.66s
Train Epoch: 286 [20480/90000 (23%)]	Loss: 2.4394	Cost: 9.95s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 2.3622	Cost: 10.42s
Train Epoch: 286 [61440/90000 (68%)]	Loss: 2.5853	Cost: 9.43s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 2.6904	Cost: 9.31s
Train Epoch: 286 	Average Loss: 2.6814
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7939

Learning rate: 0.00019554845724739558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 4.5950	Cost: 29.47s
Train Epoch: 287 [20480/90000 (23%)]	Loss: 2.4206	Cost: 9.81s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 2.3367	Cost: 9.92s
Train Epoch: 287 [61440/90000 (68%)]	Loss: 2.5094	Cost: 9.43s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 2.7195	Cost: 9.21s
Train Epoch: 287 	Average Loss: 2.6972
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6352

Learning rate: 0.00019551750823435952
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 4.4915	Cost: 29.80s
Train Epoch: 288 [20480/90000 (23%)]	Loss: 2.4211	Cost: 9.76s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 2.5655	Cost: 10.57s
Train Epoch: 288 [61440/90000 (68%)]	Loss: 2.5605	Cost: 9.45s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 2.5904	Cost: 9.19s
Train Epoch: 288 	Average Loss: 2.6883
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5258

Learning rate: 0.00019548645447466423
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 4.3972	Cost: 29.61s
Train Epoch: 289 [20480/90000 (23%)]	Loss: 2.4200	Cost: 9.58s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 2.2422	Cost: 10.52s
Train Epoch: 289 [61440/90000 (68%)]	Loss: 2.4317	Cost: 9.57s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 2.2723	Cost: 9.20s
Train Epoch: 289 	Average Loss: 2.5085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4917

Learning rate: 0.0001954552960023639
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 4.3421	Cost: 29.41s
Train Epoch: 290 [20480/90000 (23%)]	Loss: 2.4620	Cost: 9.75s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 2.1550	Cost: 10.55s
Train Epoch: 290 [61440/90000 (68%)]	Loss: 2.6856	Cost: 9.46s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 3.0046	Cost: 9.21s
Train Epoch: 290 	Average Loss: 2.7586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9737

Learning rate: 0.00019542403285162762
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 4.9464	Cost: 29.49s
Train Epoch: 291 [20480/90000 (23%)]	Loss: 2.5638	Cost: 9.75s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 2.4768	Cost: 10.52s
Train Epoch: 291 [61440/90000 (68%)]	Loss: 2.5253	Cost: 9.50s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 2.6782	Cost: 9.20s
Train Epoch: 291 	Average Loss: 2.7351
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5633

Learning rate: 0.0001953926650567393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 4.2864	Cost: 29.71s
Train Epoch: 292 [20480/90000 (23%)]	Loss: 2.5333	Cost: 9.77s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 2.2745	Cost: 10.18s
Train Epoch: 292 [61440/90000 (68%)]	Loss: 2.4969	Cost: 9.43s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 2.4571	Cost: 9.20s
Train Epoch: 292 	Average Loss: 2.5682
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5612

Learning rate: 0.00019536119265209752
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 4.5895	Cost: 28.93s
Train Epoch: 293 [20480/90000 (23%)]	Loss: 2.2501	Cost: 10.03s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 2.3273	Cost: 9.90s
Train Epoch: 293 [61440/90000 (68%)]	Loss: 2.4911	Cost: 9.47s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 2.3764	Cost: 9.23s
Train Epoch: 293 	Average Loss: 2.5382
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4321

Learning rate: 0.00019532961567221568
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 4.4196	Cost: 29.22s
Train Epoch: 294 [20480/90000 (23%)]	Loss: 2.3667	Cost: 9.72s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 2.1841	Cost: 10.15s
Train Epoch: 294 [61440/90000 (68%)]	Loss: 2.4613	Cost: 9.50s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 2.3134	Cost: 9.29s
Train Epoch: 294 	Average Loss: 2.5238
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4544

Learning rate: 0.0001952979341517218
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 4.1293	Cost: 29.38s
Train Epoch: 295 [20480/90000 (23%)]	Loss: 2.3153	Cost: 9.79s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 2.0648	Cost: 10.70s
Train Epoch: 295 [61440/90000 (68%)]	Loss: 2.2990	Cost: 9.39s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 2.3203	Cost: 9.19s
Train Epoch: 295 	Average Loss: 2.4240
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4640

Learning rate: 0.00019526614812535853
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 4.2145	Cost: 29.74s
Train Epoch: 296 [20480/90000 (23%)]	Loss: 1.9908	Cost: 9.82s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 2.2633	Cost: 10.49s
Train Epoch: 296 [61440/90000 (68%)]	Loss: 2.3661	Cost: 9.47s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 2.2002	Cost: 9.22s
Train Epoch: 296 	Average Loss: 2.3361
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3122

Learning rate: 0.00019523425762798318
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 3.9652	Cost: 30.72s
Train Epoch: 297 [20480/90000 (23%)]	Loss: 2.2691	Cost: 9.72s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 2.0730	Cost: 9.94s
Train Epoch: 297 [61440/90000 (68%)]	Loss: 2.2287	Cost: 9.42s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 2.2180	Cost: 9.22s
Train Epoch: 297 	Average Loss: 2.3679
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3721

Learning rate: 0.00019520226269456755
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 4.0928	Cost: 28.78s
Train Epoch: 298 [20480/90000 (23%)]	Loss: 1.9103	Cost: 9.81s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 1.9378	Cost: 10.45s
Train Epoch: 298 [61440/90000 (68%)]	Loss: 2.2556	Cost: 9.41s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 2.1834	Cost: 9.26s
Train Epoch: 298 	Average Loss: 2.2097
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2340

Learning rate: 0.00019517016336019803
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 4.3033	Cost: 29.18s
Train Epoch: 299 [20480/90000 (23%)]	Loss: 2.1549	Cost: 9.73s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 2.0171	Cost: 10.18s
Train Epoch: 299 [61440/90000 (68%)]	Loss: 2.1738	Cost: 9.41s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 2.1815	Cost: 9.20s
Train Epoch: 299 	Average Loss: 2.2547
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1929

Learning rate: 0.0001951379596600755
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 3.9881	Cost: 29.26s
Train Epoch: 300 [20480/90000 (23%)]	Loss: 1.9136	Cost: 9.78s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 2.0007	Cost: 10.71s
Train Epoch: 300 [61440/90000 (68%)]	Loss: 2.2355	Cost: 9.43s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 2.2862	Cost: 9.29s
Train Epoch: 300 	Average Loss: 2.2607
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4645

Saving model as model.pt_e300 & waveforms_supplementary.hdf5_e300
Learning rate: 0.00019510565162951526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 4.3496	Cost: 29.10s
Train Epoch: 301 [20480/90000 (23%)]	Loss: 2.3303	Cost: 9.81s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 2.2767	Cost: 10.29s
Train Epoch: 301 [61440/90000 (68%)]	Loss: 2.2606	Cost: 9.37s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 2.1387	Cost: 9.23s
Train Epoch: 301 	Average Loss: 2.4019
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3465

Learning rate: 0.00019507323930394695
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 4.2650	Cost: 28.86s
Train Epoch: 302 [20480/90000 (23%)]	Loss: 1.9882	Cost: 9.82s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 1.7093	Cost: 10.50s
Train Epoch: 302 [61440/90000 (68%)]	Loss: 1.8725	Cost: 9.51s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 1.9688	Cost: 9.21s
Train Epoch: 302 	Average Loss: 2.1054
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1546

Learning rate: 0.00019504072271891475
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 4.1208	Cost: 29.03s
Train Epoch: 303 [20480/90000 (23%)]	Loss: 1.8872	Cost: 10.14s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 1.8029	Cost: 9.92s
Train Epoch: 303 [61440/90000 (68%)]	Loss: 1.7994	Cost: 9.41s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 1.9599	Cost: 9.16s
Train Epoch: 303 	Average Loss: 2.0537
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2040

Learning rate: 0.00019500810191007704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 4.0377	Cost: 29.69s
Train Epoch: 304 [20480/90000 (23%)]	Loss: 1.7783	Cost: 9.73s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 1.5556	Cost: 10.73s
Train Epoch: 304 [61440/90000 (68%)]	Loss: 2.3960	Cost: 9.41s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 2.2881	Cost: 9.27s
Train Epoch: 304 	Average Loss: 2.1792
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3464

Learning rate: 0.00019497537691320655
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 4.1924	Cost: 30.01s
Train Epoch: 305 [20480/90000 (23%)]	Loss: 1.8566	Cost: 9.87s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 1.7377	Cost: 10.10s
Train Epoch: 305 [61440/90000 (68%)]	Loss: 1.9034	Cost: 9.45s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 1.8420	Cost: 9.19s
Train Epoch: 305 	Average Loss: 2.0510
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0146

Learning rate: 0.00019494254776419027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 4.2194	Cost: 29.04s
Train Epoch: 306 [20480/90000 (23%)]	Loss: 1.5825	Cost: 9.84s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 1.3423	Cost: 10.47s
Train Epoch: 306 [61440/90000 (68%)]	Loss: 1.7687	Cost: 9.43s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 1.9611	Cost: 9.37s
Train Epoch: 306 	Average Loss: 1.9018
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2121

Learning rate: 0.00019490961449902933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 4.1235	Cost: 29.42s
Train Epoch: 307 [20480/90000 (23%)]	Loss: 1.6890	Cost: 9.77s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 1.4455	Cost: 10.97s
Train Epoch: 307 [61440/90000 (68%)]	Loss: 1.8433	Cost: 9.67s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 1.7697	Cost: 9.17s
Train Epoch: 307 	Average Loss: 1.9571
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0473

Learning rate: 0.00019487657715383912
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 3.8495	Cost: 28.92s
Train Epoch: 308 [20480/90000 (23%)]	Loss: 1.5564	Cost: 10.34s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 1.4726	Cost: 10.24s
Train Epoch: 308 [61440/90000 (68%)]	Loss: 1.7607	Cost: 9.44s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 1.7534	Cost: 9.22s
Train Epoch: 308 	Average Loss: 1.8524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9504

Learning rate: 0.0001948434357648492
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 3.8935	Cost: 29.37s
Train Epoch: 309 [20480/90000 (23%)]	Loss: 1.4800	Cost: 9.80s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 1.4955	Cost: 10.44s
Train Epoch: 309 [61440/90000 (68%)]	Loss: 1.6023	Cost: 9.62s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 1.6985	Cost: 9.22s
Train Epoch: 309 	Average Loss: 1.7619
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9105

Learning rate: 0.00019481019036840305
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 3.8752	Cost: 29.32s
Train Epoch: 310 [20480/90000 (23%)]	Loss: 1.4641	Cost: 9.65s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 1.2321	Cost: 10.84s
Train Epoch: 310 [61440/90000 (68%)]	Loss: 1.7396	Cost: 9.39s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 1.9137	Cost: 9.31s
Train Epoch: 310 	Average Loss: 1.7601
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0245

Learning rate: 0.00019477684100095846
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 4.2058	Cost: 29.69s
Train Epoch: 311 [20480/90000 (23%)]	Loss: 1.6865	Cost: 9.77s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 1.5747	Cost: 10.81s
Train Epoch: 311 [61440/90000 (68%)]	Loss: 1.7135	Cost: 9.77s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 1.7643	Cost: 9.12s
Train Epoch: 311 	Average Loss: 1.8193
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0403

Learning rate: 0.00019474338769908696
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 3.9626	Cost: 28.75s
Train Epoch: 312 [20480/90000 (23%)]	Loss: 1.6549	Cost: 9.75s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 1.4499	Cost: 10.83s
Train Epoch: 312 [61440/90000 (68%)]	Loss: 1.6044	Cost: 9.44s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 1.6189	Cost: 9.26s
Train Epoch: 312 	Average Loss: 1.7691
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9427

Learning rate: 0.00019470983049947428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 3.8445	Cost: 29.84s
Train Epoch: 313 [20480/90000 (23%)]	Loss: 1.5325	Cost: 9.90s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 1.3338	Cost: 10.40s
Train Epoch: 313 [61440/90000 (68%)]	Loss: 1.5720	Cost: 9.62s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 1.4499	Cost: 9.22s
Train Epoch: 313 	Average Loss: 1.6620
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8069

Learning rate: 0.00019467616943892
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 3.8540	Cost: 29.27s
Train Epoch: 314 [20480/90000 (23%)]	Loss: 1.5348	Cost: 10.18s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 1.4932	Cost: 10.18s
Train Epoch: 314 [61440/90000 (68%)]	Loss: 1.6767	Cost: 9.50s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 1.6741	Cost: 9.25s
Train Epoch: 314 	Average Loss: 1.7954
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9229

Learning rate: 0.00019464240455433756
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 3.5178	Cost: 29.01s
Train Epoch: 315 [20480/90000 (23%)]	Loss: 1.3076	Cost: 9.67s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 1.2682	Cost: 10.96s
Train Epoch: 315 [61440/90000 (68%)]	Loss: 1.5945	Cost: 9.63s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 1.3919	Cost: 9.15s
Train Epoch: 315 	Average Loss: 1.6217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8308

Learning rate: 0.00019460853588275435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 3.7020	Cost: 29.88s
Train Epoch: 316 [20480/90000 (23%)]	Loss: 1.2944	Cost: 10.41s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 1.1359	Cost: 10.13s
Train Epoch: 316 [61440/90000 (68%)]	Loss: 1.5026	Cost: 9.42s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 1.6078	Cost: 9.27s
Train Epoch: 316 	Average Loss: 1.5750
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8082

Learning rate: 0.0001945745634613115
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 3.8011	Cost: 28.91s
Train Epoch: 317 [20480/90000 (23%)]	Loss: 1.2493	Cost: 9.84s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 0.9069	Cost: 10.56s
Train Epoch: 317 [61440/90000 (68%)]	Loss: 1.3551	Cost: 9.69s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 1.3326	Cost: 9.21s
Train Epoch: 317 	Average Loss: 1.4563
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7454

Learning rate: 0.00019454048732726396
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 3.6076	Cost: 29.24s
Train Epoch: 318 [20480/90000 (23%)]	Loss: 1.2637	Cost: 9.90s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 0.9663	Cost: 10.42s
Train Epoch: 318 [61440/90000 (68%)]	Loss: 1.2886	Cost: 9.47s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 1.2086	Cost: 9.21s
Train Epoch: 318 	Average Loss: 1.4052
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6071

Learning rate: 0.00019450630751798032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 3.6069	Cost: 29.58s
Train Epoch: 319 [20480/90000 (23%)]	Loss: 1.3001	Cost: 9.89s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 1.0364	Cost: 10.02s
Train Epoch: 319 [61440/90000 (68%)]	Loss: 1.3788	Cost: 9.59s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 1.3587	Cost: 9.18s
Train Epoch: 319 	Average Loss: 1.4186
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6857

Learning rate: 0.000194472024070943
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 3.4574	Cost: 28.49s
Train Epoch: 320 [20480/90000 (23%)]	Loss: 1.1736	Cost: 9.83s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 0.9425	Cost: 10.72s
Train Epoch: 320 [61440/90000 (68%)]	Loss: 1.2673	Cost: 10.08s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 1.1678	Cost: 9.29s
Train Epoch: 320 	Average Loss: 1.3770
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6369

Learning rate: 0.00019443763702374796
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 3.5131	Cost: 30.08s
Train Epoch: 321 [20480/90000 (23%)]	Loss: 1.0573	Cost: 9.72s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 0.9959	Cost: 10.25s
Train Epoch: 321 [61440/90000 (68%)]	Loss: 1.0479	Cost: 9.70s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 1.2166	Cost: 9.14s
Train Epoch: 321 	Average Loss: 1.2705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4968

Learning rate: 0.00019440314641410483
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 3.6007	Cost: 28.69s
Train Epoch: 322 [20480/90000 (23%)]	Loss: 0.8332	Cost: 9.73s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 0.7524	Cost: 10.66s
Train Epoch: 322 [61440/90000 (68%)]	Loss: 1.0446	Cost: 9.43s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 1.1135	Cost: 9.22s
Train Epoch: 322 	Average Loss: 1.2290
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6817

Learning rate: 0.00019436855227983676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 3.5437	Cost: 29.96s
Train Epoch: 323 [20480/90000 (23%)]	Loss: 1.1150	Cost: 9.73s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 1.0517	Cost: 11.02s
Train Epoch: 323 [61440/90000 (68%)]	Loss: 1.3540	Cost: 10.03s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 1.2025	Cost: 9.28s
Train Epoch: 323 	Average Loss: 1.2963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5757

Learning rate: 0.00019433385465888052
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 3.2937	Cost: 29.65s
Train Epoch: 324 [20480/90000 (23%)]	Loss: 0.8467	Cost: 9.82s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 0.9463	Cost: 10.88s
Train Epoch: 324 [61440/90000 (68%)]	Loss: 1.3963	Cost: 9.52s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 1.4442	Cost: 9.16s
Train Epoch: 324 	Average Loss: 1.3395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8332

Learning rate: 0.00019429905358928627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 3.5808	Cost: 29.08s
Train Epoch: 325 [20480/90000 (23%)]	Loss: 1.1547	Cost: 9.71s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 0.8487	Cost: 10.60s
Train Epoch: 325 [61440/90000 (68%)]	Loss: 1.2968	Cost: 9.73s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 1.2603	Cost: 9.18s
Train Epoch: 325 	Average Loss: 1.4083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8101

Learning rate: 0.00019426414910921766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 3.6754	Cost: 29.64s
Train Epoch: 326 [20480/90000 (23%)]	Loss: 1.2164	Cost: 9.71s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 0.9568	Cost: 10.56s
Train Epoch: 326 [61440/90000 (68%)]	Loss: 1.2977	Cost: 9.39s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 1.0719	Cost: 9.29s
Train Epoch: 326 	Average Loss: 1.3699
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5473

Learning rate: 0.0001942291412569517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 3.6848	Cost: 28.65s
Train Epoch: 327 [20480/90000 (23%)]	Loss: 1.1368	Cost: 9.71s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 1.0546	Cost: 10.75s
Train Epoch: 327 [61440/90000 (68%)]	Loss: 1.3305	Cost: 9.55s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 1.1339	Cost: 9.27s
Train Epoch: 327 	Average Loss: 1.3972
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7299

Learning rate: 0.00019419403007087886
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 3.7385	Cost: 29.10s
Train Epoch: 328 [20480/90000 (23%)]	Loss: 1.0881	Cost: 9.75s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 0.8769	Cost: 10.66s
Train Epoch: 328 [61440/90000 (68%)]	Loss: 1.1441	Cost: 9.52s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 1.4754	Cost: 9.22s
Train Epoch: 328 	Average Loss: 1.3592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7960

Learning rate: 0.00019415881558950283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 3.6682	Cost: 29.10s
Train Epoch: 329 [20480/90000 (23%)]	Loss: 0.9724	Cost: 9.79s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 0.8883	Cost: 10.20s
Train Epoch: 329 [61440/90000 (68%)]	Loss: 1.0769	Cost: 9.74s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 0.9459	Cost: 9.16s
Train Epoch: 329 	Average Loss: 1.2431
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5299

Learning rate: 0.00019412349785144059
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 3.2802	Cost: 29.59s
Train Epoch: 330 [20480/90000 (23%)]	Loss: 0.8080	Cost: 9.86s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 0.7323	Cost: 10.29s
Train Epoch: 330 [61440/90000 (68%)]	Loss: 1.0967	Cost: 9.49s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 1.0923	Cost: 9.18s
Train Epoch: 330 	Average Loss: 1.1298
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5536

Learning rate: 0.00019408807689542238
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 3.4190	Cost: 28.69s
Train Epoch: 331 [20480/90000 (23%)]	Loss: 0.9447	Cost: 9.90s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 1.0213	Cost: 10.51s
Train Epoch: 331 [61440/90000 (68%)]	Loss: 1.1807	Cost: 9.64s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 1.0947	Cost: 9.22s
Train Epoch: 331 	Average Loss: 1.2804
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5537

Learning rate: 0.0001940525527602916
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 3.6794	Cost: 29.32s
Train Epoch: 332 [20480/90000 (23%)]	Loss: 0.8685	Cost: 9.86s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 0.5632	Cost: 10.21s
Train Epoch: 332 [61440/90000 (68%)]	Loss: 0.9094	Cost: 9.48s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 0.7601	Cost: 9.27s
Train Epoch: 332 	Average Loss: 1.0820
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3615

Learning rate: 0.00019401692548500483
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 3.0113	Cost: 28.89s
Train Epoch: 333 [20480/90000 (23%)]	Loss: 0.6686	Cost: 9.73s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 0.5239	Cost: 10.57s
Train Epoch: 333 [61440/90000 (68%)]	Loss: 0.7689	Cost: 9.41s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 0.8534	Cost: 9.37s
Train Epoch: 333 	Average Loss: 0.9160
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3530

Learning rate: 0.00019398119510863178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 3.3122	Cost: 28.72s
Train Epoch: 334 [20480/90000 (23%)]	Loss: 0.6230	Cost: 9.76s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 0.4865	Cost: 10.61s
Train Epoch: 334 [61440/90000 (68%)]	Loss: 0.7686	Cost: 9.41s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 0.6006	Cost: 9.20s
Train Epoch: 334 	Average Loss: 0.7935
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2390

Learning rate: 0.00019394536167035515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 3.1346	Cost: 29.59s
Train Epoch: 335 [20480/90000 (23%)]	Loss: 0.6684	Cost: 9.75s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 0.3496	Cost: 10.82s
Train Epoch: 335 [61440/90000 (68%)]	Loss: 0.6325	Cost: 9.38s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 0.5166	Cost: 9.46s
Train Epoch: 335 	Average Loss: 0.7348
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3272

Learning rate: 0.0001939094252094707
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 3.1466	Cost: 29.68s
Train Epoch: 336 [20480/90000 (23%)]	Loss: 0.6520	Cost: 9.81s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 0.3127	Cost: 10.46s
Train Epoch: 336 [61440/90000 (68%)]	Loss: 0.6531	Cost: 9.40s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 0.6329	Cost: 9.31s
Train Epoch: 336 	Average Loss: 0.7264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1761

Learning rate: 0.00019387338576538722
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 2.8871	Cost: 29.46s
Train Epoch: 337 [20480/90000 (23%)]	Loss: 0.4157	Cost: 9.82s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 0.2269	Cost: 10.96s
Train Epoch: 337 [61440/90000 (68%)]	Loss: 0.4499	Cost: 9.58s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 0.4523	Cost: 9.41s
Train Epoch: 337 	Average Loss: 0.6397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1295

Learning rate: 0.0001938372433776263
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 2.9802	Cost: 28.56s
Train Epoch: 338 [20480/90000 (23%)]	Loss: 0.3675	Cost: 10.10s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 0.2436	Cost: 10.40s
Train Epoch: 338 [61440/90000 (68%)]	Loss: 0.5842	Cost: 9.85s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 0.5770	Cost: 9.25s
Train Epoch: 338 	Average Loss: 0.5903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2480

Learning rate: 0.0001938009980858226
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 3.0419	Cost: 29.10s
Train Epoch: 339 [20480/90000 (23%)]	Loss: 0.3256	Cost: 9.82s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 0.2551	Cost: 10.22s
Train Epoch: 339 [61440/90000 (68%)]	Loss: 0.5188	Cost: 9.39s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 0.2649	Cost: 9.41s
Train Epoch: 339 	Average Loss: 0.5922
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0418

Learning rate: 0.00019376464992972337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 3.2772	Cost: 29.45s
Train Epoch: 340 [20480/90000 (23%)]	Loss: 0.4026	Cost: 9.77s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 0.3061	Cost: 10.65s
Train Epoch: 340 [61440/90000 (68%)]	Loss: 0.6156	Cost: 9.41s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 0.4545	Cost: 9.26s
Train Epoch: 340 	Average Loss: 0.6199
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0703

Learning rate: 0.00019372819894918896
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 3.0526	Cost: 29.47s
Train Epoch: 341 [20480/90000 (23%)]	Loss: 0.2544	Cost: 9.79s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 0.5019	Cost: 10.36s
Train Epoch: 341 [61440/90000 (68%)]	Loss: 0.7325	Cost: 9.46s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 0.5850	Cost: 9.32s
Train Epoch: 341 	Average Loss: 0.7111
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1748

Learning rate: 0.0001936916451841923
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 3.1420	Cost: 29.53s
Train Epoch: 342 [20480/90000 (23%)]	Loss: 0.2765	Cost: 9.79s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 0.1086	Cost: 10.56s
Train Epoch: 342 [61440/90000 (68%)]	Loss: 0.4180	Cost: 9.43s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 0.4191	Cost: 9.17s
Train Epoch: 342 	Average Loss: 0.6156
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0822

Learning rate: 0.00019365498867481907
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 3.1909	Cost: 28.84s
Train Epoch: 343 [20480/90000 (23%)]	Loss: 0.3641	Cost: 9.88s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 0.0934	Cost: 10.61s
Train Epoch: 343 [61440/90000 (68%)]	Loss: 0.3837	Cost: 9.51s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 0.1874	Cost: 9.44s
Train Epoch: 343 	Average Loss: 0.4699
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0549

Learning rate: 0.00019361822946126762
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 2.6659	Cost: 29.35s
Train Epoch: 344 [20480/90000 (23%)]	Loss: 0.2958	Cost: 9.90s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 0.0450	Cost: 10.36s
Train Epoch: 344 [61440/90000 (68%)]	Loss: 0.3634	Cost: 9.39s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 0.2840	Cost: 9.22s
Train Epoch: 344 	Average Loss: 0.4509
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0397

Learning rate: 0.00019358136758384893
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 2.8870	Cost: 29.78s
Train Epoch: 345 [20480/90000 (23%)]	Loss: 0.1989	Cost: 9.80s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 0.1606	Cost: 10.87s
Train Epoch: 345 [61440/90000 (68%)]	Loss: 0.1861	Cost: 9.42s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 0.1552	Cost: 9.38s
Train Epoch: 345 	Average Loss: 0.3682
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0262

Learning rate: 0.00019354440308298656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 3.3403	Cost: 29.89s
Train Epoch: 346 [20480/90000 (23%)]	Loss: -0.0383	Cost: 9.92s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 2.5580	Cost: 10.57s
Train Epoch: 346 [61440/90000 (68%)]	Loss: 2.6360	Cost: 9.39s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 1.9658	Cost: 9.38s
Train Epoch: 346 	Average Loss: 1.7926
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1094

Learning rate: 0.0001935073359992166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 3.9924	Cost: 29.21s
Train Epoch: 347 [20480/90000 (23%)]	Loss: 1.1296	Cost: 9.74s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 0.6261	Cost: 11.03s
Train Epoch: 347 [61440/90000 (68%)]	Loss: 0.7036	Cost: 9.45s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 0.7714	Cost: 9.31s
Train Epoch: 347 	Average Loss: 1.1007
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3045

Learning rate: 0.00019347016637318777
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 2.9848	Cost: 29.41s
Train Epoch: 348 [20480/90000 (23%)]	Loss: 0.4607	Cost: 9.78s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 0.1572	Cost: 10.80s
Train Epoch: 348 [61440/90000 (68%)]	Loss: 0.5265	Cost: 9.44s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 0.3587	Cost: 9.22s
Train Epoch: 348 	Average Loss: 0.5597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9891

Learning rate: 0.00019343289424566103
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 2.9983	Cost: 28.79s
Train Epoch: 349 [20480/90000 (23%)]	Loss: 0.0908	Cost: 9.72s
Train Epoch: 349 [40960/90000 (45%)]	Loss: -0.2285	Cost: 10.51s
Train Epoch: 349 [61440/90000 (68%)]	Loss: 0.1692	Cost: 9.40s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 0.2857	Cost: 9.37s
Train Epoch: 349 	Average Loss: 0.3288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9540

Learning rate: 0.00019339551965750983
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 2.8434	Cost: 29.94s
Train Epoch: 350 [20480/90000 (23%)]	Loss: 0.6188	Cost: 9.72s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 0.4169	Cost: 10.39s
Train Epoch: 350 [61440/90000 (68%)]	Loss: 0.5083	Cost: 9.41s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 0.3520	Cost: 9.24s
Train Epoch: 350 	Average Loss: 0.6058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9737

Saving model as model.pt_e350 & waveforms_supplementary.hdf5_e350
Learning rate: 0.00019335804264971997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 2.7143	Cost: 29.83s
Train Epoch: 351 [20480/90000 (23%)]	Loss: 0.1379	Cost: 9.77s
Train Epoch: 351 [40960/90000 (45%)]	Loss: -0.0567	Cost: 10.50s
Train Epoch: 351 [61440/90000 (68%)]	Loss: 0.2698	Cost: 9.39s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 0.1028	Cost: 9.70s
Train Epoch: 351 	Average Loss: 0.3265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8078

Learning rate: 0.00019332046326338964
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 2.9507	Cost: 28.62s
Train Epoch: 352 [20480/90000 (23%)]	Loss: 0.1208	Cost: 9.82s
Train Epoch: 352 [40960/90000 (45%)]	Loss: -0.3491	Cost: 10.69s
Train Epoch: 352 [61440/90000 (68%)]	Loss: 0.0898	Cost: 9.43s
Train Epoch: 352 [81920/90000 (91%)]	Loss: -0.1073	Cost: 9.28s
Train Epoch: 352 	Average Loss: 0.1727
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7709

Learning rate: 0.00019328278153972925
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 2.7226	Cost: 30.00s
Train Epoch: 353 [20480/90000 (23%)]	Loss: -0.1794	Cost: 10.10s
Train Epoch: 353 [40960/90000 (45%)]	Loss: -0.4669	Cost: 10.40s
Train Epoch: 353 [61440/90000 (68%)]	Loss: -0.0656	Cost: 9.56s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 0.1380	Cost: 9.30s
Train Epoch: 353 	Average Loss: 0.1470
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9088

Learning rate: 0.00019324499752006137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 2.8064	Cost: 29.42s
Train Epoch: 354 [20480/90000 (23%)]	Loss: -0.0438	Cost: 9.80s
Train Epoch: 354 [40960/90000 (45%)]	Loss: -0.3050	Cost: 10.28s
Train Epoch: 354 [61440/90000 (68%)]	Loss: 0.1403	Cost: 9.46s
Train Epoch: 354 [81920/90000 (91%)]	Loss: -0.0436	Cost: 9.16s
Train Epoch: 354 	Average Loss: 0.2123
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7712

Learning rate: 0.00019320711124582086
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 2.4344	Cost: 29.45s
Train Epoch: 355 [20480/90000 (23%)]	Loss: -0.0886	Cost: 9.76s
Train Epoch: 355 [40960/90000 (45%)]	Loss: -0.3229	Cost: 10.30s
Train Epoch: 355 [61440/90000 (68%)]	Loss: -0.0681	Cost: 9.45s
Train Epoch: 355 [81920/90000 (91%)]	Loss: -0.0755	Cost: 9.13s
Train Epoch: 355 	Average Loss: 0.0287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7651

Learning rate: 0.00019316912275855466
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 2.6172	Cost: 29.13s
Train Epoch: 356 [20480/90000 (23%)]	Loss: -0.1495	Cost: 9.76s
Train Epoch: 356 [40960/90000 (45%)]	Loss: -0.3216	Cost: 10.58s
Train Epoch: 356 [61440/90000 (68%)]	Loss: 0.0123	Cost: 9.39s
Train Epoch: 356 [81920/90000 (91%)]	Loss: -0.0951	Cost: 9.33s
Train Epoch: 356 	Average Loss: 0.0724
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7170

Learning rate: 0.0001931310320999218
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 2.2852	Cost: 29.61s
Train Epoch: 357 [20480/90000 (23%)]	Loss: -0.3249	Cost: 9.81s
Train Epoch: 357 [40960/90000 (45%)]	Loss: -0.3792	Cost: 10.60s
Train Epoch: 357 [61440/90000 (68%)]	Loss: -0.2561	Cost: 9.57s
Train Epoch: 357 [81920/90000 (91%)]	Loss: -0.0857	Cost: 9.15s
Train Epoch: 357 	Average Loss: -0.0340
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6320

Learning rate: 0.00019309283931169332
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 2.4978	Cost: 29.25s
Train Epoch: 358 [20480/90000 (23%)]	Loss: -0.3451	Cost: 9.77s
Train Epoch: 358 [40960/90000 (45%)]	Loss: -0.5403	Cost: 10.46s
Train Epoch: 358 [61440/90000 (68%)]	Loss: 0.0144	Cost: 9.45s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 0.0834	Cost: 9.29s
Train Epoch: 358 	Average Loss: -0.0173
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7806

Learning rate: 0.00019305454443575238
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 2.8521	Cost: 29.93s
Train Epoch: 359 [20480/90000 (23%)]	Loss: -0.1892	Cost: 9.85s
Train Epoch: 359 [40960/90000 (45%)]	Loss: -0.4999	Cost: 10.31s
Train Epoch: 359 [61440/90000 (68%)]	Loss: -0.2106	Cost: 9.58s
Train Epoch: 359 [81920/90000 (91%)]	Loss: -0.1506	Cost: 9.26s
Train Epoch: 359 	Average Loss: 0.0126
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7401

Learning rate: 0.00019301614751409394
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 2.5479	Cost: 29.17s
Train Epoch: 360 [20480/90000 (23%)]	Loss: -0.4702	Cost: 9.74s
Train Epoch: 360 [40960/90000 (45%)]	Loss: -0.6104	Cost: 10.69s
Train Epoch: 360 [61440/90000 (68%)]	Loss: -0.2689	Cost: 9.42s
Train Epoch: 360 [81920/90000 (91%)]	Loss: -0.3578	Cost: 9.22s
Train Epoch: 360 	Average Loss: -0.1119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6706

Learning rate: 0.00019297764858882492
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 2.2560	Cost: 28.77s
Train Epoch: 361 [20480/90000 (23%)]	Loss: -0.3476	Cost: 9.78s
Train Epoch: 361 [40960/90000 (45%)]	Loss: -0.5620	Cost: 11.04s
Train Epoch: 361 [61440/90000 (68%)]	Loss: -0.4096	Cost: 9.55s
Train Epoch: 361 [81920/90000 (91%)]	Loss: -0.4115	Cost: 9.27s
Train Epoch: 361 	Average Loss: -0.2043
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5537

Learning rate: 0.00019293904770216415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 2.6907	Cost: 29.74s
Train Epoch: 362 [20480/90000 (23%)]	Loss: -0.4175	Cost: 9.85s
Train Epoch: 362 [40960/90000 (45%)]	Loss: -0.3812	Cost: 10.20s
Train Epoch: 362 [61440/90000 (68%)]	Loss: -0.2101	Cost: 9.42s
Train Epoch: 362 [81920/90000 (91%)]	Loss: -0.2472	Cost: 9.14s
Train Epoch: 362 	Average Loss: -0.1331
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5271

Learning rate: 0.00019290034489644224
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 2.4580	Cost: 28.74s
Train Epoch: 363 [20480/90000 (23%)]	Loss: -0.3654	Cost: 9.84s
Train Epoch: 363 [40960/90000 (45%)]	Loss: -0.8146	Cost: 10.90s
Train Epoch: 363 [61440/90000 (68%)]	Loss: -0.3235	Cost: 9.68s
Train Epoch: 363 [81920/90000 (91%)]	Loss: -0.4968	Cost: 9.16s
Train Epoch: 363 	Average Loss: -0.2384
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4831

Learning rate: 0.00019286154021410154
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 2.1506	Cost: 29.85s
Train Epoch: 364 [20480/90000 (23%)]	Loss: -0.4764	Cost: 9.70s
Train Epoch: 364 [40960/90000 (45%)]	Loss: -0.8761	Cost: 10.64s
Train Epoch: 364 [61440/90000 (68%)]	Loss: -0.4343	Cost: 9.40s
Train Epoch: 364 [81920/90000 (91%)]	Loss: -0.5527	Cost: 9.20s
Train Epoch: 364 	Average Loss: -0.3568
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4400

Learning rate: 0.00019282263369769612
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 2.3695	Cost: 28.64s
Train Epoch: 365 [20480/90000 (23%)]	Loss: -0.7552	Cost: 9.72s
Train Epoch: 365 [40960/90000 (45%)]	Loss: -0.8548	Cost: 11.21s
Train Epoch: 365 [61440/90000 (68%)]	Loss: -0.2452	Cost: 9.68s
Train Epoch: 365 [81920/90000 (91%)]	Loss: -0.1111	Cost: 9.17s
Train Epoch: 365 	Average Loss: -0.2527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6942

Learning rate: 0.00019278362538989178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 2.6366	Cost: 29.52s
Train Epoch: 366 [20480/90000 (23%)]	Loss: -0.2060	Cost: 9.82s
Train Epoch: 366 [40960/90000 (45%)]	Loss: -0.5728	Cost: 10.34s
Train Epoch: 366 [61440/90000 (68%)]	Loss: -0.3198	Cost: 9.43s
Train Epoch: 366 [81920/90000 (91%)]	Loss: -0.3892	Cost: 9.27s
Train Epoch: 366 	Average Loss: -0.1257
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7919

Learning rate: 0.00019274451533346593
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 2.6604	Cost: 29.02s
Train Epoch: 367 [20480/90000 (23%)]	Loss: -0.4715	Cost: 9.77s
Train Epoch: 367 [40960/90000 (45%)]	Loss: -0.6900	Cost: 10.58s
Train Epoch: 367 [61440/90000 (68%)]	Loss: -0.1212	Cost: 9.71s
Train Epoch: 367 [81920/90000 (91%)]	Loss: -0.2128	Cost: 9.19s
Train Epoch: 367 	Average Loss: -0.1381
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6319

Learning rate: 0.0001927053035713075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 3.0058	Cost: 29.47s
Train Epoch: 368 [20480/90000 (23%)]	Loss: -0.6022	Cost: 9.90s
Train Epoch: 368 [40960/90000 (45%)]	Loss: -0.7096	Cost: 10.29s
Train Epoch: 368 [61440/90000 (68%)]	Loss: -0.1899	Cost: 9.41s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 0.0405	Cost: 9.28s
Train Epoch: 368 	Average Loss: -0.1224
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6720

Learning rate: 0.000192665990146417
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 2.4660	Cost: 29.17s
Train Epoch: 369 [20480/90000 (23%)]	Loss: -0.4378	Cost: 9.77s
Train Epoch: 369 [40960/90000 (45%)]	Loss: -0.9359	Cost: 10.02s
Train Epoch: 369 [61440/90000 (68%)]	Loss: -0.3679	Cost: 9.58s
Train Epoch: 369 [81920/90000 (91%)]	Loss: -0.5177	Cost: 9.20s
Train Epoch: 369 	Average Loss: -0.2959
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3582

Learning rate: 0.00019262657510190644
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 2.4792	Cost: 28.92s
Train Epoch: 370 [20480/90000 (23%)]	Loss: -0.7170	Cost: 9.66s
Train Epoch: 370 [40960/90000 (45%)]	Loss: -0.9395	Cost: 10.80s
Train Epoch: 370 [61440/90000 (68%)]	Loss: -0.6224	Cost: 9.42s
Train Epoch: 370 [81920/90000 (91%)]	Loss: -0.6370	Cost: 9.27s
Train Epoch: 370 	Average Loss: -0.4768
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2378

Learning rate: 0.00019258705848099926
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 2.0369	Cost: 29.10s
Train Epoch: 371 [20480/90000 (23%)]	Loss: -0.6667	Cost: 9.80s
Train Epoch: 371 [40960/90000 (45%)]	Loss: -0.9238	Cost: 10.88s
Train Epoch: 371 [61440/90000 (68%)]	Loss: -0.6392	Cost: 9.62s
Train Epoch: 371 [81920/90000 (91%)]	Loss: -0.7156	Cost: 9.26s
Train Epoch: 371 	Average Loss: -0.5484
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2011

Learning rate: 0.00019254744032703026
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 2.2172	Cost: 29.72s
Train Epoch: 372 [20480/90000 (23%)]	Loss: -0.9583	Cost: 10.09s
Train Epoch: 372 [40960/90000 (45%)]	Loss: -1.1168	Cost: 9.69s
Train Epoch: 372 [61440/90000 (68%)]	Loss: -0.6574	Cost: 9.41s
Train Epoch: 372 [81920/90000 (91%)]	Loss: -0.4964	Cost: 9.27s
Train Epoch: 372 	Average Loss: -0.5732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2674

Learning rate: 0.00019250772068344558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 2.0505	Cost: 28.57s
Train Epoch: 373 [20480/90000 (23%)]	Loss: -0.7755	Cost: 10.17s
Train Epoch: 373 [40960/90000 (45%)]	Loss: -0.7842	Cost: 10.29s
Train Epoch: 373 [61440/90000 (68%)]	Loss: -0.5606	Cost: 9.70s
Train Epoch: 373 [81920/90000 (91%)]	Loss: -0.5838	Cost: 9.18s
Train Epoch: 373 	Average Loss: -0.4810
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4066

Learning rate: 0.00019246789959380276
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 2.1392	Cost: 29.83s
Train Epoch: 374 [20480/90000 (23%)]	Loss: -0.8869	Cost: 9.75s
Train Epoch: 374 [40960/90000 (45%)]	Loss: -1.1008	Cost: 10.70s
Train Epoch: 374 [61440/90000 (68%)]	Loss: -0.7730	Cost: 9.41s
Train Epoch: 374 [81920/90000 (91%)]	Loss: -0.8705	Cost: 9.36s
Train Epoch: 374 	Average Loss: -0.6640
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0559

Learning rate: 0.0001924279771017704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 1.9967	Cost: 29.38s
Train Epoch: 375 [20480/90000 (23%)]	Loss: -1.0499	Cost: 9.74s
Train Epoch: 375 [40960/90000 (45%)]	Loss: -1.1509	Cost: 11.07s
Train Epoch: 375 [61440/90000 (68%)]	Loss: -0.7520	Cost: 9.68s
Train Epoch: 375 [81920/90000 (91%)]	Loss: -0.9535	Cost: 9.24s
Train Epoch: 375 	Average Loss: -0.7688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0790

Learning rate: 0.00019238795325112848
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 2.1426	Cost: 28.85s
Train Epoch: 376 [20480/90000 (23%)]	Loss: -1.1333	Cost: 9.81s
Train Epoch: 376 [40960/90000 (45%)]	Loss: -1.3704	Cost: 10.43s
Train Epoch: 376 [61440/90000 (68%)]	Loss: -0.8904	Cost: 9.40s
Train Epoch: 376 [81920/90000 (91%)]	Loss: -0.8761	Cost: 9.22s
Train Epoch: 376 	Average Loss: -0.8005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2030

Learning rate: 0.00019234782808576803
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 1.8866	Cost: 29.46s
Train Epoch: 377 [20480/90000 (23%)]	Loss: -0.8977	Cost: 9.87s
Train Epoch: 377 [40960/90000 (45%)]	Loss: -1.2255	Cost: 9.97s
Train Epoch: 377 [61440/90000 (68%)]	Loss: -0.8505	Cost: 9.71s
Train Epoch: 377 [81920/90000 (91%)]	Loss: -0.9341	Cost: 9.13s
Train Epoch: 377 	Average Loss: -0.7824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0050

Learning rate: 0.00019230760164969124
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 2.0853	Cost: 28.64s
Train Epoch: 378 [20480/90000 (23%)]	Loss: -0.9715	Cost: 9.74s
Train Epoch: 378 [40960/90000 (45%)]	Loss: -1.2305	Cost: 10.67s
Train Epoch: 378 [61440/90000 (68%)]	Loss: -0.8014	Cost: 9.41s
Train Epoch: 378 [81920/90000 (91%)]	Loss: -1.0670	Cost: 9.17s
Train Epoch: 378 	Average Loss: -0.8302
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9866

Learning rate: 0.00019226727398701128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 2.0066	Cost: 28.82s
Train Epoch: 379 [20480/90000 (23%)]	Loss: -1.1478	Cost: 9.67s
Train Epoch: 379 [40960/90000 (45%)]	Loss: -1.2804	Cost: 10.91s
Train Epoch: 379 [61440/90000 (68%)]	Loss: -1.0634	Cost: 9.56s
Train Epoch: 379 [81920/90000 (91%)]	Loss: -1.1133	Cost: 9.24s
Train Epoch: 379 	Average Loss: -0.8861
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0783

Learning rate: 0.00019222684514195242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 2.0613	Cost: 29.31s
Train Epoch: 380 [20480/90000 (23%)]	Loss: -1.1715	Cost: 9.72s
Train Epoch: 380 [40960/90000 (45%)]	Loss: -1.3634	Cost: 10.74s
Train Epoch: 380 [61440/90000 (68%)]	Loss: -1.0209	Cost: 9.39s
Train Epoch: 380 [81920/90000 (91%)]	Loss: -1.1428	Cost: 9.18s
Train Epoch: 380 	Average Loss: -0.8877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8089

Learning rate: 0.00019218631515884984
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 2.0129	Cost: 29.41s
Train Epoch: 381 [20480/90000 (23%)]	Loss: -1.0428	Cost: 9.84s
Train Epoch: 381 [40960/90000 (45%)]	Loss: -1.4273	Cost: 10.72s
Train Epoch: 381 [61440/90000 (68%)]	Loss: -1.0046	Cost: 9.72s
Train Epoch: 381 [81920/90000 (91%)]	Loss: -1.2334	Cost: 9.26s
Train Epoch: 381 	Average Loss: -0.9323
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8298

Learning rate: 0.00019214568408214963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 2.0481	Cost: 28.87s
Train Epoch: 382 [20480/90000 (23%)]	Loss: -1.3253	Cost: 9.81s
Train Epoch: 382 [40960/90000 (45%)]	Loss: -1.5618	Cost: 10.83s
Train Epoch: 382 [61440/90000 (68%)]	Loss: -1.1978	Cost: 9.40s
Train Epoch: 382 [81920/90000 (91%)]	Loss: -1.1264	Cost: 9.32s
Train Epoch: 382 	Average Loss: -1.0228
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8725

Learning rate: 0.00019210495195640874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 1.7387	Cost: 28.39s
Train Epoch: 383 [20480/90000 (23%)]	Loss: -0.9137	Cost: 9.70s
Train Epoch: 383 [40960/90000 (45%)]	Loss: -1.3574	Cost: 11.43s
Train Epoch: 383 [61440/90000 (68%)]	Loss: -1.0332	Cost: 9.64s
Train Epoch: 383 [81920/90000 (91%)]	Loss: -1.0678	Cost: 9.29s
Train Epoch: 383 	Average Loss: -0.8939
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9061

Learning rate: 0.00019206411882629495
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 1.6139	Cost: 29.64s
Train Epoch: 384 [20480/90000 (23%)]	Loss: -1.2847	Cost: 9.73s
Train Epoch: 384 [40960/90000 (45%)]	Loss: -1.4956	Cost: 10.35s
Train Epoch: 384 [61440/90000 (68%)]	Loss: -1.2301	Cost: 9.39s
Train Epoch: 384 [81920/90000 (91%)]	Loss: -1.4142	Cost: 9.23s
Train Epoch: 384 	Average Loss: -1.1472
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8048

Learning rate: 0.00019202318473658683
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 1.7759	Cost: 29.42s
Train Epoch: 385 [20480/90000 (23%)]	Loss: -0.9205	Cost: 9.85s
Train Epoch: 385 [40960/90000 (45%)]	Loss: -1.4487	Cost: 10.71s
Train Epoch: 385 [61440/90000 (68%)]	Loss: -1.1308	Cost: 9.57s
Train Epoch: 385 [81920/90000 (91%)]	Loss: -1.1166	Cost: 9.21s
Train Epoch: 385 	Average Loss: -0.9613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9204

Learning rate: 0.00019198214973217357
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 1.6634	Cost: 29.54s
Train Epoch: 386 [20480/90000 (23%)]	Loss: -1.3952	Cost: 9.70s
Train Epoch: 386 [40960/90000 (45%)]	Loss: -1.7025	Cost: 10.87s
Train Epoch: 386 [61440/90000 (68%)]	Loss: -1.1740	Cost: 9.46s
Train Epoch: 386 [81920/90000 (91%)]	Loss: -1.1910	Cost: 9.17s
Train Epoch: 386 	Average Loss: -1.1273
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8051

Learning rate: 0.00019194101385805508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 1.7085	Cost: 29.02s
Train Epoch: 387 [20480/90000 (23%)]	Loss: -1.2409	Cost: 9.79s
Train Epoch: 387 [40960/90000 (45%)]	Loss: -1.2751	Cost: 10.63s
Train Epoch: 387 [61440/90000 (68%)]	Loss: -1.0957	Cost: 9.60s
Train Epoch: 387 [81920/90000 (91%)]	Loss: -0.4992	Cost: 9.24s
Train Epoch: 387 	Average Loss: -0.8173
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3275

Learning rate: 0.0001918997771593419
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 2.4673	Cost: 28.77s
Train Epoch: 388 [20480/90000 (23%)]	Loss: -1.1638	Cost: 9.82s
Train Epoch: 388 [40960/90000 (45%)]	Loss: -1.4655	Cost: 10.40s
Train Epoch: 388 [61440/90000 (68%)]	Loss: -1.1716	Cost: 9.49s
Train Epoch: 388 [81920/90000 (91%)]	Loss: -1.4487	Cost: 9.20s
Train Epoch: 388 	Average Loss: -0.9852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7731

Learning rate: 0.00019185843968125518
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 1.5564	Cost: 29.77s
Train Epoch: 389 [20480/90000 (23%)]	Loss: -1.3904	Cost: 9.65s
Train Epoch: 389 [40960/90000 (45%)]	Loss: -1.4363	Cost: 10.54s
Train Epoch: 389 [61440/90000 (68%)]	Loss: -1.1602	Cost: 9.61s
Train Epoch: 389 [81920/90000 (91%)]	Loss: -1.4044	Cost: 9.17s
Train Epoch: 389 	Average Loss: -1.1200
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7426

Learning rate: 0.0001918170014691265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 1.8887	Cost: 29.59s
Train Epoch: 390 [20480/90000 (23%)]	Loss: -1.3561	Cost: 9.78s
Train Epoch: 390 [40960/90000 (45%)]	Loss: -1.8003	Cost: 10.30s
Train Epoch: 390 [61440/90000 (68%)]	Loss: -1.3357	Cost: 9.43s
Train Epoch: 390 [81920/90000 (91%)]	Loss: -1.5432	Cost: 9.36s
Train Epoch: 390 	Average Loss: -1.2431
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5324

Learning rate: 0.0001917754625683979
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 1.6326	Cost: 29.25s
Train Epoch: 391 [20480/90000 (23%)]	Loss: -1.7707	Cost: 9.74s
Train Epoch: 391 [40960/90000 (45%)]	Loss: -1.9353	Cost: 10.30s
Train Epoch: 391 [61440/90000 (68%)]	Loss: -1.4929	Cost: 9.61s
Train Epoch: 391 [81920/90000 (91%)]	Loss: -1.3945	Cost: 9.14s
Train Epoch: 391 	Average Loss: -1.4263
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7228

Learning rate: 0.00019173382302462195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 1.5419	Cost: 28.54s
Train Epoch: 392 [20480/90000 (23%)]	Loss: -1.4405	Cost: 9.75s
Train Epoch: 392 [40960/90000 (45%)]	Loss: -1.8980	Cost: 10.74s
Train Epoch: 392 [61440/90000 (68%)]	Loss: -1.6349	Cost: 9.46s
Train Epoch: 392 [81920/90000 (91%)]	Loss: -1.7082	Cost: 9.32s
Train Epoch: 392 	Average Loss: -1.4449
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5340

Learning rate: 0.00019169208288346147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 1.4719	Cost: 29.50s
Train Epoch: 393 [20480/90000 (23%)]	Loss: -1.8663	Cost: 9.75s
Train Epoch: 393 [40960/90000 (45%)]	Loss: -1.9904	Cost: 10.31s
Train Epoch: 393 [61440/90000 (68%)]	Loss: -1.8013	Cost: 9.59s
Train Epoch: 393 [81920/90000 (91%)]	Loss: -1.7422	Cost: 9.31s
Train Epoch: 393 	Average Loss: -1.5947
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4746

Learning rate: 0.00019165024219068962
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 1.2740	Cost: 28.83s
Train Epoch: 394 [20480/90000 (23%)]	Loss: -1.7759	Cost: 9.74s
Train Epoch: 394 [40960/90000 (45%)]	Loss: -2.0586	Cost: 10.57s
Train Epoch: 394 [61440/90000 (68%)]	Loss: -1.5448	Cost: 9.41s
Train Epoch: 394 [81920/90000 (91%)]	Loss: -1.6055	Cost: 9.28s
Train Epoch: 394 	Average Loss: -1.5518
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5761

Learning rate: 0.00019160830099218987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 1.4681	Cost: 28.85s
Train Epoch: 395 [20480/90000 (23%)]	Loss: -1.7998	Cost: 9.85s
Train Epoch: 395 [40960/90000 (45%)]	Loss: -2.1038	Cost: 10.75s
Train Epoch: 395 [61440/90000 (68%)]	Loss: -1.6909	Cost: 9.84s
Train Epoch: 395 [81920/90000 (91%)]	Loss: -1.8432	Cost: 9.11s
Train Epoch: 395 	Average Loss: -1.6410
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4557

Learning rate: 0.00019156625933395592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 1.4421	Cost: 28.76s
Train Epoch: 396 [20480/90000 (23%)]	Loss: -1.8969	Cost: 9.70s
Train Epoch: 396 [40960/90000 (45%)]	Loss: -2.0275	Cost: 10.85s
Train Epoch: 396 [61440/90000 (68%)]	Loss: -1.6772	Cost: 9.51s
Train Epoch: 396 [81920/90000 (91%)]	Loss: -1.8239	Cost: 9.24s
Train Epoch: 396 	Average Loss: -1.6082
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4996

Learning rate: 0.00019152411726209155
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 1.1135	Cost: 29.73s
Train Epoch: 397 [20480/90000 (23%)]	Loss: -1.9671	Cost: 9.79s
Train Epoch: 397 [40960/90000 (45%)]	Loss: -2.1339	Cost: 10.85s
Train Epoch: 397 [61440/90000 (68%)]	Loss: -1.8449	Cost: 9.54s
Train Epoch: 397 [81920/90000 (91%)]	Loss: -1.9476	Cost: 9.22s
Train Epoch: 397 	Average Loss: -1.6930
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3407

Learning rate: 0.00019148187482281076
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 1.1480	Cost: 28.57s
Train Epoch: 398 [20480/90000 (23%)]	Loss: -2.0245	Cost: 9.79s
Train Epoch: 398 [40960/90000 (45%)]	Loss: -2.2524	Cost: 10.66s
Train Epoch: 398 [61440/90000 (68%)]	Loss: -1.9220	Cost: 9.42s
Train Epoch: 398 [81920/90000 (91%)]	Loss: -1.6321	Cost: 9.19s
Train Epoch: 398 	Average Loss: -1.7227
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6477

Learning rate: 0.00019143953206243755
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 1.3402	Cost: 29.32s
Train Epoch: 399 [20480/90000 (23%)]	Loss: -1.5928	Cost: 9.74s
Train Epoch: 399 [40960/90000 (45%)]	Loss: -0.5256	Cost: 10.27s
Train Epoch: 399 [61440/90000 (68%)]	Loss: -0.6740	Cost: 9.52s
Train Epoch: 399 [81920/90000 (91%)]	Loss: -1.1231	Cost: 9.26s
Train Epoch: 399 	Average Loss: -0.7741
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9526

Learning rate: 0.0001913970890274059
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 1.8346	Cost: 28.89s
Train Epoch: 400 [20480/90000 (23%)]	Loss: -1.1454	Cost: 9.76s
Train Epoch: 400 [40960/90000 (45%)]	Loss: -1.6063	Cost: 10.50s
Train Epoch: 400 [61440/90000 (68%)]	Loss: -1.3943	Cost: 9.40s
Train Epoch: 400 [81920/90000 (91%)]	Loss: -1.6542	Cost: 9.28s
Train Epoch: 400 	Average Loss: -1.1959
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4646

Saving model as model.pt_e400 & waveforms_supplementary.hdf5_e400
Learning rate: 0.00019135454576425985
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 401 [0/90000 (0%)]	Loss: 1.3954	Cost: 28.88s
Train Epoch: 401 [20480/90000 (23%)]	Loss: -1.7883	Cost: 9.81s
Train Epoch: 401 [40960/90000 (45%)]	Loss: -1.9974	Cost: 10.58s
Train Epoch: 401 [61440/90000 (68%)]	Loss: -1.7188	Cost: 9.45s
Train Epoch: 401 [81920/90000 (91%)]	Loss: -1.8396	Cost: 9.21s
Train Epoch: 401 	Average Loss: -1.5917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3838

Learning rate: 0.00019131190231965335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 402 [0/90000 (0%)]	Loss: 1.3549	Cost: 29.60s
Train Epoch: 402 [20480/90000 (23%)]	Loss: -1.9736	Cost: 9.74s
Train Epoch: 402 [40960/90000 (45%)]	Loss: -2.3082	Cost: 10.66s
Train Epoch: 402 [61440/90000 (68%)]	Loss: -1.8903	Cost: 9.48s
Train Epoch: 402 [81920/90000 (91%)]	Loss: -1.8345	Cost: 9.23s
Train Epoch: 402 	Average Loss: -1.7456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3296

Learning rate: 0.00019126915874035006
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 403 [0/90000 (0%)]	Loss: 1.3715	Cost: 29.83s
Train Epoch: 403 [20480/90000 (23%)]	Loss: -1.9868	Cost: 9.74s
Train Epoch: 403 [40960/90000 (45%)]	Loss: -2.3212	Cost: 10.40s
Train Epoch: 403 [61440/90000 (68%)]	Loss: -2.0638	Cost: 9.43s
Train Epoch: 403 [81920/90000 (91%)]	Loss: -2.1076	Cost: 9.19s
Train Epoch: 403 	Average Loss: -1.8273
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2230

Learning rate: 0.00019122631507322363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 404 [0/90000 (0%)]	Loss: 0.8774	Cost: 29.26s
Train Epoch: 404 [20480/90000 (23%)]	Loss: -2.1316	Cost: 9.73s
Train Epoch: 404 [40960/90000 (45%)]	Loss: -2.3671	Cost: 10.22s
Train Epoch: 404 [61440/90000 (68%)]	Loss: -2.1237	Cost: 9.41s
Train Epoch: 404 [81920/90000 (91%)]	Loss: -2.2604	Cost: 9.35s
Train Epoch: 404 	Average Loss: -1.9242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1938

Learning rate: 0.00019118337136525735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 405 [0/90000 (0%)]	Loss: 0.9825	Cost: 29.21s
Train Epoch: 405 [20480/90000 (23%)]	Loss: -2.1851	Cost: 9.89s
Train Epoch: 405 [40960/90000 (45%)]	Loss: -2.3264	Cost: 10.55s
Train Epoch: 405 [61440/90000 (68%)]	Loss: -1.8990	Cost: 9.42s
Train Epoch: 405 [81920/90000 (91%)]	Loss: -1.6677	Cost: 9.14s
Train Epoch: 405 	Average Loss: -1.7960
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4180

Learning rate: 0.0001911403276635443
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 406 [0/90000 (0%)]	Loss: 0.9855	Cost: 29.57s
Train Epoch: 406 [20480/90000 (23%)]	Loss: -2.0690	Cost: 9.74s
Train Epoch: 406 [40960/90000 (45%)]	Loss: -2.3736	Cost: 10.52s
Train Epoch: 406 [61440/90000 (68%)]	Loss: -2.1440	Cost: 9.53s
Train Epoch: 406 [81920/90000 (91%)]	Loss: -2.1150	Cost: 9.24s
Train Epoch: 406 	Average Loss: -1.8774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1621

Learning rate: 0.00019109718401528718
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 407 [0/90000 (0%)]	Loss: 1.0045	Cost: 29.34s
Train Epoch: 407 [20480/90000 (23%)]	Loss: -2.2800	Cost: 9.76s
Train Epoch: 407 [40960/90000 (45%)]	Loss: -2.5185	Cost: 10.39s
Train Epoch: 407 [61440/90000 (68%)]	Loss: -2.1597	Cost: 9.68s
Train Epoch: 407 [81920/90000 (91%)]	Loss: -2.2168	Cost: 9.19s
Train Epoch: 407 	Average Loss: -2.0128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0958

Learning rate: 0.00019105394046779823
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 408 [0/90000 (0%)]	Loss: 1.3265	Cost: 29.77s
Train Epoch: 408 [20480/90000 (23%)]	Loss: -2.4331	Cost: 9.78s
Train Epoch: 408 [40960/90000 (45%)]	Loss: -2.7059	Cost: 10.50s
Train Epoch: 408 [61440/90000 (68%)]	Loss: -2.2670	Cost: 9.45s
Train Epoch: 408 [81920/90000 (91%)]	Loss: -2.3493	Cost: 9.20s
Train Epoch: 408 	Average Loss: -2.1486
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0103

Learning rate: 0.00019101059706849935
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 409 [0/90000 (0%)]	Loss: 0.9576	Cost: 28.58s
Train Epoch: 409 [20480/90000 (23%)]	Loss: -2.3278	Cost: 9.85s
Train Epoch: 409 [40960/90000 (45%)]	Loss: -2.1823	Cost: 10.15s
Train Epoch: 409 [61440/90000 (68%)]	Loss: -1.8104	Cost: 9.65s
Train Epoch: 409 [81920/90000 (91%)]	Loss: -2.0449	Cost: 9.18s
Train Epoch: 409 	Average Loss: -1.8667
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2794

Learning rate: 0.00019096715386492192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 410 [0/90000 (0%)]	Loss: 1.0732	Cost: 28.90s
Train Epoch: 410 [20480/90000 (23%)]	Loss: -2.3280	Cost: 9.65s
Train Epoch: 410 [40960/90000 (45%)]	Loss: -2.6083	Cost: 10.65s
Train Epoch: 410 [61440/90000 (68%)]	Loss: -1.9604	Cost: 9.49s
Train Epoch: 410 [81920/90000 (91%)]	Loss: -1.9395	Cost: 9.28s
Train Epoch: 410 	Average Loss: -1.9702
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3192

Learning rate: 0.00019092361090470667
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 411 [0/90000 (0%)]	Loss: 1.3641	Cost: 28.52s
Train Epoch: 411 [20480/90000 (23%)]	Loss: -2.1317	Cost: 9.82s
Train Epoch: 411 [40960/90000 (45%)]	Loss: -2.4807	Cost: 10.74s
Train Epoch: 411 [61440/90000 (68%)]	Loss: -2.2382	Cost: 9.63s
Train Epoch: 411 [81920/90000 (91%)]	Loss: -2.3390	Cost: 9.19s
Train Epoch: 411 	Average Loss: -1.9585
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0540

Learning rate: 0.00019087996823560383
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 412 [0/90000 (0%)]	Loss: 0.7878	Cost: 29.37s
Train Epoch: 412 [20480/90000 (23%)]	Loss: -2.5041	Cost: 9.80s
Train Epoch: 412 [40960/90000 (45%)]	Loss: -2.6742	Cost: 10.52s
Train Epoch: 412 [61440/90000 (68%)]	Loss: -2.4268	Cost: 9.43s
Train Epoch: 412 [81920/90000 (91%)]	Loss: -2.5529	Cost: 9.17s
Train Epoch: 412 	Average Loss: -2.2647
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0019

Learning rate: 0.00019083622590547293
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 413 [0/90000 (0%)]	Loss: 1.0942	Cost: 29.30s
Train Epoch: 413 [20480/90000 (23%)]	Loss: -2.2779	Cost: 9.69s
Train Epoch: 413 [40960/90000 (45%)]	Loss: -2.4705	Cost: 10.81s
Train Epoch: 413 [61440/90000 (68%)]	Loss: -2.3181	Cost: 9.53s
Train Epoch: 413 [81920/90000 (91%)]	Loss: -2.3072	Cost: 9.20s
Train Epoch: 413 	Average Loss: -2.1142
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0052

Learning rate: 0.0001907923839622828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 414 [0/90000 (0%)]	Loss: 1.1188	Cost: 29.46s
Train Epoch: 414 [20480/90000 (23%)]	Loss: -2.4751	Cost: 9.81s
Train Epoch: 414 [40960/90000 (45%)]	Loss: -2.9458	Cost: 10.55s
Train Epoch: 414 [61440/90000 (68%)]	Loss: -2.4837	Cost: 9.44s
Train Epoch: 414 [81920/90000 (91%)]	Loss: -2.5662	Cost: 9.19s
Train Epoch: 414 	Average Loss: -2.3137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0240

Learning rate: 0.00019074844245411154
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 415 [0/90000 (0%)]	Loss: 0.9895	Cost: 28.53s
Train Epoch: 415 [20480/90000 (23%)]	Loss: -2.5574	Cost: 9.84s
Train Epoch: 415 [40960/90000 (45%)]	Loss: -3.0521	Cost: 10.50s
Train Epoch: 415 [61440/90000 (68%)]	Loss: -2.5687	Cost: 9.45s
Train Epoch: 415 [81920/90000 (91%)]	Loss: -2.7191	Cost: 9.29s
Train Epoch: 415 	Average Loss: -2.3854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8329

Learning rate: 0.00019070440142914633
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 416 [0/90000 (0%)]	Loss: 0.6781	Cost: 30.33s
Train Epoch: 416 [20480/90000 (23%)]	Loss: -2.6851	Cost: 9.91s
Train Epoch: 416 [40960/90000 (45%)]	Loss: -2.9470	Cost: 10.26s
Train Epoch: 416 [61440/90000 (68%)]	Loss: -2.6473	Cost: 9.44s
Train Epoch: 416 [81920/90000 (91%)]	Loss: -0.7627	Cost: 9.22s
Train Epoch: 416 	Average Loss: -2.1303
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3554

Learning rate: 0.00019066026093568362
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 417 [0/90000 (0%)]	Loss: 3.0889	Cost: 30.14s
Train Epoch: 417 [20480/90000 (23%)]	Loss: -0.3716	Cost: 9.77s
Train Epoch: 417 [40960/90000 (45%)]	Loss: -0.5786	Cost: 10.68s
Train Epoch: 417 [61440/90000 (68%)]	Loss: -0.1620	Cost: 9.55s
Train Epoch: 417 [81920/90000 (91%)]	Loss: -0.7678	Cost: 9.40s
Train Epoch: 417 	Average Loss: -0.1888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9262

Learning rate: 0.00019061602102212884
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 418 [0/90000 (0%)]	Loss: 2.1246	Cost: 28.64s
Train Epoch: 418 [20480/90000 (23%)]	Loss: -1.6189	Cost: 9.77s
Train Epoch: 418 [40960/90000 (45%)]	Loss: -2.1679	Cost: 10.31s
Train Epoch: 418 [61440/90000 (68%)]	Loss: -2.0116	Cost: 9.41s
Train Epoch: 418 [81920/90000 (91%)]	Loss: -2.1452	Cost: 9.24s
Train Epoch: 418 	Average Loss: -1.5399
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1756

Learning rate: 0.00019057168173699647
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 419 [0/90000 (0%)]	Loss: 0.7901	Cost: 29.47s
Train Epoch: 419 [20480/90000 (23%)]	Loss: -2.3094	Cost: 9.81s
Train Epoch: 419 [40960/90000 (45%)]	Loss: -2.7124	Cost: 10.39s
Train Epoch: 419 [61440/90000 (68%)]	Loss: -2.3997	Cost: 9.39s
Train Epoch: 419 [81920/90000 (91%)]	Loss: -2.4889	Cost: 9.13s
Train Epoch: 419 	Average Loss: -2.2422
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8680

Learning rate: 0.00019052724312890998
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 420 [0/90000 (0%)]	Loss: 0.6272	Cost: 30.23s
Train Epoch: 420 [20480/90000 (23%)]	Loss: -2.7121	Cost: 9.64s
Train Epoch: 420 [40960/90000 (45%)]	Loss: -2.9962	Cost: 10.46s
Train Epoch: 420 [61440/90000 (68%)]	Loss: -2.4951	Cost: 9.43s
Train Epoch: 420 [81920/90000 (91%)]	Loss: -2.7331	Cost: 9.21s
Train Epoch: 420 	Average Loss: -2.4532
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8720

Learning rate: 0.0001904827052466018
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 421 [0/90000 (0%)]	Loss: 0.4685	Cost: 29.33s
Train Epoch: 421 [20480/90000 (23%)]	Loss: -2.7714	Cost: 9.89s
Train Epoch: 421 [40960/90000 (45%)]	Loss: -2.9226	Cost: 10.40s
Train Epoch: 421 [61440/90000 (68%)]	Loss: -2.5828	Cost: 9.45s
Train Epoch: 421 [81920/90000 (91%)]	Loss: -2.8309	Cost: 9.22s
Train Epoch: 421 	Average Loss: -2.4877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7736

Learning rate: 0.00019043806813891313
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 422 [0/90000 (0%)]	Loss: 0.9321	Cost: 29.76s
Train Epoch: 422 [20480/90000 (23%)]	Loss: -2.7484	Cost: 9.86s
Train Epoch: 422 [40960/90000 (45%)]	Loss: -3.1715	Cost: 10.54s
Train Epoch: 422 [61440/90000 (68%)]	Loss: -0.7238	Cost: 9.43s
Train Epoch: 422 [81920/90000 (91%)]	Loss: -0.9979	Cost: 9.25s
Train Epoch: 422 	Average Loss: -1.5664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9735

Learning rate: 0.00019039333185479402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 423 [0/90000 (0%)]	Loss: 1.4566	Cost: 29.61s
Train Epoch: 423 [20480/90000 (23%)]	Loss: -1.8966	Cost: 9.77s
Train Epoch: 423 [40960/90000 (45%)]	Loss: -2.4460	Cost: 10.81s
Train Epoch: 423 [61440/90000 (68%)]	Loss: -2.3530	Cost: 9.43s
Train Epoch: 423 [81920/90000 (91%)]	Loss: -2.4159	Cost: 9.28s
Train Epoch: 423 	Average Loss: -1.8765
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9621

Learning rate: 0.00019034849644330334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 424 [0/90000 (0%)]	Loss: 0.7495	Cost: 28.93s
Train Epoch: 424 [20480/90000 (23%)]	Loss: -2.6087	Cost: 9.78s
Train Epoch: 424 [40960/90000 (45%)]	Loss: -2.9590	Cost: 10.48s
Train Epoch: 424 [61440/90000 (68%)]	Loss: -2.7140	Cost: 9.58s
Train Epoch: 424 [81920/90000 (91%)]	Loss: -2.7930	Cost: 9.28s
Train Epoch: 424 	Average Loss: -2.4817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7185

Learning rate: 0.00019030356195360858
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 425 [0/90000 (0%)]	Loss: 0.5467	Cost: 29.19s
Train Epoch: 425 [20480/90000 (23%)]	Loss: -2.8051	Cost: 9.78s
Train Epoch: 425 [40960/90000 (45%)]	Loss: -3.0478	Cost: 10.29s
Train Epoch: 425 [61440/90000 (68%)]	Loss: -2.7565	Cost: 9.47s
Train Epoch: 425 [81920/90000 (91%)]	Loss: -2.7084	Cost: 9.23s
Train Epoch: 425 	Average Loss: -2.5443
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6847

Learning rate: 0.0001902585284349859
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 426 [0/90000 (0%)]	Loss: 0.7805	Cost: 29.48s
Train Epoch: 426 [20480/90000 (23%)]	Loss: -2.6173	Cost: 9.81s
Train Epoch: 426 [40960/90000 (45%)]	Loss: -2.9805	Cost: 10.58s
Train Epoch: 426 [61440/90000 (68%)]	Loss: -2.5195	Cost: 9.44s
Train Epoch: 426 [81920/90000 (91%)]	Loss: -2.7557	Cost: 9.29s
Train Epoch: 426 	Average Loss: -2.4268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7837

Learning rate: 0.00019021339593682012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 427 [0/90000 (0%)]	Loss: 0.8653	Cost: 29.24s
Train Epoch: 427 [20480/90000 (23%)]	Loss: -3.0310	Cost: 9.74s
Train Epoch: 427 [40960/90000 (45%)]	Loss: -3.1854	Cost: 10.82s
Train Epoch: 427 [61440/90000 (68%)]	Loss: -2.7782	Cost: 9.40s
Train Epoch: 427 [81920/90000 (91%)]	Loss: -2.6922	Cost: 9.13s
Train Epoch: 427 	Average Loss: -2.6122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7491

Learning rate: 0.00019016816450860455
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 428 [0/90000 (0%)]	Loss: 0.5946	Cost: 29.82s
Train Epoch: 428 [20480/90000 (23%)]	Loss: -3.0174	Cost: 9.70s
Train Epoch: 428 [40960/90000 (45%)]	Loss: -3.2147	Cost: 10.45s
Train Epoch: 428 [61440/90000 (68%)]	Loss: -2.9208	Cost: 9.43s
Train Epoch: 428 [81920/90000 (91%)]	Loss: -2.8811	Cost: 9.21s
Train Epoch: 428 	Average Loss: -2.7612
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5655

Learning rate: 0.00019012283419994098
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 429 [0/90000 (0%)]	Loss: 0.5652	Cost: 29.31s
Train Epoch: 429 [20480/90000 (23%)]	Loss: -3.0662	Cost: 9.78s
Train Epoch: 429 [40960/90000 (45%)]	Loss: -3.2333	Cost: 10.00s
Train Epoch: 429 [61440/90000 (68%)]	Loss: -2.9975	Cost: 9.87s
Train Epoch: 429 [81920/90000 (91%)]	Loss: -2.9042	Cost: 9.15s
Train Epoch: 429 	Average Loss: -2.7927
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4743

Learning rate: 0.00019007740506053966
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 430 [0/90000 (0%)]	Loss: 0.5577	Cost: 29.04s
Train Epoch: 430 [20480/90000 (23%)]	Loss: -2.8711	Cost: 9.74s
Train Epoch: 430 [40960/90000 (45%)]	Loss: -2.9886	Cost: 10.24s
Train Epoch: 430 [61440/90000 (68%)]	Loss: -2.6944	Cost: 9.42s
Train Epoch: 430 [81920/90000 (91%)]	Loss: -2.9784	Cost: 9.31s
Train Epoch: 430 	Average Loss: -2.6156
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5381

Learning rate: 0.00019003187714021922
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 431 [0/90000 (0%)]	Loss: 0.0719	Cost: 29.17s
Train Epoch: 431 [20480/90000 (23%)]	Loss: -3.0873	Cost: 9.75s
Train Epoch: 431 [40960/90000 (45%)]	Loss: -3.3895	Cost: 10.43s
Train Epoch: 431 [61440/90000 (68%)]	Loss: -2.9149	Cost: 9.42s
Train Epoch: 431 [81920/90000 (91%)]	Loss: -3.0175	Cost: 9.21s
Train Epoch: 431 	Average Loss: -2.8689
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4810

Learning rate: 0.00018998625048890656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 432 [0/90000 (0%)]	Loss: 0.2607	Cost: 29.25s
Train Epoch: 432 [20480/90000 (23%)]	Loss: -3.1786	Cost: 9.82s
Train Epoch: 432 [40960/90000 (45%)]	Loss: -3.1994	Cost: 10.40s
Train Epoch: 432 [61440/90000 (68%)]	Loss: -2.9628	Cost: 9.42s
Train Epoch: 432 [81920/90000 (91%)]	Loss: -2.7519	Cost: 9.30s
Train Epoch: 432 	Average Loss: -2.7743
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8437

Learning rate: 0.00018994052515663694
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 433 [0/90000 (0%)]	Loss: 0.8887	Cost: 30.33s
Train Epoch: 433 [20480/90000 (23%)]	Loss: -2.9263	Cost: 9.72s
Train Epoch: 433 [40960/90000 (45%)]	Loss: -3.3958	Cost: 10.42s
Train Epoch: 433 [61440/90000 (68%)]	Loss: -3.0537	Cost: 9.41s
Train Epoch: 433 [81920/90000 (91%)]	Loss: -3.1738	Cost: 9.25s
Train Epoch: 433 	Average Loss: -2.7995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3803

Learning rate: 0.0001898947011935538
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 434 [0/90000 (0%)]	Loss: 0.2723	Cost: 29.25s
Train Epoch: 434 [20480/90000 (23%)]	Loss: -3.3232	Cost: 9.75s
Train Epoch: 434 [40960/90000 (45%)]	Loss: -3.6975	Cost: 10.79s
Train Epoch: 434 [61440/90000 (68%)]	Loss: -3.1978	Cost: 9.44s
Train Epoch: 434 [81920/90000 (91%)]	Loss: -3.0702	Cost: 9.18s
Train Epoch: 434 	Average Loss: -3.0516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2932

Learning rate: 0.00018984877864990869
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 435 [0/90000 (0%)]	Loss: 0.4589	Cost: 29.13s
Train Epoch: 435 [20480/90000 (23%)]	Loss: -3.3140	Cost: 9.78s
Train Epoch: 435 [40960/90000 (45%)]	Loss: -3.5653	Cost: 10.72s
Train Epoch: 435 [61440/90000 (68%)]	Loss: -3.1413	Cost: 9.74s
Train Epoch: 435 [81920/90000 (91%)]	Loss: -3.0331	Cost: 9.27s
Train Epoch: 435 	Average Loss: -2.9520
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3448

Learning rate: 0.00018980275757606135
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 436 [0/90000 (0%)]	Loss: 0.7130	Cost: 29.24s
Train Epoch: 436 [20480/90000 (23%)]	Loss: -3.2692	Cost: 9.59s
Train Epoch: 436 [40960/90000 (45%)]	Loss: -3.3983	Cost: 10.84s
Train Epoch: 436 [61440/90000 (68%)]	Loss: -3.0948	Cost: 9.44s
Train Epoch: 436 [81920/90000 (91%)]	Loss: -3.3670	Cost: 9.57s
Train Epoch: 436 	Average Loss: -2.9904
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3395

Learning rate: 0.00018975663802247954
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 437 [0/90000 (0%)]	Loss: -0.0869	Cost: 39.54s
Train Epoch: 437 [20480/90000 (23%)]	Loss: -3.3286	Cost: 9.59s
Train Epoch: 437 [40960/90000 (45%)]	Loss: -3.7250	Cost: 16.38s
Train Epoch: 437 [61440/90000 (68%)]	Loss: -3.2761	Cost: 10.61s
Train Epoch: 437 [81920/90000 (91%)]	Loss: -3.3449	Cost: 18.65s
Train Epoch: 437 	Average Loss: -3.1237
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2594

Learning rate: 0.00018971042003973902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 438 [0/90000 (0%)]	Loss: 0.3777	Cost: 48.11s
Train Epoch: 438 [20480/90000 (23%)]	Loss: -3.1833	Cost: 12.10s
Train Epoch: 438 [40960/90000 (45%)]	Loss: -3.5012	Cost: 15.89s
Train Epoch: 438 [61440/90000 (68%)]	Loss: -3.2215	Cost: 12.92s
Train Epoch: 438 [81920/90000 (91%)]	Loss: -3.4211	Cost: 13.91s
Train Epoch: 438 	Average Loss: -3.0300
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3811

Learning rate: 0.0001896641036785234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 439 [0/90000 (0%)]	Loss: -0.0557	Cost: 46.68s
Train Epoch: 439 [20480/90000 (23%)]	Loss: -3.4454	Cost: 11.82s
Train Epoch: 439 [40960/90000 (45%)]	Loss: -3.7901	Cost: 20.97s
Train Epoch: 439 [61440/90000 (68%)]	Loss: -3.4179	Cost: 10.82s
Train Epoch: 439 [81920/90000 (91%)]	Loss: -3.4905	Cost: 20.72s
Train Epoch: 439 	Average Loss: -3.2246
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2444

Learning rate: 0.00018961768898962428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 440 [0/90000 (0%)]	Loss: 0.3381	Cost: 79.47s
Train Epoch: 440 [20480/90000 (23%)]	Loss: -3.5709	Cost: 19.35s
Train Epoch: 440 [40960/90000 (45%)]	Loss: -3.7949	Cost: 26.24s
Train Epoch: 440 [61440/90000 (68%)]	Loss: -3.3603	Cost: 12.10s
Train Epoch: 440 [81920/90000 (91%)]	Loss: -3.2657	Cost: 36.06s
Train Epoch: 440 	Average Loss: -3.2387
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2789

Learning rate: 0.0001895711760239411
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 441 [0/90000 (0%)]	Loss: 0.4236	Cost: 38.06s
Train Epoch: 441 [20480/90000 (23%)]	Loss: -3.5261	Cost: 14.85s
Train Epoch: 441 [40960/90000 (45%)]	Loss: -3.7609	Cost: 16.27s
Train Epoch: 441 [61440/90000 (68%)]	Loss: -3.3841	Cost: 10.27s
Train Epoch: 441 [81920/90000 (91%)]	Loss: -3.5044	Cost: 13.51s
Train Epoch: 441 	Average Loss: -3.1851
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2234

Learning rate: 0.00018952456483248097
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 442 [0/90000 (0%)]	Loss: 0.1024	Cost: 36.79s
Train Epoch: 442 [20480/90000 (23%)]	Loss: -3.4430	Cost: 14.98s
Train Epoch: 442 [40960/90000 (45%)]	Loss: -3.9387	Cost: 15.29s
Train Epoch: 442 [61440/90000 (68%)]	Loss: -3.2709	Cost: 10.59s
Train Epoch: 442 [81920/90000 (91%)]	Loss: -3.4533	Cost: 19.99s
Train Epoch: 442 	Average Loss: -3.2281
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2764

Learning rate: 0.00018947785546635885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 443 [0/90000 (0%)]	Loss: 0.5150	Cost: 82.62s
Train Epoch: 443 [20480/90000 (23%)]	Loss: -3.5621	Cost: 14.73s
Train Epoch: 443 [40960/90000 (45%)]	Loss: -3.7201	Cost: 21.61s
Train Epoch: 443 [61440/90000 (68%)]	Loss: -2.4775	Cost: 12.44s
Train Epoch: 443 [81920/90000 (91%)]	Loss: -2.3824	Cost: 26.81s
Train Epoch: 443 	Average Loss: -2.7677
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9719

Learning rate: 0.0001894310479767972
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 444 [0/90000 (0%)]	Loss: 0.8088	Cost: 114.63s
Train Epoch: 444 [20480/90000 (23%)]	Loss: -2.8713	Cost: 15.57s
Train Epoch: 444 [40960/90000 (45%)]	Loss: -3.5218	Cost: 41.60s
Train Epoch: 444 [61440/90000 (68%)]	Loss: -3.2838	Cost: 15.47s
Train Epoch: 444 [81920/90000 (91%)]	Loss: -3.4380	Cost: 53.85s
Train Epoch: 444 	Average Loss: -2.8543
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2123

Learning rate: 0.0001893841424151262
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 445 [0/90000 (0%)]	Loss: 0.3631	Cost: 109.82s
Train Epoch: 445 [20480/90000 (23%)]	Loss: -3.4008	Cost: 17.79s
Train Epoch: 445 [40960/90000 (45%)]	Loss: -3.6975	Cost: 45.84s
Train Epoch: 445 [61440/90000 (68%)]	Loss: -3.4189	Cost: 14.48s
Train Epoch: 445 [81920/90000 (91%)]	Loss: -3.5710	Cost: 72.65s
Train Epoch: 445 	Average Loss: -3.2349
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1190

Learning rate: 0.00018933713883278357
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 446 [0/90000 (0%)]	Loss: 0.0872	Cost: 168.78s
Train Epoch: 446 [20480/90000 (23%)]	Loss: -3.6033	Cost: 29.32s
Train Epoch: 446 [40960/90000 (45%)]	Loss: -3.9538	Cost: 91.01s
Train Epoch: 446 [61440/90000 (68%)]	Loss: -3.6558	Cost: 26.82s
Train Epoch: 446 [81920/90000 (91%)]	Loss: -3.7459	Cost: 57.16s
Train Epoch: 446 	Average Loss: -3.3928
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0568

Learning rate: 0.0001892900372813145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 447 [0/90000 (0%)]	Loss: -0.2173	Cost: 208.20s
Train Epoch: 447 [20480/90000 (23%)]	Loss: -3.8872	Cost: 21.75s
Train Epoch: 447 [40960/90000 (45%)]	Loss: -4.1729	Cost: 73.22s
Train Epoch: 447 [61440/90000 (68%)]	Loss: -3.5834	Cost: 16.60s
Train Epoch: 447 [81920/90000 (91%)]	Loss: -3.7973	Cost: 68.30s
Train Epoch: 447 	Average Loss: -3.5203
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0808

Learning rate: 0.00018924283781237162
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 448 [0/90000 (0%)]	Loss: 0.2024	Cost: 291.07s
Train Epoch: 448 [20480/90000 (23%)]	Loss: -3.8365	Cost: 27.49s
Train Epoch: 448 [40960/90000 (45%)]	Loss: -4.0021	Cost: 114.18s
Train Epoch: 448 [61440/90000 (68%)]	Loss: -3.7285	Cost: 26.38s
Train Epoch: 448 [81920/90000 (91%)]	Loss: -3.5836	Cost: 104.81s
Train Epoch: 448 	Average Loss: -3.5119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0607

Learning rate: 0.0001891955404777149
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 449 [0/90000 (0%)]	Loss: 0.0918	Cost: 230.08s
Train Epoch: 449 [20480/90000 (23%)]	Loss: -3.8111	Cost: 21.17s
Train Epoch: 449 [40960/90000 (45%)]	Loss: -4.0616	Cost: 65.84s
Train Epoch: 449 [61440/90000 (68%)]	Loss: -3.5711	Cost: 19.98s
Train Epoch: 449 [81920/90000 (91%)]	Loss: -3.7867	Cost: 82.03s
Train Epoch: 449 	Average Loss: -3.4806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1329

Learning rate: 0.0001891481453292117
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 450 [0/90000 (0%)]	Loss: -0.2976	Cost: 162.27s
Train Epoch: 450 [20480/90000 (23%)]	Loss: -3.7810	Cost: 22.11s
Train Epoch: 450 [40960/90000 (45%)]	Loss: -4.2142	Cost: 65.82s
Train Epoch: 450 [61440/90000 (68%)]	Loss: -3.8017	Cost: 16.90s
Train Epoch: 450 [81920/90000 (91%)]	Loss: -3.7959	Cost: 65.64s
Train Epoch: 450 	Average Loss: -3.5657
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0017

Saving model as model.pt_e450 & waveforms_supplementary.hdf5_e450
Learning rate: 0.0001891006524188366
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 451 [0/90000 (0%)]	Loss: -0.1978	Cost: 118.09s
Train Epoch: 451 [20480/90000 (23%)]	Loss: -3.9966	Cost: 16.41s
Train Epoch: 451 [40960/90000 (45%)]	Loss: -4.1389	Cost: 45.51s
Train Epoch: 451 [61440/90000 (68%)]	Loss: -3.7359	Cost: 15.31s
Train Epoch: 451 [81920/90000 (91%)]	Loss: -3.7788	Cost: 33.41s
Train Epoch: 451 	Average Loss: -3.6078
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0413

Learning rate: 0.0001890530617986714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 452 [0/90000 (0%)]	Loss: -0.1885	Cost: 30.72s
Train Epoch: 452 [20480/90000 (23%)]	Loss: -4.1918	Cost: 9.75s
Train Epoch: 452 [40960/90000 (45%)]	Loss: -4.1474	Cost: 12.28s
Train Epoch: 452 [61440/90000 (68%)]	Loss: -3.7878	Cost: 9.94s
Train Epoch: 452 [81920/90000 (91%)]	Loss: -3.8767	Cost: 10.98s
Train Epoch: 452 	Average Loss: -3.6734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0790

Learning rate: 0.00018900537352090508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 453 [0/90000 (0%)]	Loss: -0.2176	Cost: 31.12s
Train Epoch: 453 [20480/90000 (23%)]	Loss: -2.4395	Cost: 9.75s
Train Epoch: 453 [40960/90000 (45%)]	Loss: -3.1698	Cost: 11.81s
Train Epoch: 453 [61440/90000 (68%)]	Loss: -3.2246	Cost: 9.57s
Train Epoch: 453 [81920/90000 (91%)]	Loss: -3.3457	Cost: 11.61s
Train Epoch: 453 	Average Loss: -2.7851
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1508

Learning rate: 0.00018895758763783364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 454 [0/90000 (0%)]	Loss: 0.2161	Cost: 32.90s
Train Epoch: 454 [20480/90000 (23%)]	Loss: -3.7494	Cost: 9.72s
Train Epoch: 454 [40960/90000 (45%)]	Loss: -4.0317	Cost: 11.02s
Train Epoch: 454 [61440/90000 (68%)]	Loss: -3.7844	Cost: 9.59s
Train Epoch: 454 [81920/90000 (91%)]	Loss: -3.7227	Cost: 10.70s
Train Epoch: 454 	Average Loss: -3.5113
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1971

Learning rate: 0.00018890970420186014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 455 [0/90000 (0%)]	Loss: 0.1406	Cost: 32.96s
Train Epoch: 455 [20480/90000 (23%)]	Loss: -4.0462	Cost: 9.78s
Train Epoch: 455 [40960/90000 (45%)]	Loss: -4.2765	Cost: 11.31s
Train Epoch: 455 [61440/90000 (68%)]	Loss: -3.6884	Cost: 9.74s
Train Epoch: 455 [81920/90000 (91%)]	Loss: -3.8406	Cost: 11.01s
Train Epoch: 455 	Average Loss: -3.7190
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0361

Learning rate: 0.0001888617232654947
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 456 [0/90000 (0%)]	Loss: -0.0971	Cost: 31.43s
Train Epoch: 456 [20480/90000 (23%)]	Loss: -3.8833	Cost: 9.76s
Train Epoch: 456 [40960/90000 (45%)]	Loss: -4.2314	Cost: 12.13s
Train Epoch: 456 [61440/90000 (68%)]	Loss: -3.8425	Cost: 9.59s
Train Epoch: 456 [81920/90000 (91%)]	Loss: -3.7199	Cost: 11.29s
Train Epoch: 456 	Average Loss: -3.6761
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0962

Learning rate: 0.00018881364488135426
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 457 [0/90000 (0%)]	Loss: -0.2002	Cost: 30.36s
Train Epoch: 457 [20480/90000 (23%)]	Loss: -3.5539	Cost: 9.90s
Train Epoch: 457 [40960/90000 (45%)]	Loss: -4.0971	Cost: 11.42s
Train Epoch: 457 [61440/90000 (68%)]	Loss: -3.9092	Cost: 9.60s
Train Epoch: 457 [81920/90000 (91%)]	Loss: -4.0375	Cost: 10.87s
Train Epoch: 457 	Average Loss: -3.6274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1351

Learning rate: 0.00018876546910216269
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 458 [0/90000 (0%)]	Loss: -0.5072	Cost: 30.00s
Train Epoch: 458 [20480/90000 (23%)]	Loss: -4.1338	Cost: 9.91s
Train Epoch: 458 [40960/90000 (45%)]	Loss: -4.2650	Cost: 12.20s
Train Epoch: 458 [61440/90000 (68%)]	Loss: -4.0806	Cost: 9.67s
Train Epoch: 458 [81920/90000 (91%)]	Loss: -3.9663	Cost: 11.62s
Train Epoch: 458 	Average Loss: -3.7839
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2704

Learning rate: 0.00018871719598075062
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 459 [0/90000 (0%)]	Loss: -0.2863	Cost: 32.66s
Train Epoch: 459 [20480/90000 (23%)]	Loss: -4.1439	Cost: 9.75s
Train Epoch: 459 [40960/90000 (45%)]	Loss: -4.3357	Cost: 11.45s
Train Epoch: 459 [61440/90000 (68%)]	Loss: -3.9544	Cost: 9.54s
Train Epoch: 459 [81920/90000 (91%)]	Loss: -4.0743	Cost: 11.08s
Train Epoch: 459 	Average Loss: -3.8171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3141

Learning rate: 0.00018866882557005548
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 460 [0/90000 (0%)]	Loss: 0.0441	Cost: 31.87s
Train Epoch: 460 [20480/90000 (23%)]	Loss: -4.0964	Cost: 9.71s
Train Epoch: 460 [40960/90000 (45%)]	Loss: -4.4532	Cost: 10.93s
Train Epoch: 460 [61440/90000 (68%)]	Loss: -4.2290	Cost: 9.56s
Train Epoch: 460 [81920/90000 (91%)]	Loss: -4.2488	Cost: 10.81s
Train Epoch: 460 	Average Loss: -3.9103
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3871

Learning rate: 0.00018862035792312128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 461 [0/90000 (0%)]	Loss: -0.6247	Cost: 32.43s
Train Epoch: 461 [20480/90000 (23%)]	Loss: -4.2883	Cost: 9.62s
Train Epoch: 461 [40960/90000 (45%)]	Loss: -4.4305	Cost: 11.42s
Train Epoch: 461 [61440/90000 (68%)]	Loss: -4.1255	Cost: 9.57s
Train Epoch: 461 [81920/90000 (91%)]	Loss: -4.1569	Cost: 10.85s
Train Epoch: 461 	Average Loss: -3.9381
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3919

Learning rate: 0.00018857179309309882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 462 [0/90000 (0%)]	Loss: -0.1371	Cost: 33.25s
Train Epoch: 462 [20480/90000 (23%)]	Loss: -3.5837	Cost: 9.83s
Train Epoch: 462 [40960/90000 (45%)]	Loss: -4.0241	Cost: 10.92s
Train Epoch: 462 [61440/90000 (68%)]	Loss: -3.6862	Cost: 9.57s
Train Epoch: 462 [81920/90000 (91%)]	Loss: -3.9976	Cost: 11.06s
Train Epoch: 462 	Average Loss: -3.6105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3577

Learning rate: 0.00018852313113324536
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 463 [0/90000 (0%)]	Loss: -0.5235	Cost: 31.92s
Train Epoch: 463 [20480/90000 (23%)]	Loss: -4.1786	Cost: 9.61s
Train Epoch: 463 [40960/90000 (45%)]	Loss: -4.5087	Cost: 12.24s
Train Epoch: 463 [61440/90000 (68%)]	Loss: -4.1794	Cost: 9.64s
Train Epoch: 463 [81920/90000 (91%)]	Loss: -4.1043	Cost: 11.74s
Train Epoch: 463 	Average Loss: -3.9647
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4965

Learning rate: 0.0001884743720969247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 464 [0/90000 (0%)]	Loss: -0.2661	Cost: 31.58s
Train Epoch: 464 [20480/90000 (23%)]	Loss: -4.4426	Cost: 9.89s
Train Epoch: 464 [40960/90000 (45%)]	Loss: -4.6104	Cost: 12.18s
Train Epoch: 464 [61440/90000 (68%)]	Loss: -4.2801	Cost: 9.57s
Train Epoch: 464 [81920/90000 (91%)]	Loss: -4.0590	Cost: 11.89s
Train Epoch: 464 	Average Loss: -4.0250
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2584

Learning rate: 0.00018842551603760708
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 465 [0/90000 (0%)]	Loss: -0.1035	Cost: 31.85s
Train Epoch: 465 [20480/90000 (23%)]	Loss: -4.3936	Cost: 9.80s
Train Epoch: 465 [40960/90000 (45%)]	Loss: -4.5859	Cost: 11.45s
Train Epoch: 465 [61440/90000 (68%)]	Loss: -4.3204	Cost: 9.48s
Train Epoch: 465 [81920/90000 (91%)]	Loss: -4.3151	Cost: 11.02s
Train Epoch: 465 	Average Loss: -4.0558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4503

Learning rate: 0.00018837656300886918
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 466 [0/90000 (0%)]	Loss: -0.7243	Cost: 31.41s
Train Epoch: 466 [20480/90000 (23%)]	Loss: -4.3691	Cost: 9.75s
Train Epoch: 466 [40960/90000 (45%)]	Loss: -4.6780	Cost: 11.43s
Train Epoch: 466 [61440/90000 (68%)]	Loss: -4.1860	Cost: 9.82s
Train Epoch: 466 [81920/90000 (91%)]	Loss: -4.0886	Cost: 11.01s
Train Epoch: 466 	Average Loss: -4.0412
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3118

Learning rate: 0.000188327513064394
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 467 [0/90000 (0%)]	Loss: -0.4422	Cost: 32.78s
Train Epoch: 467 [20480/90000 (23%)]	Loss: -4.3817	Cost: 9.88s
Train Epoch: 467 [40960/90000 (45%)]	Loss: -4.8692	Cost: 10.92s
Train Epoch: 467 [61440/90000 (68%)]	Loss: -4.1972	Cost: 9.65s
Train Epoch: 467 [81920/90000 (91%)]	Loss: -4.3680	Cost: 10.49s
Train Epoch: 467 	Average Loss: -4.0843
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4453

Learning rate: 0.00018827836625797084
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 468 [0/90000 (0%)]	Loss: -0.0465	Cost: 31.70s
Train Epoch: 468 [20480/90000 (23%)]	Loss: -3.9016	Cost: 9.79s
Train Epoch: 468 [40960/90000 (45%)]	Loss: -4.3990	Cost: 12.17s
Train Epoch: 468 [61440/90000 (68%)]	Loss: -4.2962	Cost: 9.47s
Train Epoch: 468 [81920/90000 (91%)]	Loss: -4.5367	Cost: 11.70s
Train Epoch: 468 	Average Loss: -3.9493
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4547

Learning rate: 0.00018822912264349518
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 469 [0/90000 (0%)]	Loss: -0.3688	Cost: 32.70s
Train Epoch: 469 [20480/90000 (23%)]	Loss: -4.1736	Cost: 9.65s
Train Epoch: 469 [40960/90000 (45%)]	Loss: -4.7019	Cost: 11.40s
Train Epoch: 469 [61440/90000 (68%)]	Loss: -4.3825	Cost: 9.54s
Train Epoch: 469 [81920/90000 (91%)]	Loss: -4.1472	Cost: 10.66s
Train Epoch: 469 	Average Loss: -4.0527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3894

Learning rate: 0.00018817978227496867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 470 [0/90000 (0%)]	Loss: -0.5092	Cost: 31.32s
Train Epoch: 470 [20480/90000 (23%)]	Loss: -4.4875	Cost: 9.77s
Train Epoch: 470 [40960/90000 (45%)]	Loss: -4.8449	Cost: 11.42s
Train Epoch: 470 [61440/90000 (68%)]	Loss: -4.3688	Cost: 9.50s
Train Epoch: 470 [81920/90000 (91%)]	Loss: -4.3669	Cost: 11.14s
Train Epoch: 470 	Average Loss: -4.1755
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4935

Learning rate: 0.0001881303452064991
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 471 [0/90000 (0%)]	Loss: -0.3288	Cost: 32.19s
Train Epoch: 471 [20480/90000 (23%)]	Loss: -4.6328	Cost: 9.78s
Train Epoch: 471 [40960/90000 (45%)]	Loss: -4.6688	Cost: 11.05s
Train Epoch: 471 [61440/90000 (68%)]	Loss: -4.5141	Cost: 9.76s
Train Epoch: 471 [81920/90000 (91%)]	Loss: -4.4637	Cost: 10.77s
Train Epoch: 471 	Average Loss: -4.2709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5872

Learning rate: 0.00018808081149230025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 472 [0/90000 (0%)]	Loss: -0.4938	Cost: 32.44s
Train Epoch: 472 [20480/90000 (23%)]	Loss: -4.4929	Cost: 9.69s
Train Epoch: 472 [40960/90000 (45%)]	Loss: -4.6910	Cost: 11.25s
Train Epoch: 472 [61440/90000 (68%)]	Loss: -4.5836	Cost: 9.53s
Train Epoch: 472 [81920/90000 (91%)]	Loss: -4.4117	Cost: 10.76s
Train Epoch: 472 	Average Loss: -4.2964
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4410

Learning rate: 0.00018803118118669191
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 473 [0/90000 (0%)]	Loss: -0.3516	Cost: 31.17s
Train Epoch: 473 [20480/90000 (23%)]	Loss: -4.2254	Cost: 9.86s
Train Epoch: 473 [40960/90000 (45%)]	Loss: -4.5894	Cost: 11.31s
Train Epoch: 473 [61440/90000 (68%)]	Loss: -4.3687	Cost: 9.48s
Train Epoch: 473 [81920/90000 (91%)]	Loss: -4.2651	Cost: 11.30s
Train Epoch: 473 	Average Loss: -4.0924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3817

Learning rate: 0.00018798145434409982
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 474 [0/90000 (0%)]	Loss: -0.7143	Cost: 31.10s
Train Epoch: 474 [20480/90000 (23%)]	Loss: -4.3134	Cost: 9.68s
Train Epoch: 474 [40960/90000 (45%)]	Loss: -4.6342	Cost: 11.82s
Train Epoch: 474 [61440/90000 (68%)]	Loss: -4.3410	Cost: 9.62s
Train Epoch: 474 [81920/90000 (91%)]	Loss: -4.4769	Cost: 11.75s
Train Epoch: 474 	Average Loss: -4.1666
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6195

Learning rate: 0.00018793163101905552
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 475 [0/90000 (0%)]	Loss: -0.9081	Cost: 32.65s
Train Epoch: 475 [20480/90000 (23%)]	Loss: -4.8460	Cost: 9.78s
Train Epoch: 475 [40960/90000 (45%)]	Loss: -4.9549	Cost: 10.85s
Train Epoch: 475 [61440/90000 (68%)]	Loss: -4.5691	Cost: 9.55s
Train Epoch: 475 [81920/90000 (91%)]	Loss: -4.7842	Cost: 10.98s
Train Epoch: 475 	Average Loss: -4.4732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7828

Learning rate: 0.00018788171126619643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 476 [0/90000 (0%)]	Loss: -0.2554	Cost: 30.93s
Train Epoch: 476 [20480/90000 (23%)]	Loss: -4.8453	Cost: 9.87s
Train Epoch: 476 [40960/90000 (45%)]	Loss: -4.9982	Cost: 11.10s
Train Epoch: 476 [61440/90000 (68%)]	Loss: -4.1205	Cost: 9.59s
Train Epoch: 476 [81920/90000 (91%)]	Loss: -4.1168	Cost: 10.69s
Train Epoch: 476 	Average Loss: -4.2499
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3117

Learning rate: 0.00018783169514026567
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 477 [0/90000 (0%)]	Loss: -0.5194	Cost: 31.06s
Train Epoch: 477 [20480/90000 (23%)]	Loss: -4.6275	Cost: 9.81s
Train Epoch: 477 [40960/90000 (45%)]	Loss: -4.9084	Cost: 11.08s
Train Epoch: 477 [61440/90000 (68%)]	Loss: -4.5768	Cost: 9.52s
Train Epoch: 477 [81920/90000 (91%)]	Loss: -4.6789	Cost: 11.11s
Train Epoch: 477 	Average Loss: -4.3020
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7631

Learning rate: 0.00018778158269611207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 478 [0/90000 (0%)]	Loss: -1.0340	Cost: 31.92s
Train Epoch: 478 [20480/90000 (23%)]	Loss: -4.8859	Cost: 9.85s
Train Epoch: 478 [40960/90000 (45%)]	Loss: -4.9046	Cost: 10.96s
Train Epoch: 478 [61440/90000 (68%)]	Loss: -4.7449	Cost: 9.85s
Train Epoch: 478 [81920/90000 (91%)]	Loss: -4.7252	Cost: 10.58s
Train Epoch: 478 	Average Loss: -4.4807
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7079

Learning rate: 0.00018773137398869004
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 479 [0/90000 (0%)]	Loss: -0.4060	Cost: 31.90s
Train Epoch: 479 [20480/90000 (23%)]	Loss: -4.6957	Cost: 9.77s
Train Epoch: 479 [40960/90000 (45%)]	Loss: -4.7038	Cost: 11.96s
Train Epoch: 479 [61440/90000 (68%)]	Loss: -4.3961	Cost: 9.53s
Train Epoch: 479 [81920/90000 (91%)]	Loss: -4.5895	Cost: 11.53s
Train Epoch: 479 	Average Loss: -4.3315
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6310

Learning rate: 0.0001876810690730596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 480 [0/90000 (0%)]	Loss: -0.6455	Cost: 33.23s
Train Epoch: 480 [20480/90000 (23%)]	Loss: -4.6883	Cost: 9.87s
Train Epoch: 480 [40960/90000 (45%)]	Loss: -4.9500	Cost: 10.67s
Train Epoch: 480 [61440/90000 (68%)]	Loss: -4.5464	Cost: 9.45s
Train Epoch: 480 [81920/90000 (91%)]	Loss: -4.6172	Cost: 10.54s
Train Epoch: 480 	Average Loss: -4.3215
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6844

Learning rate: 0.00018763066800438623
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 481 [0/90000 (0%)]	Loss: -0.3729	Cost: 31.69s
Train Epoch: 481 [20480/90000 (23%)]	Loss: -4.7786	Cost: 9.81s
Train Epoch: 481 [40960/90000 (45%)]	Loss: -5.2533	Cost: 10.86s
Train Epoch: 481 [61440/90000 (68%)]	Loss: -4.8343	Cost: 9.52s
Train Epoch: 481 [81920/90000 (91%)]	Loss: -5.0041	Cost: 10.89s
Train Epoch: 481 	Average Loss: -4.5989
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9778

Learning rate: 0.00018758017083794095
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 482 [0/90000 (0%)]	Loss: -0.5437	Cost: 31.52s
Train Epoch: 482 [20480/90000 (23%)]	Loss: -5.1914	Cost: 9.83s
Train Epoch: 482 [40960/90000 (45%)]	Loss: -5.0612	Cost: 12.40s
Train Epoch: 482 [61440/90000 (68%)]	Loss: -4.8226	Cost: 9.46s
Train Epoch: 482 [81920/90000 (91%)]	Loss: -4.8751	Cost: 11.67s
Train Epoch: 482 	Average Loss: -4.6119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7334

Learning rate: 0.00018752957762910004
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 483 [0/90000 (0%)]	Loss: -1.2097	Cost: 32.59s
Train Epoch: 483 [20480/90000 (23%)]	Loss: -4.8464	Cost: 9.64s
Train Epoch: 483 [40960/90000 (45%)]	Loss: -5.1441	Cost: 12.18s
Train Epoch: 483 [61440/90000 (68%)]	Loss: -4.6512	Cost: 9.62s
Train Epoch: 483 [81920/90000 (91%)]	Loss: -4.7626	Cost: 11.31s
Train Epoch: 483 	Average Loss: -4.6415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8533

Learning rate: 0.00018747888843334516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 484 [0/90000 (0%)]	Loss: -1.0575	Cost: 32.54s
Train Epoch: 484 [20480/90000 (23%)]	Loss: -5.0544	Cost: 9.81s
Train Epoch: 484 [40960/90000 (45%)]	Loss: -3.0867	Cost: 11.12s
Train Epoch: 484 [61440/90000 (68%)]	Loss: -2.8293	Cost: 9.70s
Train Epoch: 484 [81920/90000 (91%)]	Loss: -2.2205	Cost: 10.85s
Train Epoch: 484 	Average Loss: -3.3159
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2207

Learning rate: 0.00018742810330626324
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 485 [0/90000 (0%)]	Loss: 0.9737	Cost: 32.49s
Train Epoch: 485 [20480/90000 (23%)]	Loss: -2.9007	Cost: 9.76s
Train Epoch: 485 [40960/90000 (45%)]	Loss: -3.7381	Cost: 11.20s
Train Epoch: 485 [61440/90000 (68%)]	Loss: -3.6874	Cost: 9.50s
Train Epoch: 485 [81920/90000 (91%)]	Loss: -3.9805	Cost: 10.96s
Train Epoch: 485 	Average Loss: -3.1215
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4514

Learning rate: 0.0001873772223035464
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 486 [0/90000 (0%)]	Loss: -0.3832	Cost: 31.58s
Train Epoch: 486 [20480/90000 (23%)]	Loss: -4.6419	Cost: 9.87s
Train Epoch: 486 [40960/90000 (45%)]	Loss: -4.9460	Cost: 11.47s
Train Epoch: 486 [61440/90000 (68%)]	Loss: -4.3786	Cost: 9.67s
Train Epoch: 486 [81920/90000 (91%)]	Loss: -4.5419	Cost: 10.85s
Train Epoch: 486 	Average Loss: -4.2810
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6590

Learning rate: 0.00018732624548099187
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 487 [0/90000 (0%)]	Loss: -0.5602	Cost: 31.45s
Train Epoch: 487 [20480/90000 (23%)]	Loss: 0.6986	Cost: 9.75s
Train Epoch: 487 [40960/90000 (45%)]	Loss: -0.3502	Cost: 11.66s
Train Epoch: 487 [61440/90000 (68%)]	Loss: -1.2043	Cost: 9.94s
Train Epoch: 487 [81920/90000 (91%)]	Loss: -2.1818	Cost: 10.25s
Train Epoch: 487 	Average Loss: -1.2444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8536

Learning rate: 0.00018727517289450203
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 488 [0/90000 (0%)]	Loss: 0.3615	Cost: 32.11s
Train Epoch: 488 [20480/90000 (23%)]	Loss: -3.2545	Cost: 9.81s
Train Epoch: 488 [40960/90000 (45%)]	Loss: -4.0233	Cost: 10.73s
Train Epoch: 488 [61440/90000 (68%)]	Loss: -3.9198	Cost: 9.60s
Train Epoch: 488 [81920/90000 (91%)]	Loss: -4.1720	Cost: 10.75s
Train Epoch: 488 	Average Loss: -3.4601
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4809

Learning rate: 0.00018722400460008422
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 489 [0/90000 (0%)]	Loss: -0.8063	Cost: 30.80s
Train Epoch: 489 [20480/90000 (23%)]	Loss: -4.5152	Cost: 9.82s
Train Epoch: 489 [40960/90000 (45%)]	Loss: -4.6308	Cost: 11.38s
Train Epoch: 489 [61440/90000 (68%)]	Loss: -4.3580	Cost: 9.57s
Train Epoch: 489 [81920/90000 (91%)]	Loss: -4.4550	Cost: 11.04s
Train Epoch: 489 	Average Loss: -4.2615
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8136

Learning rate: 0.00018717274065385077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 490 [0/90000 (0%)]	Loss: -0.5377	Cost: 32.72s
Train Epoch: 490 [20480/90000 (23%)]	Loss: -4.7502	Cost: 9.78s
Train Epoch: 490 [40960/90000 (45%)]	Loss: -5.0712	Cost: 10.75s
Train Epoch: 490 [61440/90000 (68%)]	Loss: -4.6563	Cost: 9.59s
Train Epoch: 490 [81920/90000 (91%)]	Loss: -4.6973	Cost: 10.79s
Train Epoch: 490 	Average Loss: -4.4530
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7533

Learning rate: 0.00018712138111201881
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 491 [0/90000 (0%)]	Loss: -0.9523	Cost: 31.35s
Train Epoch: 491 [20480/90000 (23%)]	Loss: -4.7944	Cost: 9.88s
Train Epoch: 491 [40960/90000 (45%)]	Loss: -5.2030	Cost: 10.60s
Train Epoch: 491 [61440/90000 (68%)]	Loss: -4.6934	Cost: 9.76s
Train Epoch: 491 [81920/90000 (91%)]	Loss: -4.9613	Cost: 10.56s
Train Epoch: 491 	Average Loss: -4.5818
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7759

Learning rate: 0.00018706992603091045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 492 [0/90000 (0%)]	Loss: -1.0350	Cost: 31.66s
Train Epoch: 492 [20480/90000 (23%)]	Loss: -4.8501	Cost: 9.88s
Train Epoch: 492 [40960/90000 (45%)]	Loss: -5.0787	Cost: 10.73s
Train Epoch: 492 [61440/90000 (68%)]	Loss: -4.8411	Cost: 9.60s
Train Epoch: 492 [81920/90000 (91%)]	Loss: -4.7826	Cost: 11.03s
Train Epoch: 492 	Average Loss: -4.6499
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9493

Learning rate: 0.00018701837546695246
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 493 [0/90000 (0%)]	Loss: -0.7679	Cost: 31.25s
Train Epoch: 493 [20480/90000 (23%)]	Loss: -5.1401	Cost: 9.88s
Train Epoch: 493 [40960/90000 (45%)]	Loss: -5.3792	Cost: 10.59s
Train Epoch: 493 [61440/90000 (68%)]	Loss: -5.0119	Cost: 9.56s
Train Epoch: 493 [81920/90000 (91%)]	Loss: -4.9251	Cost: 10.92s
Train Epoch: 493 	Average Loss: -4.7394
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9227

Learning rate: 0.00018696672947667633
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 494 [0/90000 (0%)]	Loss: -0.9019	Cost: 32.13s
Train Epoch: 494 [20480/90000 (23%)]	Loss: -5.0297	Cost: 9.75s
Train Epoch: 494 [40960/90000 (45%)]	Loss: -5.2677	Cost: 11.06s
Train Epoch: 494 [61440/90000 (68%)]	Loss: -5.0974	Cost: 9.74s
Train Epoch: 494 [81920/90000 (91%)]	Loss: -5.1856	Cost: 10.97s
Train Epoch: 494 	Average Loss: -4.7810
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0521

Learning rate: 0.00018691498811671827
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 495 [0/90000 (0%)]	Loss: -1.2009	Cost: 30.88s
Train Epoch: 495 [20480/90000 (23%)]	Loss: -5.0639	Cost: 9.79s
Train Epoch: 495 [40960/90000 (45%)]	Loss: -5.2457	Cost: 11.84s
Train Epoch: 495 [61440/90000 (68%)]	Loss: -4.9874	Cost: 9.52s
Train Epoch: 495 [81920/90000 (91%)]	Loss: -5.0890	Cost: 11.90s
Train Epoch: 495 	Average Loss: -4.8151
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9887

Learning rate: 0.00018686315144381902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 496 [0/90000 (0%)]	Loss: -1.0737	Cost: 31.44s
Train Epoch: 496 [20480/90000 (23%)]	Loss: -5.1433	Cost: 10.45s
Train Epoch: 496 [40960/90000 (45%)]	Loss: -5.5603	Cost: 11.48s
Train Epoch: 496 [61440/90000 (68%)]	Loss: -5.1121	Cost: 9.71s
Train Epoch: 496 [81920/90000 (91%)]	Loss: -5.2944	Cost: 11.57s
Train Epoch: 496 	Average Loss: -4.9319
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0022

Learning rate: 0.00018681121951482382
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 497 [0/90000 (0%)]	Loss: -1.0376	Cost: 31.46s
Train Epoch: 497 [20480/90000 (23%)]	Loss: -5.2412	Cost: 9.75s
Train Epoch: 497 [40960/90000 (45%)]	Loss: -5.4080	Cost: 11.44s
Train Epoch: 497 [61440/90000 (68%)]	Loss: -4.9554	Cost: 9.53s
Train Epoch: 497 [81920/90000 (91%)]	Loss: -5.1153	Cost: 10.99s
Train Epoch: 497 	Average Loss: -4.9047
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1827

Learning rate: 0.0001867591923866824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 498 [0/90000 (0%)]	Loss: -0.9790	Cost: 30.24s
Train Epoch: 498 [20480/90000 (23%)]	Loss: -5.2237	Cost: 9.85s
Train Epoch: 498 [40960/90000 (45%)]	Loss: -5.4318	Cost: 11.66s
Train Epoch: 498 [61440/90000 (68%)]	Loss: -5.2565	Cost: 9.69s
Train Epoch: 498 [81920/90000 (91%)]	Loss: -5.1095	Cost: 11.28s
Train Epoch: 498 	Average Loss: -4.9608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1367

Learning rate: 0.0001867070701164489
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 499 [0/90000 (0%)]	Loss: -1.2131	Cost: 31.93s
Train Epoch: 499 [20480/90000 (23%)]	Loss: -5.4998	Cost: 9.80s
Train Epoch: 499 [40960/90000 (45%)]	Loss: -5.5036	Cost: 11.64s
Train Epoch: 499 [61440/90000 (68%)]	Loss: -5.3455	Cost: 9.60s
Train Epoch: 499 [81920/90000 (91%)]	Loss: -5.4071	Cost: 11.46s
Train Epoch: 499 	Average Loss: -5.0558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3522

Learning rate: 0.0001866548527612818
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 500 [0/90000 (0%)]	Loss: -1.3930	Cost: 32.26s
Train Epoch: 500 [20480/90000 (23%)]	Loss: -5.4366	Cost: 9.78s
Train Epoch: 500 [40960/90000 (45%)]	Loss: -5.6674	Cost: 11.45s
Train Epoch: 500 [61440/90000 (68%)]	Loss: -5.0911	Cost: 9.65s
Train Epoch: 500 [81920/90000 (91%)]	Loss: -5.0925	Cost: 11.39s
Train Epoch: 500 	Average Loss: -5.1013
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9647

Saving model as model.pt_e500 & waveforms_supplementary.hdf5_e500
Learning rate: 0.0001866025403784438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 501 [0/90000 (0%)]	Loss: -1.2153	Cost: 31.01s
Train Epoch: 501 [20480/90000 (23%)]	Loss: -5.2435	Cost: 9.80s
Train Epoch: 501 [40960/90000 (45%)]	Loss: -5.6461	Cost: 11.95s
Train Epoch: 501 [61440/90000 (68%)]	Loss: -5.3743	Cost: 9.51s
Train Epoch: 501 [81920/90000 (91%)]	Loss: -5.4899	Cost: 11.92s
Train Epoch: 501 	Average Loss: -5.0794
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3829

Learning rate: 0.00018655013302530183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 502 [0/90000 (0%)]	Loss: -1.4062	Cost: 33.09s
Train Epoch: 502 [20480/90000 (23%)]	Loss: -5.4342	Cost: 9.84s
Train Epoch: 502 [40960/90000 (45%)]	Loss: -5.8841	Cost: 12.17s
Train Epoch: 502 [61440/90000 (68%)]	Loss: -5.3851	Cost: 9.64s
Train Epoch: 502 [81920/90000 (91%)]	Loss: -5.4333	Cost: 11.51s
Train Epoch: 502 	Average Loss: -5.2268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2720

Learning rate: 0.00018649763075932703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 503 [0/90000 (0%)]	Loss: -1.4614	Cost: 31.03s
Train Epoch: 503 [20480/90000 (23%)]	Loss: -5.4186	Cost: 9.85s
Train Epoch: 503 [40960/90000 (45%)]	Loss: -5.9406	Cost: 11.65s
Train Epoch: 503 [61440/90000 (68%)]	Loss: -5.3823	Cost: 9.65s
Train Epoch: 503 [81920/90000 (91%)]	Loss: -5.5788	Cost: 11.57s
Train Epoch: 503 	Average Loss: -5.2624
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3656

Learning rate: 0.0001864450336380945
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 504 [0/90000 (0%)]	Loss: -1.3428	Cost: 32.00s
Train Epoch: 504 [20480/90000 (23%)]	Loss: -5.5594	Cost: 9.71s
Train Epoch: 504 [40960/90000 (45%)]	Loss: -5.8734	Cost: 11.64s
Train Epoch: 504 [61440/90000 (68%)]	Loss: -5.4271	Cost: 9.47s
Train Epoch: 504 [81920/90000 (91%)]	Loss: -5.4488	Cost: 11.04s
Train Epoch: 504 	Average Loss: -5.2516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4004

Learning rate: 0.00018639234171928344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 505 [0/90000 (0%)]	Loss: -1.0882	Cost: 32.70s
Train Epoch: 505 [20480/90000 (23%)]	Loss: -5.4538	Cost: 9.79s
Train Epoch: 505 [40960/90000 (45%)]	Loss: -5.7942	Cost: 11.18s
Train Epoch: 505 [61440/90000 (68%)]	Loss: -5.3029	Cost: 9.54s
Train Epoch: 505 [81920/90000 (91%)]	Loss: -5.2991	Cost: 10.97s
Train Epoch: 505 	Average Loss: -5.1911
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2462

Learning rate: 0.0001863395550606771
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 506 [0/90000 (0%)]	Loss: -1.2501	Cost: 32.04s
Train Epoch: 506 [20480/90000 (23%)]	Loss: -5.6051	Cost: 9.73s
Train Epoch: 506 [40960/90000 (45%)]	Loss: -5.7277	Cost: 11.36s
Train Epoch: 506 [61440/90000 (68%)]	Loss: -5.3473	Cost: 9.70s
Train Epoch: 506 [81920/90000 (91%)]	Loss: -5.3873	Cost: 10.64s
Train Epoch: 506 	Average Loss: -5.1807
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2723

Learning rate: 0.00018628667372016245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 507 [0/90000 (0%)]	Loss: -1.5896	Cost: 30.65s
Train Epoch: 507 [20480/90000 (23%)]	Loss: -5.6155	Cost: 9.80s
Train Epoch: 507 [40960/90000 (45%)]	Loss: -5.8161	Cost: 11.68s
Train Epoch: 507 [61440/90000 (68%)]	Loss: -5.2781	Cost: 9.50s
Train Epoch: 507 [81920/90000 (91%)]	Loss: -5.6169	Cost: 11.56s
Train Epoch: 507 	Average Loss: -5.2001
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4007

Learning rate: 0.00018623369775573034
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 508 [0/90000 (0%)]	Loss: -1.8697	Cost: 30.54s
Train Epoch: 508 [20480/90000 (23%)]	Loss: -5.5769	Cost: 9.77s
Train Epoch: 508 [40960/90000 (45%)]	Loss: -5.9857	Cost: 11.20s
Train Epoch: 508 [61440/90000 (68%)]	Loss: -5.5511	Cost: 9.62s
Train Epoch: 508 [81920/90000 (91%)]	Loss: -5.6260	Cost: 10.73s
Train Epoch: 508 	Average Loss: -5.3900
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3995

Learning rate: 0.00018618062722547545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 509 [0/90000 (0%)]	Loss: -1.4960	Cost: 30.65s
Train Epoch: 509 [20480/90000 (23%)]	Loss: -5.6921	Cost: 9.74s
Train Epoch: 509 [40960/90000 (45%)]	Loss: -6.0057	Cost: 11.33s
Train Epoch: 509 [61440/90000 (68%)]	Loss: -5.5883	Cost: 9.67s
Train Epoch: 509 [81920/90000 (91%)]	Loss: -5.5084	Cost: 10.47s
Train Epoch: 509 	Average Loss: -5.3839
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3541

Learning rate: 0.00018612746218759613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 510 [0/90000 (0%)]	Loss: -1.8221	Cost: 32.44s
Train Epoch: 510 [20480/90000 (23%)]	Loss: -5.5248	Cost: 9.88s
Train Epoch: 510 [40960/90000 (45%)]	Loss: -6.0082	Cost: 10.59s
Train Epoch: 510 [61440/90000 (68%)]	Loss: -5.5241	Cost: 9.64s
Train Epoch: 510 [81920/90000 (91%)]	Loss: -5.5513	Cost: 10.58s
Train Epoch: 510 	Average Loss: -5.3525
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5547

Learning rate: 0.00018607420270039433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 511 [0/90000 (0%)]	Loss: -1.0805	Cost: 30.11s
Train Epoch: 511 [20480/90000 (23%)]	Loss: -5.8566	Cost: 9.99s
Train Epoch: 511 [40960/90000 (45%)]	Loss: -6.2760	Cost: 11.31s
Train Epoch: 511 [61440/90000 (68%)]	Loss: -5.6353	Cost: 9.93s
Train Epoch: 511 [81920/90000 (91%)]	Loss: -5.7611	Cost: 10.17s
Train Epoch: 511 	Average Loss: -5.4888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5885

Learning rate: 0.00018602084882227564
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 512 [0/90000 (0%)]	Loss: -1.4707	Cost: 31.99s
Train Epoch: 512 [20480/90000 (23%)]	Loss: -5.8213	Cost: 9.79s
Train Epoch: 512 [40960/90000 (45%)]	Loss: -6.1399	Cost: 11.23s
Train Epoch: 512 [61440/90000 (68%)]	Loss: -5.3879	Cost: 9.58s
Train Epoch: 512 [81920/90000 (91%)]	Loss: -5.2957	Cost: 10.99s
Train Epoch: 512 	Average Loss: -5.3462
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1181

Learning rate: 0.00018596740061174909
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 513 [0/90000 (0%)]	Loss: -1.3677	Cost: 31.82s
Train Epoch: 513 [20480/90000 (23%)]	Loss: -4.5784	Cost: 9.88s
Train Epoch: 513 [40960/90000 (45%)]	Loss: -4.9239	Cost: 10.84s
Train Epoch: 513 [61440/90000 (68%)]	Loss: -5.0570	Cost: 9.58s
Train Epoch: 513 [81920/90000 (91%)]	Loss: -5.2046	Cost: 10.59s
Train Epoch: 513 	Average Loss: -4.7014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1986

Learning rate: 0.00018591385812742722
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 514 [0/90000 (0%)]	Loss: -1.2440	Cost: 31.59s
Train Epoch: 514 [20480/90000 (23%)]	Loss: -5.6702	Cost: 9.80s
Train Epoch: 514 [40960/90000 (45%)]	Loss: -5.9946	Cost: 11.66s
Train Epoch: 514 [61440/90000 (68%)]	Loss: -5.2773	Cost: 9.75s
Train Epoch: 514 [81920/90000 (91%)]	Loss: -5.5751	Cost: 11.52s
Train Epoch: 514 	Average Loss: -5.2970
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4821

Learning rate: 0.00018586022142802594
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 515 [0/90000 (0%)]	Loss: -1.3199	Cost: 32.57s
Train Epoch: 515 [20480/90000 (23%)]	Loss: -5.7197	Cost: 9.80s
Train Epoch: 515 [40960/90000 (45%)]	Loss: -5.8432	Cost: 10.87s
Train Epoch: 515 [61440/90000 (68%)]	Loss: -5.6221	Cost: 9.60s
Train Epoch: 515 [81920/90000 (91%)]	Loss: -5.6864	Cost: 10.59s
Train Epoch: 515 	Average Loss: -5.4259
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5873

Learning rate: 0.00018580649057236445
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 516 [0/90000 (0%)]	Loss: -1.6946	Cost: 31.42s
Train Epoch: 516 [20480/90000 (23%)]	Loss: -5.8298	Cost: 9.91s
Train Epoch: 516 [40960/90000 (45%)]	Loss: -6.0267	Cost: 11.42s
Train Epoch: 516 [61440/90000 (68%)]	Loss: -5.8287	Cost: 9.60s
Train Epoch: 516 [81920/90000 (91%)]	Loss: -5.7405	Cost: 11.70s
Train Epoch: 516 	Average Loss: -5.5243
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6116

Learning rate: 0.0001857526656193652
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 517 [0/90000 (0%)]	Loss: -1.6739	Cost: 31.52s
Train Epoch: 517 [20480/90000 (23%)]	Loss: -5.9280	Cost: 9.76s
Train Epoch: 517 [40960/90000 (45%)]	Loss: -6.1908	Cost: 11.35s
Train Epoch: 517 [61440/90000 (68%)]	Loss: -5.9357	Cost: 9.54s
Train Epoch: 517 [81920/90000 (91%)]	Loss: -5.7363	Cost: 10.81s
Train Epoch: 517 	Average Loss: -5.6427
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6602

Learning rate: 0.00018569874662805388
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 518 [0/90000 (0%)]	Loss: -1.7355	Cost: 30.96s
Train Epoch: 518 [20480/90000 (23%)]	Loss: -5.7531	Cost: 9.86s
Train Epoch: 518 [40960/90000 (45%)]	Loss: -6.1461	Cost: 10.66s
Train Epoch: 518 [61440/90000 (68%)]	Loss: -5.9170	Cost: 9.60s
Train Epoch: 518 [81920/90000 (91%)]	Loss: -5.8615	Cost: 11.08s
Train Epoch: 518 	Average Loss: -5.6059
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6656

Learning rate: 0.0001856447336575593
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 519 [0/90000 (0%)]	Loss: -1.4928	Cost: 32.82s
Train Epoch: 519 [20480/90000 (23%)]	Loss: -5.9538	Cost: 9.67s
Train Epoch: 519 [40960/90000 (45%)]	Loss: -6.4866	Cost: 10.96s
Train Epoch: 519 [61440/90000 (68%)]	Loss: -5.9559	Cost: 9.58s
Train Epoch: 519 [81920/90000 (91%)]	Loss: -6.0901	Cost: 10.65s
Train Epoch: 519 	Average Loss: -5.7806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8968

Learning rate: 0.00018559062676711324
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 520 [0/90000 (0%)]	Loss: -1.6696	Cost: 30.44s
Train Epoch: 520 [20480/90000 (23%)]	Loss: -6.0561	Cost: 9.79s
Train Epoch: 520 [40960/90000 (45%)]	Loss: -6.2779	Cost: 11.32s
Train Epoch: 520 [61440/90000 (68%)]	Loss: -6.0660	Cost: 9.58s
Train Epoch: 520 [81920/90000 (91%)]	Loss: -6.1290	Cost: 11.27s
Train Epoch: 520 	Average Loss: -5.7963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7049

Learning rate: 0.00018553642601605062
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 521 [0/90000 (0%)]	Loss: -1.6646	Cost: 30.82s
Train Epoch: 521 [20480/90000 (23%)]	Loss: -6.1448	Cost: 9.52s
Train Epoch: 521 [40960/90000 (45%)]	Loss: -2.6051	Cost: 12.28s
Train Epoch: 521 [61440/90000 (68%)]	Loss: -0.8683	Cost: 9.45s
Train Epoch: 521 [81920/90000 (91%)]	Loss: -1.9428	Cost: 11.28s
Train Epoch: 521 	Average Loss: -2.7847
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1862

Learning rate: 0.00018548213146380916
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 522 [0/90000 (0%)]	Loss: 0.8969	Cost: 32.46s
Train Epoch: 522 [20480/90000 (23%)]	Loss: -3.1785	Cost: 9.67s
Train Epoch: 522 [40960/90000 (45%)]	Loss: -4.2090	Cost: 10.73s
Train Epoch: 522 [61440/90000 (68%)]	Loss: -4.3326	Cost: 9.51s
Train Epoch: 522 [81920/90000 (91%)]	Loss: -4.7918	Cost: 10.61s
Train Epoch: 522 	Average Loss: -3.6250
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7923

Learning rate: 0.00018542774316992948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 523 [0/90000 (0%)]	Loss: -0.6084	Cost: 33.06s
Train Epoch: 523 [20480/90000 (23%)]	Loss: -5.2515	Cost: 9.80s
Train Epoch: 523 [40960/90000 (45%)]	Loss: -5.4767	Cost: 11.05s
Train Epoch: 523 [61440/90000 (68%)]	Loss: -5.5481	Cost: 9.54s
Train Epoch: 523 [81920/90000 (91%)]	Loss: -5.5368	Cost: 11.02s
Train Epoch: 523 	Average Loss: -5.0847
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5379

Learning rate: 0.00018537326119405503
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 524 [0/90000 (0%)]	Loss: -1.4206	Cost: 30.51s
Train Epoch: 524 [20480/90000 (23%)]	Loss: -5.8229	Cost: 9.78s
Train Epoch: 524 [40960/90000 (45%)]	Loss: -6.0677	Cost: 11.37s
Train Epoch: 524 [61440/90000 (68%)]	Loss: -5.6363	Cost: 9.65s
Train Epoch: 524 [81920/90000 (91%)]	Loss: -5.6093	Cost: 10.88s
Train Epoch: 524 	Average Loss: -5.4738
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6456

Learning rate: 0.00018531868559593199
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 525 [0/90000 (0%)]	Loss: -1.5150	Cost: 30.40s
Train Epoch: 525 [20480/90000 (23%)]	Loss: -5.9411	Cost: 9.73s
Train Epoch: 525 [40960/90000 (45%)]	Loss: -6.2693	Cost: 11.34s
Train Epoch: 525 [61440/90000 (68%)]	Loss: -6.0102	Cost: 9.56s
Train Epoch: 525 [81920/90000 (91%)]	Loss: -5.9241	Cost: 10.35s
Train Epoch: 525 	Average Loss: -5.6589
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7933

Learning rate: 0.0001852640164354092
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 526 [0/90000 (0%)]	Loss: -1.8345	Cost: 31.81s
Train Epoch: 526 [20480/90000 (23%)]	Loss: -5.9552	Cost: 9.86s
Train Epoch: 526 [40960/90000 (45%)]	Loss: -6.2698	Cost: 10.53s
Train Epoch: 526 [61440/90000 (68%)]	Loss: -6.0148	Cost: 9.61s
Train Epoch: 526 [81920/90000 (91%)]	Loss: -6.0371	Cost: 10.93s
Train Epoch: 526 	Average Loss: -5.6756
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6762

Learning rate: 0.00018520925377243808
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 527 [0/90000 (0%)]	Loss: -1.4077	Cost: 30.65s
Train Epoch: 527 [20480/90000 (23%)]	Loss: -6.0718	Cost: 9.85s
Train Epoch: 527 [40960/90000 (45%)]	Loss: -6.4661	Cost: 11.36s
Train Epoch: 527 [61440/90000 (68%)]	Loss: -5.9229	Cost: 9.58s
Train Epoch: 527 [81920/90000 (91%)]	Loss: -5.7953	Cost: 10.88s
Train Epoch: 527 	Average Loss: -5.7414
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6976

Learning rate: 0.0001851543976670726
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 528 [0/90000 (0%)]	Loss: -1.4238	Cost: 32.43s
Train Epoch: 528 [20480/90000 (23%)]	Loss: -6.1584	Cost: 9.83s
Train Epoch: 528 [40960/90000 (45%)]	Loss: -6.3431	Cost: 10.63s
Train Epoch: 528 [61440/90000 (68%)]	Loss: -5.9269	Cost: 9.52s
Train Epoch: 528 [81920/90000 (91%)]	Loss: -6.0619	Cost: 11.01s
Train Epoch: 528 	Average Loss: -5.8187
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8605

Learning rate: 0.00018509944817946916
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 529 [0/90000 (0%)]	Loss: -2.2327	Cost: 30.26s
Train Epoch: 529 [20480/90000 (23%)]	Loss: -6.1882	Cost: 9.81s
Train Epoch: 529 [40960/90000 (45%)]	Loss: -6.5701	Cost: 11.79s
Train Epoch: 529 [61440/90000 (68%)]	Loss: -6.0220	Cost: 9.53s
Train Epoch: 529 [81920/90000 (91%)]	Loss: -6.0941	Cost: 11.29s
Train Epoch: 529 	Average Loss: -5.9103
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8680

Learning rate: 0.00018504440536988668
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 530 [0/90000 (0%)]	Loss: -1.4330	Cost: 32.57s
Train Epoch: 530 [20480/90000 (23%)]	Loss: -5.8259	Cost: 9.77s
Train Epoch: 530 [40960/90000 (45%)]	Loss: -5.9507	Cost: 10.74s
Train Epoch: 530 [61440/90000 (68%)]	Loss: -5.9440	Cost: 9.61s
Train Epoch: 530 [81920/90000 (91%)]	Loss: -5.9848	Cost: 10.59s
Train Epoch: 530 	Average Loss: -5.6087
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6979

Learning rate: 0.00018498926929868636
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 531 [0/90000 (0%)]	Loss: -1.3592	Cost: 30.33s
Train Epoch: 531 [20480/90000 (23%)]	Loss: -5.8236	Cost: 9.80s
Train Epoch: 531 [40960/90000 (45%)]	Loss: -5.9740	Cost: 12.02s
Train Epoch: 531 [61440/90000 (68%)]	Loss: -5.7088	Cost: 9.61s
Train Epoch: 531 [81920/90000 (91%)]	Loss: -5.7370	Cost: 12.10s
Train Epoch: 531 	Average Loss: -5.4734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6094

Learning rate: 0.00018493404002633163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 532 [0/90000 (0%)]	Loss: -1.7342	Cost: 32.64s
Train Epoch: 532 [20480/90000 (23%)]	Loss: -5.6848	Cost: 9.71s
Train Epoch: 532 [40960/90000 (45%)]	Loss: -6.1006	Cost: 10.84s
Train Epoch: 532 [61440/90000 (68%)]	Loss: -5.6151	Cost: 9.62s
Train Epoch: 532 [81920/90000 (91%)]	Loss: -5.7742	Cost: 10.97s
Train Epoch: 532 	Average Loss: -5.5083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5869

Learning rate: 0.00018487871761338817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 533 [0/90000 (0%)]	Loss: -1.7227	Cost: 33.47s
Train Epoch: 533 [20480/90000 (23%)]	Loss: -6.1340	Cost: 9.73s
Train Epoch: 533 [40960/90000 (45%)]	Loss: -6.3247	Cost: 11.57s
Train Epoch: 533 [61440/90000 (68%)]	Loss: -6.0996	Cost: 9.53s
Train Epoch: 533 [81920/90000 (91%)]	Loss: -6.0427	Cost: 10.46s
Train Epoch: 533 	Average Loss: -5.7847
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9265

Learning rate: 0.00018482330212052378
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 534 [0/90000 (0%)]	Loss: -1.8636	Cost: 33.43s
Train Epoch: 534 [20480/90000 (23%)]	Loss: -6.1580	Cost: 9.76s
Train Epoch: 534 [40960/90000 (45%)]	Loss: -6.6209	Cost: 10.69s
Train Epoch: 534 [61440/90000 (68%)]	Loss: -5.7362	Cost: 9.49s
Train Epoch: 534 [81920/90000 (91%)]	Loss: -5.6415	Cost: 11.06s
Train Epoch: 534 	Average Loss: -5.7630
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4608

Learning rate: 0.00018476779360850832
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 535 [0/90000 (0%)]	Loss: -2.0104	Cost: 32.70s
Train Epoch: 535 [20480/90000 (23%)]	Loss: -6.0617	Cost: 9.77s
Train Epoch: 535 [40960/90000 (45%)]	Loss: -6.3085	Cost: 10.97s
Train Epoch: 535 [61440/90000 (68%)]	Loss: -6.1640	Cost: 9.52s
Train Epoch: 535 [81920/90000 (91%)]	Loss: -6.0555	Cost: 11.15s
Train Epoch: 535 	Average Loss: -5.7844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8192

Learning rate: 0.00018471219213821372
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 536 [0/90000 (0%)]	Loss: -2.2468	Cost: 32.72s
Train Epoch: 536 [20480/90000 (23%)]	Loss: -6.2356	Cost: 9.85s
Train Epoch: 536 [40960/90000 (45%)]	Loss: -6.5902	Cost: 10.94s
Train Epoch: 536 [61440/90000 (68%)]	Loss: -6.3399	Cost: 9.57s
Train Epoch: 536 [81920/90000 (91%)]	Loss: -6.3032	Cost: 10.97s
Train Epoch: 536 	Average Loss: -6.0355
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9498

Learning rate: 0.00018465649777061377
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 537 [0/90000 (0%)]	Loss: -2.3126	Cost: 31.77s
Train Epoch: 537 [20480/90000 (23%)]	Loss: -6.2510	Cost: 9.91s
Train Epoch: 537 [40960/90000 (45%)]	Loss: -6.5567	Cost: 11.16s
Train Epoch: 537 [61440/90000 (68%)]	Loss: -6.2589	Cost: 9.54s
Train Epoch: 537 [81920/90000 (91%)]	Loss: -6.4695	Cost: 10.86s
Train Epoch: 537 	Average Loss: -6.1058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1461

Learning rate: 0.00018460071056678422
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 538 [0/90000 (0%)]	Loss: -1.8738	Cost: 31.87s
Train Epoch: 538 [20480/90000 (23%)]	Loss: -6.3897	Cost: 9.72s
Train Epoch: 538 [40960/90000 (45%)]	Loss: -6.8151	Cost: 12.50s
Train Epoch: 538 [61440/90000 (68%)]	Loss: -6.3889	Cost: 9.56s
Train Epoch: 538 [81920/90000 (91%)]	Loss: -6.4640	Cost: 11.94s
Train Epoch: 538 	Average Loss: -6.1691
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2412

Learning rate: 0.00018454483058790255
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 539 [0/90000 (0%)]	Loss: -2.4455	Cost: 31.75s
Train Epoch: 539 [20480/90000 (23%)]	Loss: -6.6041	Cost: 9.82s
Train Epoch: 539 [40960/90000 (45%)]	Loss: -6.6786	Cost: 11.43s
Train Epoch: 539 [61440/90000 (68%)]	Loss: -6.3989	Cost: 9.62s
Train Epoch: 539 [81920/90000 (91%)]	Loss: -6.4179	Cost: 11.03s
Train Epoch: 539 	Average Loss: -6.2234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1561

Learning rate: 0.000184488857895248
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 540 [0/90000 (0%)]	Loss: -2.4069	Cost: 30.16s
Train Epoch: 540 [20480/90000 (23%)]	Loss: -6.4459	Cost: 9.77s
Train Epoch: 540 [40960/90000 (45%)]	Loss: -6.8847	Cost: 11.13s
Train Epoch: 540 [61440/90000 (68%)]	Loss: -5.9035	Cost: 9.62s
Train Epoch: 540 [81920/90000 (91%)]	Loss: -6.0256	Cost: 11.16s
Train Epoch: 540 	Average Loss: -6.0730
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8227

Learning rate: 0.0001844327925502015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 541 [0/90000 (0%)]	Loss: -1.6210	Cost: 30.32s
Train Epoch: 541 [20480/90000 (23%)]	Loss: -6.4578	Cost: 9.85s
Train Epoch: 541 [40960/90000 (45%)]	Loss: -6.8826	Cost: 11.84s
Train Epoch: 541 [61440/90000 (68%)]	Loss: -6.5670	Cost: 9.58s
Train Epoch: 541 [81920/90000 (91%)]	Loss: -6.5164	Cost: 11.33s
Train Epoch: 541 	Average Loss: -6.1573
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0297

Learning rate: 0.00018437663461424558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 542 [0/90000 (0%)]	Loss: -1.9767	Cost: 31.67s
Train Epoch: 542 [20480/90000 (23%)]	Loss: -6.5847	Cost: 9.83s
Train Epoch: 542 [40960/90000 (45%)]	Loss: -6.7202	Cost: 11.00s
Train Epoch: 542 [61440/90000 (68%)]	Loss: -6.2663	Cost: 9.61s
Train Epoch: 542 [81920/90000 (91%)]	Loss: -6.2871	Cost: 11.20s
Train Epoch: 542 	Average Loss: -6.1605
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9551

Learning rate: 0.00018432038414896432
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 543 [0/90000 (0%)]	Loss: -1.6734	Cost: 32.27s
Train Epoch: 543 [20480/90000 (23%)]	Loss: -6.4635	Cost: 9.76s
Train Epoch: 543 [40960/90000 (45%)]	Loss: -6.7630	Cost: 10.97s
Train Epoch: 543 [61440/90000 (68%)]	Loss: -6.5731	Cost: 9.78s
Train Epoch: 543 [81920/90000 (91%)]	Loss: -6.4716	Cost: 10.47s
Train Epoch: 543 	Average Loss: -6.1799
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2162

Learning rate: 0.00018426404121604323
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 544 [0/90000 (0%)]	Loss: -2.0598	Cost: 30.38s
Train Epoch: 544 [20480/90000 (23%)]	Loss: -6.7180	Cost: 9.94s
Train Epoch: 544 [40960/90000 (45%)]	Loss: -6.9143	Cost: 11.19s
Train Epoch: 544 [61440/90000 (68%)]	Loss: -6.5254	Cost: 9.61s
Train Epoch: 544 [81920/90000 (91%)]	Loss: -6.4558	Cost: 11.05s
Train Epoch: 544 	Average Loss: -6.3104
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1318

Learning rate: 0.00018420760587726923
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 545 [0/90000 (0%)]	Loss: -1.9813	Cost: 32.91s
Train Epoch: 545 [20480/90000 (23%)]	Loss: -6.4237	Cost: 9.67s
Train Epoch: 545 [40960/90000 (45%)]	Loss: -6.8415	Cost: 11.60s
Train Epoch: 545 [61440/90000 (68%)]	Loss: -6.5983	Cost: 10.13s
Train Epoch: 545 [81920/90000 (91%)]	Loss: -6.5585	Cost: 9.81s
Train Epoch: 545 	Average Loss: -6.2646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0629

Learning rate: 0.00018415107819453062
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 546 [0/90000 (0%)]	Loss: -1.9857	Cost: 30.60s
Train Epoch: 546 [20480/90000 (23%)]	Loss: -6.6820	Cost: 9.87s
Train Epoch: 546 [40960/90000 (45%)]	Loss: -7.0186	Cost: 11.15s
Train Epoch: 546 [61440/90000 (68%)]	Loss: -6.6878	Cost: 9.54s
Train Epoch: 546 [81920/90000 (91%)]	Loss: -6.6212	Cost: 11.07s
Train Epoch: 546 	Average Loss: -6.3939
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3563

Learning rate: 0.00018409445822981693
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 547 [0/90000 (0%)]	Loss: -2.8585	Cost: 31.84s
Train Epoch: 547 [20480/90000 (23%)]	Loss: -6.2106	Cost: 9.86s
Train Epoch: 547 [40960/90000 (45%)]	Loss: -6.7271	Cost: 11.20s
Train Epoch: 547 [61440/90000 (68%)]	Loss: -6.5849	Cost: 10.23s
Train Epoch: 547 [81920/90000 (91%)]	Loss: -6.5886	Cost: 9.77s
Train Epoch: 547 	Average Loss: -6.1471
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0866

Learning rate: 0.00018403774604521886
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 548 [0/90000 (0%)]	Loss: -2.2777	Cost: 31.34s
Train Epoch: 548 [20480/90000 (23%)]	Loss: -6.7923	Cost: 9.78s
Train Epoch: 548 [40960/90000 (45%)]	Loss: -7.1302	Cost: 12.20s
Train Epoch: 548 [61440/90000 (68%)]	Loss: -6.5713	Cost: 9.61s
Train Epoch: 548 [81920/90000 (91%)]	Loss: -6.6182	Cost: 11.87s
Train Epoch: 548 	Average Loss: -6.3860
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2815

Learning rate: 0.0001839809417029283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 549 [0/90000 (0%)]	Loss: -2.1069	Cost: 30.91s
Train Epoch: 549 [20480/90000 (23%)]	Loss: -6.7076	Cost: 9.72s
Train Epoch: 549 [40960/90000 (45%)]	Loss: -7.0109	Cost: 12.43s
Train Epoch: 549 [61440/90000 (68%)]	Loss: -6.6403	Cost: 9.54s
Train Epoch: 549 [81920/90000 (91%)]	Loss: -6.6459	Cost: 11.76s
Train Epoch: 549 	Average Loss: -6.4430
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3371

Learning rate: 0.00018392404526523817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 550 [0/90000 (0%)]	Loss: -2.4200	Cost: 30.36s
Train Epoch: 550 [20480/90000 (23%)]	Loss: -6.7196	Cost: 9.91s
Train Epoch: 550 [40960/90000 (45%)]	Loss: -6.9500	Cost: 11.07s
Train Epoch: 550 [61440/90000 (68%)]	Loss: -6.2128	Cost: 9.58s
Train Epoch: 550 [81920/90000 (91%)]	Loss: -6.4691	Cost: 11.11s
Train Epoch: 550 	Average Loss: -6.2565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1158

Saving model as model.pt_e550 & waveforms_supplementary.hdf5_e550
Learning rate: 0.00018386705679454242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 551 [0/90000 (0%)]	Loss: -2.3022	Cost: 31.02s
Train Epoch: 551 [20480/90000 (23%)]	Loss: -6.6936	Cost: 9.79s
Train Epoch: 551 [40960/90000 (45%)]	Loss: -6.9558	Cost: 12.13s
Train Epoch: 551 [61440/90000 (68%)]	Loss: -6.6502	Cost: 9.57s
Train Epoch: 551 [81920/90000 (91%)]	Loss: -6.8286	Cost: 11.87s
Train Epoch: 551 	Average Loss: -6.4226
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3222

Learning rate: 0.00018380997635333585
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 552 [0/90000 (0%)]	Loss: -2.4023	Cost: 33.11s
Train Epoch: 552 [20480/90000 (23%)]	Loss: -6.8548	Cost: 9.76s
Train Epoch: 552 [40960/90000 (45%)]	Loss: -7.1957	Cost: 12.13s
Train Epoch: 552 [61440/90000 (68%)]	Loss: -6.9078	Cost: 9.51s
Train Epoch: 552 [81920/90000 (91%)]	Loss: -6.9700	Cost: 12.25s
Train Epoch: 552 	Average Loss: -6.6080
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4097

Learning rate: 0.0001837528040042142
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 553 [0/90000 (0%)]	Loss: -2.7456	Cost: 30.40s
Train Epoch: 553 [20480/90000 (23%)]	Loss: -7.0245	Cost: 10.02s
Train Epoch: 553 [40960/90000 (45%)]	Loss: -7.2078	Cost: 11.26s
Train Epoch: 553 [61440/90000 (68%)]	Loss: -6.9234	Cost: 9.59s
Train Epoch: 553 [81920/90000 (91%)]	Loss: -6.8364	Cost: 12.06s
Train Epoch: 553 	Average Loss: -6.6299
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4367

Learning rate: 0.0001836955398098739
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 554 [0/90000 (0%)]	Loss: -2.5670	Cost: 30.65s
Train Epoch: 554 [20480/90000 (23%)]	Loss: -6.9232	Cost: 9.64s
Train Epoch: 554 [40960/90000 (45%)]	Loss: -7.0567	Cost: 12.68s
Train Epoch: 554 [61440/90000 (68%)]	Loss: -6.7338	Cost: 9.58s
Train Epoch: 554 [81920/90000 (91%)]	Loss: -6.9381	Cost: 11.43s
Train Epoch: 554 	Average Loss: -6.5704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4019

Learning rate: 0.00018363818383311225
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 555 [0/90000 (0%)]	Loss: -2.6680	Cost: 33.23s
Train Epoch: 555 [20480/90000 (23%)]	Loss: -6.8871	Cost: 9.83s
Train Epoch: 555 [40960/90000 (45%)]	Loss: -7.1603	Cost: 11.11s
Train Epoch: 555 [61440/90000 (68%)]	Loss: -6.8682	Cost: 9.54s
Train Epoch: 555 [81920/90000 (91%)]	Loss: -6.8292	Cost: 10.73s
Train Epoch: 555 	Average Loss: -6.5910
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4738

Learning rate: 0.00018358073613682706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 556 [0/90000 (0%)]	Loss: -2.7704	Cost: 30.90s
Train Epoch: 556 [20480/90000 (23%)]	Loss: -7.0953	Cost: 9.84s
Train Epoch: 556 [40960/90000 (45%)]	Loss: -7.3964	Cost: 12.07s
Train Epoch: 556 [61440/90000 (68%)]	Loss: -6.9237	Cost: 9.71s
Train Epoch: 556 [81920/90000 (91%)]	Loss: -6.8778	Cost: 11.36s
Train Epoch: 556 	Average Loss: -6.7419
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6070

Learning rate: 0.00018352319678401676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 557 [0/90000 (0%)]	Loss: -3.2063	Cost: 30.54s
Train Epoch: 557 [20480/90000 (23%)]	Loss: -7.0653	Cost: 9.72s
Train Epoch: 557 [40960/90000 (45%)]	Loss: -7.4245	Cost: 11.84s
Train Epoch: 557 [61440/90000 (68%)]	Loss: -6.7817	Cost: 9.93s
Train Epoch: 557 [81920/90000 (91%)]	Loss: -6.8123	Cost: 11.29s
Train Epoch: 557 	Average Loss: -6.6773
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3863

Learning rate: 0.00018346556583778034
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 558 [0/90000 (0%)]	Loss: -2.2802	Cost: 31.96s
Train Epoch: 558 [20480/90000 (23%)]	Loss: -7.0912	Cost: 9.79s
Train Epoch: 558 [40960/90000 (45%)]	Loss: -7.1447	Cost: 11.21s
Train Epoch: 558 [61440/90000 (68%)]	Loss: -6.9526	Cost: 9.63s
Train Epoch: 558 [81920/90000 (91%)]	Loss: -6.9006	Cost: 10.92s
Train Epoch: 558 	Average Loss: -6.6664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5544

Learning rate: 0.00018340784336131716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 559 [0/90000 (0%)]	Loss: -2.4281	Cost: 32.90s
Train Epoch: 559 [20480/90000 (23%)]	Loss: -7.0496	Cost: 9.74s
Train Epoch: 559 [40960/90000 (45%)]	Loss: -7.4025	Cost: 11.20s
Train Epoch: 559 [61440/90000 (68%)]	Loss: -6.8229	Cost: 9.74s
Train Epoch: 559 [81920/90000 (91%)]	Loss: -7.0091	Cost: 11.01s
Train Epoch: 559 	Average Loss: -6.7470
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4343

Learning rate: 0.000183350029417927
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 560 [0/90000 (0%)]	Loss: -3.0583	Cost: 32.21s
Train Epoch: 560 [20480/90000 (23%)]	Loss: -7.0640	Cost: 9.82s
Train Epoch: 560 [40960/90000 (45%)]	Loss: -7.1716	Cost: 11.07s
Train Epoch: 560 [61440/90000 (68%)]	Loss: -6.9829	Cost: 9.58s
Train Epoch: 560 [81920/90000 (91%)]	Loss: -6.9898	Cost: 10.91s
Train Epoch: 560 	Average Loss: -6.7030
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6025

Learning rate: 0.00018329212407101
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 561 [0/90000 (0%)]	Loss: -2.6773	Cost: 30.65s
Train Epoch: 561 [20480/90000 (23%)]	Loss: -7.1495	Cost: 9.74s
Train Epoch: 561 [40960/90000 (45%)]	Loss: -7.2728	Cost: 12.01s
Train Epoch: 561 [61440/90000 (68%)]	Loss: -6.8115	Cost: 9.55s
Train Epoch: 561 [81920/90000 (91%)]	Loss: -6.7054	Cost: 12.02s
Train Epoch: 561 	Average Loss: -6.6750
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4082

Learning rate: 0.00018323412738406638
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 562 [0/90000 (0%)]	Loss: -2.6663	Cost: 31.54s
Train Epoch: 562 [20480/90000 (23%)]	Loss: -6.9000	Cost: 9.83s
Train Epoch: 562 [40960/90000 (45%)]	Loss: -7.1249	Cost: 10.99s
Train Epoch: 562 [61440/90000 (68%)]	Loss: -6.5318	Cost: 9.55s
Train Epoch: 562 [81920/90000 (91%)]	Loss: -6.5306	Cost: 11.05s
Train Epoch: 562 	Average Loss: -6.5064
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3908

Learning rate: 0.0001831760394206967
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 563 [0/90000 (0%)]	Loss: -2.2670	Cost: 32.92s
Train Epoch: 563 [20480/90000 (23%)]	Loss: -6.9175	Cost: 9.63s
Train Epoch: 563 [40960/90000 (45%)]	Loss: -7.1589	Cost: 11.11s
Train Epoch: 563 [61440/90000 (68%)]	Loss: -6.9532	Cost: 9.54s
Train Epoch: 563 [81920/90000 (91%)]	Loss: -6.9834	Cost: 10.58s
Train Epoch: 563 	Average Loss: -6.6291
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5466

Learning rate: 0.00018311786024460147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 564 [0/90000 (0%)]	Loss: -2.7722	Cost: 30.37s
Train Epoch: 564 [20480/90000 (23%)]	Loss: -7.1520	Cost: 9.80s
Train Epoch: 564 [40960/90000 (45%)]	Loss: -7.4991	Cost: 11.13s
Train Epoch: 564 [61440/90000 (68%)]	Loss: -6.8759	Cost: 9.64s
Train Epoch: 564 [81920/90000 (91%)]	Loss: -7.1308	Cost: 10.92s
Train Epoch: 564 	Average Loss: -6.8070
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5945

Learning rate: 0.00018305958991958132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 565 [0/90000 (0%)]	Loss: -2.5594	Cost: 34.05s
Train Epoch: 565 [20480/90000 (23%)]	Loss: -7.2631	Cost: 9.89s
Train Epoch: 565 [40960/90000 (45%)]	Loss: -7.4623	Cost: 10.90s
Train Epoch: 565 [61440/90000 (68%)]	Loss: -7.2803	Cost: 9.56s
Train Epoch: 565 [81920/90000 (91%)]	Loss: -6.5199	Cost: 11.08s
Train Epoch: 565 	Average Loss: -6.7943
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1791

Learning rate: 0.0001830012285095368
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 566 [0/90000 (0%)]	Loss: -2.3542	Cost: 31.28s
Train Epoch: 566 [20480/90000 (23%)]	Loss: -6.4777	Cost: 9.84s
Train Epoch: 566 [40960/90000 (45%)]	Loss: -7.0740	Cost: 12.04s
Train Epoch: 566 [61440/90000 (68%)]	Loss: -6.9102	Cost: 9.50s
Train Epoch: 566 [81920/90000 (91%)]	Loss: -7.2549	Cost: 11.69s
Train Epoch: 566 	Average Loss: -6.5468
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7570

Learning rate: 0.00018294277607846837
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 567 [0/90000 (0%)]	Loss: -2.2626	Cost: 30.34s
Train Epoch: 567 [20480/90000 (23%)]	Loss: -7.2978	Cost: 9.67s
Train Epoch: 567 [40960/90000 (45%)]	Loss: -7.3531	Cost: 11.96s
Train Epoch: 567 [61440/90000 (68%)]	Loss: -7.2783	Cost: 9.57s
Train Epoch: 567 [81920/90000 (91%)]	Loss: -7.3436	Cost: 11.67s
Train Epoch: 567 	Average Loss: -6.9405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7016

Learning rate: 0.00018288423269047623
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 568 [0/90000 (0%)]	Loss: -2.3833	Cost: 32.20s
Train Epoch: 568 [20480/90000 (23%)]	Loss: -7.3350	Cost: 9.75s
Train Epoch: 568 [40960/90000 (45%)]	Loss: -7.6528	Cost: 10.83s
Train Epoch: 568 [61440/90000 (68%)]	Loss: -7.1691	Cost: 9.61s
Train Epoch: 568 [81920/90000 (91%)]	Loss: -7.0710	Cost: 11.06s
Train Epoch: 568 	Average Loss: -6.9892
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6254

Learning rate: 0.00018282559840976048
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 569 [0/90000 (0%)]	Loss: -2.7968	Cost: 31.98s
Train Epoch: 569 [20480/90000 (23%)]	Loss: -7.0559	Cost: 9.74s
Train Epoch: 569 [40960/90000 (45%)]	Loss: -7.5400	Cost: 11.76s
Train Epoch: 569 [61440/90000 (68%)]	Loss: -7.3068	Cost: 9.49s
Train Epoch: 569 [81920/90000 (91%)]	Loss: -7.1941	Cost: 11.36s
Train Epoch: 569 	Average Loss: -6.9182
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7269

Learning rate: 0.0001827668733006207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 570 [0/90000 (0%)]	Loss: -2.6921	Cost: 31.28s
Train Epoch: 570 [20480/90000 (23%)]	Loss: -7.3867	Cost: 9.82s
Train Epoch: 570 [40960/90000 (45%)]	Loss: -7.5062	Cost: 10.91s
Train Epoch: 570 [61440/90000 (68%)]	Loss: -7.0620	Cost: 9.59s
Train Epoch: 570 [81920/90000 (91%)]	Loss: -7.1750	Cost: 10.90s
Train Epoch: 570 	Average Loss: -6.9346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7474

Learning rate: 0.00018270805742745622
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 571 [0/90000 (0%)]	Loss: -2.8279	Cost: 31.30s
Train Epoch: 571 [20480/90000 (23%)]	Loss: -7.3232	Cost: 9.82s
Train Epoch: 571 [40960/90000 (45%)]	Loss: -7.6282	Cost: 11.42s
Train Epoch: 571 [61440/90000 (68%)]	Loss: -7.2890	Cost: 9.55s
Train Epoch: 571 [81920/90000 (91%)]	Loss: -7.5643	Cost: 11.13s
Train Epoch: 571 	Average Loss: -7.0782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8451

Learning rate: 0.0001826491508547659
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 572 [0/90000 (0%)]	Loss: -2.8288	Cost: 32.30s
Train Epoch: 572 [20480/90000 (23%)]	Loss: -7.5184	Cost: 9.78s
Train Epoch: 572 [40960/90000 (45%)]	Loss: -7.7522	Cost: 10.79s
Train Epoch: 572 [61440/90000 (68%)]	Loss: -7.3946	Cost: 9.55s
Train Epoch: 572 [81920/90000 (91%)]	Loss: -7.1331	Cost: 10.95s
Train Epoch: 572 	Average Loss: -7.1330
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7498

Learning rate: 0.00018259015364714793
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 573 [0/90000 (0%)]	Loss: -3.1996	Cost: 32.11s
Train Epoch: 573 [20480/90000 (23%)]	Loss: -7.3986	Cost: 9.74s
Train Epoch: 573 [40960/90000 (45%)]	Loss: -7.6159	Cost: 11.25s
Train Epoch: 573 [61440/90000 (68%)]	Loss: -7.4578	Cost: 10.27s
Train Epoch: 573 [81920/90000 (91%)]	Loss: -7.2374	Cost: 10.10s
Train Epoch: 573 	Average Loss: -7.0884
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7503

Learning rate: 0.00018253106586930005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 574 [0/90000 (0%)]	Loss: -3.1964	Cost: 32.46s
Train Epoch: 574 [20480/90000 (23%)]	Loss: -7.5695	Cost: 9.80s
Train Epoch: 574 [40960/90000 (45%)]	Loss: -7.7019	Cost: 11.02s
Train Epoch: 574 [61440/90000 (68%)]	Loss: -7.2929	Cost: 9.67s
Train Epoch: 574 [81920/90000 (91%)]	Loss: -7.3204	Cost: 10.84s
Train Epoch: 574 	Average Loss: -7.0996
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7969

Learning rate: 0.0001824718875860192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 575 [0/90000 (0%)]	Loss: -2.5568	Cost: 31.89s
Train Epoch: 575 [20480/90000 (23%)]	Loss: -7.4743	Cost: 9.82s
Train Epoch: 575 [40960/90000 (45%)]	Loss: -7.5918	Cost: 11.73s
Train Epoch: 575 [61440/90000 (68%)]	Loss: -7.4201	Cost: 9.59s
Train Epoch: 575 [81920/90000 (91%)]	Loss: -7.4434	Cost: 11.31s
Train Epoch: 575 	Average Loss: -7.1294
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0816

Learning rate: 0.00018241261886220165
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 576 [0/90000 (0%)]	Loss: -3.3753	Cost: 32.62s
Train Epoch: 576 [20480/90000 (23%)]	Loss: -7.6662	Cost: 9.80s
Train Epoch: 576 [40960/90000 (45%)]	Loss: -7.8910	Cost: 10.72s
Train Epoch: 576 [61440/90000 (68%)]	Loss: -7.5091	Cost: 9.60s
Train Epoch: 576 [81920/90000 (91%)]	Loss: -7.3194	Cost: 11.06s
Train Epoch: 576 	Average Loss: -7.2392
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8709

Learning rate: 0.0001823532597628428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 577 [0/90000 (0%)]	Loss: -2.3660	Cost: 31.18s
Train Epoch: 577 [20480/90000 (23%)]	Loss: -7.3805	Cost: 9.78s
Train Epoch: 577 [40960/90000 (45%)]	Loss: -7.6119	Cost: 11.35s
Train Epoch: 577 [61440/90000 (68%)]	Loss: -7.1946	Cost: 9.53s
Train Epoch: 577 [81920/90000 (91%)]	Loss: -7.2766	Cost: 10.78s
Train Epoch: 577 	Average Loss: -7.0272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8384

Learning rate: 0.00018229381035303723
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 578 [0/90000 (0%)]	Loss: -2.7926	Cost: 32.75s
Train Epoch: 578 [20480/90000 (23%)]	Loss: -7.3711	Cost: 9.79s
Train Epoch: 578 [40960/90000 (45%)]	Loss: -7.8579	Cost: 10.72s
Train Epoch: 578 [61440/90000 (68%)]	Loss: -7.5976	Cost: 9.58s
Train Epoch: 578 [81920/90000 (91%)]	Loss: -7.4870	Cost: 11.02s
Train Epoch: 578 	Average Loss: -7.2160
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1153

Learning rate: 0.00018223427069797852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 579 [0/90000 (0%)]	Loss: -3.4878	Cost: 32.19s
Train Epoch: 579 [20480/90000 (23%)]	Loss: -7.7932	Cost: 9.83s
Train Epoch: 579 [40960/90000 (45%)]	Loss: -7.8063	Cost: 11.20s
Train Epoch: 579 [61440/90000 (68%)]	Loss: -7.3932	Cost: 9.57s
Train Epoch: 579 [81920/90000 (91%)]	Loss: -7.5195	Cost: 10.78s
Train Epoch: 579 	Average Loss: -7.3010
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9158

Learning rate: 0.00018217464086295912
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 580 [0/90000 (0%)]	Loss: -2.9266	Cost: 32.86s
Train Epoch: 580 [20480/90000 (23%)]	Loss: -7.5534	Cost: 9.74s
Train Epoch: 580 [40960/90000 (45%)]	Loss: -7.6629	Cost: 10.68s
Train Epoch: 580 [61440/90000 (68%)]	Loss: -7.5004	Cost: 9.64s
Train Epoch: 580 [81920/90000 (91%)]	Loss: -7.5254	Cost: 10.64s
Train Epoch: 580 	Average Loss: -7.2239
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0114

Learning rate: 0.0001821149209133705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 581 [0/90000 (0%)]	Loss: -3.5721	Cost: 31.01s
Train Epoch: 581 [20480/90000 (23%)]	Loss: -7.6821	Cost: 9.81s
Train Epoch: 581 [40960/90000 (45%)]	Loss: -8.1125	Cost: 11.20s
Train Epoch: 581 [61440/90000 (68%)]	Loss: -7.5375	Cost: 9.52s
Train Epoch: 581 [81920/90000 (91%)]	Loss: -7.4404	Cost: 10.71s
Train Epoch: 581 	Average Loss: -7.3528
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9914

Learning rate: 0.0001820551109147029
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 582 [0/90000 (0%)]	Loss: -2.8438	Cost: 32.45s
Train Epoch: 582 [20480/90000 (23%)]	Loss: -7.5288	Cost: 9.73s
Train Epoch: 582 [40960/90000 (45%)]	Loss: -7.8987	Cost: 10.98s
Train Epoch: 582 [61440/90000 (68%)]	Loss: -7.4658	Cost: 9.61s
Train Epoch: 582 [81920/90000 (91%)]	Loss: -7.4501	Cost: 11.17s
Train Epoch: 582 	Average Loss: -7.2243
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8481

Learning rate: 0.00018199521093254534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 583 [0/90000 (0%)]	Loss: -2.4546	Cost: 31.29s
Train Epoch: 583 [20480/90000 (23%)]	Loss: -7.5275	Cost: 9.82s
Train Epoch: 583 [40960/90000 (45%)]	Loss: -7.9059	Cost: 11.59s
Train Epoch: 583 [61440/90000 (68%)]	Loss: -7.7198	Cost: 9.52s
Train Epoch: 583 [81920/90000 (91%)]	Loss: -7.7470	Cost: 11.60s
Train Epoch: 583 	Average Loss: -7.3207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9950

Learning rate: 0.00018193522103258545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 584 [0/90000 (0%)]	Loss: -3.2446	Cost: 30.62s
Train Epoch: 584 [20480/90000 (23%)]	Loss: -7.1835	Cost: 9.84s
Train Epoch: 584 [40960/90000 (45%)]	Loss: -7.3456	Cost: 11.64s
Train Epoch: 584 [61440/90000 (68%)]	Loss: -6.9378	Cost: 9.75s
Train Epoch: 584 [81920/90000 (91%)]	Loss: -7.2738	Cost: 11.90s
Train Epoch: 584 	Average Loss: -6.8191
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7438

Learning rate: 0.00018187514128060954
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 585 [0/90000 (0%)]	Loss: -2.5588	Cost: 32.66s
Train Epoch: 585 [20480/90000 (23%)]	Loss: -7.2074	Cost: 9.70s
Train Epoch: 585 [40960/90000 (45%)]	Loss: -7.7689	Cost: 10.91s
Train Epoch: 585 [61440/90000 (68%)]	Loss: -7.3724	Cost: 9.62s
Train Epoch: 585 [81920/90000 (91%)]	Loss: -7.3459	Cost: 10.37s
Train Epoch: 585 	Average Loss: -7.1060
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9002

Learning rate: 0.00018181497174250244
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 586 [0/90000 (0%)]	Loss: -2.5933	Cost: 30.81s
Train Epoch: 586 [20480/90000 (23%)]	Loss: -7.3928	Cost: 9.89s
Train Epoch: 586 [40960/90000 (45%)]	Loss: -7.7131	Cost: 11.09s
Train Epoch: 586 [61440/90000 (68%)]	Loss: -7.2954	Cost: 9.50s
Train Epoch: 586 [81920/90000 (91%)]	Loss: -7.4417	Cost: 11.26s
Train Epoch: 586 	Average Loss: -7.0934
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9539

Learning rate: 0.00018175471248424742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 587 [0/90000 (0%)]	Loss: -3.1838	Cost: 30.56s
Train Epoch: 587 [20480/90000 (23%)]	Loss: -7.4327	Cost: 9.77s
Train Epoch: 587 [40960/90000 (45%)]	Loss: -8.0323	Cost: 11.87s
Train Epoch: 587 [61440/90000 (68%)]	Loss: -7.6212	Cost: 9.64s
Train Epoch: 587 [81920/90000 (91%)]	Loss: -7.6837	Cost: 11.20s
Train Epoch: 587 	Average Loss: -7.3268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1902

Learning rate: 0.0001816943635719261
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 588 [0/90000 (0%)]	Loss: -3.1050	Cost: 33.07s
Train Epoch: 588 [20480/90000 (23%)]	Loss: -7.7249	Cost: 9.73s
Train Epoch: 588 [40960/90000 (45%)]	Loss: -8.0990	Cost: 10.72s
Train Epoch: 588 [61440/90000 (68%)]	Loss: -7.6513	Cost: 9.54s
Train Epoch: 588 [81920/90000 (91%)]	Loss: -7.3386	Cost: 10.81s
Train Epoch: 588 	Average Loss: -7.4180
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0882

Learning rate: 0.0001816339250717185
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 589 [0/90000 (0%)]	Loss: -2.9039	Cost: 32.87s
Train Epoch: 589 [20480/90000 (23%)]	Loss: -7.5851	Cost: 9.79s
Train Epoch: 589 [40960/90000 (45%)]	Loss: -7.8532	Cost: 10.68s
Train Epoch: 589 [61440/90000 (68%)]	Loss: -7.7967	Cost: 9.54s
Train Epoch: 589 [81920/90000 (91%)]	Loss: -7.7196	Cost: 10.75s
Train Epoch: 589 	Average Loss: -7.3609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0940

Learning rate: 0.00018157339704990283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 590 [0/90000 (0%)]	Loss: -3.5839	Cost: 31.93s
Train Epoch: 590 [20480/90000 (23%)]	Loss: -7.7818	Cost: 9.85s
Train Epoch: 590 [40960/90000 (45%)]	Loss: -8.0042	Cost: 10.69s
Train Epoch: 590 [61440/90000 (68%)]	Loss: -7.8336	Cost: 9.56s
Train Epoch: 590 [81920/90000 (91%)]	Loss: -7.8637	Cost: 11.22s
Train Epoch: 590 	Average Loss: -7.6007
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3832

Learning rate: 0.0001815127795728555
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 591 [0/90000 (0%)]	Loss: -3.5468	Cost: 31.90s
Train Epoch: 591 [20480/90000 (23%)]	Loss: -8.1186	Cost: 9.81s
Train Epoch: 591 [40960/90000 (45%)]	Loss: -8.0174	Cost: 11.19s
Train Epoch: 591 [61440/90000 (68%)]	Loss: -7.6325	Cost: 9.57s
Train Epoch: 591 [81920/90000 (91%)]	Loss: -7.1472	Cost: 10.89s
Train Epoch: 591 	Average Loss: -7.4750
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9520

Learning rate: 0.00018145207270705104
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 592 [0/90000 (0%)]	Loss: -2.7055	Cost: 32.50s
Train Epoch: 592 [20480/90000 (23%)]	Loss: -7.6245	Cost: 10.27s
Train Epoch: 592 [40960/90000 (45%)]	Loss: -7.1641	Cost: 10.62s
Train Epoch: 592 [61440/90000 (68%)]	Loss: -6.8850	Cost: 9.55s
Train Epoch: 592 [81920/90000 (91%)]	Loss: -7.2648	Cost: 11.14s
Train Epoch: 592 	Average Loss: -6.9272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9144

Learning rate: 0.00018139127651906192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 593 [0/90000 (0%)]	Loss: -3.2570	Cost: 32.15s
Train Epoch: 593 [20480/90000 (23%)]	Loss: -7.6459	Cost: 9.81s
Train Epoch: 593 [40960/90000 (45%)]	Loss: -7.9792	Cost: 12.05s
Train Epoch: 593 [61440/90000 (68%)]	Loss: -7.7525	Cost: 9.63s
Train Epoch: 593 [81920/90000 (91%)]	Loss: -7.6277	Cost: 12.01s
Train Epoch: 593 	Average Loss: -7.3429
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9927

Learning rate: 0.0001813303910755586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 594 [0/90000 (0%)]	Loss: -3.2101	Cost: 31.82s
Train Epoch: 594 [20480/90000 (23%)]	Loss: -7.6474	Cost: 9.80s
Train Epoch: 594 [40960/90000 (45%)]	Loss: -7.9059	Cost: 12.28s
Train Epoch: 594 [61440/90000 (68%)]	Loss: -7.7853	Cost: 9.69s
Train Epoch: 594 [81920/90000 (91%)]	Loss: -7.9241	Cost: 12.07s
Train Epoch: 594 	Average Loss: -7.4157
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3213

Learning rate: 0.00018126941644330949
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 595 [0/90000 (0%)]	Loss: -3.2327	Cost: 32.84s
Train Epoch: 595 [20480/90000 (23%)]	Loss: -8.0905	Cost: 9.83s
Train Epoch: 595 [40960/90000 (45%)]	Loss: -8.1808	Cost: 11.59s
Train Epoch: 595 [61440/90000 (68%)]	Loss: -7.9278	Cost: 9.50s
Train Epoch: 595 [81920/90000 (91%)]	Loss: -7.7596	Cost: 11.36s
Train Epoch: 595 	Average Loss: -7.6698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3475

Learning rate: 0.00018120835268918073
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 596 [0/90000 (0%)]	Loss: -3.6788	Cost: 32.07s
Train Epoch: 596 [20480/90000 (23%)]	Loss: -7.8751	Cost: 9.73s
Train Epoch: 596 [40960/90000 (45%)]	Loss: -8.0829	Cost: 10.80s
Train Epoch: 596 [61440/90000 (68%)]	Loss: -7.8330	Cost: 9.59s
Train Epoch: 596 [81920/90000 (91%)]	Loss: -7.9092	Cost: 10.89s
Train Epoch: 596 	Average Loss: -7.6154
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4028

Learning rate: 0.00018114719988013617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 597 [0/90000 (0%)]	Loss: -3.4683	Cost: 30.55s
Train Epoch: 597 [20480/90000 (23%)]	Loss: -8.0068	Cost: 9.85s
Train Epoch: 597 [40960/90000 (45%)]	Loss: -8.3340	Cost: 11.23s
Train Epoch: 597 [61440/90000 (68%)]	Loss: -7.3273	Cost: 9.52s
Train Epoch: 597 [81920/90000 (91%)]	Loss: -7.0296	Cost: 11.05s
Train Epoch: 597 	Average Loss: -7.3901
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6395

Learning rate: 0.00018108595808323744
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 598 [0/90000 (0%)]	Loss: -2.4882	Cost: 31.74s
Train Epoch: 598 [20480/90000 (23%)]	Loss: -7.5188	Cost: 10.20s
Train Epoch: 598 [40960/90000 (45%)]	Loss: -7.8801	Cost: 10.22s
Train Epoch: 598 [61440/90000 (68%)]	Loss: -7.6093	Cost: 9.66s
Train Epoch: 598 [81920/90000 (91%)]	Loss: -7.8606	Cost: 10.85s
Train Epoch: 598 	Average Loss: -7.2824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2955

Learning rate: 0.00018102462736564363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 599 [0/90000 (0%)]	Loss: -3.8088	Cost: 31.81s
Train Epoch: 599 [20480/90000 (23%)]	Loss: -8.0379	Cost: 9.86s
Train Epoch: 599 [40960/90000 (45%)]	Loss: -8.2515	Cost: 11.41s
Train Epoch: 599 [61440/90000 (68%)]	Loss: -8.0521	Cost: 9.56s
Train Epoch: 599 [81920/90000 (91%)]	Loss: -8.0451	Cost: 10.76s
Train Epoch: 599 	Average Loss: -7.6844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3419

Learning rate: 0.0001809632077946114
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 600 [0/90000 (0%)]	Loss: -3.6064	Cost: 32.28s
Train Epoch: 600 [20480/90000 (23%)]	Loss: -7.8959	Cost: 9.79s
Train Epoch: 600 [40960/90000 (45%)]	Loss: -8.4176	Cost: 10.83s
Train Epoch: 600 [61440/90000 (68%)]	Loss: -7.9041	Cost: 9.63s
Train Epoch: 600 [81920/90000 (91%)]	Loss: -8.1840	Cost: 10.63s
Train Epoch: 600 	Average Loss: -7.7357
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4179

Saving model as model.pt_e600 & waveforms_supplementary.hdf5_e600
Learning rate: 0.00018090169943749484
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 601 [0/90000 (0%)]	Loss: -2.8194	Cost: 32.00s
Train Epoch: 601 [20480/90000 (23%)]	Loss: -7.6508	Cost: 9.82s
Train Epoch: 601 [40960/90000 (45%)]	Loss: -7.8606	Cost: 11.21s
Train Epoch: 601 [61440/90000 (68%)]	Loss: -7.7442	Cost: 9.51s
Train Epoch: 601 [81920/90000 (91%)]	Loss: -7.4355	Cost: 11.12s
Train Epoch: 601 	Average Loss: -7.4061
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0183

Learning rate: 0.00018084010236174542
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 602 [0/90000 (0%)]	Loss: -3.3718	Cost: 31.30s
Train Epoch: 602 [20480/90000 (23%)]	Loss: -7.7796	Cost: 9.82s
Train Epoch: 602 [40960/90000 (45%)]	Loss: -7.4818	Cost: 10.98s
Train Epoch: 602 [61440/90000 (68%)]	Loss: -7.1938	Cost: 9.53s
Train Epoch: 602 [81920/90000 (91%)]	Loss: -7.5681	Cost: 11.07s
Train Epoch: 602 	Average Loss: -7.1735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1070

Learning rate: 0.00018077841663491186
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 603 [0/90000 (0%)]	Loss: -2.2685	Cost: 32.16s
Train Epoch: 603 [20480/90000 (23%)]	Loss: -7.8169	Cost: 9.82s
Train Epoch: 603 [40960/90000 (45%)]	Loss: -8.0194	Cost: 11.43s
Train Epoch: 603 [61440/90000 (68%)]	Loss: -7.8998	Cost: 9.47s
Train Epoch: 603 [81920/90000 (91%)]	Loss: -7.8900	Cost: 10.82s
Train Epoch: 603 	Average Loss: -7.5189
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3184

Learning rate: 0.00018071664232464013
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 604 [0/90000 (0%)]	Loss: -3.6042	Cost: 31.25s
Train Epoch: 604 [20480/90000 (23%)]	Loss: -7.7135	Cost: 9.80s
Train Epoch: 604 [40960/90000 (45%)]	Loss: -8.2913	Cost: 11.36s
Train Epoch: 604 [61440/90000 (68%)]	Loss: -7.9781	Cost: 9.54s
Train Epoch: 604 [81920/90000 (91%)]	Loss: -8.0270	Cost: 11.07s
Train Epoch: 604 	Average Loss: -7.6984
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4342

Learning rate: 0.00018065477949867335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 605 [0/90000 (0%)]	Loss: -3.2231	Cost: 31.40s
Train Epoch: 605 [20480/90000 (23%)]	Loss: -8.0771	Cost: 9.72s
Train Epoch: 605 [40960/90000 (45%)]	Loss: -8.2255	Cost: 12.02s
Train Epoch: 605 [61440/90000 (68%)]	Loss: -8.1159	Cost: 9.54s
Train Epoch: 605 [81920/90000 (91%)]	Loss: -7.9510	Cost: 11.76s
Train Epoch: 605 	Average Loss: -7.7347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5045

Learning rate: 0.0001805928282248517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 606 [0/90000 (0%)]	Loss: -3.6725	Cost: 32.26s
Train Epoch: 606 [20480/90000 (23%)]	Loss: -8.0506	Cost: 9.83s
Train Epoch: 606 [40960/90000 (45%)]	Loss: -8.3083	Cost: 11.27s
Train Epoch: 606 [61440/90000 (68%)]	Loss: -8.1078	Cost: 9.61s
Train Epoch: 606 [81920/90000 (91%)]	Loss: -8.0730	Cost: 10.55s
Train Epoch: 606 	Average Loss: -7.8405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5813

Learning rate: 0.0001805307885711123
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 607 [0/90000 (0%)]	Loss: -3.0805	Cost: 31.11s
Train Epoch: 607 [20480/90000 (23%)]	Loss: -8.0581	Cost: 9.86s
Train Epoch: 607 [40960/90000 (45%)]	Loss: -8.6337	Cost: 11.56s
Train Epoch: 607 [61440/90000 (68%)]	Loss: -8.3615	Cost: 9.53s
Train Epoch: 607 [81920/90000 (91%)]	Loss: -8.2396	Cost: 11.63s
Train Epoch: 607 	Average Loss: -7.9182
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6739

Learning rate: 0.0001804686606054893
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 608 [0/90000 (0%)]	Loss: -3.0519	Cost: 30.91s
Train Epoch: 608 [20480/90000 (23%)]	Loss: -8.4555	Cost: 9.74s
Train Epoch: 608 [40960/90000 (45%)]	Loss: -8.6308	Cost: 11.67s
Train Epoch: 608 [61440/90000 (68%)]	Loss: -8.3569	Cost: 9.48s
Train Epoch: 608 [81920/90000 (91%)]	Loss: -8.3664	Cost: 11.56s
Train Epoch: 608 	Average Loss: -8.0397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6449

Learning rate: 0.00018040644439611358
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 609 [0/90000 (0%)]	Loss: -3.7850	Cost: 31.98s
Train Epoch: 609 [20480/90000 (23%)]	Loss: -8.3879	Cost: 9.70s
Train Epoch: 609 [40960/90000 (45%)]	Loss: -8.6650	Cost: 12.05s
Train Epoch: 609 [61440/90000 (68%)]	Loss: -8.3286	Cost: 9.62s
Train Epoch: 609 [81920/90000 (91%)]	Loss: -8.3199	Cost: 11.77s
Train Epoch: 609 	Average Loss: -8.0547
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5768

Learning rate: 0.0001803441400112129
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 610 [0/90000 (0%)]	Loss: -3.7838	Cost: 32.10s
Train Epoch: 610 [20480/90000 (23%)]	Loss: -8.1941	Cost: 9.89s
Train Epoch: 610 [40960/90000 (45%)]	Loss: -8.6261	Cost: 10.92s
Train Epoch: 610 [61440/90000 (68%)]	Loss: -8.4204	Cost: 13.83s
Train Epoch: 610 [81920/90000 (91%)]	Loss: -8.4055	Cost: 14.52s
Train Epoch: 610 	Average Loss: -8.0489
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7600

Learning rate: 0.00018028174751911157
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 611 [0/90000 (0%)]	Loss: -3.5461	Cost: 54.85s
Train Epoch: 611 [20480/90000 (23%)]	Loss: -8.4157	Cost: 13.59s
Train Epoch: 611 [40960/90000 (45%)]	Loss: -8.3852	Cost: 19.83s
Train Epoch: 611 [61440/90000 (68%)]	Loss: -8.2081	Cost: 10.54s
Train Epoch: 611 [81920/90000 (91%)]	Loss: -8.3048	Cost: 14.98s
Train Epoch: 611 	Average Loss: -8.0303
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4548

Learning rate: 0.00018021926698823067
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 612 [0/90000 (0%)]	Loss: -3.6552	Cost: 85.07s
Train Epoch: 612 [20480/90000 (23%)]	Loss: -8.2698	Cost: 10.99s
Train Epoch: 612 [40960/90000 (45%)]	Loss: -8.5349	Cost: 18.88s
Train Epoch: 612 [61440/90000 (68%)]	Loss: -8.2528	Cost: 12.97s
Train Epoch: 612 [81920/90000 (91%)]	Loss: -8.0001	Cost: 27.88s
Train Epoch: 612 	Average Loss: -7.9684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5366

Learning rate: 0.00018015669848708778
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 613 [0/90000 (0%)]	Loss: -3.4100	Cost: 114.49s
Train Epoch: 613 [20480/90000 (23%)]	Loss: -8.2116	Cost: 13.21s
Train Epoch: 613 [40960/90000 (45%)]	Loss: -8.6456	Cost: 39.50s
Train Epoch: 613 [61440/90000 (68%)]	Loss: -8.2280	Cost: 12.30s
Train Epoch: 613 [81920/90000 (91%)]	Loss: -8.2140	Cost: 40.65s
Train Epoch: 613 	Average Loss: -7.9304
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4906

Learning rate: 0.00018009404208429688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 614 [0/90000 (0%)]	Loss: -4.1594	Cost: 72.77s
Train Epoch: 614 [20480/90000 (23%)]	Loss: -8.0781	Cost: 21.01s
Train Epoch: 614 [40960/90000 (45%)]	Loss: -8.6480	Cost: 34.48s
Train Epoch: 614 [61440/90000 (68%)]	Loss: -8.2681	Cost: 18.97s
Train Epoch: 614 [81920/90000 (91%)]	Loss: -8.3415	Cost: 32.84s
Train Epoch: 614 	Average Loss: -8.0066
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7206

Learning rate: 0.0001800312978485684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 615 [0/90000 (0%)]	Loss: -3.0385	Cost: 32.64s
Train Epoch: 615 [20480/90000 (23%)]	Loss: -8.2507	Cost: 15.53s
Train Epoch: 615 [40960/90000 (45%)]	Loss: -8.5472	Cost: 16.96s
Train Epoch: 615 [61440/90000 (68%)]	Loss: -8.2632	Cost: 14.47s
Train Epoch: 615 [81920/90000 (91%)]	Loss: -8.3256	Cost: 21.07s
Train Epoch: 615 	Average Loss: -7.9908
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7393

Learning rate: 0.00017996846584870916
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 616 [0/90000 (0%)]	Loss: -3.9975	Cost: 61.80s
Train Epoch: 616 [20480/90000 (23%)]	Loss: -8.4537	Cost: 13.08s
Train Epoch: 616 [40960/90000 (45%)]	Loss: -8.8576	Cost: 21.87s
Train Epoch: 616 [61440/90000 (68%)]	Loss: -8.4935	Cost: 14.27s
Train Epoch: 616 [81920/90000 (91%)]	Loss: -8.6133	Cost: 22.69s
Train Epoch: 616 	Average Loss: -8.1847
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8042

Learning rate: 0.00017990554615362206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 617 [0/90000 (0%)]	Loss: -4.0157	Cost: 71.21s
Train Epoch: 617 [20480/90000 (23%)]	Loss: -8.5166	Cost: 13.11s
Train Epoch: 617 [40960/90000 (45%)]	Loss: -8.5126	Cost: 31.18s
Train Epoch: 617 [61440/90000 (68%)]	Loss: -8.1883	Cost: 13.80s
Train Epoch: 617 [81920/90000 (91%)]	Loss: -8.3041	Cost: 30.98s
Train Epoch: 617 	Average Loss: -7.9823
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6619

Learning rate: 0.00017984253883230635
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 618 [0/90000 (0%)]	Loss: -3.3481	Cost: 53.34s
Train Epoch: 618 [20480/90000 (23%)]	Loss: -8.4009	Cost: 9.65s
Train Epoch: 618 [40960/90000 (45%)]	Loss: -8.7977	Cost: 11.33s
Train Epoch: 618 [61440/90000 (68%)]	Loss: -8.3572	Cost: 9.48s
Train Epoch: 618 [81920/90000 (91%)]	Loss: -8.5032	Cost: 11.37s
Train Epoch: 618 	Average Loss: -8.1688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7678

Learning rate: 0.00017977944395385718
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 619 [0/90000 (0%)]	Loss: -3.4463	Cost: 31.33s
Train Epoch: 619 [20480/90000 (23%)]	Loss: -8.5386	Cost: 9.72s
Train Epoch: 619 [40960/90000 (45%)]	Loss: -8.6524	Cost: 11.05s
Train Epoch: 619 [61440/90000 (68%)]	Loss: -8.4227	Cost: 9.74s
Train Epoch: 619 [81920/90000 (91%)]	Loss: -8.3244	Cost: 10.42s
Train Epoch: 619 	Average Loss: -8.1602
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7908

Learning rate: 0.00017971626158746592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 620 [0/90000 (0%)]	Loss: -4.1315	Cost: 31.10s
Train Epoch: 620 [20480/90000 (23%)]	Loss: -8.4757	Cost: 9.86s
Train Epoch: 620 [40960/90000 (45%)]	Loss: -8.7156	Cost: 10.58s
Train Epoch: 620 [61440/90000 (68%)]	Loss: -8.5244	Cost: 9.55s
Train Epoch: 620 [81920/90000 (91%)]	Loss: -8.3056	Cost: 10.10s
Train Epoch: 620 	Average Loss: -8.1299
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7833

Learning rate: 0.0001796529918024197
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 621 [0/90000 (0%)]	Loss: -4.0610	Cost: 41.15s
Train Epoch: 621 [20480/90000 (23%)]	Loss: -8.2609	Cost: 12.93s
Train Epoch: 621 [40960/90000 (45%)]	Loss: -8.5206	Cost: 16.24s
Train Epoch: 621 [61440/90000 (68%)]	Loss: -8.3684	Cost: 10.12s
Train Epoch: 621 [81920/90000 (91%)]	Loss: -8.4604	Cost: 16.11s
Train Epoch: 621 	Average Loss: -8.0115
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7900

Learning rate: 0.00017958963466810167
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 622 [0/90000 (0%)]	Loss: -3.6077	Cost: 44.03s
Train Epoch: 622 [20480/90000 (23%)]	Loss: -8.6091	Cost: 11.64s
Train Epoch: 622 [40960/90000 (45%)]	Loss: -8.8835	Cost: 17.37s
Train Epoch: 622 [61440/90000 (68%)]	Loss: -8.4857	Cost: 9.68s
Train Epoch: 622 [81920/90000 (91%)]	Loss: -8.4063	Cost: 17.22s
Train Epoch: 622 	Average Loss: -8.1670
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8370

Learning rate: 0.00017952619025399068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 623 [0/90000 (0%)]	Loss: -3.4386	Cost: 43.79s
Train Epoch: 623 [20480/90000 (23%)]	Loss: -8.4000	Cost: 14.29s
Train Epoch: 623 [40960/90000 (45%)]	Loss: -8.7518	Cost: 17.30s
Train Epoch: 623 [61440/90000 (68%)]	Loss: -8.4232	Cost: 10.97s
Train Epoch: 623 [81920/90000 (91%)]	Loss: -8.5058	Cost: 22.56s
Train Epoch: 623 	Average Loss: -8.1384
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8031

Learning rate: 0.00017946265862966122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 624 [0/90000 (0%)]	Loss: -3.5181	Cost: 80.11s
Train Epoch: 624 [20480/90000 (23%)]	Loss: -8.6331	Cost: 13.64s
Train Epoch: 624 [40960/90000 (45%)]	Loss: -8.8369	Cost: 20.66s
Train Epoch: 624 [61440/90000 (68%)]	Loss: -8.3756	Cost: 12.13s
Train Epoch: 624 [81920/90000 (91%)]	Loss: -8.5674	Cost: 24.98s
Train Epoch: 624 	Average Loss: -8.1730
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7777

Learning rate: 0.00017939903986478363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 625 [0/90000 (0%)]	Loss: -3.9608	Cost: 31.05s
Train Epoch: 625 [20480/90000 (23%)]	Loss: -8.8045	Cost: 9.79s
Train Epoch: 625 [40960/90000 (45%)]	Loss: -8.8899	Cost: 10.66s
Train Epoch: 625 [61440/90000 (68%)]	Loss: -8.6426	Cost: 9.58s
Train Epoch: 625 [81920/90000 (91%)]	Loss: -8.7249	Cost: 10.31s
Train Epoch: 625 	Average Loss: -8.3746
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9848

Learning rate: 0.00017933533402912362
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 626 [0/90000 (0%)]	Loss: -4.3584	Cost: 30.60s
Train Epoch: 626 [20480/90000 (23%)]	Loss: -8.8238	Cost: 9.63s
Train Epoch: 626 [40960/90000 (45%)]	Loss: -8.9957	Cost: 11.64s
Train Epoch: 626 [61440/90000 (68%)]	Loss: -8.7056	Cost: 9.52s
Train Epoch: 626 [81920/90000 (91%)]	Loss: -8.5138	Cost: 10.98s
Train Epoch: 626 	Average Loss: -8.3585
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8974

Learning rate: 0.00017927154119254244
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 627 [0/90000 (0%)]	Loss: -3.9598	Cost: 30.91s
Train Epoch: 627 [20480/90000 (23%)]	Loss: -8.7705	Cost: 9.75s
Train Epoch: 627 [40960/90000 (45%)]	Loss: -8.9604	Cost: 11.32s
Train Epoch: 627 [61440/90000 (68%)]	Loss: -8.4756	Cost: 9.62s
Train Epoch: 627 [81920/90000 (91%)]	Loss: -8.4880	Cost: 10.66s
Train Epoch: 627 	Average Loss: -8.2886
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8542

Learning rate: 0.00017920766142499682
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 628 [0/90000 (0%)]	Loss: -3.2429	Cost: 32.04s
Train Epoch: 628 [20480/90000 (23%)]	Loss: -8.7398	Cost: 15.65s
Train Epoch: 628 [40960/90000 (45%)]	Loss: -8.7199	Cost: 13.31s
Train Epoch: 628 [61440/90000 (68%)]	Loss: -8.7160	Cost: 12.30s
Train Epoch: 628 [81920/90000 (91%)]	Loss: -8.6088	Cost: 15.80s
Train Epoch: 628 	Average Loss: -8.3100
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8567

Learning rate: 0.00017914369479653868
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 629 [0/90000 (0%)]	Loss: -3.8247	Cost: 39.80s
Train Epoch: 629 [20480/90000 (23%)]	Loss: -8.4308	Cost: 16.02s
Train Epoch: 629 [40960/90000 (45%)]	Loss: -8.7910	Cost: 14.08s
Train Epoch: 629 [61440/90000 (68%)]	Loss: -8.5187	Cost: 10.87s
Train Epoch: 629 [81920/90000 (91%)]	Loss: -8.8232	Cost: 17.65s
Train Epoch: 629 	Average Loss: -8.2709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9291

Learning rate: 0.0001790796413773153
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 630 [0/90000 (0%)]	Loss: -3.8753	Cost: 37.56s
Train Epoch: 630 [20480/90000 (23%)]	Loss: -8.7785	Cost: 14.23s
Train Epoch: 630 [40960/90000 (45%)]	Loss: -8.9337	Cost: 16.48s
Train Epoch: 630 [61440/90000 (68%)]	Loss: -8.7699	Cost: 11.24s
Train Epoch: 630 [81920/90000 (91%)]	Loss: -8.8332	Cost: 17.28s
Train Epoch: 630 	Average Loss: -8.4651
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1774

Learning rate: 0.00017901550123756914
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 631 [0/90000 (0%)]	Loss: -4.1018	Cost: 70.29s
Train Epoch: 631 [20480/90000 (23%)]	Loss: -8.8773	Cost: 14.04s
Train Epoch: 631 [40960/90000 (45%)]	Loss: -9.0118	Cost: 22.33s
Train Epoch: 631 [61440/90000 (68%)]	Loss: -8.6720	Cost: 12.02s
Train Epoch: 631 [81920/90000 (91%)]	Loss: -8.8237	Cost: 21.45s
Train Epoch: 631 	Average Loss: -8.4452
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9913

Learning rate: 0.0001789512744476377
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 632 [0/90000 (0%)]	Loss: -3.9865	Cost: 70.65s
Train Epoch: 632 [20480/90000 (23%)]	Loss: -8.6102	Cost: 9.75s
Train Epoch: 632 [40960/90000 (45%)]	Loss: -8.9392	Cost: 10.05s
Train Epoch: 632 [61440/90000 (68%)]	Loss: -8.8320	Cost: 9.54s
Train Epoch: 632 [81920/90000 (91%)]	Loss: -8.6247	Cost: 9.96s
Train Epoch: 632 	Average Loss: -8.3738
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9859

Learning rate: 0.00017888696107795353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 633 [0/90000 (0%)]	Loss: -4.2471	Cost: 30.26s
Train Epoch: 633 [20480/90000 (23%)]	Loss: -8.7830	Cost: 9.73s
Train Epoch: 633 [40960/90000 (45%)]	Loss: -9.0453	Cost: 11.21s
Train Epoch: 633 [61440/90000 (68%)]	Loss: -8.8299	Cost: 9.45s
Train Epoch: 633 [81920/90000 (91%)]	Loss: -8.6854	Cost: 10.73s
Train Epoch: 633 	Average Loss: -8.4778
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0891

Learning rate: 0.00017882256119904413
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 634 [0/90000 (0%)]	Loss: -4.4974	Cost: 30.03s
Train Epoch: 634 [20480/90000 (23%)]	Loss: -8.5058	Cost: 9.74s
Train Epoch: 634 [40960/90000 (45%)]	Loss: -8.5917	Cost: 11.52s
Train Epoch: 634 [61440/90000 (68%)]	Loss: -8.3437	Cost: 9.49s
Train Epoch: 634 [81920/90000 (91%)]	Loss: -8.3935	Cost: 10.77s
Train Epoch: 634 	Average Loss: -8.1804
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7459

Learning rate: 0.00017875807488153185
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 635 [0/90000 (0%)]	Loss: -2.8613	Cost: 30.62s
Train Epoch: 635 [20480/90000 (23%)]	Loss: -8.6682	Cost: 9.76s
Train Epoch: 635 [40960/90000 (45%)]	Loss: -8.8769	Cost: 10.67s
Train Epoch: 635 [61440/90000 (68%)]	Loss: -8.2192	Cost: 9.45s
Train Epoch: 635 [81920/90000 (91%)]	Loss: -8.1389	Cost: 9.96s
Train Epoch: 635 	Average Loss: -8.1045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5994

Learning rate: 0.00017869350219613386
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 636 [0/90000 (0%)]	Loss: -3.5197	Cost: 29.68s
Train Epoch: 636 [20480/90000 (23%)]	Loss: -8.4754	Cost: 9.74s
Train Epoch: 636 [40960/90000 (45%)]	Loss: -8.9258	Cost: 11.54s
Train Epoch: 636 [61440/90000 (68%)]	Loss: -8.6027	Cost: 9.48s
Train Epoch: 636 [81920/90000 (91%)]	Loss: -8.5900	Cost: 10.71s
Train Epoch: 636 	Average Loss: -8.3259
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0260

Learning rate: 0.000178628843213662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 637 [0/90000 (0%)]	Loss: -3.9024	Cost: 30.76s
Train Epoch: 637 [20480/90000 (23%)]	Loss: -8.8262	Cost: 9.94s
Train Epoch: 637 [40960/90000 (45%)]	Loss: -8.9070	Cost: 10.75s
Train Epoch: 637 [61440/90000 (68%)]	Loss: -8.7107	Cost: 9.51s
Train Epoch: 637 [81920/90000 (91%)]	Loss: -8.3255	Cost: 9.96s
Train Epoch: 637 	Average Loss: -8.3187
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5199

Learning rate: 0.0001785640980050228
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 638 [0/90000 (0%)]	Loss: -3.1796	Cost: 29.86s
Train Epoch: 638 [20480/90000 (23%)]	Loss: -8.4183	Cost: 9.85s
Train Epoch: 638 [40960/90000 (45%)]	Loss: -8.7807	Cost: 11.39s
Train Epoch: 638 [61440/90000 (68%)]	Loss: -8.5778	Cost: 9.57s
Train Epoch: 638 [81920/90000 (91%)]	Loss: -8.5871	Cost: 10.88s
Train Epoch: 638 	Average Loss: -8.1425
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7863

Learning rate: 0.00017849926664121734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 639 [0/90000 (0%)]	Loss: -3.8011	Cost: 30.78s
Train Epoch: 639 [20480/90000 (23%)]	Loss: -8.5200	Cost: 9.84s
Train Epoch: 639 [40960/90000 (45%)]	Loss: -8.7777	Cost: 10.75s
Train Epoch: 639 [61440/90000 (68%)]	Loss: -8.6868	Cost: 9.56s
Train Epoch: 639 [81920/90000 (91%)]	Loss: -8.9175	Cost: 10.35s
Train Epoch: 639 	Average Loss: -8.3097
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1147

Learning rate: 0.0001784343491933411
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 640 [0/90000 (0%)]	Loss: -4.0507	Cost: 30.28s
Train Epoch: 640 [20480/90000 (23%)]	Loss: -8.9214	Cost: 9.81s
Train Epoch: 640 [40960/90000 (45%)]	Loss: -9.1599	Cost: 11.26s
Train Epoch: 640 [61440/90000 (68%)]	Loss: -8.5578	Cost: 9.53s
Train Epoch: 640 [81920/90000 (91%)]	Loss: -8.7151	Cost: 10.65s
Train Epoch: 640 	Average Loss: -8.4693
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1022

Learning rate: 0.00017836934573258405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 641 [0/90000 (0%)]	Loss: -3.7564	Cost: 29.73s
Train Epoch: 641 [20480/90000 (23%)]	Loss: -8.9623	Cost: 9.83s
Train Epoch: 641 [40960/90000 (45%)]	Loss: -9.0771	Cost: 11.33s
Train Epoch: 641 [61440/90000 (68%)]	Loss: -8.6224	Cost: 9.46s
Train Epoch: 641 [81920/90000 (91%)]	Loss: -8.5760	Cost: 10.72s
Train Epoch: 641 	Average Loss: -8.4767
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9133

Learning rate: 0.00017830425633023048
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 642 [0/90000 (0%)]	Loss: -4.0533	Cost: 30.30s
Train Epoch: 642 [20480/90000 (23%)]	Loss: -8.9807	Cost: 9.71s
Train Epoch: 642 [40960/90000 (45%)]	Loss: -8.9845	Cost: 10.73s
Train Epoch: 642 [61440/90000 (68%)]	Loss: -8.8899	Cost: 9.58s
Train Epoch: 642 [81920/90000 (91%)]	Loss: -8.6479	Cost: 10.03s
Train Epoch: 642 	Average Loss: -8.4857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9723

Learning rate: 0.00017823908105765886
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 643 [0/90000 (0%)]	Loss: -3.5990	Cost: 30.55s
Train Epoch: 643 [20480/90000 (23%)]	Loss: -8.8156	Cost: 9.69s
Train Epoch: 643 [40960/90000 (45%)]	Loss: -9.0501	Cost: 10.57s
Train Epoch: 643 [61440/90000 (68%)]	Loss: -8.7650	Cost: 9.49s
Train Epoch: 643 [81920/90000 (91%)]	Loss: -8.7892	Cost: 13.88s
Train Epoch: 643 	Average Loss: -8.5065
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1403

Learning rate: 0.0001781738199863419
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 644 [0/90000 (0%)]	Loss: -4.0246	Cost: 54.71s
Train Epoch: 644 [20480/90000 (23%)]	Loss: -9.1067	Cost: 11.03s
Train Epoch: 644 [40960/90000 (45%)]	Loss: -9.4827	Cost: 11.43s
Train Epoch: 644 [61440/90000 (68%)]	Loss: -8.8101	Cost: 9.45s
Train Epoch: 644 [81920/90000 (91%)]	Loss: -8.8940	Cost: 14.12s
Train Epoch: 644 	Average Loss: -8.6873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2824

Learning rate: 0.00017810847318784636
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 645 [0/90000 (0%)]	Loss: -4.1141	Cost: 42.35s
Train Epoch: 645 [20480/90000 (23%)]	Loss: -8.9780	Cost: 14.92s
Train Epoch: 645 [40960/90000 (45%)]	Loss: -9.2320	Cost: 21.89s
Train Epoch: 645 [61440/90000 (68%)]	Loss: -8.9197	Cost: 9.39s
Train Epoch: 645 [81920/90000 (91%)]	Loss: -8.8073	Cost: 12.14s
Train Epoch: 645 	Average Loss: -8.6008
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0449

Learning rate: 0.00017804304073383302
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 646 [0/90000 (0%)]	Loss: -4.0706	Cost: 36.97s
Train Epoch: 646 [20480/90000 (23%)]	Loss: -8.9049	Cost: 12.96s
Train Epoch: 646 [40960/90000 (45%)]	Loss: -9.3906	Cost: 17.54s
Train Epoch: 646 [61440/90000 (68%)]	Loss: -8.9628	Cost: 12.98s
Train Epoch: 646 [81920/90000 (91%)]	Loss: -9.0320	Cost: 16.50s
Train Epoch: 646 	Average Loss: -8.6403
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2212

Learning rate: 0.00017797752269605658
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 647 [0/90000 (0%)]	Loss: -4.2517	Cost: 29.58s
Train Epoch: 647 [20480/90000 (23%)]	Loss: -8.9416	Cost: 12.65s
Train Epoch: 647 [40960/90000 (45%)]	Loss: -9.1013	Cost: 17.78s
Train Epoch: 647 [61440/90000 (68%)]	Loss: -8.6079	Cost: 11.91s
Train Epoch: 647 [81920/90000 (91%)]	Loss: -8.2466	Cost: 20.34s
Train Epoch: 647 	Average Loss: -8.3947
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6620

Learning rate: 0.00017791191914636557
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 648 [0/90000 (0%)]	Loss: -3.5257	Cost: 64.84s
Train Epoch: 648 [20480/90000 (23%)]	Loss: -8.3516	Cost: 11.75s
Train Epoch: 648 [40960/90000 (45%)]	Loss: -8.9283	Cost: 23.37s
Train Epoch: 648 [61440/90000 (68%)]	Loss: -8.9574	Cost: 13.30s
Train Epoch: 648 [81920/90000 (91%)]	Loss: -8.6853	Cost: 23.28s
Train Epoch: 648 	Average Loss: -8.3594
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2009

Learning rate: 0.0001778462301567024
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 649 [0/90000 (0%)]	Loss: -4.6060	Cost: 62.57s
Train Epoch: 649 [20480/90000 (23%)]	Loss: -8.8592	Cost: 12.66s
Train Epoch: 649 [40960/90000 (45%)]	Loss: -9.1585	Cost: 24.09s
Train Epoch: 649 [61440/90000 (68%)]	Loss: -9.1469	Cost: 12.28s
Train Epoch: 649 [81920/90000 (91%)]	Loss: -8.9585	Cost: 25.38s
Train Epoch: 649 	Average Loss: -8.6240
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2697

Learning rate: 0.00017778045579910302
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 650 [0/90000 (0%)]	Loss: -3.5701	Cost: 29.85s
Train Epoch: 650 [20480/90000 (23%)]	Loss: -8.9890	Cost: 9.62s
Train Epoch: 650 [40960/90000 (45%)]	Loss: -9.4545	Cost: 10.89s
Train Epoch: 650 [61440/90000 (68%)]	Loss: -9.2473	Cost: 9.59s
Train Epoch: 650 [81920/90000 (91%)]	Loss: -8.9930	Cost: 9.68s
Train Epoch: 650 	Average Loss: -8.7831
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2183

Saving model as model.pt_e650 & waveforms_supplementary.hdf5_e650
Learning rate: 0.00017771459614569714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 651 [0/90000 (0%)]	Loss: -4.1493	Cost: 29.89s
Train Epoch: 651 [20480/90000 (23%)]	Loss: -8.7847	Cost: 9.87s
Train Epoch: 651 [40960/90000 (45%)]	Loss: -9.0167	Cost: 11.16s
Train Epoch: 651 [61440/90000 (68%)]	Loss: -8.9315	Cost: 9.71s
Train Epoch: 651 [81920/90000 (91%)]	Loss: -8.8293	Cost: 10.86s
Train Epoch: 651 	Average Loss: -8.6517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4128

Learning rate: 0.0001776486512687079
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 652 [0/90000 (0%)]	Loss: -3.9222	Cost: 30.54s
Train Epoch: 652 [20480/90000 (23%)]	Loss: -9.1132	Cost: 9.68s
Train Epoch: 652 [40960/90000 (45%)]	Loss: -9.5395	Cost: 10.98s
Train Epoch: 652 [61440/90000 (68%)]	Loss: -9.2134	Cost: 9.51s
Train Epoch: 652 [81920/90000 (91%)]	Loss: -8.3580	Cost: 10.57s
Train Epoch: 652 	Average Loss: -8.7219
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7328

Learning rate: 0.000177582621240452
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 653 [0/90000 (0%)]	Loss: -3.8014	Cost: 30.08s
Train Epoch: 653 [20480/90000 (23%)]	Loss: -8.6062	Cost: 9.66s
Train Epoch: 653 [40960/90000 (45%)]	Loss: -9.0836	Cost: 11.34s
Train Epoch: 653 [61440/90000 (68%)]	Loss: -8.8082	Cost: 9.45s
Train Epoch: 653 [81920/90000 (91%)]	Loss: -8.9303	Cost: 10.57s
Train Epoch: 653 	Average Loss: -8.4799
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5419

Learning rate: 0.0001775165061333394
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 654 [0/90000 (0%)]	Loss: -4.3351	Cost: 30.02s
Train Epoch: 654 [20480/90000 (23%)]	Loss: -9.2739	Cost: 9.66s
Train Epoch: 654 [40960/90000 (45%)]	Loss: -9.6145	Cost: 11.19s
Train Epoch: 654 [61440/90000 (68%)]	Loss: -9.0817	Cost: 9.48s
Train Epoch: 654 [81920/90000 (91%)]	Loss: -9.2745	Cost: 10.02s
Train Epoch: 654 	Average Loss: -8.9377
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3830

Learning rate: 0.00017745030601987343
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 655 [0/90000 (0%)]	Loss: -4.1210	Cost: 30.40s
Train Epoch: 655 [20480/90000 (23%)]	Loss: -9.2105	Cost: 9.62s
Train Epoch: 655 [40960/90000 (45%)]	Loss: -9.6757	Cost: 10.95s
Train Epoch: 655 [61440/90000 (68%)]	Loss: -8.7308	Cost: 9.60s
Train Epoch: 655 [81920/90000 (91%)]	Loss: -8.8682	Cost: 9.85s
Train Epoch: 655 	Average Loss: -8.8076
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0382

Learning rate: 0.0001773840209726507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 656 [0/90000 (0%)]	Loss: -4.5567	Cost: 30.20s
Train Epoch: 656 [20480/90000 (23%)]	Loss: -8.9744	Cost: 9.65s
Train Epoch: 656 [40960/90000 (45%)]	Loss: -9.2673	Cost: 11.23s
Train Epoch: 656 [61440/90000 (68%)]	Loss: -9.0212	Cost: 9.44s
Train Epoch: 656 [81920/90000 (91%)]	Loss: -9.2144	Cost: 10.33s
Train Epoch: 656 	Average Loss: -8.7375
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4129

Learning rate: 0.00017731765106436079
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 657 [0/90000 (0%)]	Loss: -4.6975	Cost: 30.03s
Train Epoch: 657 [20480/90000 (23%)]	Loss: -9.4133	Cost: 9.70s
Train Epoch: 657 [40960/90000 (45%)]	Loss: -9.7245	Cost: 11.21s
Train Epoch: 657 [61440/90000 (68%)]	Loss: -9.3807	Cost: 9.61s
Train Epoch: 657 [81920/90000 (91%)]	Loss: -8.0644	Cost: 9.96s
Train Epoch: 657 	Average Loss: -8.8570
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1233

Learning rate: 0.0001772511963677865
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 658 [0/90000 (0%)]	Loss: -3.3139	Cost: 30.39s
Train Epoch: 658 [20480/90000 (23%)]	Loss: -8.0973	Cost: 9.54s
Train Epoch: 658 [40960/90000 (45%)]	Loss: -8.7917	Cost: 11.65s
Train Epoch: 658 [61440/90000 (68%)]	Loss: -8.8364	Cost: 9.34s
Train Epoch: 658 [81920/90000 (91%)]	Loss: -8.8617	Cost: 10.77s
Train Epoch: 658 	Average Loss: -8.1165
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2592

Learning rate: 0.00017718465695580355
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 659 [0/90000 (0%)]	Loss: -3.7531	Cost: 29.77s
Train Epoch: 659 [20480/90000 (23%)]	Loss: -8.9027	Cost: 9.69s
Train Epoch: 659 [40960/90000 (45%)]	Loss: -9.3910	Cost: 11.12s
Train Epoch: 659 [61440/90000 (68%)]	Loss: -9.1258	Cost: 9.44s
Train Epoch: 659 [81920/90000 (91%)]	Loss: -9.2685	Cost: 10.77s
Train Epoch: 659 	Average Loss: -8.8254
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5561

Learning rate: 0.00017711803290138057
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 660 [0/90000 (0%)]	Loss: -4.9302	Cost: 29.94s
Train Epoch: 660 [20480/90000 (23%)]	Loss: -9.3013	Cost: 9.63s
Train Epoch: 660 [40960/90000 (45%)]	Loss: -9.6811	Cost: 11.36s
Train Epoch: 660 [61440/90000 (68%)]	Loss: -9.5169	Cost: 9.49s
Train Epoch: 660 [81920/90000 (91%)]	Loss: -9.2964	Cost: 13.24s
Train Epoch: 660 	Average Loss: -9.0707
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5028

Learning rate: 0.00017705132427757897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 661 [0/90000 (0%)]	Loss: -4.4396	Cost: 39.20s
Train Epoch: 661 [20480/90000 (23%)]	Loss: -9.3403	Cost: 15.45s
Train Epoch: 661 [40960/90000 (45%)]	Loss: -9.6469	Cost: 16.47s
Train Epoch: 661 [61440/90000 (68%)]	Loss: -9.4807	Cost: 11.77s
Train Epoch: 661 [81920/90000 (91%)]	Loss: -9.3027	Cost: 17.53s
Train Epoch: 661 	Average Loss: -9.0401
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3230

Learning rate: 0.00017698453115755296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 662 [0/90000 (0%)]	Loss: -3.8992	Cost: 45.32s
Train Epoch: 662 [20480/90000 (23%)]	Loss: -9.2741	Cost: 12.67s
Train Epoch: 662 [40960/90000 (45%)]	Loss: -9.7059	Cost: 12.78s
Train Epoch: 662 [61440/90000 (68%)]	Loss: -9.3738	Cost: 11.96s
Train Epoch: 662 [81920/90000 (91%)]	Loss: -9.2987	Cost: 16.43s
Train Epoch: 662 	Average Loss: -9.0720
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5933

Learning rate: 0.0001769176536145494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 663 [0/90000 (0%)]	Loss: -4.0891	Cost: 50.28s
Train Epoch: 663 [20480/90000 (23%)]	Loss: -9.4972	Cost: 13.56s
Train Epoch: 663 [40960/90000 (45%)]	Loss: -9.7712	Cost: 22.15s
Train Epoch: 663 [61440/90000 (68%)]	Loss: -9.4235	Cost: 12.16s
Train Epoch: 663 [81920/90000 (91%)]	Loss: -9.3902	Cost: 26.36s
Train Epoch: 663 	Average Loss: -9.1412
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7220

Learning rate: 0.00017685069172190771
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 664 [0/90000 (0%)]	Loss: -4.8052	Cost: 54.57s
Train Epoch: 664 [20480/90000 (23%)]	Loss: -9.7117	Cost: 13.26s
Train Epoch: 664 [40960/90000 (45%)]	Loss: -9.8202	Cost: 21.39s
Train Epoch: 664 [61440/90000 (68%)]	Loss: -9.5959	Cost: 11.92s
Train Epoch: 664 [81920/90000 (91%)]	Loss: -9.3441	Cost: 14.17s
Train Epoch: 664 	Average Loss: -9.1820
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5449

Learning rate: 0.0001767836455530598
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 665 [0/90000 (0%)]	Loss: -4.3674	Cost: 30.10s
Train Epoch: 665 [20480/90000 (23%)]	Loss: -9.5183	Cost: 9.51s
Train Epoch: 665 [40960/90000 (45%)]	Loss: -9.8023	Cost: 11.61s
Train Epoch: 665 [61440/90000 (68%)]	Loss: -9.3269	Cost: 9.38s
Train Epoch: 665 [81920/90000 (91%)]	Loss: -9.3474	Cost: 10.06s
Train Epoch: 665 	Average Loss: -9.0399
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4150

Learning rate: 0.00017671651518153005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 666 [0/90000 (0%)]	Loss: -4.3426	Cost: 29.52s
Train Epoch: 666 [20480/90000 (23%)]	Loss: -9.4359	Cost: 9.74s
Train Epoch: 666 [40960/90000 (45%)]	Loss: -9.3834	Cost: 10.43s
Train Epoch: 666 [61440/90000 (68%)]	Loss: -9.5199	Cost: 9.63s
Train Epoch: 666 [81920/90000 (91%)]	Loss: -9.3983	Cost: 9.38s
Train Epoch: 666 	Average Loss: -8.9885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5618

Learning rate: 0.00017664930068093506
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 667 [0/90000 (0%)]	Loss: -4.6350	Cost: 29.62s
Train Epoch: 667 [20480/90000 (23%)]	Loss: -9.5020	Cost: 9.81s
Train Epoch: 667 [40960/90000 (45%)]	Loss: -9.6145	Cost: 10.76s
Train Epoch: 667 [61440/90000 (68%)]	Loss: -9.3911	Cost: 9.42s
Train Epoch: 667 [81920/90000 (91%)]	Loss: -9.3694	Cost: 9.84s
Train Epoch: 667 	Average Loss: -9.0951
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5781

Learning rate: 0.00017658200212498383
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 668 [0/90000 (0%)]	Loss: -4.5381	Cost: 30.09s
Train Epoch: 668 [20480/90000 (23%)]	Loss: -9.4790	Cost: 9.94s
Train Epoch: 668 [40960/90000 (45%)]	Loss: -9.5470	Cost: 11.12s
Train Epoch: 668 [61440/90000 (68%)]	Loss: -9.3410	Cost: 9.75s
Train Epoch: 668 [81920/90000 (91%)]	Loss: -9.3527	Cost: 10.14s
Train Epoch: 668 	Average Loss: -9.0600
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4859

Learning rate: 0.0001765146195874775
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 669 [0/90000 (0%)]	Loss: -4.5296	Cost: 29.98s
Train Epoch: 669 [20480/90000 (23%)]	Loss: -9.5262	Cost: 9.63s
Train Epoch: 669 [40960/90000 (45%)]	Loss: -9.8256	Cost: 10.91s
Train Epoch: 669 [61440/90000 (68%)]	Loss: -9.3030	Cost: 9.44s
Train Epoch: 669 [81920/90000 (91%)]	Loss: -9.7884	Cost: 9.85s
Train Epoch: 669 	Average Loss: -9.2085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7491

Learning rate: 0.00017644715314230923
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 670 [0/90000 (0%)]	Loss: -4.4652	Cost: 29.90s
Train Epoch: 670 [20480/90000 (23%)]	Loss: -9.6003	Cost: 9.82s
Train Epoch: 670 [40960/90000 (45%)]	Loss: -9.9821	Cost: 10.54s
Train Epoch: 670 [61440/90000 (68%)]	Loss: -9.0729	Cost: 9.79s
Train Epoch: 670 [81920/90000 (91%)]	Loss: -9.2727	Cost: 9.34s
Train Epoch: 670 	Average Loss: -9.1390
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5557

Learning rate: 0.0001763796028634643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 671 [0/90000 (0%)]	Loss: -4.6073	Cost: 29.38s
Train Epoch: 671 [20480/90000 (23%)]	Loss: -9.5065	Cost: 9.76s
Train Epoch: 671 [40960/90000 (45%)]	Loss: -9.6924	Cost: 11.26s
Train Epoch: 671 [61440/90000 (68%)]	Loss: -9.4264	Cost: 9.48s
Train Epoch: 671 [81920/90000 (91%)]	Loss: -9.4470	Cost: 10.23s
Train Epoch: 671 	Average Loss: -9.0980
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6779

Learning rate: 0.00017631196882501982
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 672 [0/90000 (0%)]	Loss: -4.5932	Cost: 30.57s
Train Epoch: 672 [20480/90000 (23%)]	Loss: -9.6680	Cost: 9.98s
Train Epoch: 672 [40960/90000 (45%)]	Loss: -9.7620	Cost: 10.57s
Train Epoch: 672 [61440/90000 (68%)]	Loss: -9.6765	Cost: 9.49s
Train Epoch: 672 [81920/90000 (91%)]	Loss: -9.4734	Cost: 9.55s
Train Epoch: 672 	Average Loss: -9.2580
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7629

Learning rate: 0.00017624425110114486
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 673 [0/90000 (0%)]	Loss: -4.4155	Cost: 28.79s
Train Epoch: 673 [20480/90000 (23%)]	Loss: -9.5846	Cost: 9.78s
Train Epoch: 673 [40960/90000 (45%)]	Loss: -10.1103	Cost: 10.98s
Train Epoch: 673 [61440/90000 (68%)]	Loss: -9.6394	Cost: 9.47s
Train Epoch: 673 [81920/90000 (91%)]	Loss: -9.5827	Cost: 9.65s
Train Epoch: 673 	Average Loss: -9.3726
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7675

Learning rate: 0.00017617644976610015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 674 [0/90000 (0%)]	Loss: -4.6582	Cost: 29.10s
Train Epoch: 674 [20480/90000 (23%)]	Loss: -9.6863	Cost: 9.79s
Train Epoch: 674 [40960/90000 (45%)]	Loss: -10.0479	Cost: 10.83s
Train Epoch: 674 [61440/90000 (68%)]	Loss: -9.8403	Cost: 9.44s
Train Epoch: 674 [81920/90000 (91%)]	Loss: -9.7090	Cost: 9.28s
Train Epoch: 674 	Average Loss: -9.3865
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8440

Learning rate: 0.00017610856489423825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 675 [0/90000 (0%)]	Loss: -4.9381	Cost: 29.64s
Train Epoch: 675 [20480/90000 (23%)]	Loss: -9.7685	Cost: 9.74s
Train Epoch: 675 [40960/90000 (45%)]	Loss: -10.1170	Cost: 11.06s
Train Epoch: 675 [61440/90000 (68%)]	Loss: -9.7992	Cost: 9.46s
Train Epoch: 675 [81920/90000 (91%)]	Loss: -9.6503	Cost: 9.63s
Train Epoch: 675 	Average Loss: -9.3764
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7191

Learning rate: 0.00017604059656000317
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 676 [0/90000 (0%)]	Loss: -4.3363	Cost: 29.31s
Train Epoch: 676 [20480/90000 (23%)]	Loss: -9.8240	Cost: 9.78s
Train Epoch: 676 [40960/90000 (45%)]	Loss: -9.8995	Cost: 11.22s
Train Epoch: 676 [61440/90000 (68%)]	Loss: -9.8200	Cost: 9.52s
Train Epoch: 676 [81920/90000 (91%)]	Loss: -9.7869	Cost: 9.42s
Train Epoch: 676 	Average Loss: -9.4511
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0091

Learning rate: 0.00017597254483793054
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 677 [0/90000 (0%)]	Loss: -4.5470	Cost: 30.81s
Train Epoch: 677 [20480/90000 (23%)]	Loss: -8.8302	Cost: 11.78s
Train Epoch: 677 [40960/90000 (45%)]	Loss: -9.2709	Cost: 19.92s
Train Epoch: 677 [61440/90000 (68%)]	Loss: -9.1740	Cost: 10.26s
Train Epoch: 677 [81920/90000 (91%)]	Loss: -9.3411	Cost: 11.83s
Train Epoch: 677 	Average Loss: -8.8556
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6972

Learning rate: 0.00017590440980264744
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 678 [0/90000 (0%)]	Loss: -4.3375	Cost: 47.14s
Train Epoch: 678 [20480/90000 (23%)]	Loss: -9.5448	Cost: 12.85s
Train Epoch: 678 [40960/90000 (45%)]	Loss: -9.9052	Cost: 16.77s
Train Epoch: 678 [61440/90000 (68%)]	Loss: -9.5034	Cost: 9.52s
Train Epoch: 678 [81920/90000 (91%)]	Loss: -9.4507	Cost: 13.16s
Train Epoch: 678 	Average Loss: -9.2258
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6436

Learning rate: 0.00017583619152887226
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 679 [0/90000 (0%)]	Loss: -5.2542	Cost: 52.72s
Train Epoch: 679 [20480/90000 (23%)]	Loss: -9.7290	Cost: 9.75s
Train Epoch: 679 [40960/90000 (45%)]	Loss: -9.9236	Cost: 10.43s
Train Epoch: 679 [61440/90000 (68%)]	Loss: -9.8670	Cost: 13.57s
Train Epoch: 679 [81920/90000 (91%)]	Loss: -9.5148	Cost: 16.39s
Train Epoch: 679 	Average Loss: -9.3816
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7162

Learning rate: 0.0001757678900914147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 680 [0/90000 (0%)]	Loss: -4.7538	Cost: 51.45s
Train Epoch: 680 [20480/90000 (23%)]	Loss: -9.4868	Cost: 9.71s
Train Epoch: 680 [40960/90000 (45%)]	Loss: -10.1133	Cost: 9.90s
Train Epoch: 680 [61440/90000 (68%)]	Loss: -9.9895	Cost: 13.29s
Train Epoch: 680 [81920/90000 (91%)]	Loss: -9.8786	Cost: 16.00s
Train Epoch: 680 	Average Loss: -9.4338
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1620

Learning rate: 0.0001756995055651757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 681 [0/90000 (0%)]	Loss: -4.7579	Cost: 72.28s
Train Epoch: 681 [20480/90000 (23%)]	Loss: -9.8341	Cost: 13.27s
Train Epoch: 681 [40960/90000 (45%)]	Loss: -10.0318	Cost: 23.29s
Train Epoch: 681 [61440/90000 (68%)]	Loss: -9.8990	Cost: 12.23s
Train Epoch: 681 [81920/90000 (91%)]	Loss: -9.8253	Cost: 27.79s
Train Epoch: 681 	Average Loss: -9.4936
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9504

Learning rate: 0.00017563103802514725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 682 [0/90000 (0%)]	Loss: -5.1473	Cost: 78.00s
Train Epoch: 682 [20480/90000 (23%)]	Loss: -9.6458	Cost: 13.46s
Train Epoch: 682 [40960/90000 (45%)]	Loss: -10.1129	Cost: 22.22s
Train Epoch: 682 [61440/90000 (68%)]	Loss: -9.7890	Cost: 12.13s
Train Epoch: 682 [81920/90000 (91%)]	Loss: -9.9110	Cost: 26.19s
Train Epoch: 682 	Average Loss: -9.4897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0238

Learning rate: 0.00017556248754641238
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 683 [0/90000 (0%)]	Loss: -4.8237	Cost: 30.08s
Train Epoch: 683 [20480/90000 (23%)]	Loss: -9.8865	Cost: 9.46s
Train Epoch: 683 [40960/90000 (45%)]	Loss: -10.1233	Cost: 10.41s
Train Epoch: 683 [61440/90000 (68%)]	Loss: -9.8663	Cost: 9.41s
Train Epoch: 683 [81920/90000 (91%)]	Loss: -9.8061	Cost: 9.26s
Train Epoch: 683 	Average Loss: -9.5874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9661

Learning rate: 0.00017549385420414517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 684 [0/90000 (0%)]	Loss: -4.7214	Cost: 29.20s
Train Epoch: 684 [20480/90000 (23%)]	Loss: -9.8986	Cost: 9.51s
Train Epoch: 684 [40960/90000 (45%)]	Loss: -10.2695	Cost: 11.19s
Train Epoch: 684 [61440/90000 (68%)]	Loss: -9.8513	Cost: 9.33s
Train Epoch: 684 [81920/90000 (91%)]	Loss: -9.7675	Cost: 10.45s
Train Epoch: 684 	Average Loss: -9.5877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9452

Learning rate: 0.00017542513807361043
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 685 [0/90000 (0%)]	Loss: -4.7887	Cost: 30.12s
Train Epoch: 685 [20480/90000 (23%)]	Loss: -9.8341	Cost: 9.52s
Train Epoch: 685 [40960/90000 (45%)]	Loss: -10.2215	Cost: 10.81s
Train Epoch: 685 [61440/90000 (68%)]	Loss: -9.8645	Cost: 9.52s
Train Epoch: 685 [81920/90000 (91%)]	Loss: -9.8997	Cost: 9.61s
Train Epoch: 685 	Average Loss: -9.6010
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0341

Learning rate: 0.00017535633923016384
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 686 [0/90000 (0%)]	Loss: -4.8106	Cost: 30.07s
Train Epoch: 686 [20480/90000 (23%)]	Loss: -10.0162	Cost: 9.74s
Train Epoch: 686 [40960/90000 (45%)]	Loss: -10.0901	Cost: 10.90s
Train Epoch: 686 [61440/90000 (68%)]	Loss: -9.8709	Cost: 10.07s
Train Epoch: 686 [81920/90000 (91%)]	Loss: -9.8164	Cost: 9.95s
Train Epoch: 686 	Average Loss: -9.6047
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8973

Learning rate: 0.00017528745774925177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 687 [0/90000 (0%)]	Loss: -4.8520	Cost: 29.67s
Train Epoch: 687 [20480/90000 (23%)]	Loss: -9.7868	Cost: 9.62s
Train Epoch: 687 [40960/90000 (45%)]	Loss: -10.0267	Cost: 10.96s
Train Epoch: 687 [61440/90000 (68%)]	Loss: -9.6991	Cost: 9.41s
Train Epoch: 687 [81920/90000 (91%)]	Loss: -9.7771	Cost: 9.63s
Train Epoch: 687 	Average Loss: -9.3999
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9346

Learning rate: 0.0001752184937064112
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 688 [0/90000 (0%)]	Loss: -4.8615	Cost: 29.45s
Train Epoch: 688 [20480/90000 (23%)]	Loss: -10.0064	Cost: 9.59s
Train Epoch: 688 [40960/90000 (45%)]	Loss: -10.2776	Cost: 11.02s
Train Epoch: 688 [61440/90000 (68%)]	Loss: -9.8520	Cost: 9.39s
Train Epoch: 688 [81920/90000 (91%)]	Loss: -9.9119	Cost: 9.89s
Train Epoch: 688 	Average Loss: -9.5641
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9968

Learning rate: 0.00017514944717726965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 689 [0/90000 (0%)]	Loss: -4.8236	Cost: 29.59s
Train Epoch: 689 [20480/90000 (23%)]	Loss: -10.1977	Cost: 9.64s
Train Epoch: 689 [40960/90000 (45%)]	Loss: -10.4243	Cost: 11.06s
Train Epoch: 689 [61440/90000 (68%)]	Loss: -10.1828	Cost: 9.40s
Train Epoch: 689 [81920/90000 (91%)]	Loss: -10.1914	Cost: 10.06s
Train Epoch: 689 	Average Loss: -9.7456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2041

Learning rate: 0.00017508031823754513
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 690 [0/90000 (0%)]	Loss: -4.6690	Cost: 29.76s
Train Epoch: 690 [20480/90000 (23%)]	Loss: -9.9793	Cost: 9.51s
Train Epoch: 690 [40960/90000 (45%)]	Loss: -10.0443	Cost: 11.05s
Train Epoch: 690 [61440/90000 (68%)]	Loss: -9.7631	Cost: 9.38s
Train Epoch: 690 [81920/90000 (91%)]	Loss: -9.6599	Cost: 9.90s
Train Epoch: 690 	Average Loss: -9.5425
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7736

Learning rate: 0.000175011106963046
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 691 [0/90000 (0%)]	Loss: -4.9529	Cost: 29.40s
Train Epoch: 691 [20480/90000 (23%)]	Loss: -9.5903	Cost: 9.61s
Train Epoch: 691 [40960/90000 (45%)]	Loss: -10.0026	Cost: 10.99s
Train Epoch: 691 [61440/90000 (68%)]	Loss: -9.7539	Cost: 9.40s
Train Epoch: 691 [81920/90000 (91%)]	Loss: -9.6729	Cost: 10.02s
Train Epoch: 691 	Average Loss: -9.3920
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8830

Learning rate: 0.00017494181342967086
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 692 [0/90000 (0%)]	Loss: -4.6050	Cost: 29.59s
Train Epoch: 692 [20480/90000 (23%)]	Loss: -10.0495	Cost: 9.58s
Train Epoch: 692 [40960/90000 (45%)]	Loss: -10.3590	Cost: 11.09s
Train Epoch: 692 [61440/90000 (68%)]	Loss: -10.1540	Cost: 9.39s
Train Epoch: 692 [81920/90000 (91%)]	Loss: -9.7371	Cost: 9.87s
Train Epoch: 692 	Average Loss: -9.6680
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0077

Learning rate: 0.00017487243771340864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 693 [0/90000 (0%)]	Loss: -5.1938	Cost: 29.58s
Train Epoch: 693 [20480/90000 (23%)]	Loss: -10.0130	Cost: 9.59s
Train Epoch: 693 [40960/90000 (45%)]	Loss: -10.2851	Cost: 10.70s
Train Epoch: 693 [61440/90000 (68%)]	Loss: -10.1797	Cost: 9.42s
Train Epoch: 693 [81920/90000 (91%)]	Loss: -9.8136	Cost: 9.70s
Train Epoch: 693 	Average Loss: -9.7223
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9665

Learning rate: 0.00017480297989033827
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 694 [0/90000 (0%)]	Loss: -5.6140	Cost: 29.62s
Train Epoch: 694 [20480/90000 (23%)]	Loss: -9.8717	Cost: 9.60s
Train Epoch: 694 [40960/90000 (45%)]	Loss: -10.2474	Cost: 11.09s
Train Epoch: 694 [61440/90000 (68%)]	Loss: -10.1768	Cost: 9.63s
Train Epoch: 694 [81920/90000 (91%)]	Loss: -10.1873	Cost: 10.58s
Train Epoch: 694 	Average Loss: -9.7613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1398

Learning rate: 0.00017473344003662877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 695 [0/90000 (0%)]	Loss: -4.8699	Cost: 29.62s
Train Epoch: 695 [20480/90000 (23%)]	Loss: -10.0015	Cost: 9.61s
Train Epoch: 695 [40960/90000 (45%)]	Loss: -10.3581	Cost: 10.88s
Train Epoch: 695 [61440/90000 (68%)]	Loss: -10.0343	Cost: 9.43s
Train Epoch: 695 [81920/90000 (91%)]	Loss: -9.3922	Cost: 9.95s
Train Epoch: 695 	Average Loss: -9.6586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4900

Learning rate: 0.00017466381822853915
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 696 [0/90000 (0%)]	Loss: -3.7878	Cost: 29.04s
Train Epoch: 696 [20480/90000 (23%)]	Loss: -9.5483	Cost: 9.64s
Train Epoch: 696 [40960/90000 (45%)]	Loss: -9.9167	Cost: 10.73s
Train Epoch: 696 [61440/90000 (68%)]	Loss: -9.8524	Cost: 9.41s
Train Epoch: 696 [81920/90000 (91%)]	Loss: -9.8738	Cost: 9.73s
Train Epoch: 696 	Average Loss: -9.4008
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9704

Learning rate: 0.00017459411454241825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 697 [0/90000 (0%)]	Loss: -4.8296	Cost: 29.44s
Train Epoch: 697 [20480/90000 (23%)]	Loss: -9.9553	Cost: 9.59s
Train Epoch: 697 [40960/90000 (45%)]	Loss: -10.3463	Cost: 11.09s
Train Epoch: 697 [61440/90000 (68%)]	Loss: -10.1589	Cost: 9.39s
Train Epoch: 697 [81920/90000 (91%)]	Loss: -10.1374	Cost: 9.96s
Train Epoch: 697 	Average Loss: -9.7818
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1565

Learning rate: 0.00017452432905470464
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 698 [0/90000 (0%)]	Loss: -4.5795	Cost: 29.29s
Train Epoch: 698 [20480/90000 (23%)]	Loss: -10.2228	Cost: 9.61s
Train Epoch: 698 [40960/90000 (45%)]	Loss: -10.5655	Cost: 11.26s
Train Epoch: 698 [61440/90000 (68%)]	Loss: -10.3370	Cost: 9.37s
Train Epoch: 698 [81920/90000 (91%)]	Loss: -10.1990	Cost: 9.56s
Train Epoch: 698 	Average Loss: -9.8878
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2455

Learning rate: 0.00017445446184192676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 699 [0/90000 (0%)]	Loss: -5.1839	Cost: 29.17s
Train Epoch: 699 [20480/90000 (23%)]	Loss: -10.1111	Cost: 9.62s
Train Epoch: 699 [40960/90000 (45%)]	Loss: -10.4477	Cost: 11.01s
Train Epoch: 699 [61440/90000 (68%)]	Loss: -10.0600	Cost: 9.76s
Train Epoch: 699 [81920/90000 (91%)]	Loss: -10.1063	Cost: 10.12s
Train Epoch: 699 	Average Loss: -9.8766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2255

Learning rate: 0.0001743845129807025
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 700 [0/90000 (0%)]	Loss: -5.0237	Cost: 30.23s
Train Epoch: 700 [20480/90000 (23%)]	Loss: -10.1705	Cost: 9.61s
Train Epoch: 700 [40960/90000 (45%)]	Loss: -10.3129	Cost: 11.06s
Train Epoch: 700 [61440/90000 (68%)]	Loss: -10.1460	Cost: 9.39s
Train Epoch: 700 [81920/90000 (91%)]	Loss: -10.1874	Cost: 9.92s
Train Epoch: 700 	Average Loss: -9.8013
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1558

Saving model as model.pt_e700 & waveforms_supplementary.hdf5_e700
Learning rate: 0.00017431448254773944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 701 [0/90000 (0%)]	Loss: -4.1000	Cost: 29.26s
Train Epoch: 701 [20480/90000 (23%)]	Loss: -10.0560	Cost: 9.58s
Train Epoch: 701 [40960/90000 (45%)]	Loss: -10.3170	Cost: 11.04s
Train Epoch: 701 [61440/90000 (68%)]	Loss: -10.1581	Cost: 9.43s
Train Epoch: 701 [81920/90000 (91%)]	Loss: -10.1990	Cost: 10.23s
Train Epoch: 701 	Average Loss: -9.8175
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2367

Learning rate: 0.00017424437061983443
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 702 [0/90000 (0%)]	Loss: -5.4007	Cost: 29.53s
Train Epoch: 702 [20480/90000 (23%)]	Loss: -10.1729	Cost: 9.95s
Train Epoch: 702 [40960/90000 (45%)]	Loss: -10.4457	Cost: 10.49s
Train Epoch: 702 [61440/90000 (68%)]	Loss: -10.1207	Cost: 9.45s
Train Epoch: 702 [81920/90000 (91%)]	Loss: -10.2191	Cost: 9.83s
Train Epoch: 702 	Average Loss: -9.9253
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9694

Learning rate: 0.00017417417727387391
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 703 [0/90000 (0%)]	Loss: -4.8381	Cost: 30.00s
Train Epoch: 703 [20480/90000 (23%)]	Loss: -9.6746	Cost: 9.58s
Train Epoch: 703 [40960/90000 (45%)]	Loss: -9.8569	Cost: 11.21s
Train Epoch: 703 [61440/90000 (68%)]	Loss: -10.0092	Cost: 9.41s
Train Epoch: 703 [81920/90000 (91%)]	Loss: -10.0265	Cost: 9.95s
Train Epoch: 703 	Average Loss: -9.5637
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1929

Learning rate: 0.00017410390258683342
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 704 [0/90000 (0%)]	Loss: -5.1786	Cost: 29.29s
Train Epoch: 704 [20480/90000 (23%)]	Loss: -10.2041	Cost: 9.57s
Train Epoch: 704 [40960/90000 (45%)]	Loss: -10.2631	Cost: 11.23s
Train Epoch: 704 [61440/90000 (68%)]	Loss: -10.1935	Cost: 9.42s
Train Epoch: 704 [81920/90000 (91%)]	Loss: -10.2425	Cost: 10.10s
Train Epoch: 704 	Average Loss: -9.8317
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2366

Learning rate: 0.0001740335466357778
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 705 [0/90000 (0%)]	Loss: -5.2087	Cost: 30.13s
Train Epoch: 705 [20480/90000 (23%)]	Loss: -10.1554	Cost: 9.61s
Train Epoch: 705 [40960/90000 (45%)]	Loss: -10.2959	Cost: 11.03s
Train Epoch: 705 [61440/90000 (68%)]	Loss: -10.1680	Cost: 9.42s
Train Epoch: 705 [81920/90000 (91%)]	Loss: -10.0350	Cost: 9.57s
Train Epoch: 705 	Average Loss: -9.8629
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0782

Learning rate: 0.00017396310949786096
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 706 [0/90000 (0%)]	Loss: -4.6214	Cost: 29.38s
Train Epoch: 706 [20480/90000 (23%)]	Loss: -10.0533	Cost: 9.60s
Train Epoch: 706 [40960/90000 (45%)]	Loss: -10.4913	Cost: 10.88s
Train Epoch: 706 [61440/90000 (68%)]	Loss: -10.2248	Cost: 9.38s
Train Epoch: 706 [81920/90000 (91%)]	Loss: -10.3699	Cost: 9.61s
Train Epoch: 706 	Average Loss: -9.8674
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1958

Learning rate: 0.0001738925912503259
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 707 [0/90000 (0%)]	Loss: -5.3439	Cost: 30.39s
Train Epoch: 707 [20480/90000 (23%)]	Loss: -9.9064	Cost: 9.58s
Train Epoch: 707 [40960/90000 (45%)]	Loss: -10.3537	Cost: 11.11s
Train Epoch: 707 [61440/90000 (68%)]	Loss: -10.0890	Cost: 9.47s
Train Epoch: 707 [81920/90000 (91%)]	Loss: -10.3064	Cost: 9.55s
Train Epoch: 707 	Average Loss: -9.8269
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2405

Learning rate: 0.00017382199197050444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 708 [0/90000 (0%)]	Loss: -5.0598	Cost: 29.32s
Train Epoch: 708 [20480/90000 (23%)]	Loss: -10.2168	Cost: 9.61s
Train Epoch: 708 [40960/90000 (45%)]	Loss: -10.4239	Cost: 11.08s
Train Epoch: 708 [61440/90000 (68%)]	Loss: -10.2986	Cost: 9.41s
Train Epoch: 708 [81920/90000 (91%)]	Loss: -10.2378	Cost: 9.93s
Train Epoch: 708 	Average Loss: -9.9174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3040

Learning rate: 0.00017375131173581737
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 709 [0/90000 (0%)]	Loss: -5.6639	Cost: 29.33s
Train Epoch: 709 [20480/90000 (23%)]	Loss: -10.2531	Cost: 9.57s
Train Epoch: 709 [40960/90000 (45%)]	Loss: -10.2392	Cost: 11.33s
Train Epoch: 709 [61440/90000 (68%)]	Loss: -10.1449	Cost: 9.53s
Train Epoch: 709 [81920/90000 (91%)]	Loss: -9.9549	Cost: 9.82s
Train Epoch: 709 	Average Loss: -9.8719
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2556

Learning rate: 0.00017368055062377434
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 710 [0/90000 (0%)]	Loss: -5.4053	Cost: 30.48s
Train Epoch: 710 [20480/90000 (23%)]	Loss: -9.9166	Cost: 9.60s
Train Epoch: 710 [40960/90000 (45%)]	Loss: -10.1903	Cost: 11.05s
Train Epoch: 710 [61440/90000 (68%)]	Loss: -9.8837	Cost: 9.42s
Train Epoch: 710 [81920/90000 (91%)]	Loss: -9.9108	Cost: 9.69s
Train Epoch: 710 	Average Loss: -9.6328
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0548

Learning rate: 0.00017360970871197346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 711 [0/90000 (0%)]	Loss: -4.8857	Cost: 29.40s
Train Epoch: 711 [20480/90000 (23%)]	Loss: -10.2380	Cost: 9.67s
Train Epoch: 711 [40960/90000 (45%)]	Loss: -8.5053	Cost: 10.72s
Train Epoch: 711 [61440/90000 (68%)]	Loss: -8.1924	Cost: 9.61s
Train Epoch: 711 [81920/90000 (91%)]	Loss: -8.2434	Cost: 9.69s
Train Epoch: 711 	Average Loss: -8.6233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1766

Learning rate: 0.0001735387860781016
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 712 [0/90000 (0%)]	Loss: -3.8539	Cost: 51.67s
Train Epoch: 712 [20480/90000 (23%)]	Loss: -9.3913	Cost: 9.59s
Train Epoch: 712 [40960/90000 (45%)]	Loss: -9.9984	Cost: 12.98s
Train Epoch: 712 [61440/90000 (68%)]	Loss: -9.7679	Cost: 10.52s
Train Epoch: 712 [81920/90000 (91%)]	Loss: -9.8642	Cost: 18.47s
Train Epoch: 712 	Average Loss: -9.2928
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1573

Learning rate: 0.00017346778279993415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 713 [0/90000 (0%)]	Loss: -5.0072	Cost: 45.13s
Train Epoch: 713 [20480/90000 (23%)]	Loss: -10.2817	Cost: 9.63s
Train Epoch: 713 [40960/90000 (45%)]	Loss: -10.4306	Cost: 16.36s
Train Epoch: 713 [61440/90000 (68%)]	Loss: -9.8404	Cost: 13.22s
Train Epoch: 713 [81920/90000 (91%)]	Loss: -9.6811	Cost: 15.29s
Train Epoch: 713 	Average Loss: -9.6875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0143

Learning rate: 0.0001733966989553349
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 714 [0/90000 (0%)]	Loss: -4.9614	Cost: 45.13s
Train Epoch: 714 [20480/90000 (23%)]	Loss: -10.3318	Cost: 13.25s
Train Epoch: 714 [40960/90000 (45%)]	Loss: -10.4969	Cost: 19.97s
Train Epoch: 714 [61440/90000 (68%)]	Loss: -10.2672	Cost: 12.31s
Train Epoch: 714 [81920/90000 (91%)]	Loss: -10.5387	Cost: 25.51s
Train Epoch: 714 	Average Loss: -9.9319
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4425

Learning rate: 0.00017332553462225602
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 715 [0/90000 (0%)]	Loss: -5.1106	Cost: 78.64s
Train Epoch: 715 [20480/90000 (23%)]	Loss: -10.3961	Cost: 10.55s
Train Epoch: 715 [40960/90000 (45%)]	Loss: -10.3748	Cost: 12.78s
Train Epoch: 715 [61440/90000 (68%)]	Loss: -10.2498	Cost: 9.69s
Train Epoch: 715 [81920/90000 (91%)]	Loss: -10.4018	Cost: 9.24s
Train Epoch: 715 	Average Loss: -9.9508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4488

Learning rate: 0.0001732542898787379
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 716 [0/90000 (0%)]	Loss: -5.1861	Cost: 28.35s
Train Epoch: 716 [20480/90000 (23%)]	Loss: -10.6955	Cost: 9.82s
Train Epoch: 716 [40960/90000 (45%)]	Loss: -10.6995	Cost: 10.78s
Train Epoch: 716 [61440/90000 (68%)]	Loss: -10.3185	Cost: 9.48s
Train Epoch: 716 [81920/90000 (91%)]	Loss: -10.2696	Cost: 9.14s
Train Epoch: 716 	Average Loss: -10.0615
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4183

Learning rate: 0.00017318296480290914
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 717 [0/90000 (0%)]	Loss: -5.5982	Cost: 29.80s
Train Epoch: 717 [20480/90000 (23%)]	Loss: -10.4291	Cost: 9.93s
Train Epoch: 717 [40960/90000 (45%)]	Loss: -10.6976	Cost: 10.50s
Train Epoch: 717 [61440/90000 (68%)]	Loss: -10.4631	Cost: 9.52s
Train Epoch: 717 [81920/90000 (91%)]	Loss: -10.4244	Cost: 9.16s
Train Epoch: 717 	Average Loss: -10.1299
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5001

Learning rate: 0.00017311155947298643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 718 [0/90000 (0%)]	Loss: -5.2168	Cost: 29.21s
Train Epoch: 718 [20480/90000 (23%)]	Loss: -10.6612	Cost: 9.76s
Train Epoch: 718 [40960/90000 (45%)]	Loss: -10.5676	Cost: 10.22s
Train Epoch: 718 [61440/90000 (68%)]	Loss: -10.4036	Cost: 9.44s
Train Epoch: 718 [81920/90000 (91%)]	Loss: -10.4625	Cost: 9.25s
Train Epoch: 718 	Average Loss: -10.1669
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4238

Learning rate: 0.0001730400739672745
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 719 [0/90000 (0%)]	Loss: -5.4900	Cost: 29.33s
Train Epoch: 719 [20480/90000 (23%)]	Loss: -10.8473	Cost: 9.76s
Train Epoch: 719 [40960/90000 (45%)]	Loss: -10.8472	Cost: 10.55s
Train Epoch: 719 [61440/90000 (68%)]	Loss: -10.6899	Cost: 9.59s
Train Epoch: 719 [81920/90000 (91%)]	Loss: -10.4508	Cost: 9.22s
Train Epoch: 719 	Average Loss: -10.2562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5707

Learning rate: 0.00017296850836416594
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 720 [0/90000 (0%)]	Loss: -5.8973	Cost: 30.10s
Train Epoch: 720 [20480/90000 (23%)]	Loss: -10.5770	Cost: 9.82s
Train Epoch: 720 [40960/90000 (45%)]	Loss: -10.7351	Cost: 10.58s
Train Epoch: 720 [61440/90000 (68%)]	Loss: -10.5834	Cost: 9.45s
Train Epoch: 720 [81920/90000 (91%)]	Loss: -10.6246	Cost: 9.20s
Train Epoch: 720 	Average Loss: -10.2204
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6102

Learning rate: 0.0001728968627421412
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 721 [0/90000 (0%)]	Loss: -6.0516	Cost: 29.57s
Train Epoch: 721 [20480/90000 (23%)]	Loss: -10.5368	Cost: 10.18s
Train Epoch: 721 [40960/90000 (45%)]	Loss: -10.7198	Cost: 9.83s
Train Epoch: 721 [61440/90000 (68%)]	Loss: -10.3471	Cost: 9.59s
Train Epoch: 721 [81920/90000 (91%)]	Loss: -10.2463	Cost: 9.22s
Train Epoch: 721 	Average Loss: -10.1276
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3806

Learning rate: 0.0001728251371797685
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 722 [0/90000 (0%)]	Loss: -5.3150	Cost: 29.91s
Train Epoch: 722 [20480/90000 (23%)]	Loss: -10.4417	Cost: 10.16s
Train Epoch: 722 [40960/90000 (45%)]	Loss: -10.6434	Cost: 9.67s
Train Epoch: 722 [61440/90000 (68%)]	Loss: -10.5431	Cost: 9.42s
Train Epoch: 722 [81920/90000 (91%)]	Loss: -10.4174	Cost: 9.23s
Train Epoch: 722 	Average Loss: -10.1574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4490

Learning rate: 0.00017275333175570374
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 723 [0/90000 (0%)]	Loss: -5.1725	Cost: 29.72s
Train Epoch: 723 [20480/90000 (23%)]	Loss: -10.6302	Cost: 9.89s
Train Epoch: 723 [40960/90000 (45%)]	Loss: -9.4194	Cost: 10.50s
Train Epoch: 723 [61440/90000 (68%)]	Loss: -9.6340	Cost: 9.69s
Train Epoch: 723 [81920/90000 (91%)]	Loss: -9.7381	Cost: 9.17s
Train Epoch: 723 	Average Loss: -9.6534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9496

Learning rate: 0.00017268144654869033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 724 [0/90000 (0%)]	Loss: -5.8696	Cost: 29.16s
Train Epoch: 724 [20480/90000 (23%)]	Loss: -10.1785	Cost: 9.72s
Train Epoch: 724 [40960/90000 (45%)]	Loss: -10.5222	Cost: 10.48s
Train Epoch: 724 [61440/90000 (68%)]	Loss: -10.3007	Cost: 9.48s
Train Epoch: 724 [81920/90000 (91%)]	Loss: -9.4226	Cost: 9.22s
Train Epoch: 724 	Average Loss: -9.7760
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8998

Learning rate: 0.00017260948163755924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 725 [0/90000 (0%)]	Loss: -4.1256	Cost: 28.55s
Train Epoch: 725 [20480/90000 (23%)]	Loss: -8.9236	Cost: 9.82s
Train Epoch: 725 [40960/90000 (45%)]	Loss: -9.4124	Cost: 10.91s
Train Epoch: 725 [61440/90000 (68%)]	Loss: -9.8504	Cost: 9.63s
Train Epoch: 725 [81920/90000 (91%)]	Loss: -9.9371	Cost: 9.28s
Train Epoch: 725 	Average Loss: -9.1821
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1727

Learning rate: 0.0001725374371012288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 726 [0/90000 (0%)]	Loss: -5.3856	Cost: 28.50s
Train Epoch: 726 [20480/90000 (23%)]	Loss: -10.0319	Cost: 9.82s
Train Epoch: 726 [40960/90000 (45%)]	Loss: -10.4978	Cost: 10.51s
Train Epoch: 726 [61440/90000 (68%)]	Loss: -10.3341	Cost: 9.40s
Train Epoch: 726 [81920/90000 (91%)]	Loss: -10.4607	Cost: 9.23s
Train Epoch: 726 	Average Loss: -10.0172
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5216

Learning rate: 0.0001724653130187047
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 727 [0/90000 (0%)]	Loss: -5.8466	Cost: 29.53s
Train Epoch: 727 [20480/90000 (23%)]	Loss: -10.5416	Cost: 9.75s
Train Epoch: 727 [40960/90000 (45%)]	Loss: -10.9906	Cost: 10.48s
Train Epoch: 727 [61440/90000 (68%)]	Loss: -10.7877	Cost: 9.65s
Train Epoch: 727 [81920/90000 (91%)]	Loss: -10.7007	Cost: 9.24s
Train Epoch: 727 	Average Loss: -10.3773
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6556

Learning rate: 0.00017239310946907984
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 728 [0/90000 (0%)]	Loss: -5.5272	Cost: 29.35s
Train Epoch: 728 [20480/90000 (23%)]	Loss: -10.7554	Cost: 9.79s
Train Epoch: 728 [40960/90000 (45%)]	Loss: -10.8414	Cost: 9.97s
Train Epoch: 728 [61440/90000 (68%)]	Loss: -10.6953	Cost: 9.42s
Train Epoch: 728 [81920/90000 (91%)]	Loss: -10.7897	Cost: 9.25s
Train Epoch: 728 	Average Loss: -10.3698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8536

Learning rate: 0.00017232082653153424
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 729 [0/90000 (0%)]	Loss: -5.3408	Cost: 29.25s
Train Epoch: 729 [20480/90000 (23%)]	Loss: -10.7149	Cost: 9.84s
Train Epoch: 729 [40960/90000 (45%)]	Loss: -11.1150	Cost: 10.99s
Train Epoch: 729 [61440/90000 (68%)]	Loss: -10.8790	Cost: 9.58s
Train Epoch: 729 [81920/90000 (91%)]	Loss: -10.7926	Cost: 9.17s
Train Epoch: 729 	Average Loss: -10.4616
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8271

Learning rate: 0.000172248464285335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 730 [0/90000 (0%)]	Loss: -5.5946	Cost: 29.04s
Train Epoch: 730 [20480/90000 (23%)]	Loss: -10.9893	Cost: 9.75s
Train Epoch: 730 [40960/90000 (45%)]	Loss: -11.2742	Cost: 10.64s
Train Epoch: 730 [61440/90000 (68%)]	Loss: -10.7874	Cost: 9.53s
Train Epoch: 730 [81920/90000 (91%)]	Loss: -10.6532	Cost: 9.07s
Train Epoch: 730 	Average Loss: -10.5062
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8358

Learning rate: 0.00017217602280983625
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 731 [0/90000 (0%)]	Loss: -5.5432	Cost: 29.55s
Train Epoch: 731 [20480/90000 (23%)]	Loss: -10.8312	Cost: 9.84s
Train Epoch: 731 [40960/90000 (45%)]	Loss: -10.9380	Cost: 10.62s
Train Epoch: 731 [61440/90000 (68%)]	Loss: -10.8695	Cost: 9.59s
Train Epoch: 731 [81920/90000 (91%)]	Loss: -10.9552	Cost: 9.24s
Train Epoch: 731 	Average Loss: -10.4916
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8714

Learning rate: 0.0001721035021844789
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 732 [0/90000 (0%)]	Loss: -5.8863	Cost: 29.99s
Train Epoch: 732 [20480/90000 (23%)]	Loss: -10.9034	Cost: 9.80s
Train Epoch: 732 [40960/90000 (45%)]	Loss: -11.2177	Cost: 10.26s
Train Epoch: 732 [61440/90000 (68%)]	Loss: -10.8123	Cost: 9.42s
Train Epoch: 732 [81920/90000 (91%)]	Loss: -10.6442	Cost: 9.18s
Train Epoch: 732 	Average Loss: -10.5423
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6092

Learning rate: 0.00017203090248879072
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 733 [0/90000 (0%)]	Loss: -4.9675	Cost: 28.44s
Train Epoch: 733 [20480/90000 (23%)]	Loss: -10.9015	Cost: 9.77s
Train Epoch: 733 [40960/90000 (45%)]	Loss: -11.0470	Cost: 10.88s
Train Epoch: 733 [61440/90000 (68%)]	Loss: -10.7647	Cost: 9.69s
Train Epoch: 733 [81920/90000 (91%)]	Loss: -10.8049	Cost: 9.46s
Train Epoch: 733 	Average Loss: -10.4875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8096

Learning rate: 0.00017195822380238618
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 734 [0/90000 (0%)]	Loss: -5.7558	Cost: 29.57s
Train Epoch: 734 [20480/90000 (23%)]	Loss: -11.0591	Cost: 9.79s
Train Epoch: 734 [40960/90000 (45%)]	Loss: -11.2698	Cost: 10.29s
Train Epoch: 734 [61440/90000 (68%)]	Loss: -10.8033	Cost: 9.42s
Train Epoch: 734 [81920/90000 (91%)]	Loss: -10.6341	Cost: 9.23s
Train Epoch: 734 	Average Loss: -10.5558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6062

Learning rate: 0.00017188546620496638
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 735 [0/90000 (0%)]	Loss: -6.1629	Cost: 28.90s
Train Epoch: 735 [20480/90000 (23%)]	Loss: -10.7453	Cost: 9.84s
Train Epoch: 735 [40960/90000 (45%)]	Loss: -10.6924	Cost: 10.29s
Train Epoch: 735 [61440/90000 (68%)]	Loss: -10.5530	Cost: 9.60s
Train Epoch: 735 [81920/90000 (91%)]	Loss: -10.5737	Cost: 9.24s
Train Epoch: 735 	Average Loss: -10.2763
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7421

Learning rate: 0.00017181262977631893
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 736 [0/90000 (0%)]	Loss: -5.9585	Cost: 29.40s
Train Epoch: 736 [20480/90000 (23%)]	Loss: -10.7022	Cost: 9.72s
Train Epoch: 736 [40960/90000 (45%)]	Loss: -10.9378	Cost: 10.62s
Train Epoch: 736 [61440/90000 (68%)]	Loss: -10.8249	Cost: 9.53s
Train Epoch: 736 [81920/90000 (91%)]	Loss: -10.8042	Cost: 9.21s
Train Epoch: 736 	Average Loss: -10.4763
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6908

Learning rate: 0.00017173971459631793
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 737 [0/90000 (0%)]	Loss: -5.4416	Cost: 29.66s
Train Epoch: 737 [20480/90000 (23%)]	Loss: -11.0088	Cost: 9.82s
Train Epoch: 737 [40960/90000 (45%)]	Loss: -11.0514	Cost: 10.10s
Train Epoch: 737 [61440/90000 (68%)]	Loss: -10.9911	Cost: 9.59s
Train Epoch: 737 [81920/90000 (91%)]	Loss: -10.9408	Cost: 9.32s
Train Epoch: 737 	Average Loss: -10.6008
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9094

Learning rate: 0.00017166672074492376
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 738 [0/90000 (0%)]	Loss: -5.9600	Cost: 29.31s
Train Epoch: 738 [20480/90000 (23%)]	Loss: -11.0758	Cost: 9.75s
Train Epoch: 738 [40960/90000 (45%)]	Loss: -11.2286	Cost: 10.83s
Train Epoch: 738 [61440/90000 (68%)]	Loss: -10.9511	Cost: 9.48s
Train Epoch: 738 [81920/90000 (91%)]	Loss: -10.9231	Cost: 9.30s
Train Epoch: 738 	Average Loss: -10.5986
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8670

Learning rate: 0.00017159364830218317
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 739 [0/90000 (0%)]	Loss: -6.0239	Cost: 28.86s
Train Epoch: 739 [20480/90000 (23%)]	Loss: -11.0539	Cost: 9.73s
Train Epoch: 739 [40960/90000 (45%)]	Loss: -11.2521	Cost: 10.81s
Train Epoch: 739 [61440/90000 (68%)]	Loss: -11.1989	Cost: 9.57s
Train Epoch: 739 [81920/90000 (91%)]	Loss: -11.1069	Cost: 9.17s
Train Epoch: 739 	Average Loss: -10.7481
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9603

Learning rate: 0.00017152049734822907
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 740 [0/90000 (0%)]	Loss: -5.2622	Cost: 28.79s
Train Epoch: 740 [20480/90000 (23%)]	Loss: -10.9171	Cost: 9.68s
Train Epoch: 740 [40960/90000 (45%)]	Loss: -11.1621	Cost: 10.77s
Train Epoch: 740 [61440/90000 (68%)]	Loss: -11.0038	Cost: 9.92s
Train Epoch: 740 [81920/90000 (91%)]	Loss: -10.8949	Cost: 9.29s
Train Epoch: 740 	Average Loss: -10.5614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8509

Learning rate: 0.0001714472679632804
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 741 [0/90000 (0%)]	Loss: -5.8133	Cost: 29.88s
Train Epoch: 741 [20480/90000 (23%)]	Loss: -10.6804	Cost: 9.82s
Train Epoch: 741 [40960/90000 (45%)]	Loss: -11.1271	Cost: 10.80s
Train Epoch: 741 [61440/90000 (68%)]	Loss: -10.6484	Cost: 9.75s
Train Epoch: 741 [81920/90000 (91%)]	Loss: -10.7836	Cost: 9.31s
Train Epoch: 741 	Average Loss: -10.4757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8388

Learning rate: 0.0001713739602276422
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 742 [0/90000 (0%)]	Loss: -5.7014	Cost: 28.97s
Train Epoch: 742 [20480/90000 (23%)]	Loss: -10.7972	Cost: 9.82s
Train Epoch: 742 [40960/90000 (45%)]	Loss: -11.2632	Cost: 10.54s
Train Epoch: 742 [61440/90000 (68%)]	Loss: -10.9958	Cost: 9.94s
Train Epoch: 742 [81920/90000 (91%)]	Loss: -10.9654	Cost: 9.27s
Train Epoch: 742 	Average Loss: -10.6585
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9816

Learning rate: 0.00017130057422170536
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 743 [0/90000 (0%)]	Loss: -6.1094	Cost: 29.26s
Train Epoch: 743 [20480/90000 (23%)]	Loss: -11.1902	Cost: 9.85s
Train Epoch: 743 [40960/90000 (45%)]	Loss: -11.2456	Cost: 10.48s
Train Epoch: 743 [61440/90000 (68%)]	Loss: -11.0638	Cost: 9.64s
Train Epoch: 743 [81920/90000 (91%)]	Loss: -10.9507	Cost: 9.16s
Train Epoch: 743 	Average Loss: -10.7104
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7464

Learning rate: 0.00017122711002594664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 744 [0/90000 (0%)]	Loss: -5.8791	Cost: 29.09s
Train Epoch: 744 [20480/90000 (23%)]	Loss: -10.9537	Cost: 9.81s
Train Epoch: 744 [40960/90000 (45%)]	Loss: -11.2891	Cost: 10.59s
Train Epoch: 744 [61440/90000 (68%)]	Loss: -10.9824	Cost: 9.45s
Train Epoch: 744 [81920/90000 (91%)]	Loss: -10.9407	Cost: 9.27s
Train Epoch: 744 	Average Loss: -10.6475
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3067

Learning rate: 0.0001711535677209286
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 745 [0/90000 (0%)]	Loss: -5.6709	Cost: 29.51s
Train Epoch: 745 [20480/90000 (23%)]	Loss: -10.2898	Cost: 9.84s
Train Epoch: 745 [40960/90000 (45%)]	Loss: -10.7404	Cost: 10.32s
Train Epoch: 745 [61440/90000 (68%)]	Loss: -10.7731	Cost: 9.63s
Train Epoch: 745 [81920/90000 (91%)]	Loss: -10.7851	Cost: 9.32s
Train Epoch: 745 	Average Loss: -10.2383
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8348

Learning rate: 0.0001710799473872993
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 746 [0/90000 (0%)]	Loss: -4.7929	Cost: 28.91s
Train Epoch: 746 [20480/90000 (23%)]	Loss: -9.4729	Cost: 9.72s
Train Epoch: 746 [40960/90000 (45%)]	Loss: -10.3180	Cost: 10.45s
Train Epoch: 746 [61440/90000 (68%)]	Loss: -10.2515	Cost: 9.38s
Train Epoch: 746 [81920/90000 (91%)]	Loss: -10.3844	Cost: 9.14s
Train Epoch: 746 	Average Loss: -9.7310
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7144

Learning rate: 0.00017100624910579252
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 747 [0/90000 (0%)]	Loss: -5.5260	Cost: 29.08s
Train Epoch: 747 [20480/90000 (23%)]	Loss: -10.9119	Cost: 9.77s
Train Epoch: 747 [40960/90000 (45%)]	Loss: -11.2944	Cost: 10.37s
Train Epoch: 747 [61440/90000 (68%)]	Loss: -10.9787	Cost: 9.68s
Train Epoch: 747 [81920/90000 (91%)]	Loss: -11.1598	Cost: 9.05s
Train Epoch: 747 	Average Loss: -10.6197
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0263

Learning rate: 0.00017093247295722741
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 748 [0/90000 (0%)]	Loss: -6.0690	Cost: 29.24s
Train Epoch: 748 [20480/90000 (23%)]	Loss: -11.0946	Cost: 9.75s
Train Epoch: 748 [40960/90000 (45%)]	Loss: -11.4080	Cost: 10.59s
Train Epoch: 748 [61440/90000 (68%)]	Loss: -10.9648	Cost: 9.39s
Train Epoch: 748 [81920/90000 (91%)]	Loss: -11.1932	Cost: 9.30s
Train Epoch: 748 	Average Loss: -10.8337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2299

Learning rate: 0.00017085861902250868
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 749 [0/90000 (0%)]	Loss: -5.9402	Cost: 28.83s
Train Epoch: 749 [20480/90000 (23%)]	Loss: -11.4267	Cost: 9.82s
Train Epoch: 749 [40960/90000 (45%)]	Loss: -11.5310	Cost: 10.65s
Train Epoch: 749 [61440/90000 (68%)]	Loss: -11.1729	Cost: 9.62s
Train Epoch: 749 [81920/90000 (91%)]	Loss: -11.1554	Cost: 9.21s
Train Epoch: 749 	Average Loss: -10.9342
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0914

Learning rate: 0.00017078468738262608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 750 [0/90000 (0%)]	Loss: -5.7706	Cost: 29.48s
Train Epoch: 750 [20480/90000 (23%)]	Loss: -11.2275	Cost: 9.84s
Train Epoch: 750 [40960/90000 (45%)]	Loss: -11.4249	Cost: 10.62s
Train Epoch: 750 [61440/90000 (68%)]	Loss: -11.0964	Cost: 9.45s
Train Epoch: 750 [81920/90000 (91%)]	Loss: -11.0285	Cost: 9.18s
Train Epoch: 750 	Average Loss: -10.8062
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9674

Saving model as model.pt_e750 & waveforms_supplementary.hdf5_e750
Learning rate: 0.0001707106781186548
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 751 [0/90000 (0%)]	Loss: -6.0171	Cost: 28.91s
Train Epoch: 751 [20480/90000 (23%)]	Loss: -11.0786	Cost: 9.81s
Train Epoch: 751 [40960/90000 (45%)]	Loss: -11.0461	Cost: 10.57s
Train Epoch: 751 [61440/90000 (68%)]	Loss: -10.7865	Cost: 9.52s
Train Epoch: 751 [81920/90000 (91%)]	Loss: -11.0142	Cost: 9.30s
Train Epoch: 751 	Average Loss: -10.6574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0571

Learning rate: 0.0001706365913117551
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 752 [0/90000 (0%)]	Loss: -5.8828	Cost: 29.30s
Train Epoch: 752 [20480/90000 (23%)]	Loss: -11.1418	Cost: 9.84s
Train Epoch: 752 [40960/90000 (45%)]	Loss: -11.4281	Cost: 10.59s
Train Epoch: 752 [61440/90000 (68%)]	Loss: -11.1004	Cost: 9.50s
Train Epoch: 752 [81920/90000 (91%)]	Loss: -11.2015	Cost: 9.20s
Train Epoch: 752 	Average Loss: -10.8452
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0537

Learning rate: 0.00017056242704317214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 753 [0/90000 (0%)]	Loss: -5.9408	Cost: 30.07s
Train Epoch: 753 [20480/90000 (23%)]	Loss: -11.2910	Cost: 9.83s
Train Epoch: 753 [40960/90000 (45%)]	Loss: -11.2847	Cost: 10.60s
Train Epoch: 753 [61440/90000 (68%)]	Loss: -11.2342	Cost: 9.48s
Train Epoch: 753 [81920/90000 (91%)]	Loss: -11.2549	Cost: 9.11s
Train Epoch: 753 	Average Loss: -10.8805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9796

Learning rate: 0.00017048818539423623
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 754 [0/90000 (0%)]	Loss: -6.1014	Cost: 29.13s
Train Epoch: 754 [20480/90000 (23%)]	Loss: -10.9077	Cost: 9.86s
Train Epoch: 754 [40960/90000 (45%)]	Loss: -11.2038	Cost: 10.34s
Train Epoch: 754 [61440/90000 (68%)]	Loss: -11.2320	Cost: 9.62s
Train Epoch: 754 [81920/90000 (91%)]	Loss: -10.9879	Cost: 9.19s
Train Epoch: 754 	Average Loss: -10.7838
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0464

Learning rate: 0.00017041386644636242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 755 [0/90000 (0%)]	Loss: -5.8622	Cost: 29.46s
Train Epoch: 755 [20480/90000 (23%)]	Loss: -11.3442	Cost: 9.78s
Train Epoch: 755 [40960/90000 (45%)]	Loss: -11.5245	Cost: 10.39s
Train Epoch: 755 [61440/90000 (68%)]	Loss: -11.0852	Cost: 9.47s
Train Epoch: 755 [81920/90000 (91%)]	Loss: -11.3042	Cost: 9.13s
Train Epoch: 755 	Average Loss: -10.8948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0817

Learning rate: 0.0001703394702810505
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 756 [0/90000 (0%)]	Loss: -6.1015	Cost: 28.23s
Train Epoch: 756 [20480/90000 (23%)]	Loss: -11.3015	Cost: 9.68s
Train Epoch: 756 [40960/90000 (45%)]	Loss: -11.5640	Cost: 10.75s
Train Epoch: 756 [61440/90000 (68%)]	Loss: -11.2301	Cost: 9.64s
Train Epoch: 756 [81920/90000 (91%)]	Loss: -11.1720	Cost: 9.24s
Train Epoch: 756 	Average Loss: -10.8867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1236

Learning rate: 0.00017026499697988504
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 757 [0/90000 (0%)]	Loss: -6.0279	Cost: 28.90s
Train Epoch: 757 [20480/90000 (23%)]	Loss: -11.4422	Cost: 9.78s
Train Epoch: 757 [40960/90000 (45%)]	Loss: -11.5744	Cost: 10.11s
Train Epoch: 757 [61440/90000 (68%)]	Loss: -11.3098	Cost: 9.48s
Train Epoch: 757 [81920/90000 (91%)]	Loss: -11.0435	Cost: 9.16s
Train Epoch: 757 	Average Loss: -10.9886
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0587

Learning rate: 0.00017019044662453512
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 758 [0/90000 (0%)]	Loss: -6.3893	Cost: 28.72s
Train Epoch: 758 [20480/90000 (23%)]	Loss: -11.4375	Cost: 9.71s
Train Epoch: 758 [40960/90000 (45%)]	Loss: -11.6227	Cost: 10.79s
Train Epoch: 758 [61440/90000 (68%)]	Loss: -11.2819	Cost: 9.55s
Train Epoch: 758 [81920/90000 (91%)]	Loss: -11.2422	Cost: 9.20s
Train Epoch: 758 	Average Loss: -11.0376
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0972

Learning rate: 0.00017011581929675433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 759 [0/90000 (0%)]	Loss: -5.7918	Cost: 29.01s
Train Epoch: 759 [20480/90000 (23%)]	Loss: -11.1275	Cost: 9.78s
Train Epoch: 759 [40960/90000 (45%)]	Loss: -11.3538	Cost: 10.58s
Train Epoch: 759 [61440/90000 (68%)]	Loss: -11.1140	Cost: 9.62s
Train Epoch: 759 [81920/90000 (91%)]	Loss: -11.1697	Cost: 9.15s
Train Epoch: 759 	Average Loss: -10.8588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1491

Learning rate: 0.00017004111507838072
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 760 [0/90000 (0%)]	Loss: -6.3726	Cost: 28.97s
Train Epoch: 760 [20480/90000 (23%)]	Loss: -11.0130	Cost: 9.72s
Train Epoch: 760 [40960/90000 (45%)]	Loss: -11.4119	Cost: 10.66s
Train Epoch: 760 [61440/90000 (68%)]	Loss: -11.3078	Cost: 9.48s
Train Epoch: 760 [81920/90000 (91%)]	Loss: -10.3701	Cost: 9.30s
Train Epoch: 760 	Average Loss: -10.6761
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3307

Learning rate: 0.00016996633405133666
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 761 [0/90000 (0%)]	Loss: -4.5840	Cost: 28.89s
Train Epoch: 761 [20480/90000 (23%)]	Loss: -10.4876	Cost: 9.71s
Train Epoch: 761 [40960/90000 (45%)]	Loss: -11.2698	Cost: 11.18s
Train Epoch: 761 [61440/90000 (68%)]	Loss: -11.0124	Cost: 9.65s
Train Epoch: 761 [81920/90000 (91%)]	Loss: -11.1479	Cost: 9.15s
Train Epoch: 761 	Average Loss: -10.4753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9462

Learning rate: 0.00016989147629762862
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 762 [0/90000 (0%)]	Loss: -5.7998	Cost: 29.55s
Train Epoch: 762 [20480/90000 (23%)]	Loss: -11.1671	Cost: 9.64s
Train Epoch: 762 [40960/90000 (45%)]	Loss: -11.7854	Cost: 10.40s
Train Epoch: 762 [61440/90000 (68%)]	Loss: -11.3778	Cost: 9.41s
Train Epoch: 762 [81920/90000 (91%)]	Loss: -11.3021	Cost: 9.28s
Train Epoch: 762 	Average Loss: -10.9528
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3241

Learning rate: 0.00016981654189934738
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 763 [0/90000 (0%)]	Loss: -6.7476	Cost: 29.51s
Train Epoch: 763 [20480/90000 (23%)]	Loss: -11.3419	Cost: 9.77s
Train Epoch: 763 [40960/90000 (45%)]	Loss: -11.7343	Cost: 10.19s
Train Epoch: 763 [61440/90000 (68%)]	Loss: -11.5683	Cost: 9.65s
Train Epoch: 763 [81920/90000 (91%)]	Loss: -11.3076	Cost: 9.25s
Train Epoch: 763 	Average Loss: -11.0883
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3267

Learning rate: 0.00016974153093866765
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 764 [0/90000 (0%)]	Loss: -6.1690	Cost: 28.39s
Train Epoch: 764 [20480/90000 (23%)]	Loss: -11.5299	Cost: 10.08s
Train Epoch: 764 [40960/90000 (45%)]	Loss: -11.6085	Cost: 10.21s
Train Epoch: 764 [61440/90000 (68%)]	Loss: -11.5358	Cost: 9.44s
Train Epoch: 764 [81920/90000 (91%)]	Loss: -11.4530	Cost: 9.19s
Train Epoch: 764 	Average Loss: -11.0923
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2203

Learning rate: 0.00016966644349784819
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 765 [0/90000 (0%)]	Loss: -5.5367	Cost: 29.31s
Train Epoch: 765 [20480/90000 (23%)]	Loss: -11.5222	Cost: 9.69s
Train Epoch: 765 [40960/90000 (45%)]	Loss: -11.5076	Cost: 10.57s
Train Epoch: 765 [61440/90000 (68%)]	Loss: -11.2434	Cost: 9.76s
Train Epoch: 765 [81920/90000 (91%)]	Loss: -11.3691	Cost: 9.13s
Train Epoch: 765 	Average Loss: -11.0213
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2277

Learning rate: 0.00016959127965923153
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 766 [0/90000 (0%)]	Loss: -5.9635	Cost: 28.14s
Train Epoch: 766 [20480/90000 (23%)]	Loss: -11.3996	Cost: 9.86s
Train Epoch: 766 [40960/90000 (45%)]	Loss: -11.6850	Cost: 10.80s
Train Epoch: 766 [61440/90000 (68%)]	Loss: -11.4899	Cost: 9.43s
Train Epoch: 766 [81920/90000 (91%)]	Loss: -11.3942	Cost: 9.27s
Train Epoch: 766 	Average Loss: -11.0745
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2594

Learning rate: 0.0001695160395052441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 767 [0/90000 (0%)]	Loss: -6.0709	Cost: 29.11s
Train Epoch: 767 [20480/90000 (23%)]	Loss: -11.5290	Cost: 9.84s
Train Epoch: 767 [40960/90000 (45%)]	Loss: -11.7410	Cost: 10.15s
Train Epoch: 767 [61440/90000 (68%)]	Loss: -11.4298	Cost: 9.58s
Train Epoch: 767 [81920/90000 (91%)]	Loss: -11.3798	Cost: 9.12s
Train Epoch: 767 	Average Loss: -11.0924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2864

Learning rate: 0.00016944072311839592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 768 [0/90000 (0%)]	Loss: -6.3013	Cost: 29.41s
Train Epoch: 768 [20480/90000 (23%)]	Loss: -11.6440	Cost: 9.86s
Train Epoch: 768 [40960/90000 (45%)]	Loss: -11.8665	Cost: 10.81s
Train Epoch: 768 [61440/90000 (68%)]	Loss: -11.4319	Cost: 10.10s
Train Epoch: 768 [81920/90000 (91%)]	Loss: -11.5389	Cost: 9.26s
Train Epoch: 768 	Average Loss: -11.1782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2408

Learning rate: 0.00016936533058128063
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 769 [0/90000 (0%)]	Loss: -6.2732	Cost: 29.33s
Train Epoch: 769 [20480/90000 (23%)]	Loss: -11.6176	Cost: 9.82s
Train Epoch: 769 [40960/90000 (45%)]	Loss: -11.8958	Cost: 10.96s
Train Epoch: 769 [61440/90000 (68%)]	Loss: -11.5690	Cost: 9.60s
Train Epoch: 769 [81920/90000 (91%)]	Loss: -11.3699	Cost: 9.25s
Train Epoch: 769 	Average Loss: -11.2260
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2111

Learning rate: 0.00016928986197657542
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 770 [0/90000 (0%)]	Loss: -6.1094	Cost: 28.91s
Train Epoch: 770 [20480/90000 (23%)]	Loss: -11.5098	Cost: 9.84s
Train Epoch: 770 [40960/90000 (45%)]	Loss: -11.6441	Cost: 10.60s
Train Epoch: 770 [61440/90000 (68%)]	Loss: -11.3951	Cost: 9.52s
Train Epoch: 770 [81920/90000 (91%)]	Loss: -11.5581	Cost: 9.13s
Train Epoch: 770 	Average Loss: -11.0489
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4173

Learning rate: 0.0001692143173870408
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 771 [0/90000 (0%)]	Loss: -6.2545	Cost: 28.92s
Train Epoch: 771 [20480/90000 (23%)]	Loss: -11.6319	Cost: 9.73s
Train Epoch: 771 [40960/90000 (45%)]	Loss: -11.9456	Cost: 10.59s
Train Epoch: 771 [61440/90000 (68%)]	Loss: -11.6067	Cost: 9.62s
Train Epoch: 771 [81920/90000 (91%)]	Loss: -11.4495	Cost: 9.19s
Train Epoch: 771 	Average Loss: -11.2390
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4064

Learning rate: 0.00016913869689552078
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 772 [0/90000 (0%)]	Loss: -5.9323	Cost: 29.27s
Train Epoch: 772 [20480/90000 (23%)]	Loss: -11.6254	Cost: 9.89s
Train Epoch: 772 [40960/90000 (45%)]	Loss: -11.7683	Cost: 10.34s
Train Epoch: 772 [61440/90000 (68%)]	Loss: -11.3377	Cost: 9.66s
Train Epoch: 772 [81920/90000 (91%)]	Loss: -11.4109	Cost: 9.14s
Train Epoch: 772 	Average Loss: -11.1389
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4176

Learning rate: 0.00016906300058494242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 773 [0/90000 (0%)]	Loss: -6.3538	Cost: 29.60s
Train Epoch: 773 [20480/90000 (23%)]	Loss: -11.2642	Cost: 9.63s
Train Epoch: 773 [40960/90000 (45%)]	Loss: -11.6187	Cost: 11.08s
Train Epoch: 773 [61440/90000 (68%)]	Loss: -11.4558	Cost: 9.58s
Train Epoch: 773 [81920/90000 (91%)]	Loss: -11.3737	Cost: 9.25s
Train Epoch: 773 	Average Loss: -11.1159
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2294

Learning rate: 0.00016898722853831607
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 774 [0/90000 (0%)]	Loss: -6.7245	Cost: 28.61s
Train Epoch: 774 [20480/90000 (23%)]	Loss: -11.6217	Cost: 9.80s
Train Epoch: 774 [40960/90000 (45%)]	Loss: -11.8576	Cost: 10.20s
Train Epoch: 774 [61440/90000 (68%)]	Loss: -11.7036	Cost: 9.52s
Train Epoch: 774 [81920/90000 (91%)]	Loss: -11.4550	Cost: 9.25s
Train Epoch: 774 	Average Loss: -11.2508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3828

Learning rate: 0.000168911380838735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 775 [0/90000 (0%)]	Loss: -5.9564	Cost: 29.81s
Train Epoch: 775 [20480/90000 (23%)]	Loss: -11.7274	Cost: 9.87s
Train Epoch: 775 [40960/90000 (45%)]	Loss: -11.7812	Cost: 10.21s
Train Epoch: 775 [61440/90000 (68%)]	Loss: -11.5104	Cost: 9.64s
Train Epoch: 775 [81920/90000 (91%)]	Loss: -11.5648	Cost: 9.16s
Train Epoch: 775 	Average Loss: -11.3276
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3011

Learning rate: 0.00016883545756937556
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 776 [0/90000 (0%)]	Loss: -6.7282	Cost: 29.76s
Train Epoch: 776 [20480/90000 (23%)]	Loss: -11.5409	Cost: 9.93s
Train Epoch: 776 [40960/90000 (45%)]	Loss: -11.6684	Cost: 10.48s
Train Epoch: 776 [61440/90000 (68%)]	Loss: -11.6382	Cost: 9.43s
Train Epoch: 776 [81920/90000 (91%)]	Loss: -11.6079	Cost: 9.34s
Train Epoch: 776 	Average Loss: -11.2538
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3612

Learning rate: 0.00016875945881349692
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 777 [0/90000 (0%)]	Loss: -5.8318	Cost: 29.14s
Train Epoch: 777 [20480/90000 (23%)]	Loss: -11.6012	Cost: 9.77s
Train Epoch: 777 [40960/90000 (45%)]	Loss: -11.9655	Cost: 11.16s
Train Epoch: 777 [61440/90000 (68%)]	Loss: -11.8232	Cost: 9.67s
Train Epoch: 777 [81920/90000 (91%)]	Loss: -11.8229	Cost: 9.20s
Train Epoch: 777 	Average Loss: -11.4817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5530

Learning rate: 0.00016868338465444101
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 778 [0/90000 (0%)]	Loss: -6.1798	Cost: 28.89s
Train Epoch: 778 [20480/90000 (23%)]	Loss: -11.5969	Cost: 9.73s
Train Epoch: 778 [40960/90000 (45%)]	Loss: -11.9478	Cost: 10.63s
Train Epoch: 778 [61440/90000 (68%)]	Loss: -11.5796	Cost: 9.54s
Train Epoch: 778 [81920/90000 (91%)]	Loss: -11.7930	Cost: 9.22s
Train Epoch: 778 	Average Loss: -11.3598
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5437

Learning rate: 0.00016860723517563247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 779 [0/90000 (0%)]	Loss: -5.8767	Cost: 28.84s
Train Epoch: 779 [20480/90000 (23%)]	Loss: -11.5597	Cost: 9.81s
Train Epoch: 779 [40960/90000 (45%)]	Loss: -11.9062	Cost: 10.21s
Train Epoch: 779 [61440/90000 (68%)]	Loss: -11.7798	Cost: 9.69s
Train Epoch: 779 [81920/90000 (91%)]	Loss: -11.6202	Cost: 9.17s
Train Epoch: 779 	Average Loss: -11.3530
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5828

Learning rate: 0.00016853101046057856
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 780 [0/90000 (0%)]	Loss: -6.3321	Cost: 29.04s
Train Epoch: 780 [20480/90000 (23%)]	Loss: -11.6162	Cost: 9.66s
Train Epoch: 780 [40960/90000 (45%)]	Loss: -12.0765	Cost: 10.86s
Train Epoch: 780 [61440/90000 (68%)]	Loss: -11.8399	Cost: 9.42s
Train Epoch: 780 [81920/90000 (91%)]	Loss: -11.3524	Cost: 9.26s
Train Epoch: 780 	Average Loss: -11.4128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4250

Learning rate: 0.00016845471059286904
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 781 [0/90000 (0%)]	Loss: -6.2318	Cost: 29.34s
Train Epoch: 781 [20480/90000 (23%)]	Loss: -11.6793	Cost: 9.84s
Train Epoch: 781 [40960/90000 (45%)]	Loss: -11.9934	Cost: 9.94s
Train Epoch: 781 [61440/90000 (68%)]	Loss: -11.6341	Cost: 9.62s
Train Epoch: 781 [81920/90000 (91%)]	Loss: -11.4143	Cost: 9.28s
Train Epoch: 781 	Average Loss: -11.2826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2843

Learning rate: 0.00016837833565617604
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 782 [0/90000 (0%)]	Loss: -6.4926	Cost: 28.79s
Train Epoch: 782 [20480/90000 (23%)]	Loss: -11.6749	Cost: 9.89s
Train Epoch: 782 [40960/90000 (45%)]	Loss: -11.9881	Cost: 10.88s
Train Epoch: 782 [61440/90000 (68%)]	Loss: -11.6930	Cost: 9.45s
Train Epoch: 782 [81920/90000 (91%)]	Loss: -11.6340	Cost: 9.19s
Train Epoch: 782 	Average Loss: -11.2887
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5493

Learning rate: 0.00016830188573425402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 783 [0/90000 (0%)]	Loss: -6.6555	Cost: 29.72s
Train Epoch: 783 [20480/90000 (23%)]	Loss: -11.9099	Cost: 9.70s
Train Epoch: 783 [40960/90000 (45%)]	Loss: -12.0243	Cost: 10.20s
Train Epoch: 783 [61440/90000 (68%)]	Loss: -11.7498	Cost: 9.63s
Train Epoch: 783 [81920/90000 (91%)]	Loss: -11.8217	Cost: 9.18s
Train Epoch: 783 	Average Loss: -11.4110
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4167

Learning rate: 0.0001682253609109398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 784 [0/90000 (0%)]	Loss: -6.6484	Cost: 29.53s
Train Epoch: 784 [20480/90000 (23%)]	Loss: -11.8712	Cost: 9.94s
Train Epoch: 784 [40960/90000 (45%)]	Loss: -12.1005	Cost: 9.81s
Train Epoch: 784 [61440/90000 (68%)]	Loss: -11.9940	Cost: 9.45s
Train Epoch: 784 [81920/90000 (91%)]	Loss: -11.8134	Cost: 9.18s
Train Epoch: 784 	Average Loss: -11.4185
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5530

Learning rate: 0.00016814876127015213
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 785 [0/90000 (0%)]	Loss: -6.4707	Cost: 29.73s
Train Epoch: 785 [20480/90000 (23%)]	Loss: -11.9663	Cost: 9.71s
Train Epoch: 785 [40960/90000 (45%)]	Loss: -11.7562	Cost: 10.64s
Train Epoch: 785 [61440/90000 (68%)]	Loss: -11.6305	Cost: 9.61s
Train Epoch: 785 [81920/90000 (91%)]	Loss: -11.6089	Cost: 9.20s
Train Epoch: 785 	Average Loss: -11.3555
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5084

Learning rate: 0.00016807208689589192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 786 [0/90000 (0%)]	Loss: -6.2071	Cost: 30.76s
Train Epoch: 786 [20480/90000 (23%)]	Loss: -11.7856	Cost: 9.73s
Train Epoch: 786 [40960/90000 (45%)]	Loss: -11.8879	Cost: 10.58s
Train Epoch: 786 [61440/90000 (68%)]	Loss: -11.7465	Cost: 9.69s
Train Epoch: 786 [81920/90000 (91%)]	Loss: -11.5510	Cost: 9.18s
Train Epoch: 786 	Average Loss: -11.3687
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4490

Learning rate: 0.00016799533787224206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 787 [0/90000 (0%)]	Loss: -6.5645	Cost: 29.35s
Train Epoch: 787 [20480/90000 (23%)]	Loss: -11.9850	Cost: 9.77s
Train Epoch: 787 [40960/90000 (45%)]	Loss: -12.2239	Cost: 10.67s
Train Epoch: 787 [61440/90000 (68%)]	Loss: -11.9708	Cost: 9.58s
Train Epoch: 787 [81920/90000 (91%)]	Loss: -11.7933	Cost: 9.19s
Train Epoch: 787 	Average Loss: -11.5438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5734

Learning rate: 0.00016791851428336725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 788 [0/90000 (0%)]	Loss: -6.6838	Cost: 29.46s
Train Epoch: 788 [20480/90000 (23%)]	Loss: -11.8549	Cost: 9.75s
Train Epoch: 788 [40960/90000 (45%)]	Loss: -12.2892	Cost: 10.34s
Train Epoch: 788 [61440/90000 (68%)]	Loss: -11.6032	Cost: 9.43s
Train Epoch: 788 [81920/90000 (91%)]	Loss: -11.6496	Cost: 9.36s
Train Epoch: 788 	Average Loss: -11.3975
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4265

Learning rate: 0.00016784161621351395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 789 [0/90000 (0%)]	Loss: -6.0004	Cost: 29.40s
Train Epoch: 789 [20480/90000 (23%)]	Loss: -11.6867	Cost: 9.76s
Train Epoch: 789 [40960/90000 (45%)]	Loss: -12.0881	Cost: 10.78s
Train Epoch: 789 [61440/90000 (68%)]	Loss: -11.7716	Cost: 9.58s
Train Epoch: 789 [81920/90000 (91%)]	Loss: -11.8653	Cost: 9.31s
Train Epoch: 789 	Average Loss: -11.3861
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6480

Learning rate: 0.00016776464374701038
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 790 [0/90000 (0%)]	Loss: -6.4722	Cost: 29.03s
Train Epoch: 790 [20480/90000 (23%)]	Loss: -11.8629	Cost: 9.81s
Train Epoch: 790 [40960/90000 (45%)]	Loss: -12.4258	Cost: 10.53s
Train Epoch: 790 [61440/90000 (68%)]	Loss: -11.8896	Cost: 10.12s
Train Epoch: 790 [81920/90000 (91%)]	Loss: -11.7886	Cost: 9.20s
Train Epoch: 790 	Average Loss: -11.4899
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6527

Learning rate: 0.00016768759696826624
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 791 [0/90000 (0%)]	Loss: -7.0290	Cost: 28.86s
Train Epoch: 791 [20480/90000 (23%)]	Loss: -11.9734	Cost: 9.85s
Train Epoch: 791 [40960/90000 (45%)]	Loss: -12.2453	Cost: 11.03s
Train Epoch: 791 [61440/90000 (68%)]	Loss: -11.9239	Cost: 9.61s
Train Epoch: 791 [81920/90000 (91%)]	Loss: -11.8494	Cost: 9.40s
Train Epoch: 791 	Average Loss: -11.6038
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6667

Learning rate: 0.0001676104759617728
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 792 [0/90000 (0%)]	Loss: -6.1767	Cost: 29.52s
Train Epoch: 792 [20480/90000 (23%)]	Loss: -11.9300	Cost: 9.89s
Train Epoch: 792 [40960/90000 (45%)]	Loss: -12.2600	Cost: 10.00s
Train Epoch: 792 [61440/90000 (68%)]	Loss: -12.1200	Cost: 9.42s
Train Epoch: 792 [81920/90000 (91%)]	Loss: -10.5891	Cost: 9.17s
Train Epoch: 792 	Average Loss: -11.4986
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5244

Learning rate: 0.0001675332808121026
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 793 [0/90000 (0%)]	Loss: -4.2305	Cost: 28.86s
Train Epoch: 793 [20480/90000 (23%)]	Loss: -9.4143	Cost: 10.19s
Train Epoch: 793 [40960/90000 (45%)]	Loss: -10.0350	Cost: 10.46s
Train Epoch: 793 [61440/90000 (68%)]	Loss: -9.6876	Cost: 9.62s
Train Epoch: 793 [81920/90000 (91%)]	Loss: -9.9744	Cost: 9.22s
Train Epoch: 793 	Average Loss: -9.3078
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3210

Learning rate: 0.00016745601160390975
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 794 [0/90000 (0%)]	Loss: -5.8640	Cost: 28.62s
Train Epoch: 794 [20480/90000 (23%)]	Loss: -9.5888	Cost: 9.90s
Train Epoch: 794 [40960/90000 (45%)]	Loss: -8.9144	Cost: 10.38s
Train Epoch: 794 [61440/90000 (68%)]	Loss: -9.2796	Cost: 9.40s
Train Epoch: 794 [81920/90000 (91%)]	Loss: -10.0347	Cost: 9.29s
Train Epoch: 794 	Average Loss: -9.1950
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2828

Learning rate: 0.00016737866842192925
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 795 [0/90000 (0%)]	Loss: -4.9053	Cost: 29.13s
Train Epoch: 795 [20480/90000 (23%)]	Loss: -10.6344	Cost: 9.81s
Train Epoch: 795 [40960/90000 (45%)]	Loss: -11.1806	Cost: 9.97s
Train Epoch: 795 [61440/90000 (68%)]	Loss: -11.1618	Cost: 9.61s
Train Epoch: 795 [81920/90000 (91%)]	Loss: -11.2423	Cost: 9.30s
Train Epoch: 795 	Average Loss: -10.5516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3976

Learning rate: 0.0001673012513509775
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 796 [0/90000 (0%)]	Loss: -6.0897	Cost: 29.25s
Train Epoch: 796 [20480/90000 (23%)]	Loss: -11.6336	Cost: 9.82s
Train Epoch: 796 [40960/90000 (45%)]	Loss: -11.6172	Cost: 10.50s
Train Epoch: 796 [61440/90000 (68%)]	Loss: -11.3948	Cost: 9.45s
Train Epoch: 796 [81920/90000 (91%)]	Loss: -11.5585	Cost: 9.25s
Train Epoch: 796 	Average Loss: -11.1184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6110

Learning rate: 0.00016722376047595178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 797 [0/90000 (0%)]	Loss: -6.6249	Cost: 29.92s
Train Epoch: 797 [20480/90000 (23%)]	Loss: -11.8678	Cost: 9.77s
Train Epoch: 797 [40960/90000 (45%)]	Loss: -11.9287	Cost: 10.01s
Train Epoch: 797 [61440/90000 (68%)]	Loss: -11.6028	Cost: 9.56s
Train Epoch: 797 [81920/90000 (91%)]	Loss: -11.3907	Cost: 9.20s
Train Epoch: 797 	Average Loss: -11.2709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3078

Learning rate: 0.0001671461958818303
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 798 [0/90000 (0%)]	Loss: -5.5456	Cost: 28.78s
Train Epoch: 798 [20480/90000 (23%)]	Loss: -11.5917	Cost: 9.76s
Train Epoch: 798 [40960/90000 (45%)]	Loss: -12.0610	Cost: 10.77s
Train Epoch: 798 [61440/90000 (68%)]	Loss: -11.9537	Cost: 9.38s
Train Epoch: 798 [81920/90000 (91%)]	Loss: -12.0320	Cost: 9.32s
Train Epoch: 798 	Average Loss: -11.4328
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7401

Learning rate: 0.0001670685576536722
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 799 [0/90000 (0%)]	Loss: -6.6471	Cost: 29.09s
Train Epoch: 799 [20480/90000 (23%)]	Loss: -12.0270	Cost: 9.79s
Train Epoch: 799 [40960/90000 (45%)]	Loss: -12.3854	Cost: 10.60s
Train Epoch: 799 [61440/90000 (68%)]	Loss: -11.9108	Cost: 9.69s
Train Epoch: 799 [81920/90000 (91%)]	Loss: -11.0389	Cost: 9.07s
Train Epoch: 799 	Average Loss: -11.4787
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0822

Learning rate: 0.00016699084587661726
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 800 [0/90000 (0%)]	Loss: -6.4348	Cost: 29.29s
Train Epoch: 800 [20480/90000 (23%)]	Loss: -11.6137	Cost: 9.88s
Train Epoch: 800 [40960/90000 (45%)]	Loss: -11.9389	Cost: 10.53s
Train Epoch: 800 [61440/90000 (68%)]	Loss: -11.6318	Cost: 9.59s
Train Epoch: 800 [81920/90000 (91%)]	Loss: -11.5426	Cost: 9.17s
Train Epoch: 800 	Average Loss: -11.2297
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3748

Saving model as model.pt_e800 & waveforms_supplementary.hdf5_e800
Learning rate: 0.00016691306063588602
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 801 [0/90000 (0%)]	Loss: -6.5594	Cost: 28.46s
Train Epoch: 801 [20480/90000 (23%)]	Loss: -11.4809	Cost: 9.80s
Train Epoch: 801 [40960/90000 (45%)]	Loss: -11.8430	Cost: 10.60s
Train Epoch: 801 [61440/90000 (68%)]	Loss: -11.6266	Cost: 9.43s
Train Epoch: 801 [81920/90000 (91%)]	Loss: -11.8817	Cost: 9.53s
Train Epoch: 801 	Average Loss: -11.3000
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7349

Learning rate: 0.0001668352020167795
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 802 [0/90000 (0%)]	Loss: -7.0038	Cost: 29.09s
Train Epoch: 802 [20480/90000 (23%)]	Loss: -11.9378	Cost: 9.83s
Train Epoch: 802 [40960/90000 (45%)]	Loss: -11.9739	Cost: 10.90s
Train Epoch: 802 [61440/90000 (68%)]	Loss: -11.8155	Cost: 9.45s
Train Epoch: 802 [81920/90000 (91%)]	Loss: -11.8585	Cost: 9.23s
Train Epoch: 802 	Average Loss: -11.5546
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7987

Learning rate: 0.00016675727010467925
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 803 [0/90000 (0%)]	Loss: -6.7421	Cost: 29.59s
Train Epoch: 803 [20480/90000 (23%)]	Loss: -12.0403	Cost: 9.78s
Train Epoch: 803 [40960/90000 (45%)]	Loss: -12.3654	Cost: 10.65s
Train Epoch: 803 [61440/90000 (68%)]	Loss: -12.0003	Cost: 9.41s
Train Epoch: 803 [81920/90000 (91%)]	Loss: -12.1151	Cost: 9.26s
Train Epoch: 803 	Average Loss: -11.6641
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9999

Learning rate: 0.00016667926498504712
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 804 [0/90000 (0%)]	Loss: -6.6574	Cost: 29.38s
Train Epoch: 804 [20480/90000 (23%)]	Loss: -12.1578	Cost: 9.80s
Train Epoch: 804 [40960/90000 (45%)]	Loss: -12.2337	Cost: 10.59s
Train Epoch: 804 [61440/90000 (68%)]	Loss: -12.0500	Cost: 9.40s
Train Epoch: 804 [81920/90000 (91%)]	Loss: -12.1132	Cost: 9.16s
Train Epoch: 804 	Average Loss: -11.7470
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8992

Learning rate: 0.00016660118674342533
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 805 [0/90000 (0%)]	Loss: -6.6591	Cost: 29.73s
Train Epoch: 805 [20480/90000 (23%)]	Loss: -12.1096	Cost: 9.75s
Train Epoch: 805 [40960/90000 (45%)]	Loss: -12.3315	Cost: 10.55s
Train Epoch: 805 [61440/90000 (68%)]	Loss: -12.1629	Cost: 9.43s
Train Epoch: 805 [81920/90000 (91%)]	Loss: -12.0668	Cost: 9.19s
Train Epoch: 805 	Average Loss: -11.7031
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0561

Learning rate: 0.00016652303546543624
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 806 [0/90000 (0%)]	Loss: -6.8766	Cost: 29.97s
Train Epoch: 806 [20480/90000 (23%)]	Loss: -12.1874	Cost: 9.78s
Train Epoch: 806 [40960/90000 (45%)]	Loss: -12.3846	Cost: 10.44s
Train Epoch: 806 [61440/90000 (68%)]	Loss: -12.1500	Cost: 9.43s
Train Epoch: 806 [81920/90000 (91%)]	Loss: -11.9534	Cost: 9.22s
Train Epoch: 806 	Average Loss: -11.8044
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6998

Learning rate: 0.00016644481123678233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 807 [0/90000 (0%)]	Loss: -7.1009	Cost: 29.93s
Train Epoch: 807 [20480/90000 (23%)]	Loss: -12.2247	Cost: 9.76s
Train Epoch: 807 [40960/90000 (45%)]	Loss: -12.5146	Cost: 10.59s
Train Epoch: 807 [61440/90000 (68%)]	Loss: -12.3547	Cost: 9.41s
Train Epoch: 807 [81920/90000 (91%)]	Loss: -12.0527	Cost: 9.23s
Train Epoch: 807 	Average Loss: -11.8446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0355

Learning rate: 0.00016636651414324603
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 808 [0/90000 (0%)]	Loss: -6.6101	Cost: 29.64s
Train Epoch: 808 [20480/90000 (23%)]	Loss: -12.2961	Cost: 9.78s
Train Epoch: 808 [40960/90000 (45%)]	Loss: -12.6574	Cost: 10.34s
Train Epoch: 808 [61440/90000 (68%)]	Loss: -12.1448	Cost: 9.41s
Train Epoch: 808 [81920/90000 (91%)]	Loss: -12.0998	Cost: 9.20s
Train Epoch: 808 	Average Loss: -11.8970
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9166

Learning rate: 0.0001662881442706897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 809 [0/90000 (0%)]	Loss: -6.9423	Cost: 29.43s
Train Epoch: 809 [20480/90000 (23%)]	Loss: -11.9750	Cost: 9.78s
Train Epoch: 809 [40960/90000 (45%)]	Loss: -12.6640	Cost: 9.99s
Train Epoch: 809 [61440/90000 (68%)]	Loss: -12.2261	Cost: 9.61s
Train Epoch: 809 [81920/90000 (91%)]	Loss: -12.1715	Cost: 9.15s
Train Epoch: 809 	Average Loss: -11.9225
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1705

Learning rate: 0.0001662097017050555
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 810 [0/90000 (0%)]	Loss: -7.4677	Cost: 28.83s
Train Epoch: 810 [20480/90000 (23%)]	Loss: -12.4197	Cost: 9.71s
Train Epoch: 810 [40960/90000 (45%)]	Loss: -12.6661	Cost: 10.95s
Train Epoch: 810 [61440/90000 (68%)]	Loss: -12.1721	Cost: 9.40s
Train Epoch: 810 [81920/90000 (91%)]	Loss: -12.3858	Cost: 9.21s
Train Epoch: 810 	Average Loss: -12.0274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9932

Learning rate: 0.00016613118653236534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 811 [0/90000 (0%)]	Loss: -6.7154	Cost: 29.74s
Train Epoch: 811 [20480/90000 (23%)]	Loss: -12.3818	Cost: 9.79s
Train Epoch: 811 [40960/90000 (45%)]	Loss: -12.5674	Cost: 10.87s
Train Epoch: 811 [61440/90000 (68%)]	Loss: -12.3307	Cost: 9.59s
Train Epoch: 811 [81920/90000 (91%)]	Loss: -12.2321	Cost: 9.19s
Train Epoch: 811 	Average Loss: -12.0184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0397

Learning rate: 0.00016605259883872077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 812 [0/90000 (0%)]	Loss: -6.8200	Cost: 29.20s
Train Epoch: 812 [20480/90000 (23%)]	Loss: -12.3578	Cost: 9.69s
Train Epoch: 812 [40960/90000 (45%)]	Loss: -12.7494	Cost: 10.48s
Train Epoch: 812 [61440/90000 (68%)]	Loss: -12.2042	Cost: 9.42s
Train Epoch: 812 [81920/90000 (91%)]	Loss: -12.1806	Cost: 9.24s
Train Epoch: 812 	Average Loss: -11.9273
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8886

Learning rate: 0.00016597393871030277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 813 [0/90000 (0%)]	Loss: -6.6976	Cost: 29.26s
Train Epoch: 813 [20480/90000 (23%)]	Loss: -12.1962	Cost: 9.82s
Train Epoch: 813 [40960/90000 (45%)]	Loss: -12.3104	Cost: 10.62s
Train Epoch: 813 [61440/90000 (68%)]	Loss: -12.1373	Cost: 9.67s
Train Epoch: 813 [81920/90000 (91%)]	Loss: -12.2254	Cost: 9.18s
Train Epoch: 813 	Average Loss: -11.7642
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8770

Learning rate: 0.00016589520623337185
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 814 [0/90000 (0%)]	Loss: -6.7928	Cost: 29.41s
Train Epoch: 814 [20480/90000 (23%)]	Loss: -12.3226	Cost: 9.91s
Train Epoch: 814 [40960/90000 (45%)]	Loss: -12.6787	Cost: 10.57s
Train Epoch: 814 [61440/90000 (68%)]	Loss: -12.3973	Cost: 9.57s
Train Epoch: 814 [81920/90000 (91%)]	Loss: -12.3995	Cost: 9.21s
Train Epoch: 814 	Average Loss: -12.0063
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2360

Learning rate: 0.00016581640149426782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 815 [0/90000 (0%)]	Loss: -7.2671	Cost: 29.27s
Train Epoch: 815 [20480/90000 (23%)]	Loss: -11.9997	Cost: 9.93s
Train Epoch: 815 [40960/90000 (45%)]	Loss: -12.4087	Cost: 10.18s
Train Epoch: 815 [61440/90000 (68%)]	Loss: -12.0642	Cost: 9.67s
Train Epoch: 815 [81920/90000 (91%)]	Loss: -12.1882	Cost: 9.16s
Train Epoch: 815 	Average Loss: -11.7564
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8827

Learning rate: 0.00016573752457940975
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 816 [0/90000 (0%)]	Loss: -6.5837	Cost: 29.05s
Train Epoch: 816 [20480/90000 (23%)]	Loss: -12.1830	Cost: 9.63s
Train Epoch: 816 [40960/90000 (45%)]	Loss: -12.6394	Cost: 10.72s
Train Epoch: 816 [61440/90000 (68%)]	Loss: -12.2218	Cost: 9.37s
Train Epoch: 816 [81920/90000 (91%)]	Loss: -12.3298	Cost: 9.28s
Train Epoch: 816 	Average Loss: -11.9250
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0195

Learning rate: 0.00016565857557529582
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 817 [0/90000 (0%)]	Loss: -6.4343	Cost: 29.36s
Train Epoch: 817 [20480/90000 (23%)]	Loss: -12.2975	Cost: 9.79s
Train Epoch: 817 [40960/90000 (45%)]	Loss: -12.6478	Cost: 10.57s
Train Epoch: 817 [61440/90000 (68%)]	Loss: -12.3563	Cost: 9.61s
Train Epoch: 817 [81920/90000 (91%)]	Loss: -12.3374	Cost: 9.14s
Train Epoch: 817 	Average Loss: -11.9856
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1019

Learning rate: 0.0001655795545685033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 818 [0/90000 (0%)]	Loss: -6.5296	Cost: 30.11s
Train Epoch: 818 [20480/90000 (23%)]	Loss: -12.5373	Cost: 9.69s
Train Epoch: 818 [40960/90000 (45%)]	Loss: -12.7341	Cost: 10.85s
Train Epoch: 818 [61440/90000 (68%)]	Loss: -12.3627	Cost: 9.51s
Train Epoch: 818 [81920/90000 (91%)]	Loss: -12.4605	Cost: 9.49s
Train Epoch: 818 	Average Loss: -12.0557
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0695

Learning rate: 0.00016550046164568843
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 819 [0/90000 (0%)]	Loss: -7.5184	Cost: 29.41s
Train Epoch: 819 [20480/90000 (23%)]	Loss: -12.4473	Cost: 9.72s
Train Epoch: 819 [40960/90000 (45%)]	Loss: -12.7483	Cost: 10.79s
Train Epoch: 819 [61440/90000 (68%)]	Loss: -12.3746	Cost: 9.83s
Train Epoch: 819 [81920/90000 (91%)]	Loss: -12.4831	Cost: 9.59s
Train Epoch: 819 	Average Loss: -12.1259
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2275

Learning rate: 0.00016542129689358628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 820 [0/90000 (0%)]	Loss: -6.6220	Cost: 29.84s
Train Epoch: 820 [20480/90000 (23%)]	Loss: -12.6423	Cost: 9.68s
Train Epoch: 820 [40960/90000 (45%)]	Loss: -12.8676	Cost: 11.21s
Train Epoch: 820 [61440/90000 (68%)]	Loss: -12.6211	Cost: 9.41s
Train Epoch: 820 [81920/90000 (91%)]	Loss: -12.5219	Cost: 9.23s
Train Epoch: 820 	Average Loss: -12.2061
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1424

Learning rate: 0.00016534206039901073
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 821 [0/90000 (0%)]	Loss: -6.6993	Cost: 29.92s
Train Epoch: 821 [20480/90000 (23%)]	Loss: -12.6393	Cost: 9.90s
Train Epoch: 821 [40960/90000 (45%)]	Loss: -11.5452	Cost: 10.37s
Train Epoch: 821 [61440/90000 (68%)]	Loss: -11.4720	Cost: 9.60s
Train Epoch: 821 [81920/90000 (91%)]	Loss: -11.6924	Cost: 9.18s
Train Epoch: 821 	Average Loss: -11.4129
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5927

Learning rate: 0.0001652627522488543
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 822 [0/90000 (0%)]	Loss: -6.8317	Cost: 28.79s
Train Epoch: 822 [20480/90000 (23%)]	Loss: -11.8080	Cost: 9.73s
Train Epoch: 822 [40960/90000 (45%)]	Loss: -12.1410	Cost: 10.67s
Train Epoch: 822 [61440/90000 (68%)]	Loss: -12.1567	Cost: 9.40s
Train Epoch: 822 [81920/90000 (91%)]	Loss: -12.1192	Cost: 9.27s
Train Epoch: 822 	Average Loss: -11.6558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0369

Learning rate: 0.00016518337253008806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 823 [0/90000 (0%)]	Loss: -7.2950	Cost: 29.19s
Train Epoch: 823 [20480/90000 (23%)]	Loss: -12.2841	Cost: 9.72s
Train Epoch: 823 [40960/90000 (45%)]	Loss: -12.4692	Cost: 10.84s
Train Epoch: 823 [61440/90000 (68%)]	Loss: -12.3008	Cost: 9.51s
Train Epoch: 823 [81920/90000 (91%)]	Loss: -12.2550	Cost: 9.16s
Train Epoch: 823 	Average Loss: -11.9651
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0234

Learning rate: 0.00016510392132976166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 824 [0/90000 (0%)]	Loss: -6.6587	Cost: 29.29s
Train Epoch: 824 [20480/90000 (23%)]	Loss: -12.6471	Cost: 9.78s
Train Epoch: 824 [40960/90000 (45%)]	Loss: -12.7786	Cost: 10.45s
Train Epoch: 824 [61440/90000 (68%)]	Loss: -12.4691	Cost: 9.44s
Train Epoch: 824 [81920/90000 (91%)]	Loss: -12.4489	Cost: 9.27s
Train Epoch: 824 	Average Loss: -12.1383
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3323

Learning rate: 0.00016502439873500307
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 825 [0/90000 (0%)]	Loss: -7.1350	Cost: 28.43s
Train Epoch: 825 [20480/90000 (23%)]	Loss: -12.5551	Cost: 9.77s
Train Epoch: 825 [40960/90000 (45%)]	Loss: -12.8612	Cost: 10.49s
Train Epoch: 825 [61440/90000 (68%)]	Loss: -12.4756	Cost: 9.51s
Train Epoch: 825 [81920/90000 (91%)]	Loss: -12.7372	Cost: 9.17s
Train Epoch: 825 	Average Loss: -12.2198
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2167

Learning rate: 0.00016494480483301852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 826 [0/90000 (0%)]	Loss: -6.5966	Cost: 29.48s
Train Epoch: 826 [20480/90000 (23%)]	Loss: -12.3478	Cost: 9.82s
Train Epoch: 826 [40960/90000 (45%)]	Loss: -12.6303	Cost: 10.63s
Train Epoch: 826 [61440/90000 (68%)]	Loss: -12.4222	Cost: 9.43s
Train Epoch: 826 [81920/90000 (91%)]	Loss: -12.3198	Cost: 9.26s
Train Epoch: 826 	Average Loss: -11.9830
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2476

Learning rate: 0.00016486513971109256
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 827 [0/90000 (0%)]	Loss: -7.4499	Cost: 29.73s
Train Epoch: 827 [20480/90000 (23%)]	Loss: -12.5084	Cost: 9.64s
Train Epoch: 827 [40960/90000 (45%)]	Loss: -12.7480	Cost: 10.64s
Train Epoch: 827 [61440/90000 (68%)]	Loss: -12.6316	Cost: 9.39s
Train Epoch: 827 [81920/90000 (91%)]	Loss: -12.5658	Cost: 10.80s
Train Epoch: 827 	Average Loss: -12.1321
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1954

Learning rate: 0.00016478540345658772
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 828 [0/90000 (0%)]	Loss: -7.6385	Cost: 29.57s
Train Epoch: 828 [20480/90000 (23%)]	Loss: -12.6632	Cost: 9.51s
Train Epoch: 828 [40960/90000 (45%)]	Loss: -12.8203	Cost: 10.34s
Train Epoch: 828 [61440/90000 (68%)]	Loss: -12.2011	Cost: 9.41s
Train Epoch: 828 [81920/90000 (91%)]	Loss: -12.3934	Cost: 9.05s
Train Epoch: 828 	Average Loss: -12.1919
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3045

Learning rate: 0.0001647055961569446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 829 [0/90000 (0%)]	Loss: -6.4538	Cost: 31.26s
Train Epoch: 829 [20480/90000 (23%)]	Loss: -12.5795	Cost: 9.47s
Train Epoch: 829 [40960/90000 (45%)]	Loss: -12.7416	Cost: 10.58s
Train Epoch: 829 [61440/90000 (68%)]	Loss: -12.5127	Cost: 9.41s
Train Epoch: 829 [81920/90000 (91%)]	Loss: -12.5044	Cost: 9.06s
Train Epoch: 829 	Average Loss: -12.1841
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3351

Learning rate: 0.00016462571789968165
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 830 [0/90000 (0%)]	Loss: -7.0072	Cost: 30.38s
Train Epoch: 830 [20480/90000 (23%)]	Loss: -12.6119	Cost: 9.58s
Train Epoch: 830 [40960/90000 (45%)]	Loss: -12.7313	Cost: 11.55s
Train Epoch: 830 [61440/90000 (68%)]	Loss: -12.6012	Cost: 9.37s
Train Epoch: 830 [81920/90000 (91%)]	Loss: -12.5629	Cost: 9.19s
Train Epoch: 830 	Average Loss: -12.1659
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2662

Learning rate: 0.0001645457687723952
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 831 [0/90000 (0%)]	Loss: -7.2143	Cost: 30.21s
Train Epoch: 831 [20480/90000 (23%)]	Loss: -12.7981	Cost: 9.46s
Train Epoch: 831 [40960/90000 (45%)]	Loss: -12.8941	Cost: 10.69s
Train Epoch: 831 [61440/90000 (68%)]	Loss: -12.5830	Cost: 9.41s
Train Epoch: 831 [81920/90000 (91%)]	Loss: -12.5911	Cost: 9.06s
Train Epoch: 831 	Average Loss: -12.2683
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2729

Learning rate: 0.00016446574886275927
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 832 [0/90000 (0%)]	Loss: -7.3077	Cost: 30.00s
Train Epoch: 832 [20480/90000 (23%)]	Loss: -12.7343	Cost: 9.68s
Train Epoch: 832 [40960/90000 (45%)]	Loss: -12.7571	Cost: 11.66s
Train Epoch: 832 [61440/90000 (68%)]	Loss: -12.5846	Cost: 9.50s
Train Epoch: 832 [81920/90000 (91%)]	Loss: -12.3769	Cost: 9.31s
Train Epoch: 832 	Average Loss: -12.1941
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1209

Learning rate: 0.00016438565825852553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 833 [0/90000 (0%)]	Loss: -7.4083	Cost: 29.88s
Train Epoch: 833 [20480/90000 (23%)]	Loss: -12.3974	Cost: 9.63s
Train Epoch: 833 [40960/90000 (45%)]	Loss: -12.8748	Cost: 11.23s
Train Epoch: 833 [61440/90000 (68%)]	Loss: -12.5778	Cost: 9.70s
Train Epoch: 833 [81920/90000 (91%)]	Loss: -12.5507	Cost: 11.03s
Train Epoch: 833 	Average Loss: -12.2122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3577

Learning rate: 0.0001643054970475231
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 834 [0/90000 (0%)]	Loss: -6.7096	Cost: 33.27s
Train Epoch: 834 [20480/90000 (23%)]	Loss: -12.7283	Cost: 9.64s
Train Epoch: 834 [40960/90000 (45%)]	Loss: -12.9972	Cost: 11.70s
Train Epoch: 834 [61440/90000 (68%)]	Loss: -12.8265	Cost: 9.83s
Train Epoch: 834 [81920/90000 (91%)]	Loss: -12.6144	Cost: 10.93s
Train Epoch: 834 	Average Loss: -12.4180
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4301

Learning rate: 0.00016422526531765862
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 835 [0/90000 (0%)]	Loss: -7.2460	Cost: 33.15s
Train Epoch: 835 [20480/90000 (23%)]	Loss: -12.7711	Cost: 9.58s
Train Epoch: 835 [40960/90000 (45%)]	Loss: -13.0942	Cost: 11.20s
Train Epoch: 835 [61440/90000 (68%)]	Loss: -12.7609	Cost: 9.76s
Train Epoch: 835 [81920/90000 (91%)]	Loss: -12.7066	Cost: 11.49s
Train Epoch: 835 	Average Loss: -12.3950
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3819

Learning rate: 0.00016414496315691598
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 836 [0/90000 (0%)]	Loss: -7.2550	Cost: 36.68s
Train Epoch: 836 [20480/90000 (23%)]	Loss: -12.7802	Cost: 9.51s
Train Epoch: 836 [40960/90000 (45%)]	Loss: -13.0378	Cost: 10.26s
Train Epoch: 836 [61440/90000 (68%)]	Loss: -12.7538	Cost: 9.69s
Train Epoch: 836 [81920/90000 (91%)]	Loss: -12.5502	Cost: 12.04s
Train Epoch: 836 	Average Loss: -12.3257
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3671

Learning rate: 0.00016406459065335634
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 837 [0/90000 (0%)]	Loss: -7.2965	Cost: 32.92s
Train Epoch: 837 [20480/90000 (23%)]	Loss: -12.5695	Cost: 9.74s
Train Epoch: 837 [40960/90000 (45%)]	Loss: -12.9980	Cost: 11.94s
Train Epoch: 837 [61440/90000 (68%)]	Loss: -12.7614	Cost: 9.61s
Train Epoch: 837 [81920/90000 (91%)]	Loss: -12.5955	Cost: 12.15s
Train Epoch: 837 	Average Loss: -12.3051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2774

Learning rate: 0.00016398414789511802
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 838 [0/90000 (0%)]	Loss: -7.1446	Cost: 34.07s
Train Epoch: 838 [20480/90000 (23%)]	Loss: -12.5260	Cost: 9.79s
Train Epoch: 838 [40960/90000 (45%)]	Loss: -12.9003	Cost: 10.22s
Train Epoch: 838 [61440/90000 (68%)]	Loss: -12.8635	Cost: 9.78s
Train Epoch: 838 [81920/90000 (91%)]	Loss: -12.6159	Cost: 11.42s
Train Epoch: 838 	Average Loss: -12.3079
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3607

Learning rate: 0.00016390363497041638
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 839 [0/90000 (0%)]	Loss: -7.5353	Cost: 36.99s
Train Epoch: 839 [20480/90000 (23%)]	Loss: -12.8087	Cost: 9.56s
Train Epoch: 839 [40960/90000 (45%)]	Loss: -13.0634	Cost: 10.58s
Train Epoch: 839 [61440/90000 (68%)]	Loss: -12.8581	Cost: 9.72s
Train Epoch: 839 [81920/90000 (91%)]	Loss: -12.6431	Cost: 11.43s
Train Epoch: 839 	Average Loss: -12.4240
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3417

Learning rate: 0.00016382305196754372
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 840 [0/90000 (0%)]	Loss: -7.1596	Cost: 32.42s
Train Epoch: 840 [20480/90000 (23%)]	Loss: -12.7775	Cost: 9.91s
Train Epoch: 840 [40960/90000 (45%)]	Loss: -12.8517	Cost: 10.48s
Train Epoch: 840 [61440/90000 (68%)]	Loss: -12.6089	Cost: 9.49s
Train Epoch: 840 [81920/90000 (91%)]	Loss: -12.4850	Cost: 10.12s
Train Epoch: 840 	Average Loss: -12.3648
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3340

Learning rate: 0.00016374239897486915
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 841 [0/90000 (0%)]	Loss: -7.0179	Cost: 31.35s
Train Epoch: 841 [20480/90000 (23%)]	Loss: -12.5067	Cost: 9.89s
Train Epoch: 841 [40960/90000 (45%)]	Loss: -13.0566	Cost: 11.26s
Train Epoch: 841 [61440/90000 (68%)]	Loss: -12.5443	Cost: 9.63s
Train Epoch: 841 [81920/90000 (91%)]	Loss: -12.4400	Cost: 10.23s
Train Epoch: 841 	Average Loss: -12.2602
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2566

Learning rate: 0.0001636616760808386
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 842 [0/90000 (0%)]	Loss: -7.2268	Cost: 32.54s
Train Epoch: 842 [20480/90000 (23%)]	Loss: -12.5942	Cost: 9.82s
Train Epoch: 842 [40960/90000 (45%)]	Loss: -13.1258	Cost: 11.51s
Train Epoch: 842 [61440/90000 (68%)]	Loss: -12.5064	Cost: 9.44s
Train Epoch: 842 [81920/90000 (91%)]	Loss: -12.6503	Cost: 9.32s
Train Epoch: 842 	Average Loss: -12.3387
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4277

Learning rate: 0.00016358088337397459
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 843 [0/90000 (0%)]	Loss: -6.9608	Cost: 31.34s
Train Epoch: 843 [20480/90000 (23%)]	Loss: -12.7765	Cost: 9.56s
Train Epoch: 843 [40960/90000 (45%)]	Loss: -12.9351	Cost: 11.45s
Train Epoch: 843 [61440/90000 (68%)]	Loss: -12.7806	Cost: 9.70s
Train Epoch: 843 [81920/90000 (91%)]	Loss: -12.5803	Cost: 10.21s
Train Epoch: 843 	Average Loss: -12.4127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4757

Learning rate: 0.00016350002094287627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 844 [0/90000 (0%)]	Loss: -7.3129	Cost: 32.51s
Train Epoch: 844 [20480/90000 (23%)]	Loss: -12.5798	Cost: 9.81s
Train Epoch: 844 [40960/90000 (45%)]	Loss: -12.8123	Cost: 11.01s
Train Epoch: 844 [61440/90000 (68%)]	Loss: -12.3494	Cost: 9.83s
Train Epoch: 844 [81920/90000 (91%)]	Loss: -12.4835	Cost: 11.20s
Train Epoch: 844 	Average Loss: -12.1879
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4304

Learning rate: 0.00016341908887621917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 845 [0/90000 (0%)]	Loss: -7.4146	Cost: 34.82s
Train Epoch: 845 [20480/90000 (23%)]	Loss: -12.5898	Cost: 9.48s
Train Epoch: 845 [40960/90000 (45%)]	Loss: -12.8203	Cost: 10.89s
Train Epoch: 845 [61440/90000 (68%)]	Loss: -12.4465	Cost: 9.64s
Train Epoch: 845 [81920/90000 (91%)]	Loss: -12.6023	Cost: 11.55s
Train Epoch: 845 	Average Loss: -12.2308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4030

Learning rate: 0.00016333808726275522
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 846 [0/90000 (0%)]	Loss: -7.0907	Cost: 34.03s
Train Epoch: 846 [20480/90000 (23%)]	Loss: -12.8908	Cost: 9.56s
Train Epoch: 846 [40960/90000 (45%)]	Loss: -12.9156	Cost: 10.75s
Train Epoch: 846 [61440/90000 (68%)]	Loss: -12.7407	Cost: 9.53s
Train Epoch: 846 [81920/90000 (91%)]	Loss: -12.9260	Cost: 12.23s
Train Epoch: 846 	Average Loss: -12.4998
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4811

Learning rate: 0.00016325701619131265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 847 [0/90000 (0%)]	Loss: -7.4101	Cost: 32.83s
Train Epoch: 847 [20480/90000 (23%)]	Loss: -12.2796	Cost: 9.80s
Train Epoch: 847 [40960/90000 (45%)]	Loss: -12.6976	Cost: 10.43s
Train Epoch: 847 [61440/90000 (68%)]	Loss: -12.5718	Cost: 9.75s
Train Epoch: 847 [81920/90000 (91%)]	Loss: -12.6410	Cost: 9.76s
Train Epoch: 847 	Average Loss: -12.1616
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3044

Learning rate: 0.00016317587575079582
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 848 [0/90000 (0%)]	Loss: -7.1402	Cost: 31.48s
Train Epoch: 848 [20480/90000 (23%)]	Loss: -12.6321	Cost: 9.93s
Train Epoch: 848 [40960/90000 (45%)]	Loss: -12.9805	Cost: 11.99s
Train Epoch: 848 [61440/90000 (68%)]	Loss: -12.9089	Cost: 9.67s
Train Epoch: 848 [81920/90000 (91%)]	Loss: -12.9646	Cost: 11.40s
Train Epoch: 848 	Average Loss: -12.4254
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6508

Learning rate: 0.00016309466603018518
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 849 [0/90000 (0%)]	Loss: -7.5129	Cost: 32.40s
Train Epoch: 849 [20480/90000 (23%)]	Loss: -13.0555	Cost: 10.22s
Train Epoch: 849 [40960/90000 (45%)]	Loss: -13.3237	Cost: 10.56s
Train Epoch: 849 [61440/90000 (68%)]	Loss: -12.9815	Cost: 9.61s
Train Epoch: 849 [81920/90000 (91%)]	Loss: -12.8837	Cost: 11.08s
Train Epoch: 849 	Average Loss: -12.5969
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6016

Learning rate: 0.00016301338711853712
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 850 [0/90000 (0%)]	Loss: -7.6043	Cost: 30.38s
Train Epoch: 850 [20480/90000 (23%)]	Loss: -12.4744	Cost: 9.79s
Train Epoch: 850 [40960/90000 (45%)]	Loss: -12.9560	Cost: 10.81s
Train Epoch: 850 [61440/90000 (68%)]	Loss: -12.6458	Cost: 9.57s
Train Epoch: 850 [81920/90000 (91%)]	Loss: -12.6339	Cost: 9.26s
Train Epoch: 850 	Average Loss: -12.3306
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5758

Saving model as model.pt_e850 & waveforms_supplementary.hdf5_e850
Learning rate: 0.00016293203910498397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 851 [0/90000 (0%)]	Loss: -7.5387	Cost: 29.57s
Train Epoch: 851 [20480/90000 (23%)]	Loss: -12.9180	Cost: 9.69s
Train Epoch: 851 [40960/90000 (45%)]	Loss: -13.0754	Cost: 11.49s
Train Epoch: 851 [61440/90000 (68%)]	Loss: -12.9087	Cost: 9.57s
Train Epoch: 851 [81920/90000 (91%)]	Loss: -12.8223	Cost: 10.12s
Train Epoch: 851 	Average Loss: -12.4784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6051

Learning rate: 0.00016285062207873377
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 852 [0/90000 (0%)]	Loss: -7.0203	Cost: 32.93s
Train Epoch: 852 [20480/90000 (23%)]	Loss: -12.9030	Cost: 9.62s
Train Epoch: 852 [40960/90000 (45%)]	Loss: -13.3179	Cost: 11.51s
Train Epoch: 852 [61440/90000 (68%)]	Loss: -13.0480	Cost: 9.66s
Train Epoch: 852 [81920/90000 (91%)]	Loss: -12.6711	Cost: 11.11s
Train Epoch: 852 	Average Loss: -12.5257
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2264

Learning rate: 0.00016276913612907028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 853 [0/90000 (0%)]	Loss: -6.9812	Cost: 33.98s
Train Epoch: 853 [20480/90000 (23%)]	Loss: -12.5939	Cost: 9.73s
Train Epoch: 853 [40960/90000 (45%)]	Loss: -12.8639	Cost: 10.93s
Train Epoch: 853 [61440/90000 (68%)]	Loss: -12.6603	Cost: 9.88s
Train Epoch: 853 [81920/90000 (91%)]	Loss: -12.7029	Cost: 11.01s
Train Epoch: 853 	Average Loss: -12.3001
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4126

Learning rate: 0.00016268758134535283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 854 [0/90000 (0%)]	Loss: -7.2289	Cost: 32.23s
Train Epoch: 854 [20480/90000 (23%)]	Loss: -12.8515	Cost: 9.55s
Train Epoch: 854 [40960/90000 (45%)]	Loss: -13.1755	Cost: 10.66s
Train Epoch: 854 [61440/90000 (68%)]	Loss: -12.9651	Cost: 9.63s
Train Epoch: 854 [81920/90000 (91%)]	Loss: -12.7640	Cost: 11.86s
Train Epoch: 854 	Average Loss: -12.4841
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4490

Learning rate: 0.00016260595781701629
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 855 [0/90000 (0%)]	Loss: -6.7541	Cost: 32.50s
Train Epoch: 855 [20480/90000 (23%)]	Loss: -12.9114	Cost: 9.55s
Train Epoch: 855 [40960/90000 (45%)]	Loss: -12.9491	Cost: 10.91s
Train Epoch: 855 [61440/90000 (68%)]	Loss: -12.8326	Cost: 9.72s
Train Epoch: 855 [81920/90000 (91%)]	Loss: -12.7737	Cost: 11.41s
Train Epoch: 855 	Average Loss: -12.4384
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6224

Learning rate: 0.00016252426563357077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 856 [0/90000 (0%)]	Loss: -6.8502	Cost: 34.64s
Train Epoch: 856 [20480/90000 (23%)]	Loss: -13.0982	Cost: 9.79s
Train Epoch: 856 [40960/90000 (45%)]	Loss: -13.3207	Cost: 10.44s
Train Epoch: 856 [61440/90000 (68%)]	Loss: -12.9666	Cost: 9.73s
Train Epoch: 856 [81920/90000 (91%)]	Loss: -13.0094	Cost: 10.10s
Train Epoch: 856 	Average Loss: -12.5736
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6895

Learning rate: 0.00016244250488460182
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 857 [0/90000 (0%)]	Loss: -7.1637	Cost: 31.69s
Train Epoch: 857 [20480/90000 (23%)]	Loss: -12.8770	Cost: 9.73s
Train Epoch: 857 [40960/90000 (45%)]	Loss: -13.1631	Cost: 11.72s
Train Epoch: 857 [61440/90000 (68%)]	Loss: -12.9461	Cost: 9.51s
Train Epoch: 857 [81920/90000 (91%)]	Loss: -12.9257	Cost: 11.03s
Train Epoch: 857 	Average Loss: -12.5080
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6280

Learning rate: 0.00016236067565977017
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 858 [0/90000 (0%)]	Loss: -7.8439	Cost: 31.78s
Train Epoch: 858 [20480/90000 (23%)]	Loss: -12.9265	Cost: 9.68s
Train Epoch: 858 [40960/90000 (45%)]	Loss: -13.3691	Cost: 10.97s
Train Epoch: 858 [61440/90000 (68%)]	Loss: -12.8139	Cost: 9.48s
Train Epoch: 858 [81920/90000 (91%)]	Loss: -12.9022	Cost: 10.68s
Train Epoch: 858 	Average Loss: -12.5899
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6085

Learning rate: 0.00016227877804881152
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 859 [0/90000 (0%)]	Loss: -6.8264	Cost: 30.04s
Train Epoch: 859 [20480/90000 (23%)]	Loss: -12.9315	Cost: 9.65s
Train Epoch: 859 [40960/90000 (45%)]	Loss: -13.4228	Cost: 11.68s
Train Epoch: 859 [61440/90000 (68%)]	Loss: -12.9483	Cost: 9.58s
Train Epoch: 859 [81920/90000 (91%)]	Loss: -13.3095	Cost: 10.86s
Train Epoch: 859 	Average Loss: -12.6926
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8424

Learning rate: 0.00016219681214153667
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 860 [0/90000 (0%)]	Loss: -7.6205	Cost: 32.33s
Train Epoch: 860 [20480/90000 (23%)]	Loss: -13.1625	Cost: 9.94s
Train Epoch: 860 [40960/90000 (45%)]	Loss: -13.4192	Cost: 10.64s
Train Epoch: 860 [61440/90000 (68%)]	Loss: -13.0899	Cost: 9.78s
Train Epoch: 860 [81920/90000 (91%)]	Loss: -13.0150	Cost: 11.05s
Train Epoch: 860 	Average Loss: -12.7576
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7884

Learning rate: 0.0001621147780278313
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 861 [0/90000 (0%)]	Loss: -7.7282	Cost: 34.50s
Train Epoch: 861 [20480/90000 (23%)]	Loss: -13.1945	Cost: 9.51s
Train Epoch: 861 [40960/90000 (45%)]	Loss: -13.4200	Cost: 10.89s
Train Epoch: 861 [61440/90000 (68%)]	Loss: -13.2112	Cost: 9.75s
Train Epoch: 861 [81920/90000 (91%)]	Loss: -13.1468	Cost: 11.27s
Train Epoch: 861 	Average Loss: -12.8544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9378

Learning rate: 0.00016203267579765584
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 862 [0/90000 (0%)]	Loss: -7.1009	Cost: 33.62s
Train Epoch: 862 [20480/90000 (23%)]	Loss: -13.0467	Cost: 9.61s
Train Epoch: 862 [40960/90000 (45%)]	Loss: -13.3791	Cost: 10.73s
Train Epoch: 862 [61440/90000 (68%)]	Loss: -13.1833	Cost: 9.68s
Train Epoch: 862 [81920/90000 (91%)]	Loss: -13.0838	Cost: 12.01s
Train Epoch: 862 	Average Loss: -12.8234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9826

Learning rate: 0.0001619505055410455
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 863 [0/90000 (0%)]	Loss: -7.7285	Cost: 33.27s
Train Epoch: 863 [20480/90000 (23%)]	Loss: -13.4368	Cost: 9.81s
Train Epoch: 863 [40960/90000 (45%)]	Loss: -13.5308	Cost: 10.41s
Train Epoch: 863 [61440/90000 (68%)]	Loss: -13.3195	Cost: 9.96s
Train Epoch: 863 [81920/90000 (91%)]	Loss: -13.2188	Cost: 11.29s
Train Epoch: 863 	Average Loss: -12.9675
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8700

Learning rate: 0.00016186826734811003
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 864 [0/90000 (0%)]	Loss: -7.1592	Cost: 34.20s
Train Epoch: 864 [20480/90000 (23%)]	Loss: -13.1992	Cost: 9.70s
Train Epoch: 864 [40960/90000 (45%)]	Loss: -13.5132	Cost: 9.93s
Train Epoch: 864 [61440/90000 (68%)]	Loss: -13.0252	Cost: 9.74s
Train Epoch: 864 [81920/90000 (91%)]	Loss: -13.0071	Cost: 10.70s
Train Epoch: 864 	Average Loss: -12.7211
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8251

Learning rate: 0.00016178596130903366
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 865 [0/90000 (0%)]	Loss: -7.4921	Cost: 33.53s
Train Epoch: 865 [20480/90000 (23%)]	Loss: -13.0449	Cost: 9.92s
Train Epoch: 865 [40960/90000 (45%)]	Loss: -13.5221	Cost: 10.81s
Train Epoch: 865 [61440/90000 (68%)]	Loss: -13.1681	Cost: 9.59s
Train Epoch: 865 [81920/90000 (91%)]	Loss: -13.0842	Cost: 9.58s
Train Epoch: 865 	Average Loss: -12.7942
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7593

Learning rate: 0.00016170358751407512
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 866 [0/90000 (0%)]	Loss: -7.1191	Cost: 32.04s
Train Epoch: 866 [20480/90000 (23%)]	Loss: -13.1046	Cost: 10.33s
Train Epoch: 866 [40960/90000 (45%)]	Loss: -13.5272	Cost: 11.43s
Train Epoch: 866 [61440/90000 (68%)]	Loss: -13.0045	Cost: 9.64s
Train Epoch: 866 [81920/90000 (91%)]	Loss: -13.0143	Cost: 10.62s
Train Epoch: 866 	Average Loss: -12.7449
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9222

Learning rate: 0.0001616211460535673
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 867 [0/90000 (0%)]	Loss: -8.0928	Cost: 32.16s
Train Epoch: 867 [20480/90000 (23%)]	Loss: -13.2160	Cost: 9.86s
Train Epoch: 867 [40960/90000 (45%)]	Loss: -13.6194	Cost: 10.99s
Train Epoch: 867 [61440/90000 (68%)]	Loss: -13.3031	Cost: 9.47s
Train Epoch: 867 [81920/90000 (91%)]	Loss: -13.2260	Cost: 10.31s
Train Epoch: 867 	Average Loss: -12.8506
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9316

Learning rate: 0.0001615386370179174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 868 [0/90000 (0%)]	Loss: -7.5588	Cost: 30.27s
Train Epoch: 868 [20480/90000 (23%)]	Loss: -13.2591	Cost: 9.79s
Train Epoch: 868 [40960/90000 (45%)]	Loss: -13.4917	Cost: 11.19s
Train Epoch: 868 [61440/90000 (68%)]	Loss: -13.1504	Cost: 9.71s
Train Epoch: 868 [81920/90000 (91%)]	Loss: -13.1750	Cost: 9.48s
Train Epoch: 868 	Average Loss: -12.8882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8961

Learning rate: 0.00016145606049760666
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 869 [0/90000 (0%)]	Loss: -7.1795	Cost: 31.61s
Train Epoch: 869 [20480/90000 (23%)]	Loss: -13.2271	Cost: 9.64s
Train Epoch: 869 [40960/90000 (45%)]	Loss: -13.7229	Cost: 11.19s
Train Epoch: 869 [61440/90000 (68%)]	Loss: -13.2399	Cost: 9.67s
Train Epoch: 869 [81920/90000 (91%)]	Loss: -13.3734	Cost: 10.85s
Train Epoch: 869 	Average Loss: -12.9615
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0200

Learning rate: 0.00016137341658319044
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 870 [0/90000 (0%)]	Loss: -7.7211	Cost: 32.01s
Train Epoch: 870 [20480/90000 (23%)]	Loss: -13.3559	Cost: 9.64s
Train Epoch: 870 [40960/90000 (45%)]	Loss: -13.6747	Cost: 10.65s
Train Epoch: 870 [61440/90000 (68%)]	Loss: -13.3405	Cost: 9.78s
Train Epoch: 870 [81920/90000 (91%)]	Loss: -13.2583	Cost: 11.31s
Train Epoch: 870 	Average Loss: -13.0501
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0346

Learning rate: 0.00016129070536529788
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 871 [0/90000 (0%)]	Loss: -7.6356	Cost: 35.26s
Train Epoch: 871 [20480/90000 (23%)]	Loss: -13.2786	Cost: 9.46s
Train Epoch: 871 [40960/90000 (45%)]	Loss: -13.6975	Cost: 10.91s
Train Epoch: 871 [61440/90000 (68%)]	Loss: -13.4215	Cost: 9.81s
Train Epoch: 871 [81920/90000 (91%)]	Loss: -13.0822	Cost: 11.38s
Train Epoch: 871 	Average Loss: -13.0102
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9719

Learning rate: 0.00016120792693463193
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 872 [0/90000 (0%)]	Loss: -7.8734	Cost: 33.20s
Train Epoch: 872 [20480/90000 (23%)]	Loss: -13.2228	Cost: 9.81s
Train Epoch: 872 [40960/90000 (45%)]	Loss: -13.4153	Cost: 10.35s
Train Epoch: 872 [61440/90000 (68%)]	Loss: -13.2958	Cost: 9.80s
Train Epoch: 872 [81920/90000 (91%)]	Loss: -13.1682	Cost: 11.70s
Train Epoch: 872 	Average Loss: -12.8857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9794

Learning rate: 0.0001611250813819694
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 873 [0/90000 (0%)]	Loss: -7.8189	Cost: 33.60s
Train Epoch: 873 [20480/90000 (23%)]	Loss: -13.4656	Cost: 9.74s
Train Epoch: 873 [40960/90000 (45%)]	Loss: -13.6402	Cost: 10.45s
Train Epoch: 873 [61440/90000 (68%)]	Loss: -13.4913	Cost: 9.69s
Train Epoch: 873 [81920/90000 (91%)]	Loss: -13.4943	Cost: 11.41s
Train Epoch: 873 	Average Loss: -13.0733
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9188

Learning rate: 0.00016104216879816045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 874 [0/90000 (0%)]	Loss: -8.2736	Cost: 36.65s
Train Epoch: 874 [20480/90000 (23%)]	Loss: -13.5061	Cost: 9.69s
Train Epoch: 874 [40960/90000 (45%)]	Loss: -13.6086	Cost: 10.29s
Train Epoch: 874 [61440/90000 (68%)]	Loss: -13.4478	Cost: 9.56s
Train Epoch: 874 [81920/90000 (91%)]	Loss: -13.4832	Cost: 10.11s
Train Epoch: 874 	Average Loss: -13.0786
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0754

Learning rate: 0.00016095918927412902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 875 [0/90000 (0%)]	Loss: -8.0015	Cost: 33.74s
Train Epoch: 875 [20480/90000 (23%)]	Loss: -13.3558	Cost: 9.66s
Train Epoch: 875 [40960/90000 (45%)]	Loss: -13.4437	Cost: 10.88s
Train Epoch: 875 [61440/90000 (68%)]	Loss: -13.1556	Cost: 9.52s
Train Epoch: 875 [81920/90000 (91%)]	Loss: -13.1644	Cost: 9.66s
Train Epoch: 875 	Average Loss: -12.9136
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6579

Learning rate: 0.0001608761429008723
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 876 [0/90000 (0%)]	Loss: -7.4769	Cost: 30.93s
Train Epoch: 876 [20480/90000 (23%)]	Loss: -13.0990	Cost: 9.99s
Train Epoch: 876 [40960/90000 (45%)]	Loss: -13.2900	Cost: 11.31s
Train Epoch: 876 [61440/90000 (68%)]	Loss: -12.9047	Cost: 9.49s
Train Epoch: 876 [81920/90000 (91%)]	Loss: -12.7571	Cost: 10.15s
Train Epoch: 876 	Average Loss: -12.6113
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6628

Learning rate: 0.00016079302976946074
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 877 [0/90000 (0%)]	Loss: -6.5475	Cost: 31.77s
Train Epoch: 877 [20480/90000 (23%)]	Loss: -13.1926	Cost: 9.93s
Train Epoch: 877 [40960/90000 (45%)]	Loss: -13.5811	Cost: 10.93s
Train Epoch: 877 [61440/90000 (68%)]	Loss: -13.3286	Cost: 9.57s
Train Epoch: 877 [81920/90000 (91%)]	Loss: -13.2755	Cost: 9.30s
Train Epoch: 877 	Average Loss: -12.8204
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0411

Learning rate: 0.0001607098499710382
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 878 [0/90000 (0%)]	Loss: -7.6686	Cost: 30.40s
Train Epoch: 878 [20480/90000 (23%)]	Loss: -13.5333	Cost: 9.63s
Train Epoch: 878 [40960/90000 (45%)]	Loss: -13.8981	Cost: 11.15s
Train Epoch: 878 [61440/90000 (68%)]	Loss: -13.4543	Cost: 9.66s
Train Epoch: 878 [81920/90000 (91%)]	Loss: -13.4347	Cost: 10.11s
Train Epoch: 878 	Average Loss: -13.0998
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.9544

Learning rate: 0.00016062660359682143
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 879 [0/90000 (0%)]	Loss: -7.6962	Cost: 32.12s
Train Epoch: 879 [20480/90000 (23%)]	Loss: -13.3563	Cost: 9.80s
Train Epoch: 879 [40960/90000 (45%)]	Loss: -13.6201	Cost: 11.27s
Train Epoch: 879 [61440/90000 (68%)]	Loss: -13.2550	Cost: 9.82s
Train Epoch: 879 [81920/90000 (91%)]	Loss: -12.9459	Cost: 10.69s
Train Epoch: 879 	Average Loss: -12.9120
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8144

Learning rate: 0.00016054329073810034
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 880 [0/90000 (0%)]	Loss: -6.8881	Cost: 32.36s
Train Epoch: 880 [20480/90000 (23%)]	Loss: -13.2027	Cost: 9.76s
Train Epoch: 880 [40960/90000 (45%)]	Loss: -13.4845	Cost: 10.74s
Train Epoch: 880 [61440/90000 (68%)]	Loss: -13.4422	Cost: 9.66s
Train Epoch: 880 [81920/90000 (91%)]	Loss: -13.3588	Cost: 11.30s
Train Epoch: 880 	Average Loss: -12.8577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1684

Learning rate: 0.00016045991148623767
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 881 [0/90000 (0%)]	Loss: -7.7418	Cost: 32.49s
Train Epoch: 881 [20480/90000 (23%)]	Loss: -13.3784	Cost: 9.82s
Train Epoch: 881 [40960/90000 (45%)]	Loss: -13.6342	Cost: 10.90s
Train Epoch: 881 [61440/90000 (68%)]	Loss: -13.4043	Cost: 10.03s
Train Epoch: 881 [81920/90000 (91%)]	Loss: -13.3068	Cost: 10.99s
Train Epoch: 881 	Average Loss: -13.0206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1614

Learning rate: 0.00016037646593266902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 882 [0/90000 (0%)]	Loss: -7.5798	Cost: 33.16s
Train Epoch: 882 [20480/90000 (23%)]	Loss: -13.6079	Cost: 9.90s
Train Epoch: 882 [40960/90000 (45%)]	Loss: -13.8460	Cost: 11.31s
Train Epoch: 882 [61440/90000 (68%)]	Loss: -13.3972	Cost: 9.67s
Train Epoch: 882 [81920/90000 (91%)]	Loss: -13.4221	Cost: 9.61s
Train Epoch: 882 	Average Loss: -13.1558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1155

Learning rate: 0.00016029295416890266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 883 [0/90000 (0%)]	Loss: -7.4052	Cost: 31.60s
Train Epoch: 883 [20480/90000 (23%)]	Loss: -13.5164	Cost: 9.85s
Train Epoch: 883 [40960/90000 (45%)]	Loss: -13.9381	Cost: 10.86s
Train Epoch: 883 [61440/90000 (68%)]	Loss: -13.5647	Cost: 9.54s
Train Epoch: 883 [81920/90000 (91%)]	Loss: -13.2251	Cost: 10.47s
Train Epoch: 883 	Average Loss: -13.1304
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0203

Learning rate: 0.00016020937628651946
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 884 [0/90000 (0%)]	Loss: -7.3068	Cost: 31.18s
Train Epoch: 884 [20480/90000 (23%)]	Loss: -13.5371	Cost: 9.88s
Train Epoch: 884 [40960/90000 (45%)]	Loss: -13.7452	Cost: 11.26s
Train Epoch: 884 [61440/90000 (68%)]	Loss: -13.5015	Cost: 9.49s
Train Epoch: 884 [81920/90000 (91%)]	Loss: -13.3099	Cost: 9.35s
Train Epoch: 884 	Average Loss: -12.9732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0201

Learning rate: 0.00016012573237717285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 885 [0/90000 (0%)]	Loss: -7.8714	Cost: 30.11s
Train Epoch: 885 [20480/90000 (23%)]	Loss: -13.5039	Cost: 9.72s
Train Epoch: 885 [40960/90000 (45%)]	Loss: -13.8424	Cost: 11.13s
Train Epoch: 885 [61440/90000 (68%)]	Loss: -13.5065	Cost: 9.79s
Train Epoch: 885 [81920/90000 (91%)]	Loss: -13.4137	Cost: 11.62s
Train Epoch: 885 	Average Loss: -13.1623
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1735

Learning rate: 0.00016004202253258858
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 886 [0/90000 (0%)]	Loss: -7.8769	Cost: 31.45s
Train Epoch: 886 [20480/90000 (23%)]	Loss: -12.0125	Cost: 9.82s
Train Epoch: 886 [40960/90000 (45%)]	Loss: -12.6781	Cost: 10.94s
Train Epoch: 886 [61440/90000 (68%)]	Loss: -12.4259	Cost: 9.73s
Train Epoch: 886 [81920/90000 (91%)]	Loss: -12.7356	Cost: 11.15s
Train Epoch: 886 	Average Loss: -12.1366
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5352

Learning rate: 0.00015995824684456484
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 887 [0/90000 (0%)]	Loss: -7.5982	Cost: 32.87s
Train Epoch: 887 [20480/90000 (23%)]	Loss: -12.7901	Cost: 9.82s
Train Epoch: 887 [40960/90000 (45%)]	Loss: -13.2213	Cost: 11.09s
Train Epoch: 887 [61440/90000 (68%)]	Loss: -12.9712	Cost: 9.65s
Train Epoch: 887 [81920/90000 (91%)]	Loss: -12.9542	Cost: 11.04s
Train Epoch: 887 	Average Loss: -12.5523
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7448

Learning rate: 0.00015987440540497183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 888 [0/90000 (0%)]	Loss: -8.1665	Cost: 33.38s
Train Epoch: 888 [20480/90000 (23%)]	Loss: -13.3244	Cost: 9.77s
Train Epoch: 888 [40960/90000 (45%)]	Loss: -13.5803	Cost: 11.14s
Train Epoch: 888 [61440/90000 (68%)]	Loss: -13.3666	Cost: 9.52s
Train Epoch: 888 [81920/90000 (91%)]	Loss: -13.5124	Cost: 10.55s
Train Epoch: 888 	Average Loss: -12.9745
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0666

Learning rate: 0.00015979049830575206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 889 [0/90000 (0%)]	Loss: -7.8092	Cost: 32.31s
Train Epoch: 889 [20480/90000 (23%)]	Loss: -13.5123	Cost: 9.88s
Train Epoch: 889 [40960/90000 (45%)]	Loss: -13.5215	Cost: 10.54s
Train Epoch: 889 [61440/90000 (68%)]	Loss: -13.1689	Cost: 9.61s
Train Epoch: 889 [81920/90000 (91%)]	Loss: -13.3864	Cost: 9.94s
Train Epoch: 889 	Average Loss: -12.9950
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8702

Learning rate: 0.00015970652563891991
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 890 [0/90000 (0%)]	Loss: -7.9901	Cost: 31.14s
Train Epoch: 890 [20480/90000 (23%)]	Loss: -13.5285	Cost: 9.84s
Train Epoch: 890 [40960/90000 (45%)]	Loss: -13.6888	Cost: 10.86s
Train Epoch: 890 [61440/90000 (68%)]	Loss: -13.1882	Cost: 9.57s
Train Epoch: 890 [81920/90000 (91%)]	Loss: -13.2041	Cost: 9.56s
Train Epoch: 890 	Average Loss: -12.9336
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0231

Learning rate: 0.00015962248749656172
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 891 [0/90000 (0%)]	Loss: -7.6256	Cost: 31.69s
Train Epoch: 891 [20480/90000 (23%)]	Loss: -13.5511	Cost: 9.92s
Train Epoch: 891 [40960/90000 (45%)]	Loss: -13.7166	Cost: 11.04s
Train Epoch: 891 [61440/90000 (68%)]	Loss: -13.2146	Cost: 9.74s
Train Epoch: 891 [81920/90000 (91%)]	Loss: -13.5219	Cost: 11.04s
Train Epoch: 891 	Average Loss: -13.0725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0835

Learning rate: 0.00015953838397083563
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 892 [0/90000 (0%)]	Loss: -7.7653	Cost: 32.93s
Train Epoch: 892 [20480/90000 (23%)]	Loss: -13.7670	Cost: 9.69s
Train Epoch: 892 [40960/90000 (45%)]	Loss: -13.8364	Cost: 11.40s
Train Epoch: 892 [61440/90000 (68%)]	Loss: -13.5499	Cost: 9.70s
Train Epoch: 892 [81920/90000 (91%)]	Loss: -13.4774	Cost: 11.43s
Train Epoch: 892 	Average Loss: -13.2550
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3331

Learning rate: 0.00015945421515397147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 893 [0/90000 (0%)]	Loss: -8.4819	Cost: 34.28s
Train Epoch: 893 [20480/90000 (23%)]	Loss: -13.7826	Cost: 9.72s
Train Epoch: 893 [40960/90000 (45%)]	Loss: -13.9208	Cost: 10.21s
Train Epoch: 893 [61440/90000 (68%)]	Loss: -13.6470	Cost: 9.91s
Train Epoch: 893 [81920/90000 (91%)]	Loss: -13.7174	Cost: 11.06s
Train Epoch: 893 	Average Loss: -13.3708
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4176

Learning rate: 0.00015936998113827064
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 894 [0/90000 (0%)]	Loss: -8.1705	Cost: 34.09s
Train Epoch: 894 [20480/90000 (23%)]	Loss: -13.9386	Cost: 9.77s
Train Epoch: 894 [40960/90000 (45%)]	Loss: -14.1541	Cost: 10.84s
Train Epoch: 894 [61440/90000 (68%)]	Loss: -13.7409	Cost: 9.89s
Train Epoch: 894 [81920/90000 (91%)]	Loss: -13.6373	Cost: 10.84s
Train Epoch: 894 	Average Loss: -13.4172
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2683

Learning rate: 0.00015928568201610608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 895 [0/90000 (0%)]	Loss: -8.0790	Cost: 33.11s
Train Epoch: 895 [20480/90000 (23%)]	Loss: -13.8202	Cost: 9.83s
Train Epoch: 895 [40960/90000 (45%)]	Loss: -14.0233	Cost: 10.94s
Train Epoch: 895 [61440/90000 (68%)]	Loss: -13.3744	Cost: 9.68s
Train Epoch: 895 [81920/90000 (91%)]	Loss: -13.2723	Cost: 10.52s
Train Epoch: 895 	Average Loss: -13.2948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.1387

Learning rate: 0.0001592013178799221
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 896 [0/90000 (0%)]	Loss: -7.6773	Cost: 32.00s
Train Epoch: 896 [20480/90000 (23%)]	Loss: -13.5209	Cost: 10.02s
Train Epoch: 896 [40960/90000 (45%)]	Loss: -13.9232	Cost: 10.76s
Train Epoch: 896 [61440/90000 (68%)]	Loss: -13.6566	Cost: 9.56s
Train Epoch: 896 [81920/90000 (91%)]	Loss: -13.6622	Cost: 11.46s
Train Epoch: 896 	Average Loss: -13.2744
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3545

Learning rate: 0.00015911688882223435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 897 [0/90000 (0%)]	Loss: -8.3745	Cost: 31.78s
Train Epoch: 897 [20480/90000 (23%)]	Loss: -13.7948	Cost: 9.92s
Train Epoch: 897 [40960/90000 (45%)]	Loss: -14.4331	Cost: 11.45s
Train Epoch: 897 [61440/90000 (68%)]	Loss: -14.0142	Cost: 9.39s
Train Epoch: 897 [81920/90000 (91%)]	Loss: -13.8253	Cost: 9.66s
Train Epoch: 897 	Average Loss: -13.5938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5635

Learning rate: 0.00015903239493562961
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 898 [0/90000 (0%)]	Loss: -8.6288	Cost: 29.86s
Train Epoch: 898 [20480/90000 (23%)]	Loss: -13.8545	Cost: 9.81s
Train Epoch: 898 [40960/90000 (45%)]	Loss: -14.0857	Cost: 10.93s
Train Epoch: 898 [61440/90000 (68%)]	Loss: -13.8430	Cost: 9.53s
Train Epoch: 898 [81920/90000 (91%)]	Loss: -13.7481	Cost: 10.16s
Train Epoch: 898 	Average Loss: -13.4898
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3992

Learning rate: 0.0001589478363127658
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 899 [0/90000 (0%)]	Loss: -8.1266	Cost: 31.65s
Train Epoch: 899 [20480/90000 (23%)]	Loss: -13.9465	Cost: 9.58s
Train Epoch: 899 [40960/90000 (45%)]	Loss: -14.2293	Cost: 11.17s
Train Epoch: 899 [61440/90000 (68%)]	Loss: -13.8328	Cost: 9.72s
Train Epoch: 899 [81920/90000 (91%)]	Loss: -13.8518	Cost: 11.46s
Train Epoch: 899 	Average Loss: -13.4950
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5628

Learning rate: 0.00015886321304637183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 900 [0/90000 (0%)]	Loss: -8.2522	Cost: 31.97s
Train Epoch: 900 [20480/90000 (23%)]	Loss: -13.8692	Cost: 9.52s
Train Epoch: 900 [40960/90000 (45%)]	Loss: -14.1916	Cost: 10.85s
Train Epoch: 900 [61440/90000 (68%)]	Loss: -13.7968	Cost: 9.77s
Train Epoch: 900 [81920/90000 (91%)]	Loss: -13.6264	Cost: 11.60s
Train Epoch: 900 	Average Loss: -13.4288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4444

Saving model as model.pt_e900 & waveforms_supplementary.hdf5_e900
Learning rate: 0.00015877852522924745
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 901 [0/90000 (0%)]	Loss: -8.2015	Cost: 32.43s
Train Epoch: 901 [20480/90000 (23%)]	Loss: -13.8531	Cost: 9.52s
Train Epoch: 901 [40960/90000 (45%)]	Loss: -14.0530	Cost: 10.60s
Train Epoch: 901 [61440/90000 (68%)]	Loss: -13.7819	Cost: 9.64s
Train Epoch: 901 [81920/90000 (91%)]	Loss: -13.4920	Cost: 11.39s
Train Epoch: 901 	Average Loss: -13.3943
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.0871

Learning rate: 0.0001586937729542633
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 902 [0/90000 (0%)]	Loss: -7.9083	Cost: 33.45s
Train Epoch: 902 [20480/90000 (23%)]	Loss: -13.6135	Cost: 9.80s
Train Epoch: 902 [40960/90000 (45%)]	Loss: -14.0323	Cost: 10.72s
Train Epoch: 902 [61440/90000 (68%)]	Loss: -13.5204	Cost: 9.69s
Train Epoch: 902 [81920/90000 (91%)]	Loss: -13.8659	Cost: 11.18s
Train Epoch: 902 	Average Loss: -13.2762
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4343

Learning rate: 0.00015860895631436057
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 903 [0/90000 (0%)]	Loss: -8.5449	Cost: 36.16s
Train Epoch: 903 [20480/90000 (23%)]	Loss: -13.9290	Cost: 9.63s
Train Epoch: 903 [40960/90000 (45%)]	Loss: -14.2449	Cost: 11.00s
Train Epoch: 903 [61440/90000 (68%)]	Loss: -13.9025	Cost: 9.58s
Train Epoch: 903 [81920/90000 (91%)]	Loss: -13.9208	Cost: 11.45s
Train Epoch: 903 	Average Loss: -13.5978
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.6198

Learning rate: 0.00015852407540255118
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 904 [0/90000 (0%)]	Loss: -8.7650	Cost: 33.20s
Train Epoch: 904 [20480/90000 (23%)]	Loss: -13.9946	Cost: 9.87s
Train Epoch: 904 [40960/90000 (45%)]	Loss: -14.2749	Cost: 10.78s
Train Epoch: 904 [61440/90000 (68%)]	Loss: -14.0900	Cost: 9.49s
Train Epoch: 904 [81920/90000 (91%)]	Loss: -13.8000	Cost: 9.64s
Train Epoch: 904 	Average Loss: -13.6620
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5873

Learning rate: 0.00015843913031191736
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 905 [0/90000 (0%)]	Loss: -8.4562	Cost: 31.72s
Train Epoch: 905 [20480/90000 (23%)]	Loss: -14.0488	Cost: 10.10s
Train Epoch: 905 [40960/90000 (45%)]	Loss: -14.0918	Cost: 11.16s
Train Epoch: 905 [61440/90000 (68%)]	Loss: -13.8758	Cost: 9.51s
Train Epoch: 905 [81920/90000 (91%)]	Loss: -13.5051	Cost: 9.91s
Train Epoch: 905 	Average Loss: -13.4885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2001

Learning rate: 0.0001583541211356119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 906 [0/90000 (0%)]	Loss: -8.7872	Cost: 29.58s
Train Epoch: 906 [20480/90000 (23%)]	Loss: -13.3147	Cost: 9.67s
Train Epoch: 906 [40960/90000 (45%)]	Loss: -13.7887	Cost: 11.30s
Train Epoch: 906 [61440/90000 (68%)]	Loss: -13.5506	Cost: 9.66s
Train Epoch: 906 [81920/90000 (91%)]	Loss: -13.5647	Cost: 9.81s
Train Epoch: 906 	Average Loss: -13.1863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5059

Learning rate: 0.00015826904796685775
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 907 [0/90000 (0%)]	Loss: -7.3702	Cost: 32.84s
Train Epoch: 907 [20480/90000 (23%)]	Loss: -13.9186	Cost: 9.64s
Train Epoch: 907 [40960/90000 (45%)]	Loss: -14.3140	Cost: 11.79s
Train Epoch: 907 [61440/90000 (68%)]	Loss: -13.9059	Cost: 9.73s
Train Epoch: 907 [81920/90000 (91%)]	Loss: -13.9146	Cost: 11.07s
Train Epoch: 907 	Average Loss: -13.5967
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5465

Learning rate: 0.0001581839108989481
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 908 [0/90000 (0%)]	Loss: -8.2319	Cost: 33.74s
Train Epoch: 908 [20480/90000 (23%)]	Loss: -13.9183	Cost: 9.64s
Train Epoch: 908 [40960/90000 (45%)]	Loss: -14.4214	Cost: 10.59s
Train Epoch: 908 [61440/90000 (68%)]	Loss: -13.8431	Cost: 9.75s
Train Epoch: 908 [81920/90000 (91%)]	Loss: -13.8538	Cost: 11.36s
Train Epoch: 908 	Average Loss: -13.5999
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5141

Learning rate: 0.00015809871002524616
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 909 [0/90000 (0%)]	Loss: -8.3365	Cost: 34.71s
Train Epoch: 909 [20480/90000 (23%)]	Loss: -14.2075	Cost: 9.65s
Train Epoch: 909 [40960/90000 (45%)]	Loss: -14.5120	Cost: 10.31s
Train Epoch: 909 [61440/90000 (68%)]	Loss: -14.1035	Cost: 9.60s
Train Epoch: 909 [81920/90000 (91%)]	Loss: -13.8808	Cost: 11.52s
Train Epoch: 909 	Average Loss: -13.7400
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.5993

Learning rate: 0.00015801344543918508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 910 [0/90000 (0%)]	Loss: -8.3137	Cost: 33.57s
Train Epoch: 910 [20480/90000 (23%)]	Loss: -14.0554	Cost: 9.89s
Train Epoch: 910 [40960/90000 (45%)]	Loss: -14.3738	Cost: 10.07s
Train Epoch: 910 [61440/90000 (68%)]	Loss: -14.1076	Cost: 9.83s
Train Epoch: 910 [81920/90000 (91%)]	Loss: -13.9455	Cost: 11.06s
Train Epoch: 910 	Average Loss: -13.6614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.6480

Learning rate: 0.00015792811723426803
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 911 [0/90000 (0%)]	Loss: -8.1451	Cost: 32.44s
Train Epoch: 911 [20480/90000 (23%)]	Loss: -14.1500	Cost: 9.75s
Train Epoch: 911 [40960/90000 (45%)]	Loss: -14.3221	Cost: 11.01s
Train Epoch: 911 [61440/90000 (68%)]	Loss: -14.1722	Cost: 9.43s
Train Epoch: 911 [81920/90000 (91%)]	Loss: -13.8654	Cost: 11.01s
Train Epoch: 911 	Average Loss: -13.7305
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4415

Learning rate: 0.00015784272550406782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 912 [0/90000 (0%)]	Loss: -8.1383	Cost: 30.92s
Train Epoch: 912 [20480/90000 (23%)]	Loss: -13.6447	Cost: 9.77s
Train Epoch: 912 [40960/90000 (45%)]	Loss: -14.2600	Cost: 11.28s
Train Epoch: 912 [61440/90000 (68%)]	Loss: -13.7848	Cost: 9.50s
Train Epoch: 912 [81920/90000 (91%)]	Loss: -13.8078	Cost: 9.53s
Train Epoch: 912 	Average Loss: -13.4764
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4803

Learning rate: 0.00015775727034222692
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 913 [0/90000 (0%)]	Loss: -8.7521	Cost: 31.39s
Train Epoch: 913 [20480/90000 (23%)]	Loss: -13.9468	Cost: 9.59s
Train Epoch: 913 [40960/90000 (45%)]	Loss: -14.2975	Cost: 11.24s
Train Epoch: 913 [61440/90000 (68%)]	Loss: -14.0822	Cost: 9.67s
Train Epoch: 913 [81920/90000 (91%)]	Loss: -14.1375	Cost: 10.14s
Train Epoch: 913 	Average Loss: -13.6626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.6811

Learning rate: 0.00015767175184245742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 914 [0/90000 (0%)]	Loss: -8.8401	Cost: 33.02s
Train Epoch: 914 [20480/90000 (23%)]	Loss: -14.0077	Cost: 9.58s
Train Epoch: 914 [40960/90000 (45%)]	Loss: -14.2636	Cost: 11.82s
Train Epoch: 914 [61440/90000 (68%)]	Loss: -13.9535	Cost: 9.68s
Train Epoch: 914 [81920/90000 (91%)]	Loss: -13.8220	Cost: 11.35s
Train Epoch: 914 	Average Loss: -13.6081
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4956

Learning rate: 0.00015758617009854084
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 915 [0/90000 (0%)]	Loss: -8.2876	Cost: 31.96s
Train Epoch: 915 [20480/90000 (23%)]	Loss: -13.8604	Cost: 10.00s
Train Epoch: 915 [40960/90000 (45%)]	Loss: -14.2178	Cost: 10.81s
Train Epoch: 915 [61440/90000 (68%)]	Loss: -10.6941	Cost: 9.82s
Train Epoch: 915 [81920/90000 (91%)]	Loss: -11.0548	Cost: 11.10s
Train Epoch: 915 	Average Loss: -12.2384
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3021

Learning rate: 0.000157500525204328
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 916 [0/90000 (0%)]	Loss: -6.0509	Cost: 33.70s
Train Epoch: 916 [20480/90000 (23%)]	Loss: -11.4079	Cost: 9.74s
Train Epoch: 916 [40960/90000 (45%)]	Loss: -12.2448	Cost: 10.96s
Train Epoch: 916 [61440/90000 (68%)]	Loss: -12.4076	Cost: 9.65s
Train Epoch: 916 [81920/90000 (91%)]	Loss: -12.8108	Cost: 11.47s
Train Epoch: 916 	Average Loss: -11.7570
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.8245

Learning rate: 0.0001574148172537391
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 917 [0/90000 (0%)]	Loss: -7.9396	Cost: 33.81s
Train Epoch: 917 [20480/90000 (23%)]	Loss: -13.3822	Cost: 9.84s
Train Epoch: 917 [40960/90000 (45%)]	Loss: -13.8298	Cost: 10.70s
Train Epoch: 917 [61440/90000 (68%)]	Loss: -13.7345	Cost: 10.05s
Train Epoch: 917 [81920/90000 (91%)]	Loss: -13.6878	Cost: 11.09s
Train Epoch: 917 	Average Loss: -13.2323
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4082

Learning rate: 0.00015732904634076342
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 918 [0/90000 (0%)]	Loss: -8.4291	Cost: 34.10s
Train Epoch: 918 [20480/90000 (23%)]	Loss: -13.9404	Cost: 9.78s
Train Epoch: 918 [40960/90000 (45%)]	Loss: -14.1496	Cost: 11.63s
Train Epoch: 918 [61440/90000 (68%)]	Loss: -13.9122	Cost: 9.81s
Train Epoch: 918 [81920/90000 (91%)]	Loss: -13.8645	Cost: 11.46s
Train Epoch: 918 	Average Loss: -13.5435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.4375

Learning rate: 0.0001572432125594592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 919 [0/90000 (0%)]	Loss: -7.7166	Cost: 33.53s
Train Epoch: 919 [20480/90000 (23%)]	Loss: -14.2058	Cost: 9.84s
Train Epoch: 919 [40960/90000 (45%)]	Loss: -14.4362	Cost: 11.47s
Train Epoch: 919 [61440/90000 (68%)]	Loss: -13.9333	Cost: 9.55s
Train Epoch: 919 [81920/90000 (91%)]	Loss: -13.8556	Cost: 10.40s
Train Epoch: 919 	Average Loss: -13.6393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.6779

Learning rate: 0.00015715731600395385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 920 [0/90000 (0%)]	Loss: -8.3153	Cost: 30.81s
Train Epoch: 920 [20480/90000 (23%)]	Loss: -14.1154	Cost: 9.95s
Train Epoch: 920 [40960/90000 (45%)]	Loss: -14.2489	Cost: 11.08s
Train Epoch: 920 [61440/90000 (68%)]	Loss: -13.9846	Cost: 9.57s
Train Epoch: 920 [81920/90000 (91%)]	Loss: -13.9046	Cost: 10.42s
Train Epoch: 920 	Average Loss: -13.6840
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.6938

Learning rate: 0.00015707135676844332
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 921 [0/90000 (0%)]	Loss: -8.9060	Cost: 30.90s
Train Epoch: 921 [20480/90000 (23%)]	Loss: -14.0757	Cost: 9.74s
Train Epoch: 921 [40960/90000 (45%)]	Loss: -14.1686	Cost: 10.92s
Train Epoch: 921 [61440/90000 (68%)]	Loss: -14.4275	Cost: 9.59s
Train Epoch: 921 [81920/90000 (91%)]	Loss: -14.1568	Cost: 9.53s
Train Epoch: 921 	Average Loss: -13.7830
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.6787

Learning rate: 0.00015698533494719252
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 922 [0/90000 (0%)]	Loss: -8.3446	Cost: 33.51s
Train Epoch: 922 [20480/90000 (23%)]	Loss: -14.3942	Cost: 9.55s
Train Epoch: 922 [40960/90000 (45%)]	Loss: -14.6742	Cost: 10.64s
Train Epoch: 922 [61440/90000 (68%)]	Loss: -14.1932	Cost: 9.79s
Train Epoch: 922 [81920/90000 (91%)]	Loss: -14.1757	Cost: 11.21s
Train Epoch: 922 	Average Loss: -13.9091
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.7129

Learning rate: 0.00015689925063453494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 923 [0/90000 (0%)]	Loss: -8.4291	Cost: 33.55s
Train Epoch: 923 [20480/90000 (23%)]	Loss: -14.3976	Cost: 9.73s
Train Epoch: 923 [40960/90000 (45%)]	Loss: -14.4199	Cost: 10.37s
Train Epoch: 923 [61440/90000 (68%)]	Loss: -14.2556	Cost: 9.65s
Train Epoch: 923 [81920/90000 (91%)]	Loss: -14.1469	Cost: 11.28s
Train Epoch: 923 	Average Loss: -13.8803
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8114

Learning rate: 0.00015681310392487254
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 924 [0/90000 (0%)]	Loss: -8.6015	Cost: 33.48s
Train Epoch: 924 [20480/90000 (23%)]	Loss: -14.2391	Cost: 9.77s
Train Epoch: 924 [40960/90000 (45%)]	Loss: -14.3841	Cost: 10.62s
Train Epoch: 924 [61440/90000 (68%)]	Loss: -14.1826	Cost: 9.67s
Train Epoch: 924 [81920/90000 (91%)]	Loss: -14.2413	Cost: 11.00s
Train Epoch: 924 	Average Loss: -13.8618
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.7541

Learning rate: 0.00015672689491267577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 925 [0/90000 (0%)]	Loss: -8.1690	Cost: 32.73s
Train Epoch: 925 [20480/90000 (23%)]	Loss: -14.2260	Cost: 9.86s
Train Epoch: 925 [40960/90000 (45%)]	Loss: -14.6650	Cost: 10.56s
Train Epoch: 925 [61440/90000 (68%)]	Loss: -14.2501	Cost: 9.52s
Train Epoch: 925 [81920/90000 (91%)]	Loss: -14.2085	Cost: 9.68s
Train Epoch: 925 	Average Loss: -13.8869
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.7511

Learning rate: 0.00015664062369248342
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 926 [0/90000 (0%)]	Loss: -9.6164	Cost: 33.19s
Train Epoch: 926 [20480/90000 (23%)]	Loss: -14.3520	Cost: 10.01s
Train Epoch: 926 [40960/90000 (45%)]	Loss: -14.4464	Cost: 10.49s
Train Epoch: 926 [61440/90000 (68%)]	Loss: -14.1433	Cost: 9.51s
Train Epoch: 926 [81920/90000 (91%)]	Loss: -14.1262	Cost: 10.00s
Train Epoch: 926 	Average Loss: -13.8875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.6086

Learning rate: 0.00015655429035890241
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 927 [0/90000 (0%)]	Loss: -8.6060	Cost: 29.00s
Train Epoch: 927 [20480/90000 (23%)]	Loss: -14.0376	Cost: 9.72s
Train Epoch: 927 [40960/90000 (45%)]	Loss: -14.3394	Cost: 10.83s
Train Epoch: 927 [61440/90000 (68%)]	Loss: -14.0184	Cost: 9.58s
Train Epoch: 927 [81920/90000 (91%)]	Loss: -13.9604	Cost: 10.53s
Train Epoch: 927 	Average Loss: -13.6661
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.6861

Learning rate: 0.00015646789500660784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 928 [0/90000 (0%)]	Loss: -8.6075	Cost: 32.05s
Train Epoch: 928 [20480/90000 (23%)]	Loss: -14.1362	Cost: 9.57s
Train Epoch: 928 [40960/90000 (45%)]	Loss: -14.2787	Cost: 10.93s
Train Epoch: 928 [61440/90000 (68%)]	Loss: -14.2446	Cost: 9.65s
Train Epoch: 928 [81920/90000 (91%)]	Loss: -14.2032	Cost: 11.39s
Train Epoch: 928 	Average Loss: -13.8695
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.7685

Learning rate: 0.00015638143773034278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 929 [0/90000 (0%)]	Loss: -8.3918	Cost: 32.82s
Train Epoch: 929 [20480/90000 (23%)]	Loss: -13.9368	Cost: 10.15s
Train Epoch: 929 [40960/90000 (45%)]	Loss: -14.3211	Cost: 10.07s
Train Epoch: 929 [61440/90000 (68%)]	Loss: -14.2178	Cost: 9.98s
Train Epoch: 929 [81920/90000 (91%)]	Loss: -14.0708	Cost: 10.71s
Train Epoch: 929 	Average Loss: -13.7577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8301

Learning rate: 0.0001562949186249183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 930 [0/90000 (0%)]	Loss: -8.5825	Cost: 31.23s
Train Epoch: 930 [20480/90000 (23%)]	Loss: -14.2845	Cost: 9.74s
Train Epoch: 930 [40960/90000 (45%)]	Loss: -14.4379	Cost: 11.77s
Train Epoch: 930 [61440/90000 (68%)]	Loss: -14.1112	Cost: 9.71s
Train Epoch: 930 [81920/90000 (91%)]	Loss: -14.2894	Cost: 10.99s
Train Epoch: 930 	Average Loss: -13.8738
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8324

Learning rate: 0.0001562083377852132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 931 [0/90000 (0%)]	Loss: -8.4484	Cost: 32.19s
Train Epoch: 931 [20480/90000 (23%)]	Loss: -14.1146	Cost: 9.95s
Train Epoch: 931 [40960/90000 (45%)]	Loss: -14.6240	Cost: 11.11s
Train Epoch: 931 [61440/90000 (68%)]	Loss: -14.3013	Cost: 9.48s
Train Epoch: 931 [81920/90000 (91%)]	Loss: -14.3740	Cost: 9.87s
Train Epoch: 931 	Average Loss: -13.8682
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8834

Learning rate: 0.00015612169530617392
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 932 [0/90000 (0%)]	Loss: -8.3023	Cost: 30.71s
Train Epoch: 932 [20480/90000 (23%)]	Loss: -14.3087	Cost: 9.66s
Train Epoch: 932 [40960/90000 (45%)]	Loss: -14.5294	Cost: 11.26s
Train Epoch: 932 [61440/90000 (68%)]	Loss: -14.1320	Cost: 9.57s
Train Epoch: 932 [81920/90000 (91%)]	Loss: -14.1137	Cost: 9.71s
Train Epoch: 932 	Average Loss: -13.9194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8233

Learning rate: 0.00015603499128281459
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 933 [0/90000 (0%)]	Loss: -8.2805	Cost: 32.71s
Train Epoch: 933 [20480/90000 (23%)]	Loss: -14.2866	Cost: 9.86s
Train Epoch: 933 [40960/90000 (45%)]	Loss: -14.6739	Cost: 11.10s
Train Epoch: 933 [61440/90000 (68%)]	Loss: -14.2777	Cost: 9.75s
Train Epoch: 933 [81920/90000 (91%)]	Loss: -14.3426	Cost: 10.92s
Train Epoch: 933 	Average Loss: -13.9157
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8557

Learning rate: 0.00015594822581021682
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 934 [0/90000 (0%)]	Loss: -9.0155	Cost: 34.25s
Train Epoch: 934 [20480/90000 (23%)]	Loss: -14.2766	Cost: 9.76s
Train Epoch: 934 [40960/90000 (45%)]	Loss: -14.7017	Cost: 10.68s
Train Epoch: 934 [61440/90000 (68%)]	Loss: -14.3011	Cost: 9.81s
Train Epoch: 934 [81920/90000 (91%)]	Loss: -14.3166	Cost: 11.57s
Train Epoch: 934 	Average Loss: -13.9531
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.9327

Learning rate: 0.0001558613989835296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 935 [0/90000 (0%)]	Loss: -8.4568	Cost: 32.02s
Train Epoch: 935 [20480/90000 (23%)]	Loss: -14.4094	Cost: 9.49s
Train Epoch: 935 [40960/90000 (45%)]	Loss: -14.5820	Cost: 10.88s
Train Epoch: 935 [61440/90000 (68%)]	Loss: -14.3238	Cost: 9.52s
Train Epoch: 935 [81920/90000 (91%)]	Loss: -14.4414	Cost: 11.75s
Train Epoch: 935 	Average Loss: -13.9839
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.9206

Learning rate: 0.00015577451089796913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 936 [0/90000 (0%)]	Loss: -8.5324	Cost: 32.87s
Train Epoch: 936 [20480/90000 (23%)]	Loss: -14.3937	Cost: 9.60s
Train Epoch: 936 [40960/90000 (45%)]	Loss: -14.7246	Cost: 11.75s
Train Epoch: 936 [61440/90000 (68%)]	Loss: -14.4250	Cost: 9.58s
Train Epoch: 936 [81920/90000 (91%)]	Loss: -14.2183	Cost: 12.46s
Train Epoch: 936 	Average Loss: -14.0059
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.7540

Learning rate: 0.00015568756164881893
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 937 [0/90000 (0%)]	Loss: -9.2361	Cost: 33.20s
Train Epoch: 937 [20480/90000 (23%)]	Loss: -14.4702	Cost: 9.94s
Train Epoch: 937 [40960/90000 (45%)]	Loss: -14.9149	Cost: 10.37s
Train Epoch: 937 [61440/90000 (68%)]	Loss: -14.4343	Cost: 9.71s
Train Epoch: 937 [81920/90000 (91%)]	Loss: -14.3848	Cost: 10.36s
Train Epoch: 937 	Average Loss: -14.1445
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.1091

Learning rate: 0.00015560055133142945
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 938 [0/90000 (0%)]	Loss: -9.0791	Cost: 33.43s
Train Epoch: 938 [20480/90000 (23%)]	Loss: -14.4912	Cost: 9.82s
Train Epoch: 938 [40960/90000 (45%)]	Loss: -14.3406	Cost: 11.13s
Train Epoch: 938 [61440/90000 (68%)]	Loss: -13.2399	Cost: 9.51s
Train Epoch: 938 [81920/90000 (91%)]	Loss: -13.3894	Cost: 10.75s
Train Epoch: 938 	Average Loss: -13.5634
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2190

Learning rate: 0.00015551348004121817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 939 [0/90000 (0%)]	Loss: -8.2493	Cost: 32.09s
Train Epoch: 939 [20480/90000 (23%)]	Loss: -13.7615	Cost: 9.83s
Train Epoch: 939 [40960/90000 (45%)]	Loss: -14.1335	Cost: 11.48s
Train Epoch: 939 [61440/90000 (68%)]	Loss: -13.8515	Cost: 9.51s
Train Epoch: 939 [81920/90000 (91%)]	Loss: -14.0722	Cost: 9.33s
Train Epoch: 939 	Average Loss: -13.4985
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8592

Learning rate: 0.0001554263478736695
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 940 [0/90000 (0%)]	Loss: -8.2932	Cost: 30.00s
Train Epoch: 940 [20480/90000 (23%)]	Loss: -14.2245	Cost: 10.09s
Train Epoch: 940 [40960/90000 (45%)]	Loss: -14.7204	Cost: 10.89s
Train Epoch: 940 [61440/90000 (68%)]	Loss: -14.3855	Cost: 9.71s
Train Epoch: 940 [81920/90000 (91%)]	Loss: -14.5446	Cost: 10.85s
Train Epoch: 940 	Average Loss: -14.0979
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.0346

Learning rate: 0.0001553391549243345
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 941 [0/90000 (0%)]	Loss: -9.2116	Cost: 33.21s
Train Epoch: 941 [20480/90000 (23%)]	Loss: -14.7299	Cost: 9.64s
Train Epoch: 941 [40960/90000 (45%)]	Loss: -14.8814	Cost: 10.68s
Train Epoch: 941 [61440/90000 (68%)]	Loss: -14.4535	Cost: 9.82s
Train Epoch: 941 [81920/90000 (91%)]	Loss: -14.4820	Cost: 11.29s
Train Epoch: 941 	Average Loss: -14.1886
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8218

Learning rate: 0.00015525190128883094
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 942 [0/90000 (0%)]	Loss: -8.6778	Cost: 32.80s
Train Epoch: 942 [20480/90000 (23%)]	Loss: -14.3109	Cost: 9.54s
Train Epoch: 942 [40960/90000 (45%)]	Loss: -14.3208	Cost: 10.50s
Train Epoch: 942 [61440/90000 (68%)]	Loss: -14.1892	Cost: 9.44s
Train Epoch: 942 [81920/90000 (91%)]	Loss: -14.3025	Cost: 11.87s
Train Epoch: 942 	Average Loss: -13.9043
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.9935

Learning rate: 0.00015516458706284314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 943 [0/90000 (0%)]	Loss: -8.7627	Cost: 32.13s
Train Epoch: 943 [20480/90000 (23%)]	Loss: -14.2249	Cost: 9.51s
Train Epoch: 943 [40960/90000 (45%)]	Loss: -14.5161	Cost: 11.35s
Train Epoch: 943 [61440/90000 (68%)]	Loss: -14.3103	Cost: 9.50s
Train Epoch: 943 [81920/90000 (91%)]	Loss: -14.2156	Cost: 10.27s
Train Epoch: 943 	Average Loss: -13.9779
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.1555

Learning rate: 0.0001550772123421218
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 944 [0/90000 (0%)]	Loss: -8.3714	Cost: 31.23s
Train Epoch: 944 [20480/90000 (23%)]	Loss: -14.4610	Cost: 10.14s
Train Epoch: 944 [40960/90000 (45%)]	Loss: -14.8073	Cost: 10.52s
Train Epoch: 944 [61440/90000 (68%)]	Loss: -14.5504	Cost: 9.66s
Train Epoch: 944 [81920/90000 (91%)]	Loss: -14.7249	Cost: 10.70s
Train Epoch: 944 	Average Loss: -14.1540
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.1666

Learning rate: 0.00015498977722248406
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 945 [0/90000 (0%)]	Loss: -9.0555	Cost: 30.17s
Train Epoch: 945 [20480/90000 (23%)]	Loss: -14.6921	Cost: 10.06s
Train Epoch: 945 [40960/90000 (45%)]	Loss: -15.0285	Cost: 11.40s
Train Epoch: 945 [61440/90000 (68%)]	Loss: -14.4826	Cost: 9.68s
Train Epoch: 945 [81920/90000 (91%)]	Loss: -14.5405	Cost: 9.27s
Train Epoch: 945 	Average Loss: -14.3125
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.1876

Learning rate: 0.00015490228179981328
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 946 [0/90000 (0%)]	Loss: -8.9571	Cost: 32.32s
Train Epoch: 946 [20480/90000 (23%)]	Loss: -14.4923	Cost: 9.62s
Train Epoch: 946 [40960/90000 (45%)]	Loss: -14.6646	Cost: 11.36s
Train Epoch: 946 [61440/90000 (68%)]	Loss: -14.3909	Cost: 9.69s
Train Epoch: 946 [81920/90000 (91%)]	Loss: -14.4690	Cost: 11.69s
Train Epoch: 946 	Average Loss: -14.0724
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.0409

Learning rate: 0.00015481472617005884
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 947 [0/90000 (0%)]	Loss: -8.8047	Cost: 31.65s
Train Epoch: 947 [20480/90000 (23%)]	Loss: -13.5895	Cost: 9.53s
Train Epoch: 947 [40960/90000 (45%)]	Loss: -13.9374	Cost: 12.22s
Train Epoch: 947 [61440/90000 (68%)]	Loss: -13.2122	Cost: 9.49s
Train Epoch: 947 [81920/90000 (91%)]	Loss: -13.4976	Cost: 12.78s
Train Epoch: 947 	Average Loss: -13.2055
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.2955

Learning rate: 0.00015472711042923627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 948 [0/90000 (0%)]	Loss: -7.8056	Cost: 33.76s
Train Epoch: 948 [20480/90000 (23%)]	Loss: -13.8380	Cost: 9.69s
Train Epoch: 948 [40960/90000 (45%)]	Loss: -14.3385	Cost: 11.47s
Train Epoch: 948 [61440/90000 (68%)]	Loss: -14.2076	Cost: 9.51s
Train Epoch: 948 [81920/90000 (91%)]	Loss: -13.9609	Cost: 13.05s
Train Epoch: 948 	Average Loss: -13.5870
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8172

Learning rate: 0.000154639434673427
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 949 [0/90000 (0%)]	Loss: -8.6992	Cost: 33.60s
Train Epoch: 949 [20480/90000 (23%)]	Loss: -14.1988	Cost: 9.71s
Train Epoch: 949 [40960/90000 (45%)]	Loss: -14.5008	Cost: 11.25s
Train Epoch: 949 [61440/90000 (68%)]	Loss: -14.2772	Cost: 9.54s
Train Epoch: 949 [81920/90000 (91%)]	Loss: -14.2203	Cost: 11.05s
Train Epoch: 949 	Average Loss: -13.8500
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.9725

Learning rate: 0.00015455169899877822
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 950 [0/90000 (0%)]	Loss: -9.1737	Cost: 34.19s
Train Epoch: 950 [20480/90000 (23%)]	Loss: -14.5290	Cost: 9.79s
Train Epoch: 950 [40960/90000 (45%)]	Loss: -14.8298	Cost: 11.14s
Train Epoch: 950 [61440/90000 (68%)]	Loss: -14.5254	Cost: 9.44s
Train Epoch: 950 [81920/90000 (91%)]	Loss: -14.7491	Cost: 10.65s
Train Epoch: 950 	Average Loss: -14.2337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.1694

Saving model as model.pt_e950 & waveforms_supplementary.hdf5_e950
Learning rate: 0.0001544639035015028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 951 [0/90000 (0%)]	Loss: -9.0074	Cost: 32.06s
Train Epoch: 951 [20480/90000 (23%)]	Loss: -14.5986	Cost: 9.91s
Train Epoch: 951 [40960/90000 (45%)]	Loss: -14.9017	Cost: 11.17s
Train Epoch: 951 [61440/90000 (68%)]	Loss: -14.6390	Cost: 9.51s
Train Epoch: 951 [81920/90000 (91%)]	Loss: -14.5390	Cost: 9.81s
Train Epoch: 951 	Average Loss: -14.2073
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.1459

Learning rate: 0.00015437604827787938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 952 [0/90000 (0%)]	Loss: -8.8860	Cost: 31.39s
Train Epoch: 952 [20480/90000 (23%)]	Loss: -14.4792	Cost: 10.19s
Train Epoch: 952 [40960/90000 (45%)]	Loss: -15.0643	Cost: 11.90s
Train Epoch: 952 [61440/90000 (68%)]	Loss: -14.5212	Cost: 9.56s
Train Epoch: 952 [81920/90000 (91%)]	Loss: -14.5418	Cost: 10.21s
Train Epoch: 952 	Average Loss: -14.2081
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.0810

Learning rate: 0.00015428813342425188
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 953 [0/90000 (0%)]	Loss: -9.2157	Cost: 31.42s
Train Epoch: 953 [20480/90000 (23%)]	Loss: -14.6349	Cost: 9.55s
Train Epoch: 953 [40960/90000 (45%)]	Loss: -14.9544	Cost: 11.68s
Train Epoch: 953 [61440/90000 (68%)]	Loss: -14.8274	Cost: 9.60s
Train Epoch: 953 [81920/90000 (91%)]	Loss: -14.5868	Cost: 11.13s
Train Epoch: 953 	Average Loss: -14.2868
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2049

Learning rate: 0.00015420015903702973
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 954 [0/90000 (0%)]	Loss: -9.0566	Cost: 32.86s
Train Epoch: 954 [20480/90000 (23%)]	Loss: -14.7506	Cost: 9.62s
Train Epoch: 954 [40960/90000 (45%)]	Loss: -14.9482	Cost: 11.48s
Train Epoch: 954 [61440/90000 (68%)]	Loss: -14.4774	Cost: 9.68s
Train Epoch: 954 [81920/90000 (91%)]	Loss: -14.5828	Cost: 11.06s
Train Epoch: 954 	Average Loss: -14.2879
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.1647

Learning rate: 0.0001541121252126877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 955 [0/90000 (0%)]	Loss: -8.4390	Cost: 33.47s
Train Epoch: 955 [20480/90000 (23%)]	Loss: -14.6737	Cost: 9.60s
Train Epoch: 955 [40960/90000 (45%)]	Loss: -14.8623	Cost: 11.25s
Train Epoch: 955 [61440/90000 (68%)]	Loss: -14.6367	Cost: 9.97s
Train Epoch: 955 [81920/90000 (91%)]	Loss: -14.4051	Cost: 11.43s
Train Epoch: 955 	Average Loss: -14.2233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.0427

Learning rate: 0.00015402403204776562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 956 [0/90000 (0%)]	Loss: -8.9097	Cost: 33.93s
Train Epoch: 956 [20480/90000 (23%)]	Loss: -14.4622	Cost: 9.64s
Train Epoch: 956 [40960/90000 (45%)]	Loss: -14.8305	Cost: 10.35s
Train Epoch: 956 [61440/90000 (68%)]	Loss: -14.6609	Cost: 9.62s
Train Epoch: 956 [81920/90000 (91%)]	Loss: -14.5226	Cost: 11.90s
Train Epoch: 956 	Average Loss: -14.2082
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.0935

Learning rate: 0.00015393587963886845
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 957 [0/90000 (0%)]	Loss: -9.2512	Cost: 33.03s
Train Epoch: 957 [20480/90000 (23%)]	Loss: -14.5180	Cost: 9.85s
Train Epoch: 957 [40960/90000 (45%)]	Loss: -14.5035	Cost: 10.35s
Train Epoch: 957 [61440/90000 (68%)]	Loss: -14.2309	Cost: 10.05s
Train Epoch: 957 [81920/90000 (91%)]	Loss: -14.4677	Cost: 11.47s
Train Epoch: 957 	Average Loss: -14.0456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8931

Learning rate: 0.00015384766808266613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 958 [0/90000 (0%)]	Loss: -9.1274	Cost: 35.56s
Train Epoch: 958 [20480/90000 (23%)]	Loss: -14.4284	Cost: 9.71s
Train Epoch: 958 [40960/90000 (45%)]	Loss: -14.4456	Cost: 10.73s
Train Epoch: 958 [61440/90000 (68%)]	Loss: -14.1382	Cost: 9.93s
Train Epoch: 958 [81920/90000 (91%)]	Loss: -14.3976	Cost: 10.72s
Train Epoch: 958 	Average Loss: -13.9400
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.0237

Learning rate: 0.00015375939747589346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 959 [0/90000 (0%)]	Loss: -8.7594	Cost: 39.30s
Train Epoch: 959 [20480/90000 (23%)]	Loss: -14.3801	Cost: 9.73s
Train Epoch: 959 [40960/90000 (45%)]	Loss: -14.6515	Cost: 10.71s
Train Epoch: 959 [61440/90000 (68%)]	Loss: -14.7209	Cost: 9.73s
Train Epoch: 959 [81920/90000 (91%)]	Loss: -14.5002	Cost: 12.07s
Train Epoch: 959 	Average Loss: -14.1866
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.0846

Learning rate: 0.00015367106791534994
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 960 [0/90000 (0%)]	Loss: -8.9120	Cost: 31.28s
Train Epoch: 960 [20480/90000 (23%)]	Loss: -13.9927	Cost: 9.90s
Train Epoch: 960 [40960/90000 (45%)]	Loss: -14.0328	Cost: 11.54s
Train Epoch: 960 [61440/90000 (68%)]	Loss: -13.8962	Cost: 9.89s
Train Epoch: 960 [81920/90000 (91%)]	Loss: -14.0315	Cost: 11.87s
Train Epoch: 960 	Average Loss: -13.7303
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.8001

Learning rate: 0.0001535826794978998
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 961 [0/90000 (0%)]	Loss: -8.8022	Cost: 39.85s
Train Epoch: 961 [20480/90000 (23%)]	Loss: -14.4863	Cost: 9.74s
Train Epoch: 961 [40960/90000 (45%)]	Loss: -14.4339	Cost: 9.88s
Train Epoch: 961 [61440/90000 (68%)]	Loss: -14.0791	Cost: 9.40s
Train Epoch: 961 [81920/90000 (91%)]	Loss: -14.3596	Cost: 9.77s
Train Epoch: 961 	Average Loss: -13.9303
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.1286

Learning rate: 0.00015349423232047173
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 962 [0/90000 (0%)]	Loss: -8.6363	Cost: 39.74s
Train Epoch: 962 [20480/90000 (23%)]	Loss: -14.7312	Cost: 10.28s
Train Epoch: 962 [40960/90000 (45%)]	Loss: -14.8706	Cost: 10.95s
Train Epoch: 962 [61440/90000 (68%)]	Loss: -14.7450	Cost: 9.60s
Train Epoch: 962 [81920/90000 (91%)]	Loss: -14.8915	Cost: 10.45s
Train Epoch: 962 	Average Loss: -14.3719
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3449

Learning rate: 0.00015340572648005898
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 963 [0/90000 (0%)]	Loss: -9.0717	Cost: 43.56s
Train Epoch: 963 [20480/90000 (23%)]	Loss: -14.7503	Cost: 9.75s
Train Epoch: 963 [40960/90000 (45%)]	Loss: -15.2216	Cost: 10.42s
Train Epoch: 963 [61440/90000 (68%)]	Loss: -14.9472	Cost: 10.06s
Train Epoch: 963 [81920/90000 (91%)]	Loss: -14.7723	Cost: 11.10s
Train Epoch: 963 	Average Loss: -14.5194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2851

Learning rate: 0.00015331716207371898
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 964 [0/90000 (0%)]	Loss: -9.1785	Cost: 46.23s
Train Epoch: 964 [20480/90000 (23%)]	Loss: -14.7837	Cost: 9.63s
Train Epoch: 964 [40960/90000 (45%)]	Loss: -15.2156	Cost: 10.91s
Train Epoch: 964 [61440/90000 (68%)]	Loss: -14.8946	Cost: 9.65s
Train Epoch: 964 [81920/90000 (91%)]	Loss: -14.8725	Cost: 9.23s
Train Epoch: 964 	Average Loss: -14.4830
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2971

Learning rate: 0.00015322853919857353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 965 [0/90000 (0%)]	Loss: -9.0715	Cost: 40.73s
Train Epoch: 965 [20480/90000 (23%)]	Loss: -14.9399	Cost: 10.70s
Train Epoch: 965 [40960/90000 (45%)]	Loss: -15.1743	Cost: 11.33s
Train Epoch: 965 [61440/90000 (68%)]	Loss: -14.9924	Cost: 9.67s
Train Epoch: 965 [81920/90000 (91%)]	Loss: -14.7502	Cost: 11.37s
Train Epoch: 965 	Average Loss: -14.4547
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3798

Learning rate: 0.00015313985795180842
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 966 [0/90000 (0%)]	Loss: -9.1038	Cost: 42.62s
Train Epoch: 966 [20480/90000 (23%)]	Loss: -14.9336	Cost: 9.88s
Train Epoch: 966 [40960/90000 (45%)]	Loss: -15.1650	Cost: 12.58s
Train Epoch: 966 [61440/90000 (68%)]	Loss: -14.8768	Cost: 9.67s
Train Epoch: 966 [81920/90000 (91%)]	Loss: -14.9019	Cost: 11.27s
Train Epoch: 966 	Average Loss: -14.5113
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4343

Learning rate: 0.00015305111843067355
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 967 [0/90000 (0%)]	Loss: -9.7228	Cost: 34.39s
Train Epoch: 967 [20480/90000 (23%)]	Loss: -14.8586	Cost: 10.97s
Train Epoch: 967 [40960/90000 (45%)]	Loss: -15.2903	Cost: 16.33s
Train Epoch: 967 [61440/90000 (68%)]	Loss: -14.8863	Cost: 10.04s
Train Epoch: 967 [81920/90000 (91%)]	Loss: -14.9773	Cost: 11.66s
Train Epoch: 967 	Average Loss: -14.5400
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2533

Learning rate: 0.00015296232073248268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 968 [0/90000 (0%)]	Loss: -9.4402	Cost: 30.62s
Train Epoch: 968 [20480/90000 (23%)]	Loss: -14.8738	Cost: 9.71s
Train Epoch: 968 [40960/90000 (45%)]	Loss: -15.0221	Cost: 12.16s
Train Epoch: 968 [61440/90000 (68%)]	Loss: -14.8650	Cost: 10.73s
Train Epoch: 968 [81920/90000 (91%)]	Loss: -14.8709	Cost: 13.47s
Train Epoch: 968 	Average Loss: -14.4989
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3531

Learning rate: 0.00015287346495461332
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 969 [0/90000 (0%)]	Loss: -9.5602	Cost: 32.23s
Train Epoch: 969 [20480/90000 (23%)]	Loss: -14.9034	Cost: 9.84s
Train Epoch: 969 [40960/90000 (45%)]	Loss: -15.0750	Cost: 12.30s
Train Epoch: 969 [61440/90000 (68%)]	Loss: -14.6725	Cost: 11.04s
Train Epoch: 969 [81920/90000 (91%)]	Loss: -14.6663	Cost: 12.34s
Train Epoch: 969 	Average Loss: -14.4497
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2021

Learning rate: 0.0001527845511945068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 970 [0/90000 (0%)]	Loss: -9.6859	Cost: 32.36s
Train Epoch: 970 [20480/90000 (23%)]	Loss: -14.8584	Cost: 10.50s
Train Epoch: 970 [40960/90000 (45%)]	Loss: -15.0082	Cost: 10.99s
Train Epoch: 970 [61440/90000 (68%)]	Loss: -14.8361	Cost: 9.91s
Train Epoch: 970 [81920/90000 (91%)]	Loss: -14.8865	Cost: 11.97s
Train Epoch: 970 	Average Loss: -14.4272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3611

Learning rate: 0.00015269557954966791
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 971 [0/90000 (0%)]	Loss: -9.6005	Cost: 29.99s
Train Epoch: 971 [20480/90000 (23%)]	Loss: -14.9431	Cost: 10.02s
Train Epoch: 971 [40960/90000 (45%)]	Loss: -15.2344	Cost: 12.50s
Train Epoch: 971 [61440/90000 (68%)]	Loss: -15.1177	Cost: 9.76s
Train Epoch: 971 [81920/90000 (91%)]	Loss: -15.1501	Cost: 11.97s
Train Epoch: 971 	Average Loss: -14.6456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5811

Learning rate: 0.000152606550117665
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 972 [0/90000 (0%)]	Loss: -9.0235	Cost: 36.20s
Train Epoch: 972 [20480/90000 (23%)]	Loss: -15.0945	Cost: 9.73s
Train Epoch: 972 [40960/90000 (45%)]	Loss: -15.2977	Cost: 11.16s
Train Epoch: 972 [61440/90000 (68%)]	Loss: -14.9340	Cost: 9.83s
Train Epoch: 972 [81920/90000 (91%)]	Loss: -14.8049	Cost: 11.26s
Train Epoch: 972 	Average Loss: -14.6195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3445

Learning rate: 0.00015251746299612973
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 973 [0/90000 (0%)]	Loss: -9.3793	Cost: 33.06s
Train Epoch: 973 [20480/90000 (23%)]	Loss: -14.9276	Cost: 10.61s
Train Epoch: 973 [40960/90000 (45%)]	Loss: -15.1682	Cost: 11.62s
Train Epoch: 973 [61440/90000 (68%)]	Loss: -14.9747	Cost: 9.53s
Train Epoch: 973 [81920/90000 (91%)]	Loss: -15.0427	Cost: 9.78s
Train Epoch: 973 	Average Loss: -14.5963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5960

Learning rate: 0.00015242831828275705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 974 [0/90000 (0%)]	Loss: -9.1744	Cost: 29.87s
Train Epoch: 974 [20480/90000 (23%)]	Loss: -14.9782	Cost: 9.69s
Train Epoch: 974 [40960/90000 (45%)]	Loss: -15.1318	Cost: 11.37s
Train Epoch: 974 [61440/90000 (68%)]	Loss: -14.9016	Cost: 9.80s
Train Epoch: 974 [81920/90000 (91%)]	Loss: -15.0576	Cost: 12.21s
Train Epoch: 974 	Average Loss: -14.5679
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3786

Learning rate: 0.0001523391160753051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 975 [0/90000 (0%)]	Loss: -9.8446	Cost: 38.59s
Train Epoch: 975 [20480/90000 (23%)]	Loss: -14.8820	Cost: 9.73s
Train Epoch: 975 [40960/90000 (45%)]	Loss: -15.1653	Cost: 10.71s
Train Epoch: 975 [61440/90000 (68%)]	Loss: -15.0297	Cost: 9.59s
Train Epoch: 975 [81920/90000 (91%)]	Loss: -14.7259	Cost: 11.61s
Train Epoch: 975 	Average Loss: -14.5682
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3262

Learning rate: 0.00015224985647159503
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 976 [0/90000 (0%)]	Loss: -8.7188	Cost: 32.75s
Train Epoch: 976 [20480/90000 (23%)]	Loss: -14.9084	Cost: 10.26s
Train Epoch: 976 [40960/90000 (45%)]	Loss: -15.3580	Cost: 12.43s
Train Epoch: 976 [61440/90000 (68%)]	Loss: -15.1226	Cost: 9.62s
Train Epoch: 976 [81920/90000 (91%)]	Loss: -15.1180	Cost: 11.53s
Train Epoch: 976 	Average Loss: -14.6155
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4433

Learning rate: 0.00015216053956951096
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 977 [0/90000 (0%)]	Loss: -9.0429	Cost: 34.08s
Train Epoch: 977 [20480/90000 (23%)]	Loss: -15.0684	Cost: 9.67s
Train Epoch: 977 [40960/90000 (45%)]	Loss: -15.3859	Cost: 10.65s
Train Epoch: 977 [61440/90000 (68%)]	Loss: -14.8277	Cost: 9.64s
Train Epoch: 977 [81920/90000 (91%)]	Loss: -15.0958	Cost: 12.43s
Train Epoch: 977 	Average Loss: -14.7121
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6614

Learning rate: 0.00015207116546699976
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 978 [0/90000 (0%)]	Loss: -10.0738	Cost: 34.36s
Train Epoch: 978 [20480/90000 (23%)]	Loss: -15.0453	Cost: 9.88s
Train Epoch: 978 [40960/90000 (45%)]	Loss: -15.3659	Cost: 12.91s
Train Epoch: 978 [61440/90000 (68%)]	Loss: -15.0534	Cost: 9.98s
Train Epoch: 978 [81920/90000 (91%)]	Loss: -14.9939	Cost: 11.96s
Train Epoch: 978 	Average Loss: -14.7102
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4693

Learning rate: 0.0001519817342620711
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 979 [0/90000 (0%)]	Loss: -9.5661	Cost: 29.45s
Train Epoch: 979 [20480/90000 (23%)]	Loss: -15.0319	Cost: 10.00s
Train Epoch: 979 [40960/90000 (45%)]	Loss: -14.5987	Cost: 12.11s
Train Epoch: 979 [61440/90000 (68%)]	Loss: -14.3184	Cost: 9.65s
Train Epoch: 979 [81920/90000 (91%)]	Loss: -14.6025	Cost: 11.88s
Train Epoch: 979 	Average Loss: -14.2732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.1777

Learning rate: 0.00015189224605279732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 980 [0/90000 (0%)]	Loss: -8.8878	Cost: 37.77s
Train Epoch: 980 [20480/90000 (23%)]	Loss: -14.7820	Cost: 9.81s
Train Epoch: 980 [40960/90000 (45%)]	Loss: -15.2281	Cost: 10.37s
Train Epoch: 980 [61440/90000 (68%)]	Loss: -14.9105	Cost: 9.66s
Train Epoch: 980 [81920/90000 (91%)]	Loss: -15.0554	Cost: 11.58s
Train Epoch: 980 	Average Loss: -14.5421
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5947

Learning rate: 0.0001518027009373132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 981 [0/90000 (0%)]	Loss: -9.2052	Cost: 35.44s
Train Epoch: 981 [20480/90000 (23%)]	Loss: -14.9453	Cost: 10.13s
Train Epoch: 981 [40960/90000 (45%)]	Loss: -15.2586	Cost: 13.13s
Train Epoch: 981 [61440/90000 (68%)]	Loss: -14.9371	Cost: 9.62s
Train Epoch: 981 [81920/90000 (91%)]	Loss: -14.8174	Cost: 12.44s
Train Epoch: 981 	Average Loss: -14.6651
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5795

Learning rate: 0.00015171309901381588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 982 [0/90000 (0%)]	Loss: -9.7942	Cost: 28.83s
Train Epoch: 982 [20480/90000 (23%)]	Loss: -15.2157	Cost: 9.87s
Train Epoch: 982 [40960/90000 (45%)]	Loss: -15.1684	Cost: 12.04s
Train Epoch: 982 [61440/90000 (68%)]	Loss: -15.0350	Cost: 10.35s
Train Epoch: 982 [81920/90000 (91%)]	Loss: -15.1381	Cost: 11.56s
Train Epoch: 982 	Average Loss: -14.6879
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4814

Learning rate: 0.00015162344038056492
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 983 [0/90000 (0%)]	Loss: -9.8558	Cost: 43.15s
Train Epoch: 983 [20480/90000 (23%)]	Loss: -14.9352	Cost: 9.49s
Train Epoch: 983 [40960/90000 (45%)]	Loss: -14.3200	Cost: 9.89s
Train Epoch: 983 [61440/90000 (68%)]	Loss: -13.9965	Cost: 9.75s
Train Epoch: 983 [81920/90000 (91%)]	Loss: -14.1403	Cost: 11.80s
Train Epoch: 983 	Average Loss: -13.9714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.3813

Learning rate: 0.00015153372513588198
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 984 [0/90000 (0%)]	Loss: -8.5041	Cost: 34.52s
Train Epoch: 984 [20480/90000 (23%)]	Loss: -14.3070	Cost: 10.15s
Train Epoch: 984 [40960/90000 (45%)]	Loss: -14.6871	Cost: 11.08s
Train Epoch: 984 [61440/90000 (68%)]	Loss: -14.6036	Cost: 9.80s
Train Epoch: 984 [81920/90000 (91%)]	Loss: -14.9543	Cost: 13.29s
Train Epoch: 984 	Average Loss: -14.1189
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4215

Learning rate: 0.0001514439533781508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 985 [0/90000 (0%)]	Loss: -8.4734	Cost: 30.98s
Train Epoch: 985 [20480/90000 (23%)]	Loss: -15.0664	Cost: 9.87s
Train Epoch: 985 [40960/90000 (45%)]	Loss: -15.4759	Cost: 11.65s
Train Epoch: 985 [61440/90000 (68%)]	Loss: -15.0929	Cost: 9.89s
Train Epoch: 985 [81920/90000 (91%)]	Loss: -15.2075	Cost: 12.25s
Train Epoch: 985 	Average Loss: -14.7185
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5959

Learning rate: 0.00015135412520581718
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 986 [0/90000 (0%)]	Loss: -9.8026	Cost: 45.38s
Train Epoch: 986 [20480/90000 (23%)]	Loss: -15.3082	Cost: 9.54s
Train Epoch: 986 [40960/90000 (45%)]	Loss: -15.5246	Cost: 10.17s
Train Epoch: 986 [61440/90000 (68%)]	Loss: -15.1728	Cost: 9.68s
Train Epoch: 986 [81920/90000 (91%)]	Loss: -15.1826	Cost: 12.70s
Train Epoch: 986 	Average Loss: -14.8518
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7502

Learning rate: 0.00015126424071738867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 987 [0/90000 (0%)]	Loss: -9.9921	Cost: 32.49s
Train Epoch: 987 [20480/90000 (23%)]	Loss: -15.3598	Cost: 10.50s
Train Epoch: 987 [40960/90000 (45%)]	Loss: -15.6691	Cost: 12.28s
Train Epoch: 987 [61440/90000 (68%)]	Loss: -15.1056	Cost: 9.83s
Train Epoch: 987 [81920/90000 (91%)]	Loss: -15.1284	Cost: 11.47s
Train Epoch: 987 	Average Loss: -14.8257
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6852

Learning rate: 0.00015117430001143465
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 988 [0/90000 (0%)]	Loss: -9.0707	Cost: 30.32s
Train Epoch: 988 [20480/90000 (23%)]	Loss: -15.1432	Cost: 9.83s
Train Epoch: 988 [40960/90000 (45%)]	Loss: -15.4679	Cost: 11.88s
Train Epoch: 988 [61440/90000 (68%)]	Loss: -15.1554	Cost: 9.83s
Train Epoch: 988 [81920/90000 (91%)]	Loss: -15.1987	Cost: 12.63s
Train Epoch: 988 	Average Loss: -14.7568
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6411

Learning rate: 0.00015108430318658614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 989 [0/90000 (0%)]	Loss: -8.9168	Cost: 43.70s
Train Epoch: 989 [20480/90000 (23%)]	Loss: -15.1348	Cost: 9.76s
Train Epoch: 989 [40960/90000 (45%)]	Loss: -15.2531	Cost: 10.20s
Train Epoch: 989 [61440/90000 (68%)]	Loss: -14.8488	Cost: 9.72s
Train Epoch: 989 [81920/90000 (91%)]	Loss: -14.9437	Cost: 12.75s
Train Epoch: 989 	Average Loss: -14.7147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4868

Learning rate: 0.00015099425034153567
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 990 [0/90000 (0%)]	Loss: -9.4735	Cost: 33.81s
Train Epoch: 990 [20480/90000 (23%)]	Loss: -15.2282	Cost: 10.69s
Train Epoch: 990 [40960/90000 (45%)]	Loss: -15.4152	Cost: 11.09s
Train Epoch: 990 [61440/90000 (68%)]	Loss: -15.0575	Cost: 9.68s
Train Epoch: 990 [81920/90000 (91%)]	Loss: -14.9548	Cost: 11.46s
Train Epoch: 990 	Average Loss: -14.7086
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4761

Learning rate: 0.00015090414157503727
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 991 [0/90000 (0%)]	Loss: -9.2166	Cost: 30.11s
Train Epoch: 991 [20480/90000 (23%)]	Loss: -15.1645	Cost: 9.79s
Train Epoch: 991 [40960/90000 (45%)]	Loss: -15.4063	Cost: 12.80s
Train Epoch: 991 [61440/90000 (68%)]	Loss: -15.1575	Cost: 9.99s
Train Epoch: 991 [81920/90000 (91%)]	Loss: -15.1497	Cost: 11.88s
Train Epoch: 991 	Average Loss: -14.7411
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5594

Learning rate: 0.00015081397698590623
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 992 [0/90000 (0%)]	Loss: -8.9134	Cost: 37.84s
Train Epoch: 992 [20480/90000 (23%)]	Loss: -15.0831	Cost: 9.60s
Train Epoch: 992 [40960/90000 (45%)]	Loss: -15.1566	Cost: 10.82s
Train Epoch: 992 [61440/90000 (68%)]	Loss: -14.9750	Cost: 9.67s
Train Epoch: 992 [81920/90000 (91%)]	Loss: -15.0605	Cost: 12.13s
Train Epoch: 992 	Average Loss: -14.6622
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6114

Learning rate: 0.00015072375667301907
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 993 [0/90000 (0%)]	Loss: -9.3181	Cost: 33.69s
Train Epoch: 993 [20480/90000 (23%)]	Loss: -15.1448	Cost: 9.93s
Train Epoch: 993 [40960/90000 (45%)]	Loss: -15.3532	Cost: 12.15s
Train Epoch: 993 [61440/90000 (68%)]	Loss: -15.3084	Cost: 9.58s
Train Epoch: 993 [81920/90000 (91%)]	Loss: -15.1021	Cost: 11.93s
Train Epoch: 993 	Average Loss: -14.8238
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7094

Learning rate: 0.00015063348073531338
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 994 [0/90000 (0%)]	Loss: -9.0902	Cost: 69.77s
Train Epoch: 994 [20480/90000 (23%)]	Loss: -15.3865	Cost: 14.14s
Train Epoch: 994 [40960/90000 (45%)]	Loss: -15.2452	Cost: 21.21s
Train Epoch: 994 [61440/90000 (68%)]	Loss: -15.1971	Cost: 13.34s
Train Epoch: 994 [81920/90000 (91%)]	Loss: -15.1781	Cost: 24.22s
Train Epoch: 994 	Average Loss: -14.8380
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8354

Learning rate: 0.00015054314927178788
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 995 [0/90000 (0%)]	Loss: -9.2171	Cost: 77.11s
Train Epoch: 995 [20480/90000 (23%)]	Loss: -15.1703	Cost: 12.90s
Train Epoch: 995 [40960/90000 (45%)]	Loss: -15.4454	Cost: 23.32s
Train Epoch: 995 [61440/90000 (68%)]	Loss: -15.2813	Cost: 14.36s
Train Epoch: 995 [81920/90000 (91%)]	Loss: -15.2754	Cost: 25.89s
Train Epoch: 995 	Average Loss: -14.7961
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5772

Learning rate: 0.00015045276238150206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 996 [0/90000 (0%)]	Loss: -8.9846	Cost: 80.08s
Train Epoch: 996 [20480/90000 (23%)]	Loss: -15.1924	Cost: 13.85s
Train Epoch: 996 [40960/90000 (45%)]	Loss: -15.4670	Cost: 20.94s
Train Epoch: 996 [61440/90000 (68%)]	Loss: -15.2138	Cost: 15.35s
Train Epoch: 996 [81920/90000 (91%)]	Loss: -15.0781	Cost: 27.77s
Train Epoch: 996 	Average Loss: -14.8389
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5304

Learning rate: 0.00015036232016357626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 997 [0/90000 (0%)]	Loss: -9.1397	Cost: 82.87s
Train Epoch: 997 [20480/90000 (23%)]	Loss: -15.0807	Cost: 14.09s
Train Epoch: 997 [40960/90000 (45%)]	Loss: -15.2484	Cost: 33.63s
Train Epoch: 997 [61440/90000 (68%)]	Loss: -15.0125	Cost: 14.49s
Train Epoch: 997 [81920/90000 (91%)]	Loss: -14.9033	Cost: 25.52s
Train Epoch: 997 	Average Loss: -14.6576
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2983

Learning rate: 0.00015027182271719136
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 998 [0/90000 (0%)]	Loss: -9.6295	Cost: 78.50s
Train Epoch: 998 [20480/90000 (23%)]	Loss: -14.9472	Cost: 13.45s
Train Epoch: 998 [40960/90000 (45%)]	Loss: -15.2789	Cost: 27.09s
Train Epoch: 998 [61440/90000 (68%)]	Loss: -14.8999	Cost: 13.29s
Train Epoch: 998 [81920/90000 (91%)]	Loss: -15.0229	Cost: 25.76s
Train Epoch: 998 	Average Loss: -14.6419
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4641

Learning rate: 0.000150181270141589
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 999 [0/90000 (0%)]	Loss: -9.1175	Cost: 84.50s
Train Epoch: 999 [20480/90000 (23%)]	Loss: -14.8458	Cost: 14.99s
Train Epoch: 999 [40960/90000 (45%)]	Loss: -15.3215	Cost: 28.64s
Train Epoch: 999 [61440/90000 (68%)]	Loss: -14.9754	Cost: 13.87s
Train Epoch: 999 [81920/90000 (91%)]	Loss: -15.1934	Cost: 25.38s
Train Epoch: 999 	Average Loss: -14.6419
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6901

Learning rate: 0.00015009066253607114
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1000 [0/90000 (0%)]	Loss: -10.3829	Cost: 84.68s
Train Epoch: 1000 [20480/90000 (23%)]	Loss: -15.3578	Cost: 14.89s
Train Epoch: 1000 [40960/90000 (45%)]	Loss: -15.7434	Cost: 24.58s
Train Epoch: 1000 [61440/90000 (68%)]	Loss: -15.1446	Cost: 13.22s
Train Epoch: 1000 [81920/90000 (91%)]	Loss: -15.1489	Cost: 24.06s
Train Epoch: 1000 	Average Loss: -14.8988
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6845

Saving model as model.pt_e1000 & waveforms_supplementary.hdf5_e1000
Learning rate: 0.00015000000000000015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1001 [0/90000 (0%)]	Loss: -9.3547	Cost: 84.56s
Train Epoch: 1001 [20480/90000 (23%)]	Loss: -15.3112	Cost: 13.97s
Train Epoch: 1001 [40960/90000 (45%)]	Loss: -15.4717	Cost: 22.21s
Train Epoch: 1001 [61440/90000 (68%)]	Loss: -15.2767	Cost: 11.98s
Train Epoch: 1001 [81920/90000 (91%)]	Loss: -15.2344	Cost: 23.42s
Train Epoch: 1001 	Average Loss: -14.8694
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7158

Learning rate: 0.0001499092826327986
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1002 [0/90000 (0%)]	Loss: -9.0687	Cost: 82.04s
Train Epoch: 1002 [20480/90000 (23%)]	Loss: -15.2599	Cost: 13.72s
Train Epoch: 1002 [40960/90000 (45%)]	Loss: -14.2821	Cost: 26.70s
Train Epoch: 1002 [61440/90000 (68%)]	Loss: -14.0574	Cost: 12.95s
Train Epoch: 1002 [81920/90000 (91%)]	Loss: -14.1902	Cost: 23.60s
Train Epoch: 1002 	Average Loss: -14.0551
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -8.7594

Learning rate: 0.00014981851053394923
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1003 [0/90000 (0%)]	Loss: -8.7260	Cost: 80.17s
Train Epoch: 1003 [20480/90000 (23%)]	Loss: -14.3714	Cost: 14.16s
Train Epoch: 1003 [40960/90000 (45%)]	Loss: -15.1389	Cost: 21.34s
Train Epoch: 1003 [61440/90000 (68%)]	Loss: -14.9852	Cost: 13.11s
Train Epoch: 1003 [81920/90000 (91%)]	Loss: -14.5770	Cost: 23.43s
Train Epoch: 1003 	Average Loss: -14.3250
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3442

Learning rate: 0.00014972768380299478
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1004 [0/90000 (0%)]	Loss: -9.1320	Cost: 39.59s
Train Epoch: 1004 [20480/90000 (23%)]	Loss: -15.0565	Cost: 9.75s
Train Epoch: 1004 [40960/90000 (45%)]	Loss: -15.3740	Cost: 11.71s
Train Epoch: 1004 [61440/90000 (68%)]	Loss: -14.3645	Cost: 9.99s
Train Epoch: 1004 [81920/90000 (91%)]	Loss: -14.4390	Cost: 12.11s
Train Epoch: 1004 	Average Loss: -14.3371
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.2056

Learning rate: 0.00014963680253953784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1005 [0/90000 (0%)]	Loss: -8.5166	Cost: 30.30s
Train Epoch: 1005 [20480/90000 (23%)]	Loss: -14.6271	Cost: 10.26s
Train Epoch: 1005 [40960/90000 (45%)]	Loss: -15.0315	Cost: 12.30s
Train Epoch: 1005 [61440/90000 (68%)]	Loss: -15.0235	Cost: 9.67s
Train Epoch: 1005 [81920/90000 (91%)]	Loss: -15.1027	Cost: 10.85s
Train Epoch: 1005 	Average Loss: -14.5347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6400

Learning rate: 0.0001495458668432409
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1006 [0/90000 (0%)]	Loss: -9.3502	Cost: 31.78s
Train Epoch: 1006 [20480/90000 (23%)]	Loss: -15.2153	Cost: 9.58s
Train Epoch: 1006 [40960/90000 (45%)]	Loss: -15.4668	Cost: 11.20s
Train Epoch: 1006 [61440/90000 (68%)]	Loss: -15.0518	Cost: 9.71s
Train Epoch: 1006 [81920/90000 (91%)]	Loss: -15.1783	Cost: 13.67s
Train Epoch: 1006 	Average Loss: -14.8244
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6173

Learning rate: 0.00014945487681382612
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1007 [0/90000 (0%)]	Loss: -9.7339	Cost: 35.45s
Train Epoch: 1007 [20480/90000 (23%)]	Loss: -15.5344	Cost: 9.84s
Train Epoch: 1007 [40960/90000 (45%)]	Loss: -15.7407	Cost: 11.27s
Train Epoch: 1007 [61440/90000 (68%)]	Loss: -15.3943	Cost: 9.65s
Train Epoch: 1007 [81920/90000 (91%)]	Loss: -15.2885	Cost: 11.37s
Train Epoch: 1007 	Average Loss: -14.9834
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8321

Learning rate: 0.00014936383255107519
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1008 [0/90000 (0%)]	Loss: -9.6092	Cost: 31.13s
Train Epoch: 1008 [20480/90000 (23%)]	Loss: -15.3339	Cost: 9.81s
Train Epoch: 1008 [40960/90000 (45%)]	Loss: -15.6369	Cost: 10.94s
Train Epoch: 1008 [61440/90000 (68%)]	Loss: -15.3190	Cost: 10.23s
Train Epoch: 1008 [81920/90000 (91%)]	Loss: -15.1738	Cost: 11.71s
Train Epoch: 1008 	Average Loss: -15.0140
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8726

Learning rate: 0.0001492727341548293
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1009 [0/90000 (0%)]	Loss: -9.6588	Cost: 40.65s
Train Epoch: 1009 [20480/90000 (23%)]	Loss: -15.3470	Cost: 9.87s
Train Epoch: 1009 [40960/90000 (45%)]	Loss: -15.6859	Cost: 10.26s
Train Epoch: 1009 [61440/90000 (68%)]	Loss: -15.3452	Cost: 9.49s
Train Epoch: 1009 [81920/90000 (91%)]	Loss: -15.1048	Cost: 9.42s
Train Epoch: 1009 	Average Loss: -14.9581
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4223

Learning rate: 0.00014918158172498906
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1010 [0/90000 (0%)]	Loss: -8.6081	Cost: 35.83s
Train Epoch: 1010 [20480/90000 (23%)]	Loss: -15.1914	Cost: 12.31s
Train Epoch: 1010 [40960/90000 (45%)]	Loss: -15.4569	Cost: 13.24s
Train Epoch: 1010 [61440/90000 (68%)]	Loss: -15.3443	Cost: 9.75s
Train Epoch: 1010 [81920/90000 (91%)]	Loss: -15.2395	Cost: 9.75s
Train Epoch: 1010 	Average Loss: -14.8146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7891

Learning rate: 0.00014909037536151425
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1011 [0/90000 (0%)]	Loss: -10.2575	Cost: 38.88s
Train Epoch: 1011 [20480/90000 (23%)]	Loss: -15.0203	Cost: 9.97s
Train Epoch: 1011 [40960/90000 (45%)]	Loss: -15.1895	Cost: 12.13s
Train Epoch: 1011 [61440/90000 (68%)]	Loss: -15.1281	Cost: 9.78s
Train Epoch: 1011 [81920/90000 (91%)]	Loss: -14.9830	Cost: 12.57s
Train Epoch: 1011 	Average Loss: -14.8160
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.5145

Learning rate: 0.00014899911516442384
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1012 [0/90000 (0%)]	Loss: -9.5054	Cost: 38.65s
Train Epoch: 1012 [20480/90000 (23%)]	Loss: -14.7914	Cost: 12.73s
Train Epoch: 1012 [40960/90000 (45%)]	Loss: -15.4157	Cost: 14.97s
Train Epoch: 1012 [61440/90000 (68%)]	Loss: -15.3296	Cost: 9.71s
Train Epoch: 1012 [81920/90000 (91%)]	Loss: -15.3205	Cost: 12.81s
Train Epoch: 1012 	Average Loss: -14.7693
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8454

Learning rate: 0.0001489078012337958
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1013 [0/90000 (0%)]	Loss: -9.2764	Cost: 36.42s
Train Epoch: 1013 [20480/90000 (23%)]	Loss: -14.9793	Cost: 9.87s
Train Epoch: 1013 [40960/90000 (45%)]	Loss: -15.2254	Cost: 14.15s
Train Epoch: 1013 [61440/90000 (68%)]	Loss: -15.2262	Cost: 10.85s
Train Epoch: 1013 [81920/90000 (91%)]	Loss: -15.1463	Cost: 10.44s
Train Epoch: 1013 	Average Loss: -14.7673
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8520

Learning rate: 0.00014881643366976708
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1014 [0/90000 (0%)]	Loss: -9.3057	Cost: 30.99s
Train Epoch: 1014 [20480/90000 (23%)]	Loss: -14.9502	Cost: 10.04s
Train Epoch: 1014 [40960/90000 (45%)]	Loss: -15.2951	Cost: 14.87s
Train Epoch: 1014 [61440/90000 (68%)]	Loss: -15.1907	Cost: 10.69s
Train Epoch: 1014 [81920/90000 (91%)]	Loss: -15.2536	Cost: 12.23s
Train Epoch: 1014 	Average Loss: -14.7442
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8844

Learning rate: 0.0001487250125725334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1015 [0/90000 (0%)]	Loss: -9.6382	Cost: 34.23s
Train Epoch: 1015 [20480/90000 (23%)]	Loss: -15.3146	Cost: 9.75s
Train Epoch: 1015 [40960/90000 (45%)]	Loss: -15.2918	Cost: 12.41s
Train Epoch: 1015 [61440/90000 (68%)]	Loss: -15.1142	Cost: 11.16s
Train Epoch: 1015 [81920/90000 (91%)]	Loss: -14.9908	Cost: 11.04s
Train Epoch: 1015 	Average Loss: -14.7655
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.7034

Learning rate: 0.0001486335380423492
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1016 [0/90000 (0%)]	Loss: -9.3702	Cost: 32.53s
Train Epoch: 1016 [20480/90000 (23%)]	Loss: -15.1606	Cost: 10.69s
Train Epoch: 1016 [40960/90000 (45%)]	Loss: -15.5326	Cost: 11.80s
Train Epoch: 1016 [61440/90000 (68%)]	Loss: -15.2538	Cost: 9.61s
Train Epoch: 1016 [81920/90000 (91%)]	Loss: -14.8409	Cost: 10.49s
Train Epoch: 1016 	Average Loss: -14.6895
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6751

Learning rate: 0.00014854201017952757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1017 [0/90000 (0%)]	Loss: -8.7781	Cost: 29.54s
Train Epoch: 1017 [20480/90000 (23%)]	Loss: -15.2081	Cost: 9.71s
Train Epoch: 1017 [40960/90000 (45%)]	Loss: -15.5429	Cost: 11.08s
Train Epoch: 1017 [61440/90000 (68%)]	Loss: -15.4069	Cost: 9.72s
Train Epoch: 1017 [81920/90000 (91%)]	Loss: -15.4544	Cost: 12.25s
Train Epoch: 1017 	Average Loss: -14.8937
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.9071

Learning rate: 0.00014845042908444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1018 [0/90000 (0%)]	Loss: -9.9240	Cost: 40.35s
Train Epoch: 1018 [20480/90000 (23%)]	Loss: -15.6865	Cost: 9.67s
Train Epoch: 1018 [40960/90000 (45%)]	Loss: -15.8787	Cost: 10.52s
Train Epoch: 1018 [61440/90000 (68%)]	Loss: -15.6613	Cost: 9.71s
Train Epoch: 1018 [81920/90000 (91%)]	Loss: -15.5739	Cost: 11.25s
Train Epoch: 1018 	Average Loss: -15.2433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.3074

Learning rate: 0.00014835879485751633
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1019 [0/90000 (0%)]	Loss: -10.1466	Cost: 32.60s
Train Epoch: 1019 [20480/90000 (23%)]	Loss: -15.9341	Cost: 10.02s
Train Epoch: 1019 [40960/90000 (45%)]	Loss: -15.7288	Cost: 11.81s
Train Epoch: 1019 [61440/90000 (68%)]	Loss: -15.6193	Cost: 9.79s
Train Epoch: 1019 [81920/90000 (91%)]	Loss: -15.4430	Cost: 10.54s
Train Epoch: 1019 	Average Loss: -15.2721
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1198

Learning rate: 0.0001482671075992448
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1020 [0/90000 (0%)]	Loss: -10.2262	Cost: 34.37s
Train Epoch: 1020 [20480/90000 (23%)]	Loss: -15.5363	Cost: 9.81s
Train Epoch: 1020 [40960/90000 (45%)]	Loss: -16.1512	Cost: 10.25s
Train Epoch: 1020 [61440/90000 (68%)]	Loss: -15.6016	Cost: 9.68s
Train Epoch: 1020 [81920/90000 (91%)]	Loss: -15.4858	Cost: 10.92s
Train Epoch: 1020 	Average Loss: -15.2440
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1143

Learning rate: 0.00014817536741017171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1021 [0/90000 (0%)]	Loss: -9.1761	Cost: 38.52s
Train Epoch: 1021 [20480/90000 (23%)]	Loss: -15.4540	Cost: 9.79s
Train Epoch: 1021 [40960/90000 (45%)]	Loss: -15.8318	Cost: 10.91s
Train Epoch: 1021 [61440/90000 (68%)]	Loss: -15.5601	Cost: 9.61s
Train Epoch: 1021 [81920/90000 (91%)]	Loss: -15.4768	Cost: 11.15s
Train Epoch: 1021 	Average Loss: -15.1776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.0012

Learning rate: 0.00014808357439090143
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1022 [0/90000 (0%)]	Loss: -9.6373	Cost: 33.66s
Train Epoch: 1022 [20480/90000 (23%)]	Loss: -15.5486	Cost: 9.77s
Train Epoch: 1022 [40960/90000 (45%)]	Loss: -16.0594	Cost: 10.86s
Train Epoch: 1022 [61440/90000 (68%)]	Loss: -15.7049	Cost: 10.15s
Train Epoch: 1022 [81920/90000 (91%)]	Loss: -15.8000	Cost: 11.59s
Train Epoch: 1022 	Average Loss: -15.3093
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2432

Learning rate: 0.00014799172864209624
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1023 [0/90000 (0%)]	Loss: -9.9762	Cost: 47.38s
Train Epoch: 1023 [20480/90000 (23%)]	Loss: -15.6035	Cost: 9.68s
Train Epoch: 1023 [40960/90000 (45%)]	Loss: -15.8845	Cost: 9.87s
Train Epoch: 1023 [61440/90000 (68%)]	Loss: -15.5387	Cost: 9.84s
Train Epoch: 1023 [81920/90000 (91%)]	Loss: -14.6132	Cost: 10.66s
Train Epoch: 1023 	Average Loss: -15.0625
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3986

Learning rate: 0.00014789983026447629
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1024 [0/90000 (0%)]	Loss: -9.2490	Cost: 33.81s
Train Epoch: 1024 [20480/90000 (23%)]	Loss: -14.9195	Cost: 9.71s
Train Epoch: 1024 [40960/90000 (45%)]	Loss: -15.3638	Cost: 12.80s
Train Epoch: 1024 [61440/90000 (68%)]	Loss: -15.3622	Cost: 9.61s
Train Epoch: 1024 [81920/90000 (91%)]	Loss: -15.4474	Cost: 12.03s
Train Epoch: 1024 	Average Loss: -14.7405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.9066

Learning rate: 0.0001478078793588194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1025 [0/90000 (0%)]	Loss: -9.8364	Cost: 31.06s
Train Epoch: 1025 [20480/90000 (23%)]	Loss: -14.9493	Cost: 9.83s
Train Epoch: 1025 [40960/90000 (45%)]	Loss: -15.2998	Cost: 11.49s
Train Epoch: 1025 [61440/90000 (68%)]	Loss: -15.0103	Cost: 9.94s
Train Epoch: 1025 [81920/90000 (91%)]	Loss: -15.3037	Cost: 12.11s
Train Epoch: 1025 	Average Loss: -14.8423
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8821

Learning rate: 0.000147715876025961
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1026 [0/90000 (0%)]	Loss: -9.7643	Cost: 45.88s
Train Epoch: 1026 [20480/90000 (23%)]	Loss: -15.6226	Cost: 9.78s
Train Epoch: 1026 [40960/90000 (45%)]	Loss: -15.4997	Cost: 9.86s
Train Epoch: 1026 [61440/90000 (68%)]	Loss: -15.2852	Cost: 9.73s
Train Epoch: 1026 [81920/90000 (91%)]	Loss: -15.3585	Cost: 10.52s
Train Epoch: 1026 	Average Loss: -14.9646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8644

Learning rate: 0.00014762382036679405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1027 [0/90000 (0%)]	Loss: -9.6080	Cost: 33.80s
Train Epoch: 1027 [20480/90000 (23%)]	Loss: -15.5629	Cost: 10.02s
Train Epoch: 1027 [40960/90000 (45%)]	Loss: -15.6545	Cost: 11.44s
Train Epoch: 1027 [61440/90000 (68%)]	Loss: -15.6215	Cost: 9.92s
Train Epoch: 1027 [81920/90000 (91%)]	Loss: -15.5448	Cost: 11.97s
Train Epoch: 1027 	Average Loss: -15.1703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.9499

Learning rate: 0.00014753171248226888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1028 [0/90000 (0%)]	Loss: -9.6401	Cost: 30.21s
Train Epoch: 1028 [20480/90000 (23%)]	Loss: -15.6364	Cost: 9.69s
Train Epoch: 1028 [40960/90000 (45%)]	Loss: -16.0078	Cost: 10.93s
Train Epoch: 1028 [61440/90000 (68%)]	Loss: -15.5550	Cost: 9.74s
Train Epoch: 1028 [81920/90000 (91%)]	Loss: -15.6123	Cost: 12.34s
Train Epoch: 1028 	Average Loss: -15.2472
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.0231

Learning rate: 0.0001474395524733931
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1029 [0/90000 (0%)]	Loss: -9.7186	Cost: 37.28s
Train Epoch: 1029 [20480/90000 (23%)]	Loss: -15.6198	Cost: 9.87s
Train Epoch: 1029 [40960/90000 (45%)]	Loss: -15.9354	Cost: 11.23s
Train Epoch: 1029 [61440/90000 (68%)]	Loss: -15.7674	Cost: 9.54s
Train Epoch: 1029 [81920/90000 (91%)]	Loss: -15.7362	Cost: 10.21s
Train Epoch: 1029 	Average Loss: -15.2991
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2562

Learning rate: 0.00014734734044123134
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1030 [0/90000 (0%)]	Loss: -10.1128	Cost: 35.72s
Train Epoch: 1030 [20480/90000 (23%)]	Loss: -15.6298	Cost: 9.92s
Train Epoch: 1030 [40960/90000 (45%)]	Loss: -15.9784	Cost: 11.33s
Train Epoch: 1030 [61440/90000 (68%)]	Loss: -15.7716	Cost: 9.76s
Train Epoch: 1030 [81920/90000 (91%)]	Loss: -15.5847	Cost: 12.12s
Train Epoch: 1030 	Average Loss: -15.3251
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2121

Learning rate: 0.00014725507648690554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1031 [0/90000 (0%)]	Loss: -9.8060	Cost: 46.86s
Train Epoch: 1031 [20480/90000 (23%)]	Loss: -15.6380	Cost: 9.55s
Train Epoch: 1031 [40960/90000 (45%)]	Loss: -16.1607	Cost: 10.06s
Train Epoch: 1031 [61440/90000 (68%)]	Loss: -15.6957	Cost: 9.41s
Train Epoch: 1031 [81920/90000 (91%)]	Loss: -15.8287	Cost: 9.41s
Train Epoch: 1031 	Average Loss: -15.3389
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1864

Learning rate: 0.00014716276071159438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1032 [0/90000 (0%)]	Loss: -9.7472	Cost: 35.93s
Train Epoch: 1032 [20480/90000 (23%)]	Loss: -15.7410	Cost: 10.07s
Train Epoch: 1032 [40960/90000 (45%)]	Loss: -16.0517	Cost: 12.03s
Train Epoch: 1032 [61440/90000 (68%)]	Loss: -15.8586	Cost: 9.71s
Train Epoch: 1032 [81920/90000 (91%)]	Loss: -15.6355	Cost: 12.28s
Train Epoch: 1032 	Average Loss: -15.3591
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1937

Learning rate: 0.0001470703932165334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1033 [0/90000 (0%)]	Loss: -9.7230	Cost: 39.17s
Train Epoch: 1033 [20480/90000 (23%)]	Loss: -15.8204	Cost: 9.67s
Train Epoch: 1033 [40960/90000 (45%)]	Loss: -16.0740	Cost: 10.17s
Train Epoch: 1033 [61440/90000 (68%)]	Loss: -15.7380	Cost: 9.57s
Train Epoch: 1033 [81920/90000 (91%)]	Loss: -15.7056	Cost: 12.09s
Train Epoch: 1033 	Average Loss: -15.4326
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2347

Learning rate: 0.00014697797410301492
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1034 [0/90000 (0%)]	Loss: -10.1894	Cost: 40.06s
Train Epoch: 1034 [20480/90000 (23%)]	Loss: -15.9090	Cost: 10.54s
Train Epoch: 1034 [40960/90000 (45%)]	Loss: -16.0150	Cost: 10.93s
Train Epoch: 1034 [61440/90000 (68%)]	Loss: -15.7439	Cost: 9.55s
Train Epoch: 1034 [81920/90000 (91%)]	Loss: -15.6930	Cost: 9.31s
Train Epoch: 1034 	Average Loss: -15.4456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2722

Learning rate: 0.00014688550347238783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1035 [0/90000 (0%)]	Loss: -10.5277	Cost: 40.77s
Train Epoch: 1035 [20480/90000 (23%)]	Loss: -15.8473	Cost: 10.00s
Train Epoch: 1035 [40960/90000 (45%)]	Loss: -16.1283	Cost: 11.47s
Train Epoch: 1035 [61440/90000 (68%)]	Loss: -15.6703	Cost: 9.84s
Train Epoch: 1035 [81920/90000 (91%)]	Loss: -15.8592	Cost: 12.15s
Train Epoch: 1035 	Average Loss: -15.4667
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2174

Learning rate: 0.00014679298142605747
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1036 [0/90000 (0%)]	Loss: -10.4494	Cost: 52.73s
Train Epoch: 1036 [20480/90000 (23%)]	Loss: -15.9756	Cost: 9.79s
Train Epoch: 1036 [40960/90000 (45%)]	Loss: -14.6586	Cost: 9.90s
Train Epoch: 1036 [61440/90000 (68%)]	Loss: -14.5988	Cost: 9.56s
Train Epoch: 1036 [81920/90000 (91%)]	Loss: -14.9376	Cost: 9.55s
Train Epoch: 1036 	Average Loss: -14.6498
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3700

Learning rate: 0.0001467004080654857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1037 [0/90000 (0%)]	Loss: -9.4010	Cost: 37.24s
Train Epoch: 1037 [20480/90000 (23%)]	Loss: -15.1977	Cost: 9.88s
Train Epoch: 1037 [40960/90000 (45%)]	Loss: -15.5495	Cost: 11.93s
Train Epoch: 1037 [61440/90000 (68%)]	Loss: -15.3768	Cost: 9.80s
Train Epoch: 1037 [81920/90000 (91%)]	Loss: -15.5658	Cost: 12.10s
Train Epoch: 1037 	Average Loss: -14.9289
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1248

Learning rate: 0.00014660778349219044
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1038 [0/90000 (0%)]	Loss: -10.2706	Cost: 38.61s
Train Epoch: 1038 [20480/90000 (23%)]	Loss: -14.6507	Cost: 9.69s
Train Epoch: 1038 [40960/90000 (45%)]	Loss: -15.0305	Cost: 10.45s
Train Epoch: 1038 [61440/90000 (68%)]	Loss: -15.1521	Cost: 9.45s
Train Epoch: 1038 [81920/90000 (91%)]	Loss: -14.9225	Cost: 9.34s
Train Epoch: 1038 	Average Loss: -14.5900
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.6841

Learning rate: 0.00014651510780774597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1039 [0/90000 (0%)]	Loss: -9.5824	Cost: 35.49s
Train Epoch: 1039 [20480/90000 (23%)]	Loss: -15.0799	Cost: 11.84s
Train Epoch: 1039 [40960/90000 (45%)]	Loss: -15.9056	Cost: 12.32s
Train Epoch: 1039 [61440/90000 (68%)]	Loss: -15.4292	Cost: 9.59s
Train Epoch: 1039 [81920/90000 (91%)]	Loss: -15.6187	Cost: 11.49s
Train Epoch: 1039 	Average Loss: -15.0848
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1099

Learning rate: 0.00014642238111378254
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1040 [0/90000 (0%)]	Loss: -10.5106	Cost: 44.31s
Train Epoch: 1040 [20480/90000 (23%)]	Loss: -15.4459	Cost: 9.88s
Train Epoch: 1040 [40960/90000 (45%)]	Loss: -15.9626	Cost: 13.06s
Train Epoch: 1040 [61440/90000 (68%)]	Loss: -15.4587	Cost: 10.11s
Train Epoch: 1040 [81920/90000 (91%)]	Loss: -15.4766	Cost: 11.81s
Train Epoch: 1040 	Average Loss: -15.2074
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.0546

Learning rate: 0.00014632960351198632
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1041 [0/90000 (0%)]	Loss: -9.7605	Cost: 38.90s
Train Epoch: 1041 [20480/90000 (23%)]	Loss: -15.6883	Cost: 12.60s
Train Epoch: 1041 [40960/90000 (45%)]	Loss: -16.1348	Cost: 11.64s
Train Epoch: 1041 [61440/90000 (68%)]	Loss: -15.8697	Cost: 9.77s
Train Epoch: 1041 [81920/90000 (91%)]	Loss: -15.8298	Cost: 11.08s
Train Epoch: 1041 	Average Loss: -15.4416
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2622

Learning rate: 0.00014623677510409929
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1042 [0/90000 (0%)]	Loss: -9.7838	Cost: 35.67s
Train Epoch: 1042 [20480/90000 (23%)]	Loss: -15.9589	Cost: 11.64s
Train Epoch: 1042 [40960/90000 (45%)]	Loss: -16.2696	Cost: 12.40s
Train Epoch: 1042 [61440/90000 (68%)]	Loss: -15.7675	Cost: 9.77s
Train Epoch: 1042 [81920/90000 (91%)]	Loss: -15.9237	Cost: 14.62s
Train Epoch: 1042 	Average Loss: -15.5864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.3556

Learning rate: 0.00014614389599191928
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1043 [0/90000 (0%)]	Loss: -10.1661	Cost: 30.66s
Train Epoch: 1043 [20480/90000 (23%)]	Loss: -15.9137	Cost: 11.34s
Train Epoch: 1043 [40960/90000 (45%)]	Loss: -16.2231	Cost: 12.49s
Train Epoch: 1043 [61440/90000 (68%)]	Loss: -15.8875	Cost: 12.02s
Train Epoch: 1043 [81920/90000 (91%)]	Loss: -15.7641	Cost: 9.85s
Train Epoch: 1043 	Average Loss: -15.5647
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2652

Learning rate: 0.00014605096627729955
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1044 [0/90000 (0%)]	Loss: -10.1516	Cost: 36.17s
Train Epoch: 1044 [20480/90000 (23%)]	Loss: -15.3764	Cost: 9.83s
Train Epoch: 1044 [40960/90000 (45%)]	Loss: -15.0152	Cost: 11.30s
Train Epoch: 1044 [61440/90000 (68%)]	Loss: -14.8163	Cost: 9.78s
Train Epoch: 1044 [81920/90000 (91%)]	Loss: -14.7440	Cost: 14.93s
Train Epoch: 1044 	Average Loss: -14.7156
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.4512

Learning rate: 0.00014595798606214892
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1045 [0/90000 (0%)]	Loss: -9.0955	Cost: 29.44s
Train Epoch: 1045 [20480/90000 (23%)]	Loss: -15.3289	Cost: 9.76s
Train Epoch: 1045 [40960/90000 (45%)]	Loss: -15.7939	Cost: 11.87s
Train Epoch: 1045 [61440/90000 (68%)]	Loss: -15.6377	Cost: 9.81s
Train Epoch: 1045 [81920/90000 (91%)]	Loss: -15.3782	Cost: 12.60s
Train Epoch: 1045 	Average Loss: -15.0127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1383

Learning rate: 0.0001458649554484316
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1046 [0/90000 (0%)]	Loss: -9.6479	Cost: 36.88s
Train Epoch: 1046 [20480/90000 (23%)]	Loss: -15.6689	Cost: 9.77s
Train Epoch: 1046 [40960/90000 (45%)]	Loss: -16.0626	Cost: 12.14s
Train Epoch: 1046 [61440/90000 (68%)]	Loss: -15.7198	Cost: 10.20s
Train Epoch: 1046 [81920/90000 (91%)]	Loss: -15.6892	Cost: 11.77s
Train Epoch: 1046 	Average Loss: -15.3374
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.0577

Learning rate: 0.00014577187453816714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1047 [0/90000 (0%)]	Loss: -10.0070	Cost: 31.92s
Train Epoch: 1047 [20480/90000 (23%)]	Loss: -15.6822	Cost: 10.97s
Train Epoch: 1047 [40960/90000 (45%)]	Loss: -16.0917	Cost: 11.63s
Train Epoch: 1047 [61440/90000 (68%)]	Loss: -15.8162	Cost: 9.59s
Train Epoch: 1047 [81920/90000 (91%)]	Loss: -15.8537	Cost: 10.52s
Train Epoch: 1047 	Average Loss: -15.3987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.3836

Learning rate: 0.0001456787434334301
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1048 [0/90000 (0%)]	Loss: -9.8952	Cost: 31.12s
Train Epoch: 1048 [20480/90000 (23%)]	Loss: -16.0789	Cost: 9.73s
Train Epoch: 1048 [40960/90000 (45%)]	Loss: -16.1926	Cost: 10.83s
Train Epoch: 1048 [61440/90000 (68%)]	Loss: -15.4459	Cost: 9.78s
Train Epoch: 1048 [81920/90000 (91%)]	Loss: -15.6880	Cost: 11.80s
Train Epoch: 1048 	Average Loss: -15.4391
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1895

Learning rate: 0.00014558556223635016
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1049 [0/90000 (0%)]	Loss: -10.2677	Cost: 36.53s
Train Epoch: 1049 [20480/90000 (23%)]	Loss: -15.9688	Cost: 9.80s
Train Epoch: 1049 [40960/90000 (45%)]	Loss: -16.0879	Cost: 11.89s
Train Epoch: 1049 [61440/90000 (68%)]	Loss: -15.9667	Cost: 9.64s
Train Epoch: 1049 [81920/90000 (91%)]	Loss: -15.7550	Cost: 12.48s
Train Epoch: 1049 	Average Loss: -15.4902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2194

Learning rate: 0.00014549233104911195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1050 [0/90000 (0%)]	Loss: -9.7643	Cost: 30.07s
Train Epoch: 1050 [20480/90000 (23%)]	Loss: -15.6500	Cost: 10.18s
Train Epoch: 1050 [40960/90000 (45%)]	Loss: -16.1300	Cost: 11.68s
Train Epoch: 1050 [61440/90000 (68%)]	Loss: -15.7301	Cost: 10.00s
Train Epoch: 1050 [81920/90000 (91%)]	Loss: -15.8306	Cost: 11.91s
Train Epoch: 1050 	Average Loss: -15.3792
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2719

Saving model as model.pt_e1050 & waveforms_supplementary.hdf5_e1050
Learning rate: 0.00014539904997395485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1051 [0/90000 (0%)]	Loss: -9.7385	Cost: 34.36s
Train Epoch: 1051 [20480/90000 (23%)]	Loss: -15.8006	Cost: 10.02s
Train Epoch: 1051 [40960/90000 (45%)]	Loss: -16.0388	Cost: 9.85s
Train Epoch: 1051 [61440/90000 (68%)]	Loss: -15.7481	Cost: 9.71s
Train Epoch: 1051 [81920/90000 (91%)]	Loss: -15.6057	Cost: 12.67s
Train Epoch: 1051 	Average Loss: -15.4300
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.3723

Learning rate: 0.00014530571911317307
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1052 [0/90000 (0%)]	Loss: -10.7101	Cost: 38.15s
Train Epoch: 1052 [20480/90000 (23%)]	Loss: -15.8441	Cost: 9.77s
Train Epoch: 1052 [40960/90000 (45%)]	Loss: -16.1684	Cost: 10.99s
Train Epoch: 1052 [61440/90000 (68%)]	Loss: -15.8024	Cost: 9.67s
Train Epoch: 1052 [81920/90000 (91%)]	Loss: -15.7372	Cost: 11.00s
Train Epoch: 1052 	Average Loss: -15.4647
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2693

Learning rate: 0.00014521233856911524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1053 [0/90000 (0%)]	Loss: -9.7094	Cost: 31.88s
Train Epoch: 1053 [20480/90000 (23%)]	Loss: -15.9553	Cost: 10.29s
Train Epoch: 1053 [40960/90000 (45%)]	Loss: -16.3712	Cost: 12.21s
Train Epoch: 1053 [61440/90000 (68%)]	Loss: -15.6938	Cost: 9.82s
Train Epoch: 1053 [81920/90000 (91%)]	Loss: -15.7435	Cost: 11.06s
Train Epoch: 1053 	Average Loss: -15.5126
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2793

Learning rate: 0.0001451189084441847
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1054 [0/90000 (0%)]	Loss: -9.8268	Cost: 34.63s
Train Epoch: 1054 [20480/90000 (23%)]	Loss: -15.7938	Cost: 9.90s
Train Epoch: 1054 [40960/90000 (45%)]	Loss: -16.0838	Cost: 9.90s
Train Epoch: 1054 [61440/90000 (68%)]	Loss: -15.9113	Cost: 9.75s
Train Epoch: 1054 [81920/90000 (91%)]	Loss: -16.0747	Cost: 11.38s
Train Epoch: 1054 	Average Loss: -15.4632
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5425

Learning rate: 0.00014502542884083894
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1055 [0/90000 (0%)]	Loss: -10.4547	Cost: 36.81s
Train Epoch: 1055 [20480/90000 (23%)]	Loss: -16.3194	Cost: 10.41s
Train Epoch: 1055 [40960/90000 (45%)]	Loss: -16.3712	Cost: 10.64s
Train Epoch: 1055 [61440/90000 (68%)]	Loss: -16.0447	Cost: 9.67s
Train Epoch: 1055 [81920/90000 (91%)]	Loss: -16.0889	Cost: 11.59s
Train Epoch: 1055 	Average Loss: -15.7309
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5104

Learning rate: 0.00014493189986158986
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1056 [0/90000 (0%)]	Loss: -9.9902	Cost: 30.75s
Train Epoch: 1056 [20480/90000 (23%)]	Loss: -16.2523	Cost: 10.14s
Train Epoch: 1056 [40960/90000 (45%)]	Loss: -16.4247	Cost: 12.10s
Train Epoch: 1056 [61440/90000 (68%)]	Loss: -15.9464	Cost: 10.11s
Train Epoch: 1056 [81920/90000 (91%)]	Loss: -15.8239	Cost: 11.38s
Train Epoch: 1056 	Average Loss: -15.7085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.6185

Learning rate: 0.00014483832160900342
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1057 [0/90000 (0%)]	Loss: -10.1818	Cost: 37.22s
Train Epoch: 1057 [20480/90000 (23%)]	Loss: -15.6176	Cost: 9.76s
Train Epoch: 1057 [40960/90000 (45%)]	Loss: -15.6413	Cost: 10.26s
Train Epoch: 1057 [61440/90000 (68%)]	Loss: -15.4164	Cost: 9.80s
Train Epoch: 1057 [81920/90000 (91%)]	Loss: -15.5976	Cost: 11.01s
Train Epoch: 1057 	Average Loss: -15.2471
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2081

Learning rate: 0.00014474469418569968
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1058 [0/90000 (0%)]	Loss: -10.4252	Cost: 36.64s
Train Epoch: 1058 [20480/90000 (23%)]	Loss: -15.8957	Cost: 10.47s
Train Epoch: 1058 [40960/90000 (45%)]	Loss: -16.1760	Cost: 10.87s
Train Epoch: 1058 [61440/90000 (68%)]	Loss: -15.8114	Cost: 9.67s
Train Epoch: 1058 [81920/90000 (91%)]	Loss: -15.9216	Cost: 11.29s
Train Epoch: 1058 	Average Loss: -15.5331
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.3990

Learning rate: 0.00014465101769435258
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1059 [0/90000 (0%)]	Loss: -10.6115	Cost: 32.46s
Train Epoch: 1059 [20480/90000 (23%)]	Loss: -15.9637	Cost: 9.75s
Train Epoch: 1059 [40960/90000 (45%)]	Loss: -16.3272	Cost: 10.80s
Train Epoch: 1059 [61440/90000 (68%)]	Loss: -15.9154	Cost: 9.83s
Train Epoch: 1059 [81920/90000 (91%)]	Loss: -15.7732	Cost: 11.76s
Train Epoch: 1059 	Average Loss: -15.6320
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4133

Learning rate: 0.00014455729223768982
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1060 [0/90000 (0%)]	Loss: -9.7236	Cost: 40.26s
Train Epoch: 1060 [20480/90000 (23%)]	Loss: -15.7531	Cost: 9.68s
Train Epoch: 1060 [40960/90000 (45%)]	Loss: -15.8489	Cost: 10.42s
Train Epoch: 1060 [61440/90000 (68%)]	Loss: -15.8962	Cost: 9.44s
Train Epoch: 1060 [81920/90000 (91%)]	Loss: -15.8988	Cost: 9.53s
Train Epoch: 1060 	Average Loss: -15.5017
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.3598

Learning rate: 0.00014446351791849295
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1061 [0/90000 (0%)]	Loss: -9.7727	Cost: 38.14s
Train Epoch: 1061 [20480/90000 (23%)]	Loss: -16.2058	Cost: 11.32s
Train Epoch: 1061 [40960/90000 (45%)]	Loss: -16.5066	Cost: 12.67s
Train Epoch: 1061 [61440/90000 (68%)]	Loss: -16.0890	Cost: 9.76s
Train Epoch: 1061 [81920/90000 (91%)]	Loss: -16.2766	Cost: 10.83s
Train Epoch: 1061 	Average Loss: -15.7952
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5344

Learning rate: 0.00014436969483959698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1062 [0/90000 (0%)]	Loss: -10.2214	Cost: 42.41s
Train Epoch: 1062 [20480/90000 (23%)]	Loss: -16.1228	Cost: 9.78s
Train Epoch: 1062 [40960/90000 (45%)]	Loss: -16.4079	Cost: 12.64s
Train Epoch: 1062 [61440/90000 (68%)]	Loss: -16.0710	Cost: 9.62s
Train Epoch: 1062 [81920/90000 (91%)]	Loss: -14.8175	Cost: 10.87s
Train Epoch: 1062 	Average Loss: -15.5090
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.3657

Learning rate: 0.0001442758231038904
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1063 [0/90000 (0%)]	Loss: -9.6987	Cost: 36.22s
Train Epoch: 1063 [20480/90000 (23%)]	Loss: -15.2402	Cost: 12.61s
Train Epoch: 1063 [40960/90000 (45%)]	Loss: -15.7918	Cost: 12.72s
Train Epoch: 1063 [61440/90000 (68%)]	Loss: -15.2937	Cost: 10.30s
Train Epoch: 1063 [81920/90000 (91%)]	Loss: -15.5048	Cost: 10.80s
Train Epoch: 1063 	Average Loss: -14.9766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -9.8777

Learning rate: 0.00014418190281431507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1064 [0/90000 (0%)]	Loss: -9.0719	Cost: 33.83s
Train Epoch: 1064 [20480/90000 (23%)]	Loss: -15.4255	Cost: 11.89s
Train Epoch: 1064 [40960/90000 (45%)]	Loss: -15.8407	Cost: 11.60s
Train Epoch: 1064 [61440/90000 (68%)]	Loss: -15.5577	Cost: 9.90s
Train Epoch: 1064 [81920/90000 (91%)]	Loss: -15.5003	Cost: 12.42s
Train Epoch: 1064 	Average Loss: -15.1512
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2174

Learning rate: 0.0001440879340738661
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1065 [0/90000 (0%)]	Loss: -9.1948	Cost: 29.51s
Train Epoch: 1065 [20480/90000 (23%)]	Loss: -15.7085	Cost: 11.29s
Train Epoch: 1065 [40960/90000 (45%)]	Loss: -16.4282	Cost: 13.71s
Train Epoch: 1065 [61440/90000 (68%)]	Loss: -15.9904	Cost: 11.82s
Train Epoch: 1065 [81920/90000 (91%)]	Loss: -15.9543	Cost: 10.20s
Train Epoch: 1065 	Average Loss: -15.5699
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.3995

Learning rate: 0.00014399391698559176
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1066 [0/90000 (0%)]	Loss: -9.2853	Cost: 34.34s
Train Epoch: 1066 [20480/90000 (23%)]	Loss: -15.7687	Cost: 9.73s
Train Epoch: 1066 [40960/90000 (45%)]	Loss: -16.2895	Cost: 11.21s
Train Epoch: 1066 [61440/90000 (68%)]	Loss: -16.1008	Cost: 9.83s
Train Epoch: 1066 [81920/90000 (91%)]	Loss: -15.9399	Cost: 12.71s
Train Epoch: 1066 	Average Loss: -15.6548
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4814

Learning rate: 0.00014389985165259332
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1067 [0/90000 (0%)]	Loss: -10.3492	Cost: 29.46s
Train Epoch: 1067 [20480/90000 (23%)]	Loss: -16.0736	Cost: 9.78s
Train Epoch: 1067 [40960/90000 (45%)]	Loss: -16.3036	Cost: 11.55s
Train Epoch: 1067 [61440/90000 (68%)]	Loss: -16.2498	Cost: 9.83s
Train Epoch: 1067 [81920/90000 (91%)]	Loss: -16.1903	Cost: 12.75s
Train Epoch: 1067 	Average Loss: -15.7444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.0920

Learning rate: 0.00014380573817802491
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1068 [0/90000 (0%)]	Loss: -10.2679	Cost: 37.18s
Train Epoch: 1068 [20480/90000 (23%)]	Loss: -15.1357	Cost: 9.73s
Train Epoch: 1068 [40960/90000 (45%)]	Loss: -15.6065	Cost: 10.61s
Train Epoch: 1068 [61440/90000 (68%)]	Loss: -15.5232	Cost: 9.69s
Train Epoch: 1068 [81920/90000 (91%)]	Loss: -15.4876	Cost: 11.02s
Train Epoch: 1068 	Average Loss: -14.9621
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.2856

Learning rate: 0.00014371157666509353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1069 [0/90000 (0%)]	Loss: -9.8029	Cost: 34.89s
Train Epoch: 1069 [20480/90000 (23%)]	Loss: -15.8960	Cost: 10.50s
Train Epoch: 1069 [40960/90000 (45%)]	Loss: -16.2633	Cost: 11.42s
Train Epoch: 1069 [61440/90000 (68%)]	Loss: -16.0225	Cost: 9.56s
Train Epoch: 1069 [81920/90000 (91%)]	Loss: -16.0043	Cost: 11.27s
Train Epoch: 1069 	Average Loss: -15.5676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5685

Learning rate: 0.00014361736721705883
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1070 [0/90000 (0%)]	Loss: -10.0057	Cost: 29.44s
Train Epoch: 1070 [20480/90000 (23%)]	Loss: -15.9527	Cost: 9.74s
Train Epoch: 1070 [40960/90000 (45%)]	Loss: -16.5164	Cost: 11.40s
Train Epoch: 1070 [61440/90000 (68%)]	Loss: -15.7793	Cost: 9.74s
Train Epoch: 1070 [81920/90000 (91%)]	Loss: -16.0118	Cost: 12.55s
Train Epoch: 1070 	Average Loss: -15.6742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5573

Learning rate: 0.000143523109937233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1071 [0/90000 (0%)]	Loss: -10.6563	Cost: 38.05s
Train Epoch: 1071 [20480/90000 (23%)]	Loss: -15.9466	Cost: 9.75s
Train Epoch: 1071 [40960/90000 (45%)]	Loss: -16.3657	Cost: 10.33s
Train Epoch: 1071 [61440/90000 (68%)]	Loss: -15.9363	Cost: 9.64s
Train Epoch: 1071 [81920/90000 (91%)]	Loss: -16.1209	Cost: 11.06s
Train Epoch: 1071 	Average Loss: -15.6998
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.6368

Learning rate: 0.00014342880492898072
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1072 [0/90000 (0%)]	Loss: -10.2751	Cost: 31.96s
Train Epoch: 1072 [20480/90000 (23%)]	Loss: -16.3274	Cost: 10.12s
Train Epoch: 1072 [40960/90000 (45%)]	Loss: -16.7278	Cost: 11.61s
Train Epoch: 1072 [61440/90000 (68%)]	Loss: -16.3027	Cost: 9.61s
Train Epoch: 1072 [81920/90000 (91%)]	Loss: -16.0724	Cost: 11.87s
Train Epoch: 1072 	Average Loss: -15.9156
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.6490

Learning rate: 0.00014333445229571898
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1073 [0/90000 (0%)]	Loss: -10.6902	Cost: 36.28s
Train Epoch: 1073 [20480/90000 (23%)]	Loss: -16.4886	Cost: 9.59s
Train Epoch: 1073 [40960/90000 (45%)]	Loss: -16.6801	Cost: 10.47s
Train Epoch: 1073 [61440/90000 (68%)]	Loss: -16.3923	Cost: 9.62s
Train Epoch: 1073 [81920/90000 (91%)]	Loss: -16.3731	Cost: 10.75s
Train Epoch: 1073 	Average Loss: -16.0225
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7051

Learning rate: 0.000143240052140917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1074 [0/90000 (0%)]	Loss: -10.1882	Cost: 39.62s
Train Epoch: 1074 [20480/90000 (23%)]	Loss: -16.3925	Cost: 10.01s
Train Epoch: 1074 [40960/90000 (45%)]	Loss: -16.5236	Cost: 11.06s
Train Epoch: 1074 [61440/90000 (68%)]	Loss: -16.3168	Cost: 9.79s
Train Epoch: 1074 [81920/90000 (91%)]	Loss: -16.3894	Cost: 10.27s
Train Epoch: 1074 	Average Loss: -15.9751
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5643

Learning rate: 0.00014314560456809615
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1075 [0/90000 (0%)]	Loss: -10.7352	Cost: 37.07s
Train Epoch: 1075 [20480/90000 (23%)]	Loss: -16.4639	Cost: 9.74s
Train Epoch: 1075 [40960/90000 (45%)]	Loss: -16.8010	Cost: 10.27s
Train Epoch: 1075 [61440/90000 (68%)]	Loss: -16.4194	Cost: 9.81s
Train Epoch: 1075 [81920/90000 (91%)]	Loss: -16.1900	Cost: 10.10s
Train Epoch: 1075 	Average Loss: -16.0213
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4148

Learning rate: 0.00014305110968082976
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1076 [0/90000 (0%)]	Loss: -10.7296	Cost: 42.00s
Train Epoch: 1076 [20480/90000 (23%)]	Loss: -16.1975	Cost: 10.04s
Train Epoch: 1076 [40960/90000 (45%)]	Loss: -16.6211	Cost: 10.90s
Train Epoch: 1076 [61440/90000 (68%)]	Loss: -16.2863	Cost: 10.00s
Train Epoch: 1076 [81920/90000 (91%)]	Loss: -16.1661	Cost: 9.34s
Train Epoch: 1076 	Average Loss: -15.8137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5885

Learning rate: 0.00014295656758274308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1077 [0/90000 (0%)]	Loss: -10.4644	Cost: 44.16s
Train Epoch: 1077 [20480/90000 (23%)]	Loss: -16.0791	Cost: 10.00s
Train Epoch: 1077 [40960/90000 (45%)]	Loss: -16.2183	Cost: 11.31s
Train Epoch: 1077 [61440/90000 (68%)]	Loss: -16.1073	Cost: 9.83s
Train Epoch: 1077 [81920/90000 (91%)]	Loss: -16.0286	Cost: 11.11s
Train Epoch: 1077 	Average Loss: -15.7092
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4914

Learning rate: 0.00014286197837751308
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1078 [0/90000 (0%)]	Loss: -10.2465	Cost: 52.58s
Train Epoch: 1078 [20480/90000 (23%)]	Loss: -16.4296	Cost: 9.68s
Train Epoch: 1078 [40960/90000 (45%)]	Loss: -16.5860	Cost: 9.74s
Train Epoch: 1078 [61440/90000 (68%)]	Loss: -16.3673	Cost: 9.61s
Train Epoch: 1078 [81920/90000 (91%)]	Loss: -16.1898	Cost: 9.45s
Train Epoch: 1078 	Average Loss: -15.9663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.6365

Learning rate: 0.00014276734216886846
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1079 [0/90000 (0%)]	Loss: -10.6532	Cost: 35.35s
Train Epoch: 1079 [20480/90000 (23%)]	Loss: -16.3140	Cost: 9.93s
Train Epoch: 1079 [40960/90000 (45%)]	Loss: -16.4862	Cost: 11.82s
Train Epoch: 1079 [61440/90000 (68%)]	Loss: -16.3047	Cost: 9.72s
Train Epoch: 1079 [81920/90000 (91%)]	Loss: -16.4445	Cost: 12.25s
Train Epoch: 1079 	Average Loss: -15.9870
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7916

Learning rate: 0.00014267265906058938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1080 [0/90000 (0%)]	Loss: -11.1804	Cost: 39.69s
Train Epoch: 1080 [20480/90000 (23%)]	Loss: -16.5006	Cost: 9.74s
Train Epoch: 1080 [40960/90000 (45%)]	Loss: -16.5914	Cost: 10.46s
Train Epoch: 1080 [61440/90000 (68%)]	Loss: -16.3023	Cost: 9.75s
Train Epoch: 1080 [81920/90000 (91%)]	Loss: -16.4150	Cost: 9.40s
Train Epoch: 1080 	Average Loss: -16.0474
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7378

Learning rate: 0.0001425779291565075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1081 [0/90000 (0%)]	Loss: -10.2730	Cost: 37.89s
Train Epoch: 1081 [20480/90000 (23%)]	Loss: -16.3503	Cost: 10.73s
Train Epoch: 1081 [40960/90000 (45%)]	Loss: -16.6310	Cost: 12.51s
Train Epoch: 1081 [61440/90000 (68%)]	Loss: -16.3570	Cost: 9.59s
Train Epoch: 1081 [81920/90000 (91%)]	Loss: -16.1825	Cost: 10.37s
Train Epoch: 1081 	Average Loss: -16.0020
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.6177

Learning rate: 0.0001424831525605058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1082 [0/90000 (0%)]	Loss: -9.7879	Cost: 44.34s
Train Epoch: 1082 [20480/90000 (23%)]	Loss: -16.1040	Cost: 9.73s
Train Epoch: 1082 [40960/90000 (45%)]	Loss: -16.7668	Cost: 10.77s
Train Epoch: 1082 [61440/90000 (68%)]	Loss: -16.4118	Cost: 9.62s
Train Epoch: 1082 [81920/90000 (91%)]	Loss: -16.3787	Cost: 9.67s
Train Epoch: 1082 	Average Loss: -15.9596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7881

Learning rate: 0.0001423883293765184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1083 [0/90000 (0%)]	Loss: -10.6410	Cost: 39.38s
Train Epoch: 1083 [20480/90000 (23%)]	Loss: -16.5105	Cost: 10.50s
Train Epoch: 1083 [40960/90000 (45%)]	Loss: -16.7851	Cost: 11.54s
Train Epoch: 1083 [61440/90000 (68%)]	Loss: -16.5198	Cost: 9.43s
Train Epoch: 1083 [81920/90000 (91%)]	Loss: -16.2973	Cost: 9.13s
Train Epoch: 1083 	Average Loss: -16.0929
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9055

Learning rate: 0.00014229345970853053
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1084 [0/90000 (0%)]	Loss: -10.6045	Cost: 41.33s
Train Epoch: 1084 [20480/90000 (23%)]	Loss: -16.6049	Cost: 9.92s
Train Epoch: 1084 [40960/90000 (45%)]	Loss: -16.8906	Cost: 11.98s
Train Epoch: 1084 [61440/90000 (68%)]	Loss: -16.4118	Cost: 9.84s
Train Epoch: 1084 [81920/90000 (91%)]	Loss: -16.4772	Cost: 9.65s
Train Epoch: 1084 	Average Loss: -16.1627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9902

Learning rate: 0.0001421985436605785
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1085 [0/90000 (0%)]	Loss: -10.6153	Cost: 41.23s
Train Epoch: 1085 [20480/90000 (23%)]	Loss: -16.2355	Cost: 11.25s
Train Epoch: 1085 [40960/90000 (45%)]	Loss: -16.6640	Cost: 12.00s
Train Epoch: 1085 [61440/90000 (68%)]	Loss: -16.2716	Cost: 9.62s
Train Epoch: 1085 [81920/90000 (91%)]	Loss: -16.2257	Cost: 9.26s
Train Epoch: 1085 	Average Loss: -15.9886
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7790

Learning rate: 0.00014210358133674933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1086 [0/90000 (0%)]	Loss: -10.1885	Cost: 38.11s
Train Epoch: 1086 [20480/90000 (23%)]	Loss: -16.5422	Cost: 10.20s
Train Epoch: 1086 [40960/90000 (45%)]	Loss: -16.7287	Cost: 12.95s
Train Epoch: 1086 [61440/90000 (68%)]	Loss: -16.4469	Cost: 9.85s
Train Epoch: 1086 [81920/90000 (91%)]	Loss: -16.3651	Cost: 12.53s
Train Epoch: 1086 	Average Loss: -16.0587
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7561

Learning rate: 0.00014200857284118082
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1087 [0/90000 (0%)]	Loss: -10.4649	Cost: 34.22s
Train Epoch: 1087 [20480/90000 (23%)]	Loss: -16.5342	Cost: 12.11s
Train Epoch: 1087 [40960/90000 (45%)]	Loss: -16.6297	Cost: 12.66s
Train Epoch: 1087 [61440/90000 (68%)]	Loss: -16.3653	Cost: 9.94s
Train Epoch: 1087 [81920/90000 (91%)]	Loss: -16.4724	Cost: 12.54s
Train Epoch: 1087 	Average Loss: -16.0870
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7163

Learning rate: 0.0001419135182780615
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1088 [0/90000 (0%)]	Loss: -10.5075	Cost: 33.55s
Train Epoch: 1088 [20480/90000 (23%)]	Loss: -16.5857	Cost: 10.42s
Train Epoch: 1088 [40960/90000 (45%)]	Loss: -16.8027	Cost: 13.82s
Train Epoch: 1088 [61440/90000 (68%)]	Loss: -16.6654	Cost: 9.79s
Train Epoch: 1088 [81920/90000 (91%)]	Loss: -16.4605	Cost: 14.80s
Train Epoch: 1088 	Average Loss: -16.1987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9358

Learning rate: 0.00014181841775163034
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1089 [0/90000 (0%)]	Loss: -9.4284	Cost: 29.40s
Train Epoch: 1089 [20480/90000 (23%)]	Loss: -16.4058	Cost: 9.71s
Train Epoch: 1089 [40960/90000 (45%)]	Loss: -16.7515	Cost: 13.16s
Train Epoch: 1089 [61440/90000 (68%)]	Loss: -16.4541	Cost: 11.11s
Train Epoch: 1089 [81920/90000 (91%)]	Loss: -16.3427	Cost: 13.62s
Train Epoch: 1089 	Average Loss: -16.0926
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.8125

Learning rate: 0.00014172327136617672
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1090 [0/90000 (0%)]	Loss: -11.1216	Cost: 36.79s
Train Epoch: 1090 [20480/90000 (23%)]	Loss: -16.5039	Cost: 9.81s
Train Epoch: 1090 [40960/90000 (45%)]	Loss: -16.8436	Cost: 12.01s
Train Epoch: 1090 [61440/90000 (68%)]	Loss: -16.3752	Cost: 10.47s
Train Epoch: 1090 [81920/90000 (91%)]	Loss: -16.2734	Cost: 13.46s
Train Epoch: 1090 	Average Loss: -16.1432
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7514

Learning rate: 0.0001416280792260403
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1091 [0/90000 (0%)]	Loss: -10.5198	Cost: 31.54s
Train Epoch: 1091 [20480/90000 (23%)]	Loss: -16.4674	Cost: 10.68s
Train Epoch: 1091 [40960/90000 (45%)]	Loss: -16.7318	Cost: 10.64s
Train Epoch: 1091 [61440/90000 (68%)]	Loss: -16.4340	Cost: 9.65s
Train Epoch: 1091 [81920/90000 (91%)]	Loss: -16.3302	Cost: 10.92s
Train Epoch: 1091 	Average Loss: -16.1153
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.7868

Learning rate: 0.00014153284143561098
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1092 [0/90000 (0%)]	Loss: -10.5135	Cost: 29.86s
Train Epoch: 1092 [20480/90000 (23%)]	Loss: -16.3361	Cost: 9.75s
Train Epoch: 1092 [40960/90000 (45%)]	Loss: -16.7563	Cost: 10.91s
Train Epoch: 1092 [61440/90000 (68%)]	Loss: -16.6444	Cost: 9.73s
Train Epoch: 1092 [81920/90000 (91%)]	Loss: -16.0748	Cost: 11.98s
Train Epoch: 1092 	Average Loss: -16.0141
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.3439

Learning rate: 0.00014143755809932861
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1093 [0/90000 (0%)]	Loss: -10.6280	Cost: 32.47s
Train Epoch: 1093 [20480/90000 (23%)]	Loss: -15.9759	Cost: 9.95s
Train Epoch: 1093 [40960/90000 (45%)]	Loss: -16.2881	Cost: 11.88s
Train Epoch: 1093 [61440/90000 (68%)]	Loss: -16.1527	Cost: 9.60s
Train Epoch: 1093 [81920/90000 (91%)]	Loss: -16.2129	Cost: 11.79s
Train Epoch: 1093 	Average Loss: -15.8030
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.8369

Learning rate: 0.0001413422293216831
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1094 [0/90000 (0%)]	Loss: -10.4104	Cost: 29.47s
Train Epoch: 1094 [20480/90000 (23%)]	Loss: -16.3734	Cost: 9.88s
Train Epoch: 1094 [40960/90000 (45%)]	Loss: -16.6785	Cost: 11.77s
Train Epoch: 1094 [61440/90000 (68%)]	Loss: -16.4372	Cost: 9.89s
Train Epoch: 1094 [81920/90000 (91%)]	Loss: -16.5440	Cost: 12.04s
Train Epoch: 1094 	Average Loss: -16.0774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9066

Learning rate: 0.0001412468552072141
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1095 [0/90000 (0%)]	Loss: -11.1054	Cost: 37.37s
Train Epoch: 1095 [20480/90000 (23%)]	Loss: -16.4612	Cost: 9.65s
Train Epoch: 1095 [40960/90000 (45%)]	Loss: -16.8108	Cost: 10.02s
Train Epoch: 1095 [61440/90000 (68%)]	Loss: -16.5491	Cost: 9.83s
Train Epoch: 1095 [81920/90000 (91%)]	Loss: -16.5666	Cost: 11.18s
Train Epoch: 1095 	Average Loss: -16.1805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9870

Learning rate: 0.00014115143586051107
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1096 [0/90000 (0%)]	Loss: -10.9093	Cost: 33.09s
Train Epoch: 1096 [20480/90000 (23%)]	Loss: -16.6537	Cost: 9.99s
Train Epoch: 1096 [40960/90000 (45%)]	Loss: -16.9803	Cost: 11.45s
Train Epoch: 1096 [61440/90000 (68%)]	Loss: -16.7417	Cost: 9.95s
Train Epoch: 1096 [81920/90000 (91%)]	Loss: -16.4216	Cost: 11.88s
Train Epoch: 1096 	Average Loss: -16.1373
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5418

Learning rate: 0.000141055971386213
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1097 [0/90000 (0%)]	Loss: -10.5463	Cost: 33.50s
Train Epoch: 1097 [20480/90000 (23%)]	Loss: -16.3287	Cost: 9.54s
Train Epoch: 1097 [40960/90000 (45%)]	Loss: -16.6732	Cost: 10.10s
Train Epoch: 1097 [61440/90000 (68%)]	Loss: -16.6283	Cost: 9.46s
Train Epoch: 1097 [81920/90000 (91%)]	Loss: -16.6869	Cost: 11.16s
Train Epoch: 1097 	Average Loss: -16.0888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9375

Learning rate: 0.00014096046188900838
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1098 [0/90000 (0%)]	Loss: -10.3990	Cost: 35.44s
Train Epoch: 1098 [20480/90000 (23%)]	Loss: -16.7969	Cost: 10.46s
Train Epoch: 1098 [40960/90000 (45%)]	Loss: -16.9217	Cost: 10.48s
Train Epoch: 1098 [61440/90000 (68%)]	Loss: -16.6737	Cost: 9.74s
Train Epoch: 1098 [81920/90000 (91%)]	Loss: -16.5279	Cost: 9.99s
Train Epoch: 1098 	Average Loss: -16.2866
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0370

Learning rate: 0.00014086490747363512
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1099 [0/90000 (0%)]	Loss: -10.4508	Cost: 38.20s
Train Epoch: 1099 [20480/90000 (23%)]	Loss: -15.6963	Cost: 9.98s
Train Epoch: 1099 [40960/90000 (45%)]	Loss: -15.8137	Cost: 11.55s
Train Epoch: 1099 [61440/90000 (68%)]	Loss: -15.8809	Cost: 9.81s
Train Epoch: 1099 [81920/90000 (91%)]	Loss: -15.9784	Cost: 10.79s
Train Epoch: 1099 	Average Loss: -15.4526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.4896

Learning rate: 0.00014076930824488028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1100 [0/90000 (0%)]	Loss: -10.5406	Cost: 48.56s
Train Epoch: 1100 [20480/90000 (23%)]	Loss: -16.0303	Cost: 9.61s
Train Epoch: 1100 [40960/90000 (45%)]	Loss: -16.4279	Cost: 10.37s
Train Epoch: 1100 [61440/90000 (68%)]	Loss: -16.4690	Cost: 9.56s
Train Epoch: 1100 [81920/90000 (91%)]	Loss: -16.4503	Cost: 9.41s
Train Epoch: 1100 	Average Loss: -15.9250
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9240

Saving model as model.pt_e1100 & waveforms_supplementary.hdf5_e1100
Learning rate: 0.00014067366430758023
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1101 [0/90000 (0%)]	Loss: -11.2803	Cost: 34.61s
Train Epoch: 1101 [20480/90000 (23%)]	Loss: -16.6328	Cost: 10.02s
Train Epoch: 1101 [40960/90000 (45%)]	Loss: -16.2393	Cost: 11.55s
Train Epoch: 1101 [61440/90000 (68%)]	Loss: -15.8780	Cost: 9.75s
Train Epoch: 1101 [81920/90000 (91%)]	Loss: -16.0872	Cost: 12.00s
Train Epoch: 1101 	Average Loss: -15.8540
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.5722

Learning rate: 0.0001405779757666202
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1102 [0/90000 (0%)]	Loss: -10.1299	Cost: 42.46s
Train Epoch: 1102 [20480/90000 (23%)]	Loss: -16.4201	Cost: 9.60s
Train Epoch: 1102 [40960/90000 (45%)]	Loss: -16.4344	Cost: 9.84s
Train Epoch: 1102 [61440/90000 (68%)]	Loss: -16.3082	Cost: 9.89s
Train Epoch: 1102 [81920/90000 (91%)]	Loss: -16.4202	Cost: 9.47s
Train Epoch: 1102 	Average Loss: -15.9380
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9745

Learning rate: 0.00014048224272693443
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1103 [0/90000 (0%)]	Loss: -11.2654	Cost: 35.72s
Train Epoch: 1103 [20480/90000 (23%)]	Loss: -16.6503	Cost: 10.74s
Train Epoch: 1103 [40960/90000 (45%)]	Loss: -16.9465	Cost: 11.37s
Train Epoch: 1103 [61440/90000 (68%)]	Loss: -16.6707	Cost: 9.62s
Train Epoch: 1103 [81920/90000 (91%)]	Loss: -16.7779	Cost: 10.83s
Train Epoch: 1103 	Average Loss: -16.2869
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1148

Learning rate: 0.00014038646529350595
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1104 [0/90000 (0%)]	Loss: -9.9571	Cost: 40.22s
Train Epoch: 1104 [20480/90000 (23%)]	Loss: -16.7344	Cost: 9.79s
Train Epoch: 1104 [40960/90000 (45%)]	Loss: -16.9544	Cost: 10.95s
Train Epoch: 1104 [61440/90000 (68%)]	Loss: -16.8637	Cost: 9.63s
Train Epoch: 1104 [81920/90000 (91%)]	Loss: -16.7927	Cost: 9.95s
Train Epoch: 1104 	Average Loss: -16.3114
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2076

Learning rate: 0.00014029064357136647
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1105 [0/90000 (0%)]	Loss: -10.5081	Cost: 41.71s
Train Epoch: 1105 [20480/90000 (23%)]	Loss: -16.7954	Cost: 10.61s
Train Epoch: 1105 [40960/90000 (45%)]	Loss: -17.2216	Cost: 11.31s
Train Epoch: 1105 [61440/90000 (68%)]	Loss: -16.6645	Cost: 9.64s
Train Epoch: 1105 [81920/90000 (91%)]	Loss: -16.3214	Cost: 9.14s
Train Epoch: 1105 	Average Loss: -16.3269
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.8737

Learning rate: 0.00014019477766559623
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1106 [0/90000 (0%)]	Loss: -10.9995	Cost: 40.64s
Train Epoch: 1106 [20480/90000 (23%)]	Loss: -16.1987	Cost: 9.72s
Train Epoch: 1106 [40960/90000 (45%)]	Loss: -16.7828	Cost: 13.46s
Train Epoch: 1106 [61440/90000 (68%)]	Loss: -16.5157	Cost: 9.73s
Train Epoch: 1106 [81920/90000 (91%)]	Loss: -16.5860	Cost: 11.65s
Train Epoch: 1106 	Average Loss: -16.0809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1256

Learning rate: 0.00014009886768132394
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1107 [0/90000 (0%)]	Loss: -10.3484	Cost: 49.48s
Train Epoch: 1107 [20480/90000 (23%)]	Loss: -16.6944	Cost: 9.80s
Train Epoch: 1107 [40960/90000 (45%)]	Loss: -16.8192	Cost: 12.73s
Train Epoch: 1107 [61440/90000 (68%)]	Loss: -16.7791	Cost: 9.44s
Train Epoch: 1107 [81920/90000 (91%)]	Loss: -16.7560	Cost: 9.48s
Train Epoch: 1107 	Average Loss: -16.2904
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1012

Learning rate: 0.00014000291372372666
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1108 [0/90000 (0%)]	Loss: -10.4450	Cost: 37.63s
Train Epoch: 1108 [20480/90000 (23%)]	Loss: -16.5047	Cost: 12.59s
Train Epoch: 1108 [40960/90000 (45%)]	Loss: -16.8187	Cost: 13.06s
Train Epoch: 1108 [61440/90000 (68%)]	Loss: -16.5576	Cost: 9.87s
Train Epoch: 1108 [81920/90000 (91%)]	Loss: -16.3893	Cost: 11.39s
Train Epoch: 1108 	Average Loss: -16.1968
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0010

Learning rate: 0.00013990691589802973
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1109 [0/90000 (0%)]	Loss: -10.9664	Cost: 41.97s
Train Epoch: 1109 [20480/90000 (23%)]	Loss: -16.8016	Cost: 10.05s
Train Epoch: 1109 [40960/90000 (45%)]	Loss: -16.9905	Cost: 12.60s
Train Epoch: 1109 [61440/90000 (68%)]	Loss: -16.7258	Cost: 10.21s
Train Epoch: 1109 [81920/90000 (91%)]	Loss: -16.6644	Cost: 11.95s
Train Epoch: 1109 	Average Loss: -16.3008
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9117

Learning rate: 0.00013981087430950647
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1110 [0/90000 (0%)]	Loss: -10.8353	Cost: 35.33s
Train Epoch: 1110 [20480/90000 (23%)]	Loss: -16.7203	Cost: 12.51s
Train Epoch: 1110 [40960/90000 (45%)]	Loss: -17.0132	Cost: 13.11s
Train Epoch: 1110 [61440/90000 (68%)]	Loss: -16.7709	Cost: 9.79s
Train Epoch: 1110 [81920/90000 (91%)]	Loss: -16.6743	Cost: 11.57s
Train Epoch: 1110 	Average Loss: -16.3746
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1861

Learning rate: 0.00013971478906347825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1111 [0/90000 (0%)]	Loss: -10.7249	Cost: 33.37s
Train Epoch: 1111 [20480/90000 (23%)]	Loss: -17.0254	Cost: 11.74s
Train Epoch: 1111 [40960/90000 (45%)]	Loss: -16.9996	Cost: 11.02s
Train Epoch: 1111 [61440/90000 (68%)]	Loss: -16.7684	Cost: 9.79s
Train Epoch: 1111 [81920/90000 (91%)]	Loss: -16.5839	Cost: 12.92s
Train Epoch: 1111 	Average Loss: -16.4013
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1692

Learning rate: 0.00013961866026531436
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1112 [0/90000 (0%)]	Loss: -10.6222	Cost: 30.16s
Train Epoch: 1112 [20480/90000 (23%)]	Loss: -16.7070	Cost: 10.00s
Train Epoch: 1112 [40960/90000 (45%)]	Loss: -17.0985	Cost: 13.00s
Train Epoch: 1112 [61440/90000 (68%)]	Loss: -16.7955	Cost: 11.16s
Train Epoch: 1112 [81920/90000 (91%)]	Loss: -16.8550	Cost: 10.91s
Train Epoch: 1112 	Average Loss: -16.3760
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1299

Learning rate: 0.00013952248802043184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1113 [0/90000 (0%)]	Loss: -10.2089	Cost: 35.55s
Train Epoch: 1113 [20480/90000 (23%)]	Loss: -16.9405	Cost: 9.71s
Train Epoch: 1113 [40960/90000 (45%)]	Loss: -17.0703	Cost: 10.97s
Train Epoch: 1113 [61440/90000 (68%)]	Loss: -16.8720	Cost: 9.76s
Train Epoch: 1113 [81920/90000 (91%)]	Loss: -16.7022	Cost: 13.26s
Train Epoch: 1113 	Average Loss: -16.4195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.0166

Learning rate: 0.0001394262724342953
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1114 [0/90000 (0%)]	Loss: -10.7950	Cost: 31.81s
Train Epoch: 1114 [20480/90000 (23%)]	Loss: -16.7420	Cost: 10.48s
Train Epoch: 1114 [40960/90000 (45%)]	Loss: -17.0066	Cost: 12.68s
Train Epoch: 1114 [61440/90000 (68%)]	Loss: -16.9006	Cost: 9.81s
Train Epoch: 1114 [81920/90000 (91%)]	Loss: -16.8213	Cost: 12.49s
Train Epoch: 1114 	Average Loss: -16.4211
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1400

Learning rate: 0.0001393300136124169
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1115 [0/90000 (0%)]	Loss: -10.7052	Cost: 29.16s
Train Epoch: 1115 [20480/90000 (23%)]	Loss: -16.2106	Cost: 9.84s
Train Epoch: 1115 [40960/90000 (45%)]	Loss: -16.6085	Cost: 12.06s
Train Epoch: 1115 [61440/90000 (68%)]	Loss: -16.3505	Cost: 10.17s
Train Epoch: 1115 [81920/90000 (91%)]	Loss: -16.4716	Cost: 11.40s
Train Epoch: 1115 	Average Loss: -16.0112
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.8402

Learning rate: 0.0001392337116603563
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1116 [0/90000 (0%)]	Loss: -10.9601	Cost: 40.46s
Train Epoch: 1116 [20480/90000 (23%)]	Loss: -16.7665	Cost: 9.62s
Train Epoch: 1116 [40960/90000 (45%)]	Loss: -17.2365	Cost: 10.02s
Train Epoch: 1116 [61440/90000 (68%)]	Loss: -16.6770	Cost: 9.69s
Train Epoch: 1116 [81920/90000 (91%)]	Loss: -16.8280	Cost: 11.66s
Train Epoch: 1116 	Average Loss: -16.4515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1991

Learning rate: 0.0001391373666837204
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1117 [0/90000 (0%)]	Loss: -10.7507	Cost: 33.88s
Train Epoch: 1117 [20480/90000 (23%)]	Loss: -16.9492	Cost: 11.02s
Train Epoch: 1117 [40960/90000 (45%)]	Loss: -17.2191	Cost: 10.76s
Train Epoch: 1117 [61440/90000 (68%)]	Loss: -16.9356	Cost: 9.68s
Train Epoch: 1117 [81920/90000 (91%)]	Loss: -16.9022	Cost: 12.14s
Train Epoch: 1117 	Average Loss: -16.5216
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2362

Learning rate: 0.00013904097878816326
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1118 [0/90000 (0%)]	Loss: -11.1057	Cost: 29.08s
Train Epoch: 1118 [20480/90000 (23%)]	Loss: -16.9527	Cost: 9.73s
Train Epoch: 1118 [40960/90000 (45%)]	Loss: -17.1071	Cost: 11.52s
Train Epoch: 1118 [61440/90000 (68%)]	Loss: -16.8812	Cost: 9.85s
Train Epoch: 1118 [81920/90000 (91%)]	Loss: -16.6938	Cost: 12.57s
Train Epoch: 1118 	Average Loss: -16.5004
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2936

Learning rate: 0.000138944548079386
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1119 [0/90000 (0%)]	Loss: -10.4788	Cost: 39.50s
Train Epoch: 1119 [20480/90000 (23%)]	Loss: -16.8818	Cost: 9.67s
Train Epoch: 1119 [40960/90000 (45%)]	Loss: -17.2922	Cost: 10.17s
Train Epoch: 1119 [61440/90000 (68%)]	Loss: -16.8041	Cost: 9.73s
Train Epoch: 1119 [81920/90000 (91%)]	Loss: -16.7292	Cost: 12.03s
Train Epoch: 1119 	Average Loss: -16.4379
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1177

Learning rate: 0.00013884807466313677
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1120 [0/90000 (0%)]	Loss: -10.7345	Cost: 31.70s
Train Epoch: 1120 [20480/90000 (23%)]	Loss: -16.7975	Cost: 9.95s
Train Epoch: 1120 [40960/90000 (45%)]	Loss: -16.9191	Cost: 11.41s
Train Epoch: 1120 [61440/90000 (68%)]	Loss: -16.7656	Cost: 9.70s
Train Epoch: 1120 [81920/90000 (91%)]	Loss: -16.8102	Cost: 11.75s
Train Epoch: 1120 	Average Loss: -16.3702
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2836

Learning rate: 0.00013875155864521047
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1121 [0/90000 (0%)]	Loss: -10.1116	Cost: 35.04s
Train Epoch: 1121 [20480/90000 (23%)]	Loss: -16.9160	Cost: 9.66s
Train Epoch: 1121 [40960/90000 (45%)]	Loss: -16.9835	Cost: 10.26s
Train Epoch: 1121 [61440/90000 (68%)]	Loss: -16.8551	Cost: 9.70s
Train Epoch: 1121 [81920/90000 (91%)]	Loss: -16.8804	Cost: 9.88s
Train Epoch: 1121 	Average Loss: -16.4386
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1656

Learning rate: 0.0001386550001314487
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1122 [0/90000 (0%)]	Loss: -10.6582	Cost: 38.77s
Train Epoch: 1122 [20480/90000 (23%)]	Loss: -16.8850	Cost: 9.89s
Train Epoch: 1122 [40960/90000 (45%)]	Loss: -17.0805	Cost: 11.43s
Train Epoch: 1122 [61440/90000 (68%)]	Loss: -17.0849	Cost: 9.68s
Train Epoch: 1122 [81920/90000 (91%)]	Loss: -16.9270	Cost: 9.99s
Train Epoch: 1122 	Average Loss: -16.5639
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2138

Learning rate: 0.0001385583992277398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1123 [0/90000 (0%)]	Loss: -10.9758	Cost: 37.62s
Train Epoch: 1123 [20480/90000 (23%)]	Loss: -17.0536	Cost: 9.90s
Train Epoch: 1123 [40960/90000 (45%)]	Loss: -17.3310	Cost: 10.67s
Train Epoch: 1123 [61440/90000 (68%)]	Loss: -16.9930	Cost: 9.64s
Train Epoch: 1123 [81920/90000 (91%)]	Loss: -16.9334	Cost: 9.65s
Train Epoch: 1123 	Average Loss: -16.6552
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2622

Learning rate: 0.00013846175604001845
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1124 [0/90000 (0%)]	Loss: -10.6543	Cost: 41.95s
Train Epoch: 1124 [20480/90000 (23%)]	Loss: -16.8576	Cost: 9.93s
Train Epoch: 1124 [40960/90000 (45%)]	Loss: -17.3160	Cost: 11.30s
Train Epoch: 1124 [61440/90000 (68%)]	Loss: -16.7633	Cost: 9.46s
Train Epoch: 1124 [81920/90000 (91%)]	Loss: -16.8367	Cost: 9.43s
Train Epoch: 1124 	Average Loss: -16.5106
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4431

Learning rate: 0.00013836507067426578
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1125 [0/90000 (0%)]	Loss: -11.2140	Cost: 44.70s
Train Epoch: 1125 [20480/90000 (23%)]	Loss: -17.0988	Cost: 9.59s
Train Epoch: 1125 [40960/90000 (45%)]	Loss: -17.3323	Cost: 12.36s
Train Epoch: 1125 [61440/90000 (68%)]	Loss: -17.1687	Cost: 9.74s
Train Epoch: 1125 [81920/90000 (91%)]	Loss: -17.1595	Cost: 12.01s
Train Epoch: 1125 	Average Loss: -16.6805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.3892

Learning rate: 0.0001382683432365091
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1126 [0/90000 (0%)]	Loss: -11.5061	Cost: 41.97s
Train Epoch: 1126 [20480/90000 (23%)]	Loss: -16.8940	Cost: 10.03s
Train Epoch: 1126 [40960/90000 (45%)]	Loss: -17.2611	Cost: 11.45s
Train Epoch: 1126 [61440/90000 (68%)]	Loss: -16.8453	Cost: 9.53s
Train Epoch: 1126 [81920/90000 (91%)]	Loss: -16.6382	Cost: 9.10s
Train Epoch: 1126 	Average Loss: -16.5151
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.9009

Learning rate: 0.00013817157383282197
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1127 [0/90000 (0%)]	Loss: -10.7849	Cost: 49.42s
Train Epoch: 1127 [20480/90000 (23%)]	Loss: -16.7697	Cost: 9.91s
Train Epoch: 1127 [40960/90000 (45%)]	Loss: -16.8422	Cost: 12.14s
Train Epoch: 1127 [61440/90000 (68%)]	Loss: -16.7822	Cost: 9.65s
Train Epoch: 1127 [81920/90000 (91%)]	Loss: -16.7706	Cost: 11.43s
Train Epoch: 1127 	Average Loss: -16.3276
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1870

Learning rate: 0.00013807476256932387
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1128 [0/90000 (0%)]	Loss: -11.0868	Cost: 43.78s
Train Epoch: 1128 [20480/90000 (23%)]	Loss: -16.8319	Cost: 10.06s
Train Epoch: 1128 [40960/90000 (45%)]	Loss: -17.2474	Cost: 12.49s
Train Epoch: 1128 [61440/90000 (68%)]	Loss: -16.8965	Cost: 9.49s
Train Epoch: 1128 [81920/90000 (91%)]	Loss: -16.8960	Cost: 10.10s
Train Epoch: 1128 	Average Loss: -16.6369
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4438

Learning rate: 0.00013797790955218022
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1129 [0/90000 (0%)]	Loss: -11.5334	Cost: 41.69s
Train Epoch: 1129 [20480/90000 (23%)]	Loss: -16.8920	Cost: 10.85s
Train Epoch: 1129 [40960/90000 (45%)]	Loss: -17.3460	Cost: 13.30s
Train Epoch: 1129 [61440/90000 (68%)]	Loss: -16.8345	Cost: 10.09s
Train Epoch: 1129 [81920/90000 (91%)]	Loss: -16.9609	Cost: 10.11s
Train Epoch: 1129 	Average Loss: -16.5844
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2783

Learning rate: 0.00013788101488760224
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1130 [0/90000 (0%)]	Loss: -11.2116	Cost: 39.01s
Train Epoch: 1130 [20480/90000 (23%)]	Loss: -16.9544	Cost: 10.90s
Train Epoch: 1130 [40960/90000 (45%)]	Loss: -17.1267	Cost: 13.92s
Train Epoch: 1130 [61440/90000 (68%)]	Loss: -17.0186	Cost: 9.94s
Train Epoch: 1130 [81920/90000 (91%)]	Loss: -16.8781	Cost: 14.50s
Train Epoch: 1130 	Average Loss: -16.5738
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1722

Learning rate: 0.00013778407868184683
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1131 [0/90000 (0%)]	Loss: -11.0319	Cost: 33.67s
Train Epoch: 1131 [20480/90000 (23%)]	Loss: -16.7611	Cost: 12.18s
Train Epoch: 1131 [40960/90000 (45%)]	Loss: -17.3560	Cost: 17.52s
Train Epoch: 1131 [61440/90000 (68%)]	Loss: -17.1000	Cost: 9.66s
Train Epoch: 1131 [81920/90000 (91%)]	Loss: -16.9036	Cost: 12.46s
Train Epoch: 1131 	Average Loss: -16.6289
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4219

Learning rate: 0.00013768710104121638
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1132 [0/90000 (0%)]	Loss: -10.7455	Cost: 38.85s
Train Epoch: 1132 [20480/90000 (23%)]	Loss: -17.2049	Cost: 9.86s
Train Epoch: 1132 [40960/90000 (45%)]	Loss: -17.1480	Cost: 14.17s
Train Epoch: 1132 [61440/90000 (68%)]	Loss: -17.1462	Cost: 10.50s
Train Epoch: 1132 [81920/90000 (91%)]	Loss: -17.1779	Cost: 13.44s
Train Epoch: 1132 	Average Loss: -16.6448
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4033

Learning rate: 0.00013759008207205877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1133 [0/90000 (0%)]	Loss: -10.8689	Cost: 30.63s
Train Epoch: 1133 [20480/90000 (23%)]	Loss: -17.1171	Cost: 10.27s
Train Epoch: 1133 [40960/90000 (45%)]	Loss: -17.2465	Cost: 13.84s
Train Epoch: 1133 [61440/90000 (68%)]	Loss: -17.1057	Cost: 10.56s
Train Epoch: 1133 [81920/90000 (91%)]	Loss: -17.1258	Cost: 10.96s
Train Epoch: 1133 	Average Loss: -16.6690
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4387

Learning rate: 0.00013749302188076725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1134 [0/90000 (0%)]	Loss: -11.0758	Cost: 33.54s
Train Epoch: 1134 [20480/90000 (23%)]	Loss: -16.9850	Cost: 9.76s
Train Epoch: 1134 [40960/90000 (45%)]	Loss: -17.2492	Cost: 12.98s
Train Epoch: 1134 [61440/90000 (68%)]	Loss: -17.0478	Cost: 10.28s
Train Epoch: 1134 [81920/90000 (91%)]	Loss: -16.9209	Cost: 13.73s
Train Epoch: 1134 	Average Loss: -16.6580
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4278

Learning rate: 0.00013739592057378014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1135 [0/90000 (0%)]	Loss: -11.3091	Cost: 32.37s
Train Epoch: 1135 [20480/90000 (23%)]	Loss: -16.8926	Cost: 10.79s
Train Epoch: 1135 [40960/90000 (45%)]	Loss: -17.0933	Cost: 10.56s
Train Epoch: 1135 [61440/90000 (68%)]	Loss: -16.8183	Cost: 9.47s
Train Epoch: 1135 [81920/90000 (91%)]	Loss: -16.9049	Cost: 10.63s
Train Epoch: 1135 	Average Loss: -16.5657
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2023

Learning rate: 0.000137298778257581
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1136 [0/90000 (0%)]	Loss: -10.5154	Cost: 29.61s
Train Epoch: 1136 [20480/90000 (23%)]	Loss: -16.9782	Cost: 9.63s
Train Epoch: 1136 [40960/90000 (45%)]	Loss: -17.4567	Cost: 10.66s
Train Epoch: 1136 [61440/90000 (68%)]	Loss: -16.9241	Cost: 9.76s
Train Epoch: 1136 [81920/90000 (91%)]	Loss: -17.1065	Cost: 12.52s
Train Epoch: 1136 	Average Loss: -16.5984
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4289

Learning rate: 0.00013720159503869824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1137 [0/90000 (0%)]	Loss: -11.1240	Cost: 37.82s
Train Epoch: 1137 [20480/90000 (23%)]	Loss: -17.2732	Cost: 9.83s
Train Epoch: 1137 [40960/90000 (45%)]	Loss: -17.2590	Cost: 10.77s
Train Epoch: 1137 [61440/90000 (68%)]	Loss: -16.8443	Cost: 9.64s
Train Epoch: 1137 [81920/90000 (91%)]	Loss: -17.1258	Cost: 12.04s
Train Epoch: 1137 	Average Loss: -16.7499
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.5415

Learning rate: 0.00013710437102370517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1138 [0/90000 (0%)]	Loss: -11.1137	Cost: 31.29s
Train Epoch: 1138 [20480/90000 (23%)]	Loss: -16.8585	Cost: 9.76s
Train Epoch: 1138 [40960/90000 (45%)]	Loss: -17.2783	Cost: 12.35s
Train Epoch: 1138 [61440/90000 (68%)]	Loss: -17.0447	Cost: 9.83s
Train Epoch: 1138 [81920/90000 (91%)]	Loss: -17.0288	Cost: 11.66s
Train Epoch: 1138 	Average Loss: -16.7111
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4045

Learning rate: 0.00013700710631921992
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1139 [0/90000 (0%)]	Loss: -10.6078	Cost: 35.32s
Train Epoch: 1139 [20480/90000 (23%)]	Loss: -17.0670	Cost: 9.73s
Train Epoch: 1139 [40960/90000 (45%)]	Loss: -17.6551	Cost: 10.28s
Train Epoch: 1139 [61440/90000 (68%)]	Loss: -17.0677	Cost: 9.72s
Train Epoch: 1139 [81920/90000 (91%)]	Loss: -16.8875	Cost: 10.87s
Train Epoch: 1139 	Average Loss: -16.7040
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.3270

Learning rate: 0.00013690980103190509
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1140 [0/90000 (0%)]	Loss: -10.8243	Cost: 37.84s
Train Epoch: 1140 [20480/90000 (23%)]	Loss: -17.0706	Cost: 9.87s
Train Epoch: 1140 [40960/90000 (45%)]	Loss: -17.4032	Cost: 11.00s
Train Epoch: 1140 [61440/90000 (68%)]	Loss: -17.0844	Cost: 9.57s
Train Epoch: 1140 [81920/90000 (91%)]	Loss: -16.9895	Cost: 10.60s
Train Epoch: 1140 	Average Loss: -16.7373
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4245

Learning rate: 0.00013681245526846785
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1141 [0/90000 (0%)]	Loss: -10.1356	Cost: 36.70s
Train Epoch: 1141 [20480/90000 (23%)]	Loss: -17.0989	Cost: 9.71s
Train Epoch: 1141 [40960/90000 (45%)]	Loss: -17.2185	Cost: 10.65s
Train Epoch: 1141 [61440/90000 (68%)]	Loss: -17.1051	Cost: 9.62s
Train Epoch: 1141 [81920/90000 (91%)]	Loss: -17.0034	Cost: 10.41s
Train Epoch: 1141 	Average Loss: -16.6361
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2906

Learning rate: 0.00013671506913565985
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1142 [0/90000 (0%)]	Loss: -10.7348	Cost: 39.71s
Train Epoch: 1142 [20480/90000 (23%)]	Loss: -17.2280	Cost: 10.15s
Train Epoch: 1142 [40960/90000 (45%)]	Loss: -17.3159	Cost: 11.04s
Train Epoch: 1142 [61440/90000 (68%)]	Loss: -17.2340	Cost: 9.45s
Train Epoch: 1142 [81920/90000 (91%)]	Loss: -17.0101	Cost: 9.28s
Train Epoch: 1142 	Average Loss: -16.7510
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4669

Learning rate: 0.00013661764274027684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1143 [0/90000 (0%)]	Loss: -11.1209	Cost: 43.08s
Train Epoch: 1143 [20480/90000 (23%)]	Loss: -17.2431	Cost: 10.06s
Train Epoch: 1143 [40960/90000 (45%)]	Loss: -17.4938	Cost: 13.71s
Train Epoch: 1143 [61440/90000 (68%)]	Loss: -16.8987	Cost: 9.80s
Train Epoch: 1143 [81920/90000 (91%)]	Loss: -17.0562	Cost: 11.44s
Train Epoch: 1143 	Average Loss: -16.7762
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4375

Learning rate: 0.00013652017618915883
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1144 [0/90000 (0%)]	Loss: -11.3145	Cost: 45.72s
Train Epoch: 1144 [20480/90000 (23%)]	Loss: -17.2583	Cost: 9.87s
Train Epoch: 1144 [40960/90000 (45%)]	Loss: -17.3847	Cost: 10.82s
Train Epoch: 1144 [61440/90000 (68%)]	Loss: -16.9931	Cost: 9.82s
Train Epoch: 1144 [81920/90000 (91%)]	Loss: -16.9635	Cost: 11.65s
Train Epoch: 1144 	Average Loss: -16.7243
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2003

Learning rate: 0.0001364226695891899
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1145 [0/90000 (0%)]	Loss: -10.7643	Cost: 36.63s
Train Epoch: 1145 [20480/90000 (23%)]	Loss: -16.7733	Cost: 12.28s
Train Epoch: 1145 [40960/90000 (45%)]	Loss: -17.0520	Cost: 13.99s
Train Epoch: 1145 [61440/90000 (68%)]	Loss: -16.7789	Cost: 9.71s
Train Epoch: 1145 [81920/90000 (91%)]	Loss: -16.8678	Cost: 10.94s
Train Epoch: 1145 	Average Loss: -16.4470
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.1842

Learning rate: 0.00013632512304729793
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1146 [0/90000 (0%)]	Loss: -10.9378	Cost: 34.27s
Train Epoch: 1146 [20480/90000 (23%)]	Loss: -17.1207	Cost: 11.40s
Train Epoch: 1146 [40960/90000 (45%)]	Loss: -17.4395	Cost: 12.31s
Train Epoch: 1146 [61440/90000 (68%)]	Loss: -17.1906	Cost: 9.88s
Train Epoch: 1146 [81920/90000 (91%)]	Loss: -17.1413	Cost: 12.68s
Train Epoch: 1146 	Average Loss: -16.7646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4798

Learning rate: 0.00013622753667045465
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1147 [0/90000 (0%)]	Loss: -11.1676	Cost: 31.53s
Train Epoch: 1147 [20480/90000 (23%)]	Loss: -17.1128	Cost: 10.19s
Train Epoch: 1147 [40960/90000 (45%)]	Loss: -15.7644	Cost: 16.05s
Train Epoch: 1147 [61440/90000 (68%)]	Loss: -15.0960	Cost: 10.95s
Train Epoch: 1147 [81920/90000 (91%)]	Loss: -15.4118	Cost: 13.72s
Train Epoch: 1147 	Average Loss: -15.6110
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1395

Learning rate: 0.0001361299105656755
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1148 [0/90000 (0%)]	Loss: -9.8652	Cost: 34.57s
Train Epoch: 1148 [20480/90000 (23%)]	Loss: -15.3229	Cost: 9.83s
Train Epoch: 1148 [40960/90000 (45%)]	Loss: -16.0587	Cost: 11.58s
Train Epoch: 1148 [61440/90000 (68%)]	Loss: -16.0297	Cost: 10.15s
Train Epoch: 1148 [81920/90000 (91%)]	Loss: -16.0140	Cost: 14.63s
Train Epoch: 1148 	Average Loss: -15.3828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.6409

Learning rate: 0.00013603224484001956
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1149 [0/90000 (0%)]	Loss: -10.8339	Cost: 30.87s
Train Epoch: 1149 [20480/90000 (23%)]	Loss: -16.3118	Cost: 10.70s
Train Epoch: 1149 [40960/90000 (45%)]	Loss: -16.9637	Cost: 11.10s
Train Epoch: 1149 [61440/90000 (68%)]	Loss: -17.0076	Cost: 9.52s
Train Epoch: 1149 [81920/90000 (91%)]	Loss: -17.0234	Cost: 11.79s
Train Epoch: 1149 	Average Loss: -16.3261
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4663

Learning rate: 0.00013593453960058916
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1150 [0/90000 (0%)]	Loss: -10.3488	Cost: 30.85s
Train Epoch: 1150 [20480/90000 (23%)]	Loss: -17.1100	Cost: 9.89s
Train Epoch: 1150 [40960/90000 (45%)]	Loss: -17.3342	Cost: 11.63s
Train Epoch: 1150 [61440/90000 (68%)]	Loss: -17.1028	Cost: 9.72s
Train Epoch: 1150 [81920/90000 (91%)]	Loss: -17.0284	Cost: 13.05s
Train Epoch: 1150 	Average Loss: -16.6409
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4430

Saving model as model.pt_e1150 & waveforms_supplementary.hdf5_e1150
Learning rate: 0.00013583679495453015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1151 [0/90000 (0%)]	Loss: -10.7717	Cost: 34.46s
Train Epoch: 1151 [20480/90000 (23%)]	Loss: -16.8751	Cost: 10.03s
Train Epoch: 1151 [40960/90000 (45%)]	Loss: -17.3346	Cost: 11.27s
Train Epoch: 1151 [61440/90000 (68%)]	Loss: -17.2940	Cost: 10.04s
Train Epoch: 1151 [81920/90000 (91%)]	Loss: -17.1487	Cost: 13.40s
Train Epoch: 1151 	Average Loss: -16.6802
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4973

Learning rate: 0.00013573901100903145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1152 [0/90000 (0%)]	Loss: -11.5504	Cost: 30.33s
Train Epoch: 1152 [20480/90000 (23%)]	Loss: -17.2402	Cost: 11.23s
Train Epoch: 1152 [40960/90000 (45%)]	Loss: -17.4344	Cost: 11.36s
Train Epoch: 1152 [61440/90000 (68%)]	Loss: -17.0294	Cost: 9.50s
Train Epoch: 1152 [81920/90000 (91%)]	Loss: -16.8904	Cost: 10.77s
Train Epoch: 1152 	Average Loss: -16.7122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4651

Learning rate: 0.00013564118787132517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1153 [0/90000 (0%)]	Loss: -11.1061	Cost: 33.27s
Train Epoch: 1153 [20480/90000 (23%)]	Loss: -17.1940	Cost: 9.65s
Train Epoch: 1153 [40960/90000 (45%)]	Loss: -17.3210	Cost: 10.51s
Train Epoch: 1153 [61440/90000 (68%)]	Loss: -17.2578	Cost: 9.63s
Train Epoch: 1153 [81920/90000 (91%)]	Loss: -17.2434	Cost: 11.80s
Train Epoch: 1153 	Average Loss: -16.7461
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4872

Learning rate: 0.00013554332564868642
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1154 [0/90000 (0%)]	Loss: -11.5999	Cost: 36.41s
Train Epoch: 1154 [20480/90000 (23%)]	Loss: -17.3317	Cost: 9.74s
Train Epoch: 1154 [40960/90000 (45%)]	Loss: -17.4217	Cost: 11.04s
Train Epoch: 1154 [61440/90000 (68%)]	Loss: -17.1634	Cost: 9.65s
Train Epoch: 1154 [81920/90000 (91%)]	Loss: -17.0889	Cost: 11.32s
Train Epoch: 1154 	Average Loss: -16.7531
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4136

Learning rate: 0.00013544542444843304
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1155 [0/90000 (0%)]	Loss: -11.2509	Cost: 31.35s
Train Epoch: 1155 [20480/90000 (23%)]	Loss: -17.1139	Cost: 9.85s
Train Epoch: 1155 [40960/90000 (45%)]	Loss: -17.4152	Cost: 11.05s
Train Epoch: 1155 [61440/90000 (68%)]	Loss: -17.0640	Cost: 9.82s
Train Epoch: 1155 [81920/90000 (91%)]	Loss: -17.2117	Cost: 11.47s
Train Epoch: 1155 	Average Loss: -16.7486
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4587

Learning rate: 0.0001353474843779258
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1156 [0/90000 (0%)]	Loss: -10.7718	Cost: 50.52s
Train Epoch: 1156 [20480/90000 (23%)]	Loss: -17.2530	Cost: 9.72s
Train Epoch: 1156 [40960/90000 (45%)]	Loss: -17.5307	Cost: 9.67s
Train Epoch: 1156 [61440/90000 (68%)]	Loss: -17.2351	Cost: 9.66s
Train Epoch: 1156 [81920/90000 (91%)]	Loss: -17.3306	Cost: 10.92s
Train Epoch: 1156 	Average Loss: -16.8463
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6894

Learning rate: 0.00013524950554456795
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1157 [0/90000 (0%)]	Loss: -11.4358	Cost: 33.26s
Train Epoch: 1157 [20480/90000 (23%)]	Loss: -17.4087	Cost: 10.17s
Train Epoch: 1157 [40960/90000 (45%)]	Loss: -17.8268	Cost: 10.67s
Train Epoch: 1157 [61440/90000 (68%)]	Loss: -17.4754	Cost: 9.80s
Train Epoch: 1157 [81920/90000 (91%)]	Loss: -17.4355	Cost: 11.78s
Train Epoch: 1157 	Average Loss: -17.0145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8459

Learning rate: 0.0001351514880558053
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1158 [0/90000 (0%)]	Loss: -10.5193	Cost: 37.31s
Train Epoch: 1158 [20480/90000 (23%)]	Loss: -17.2978	Cost: 9.48s
Train Epoch: 1158 [40960/90000 (45%)]	Loss: -17.6728	Cost: 9.66s
Train Epoch: 1158 [61440/90000 (68%)]	Loss: -17.3259	Cost: 9.54s
Train Epoch: 1158 [81920/90000 (91%)]	Loss: -17.2482	Cost: 11.28s
Train Epoch: 1158 	Average Loss: -16.9884
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.5906

Learning rate: 0.00013505343201912598
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1159 [0/90000 (0%)]	Loss: -12.0397	Cost: 37.55s
Train Epoch: 1159 [20480/90000 (23%)]	Loss: -16.9772	Cost: 9.93s
Train Epoch: 1159 [40960/90000 (45%)]	Loss: -17.1147	Cost: 11.08s
Train Epoch: 1159 [61440/90000 (68%)]	Loss: -17.0277	Cost: 9.55s
Train Epoch: 1159 [81920/90000 (91%)]	Loss: -17.0147	Cost: 9.56s
Train Epoch: 1159 	Average Loss: -16.6701
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4344

Learning rate: 0.00013495533754206057
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1160 [0/90000 (0%)]	Loss: -11.3003	Cost: 39.38s
Train Epoch: 1160 [20480/90000 (23%)]	Loss: -17.2924	Cost: 9.84s
Train Epoch: 1160 [40960/90000 (45%)]	Loss: -17.5544	Cost: 11.07s
Train Epoch: 1160 [61440/90000 (68%)]	Loss: -17.4481	Cost: 9.75s
Train Epoch: 1160 [81920/90000 (91%)]	Loss: -17.0826	Cost: 11.46s
Train Epoch: 1160 	Average Loss: -16.8994
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6268

Learning rate: 0.0001348572047321816
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1161 [0/90000 (0%)]	Loss: -10.9809	Cost: 41.17s
Train Epoch: 1161 [20480/90000 (23%)]	Loss: -17.3411	Cost: 9.82s
Train Epoch: 1161 [40960/90000 (45%)]	Loss: -17.7338	Cost: 10.74s
Train Epoch: 1161 [61440/90000 (68%)]	Loss: -17.3926	Cost: 9.54s
Train Epoch: 1161 [81920/90000 (91%)]	Loss: -17.2741	Cost: 9.47s
Train Epoch: 1161 	Average Loss: -16.9854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7309

Learning rate: 0.00013475903369710378
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1162 [0/90000 (0%)]	Loss: -11.8507	Cost: 36.53s
Train Epoch: 1162 [20480/90000 (23%)]	Loss: -17.4364	Cost: 9.96s
Train Epoch: 1162 [40960/90000 (45%)]	Loss: -17.7462	Cost: 11.79s
Train Epoch: 1162 [61440/90000 (68%)]	Loss: -17.3422	Cost: 9.81s
Train Epoch: 1162 [81920/90000 (91%)]	Loss: -17.3555	Cost: 12.04s
Train Epoch: 1162 	Average Loss: -17.0806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7274

Learning rate: 0.00013466082454448368
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1163 [0/90000 (0%)]	Loss: -11.4219	Cost: 45.12s
Train Epoch: 1163 [20480/90000 (23%)]	Loss: -17.5468	Cost: 9.65s
Train Epoch: 1163 [40960/90000 (45%)]	Loss: -17.9111	Cost: 9.93s
Train Epoch: 1163 [61440/90000 (68%)]	Loss: -17.2857	Cost: 9.54s
Train Epoch: 1163 [81920/90000 (91%)]	Loss: -17.6488	Cost: 9.43s
Train Epoch: 1163 	Average Loss: -17.0660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.9489

Learning rate: 0.00013456257738201965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1164 [0/90000 (0%)]	Loss: -11.5227	Cost: 35.64s
Train Epoch: 1164 [20480/90000 (23%)]	Loss: -17.0630	Cost: 10.82s
Train Epoch: 1164 [40960/90000 (45%)]	Loss: -17.2656	Cost: 11.22s
Train Epoch: 1164 [61440/90000 (68%)]	Loss: -17.0414	Cost: 9.70s
Train Epoch: 1164 [81920/90000 (91%)]	Loss: -17.1084	Cost: 11.83s
Train Epoch: 1164 	Average Loss: -16.6979
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.3070

Learning rate: 0.00013446429231745178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1165 [0/90000 (0%)]	Loss: -11.1339	Cost: 44.67s
Train Epoch: 1165 [20480/90000 (23%)]	Loss: -17.1450	Cost: 9.68s
Train Epoch: 1165 [40960/90000 (45%)]	Loss: -17.5779	Cost: 10.85s
Train Epoch: 1165 [61440/90000 (68%)]	Loss: -17.2859	Cost: 9.50s
Train Epoch: 1165 [81920/90000 (91%)]	Loss: -17.2545	Cost: 9.88s
Train Epoch: 1165 	Average Loss: -16.9192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8269

Learning rate: 0.00013436596945856166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1166 [0/90000 (0%)]	Loss: -11.4882	Cost: 39.42s
Train Epoch: 1166 [20480/90000 (23%)]	Loss: -17.4265	Cost: 11.47s
Train Epoch: 1166 [40960/90000 (45%)]	Loss: -17.7420	Cost: 13.30s
Train Epoch: 1166 [61440/90000 (68%)]	Loss: -17.1866	Cost: 9.57s
Train Epoch: 1166 [81920/90000 (91%)]	Loss: -16.9998	Cost: 9.33s
Train Epoch: 1166 	Average Loss: -16.9382
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.2710

Learning rate: 0.00013426760891317241
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1167 [0/90000 (0%)]	Loss: -10.9131	Cost: 36.07s
Train Epoch: 1167 [20480/90000 (23%)]	Loss: -17.2080	Cost: 10.03s
Train Epoch: 1167 [40960/90000 (45%)]	Loss: -17.6143	Cost: 12.95s
Train Epoch: 1167 [61440/90000 (68%)]	Loss: -17.3328	Cost: 10.54s
Train Epoch: 1167 [81920/90000 (91%)]	Loss: -17.1424	Cost: 11.91s
Train Epoch: 1167 	Average Loss: -16.9010
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7217

Learning rate: 0.0001341692107891484
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1168 [0/90000 (0%)]	Loss: -10.8592	Cost: 37.08s
Train Epoch: 1168 [20480/90000 (23%)]	Loss: -17.2713	Cost: 12.57s
Train Epoch: 1168 [40960/90000 (45%)]	Loss: -17.8690	Cost: 14.41s
Train Epoch: 1168 [61440/90000 (68%)]	Loss: -17.4776	Cost: 9.72s
Train Epoch: 1168 [81920/90000 (91%)]	Loss: -17.3835	Cost: 13.01s
Train Epoch: 1168 	Average Loss: -17.0432
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7142

Learning rate: 0.00013407077519439524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1169 [0/90000 (0%)]	Loss: -11.2339	Cost: 38.09s
Train Epoch: 1169 [20480/90000 (23%)]	Loss: -17.5397	Cost: 9.89s
Train Epoch: 1169 [40960/90000 (45%)]	Loss: -17.4094	Cost: 15.14s
Train Epoch: 1169 [61440/90000 (68%)]	Loss: -17.2337	Cost: 11.25s
Train Epoch: 1169 [81920/90000 (91%)]	Loss: -17.2691	Cost: 12.51s
Train Epoch: 1169 	Average Loss: -16.9733
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4584

Learning rate: 0.0001339723022368596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1170 [0/90000 (0%)]	Loss: -10.4527	Cost: 29.77s
Train Epoch: 1170 [20480/90000 (23%)]	Loss: -17.2573	Cost: 9.99s
Train Epoch: 1170 [40960/90000 (45%)]	Loss: -17.6844	Cost: 12.17s
Train Epoch: 1170 [61440/90000 (68%)]	Loss: -17.3834	Cost: 10.47s
Train Epoch: 1170 [81920/90000 (91%)]	Loss: -17.2633	Cost: 14.10s
Train Epoch: 1170 	Average Loss: -16.9168
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4494

Learning rate: 0.0001338737920245292
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1171 [0/90000 (0%)]	Loss: -11.6849	Cost: 33.61s
Train Epoch: 1171 [20480/90000 (23%)]	Loss: -17.3914	Cost: 9.79s
Train Epoch: 1171 [40960/90000 (45%)]	Loss: -17.6142	Cost: 10.93s
Train Epoch: 1171 [61440/90000 (68%)]	Loss: -17.2632	Cost: 9.98s
Train Epoch: 1171 [81920/90000 (91%)]	Loss: -17.2617	Cost: 12.38s
Train Epoch: 1171 	Average Loss: -17.0242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6090

Learning rate: 0.00013377524466543254
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1172 [0/90000 (0%)]	Loss: -10.6503	Cost: 31.70s
Train Epoch: 1172 [20480/90000 (23%)]	Loss: -17.4437	Cost: 10.26s
Train Epoch: 1172 [40960/90000 (45%)]	Loss: -17.6307	Cost: 11.58s
Train Epoch: 1172 [61440/90000 (68%)]	Loss: -17.3489	Cost: 9.84s
Train Epoch: 1172 [81920/90000 (91%)]	Loss: -17.4957	Cost: 12.47s
Train Epoch: 1172 	Average Loss: -17.0363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8472

Learning rate: 0.0001336766602676389
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1173 [0/90000 (0%)]	Loss: -11.6118	Cost: 28.96s
Train Epoch: 1173 [20480/90000 (23%)]	Loss: -17.5088	Cost: 9.81s
Train Epoch: 1173 [40960/90000 (45%)]	Loss: -17.8020	Cost: 11.74s
Train Epoch: 1173 [61440/90000 (68%)]	Loss: -17.5134	Cost: 9.82s
Train Epoch: 1173 [81920/90000 (91%)]	Loss: -17.3459	Cost: 12.29s
Train Epoch: 1173 	Average Loss: -17.1607
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7716

Learning rate: 0.00013357803893925812
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1174 [0/90000 (0%)]	Loss: -11.3714	Cost: 40.75s
Train Epoch: 1174 [20480/90000 (23%)]	Loss: -17.5891	Cost: 9.68s
Train Epoch: 1174 [40960/90000 (45%)]	Loss: -17.7258	Cost: 10.04s
Train Epoch: 1174 [61440/90000 (68%)]	Loss: -17.6434	Cost: 9.66s
Train Epoch: 1174 [81920/90000 (91%)]	Loss: -17.5552	Cost: 11.49s
Train Epoch: 1174 	Average Loss: -17.1739
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.9106

Learning rate: 0.00013347938078844064
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1175 [0/90000 (0%)]	Loss: -11.4208	Cost: 33.17s
Train Epoch: 1175 [20480/90000 (23%)]	Loss: -17.5536	Cost: 10.61s
Train Epoch: 1175 [40960/90000 (45%)]	Loss: -17.9565	Cost: 11.53s
Train Epoch: 1175 [61440/90000 (68%)]	Loss: -17.5056	Cost: 9.59s
Train Epoch: 1175 [81920/90000 (91%)]	Loss: -17.5817	Cost: 10.83s
Train Epoch: 1175 	Average Loss: -17.1953
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8637

Learning rate: 0.00013338068592337718
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1176 [0/90000 (0%)]	Loss: -11.7717	Cost: 29.40s
Train Epoch: 1176 [20480/90000 (23%)]	Loss: -17.5253	Cost: 9.81s
Train Epoch: 1176 [40960/90000 (45%)]	Loss: -17.8800	Cost: 11.20s
Train Epoch: 1176 [61440/90000 (68%)]	Loss: -17.4380	Cost: 9.82s
Train Epoch: 1176 [81920/90000 (91%)]	Loss: -17.4143	Cost: 12.49s
Train Epoch: 1176 	Average Loss: -17.1916
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7174

Learning rate: 0.00013328195445229873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1177 [0/90000 (0%)]	Loss: -11.0538	Cost: 41.12s
Train Epoch: 1177 [20480/90000 (23%)]	Loss: -17.6306	Cost: 9.83s
Train Epoch: 1177 [40960/90000 (45%)]	Loss: -18.0068	Cost: 9.73s
Train Epoch: 1177 [61440/90000 (68%)]	Loss: -17.5069	Cost: 9.68s
Train Epoch: 1177 [81920/90000 (91%)]	Loss: -17.4399	Cost: 12.19s
Train Epoch: 1177 	Average Loss: -17.1671
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8230

Learning rate: 0.00013318318648347652
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1178 [0/90000 (0%)]	Loss: -11.0642	Cost: 33.91s
Train Epoch: 1178 [20480/90000 (23%)]	Loss: -17.6253	Cost: 10.06s
Train Epoch: 1178 [40960/90000 (45%)]	Loss: -17.9269	Cost: 11.86s
Train Epoch: 1178 [61440/90000 (68%)]	Loss: -17.5548	Cost: 9.82s
Train Epoch: 1178 [81920/90000 (91%)]	Loss: -17.2999	Cost: 12.31s
Train Epoch: 1178 	Average Loss: -17.1426
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7805

Learning rate: 0.0001330843821252217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1179 [0/90000 (0%)]	Loss: -11.2398	Cost: 30.53s
Train Epoch: 1179 [20480/90000 (23%)]	Loss: -17.5646	Cost: 10.26s
Train Epoch: 1179 [40960/90000 (45%)]	Loss: -17.7099	Cost: 10.67s
Train Epoch: 1179 [61440/90000 (68%)]	Loss: -17.5948	Cost: 10.10s
Train Epoch: 1179 [81920/90000 (91%)]	Loss: -17.3640	Cost: 11.81s
Train Epoch: 1179 	Average Loss: -17.1419
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7138

Learning rate: 0.00013298554148588536
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1180 [0/90000 (0%)]	Loss: -10.0980	Cost: 42.50s
Train Epoch: 1180 [20480/90000 (23%)]	Loss: -17.4062	Cost: 9.69s
Train Epoch: 1180 [40960/90000 (45%)]	Loss: -17.7234	Cost: 9.73s
Train Epoch: 1180 [61440/90000 (68%)]	Loss: -17.6069	Cost: 9.75s
Train Epoch: 1180 [81920/90000 (91%)]	Loss: -17.5012	Cost: 11.74s
Train Epoch: 1180 	Average Loss: -17.0533
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7749

Learning rate: 0.0001328866646738584
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1181 [0/90000 (0%)]	Loss: -11.7594	Cost: 31.80s
Train Epoch: 1181 [20480/90000 (23%)]	Loss: -17.7953	Cost: 9.81s
Train Epoch: 1181 [40960/90000 (45%)]	Loss: -18.0311	Cost: 12.38s
Train Epoch: 1181 [61440/90000 (68%)]	Loss: -17.4316	Cost: 9.89s
Train Epoch: 1181 [81920/90000 (91%)]	Loss: -17.6399	Cost: 11.25s
Train Epoch: 1181 	Average Loss: -17.2773
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.9402

Learning rate: 0.0001327877517975714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1182 [0/90000 (0%)]	Loss: -11.8805	Cost: 34.76s
Train Epoch: 1182 [20480/90000 (23%)]	Loss: -17.6233	Cost: 9.62s
Train Epoch: 1182 [40960/90000 (45%)]	Loss: -17.6660	Cost: 10.28s
Train Epoch: 1182 [61440/90000 (68%)]	Loss: -17.6645	Cost: 9.95s
Train Epoch: 1182 [81920/90000 (91%)]	Loss: -17.6543	Cost: 10.22s
Train Epoch: 1182 	Average Loss: -17.2395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.9466

Learning rate: 0.00013268880296549433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1183 [0/90000 (0%)]	Loss: -11.9498	Cost: 37.57s
Train Epoch: 1183 [20480/90000 (23%)]	Loss: -17.7330	Cost: 10.20s
Train Epoch: 1183 [40960/90000 (45%)]	Loss: -17.8198	Cost: 11.45s
Train Epoch: 1183 [61440/90000 (68%)]	Loss: -17.1509	Cost: 9.73s
Train Epoch: 1183 [81920/90000 (91%)]	Loss: -17.3865	Cost: 12.06s
Train Epoch: 1183 	Average Loss: -17.1598
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.9192

Learning rate: 0.00013258981828613686
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1184 [0/90000 (0%)]	Loss: -11.2719	Cost: 32.36s
Train Epoch: 1184 [20480/90000 (23%)]	Loss: -17.0933	Cost: 9.83s
Train Epoch: 1184 [40960/90000 (45%)]	Loss: -17.2684	Cost: 10.93s
Train Epoch: 1184 [61440/90000 (68%)]	Loss: -16.9357	Cost: 9.73s
Train Epoch: 1184 [81920/90000 (91%)]	Loss: -17.0418	Cost: 11.70s
Train Epoch: 1184 	Average Loss: -16.7544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.5601

Learning rate: 0.00013249079786804775
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1185 [0/90000 (0%)]	Loss: -10.8058	Cost: 46.62s
Train Epoch: 1185 [20480/90000 (23%)]	Loss: -17.4709	Cost: 9.56s
Train Epoch: 1185 [40960/90000 (45%)]	Loss: -17.7451	Cost: 10.00s
Train Epoch: 1185 [61440/90000 (68%)]	Loss: -17.3565	Cost: 9.63s
Train Epoch: 1185 [81920/90000 (91%)]	Loss: -17.4374	Cost: 10.65s
Train Epoch: 1185 	Average Loss: -17.0281
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7887

Learning rate: 0.00013239174181981503
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1186 [0/90000 (0%)]	Loss: -11.3602	Cost: 32.74s
Train Epoch: 1186 [20480/90000 (23%)]	Loss: -17.5339	Cost: 10.82s
Train Epoch: 1186 [40960/90000 (45%)]	Loss: -17.7195	Cost: 10.95s
Train Epoch: 1186 [61440/90000 (68%)]	Loss: -17.5570	Cost: 9.73s
Train Epoch: 1186 [81920/90000 (91%)]	Loss: -17.5699	Cost: 12.40s
Train Epoch: 1186 	Average Loss: -17.1983
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0523

Learning rate: 0.00013229265025006584
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1187 [0/90000 (0%)]	Loss: -10.9983	Cost: 35.41s
Train Epoch: 1187 [20480/90000 (23%)]	Loss: -17.4873	Cost: 9.65s
Train Epoch: 1187 [40960/90000 (45%)]	Loss: -18.0327	Cost: 10.39s
Train Epoch: 1187 [61440/90000 (68%)]	Loss: -17.4051	Cost: 9.53s
Train Epoch: 1187 [81920/90000 (91%)]	Loss: -17.6155	Cost: 11.25s
Train Epoch: 1187 	Average Loss: -17.2222
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8962

Learning rate: 0.0001321935232674662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1188 [0/90000 (0%)]	Loss: -11.7018	Cost: 42.15s
Train Epoch: 1188 [20480/90000 (23%)]	Loss: -17.7305	Cost: 9.64s
Train Epoch: 1188 [40960/90000 (45%)]	Loss: -17.9065	Cost: 10.69s
Train Epoch: 1188 [61440/90000 (68%)]	Loss: -17.4765	Cost: 9.72s
Train Epoch: 1188 [81920/90000 (91%)]	Loss: -17.5569	Cost: 9.47s
Train Epoch: 1188 	Average Loss: -17.2430
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7185

Learning rate: 0.00013209436098072104
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1189 [0/90000 (0%)]	Loss: -11.3140	Cost: 38.33s
Train Epoch: 1189 [20480/90000 (23%)]	Loss: -17.7612	Cost: 9.86s
Train Epoch: 1189 [40960/90000 (45%)]	Loss: -18.1056	Cost: 11.35s
Train Epoch: 1189 [61440/90000 (68%)]	Loss: -17.7362	Cost: 10.01s
Train Epoch: 1189 [81920/90000 (91%)]	Loss: -17.6252	Cost: 10.88s
Train Epoch: 1189 	Average Loss: -17.2739
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8977

Learning rate: 0.00013199516349857393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1190 [0/90000 (0%)]	Loss: -10.9920	Cost: 49.83s
Train Epoch: 1190 [20480/90000 (23%)]	Loss: -17.7513	Cost: 9.70s
Train Epoch: 1190 [40960/90000 (45%)]	Loss: -17.9627	Cost: 9.67s
Train Epoch: 1190 [61440/90000 (68%)]	Loss: -17.6888	Cost: 9.46s
Train Epoch: 1190 [81920/90000 (91%)]	Loss: -17.6332	Cost: 9.56s
Train Epoch: 1190 	Average Loss: -17.2657
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0129

Learning rate: 0.0001318959309298071
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1191 [0/90000 (0%)]	Loss: -11.3886	Cost: 35.01s
Train Epoch: 1191 [20480/90000 (23%)]	Loss: -17.8256	Cost: 10.03s
Train Epoch: 1191 [40960/90000 (45%)]	Loss: -17.8317	Cost: 11.89s
Train Epoch: 1191 [61440/90000 (68%)]	Loss: -17.5864	Cost: 9.67s
Train Epoch: 1191 [81920/90000 (91%)]	Loss: -17.4221	Cost: 11.99s
Train Epoch: 1191 	Average Loss: -17.1775
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.9981

Learning rate: 0.00013179666338324119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1192 [0/90000 (0%)]	Loss: -11.1861	Cost: 41.73s
Train Epoch: 1192 [20480/90000 (23%)]	Loss: -16.4870	Cost: 9.62s
Train Epoch: 1192 [40960/90000 (45%)]	Loss: -16.8939	Cost: 10.07s
Train Epoch: 1192 [61440/90000 (68%)]	Loss: -16.5788	Cost: 9.66s
Train Epoch: 1192 [81920/90000 (91%)]	Loss: -16.8899	Cost: 10.53s
Train Epoch: 1192 	Average Loss: -16.3984
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.4317

Learning rate: 0.00013169736096773529
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1193 [0/90000 (0%)]	Loss: -11.4129	Cost: 41.95s
Train Epoch: 1193 [20480/90000 (23%)]	Loss: -17.3587	Cost: 9.93s
Train Epoch: 1193 [40960/90000 (45%)]	Loss: -17.5447	Cost: 11.05s
Train Epoch: 1193 [61440/90000 (68%)]	Loss: -17.2642	Cost: 9.50s
Train Epoch: 1193 [81920/90000 (91%)]	Loss: -17.3615	Cost: 9.09s
Train Epoch: 1193 	Average Loss: -16.8702
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8983

Learning rate: 0.00013159802379218661
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1194 [0/90000 (0%)]	Loss: -12.1588	Cost: 44.92s
Train Epoch: 1194 [20480/90000 (23%)]	Loss: -17.8639	Cost: 10.04s
Train Epoch: 1194 [40960/90000 (45%)]	Loss: -18.0536	Cost: 12.92s
Train Epoch: 1194 [61440/90000 (68%)]	Loss: -17.7856	Cost: 9.84s
Train Epoch: 1194 [81920/90000 (91%)]	Loss: -17.6499	Cost: 11.68s
Train Epoch: 1194 	Average Loss: -17.3423
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1394

Learning rate: 0.0001314986519655306
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1195 [0/90000 (0%)]	Loss: -12.2194	Cost: 41.81s
Train Epoch: 1195 [20480/90000 (23%)]	Loss: -18.1001	Cost: 10.17s
Train Epoch: 1195 [40960/90000 (45%)]	Loss: -18.4252	Cost: 12.00s
Train Epoch: 1195 [61440/90000 (68%)]	Loss: -17.6355	Cost: 9.79s
Train Epoch: 1195 [81920/90000 (91%)]	Loss: -17.8412	Cost: 9.64s
Train Epoch: 1195 	Average Loss: -17.4936
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2803

Learning rate: 0.00013139924559674062
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1196 [0/90000 (0%)]	Loss: -11.7669	Cost: 45.46s
Train Epoch: 1196 [20480/90000 (23%)]	Loss: -17.9156	Cost: 9.84s
Train Epoch: 1196 [40960/90000 (45%)]	Loss: -18.1665	Cost: 12.03s
Train Epoch: 1196 [61440/90000 (68%)]	Loss: -17.6015	Cost: 9.74s
Train Epoch: 1196 [81920/90000 (91%)]	Loss: -17.3712	Cost: 11.59s
Train Epoch: 1196 	Average Loss: -17.3251
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8966

Learning rate: 0.00013129980479482793
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1197 [0/90000 (0%)]	Loss: -11.3012	Cost: 48.28s
Train Epoch: 1197 [20480/90000 (23%)]	Loss: -17.6336	Cost: 9.70s
Train Epoch: 1197 [40960/90000 (45%)]	Loss: -17.7640	Cost: 10.63s
Train Epoch: 1197 [61440/90000 (68%)]	Loss: -17.3098	Cost: 9.47s
Train Epoch: 1197 [81920/90000 (91%)]	Loss: -17.0057	Cost: 9.55s
Train Epoch: 1197 	Average Loss: -16.9840
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6819

Learning rate: 0.00013120032966884161
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1198 [0/90000 (0%)]	Loss: -11.1233	Cost: 35.82s
Train Epoch: 1198 [20480/90000 (23%)]	Loss: -17.3333	Cost: 12.04s
Train Epoch: 1198 [40960/90000 (45%)]	Loss: -17.7182	Cost: 11.95s
Train Epoch: 1198 [61440/90000 (68%)]	Loss: -17.5466	Cost: 9.61s
Train Epoch: 1198 [81920/90000 (91%)]	Loss: -17.6057	Cost: 9.59s
Train Epoch: 1198 	Average Loss: -17.0817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0476

Learning rate: 0.00013110082032786828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1199 [0/90000 (0%)]	Loss: -11.2436	Cost: 37.19s
Train Epoch: 1199 [20480/90000 (23%)]	Loss: -17.8973	Cost: 10.46s
Train Epoch: 1199 [40960/90000 (45%)]	Loss: -18.2771	Cost: 12.29s
Train Epoch: 1199 [61440/90000 (68%)]	Loss: -17.7336	Cost: 9.80s
Train Epoch: 1199 [81920/90000 (91%)]	Loss: -17.7380	Cost: 12.25s
Train Epoch: 1199 	Average Loss: -17.4071
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1843

Learning rate: 0.00013100127688103216
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1200 [0/90000 (0%)]	Loss: -11.7441	Cost: 33.41s
Train Epoch: 1200 [20480/90000 (23%)]	Loss: -17.9139	Cost: 11.52s
Train Epoch: 1200 [40960/90000 (45%)]	Loss: -18.0238	Cost: 15.32s
Train Epoch: 1200 [61440/90000 (68%)]	Loss: -17.5404	Cost: 10.28s
Train Epoch: 1200 [81920/90000 (91%)]	Loss: -17.5851	Cost: 14.67s
Train Epoch: 1200 	Average Loss: -17.3238
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1754

Saving model as model.pt_e1200 & waveforms_supplementary.hdf5_e1200
Learning rate: 0.00013090169943749485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1201 [0/90000 (0%)]	Loss: -11.2842	Cost: 37.65s
Train Epoch: 1201 [20480/90000 (23%)]	Loss: -18.0619	Cost: 10.01s
Train Epoch: 1201 [40960/90000 (45%)]	Loss: -18.0969	Cost: 16.77s
Train Epoch: 1201 [61440/90000 (68%)]	Loss: -17.9224	Cost: 10.61s
Train Epoch: 1201 [81920/90000 (91%)]	Loss: -17.6797	Cost: 14.23s
Train Epoch: 1201 	Average Loss: -17.4364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1825

Learning rate: 0.00013080208810645522
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1202 [0/90000 (0%)]	Loss: -12.3878	Cost: 30.76s
Train Epoch: 1202 [20480/90000 (23%)]	Loss: -17.9344	Cost: 10.41s
Train Epoch: 1202 [40960/90000 (45%)]	Loss: -18.2097	Cost: 11.65s
Train Epoch: 1202 [61440/90000 (68%)]	Loss: -17.8094	Cost: 10.64s
Train Epoch: 1202 [81920/90000 (91%)]	Loss: -17.6692	Cost: 13.58s
Train Epoch: 1202 	Average Loss: -17.4358
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2337

Learning rate: 0.00013070244299714928
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1203 [0/90000 (0%)]	Loss: -12.2423	Cost: 35.80s
Train Epoch: 1203 [20480/90000 (23%)]	Loss: -17.5955	Cost: 9.70s
Train Epoch: 1203 [40960/90000 (45%)]	Loss: -18.1232	Cost: 14.94s
Train Epoch: 1203 [61440/90000 (68%)]	Loss: -17.6562	Cost: 10.62s
Train Epoch: 1203 [81920/90000 (91%)]	Loss: -17.6111	Cost: 13.96s
Train Epoch: 1203 	Average Loss: -17.3481
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0591

Learning rate: 0.00013060276421885018
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1204 [0/90000 (0%)]	Loss: -11.9355	Cost: 36.48s
Train Epoch: 1204 [20480/90000 (23%)]	Loss: -17.7965	Cost: 9.96s
Train Epoch: 1204 [40960/90000 (45%)]	Loss: -18.0052	Cost: 10.63s
Train Epoch: 1204 [61440/90000 (68%)]	Loss: -17.7409	Cost: 9.76s
Train Epoch: 1204 [81920/90000 (91%)]	Loss: -17.7968	Cost: 11.76s
Train Epoch: 1204 	Average Loss: -17.2828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0599

Learning rate: 0.00013050305188086787
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1205 [0/90000 (0%)]	Loss: -11.4678	Cost: 29.43s
Train Epoch: 1205 [20480/90000 (23%)]	Loss: -17.7086	Cost: 10.15s
Train Epoch: 1205 [40960/90000 (45%)]	Loss: -18.0483	Cost: 12.15s
Train Epoch: 1205 [61440/90000 (68%)]	Loss: -17.5211	Cost: 10.14s
Train Epoch: 1205 [81920/90000 (91%)]	Loss: -17.6609	Cost: 11.41s
Train Epoch: 1205 	Average Loss: -17.1952
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8325

Learning rate: 0.00013040330609254914
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1206 [0/90000 (0%)]	Loss: -11.4358	Cost: 34.98s
Train Epoch: 1206 [20480/90000 (23%)]	Loss: -17.5394	Cost: 9.81s
Train Epoch: 1206 [40960/90000 (45%)]	Loss: -17.9083	Cost: 10.54s
Train Epoch: 1206 [61440/90000 (68%)]	Loss: -17.7951	Cost: 9.63s
Train Epoch: 1206 [81920/90000 (91%)]	Loss: -17.8928	Cost: 11.43s
Train Epoch: 1206 	Average Loss: -17.2576
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1414

Learning rate: 0.0001303035269632775
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1207 [0/90000 (0%)]	Loss: -12.0224	Cost: 32.04s
Train Epoch: 1207 [20480/90000 (23%)]	Loss: -17.8681	Cost: 9.82s
Train Epoch: 1207 [40960/90000 (45%)]	Loss: -18.0966	Cost: 11.85s
Train Epoch: 1207 [61440/90000 (68%)]	Loss: -17.8465	Cost: 9.98s
Train Epoch: 1207 [81920/90000 (91%)]	Loss: -17.7546	Cost: 11.70s
Train Epoch: 1207 	Average Loss: -17.4056
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0958

Learning rate: 0.00013020371460247302
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1208 [0/90000 (0%)]	Loss: -12.3646	Cost: 31.60s
Train Epoch: 1208 [20480/90000 (23%)]	Loss: -18.0409	Cost: 9.75s
Train Epoch: 1208 [40960/90000 (45%)]	Loss: -18.0611	Cost: 10.73s
Train Epoch: 1208 [61440/90000 (68%)]	Loss: -17.7643	Cost: 9.68s
Train Epoch: 1208 [81920/90000 (91%)]	Loss: -17.6318	Cost: 12.90s
Train Epoch: 1208 	Average Loss: -17.4169
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.1357

Learning rate: 0.00013010386911959217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1209 [0/90000 (0%)]	Loss: -12.0856	Cost: 35.43s
Train Epoch: 1209 [20480/90000 (23%)]	Loss: -17.7442	Cost: 9.77s
Train Epoch: 1209 [40960/90000 (45%)]	Loss: -18.2109	Cost: 12.13s
Train Epoch: 1209 [61440/90000 (68%)]	Loss: -17.9225	Cost: 9.86s
Train Epoch: 1209 [81920/90000 (91%)]	Loss: -17.2738	Cost: 10.75s
Train Epoch: 1209 	Average Loss: -17.3507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.5586

Learning rate: 0.0001300039906241277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1210 [0/90000 (0%)]	Loss: -10.9247	Cost: 32.79s
Train Epoch: 1210 [20480/90000 (23%)]	Loss: -16.9952	Cost: 9.88s
Train Epoch: 1210 [40960/90000 (45%)]	Loss: -17.3112	Cost: 11.84s
Train Epoch: 1210 [61440/90000 (68%)]	Loss: -17.3195	Cost: 9.84s
Train Epoch: 1210 [81920/90000 (91%)]	Loss: -17.3934	Cost: 12.18s
Train Epoch: 1210 	Average Loss: -16.9747
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8849

Learning rate: 0.00012990407922560876
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1211 [0/90000 (0%)]	Loss: -11.5279	Cost: 41.19s
Train Epoch: 1211 [20480/90000 (23%)]	Loss: -17.2443	Cost: 9.50s
Train Epoch: 1211 [40960/90000 (45%)]	Loss: -17.6348	Cost: 10.30s
Train Epoch: 1211 [61440/90000 (68%)]	Loss: -17.4055	Cost: 9.59s
Train Epoch: 1211 [81920/90000 (91%)]	Loss: -17.4558	Cost: 10.01s
Train Epoch: 1211 	Average Loss: -17.1183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0752

Learning rate: 0.00012980413503360037
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1212 [0/90000 (0%)]	Loss: -11.5262	Cost: 37.34s
Train Epoch: 1212 [20480/90000 (23%)]	Loss: -17.3479	Cost: 10.50s
Train Epoch: 1212 [40960/90000 (45%)]	Loss: -17.7848	Cost: 10.77s
Train Epoch: 1212 [61440/90000 (68%)]	Loss: -17.5835	Cost: 9.57s
Train Epoch: 1212 [81920/90000 (91%)]	Loss: -17.5228	Cost: 9.45s
Train Epoch: 1212 	Average Loss: -17.1622
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6839

Learning rate: 0.00012970415815770358
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1213 [0/90000 (0%)]	Loss: -11.3678	Cost: 46.29s
Train Epoch: 1213 [20480/90000 (23%)]	Loss: -17.2737	Cost: 9.94s
Train Epoch: 1213 [40960/90000 (45%)]	Loss: -17.5661	Cost: 12.46s
Train Epoch: 1213 [61440/90000 (68%)]	Loss: -17.5783	Cost: 10.14s
Train Epoch: 1213 [81920/90000 (91%)]	Loss: -17.1136	Cost: 11.72s
Train Epoch: 1213 	Average Loss: -16.9496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.5381

Learning rate: 0.0001296041487075553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1214 [0/90000 (0%)]	Loss: -11.3354	Cost: 42.41s
Train Epoch: 1214 [20480/90000 (23%)]	Loss: -17.1818	Cost: 10.62s
Train Epoch: 1214 [40960/90000 (45%)]	Loss: -17.8328	Cost: 12.97s
Train Epoch: 1214 [61440/90000 (68%)]	Loss: -17.0559	Cost: 9.66s
Train Epoch: 1214 [81920/90000 (91%)]	Loss: -16.9464	Cost: 9.12s
Train Epoch: 1214 	Average Loss: -16.7354
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.6360

Learning rate: 0.0001295041067928282
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1215 [0/90000 (0%)]	Loss: -10.8642	Cost: 34.99s
Train Epoch: 1215 [20480/90000 (23%)]	Loss: -17.2784	Cost: 10.06s
Train Epoch: 1215 [40960/90000 (45%)]	Loss: -17.5836	Cost: 12.78s
Train Epoch: 1215 [61440/90000 (68%)]	Loss: -17.4488	Cost: 10.51s
Train Epoch: 1215 [81920/90000 (91%)]	Loss: -16.9992	Cost: 11.28s
Train Epoch: 1215 	Average Loss: -16.8480
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7425

Learning rate: 0.00012940403252323046
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1216 [0/90000 (0%)]	Loss: -11.1486	Cost: 30.83s
Train Epoch: 1216 [20480/90000 (23%)]	Loss: -17.5915	Cost: 11.90s
Train Epoch: 1216 [40960/90000 (45%)]	Loss: -17.9348	Cost: 12.88s
Train Epoch: 1216 [61440/90000 (68%)]	Loss: -17.3584	Cost: 11.04s
Train Epoch: 1216 [81920/90000 (91%)]	Loss: -16.8846	Cost: 10.25s
Train Epoch: 1216 	Average Loss: -17.0494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.9424

Learning rate: 0.0001293039260085058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1217 [0/90000 (0%)]	Loss: -11.5813	Cost: 38.58s
Train Epoch: 1217 [20480/90000 (23%)]	Loss: -17.7859	Cost: 9.80s
Train Epoch: 1217 [40960/90000 (45%)]	Loss: -18.2040	Cost: 11.88s
Train Epoch: 1217 [61440/90000 (68%)]	Loss: -17.5645	Cost: 10.75s
Train Epoch: 1217 [81920/90000 (91%)]	Loss: -17.4965	Cost: 14.71s
Train Epoch: 1217 	Average Loss: -17.2991
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2376

Learning rate: 0.00012920378735843327
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1218 [0/90000 (0%)]	Loss: -11.2822	Cost: 29.96s
Train Epoch: 1218 [20480/90000 (23%)]	Loss: -17.9152	Cost: 10.20s
Train Epoch: 1218 [40960/90000 (45%)]	Loss: -18.1259	Cost: 11.90s
Train Epoch: 1218 [61440/90000 (68%)]	Loss: -17.6629	Cost: 9.75s
Train Epoch: 1218 [81920/90000 (91%)]	Loss: -17.7385	Cost: 11.89s
Train Epoch: 1218 	Average Loss: -17.4333
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2962

Learning rate: 0.0001291036166828272
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1219 [0/90000 (0%)]	Loss: -11.9869	Cost: 34.19s
Train Epoch: 1219 [20480/90000 (23%)]	Loss: -18.1461	Cost: 9.66s
Train Epoch: 1219 [40960/90000 (45%)]	Loss: -18.4410	Cost: 11.38s
Train Epoch: 1219 [61440/90000 (68%)]	Loss: -17.9713	Cost: 10.37s
Train Epoch: 1219 [81920/90000 (91%)]	Loss: -17.7058	Cost: 11.56s
Train Epoch: 1219 	Average Loss: -17.5569
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3673

Learning rate: 0.00012900341409153706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1220 [0/90000 (0%)]	Loss: -11.3804	Cost: 32.98s
Train Epoch: 1220 [20480/90000 (23%)]	Loss: -17.9193	Cost: 10.69s
Train Epoch: 1220 [40960/90000 (45%)]	Loss: -18.2979	Cost: 13.20s
Train Epoch: 1220 [61440/90000 (68%)]	Loss: -17.8927	Cost: 9.69s
Train Epoch: 1220 [81920/90000 (91%)]	Loss: -17.8082	Cost: 12.32s
Train Epoch: 1220 	Average Loss: -17.5974
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3336

Learning rate: 0.00012890317969444718
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1221 [0/90000 (0%)]	Loss: -11.6076	Cost: 28.79s
Train Epoch: 1221 [20480/90000 (23%)]	Loss: -18.2111	Cost: 9.80s
Train Epoch: 1221 [40960/90000 (45%)]	Loss: -18.3790	Cost: 12.18s
Train Epoch: 1221 [61440/90000 (68%)]	Loss: -17.9397	Cost: 10.07s
Train Epoch: 1221 [81920/90000 (91%)]	Loss: -17.8057	Cost: 12.36s
Train Epoch: 1221 	Average Loss: -17.6622
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2306

Learning rate: 0.00012880291360147696
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1222 [0/90000 (0%)]	Loss: -11.6468	Cost: 42.95s
Train Epoch: 1222 [20480/90000 (23%)]	Loss: -18.0205	Cost: 9.53s
Train Epoch: 1222 [40960/90000 (45%)]	Loss: -18.3095	Cost: 10.44s
Train Epoch: 1222 [61440/90000 (68%)]	Loss: -18.0453	Cost: 9.71s
Train Epoch: 1222 [81920/90000 (91%)]	Loss: -17.8905	Cost: 12.29s
Train Epoch: 1222 	Average Loss: -17.6024
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2243

Learning rate: 0.0001287026159225804
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1223 [0/90000 (0%)]	Loss: -11.7198	Cost: 33.51s
Train Epoch: 1223 [20480/90000 (23%)]	Loss: -18.2556	Cost: 10.79s
Train Epoch: 1223 [40960/90000 (45%)]	Loss: -18.4071	Cost: 12.47s
Train Epoch: 1223 [61440/90000 (68%)]	Loss: -17.9925	Cost: 9.99s
Train Epoch: 1223 [81920/90000 (91%)]	Loss: -17.7085	Cost: 10.94s
Train Epoch: 1223 	Average Loss: -17.7078
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2281

Learning rate: 0.00012860228676774623
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1224 [0/90000 (0%)]	Loss: -11.8612	Cost: 28.74s
Train Epoch: 1224 [20480/90000 (23%)]	Loss: -18.1220	Cost: 9.73s
Train Epoch: 1224 [40960/90000 (45%)]	Loss: -18.2897	Cost: 11.36s
Train Epoch: 1224 [61440/90000 (68%)]	Loss: -17.9176	Cost: 9.75s
Train Epoch: 1224 [81920/90000 (91%)]	Loss: -17.9022	Cost: 12.38s
Train Epoch: 1224 	Average Loss: -17.6093
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2980

Learning rate: 0.00012850192624699763
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1225 [0/90000 (0%)]	Loss: -12.1653	Cost: 43.85s
Train Epoch: 1225 [20480/90000 (23%)]	Loss: -17.8370	Cost: 9.57s
Train Epoch: 1225 [40960/90000 (45%)]	Loss: -18.2609	Cost: 10.13s
Train Epoch: 1225 [61440/90000 (68%)]	Loss: -17.9065	Cost: 9.93s
Train Epoch: 1225 [81920/90000 (91%)]	Loss: -17.8640	Cost: 11.68s
Train Epoch: 1225 	Average Loss: -17.5960
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2058

Learning rate: 0.0001284015344703923
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1226 [0/90000 (0%)]	Loss: -11.7319	Cost: 31.87s
Train Epoch: 1226 [20480/90000 (23%)]	Loss: -17.7128	Cost: 10.31s
Train Epoch: 1226 [40960/90000 (45%)]	Loss: -18.1638	Cost: 12.24s
Train Epoch: 1226 [61440/90000 (68%)]	Loss: -17.9624	Cost: 9.88s
Train Epoch: 1226 [81920/90000 (91%)]	Loss: -17.9559	Cost: 10.85s
Train Epoch: 1226 	Average Loss: -17.6124
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3113

Learning rate: 0.00012830111154802206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1227 [0/90000 (0%)]	Loss: -12.0813	Cost: 35.05s
Train Epoch: 1227 [20480/90000 (23%)]	Loss: -18.0429	Cost: 9.77s
Train Epoch: 1227 [40960/90000 (45%)]	Loss: -17.8818	Cost: 10.25s
Train Epoch: 1227 [61440/90000 (68%)]	Loss: -17.8269	Cost: 9.76s
Train Epoch: 1227 [81920/90000 (91%)]	Loss: -17.4996	Cost: 10.69s
Train Epoch: 1227 	Average Loss: -17.4233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.0147

Learning rate: 0.00012820065759001296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1228 [0/90000 (0%)]	Loss: -12.2797	Cost: 35.81s
Train Epoch: 1228 [20480/90000 (23%)]	Loss: -17.6853	Cost: 10.15s
Train Epoch: 1228 [40960/90000 (45%)]	Loss: -18.0827	Cost: 10.84s
Train Epoch: 1228 [61440/90000 (68%)]	Loss: -17.8874	Cost: 9.54s
Train Epoch: 1228 [81920/90000 (91%)]	Loss: -17.9375	Cost: 10.34s
Train Epoch: 1228 	Average Loss: -17.5192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3060

Learning rate: 0.00012810017270652516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1229 [0/90000 (0%)]	Loss: -11.6744	Cost: 35.97s
Train Epoch: 1229 [20480/90000 (23%)]	Loss: -18.0691	Cost: 9.92s
Train Epoch: 1229 [40960/90000 (45%)]	Loss: -18.4013	Cost: 10.65s
Train Epoch: 1229 [61440/90000 (68%)]	Loss: -18.1807	Cost: 10.01s
Train Epoch: 1229 [81920/90000 (91%)]	Loss: -18.0064	Cost: 9.86s
Train Epoch: 1229 	Average Loss: -17.6875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2801

Learning rate: 0.00012799965700775257
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1230 [0/90000 (0%)]	Loss: -12.2263	Cost: 42.98s
Train Epoch: 1230 [20480/90000 (23%)]	Loss: -17.9908	Cost: 9.79s
Train Epoch: 1230 [40960/90000 (45%)]	Loss: -18.4332	Cost: 10.97s
Train Epoch: 1230 [61440/90000 (68%)]	Loss: -18.0061	Cost: 9.53s
Train Epoch: 1230 [81920/90000 (91%)]	Loss: -18.0707	Cost: 9.35s
Train Epoch: 1230 	Average Loss: -17.6917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4574

Learning rate: 0.00012789911060392297
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1231 [0/90000 (0%)]	Loss: -12.1952	Cost: 38.44s
Train Epoch: 1231 [20480/90000 (23%)]	Loss: -18.2137	Cost: 10.18s
Train Epoch: 1231 [40960/90000 (45%)]	Loss: -18.3619	Cost: 12.07s
Train Epoch: 1231 [61440/90000 (68%)]	Loss: -18.0995	Cost: 9.92s
Train Epoch: 1231 [81920/90000 (91%)]	Loss: -17.9325	Cost: 11.32s
Train Epoch: 1231 	Average Loss: -17.7357
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4164

Learning rate: 0.00012779853360529787
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1232 [0/90000 (0%)]	Loss: -11.8488	Cost: 44.21s
Train Epoch: 1232 [20480/90000 (23%)]	Loss: -18.0602	Cost: 9.74s
Train Epoch: 1232 [40960/90000 (45%)]	Loss: -18.4071	Cost: 10.79s
Train Epoch: 1232 [61440/90000 (68%)]	Loss: -18.2348	Cost: 9.43s
Train Epoch: 1232 [81920/90000 (91%)]	Loss: -18.2205	Cost: 9.60s
Train Epoch: 1232 	Average Loss: -17.7664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3848

Learning rate: 0.00012769792612217227
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1233 [0/90000 (0%)]	Loss: -12.5035	Cost: 35.38s
Train Epoch: 1233 [20480/90000 (23%)]	Loss: -18.3333	Cost: 12.22s
Train Epoch: 1233 [40960/90000 (45%)]	Loss: -18.5290	Cost: 12.13s
Train Epoch: 1233 [61440/90000 (68%)]	Loss: -18.2737	Cost: 9.93s
Train Epoch: 1233 [81920/90000 (91%)]	Loss: -17.9855	Cost: 10.14s
Train Epoch: 1233 	Average Loss: -17.8461
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5634

Learning rate: 0.00012759728826487458
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1234 [0/90000 (0%)]	Loss: -11.7954	Cost: 53.32s
Train Epoch: 1234 [20480/90000 (23%)]	Loss: -18.2923	Cost: 9.92s
Train Epoch: 1234 [40960/90000 (45%)]	Loss: -18.2844	Cost: 11.49s
Train Epoch: 1234 [61440/90000 (68%)]	Loss: -18.0719	Cost: 9.75s
Train Epoch: 1234 [81920/90000 (91%)]	Loss: -18.2700	Cost: 9.44s
Train Epoch: 1234 	Average Loss: -17.8278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4619

Learning rate: 0.0001274966201437666
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1235 [0/90000 (0%)]	Loss: -12.7347	Cost: 41.77s
Train Epoch: 1235 [20480/90000 (23%)]	Loss: -18.2036	Cost: 11.49s
Train Epoch: 1235 [40960/90000 (45%)]	Loss: -18.5436	Cost: 13.07s
Train Epoch: 1235 [61440/90000 (68%)]	Loss: -18.1348	Cost: 9.79s
Train Epoch: 1235 [81920/90000 (91%)]	Loss: -17.9977	Cost: 9.14s
Train Epoch: 1235 	Average Loss: -17.7561
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2084

Learning rate: 0.00012739592186924325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1236 [0/90000 (0%)]	Loss: -11.4055	Cost: 52.76s
Train Epoch: 1236 [20480/90000 (23%)]	Loss: -18.0096	Cost: 10.19s
Train Epoch: 1236 [40960/90000 (45%)]	Loss: -18.3983	Cost: 12.03s
Train Epoch: 1236 [61440/90000 (68%)]	Loss: -18.2510	Cost: 9.85s
Train Epoch: 1236 [81920/90000 (91%)]	Loss: -17.9091	Cost: 11.24s
Train Epoch: 1236 	Average Loss: -17.7250
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4742

Learning rate: 0.00012729519355173248
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1237 [0/90000 (0%)]	Loss: -11.1425	Cost: 42.63s
Train Epoch: 1237 [20480/90000 (23%)]	Loss: -17.9901	Cost: 10.23s
Train Epoch: 1237 [40960/90000 (45%)]	Loss: -18.3442	Cost: 12.29s
Train Epoch: 1237 [61440/90000 (68%)]	Loss: -18.2574	Cost: 9.75s
Train Epoch: 1237 [81920/90000 (91%)]	Loss: -18.2033	Cost: 9.49s
Train Epoch: 1237 	Average Loss: -17.7284
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4923

Learning rate: 0.00012719443530169537
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1238 [0/90000 (0%)]	Loss: -11.9468	Cost: 35.48s
Train Epoch: 1238 [20480/90000 (23%)]	Loss: -18.1878	Cost: 11.40s
Train Epoch: 1238 [40960/90000 (45%)]	Loss: -18.6095	Cost: 13.34s
Train Epoch: 1238 [61440/90000 (68%)]	Loss: -18.2344	Cost: 10.72s
Train Epoch: 1238 [81920/90000 (91%)]	Loss: -18.2017	Cost: 10.17s
Train Epoch: 1238 	Average Loss: -17.8534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6574

Learning rate: 0.00012709364722962558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1239 [0/90000 (0%)]	Loss: -12.1903	Cost: 32.89s
Train Epoch: 1239 [20480/90000 (23%)]	Loss: -18.1832	Cost: 12.40s
Train Epoch: 1239 [40960/90000 (45%)]	Loss: -18.4518	Cost: 17.01s
Train Epoch: 1239 [61440/90000 (68%)]	Loss: -17.8863	Cost: 9.94s
Train Epoch: 1239 [81920/90000 (91%)]	Loss: -17.9340	Cost: 13.14s
Train Epoch: 1239 	Average Loss: -17.7565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2893

Learning rate: 0.0001269928294460496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1240 [0/90000 (0%)]	Loss: -11.9630	Cost: 33.08s
Train Epoch: 1240 [20480/90000 (23%)]	Loss: -18.1282	Cost: 11.43s
Train Epoch: 1240 [40960/90000 (45%)]	Loss: -18.3996	Cost: 15.20s
Train Epoch: 1240 [61440/90000 (68%)]	Loss: -18.0588	Cost: 11.33s
Train Epoch: 1240 [81920/90000 (91%)]	Loss: -18.1530	Cost: 12.30s
Train Epoch: 1240 	Average Loss: -17.6975
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4811

Learning rate: 0.00012689198206152657
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1241 [0/90000 (0%)]	Loss: -12.0433	Cost: 36.23s
Train Epoch: 1241 [20480/90000 (23%)]	Loss: -18.3235	Cost: 9.85s
Train Epoch: 1241 [40960/90000 (45%)]	Loss: -18.6758	Cost: 12.78s
Train Epoch: 1241 [61440/90000 (68%)]	Loss: -18.2878	Cost: 10.07s
Train Epoch: 1241 [81920/90000 (91%)]	Loss: -18.4755	Cost: 14.79s
Train Epoch: 1241 	Average Loss: -17.9404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5802

Learning rate: 0.00012679110518664795
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1242 [0/90000 (0%)]	Loss: -12.5685	Cost: 29.43s
Train Epoch: 1242 [20480/90000 (23%)]	Loss: -18.2889	Cost: 9.91s
Train Epoch: 1242 [40960/90000 (45%)]	Loss: -18.6165	Cost: 12.92s
Train Epoch: 1242 [61440/90000 (68%)]	Loss: -18.3928	Cost: 9.84s
Train Epoch: 1242 [81920/90000 (91%)]	Loss: -18.1513	Cost: 12.08s
Train Epoch: 1242 	Average Loss: -17.9002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4176

Learning rate: 0.00012669019893203756
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1243 [0/90000 (0%)]	Loss: -11.9463	Cost: 34.93s
Train Epoch: 1243 [20480/90000 (23%)]	Loss: -18.2048	Cost: 9.83s
Train Epoch: 1243 [40960/90000 (45%)]	Loss: -18.4585	Cost: 11.81s
Train Epoch: 1243 [61440/90000 (68%)]	Loss: -18.2954	Cost: 9.77s
Train Epoch: 1243 [81920/90000 (91%)]	Loss: -18.1310	Cost: 11.24s
Train Epoch: 1243 	Average Loss: -17.7836
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3724

Learning rate: 0.00012658926340835156
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1244 [0/90000 (0%)]	Loss: -11.7102	Cost: 32.00s
Train Epoch: 1244 [20480/90000 (23%)]	Loss: -18.0867	Cost: 10.42s
Train Epoch: 1244 [40960/90000 (45%)]	Loss: -18.5828	Cost: 11.50s
Train Epoch: 1244 [61440/90000 (68%)]	Loss: -18.2050	Cost: 9.65s
Train Epoch: 1244 [81920/90000 (91%)]	Loss: -18.1870	Cost: 9.63s
Train Epoch: 1244 	Average Loss: -17.7963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3734

Learning rate: 0.00012648829872627807
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1245 [0/90000 (0%)]	Loss: -12.3635	Cost: 30.78s
Train Epoch: 1245 [20480/90000 (23%)]	Loss: -17.9969	Cost: 9.71s
Train Epoch: 1245 [40960/90000 (45%)]	Loss: -18.3971	Cost: 10.68s
Train Epoch: 1245 [61440/90000 (68%)]	Loss: -18.1369	Cost: 9.90s
Train Epoch: 1245 [81920/90000 (91%)]	Loss: -17.9045	Cost: 11.78s
Train Epoch: 1245 	Average Loss: -17.7254
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3181

Learning rate: 0.0001263873049965373
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1246 [0/90000 (0%)]	Loss: -12.3774	Cost: 41.43s
Train Epoch: 1246 [20480/90000 (23%)]	Loss: -17.9082	Cost: 9.61s
Train Epoch: 1246 [40960/90000 (45%)]	Loss: -18.2884	Cost: 10.53s
Train Epoch: 1246 [61440/90000 (68%)]	Loss: -18.2518	Cost: 10.35s
Train Epoch: 1246 [81920/90000 (91%)]	Loss: -18.0574	Cost: 11.53s
Train Epoch: 1246 	Average Loss: -17.5965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.2986

Learning rate: 0.0001262862823298812
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1247 [0/90000 (0%)]	Loss: -12.0176	Cost: 31.25s
Train Epoch: 1247 [20480/90000 (23%)]	Loss: -17.9874	Cost: 10.00s
Train Epoch: 1247 [40960/90000 (45%)]	Loss: -18.2407	Cost: 11.26s
Train Epoch: 1247 [61440/90000 (68%)]	Loss: -18.1426	Cost: 9.99s
Train Epoch: 1247 [81920/90000 (91%)]	Loss: -17.9558	Cost: 11.75s
Train Epoch: 1247 	Average Loss: -17.6677
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.3907

Learning rate: 0.0001261852308370936
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1248 [0/90000 (0%)]	Loss: -12.0470	Cost: 40.30s
Train Epoch: 1248 [20480/90000 (23%)]	Loss: -18.2223	Cost: 9.72s
Train Epoch: 1248 [40960/90000 (45%)]	Loss: -18.3998	Cost: 9.75s
Train Epoch: 1248 [61440/90000 (68%)]	Loss: -18.3430	Cost: 9.67s
Train Epoch: 1248 [81920/90000 (91%)]	Loss: -18.2413	Cost: 10.92s
Train Epoch: 1248 	Average Loss: -17.8587
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5455

Learning rate: 0.00012608415062898972
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1249 [0/90000 (0%)]	Loss: -12.4059	Cost: 36.32s
Train Epoch: 1249 [20480/90000 (23%)]	Loss: -18.3478	Cost: 10.00s
Train Epoch: 1249 [40960/90000 (45%)]	Loss: -18.6049	Cost: 11.20s
Train Epoch: 1249 [61440/90000 (68%)]	Loss: -18.3755	Cost: 9.86s
Train Epoch: 1249 [81920/90000 (91%)]	Loss: -18.1531	Cost: 11.33s
Train Epoch: 1249 	Average Loss: -17.9473
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4355

Learning rate: 0.0001259830418164165
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1250 [0/90000 (0%)]	Loss: -12.3028	Cost: 33.68s
Train Epoch: 1250 [20480/90000 (23%)]	Loss: -18.4569	Cost: 9.91s
Train Epoch: 1250 [40960/90000 (45%)]	Loss: -18.7116	Cost: 10.74s
Train Epoch: 1250 [61440/90000 (68%)]	Loss: -18.4041	Cost: 10.08s
Train Epoch: 1250 [81920/90000 (91%)]	Loss: -18.1998	Cost: 10.47s
Train Epoch: 1250 	Average Loss: -17.9577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5733

Saving model as model.pt_e1250 & waveforms_supplementary.hdf5_e1250
Learning rate: 0.0001258819045102521
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1251 [0/90000 (0%)]	Loss: -12.6031	Cost: 38.39s
Train Epoch: 1251 [20480/90000 (23%)]	Loss: -18.3452	Cost: 9.75s
Train Epoch: 1251 [40960/90000 (45%)]	Loss: -18.5524	Cost: 11.00s
Train Epoch: 1251 [61440/90000 (68%)]	Loss: -18.2677	Cost: 9.67s
Train Epoch: 1251 [81920/90000 (91%)]	Loss: -18.1742	Cost: 11.42s
Train Epoch: 1251 	Average Loss: -17.8707
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5643

Learning rate: 0.00012578073882140602
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1252 [0/90000 (0%)]	Loss: -12.2605	Cost: 31.56s
Train Epoch: 1252 [20480/90000 (23%)]	Loss: -18.4653	Cost: 10.08s
Train Epoch: 1252 [40960/90000 (45%)]	Loss: -18.7868	Cost: 11.71s
Train Epoch: 1252 [61440/90000 (68%)]	Loss: -18.3011	Cost: 9.65s
Train Epoch: 1252 [81920/90000 (91%)]	Loss: -18.2802	Cost: 12.51s
Train Epoch: 1252 	Average Loss: -17.9793
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6303

Learning rate: 0.0001256795448608188
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1253 [0/90000 (0%)]	Loss: -12.0286	Cost: 35.21s
Train Epoch: 1253 [20480/90000 (23%)]	Loss: -18.3386	Cost: 9.62s
Train Epoch: 1253 [40960/90000 (45%)]	Loss: -18.6164	Cost: 10.45s
Train Epoch: 1253 [61440/90000 (68%)]	Loss: -18.2942	Cost: 9.64s
Train Epoch: 1253 [81920/90000 (91%)]	Loss: -18.0859	Cost: 11.23s
Train Epoch: 1253 	Average Loss: -17.9165
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5496

Learning rate: 0.00012557832273946205
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1254 [0/90000 (0%)]	Loss: -11.6194	Cost: 39.47s
Train Epoch: 1254 [20480/90000 (23%)]	Loss: -18.4548	Cost: 10.27s
Train Epoch: 1254 [40960/90000 (45%)]	Loss: -18.6396	Cost: 11.26s
Train Epoch: 1254 [61440/90000 (68%)]	Loss: -18.4060	Cost: 9.53s
Train Epoch: 1254 [81920/90000 (91%)]	Loss: -18.0864	Cost: 10.20s
Train Epoch: 1254 	Average Loss: -17.9108
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5285

Learning rate: 0.00012547707256833825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1255 [0/90000 (0%)]	Loss: -12.2345	Cost: 37.79s
Train Epoch: 1255 [20480/90000 (23%)]	Loss: -18.3194	Cost: 9.59s
Train Epoch: 1255 [40960/90000 (45%)]	Loss: -18.7119	Cost: 11.34s
Train Epoch: 1255 [61440/90000 (68%)]	Loss: -18.5897	Cost: 9.69s
Train Epoch: 1255 [81920/90000 (91%)]	Loss: -18.3640	Cost: 10.63s
Train Epoch: 1255 	Average Loss: -18.0251
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.6544

Learning rate: 0.0001253757944584806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1256 [0/90000 (0%)]	Loss: -11.9180	Cost: 41.83s
Train Epoch: 1256 [20480/90000 (23%)]	Loss: -18.3517	Cost: 9.72s
Train Epoch: 1256 [40960/90000 (45%)]	Loss: -18.5970	Cost: 11.35s
Train Epoch: 1256 [61440/90000 (68%)]	Loss: -18.3843	Cost: 9.48s
Train Epoch: 1256 [81920/90000 (91%)]	Loss: -18.4050	Cost: 9.81s
Train Epoch: 1256 	Average Loss: -18.0000
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.7187

Learning rate: 0.00012527448852095297
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1257 [0/90000 (0%)]	Loss: -11.3775	Cost: 40.08s
Train Epoch: 1257 [20480/90000 (23%)]	Loss: -18.5957	Cost: 9.89s
Train Epoch: 1257 [40960/90000 (45%)]	Loss: -18.6873	Cost: 11.87s
Train Epoch: 1257 [61440/90000 (68%)]	Loss: -18.3738	Cost: 9.88s
Train Epoch: 1257 [81920/90000 (91%)]	Loss: -18.3889	Cost: 11.42s
Train Epoch: 1257 	Average Loss: -17.9554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5599

Learning rate: 0.00012517315486684972
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1258 [0/90000 (0%)]	Loss: -12.0056	Cost: 40.58s
Train Epoch: 1258 [20480/90000 (23%)]	Loss: -18.2589	Cost: 9.93s
Train Epoch: 1258 [40960/90000 (45%)]	Loss: -18.3963	Cost: 10.37s
Train Epoch: 1258 [61440/90000 (68%)]	Loss: -18.0747	Cost: 9.56s
Train Epoch: 1258 [81920/90000 (91%)]	Loss: -18.1784	Cost: 9.29s
Train Epoch: 1258 	Average Loss: -17.8227
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4802

Learning rate: 0.0001250717936072957
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1259 [0/90000 (0%)]	Loss: -11.9512	Cost: 40.96s
Train Epoch: 1259 [20480/90000 (23%)]	Loss: -18.2859	Cost: 9.89s
Train Epoch: 1259 [40960/90000 (45%)]	Loss: -18.7537	Cost: 11.33s
Train Epoch: 1259 [61440/90000 (68%)]	Loss: -18.4301	Cost: 9.76s
Train Epoch: 1259 [81920/90000 (91%)]	Loss: -18.2680	Cost: 11.85s
Train Epoch: 1259 	Average Loss: -17.9724
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.7130

Learning rate: 0.00012497040485344587
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1260 [0/90000 (0%)]	Loss: -11.9918	Cost: 42.63s
Train Epoch: 1260 [20480/90000 (23%)]	Loss: -18.4322	Cost: 9.66s
Train Epoch: 1260 [40960/90000 (45%)]	Loss: -18.6610	Cost: 11.37s
Train Epoch: 1260 [61440/90000 (68%)]	Loss: -18.4699	Cost: 9.46s
Train Epoch: 1260 [81920/90000 (91%)]	Loss: -15.1740	Cost: 10.77s
Train Epoch: 1260 	Average Loss: -17.2290
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -10.1984

Learning rate: 0.00012486898871648549
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1261 [0/90000 (0%)]	Loss: -9.2812	Cost: 37.35s
Train Epoch: 1261 [20480/90000 (23%)]	Loss: -15.8195	Cost: 11.74s
Train Epoch: 1261 [40960/90000 (45%)]	Loss: -16.6437	Cost: 10.66s
Train Epoch: 1261 [61440/90000 (68%)]	Loss: -16.8588	Cost: 9.63s
Train Epoch: 1261 [81920/90000 (91%)]	Loss: -16.9885	Cost: 9.29s
Train Epoch: 1261 	Average Loss: -15.9353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.7233

Learning rate: 0.0001247675453076298
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1262 [0/90000 (0%)]	Loss: -11.2894	Cost: 58.59s
Train Epoch: 1262 [20480/90000 (23%)]	Loss: -17.7279	Cost: 9.91s
Train Epoch: 1262 [40960/90000 (45%)]	Loss: -18.1877	Cost: 11.71s
Train Epoch: 1262 [61440/90000 (68%)]	Loss: -17.8686	Cost: 9.96s
Train Epoch: 1262 [81920/90000 (91%)]	Loss: -17.7724	Cost: 11.23s
Train Epoch: 1262 	Average Loss: -17.3825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.4838

Learning rate: 0.0001246660747381239
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1263 [0/90000 (0%)]	Loss: -11.5721	Cost: 41.84s
Train Epoch: 1263 [20480/90000 (23%)]	Loss: -18.1049	Cost: 9.98s
Train Epoch: 1263 [40960/90000 (45%)]	Loss: -18.4563	Cost: 11.62s
Train Epoch: 1263 [61440/90000 (68%)]	Loss: -18.2575	Cost: 9.51s
Train Epoch: 1263 [81920/90000 (91%)]	Loss: -18.3584	Cost: 9.33s
Train Epoch: 1263 	Average Loss: -17.8411
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.7900

Learning rate: 0.0001245645771192427
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1264 [0/90000 (0%)]	Loss: -12.7852	Cost: 40.77s
Train Epoch: 1264 [20480/90000 (23%)]	Loss: -18.4250	Cost: 10.17s
Train Epoch: 1264 [40960/90000 (45%)]	Loss: -18.7254	Cost: 13.46s
Train Epoch: 1264 [61440/90000 (68%)]	Loss: -18.6106	Cost: 10.21s
Train Epoch: 1264 [81920/90000 (91%)]	Loss: -18.4269	Cost: 11.97s
Train Epoch: 1264 	Average Loss: -18.1340
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.8731

Learning rate: 0.0001244630525622908
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1265 [0/90000 (0%)]	Loss: -11.6431	Cost: 39.01s
Train Epoch: 1265 [20480/90000 (23%)]	Loss: -18.6058	Cost: 11.67s
Train Epoch: 1265 [40960/90000 (45%)]	Loss: -18.8751	Cost: 11.89s
Train Epoch: 1265 [61440/90000 (68%)]	Loss: -18.5367	Cost: 9.66s
Train Epoch: 1265 [81920/90000 (91%)]	Loss: -18.5645	Cost: 13.14s
Train Epoch: 1265 	Average Loss: -18.2214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9110

Learning rate: 0.0001243615011786023
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1266 [0/90000 (0%)]	Loss: -12.6113	Cost: 37.63s
Train Epoch: 1266 [20480/90000 (23%)]	Loss: -18.7410	Cost: 10.01s
Train Epoch: 1266 [40960/90000 (45%)]	Loss: -19.0376	Cost: 13.80s
Train Epoch: 1266 [61440/90000 (68%)]	Loss: -18.4560	Cost: 10.14s
Train Epoch: 1266 [81920/90000 (91%)]	Loss: -18.5159	Cost: 10.72s
Train Epoch: 1266 	Average Loss: -18.2505
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0354

Learning rate: 0.0001242599230795408
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1267 [0/90000 (0%)]	Loss: -12.2588	Cost: 31.87s
Train Epoch: 1267 [20480/90000 (23%)]	Loss: -18.6225	Cost: 9.92s
Train Epoch: 1267 [40960/90000 (45%)]	Loss: -19.0592	Cost: 14.03s
Train Epoch: 1267 [61440/90000 (68%)]	Loss: -18.6188	Cost: 10.36s
Train Epoch: 1267 [81920/90000 (91%)]	Loss: -18.4502	Cost: 11.09s
Train Epoch: 1267 	Average Loss: -18.3217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0869

Learning rate: 0.00012415831837649913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1268 [0/90000 (0%)]	Loss: -12.6256	Cost: 33.05s
Train Epoch: 1268 [20480/90000 (23%)]	Loss: -18.8066	Cost: 9.80s
Train Epoch: 1268 [40960/90000 (45%)]	Loss: -19.0786	Cost: 11.70s
Train Epoch: 1268 [61440/90000 (68%)]	Loss: -18.6332	Cost: 11.34s
Train Epoch: 1268 [81920/90000 (91%)]	Loss: -18.7187	Cost: 14.06s
Train Epoch: 1268 	Average Loss: -18.3585
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0618

Learning rate: 0.00012405668718089923
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1269 [0/90000 (0%)]	Loss: -13.1773	Cost: 34.49s
Train Epoch: 1269 [20480/90000 (23%)]	Loss: -18.6867	Cost: 10.01s
Train Epoch: 1269 [40960/90000 (45%)]	Loss: -19.0499	Cost: 10.68s
Train Epoch: 1269 [61440/90000 (68%)]	Loss: -18.5274	Cost: 9.71s
Train Epoch: 1269 [81920/90000 (91%)]	Loss: -18.4644	Cost: 12.34s
Train Epoch: 1269 	Average Loss: -18.3005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.7908

Learning rate: 0.00012395502960419225
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1270 [0/90000 (0%)]	Loss: -12.2546	Cost: 29.47s
Train Epoch: 1270 [20480/90000 (23%)]	Loss: -18.5220	Cost: 10.88s
Train Epoch: 1270 [40960/90000 (45%)]	Loss: -18.7122	Cost: 11.20s
Train Epoch: 1270 [61440/90000 (68%)]	Loss: -18.5884	Cost: 9.86s
Train Epoch: 1270 [81920/90000 (91%)]	Loss: -18.5252	Cost: 10.80s
Train Epoch: 1270 	Average Loss: -18.1657
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9244

Learning rate: 0.00012385334575785816
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1271 [0/90000 (0%)]	Loss: -12.4586	Cost: 35.70s
Train Epoch: 1271 [20480/90000 (23%)]	Loss: -18.6912	Cost: 9.60s
Train Epoch: 1271 [40960/90000 (45%)]	Loss: -18.9755	Cost: 10.28s
Train Epoch: 1271 [61440/90000 (68%)]	Loss: -18.8300	Cost: 9.61s
Train Epoch: 1271 [81920/90000 (91%)]	Loss: -18.4727	Cost: 10.89s
Train Epoch: 1271 	Average Loss: -18.2392
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0038

Learning rate: 0.00012375163575340572
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1272 [0/90000 (0%)]	Loss: -11.6946	Cost: 40.29s
Train Epoch: 1272 [20480/90000 (23%)]	Loss: -18.6324	Cost: 9.85s
Train Epoch: 1272 [40960/90000 (45%)]	Loss: -18.9315	Cost: 11.18s
Train Epoch: 1272 [61440/90000 (68%)]	Loss: -18.6840	Cost: 9.50s
Train Epoch: 1272 [81920/90000 (91%)]	Loss: -18.6749	Cost: 9.70s
Train Epoch: 1272 	Average Loss: -18.2648
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.8783

Learning rate: 0.0001236498997023725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1273 [0/90000 (0%)]	Loss: -12.6347	Cost: 39.43s
Train Epoch: 1273 [20480/90000 (23%)]	Loss: -18.8627	Cost: 9.72s
Train Epoch: 1273 [40960/90000 (45%)]	Loss: -18.9847	Cost: 11.18s
Train Epoch: 1273 [61440/90000 (68%)]	Loss: -18.5217	Cost: 9.74s
Train Epoch: 1273 [81920/90000 (91%)]	Loss: -18.6270	Cost: 11.32s
Train Epoch: 1273 	Average Loss: -18.3100
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9983

Learning rate: 0.00012354813771632453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1274 [0/90000 (0%)]	Loss: -12.4816	Cost: 51.76s
Train Epoch: 1274 [20480/90000 (23%)]	Loss: -18.8175	Cost: 9.70s
Train Epoch: 1274 [40960/90000 (45%)]	Loss: -19.0518	Cost: 9.76s
Train Epoch: 1274 [61440/90000 (68%)]	Loss: -18.7364	Cost: 9.91s
Train Epoch: 1274 [81920/90000 (91%)]	Loss: -18.6416	Cost: 10.32s
Train Epoch: 1274 	Average Loss: -18.2811
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9513

Learning rate: 0.00012344634990685627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1275 [0/90000 (0%)]	Loss: -12.3701	Cost: 35.86s
Train Epoch: 1275 [20480/90000 (23%)]	Loss: -18.4080	Cost: 10.72s
Train Epoch: 1275 [40960/90000 (45%)]	Loss: -18.8412	Cost: 10.75s
Train Epoch: 1275 [61440/90000 (68%)]	Loss: -18.4762	Cost: 9.55s
Train Epoch: 1275 [81920/90000 (91%)]	Loss: -18.1898	Cost: 10.78s
Train Epoch: 1275 	Average Loss: -18.0826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.5630

Learning rate: 0.00012334453638559057
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1276 [0/90000 (0%)]	Loss: -11.9941	Cost: 41.29s
Train Epoch: 1276 [20480/90000 (23%)]	Loss: -18.1437	Cost: 9.76s
Train Epoch: 1276 [40960/90000 (45%)]	Loss: -18.7261	Cost: 10.82s
Train Epoch: 1276 [61440/90000 (68%)]	Loss: -18.1983	Cost: 9.73s
Train Epoch: 1276 [81920/90000 (91%)]	Loss: -18.3041	Cost: 9.60s
Train Epoch: 1276 	Average Loss: -17.9069
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.8139

Learning rate: 0.0001232426972641784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1277 [0/90000 (0%)]	Loss: -12.5632	Cost: 37.88s
Train Epoch: 1277 [20480/90000 (23%)]	Loss: -18.5806	Cost: 11.83s
Train Epoch: 1277 [40960/90000 (45%)]	Loss: -19.0192	Cost: 12.15s
Train Epoch: 1277 [61440/90000 (68%)]	Loss: -18.6954	Cost: 9.58s
Train Epoch: 1277 [81920/90000 (91%)]	Loss: -18.3152	Cost: 9.48s
Train Epoch: 1277 	Average Loss: -18.1782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.8637

Learning rate: 0.00012314083265429893
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1278 [0/90000 (0%)]	Loss: -12.5006	Cost: 51.94s
Train Epoch: 1278 [20480/90000 (23%)]	Loss: -18.4963	Cost: 9.74s
Train Epoch: 1278 [40960/90000 (45%)]	Loss: -18.8538	Cost: 12.67s
Train Epoch: 1278 [61440/90000 (68%)]	Loss: -18.6042	Cost: 9.71s
Train Epoch: 1278 [81920/90000 (91%)]	Loss: -18.7118	Cost: 11.90s
Train Epoch: 1278 	Average Loss: -18.2331
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9809

Learning rate: 0.00012303894266765908
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1279 [0/90000 (0%)]	Loss: -13.0987	Cost: 48.95s
Train Epoch: 1279 [20480/90000 (23%)]	Loss: -18.7656	Cost: 9.66s
Train Epoch: 1279 [40960/90000 (45%)]	Loss: -18.9847	Cost: 11.31s
Train Epoch: 1279 [61440/90000 (68%)]	Loss: -18.8988	Cost: 9.56s
Train Epoch: 1279 [81920/90000 (91%)]	Loss: -18.7604	Cost: 9.34s
Train Epoch: 1279 	Average Loss: -18.3700
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1972

Learning rate: 0.00012293702741599378
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1280 [0/90000 (0%)]	Loss: -13.0704	Cost: 37.86s
Train Epoch: 1280 [20480/90000 (23%)]	Loss: -18.8290	Cost: 11.36s
Train Epoch: 1280 [40960/90000 (45%)]	Loss: -19.4383	Cost: 11.67s
Train Epoch: 1280 [61440/90000 (68%)]	Loss: -19.0074	Cost: 9.69s
Train Epoch: 1280 [81920/90000 (91%)]	Loss: -18.7172	Cost: 11.07s
Train Epoch: 1280 	Average Loss: -18.4979
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0730

Learning rate: 0.0001228350870110656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1281 [0/90000 (0%)]	Loss: -12.6666	Cost: 51.49s
Train Epoch: 1281 [20480/90000 (23%)]	Loss: -18.9433	Cost: 9.69s
Train Epoch: 1281 [40960/90000 (45%)]	Loss: -19.1175	Cost: 10.91s
Train Epoch: 1281 [61440/90000 (68%)]	Loss: -18.9126	Cost: 9.49s
Train Epoch: 1281 [81920/90000 (91%)]	Loss: -18.8263	Cost: 9.59s
Train Epoch: 1281 	Average Loss: -18.4802
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0210

Learning rate: 0.00012273312156466467
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1282 [0/90000 (0%)]	Loss: -9.6919	Cost: 35.23s
Train Epoch: 1282 [20480/90000 (23%)]	Loss: -18.9363	Cost: 12.57s
Train Epoch: 1282 [40960/90000 (45%)]	Loss: -19.0821	Cost: 13.38s
Train Epoch: 1282 [61440/90000 (68%)]	Loss: -18.8282	Cost: 9.83s
Train Epoch: 1282 [81920/90000 (91%)]	Loss: -18.6409	Cost: 10.57s
Train Epoch: 1282 	Average Loss: -18.3267
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0810

Learning rate: 0.0001226311311886086
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1283 [0/90000 (0%)]	Loss: -12.9566	Cost: 42.25s
Train Epoch: 1283 [20480/90000 (23%)]	Loss: -18.8600	Cost: 9.81s
Train Epoch: 1283 [40960/90000 (45%)]	Loss: -19.3082	Cost: 12.15s
Train Epoch: 1283 [61440/90000 (68%)]	Loss: -18.8915	Cost: 10.22s
Train Epoch: 1283 [81920/90000 (91%)]	Loss: -18.9669	Cost: 11.21s
Train Epoch: 1283 	Average Loss: -18.5124
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1416

Learning rate: 0.00012252911599474237
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1284 [0/90000 (0%)]	Loss: -13.0144	Cost: 48.33s
Train Epoch: 1284 [20480/90000 (23%)]	Loss: -18.9256	Cost: 9.96s
Train Epoch: 1284 [40960/90000 (45%)]	Loss: -18.8718	Cost: 12.38s
Train Epoch: 1284 [61440/90000 (68%)]	Loss: -18.6138	Cost: 9.50s
Train Epoch: 1284 [81920/90000 (91%)]	Loss: -18.7325	Cost: 9.70s
Train Epoch: 1284 	Average Loss: -18.3988
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9349

Learning rate: 0.00012242707609493812
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1285 [0/90000 (0%)]	Loss: -12.7193	Cost: 39.83s
Train Epoch: 1285 [20480/90000 (23%)]	Loss: -18.5970	Cost: 10.15s
Train Epoch: 1285 [40960/90000 (45%)]	Loss: -18.8598	Cost: 14.11s
Train Epoch: 1285 [61440/90000 (68%)]	Loss: -18.5353	Cost: 10.08s
Train Epoch: 1285 [81920/90000 (91%)]	Loss: -18.6124	Cost: 13.30s
Train Epoch: 1285 	Average Loss: -18.2453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0080

Learning rate: 0.00012232501160109514
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1286 [0/90000 (0%)]	Loss: -13.1462	Cost: 32.20s
Train Epoch: 1286 [20480/90000 (23%)]	Loss: -18.6934	Cost: 11.71s
Train Epoch: 1286 [40960/90000 (45%)]	Loss: -19.0715	Cost: 18.79s
Train Epoch: 1286 [61440/90000 (68%)]	Loss: -18.6928	Cost: 9.76s
Train Epoch: 1286 [81920/90000 (91%)]	Loss: -18.6468	Cost: 13.44s
Train Epoch: 1286 	Average Loss: -18.3455
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9929

Learning rate: 0.00012222292262513965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1287 [0/90000 (0%)]	Loss: -12.3575	Cost: 35.80s
Train Epoch: 1287 [20480/90000 (23%)]	Loss: -18.8219	Cost: 10.10s
Train Epoch: 1287 [40960/90000 (45%)]	Loss: -18.9262	Cost: 13.60s
Train Epoch: 1287 [61440/90000 (68%)]	Loss: -18.8311	Cost: 11.22s
Train Epoch: 1287 [81920/90000 (91%)]	Loss: -18.7511	Cost: 10.28s
Train Epoch: 1287 	Average Loss: -18.3994
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0969

Learning rate: 0.0001221208092790247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1288 [0/90000 (0%)]	Loss: -13.3668	Cost: 29.48s
Train Epoch: 1288 [20480/90000 (23%)]	Loss: -18.8109	Cost: 10.89s
Train Epoch: 1288 [40960/90000 (45%)]	Loss: -18.9418	Cost: 10.86s
Train Epoch: 1288 [61440/90000 (68%)]	Loss: -18.7102	Cost: 9.74s
Train Epoch: 1288 [81920/90000 (91%)]	Loss: -18.5694	Cost: 12.02s
Train Epoch: 1288 	Average Loss: -18.3848
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0411

Learning rate: 0.00012201867167473014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1289 [0/90000 (0%)]	Loss: -11.7529	Cost: 33.45s
Train Epoch: 1289 [20480/90000 (23%)]	Loss: -18.5960	Cost: 9.86s
Train Epoch: 1289 [40960/90000 (45%)]	Loss: -18.0948	Cost: 12.24s
Train Epoch: 1289 [61440/90000 (68%)]	Loss: -18.0393	Cost: 9.73s
Train Epoch: 1289 [81920/90000 (91%)]	Loss: -18.1446	Cost: 12.81s
Train Epoch: 1289 	Average Loss: -17.8626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.7234

Learning rate: 0.00012191650992426236
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1290 [0/90000 (0%)]	Loss: -11.7056	Cost: 33.06s
Train Epoch: 1290 [20480/90000 (23%)]	Loss: -18.3904	Cost: 10.30s
Train Epoch: 1290 [40960/90000 (45%)]	Loss: -18.6684	Cost: 12.09s
Train Epoch: 1290 [61440/90000 (68%)]	Loss: -18.6146	Cost: 9.75s
Train Epoch: 1290 [81920/90000 (91%)]	Loss: -18.6842	Cost: 12.08s
Train Epoch: 1290 	Average Loss: -18.1167
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9769

Learning rate: 0.00012181432413965424
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1291 [0/90000 (0%)]	Loss: -12.7498	Cost: 29.40s
Train Epoch: 1291 [20480/90000 (23%)]	Loss: -18.8984	Cost: 9.84s
Train Epoch: 1291 [40960/90000 (45%)]	Loss: -18.9878	Cost: 12.60s
Train Epoch: 1291 [61440/90000 (68%)]	Loss: -18.9414	Cost: 10.04s
Train Epoch: 1291 [81920/90000 (91%)]	Loss: -18.9189	Cost: 12.17s
Train Epoch: 1291 	Average Loss: -18.4737
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1500

Learning rate: 0.00012171211443296502
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1292 [0/90000 (0%)]	Loss: -13.1392	Cost: 40.79s
Train Epoch: 1292 [20480/90000 (23%)]	Loss: -19.0251	Cost: 9.80s
Train Epoch: 1292 [40960/90000 (45%)]	Loss: -19.1889	Cost: 10.69s
Train Epoch: 1292 [61440/90000 (68%)]	Loss: -18.7602	Cost: 9.84s
Train Epoch: 1292 [81920/90000 (91%)]	Loss: -18.9327	Cost: 11.64s
Train Epoch: 1292 	Average Loss: -18.5709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2064

Learning rate: 0.0001216098809162802
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1293 [0/90000 (0%)]	Loss: -12.4820	Cost: 32.31s
Train Epoch: 1293 [20480/90000 (23%)]	Loss: -19.0714	Cost: 10.86s
Train Epoch: 1293 [40960/90000 (45%)]	Loss: -19.0824	Cost: 10.77s
Train Epoch: 1293 [61440/90000 (68%)]	Loss: -18.7784	Cost: 9.69s
Train Epoch: 1293 [81920/90000 (91%)]	Loss: -18.7308	Cost: 9.90s
Train Epoch: 1293 	Average Loss: -18.5859
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0518

Learning rate: 0.0001215076237017113
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1294 [0/90000 (0%)]	Loss: -12.0167	Cost: 32.85s
Train Epoch: 1294 [20480/90000 (23%)]	Loss: -19.0138	Cost: 9.64s
Train Epoch: 1294 [40960/90000 (45%)]	Loss: -19.4176	Cost: 10.53s
Train Epoch: 1294 [61440/90000 (68%)]	Loss: -18.8436	Cost: 9.65s
Train Epoch: 1294 [81920/90000 (91%)]	Loss: -18.7658	Cost: 11.54s
Train Epoch: 1294 	Average Loss: -18.5596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1425

Learning rate: 0.00012140534290139597
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1295 [0/90000 (0%)]	Loss: -12.4933	Cost: 35.94s
Train Epoch: 1295 [20480/90000 (23%)]	Loss: -18.9130	Cost: 9.82s
Train Epoch: 1295 [40960/90000 (45%)]	Loss: -18.9741	Cost: 11.25s
Train Epoch: 1295 [61440/90000 (68%)]	Loss: -18.8043	Cost: 9.64s
Train Epoch: 1295 [81920/90000 (91%)]	Loss: -18.7843	Cost: 12.04s
Train Epoch: 1295 	Average Loss: -18.4432
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0185

Learning rate: 0.00012130303862749764
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1296 [0/90000 (0%)]	Loss: -12.3181	Cost: 31.43s
Train Epoch: 1296 [20480/90000 (23%)]	Loss: -19.0544	Cost: 9.89s
Train Epoch: 1296 [40960/90000 (45%)]	Loss: -19.4426	Cost: 11.57s
Train Epoch: 1296 [61440/90000 (68%)]	Loss: -18.8323	Cost: 9.73s
Train Epoch: 1296 [81920/90000 (91%)]	Loss: -18.6982	Cost: 12.08s
Train Epoch: 1296 	Average Loss: -18.5390
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1027

Learning rate: 0.00012120071099220545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1297 [0/90000 (0%)]	Loss: -12.8912	Cost: 37.63s
Train Epoch: 1297 [20480/90000 (23%)]	Loss: -18.7110	Cost: 9.63s
Train Epoch: 1297 [40960/90000 (45%)]	Loss: -19.0645	Cost: 10.18s
Train Epoch: 1297 [61440/90000 (68%)]	Loss: -18.7017	Cost: 9.61s
Train Epoch: 1297 [81920/90000 (91%)]	Loss: -18.6834	Cost: 10.81s
Train Epoch: 1297 	Average Loss: -18.3326
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9224

Learning rate: 0.0001210983601077342
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1298 [0/90000 (0%)]	Loss: -12.3954	Cost: 37.00s
Train Epoch: 1298 [20480/90000 (23%)]	Loss: -18.6222	Cost: 10.31s
Train Epoch: 1298 [40960/90000 (45%)]	Loss: -19.2293	Cost: 10.97s
Train Epoch: 1298 [61440/90000 (68%)]	Loss: -18.6588	Cost: 9.45s
Train Epoch: 1298 [81920/90000 (91%)]	Loss: -18.6202	Cost: 11.66s
Train Epoch: 1298 	Average Loss: -18.3610
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0987

Learning rate: 0.00012099598608632421
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1299 [0/90000 (0%)]	Loss: -12.3238	Cost: 42.75s
Train Epoch: 1299 [20480/90000 (23%)]	Loss: -18.9951	Cost: 9.74s
Train Epoch: 1299 [40960/90000 (45%)]	Loss: -19.3287	Cost: 9.81s
Train Epoch: 1299 [61440/90000 (68%)]	Loss: -19.0812	Cost: 10.13s
Train Epoch: 1299 [81920/90000 (91%)]	Loss: -18.7910	Cost: 10.70s
Train Epoch: 1299 	Average Loss: -18.5819
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1657

Learning rate: 0.00012089358904024113
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1300 [0/90000 (0%)]	Loss: -12.8929	Cost: 37.52s
Train Epoch: 1300 [20480/90000 (23%)]	Loss: -19.0877	Cost: 9.83s
Train Epoch: 1300 [40960/90000 (45%)]	Loss: -19.2984	Cost: 11.12s
Train Epoch: 1300 [61440/90000 (68%)]	Loss: -18.8188	Cost: 9.62s
Train Epoch: 1300 [81920/90000 (91%)]	Loss: -18.7609	Cost: 9.41s
Train Epoch: 1300 	Average Loss: -18.4948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9917

Saving model as model.pt_e1300 & waveforms_supplementary.hdf5_e1300
Learning rate: 0.0001207911690817759
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1301 [0/90000 (0%)]	Loss: -13.0084	Cost: 33.69s
Train Epoch: 1301 [20480/90000 (23%)]	Loss: -18.9716	Cost: 10.02s
Train Epoch: 1301 [40960/90000 (45%)]	Loss: -19.2530	Cost: 11.55s
Train Epoch: 1301 [61440/90000 (68%)]	Loss: -18.9016	Cost: 9.78s
Train Epoch: 1301 [81920/90000 (91%)]	Loss: -18.8676	Cost: 12.20s
Train Epoch: 1301 	Average Loss: -18.5554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2197

Learning rate: 0.00012068872632324453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1302 [0/90000 (0%)]	Loss: -13.4163	Cost: 40.83s
Train Epoch: 1302 [20480/90000 (23%)]	Loss: -18.9861	Cost: 9.66s
Train Epoch: 1302 [40960/90000 (45%)]	Loss: -19.2960	Cost: 9.95s
Train Epoch: 1302 [61440/90000 (68%)]	Loss: -19.1553	Cost: 9.59s
Train Epoch: 1302 [81920/90000 (91%)]	Loss: -18.9305	Cost: 9.62s
Train Epoch: 1302 	Average Loss: -18.6297
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4865

Learning rate: 0.0001205862608769881
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1303 [0/90000 (0%)]	Loss: -11.9734	Cost: 36.03s
Train Epoch: 1303 [20480/90000 (23%)]	Loss: -18.8791	Cost: 10.86s
Train Epoch: 1303 [40960/90000 (45%)]	Loss: -19.4046	Cost: 11.38s
Train Epoch: 1303 [61440/90000 (68%)]	Loss: -18.9705	Cost: 9.67s
Train Epoch: 1303 [81920/90000 (91%)]	Loss: -18.8913	Cost: 11.26s
Train Epoch: 1303 	Average Loss: -18.5136
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1743

Learning rate: 0.0001204837728553725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1304 [0/90000 (0%)]	Loss: -12.8730	Cost: 41.89s
Train Epoch: 1304 [20480/90000 (23%)]	Loss: -19.0424	Cost: 9.76s
Train Epoch: 1304 [40960/90000 (45%)]	Loss: -19.2287	Cost: 10.81s
Train Epoch: 1304 [61440/90000 (68%)]	Loss: -18.7889	Cost: 9.99s
Train Epoch: 1304 [81920/90000 (91%)]	Loss: -18.8144	Cost: 9.86s
Train Epoch: 1304 	Average Loss: -18.5281
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3363

Learning rate: 0.00012038126237078845
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1305 [0/90000 (0%)]	Loss: -12.4462	Cost: 39.10s
Train Epoch: 1305 [20480/90000 (23%)]	Loss: -19.0340	Cost: 10.71s
Train Epoch: 1305 [40960/90000 (45%)]	Loss: -19.3022	Cost: 11.18s
Train Epoch: 1305 [61440/90000 (68%)]	Loss: -18.8570	Cost: 9.57s
Train Epoch: 1305 [81920/90000 (91%)]	Loss: -19.0698	Cost: 9.34s
Train Epoch: 1305 	Average Loss: -18.6246
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4718

Learning rate: 0.0001202787295356512
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1306 [0/90000 (0%)]	Loss: -12.0459	Cost: 48.15s
Train Epoch: 1306 [20480/90000 (23%)]	Loss: -19.2363	Cost: 10.23s
Train Epoch: 1306 [40960/90000 (45%)]	Loss: -19.2951	Cost: 13.50s
Train Epoch: 1306 [61440/90000 (68%)]	Loss: -18.9935	Cost: 10.05s
Train Epoch: 1306 [81920/90000 (91%)]	Loss: -19.2241	Cost: 10.81s
Train Epoch: 1306 	Average Loss: -18.7019
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4164

Learning rate: 0.00012017617446240063
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1307 [0/90000 (0%)]	Loss: -12.5701	Cost: 46.68s
Train Epoch: 1307 [20480/90000 (23%)]	Loss: -19.0073	Cost: 9.87s
Train Epoch: 1307 [40960/90000 (45%)]	Loss: -19.4056	Cost: 11.71s
Train Epoch: 1307 [61440/90000 (68%)]	Loss: -19.1097	Cost: 9.67s
Train Epoch: 1307 [81920/90000 (91%)]	Loss: -18.9764	Cost: 9.54s
Train Epoch: 1307 	Average Loss: -18.5892
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1789

Learning rate: 0.000120073597263501
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1308 [0/90000 (0%)]	Loss: -12.7986	Cost: 41.87s
Train Epoch: 1308 [20480/90000 (23%)]	Loss: -19.0188	Cost: 10.33s
Train Epoch: 1308 [40960/90000 (45%)]	Loss: -19.3397	Cost: 12.79s
Train Epoch: 1308 [61440/90000 (68%)]	Loss: -19.1136	Cost: 9.89s
Train Epoch: 1308 [81920/90000 (91%)]	Loss: -18.8823	Cost: 10.72s
Train Epoch: 1308 	Average Loss: -18.5977
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3253

Learning rate: 0.00011997099805144065
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1309 [0/90000 (0%)]	Loss: -12.2079	Cost: 41.35s
Train Epoch: 1309 [20480/90000 (23%)]	Loss: -18.9273	Cost: 11.47s
Train Epoch: 1309 [40960/90000 (45%)]	Loss: -19.3027	Cost: 11.45s
Train Epoch: 1309 [61440/90000 (68%)]	Loss: -19.0132	Cost: 9.64s
Train Epoch: 1309 [81920/90000 (91%)]	Loss: -18.8693	Cost: 11.76s
Train Epoch: 1309 	Average Loss: -18.5718
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1667

Learning rate: 0.00011986837693873234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1310 [0/90000 (0%)]	Loss: -12.4955	Cost: 31.31s
Train Epoch: 1310 [20480/90000 (23%)]	Loss: -19.2255	Cost: 11.50s
Train Epoch: 1310 [40960/90000 (45%)]	Loss: -19.3988	Cost: 13.28s
Train Epoch: 1310 [61440/90000 (68%)]	Loss: -19.2424	Cost: 10.99s
Train Epoch: 1310 [81920/90000 (91%)]	Loss: -19.1006	Cost: 10.46s
Train Epoch: 1310 	Average Loss: -18.7118
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2794

Learning rate: 0.00011976573403791258
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1311 [0/90000 (0%)]	Loss: -13.1036	Cost: 32.72s
Train Epoch: 1311 [20480/90000 (23%)]	Loss: -19.0535	Cost: 10.51s
Train Epoch: 1311 [40960/90000 (45%)]	Loss: -19.5900	Cost: 10.37s
Train Epoch: 1311 [61440/90000 (68%)]	Loss: -18.9092	Cost: 9.84s
Train Epoch: 1311 [81920/90000 (91%)]	Loss: -18.9963	Cost: 12.63s
Train Epoch: 1311 	Average Loss: -18.6625
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1375

Learning rate: 0.00011966306946154196
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1312 [0/90000 (0%)]	Loss: -12.6748	Cost: 28.93s
Train Epoch: 1312 [20480/90000 (23%)]	Loss: -19.0766	Cost: 9.80s
Train Epoch: 1312 [40960/90000 (45%)]	Loss: -19.3046	Cost: 11.96s
Train Epoch: 1312 [61440/90000 (68%)]	Loss: -18.9856	Cost: 10.11s
Train Epoch: 1312 [81920/90000 (91%)]	Loss: -18.9786	Cost: 11.47s
Train Epoch: 1312 	Average Loss: -18.6520
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2033

Learning rate: 0.0001195603833222048
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1313 [0/90000 (0%)]	Loss: -12.6564	Cost: 38.10s
Train Epoch: 1313 [20480/90000 (23%)]	Loss: -18.7823	Cost: 9.83s
Train Epoch: 1313 [40960/90000 (45%)]	Loss: -19.2626	Cost: 12.12s
Train Epoch: 1313 [61440/90000 (68%)]	Loss: -17.4221	Cost: 9.90s
Train Epoch: 1313 [81920/90000 (91%)]	Loss: -17.3902	Cost: 13.17s
Train Epoch: 1313 	Average Loss: -17.7811
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -11.8955

Learning rate: 0.00011945767573250897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1314 [0/90000 (0%)]	Loss: -11.7812	Cost: 29.03s
Train Epoch: 1314 [20480/90000 (23%)]	Loss: -17.7423	Cost: 11.12s
Train Epoch: 1314 [40960/90000 (45%)]	Loss: -18.2329	Cost: 11.23s
Train Epoch: 1314 [61440/90000 (68%)]	Loss: -18.3635	Cost: 10.02s
Train Epoch: 1314 [81920/90000 (91%)]	Loss: -18.5754	Cost: 11.20s
Train Epoch: 1314 	Average Loss: -17.6847
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9538

Learning rate: 0.00011935494680508598
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1315 [0/90000 (0%)]	Loss: -12.7104	Cost: 33.46s
Train Epoch: 1315 [20480/90000 (23%)]	Loss: -19.0940	Cost: 9.60s
Train Epoch: 1315 [40960/90000 (45%)]	Loss: -19.3458	Cost: 10.56s
Train Epoch: 1315 [61440/90000 (68%)]	Loss: -18.9572	Cost: 9.76s
Train Epoch: 1315 [81920/90000 (91%)]	Loss: -19.1106	Cost: 11.07s
Train Epoch: 1315 	Average Loss: -18.5444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4958

Learning rate: 0.00011925219665259073
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1316 [0/90000 (0%)]	Loss: -13.0805	Cost: 36.26s
Train Epoch: 1316 [20480/90000 (23%)]	Loss: -19.2006	Cost: 9.98s
Train Epoch: 1316 [40960/90000 (45%)]	Loss: -19.5354	Cost: 12.45s
Train Epoch: 1316 [61440/90000 (68%)]	Loss: -18.9539	Cost: 9.81s
Train Epoch: 1316 [81920/90000 (91%)]	Loss: -19.0933	Cost: 12.00s
Train Epoch: 1316 	Average Loss: -18.6818
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3330

Learning rate: 0.00011914942538770125
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1317 [0/90000 (0%)]	Loss: -11.9983	Cost: 29.42s
Train Epoch: 1317 [20480/90000 (23%)]	Loss: -19.0535	Cost: 9.95s
Train Epoch: 1317 [40960/90000 (45%)]	Loss: -19.2937	Cost: 11.57s
Train Epoch: 1317 [61440/90000 (68%)]	Loss: -19.0110	Cost: 10.01s
Train Epoch: 1317 [81920/90000 (91%)]	Loss: -18.9737	Cost: 12.17s
Train Epoch: 1317 	Average Loss: -18.6484
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1857

Learning rate: 0.00011904663312311894
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1318 [0/90000 (0%)]	Loss: -13.2603	Cost: 38.56s
Train Epoch: 1318 [20480/90000 (23%)]	Loss: -19.2669	Cost: 9.55s
Train Epoch: 1318 [40960/90000 (45%)]	Loss: -19.5538	Cost: 10.23s
Train Epoch: 1318 [61440/90000 (68%)]	Loss: -18.9941	Cost: 9.62s
Train Epoch: 1318 [81920/90000 (91%)]	Loss: -18.9638	Cost: 11.43s
Train Epoch: 1318 	Average Loss: -18.7423
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2914

Learning rate: 0.00011894381997156812
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1319 [0/90000 (0%)]	Loss: -12.7437	Cost: 35.37s
Train Epoch: 1319 [20480/90000 (23%)]	Loss: -19.2345	Cost: 9.87s
Train Epoch: 1319 [40960/90000 (45%)]	Loss: -19.3847	Cost: 11.86s
Train Epoch: 1319 [61440/90000 (68%)]	Loss: -18.9859	Cost: 9.69s
Train Epoch: 1319 [81920/90000 (91%)]	Loss: -19.1513	Cost: 12.12s
Train Epoch: 1319 	Average Loss: -18.8232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3997

Learning rate: 0.00011884098604579593
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1320 [0/90000 (0%)]	Loss: -13.7028	Cost: 30.44s
Train Epoch: 1320 [20480/90000 (23%)]	Loss: -19.2473	Cost: 9.89s
Train Epoch: 1320 [40960/90000 (45%)]	Loss: -19.5104	Cost: 11.58s
Train Epoch: 1320 [61440/90000 (68%)]	Loss: -19.0554	Cost: 10.31s
Train Epoch: 1320 [81920/90000 (91%)]	Loss: -18.8970	Cost: 11.74s
Train Epoch: 1320 	Average Loss: -18.8309
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1932

Learning rate: 0.00011873813145857245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1321 [0/90000 (0%)]	Loss: -12.8338	Cost: 42.41s
Train Epoch: 1321 [20480/90000 (23%)]	Loss: -19.2171	Cost: 9.60s
Train Epoch: 1321 [40960/90000 (45%)]	Loss: -19.1702	Cost: 9.78s
Train Epoch: 1321 [61440/90000 (68%)]	Loss: -18.9583	Cost: 9.71s
Train Epoch: 1321 [81920/90000 (91%)]	Loss: -18.8968	Cost: 11.10s
Train Epoch: 1321 	Average Loss: -18.5554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3248

Learning rate: 0.0001186352563226903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1322 [0/90000 (0%)]	Loss: -12.8722	Cost: 35.09s
Train Epoch: 1322 [20480/90000 (23%)]	Loss: -19.1386	Cost: 9.69s
Train Epoch: 1322 [40960/90000 (45%)]	Loss: -19.5076	Cost: 11.17s
Train Epoch: 1322 [61440/90000 (68%)]	Loss: -19.1217	Cost: 10.06s
Train Epoch: 1322 [81920/90000 (91%)]	Loss: -19.0847	Cost: 11.48s
Train Epoch: 1322 	Average Loss: -18.8314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4333

Learning rate: 0.0001185323607509647
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1323 [0/90000 (0%)]	Loss: -12.8704	Cost: 33.26s
Train Epoch: 1323 [20480/90000 (23%)]	Loss: -19.4415	Cost: 10.01s
Train Epoch: 1323 [40960/90000 (45%)]	Loss: -19.6513	Cost: 11.56s
Train Epoch: 1323 [61440/90000 (68%)]	Loss: -19.2081	Cost: 9.84s
Train Epoch: 1323 [81920/90000 (91%)]	Loss: -18.9914	Cost: 12.34s
Train Epoch: 1323 	Average Loss: -18.8490
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3359

Learning rate: 0.0001184294448562333
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1324 [0/90000 (0%)]	Loss: -13.4000	Cost: 39.43s
Train Epoch: 1324 [20480/90000 (23%)]	Loss: -19.3167	Cost: 9.80s
Train Epoch: 1324 [40960/90000 (45%)]	Loss: -19.4421	Cost: 10.19s
Train Epoch: 1324 [61440/90000 (68%)]	Loss: -19.0854	Cost: 9.65s
Train Epoch: 1324 [81920/90000 (91%)]	Loss: -19.1838	Cost: 10.21s
Train Epoch: 1324 	Average Loss: -18.8363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4673

Learning rate: 0.00011832650875135595
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1325 [0/90000 (0%)]	Loss: -11.9693	Cost: 38.70s
Train Epoch: 1325 [20480/90000 (23%)]	Loss: -19.3992	Cost: 10.65s
Train Epoch: 1325 [40960/90000 (45%)]	Loss: -19.5859	Cost: 11.15s
Train Epoch: 1325 [61440/90000 (68%)]	Loss: -19.1689	Cost: 9.62s
Train Epoch: 1325 [81920/90000 (91%)]	Loss: -19.1039	Cost: 9.33s
Train Epoch: 1325 	Average Loss: -18.8574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4598

Learning rate: 0.0001182235525492147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1326 [0/90000 (0%)]	Loss: -12.5450	Cost: 40.28s
Train Epoch: 1326 [20480/90000 (23%)]	Loss: -19.2140	Cost: 9.99s
Train Epoch: 1326 [40960/90000 (45%)]	Loss: -19.5834	Cost: 12.46s
Train Epoch: 1326 [61440/90000 (68%)]	Loss: -19.1894	Cost: 9.62s
Train Epoch: 1326 [81920/90000 (91%)]	Loss: -18.6103	Cost: 11.37s
Train Epoch: 1326 	Average Loss: -18.7350
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.1970

Learning rate: 0.00011812057636271367
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1327 [0/90000 (0%)]	Loss: -12.4620	Cost: 36.12s
Train Epoch: 1327 [20480/90000 (23%)]	Loss: -19.3029	Cost: 12.04s
Train Epoch: 1327 [40960/90000 (45%)]	Loss: -19.7550	Cost: 11.54s
Train Epoch: 1327 [61440/90000 (68%)]	Loss: -19.3730	Cost: 9.65s
Train Epoch: 1327 [81920/90000 (91%)]	Loss: -19.1547	Cost: 10.57s
Train Epoch: 1327 	Average Loss: -18.8940
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6069

Learning rate: 0.00011801758030477891
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1328 [0/90000 (0%)]	Loss: -13.2988	Cost: 34.01s
Train Epoch: 1328 [20480/90000 (23%)]	Loss: -19.3826	Cost: 11.62s
Train Epoch: 1328 [40960/90000 (45%)]	Loss: -19.5752	Cost: 11.09s
Train Epoch: 1328 [61440/90000 (68%)]	Loss: -19.1769	Cost: 9.98s
Train Epoch: 1328 [81920/90000 (91%)]	Loss: -19.2630	Cost: 13.18s
Train Epoch: 1328 	Average Loss: -18.9218
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4959

Learning rate: 0.00011791456448835815
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1329 [0/90000 (0%)]	Loss: -12.8510	Cost: 33.33s
Train Epoch: 1329 [20480/90000 (23%)]	Loss: -19.3210	Cost: 12.65s
Train Epoch: 1329 [40960/90000 (45%)]	Loss: -19.5977	Cost: 15.77s
Train Epoch: 1329 [61440/90000 (68%)]	Loss: -19.2050	Cost: 10.39s
Train Epoch: 1329 [81920/90000 (91%)]	Loss: -18.9878	Cost: 12.60s
Train Epoch: 1329 	Average Loss: -18.8257
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3667

Learning rate: 0.00011781152902642094
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1330 [0/90000 (0%)]	Loss: -12.4420	Cost: 33.91s
Train Epoch: 1330 [20480/90000 (23%)]	Loss: -19.2316	Cost: 11.41s
Train Epoch: 1330 [40960/90000 (45%)]	Loss: -19.5396	Cost: 13.34s
Train Epoch: 1330 [61440/90000 (68%)]	Loss: -19.2469	Cost: 9.85s
Train Epoch: 1330 [81920/90000 (91%)]	Loss: -19.1466	Cost: 14.31s
Train Epoch: 1330 	Average Loss: -18.8210
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5887

Learning rate: 0.00011770847403195828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1331 [0/90000 (0%)]	Loss: -13.4536	Cost: 30.91s
Train Epoch: 1331 [20480/90000 (23%)]	Loss: -19.2440	Cost: 10.09s
Train Epoch: 1331 [40960/90000 (45%)]	Loss: -19.6116	Cost: 14.33s
Train Epoch: 1331 [61440/90000 (68%)]	Loss: -19.2781	Cost: 11.00s
Train Epoch: 1331 [81920/90000 (91%)]	Loss: -19.3001	Cost: 10.61s
Train Epoch: 1331 	Average Loss: -18.9573
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6429

Learning rate: 0.00011760539961798255
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1332 [0/90000 (0%)]	Loss: -13.5682	Cost: 36.80s
Train Epoch: 1332 [20480/90000 (23%)]	Loss: -19.4455	Cost: 9.68s
Train Epoch: 1332 [40960/90000 (45%)]	Loss: -19.7219	Cost: 12.00s
Train Epoch: 1332 [61440/90000 (68%)]	Loss: -19.3046	Cost: 10.37s
Train Epoch: 1332 [81920/90000 (91%)]	Loss: -19.1993	Cost: 13.46s
Train Epoch: 1332 	Average Loss: -18.9464
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4621

Learning rate: 0.00011750230589752755
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1333 [0/90000 (0%)]	Loss: -13.4004	Cost: 30.39s
Train Epoch: 1333 [20480/90000 (23%)]	Loss: -19.2156	Cost: 11.45s
Train Epoch: 1333 [40960/90000 (45%)]	Loss: -19.6304	Cost: 11.33s
Train Epoch: 1333 [61440/90000 (68%)]	Loss: -19.3422	Cost: 9.58s
Train Epoch: 1333 [81920/90000 (91%)]	Loss: -19.2205	Cost: 12.32s
Train Epoch: 1333 	Average Loss: -18.9413
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6893

Learning rate: 0.00011739919298364815
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1334 [0/90000 (0%)]	Loss: -13.3313	Cost: 30.40s
Train Epoch: 1334 [20480/90000 (23%)]	Loss: -19.3748	Cost: 9.70s
Train Epoch: 1334 [40960/90000 (45%)]	Loss: -19.4532	Cost: 11.28s
Train Epoch: 1334 [61440/90000 (68%)]	Loss: -19.1146	Cost: 9.88s
Train Epoch: 1334 [81920/90000 (91%)]	Loss: -19.2274	Cost: 11.29s
Train Epoch: 1334 	Average Loss: -18.8620
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5297

Learning rate: 0.00011729606098942032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1335 [0/90000 (0%)]	Loss: -13.6758	Cost: 33.41s
Train Epoch: 1335 [20480/90000 (23%)]	Loss: -19.1312	Cost: 10.10s
Train Epoch: 1335 [40960/90000 (45%)]	Loss: -19.5708	Cost: 12.20s
Train Epoch: 1335 [61440/90000 (68%)]	Loss: -19.2019	Cost: 9.56s
Train Epoch: 1335 [81920/90000 (91%)]	Loss: -19.1787	Cost: 12.12s
Train Epoch: 1335 	Average Loss: -18.8779
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4515

Learning rate: 0.00011719291002794089
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1336 [0/90000 (0%)]	Loss: -12.5220	Cost: 29.51s
Train Epoch: 1336 [20480/90000 (23%)]	Loss: -19.2739	Cost: 9.77s
Train Epoch: 1336 [40960/90000 (45%)]	Loss: -19.5162	Cost: 12.86s
Train Epoch: 1336 [61440/90000 (68%)]	Loss: -19.0427	Cost: 10.04s
Train Epoch: 1336 [81920/90000 (91%)]	Loss: -19.0186	Cost: 12.31s
Train Epoch: 1336 	Average Loss: -18.7999
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3991

Learning rate: 0.00011708974021232762
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1337 [0/90000 (0%)]	Loss: -13.3563	Cost: 37.35s
Train Epoch: 1337 [20480/90000 (23%)]	Loss: -19.0819	Cost: 9.65s
Train Epoch: 1337 [40960/90000 (45%)]	Loss: -19.4591	Cost: 10.69s
Train Epoch: 1337 [61440/90000 (68%)]	Loss: -19.1532	Cost: 9.67s
Train Epoch: 1337 [81920/90000 (91%)]	Loss: -18.7977	Cost: 12.53s
Train Epoch: 1337 	Average Loss: -18.6833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.0230

Learning rate: 0.0001169865516557188
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1338 [0/90000 (0%)]	Loss: -12.2684	Cost: 30.88s
Train Epoch: 1338 [20480/90000 (23%)]	Loss: -18.7064	Cost: 10.25s
Train Epoch: 1338 [40960/90000 (45%)]	Loss: -19.0448	Cost: 13.26s
Train Epoch: 1338 [61440/90000 (68%)]	Loss: -18.9121	Cost: 9.73s
Train Epoch: 1338 [81920/90000 (91%)]	Loss: -19.1039	Cost: 10.55s
Train Epoch: 1338 	Average Loss: -18.4782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3953

Learning rate: 0.00011688334447127331
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1339 [0/90000 (0%)]	Loss: -13.4978	Cost: 32.28s
Train Epoch: 1339 [20480/90000 (23%)]	Loss: -19.0695	Cost: 9.64s
Train Epoch: 1339 [40960/90000 (45%)]	Loss: -19.5439	Cost: 10.55s
Train Epoch: 1339 [61440/90000 (68%)]	Loss: -19.1937	Cost: 9.83s
Train Epoch: 1339 [81920/90000 (91%)]	Loss: -19.3491	Cost: 12.16s
Train Epoch: 1339 	Average Loss: -18.8612
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6050

Learning rate: 0.00011678011877217058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1340 [0/90000 (0%)]	Loss: -12.6120	Cost: 37.02s
Train Epoch: 1340 [20480/90000 (23%)]	Loss: -19.2485	Cost: 9.94s
Train Epoch: 1340 [40960/90000 (45%)]	Loss: -19.5422	Cost: 11.10s
Train Epoch: 1340 [61440/90000 (68%)]	Loss: -19.3534	Cost: 9.50s
Train Epoch: 1340 [81920/90000 (91%)]	Loss: -19.2450	Cost: 10.37s
Train Epoch: 1340 	Average Loss: -18.9010
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3825

Learning rate: 0.00011667687467161017
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1341 [0/90000 (0%)]	Loss: -13.3157	Cost: 36.26s
Train Epoch: 1341 [20480/90000 (23%)]	Loss: -19.2582	Cost: 9.83s
Train Epoch: 1341 [40960/90000 (45%)]	Loss: -19.4121	Cost: 11.00s
Train Epoch: 1341 [61440/90000 (68%)]	Loss: -19.3916	Cost: 10.00s
Train Epoch: 1341 [81920/90000 (91%)]	Loss: -19.2761	Cost: 11.21s
Train Epoch: 1341 	Average Loss: -18.9088
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5547

Learning rate: 0.00011657361228281189
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1342 [0/90000 (0%)]	Loss: -12.8270	Cost: 42.16s
Train Epoch: 1342 [20480/90000 (23%)]	Loss: -19.2913	Cost: 10.05s
Train Epoch: 1342 [40960/90000 (45%)]	Loss: -19.1782	Cost: 10.56s
Train Epoch: 1342 [61440/90000 (68%)]	Loss: -19.0103	Cost: 9.49s
Train Epoch: 1342 [81920/90000 (91%)]	Loss: -19.0794	Cost: 9.92s
Train Epoch: 1342 	Average Loss: -18.7409
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3607

Learning rate: 0.00011647033171901569
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1343 [0/90000 (0%)]	Loss: -12.7634	Cost: 40.87s
Train Epoch: 1343 [20480/90000 (23%)]	Loss: -19.0773	Cost: 10.15s
Train Epoch: 1343 [40960/90000 (45%)]	Loss: -19.3436	Cost: 11.18s
Train Epoch: 1343 [61440/90000 (68%)]	Loss: -19.3840	Cost: 9.76s
Train Epoch: 1343 [81920/90000 (91%)]	Loss: -19.1788	Cost: 11.93s
Train Epoch: 1343 	Average Loss: -18.8340
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4830

Learning rate: 0.00011636703309348126
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1344 [0/90000 (0%)]	Loss: -14.1104	Cost: 47.00s
Train Epoch: 1344 [20480/90000 (23%)]	Loss: -19.2942	Cost: 9.71s
Train Epoch: 1344 [40960/90000 (45%)]	Loss: -19.4156	Cost: 10.09s
Train Epoch: 1344 [61440/90000 (68%)]	Loss: -19.0680	Cost: 9.50s
Train Epoch: 1344 [81920/90000 (91%)]	Loss: -19.0801	Cost: 9.57s
Train Epoch: 1344 	Average Loss: -18.8031
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2983

Learning rate: 0.00011626371651948827
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1345 [0/90000 (0%)]	Loss: -12.8231	Cost: 34.08s
Train Epoch: 1345 [20480/90000 (23%)]	Loss: -19.3531	Cost: 10.24s
Train Epoch: 1345 [40960/90000 (45%)]	Loss: -19.6181	Cost: 11.75s
Train Epoch: 1345 [61440/90000 (68%)]	Loss: -19.3821	Cost: 9.61s
Train Epoch: 1345 [81920/90000 (91%)]	Loss: -19.2970	Cost: 12.41s
Train Epoch: 1345 	Average Loss: -18.8939
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5221

Learning rate: 0.00011616038211033605
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1346 [0/90000 (0%)]	Loss: -12.1027	Cost: 38.48s
Train Epoch: 1346 [20480/90000 (23%)]	Loss: -18.9830	Cost: 9.74s
Train Epoch: 1346 [40960/90000 (45%)]	Loss: -19.3148	Cost: 9.84s
Train Epoch: 1346 [61440/90000 (68%)]	Loss: -19.1651	Cost: 9.59s
Train Epoch: 1346 [81920/90000 (91%)]	Loss: -18.9294	Cost: 10.04s
Train Epoch: 1346 	Average Loss: -18.6778
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3002

Learning rate: 0.00011605702997934337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1347 [0/90000 (0%)]	Loss: -12.7051	Cost: 36.12s
Train Epoch: 1347 [20480/90000 (23%)]	Loss: -19.1996	Cost: 10.83s
Train Epoch: 1347 [40960/90000 (45%)]	Loss: -19.5549	Cost: 10.66s
Train Epoch: 1347 [61440/90000 (68%)]	Loss: -19.3543	Cost: 9.72s
Train Epoch: 1347 [81920/90000 (91%)]	Loss: -19.0916	Cost: 9.60s
Train Epoch: 1347 	Average Loss: -18.7720
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3559

Learning rate: 0.00011595366023984853
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1348 [0/90000 (0%)]	Loss: -12.7811	Cost: 43.81s
Train Epoch: 1348 [20480/90000 (23%)]	Loss: -19.1741	Cost: 9.76s
Train Epoch: 1348 [40960/90000 (45%)]	Loss: -19.4818	Cost: 11.76s
Train Epoch: 1348 [61440/90000 (68%)]	Loss: -18.9188	Cost: 9.75s
Train Epoch: 1348 [81920/90000 (91%)]	Loss: -18.7109	Cost: 9.44s
Train Epoch: 1348 	Average Loss: -18.6012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2313

Learning rate: 0.00011585027300520922
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1349 [0/90000 (0%)]	Loss: -12.6295	Cost: 38.92s
Train Epoch: 1349 [20480/90000 (23%)]	Loss: -19.0832	Cost: 12.06s
Train Epoch: 1349 [40960/90000 (45%)]	Loss: -19.1317	Cost: 10.44s
Train Epoch: 1349 [61440/90000 (68%)]	Loss: -18.8763	Cost: 9.61s
Train Epoch: 1349 [81920/90000 (91%)]	Loss: -18.7130	Cost: 9.68s
Train Epoch: 1349 	Average Loss: -18.4912
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -12.9609

Learning rate: 0.00011574686838880207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1350 [0/90000 (0%)]	Loss: -12.4226	Cost: 41.59s
Train Epoch: 1350 [20480/90000 (23%)]	Loss: -18.5865	Cost: 9.82s
Train Epoch: 1350 [40960/90000 (45%)]	Loss: -19.1033	Cost: 13.10s
Train Epoch: 1350 [61440/90000 (68%)]	Loss: -18.7928	Cost: 10.31s
Train Epoch: 1350 [81920/90000 (91%)]	Loss: -19.0038	Cost: 13.41s
Train Epoch: 1350 	Average Loss: -18.3999
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.2517

Saving model as model.pt_e1350 & waveforms_supplementary.hdf5_e1350
Learning rate: 0.000115643446504023
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1351 [0/90000 (0%)]	Loss: -11.8197	Cost: 43.57s
Train Epoch: 1351 [20480/90000 (23%)]	Loss: -19.2720	Cost: 10.03s
Train Epoch: 1351 [40960/90000 (45%)]	Loss: -19.5687	Cost: 13.38s
Train Epoch: 1351 [61440/90000 (68%)]	Loss: -19.3379	Cost: 9.66s
Train Epoch: 1351 [81920/90000 (91%)]	Loss: -19.3921	Cost: 12.29s
Train Epoch: 1351 	Average Loss: -18.8442
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5749

Learning rate: 0.00011554000746428682
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1352 [0/90000 (0%)]	Loss: -13.5199	Cost: 36.56s
Train Epoch: 1352 [20480/90000 (23%)]	Loss: -19.6571	Cost: 12.33s
Train Epoch: 1352 [40960/90000 (45%)]	Loss: -19.8224	Cost: 12.70s
Train Epoch: 1352 [61440/90000 (68%)]	Loss: -19.4719	Cost: 10.01s
Train Epoch: 1352 [81920/90000 (91%)]	Loss: -19.4840	Cost: 10.95s
Train Epoch: 1352 	Average Loss: -19.1249
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6044

Learning rate: 0.00011543655138302703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1353 [0/90000 (0%)]	Loss: -13.2236	Cost: 33.40s
Train Epoch: 1353 [20480/90000 (23%)]	Loss: -19.6890	Cost: 11.42s
Train Epoch: 1353 [40960/90000 (45%)]	Loss: -19.3724	Cost: 11.31s
Train Epoch: 1353 [61440/90000 (68%)]	Loss: -18.9038	Cost: 9.81s
Train Epoch: 1353 [81920/90000 (91%)]	Loss: -18.8031	Cost: 12.72s
Train Epoch: 1353 	Average Loss: -18.7755
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.3272

Learning rate: 0.000115333078373696
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1354 [0/90000 (0%)]	Loss: -12.5009	Cost: 30.23s
Train Epoch: 1354 [20480/90000 (23%)]	Loss: -19.3054	Cost: 10.84s
Train Epoch: 1354 [40960/90000 (45%)]	Loss: -19.6225	Cost: 13.66s
Train Epoch: 1354 [61440/90000 (68%)]	Loss: -19.2501	Cost: 11.53s
Train Epoch: 1354 [81920/90000 (91%)]	Loss: -19.3877	Cost: 14.88s
Train Epoch: 1354 	Average Loss: -18.9079
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8012

Learning rate: 0.00011522958854976448
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1355 [0/90000 (0%)]	Loss: -13.0175	Cost: 34.99s
Train Epoch: 1355 [20480/90000 (23%)]	Loss: -19.6353	Cost: 9.76s
Train Epoch: 1355 [40960/90000 (45%)]	Loss: -19.8799	Cost: 11.57s
Train Epoch: 1355 [61440/90000 (68%)]	Loss: -19.6582	Cost: 11.24s
Train Epoch: 1355 [81920/90000 (91%)]	Loss: -19.4407	Cost: 10.44s
Train Epoch: 1355 	Average Loss: -19.1433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7897

Learning rate: 0.00011512608202472184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1356 [0/90000 (0%)]	Loss: -14.1775	Cost: 33.51s
Train Epoch: 1356 [20480/90000 (23%)]	Loss: -19.6099	Cost: 10.59s
Train Epoch: 1356 [40960/90000 (45%)]	Loss: -19.8765	Cost: 10.51s
Train Epoch: 1356 [61440/90000 (68%)]	Loss: -19.5586	Cost: 9.60s
Train Epoch: 1356 [81920/90000 (91%)]	Loss: -19.4639	Cost: 11.41s
Train Epoch: 1356 	Average Loss: -19.2262
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6450

Learning rate: 0.00011502255891207565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1357 [0/90000 (0%)]	Loss: -13.7382	Cost: 30.22s
Train Epoch: 1357 [20480/90000 (23%)]	Loss: -19.6698	Cost: 9.79s
Train Epoch: 1357 [40960/90000 (45%)]	Loss: -19.5394	Cost: 11.62s
Train Epoch: 1357 [61440/90000 (68%)]	Loss: -19.4746	Cost: 9.98s
Train Epoch: 1357 [81920/90000 (91%)]	Loss: -19.4432	Cost: 12.20s
Train Epoch: 1357 	Average Loss: -19.0701
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7139

Learning rate: 0.00011491901932535162
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1358 [0/90000 (0%)]	Loss: -13.5516	Cost: 42.10s
Train Epoch: 1358 [20480/90000 (23%)]	Loss: -19.6528	Cost: 9.66s
Train Epoch: 1358 [40960/90000 (45%)]	Loss: -19.8451	Cost: 10.85s
Train Epoch: 1358 [61440/90000 (68%)]	Loss: -19.6440	Cost: 9.63s
Train Epoch: 1358 [81920/90000 (91%)]	Loss: -19.4133	Cost: 12.42s
Train Epoch: 1358 	Average Loss: -19.1838
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6887

Learning rate: 0.0001148154633780937
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1359 [0/90000 (0%)]	Loss: -13.7608	Cost: 31.55s
Train Epoch: 1359 [20480/90000 (23%)]	Loss: -19.6046	Cost: 9.89s
Train Epoch: 1359 [40960/90000 (45%)]	Loss: -19.8762	Cost: 12.69s
Train Epoch: 1359 [61440/90000 (68%)]	Loss: -19.6143	Cost: 10.01s
Train Epoch: 1359 [81920/90000 (91%)]	Loss: -19.5975	Cost: 10.48s
Train Epoch: 1359 	Average Loss: -19.2764
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8252

Learning rate: 0.00011471189118386366
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1360 [0/90000 (0%)]	Loss: -13.1620	Cost: 34.23s
Train Epoch: 1360 [20480/90000 (23%)]	Loss: -19.7185	Cost: 9.69s
Train Epoch: 1360 [40960/90000 (45%)]	Loss: -20.1341	Cost: 10.10s
Train Epoch: 1360 [61440/90000 (68%)]	Loss: -19.6388	Cost: 9.90s
Train Epoch: 1360 [81920/90000 (91%)]	Loss: -19.5340	Cost: 11.05s
Train Epoch: 1360 	Average Loss: -19.3402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7845

Learning rate: 0.00011460830285624107
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1361 [0/90000 (0%)]	Loss: -13.0027	Cost: 36.97s
Train Epoch: 1361 [20480/90000 (23%)]	Loss: -19.7706	Cost: 9.88s
Train Epoch: 1361 [40960/90000 (45%)]	Loss: -19.5400	Cost: 11.44s
Train Epoch: 1361 [61440/90000 (68%)]	Loss: -19.4023	Cost: 9.59s
Train Epoch: 1361 [81920/90000 (91%)]	Loss: -19.3696	Cost: 10.14s
Train Epoch: 1361 	Average Loss: -19.0242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6601

Learning rate: 0.00011450469850882324
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1362 [0/90000 (0%)]	Loss: -13.6827	Cost: 43.88s
Train Epoch: 1362 [20480/90000 (23%)]	Loss: -19.5362	Cost: 9.66s
Train Epoch: 1362 [40960/90000 (45%)]	Loss: -19.8610	Cost: 9.99s
Train Epoch: 1362 [61440/90000 (68%)]	Loss: -19.4865	Cost: 9.98s
Train Epoch: 1362 [81920/90000 (91%)]	Loss: -19.4604	Cost: 11.19s
Train Epoch: 1362 	Average Loss: -19.1162
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6219

Learning rate: 0.00011440107825522513
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1363 [0/90000 (0%)]	Loss: -12.2480	Cost: 49.66s
Train Epoch: 1363 [20480/90000 (23%)]	Loss: -19.6217	Cost: 9.59s
Train Epoch: 1363 [40960/90000 (45%)]	Loss: -20.0288	Cost: 9.92s
Train Epoch: 1363 [61440/90000 (68%)]	Loss: -19.6376	Cost: 9.60s
Train Epoch: 1363 [81920/90000 (91%)]	Loss: -19.7542	Cost: 11.65s
Train Epoch: 1363 	Average Loss: -19.2046
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9536

Learning rate: 0.00011429744220907892
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1364 [0/90000 (0%)]	Loss: -13.1224	Cost: 32.24s
Train Epoch: 1364 [20480/90000 (23%)]	Loss: -19.8380	Cost: 10.23s
Train Epoch: 1364 [40960/90000 (45%)]	Loss: -20.1821	Cost: 11.59s
Train Epoch: 1364 [61440/90000 (68%)]	Loss: -19.7756	Cost: 10.04s
Train Epoch: 1364 [81920/90000 (91%)]	Loss: -19.5831	Cost: 11.51s
Train Epoch: 1364 	Average Loss: -19.3464
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7767

Learning rate: 0.00011419379048403436
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1365 [0/90000 (0%)]	Loss: -13.3372	Cost: 34.66s
Train Epoch: 1365 [20480/90000 (23%)]	Loss: -19.7423	Cost: 9.53s
Train Epoch: 1365 [40960/90000 (45%)]	Loss: -20.3297	Cost: 10.34s
Train Epoch: 1365 [61440/90000 (68%)]	Loss: -19.6263	Cost: 9.45s
Train Epoch: 1365 [81920/90000 (91%)]	Loss: -19.4548	Cost: 11.75s
Train Epoch: 1365 	Average Loss: -19.2174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.6414

Learning rate: 0.00011409012319375817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1366 [0/90000 (0%)]	Loss: -12.7640	Cost: 39.90s
Train Epoch: 1366 [20480/90000 (23%)]	Loss: -19.3683	Cost: 9.60s
Train Epoch: 1366 [40960/90000 (45%)]	Loss: -19.7649	Cost: 11.14s
Train Epoch: 1366 [61440/90000 (68%)]	Loss: -19.5701	Cost: 9.65s
Train Epoch: 1366 [81920/90000 (91%)]	Loss: -19.5388	Cost: 9.52s
Train Epoch: 1366 	Average Loss: -19.1325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8797

Learning rate: 0.00011398644045193429
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1367 [0/90000 (0%)]	Loss: -14.0807	Cost: 40.02s
Train Epoch: 1367 [20480/90000 (23%)]	Loss: -19.8734	Cost: 9.68s
Train Epoch: 1367 [40960/90000 (45%)]	Loss: -20.0657	Cost: 11.60s
Train Epoch: 1367 [61440/90000 (68%)]	Loss: -19.7258	Cost: 9.68s
Train Epoch: 1367 [81920/90000 (91%)]	Loss: -19.8013	Cost: 11.48s
Train Epoch: 1367 	Average Loss: -19.3703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0011

Learning rate: 0.00011388274237226362
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1368 [0/90000 (0%)]	Loss: -13.9550	Cost: 42.54s
Train Epoch: 1368 [20480/90000 (23%)]	Loss: -19.8316	Cost: 9.77s
Train Epoch: 1368 [40960/90000 (45%)]	Loss: -19.9810	Cost: 11.23s
Train Epoch: 1368 [61440/90000 (68%)]	Loss: -19.6275	Cost: 9.57s
Train Epoch: 1368 [81920/90000 (91%)]	Loss: -19.5837	Cost: 9.26s
Train Epoch: 1368 	Average Loss: -19.3258
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8505

Learning rate: 0.00011377902906846371
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1369 [0/90000 (0%)]	Loss: -12.9836	Cost: 39.98s
Train Epoch: 1369 [20480/90000 (23%)]	Loss: -19.8161	Cost: 10.93s
Train Epoch: 1369 [40960/90000 (45%)]	Loss: -20.0941	Cost: 12.28s
Train Epoch: 1369 [61440/90000 (68%)]	Loss: -20.0018	Cost: 9.71s
Train Epoch: 1369 [81920/90000 (91%)]	Loss: -19.6839	Cost: 11.12s
Train Epoch: 1369 	Average Loss: -19.3954
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0563

Learning rate: 0.00011367530065426896
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1370 [0/90000 (0%)]	Loss: -13.4522	Cost: 41.00s
Train Epoch: 1370 [20480/90000 (23%)]	Loss: -19.9593	Cost: 10.15s
Train Epoch: 1370 [40960/90000 (45%)]	Loss: -20.3302	Cost: 12.23s
Train Epoch: 1370 [61440/90000 (68%)]	Loss: -19.9350	Cost: 9.67s
Train Epoch: 1370 [81920/90000 (91%)]	Loss: -19.8408	Cost: 9.46s
Train Epoch: 1370 	Average Loss: -19.4861
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0737

Learning rate: 0.00011357155724343035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1371 [0/90000 (0%)]	Loss: -13.3517	Cost: 35.18s
Train Epoch: 1371 [20480/90000 (23%)]	Loss: -19.7498	Cost: 12.52s
Train Epoch: 1371 [40960/90000 (45%)]	Loss: -20.0246	Cost: 11.12s
Train Epoch: 1371 [61440/90000 (68%)]	Loss: -19.8624	Cost: 9.87s
Train Epoch: 1371 [81920/90000 (91%)]	Loss: -19.6051	Cost: 10.52s
Train Epoch: 1371 	Average Loss: -19.3469
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0236

Learning rate: 0.00011346779894971515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1372 [0/90000 (0%)]	Loss: -14.0446	Cost: 49.67s
Train Epoch: 1372 [20480/90000 (23%)]	Loss: -19.7869	Cost: 9.84s
Train Epoch: 1372 [40960/90000 (45%)]	Loss: -19.9825	Cost: 11.98s
Train Epoch: 1372 [61440/90000 (68%)]	Loss: -19.8701	Cost: 9.95s
Train Epoch: 1372 [81920/90000 (91%)]	Loss: -19.7307	Cost: 11.70s
Train Epoch: 1372 	Average Loss: -19.4277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0470

Learning rate: 0.0001133640258869071
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1373 [0/90000 (0%)]	Loss: -13.9812	Cost: 39.22s
Train Epoch: 1373 [20480/90000 (23%)]	Loss: -19.8331	Cost: 11.41s
Train Epoch: 1373 [40960/90000 (45%)]	Loss: -20.1182	Cost: 11.42s
Train Epoch: 1373 [61440/90000 (68%)]	Loss: -19.9455	Cost: 9.71s
Train Epoch: 1373 [81920/90000 (91%)]	Loss: -19.7199	Cost: 12.04s
Train Epoch: 1373 	Average Loss: -19.4696
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0575

Learning rate: 0.00011326023816880614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1374 [0/90000 (0%)]	Loss: -13.3935	Cost: 35.43s
Train Epoch: 1374 [20480/90000 (23%)]	Loss: -19.9051	Cost: 9.87s
Train Epoch: 1374 [40960/90000 (45%)]	Loss: -20.1997	Cost: 14.24s
Train Epoch: 1374 [61440/90000 (68%)]	Loss: -19.7510	Cost: 11.07s
Train Epoch: 1374 [81920/90000 (91%)]	Loss: -19.7910	Cost: 14.32s
Train Epoch: 1374 	Average Loss: -19.4336
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0179

Learning rate: 0.00011315643590922813
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1375 [0/90000 (0%)]	Loss: -12.5933	Cost: 31.88s
Train Epoch: 1375 [20480/90000 (23%)]	Loss: -19.8056	Cost: 9.72s
Train Epoch: 1375 [40960/90000 (45%)]	Loss: -20.0785	Cost: 13.12s
Train Epoch: 1375 [61440/90000 (68%)]	Loss: -19.7936	Cost: 10.66s
Train Epoch: 1375 [81920/90000 (91%)]	Loss: -19.6979	Cost: 14.29s
Train Epoch: 1375 	Average Loss: -19.3829
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9745

Learning rate: 0.00011305261922200505
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1376 [0/90000 (0%)]	Loss: -13.9555	Cost: 31.83s
Train Epoch: 1376 [20480/90000 (23%)]	Loss: -20.0021	Cost: 9.86s
Train Epoch: 1376 [40960/90000 (45%)]	Loss: -20.1486	Cost: 11.82s
Train Epoch: 1376 [61440/90000 (68%)]	Loss: -19.7795	Cost: 11.44s
Train Epoch: 1376 [81920/90000 (91%)]	Loss: -19.6140	Cost: 11.65s
Train Epoch: 1376 	Average Loss: -19.4380
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0477

Learning rate: 0.00011294878822098458
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1377 [0/90000 (0%)]	Loss: -13.7627	Cost: 34.54s
Train Epoch: 1377 [20480/90000 (23%)]	Loss: -20.0278	Cost: 10.08s
Train Epoch: 1377 [40960/90000 (45%)]	Loss: -20.2406	Cost: 10.80s
Train Epoch: 1377 [61440/90000 (68%)]	Loss: -19.8989	Cost: 9.90s
Train Epoch: 1377 [81920/90000 (91%)]	Loss: -19.8864	Cost: 12.24s
Train Epoch: 1377 	Average Loss: -19.4947
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0730

Learning rate: 0.00011284494302003018
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1378 [0/90000 (0%)]	Loss: -14.2811	Cost: 28.60s
Train Epoch: 1378 [20480/90000 (23%)]	Loss: -19.8699	Cost: 9.95s
Train Epoch: 1378 [40960/90000 (45%)]	Loss: -19.8299	Cost: 12.03s
Train Epoch: 1378 [61440/90000 (68%)]	Loss: -19.7728	Cost: 10.05s
Train Epoch: 1378 [81920/90000 (91%)]	Loss: -19.3812	Cost: 11.81s
Train Epoch: 1378 	Average Loss: -19.3234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5882

Learning rate: 0.00011274108373302083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1379 [0/90000 (0%)]	Loss: -13.5315	Cost: 38.69s
Train Epoch: 1379 [20480/90000 (23%)]	Loss: -19.6235	Cost: 9.68s
Train Epoch: 1379 [40960/90000 (45%)]	Loss: -19.7830	Cost: 10.26s
Train Epoch: 1379 [61440/90000 (68%)]	Loss: -19.5378	Cost: 9.69s
Train Epoch: 1379 [81920/90000 (91%)]	Loss: -19.5743	Cost: 11.69s
Train Epoch: 1379 	Average Loss: -19.2047
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9429

Learning rate: 0.00011263721047385095
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1380 [0/90000 (0%)]	Loss: -13.4677	Cost: 32.95s
Train Epoch: 1380 [20480/90000 (23%)]	Loss: -20.0535	Cost: 10.56s
Train Epoch: 1380 [40960/90000 (45%)]	Loss: -20.0635	Cost: 13.13s
Train Epoch: 1380 [61440/90000 (68%)]	Loss: -19.7279	Cost: 9.81s
Train Epoch: 1380 [81920/90000 (91%)]	Loss: -19.9445	Cost: 11.39s
Train Epoch: 1380 	Average Loss: -19.4596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0680

Learning rate: 0.00011253332335643031
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1381 [0/90000 (0%)]	Loss: -13.6435	Cost: 29.84s
Train Epoch: 1381 [20480/90000 (23%)]	Loss: -19.8947	Cost: 9.59s
Train Epoch: 1381 [40960/90000 (45%)]	Loss: -20.1621	Cost: 11.38s
Train Epoch: 1381 [61440/90000 (68%)]	Loss: -19.7161	Cost: 9.62s
Train Epoch: 1381 [81920/90000 (91%)]	Loss: -19.4900	Cost: 12.07s
Train Epoch: 1381 	Average Loss: -19.3861
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9074

Learning rate: 0.00011242942249468391
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1382 [0/90000 (0%)]	Loss: -13.3735	Cost: 38.43s
Train Epoch: 1382 [20480/90000 (23%)]	Loss: -19.6417	Cost: 9.51s
Train Epoch: 1382 [40960/90000 (45%)]	Loss: -20.0890	Cost: 10.42s
Train Epoch: 1382 [61440/90000 (68%)]	Loss: -19.5924	Cost: 9.73s
Train Epoch: 1382 [81920/90000 (91%)]	Loss: -19.5333	Cost: 12.60s
Train Epoch: 1382 	Average Loss: -19.1996
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0208

Learning rate: 0.00011232550800255177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1383 [0/90000 (0%)]	Loss: -13.5392	Cost: 34.88s
Train Epoch: 1383 [20480/90000 (23%)]	Loss: -19.8107	Cost: 10.27s
Train Epoch: 1383 [40960/90000 (45%)]	Loss: -20.0891	Cost: 12.31s
Train Epoch: 1383 [61440/90000 (68%)]	Loss: -19.8802	Cost: 9.44s
Train Epoch: 1383 [81920/90000 (91%)]	Loss: -19.7866	Cost: 11.61s
Train Epoch: 1383 	Average Loss: -19.4162
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0438

Learning rate: 0.00011222157999398884
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1384 [0/90000 (0%)]	Loss: -12.8012	Cost: 29.39s
Train Epoch: 1384 [20480/90000 (23%)]	Loss: -20.0744	Cost: 9.71s
Train Epoch: 1384 [40960/90000 (45%)]	Loss: -20.2673	Cost: 11.43s
Train Epoch: 1384 [61440/90000 (68%)]	Loss: -19.9366	Cost: 10.01s
Train Epoch: 1384 [81920/90000 (91%)]	Loss: -19.7983	Cost: 12.25s
Train Epoch: 1384 	Average Loss: -19.5542
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0937

Learning rate: 0.00011211763858296496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1385 [0/90000 (0%)]	Loss: -13.6143	Cost: 43.73s
Train Epoch: 1385 [20480/90000 (23%)]	Loss: -19.8954	Cost: 9.74s
Train Epoch: 1385 [40960/90000 (45%)]	Loss: -20.2367	Cost: 9.84s
Train Epoch: 1385 [61440/90000 (68%)]	Loss: -19.8506	Cost: 9.67s
Train Epoch: 1385 [81920/90000 (91%)]	Loss: -19.8162	Cost: 12.41s
Train Epoch: 1385 	Average Loss: -19.5106
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9187

Learning rate: 0.0001120136838834646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1386 [0/90000 (0%)]	Loss: -13.2075	Cost: 34.36s
Train Epoch: 1386 [20480/90000 (23%)]	Loss: -19.8128	Cost: 10.64s
Train Epoch: 1386 [40960/90000 (45%)]	Loss: -19.9154	Cost: 10.90s
Train Epoch: 1386 [61440/90000 (68%)]	Loss: -19.8988	Cost: 9.76s
Train Epoch: 1386 [81920/90000 (91%)]	Loss: -19.9338	Cost: 11.58s
Train Epoch: 1386 	Average Loss: -19.4317
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1664

Learning rate: 0.00011190971600948686
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1387 [0/90000 (0%)]	Loss: -13.9956	Cost: 29.66s
Train Epoch: 1387 [20480/90000 (23%)]	Loss: -20.0272	Cost: 9.78s
Train Epoch: 1387 [40960/90000 (45%)]	Loss: -20.2160	Cost: 11.90s
Train Epoch: 1387 [61440/90000 (68%)]	Loss: -19.9762	Cost: 9.76s
Train Epoch: 1387 [81920/90000 (91%)]	Loss: -19.4773	Cost: 12.90s
Train Epoch: 1387 	Average Loss: -19.4363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8234

Learning rate: 0.00011180573507504524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1388 [0/90000 (0%)]	Loss: -13.6894	Cost: 39.89s
Train Epoch: 1388 [20480/90000 (23%)]	Loss: -19.7013	Cost: 9.72s
Train Epoch: 1388 [40960/90000 (45%)]	Loss: -19.9939	Cost: 10.12s
Train Epoch: 1388 [61440/90000 (68%)]	Loss: -19.6045	Cost: 9.72s
Train Epoch: 1388 [81920/90000 (91%)]	Loss: -19.7066	Cost: 12.08s
Train Epoch: 1388 	Average Loss: -19.2150
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0114

Learning rate: 0.00011170174119416764
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1389 [0/90000 (0%)]	Loss: -13.2697	Cost: 32.96s
Train Epoch: 1389 [20480/90000 (23%)]	Loss: -19.7632	Cost: 10.59s
Train Epoch: 1389 [40960/90000 (45%)]	Loss: -20.1290	Cost: 11.63s
Train Epoch: 1389 [61440/90000 (68%)]	Loss: -19.8907	Cost: 9.74s
Train Epoch: 1389 [81920/90000 (91%)]	Loss: -19.8197	Cost: 11.37s
Train Epoch: 1389 	Average Loss: -19.3606
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0627

Learning rate: 0.00011159773448089605
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1390 [0/90000 (0%)]	Loss: -14.0694	Cost: 37.21s
Train Epoch: 1390 [20480/90000 (23%)]	Loss: -20.0069	Cost: 9.83s
Train Epoch: 1390 [40960/90000 (45%)]	Loss: -20.3656	Cost: 9.90s
Train Epoch: 1390 [61440/90000 (68%)]	Loss: -20.0538	Cost: 9.99s
Train Epoch: 1390 [81920/90000 (91%)]	Loss: -20.0336	Cost: 9.76s
Train Epoch: 1390 	Average Loss: -19.6400
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2788

Learning rate: 0.00011149371504928656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1391 [0/90000 (0%)]	Loss: -13.1795	Cost: 38.44s
Train Epoch: 1391 [20480/90000 (23%)]	Loss: -20.2272	Cost: 10.13s
Train Epoch: 1391 [40960/90000 (45%)]	Loss: -20.2223	Cost: 10.90s
Train Epoch: 1391 [61440/90000 (68%)]	Loss: -19.4046	Cost: 9.43s
Train Epoch: 1391 [81920/90000 (91%)]	Loss: -19.2959	Cost: 10.00s
Train Epoch: 1391 	Average Loss: -19.2277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.4325

Learning rate: 0.00011138968301340927
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1392 [0/90000 (0%)]	Loss: -12.6595	Cost: 39.87s
Train Epoch: 1392 [20480/90000 (23%)]	Loss: -19.5681	Cost: 9.94s
Train Epoch: 1392 [40960/90000 (45%)]	Loss: -19.7912	Cost: 12.28s
Train Epoch: 1392 [61440/90000 (68%)]	Loss: -19.5742	Cost: 9.85s
Train Epoch: 1392 [81920/90000 (91%)]	Loss: -19.4126	Cost: 12.10s
Train Epoch: 1392 	Average Loss: -19.0533
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.7847

Learning rate: 0.00011128563848734806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1393 [0/90000 (0%)]	Loss: -13.2450	Cost: 49.44s
Train Epoch: 1393 [20480/90000 (23%)]	Loss: -19.7504	Cost: 9.69s
Train Epoch: 1393 [40960/90000 (45%)]	Loss: -19.9762	Cost: 10.19s
Train Epoch: 1393 [61440/90000 (68%)]	Loss: -19.7820	Cost: 9.53s
Train Epoch: 1393 [81920/90000 (91%)]	Loss: -19.5963	Cost: 9.38s
Train Epoch: 1393 	Average Loss: -19.2554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0978

Learning rate: 0.0001111815815852005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1394 [0/90000 (0%)]	Loss: -13.2366	Cost: 40.56s
Train Epoch: 1394 [20480/90000 (23%)]	Loss: -19.8933	Cost: 11.83s
Train Epoch: 1394 [40960/90000 (45%)]	Loss: -20.1635	Cost: 12.53s
Train Epoch: 1394 [61440/90000 (68%)]	Loss: -19.9710	Cost: 9.80s
Train Epoch: 1394 [81920/90000 (91%)]	Loss: -19.6863	Cost: 10.14s
Train Epoch: 1394 	Average Loss: -19.5111
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2258

Learning rate: 0.00011107751242107774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1395 [0/90000 (0%)]	Loss: -12.7661	Cost: 50.11s
Train Epoch: 1395 [20480/90000 (23%)]	Loss: -20.1147	Cost: 9.71s
Train Epoch: 1395 [40960/90000 (45%)]	Loss: -20.4956	Cost: 11.48s
Train Epoch: 1395 [61440/90000 (68%)]	Loss: -20.0169	Cost: 9.54s
Train Epoch: 1395 [81920/90000 (91%)]	Loss: -19.6561	Cost: 10.53s
Train Epoch: 1395 	Average Loss: -19.6420
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0159

Learning rate: 0.00011097343110910443
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1396 [0/90000 (0%)]	Loss: -13.3276	Cost: 36.09s
Train Epoch: 1396 [20480/90000 (23%)]	Loss: -19.9126	Cost: 12.83s
Train Epoch: 1396 [40960/90000 (45%)]	Loss: -20.1886	Cost: 14.12s
Train Epoch: 1396 [61440/90000 (68%)]	Loss: -20.0438	Cost: 9.75s
Train Epoch: 1396 [81920/90000 (91%)]	Loss: -19.9557	Cost: 10.58s
Train Epoch: 1396 	Average Loss: -19.5343
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2024

Learning rate: 0.00011086933776341839
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1397 [0/90000 (0%)]	Loss: -13.1659	Cost: 35.24s
Train Epoch: 1397 [20480/90000 (23%)]	Loss: -20.2183	Cost: 12.11s
Train Epoch: 1397 [40960/90000 (45%)]	Loss: -20.3312	Cost: 12.32s
Train Epoch: 1397 [61440/90000 (68%)]	Loss: -19.9337	Cost: 9.86s
Train Epoch: 1397 [81920/90000 (91%)]	Loss: -19.7613	Cost: 14.65s
Train Epoch: 1397 	Average Loss: -19.5741
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0177

Learning rate: 0.00011076523249817085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1398 [0/90000 (0%)]	Loss: -13.1843	Cost: 30.56s
Train Epoch: 1398 [20480/90000 (23%)]	Loss: -20.0139	Cost: 11.76s
Train Epoch: 1398 [40960/90000 (45%)]	Loss: -20.0817	Cost: 14.52s
Train Epoch: 1398 [61440/90000 (68%)]	Loss: -19.9031	Cost: 10.85s
Train Epoch: 1398 [81920/90000 (91%)]	Loss: -19.9080	Cost: 11.31s
Train Epoch: 1398 	Average Loss: -19.4913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1556

Learning rate: 0.00011066111542752587
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1399 [0/90000 (0%)]	Loss: -13.7442	Cost: 32.80s
Train Epoch: 1399 [20480/90000 (23%)]	Loss: -20.1886	Cost: 10.54s
Train Epoch: 1399 [40960/90000 (45%)]	Loss: -20.4874	Cost: 10.61s
Train Epoch: 1399 [61440/90000 (68%)]	Loss: -20.0670	Cost: 9.85s
Train Epoch: 1399 [81920/90000 (91%)]	Loss: -19.8585	Cost: 11.57s
Train Epoch: 1399 	Average Loss: -19.6607
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2518

Learning rate: 0.00011055698666566068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1400 [0/90000 (0%)]	Loss: -13.3749	Cost: 28.88s
Train Epoch: 1400 [20480/90000 (23%)]	Loss: -20.0965	Cost: 9.78s
Train Epoch: 1400 [40960/90000 (45%)]	Loss: -20.2871	Cost: 11.61s
Train Epoch: 1400 [61440/90000 (68%)]	Loss: -19.7836	Cost: 10.06s
Train Epoch: 1400 [81920/90000 (91%)]	Loss: -19.5473	Cost: 12.31s
Train Epoch: 1400 	Average Loss: -19.4848
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.5883

Saving model as model.pt_e1400 & waveforms_supplementary.hdf5_e1400
Learning rate: 0.00011045284632676524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1401 [0/90000 (0%)]	Loss: -13.5007	Cost: 34.10s
Train Epoch: 1401 [20480/90000 (23%)]	Loss: -19.7264	Cost: 9.94s
Train Epoch: 1401 [40960/90000 (45%)]	Loss: -19.8205	Cost: 11.47s
Train Epoch: 1401 [61440/90000 (68%)]	Loss: -19.3765	Cost: 9.65s
Train Epoch: 1401 [81920/90000 (91%)]	Loss: -19.4448	Cost: 11.87s
Train Epoch: 1401 	Average Loss: -19.1760
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8298

Learning rate: 0.00011034869452504213
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1402 [0/90000 (0%)]	Loss: -13.8301	Cost: 31.82s
Train Epoch: 1402 [20480/90000 (23%)]	Loss: -19.7269	Cost: 10.98s
Train Epoch: 1402 [40960/90000 (45%)]	Loss: -19.8730	Cost: 11.04s
Train Epoch: 1402 [61440/90000 (68%)]	Loss: -19.3985	Cost: 9.66s
Train Epoch: 1402 [81920/90000 (91%)]	Loss: -19.6644	Cost: 9.93s
Train Epoch: 1402 	Average Loss: -19.2780
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9256

Learning rate: 0.0001102445313747066
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1403 [0/90000 (0%)]	Loss: -13.0948	Cost: 30.78s
Train Epoch: 1403 [20480/90000 (23%)]	Loss: -20.0144	Cost: 9.60s
Train Epoch: 1403 [40960/90000 (45%)]	Loss: -20.0079	Cost: 10.83s
Train Epoch: 1403 [61440/90000 (68%)]	Loss: -19.5696	Cost: 9.88s
Train Epoch: 1403 [81920/90000 (91%)]	Loss: -19.6041	Cost: 11.69s
Train Epoch: 1403 	Average Loss: -19.4391
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9666

Learning rate: 0.00011014035698998639
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1404 [0/90000 (0%)]	Loss: -13.3784	Cost: 36.06s
Train Epoch: 1404 [20480/90000 (23%)]	Loss: -20.0243	Cost: 9.92s
Train Epoch: 1404 [40960/90000 (45%)]	Loss: -20.3451	Cost: 11.06s
Train Epoch: 1404 [61440/90000 (68%)]	Loss: -19.8006	Cost: 9.57s
Train Epoch: 1404 [81920/90000 (91%)]	Loss: -19.6786	Cost: 11.50s
Train Epoch: 1404 	Average Loss: -19.5356
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9204

Learning rate: 0.00011003617148512135
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1405 [0/90000 (0%)]	Loss: -13.3194	Cost: 30.77s
Train Epoch: 1405 [20480/90000 (23%)]	Loss: -19.6304	Cost: 9.96s
Train Epoch: 1405 [40960/90000 (45%)]	Loss: -20.2621	Cost: 11.32s
Train Epoch: 1405 [61440/90000 (68%)]	Loss: -19.9512	Cost: 9.92s
Train Epoch: 1405 [81920/90000 (91%)]	Loss: -19.8747	Cost: 12.27s
Train Epoch: 1405 	Average Loss: -19.4616
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1333

Learning rate: 0.00010993197497436376
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1406 [0/90000 (0%)]	Loss: -13.7409	Cost: 44.57s
Train Epoch: 1406 [20480/90000 (23%)]	Loss: -19.9265	Cost: 9.74s
Train Epoch: 1406 [40960/90000 (45%)]	Loss: -20.3641	Cost: 9.78s
Train Epoch: 1406 [61440/90000 (68%)]	Loss: -20.0154	Cost: 9.87s
Train Epoch: 1406 [81920/90000 (91%)]	Loss: -20.1318	Cost: 9.89s
Train Epoch: 1406 	Average Loss: -19.5401
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2604

Learning rate: 0.00010982776757197789
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1407 [0/90000 (0%)]	Loss: -13.4015	Cost: 35.30s
Train Epoch: 1407 [20480/90000 (23%)]	Loss: -20.2515	Cost: 10.11s
Train Epoch: 1407 [40960/90000 (45%)]	Loss: -20.3921	Cost: 11.13s
Train Epoch: 1407 [61440/90000 (68%)]	Loss: -20.0740	Cost: 9.74s
Train Epoch: 1407 [81920/90000 (91%)]	Loss: -19.8264	Cost: 11.66s
Train Epoch: 1407 	Average Loss: -19.6357
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.9822

Learning rate: 0.00010972354939223981
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1408 [0/90000 (0%)]	Loss: -13.3857	Cost: 31.15s
Train Epoch: 1408 [20480/90000 (23%)]	Loss: -19.8577	Cost: 9.76s
Train Epoch: 1408 [40960/90000 (45%)]	Loss: -19.9753	Cost: 11.72s
Train Epoch: 1408 [61440/90000 (68%)]	Loss: -19.5437	Cost: 10.15s
Train Epoch: 1408 [81920/90000 (91%)]	Loss: -19.7937	Cost: 12.07s
Train Epoch: 1408 	Average Loss: -19.3425
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0202

Learning rate: 0.00010961932054943767
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1409 [0/90000 (0%)]	Loss: -13.3078	Cost: 42.90s
Train Epoch: 1409 [20480/90000 (23%)]	Loss: -20.0500	Cost: 9.66s
Train Epoch: 1409 [40960/90000 (45%)]	Loss: -20.2722	Cost: 10.34s
Train Epoch: 1409 [61440/90000 (68%)]	Loss: -20.0424	Cost: 9.61s
Train Epoch: 1409 [81920/90000 (91%)]	Loss: -20.0029	Cost: 11.24s
Train Epoch: 1409 	Average Loss: -19.5884
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1873

Learning rate: 0.00010951508115787107
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1410 [0/90000 (0%)]	Loss: -13.5667	Cost: 32.28s
Train Epoch: 1410 [20480/90000 (23%)]	Loss: -20.3389	Cost: 9.88s
Train Epoch: 1410 [40960/90000 (45%)]	Loss: -20.5128	Cost: 12.12s
Train Epoch: 1410 [61440/90000 (68%)]	Loss: -19.9928	Cost: 9.97s
Train Epoch: 1410 [81920/90000 (91%)]	Loss: -19.9328	Cost: 10.96s
Train Epoch: 1410 	Average Loss: -19.7417
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3567

Learning rate: 0.00010941083133185132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1411 [0/90000 (0%)]	Loss: -13.6598	Cost: 34.31s
Train Epoch: 1411 [20480/90000 (23%)]	Loss: -20.2696	Cost: 9.67s
Train Epoch: 1411 [40960/90000 (45%)]	Loss: -20.4303	Cost: 10.15s
Train Epoch: 1411 [61440/90000 (68%)]	Loss: -19.9887	Cost: 9.68s
Train Epoch: 1411 [81920/90000 (91%)]	Loss: -20.0001	Cost: 11.14s
Train Epoch: 1411 	Average Loss: -19.7746
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4432

Learning rate: 0.0001093065711857012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1412 [0/90000 (0%)]	Loss: -13.9450	Cost: 40.70s
Train Epoch: 1412 [20480/90000 (23%)]	Loss: -20.3926	Cost: 9.71s
Train Epoch: 1412 [40960/90000 (45%)]	Loss: -20.5945	Cost: 11.66s
Train Epoch: 1412 [61440/90000 (68%)]	Loss: -20.3515	Cost: 9.74s
Train Epoch: 1412 [81920/90000 (91%)]	Loss: -20.2443	Cost: 11.83s
Train Epoch: 1412 	Average Loss: -19.9394
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4613

Learning rate: 0.00010920230083375461
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1413 [0/90000 (0%)]	Loss: -14.1499	Cost: 34.83s
Train Epoch: 1413 [20480/90000 (23%)]	Loss: -20.2146	Cost: 9.74s
Train Epoch: 1413 [40960/90000 (45%)]	Loss: -20.4881	Cost: 10.85s
Train Epoch: 1413 [61440/90000 (68%)]	Loss: -20.3285	Cost: 9.99s
Train Epoch: 1413 [81920/90000 (91%)]	Loss: -20.1075	Cost: 11.88s
Train Epoch: 1413 	Average Loss: -19.7940
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4037

Learning rate: 0.00010909802039035686
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1414 [0/90000 (0%)]	Loss: -13.9851	Cost: 40.34s
Train Epoch: 1414 [20480/90000 (23%)]	Loss: -20.0625	Cost: 9.96s
Train Epoch: 1414 [40960/90000 (45%)]	Loss: -20.3354	Cost: 10.97s
Train Epoch: 1414 [61440/90000 (68%)]	Loss: -19.9344	Cost: 9.71s
Train Epoch: 1414 [81920/90000 (91%)]	Loss: -19.9300	Cost: 10.09s
Train Epoch: 1414 	Average Loss: -19.7395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3585

Learning rate: 0.00010899372996986428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1415 [0/90000 (0%)]	Loss: -14.1102	Cost: 33.85s
Train Epoch: 1415 [20480/90000 (23%)]	Loss: -20.2989	Cost: 10.00s
Train Epoch: 1415 [40960/90000 (45%)]	Loss: -20.5967	Cost: 11.47s
Train Epoch: 1415 [61440/90000 (68%)]	Loss: -20.2133	Cost: 9.79s
Train Epoch: 1415 [81920/90000 (91%)]	Loss: -20.0084	Cost: 12.43s
Train Epoch: 1415 	Average Loss: -19.8478
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2693

Learning rate: 0.00010888942968664403
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1416 [0/90000 (0%)]	Loss: -14.0450	Cost: 42.84s
Train Epoch: 1416 [20480/90000 (23%)]	Loss: -20.1759	Cost: 9.71s
Train Epoch: 1416 [40960/90000 (45%)]	Loss: -20.5206	Cost: 10.14s
Train Epoch: 1416 [61440/90000 (68%)]	Loss: -20.2198	Cost: 10.02s
Train Epoch: 1416 [81920/90000 (91%)]	Loss: -20.1866	Cost: 9.67s
Train Epoch: 1416 	Average Loss: -19.7986
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4735

Learning rate: 0.00010878511965507419
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1417 [0/90000 (0%)]	Loss: -13.8938	Cost: 34.71s
Train Epoch: 1417 [20480/90000 (23%)]	Loss: -20.2615	Cost: 10.21s
Train Epoch: 1417 [40960/90000 (45%)]	Loss: -20.3468	Cost: 11.16s
Train Epoch: 1417 [61440/90000 (68%)]	Loss: -20.1525	Cost: 9.78s
Train Epoch: 1417 [81920/90000 (91%)]	Loss: -20.0705	Cost: 11.59s
Train Epoch: 1417 	Average Loss: -19.7085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3113

Learning rate: 0.00010868079998954353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1418 [0/90000 (0%)]	Loss: -13.7808	Cost: 38.52s
Train Epoch: 1418 [20480/90000 (23%)]	Loss: -20.1285	Cost: 9.67s
Train Epoch: 1418 [40960/90000 (45%)]	Loss: -20.3260	Cost: 10.55s
Train Epoch: 1418 [61440/90000 (68%)]	Loss: -20.0915	Cost: 9.82s
Train Epoch: 1418 [81920/90000 (91%)]	Loss: -19.9928	Cost: 9.75s
Train Epoch: 1418 	Average Loss: -19.6500
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3132

Learning rate: 0.00010857647080445128
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1419 [0/90000 (0%)]	Loss: -12.9200	Cost: 42.39s
Train Epoch: 1419 [20480/90000 (23%)]	Loss: -20.1113	Cost: 9.74s
Train Epoch: 1419 [40960/90000 (45%)]	Loss: -20.5353	Cost: 11.22s
Train Epoch: 1419 [61440/90000 (68%)]	Loss: -20.2391	Cost: 9.56s
Train Epoch: 1419 [81920/90000 (91%)]	Loss: -20.1653	Cost: 9.17s
Train Epoch: 1419 	Average Loss: -19.7775
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4025

Learning rate: 0.00010847213221420722
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1420 [0/90000 (0%)]	Loss: -13.7359	Cost: 41.00s
Train Epoch: 1420 [20480/90000 (23%)]	Loss: -20.1595	Cost: 9.95s
Train Epoch: 1420 [40960/90000 (45%)]	Loss: -20.5052	Cost: 12.63s
Train Epoch: 1420 [61440/90000 (68%)]	Loss: -20.2295	Cost: 10.01s
Train Epoch: 1420 [81920/90000 (91%)]	Loss: -19.7689	Cost: 10.70s
Train Epoch: 1420 	Average Loss: -19.6858
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3318

Learning rate: 0.00010836778433323147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1421 [0/90000 (0%)]	Loss: -13.9861	Cost: 42.85s
Train Epoch: 1421 [20480/90000 (23%)]	Loss: -20.1591	Cost: 9.72s
Train Epoch: 1421 [40960/90000 (45%)]	Loss: -20.2456	Cost: 12.16s
Train Epoch: 1421 [61440/90000 (68%)]	Loss: -19.8929	Cost: 9.53s
Train Epoch: 1421 [81920/90000 (91%)]	Loss: -20.0149	Cost: 9.34s
Train Epoch: 1421 	Average Loss: -19.5514
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2089

Learning rate: 0.00010826342727595416
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1422 [0/90000 (0%)]	Loss: -13.6921	Cost: 40.69s
Train Epoch: 1422 [20480/90000 (23%)]	Loss: -19.9902	Cost: 10.14s
Train Epoch: 1422 [40960/90000 (45%)]	Loss: -20.5337	Cost: 13.51s
Train Epoch: 1422 [61440/90000 (68%)]	Loss: -20.0858	Cost: 10.01s
Train Epoch: 1422 [81920/90000 (91%)]	Loss: -19.9087	Cost: 10.88s
Train Epoch: 1422 	Average Loss: -19.6778
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2779

Learning rate: 0.00010815906115681567
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1423 [0/90000 (0%)]	Loss: -12.6097	Cost: 50.21s
Train Epoch: 1423 [20480/90000 (23%)]	Loss: -20.0858	Cost: 9.90s
Train Epoch: 1423 [40960/90000 (45%)]	Loss: -20.3119	Cost: 12.06s
Train Epoch: 1423 [61440/90000 (68%)]	Loss: -19.8428	Cost: 9.43s
Train Epoch: 1423 [81920/90000 (91%)]	Loss: -20.1225	Cost: 9.41s
Train Epoch: 1423 	Average Loss: -19.6478
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2199

Learning rate: 0.00010805468609026622
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1424 [0/90000 (0%)]	Loss: -14.4587	Cost: 37.59s
Train Epoch: 1424 [20480/90000 (23%)]	Loss: -20.1633	Cost: 12.20s
Train Epoch: 1424 [40960/90000 (45%)]	Loss: -20.4523	Cost: 13.69s
Train Epoch: 1424 [61440/90000 (68%)]	Loss: -19.9823	Cost: 9.97s
Train Epoch: 1424 [81920/90000 (91%)]	Loss: -19.9893	Cost: 10.25s
Train Epoch: 1424 	Average Loss: -19.6987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3956

Learning rate: 0.00010795030219076588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1425 [0/90000 (0%)]	Loss: -13.0571	Cost: 39.88s
Train Epoch: 1425 [20480/90000 (23%)]	Loss: -19.9157	Cost: 11.24s
Train Epoch: 1425 [40960/90000 (45%)]	Loss: -20.0781	Cost: 12.43s
Train Epoch: 1425 [61440/90000 (68%)]	Loss: -19.7937	Cost: 9.86s
Train Epoch: 1425 [81920/90000 (91%)]	Loss: -19.6527	Cost: 12.09s
Train Epoch: 1425 	Average Loss: -19.3752
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -13.8414

Learning rate: 0.00010784590957278441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1426 [0/90000 (0%)]	Loss: -13.1430	Cost: 33.34s
Train Epoch: 1426 [20480/90000 (23%)]	Loss: -19.6893	Cost: 13.76s
Train Epoch: 1426 [40960/90000 (45%)]	Loss: -20.2247	Cost: 13.36s
Train Epoch: 1426 [61440/90000 (68%)]	Loss: -19.9668	Cost: 10.38s
Train Epoch: 1426 [81920/90000 (91%)]	Loss: -19.7959	Cost: 11.44s
Train Epoch: 1426 	Average Loss: -19.3771
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.0083

Learning rate: 0.0001077415083508011
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1427 [0/90000 (0%)]	Loss: -13.4946	Cost: 35.02s
Train Epoch: 1427 [20480/90000 (23%)]	Loss: -20.0323	Cost: 10.05s
Train Epoch: 1427 [40960/90000 (45%)]	Loss: -20.2777	Cost: 11.50s
Train Epoch: 1427 [61440/90000 (68%)]	Loss: -20.0859	Cost: 9.80s
Train Epoch: 1427 [81920/90000 (91%)]	Loss: -19.9168	Cost: 15.39s
Train Epoch: 1427 	Average Loss: -19.5430
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.1483

Learning rate: 0.00010763709863930466
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1428 [0/90000 (0%)]	Loss: -13.6493	Cost: 28.73s
Train Epoch: 1428 [20480/90000 (23%)]	Loss: -20.1533	Cost: 9.88s
Train Epoch: 1428 [40960/90000 (45%)]	Loss: -20.4874	Cost: 11.88s
Train Epoch: 1428 [61440/90000 (68%)]	Loss: -20.2562	Cost: 10.15s
Train Epoch: 1428 [81920/90000 (91%)]	Loss: -19.8683	Cost: 11.89s
Train Epoch: 1428 	Average Loss: -19.6638
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2202

Learning rate: 0.00010753268055279318
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1429 [0/90000 (0%)]	Loss: -13.9353	Cost: 38.50s
Train Epoch: 1429 [20480/90000 (23%)]	Loss: -20.2452	Cost: 9.72s
Train Epoch: 1429 [40960/90000 (45%)]	Loss: -20.5397	Cost: 10.28s
Train Epoch: 1429 [61440/90000 (68%)]	Loss: -20.0749	Cost: 9.71s
Train Epoch: 1429 [81920/90000 (91%)]	Loss: -20.0833	Cost: 11.80s
Train Epoch: 1429 	Average Loss: -19.7704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2389

Learning rate: 0.00010742825420577389
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1430 [0/90000 (0%)]	Loss: -13.8722	Cost: 33.01s
Train Epoch: 1430 [20480/90000 (23%)]	Loss: -20.4092	Cost: 10.62s
Train Epoch: 1430 [40960/90000 (45%)]	Loss: -20.6481	Cost: 13.07s
Train Epoch: 1430 [61440/90000 (68%)]	Loss: -20.0802	Cost: 9.94s
Train Epoch: 1430 [81920/90000 (91%)]	Loss: -19.8049	Cost: 11.08s
Train Epoch: 1430 	Average Loss: -19.7828
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3675

Learning rate: 0.00010732381971276306
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1431 [0/90000 (0%)]	Loss: -13.3489	Cost: 29.03s
Train Epoch: 1431 [20480/90000 (23%)]	Loss: -20.3251	Cost: 9.84s
Train Epoch: 1431 [40960/90000 (45%)]	Loss: -20.4664	Cost: 12.40s
Train Epoch: 1431 [61440/90000 (68%)]	Loss: -20.2793	Cost: 9.89s
Train Epoch: 1431 [81920/90000 (91%)]	Loss: -20.1410	Cost: 12.05s
Train Epoch: 1431 	Average Loss: -19.7591
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5084

Learning rate: 0.00010721937718828595
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1432 [0/90000 (0%)]	Loss: -14.5321	Cost: 37.99s
Train Epoch: 1432 [20480/90000 (23%)]	Loss: -20.5679	Cost: 9.80s
Train Epoch: 1432 [40960/90000 (45%)]	Loss: -20.7152	Cost: 9.87s
Train Epoch: 1432 [61440/90000 (68%)]	Loss: -20.4449	Cost: 9.72s
Train Epoch: 1432 [81920/90000 (91%)]	Loss: -20.3851	Cost: 12.03s
Train Epoch: 1432 	Average Loss: -20.0163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5588

Learning rate: 0.00010711492674687659
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1433 [0/90000 (0%)]	Loss: -13.9193	Cost: 31.81s
Train Epoch: 1433 [20480/90000 (23%)]	Loss: -20.5025	Cost: 10.21s
Train Epoch: 1433 [40960/90000 (45%)]	Loss: -20.6781	Cost: 11.93s
Train Epoch: 1433 [61440/90000 (68%)]	Loss: -20.2844	Cost: 9.91s
Train Epoch: 1433 [81920/90000 (91%)]	Loss: -20.4034	Cost: 11.04s
Train Epoch: 1433 	Average Loss: -20.0132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5146

Learning rate: 0.00010701046850307766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1434 [0/90000 (0%)]	Loss: -13.7335	Cost: 31.15s
Train Epoch: 1434 [20480/90000 (23%)]	Loss: -20.7023	Cost: 9.67s
Train Epoch: 1434 [40960/90000 (45%)]	Loss: -20.7005	Cost: 10.73s
Train Epoch: 1434 [61440/90000 (68%)]	Loss: -20.3086	Cost: 9.67s
Train Epoch: 1434 [81920/90000 (91%)]	Loss: -20.4127	Cost: 11.43s
Train Epoch: 1434 	Average Loss: -20.0317
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4522

Learning rate: 0.00010690600257144047
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1435 [0/90000 (0%)]	Loss: -14.5301	Cost: 37.02s
Train Epoch: 1435 [20480/90000 (23%)]	Loss: -20.4564	Cost: 9.90s
Train Epoch: 1435 [40960/90000 (45%)]	Loss: -20.8790	Cost: 10.88s
Train Epoch: 1435 [61440/90000 (68%)]	Loss: -20.4116	Cost: 9.69s
Train Epoch: 1435 [81920/90000 (91%)]	Loss: -20.2466	Cost: 11.71s
Train Epoch: 1435 	Average Loss: -20.0796
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4822

Learning rate: 0.0001068015290665247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1436 [0/90000 (0%)]	Loss: -14.8667	Cost: 31.71s
Train Epoch: 1436 [20480/90000 (23%)]	Loss: -20.6120	Cost: 10.38s
Train Epoch: 1436 [40960/90000 (45%)]	Loss: -20.8006	Cost: 12.10s
Train Epoch: 1436 [61440/90000 (68%)]	Loss: -20.6816	Cost: 9.92s
Train Epoch: 1436 [81920/90000 (91%)]	Loss: -20.3700	Cost: 11.08s
Train Epoch: 1436 	Average Loss: -20.1060
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6375

Learning rate: 0.00010669704810289839
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1437 [0/90000 (0%)]	Loss: -14.5033	Cost: 35.96s
Train Epoch: 1437 [20480/90000 (23%)]	Loss: -20.6988	Cost: 9.73s
Train Epoch: 1437 [40960/90000 (45%)]	Loss: -20.8068	Cost: 10.25s
Train Epoch: 1437 [61440/90000 (68%)]	Loss: -20.3558	Cost: 9.71s
Train Epoch: 1437 [81920/90000 (91%)]	Loss: -20.2047	Cost: 10.75s
Train Epoch: 1437 	Average Loss: -20.0397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5336

Learning rate: 0.00010659255979513767
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1438 [0/90000 (0%)]	Loss: -13.8960	Cost: 38.11s
Train Epoch: 1438 [20480/90000 (23%)]	Loss: -20.5407	Cost: 10.00s
Train Epoch: 1438 [40960/90000 (45%)]	Loss: -20.5404	Cost: 11.47s
Train Epoch: 1438 [61440/90000 (68%)]	Loss: -20.4500	Cost: 9.54s
Train Epoch: 1438 [81920/90000 (91%)]	Loss: -20.2242	Cost: 9.75s
Train Epoch: 1438 	Average Loss: -19.9858
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4668

Learning rate: 0.00010648806425782684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1439 [0/90000 (0%)]	Loss: -14.0560	Cost: 43.51s
Train Epoch: 1439 [20480/90000 (23%)]	Loss: -20.4015	Cost: 9.61s
Train Epoch: 1439 [40960/90000 (45%)]	Loss: -20.8924	Cost: 10.44s
Train Epoch: 1439 [61440/90000 (68%)]	Loss: -20.4022	Cost: 9.54s
Train Epoch: 1439 [81920/90000 (91%)]	Loss: -20.5227	Cost: 11.21s
Train Epoch: 1439 	Average Loss: -20.0581
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5469

Learning rate: 0.00010638356160555805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1440 [0/90000 (0%)]	Loss: -15.1315	Cost: 40.89s
Train Epoch: 1440 [20480/90000 (23%)]	Loss: -20.6335	Cost: 9.86s
Train Epoch: 1440 [40960/90000 (45%)]	Loss: -20.8034	Cost: 11.33s
Train Epoch: 1440 [61440/90000 (68%)]	Loss: -20.5499	Cost: 9.49s
Train Epoch: 1440 [81920/90000 (91%)]	Loss: -20.3617	Cost: 9.18s
Train Epoch: 1440 	Average Loss: -20.1437
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7677

Learning rate: 0.00010627905195293122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1441 [0/90000 (0%)]	Loss: -14.0596	Cost: 40.41s
Train Epoch: 1441 [20480/90000 (23%)]	Loss: -20.7468	Cost: 9.91s
Train Epoch: 1441 [40960/90000 (45%)]	Loss: -20.9228	Cost: 12.40s
Train Epoch: 1441 [61440/90000 (68%)]	Loss: -20.2764	Cost: 9.79s
Train Epoch: 1441 [81920/90000 (91%)]	Loss: -20.0900	Cost: 11.46s
Train Epoch: 1441 	Average Loss: -20.0505
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2924

Learning rate: 0.00010617453541455409
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1442 [0/90000 (0%)]	Loss: -13.8530	Cost: 49.17s
Train Epoch: 1442 [20480/90000 (23%)]	Loss: -20.4754	Cost: 9.69s
Train Epoch: 1442 [40960/90000 (45%)]	Loss: -20.8348	Cost: 10.74s
Train Epoch: 1442 [61440/90000 (68%)]	Loss: -20.3566	Cost: 9.42s
Train Epoch: 1442 [81920/90000 (91%)]	Loss: -20.0478	Cost: 9.37s
Train Epoch: 1442 	Average Loss: -19.8763
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3255

Learning rate: 0.00010607001210504179
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1443 [0/90000 (0%)]	Loss: -13.7988	Cost: 36.53s
Train Epoch: 1443 [20480/90000 (23%)]	Loss: -20.4051	Cost: 12.13s
Train Epoch: 1443 [40960/90000 (45%)]	Loss: -20.7224	Cost: 11.62s
Train Epoch: 1443 [61440/90000 (68%)]	Loss: -20.5863	Cost: 9.79s
Train Epoch: 1443 [81920/90000 (91%)]	Loss: -20.4208	Cost: 10.30s
Train Epoch: 1443 	Average Loss: -20.0408
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6351

Learning rate: 0.00010596548213901695
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1444 [0/90000 (0%)]	Loss: -13.1849	Cost: 46.96s
Train Epoch: 1444 [20480/90000 (23%)]	Loss: -20.5026	Cost: 9.86s
Train Epoch: 1444 [40960/90000 (45%)]	Loss: -20.6525	Cost: 12.00s
Train Epoch: 1444 [61440/90000 (68%)]	Loss: -20.3165	Cost: 9.66s
Train Epoch: 1444 [81920/90000 (91%)]	Loss: -20.1339	Cost: 11.37s
Train Epoch: 1444 	Average Loss: -19.8932
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4158

Learning rate: 0.00010586094563110954
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1445 [0/90000 (0%)]	Loss: -13.7832	Cost: 34.41s
Train Epoch: 1445 [20480/90000 (23%)]	Loss: -20.5764	Cost: 12.49s
Train Epoch: 1445 [40960/90000 (45%)]	Loss: -20.5943	Cost: 12.25s
Train Epoch: 1445 [61440/90000 (68%)]	Loss: -20.2740	Cost: 10.01s
Train Epoch: 1445 [81920/90000 (91%)]	Loss: -20.1369	Cost: 9.55s
Train Epoch: 1445 	Average Loss: -19.9742
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2672

Learning rate: 0.00010575640269595663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1446 [0/90000 (0%)]	Loss: -13.0421	Cost: 33.24s
Train Epoch: 1446 [20480/90000 (23%)]	Loss: -20.2874	Cost: 12.16s
Train Epoch: 1446 [40960/90000 (45%)]	Loss: -20.8370	Cost: 13.07s
Train Epoch: 1446 [61440/90000 (68%)]	Loss: -20.3353	Cost: 9.78s
Train Epoch: 1446 [81920/90000 (91%)]	Loss: -20.1395	Cost: 15.07s
Train Epoch: 1446 	Average Loss: -19.8275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4707

Learning rate: 0.00010565185344820234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1447 [0/90000 (0%)]	Loss: -13.6357	Cost: 31.02s
Train Epoch: 1447 [20480/90000 (23%)]	Loss: -20.2592	Cost: 11.47s
Train Epoch: 1447 [40960/90000 (45%)]	Loss: -20.6709	Cost: 19.95s
Train Epoch: 1447 [61440/90000 (68%)]	Loss: -20.0605	Cost: 10.25s
Train Epoch: 1447 [81920/90000 (91%)]	Loss: -20.0375	Cost: 13.55s
Train Epoch: 1447 	Average Loss: -19.7019
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3878

Learning rate: 0.0001055472980024978
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1448 [0/90000 (0%)]	Loss: -14.0117	Cost: 37.67s
Train Epoch: 1448 [20480/90000 (23%)]	Loss: -20.3530	Cost: 9.70s
Train Epoch: 1448 [40960/90000 (45%)]	Loss: -20.6830	Cost: 11.38s
Train Epoch: 1448 [61440/90000 (68%)]	Loss: -20.1952	Cost: 10.69s
Train Epoch: 1448 [81920/90000 (91%)]	Loss: -20.0607	Cost: 14.14s
Train Epoch: 1448 	Average Loss: -19.8943
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3644

Learning rate: 0.0001054427364735008
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1449 [0/90000 (0%)]	Loss: -13.6947	Cost: 28.43s
Train Epoch: 1449 [20480/90000 (23%)]	Loss: -20.4505	Cost: 10.04s
Train Epoch: 1449 [40960/90000 (45%)]	Loss: -20.7906	Cost: 12.49s
Train Epoch: 1449 [61440/90000 (68%)]	Loss: -20.3228	Cost: 9.73s
Train Epoch: 1449 [81920/90000 (91%)]	Loss: -20.2644	Cost: 12.12s
Train Epoch: 1449 	Average Loss: -19.9997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5298

Learning rate: 0.00010533816897587591
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1450 [0/90000 (0%)]	Loss: -13.8683	Cost: 34.76s
Train Epoch: 1450 [20480/90000 (23%)]	Loss: -20.5388	Cost: 9.78s
Train Epoch: 1450 [40960/90000 (45%)]	Loss: -20.5449	Cost: 11.62s
Train Epoch: 1450 [61440/90000 (68%)]	Loss: -20.3836	Cost: 9.60s
Train Epoch: 1450 [81920/90000 (91%)]	Loss: -20.2679	Cost: 12.67s
Train Epoch: 1450 	Average Loss: -19.9784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3408

Saving model as model.pt_e1450 & waveforms_supplementary.hdf5_e1450
Learning rate: 0.00010523359562429428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1451 [0/90000 (0%)]	Loss: -13.2776	Cost: 33.59s
Train Epoch: 1451 [20480/90000 (23%)]	Loss: -20.4501	Cost: 10.31s
Train Epoch: 1451 [40960/90000 (45%)]	Loss: -20.7668	Cost: 11.06s
Train Epoch: 1451 [61440/90000 (68%)]	Loss: -20.4017	Cost: 9.93s
Train Epoch: 1451 [81920/90000 (91%)]	Loss: -20.2360	Cost: 12.65s
Train Epoch: 1451 	Average Loss: -19.9097
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.3959

Learning rate: 0.00010512901653343332
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1452 [0/90000 (0%)]	Loss: -13.8221	Cost: 29.01s
Train Epoch: 1452 [20480/90000 (23%)]	Loss: -20.3350	Cost: 10.24s
Train Epoch: 1452 [40960/90000 (45%)]	Loss: -20.7849	Cost: 11.96s
Train Epoch: 1452 [61440/90000 (68%)]	Loss: -20.2468	Cost: 9.83s
Train Epoch: 1452 [81920/90000 (91%)]	Loss: -20.2454	Cost: 11.48s
Train Epoch: 1452 	Average Loss: -19.9184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4748

Learning rate: 0.00010502443181797682
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1453 [0/90000 (0%)]	Loss: -13.9397	Cost: 37.51s
Train Epoch: 1453 [20480/90000 (23%)]	Loss: -20.6705	Cost: 9.77s
Train Epoch: 1453 [40960/90000 (45%)]	Loss: -21.1326	Cost: 10.42s
Train Epoch: 1453 [61440/90000 (68%)]	Loss: -20.5683	Cost: 9.71s
Train Epoch: 1453 [81920/90000 (91%)]	Loss: -20.6547	Cost: 11.43s
Train Epoch: 1453 	Average Loss: -20.1870
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8868

Learning rate: 0.00010491984159261484
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1454 [0/90000 (0%)]	Loss: -13.9852	Cost: 33.08s
Train Epoch: 1454 [20480/90000 (23%)]	Loss: -20.5565	Cost: 10.79s
Train Epoch: 1454 [40960/90000 (45%)]	Loss: -20.8516	Cost: 11.91s
Train Epoch: 1454 [61440/90000 (68%)]	Loss: -20.4041	Cost: 9.56s
Train Epoch: 1454 [81920/90000 (91%)]	Loss: -20.1102	Cost: 11.16s
Train Epoch: 1454 	Average Loss: -20.0702
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.2500

Learning rate: 0.0001048152459720433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1455 [0/90000 (0%)]	Loss: -13.3398	Cost: 28.71s
Train Epoch: 1455 [20480/90000 (23%)]	Loss: -20.2721	Cost: 9.73s
Train Epoch: 1455 [40960/90000 (45%)]	Loss: -20.3586	Cost: 11.23s
Train Epoch: 1455 [61440/90000 (68%)]	Loss: -20.1563	Cost: 10.06s
Train Epoch: 1455 [81920/90000 (91%)]	Loss: -20.1217	Cost: 12.20s
Train Epoch: 1455 	Average Loss: -19.7757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4210

Learning rate: 0.00010471064507096417
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1456 [0/90000 (0%)]	Loss: -13.5229	Cost: 44.78s
Train Epoch: 1456 [20480/90000 (23%)]	Loss: -20.4472	Cost: 9.68s
Train Epoch: 1456 [40960/90000 (45%)]	Loss: -20.7407	Cost: 11.40s
Train Epoch: 1456 [61440/90000 (68%)]	Loss: -20.4820	Cost: 9.77s
Train Epoch: 1456 [81920/90000 (91%)]	Loss: -20.3086	Cost: 11.19s
Train Epoch: 1456 	Average Loss: -20.0268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7160

Learning rate: 0.00010460603900408511
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1457 [0/90000 (0%)]	Loss: -13.8989	Cost: 30.01s
Train Epoch: 1457 [20480/90000 (23%)]	Loss: -20.6808	Cost: 10.07s
Train Epoch: 1457 [40960/90000 (45%)]	Loss: -21.0552	Cost: 12.20s
Train Epoch: 1457 [61440/90000 (68%)]	Loss: -20.5888	Cost: 10.15s
Train Epoch: 1457 [81920/90000 (91%)]	Loss: -20.2362	Cost: 10.99s
Train Epoch: 1457 	Average Loss: -20.1662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7307

Learning rate: 0.00010450142788611953
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1458 [0/90000 (0%)]	Loss: -13.9556	Cost: 36.31s
Train Epoch: 1458 [20480/90000 (23%)]	Loss: -20.3355	Cost: 9.69s
Train Epoch: 1458 [40960/90000 (45%)]	Loss: -21.0261	Cost: 10.15s
Train Epoch: 1458 [61440/90000 (68%)]	Loss: -20.5212	Cost: 9.92s
Train Epoch: 1458 [81920/90000 (91%)]	Loss: -20.4357	Cost: 12.16s
Train Epoch: 1458 	Average Loss: -20.0560
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.5799

Learning rate: 0.00010439681183178639
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1459 [0/90000 (0%)]	Loss: -13.6965	Cost: 33.63s
Train Epoch: 1459 [20480/90000 (23%)]	Loss: -20.6137	Cost: 9.67s
Train Epoch: 1459 [40960/90000 (45%)]	Loss: -20.9108	Cost: 12.87s
Train Epoch: 1459 [61440/90000 (68%)]	Loss: -20.5353	Cost: 9.60s
Train Epoch: 1459 [81920/90000 (91%)]	Loss: -20.4992	Cost: 12.55s
Train Epoch: 1459 	Average Loss: -20.0911
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6319

Learning rate: 0.00010429219095580994
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1460 [0/90000 (0%)]	Loss: -14.0632	Cost: 30.17s
Train Epoch: 1460 [20480/90000 (23%)]	Loss: -20.7332	Cost: 9.85s
Train Epoch: 1460 [40960/90000 (45%)]	Loss: -20.9362	Cost: 10.85s
Train Epoch: 1460 [61440/90000 (68%)]	Loss: -20.5860	Cost: 10.03s
Train Epoch: 1460 [81920/90000 (91%)]	Loss: -20.5895	Cost: 11.99s
Train Epoch: 1460 	Average Loss: -20.2453
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.6922

Learning rate: 0.00010418756537291984
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1461 [0/90000 (0%)]	Loss: -14.6161	Cost: 42.72s
Train Epoch: 1461 [20480/90000 (23%)]	Loss: -20.7026	Cost: 9.97s
Train Epoch: 1461 [40960/90000 (45%)]	Loss: -20.9863	Cost: 9.82s
Train Epoch: 1461 [61440/90000 (68%)]	Loss: -20.8053	Cost: 9.82s
Train Epoch: 1461 [81920/90000 (91%)]	Loss: -20.8168	Cost: 10.60s
Train Epoch: 1461 	Average Loss: -20.3392
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0279

Learning rate: 0.00010408293519785089
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1462 [0/90000 (0%)]	Loss: -13.4794	Cost: 32.77s
Train Epoch: 1462 [20480/90000 (23%)]	Loss: -20.9325	Cost: 9.88s
Train Epoch: 1462 [40960/90000 (45%)]	Loss: -21.0569	Cost: 12.20s
Train Epoch: 1462 [61440/90000 (68%)]	Loss: -20.6483	Cost: 9.94s
Train Epoch: 1462 [81920/90000 (91%)]	Loss: -20.3555	Cost: 10.76s
Train Epoch: 1462 	Average Loss: -20.2427
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.4366

Learning rate: 0.00010397830054534287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1463 [0/90000 (0%)]	Loss: -14.6174	Cost: 34.90s
Train Epoch: 1463 [20480/90000 (23%)]	Loss: -20.4616	Cost: 9.66s
Train Epoch: 1463 [40960/90000 (45%)]	Loss: -21.0462	Cost: 10.06s
Train Epoch: 1463 [61440/90000 (68%)]	Loss: -20.7156	Cost: 9.72s
Train Epoch: 1463 [81920/90000 (91%)]	Loss: -20.7206	Cost: 11.10s
Train Epoch: 1463 	Average Loss: -20.2741
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.7912

Learning rate: 0.00010387366153014051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1464 [0/90000 (0%)]	Loss: -14.6783	Cost: 40.26s
Train Epoch: 1464 [20480/90000 (23%)]	Loss: -20.8617	Cost: 9.95s
Train Epoch: 1464 [40960/90000 (45%)]	Loss: -21.0956	Cost: 10.89s
Train Epoch: 1464 [61440/90000 (68%)]	Loss: -20.7333	Cost: 9.71s
Train Epoch: 1464 [81920/90000 (91%)]	Loss: -20.6690	Cost: 10.53s
Train Epoch: 1464 	Average Loss: -20.4214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8924

Learning rate: 0.00010376901826699338
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1465 [0/90000 (0%)]	Loss: -14.5196	Cost: 42.12s
Train Epoch: 1465 [20480/90000 (23%)]	Loss: -20.7531	Cost: 9.64s
Train Epoch: 1465 [40960/90000 (45%)]	Loss: -21.0775	Cost: 10.26s
Train Epoch: 1465 [61440/90000 (68%)]	Loss: -20.6446	Cost: 9.88s
Train Epoch: 1465 [81920/90000 (91%)]	Loss: -20.6873	Cost: 10.91s
Train Epoch: 1465 	Average Loss: -20.3713
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0042

Learning rate: 0.00010366437087065553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1466 [0/90000 (0%)]	Loss: -13.8018	Cost: 44.23s
Train Epoch: 1466 [20480/90000 (23%)]	Loss: -20.7833	Cost: 9.90s
Train Epoch: 1466 [40960/90000 (45%)]	Loss: -21.1009	Cost: 10.56s
Train Epoch: 1466 [61440/90000 (68%)]	Loss: -20.8410	Cost: 9.73s
Train Epoch: 1466 [81920/90000 (91%)]	Loss: -20.6856	Cost: 9.58s
Train Epoch: 1466 	Average Loss: -20.4086
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8753

Learning rate: 0.00010355971945588577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1467 [0/90000 (0%)]	Loss: -14.4266	Cost: 37.03s
Train Epoch: 1467 [20480/90000 (23%)]	Loss: -21.1344	Cost: 10.10s
Train Epoch: 1467 [40960/90000 (45%)]	Loss: -21.3747	Cost: 12.29s
Train Epoch: 1467 [61440/90000 (68%)]	Loss: -21.1202	Cost: 9.77s
Train Epoch: 1467 [81920/90000 (91%)]	Loss: -20.7404	Cost: 11.89s
Train Epoch: 1467 	Average Loss: -20.5547
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9756

Learning rate: 0.00010345506413744715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1468 [0/90000 (0%)]	Loss: -14.1408	Cost: 40.53s
Train Epoch: 1468 [20480/90000 (23%)]	Loss: -20.9559	Cost: 9.69s
Train Epoch: 1468 [40960/90000 (45%)]	Loss: -21.3087	Cost: 10.27s
Train Epoch: 1468 [61440/90000 (68%)]	Loss: -20.9780	Cost: 9.67s
Train Epoch: 1468 [81920/90000 (91%)]	Loss: -20.7827	Cost: 10.07s
Train Epoch: 1468 	Average Loss: -20.4620
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0536

Learning rate: 0.00010335040503010706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1469 [0/90000 (0%)]	Loss: -14.4412	Cost: 35.60s
Train Epoch: 1469 [20480/90000 (23%)]	Loss: -20.8409	Cost: 11.21s
Train Epoch: 1469 [40960/90000 (45%)]	Loss: -21.3270	Cost: 11.86s
Train Epoch: 1469 [61440/90000 (68%)]	Loss: -20.8239	Cost: 9.62s
Train Epoch: 1469 [81920/90000 (91%)]	Loss: -20.5891	Cost: 10.29s
Train Epoch: 1469 	Average Loss: -20.4341
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8323

Learning rate: 0.0001032457422486371
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1470 [0/90000 (0%)]	Loss: -14.8578	Cost: 40.95s
Train Epoch: 1470 [20480/90000 (23%)]	Loss: -20.8501	Cost: 10.03s
Train Epoch: 1470 [40960/90000 (45%)]	Loss: -21.2140	Cost: 12.50s
Train Epoch: 1470 [61440/90000 (68%)]	Loss: -20.6998	Cost: 9.92s
Train Epoch: 1470 [81920/90000 (91%)]	Loss: -20.7604	Cost: 9.51s
Train Epoch: 1470 	Average Loss: -20.4027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9957

Learning rate: 0.00010314107590781274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1471 [0/90000 (0%)]	Loss: -14.0682	Cost: 40.16s
Train Epoch: 1471 [20480/90000 (23%)]	Loss: -20.7243	Cost: 11.56s
Train Epoch: 1471 [40960/90000 (45%)]	Loss: -21.0344	Cost: 11.20s
Train Epoch: 1471 [61440/90000 (68%)]	Loss: -20.8085	Cost: 9.40s
Train Epoch: 1471 [81920/90000 (91%)]	Loss: -20.8674	Cost: 9.94s
Train Epoch: 1471 	Average Loss: -20.3976
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1047

Learning rate: 0.00010303640612241354
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1472 [0/90000 (0%)]	Loss: -14.5596	Cost: 45.68s
Train Epoch: 1472 [20480/90000 (23%)]	Loss: -20.8584	Cost: 9.87s
Train Epoch: 1472 [40960/90000 (45%)]	Loss: -21.2822	Cost: 12.83s
Train Epoch: 1472 [61440/90000 (68%)]	Loss: -20.9035	Cost: 10.28s
Train Epoch: 1472 [81920/90000 (91%)]	Loss: -20.9959	Cost: 12.16s
Train Epoch: 1472 	Average Loss: -20.5192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9304

Learning rate: 0.00010293173300722277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1473 [0/90000 (0%)]	Loss: -14.0103	Cost: 37.51s
Train Epoch: 1473 [20480/90000 (23%)]	Loss: -20.9614	Cost: 12.22s
Train Epoch: 1473 [40960/90000 (45%)]	Loss: -21.1977	Cost: 14.05s
Train Epoch: 1473 [61440/90000 (68%)]	Loss: -20.8744	Cost: 9.58s
Train Epoch: 1473 [81920/90000 (91%)]	Loss: -20.8501	Cost: 12.91s
Train Epoch: 1473 	Average Loss: -20.4533
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0146

Learning rate: 0.00010282705667702727
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1474 [0/90000 (0%)]	Loss: -14.6753	Cost: 35.00s
Train Epoch: 1474 [20480/90000 (23%)]	Loss: -21.0255	Cost: 11.07s
Train Epoch: 1474 [40960/90000 (45%)]	Loss: -21.2752	Cost: 13.15s
Train Epoch: 1474 [61440/90000 (68%)]	Loss: -21.0710	Cost: 11.50s
Train Epoch: 1474 [81920/90000 (91%)]	Loss: -20.9206	Cost: 9.97s
Train Epoch: 1474 	Average Loss: -20.6008
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9267

Learning rate: 0.00010272237724661746
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1475 [0/90000 (0%)]	Loss: -14.6664	Cost: 30.03s
Train Epoch: 1475 [20480/90000 (23%)]	Loss: -21.0268	Cost: 11.00s
Train Epoch: 1475 [40960/90000 (45%)]	Loss: -21.3336	Cost: 11.43s
Train Epoch: 1475 [61440/90000 (68%)]	Loss: -21.0815	Cost: 9.86s
Train Epoch: 1475 [81920/90000 (91%)]	Loss: -20.9493	Cost: 13.32s
Train Epoch: 1475 	Average Loss: -20.6162
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.1044

Learning rate: 0.00010261769483078726
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1476 [0/90000 (0%)]	Loss: -14.4614	Cost: 33.50s
Train Epoch: 1476 [20480/90000 (23%)]	Loss: -21.0262	Cost: 9.87s
Train Epoch: 1476 [40960/90000 (45%)]	Loss: -21.0726	Cost: 12.00s
Train Epoch: 1476 [61440/90000 (68%)]	Loss: -20.9255	Cost: 10.00s
Train Epoch: 1476 [81920/90000 (91%)]	Loss: -20.8606	Cost: 12.77s
Train Epoch: 1476 	Average Loss: -20.5240
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.9786

Learning rate: 0.00010251300954433369
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1477 [0/90000 (0%)]	Loss: -14.2903	Cost: 31.41s
Train Epoch: 1477 [20480/90000 (23%)]	Loss: -20.9507	Cost: 10.51s
Train Epoch: 1477 [40960/90000 (45%)]	Loss: -21.2947	Cost: 12.20s
Train Epoch: 1477 [61440/90000 (68%)]	Loss: -20.9615	Cost: 9.71s
Train Epoch: 1477 [81920/90000 (91%)]	Loss: -20.7643	Cost: 12.47s
Train Epoch: 1477 	Average Loss: -20.4648
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -15.0120

Learning rate: 0.00010240832150205703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1478 [0/90000 (0%)]	Loss: -14.2245	Cost: 29.32s
Train Epoch: 1478 [20480/90000 (23%)]	Loss: -20.9144	Cost: 10.13s
Train Epoch: 1478 [40960/90000 (45%)]	Loss: -21.3629	Cost: 11.45s
Train Epoch: 1478 [61440/90000 (68%)]	Loss: -21.0895	Cost: 10.28s
Train Epoch: 1478 [81920/90000 (91%)]	Loss: -20.7092	Cost: 11.40s
Train Epoch: 1478 	Average Loss: -20.4732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -14.8154

Learning rate: 0.00010230363081876058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1479 [0/90000 (0%)]	Loss: -15.1864	Cost: 40.56s
Train Epoch: 1479 [20480/90000 (23%)]	Loss: -20.8039	Cost: 9.74s
Train Epoch: 1479 [40960/90000 (45%)]	Loss: -21.0136	Cost: 9.97s
Train Epoch: 1479 [61440/90000 (68%)]	Loss: -20.5718	Cost: 9.66s
Train Epoch: 1479 [81920/90000 (91%)]	Loss: -20.6315	Cost: 11.21s
Train Epoch: 1479 	Average Loss: -20.3357
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.

Stopping timer.
Training time (including validation): 172558.82836961746 seconds
Saving model
Nestedspace(basis_dir='data/GW150914_sample_prior_basis/', batch_size=2048, bw_dstar=None, cuda=True, data_dir='data/GW150914_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, epochs=2000, flow_lr=None, kl_annealing=True, lr=0.0002, lr_anneal_method='cosine', lr_annealing=True, mode='train', model_dir='models/GW150914_sample_uniform_100basis_all_posterior_prior/', model_source='existing', nsample=100000, nsamples_target_event=1000, output_freq=10, sampling_from='posterior', save=True, save_aux_filename='waveforms_supplementary.hdf5', save_model_name='model.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, truncate_basis=100)
Waveform directory data/GW150914_sample_prior_basis/
Model directory models/GW150914_sample_uniform_100basis_all_posterior_prior/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from posterior prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
